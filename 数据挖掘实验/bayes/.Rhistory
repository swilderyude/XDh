###############################################
#install.packages("NLP")
#install.packages("tm")
#install.packages("wordcloud2")
#install.packages("tidytext")
#install.packages("reshape2")
#install.packages("dplyr")
#install.packages("RColorBrewer")
#install.packages("gmodels")
#install.packages("ggpol")
library(tm)
library(wordcloud2)
library(tidytext)
library(reshape2)
library(dplyr)
library(e1071)
library(ggpol)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE)
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
#2.清理语料库
#2.1 #  upper case to lower case
corpus_clean <- tm_map(sms_corpus, tolower)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,fileEncoding = 'GBK')
library(tm)
library(wordcloud2)
library(tidytext)
library(reshape2)
library(dplyr)
library(e1071)
library(ggpol)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,fileEncoding = 'GBK')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE)
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
#2.清理语料库
#2.1 #  upper case to lower case
corpus_clean <- tm_map(sms_corpus, tolower)
#2.清理语料库
#2.1 #  upper case to lower case
Encoding(sms_corpus)
corpus_clean <- tolower(sms_corpus)
# 2.2 remove numbers
corpus_clean <- tm_map(corpus_clean, removeNumbers)
library(tm)
# Create a corpus from the character vector
sms_corpus <- Corpus(VectorSource(sms_corpus))
# Preprocessing: Convert to lowercase
sms_corpus <- tm_map(sms_corpus, content_transformer(tolower))
# Create a corpus from the character vector
sms_corpus <- Corpus(VectorSource(sms_corpus))
# Preprocessing: Convert to lowercase
sms_corpus <- tm_map(sms_corpus, content_transformer(tolower))
# Check the resulting corpus
inspect(sms_corpus)
corpus_clean <- tm_map(sms_corpus, tolower)
inspect(sms_corpus[1:2])
corpus_clean <- tolower(sms_corpus)
# 2.2 remove numbers
corpus_clean <- tm_map(corpus_clean, removeNumbers)
library(tm)
library(wordcloud2)
library(tidytext)
library(reshape2)
library(dplyr)
library(e1071)
library(ggpol)
###############################################
#install.packages("NLP")
#install.packages("tm")
#install.packages("wordcloud2")
#install.packages("tidytext")
#install.packages("reshape2")
#install.packages("dplyr")
#install.packages("RColorBrewer")
#install.packages("gmodels")
#install.packages("ggpol")
library(NLP)
library(NLP)
library(tm)
library(wordcloud2)
library(tidytext)
library(reshape2)
library(dplyr)
library(e1071)
library(ggpol)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE)
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
corpus_clean <- tm_map(sms_corpus, tolower)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE)
corpus_clean <- tm_map(sms_corpus, tolower)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding="UTF-8")
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
corpus_clean <- tm_map(sms_corpus, tolower)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding="UTF-8",ileEncoding = 'GBK')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding="UTF-8",fileEncoding = 'GBK')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding="UTF-8",fileEncoding = 'GBK')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,Encoding = 'GBK')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding="UTF-8")
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
corpus_clean <- tm_map(sms_corpus, tolower)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding="GBK")
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
corpus_clean <- tm_map(sms_corpus, tolower)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,from="unknown-8bit",to="GBK")
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,from="unknown-8bit",to="UTF8")
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE，Encoding = 'GBK')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,Encoding = 'GBK')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,Encoding = "unknown-8bit")
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,Encoding = 'unknown-8bit')
str(sms_raw)#查看数据结构
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,Encoding = 'unknown-8bit')
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE)
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
##############    clean data    ############
############################################
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
corpus_clean <- tm_map(sms_corpus, tolower)
library(NLP)
library(tm)
library(wordcloud2)
library(tidytext)
library(reshape2)
library(dplyr)
library(e1071)
library(ggpol)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding = "UTF-8")
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
corpus_clean <- tm_map(sms_corpus, tolower)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE)
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
sms_corpus <- iconv(sms_corpus, to = "UTF-8")
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE)
options(encoding = "UTF-8")
corpus_clean <- tm_map(sms_corpus, tolower)
#2.清理语料库
#2.1 #  upper case to lower case
corpus_clean <- Corpus(VectorSource(sms_raw$text))
corpus <- Corpus(VectorSource(sms_corpus))
corpus_clean <- tm_map(corpus, content_transformer(tolower))
corpus_clean <- tm_map(sms_corpus, tolower)
# 2.2 remove numbers
corpus_clean <- tm_map(corpus_clean, removeNumbers)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding = "UTF-8")
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
#options(encoding = "UTF-8")
#2.清理语料库
#2.1 #  upper case to lower case
#corpus_clean <- Corpus(VectorSource(sms_raw$text))
#corpus <- Corpus(VectorSource(sms_corpus))
#corpus_clean <- tm_map(corpus, content_transformer(tolower))
corpus_clean <- tm_map(sms_corpus, tolower)
# 2.2 remove numbers
corpus_clean <- tm_map(corpus_clean, removeNumbers)
# 2.3 remove stop words, such as and,or,until...
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
# 2.4  remove Punctuations
corpus_clean <- tm_map(corpus_clean, removePunctuation)
# 2.5 remove extra spaces，使单词之间只保留一个空格
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
# 2.6 remove the useless characters
toSpace <- content_transformer(function(x,pattern) gsub(pattern,' ',x))
corpus_clean <- tm_map(corpus_clean,toSpace,'/')
# see effect
inspect(corpus_clean[1:3])
##########  create doc-word matrix   ##########
##########     wordcloud  词云图     ##########
###############################################
corpus_dtm <- TermDocumentMatrix(corpus_clean)
corpus_dtm_matrix <- as.matrix(corpus_dtm)
v <- sort(rowSums(corpus_dtm_matrix),decreasing = T)
corpus_dtm_frame <- data.frame(word=names(v),freq=v)
wordcloud2(corpus_dtm_frame, size = 0.3, shape = 'star')
#data：词云生成数据，包含具体词语以及频率；
#size：字体大小，默认为1，一般来说该值越小，
#生成的形状轮廓越明显；
#shape：词云形状选择，默认是‘circle’，
#‘cardioid’（苹果形或心形），‘diamond’，‘triangle-forward’
#‘triangle’），‘pentagon’
wordcloud2(corpus_dtm_frame, size = 0.5, fontFamily = "微软雅黑",
color = "random-light", backgroundColor = "grey")
