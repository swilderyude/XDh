#############  linear separable  ##########
###########################################
set.seed(12345)
#创建一个服从正态分布的矩阵
x<-matrix(rnorm(n=40*2,mean=0,sd=1),ncol=2,byrow=TRUE)
x
y<-c(rep(-1,20),rep(1,20))#-1重复20次，1重复20次，给出类标号。rep=replicate
y
x[y==1,]<-x[y==1,]+1.5# 对后二十个观测值加上1.5
data_train<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))  #traning data
data_train
#testing data
x<-matrix(rnorm(n=20,mean=0,sd=1),ncol=2,byrow=TRUE)
x
y<-sample(x=c(-1,1),size=10,replace=TRUE)
y
x[y==1,]<-x[y==1,]+1.5
x
data_test<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))
win.graph(width=16, height=16,pointsize=10)
plot(data_train[,1:2],col=as.integer(as.vector(data_train[,3]))+2,pch=8,cex=0.7,main="训练样本集-1和+1类散点图")
library("e1071")
#cost 用于指定C scale:b标准化
SvmFit<-svm(Fy~.,data=data_train,type="C-classification",kernel="linear",cost=10,scale=FALSE)
summary(SvmFit)
SvmFit$index#给出SV的编号
win.graph(width=16, height=16,pointsize=10)
plot(x=SvmFit,data=data_train,formula=Fx1~Fx2,svSymbol="#",dataSymbol="*",grid=100)
SvmFit<-svm(Fy~.,data=data_train,type="C-classification",kernel="linear",cost=0.1,scale=FALSE)
summary(SvmFit)
set.seed(12345)
tObj<-tune.svm(Fy~.,data=data_train,type="C-classification",kernel="linear",
cost=c(0.001,0.01,0.1,1,5,10,100,1000),scale=FALSE)
summary(tObj)
BestSvm<-tObj$best.model
summary(BestSvm)
win.graph(width=16, height=16,pointsize=10)
plot(x=BestSvm,data=data_train,formula=Fx1~Fx2,svSymbol="$",dataSymbol="*",grid=100)#等高线
yPred<-predict(BestSvm,data_test)
(ConfM<-table(yPred,data_test$Fy))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
set.seed(12345)
x<-matrix(rnorm(n=400,mean=0,sd=1),ncol=2,byrow=TRUE)
x
x[1:100,]<-x[1:100,]+2
x[101:150,]<-x[101:150,]-2
y<-c(rep(1,150),rep(2,50))
y
data<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))
data
flag<-sample(1:200,size=100)
data_train<-data[flag,]
data_test<-data[-flag,]
win.graph(width=16, height=16,pointsize=10)
plot(data_train[,1:2],col=as.integer(as.vector(data_train[,3])),pch=8,cex=0.7,main="训练样本集散点图")
#corss validation
library("e1071")
set.seed(12345)
tObj<-tune.svm(Fy~.,data=data_train,type="C-classification",kernel="radial",
cost=c(0.001,0.01,0.1,1,5,10,100,1000),gamma=c(0.5,1,2,3,4),scale=FALSE)
win.graph(width=16, height=16,pointsize=10)
plot(tObj,xlab=expression(gamma),ylab="损失惩罚参数C",
main="不同参数组合下的预测错误率",nlevels=10,color.palette=terrain.colors)
summary(tObj)
BestSvm<-tObj$best.model
summary(BestSvm)
win.graph(width=16, height=16,pointsize=10)
plot(x=BestSvm,data=data_train,formula=Fx1~Fx2,svSymbol="#",dataSymbol="*",grid=100)
yPred<-predict(BestSvm,data_test)
(ConfM<-table(yPred,data_test$Fy))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
set.seed(12345)
x<-matrix(rnorm(n=400,mean=0,sd=1),ncol=2,byrow=TRUE)
x
x[1:100,]<-x[1:100,]+2
x[101:150,]<-x[101:150,]-2
#纵向合并
x<-rbind(x,matrix(rnorm(n=100,mean=0,sd=1),ncol=2,byrow=TRUE))
y<-c(rep(1,150),rep(2,50))
y<-c(y,rep(0,50))
x[y==0,2]<-x[y==0,2]+3
data<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))
data
win.graph(width=16, height=16,pointsize=10)
plot(data[,2:1],col=as.integer(as.vector(data[,3]))+1,pch=8,cex=0.7,main="训练样本集散点图")
library("e1071")
set.seed(12345)
tObj<-tune.svm(Fy~.,data=data,type="C-classification",kernel="radial",
cost=c(0.001,0.01,0.1,1,5,10,100,1000),gamma=c(0.5,1,2,3,4),scale=FALSE)
BestSvm<-tObj$best.model
summary(BestSvm)
plot(x=BestSvm,data=data,formula=Fx1~Fx2,svSymbol="#",dataSymbol="*",grid=100)
SvmFit<-svm(Fy~.,data=data,type="C-classification",kernel="radial",cost=5,gamma=1,scale=FALSE)
#查看各观测点的决策函数值
head(SvmFit$decision.values)
yPred<-predict(SvmFit,data)
(ConfM<-table(yPred,data$Fy))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
#install.packages("kernlab")
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(iris)
irismodel <- ksvm(Species ~ ., data=iris,
type="C-bsvc", kernel="rbfdot",
kpar=list(sigma=0.1), C=10,
prob.model=TRUE) #training
irismodel
################### e1071 multiple catagories ##################
set.seed(12345)
library("e1071")
data(iris)
index = sample(2, nrow(iris), replace = TRUE, prob = c(0.7,0.3))
TrainData = iris[index == 1,]
TestData = iris[index == 2,]
model<-tune.svm(Species~.,data=TrainData,type="C-classification",kernel="radial",gamma=10^(-6:-3),cost=10^(-3:2) )
model
plot(model,xlab=expression(gamma),ylab="损失惩罚参数C",
main="不同参数组合下的预测错误率",nlevels=10,color.palette=terrain.colors)
summary(model)
BestSvm<-model$best.model
summary(BestSvm)
#predict testing data and compute confusion matrix
Pred<-predict(BestSvm,TestData)
ConfM<-table(Pred,TestData$Species)
ConfM
Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM)
Err
# predict new data
newdata<-data.frame(Sepal.Length=5, Sepal.Width=2.3, Petal.Length=3.3, Petal.Width=1)
predict(BestSvm,newdata)
Tmall_train<-read.table(file="/Users/zhao/Desktop/大三课作业/数据挖掘实验/svm/天猫_Train_1.txt",header=TRUE,sep=",")
Tmall_train$BuyOrNot<-as.factor(Tmall_train$BuyOrNot)
Tmall_train
win.graph(width=16, height=16,pointsize=10)
plot(Tmall_train[,3:4],col=as.integer(as.vector(data_train[,3]))+2,pch=8,cex=0.7,main="散点图")
set.seed(12345)
library("e1071")
tObj<-tune.svm(BuyOrNot~.,data=Tmall_train,type="C-classification",kernel="radial",gamma=10^(-6:-3),cost=10^(-3:2))
win.graph(width=16, height=16,pointsize=10)
plot(tObj,xlab=expression(gamma),ylab="损失惩罚参数C",
main="不同参数组合下的预测错误率",nlevels=10,color.palette=terrain.colors)
BestSvm<-tObj$best.model
summary(BestSvm)
Tmall_test<-read.table(file="E:/ExperimentRcodes/SVM/天猫_Test_1.txt",header=TRUE,sep=",")
Tmall_test<-read.table(file="/Users/zhao/Desktop/大三课作业/数据挖掘实验/svm/天猫_Test_1.txt",header=TRUE,sep=",")
Tmall_test$BuyOrNot<-as.factor(Tmall_test$BuyOrNot)
yPred<-predict(BestSvm,Tmall_test)
(ConfM<-table(yPred,Tmall_test$BuyOrNot))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
library(NLP)
library(tm)
library(wordcloud2)
library(tidytext)
library(reshape2)
library(dplyr)
library(e1071)
library(ggpol)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding = "UTF-8")
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
#2.清理语料库
#2.1 #  upper case to lower case
corpus_clean <- tm_map(sms_corpus, tolower)
# Remove invalid characters
sms_corpus_clean <- gsub("[^[:print:]]", "", sms_corpus)
corpus_clean <- tm_map(sms_corpus_clean, tolower)
# Remove invalid characters
sms_corpus_clean <- gsub("[^[:print:]]", "", sms_corpus)
# Create a Corpus object from the cleaned text
sms_corpus <- Corpus(VectorSource(sms_corpus_clean))
# Apply the tolower transformation using tm_map
corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
corpus_clean <- tm_map(sms_corpus, tolower)
library(NLP)
library(tm)
library(wordcloud2)
library(tidytext)
library(reshape2)
library(dplyr)
library(e1071)
library(ggpol)
###read data
sms_raw <- read.csv("/Users/zhao/Desktop/大三课作业/数据挖掘实验/bayes/sms_spam.csv",header=TRUE,stringsAsFactors=FALSE,encoding = "UTF-8")
str(sms_raw)#查看数据结构
sms_raw$type <-as.factor(sms_raw$type) ####将type设为因子变量
str(sms_raw)#查看数据结构
table(sms_raw$type)#每个类型的数量
prop.table(table(sms_raw$type))#查看每个类型的占的百分比
#1. Create 语料库corpus,文本文档的集合
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
# Remove invalid characters
sms_corpus_clean <- gsub("[^[:print:]]", "", sms_corpus)
# Create a Corpus object from the cleaned text
sms_corpus <- Corpus(VectorSource(sms_corpus_clean))
corpus_clean <- tm_map(sms_corpus, tolower)
# 2.2 remove numbers
corpus_clean <- tm_map(corpus_clean, removeNumbers)
# 2.3 remove stop words, such as and,or,until...
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
# 2.4  remove Punctuations
corpus_clean <- tm_map(corpus_clean, removePunctuation)
# 2.5 remove extra spaces，使单词之间只保留一个空格
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
# 2.6 remove the useless characters
toSpace <- content_transformer(function(x,pattern) gsub(pattern,' ',x))
corpus_clean <- tm_map(corpus_clean,toSpace,'/')
# see effect
inspect(corpus_clean[1:3])
##########  create doc-word matrix   ##########
##########     wordcloud  词云图     ##########
###############################################
corpus_dtm <- TermDocumentMatrix(corpus_clean)
corpus_dtm_matrix <- as.matrix(corpus_dtm)
v <- sort(rowSums(corpus_dtm_matrix),decreasing = T)
corpus_dtm_frame <- data.frame(word=names(v),freq=v)
wordcloud2(corpus_dtm_frame, size = 0.3, shape = 'star')
#data：词云生成数据，包含具体词语以及频率；
#size：字体大小，默认为1，一般来说该值越小，
#生成的形状轮廓越明显；
#shape：词云形状选择，默认是‘circle’，
#‘cardioid’（苹果形或心形），‘diamond’，‘triangle-forward’
#‘triangle’），‘pentagon’
wordcloud2(corpus_dtm_frame, size = 0.5, fontFamily = "微软雅黑",
color = "random-light", backgroundColor = "grey")
############## change spars matrix into the structure for bayes classifier  ###########
#为了减少特征的数量，剔除训练数据中出现在少于5条短信中或者少于记录总数的0.1%的所有词
# find the words DTM 用单词命名列,文档单词矩阵
corpus_dtm <-DocumentTermMatrix(corpus_clean)
col(corpus_dtm)
#查看行列数
dim(corpus_dtm)
# Subset the DTM using valid indices
subset_dtm <- corpus_dtm[1:10, ]  # Subset the first 10 rows
# Perform further operations on the subsetted DTM
inspect(corpus_dtm[1:10, 1200:1204])
#inspect(sms_tdm[1:10, 1200:1204])
corpus_freq_words<-findFreqTerms(corpus_dtm,5)
corpus_dtm_train <- corpus_dtm[1:4169,]
corpus_dtm_test <- corpus_dtm[4170:5571,]
#at least 5 messages include the same word
corpus_freq_words_train<-findFreqTerms(corpus_dtm_train,5)
str(corpus_freq_words_train)
corpus_freq_words_test<-findFreqTerms(corpus_dtm_test,5)
# Testing sets and training sets only contain the words that appear more than
# or equle to  5 times  过滤掉包含频率低的单词的短信
corpus_dtm_freq_train<-corpus_dtm_train[,corpus_freq_words_train]
corpus_dtm_freq_test<-corpus_dtm_test[,corpus_freq_words_test]
Tmall_train<-read.table(file="/Users/zhao/Desktop/大三课作业/数据挖掘实验/svm/天猫_Train_1.txt",header=TRUE,sep=",")
Tmall_train$BuyOrNot<-as.factor(Tmall_train$BuyOrNot)
Tmall_train
win.graph(width=16, height=16,pointsize=10)
plot(Tmall_train[,3:4],col=as.integer(as.vector(data_train[,3]))+2,pch=8,cex=0.7,main="散点图")
#############  linear separable  ##########
###########################################
set.seed(12345)
#创建一个服从正态分布的矩阵
x<-matrix(rnorm(n=40*2,mean=0,sd=1),ncol=2,byrow=TRUE)
x
y<-c(rep(-1,20),rep(1,20))#-1重复20次，1重复20次，给出类标号。rep=replicate
y
x[y==1,]<-x[y==1,]+1.5# 对后二十个观测值加上1.5
data_train<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))  #traning data
data_train
#testing data
x<-matrix(rnorm(n=20,mean=0,sd=1),ncol=2,byrow=TRUE)
x
y<-sample(x=c(-1,1),size=10,replace=TRUE)
y
x[y==1,]<-x[y==1,]+1.5
x
data_test<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))
win.graph(width=16, height=16,pointsize=10)
plot(data_train[,1:2],col=as.integer(as.vector(data_train[,3]))+2,pch=8,cex=0.7,main="训练样本集-1和+1类散点图")
library("e1071")
#cost 用于指定C scale:b标准化
SvmFit<-svm(Fy~.,data=data_train,type="C-classification",kernel="linear",cost=10,scale=FALSE)
summary(SvmFit)
SvmFit$index#给出SV的编号
win.graph(width=16, height=16,pointsize=10)
plot(x=SvmFit,data=data_train,formula=Fx1~Fx2,svSymbol="#",dataSymbol="*",grid=100)
SvmFit<-svm(Fy~.,data=data_train,type="C-classification",kernel="linear",cost=0.1,scale=FALSE)
summary(SvmFit)
set.seed(12345)
tObj<-tune.svm(Fy~.,data=data_train,type="C-classification",kernel="linear",
cost=c(0.001,0.01,0.1,1,5,10,100,1000),scale=FALSE)
summary(tObj)
BestSvm<-tObj$best.model
summary(BestSvm)
win.graph(width=16, height=16,pointsize=10)
plot(x=BestSvm,data=data_train,formula=Fx1~Fx2,svSymbol="$",dataSymbol="*",grid=100)#等高线
yPred<-predict(BestSvm,data_test)
(ConfM<-table(yPred,data_test$Fy))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
set.seed(12345)
x<-matrix(rnorm(n=400,mean=0,sd=1),ncol=2,byrow=TRUE)
x
x[1:100,]<-x[1:100,]+2
x[101:150,]<-x[101:150,]-2
y<-c(rep(1,150),rep(2,50))
y
data<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))
data
flag<-sample(1:200,size=100)
data_train<-data[flag,]
data_test<-data[-flag,]
win.graph(width=16, height=16,pointsize=10)
plot(data_train[,1:2],col=as.integer(as.vector(data_train[,3])),pch=8,cex=0.7,main="训练样本集散点图")
#corss validation
library("e1071")
set.seed(12345)
tObj<-tune.svm(Fy~.,data=data_train,type="C-classification",kernel="radial",
cost=c(0.001,0.01,0.1,1,5,10,100,1000),gamma=c(0.5,1,2,3,4),scale=FALSE)
win.graph(width=16, height=16,pointsize=10)
summary(tObj)
BestSvm<-tObj$best.model
summary(BestSvm)
win.graph(width=16, height=16,pointsize=10)
plot(x=BestSvm,data=data_train,formula=Fx1~Fx2,svSymbol="#",dataSymbol="*",grid=100)
yPred<-predict(BestSvm,data_test)
(ConfM<-table(yPred,data_test$Fy))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
set.seed(12345)
x<-matrix(rnorm(n=400,mean=0,sd=1),ncol=2,byrow=TRUE)
x
x[1:100,]<-x[1:100,]+2
x[101:150,]<-x[101:150,]-2
#纵向合并
x<-rbind(x,matrix(rnorm(n=100,mean=0,sd=1),ncol=2,byrow=TRUE))
y<-c(rep(1,150),rep(2,50))
y<-c(y,rep(0,50))
x[y==0,2]<-x[y==0,2]+3
data<-data.frame(Fx1=x[,1],Fx2=x[,2],Fy=as.factor(y))
data
win.graph(width=16, height=16,pointsize=10)
plot(data[,2:1],col=as.integer(as.vector(data[,3]))+1,pch=8,cex=0.7,main="训练样本集散点图")
library("e1071")
set.seed(12345)
tObj<-tune.svm(Fy~.,data=data,type="C-classification",kernel="radial",
cost=c(0.001,0.01,0.1,1,5,10,100,1000),gamma=c(0.5,1,2,3,4),scale=FALSE)
BestSvm<-tObj$best.model
summary(BestSvm)
plot(x=BestSvm,data=data,formula=Fx1~Fx2,svSymbol="#",dataSymbol="*",grid=100)
SvmFit<-svm(Fy~.,data=data,type="C-classification",kernel="radial",cost=5,gamma=1,scale=FALSE)
#查看各观测点的决策函数值
head(SvmFit$decision.values)
yPred<-predict(SvmFit,data)
(ConfM<-table(yPred,data$Fy))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
#install.packages("kernlab")
library(kernlab)
data(iris)
irismodel <- ksvm(Species ~ ., data=iris,
type="C-bsvc", kernel="rbfdot",
kpar=list(sigma=0.1), C=10,
prob.model=TRUE) #training
irismodel
################### e1071 multiple catagories ##################
set.seed(12345)
library("e1071")
data(iris)
index = sample(2, nrow(iris), replace = TRUE, prob = c(0.7,0.3))
TrainData = iris[index == 1,]
TestData = iris[index == 2,]
model<-tune.svm(Species~.,data=TrainData,type="C-classification",kernel="radial",gamma=10^(-6:-3),cost=10^(-3:2) )
model
plot(model,xlab=expression(gamma),ylab="损失惩罚参数C",
main="不同参数组合下的预测错误率",nlevels=10,color.palette=terrain.colors)
summary(model)
BestSvm<-model$best.model
summary(BestSvm)
#predict testing data and compute confusion matrix
Pred<-predict(BestSvm,TestData)
ConfM<-table(Pred,TestData$Species)
ConfM
Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM)
Err
# predict new data
newdata<-data.frame(Sepal.Length=5, Sepal.Width=2.3, Petal.Length=3.3, Petal.Width=1)
predict(BestSvm,newdata)
Tmall_train<-read.table(file="/Users/zhao/Desktop/大三课作业/数据挖掘实验/svm/天猫_Train_1.txt",header=TRUE,sep=",")
Tmall_train$BuyOrNot<-as.factor(Tmall_train$BuyOrNot)
Tmall_train
win.graph(width=16, height=16,pointsize=10)
plot(Tmall_train[,3:4],col=as.integer(as.vector(data_train[,3]))+2,pch=8,cex=0.7,main="散点图")
set.seed(12345)
library("e1071")
tObj<-tune.svm(BuyOrNot~.,data=Tmall_train,type="C-classification",kernel="radial",gamma=10^(-6:-3),cost=10^(-3:2))
win.graph(width=16, height=16,pointsize=10)
plot(tObj,xlab=expression(gamma),ylab="损失惩罚参数C",
main="不同参数组合下的预测错误率",nlevels=10,color.palette=terrain.colors)
BestSvm<-tObj$best.model
summary(BestSvm)
Tmall_test<-read.table(file="/Users/zhao/Desktop/大三课作业/数据挖掘实验/svm/天猫_Test_1.txt",header=TRUE,sep=",")
Tmall_test$BuyOrNot<-as.factor(Tmall_test$BuyOrNot)
yPred<-predict(BestSvm,Tmall_test)
(ConfM<-table(yPred,Tmall_test$BuyOrNot))
(Err<-(sum(ConfM)-sum(diag(ConfM)))/sum(ConfM))
