PT J
AU Marreddy, M
   Oota, SR
   Vakada, LS
   Chinni, VC
   Mamidi, R
AF Marreddy, Mounika
   Oota, Subba Reddy
   Vakada, Lakshmi Sireesha
   Chinni, Venkata Charan
   Mamidi, Radhika
TI Am I a Resource-Poor Language? Data Sets, Embeddings, Models and Analysis for four different NLP Tasks in Telugu Language
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE BERT-Te; RoBERTa-Te; ELMo-Te; resource creation; text classification; low-resource languages
ID classification; emotions
AB Due to the lack of a large annotated corpus, many resource-poor Indian languages struggle to reap the benefits of recent deep feature representations in Natural Language Processing (NLP). Moreover, adopting existing language models trained on large English corpora for Indian languages is often limited by data availability, rich morphological variation, syntax, and semantic differences. In this paper, we explore the traditional to recent efficient representations to overcome the challenges of a low resource language, Telugu. In particular, our main objective is to mitigate the low-resource problem for Telugu. Overall, we present several contributions to a resource-poor language viz. Telugu. (i) a large annotated data (35,142 sentences in each task) for multiple NLP tasks such as sentiment analysis, emotion identification, hate-speech detection, and sarcasm detection, (ii) we create different lexicons for sentiment, emotion, and hate-speech for improving the efficiency of the models, (iii) pretrained word and sentence embeddings, and (iv) different pretrained language models for Telugu such as ELMo-Te, BERT-Te, RoBERTa-Te, ALBERT-Te, and DistilBERT-Te on a large Telugu corpus consisting of 8,015,588 sentences (1,637,408 sentences from TeluguWikipedia and 6,378,180 sentences crawled from different Telugu websites). Further, we show that these representations significantly improve the performance of four NLP tasks and present the benchmark results for Telugu. We argue that our pretrained embeddings are competitive or better than the existing multilingual pretrained models: mBERT, XLM-R, and IndicBERT. Lastly, the fine-tuning of pretrained models show higher performance than linear probing results on four NLP tasks with the following F1-scores: Sentiment (68.72), Emotion (58.04), Hate-Speech (64.27), and Sarcasm (77.93). We also experiment on publicly available Telugu datasets (Named Entity Recognition, Article Genre Classification, and Sentiment Analysis) and find that our Telugu pretrained language models (BERT-Te and RoBERTa-Te) outperform the state-of-the-art system except for the sentiment task. We open-source our corpus, four different datasets, lexicons, embeddings, and code https://github.com/Cha14ran/DREAM- T. The pretrained Transformer models for Telugu are available at https://huggingface.co/ltrctelugu.
C1 [Marreddy, Mounika; Oota, Subba Reddy; Vakada, Lakshmi Sireesha; Chinni, Venkata Charan; Mamidi, Radhika] IIITH, Prof CR Rao Rd, Hyderabad, Telengana, India.
C3 International Institute of Information Technology Hyderabad
RP Marreddy, M (通讯作者)，IIITH, Prof CR Rao Rd, Hyderabad, Telengana, India.
EM marreddy@research.iiit.ac.in; oota.subba@students.iiit.ac.in; lakshmi.sireesha@research.iiit.ac.in; venkata.charan@students.iiit.ac.in; radhika.mamidi@iiit.ac.in
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Amir S, 2016, ARXIV, V0, P0
   [Anonymous], 2010, P CONLL, V0, P0
   [Anonymous], 2008, EMNLP, V0, P0
   [Anonymous], 2012, P 2012 JOINT C EMPIR, V0, P0
   [Anonymous], 2007, P 45 ANN M ACL INTER, V0, P0
   [Anonymous], 2017, ADV NEURAL INFORM PR, V0, P0
   Arulmozi S, 2017, WORDNET INDIAN LANGU, V0, P201
   Barbieri F, 2014, P 5 WORKSHOP COMPUTA, V0, P50~58
   Bhowmick PK, 2009, LECT NOTES COMPUT SC, V5909, P261, DOI 10.1007/978-3-642-11164-8_42
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Brill E, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, P257
   Burnap P, 2015, POLICY INTERNET, V7, P223, DOI 10.1002/poi3.85
   Burnap P, 2016, EPJ DATA SCI, V5, P0, DOI 10.1140/epjds/s13688-016-0072-6
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen Ying, 2010, P CCF INT C NAT LANG, V0, P179
   Chen ZY, 2018, ARXIV, V0, P0
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Choudhary N, 2018, ARXIV, V0, P0
   Chung JY, 2014, ARXIV, V0, P0
   Cohn Trevor, 2005, SEMANTIC ROLE LABELL, V0, P0
   Das A, 2010, P 8 WORKSHOP ASIAN L, V0, P56
   Devlin J, 2018, ARXIV, V1, P4171
   Devlin Jacob, 2018, MULTILINGUAL BERT R, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Esuli A, 2006, P 5 INT C LANG RES E, V5, P417, DOI 10.1155/2015/715730
   Felbo B, 2017, ARXIV, V0, P0
   Gangula Rama Rohit Reddy, 2018, P 11 INT C LANGUAGE, V0, P0
   Gitari ND, 2015, INT J MULTIMEDIA UBI, V10, P215, DOI 10.14257/IJMUE.2015.10.4.21
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hadiwinoto C, 2019, ARXIV, V0, P0
   Heinzerling B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P2989
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, V0, P755
   Joshi A, 2016, ARXIV161000883, V0, P0
   Joshi A, 2017, ACM COMPUT SURV, V50, P0, DOI 10.1145/3124420
   Joulin A, 2016, ARXIV, V0, P0
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, V0, P4948
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim Hae-Young, 2014, RESTOR DENT ENDOD, V39, P74, DOI 10.5395/rde.2014.39.1.74
   Kim S, 2004, P 20 INT C COMP LING, V0, PP1367, DOI 10.3115/1220355.1220555
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V0, PP3294, DOI 10.5555/2969442.2969607
   Kshirsagar R, 2018, ARXIV, V0, P0
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G, 2019, ARXIV, V0, P0
   Lan ZZ, 2020, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Mohammad SM, 2013, ARXIV, V0, P0
   Marreddy M, 2021, 2021 INT JOINT C NEU, V0, P1
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mohammad SM, 2010, P NAACL HLT 2010 WOR, V0, P0
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Moilanen Karo, 2007, SENTIMENT COMPOSITIO, V0, P0
   Mukku SS, 2017, P 1 WORKSHOP BUILDIN, V0, P54
   Mukku SS, 2017, LECT NOTES COMPUT SC, V10440, P355, DOI 10.1007/978-3-319-64283-3_26
   Nobata C, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16), V0, PP145, DOI 10.1145/2872427.2883062
   Pang B, 2005, P ACL, V0, PP115, DOI 10.3115/1219840.1219855
   Parupalli S, 2018, ARXIV, V0, P0
   Parupalli Sreekavitha, 2018, P ACL 2018 STUDENT R, V0, P99
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.28.739
   Qian Q, 2016, ARXIV, V0, P0
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ramos J, 2003, P 1 INSTR C MACH LEA, VVolume 242, P29
   Reagan AJ, 2016, EPJ DATA SCI, V5, P0, DOI 10.1140/epjds/s13688-016-0093-1
   Riloff Ellen, 2013, EMNLP, V0, P0
   Ruxton GD, 2008, BEHAV ECOL, V19, P690, DOI 10.1093/beheco/arn020
   Sanh V, 2020, ARXIV, V0, P0
   Sharma R, 2017, P 2017 C EMPIRICAL M, V0, P547
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Stieglitz S, 2013, J MANAGE INFORM SYST, V29, P217, DOI 10.2753/MIS0742-1222290408
   Suarez Pedro Javier Ortiz, 2019, 7THWORKSHOP CHALLENG, V0, P0
   SWIER R, 2005, P HUM LANG TECHN C C, V0, P883
   Tang D, 2015, EMNLP, V0, P0, DOI DOI 10.18653/v1/D15-1167
   Tokuhisa R, 2008, P 22 INT C COMP LING, V1, P881, DOI 10.3115/1599081.1599192
   Tummalapalli Madhuri, 2018, P INT C COMPUTATIONA, V0, P0
   Varshit Battu, 2018, P INT C PATTERN RECO, V0, P148
   Wallach HM, 2006, P 23 INT C MACH LEAR, V23, P977, DOI 10.1145/1143844.1143967
   Waseem Zeerak, 2016, P NAACL STUD RES WOR, V0, PP88, DOI 10.18653/V1/N16-2013
   Wilson Theresa, 2005, P HUMAN LANGUAGE TEC, V0, PP347, DOI 10.3115/1220575.1220619
   Wu SJ, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P120
   Xiong CM, 2018, ARXIV, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yen SJ, 2006, LECT NOTES CONTR INF, V344, P731
   Yessenalina A, 2010, P 2010 C EMP METH NA, V0, P1046
   Yin WP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1351
   Yu HF, 2011, MACH LEARN, V85, P41, DOI 10.1007/s10994-010-5221-8
   Yu L-C, 2017, EMNLP, V0, PP534, DOI 10.18653/V1/D17-1056
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
   Zhang Meishan, 2016, COLING, V0, P0
   Zhang X, 2015, ADV NEUR IN, V28, P0
   Zhang ZQ, 2018, LECT NOTES COMPUT SC, V10843, P745, DOI 10.1007/978-3-319-93417-4_48
   Zhao Han, 2015, P 24 INT JOINT C ART, V0, P0
   Zhou D, 2016, C EMP METH NAT LANG, V0, P638
   Zhou P, 2016, ARXIV, V0, P0
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 98
TC 1
Z9 1
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JAN 15
PY 2023
VL 22
IS 1
BP 
EP 
DI 10.1145/3531535
PG 34
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9D8QE
UT WOS:000936360700002
DA 2023-11-10
ER

PT J
AU An, B
AF An, Bo
TI Prompt-based for Low-Resource Tibetan Text Classification
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Tibetan text classification; prompt learning; deep learning; pre-trained language model
AB Text classification is a critical and foundational task in Tibetan natural language processing, it plays a crucial role in various applications, such as sentiment analysis and information extraction. However, the limited availability of annotated data poses a significant challenge to Tibetan natural language processing. This paper proposes a prompt learning-based method for low-resource Tibetan text classification to overcome this challenge. This method utilizes pre-trained language models to learn text representation and generation capabilities on a large-scale unsupervised Tibetan corpus, enabling few-shot Tibetan text classification. Experimental results demonstrate that the proposed method significantly improves the performance of Tibetan text classification in low-resource scenarios. This work provides a new research idea and method for low-resource language processing, such as Tibetan natural language processing. Hopefully, it will inspire subsequent work on low-resource language processing.
C1 [An, Bo] Chinese Acad Social Sci, Inst Ethnol & Anthropol, South Tweenty 7 St,Bldg 6,Zhongguancun Nandajie 2, Beijing, Beijing, Peoples R China.
C3 Chinese Academy of Social Sciences
RP An, B (通讯作者)，Chinese Acad Social Sci, Inst Ethnol & Anthropol, South Tweenty 7 St,Bldg 6,Zhongguancun Nandajie 2, Beijing, Beijing, Peoples R China.
EM anbo@cass.org.cn
FU National Social Science Foundation of China [22BTQ010]; National Natural Science Foundation of China [62076233]; Innovation Project major research of Chinese Academy of Social Sciences [2022MZSQN001]
CR An Bo, 2022, J CHINESE INFORM PRO, V0, P0
   Brauwers G, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3503044
   Cai JJ, 2018, I COMP CONF WAVELET, V0, PP123, DOI 10.1109/ICCWAMTIP.2018.8632592
   Cao H, 2013, INT CONF ASIAN LANG, V0, PP220, DOI 10.1109/IALP.2013.63
   Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334
   Constant N, 2020, ARXIV, V0, P0
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Cun YZ, 2010, MOL PHYLOGENET EVOL, V56, P972, DOI 10.1016/j.ympev.2010.05.007
   Grave E, 2018, ARXIV, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu YX, 2022, ARXIV, V0, P0
   Han Kai, 2021, ADV NEURAL INFORM PR, V34, P15908
   Hill Nathan W, 2016, HIMALAYAN LINGUISTIC, V15, P1
   Ilic S, 2018, ARXIV, V0, P0
   Jia Hongyun, 2019, THESIS TIBET U, V0, P0
   Jia Huiqiang, 2010, GUIDE BECOMING RICH, V4X, P30
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Li Ailin, 2014, THESIS NW U NATL, V0, P0
   Li Jia, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND ELECTROMECHANICAL AUTOMATION (AIEA), V0, PP27, DOI 10.1109/AIEA51086.2020.00013
   Li ZS, 2019, INT CONF ASIAN LANG, V0, PP379, DOI 10.1109/IALP48816.2019.9037706
   [刘汇丹 Liu Huidan], 2012, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V26, P97
   Liu Huidan, 2012, 24 INT C COMP LING, V11, P0
   Liu P, 2021, ARXIV, V0, P0
   Lu Y, 2022, PREPRINT, V0, P0
   Ma Wei, 2019, 3 INT C COMPUTER ENG, V0, P374
   Minaee S, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3439726
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Oyedare T, 2019, IEEE INT SYMP DYNAM, V0, PP41, DOI 10.1109/dyspan.2019.8935823
   Qin XF, 2019, IEEE INT SYMP DYNAM, V0, PP440, DOI 10.1109/dyspan.2019.8935805
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Qun N, 2017, LECT NOTES ARTIF INT, V10565, P472, DOI 10.1007/978-3-319-69005-6_39
   Nguyen DQ, 2020, ARXIV, V0, P0
   Salazar J, 2021, ARXIV, V0, P0
   Sun BW, 2018, 2018 INTERNATIONAL CONFERENCE ON AUDIO, V0, P109, DOI 10.1109/ICALIP.2018.8455328
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang YQ, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3386252
   Wang Yong, 2013, THESIS NW U NATL, V0, P0
   Wei Yan, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1848, P0, DOI 10.1088/1742-6596/1848/1/012139
   Wright RE, 1995, READING UNDERSTANDIN, V0, P0
   [胥桂仙 XU Guixian], 2011, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V25, P20
   Xu Guixian, 2022, DATA ANAL KNOWLEDGE, V0, P1
   Yang Hongwu, 2020, J NANJING U POSTS TE, V0, P0
   Yang Ziqing, 2022, P 29 INT C COMPUTATI, V0, P3937
   Yao L, 2019, AAAI CONF ARTIF INTE, V0, P7370
   Yuan Bin, 2016, THESIS NW U NATL, V0, P0
NR 46
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG 15
PY 2023
VL 22
IS 8
BP 
EP 
DI 10.1145/3603168
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q7NS7
UT WOS:001059361200005
DA 2023-11-10
ER

PT J
AU Zou, A
   Hao, WN
   Jin, DW
   Chen, G
   Sun, FY
AF Zou, Ao
   Hao, Wenning
   Jin, Dawei
   Chen, Gang
   Sun, Feiyan
TI MoCoUTRL: a momentum contrastive framework for unsupervised text representation learning
SO CONNECTION SCIENCE
LA English
DT Article
DE Natural language processing; text representation learning; momentum contrast; alignment; uniformity
AB This paper presents MoCoUTRL: a Momentum Contrastive Framework for Unsupervised Text Representation Learning. This model improves two aspects of recently popular contrastive learning algorithms in natural language processing (NLP). Firstly, MoCoUTRL employs multi-granularity semantic contrastive learning objectives, enabling a more comprehensive understanding of the semantic features of samples. Secondly, MoCoUTRL uses a dynamic dictionary to act as the approximately ground-truth representation for each token, providing the pseudo labels for token-level contrastive learning. The MoCoUTRL can extend the use of pre-trained language models (PLM) and even large-scale language models (LLM) into a plug-and-play semantic feature extractor that can fuel multiple downstream tasks. Experimental results on several publicly available datasets and further theoretical analysis validate the effectiveness and interpretability of the proposed method in this paper.
C1 [Zou, Ao; Hao, Wenning; Jin, Dawei; Chen, Gang; Sun, Feiyan] Army Engn Univ PLA, Command & Control Engn Coll, Nanjing, Peoples R China.
   [Sun, Feiyan] Jinling Inst Technol, Nanjing, Peoples R China.
C3 Army Engineering University of PLA; Jinling Institute of Technology
RP Hao, WN (通讯作者)，Army Engn Univ PLA, Command & Control Engn Coll, Nanjing, Peoples R China.
EM hwnbox@aeu.edu.cn
FU Defense Industrial Technology Development Program [JCKY2020601B018]
CR Bachman P, 2019, ADV NEUR IN, V32, P0
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Carlsson F, 2021, SEMANTIC RE TUNING C, V0, P21
   Caron Mathilde, 2020, ADV NEURAL INFORM PR, V3, P0, DOI 10.5555/3495724.3496555
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chowdhery A, 2022, ARXIV, V0, P0
   Chuang Y-S, 2022, P 2022 C N AM CHAPT, V0, P0
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, ARXIV, V0, P0
   Dosovitskiy Alexey, 2014, NEURIPS, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6894
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   Grill J-B, 2020, ADV NEURAL INFORM PR, V0, P21271
   Hadsell Raia, 2006, 2006 IEEE COMPUTER S, V2, P1735
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   He KM, 2022, PROC CVPR IEEE, V0, PP15979, DOI 10.1109/CVPR52688.2022.01553
   He Pengcheng, 2020, ARXIV200603654, V0, P0
   Hill Felix, 2016, P NAACL HLT, V0, PP1367, DOI 10.18653/V1/N16-1162
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI 10.1109/69.917563
   Hjelm RD, 2019, LEARNING DEEP REPRES, V0, P24
   Kaiming He, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9726, DOI 10.1109/CVPR42600.2020.00975
   Kitaev Nikita, 2020, ARXIV200104451, V0, P0
   Kong L, 2019, INT C LEARNING REPRE, V0, P0
   Kowsari K, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP364, DOI 10.1109/ICMLA.2017.0-134
   Lan Z, 2020, ALBERT LITE BERT SEL, V0, P17
   Lee SY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5969
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li BH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9119
   LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2013, ARXIV, V0, P0
   Oquab M, 2014, PROC CVPR IEEE, V0, PP1717, DOI 10.1109/CVPR.2014.222
   Paszke A, 2019, ARXIV, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qian J, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P2912
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Keskar NS, 2019, ARXIV, V0, P0
   Su Jianlin, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2103.15316
   Touvron H, 2023, ARXIV, V0, P0
   van den Oord A, 2019, ARXIV, V0, P0
   Wang T, 2020, PROC INT C MACH LEAR, V0, P9929
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
   Zhuang Liu, 2021, CHINESE COMPUTATIONAL LINGUISTICS: 20TH CHINA NATIONAL CONFERENCE, V0, Proceedings. Lecture Notes in Computer Science
   2023, 1900, DOI ARXIV:2303.08774, V0, P0
NR 52
TC 0
Z9 0
U1 5
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0954-0091
EI 1360-0494
J9 CONNECT SCI
JI Connect. Sci.
PD DEC 31
PY 2023
VL 35
IS 1
BP 
EP 
DI 10.1080/09540091.2023.2221406
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA J1AA5
UT WOS:001006989400001
DA 2023-11-10
ER

PT J
AU Baker, O
   Montefinese, M
   Castro, N
   Stella, M
AF Baker, Oliver
   Montefinese, Maria
   Castro, Nichol
   Stella, Massimo
TI Multiplex lexical networks and artificial intelligence unravel cognitive patterns of picture naming in people with anomic aphasia
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Artificial general intelligence; Cognitive networks; Cognitive modelling; Aphasia; Multiplex networks
ID spreading activation theory; access
AB Aphasia is a language disorder which impairs people's ability to comprehend or produce words. The mechanisms behind this disorder are not yet fully understood mainly because of the challenge of interpreting them through large-scale quantitative models. To this aim, we use artificial intelligence and knowledge graphs to investigate picture naming in people affected by anomic aphasia. Our knowledge graphs encode four aspects of associative knowledge: free word associations, synonyms, generalisations and phonological similarities. We then use these networks to compute features of target words and mistakes in producing them as recorded in a psychological mega-study with 31700 utterances. Adopting a human-centric AI approach, we train an artificial general intelligence (AGI) to predict the type of mistake (formal, semantic or mixed) according to network distances and individual level psychological norms. Our results reveal some key relationships between the multiplex structure and the errors made: (i) Network distance is found to be predictive of the error type but only when considered independently across each layer (accuracy: 73.3%, precision: 74.1%, recall 70.9%); (ii) The most predictive model is achieved when closeness centrality, rather than other psychological norms is added to the four network distances (accuracy: 80.9%, precision: 80.1%, recall 79.7%). We find that the ability to predict different types of mistakes crucially depends on the presence or absence of different aspects of knowledge in the network. In particular, removing free associations damages predictions of all mistakes the most. This indicates the importance of free associations in driving picture naming.
C1 [Baker, Oliver] Univ Exeter, Dept Comp Sci, Exeter, England.
   [Montefinese, Maria] IRCCS San Camillo Hosp, Venice, Italy.
   [Castro, Nichol] Univ Buffalo, Dept Commun Disorders & Sci, Adult Language Network Lab, Buffalo, NY USA.
   [Stella, Massimo] Univ Trento, Dept Psychol & Cognit Sci, Rovereto, Italy.
C3 University of Exeter; IRCCS Ospedale San Camillo; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; University of Trento
RP Stella, M (通讯作者)，Univ Trento, Dept Psychol & Cognit Sci, Rovereto, Italy.
EM massimo.stella-1@unitn.it
FU Italian Ministry of Health [GR-2019-12371166]
CR Aitchison J, 2012, WORDS MIND INTRO MEN, V4th Edn, P0
   Alario FX, 2000, Q J EXP PSYCHOL-A, V53, P741, DOI 10.1080/027249800410535
   ANDERSON JR, 1983, J VERB LEARN VERB BE, V22, P261, DOI 10.1016/S0022-5371(83)90201-3
   Aroef C, 2020, TELKOMNIKA, V18, P815, DOI 10.12928/TELKOMNIKA.v18i2.14785
   Best W, 1996, COGNITIVE NEUROPSYCH, V13, P443, DOI 10.1080/026432996381971
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   BROWN AS, 1991, PSYCHOL BULL, V109, P204, DOI 10.1037/0033-2909.109.2.204
   Castro N, 2020, COGNITIVE SCI, V44, P0, DOI 10.1111/cogs.12881
   Castro N, 2020, P ROY SOC A-MATH PHY, V476, P0, DOI 10.1098/rspa.2019.0825
   Castro N, 2019, J COMPLEX NETW, V7, P913, DOI 10.1093/comnet/cnz012
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407
   De Deyne S, 2019, BEHAV RES METHODS, V51, P987, DOI 10.3758/s13428-018-1115-7
   DeDomenico M, 2022, MULTILAYER NETWORKS, V0, P0
   Dell GS, 2014, OXFORD HDB LANGUAGE, V0, PP88, DOI 10.1093/OXFORDHB/9780199735471.013.014
   Dell GS, 2015, BLACKW HBK LINGUIST, V0, P559
   DELL GS, 1992, COGNITION, V42, P287, DOI 10.1016/0010-0277(92)90046-K
   Dell GS, 1997, PSYCHOL REV, V104, P801, DOI 10.1037/0033-295X.104.4.801
   Doczi B, 2019, ROUTLEDGE HDB VOCABU, V0, P46
   Goertzel Ben, 2014, JOURNAL OF ARTIFICIAL GENERAL INTELLIGENCE, V5, P1, DOI 10.2478/jagi-2014-0001
   Goldstein R, 2017, FRONT PSYCHOL, V8, P0, DOI 10.3389/fpsyg.2017.01683
   Hegde MN, 2022, COURSEBOOK APHASIA O, V0, P0
   Johansson MB, 2012, INT J LANG COMM DIS, V47, P144, DOI 10.1111/j.1460-6984.2011.00089.x
   Katz RC, 2000, INT J LANG COMM DIS, V35, P303
   Kenett YN, 2017, J EXP PSYCHOL LEARN, V43, P1470, DOI 10.1037/xlm0000391
   Kumar AA, 2020, J EXP PSYCHOL LEARN, V46, P2261, DOI 10.1037/xlm0000793
   Levy O, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-93925-y
   Litovsky CP, 2022, NEUROPSYCHOLOGIA, V170, P0, DOI 10.1016/j.neuropsychologia.2022.108235
   Longe JL, 2015, GALE ENCY MED, V0, P0
   Mayer M, 2021, MISSRANGER FAST IMPU, V0, P0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Molnar C, 2020, INTERPRETABLE MACHIN, V0, P0
   Montefinese M, 2021, PSYCHOPHYSIOLOGY, V58, P0, DOI 10.1111/psyp.13750
   Montefinese M, 2019, J NEUROPHYSIOL, V121, P1585, DOI 10.1152/jn.00065.2019
   Nardo D, 2017, BRAIN, V140, P3039, DOI 10.1093/brain/awx234
   Newman M, 2010, NETWORKS INTRO, V0, P0, DOI DOI 10.1093/acprof:oso/9780199206650.001.0001
   Osisanwo FY, 2017, INT J COMPUT TRENDS, V48, P128, DOI 10.14445/22312803/IJCTT-V48P126
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pirrelli V, 2020, WORD KNOWLEDGE WORD, V337, P0
   Quispe LVC, 2021, PHYSICA A, V562, P0, DOI 10.1016/j.physa.2020.125344
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Roach A, 1996, CLIN APHASIOLOGY, V24, P121, DOI 10.1037/T56477-000
   Siew CSQ, 2019, COMPLEXITY, V2019, P0, DOI 10.1155/2019/2108423
   Stella M, 2022, ARXIV, V0, P0
   Stella M, 2020, PHYSICA A, V554, P0, DOI 10.1016/j.physa.2020.124382
   Stella M, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-20730-5
   Stella M, 2017, SCI REP-UK, V7, P0, DOI 10.1038/srep46730
   Steyvers M, 2005, COGNITIVE SCI, V29, P41, DOI 10.1207/s15516709cog2901_3
   Van Rensbergen B, 2015, PSYCHON B REV, V22, P1717, DOI 10.3758/s13423-015-0832-5
   Vitevitch MS, 2014, YB POZNAN LINGUISTIC, V1, P0
   Vitevitch MS, 2019, NETWORK SCI COGNITIV, V0, P0
   Vukic D, 2020, COMPLEXITY, V2020, P0, DOI 10.1155/2020/9407162
   Zhou Y, 2022, MACH LEARN, V111, P345, DOI 10.1007/s10994-021-06056-w
   Zock M, 2020, J COGN SCI, V21, P193
NR 53
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-4366
EI 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD JUN 15
PY 2023
VL 79
IS 
BP 43
EP 54
DI 10.1016/j.cogsys.2023.01.007
EA JAN 2023
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology, Experimental
SC Computer Science; Neurosciences & Neurology; Psychology
GA I4JG5
UT WOS:001002453600001
DA 2023-11-10
ER

PT J
AU Zhang, PF
   Chai, TT
   Xu, YD
AF Zhang, Pengfei
   Chai, Tingting
   Xu, Yongdong
TI Adaptive Prompt Learning-Based Few-Shot Sentiment Analysis
SO NEURAL PROCESSING LETTERS
LA English
DT Article; Early Access
DE Natural language processing; Sentiment analysis; Adaptive prompt learning; Seq2seq-attention
AB In the field of natural language processing, sentiment analysis via deep learning has a excellent performance by using large labeled datasets. Meanwhile, labeled data are insufficient in many sentiment analysis tasks, and obtaining these data is time-consuming and laborious. Prompt learning devotes to resolving the data deficiency by reformulating downstream tasks with the help of prompt. The model performance of this method depends on the quality of the prompt. This paper proposes an adaptive prompting (AP) construction strategy using seq2seq-attention structure to acquire the semantic information of the input sequence. Our method of dynamically constructing adaptive prompts can not only improve the quality of prompt, but also can effectively generalize to other fields by constructing a pre-trained prompt with existing public labeled data. The experimental results on FewCLUE datasets demonstrate that the proposed method AP can effectively construct appropriate adaptive prompt regardless of the quality of hand-crafted prompt and outperform the state-of-the-art baselines.
C1 [Zhang, Pengfei; Chai, Tingting; Xu, Yongdong] Harbin Inst Technol WeiHai, Sch Comp Sci & Technol, 2 WenHuaXi Rd, Weihai 264209, Shandong, Peoples R China.
C3 Harbin Institute of Technology
RP Xu, YD (通讯作者)，Harbin Inst Technol WeiHai, Sch Comp Sci & Technol, 2 WenHuaXi Rd, Weihai 264209, Shandong, Peoples R China.
EM ydxu@hit.edu.cn
CR Araci D, 2019, ARXIV, V0, P0
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   Bai X, 2022, P IEEE CVF C COMP VI, V0, P1090
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Cai Y, 2019, INT J MACH LEARN CYB, V10, P2131, DOI 10.1007/s13042-017-0757-6
   Chen J, 2021, NEURAL PROCESS LETT, V53, P2095, DOI 10.1007/s11063-021-10423-y
   Chen MR, 2019, IEEE INTERNET THINGS, V6, P6997, DOI 10.1109/JIOT.2019.2913176
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Devlin J, 2019, ARXIV, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   Farahani M, 2021, NEURAL PROCESS LETT, V53, P3831, DOI 10.1007/s11063-021-10528-4
   Feldman J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1173
   Gao T, 2021, ARXIV, V0, P0
   Jiang F, 2015, J COMPUT SCI TECH-CH, V30, P1120, DOI 10.1007/s11390-015-1587-1
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Lafferty J, 2001, P INT C MACHINE LEAR, V0, P0
   Lan ZZ, 2020, ARXIV, V0, P0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li D, 2021, IEEE T VIS COMPUT GR, V0, P0
   Li G, 2020, NEURAL PROCESS LETT, V51, P0
   Li J, 2016, NEUROCOMPUTING, V210, P247, DOI 10.1016/j.neucom.2016.03.088
   Liu P, 2021, ARXIV, V0, P0
   Liu X, 2021, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Lu KD, 2021, IEEE T IND INFORM, V17, P7618, DOI 10.1109/TII.2021.3053304
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Petroni F, 2019, ARXIV, V0, P0
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Sadr H, 2019, NEURAL PROCESS LETT, V50, P2745, DOI 10.1007/s11063-019-10049-1
   Schick T, 2021, ARXIV, V0, P0
   TONG RM, 2001, P WORKSH OP TEXT CLA, V0, P0
   Wang SN, 2021, ARXIV, V0, P0
   Wiebe J, 1999, P 37 ANN M ASS COMP, V0, PP246, DOI 10.3115/1034678.1034721
   Xu Liang, 2021, ARXIV, V0, P0
   Xue Y, 2014, INT C HLTH INF SCI, V0, P0
   Yu ZW, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), V0, PP339, DOI 10.1109/SmartCity.2015.94
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
NR 37
TC 0
Z9 0
U1 12
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s11063-023-11259-4
EA MAR 2023
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA A9YQ6
UT WOS:000958603600001
DA 2023-11-10
ER

PT J
AU Baykara, B
   Güngör, T
AF Baykara, Batuhan
   Gungor, Tunga
TI Turkish abstractive text summarization using pretrained sequence-to-sequence models
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Abstractive text summarization; News title generation; Pretrained sequence-to-sequence models
AB The tremendous amount of increase in the number of documents available on the Web has turned finding the relevant piece of information into a challenging, tedious, and time-consuming activity. Accordingly, automatic text summarization has become an important field of study by gaining significant attention from the researchers. Lately, with the advances in deep learning, neural abstractive text summarization with sequence-to-sequence (Seq2Seq) models has gained popularity. There have been many improvements in these models such as the use of pretrained language models (e.g., GPT, BERT, and XLM) and pretrained Seq2Seq models (e.g., BART and T5). These improvements have addressed certain shortcomings in neural summarization and have improved upon challenges such as saliency, fluency, and semantics which enable generating higher quality summaries. Unfortunately, these research attempts were mostly limited to the English language. Monolingual BERT models and multilingual pretrained Seq2Seq models have been released recently providing the opportunity to utilize such state-of-the-art models in low-resource languages such as Turkish. In this study, we make use of pretrained Seq2Seq models and obtain state-of-the-art results on the two large-scale Turkish datasets, TR-News and MLSum, for the text summarization task. Then, we utilize the title information in the datasets and establish hard baselines for the title generation task on both datasets. We show that the input to the models has a substantial amount of importance for the success of such tasks. Additionally, we provide extensive analysis of the models including cross-dataset evaluations, various text generation options, and the effect of preprocessing in ROUGE evaluations for Turkish. It is shown that the monolingual BERT models outperform the multilingual BERT models on all tasks across all the datasets. Lastly, qualitative evaluations of the generated summaries and titles of the models are provided.
C1 [Baykara, Batuhan; Gungor, Tunga] Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.
C3 Bogazici University
RP Baykara, B (通讯作者)，Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.
EM batuhan.baykara@boun.edu.tr
CR Altan, 2004, IASTED INT C AIA, V0, P0
   Baykara B, 2022, LANG RESOUR EVAL, V56, P973, DOI 10.1007/s10579-021-09568-y
   Bostrom Kaj, 2020, ARXIV200403720, V0, P0
   Celikyilmaz A, 2018, P 2018 C N AM CHAPT, V1, P1662, DOI 10.18653/V1/N18-1150
   Chan B, 2020, ABS201010906 CORR, V0, P0
   Chopra S, 2016, P 2016 C N AM ASS CO, V0, P93
   Cigir C, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, V0, P223
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong L, 2019, ADV NEUR IN, V32, P0
   EDMUNDSON HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Guran A, 2011, 2011 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2011), V0, PP480, DOI 10.1109/INISTA.2011.5946121
   Güran A, 2013, TURK J ELECTR ENG CO, V21, P1411, DOI 10.3906/elk-1201-15
   Hermann KM, 2015, P 28 INT C NEURAL IN, V1, P0
   Hu JJ, 2020, PR MACH LEARN RES, V119, P0
   Kartal Yavuz Selim, 2020, 2020 28TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE (SIU). PROCEEDINGS, V0, P0, DOI DOI 10.1109/SIU49456.2020.9302096
   Kingma DP, 2014, C TRACK P, V0, P0
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Kuratov Y, 2019, ABS190507213 CORR, V0, P0
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3730
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Nallapati R, 2017, P 31 AAAI C ARTIFICI, V0, P3075 3081
   Narayan S, 2018, P 2018 C N AM CHAPT, V1, P1747, DOI 10.18653/V1/N18-1158
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Ng A, 2014, CS229 LECT NOTES, V0, P1
   Oflazer K, 2014, LANG RESOUR EVAL, V48, P639, DOI 10.1007/s10579-014-9267-2
   Paulus Romain, 2018, 6 INT C LEARN REPR I, V0, P0
   Pembe FC, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, V0, P279
   Polignano M, 2019, CEUR WORKSHOP PROC, VVolume 2481, P1
   Qi Weizhen, 2020, FINDINGS ASS COMPUTA, V0, PP2401, DOI 10.18653/v1/2020.findingsemnlp.217
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI 10.1162/tacl_a_.00313
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Rust P, 2020, ABS201215613 CORR, V0, P0
   Scialom T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8051
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Shazeer N, 2018, PR MACH LEARN RES, V80, P0
   Song K, 2019, INT C MACHINE LEARNI, V0, P5926 5936
   TorresMoreno JM, 2014, WILEY-ISTE, V0, P0, DOI DOI 10.1002/9781119004752
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Virtanen A, 2019, ABS191207076 CORR, V0, P0
   Wenzek G, 2020, P 12 LANGUAGE RESOUR, V0, P4003 4012
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Xue L, 2021, ARXIV ABS201011934, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang Jingqing, 2020, P INT C MACH LEARN, V0, PP11328, DOI 10.1038/S41746-021-00437-0
NR 57
TC 1
Z9 1
U1 4
U2 14
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD SEP 15
PY 2023
VL 29
IS 5
BP 1275
EP 1304
DI 10.1017/S1351324922000195
EA MAY 2022
PG 30
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA R2BC5
UT WOS:000794381000001
DA 2023-11-10
ER

PT J
AU Haghiri, S
   Yahya, SI
   Rezaei, A
   Ahmadi, A
AF Haghiri, Saeed
   Yahya, Salah I.
   Rezaei, Abbas
   Ahmadi, Arash
TI Multiplierless Implementation of Fitz-Hugh Nagumo (FHN) Modeling Using CORDIC Approach
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
LA English
DT Article; Early Access
DE Neuron; FHN; CNS; FPGA
ID digital implementation; analog implementation; neuron model; astrocyte; realization; efficient; design
AB The study, simulation, and implementation of neural behavior in the human brain are central goals of neuromorphic engineering. By integrating various scientific fields, we present a hardware solution based on neuronal cell mechanisms that can emulate such a nature-inspired system. This article presents a Fitz-Hugh Nagumo (FHN) neuron implemented using COordinate Rotation DIgital Computer (CORDIC), which accurately reproduces various patterns of the original FHN neuron model. We propose a modification to the original nonlinear term using a CORDIC IP-Core, resulting in high matching accuracy and low computational error. The proposed model is validated through time domain and dynamic analysis, which demonstrates its high accuracy and low error in reproducing all features of the FHN model. For large scale neuron implementations, we present an efficient digital hardware solution based on the resource sharing techniques. The hardware is implemented on Field-Programmable Gate Array (FPGA) using Hardware Description Language (HDL), as a proof of concept. The results from the hardware implementation show that the proposed model uses only 1% of the resources available on a Virtex 4 FPGA board. Additionally, the static timing analysis shows that the circuit can operate at a maximum frequency of 320 MHz.
C1 [Haghiri, Saeed; Rezaei, Abbas] Kermanshah Univ Technol, Dept Elect Engn, Kermanshah 6715685420, Iran.
   [Yahya, Salah I.] Cihan Univ Erbil, Dept Commun & Comp Engn, Erbil 44001, Iraq.
   [Yahya, Salah I.] Koya Univ, Fac Engn, Dept Software Engn, KOY45, Koya, Iraq.
   [Ahmadi, Arash] Carleton Univ, Dept Elect, Ottawa, ON K1S 5B6, Canada.
C3 Kermanshah University of Technology; Cihan University-Erbil; Koya University; Carleton University
RP Haghiri, S (通讯作者)，Kermanshah Univ Technol, Dept Elect Engn, Kermanshah 6715685420, Iran.
EM s.haghiri@kut.ac.ir; salah.ismaeel@koyauniversity.org; a.rezaee@kut.ac.ir; arashahmadi3@cunet.carleton.ca
CR Akbarzadeh-Sherbaf K, 2021, FRONT NEUROSCI, V68, P0
   Amiri M, 2018, J COMPUT ELECTRON, V17, P1382, DOI 10.1007/s10825-018-1207-8
   [Anonymous], 2010, ADV NEURAL INFORM PR, V0, P0
   Bonabi SY, 2014, FRONT NEUROSCI-SWITZ, V8, P0, DOI 10.3389/fnins.2014.00379
   Brink S, 2013, IEEE T BIOMED CIRC S, V7, P71, DOI 10.1109/TBCAS.2012.2197858
   Frenkel C, 2019, IEEE T BIOMED CIRC S, V13, P999, DOI 10.1109/TBCAS.2019.2928793
   Frenkel C, 2019, IEEE T BIOMED CIRC S, V13, P145, DOI 10.1109/TBCAS.2018.2880425
   Ghanbarpour M, 2023, IEEE T BIOMED CIRC S, V17, P246, DOI 10.1109/TBCAS.2023.3233985
   Ghanbarpour M, 2021, IEEE T CIRCUITS-I, V68, P5072, DOI 10.1109/TCSI.2021.3111202
   Haghiri S, 2020, IEEE T CIRCUITS-II, V67, P1444, DOI 10.1109/TCSII.2019.2938180
   Haghiri S, 2017, IEEE T BIOMED CIRC S, V11, P117, DOI 10.1109/TBCAS.2016.2583920
   Haghiri S, 2016, NEUROCOMPUTING, V214, P280, DOI 10.1016/j.neucom.2016.06.015
   Hayati M, 2016, IEEE T BIOMED CIRC S, V10, P518, DOI 10.1109/TBCAS.2015.2450837
   Heidarpour M, 2016, IEEE T CIRCUITS-I, V63, P1986, DOI 10.1109/TCSI.2016.2598161
   Heidarpur M, 2019, IEEE T CIRCUITS-I, V66, P2651, DOI 10.1109/TCSI.2019.2899356
   Imani MA, 2018, IEEE T BIOMED CIRC S, V12, P1431, DOI 10.1109/TBCAS.2018.2869319
   Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, P0, DOI 10.3389/fnins.2011.00073
   Jokar E, 2019, IEEE T CIRCUITS-I, V66, P2336, DOI 10.1109/TCSI.2018.2889974
   Jokar E, 2019, IEEE T BIOMED CIRC S, V13, P454, DOI 10.1109/TBCAS.2019.2900943
   Jokar E, 2017, IEEE T CIRCUITS-I, V64, P2013, DOI 10.1109/TCSI.2017.2688859
   Jokar E, 2017, IEEE T CIRCUITS-II, V64, P832, DOI 10.1109/TCSII.2016.2621823
   Nazari S, 2015, J COMPUT ELECTRON, V14, P227, DOI 10.1007/s10825-014-0643-3
   Nouri M, 2015, NEUROCOMPUTING, V165, P468, DOI 10.1016/j.neucom.2015.03.084
   Pfister JP, 2006, J NEUROSCI, V26, P9673, DOI 10.1523/JNEUROSCI.1425-06.2006
   Qiao N, 2015, FRONT NEUROSCI-SWITZ, V9, P0, DOI 10.3389/fnins.2015.00141
   Sharifipoor O, 2012, NEURAL NETWORKS, V36, P129, DOI 10.1016/j.neunet.2012.08.017
   Soleimani H, 2018, IEEE T CIRCUITS-II, V65, P91, DOI 10.1109/TCSII.2017.2697826
   Soleimani H, 2015, IEEE T NEUR NET LEAR, V26, P127, DOI 10.1109/TNNLS.2014.2311839
   Soleimani H, 2014, NEURAL NETWORKS, V51, P26, DOI 10.1016/j.neunet.2013.12.004
   Soleimani H, 2012, IEEE T CIRCUITS-I, V59, P2991, DOI 10.1109/TCSI.2012.2206463
   Song S, 2000, NAT NEUROSCI, V3, P919, DOI 10.1038/78829
   Starzyk JA, 2014, IEEE T CIRCUITS-I, V61, P2390, DOI 10.1109/TCSI.2014.2304653
   Volder JE, 1959, IRE T ELECT COMPUT, VEC-8, P330, DOI 10.1109/TEC.1959.5222693
   Walther JS, 2000, J VLSI SIG PROCESS S, V25, P107, DOI 10.1023/A:1008162721424
   Wang YX, 2011, IEEE T CIRCUITS-I, V58, P2159, DOI 10.1109/TCSI.2011.2112570
   Yamashita Y, 2012, IEEE T CIRCUITS-I, V59, P2678, DOI 10.1109/TCSI.2012.2190651
   Zahedi A, 2019, IEEE T CIRCUITS-I, V66, P2662, DOI 10.1109/TCSI.2019.2899361
NR 37
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2471-285X
EI 
J9 IEEE TETCI
JI IEEE Trans. Emerg. Top. Comput. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1109/TETCI.2023.3300176
EA AUG 2023
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA O4BD1
UT WOS:001043275400001
DA 2023-11-10
ER

PT J
AU Zhang, JH
   Huang, B
   Fujita, H
   Zeng, GH
   Liu, J
AF Zhang, Jiahao
   Huang, Bo
   Fujita, Hamido
   Zeng, Guohui
   Liu, Jin
TI FeQA: Fusion and enhancement of multi-source knowledge on question answering
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Question answering system; Semantic enhancement; Knowledge graph; Knowledge interaction
AB In the question answering task, we usually need to reason the answer according to the question. Question answering tasks mostly use the pretrained language model to obtain the semantic embedding of questions and choices to predict answers, while the pretrained language model cannot accurately represent the potential relationship between entities in the question. Therefore, researchers introduce knowledge graph to realize the reasoning from question entity to answer entity. However, the limitation of knowledge graph lies in the lack of background information of entities, which may lead to wrong reasoning. To solve the above problems, a new question answering system model FeQA is proposed, which adopts large-scale pretrained language model and knowledge graph. The former uses dual-attention mechanism to enhance the semantics of questions by using Wiktionary and other question answering datasets, while the latter uses graph neural network to infer entities. During the interaction of two modal knowledge, the former provides the basis for the reasoning of nodes in the latter, and the latter provides structured knowledge for the former. After several reasoning iterations, the final answer is obtained by using the knowledge of the two modes. The experimental results on the CommonsenseQA and OpenBookQA datasets show that the performance of this model is better than that of the baseline models. Ablation experiments show that the components and knowledge sources included in this model play an important role in the effect of question and answering task. Extended experiments show the model has good application capability.
C1 [Zhang, Jiahao; Huang, Bo; Zeng, Guohui; Liu, Jin] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201600, Peoples R China.
   [Fujita, Hamido] HUTECH Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Fujita, Hamido] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Kuala Lumpur, Malaysia.
   [Fujita, Hamido] Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Granada, Spain.
   [Fujita, Hamido] Iwate Prefectural Univ, Iwate, Japan.
C3 Shanghai University of Engineering Science; Ho Chi Minh City University of Technology (HUTECH); Vietnam National University Hochiminh City; Universiti Teknologi Malaysia; University of Granada; Iwate Prefectural University
RP Fujita, H (通讯作者)，Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Kuala Lumpur, Malaysia.
EM TracyQAQ@126.com; huangbosues@sues.edu.cn; h.fujita@hutech.edu.vn; zenggh@sues.edu.cn; liujin@sues.edu.cn
FU Scientific and Technological Innovation 2030 - Major Project of New Generation Artificial Intelligence [2020AAA0109300]; Shanghai Science and Technology Young Talents Sailing Program [19YF1418400]; National Natural Science Foundation of China [62006150]; Shanghai Science and Technology Innovation Action Plan [22S31903700, 21S31904200]; Songjiang District Science and Technology Research Project [19SJKJGG83]; Shanghai Local Capacity Enhancement Project [21010501500]
CR Alon T, 2019, ABS181100937, V0, P0
   Cao X, 2023, APPL INTELL, V53, P12032, DOI 10.1007/s10489-022-04123-w
   Chen QL, 2020, ARXIV, V0, P0
   Fang YW, 2020, ARXIV, V0, P0
   Feng YL, 2020, ARXIV, V0, P0
   Huang Z, 2022, ARXIV, V0, P0
   Jiao J, 2021, KNOWL-BASED SYST, V228, P0, DOI 10.1016/j.knosys.2021.107270
   Jiao S, 2022, APPL INTELL, V0, P1
   Kim E, 2022, EXPERT SYST APPL, V203, P0, DOI 10.1016/j.eswa.2022.117405
   Liu YH, 2019, ARXIV, V0, P0
   Lv SW, 2020, AAAI CONF ARTIF INTE, V34, P8449
   Macdonald C, 2021, CIKM 21 30 ACM INT C, V0, PP4526, DOI 10.1145/3459637.3482013
   Mao YN, 2021, ARXIV, V0, P0
   Mihaylov T, 2018, ARXIV, V0, P0
   Nassiri K, 2023, APPL INTELL, V53, P10602, DOI 10.1007/s10489-022-04052-8
   Rodriguez-Torrealba R, 2022, EXPERT SYST APPL, V208, P0, DOI 10.1016/j.eswa.2022.118258
   Santoro A, 2017, ADV NEUR IN, V30, P0
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Sun HT, 2019, ARXIV, V0, P0
   Sun HT, 2018, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Velickovic P, 2018, P 6 INT C LEARN REPR, V0, P0
   Wang XY, 2019, AAAI CONF ARTIF INTE, V0, P7208
   Wu WQ, 2021, APPL INTELL, V51, P4515, DOI 10.1007/s10489-020-02111-6
   Xiong HB, 2021, KNOWL-BASED SYST, V221, P0, DOI 10.1016/j.knosys.2021.106954
   Xu Y, 2021, HUMAN PARITY COMMONS, V0, P0
   Xu YC, 2021, ARXIV, V0, P0
   Yamada I, 2021, ARXIV, V0, P0
   Yao YZ, 2022, LECT NOTES ARTIF INT, V13551, P131, DOI 10.1007/978-3-031-17120-8_11
   Yasunaga M, 2021, ARXIV, V0, P0
   Lin BY, 2019, ARXIV, V0, P0
   Zhang X, 2022, INT C LEARNING REPRE, V0, P0
NR 33
TC 0
Z9 0
U1 16
U2 16
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD OCT 1
PY 2023
VL 227
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120286
EA MAY 2023
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA I2TC0
UT WOS:001001348500001
DA 2023-11-10
ER

PT J
AU Sun, F
   Xu, H
   Meng, YH
   Lu, ZM
AF Sun, Feng
   Xu, He
   Meng, Yihan
   Lu, Zhimao
TI A BERT-based model for coupled biological strategies in biomimetic design
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Biomimetic design; Bert model; Coupled biological strategies
ID language; search; tool
AB The biomimetic design provides an adequate solution to attain an excellent design. However, the prototype space for biomimetic design is relatively large, and it becomes more and more challenging to find the required biological prototypes efficiently and accurately. To improve the design efficiency and enrich the biomimetic information, this paper proposes a coupled biological strategies-enabled bidirectional encoder representation from transformers (BERT) model to assist biomimetic design, namely BioDesign. We extract the biological strategies and extract dimensional information from AskNature as a part of the database. The linguistic expression model-BERT helps to search for biological strategy. Based on the coupled biological strategies analysis, the quantitative results of biomimetic strategies are given by BioDesign. Finally, we take the erosion wear-resistant design of the control valve core as an example to demonstrate the utilization based on the proposed BioDesign. The erosion wear experiment demonstrated the feasibility and effectiveness of the proposed method.
C1 [Sun, Feng; Xu, He; Meng, Yihan] Harbin Engn Univ, Coll Mech & Elect Engn, Harbin 150000, Heilongjiang, Peoples R China.
   [Lu, Zhimao] Dalian Univ Technol, Coll Comp Sci, Dalian 116000, Liaoning, Peoples R China.
C3 Harbin Engineering University; Dalian University of Technology
RP Xu, H (通讯作者)，Harbin Engn Univ, Coll Mech & Elect Engn, Harbin 150000, Heilongjiang, Peoples R China.
EM xuhe@hrbeu.edu.cn
FU Natural Science Foundation of China [51875113]; Natural Science Joint Guidance Foundation of the Heilongjiang Province of China [LH2019E027]; PhD Student Research and Innovation Fund of the Fundamental Research Funds for the Central Universities [XK2070021009]
CR Abudeif AM, 2015, ANN NUCL ENERGY, V75, P682, DOI 10.1016/j.anucene.2014.09.024
   Bhasin D, 2019, 31 INT C DES THEOR M, V7, P0
   Bonfanti S, 2021, APL MATER, V9, P0, DOI 10.1063/5.0026817
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Buche A, 2020, BIOSCI BIOTECH RES C, V13, P35, DOI 10.21786/bbrc/13.14/9
   Chakrabarti A, 2017, SMART INNOV SYST TEC, V66, P475, DOI 10.1007/978-981-10-3521-0_41
   Chen C, 2021, P I MECH ENG C-J MEC, V235, P30, DOI 10.1177/0954406220932595
   Chen T, 2019, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/baz116
   Cheong H, 2014, AI EDAM, V28, P27, DOI 10.1017/S0890060413000486
   Chiarello F, 2021, COMPUT IND, V129, P0, DOI 10.1016/j.compind.2021.103447
   Chiu I, 2007, AI EDAM, V21, P45, DOI 10.1017/S0890060407070138
   Cruz E, 2021, ENERG BUILDINGS, V246, P0, DOI 10.1016/j.enbuild.2021.111034
   Devlin J, 2018, ARXIV, V1, P4171
   FARZANEH HH, 2015, INT CONF ENG DES, V0, P0
   Fu K, 2014, J MECH DESIGN, V136, P0, DOI 10.1115/1.4028289
   Graeff E, 2019, PROC SOC INT C ENG, V1, P319
   Graeff E, 2019, J ENG DESIGN, V30, P289, DOI 10.1080/09544828.2019.1642462
   Gu GX, 2018, MATER HORIZ, V5, P939, DOI 10.1039/c8mh00653a
   Han J, 2018, AI EDAM, V32, P462, DOI 10.1017/S0890060418000082
   Jiang S, 2021, J MECH DESIGN, V144, P0
   Kadkhodapour J, 2015, J FAIL ANAL PREV, V15, P272, DOI 10.1007/s11668-015-9926-7
   Krichmar JL, 2019, FRONT NEUROSCI-SWITZ, V13, P0, DOI 10.3389/fnins.2019.00666
   Kruiper R, 2018, BIOMIMETICS-BASEL, V3, P0, DOI 10.3390/biomimetics3030014
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lenau TA, 2018, PROC SPIE, V10593, P0, DOI 10.1117/12.2296560
   Li MG, 2021, NEURAL COMPUT APPL, V33, P4663, DOI 10.1007/s00521-020-05411-7
   Li R, 2021, ADV ENG INFORM, V50, P0, DOI 10.1016/j.aei.2021.101416
   Li X, 2021, MATH PROBL ENG, V2021, P0, DOI 10.1155/2021/9942277
   Linsey JS, 2012, J MECH DESIGN, V134, P0, DOI 10.1115/1.4006145
   Miller G, 1990, INT J LEXICOGR, V3, P235, DOI 10.1093/IJL/3.4.235
   Nagel JKS, 2014, BIOL INSPIRED DESIGN, V0, P63
   Nagel JKS, 2012, AI EDAM, V26, P161, DOI 10.1017/S0890060412000054
   Nam S, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su13010391
   Ofer D, 2021, COMPUT STRUCT BIOTEC, V19, P1750, DOI 10.1016/j.csbj.2021.03.022
   Palin D, 2020, DEARQ, V0, PP52, DOI 10.18389/dearq26.2020.06
   Pentelovitch N, 2022, BIOMIMETICS-BASEL, V7, P0, DOI 10.3390/biomimetics7020063
   Pham CTA, 2022, INNOV-ORGAN MANAG, V24, P290, DOI 10.1080/14479338.2021.1894942
   Pota M, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21010133
   Qiao B, 2022, NEURAL COMPUT APPL, V34, P3471, DOI 10.1007/s00521-021-05815-z
   Saha T, 2020, IEEE T COMPUT SOC SY, V7, P1168, DOI 10.1109/TCSS.2020.3014128
   Sarica S, 2021, P DESIGN SOC, V1, P1043, DOI 10.1017/PDS.2021.104
   Sarica S, 2020, EXPERT SYST APPL, V142, P0, DOI 10.1016/j.eswa.2019.112995
   Sartori J, 2010, AI EDAM, V24, P483, DOI 10.1017/S0890060410000351
   Seluk SA, 2021, INT J TECHNOL DES ED, V3, P1
   Sha WX, 2020, ADV INTELL SYST-GER, V2, P0, DOI 10.1002/aisy.201900143
   Sherif HA, 2018, WEAR, V412, P127, DOI 10.1016/j.wear.2018.07.013
   Shu LH, 2010, AI EDAM, V24, P507, DOI 10.1017/S0890060410000363
   Speck O, 2017, BIOINSPIR BIOMIM, V12, P0, DOI 10.1088/1748-3190/12/1/011004
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Stroble JK, 2009, ICED 09 - THE 17TH INTERNATIONAL CONFERENCE ON ENGINEERING DESIGN, VOL 2: DESIGN THEORY AND RESEARCH METHODOLOGY, P53
   Sullivan TN, 2019, MAT SCI ENG C-MATER, V105, P0, DOI 10.1016/j.msec.2019.110066
   Sun F, 2020, BIO-DES MANUF, V3, P331, DOI 10.1007/s42242-020-00079-3
   Thuethongchai N, 2020, SOC SCI-BASEL, V9, P0, DOI 10.3390/socsci9030029
   Vandevenne D, 2016, AI EDAM, V30, P78, DOI 10.1017/S0890060415000177
   Verganti R, 2020, J PROD INNOVAT MANAG, V37, P212, DOI 10.1111/jpim.12523
   Wang J, 2021, KNOWL-BASED SYST, V232, P0, DOI 10.1016/j.knosys.2021.107476
   Wang X, 2021, SCIENTOMETRICS, V126, P5531, DOI 10.1007/s11192-021-04003-z
   Weidner BV, 2018, INT J DES CREAT INNO, V6, P211, DOI 10.1080/21650349.2018.1428689
   Willocx M, 2020, CIRP J MANUF SCI TEC, V31, P61, DOI 10.1016/j.cirpj.2020.09.013
   Xu Jiang, 2017, CHINA MECHANICAL ENGINEERING, V28, P596, DOI 10.3969/j.issn.1004-132X.2017.05.015
   Zhang XC, 2020, MATER TODAY COMMUN, V23, P0, DOI 10.1016/j.mtcomm.2020.100918
   Zhong FS, 2018, SCI CHINA LIFE SCI, V61, P1191, DOI 10.1007/s11427-018-9342-2
NR 62
TC 3
Z9 3
U1 9
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JAN 15
PY 2023
VL 35
IS 3
BP 2827
EP 2843
DI 10.1007/s00521-022-07734-z
EA SEP 2022
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 8B9NM
UT WOS:000850389800005
DA 2023-11-10
ER

PT J
AU McCoy, RT
   Smolensky, P
   Linzen, T
   Gao, JF
   Celikyilmaz, A
AF McCoy, R. Thomas
   Smolensky, Paul
   Linzen, Tal
   Gao, Jianfeng
   Celikyilmaz, Asli
TI How Much Do Language Models Copy From Their Training Data? Evaluating Linguistic Novelty in Text Generation Using RAVEN
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Current language models can generate high-quality text. Are they simply copying text they have seen before, or have they learned generalizable linguistic abstractions? To tease apart these possibilities, we introduce RAVEN, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure. We apply these analyses to four neural language models trained on English (an LSTM, a Transformer, Transformer-XL, and GPT-2). For local structure-e.g., individual dependencies-text generated with a standard sampling scheme is substantially less novel than our baseline of human-generated text from each model's test set. For larger-scale structure-e.g., overall sentence structure-model-generated text is as novel or even more novel than the human-generated baseline, but models still sometimes copy substantially, in some cases duplicating passages over 1,000 words long from the training set. We also perform extensive manual analysis, finding evidence that GPT-2 uses both compositional and analogical generalization mechanisms and showing that GPT-2's novel text is usually well-formed morphologically and syntactically but has reasonably frequent semantic issues (e.g., being self-contradictory).
C1 [McCoy, R. Thomas] Princeton Univ, Princeton, NJ 08544 USA.
   [McCoy, R. Thomas; Smolensky, Paul; Gao, Jianfeng; Celikyilmaz, Asli] Microsoft Res, Redmond, WA 98052 USA.
   [McCoy, R. Thomas; Smolensky, Paul] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Linzen, Tal] NYU, New York, NY USA.
   [Celikyilmaz, Asli] Meta AI, Menlo Pk, CA USA.
C3 Princeton University; Microsoft; Johns Hopkins University; New York University
RP McCoy, RT (通讯作者)，Princeton Univ, Princeton, NJ 08544 USA.; McCoy, RT (通讯作者)，Microsoft Res, Redmond, WA 98052 USA.; McCoy, RT (通讯作者)，Johns Hopkins Univ, Baltimore, MD 21218 USA.
EM tom.mccoy@princeton.edu; psmo@microsoft.com; linzen@nyu.edu; jfgao@microsoft.com; aslic@meta.com
FU National Science Foundation [1746891]
CR Akyurek Ekin, 2022, FINDINGS ASS COMPUTA, V0, P2429
   Albright A, 2003, COGNITION, V90, P119, DOI 10.1016/S0010-0277(03)00146-X
   Bender Emily M, 2021, FACCT 21: PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, V0, P0
   Bender EM, 2020, C SESSION P 58 ANN M, V0, P0
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, V0, P2633
   Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, V0, P267
   Carlini Nicholas, 2023, 11 INT C LEARNING RE, V0, P0
   Celikyilmaz A, 2021, ARXIV, V0, P0
   Chen Mark, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2107.03374
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Dasgupta Ishita, 2022, P 39 INT C MACH LEAR, V162 of Proceedings of Machine Learning Research, P4816
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7250
   Dyer Chris, 2016, P 2016 C N AM CHAPT, V0, PP199, DOI 10.18653/v1/N16-1024
   Elazar Y, 2022, ARXIV, V0, P0
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   HADLEY RF, 1994, MIND LANG, V9, P431, DOI 10.1111/j.1468-0017.1994.tb00225.x
   Haley Coleman, 2020, P 3 BLACKBOXNLP WORK, V0, PP333, DOI 10.18653/v1/2020.blackboxnlp-1.31
   Han XC, 2022, ARXIV, V0, P0
   Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689
   Holtzman Ari, 2020, ICLR, V0, P0
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1725
   Hupkes D, 2020, J ARTIF INTELL RES, V67, P757
   Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4
   Kandpal N, 2022, PR MACH LEARN RES, V0, P10697
   Kaplan J, 2020, ARXIV, V0, P0
   Keysers Daniel, 2020, INT C LEARNING REPRE, V0, P0
   Khandelwal Urvashi, 2020, INT C LEARN REPR ICL, V0, P0
   Kim N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9087
   Kitaev N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2676
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9332
   KUCZAJ SA, 1977, J VERB LEARN VERB BE, V16, P589, DOI 10.1016/S0022-5371(77)80021-2
   Lake B, 2018, PR MACH LEARN RES, V80, P0
   LeBrun Benjamin, 2022, INT C LEARN REPR, V0, P0
   Lee J, 2023, ARXIV, V0, P0
   Lee K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8424
   Li YF, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4767
   Marcus G, 2020, ARXIV, V0, P0
   MARCUS GF, 1992, MONOGR SOC RES CHILD, V57, P0
   McCoy RT, 2020, T ASSOC COMPUT LING, V8, P125, DOI 10.1162/tacl_a_00304
   Meister Clara, 2021, P 59 ANN M ASS COMPU, V0, PP5328, DOI 10.18653/v1/2021.acl-long.414
   Merity S, 2017, INT C LEARNING REPRE, V0, P0
   MONTAGUE R, 1970, THEORIA, V36, P373
   Mutton A, 2007, P 45 ANN M ASS COMPU, V0, P344
   ODonnell TJ, 2015, PRODUCTIVITY REUSE L, V0, P0, DOI DOI 10.7551/mitpress/9780262028844.001.0001
   Pannitto Ludovica, 2020, P 24 C COMPUTATIONAL, V0, PP165, DOI 10.18653/V1/2020.CONLL-1.13
   PRASADA S, 1993, LANG COGNITIVE PROC, V8, P1, DOI 10.1080/01690969308406948
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0
   Rashkin H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4274
   Ravfogel S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3532
   Schlag Imanol, 2019, NEURIPS WORKSHOP CON, V0, P0, DOI DOI 10.48550/arXiv.1910.06611
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Keskar NS, 2019, ARXIV, V0, P0
   Shokri R, 2017, P IEEE S SECUR PRIV, V0, PP3, DOI 10.1109/SP.2017.41
   Vaswani A, 2017, ARXIV, V30, P5998
   Wei J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P932
   Yamakoshi T, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P3977
   Yang C, 2016, PRICE OF LINGUISTIC PRODUCTIVITY: HOW CHILDREN LEARN TO BREAK THE RULES OF LANGUAGE, V0, PP1, DOI 10.7551/mitpress/9780262035323.001.0001
   Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776
   Zhang SS, 2022, ARXIV, V0, P0
   Zhang YA, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1112
   Zhang Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3295
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1097, DOI 10.1145/3209978.3210080
   Ziegler Albert, 2021, 1 LOOK ROTE LEARNING, V0, P0
NR 68
TC 0
Z9 0
U1 3
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 29
PY 2023
VL 11
IS 
BP 652
EP 670
DI 10.1162/tacl_a_00567
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA L6IQ3
UT WOS:001024283700001
DA 2023-11-10
ER

PT J
AU Attieh, J
   Tekli, J
AF Attieh, Joseph
   Tekli, Joe
TI Supervised term-category feature weighting for improved text classification
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Text classification; Document and text processing; Feature Engineering; Supervised term weighting; Inverse Category Frequency; TF-IDF; Text representation
ID schemes; model
AB Text classification is a central task in Natural Language Processing (NLP) that aims at categorizing text documents into predefined classes or categories. It requires appropriate features to describe the contents and meaning of text documents, and map them with their target categories. Existing text feature representations rely on a weighted representation of the document terms. Hence, choosing a suitable method for term weighting is of major importance and can help increase the effectiveness of the classification task. In this study, we provide a novel text classification framework for Category -based Feature Engineering titled CFE. It consists of a supervised weighting scheme defined based on a variant of the TF-ICF (Term Frequency-Inverse Category Frequency) model, embedded into three new lean classification approaches: (i) IterativeAdditive (flat), (ii) GradientDescentANN (1-layered), and (iii) FeedForwardANN (2-layered). The IterativeAdditive approach augments each document representation with a set of synthetic features inferred from TF-ICF category representations. It builds a term-category TF-ICF matrix using an iterative and additive algorithm that produces category vector representations and updates until reaching convergence. GradientDescentANN replaces the iterative additive process mentioned previously by computing the term-category matrix using a gradient descent ANN model. Training the ANN using the gradient descent algorithm allows updating the term-category matrix until reaching convergence. FeedForwardANN uses a feed-forward ANN model to transform document representations into the category vector space. The transformed document vectors are then compared with the target category vectors, and are associated with the most similar categories. We have implemented CFE including its three classification approaches, and we have conducted a large battery of tests to evaluate their performance. Experimental results on five benchmark datasets show that our lean approaches mostly improve text classification accuracy while requiring significantly less computation time compared with their deep model alternatives.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Attieh, Joseph; Tekli, Joe] Lebanese Amer Univ LAU, Elect & Comp Engn Dept, Byblos 36, Lebanon.
   [Tekli, Joe] Univ Pay & Pays Adour UPPA, LIUPPA Lab, SPIDER Res Team, F-64600 Anglet, Aquitaine, France.
C3 Lebanese American University; Universite de Pau et des Pays de l'Adour
RP Tekli, J (通讯作者)，Lebanese Amer Univ LAU, Elect & Comp Engn Dept, Byblos 36, Lebanon.
EM joe.tekli@lau.edu.lb
CR Abboud R, 2020, SOFT COMPUT, V24, P9875, DOI 10.1007/s00500-019-04503-4
   Acheampong FA, 2021, ARTIF INTELL REV, V54, P5789, DOI 10.1007/s10462-021-09958-2
   Ahmed H, 2018, SECUR PRIVACY, V1, P0, DOI 10.1002/spy2.9
   Alsaeedi A, 2020, INT J DATA MIN MODEL, V12, P237
   [Anonymous], 2017, P ACL, V0, P0
   Mourino-García MA, 2018, SOFT COMPUT, V22, P6047, DOI 10.1007/s00500-018-3101-5
   Attieh J, 2021, FAST SIMPLE EFFECTIV, V0, P0
   Azar D, 2016, INT J ARTIFICIAL INT, V14, P2
   Byerly A, 2021, IEEE ACCESS, V9, P48519, DOI 10.1109/ACCESS.2021.3066842
   Cai LK, 2020, IEEE ACCESS, V8, P152183, DOI 10.1109/ACCESS.2020.3017382
   Chauhan UA, 2020, WORLD WIDE WEB, V23, P1811, DOI 10.1007/s11280-020-00785-z
   Chen Wang, 2021, CCEAI 2021: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONTROL ENGINEERING AND ARTIFICIAL INTELLIGENCE, V0, PP136, DOI 10.1145/3448218.3448235
   Daniel DAJ, 2021, SCALABLE COMPUT-PRAC, V22, P53, DOI 10.12694/scpe.v22i1.1839
   Debole F, 2004, STUD FUZZ SOFT COMP, V138, P81
   Defferrard Michael, 2016, ADV NEURAL INFORM PR, V0, P3837
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Ding KZ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4927
   Domeniconi G, 2015, DATA REVISED SELECTE, V584, P39, DOI 10.1007/978-3-319-30162-4_4
   Domeniconi G, 2015, INT C DATA TECHNOLOG, V0, PP26, DOI 10.5220/0005511900260037
   Fares M, 2019, IEEE INT C COGN COMP, V0, P0
   Fares M, 2019, KNOWL-BASED SYST, V165, P432, DOI 10.1016/j.knosys.2018.12.017
   Flexa C, 2021, EXPERT SYST APPL, V175, P0, DOI 10.1016/j.eswa.2021.114741
   Flisar J, 2020, FUND INFORM, V172, P261, DOI 10.3233/FI-2020-1905
   Han JL, 2018, AAAI CONF ARTIF INTE, V0, P8202
   Haraty RA, 2019, LIBR HI TECH, V37, P101, DOI 10.1108/LHT-07-2017-0147
   Haraty RA, 2015, INT J DISTRIB SENS N, V0, P0, DOI DOI 10.1155/2015/615740
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hopfield JJ, 1989, IFIP WORLD COMPUTER, V0, P402
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Joon Ho Lee, 1994, SIGIR 94. PROCEEDINGS OF THE SEVENTEENTH ANNUAL INTERNATIONAL ACM-SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P182
   Kaddoura Sanaa, 2020, 2020 IEEE 29TH INTERNATIONAL CONFERENCE ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES (WETICE), V0, PP193, DOI 10.1109/WETICE49692.2020.00045
   Kadhim AI, 2019, ARTIF INTELL REV, V52, P273, DOI 10.1007/s10462-018-09677-1
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Li Xiao, 2020, ICBDC 20: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON BIG DATA AND COMPUTING, V0, PP90, DOI 10.1145/3404687.3404706
   Lin XJ, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW22), V0, PP633, DOI 10.1145/3485447.3512217
   Lu H, 2019, ABS190612330 CORR, V0, P0
   Ma YL, 2022, EXPERT SYST APPL, V187, P0, DOI 10.1016/j.eswa.2021.115905
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Mladenic D, 1998, C AUT LEARN DIS CONA, V0, P0
   Moreo A, 2021, DATA MIN KNOWL DISC, V35, P911, DOI 10.1007/s10618-020-00735-3
   Park K, 2020, APPL ARTIF INTELL, V34, P396, DOI 10.1080/08839514.2020.1723868
   Pham P, 2023, ARTIF INTELL REV, V56, P4893, DOI 10.1007/s10462-022-10265-7
   Pintas JT, 2021, ARTIF INTELL REV, V54, P6149, DOI 10.1007/s10462-021-09970-6
   Poostchi H, 2018, AUSTRALASIAN LANGUAG, V0, P66
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Raghavan AK, 2019, C NAT LANG PROC KONV, V0, P0
   Revina A, 2020, IEEE ACCESS, V8, P193380, DOI 10.1109/ACCESS.2020.3032840
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Salton G, 1989, AUTOMATIC TEXT PROCE, V0, P530
   Sarkissian Sarkis, 2021, MEDES 21: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS, V0, PP87, DOI 10.1145/3444757.3485078
   Shen DH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P440
   Tang Z, 2022, EXPERT SYST APPL, V189, P0, DOI 10.1016/j.eswa.2021.115985
   Tang Z, 2020, KNOWL-BASED SYST, V207, P0, DOI 10.1016/j.knosys.2020.106399
   Tekli J, 2019, KNOWL-BASED SYST, V164, P378, DOI 10.1016/j.knosys.2018.11.010
   Tekli J, 2018, DATA KNOWL ENG, V117, P133, DOI 10.1016/j.datak.2018.07.007
   Tekli J, 2009, COMPUT SCI REV, V3, P151, DOI 10.1016/j.cosrev.2009.03.001
   Thongtan T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P407
   Wang DQ, 2013, J INF SCI ENG, V29, P209
   Wang GY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2321
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6382
   Xinhua Zhu, 2019, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 8TH CCF INTERNATIONAL CONFERENCE, V0, P0
   Yao L, 2019, AAAI CONF ARTIF INTE, V0, P7370
   Zhang HL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4545
   Zou F, 2021, INFORM SCIENCES, V546, P815, DOI 10.1016/j.ins.2020.08.101
NR 64
TC 4
Z9 4
U1 3
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD FEB 15
PY 2023
VL 261
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.110215
EA DEC 2022
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA D4VP3
UT WOS:000968729800001
DA 2023-11-10
ER

PT J
AU Singh, I
   Blukis, V
   Mousavian, A
   Goyal, A
   Xu, DF
   Tremblay, J
   Fox, D
   Thomason, J
   Garg, A
AF Singh, Ishika
   Blukis, Valts
   Mousavian, Arsalan
   Goyal, Ankit
   Xu, Danfei
   Tremblay, Jonathan
   Fox, Dieter
   Thomason, Jesse
   Garg, Animesh
TI PROGPROMPT: program generation for situated robot task planning using large language models
SO AUTONOMOUS ROBOTS
LA English
DT Article; Early Access
DE Robot task planning; LLM code generation; Planning domain generalization; Symbolic planning
AB Task planning can require defining myriad domain knowledge about the world in which a robot needs to act. To ameliorate that effort, large language models (LLMs) can be used to score potential next actions during task planning, and even generate action sequences directly, given an instruction in natural language with no additional domain information. However, such methods either require enumerating all possible next steps for scoring, or generate free-form text that may contain actions not possible on a given robot in its current context. We present a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example programs that can be executed. We make concrete recommendations about prompt structure and generation constraints through ablation experiments, demonstrate state of the art success rates in VirtualHome household tasks, and deploy our method on a physical robot arm for tabletop tasks. Website and code at progprompt.github.io
C1 [Singh, Ishika; Thomason, Jesse] Univ Southern Calif, Comp Sci, Los Angeles, CA 90089 USA.
   [Blukis, Valts; Mousavian, Arsalan; Goyal, Ankit; Xu, Danfei; Tremblay, Jonathan; Fox, Dieter; Garg, Animesh] NVIDIA, Seattle Robot Lab, Seattle, WA 98105 USA.
   [Fox, Dieter] Univ Washington, Comp Sci & Engn, Seattle, WA 98195 USA.
   [Garg, Animesh] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30308 USA.
C3 University of Southern California; University of Washington; University of Washington Seattle; University System of Georgia; Georgia Institute of Technology
RP Singh, I (通讯作者)，Univ Southern Calif, Comp Sci, Los Angeles, CA 90089 USA.
EM ishikasi@usc.edu; vblukis@nvidia.com; amousavian@nvidia.com; angoyal@nvidia.com; danfeix@nvidia.com; jtremblay@nvidia.com; dieterf@nvidia.com; jessetho@usc.edu; animeshg@nvidia.com
FU SCELC, Statewide California Electronic Library Consortium; NVIDIA
CR Ahn M, 2022, ARXIV, V0, P0
   Akakzia A, 2021, INT C LEARNING REPRE, V0, P0
   Baier JA, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1808
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Bryce D, 2007, AI MAG, V28, P47
   Cao Y, 2023, ARXIV, V0, P0
   Capitanelli A, 2023, ARXIV, V0, P0
   Chen M, 2021, ARXIV, V0, P0
   Danielczuk M, 2021, IEEE INT CONF ROBOT, V0, PP6010, DOI 10.1109/ICRA48506.2021.9561516
   Eysenbach Ben, 2019, ADV NEURAL INFORM PR, V32, P0
   FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5
   Garrett Caelan Reed, 2020, P INT C AUTOMATED PL, V30, P440
   Gu Xiuye, 2022, INT C LEARN REPR, V0, P0
   Gupta T, 2022, ARXIV, V0, P0
   Helmert M, 2006, J ARTIF INTELL RES, V26, P191, DOI 10.1613/jair.1705
   Hoffmann J, 2001, AI MAG, V22, P57
   Holtzman Ari, 2020, ICLR, V0, P0
   Huang WL, 2023, ARXIV, V0, P0
   Huang WL, 2022, ARXIV, V0, P0
   Huang WL, 2022, ARXIV, V0, P0
   Jansen P, 2020, FINDINGS ASS COMPUTA, V0, P4412
   Jiang Y, 2018, ARXIV, V0, P0
   Jiang YD, 2019, ADV NEUR IN, V32, P0
   Kurutach T, 2018, ADV NEUR IN, V31, P0
   Li S, 2022, ARXIV, V0, P0
   Liang J, 2023, CODE POLICIES LANGUA, V0, P0
   Liu P, 2021, ARXIV, V0, P0
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Mai JJ, 2023, ARXIV, V0, P0
   Mirchandani S, 2021, ADV NEURAL INFORM PR, V34, P29529
   Nair S, 2020, INT C LEARNING REPRE, V0, P0
   OpenAI, 2023, ARXIV, V0, P0
   Patel R, 2022, INT C LEARNING REPRE, V0, P0
   Puig X, 2018, PROC CVPR IEEE, V0, PP8494, DOI 10.1109/CVPR.2018.00886
   Shah D, 2022, INT C LEARNING REPRE, V0, P0
   Sharma P, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1713
   Shridhar M, 2020, IEEE C COMPUTER VISI, V0, P0
   Silver T, 2022, MULTIDISCIPLINARY C, V0, P0
   Skreta M, 2023, ARXIV, V0, P0
   Srinivas A, 2018, INT C MACHINE LEARNI, V80, P4732
   Sundermeyer M, 2021, IEEE INT CONF ROBOT, V0, PP13438, DOI 10.1109/ICRA48506.2021.9561877
   Vemprala S, 2023, CHATGPT ROBOTICS DES, V0, P0
   Wei J-J, 2022, ARXIV, V0, P0
   Wiseman S, 2017, P 2017 C EMPIRICAL M, V0, P0
   Xie Y, 2023, TRANSLATING NATURAL, V0, P0
   Xie YQ, 2023, ARXIV, V0, P0
   Xu D, 2019, ADV NEUR IN, V32, P0
   Xu DF, 2018, IEEE INT CONF ROBOT, V0, P3795
   Zeng A, 2022, ARXIV, V0, P0
   Zhu Y, 2020, ARXIV, V0, P0
NR 50
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0929-5593
EI 1573-7527
J9 AUTON ROBOT
JI Auton. Robot.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10514-023-10135-3
EA AUG 2023
PG 14
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA R4AF1
UT WOS:001063783800001
DA 2023-11-10
ER

PT J
AU Jyothi, K
   Okade, M
AF Jyothi, Kondalarao
   Okade, Manish
TI Text2Color Networks: Deep Learning Models for Color Generation from Compositional Color Descriptions
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Color generation; color names; word embeddings; neural networks
ID language
AB Color serves as an important cue in graphics, arts and in many computer vision applications. We reliably and effortlessly name colors and communicate them with their names. However, many applications such as graphics, color design, palette generation and color selection tools demand numerical values of colors. Predicting and communicating colors by their numerical values is less intuitive and difficult task as it is a mapping of millions of colors for a specific color space. To bridge the gap between linguistic color names and numerical color values, in this paper, we present neural network architectures that predict a point in color space for a given color name. Proposed models provide user interface between colors and names by learning the language semantics and mimic human level comprehension of color descriptions to predict colors and modify them with respect to linguistic adjectives of color names. We consider color prediction as a regression problem and solve it as a language modeling task. Color descriptions are taken as text sequences and each sentence is represented with word-level tokenization. Each token is transformed into a word vector in the latent space using CBOW word embeddings model. Word vectors representing color names are fed as input to neural networks and trained with normalized R, G, B values as supervision information. Trained models are capable of predicting color for a given color name and modify colors for different nouns and adjectives associated with color names. We also built color generation models based on pre-trained word embeddings to overcome the limited availability of large linguistic color name datasets. These pre-trained models perform well with datasets containing few thousand color names. We then present two recommendation engines that suggest similar color palette to user given color name. These recommendation engines enhance the color vocabulary and assist users in the color selection process.
C1 [Jyothi, Kondalarao; Okade, Manish] Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Intelligent Syst Lab, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Rourkela
RP Jyothi, K (通讯作者)，Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Intelligent Syst Lab, Rourkela 769008, India.
EM rao.nitrkl@gmail.com; okadem@nitrkl.ac.in
CR Albahli AS, 2021, CMC-COMPUT MATER CON, V67, P1613, DOI 10.32604/cmc.2021.014265
   [Anonymous], 2003, SCI COLOR, V0, P0, DOI DOI 10.1016/B978-044451251-2/50006-4
   Bahdanau D, 2016, ARXIV, V0, P0
   Baldrich R, 2006, CTR FRANCAIS COULEU, V31, P48
   Benavente R, 2002, CGIV2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, V0, P0
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bergman LD, 1995, VISUALIZATION 95 - PROCEEDINGS, V0, PP118, DOI 10.1109/VISUAL.1995.480803
   BERK T, 1982, IEEE COMPUT GRAPH, V2, P37
   Berlin B, 1991, BASIC COLOR TERMS TH, V0, P0
   Chuang J, 2008, COL IM C SOC IM SCI, V0, P6
   Cook RS, 2005, HDB CATEGORIZATION C, V0, P0
   Das M, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV98, V0, P94, DOI 10.1109/ACV.1998.732864
   Fu YW, 2016, PROC CVPR IEEE, V0, PP5337, DOI 10.1109/CVPR.2016.576
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Heer Jeffrey, 2012, P SIGCHI C HUMAN FAC, V0, PP1007, DOI 10.1145/2207676.2208547
   Kaufman A, 1986, VISUAL COMPUTER, V2, P255, DOI 10.1007/BF01900349
   Kelly KL, 1976, COLOR UNIVERSAL LANG, V0, P0
   Levy O, 2014, ADV NEUR IN, V27, P0
   Liu Y, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, V0, P180
   Meier BJ, 2004, IEEE COMPUT GRAPH, V24, P64, DOI 10.1109/MCG.2004.1297012
   Menegaz G, 2007, EURASIP J ADV SIG PR, V0, P0, DOI DOI 10.1155/2007/29125
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Mikolov T, 2013, ARXIV, V0, P0
   Mnih A, 2013, NIPS, V0, P0
   Mojsilovic A, 2005, IEEE T IMAGE PROCESS, V14, P690, DOI 10.1109/TIP.2004.841201
   Moroney N, 2003, PROC SPIE, V5008, P36, DOI 10.1117/12.472013
   Motomura H, 2001, J IMAGING SCI TECHN, V45, P117
   Munroe R, 2010, COLOR SURVEY RESULTS, V0, P0
   Mylonas D, 2010, COLOR IMAG CONF, V0, P140
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rheingans P, 1990, COMPUTER GRAPHICS, V24, P145, DOI 10.1145/91394.91436
   Roberson D, 2000, J EXP PSYCHOL GEN, V129, P369, DOI 10.1037//0096-3445.129.3.369
   Rudolph M, 2017, ARXIV, V0, P0
   Schettini R, 1992, VISUAL COMPUTER, V9, P143, DOI 10.1007/BF01902553
   Socher R, 2013, LONG PAPERS, V1, P455
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Vilnis L, 2015, ARXIV, V0, P0
   Vinyals O, 2015, ARXIV, V0, P0
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Wang XH, 2013, VISUAL COMPUT, V29, P1121, DOI 10.1007/s00371-012-0755-3
   Winawer J, 2007, P NATL ACAD SCI USA, V104, P7780, DOI 10.1073/pnas.0701644104
   Yu L, 2018, MACH VISION APPL, V29, P361, DOI 10.1007/s00138-017-0902-y
   Zhou XY, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10091024
NR 47
TC 0
Z9 0
U1 0
U2 0
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD SEP 15
PY 2023
VL 32
IS 06
BP 
EP 
DI 10.1142/S0218213023500264
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA T9EL5
UT WOS:001080941700008
DA 2023-11-10
ER

PT J
AU Zhang, YH
   Chen, L
   Ju, SG
   Liu, GS
AF Zhang, Yuhui
   Chen, Li
   Ju, Shenggen
   Liu, Gaoshuo
TI Multi-domain adaptation for cross-domain semantic slot filling
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Slot filling; Transfer learning; Cross-domain; Maximum mean difference; Label aware
AB Slot filling is a crucial sub-task in the field of Spoken Language Understanding and aims to match the corresponding semantic slot for each word in the sequence. Slot prediction in an unknown domain requires a large amount of data in the domain for training, but in reality, there is often a lack of trainable samples in the unknown domain, which makes it difficult for the model to predict new domains. This is the biggest challenge of the cross-domain slot filling task. In recent years, the idea of transfer learning has been applied to cross-domain slot filling tasks. The current training method directly mixes the source domain data samples without considering the differences between the various domains in the source domain, which ignores the domain-invariant features contained in the source domain. In this paper, we proposed a cross-domain slot filling model based on multi-domain adaptation. First, we used the domain-adaptive domain projection layer to let the feature learner classify the domain-invariant information and domain-exclusive information into the specified dimension part of the vector, so as to realize the extraction of domain-invariant feature information, and then used the trainable linear transformation matrix to relieve the generalization burden of the feature learner. Experimental results show that our proposed models significantly outperform other methods on average F1-score.
C1 [Zhang, Yuhui; Chen, Li; Ju, Shenggen; Liu, Gaoshuo] SiChuan Univ, Coll Comp Sci, No South Sect 24 1, 24,South Sect 1,First Ring Rd, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Ju, SG (通讯作者)，SiChuan Univ, Coll Comp Sci, No South Sect 24 1, 24,South Sect 1,First Ring Rd, Chengdu 610065, Sichuan, Peoples R China.
EM jsg@scu.edu.cn
FU Key projects of the National Natural Science Foun-dation of China [62137001]
CR Bapna A, 2017, INTERSPEECH, V0, PP2476, DOI 10.21437/Interspeech.2017-518
   Bu LC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7638, DOI 10.1109/ICASSP39728.2021.9414625
   Coucke A, 2018, ARXIV, V0, P0
   Dredze M, 2010, MACH LEARN, V79, P123, DOI 10.1007/s10994-009-5148-0
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He Keqing, 2020, P 28 INT C COMP LING, V0, P1461
   Khan W, 2022, SYMMETRY-BASEL, V14, P0, DOI 10.3390/sym14101976
   Kipf TN, 2017, ICLR, V0, P0, DOI DOI 10.48550/ARXIV.1609.02907
   Lawal MO, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-81216-5
   Liu B, 2015, PROCEEDING NIPS WORK, V0, P0
   Liu J, 2019, J PHYS CONF SER, V1267, P0, DOI 10.1088/1742-6596/1267/1/012059
   Liu S, 2021, CCF INT C NAT LANG P, V0, P517
   Liu ZH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P19
   Lu H, 2021, FINDINGS ASS COMPUTA, V0, P4970
   Montenegro C, 2021, ENG APPL ARTIF INTEL, V100, P0, DOI 10.1016/j.engappai.2021.104189
   Tran OT, 2020, ENG APPL ARTIF INTEL, V87, P0, DOI 10.1016/j.engappai.2019.103322
   Peng Nanyun, 2017, P 2 WORKSH REPR LEAR, V0, PP91, DOI 10.18653/V1/W17-2612
   Schuster S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2371
   Shah DJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5484
   Tur G, 2011, SPOKEN LANGUAGE UNDE, V0, P0
   Yang Y, 2015, P 2015 C N AM CHAPT, V0, P672
   Yang Yongxin, 2015, ICLR, V0, P0
   [俞凯 Yu Kai], 2015, 计算机学报 CHINESE JOURNAL OF COMPUTERS, V38, P2333
NR 24
TC 0
Z9 0
U1 3
U2 3
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD AUG 15
PY 2023
VL 123
IS 
BP 
EP 
DI 10.1016/j.engappai.2023.106364
EA MAY 2023
PG 10
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA I1XT9
UT WOS:001000791200001
DA 2023-11-10
ER

PT J
AU Qin, BW
   Hui, BY
   Wang, LH
   Yang, M
   Li, BH
   Huang, F
   Si, L
   Jiang, QS
   Li, YB
AF Qin, Bowen
   Hui, Binyuan
   Wang, Lihan
   Yang, Min
   Li, Binhua
   Huang, Fei
   Si, Luo
   Jiang, Qingshan
   Li, Yongbin
TI Schema dependency-enhanced curriculum pre-training for table semantic parsing
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Table semantic parsing; Table pre-training; Schema dependency; Curriculum learning
AB Large pre-trained models exhibit improved table-semantic-parsing performances by leveraging large-scale corpora to enhance the representation learning ability of semantic parsers. However, existing table pre-training methods do not sufficiently consider the explicit interactions among natural language (NL) questions, SQL queries, and the corresponding database schemas, which are essential for table semantic parsing. To overcome the aforementioned limitation, this study designs a novel schema dependency prediction (SDP) objective to incorporate SQL-aware schema linking information into table pre-training. Specifically, SDP aims to predict the schema dependency connecting the NL question, table schema, and triggered SQL operations. We further propose a schema-aware curriculum learning approach (SAC) to mitigate the impact of noise present in the pre-training data and train the table pre -training model in an easy-to-hard manner. We evaluate the effectiveness of our pre-training framework by fine-tuning it on three downstream benchmarks (Spider, Spider-DK, and SQUALL). Experimental results demonstrate that the proposed pre-training method outperforms existing methods considered for comparison. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Qin, Bowen; Wang, Lihan; Yang, Min; Jiang, Qingshan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Qin, Bowen; Wang, Lihan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Hui, Binyuan; Li, Binhua; Huang, Fei; Si, Luo; Li, Yongbin] Alibaba Grp, DAMO Acad, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Alibaba Group
RP Yang, M (通讯作者)，Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.; Li, YB (通讯作者)，Alibaba Grp, DAMO Acad, Beijing, Peoples R China.
EM bw.qin@siat.ac.cn; binyuan.hby@alibaba-inc.com; lh.wang1@siat.ac.cn; min.yang@siat.ac.cn; binhua.lbh@alibaba-inc.com; f.huang@alibaba-inc.com; luo.si@alibaba-inc.com; qs.jiang@siat.ac.cn; shuide.lyb@alibaba-inc.com
FU National Natural Science Foundation of China [61906185, 61876053]; National Key Re- search and Development Program of China [2022YFF0902100]; Youth Innovation Promotion Association of CAS China [2020357]; Shenzhen Science and Technology Innovation Program, China [KQTD20190929172835662]; Shenzhen Basic Re- search Foundation, China [JCYJ20210324115614039, JCYJ20200109113441941]; Alibaba Group, China through Alibaba Innovative Research Program
CR [Anonymous], 2014, 28 C NEUR INF PROC S, V0, P0
   Bengio Y, 2009, P 26 ANN INT C MACHI, V0, P0, DOI DOI 10.1145/1553374.1553380
   Berant J, 2013, P 2013 C EMPIRICAL M, V0, P0
   Bhagavatula CS, 2015, LECT NOTES COMPUT SC, V9366, P425, DOI 10.1007/978-3-319-25007-6_25
   Bogin B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4560
   Cai Z, 2022, EMNLP, V0, P0
   Cao RS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2541
   Chen Z, 2021, NAACL, V0, P0
   Choi D, 2020, RYANSQL RECURSIVELY, V0, P0
   Deng X, 2021, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731
   dos Santos CN, 2021, PROC AAAI, V0, P0
   Dozat T, 2017, ICLR, V0, P0
   Gan Y, 2021, EMNLP, V0, P0
   Patro SGK, 2015, ARXIV, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Guo JQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4524
   Gururangan Suchin, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Herzig J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4320
   Huang J, 2021, PREPRINT, V0, P0
   Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089
   Kendall A, 2018, PROC CVPR IEEE, V0, PP7482, DOI 10.1109/CVPR.2018.00781
   Lewis M, 2019, ARXIV, V0, P0
   Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468
   Lin Xi Victoria, 2020, FINDINGS EMNLP, V0, P0
   Liu Y, 2019, ROBUSTLY OPTIMIZED B, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Loshchilov Ilya, 2019, ARXIV, V0, P0
   Platanios EA, 2019, PROC NAACL, V0, P0
   Rosset C, 2020, ARXIV, V0, P0
   Rubin O, 2021, SPNLP 2021: THE 5TH WORKSHOP ON STRUCTURED PREDICTION FOR NLP, V0, P12
   Scholak T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P9895
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi P, 2021, AAAI CONF ARTIF INTE, V35, P13806
   Shi T, 2020, ARXIV, V0, P0
   Wang B, 2020, P ACL, V0, P0
   Wang B, 2021, PROC NAACL, V0, P0
   Wang B, 2020, P 58 ANN M ASS COMP, V0, P7567
   Wang L, 2020, EMNLP, V0, P0
   Wang R, 2020, ARXIV, V0, P0
   Wang X, 2021, ARXIV, V0, P0
   Wong YW, 2007, P 45 ANN M ASS COMP, V0, P960
   Xiong WH, 2019, ARXIV, V0, P0
   Xuan K, 2021, ARXIV, V0, P0
   Yaghmazadeh N, 2017, PROC ACM PROGRAMM LA, V0, P0
   Yin P, 2020, P 58 ANN M ASS COMP, V0, PP8413, DOI 10.18653/V1/2020.ACL-MAIN.745
   Yu T, 2021, ICLR, V0, P0
   Yu T, 2021, P ICLR, V0, P0
   Yu T, 2018, PROC NAACL, V0, P0
   Yu T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4511
   Yu T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1962
   Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3911
   Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050
   Zettlemoyer L, 2007, P 2007 JOINT C EMP M, V0, P0
   Zettlemoyer Luke S, 2005, P 21 C UNC ART INT, V0, P658
   Zhang R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5338
   Zhao C, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5568
   Zhong V, 2017, PREPRINT, V0, P0
   Zhong Victor, 2017, SEQ2SQL GENERATING S, V0, P0
NR 60
TC 0
Z9 0
U1 6
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD FEB 28
PY 2023
VL 262
IS 
BP 
EP 
DI 10.1016/j.knosys.2023.110264
EA JAN 2023
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 8H1WH
UT WOS:000920827000001
DA 2023-11-10
ER

PT J
AU Zhang, YZ
AF Zhang, Yanzi
TI Relation extraction in Chinese using attention-based bidirectional long short- term networks
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Data science; Deep learning; NLP; Artificial intelligence; Relation extraction
ID graph
AB Relation extraction is an important topic in information extraction, as it is used to create large-scale knowledge graphs for a variety of downstream applications. Its goal is to find and extract semantic links between entity pairs in natural language sentences. Deep learning has substantially advanced neural relation extraction, allowing for the autonomous learning of semantic features. We offer an effective Chinese relation extraction model that uses bidirectional LSTM (Bi-LSTM) and an attention mechanism to extract crucial semantic information from phrases without relying on domain knowledge from lexical resources or language systems in this study. The attention mechanism included into the Bi-LSTM network allows for automatic focus on key words. Two benchmark datasets were used to create and test our models: Chinese SanWen and FinRE. The experimental results show that the SanWen dataset model outperforms the FinRE dataset model, with area under the receiver operating characteristic curve values of 0.70 and 0.50, respectively. The models trained on the SanWen and FinRE datasets achieve values of 0.44 and 0.19, respectively, for the area under the precision-recall curve. In addition, the results of repeated modeling experiments indicated that our proposed method was robust and reproducible.
C1 [Zhang, Yanzi] Jinan Univ, Coll Chinese Language & Culture, Guangzhou, Peoples R China.
C3 Jinan University
RP Zhang, YZ (通讯作者)，Jinan Univ, Coll Chinese Language & Culture, Guangzhou, Peoples R China.
EM qingwuyuer1986@163.com
FU Language Ecology Research and Language Resource Database Construction in The South China Sea Project [25016207]
CR Chen Xinchi, 2015, P 2015 C EMPIRICAL M, V0, PP1197, DOI 10.18653/V1/D15-1141
   Chen Y, 2014, P 52 ANN M ASS COMP, V1, P0
   Chen YJ, 2016, AAAI WORKSHOP KNOWLE, V0, P0
   Chorowski J, 2015, ARXIV, V0, P0
   ChunYang Liu, 2013, ADVANCED DATA MINING AND APPLICATIONS. 9TH INTERNATIONAL CONFERENCE, V0, P231, DOI 10.1007/978-3-642-53917-6_21
   Daojian Zeng, 2014, P COLING 25 INT C CO, V0, P2335
   Dong CH, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3554727
   EHinton Geoffrey, 2012, ARXIV, V0, P0
   Geng ZQ, 2020, INFORM SCIENCES, V509, P183, DOI 10.1016/j.ins.2019.09.006
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, ARXIV, V0, P0
   Huang L, 2019, ARXIV, V0, P0
   Jiang X, 2016, P COLING 26 INT C CO, V0, P1471
   Konstantinova N, 2014, COMM COM INF SC, V436, P15, DOI 10.1007/978-3-319-12580-0_2
   Li L, 2023, INFORM FUSION, V99, P0, DOI 10.1016/j.inffus.2023.101862
   Li ZR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4377
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Liu XE, 2023, ELECTRONICS-SWITZ, V12, P0, DOI 10.3390/electronics12102320
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P1978, DOI 10.1109/TIP.2022.3147032
   Lu JS, 2017, ARXIV, V0, P0
   Lu SY, 2023, PEERJ COMPUT SCI, V9, P0, DOI 10.7717/peerj-cs.1400
   Luong MT, 2015, ARXIV, V0, P0
   Peng NY, 2017, ARXIV, V0, P0
   Ronnqvist S, 2017, P 55 ANN M ASS COMP, V2, P0
   Shen Y, 2021, IEEE T KNOWL DATA EN, V33, P3607, DOI 10.1109/TKDE.2020.2970044
   Tai KS, 2015, ARXIV, V0, P0
   Sperber M, 2017, ARXIV, V0, P0
   Su JS, 2016, ARXIV, V0, P0
   Sun L, 2017, ARXIV, V0, P0
   Wang Yan, 2023, IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, V0, PP6144, DOI 10.1109/TCSVT.2023.3254530
   Wang YH, 2022, IEEE T CIRC SYST VID, V32, P4417, DOI 10.1109/TCSVT.2021.3121062
   Xu JJ, 2019, ARXIV, V0, P0
   Yang J, 2017, ARXIV, V0, P0
   Yanjun Qi, 2014, ADVANCES IN INFORMATION RETRIEVAL. 36TH EUROPEAN CONFERENCE ON IR RESEARCH, V0, P668, DOI 10.1007/978-3-319-06028-6_74
   Zeng D, 2015, P 2015 C EMPIRICAL M, V0, P1753
   Zhang DX, 2015, ARXIV, V0, P0
   Zhang Q, 2017, DESTECH T COMPUTER S, V0, P0
   Zhang Y, 2018, ARXIV, V0, P0
   Zhao H, 2008, P 6 SIGHAN WORKSHOP, V0, P0
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 40
TC 0
Z9 0
U1 4
U2 4
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD AUG 17
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1509
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA P7RE3
UT WOS:001052600400004
DA 2023-11-10
ER

PT J
AU Liang, C
   Wang, WG
   Zhou, TF
   Miao, JX
   Luo, YW
   Yang, Y
AF Liang, Chen
   Wang, Wenguan
   Zhou, Tianfei
   Miao, Jiaxu
   Luo, Yawei
   Yang, Yi
TI Local-Global Context Aware Transformer for Language-Guided Video Segmentation
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Transformers; Task analysis; Visualization; Three-dimensional displays; Linguistics; Object segmentation; Grounding; Language-guided video segmentation; memory network; multi-modal transformer
AB We explore the task of language-guided video segmentation (LVS). Previous algorithms mostly adopt 3D CNNs to learn video representation, struggling to capture long-term context and easily suffering from visual-linguistic misalignment. In light of this, we present LOCATER (local-global context aware Transformer), which augments the Transformer architecture with a finite memory so as to query the entire video with the language expression in an efficient manner. The memory is designed to involve two components - one for persistently preserving global video content, and one for dynamically gathering local temporal context and segmentation history. Based on the memorized local-global context and the particular content of each frame, LOCATER holistically and flexibly comprehends the expression as an adaptive query vector for each frame. The vector is used to query the corresponding frame for mask generation. The memory also allows LOCATER to process videos with linear time complexity and constant size memory, while Transformer-style self-attention computation scales quadratically with sequence length. To thoroughly examine the visual grounding capability of LVS models, we contribute a new LVS dataset, A2D-S+, which is built upon A2D-S dataset but poses increased challenges in disambiguating among similar objects. Experiments on three LVS datasets and our A2D-S+ show that LOCATER outperforms previous state-of-the-arts. Further, we won the 1st place in the Referring Video Object Segmentation Track of the 3rd Large-scale Video Object Segmentation Challenge, where LOCATER served as the foundation for the winning solution.
C1 [Liang, Chen; Wang, Wenguan; Miao, Jiaxu; Luo, Yawei; Yang, Yi] Zhejiang Univ, ReLER, CCAI, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhou, Tianfei] Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.
C3 Zhejiang University; Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Yang, Y (通讯作者)，Zhejiang Univ, ReLER, CCAI, Hangzhou 310027, Zhejiang, Peoples R China.
EM leonliang@zju.edu.cn; wenguanwang.ai@gmail.com; ztfei.debug@gmail.com; jiaxu.miao@yahoo.com; yaweiluo329@gmail.com; yangyics@zju.edu.cn
FU National Key R&D Program of China [2020AAA0108800]; Fundamental Research Funds for the Central Universities [226-2022-00051]
CR Bahdanau D, 2016, ARXIV, V0, P0
   Bajaj M, 2019, IEEE I CONF COMP VIS, V0, PP4280, DOI 10.1109/ICCV.2019.00438
   Beltagy I, 2020, ARXIV, V0, P0
   Botach A, 2022, PROC CVPR IEEE, V0, PP4975, DOI 10.1109/CVPR52688.2022.00493
   Caelles S, 2017, PROC CVPR IEEE, V0, PP5320, DOI 10.1109/CVPR.2017.565
   Carion Nicolas, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12346), V0, PP213, DOI 10.1007/978-3-030-58452-8_13
   Carreira J, 2017, PROC CVPR IEEE, V0, PP4724, DOI 10.1109/CVPR.2017.502
   Child R, 2019, ARXIV, V0, P0
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Deng Jiajun, 2021, PROC IEEE INT C COMP, V0, P1769
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding Henghui, 2021, P IEEE CVF INT C COM, V0, P16321
   Ding Z, 2021, 3 LARGE SCALE VIDEO, V0, P7
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R, V0, P0
   Feng G, 2021, PROC CVPR IEEE, V0, PP15501, DOI 10.1109/CVPR46437.2021.01525
   Feng Q, 2021, PROC CVPR IEEE, V0, PP5847, DOI 10.1109/CVPR46437.2021.00579
   Gabeur Valentin, 2020, ECCV, V0, PP2, DOI 10.1007/978-3-030-58548-8_13
   Gavrilyuk K, 2018, PROC CVPR IEEE, V0, PP5958, DOI 10.1109/CVPR.2018.00624
   Gen Luo, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10031, DOI 10.1109/CVPR42600.2020.01005
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2014, ARXIV, V0, P0
   Hao Weituo, 2020, P IEEE CVF C COMP VI, V0, PP13137, DOI 10.1109/CVPR42600.2020.01315
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu R, 2020, P IEEE CVF C COMP VI, V0, PP9992, DOI 10.1109/CVPR42600.2020.01001
   Hu RH, 2017, PROC CVPR IEEE, V0, PP4418, DOI 10.1109/CVPR.2017.470
   Hu RH, 2016, PROC CVPR IEEE, V0, PP4555, DOI 10.1109/CVPR.2016.493
   Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7
   Huang Shaofei, 2020, P IEEE CVF C COMP VI, V0, PP10488, DOI 10.1109/CVPR42600.2020.01050
   Huang ZH, 2015, ARXIV, V0, P0
   Hui TR, 2021, PROC CVPR IEEE, V0, PP4185, DOI 10.1109/CVPR46437.2021.00417
   Hui Tianrui, 2020, PROC EUR C COMPUT VI, V0, PP59, DOI 10.1007/978-3-030-58607-2_4
   Jampani V, 2017, PROC CVPR IEEE, V0, PP3154, DOI 10.1109/CVPR.2017.336
   Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP1760, DOI 10.1109/ICCV48922.2021.00180
   Katharopoulos A, 2020, PR MACH LEARN RES, V119, P0
   Khoreva A, 2019, LECT NOTES COMPUT SC, V11364, P123, DOI 10.1007/978-3-030-20870-7_8
   Kingma DP, 2017, PROC 3 INT C LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lei J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2603
   Li DZ, 2022, AAAI CONF ARTIF INTE, V0, P1297
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li Liulei, 2022, P IEEECVF C COMPUTER, V0, P8719
   Li Muchen, 2021, P ADV NEUR INF PROC, V34, P19652
   Li RY, 2018, PROC CVPR IEEE, V0, PP5745, DOI 10.1109/CVPR.2018.00602
   Li ZY, 2017, PROC CVPR IEEE, V0, PP7350, DOI 10.1109/CVPR.2017.777
   Liang C, 2021, ARXIV, V0, P0
   Liang C, 2022, P ADV NEUR INF PROC, V0, P1
   Liang C, 2022, PROC CVPR IEEE, V0, PP15544, DOI 10.1109/CVPR52688.2022.01512
   Liao Yue, 2020, CVPR, V0, PP10880, DOI 10.1109/CVPR42600.2020.01089
   Liu CX, 2017, IEEE I CONF COMP VIS, V0, PP1280, DOI 10.1109/ICCV.2017.143
   Liu XH, 2019, PROC CVPR IEEE, V0, PP1950, DOI 10.1109/CVPR.2019.00205
   Liu Z, 2022, PROC CVPR IEEE, V0, PP3192, DOI 10.1109/CVPR52688.2022.00320
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Luo RT, 2017, PROC CVPR IEEE, V0, PP3125, DOI 10.1109/CVPR.2017.333
   Mao JH, 2016, PROC CVPR IEEE, V0, PP11, DOI 10.1109/CVPR.2016.9
   Margffoy-Tuay E, 2018, LECT NOTES COMPUT SC, V11215, P656, DOI 10.1007/978-3-030-01252-6_39
   McIntosh Bruce, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9939, DOI 10.1109/CVPR42600.2020.00996
   Miao JX, 2021, PROC CVPR IEEE, V0, PP4131, DOI 10.1109/CVPR46437.2021.00412
   Miech A, 2021, PROC CVPR IEEE, V0, PP9821, DOI 10.1109/CVPR46437.2021.00970
   Murahari Vishvak, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12363), V0, PP336, DOI 10.1007/978-3-030-58523-5_20
   Nicolicioiu A, 2019, ADV NEUR IN, V32, P0
   Ning K, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P948
   Oh J, 2016, PR MACH LEARN RES, V48, P0
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Parisotto E, 2019, PROC INT C LEARN REP, V0, P0
   Perazzi F, 2016, PROC CVPR IEEE, V0, PP724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2017, PROC CVPR IEEE, V0, PP3491, DOI 10.1109/CVPR.2017.372
   Piergiovanni AJ, 2018, PROC CVPR IEEE, V0, PP5304, DOI 10.1109/CVPR.2018.00556
   Pradhan Sameer, 2013, P 17 C COMPUTATIONAL, V0, P143
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P101
   Qin Z, 2023, IEEECAA J AUTOM SINI, V10, P1
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sadhu Arka, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10414, DOI 10.1109/CVPR42600.2020.01043
   Seonguk Seo, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12360), V0, PP208, DOI 10.1007/978-3-030-58555-6_13
   Shi HC, 2018, LECT NOTES COMPUT SC, V11210, P38, DOI 10.1007/978-3-030-01231-1_3
   Shi P, 2019, ARXIV, V0, P0
   SIEGELMANN HT, 1995, J COMPUT SYST SCI, V50, P132, DOI 10.1006/jcss.1995.1013
   Simonyan K, 2015, VERY DEEP CONVOLUTIO, V0, P1
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5027
   Su Weijie, 2020, PROC INT C LEARN REP, V0, P0
   Sukhbaatar S, 2015, ADV NEUR IN, V28, P0
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Urooj A, 2020, FIND 2020 C EMP METH, V0, P0, DOI DOI 10.18653/v1/2020.findings-emnlp.417
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Voigtlaender Paul, 2017, ARXIV170609364, V0, P0, DOI DOI 10.5244/C.31.116
   Wang HQ, 2023, INT J COMPUT VISION, V131, P607, DOI 10.1007/s11263-022-01721-6
   Wang H, 2020, AAAI CONF ARTIF INTE, V34, P12152
   Wang H, 2019, IEEE I CONF COMP VIS, V0, PP3938, DOI 10.1109/ICCV.2019.00404
   Wang P, 2019, PROC CVPR IEEE, V0, PP1960, DOI 10.1109/CVPR.2019.00206
   Wang SN, 2020, ARXIV, V0, P0
   Wang WL, 2022, INFOMAT, V4, P0, DOI 10.1002/inf2.12262
   Wang WG, 2022, ARXIV, V0, P0
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P2413, DOI 10.1109/TPAMI.2020.2966453
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173
   Wang X, 2023, PROC IEEE C COMPUT V, V0, P0
   Wang XH, 2023, IEEE T PATTERN ANAL, V45, P6605, DOI 10.1109/TPAMI.2020.3015894
   Wang YQ, 2021, PROC CVPR IEEE, V0, PP8737, DOI 10.1109/CVPR46437.2021.00863
   Weston J, 2015, PROC INT C LEARN REP, V0, P0
   Wu JN, 2022, PROC CVPR IEEE, V0, PP4964, DOI 10.1109/CVPR52688.2022.00492
   Xiankai Lu, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12348), V0, PP661, DOI 10.1007/978-3-030-58580-8_39
   Xiao W, 2021, P IEEE CVF C COMP VI, V0, P13763
   Xie SN, 2015, IEEE I CONF COMP VIS, V0, PP1395, DOI 10.1109/ICCV.2015.164
   Yang SB, 2021, PROC CVPR IEEE, V0, PP11261, DOI 10.1109/CVPR46437.2021.01111
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yang Z, 2022, ADV NEURAL INFORM PR, V0, P0
   Yang Z, 2021, PROC BRIT MACH VIS C, V0, P0
   Yang ZY, 2019, IEEE I CONF COMP VIS, V0, PP4682, DOI 10.1109/ICCV.2019.00478
   Yang ZX, 2022, IEEE T PATTERN ANAL, V44, P4701, DOI 10.1109/TPAMI.2021.3081597
   Yang Zongxin, 2021, ADV NEURAL INFORM PR, V0, P2491
   Ye LW, 2019, PROC CVPR IEEE, V0, PP10494, DOI 10.1109/CVPR.2019.01075
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yoon JS, 2017, IEEE I CONF COMP VIS, V0, PP2186, DOI 10.1109/ICCV.2017.238
   youtube vos, 2021, 3 LARGE SCALE VIDEO, V0, P0
   Yu LC, 2017, PROC CVPR IEEE, V0, PP3521, DOI 10.1109/CVPR.2017.375
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zhang MX, 2021, PROC CVPR IEEE, V0, PP12664, DOI 10.1109/CVPR46437.2021.01248
   Zhu Linchao, 2020, P IEEE CVF C COMP VI, V0, PP8746, DOI 10.1109/CVPR42600.2020.00877
NR 122
TC 3
Z9 3
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD AUG 15
PY 2023
VL 45
IS 8
BP 10055
EP 10069
DI 10.1109/TPAMI.2023.3262578
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA L4KG5
UT WOS:001022958600052
PM 37819831
DA 2023-11-10
ER

PT J
AU Sirasapalli, JJ
   Malla, RM
AF Sirasapalli, Joshua Johnson
   Malla, Ramakrishna Murty
TI A deep learning approach to text-based personality prediction using multiple data sources mapping
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article; Early Access
DE Personality detection; BERT; Deep learning; Social media; Data mapping; Data fusion
ID briggs type indicator; 5-factor model; performance; leadership; behavior; traits; impact
AB Automated personality traits prediction from widely available social media text data, is finding its increased applications in recommender systems, psychology, forecasting, and decision making. The aim of this research is to break the digital text data into features, analyse and map it to an appropriate personality model. Because of its simplicity and shown competence, a well-known personality model known as the Big Five personality characteristics has frequently been welcomed in the literature as the norm for personality evaluation. Recent advances in automated personality detection have focused on including sentiments, emotions, linguistic styles, and other natural language processing techniques. All these approaches are proposed by a fact concerned with the limited amount of data available for processing by deep learning algorithms. Personality datasets with conventional personality labels are few, and collecting them is challenging due to privacy concerns, as well as the high expense of hiring expert psychologists to label them. The performance of the model can even be increased if a large amount of labelled data is available. This research proposes a new personality prediction model using data source mapping and data fusion techniques. The results are evident that the proposed methodology has outperformed the existing methodologies. To be more precise, the results had the highest accuracy of 87.89% and 0.924 F1 measure score after mapping MBTI into Big Five personality traits and later, fusion with Essays and myPersonality datasets.
C1 [Sirasapalli, Joshua Johnson; Malla, Ramakrishna Murty] Andhra Univ, Dept Comp Sci & Syst Engn, Visakhapatnam, India.
C3 Andhra University
RP Sirasapalli, JJ (通讯作者)，Andhra Univ, Dept Comp Sci & Syst Engn, Visakhapatnam, India.
EM joshua.cse@anits.edu.in; mramakrishna.cse@anits.edu.in
CR Adamopoulos P, 2018, INFORM SYST RES, V29, P612, DOI 10.1287/isre.2017.0768
   Alam Firoj, 2013, P INT AAAI C WEB SOC, V7, P6
   [Anonymous], 2018, 15 INT C SERVICE SYS, V0, P0
   [Anonymous], 2013, P 7 INT AAAI C WEBLO, V0, P0
   Bazelli B, 2013, PROC IEEE INT CONF S, V0, PP460, DOI 10.1109/ICSM.2013.72
   Cattell HE, 2008, 16 PERSONALITY FACTO, V0, P0
   Celli F, 2013, AAAI WORKSH TECHN RE, VWS-13-01, P2
   Christian H, 2021, J BIG DATA-GER, V8, P0, DOI 10.1186/s40537-021-00459-1
   Costa Paul T, 1998, ADV PERSONALITY, V0, PP103, DOI 10.1007/978-1-4419-8580-4_5
   Crayne MP, 2021, AM PSYCHOL, V76, P462, DOI 10.1037/amp0000715
   Dalvi-Esfahani M, 2021, TELEMAT INFORM, V57, P0, DOI 10.1016/j.tele.2020.101516
   Devlin J, 2019, ARXIV, V0, P0
   Du K-L, 2019, NEURAL NETWORKS STAT, V0, P0
   El-Demerdash K, 2022, EGYPT INFORM J, V23, P47, DOI 10.1016/j.eij.2021.05.004
   Elmitwally NS, 2022, CMC-COMPUT MATER CON, V70, P4947, DOI 10.32604/cmc.2022.021104
   Furnham A, 1996, PERS INDIV DIFFER, V21, P303, DOI 10.1016/0191-8869(96)00033-5
   Furnham A, 2003, SOC BEHAV PERSONAL, V31, P577, DOI 10.2224/sbp.2003.31.6.577
   Golbeck JA, 2016, AIS T REPLICATION RE, V2, P0, DOI 10.17705/1ATRR.00009
   Guest JL, 2020, JMIR PUBLIC HLTH SUR, V6, P4, DOI 10.2196/19043
   Han SQ, 2020, KNOWL-BASED SYST, V194, P0, DOI 10.1016/j.knosys.2020.105550
   Hernandez R, 2017, 31 C NEUR INF PROC S, V0, P4
   Howlader P, 2018, P ACM S APPL COMPUT, V0, P0, DOI DOI 10.1145/3167132.3167166
   Judge TA, 2002, J APPL PSYCHOL, V87, P765, DOI 10.1037/0021-9010.87.4.765
   Judge TA, 2009, LEADERSHIP QUART, V20, P855, DOI 10.1016/j.leaqua.2009.09.004
   Kerz E, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2204.04629
   Khurana D, 2018, PREPRINT, V0, P0
   Kircaburun K, 2020, INT J MENT HEALTH AD, V18, P525, DOI 10.1007/s11469-018-9940-6
   Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110
   Krushnasamy VS, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), V0, PP694, DOI 10.1109/ICIMIA.2017.7975553
   LePine JA, 2001, J APPL PSYCHOL, V86, P326, DOI 10.1037//0021-9010.86.2.326
   Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23
   MCCRAE RR, 1989, J PERS, V57, P17, DOI 10.1111/j.1467-6494.1989.tb00759.x
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mehta Y, 2020, IEEE DATA MINING, V0, PP1184, DOI 10.1109/ICDM50108.2020.00146
   Mehta Y, 2020, ARTIF INTELL REV, V53, P2313, DOI 10.1007/s10462-019-09770-z
   Nadkarni S, 2010, ACAD MANAGE J, V53, P1050, DOI 10.5465/AMJ.2010.54533196
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Pennebaker JW, 2001, LINGUISTIC INQUIRY W, V0, P0, DOI DOI 10.4018/978-1-60960-741-8.CH012
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Peterson RS, 2003, J APPL PSYCHOL, V88, P795, DOI 10.1037/0021-9010.88.5.795
   Prantik H, 2018, P 33 ANN ACM S APPL, V0, P0
   Pratama BY, 2015, 2015 INTERNATIONAL CONFERENCE ON DATA AND SOFTWARE ENGINEERING (ICODSE), V0, PP170, DOI 10.1109/ICODSE.2015.7436992
   Ren ZC, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102532
   Riaz MN, 2012, J BEHAV SCI, V22, P99
   Sun X, 2018, 14 IEEE INT C SOLID, V0, PP1, DOI 10.1109/ICC.2018.8422105
   Tadesse MM, 2018, IEEE ACCESS, V6, P61959, DOI 10.1109/ACCESS.2018.2876502
   Tandera T, 2017, PROCEDIA COMPUT SCI, V116, P604, DOI 10.1016/j.procs.2017.10.016
   Vilares D, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), V0, PP1292, DOI 10.1109/SSCI.2018.8628718
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Xue D, 2018, APPL INTELL, V48, P4232, DOI 10.1007/s10489-018-1212-4
   Yang T, 2023, ARXIV, V0, P0
   Yu JG, 2017, INT CONF AWARE SCI, V0, PP383, DOI 10.1109/ICAwST.2017.8256484
   Zheng HC, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, V0, PP53, DOI 10.1145/3318299.3318363
   Zhu YF, 2022, KNOWL-BASED SYST, V249, P0, DOI 10.1016/j.knosys.2022.108952
NR 54
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s00521-023-08846-w
EA JUL 2023
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA N1HJ9
UT WOS:001034605100001
DA 2023-11-10
ER

PT J
AU Correia, A
   Guimaraes, D
   Paredes, H
   Fonseca, B
   Paulino, D
   Trigo, L
   Brazdil, P
   Schneider, D
   Grover, A
   Jameel, S
AF Correia, Antonio
   Guimaraes, Diogo
   Paredes, Hugo
   Fonseca, Benjamim
   Paulino, Dennis
   Trigo, Luis
   Brazdil, Pavel
   Schneider, Daniel
   Grover, Andrea
   Jameel, Shoaib
TI NLP-Crowdsourcing Hybrid Framework for Inter-Researcher Similarity Detection
SO IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS
LA English
DT Article; Early Access
DE Adaptive human-machine systems; bidirectional language models; crowdsourcing; human-computer interaction (HCI); natural language processing (NLP); text-based similarity algorithms; term frequency-inverse document frequency (TF-IDF)
AB Visualizing and examining the intellectual landscape and evolution of scientific communities to support collaboration is crucial for multiple research purposes. In some cases, measuring similarities and matching patterns between research publication document sets can help to identify people with similar interests for building research collaboration networks and university-industry linkages. The premise of this work is assessing feasibility for resolving ambiguous cases in similarity detection to determine authorship with natural language processing (NLP) techniques so that crowdsourcing is applied only in instances that require human judgment. Using an NLP-crowdsourcing convergence strategy, we can reduce the costs of microtask crowdsourcing while saving time and maintaining disambiguation accuracy over large datasets. This article contributes a next-gen crowd-artificial intelligence framework that used an ensemble of term frequency-inverse document frequency and bidirectional encoder representation from transformers to obtain similarity rankings for pairs of scientific documents. A sequence of content-based similarity tasks was created using a crowd-powered interface for solving disambiguation problems. Our experimental results suggest that an adaptive NLP-crowdsourcing hybrid framework has advantages for inter-researcher similarity detection tasks where fully automatic algorithms provide unsatisfactory results, with the goal of helping researchers discover potential collaborators using data-driven approaches.
C1 [Correia, Antonio; Guimaraes, Diogo; Paredes, Hugo; Fonseca, Benjamim; Paulino, Dennis; Trigo, Luis; Brazdil, Pavel] INESC TEC, P-4200465 Porto, Portugal.
   [Correia, Antonio; Guimaraes, Diogo; Paredes, Hugo; Fonseca, Benjamim; Paulino, Dennis] Univ Tras Os Montes & Alto Douro, P-5000801 Vila Real, Portugal.
   [Trigo, Luis; Brazdil, Pavel] Univ Porto, P-4200465 Porto, Portugal.
   [Schneider, Daniel] Univ Fed Rio de Janeiro, BR-21941916 Rio De Janeiro, Brazil.
   [Grover, Andrea] Univ Nebraska, Omaha, NE 68182 USA.
   [Jameel, Shoaib] Univ Southampton, Southampton SO17 1BJ, England.
C3 INESC TEC; University of Tras-os-Montes & Alto Douro; Universidade do Porto; Universidade Federal do Rio de Janeiro; University of Nebraska System; University of Southampton
RP Correia, A (通讯作者)，INESC TEC, P-4200465 Porto, Portugal.
EM antonio.g.correia@inesctec.pt; diogo.j.pereira@inesctec.pt; hparedes@utad.pt; benjaf@utad.pt; dennis.l.paulino@inesctec.pt; luis.p.trigo@inesctec.pt; pavel.brazdil@inesctec.pt; schneider@nce.ufrj.br; andreagrover@unomaha.edu; m.s.jameel@southampton.ac.uk
FU National Funds Through the Portuguese Funding Agency; Fundaco Para a Ciencia e a Tecnologia [UIDB/50014/2020, SFRH/BD/136211/2018]
CR Ahlgren P, 2009, J INFORMETR, V3, P49, DOI 10.1016/j.joi.2008.11.003
   Alzubi JA, 2020, J INTELL FUZZY SYST, V39, P1021, DOI 10.3233/JIFS-191933
   Alzubi OA, 2022, CLUSTER COMPUT, V25, P2369, DOI 10.1007/s10586-021-03459-1
   Alzubi OA, 2020, NEURAL COMPUT APPL, V32, P16091, DOI 10.1007/s00521-020-04761-6
   Andre P, 2013, P AAAI C HUM COMP CR, V0, P9
   Ayoub J, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102569
   Benazir A, 2020, 2020 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2020), V0, PP837, DOI 10.1109/WIIAT50758.2020.00129
   Bhatti SS, 2020, J SYST SOFTWARE, V167, P0, DOI 10.1016/j.jss.2020.110611
   Brabham DC, 2017, INT ENCY ORG COMMUNI, V0, P0
   Bragg J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, V0, PP165, DOI 10.1145/3242587.3242598
   Brown PF, 1990, COMPUTATIONAL LINGUISTICS, V16, P79
   Cabanac G, 2011, SCIENTOMETRICS, V87, P597, DOI 10.1007/s11192-011-0358-1
   Chan Joel, 2018, PROCEEDINGS OF THE ACM ON HUMAN-COMPUTER INTERACTION, V2, P0, DOI 10.1145/3274300
   Chandrasekaran D, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3440755
   Cheng Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, PP1213, DOI 10.1145/2505515.2507858
   Christenson DP, 2013, POLITICAL METHODOLOG, V20, P27
   Correia A, 2023, ARTIF INTELL REV, V56, P983, DOI 10.1007/s10462-023-10548-7
   Correia A, 2023, APPL SCI-BASEL, V13, P0, DOI 10.3390/app13042198
   Correia A, 2021, INT C COMP SUPP COOP, V0, PP150, DOI 10.1109/CSCWD49262.2021.9437769
   Ferrara A, 2012, SCIENTOMETRICS, V93, P765, DOI 10.1007/s11192-012-0810-x
   Foltynek T, 2020, ACM COMPUT SURV, V52, P0, DOI 10.1145/3345317
   Fortunato S, 2018, SCIENCE, V359, P0, DOI 10.1126/science.aao0185
   Harris CG, 2019, LECT NOTES COMPUT SC, V11701, P75, DOI 10.1007/978-3-030-29374-1_7
   Haruna CR, 2018, COMM COM INF SC, V879, P153, DOI 10.1007/978-981-13-3095-7_12
   Hewett TT, 1992, ACM SIGCHI CURRICULA, V0, P0
   Hope T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P135
   Huber DJ, 2019, IEEE INT CONF BIG DA, V0, P2028
   Izacard G, 2022, P 46 INT ACM SIGIR C, V0, P1
   Kim M, 2018, APPL SOFT COMPUT, V66, P506, DOI 10.1016/j.asoc.2017.09.028
   Kim SW, 2019, HUM-CENT COMPUT INFO, V9, P0, DOI 10.1186/s13673-019-0192-7
   Law E, 2011, SYNTH LECT ARTIF INT, V5, P1
   Li G, 2013, P INT C WEB AG INF M, V0, P179
   Li Yang, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SYSTEMS AND INFORMATICS (ICSAI), V0, PP492, DOI 10.1109/ICSAI48974.2019.9010163
   Lowry CS, 2013, GROUND WATER, V51, P151, DOI 10.1111/j.1745-6584.2012.00956.x
   Lu K, 2012, J AM SOC INF SCI TEC, V63, P1973, DOI 10.1002/asi.22628
   Massung E, 2013, P SIGCHI C HUM FACT, V0, PP371, DOI 10.1145/2470654.2470708
   Moradi Morteza, 2019, INTERNATIONAL JOURNAL OF CROWD SCIENCE, V3, P0, DOI 10.1108/IJCS-03-2019-0012
   Mortensen ML, 2017, RES SYNTH METHODS, V8, P366, DOI 10.1002/jrsm.1252
   Movassagh AA, 2021, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-020-02623-6
   Murray-Rust D, 2014, 2014 INTERNATIONAL CONFERENCE ON COLLABORATIVE COMPUTING: NETWORKING, V0, P84, DOI 10.4108/icst.collaboratecom.2014.257245
   Nushi B, 2018, P C EMP METH NAT LAN, V0, P126
   Ofli F, 2016, BIG DATA-US, V4, P47, DOI 10.1089/big.2014.0064
   Onan A, 2019, IEEE ACCESS, V7, P145614, DOI 10.1109/ACCESS.2019.2945911
   Onan A, 2019, SCI PROGRAMMING-NETH, V2019, P0, DOI 10.1155/2019/5901087
   Onan A, 2017, J INF SCI, V43, P25, DOI 10.1177/0165551515613226
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   Palmer MS, 2021, HUM COMPUT, V8, P54, DOI 10.15346/hc.v8i2.123
   Pradhan T, 2020, FUTURE GENER COMP SY, V110, P1139, DOI 10.1016/j.future.2019.11.017
   Rahmanian B, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, V0, P405, DOI 10.1145/2598153.2602248
   Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290
   Ramirez J, 2018, COLLECTIVE INTELL, V1, P1
   Ramirez J, 2021, P ACM HUM COMP INT, V0, P1
   Samghabadi NS, 2020, P 2 WORKSH TROLL AGG, V0, P126
   Sarmento RP, 2021, SOC NETW ANAL MIN, V11, P0, DOI 10.1007/s13278-021-00826-z
   Seeber I, 2020, INFORM MANAGE-AMSTER, V57, P0, DOI 10.1016/j.im.2019.103174
   Sexton T, 2017, IEEE INT CONF BIG DA, V0, PP1769, DOI 10.1109/BigData.2017.8258120
   Szyperski C, 2003, PROC INT CONF SOFTW, V0, PP684, DOI 10.1109/ICSE.2003.1201255
   Takoulidou E, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), V0, PP53, DOI 10.1109/SMAP.2016.7753384
   Tchoua RB, 2017, P IEEE INT C E-SCI, V0, PP109, DOI 10.1109/eScience.2017.23
   Trigo Luis, 2015, IC3K 2015. 7TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, V0, P452
   Wang D, 2019, P P ACM HUM COMP INT, V0, P1
   Wang HW, 2020, AAAI CONF ARTIF INTE, V34, P238
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Zhang CJ, 2020, IEEE T KNOWL DATA EN, V32, P135, DOI 10.1109/TKDE.2018.2881185
   Zhang D, 2019, INT CON DISTR COMP S, V0, PP1221, DOI 10.1109/ICDCS.2019.00123
   Zhang YT, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1002, DOI 10.1145/3219819.3219859
   Zhou M, 2020, ENGINEERING-PRC, V6, P275, DOI 10.1016/j.eng.2019.12.014
   Zhuang Y, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP1917, DOI 10.1145/3132847.3132912
NR 68
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2291
EI 2168-2305
J9 IEEE T HUM-MACH SYST
JI IEEE T. Hum.-Mach. Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1109/THMS.2023.3319290
EA OCT 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA U7GM2
UT WOS:001086452000001
DA 2023-11-10
ER

PT J
AU Zhao, B
   Jin, WQ
   Del Ser, J
   Yang, G
AF Zhao, Biao
   Jin, Weiqiang
   Del Ser, Javier
   Yang, Guang
TI ChatAgri: Exploring potentials of ChatGPT on cross-linguistic agricultural text classification
SO NEUROCOMPUTING
LA English
DT Article
DE Agricultural text classification; Very large pre-trained language model; Generative Pre-trained Transformer (GPT); ChatGPT; GPT-4
AB In the era of sustainable smart agriculture, a vast amount of agricultural news text is posted online, accu-mulating significant agricultural knowledge. To efficiently access this knowledge, effective text classification techniques are urgently needed. Deep learning approaches, such as fine-tuning strategies on pre-trained language models (PLMs), have shown remarkable performance gains. Nonetheless, these methods face several complex challenges, including limited agricultural training data, poor domain transferability (especially across languages), and complex and expensive deployment of large models. Inspired by the success of recent ChatGPT models (e.g., GPT-3.5, GPT-4), this work explores the potential of applying ChatGPT in the field of agricultural informatization. Various crucial factors, such as prompt construction, answer parsing, and different ChatGPT variants, are thoroughly investigated to maximize its capabilities. A preliminary comparative study is conducted, comparing ChatGPT with PLMs-based fine-tuning methods and PLMs-based prompt-tuning methods. Empirical results demonstrate that ChatGPT effectively addresses the mentioned research challenges and bottlenecks, making it an ideal solution for agricultural text classification. Moreover, ChatGPT achieves comparable performance to existing PLM-based fine-tuning methods, even without fine-tuning on agricultural data samples. We hope this preliminary study could inspire the emergence of a general-purpose AI paradigm for agricultural text processing.
C1 [Zhao, Biao; Jin, Weiqiang] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Innovat Harbour, Xian 710049, Shaanxi, Peoples R China.
   [Del Ser, Javier] Basque Res & Technol Alliance BRTA, TECNALIA, Derio 48160, Spain.
   [Yang, Guang] Imperial Coll London, Bioengn, London SW7 2BX, England.
   [Yang, Guang] Imperial Coll London, Imperial X, W12, London W12 7SL, England.
   [Yang, Guang] Imperial Coll London, Natl Heart & Lung Inst, London SW3 6LY, England.
C3 Xi'an Jiaotong University; Imperial College London; Imperial College London; Imperial College London
RP Yang, G (通讯作者)，Imperial Coll London, Bioengn, London SW7 2BX, England.; Yang, G (通讯作者)，Imperial Coll London, Imperial X, W12, London W12 7SL, England.; Yang, G (通讯作者)，Imperial Coll London, Natl Heart & Lung Inst, London SW3 6LY, England.
EM biaozhao@xjtu.edu.cn; weiqiangjin@stu.xjtu.edu.cn; javier.delser@tecnalia.com; g.yang@imperial.ac.uk
FU ERC IMI, UK [101005122]; H2020 [952172]; MRC, UK [MC/PC/21013]; Royal Society, UK [IEC\NSFC\211235]; NVIDIA Academic Hardware Grant Program, UK; SABER project supported by Boehringer Ingelheim Ltd, UK; UKRI Future Leaders Fellowship, UK [MR/V023799/1]; Spanish Centro para el Desarrollo Tecnologico Industrial (CDTI) , Spain through the AI4ES project; Department of Education of the Basque Government (Eusko Jaurlaritza) , Spain via the Consolidated Research Group MATHMODE [IT1456-22]; Natural Science Basis Research Plan in Shaanxi Province of China [2021JQ-061]
CR Alec R, 2019, OPENAI BLOG, V0, P0
   Azeez N, 2018, COMPUT SCI ELECTR, V0, PP131, DOI 10.1109/CEEC.2018.8674193
   Bang Y, 2023, ARXIV, V0, P0
   Brown TB, 2020, P 34 INT C NEUR INF, V0, P182
   Cao Y, 2022, SYMMETRY-BASEL, V14, P0, DOI 10.3390/sym14081604
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P105
   Dunnmon J, 2019, ARXIV, V0, P0
   Edio da C, 2020, INT J ELECT COMPUT E, V8, P1671, DOI 10.11591/ijece.v8i3.pp1671-1683
   Eloundou T, 2023, ARXIV, V0, P0
   Fang JZ, 2022, IEEE T AUTOM SCI ENG, V0, P0, DOI DOI 10.1109/TASE.2022.3230080
   Gao JQ, 2022, KNOWL-BASED SYST, V258, P0, DOI 10.1016/j.knosys.2022.109935
   Gao J, 2023, ARXIV, V0, P0
   Haque MU, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2212.05856
   Hu SD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2225
   Jiang S, 2021, ARXIV, V0, P0
   Jiao WX, 2023, ARXIV, V0, P0
   Jin Weiqiang, 2023, DATABASE SYSTEMS FOR ADVANCED APPLICATIONS: 28TH INTERNATIONAL CONFERENCE, V0, Proceedings. Lecture Notes in Computer Science (13945)
   Jin WQ, 2023, INFORM PROCESS MANAG, V60, P0, DOI 10.1016/j.ipm.2022.103260
   Jin WQ, 2023, DATA MIN KNOWL DISC, V37, P255, DOI 10.1007/s10618-022-00891-8
   Jin WQ, 2021, PROC INT C TOOLS ART, V0, PP736, DOI 10.1109/ICTAI52525.2021.00117
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Leong FH, 2022, COMM COM INF SC, V1653, P223, DOI 10.1007/978-3-031-16210-7_18
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li YC, 2023, IEEE ACCESS, V11, P27034, DOI 10.1109/ACCESS.2023.3253386
   Liu HZ, 2022, IEICE T INF SYST, VE105D, P1472, DOI 10.1587/transinf.2021EDP7261
   Liu P, 2016, ARXIV160505101, V0, PP2873, DOI 10.5555/3060832.3061023
   Liu PF, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3560815
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61
   Liu X, 2021, ARXIV, V0, P0
   Lyu Q, 2023, VIS COMPUT IND BIOME, V6, P0, DOI 10.1186/s42492-023-00136-5
   Meng LY, 2020, ARXIV, V0, P0
   OpenAI, 2023, GPT4 OPENAI, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Shen YL, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P947
   Shen YL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2782
   Susnjak T, 2023, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang JA, 2023, ARXIV, V0, P0
   Wang YQ, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3386252
   Wei X, 2023, ARXIV, V0, P0
   Wu PS, 2023, COMPUT BIOL MED, V152, P0, DOI 10.1016/j.compbiomed.2022.106457
   Xia N, 2023, MACH LEARN, V112, P1011, DOI 10.1007/s10994-022-06198-5
   Xiao YQ, 2023, ARXIV, V0, P0
   Xu JL, 2022, J SUPERCOMPUT, V78, P10876, DOI 10.1007/s11227-021-04238-w
   Yunlai S, 2022, J LIBR INF SCI AGR, V34, P19, DOI 10.13998/j.cnki.issn1002-1248.22-0172
   Zhang YQ, 2023, NEUROCOMPUTING, V523, P182, DOI 10.1016/j.neucom.2022.12.034
   Zhong QH, 2023, ARXIV, V0, P0
   Zhou C, 2023, ARXIV, V0, P0
   Zhu NY, 2018, INT J AGR BIOL ENG, V11, P32, DOI 10.25165/j.ijabe.20181104.4475
NR 52
TC 0
Z9 0
U1 19
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD NOV 7
PY 2023
VL 557
IS 
BP 
EP 
DI 10.1016/j.neucom.2023.126708
EA SEP 2023
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA S9ND6
UT WOS:001074351000001
DA 2023-11-10
ER

PT J
AU He, K
   Huang, YC
   Mao, R
   Gong, TL
   Li, C
   Cambria, E
AF He, Kai
   Huang, Yucheng
   Mao, Rui
   Gong, Tieliang
   Li, Chen
   Cambria, Erik
TI Virtual prompt pre-training for prototype-based few-shot relation extraction
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Few-shot learning; Information extraction; Prompt tuning; Pre-trained Language Model
AB Prompt tuning with pre-trained language models (PLM) has exhibited outstanding performance by reducing the gap between pre-training tasks and various downstream applications, which requires additional labor efforts in label word mappings and prompt template engineering. However, in a label intensive research domain, e.g., few-shot relation extraction (RE), manually defining label word mappings is particularly challenging, because the number of utilized relation label classes with complex relation names can be extremely large. Besides, the manual prompt development in natural language is subjective to individuals. To tackle these issues, we propose a virtual prompt pre-training method, projecting the virtual prompt to latent space, then fusing with PLM parameters. The pre-training is entity-relation-aware for RE, including the tasks of mask entity prediction, entity typing, distant supervised RE, and contrastive prompt pre-training. The proposed pre-training method can provide robust initialization for prompt encoding, while maintaining the interaction with the PLM. Furthermore, the virtual prompt can effectively avoid the labor efforts and the subjectivity issue in label word mapping and prompt template engineering. Our proposed prompt-based prototype network delivers a novel learning paradigm to model entities and relations via the probability distribution and Euclidean distance of the predictions of query instances and prototypes. The results indicate that our model yields an averaged accuracy gain of 4.21% on two few-shot datasets over strong RE baselines. Based on our proposed framework, our pre-trained model outperforms the strongest RE-related PLM by 6.52%.
C1 [He, Kai; Huang, Yucheng; Gong, Tieliang; Li, Chen] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
   [He, Kai; Huang, Yucheng; Gong, Tieliang; Li, Chen] Shanxi Prov Key Lab Satellite & Terr Network Techn, Xian, Peoples R China.
   [Mao, Rui; Cambria, Erik] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Cambria, Erik] Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave,Block N4 02a, Singapore 639798, Singapore.
C3 Xi'an Jiaotong University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Cambria, E (通讯作者)，Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave,Block N4 02a, Singapore 639798, Singapore.
EM hk52025804@stu.xjtu.edu.cn; huangyucheng@stu.xjtu.edu.cn; rui.mao@ntu.edu.sg; gongtl@xjtu.edu.cn; cli@xjtu.edu.cn; cambria@ntu.edu.sg
FU Agency for Science, Technology and Research (A*STAR) [A18A2b0046]; Key Research and Development Program of Ningxia Hui Nationality Autonomous Region [2022BEG02025]; Key Research and Development Program of Shaanxi Province [2021GXLH-Z-095]; Innovative Research Group of the National Natural Science Foundation of China [61721002]; Ministry of Education [IRT_17R86]
CR [Anonymous], 2013, PUBMED BIBLIO DATABA, V0, P0
   Brown TB, 2020, ARXIV, V0, P0
   Balntas Vassileios, 2016, P BRIT MACH VIS C, V1, P0, DOI 10.5244/C.30.119
   Bao H, 2021, NATURAL LANGUAGE PRO, V0, P235
   Cambria E, 2022, P LREC 2022, V0, P0
   Chen X, 2023, ARXIV, V0, P0
   Dong B, 2020, P 28 INT C COMPUTATI, V0, PP1594, DOI 10.18653/V1/2020.COLING-MAIN.140
   Peters ME, 2018, ARXIV, V0, P0
   Gao T, 2021, ARXIV, V0, P0
   Gao TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6250
   Guo JF, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102067
   Han X, 2021, ARXIV, V0, P0
   Han X, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Haviv A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P3618
   He K, 2023, IEEE T AFFECT COMPUT, V14, P1731, DOI 10.1109/TAFFC.2022.3202831
   He K, 2021, J MED INTERNET RES, V23, P0, DOI 10.2196/25670
   Ji GL, 2017, AAAI CONF ARTIF INTE, V0, P3060
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Kingma DP, 2014, C TRACK P, V0, P0
   Lan YS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3288
   Lester B, 2021, ARXIV, V0, P0
   Lin Q, 2021, IEEE T KNOWL DATA EN, V0, P0
   Li XL, 2021, ARXIV, V0, P0
   Liu X, 2021, ARXIV, V0, P0
   Mao R, 2023, IEEE T AFFECT COMPUT, V14, P1743, DOI 10.1109/TAFFC.2022.3204972
   Mao R, 2022, INFORM FUSION, V86-87, P30, DOI 10.1016/j.inffus.2022.06.002
   Mao R, 2021, AAAI CONF ARTIF INTE, V35, P13534
   Mikolov T, 2013, ARXIV, V0, P0
   Peng H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3661
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Qu M, 2020, INT C MACH LEARN, V0, P7867
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ren X, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1015, DOI 10.1145/3038912.3052708
   Roy A, 2022, COGN COMPUT, V14, P2212, DOI 10.1007/s12559-022-10044-0
   Schick T, 2020, P 28 INT C COMP LING, V0, P5569
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P255
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2339
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Snell J, 2017, ADV NEUR IN, V30, P0
   Sun Y, 2021, ARXIV, V0, P0
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Vu T, 2021, ARXIV, V0, P0
   Wang J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1706
   Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360
   Wang YS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1790
   Wen W, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102596
   Wheeler DL, 2008, NUCLEIC ACIDS RES, V36, PD13, DOI 10.1093/nar/gkm1000
   Xu J, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-0543-2
   Yang S, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P987
NR 49
TC 7
Z9 7
U1 10
U2 19
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 1
PY 2023
VL 213
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118927
EA OCT 2022
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 5R7AE
UT WOS:000874658100004
DA 2023-11-10
ER

PT J
AU Zhang, JW
   Liu, TL
   Tao, DC
AF Zhang, Jingwei
   Liu, Tongliang
   Tao, Dacheng
TI An Optimal Transport Analysis on Generalization in Deep Learning
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Statistics; Sociology; Deep learning; Training; Stability analysis; Measurement; Computational modeling; Deep neural networks (DNNs); generalization; learning theory; optimal transport
ID stability
AB Deep neural networks (DNNs) have achieved state-of-the-art performance in various learning tasks, such as computer vision, natural language processing, and speech recognition. However, the fundamental theory of generalization still remains obscure in deep learning--why DNN models can generalize well, despite that they are heavily overparametrized in both depth and width? Recently, some work shows that traditional theory of analyzing the generalization error of learning models fails to explain the generalization of DNNs. The failure is mainly because of one simple fact that the worse case analysis of generalization error for learning models would be too loose for models with large parameter space, such as DNNs. In this work, we propose a new analysis of generalization in DNNs from an optimal transport perspective. Unlike traditional worse-case uniform convergence analysis in learning theory, our analysis of generalization error is dependent on both the learning algorithm and the data distribution and is the average-case analysis. Thus, our theory can be more practical and accurate to describe the generalization behavior of DNNs. More specifically, in this article, we try to answer a fundamental yet unsolved question in deep learning--why deeper models can generalize well than shallow models? The main contribution of this article can be summarized in four aspects. First, under a general learning framework, we derive upper bounds on the generalization error of learning algorithms by their algorithmic transport cost: the expected Wasserstein distance between the output hypothesis and the output hypothesis conditioned on an input example. We further provide several upper bounds on the algorithmic transport cost in terms of total variation distance, relative entropy, and Vapnik-Chervonenkis (VC) dimension. Moreover, we also study different conditions for loss functions under which the generalization error of a learning algorithm can be upper bounded by different probability metrics between distributions relating to the output hypothesis and/or the input data. Finally, under our established framework, we obtain our main results, showing that the generalization error in DNNs decreases exponentially to zero as the number of layers increases.
C1 [Zhang, Jingwei] Hong Kong Univ Sci & Technol, Sch Engn, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Sch Comp Sci, Fac Engn, Darlington, NSW 2008, Australia.
C3 Hong Kong University of Science & Technology; University of Sydney
RP Tao, DC (通讯作者)，Univ Sydney, Sch Comp Sci, Fac Engn, Darlington, NSW 2008, Australia.
EM jzhangey@cse.ust.hk; tongliang.liu@sydney.edu.au; dacheng.tao@sydney.edu.au
FU Australian Research Council [FL-170100117, DP-180103424, IH-180100002]
CR Ajjanagadde G, 2017, LAB INF DECIS SYST M, V0, P0
   ALABDULMOHSIN I, 2018, P INT C MACH LEARN I, V0, P149
   Alabdulmohsin IM, 2015, ADV NEURAL INFORM PR, V0, P19
   Alabdulmohsin I, 2017, PR MACH LEARN RES, V54, P92
   Ambroladze A, 2006, ADV NEURAL INFORM PR, V0, P9
   [Anonymous], 2015, ADV NEURAL INFORM PR, V0, P0
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Bartlett PL, 2003, JOURNAL OF MACHINE LEARNING RESEARCH, V3, P463, DOI 10.1162/153244303321897690
   Bartlett PL, 2005, ANN STAT, V33, P1497, DOI 10.1214/009053605000000282
   Bassily R, 2018, P MACHINE LEARNING R, V83, P25
   Bassily R, 2016, ACM S THEORY COMPUT, V0, PP1046, DOI 10.1145/2897518.2897566
   Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704
   Cam, 1996, THEORIE ASYMPTOTIQUE, V33, P0
   Chai RQ, 2022, IEEE T NEUR NET LEAR, V33, P1400, DOI 10.1109/TNNLS.2020.3042120
   Chai RQ, 2020, IEEE T NEUR NET LEAR, V31, P5005, DOI 10.1109/TNNLS.2019.2955400
   Chai R, 2020, IEEE T IND ELECTRON, V67, P6904, DOI 10.1109/TIE.2019.2939934
   Chai RQ, 2020, IEEE T CYBERNETICS, V50, P4332, DOI 10.1109/TCYB.2019.2895305
   Chai RQ, 2019, IEEE T CYBERNETICS, V49, P467, DOI 10.1109/TCYB.2017.2778195
   Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921
   Cover T, 2006, ELEMENTS INFORM THEO, V2nd ed., P0
   Gao R, 2016, ARXIV OPTIMIZATION C, V0, P0, DOI DOI 10.48550/ARXIV.1604.02199
   Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865
   Herbrich R, 2003, J MACH LEARN RES, V3, P175, DOI 10.1162/153244303765208368
   Gulrajani I, 2017, ADV NEUR IN, V30, P0
   Kushner HJ, 2003, STOCHASTIC APPROXIMA, V35, P0
   Langford J, 2005, J MACH LEARN RES, V6, P273
   Lee J, 2017, ARXIV170507815, V0, P0
   Liu TL, 2017, PR MACH LEARN RES, V70, P0
   Mohri M, 2012, FDN MACHINE LEARNING, V0, P0
   Nachum I, 2018, ARXIV180405474, V0, P0
   Nagarajan V, 2019, ADV NEUR IN, V32, P0
   Peyré G, 2019, FOUND TRENDS MACH LE, V11, P355, DOI 10.1561/2200000073
   Polyanskiy Y, 2017, IMA VOL MATH APPL, V161, P211, DOI 10.1007/978-1-4939-7005-6_7
   Raginsky Maxim, 2016, 2016 IEEE INFORMATION THEORY WORKSHOP (ITW), V0, PP26, DOI 10.1109/ITW.2016.7606789
   RIVASPLATA O, 2018, ARXIV180606827, V0, P0
   Russo D, 2016, JMLR WORKSH CONF PRO, V51, P1232
   Sason I, 2016, IEEE T INFORM THEORY, V62, P5973, DOI 10.1109/TIT.2016.2603151
   Shalev-Shwartz S, 2010, J MACH LEARN RES, V11, P2635
   Vapnik Vladimir, 1999, NATURE STAT LEARNING, V2, P0
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5
   Wang YX, 2016, LECT NOTES COMPUT SC, V9867, P121, DOI 10.1007/978-3-319-45381-1_10
   Xu A, 2017, ADV NEURAL INFORM PR, V0, P2524
   Xu H, 2012, MACH LEARN, V86, P391, DOI 10.1007/s10994-011-5268-1
   Zhang C, 2016, ARXIV161103530, V0, P0
   Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713
   Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635
NR 47
TC 1
Z9 1
U1 1
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2023
VL 34
IS 6
BP 2842
EP 2853
DI 10.1109/TNNLS.2021.3109942
EA SEP 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA I2IA8
UT WOS:000732209500001
PM 34554918
DA 2023-11-10
ER

PT J
AU Nag, A
   Samanta, B
   Mukherjee, A
   Ganguly, N
   Chakrabarti, S
AF Nag, Arijit
   Samanta, Bidisha
   Mukherjee, Animesh
   Ganguly, Niloy
   Chakrabarti, Soumen
TI Transfer Learning for Low-Resource Multilingual Relation Classification
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Relation extraction
AB Relation classification (sometimes called relation extraction) requires trustworthy datasets for fine-tuning large language models, as well as for evaluation. Data collection is challenging for Indian languages, because they are syntactically and morphologically diverse, as well as different from resource-rich languages like English. Despite recent interest in deep generative models for Indian languages, relation classification is still not well served by public datasets. In response, we present IndoRE, a dataset with 21K entity- and relationtagged gold sentences in three Indian languages (Bengali, Hindi, and Telugu), plus English. We start with a multilingual BERT (mBERT)-based system that captures entity span positions and type information, and provides competitive performance on monolingual relation classification. Using this baseline system, we explore transfer mechanisms between languages and the scope to reduce expensive data annotation while achieving reasonable relation extraction performance. Specifically, we (a) study the accuracy-efficiency trade-off between expensive, manually labeled gold instances vs. automatically translated and aligned silver instances to train a relation extractor, (b) device a simple mechanism for budgeted gold data annotation by intelligently converting distant-supervised silver training instances to gold training instances with human annotators using active learning, and finally (c) propose an ensemble model to provide a performance boost over that achieved via limited gold training instances. We release the dataset for future research.(1)
C1 [Nag, Arijit; Samanta, Bidisha; Mukherjee, Animesh; Ganguly, Niloy; Chakrabarti, Soumen] Indian Inst Technol, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Kharagpur
RP Nag, A (通讯作者)，Indian Inst Technol, Kharagpur, W Bengal, India.
EM arijitnag@iitkgp.ac.in; bidisha@iitkgp.ac.in; animeshm@iitkgp.ac.in; niloy@cse.iitkgp.ac.in; soumen@cse.iitb.ac.in
CR Angluin D, 1988, MACHINE LEARNING, V2, P319, DOI 10.1007/BF00116828
   [Anonymous], 2015, P 29 PAC AS C LANG I, V0, P0
   [Anonymous], 2009, HUMAN LANGUAGE TECHN, V0, P0, DOI DOI 10.3115/1620754.1620815
   Balcan MF, 2009, J COMPUT SYST SCI, V75, P78, DOI 10.1016/j.jcss.2008.07.003
   Soares LB, 2019, ARXIV, V0, P0
   Bastos Anson, 2020, P WEB C 2021 WWW 21, V0, P0
   Bekoulis G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2830
   Beluch WH, 2018, PROC CVPR IEEE, V0, PP9368, DOI 10.1109/CVPR.2018.00976
   Beygelzimer A, 2009, P 26 ANN INT C MACH, V0, P49
   Bilgic Mustafa, 2009, P NIPS WORKSH AN NET, V0, P0
   Bloodgood M, 2014, ARXIV, V0, P0
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Cai R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P756
   Chen J, 2020, ARXIV, V0, P0
   Chen M, 2020, P 3 CLIN NATURAL LAN, V0, PP234, DOI 10.18653/V1/2020.CLINICALNLP-1.26
   Dagan I, 1995, MACHINE LEARNING. PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING, V0, P150
   Daojian Zeng, 2014, P COLING 25 INT C CO, V0, P2335
   Dasgupta S, 2005, LECT NOTES COMPUT SC, V3559, P249, DOI 10.1007/11503415_17
   Dat Quoc Nguyen, 2019, ADVANCES IN INFORMATION RETRIEVAL. 41ST EUROPEAN CONFERENCE ON IR RESEARCH, V0, P729, DOI 10.1007/978-3-030-15712-8_47
   dos Santos CN, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P626
   Figueroa RL, 2012, J AM MED INFORM ASSN, V19, P809, DOI 10.1136/amiajnl-2011-000648
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   Freytag A, 2014, LECT NOTES COMPUT SC, V8692, P562, DOI 10.1007/978-3-319-10593-2_37
   Fu TJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1409
   Gal Y, 2017, PR MACH LEARN RES, V70, P0
   Gal Y, 2016, PR MACH LEARN RES, V48, P0
   Guo Yuhong, 2010, ADV NEURAL INFORM PR, V0, P802
   Han X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4803
   Han X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2236
   Hendrickx Iris, 2010, P 5 INT WORKSH SEM E, V0, PP33, DOI 10.3115/1621969.1621986
   Hoffmann R, 2011, PROC 49 ANN M ASS CO, V1, P541, DOI 10.5555/2002472
   Goodfellow IJ, 2015, ARXIV, V0, P0
   Jiang X, 2016, P COLING 26 INT C CO, V0, P1471
   Jin ZJ, 2020, ARXIV, V0, P0
   Joshi Ajay J, 2009, 2009 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP2372, DOI 10.1109/CVPRW.2009.5206627
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kemker R, 2018, AAAI CONF ARTIF INTE, V0, P3390
   Khanuja S, 2021, ARXIV, V0, P0
   King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kozhevnikov M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P579
   Krishnamurthy V, 2002, IEEE T SIGNAL PROCES, V50, P1382, DOI 10.1109/TSP.2002.1003062
   Lee JY, 2017, ARXIV170401523, V0, P0
   Lee JH, 2019, ARXIV, V0, P0
   Lewis DD, 1995, SIGIR FORUM, V29, P13, DOI 10.1145/219587.219592
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Liu TY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2195
   Liu Y, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P285
   McCallumzy AK, 1998, PROC INT C MACHINE L, V0, PP359, DOI 10.1023/A:1007692713085
   Mintz M, 2009, P JOINT C 47 ANN M A, V0, PP1003, DOI 10.3115/1690219.1690287
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Nadgeri Abhishek, 2021, FINDINGS ASS COMPUTA, V0, PP535, DOI 10.18653/v1/2021.findings-acl.48
   Nag Arijit, 2021, P 25 C COMPUTATIONAL, V0, P575
   Nguyen Hieu T, 2004, P ICML, V0, P0, DOI DOI 10.1145/1015330.1015349
   Nguyen TH, 2015, P 1 WORKSH VECT SPAC, V0, PP39, DOI 10.3115/V1/W15-1506
   Ni J, 2020, ARXIV, V0, P0
   Pfeiffer J, 2020, ARXIV, V0, P0
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P46
   Pires T, 2019, ARXIV, V0, P0
   Ranganathan H, 2017, IEEE IMAGE PROC, V0, PP3934, DOI 10.1109/ICIP.2017.8297020
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Roy N, 2001, P 18 INT C MACH LEAR, V2, P441
   Serrà J, 2018, PR MACH LEARN RES, V80, P0
   Settles Burr, 2007, ADV NEURAL INFORM PR, V20, P1289
   Seung HS, 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP287, DOI 10.1145/130385.130417
   Sha F, 2007, ADV NEURAL INFORM PR, V0, P1249
   Shen Y, 2016, 26 INT C COMPUTATION, V0, P2526
   Shen YY, 2018, ARXIV, V0, P0
   Shui C, 2020, INT C ART INT STAT, V0, P1308
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2895
   Su J, 2015, EMNLP, V0, P536
   Surdeanu M, 2012, EMNLP CONLL, V0, P455
   Ash JT, 2020, ARXIV, V0, P0
   Thompson CA, 1999, MACHINE LEARNING, V0, P406
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Ulges A, 2019, PREPRINT, V0, P0, DOI DOI 10.3233/FAIA200321
   Vashishth S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1257
   Wang J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1706
   Wang LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1298
   Wang Xinyi, 2021, FINDINGS ASS COMPUTA, V0, PP730, DOI 10.18653/v1/2021.findings-emnlp.63
   Wu SC, 2019, ARXIV, V0, P0
   Wu Y, 2017, P 2017 C EMPIRICAL M, V0, P1778
   Xiao M, 2016, P COLING 2016 26 INT, V0, P1254
   Xu Y, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Xu Y, 2015, P 2015 C EMP METH NA, V0, PP1785, DOI 10.18653/V1/D15-1206
   Xue FZ, 2020, ARXIV, V0, P0
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
   Ye ZX, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2810
   Yin CC, 2017, IEEE DATA MINING, V0, PP575, DOI 10.1109/ICDM.2017.67
   Zeng D, 2015, P 2015 C EMPIRICAL M, V0, P1753
   Zeng W, 2017, P 2017 C EMP METH NA, V0, PP1768, DOI 10.18653/V1/D17-1186
   Zhang C, 2018, ARXIV180502350, V0, P0
   Zhang DX, 2015, ARXIV, V0, P0
   Zhang Y, 2017, P 2017 C EMPIRICAL M, V0, P35
   Zhdanov Fedor, 2019, DIVERSE MINI BATCH A, V0, P0
   Zheng SC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1227, DOI 10.18653/v1/P17-1113
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 97
TC 0
Z9 0
U1 2
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB 15
PY 2023
VL 22
IS 2
BP 
EP 
DI 10.1145/3554734
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA C7AF6
UT WOS:000963394900019
DA 2023-11-10
ER

PT J
AU Muhammad, AU
   Lee, HYS
   Choi, J
AF Muhammad, Ammar Ul Hassan
   Lee, Hyunsoo
   Choi, Jaeyoung
TI Exploiting mixing regularization for truly unsupervised font synthesis
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Keyword1; Keyword2; Keyword3
AB Creating a novel font set requires domain expertise and is a laborious and time-consuming process, par-ticularly for languages with a large number of characters and complicated structures. Existing deep learn-ing based methods consider font generation (FG) as an image-to-image translation problem, mostly in a supervised setting, either in the form of pair images (paired data) or font labels (character or style la-bels), which requires extensive effort and is expensive to collect. Additionally, these supervised counter parts lack generalization for extending to other text image-related tasks, such as word image genera-tion and font attribute control at inference time. We found that these drawbacks are mainly due to the supervised setting adopted by these existing methods for font generation. In this paper, we tackle the FG problem in a truly unsupervised fashion, where a complete font set can be generated by training the generator such that adjacent styles are not correlated and projecting the input glyph image into its corresponding font style latent space. To accomplish this, we propose the Font Mixing Generative Adver-sarial Network (FM-GAN), which employs mixing regularization to supervise the generator to localize the font styles, and a projection encoder to project an arbitrary glyph image into its corresponding semantic space that is compatible with the generator. In the experiments, we demonstrated that our unsupervised model synthesizes font images that are comparable to supervised state-of-the-art FG baselines. Further-more, FM-GAN can be directly applied to other text image related tasks, such as multi-lingual font style transfer, word image generation, and font attribute control.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Muhammad, Ammar Ul Hassan; Lee, Hyunsoo; Choi, Jaeyoung] Soongsil Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Soongsil University
RP Choi, J (通讯作者)，Soongsil Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM ammar91@soongsil.ac.kr; lhs1218@soongsil.ac.kr; choi@ssu.ac.kr
CR Cha Junbum, 2020, LNCS, V12364, P2, DOI 10.1007/978-3-030-58529-7_43
   Gao Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3355089.3356574
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Harkonen Erik, 2020, ADV NEURAL INFORM PR, V0, P0, DOI DOI 10.48550/ARXIV.2004.02546
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang X, 2017, IEEE I CONF COMP VIS, V0, PP1510, DOI 10.1109/ICCV.2017.167
   Karras Tero, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, V0, PP4396, DOI 10.1109/CVPR.2019.00453
   Kingma DP, 2014, C TRACK P, V0, P0
   Ko DH, 2021, INT J DOC ANAL RECOG, V24, P325, DOI 10.1007/s10032-021-00374-4
   Li CH, 2021, IEEE WINT CONF APPL, V0, PP433, DOI 10.1109/WACV48630.2021.00048
   Liu MY, 2019, IEEE I CONF COMP VIS, V0, PP10550, DOI 10.1109/ICCV.2019.01065
   Mescheder L, 2018, PR MACH LEARN RES, V80, P0
   Park S, 2020, ARXIV, V0, P0
   Park Song, 2021, ICCV, V0, P13900
   Parmar G, 2022, ARXIV, V0, P0
   Salimans T, 2016, ADV NEUR IN, V29, P0
   Shannon M, 2020, ARXIV, V0, P0
   Tian Yuchen, 2017, ZI2ZI MASTER CHINESE, V0, P0
   Xie Yangchen, 2021, CVPR, V0, P5130
   Yunjey Choi, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8185, DOI 10.1109/CVPR42600.2020.00821
NR 21
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD MAY 15
PY 2023
VL 169
IS 
BP 35
EP 42
DI 10.1016/j.patrec.2023.03.019
EA APR 2023
PG 8
WC Computer Science, Artificial Intelligence
SC Computer Science
GA E6UE6
UT WOS:000976862600001
DA 2023-11-10
ER

PT J
AU Pataranutaporn, P
   Liu, R
   Finn, E
   Maes, P
AF Pataranutaporn, Pat
   Liu, Ruby
   Finn, Ed
   Maes, Pattie
TI Influencing human-AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article; Early Access
ID artificial-intelligence; placebo; program
AB As conversational agents powered by large language models become more human-like, users are starting to view them as companions rather than mere assistants. Our study explores how changes to a person's mental model of an AI system affects their interaction with the system. Participants interacted with the same conversational AI, but were influenced by different priming statements regarding the AI's inner motives: caring, manipulative or no motives. Here we show that those who perceived a caring motive for the AI also perceived it as more trustworthy, empathetic and better-performing, and that the effects of priming and initial mental models were stronger for a more sophisticated AI model. Our work also indicates a feedback loop in which the user and AI reinforce the user's mental model over a short time; further work should investigate long-term effects. The research highlights the importance of how AI systems are introduced can notably affect the interaction and how the AI is experienced. The recent accessibility of large language models brought them into contact with a large number of users and, due to the social nature of language, it is hard to avoid prescribing human characteristics such as intentions to a chatbot. Pataranutaporn and colleagues investigated how framing a bot as helpful or manipulative can influence this perception and the behaviour of the humans that interact with it.
C1 [Pataranutaporn, Pat; Liu, Ruby; Maes, Pattie] MIT, Media Lab, Cambridge, MA 02139 USA.
   [Liu, Ruby] MIT, Harvard MIT Hlth Sci & Technol, Cambridge, MA 02139 USA.
   [Finn, Ed] Arizona State Univ, Ctr Sci & Imaginat, Tempe, AZ USA.
C3 Massachusetts Institute of Technology (MIT); Harvard University; Massachusetts Institute of Technology (MIT); Arizona State University; Arizona State University-Tempe
RP Pataranutaporn, P; Liu, R (通讯作者)，MIT, Media Lab, Cambridge, MA 02139 USA.; Liu, R (通讯作者)，MIT, Harvard MIT Hlth Sci & Technol, Cambridge, MA 02139 USA.
EM patpat@mit.edu; rliu34@media.mit.edu
FU Our paper benefited greatly from the valuable feedback provided by the reviewers, and we extend our gratitude for their contribution. We thank J. Liu, data science specialist at the Institute for Quantitative Social Science, Harvard University, for reviewi; MIT Media Lab; Harvard-MIT Health Sciences and Technology; Accenture
CR Adamopoulou E, 2020, MACHINE LEARNING APP, V2, P0, DOI 10.1016/j.mlwa.2020.100006
   [Anonymous], 2021, GPT 3 POWERS NEXT GE, V0, P0
   [Anonymous], 2004, DESIGNING SOCIABLE R, V0, P0
   Aylett MP, 2019, 2019 CHI C HUM FACT, V0, P1
   Balch O, 2020, THE GUARDIAN 0507, V0, P0
   Bansal G, 2019, P AAAI C HUM COMP CR, V7, P2, DOI 10.1609/HCOMP.V7I1.5285
   Bavaresco R, 2020, COMPUT SCI REV, V36, P0, DOI 10.1016/j.cosrev.2020.100239
   Bender Emily M, 2021, FACCT 21: PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, V0, P0
   Bingaman J, 2021, SCI COMMUN, V43, P388, DOI 10.1177/1075547021998069
   Birkhäuer J, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0170988
   Bower AH, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-00426-z
   Brandtzaeg PB, 2022, HUM COMMUN RES, V48, P404, DOI 10.1093/hcr/hqac008
   Brown T, 2020, C NEUR INF PROC SYST, V0, P0
   Castro-González A, 2016, INT J HUM-COMPUT ST, V90, P27, DOI 10.1016/j.ijhcs.2016.02.004
   Cave S, 2020, AI NARRATIVES HIST I, V0, P0
   Cave S, 2019, AIES 19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, V0, P0
   Cave S, 2019, NAT MACH INTELL, V1, P74, DOI 10.1038/s42256-019-0020-9
   Cho M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), V0, PP1557, DOI 10.1145/3322276.3322332
   Chowdhery A, 2022, ARXIV, V0, P0
   Chubb J, 2022, AI SOC, V0, P0, DOI DOI 10.1007/s00146-022-01548-2
   Colagiuri B, 2015, NEUROSCIENCE, V307, P171, DOI 10.1016/j.neuroscience.2015.08.017
   Croes EAJ, 2021, J SOC PERS RELAT, V38, P279, DOI 10.1177/0265407520959463
   Danry V, 2022, PROCEEDINGS OF AUGMENTED HUMANS CONFERENCE 2022 (AHS 2022), V0, PP68, DOI 10.1145/3519391.3519414
   de Vignemont F, 2006, TRENDS COGN SCI, V10, P435, DOI 10.1016/j.tics.2006.08.008
   Denisova A, 2015, P 2015 ANN S COMP HU, V0, PP23, DOI 10.1145/2793107.2793109
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ehret J, 2021, ACM T APPL PERCEPT, V18, P0, DOI 10.1145/3486580
   Ekström AG, 2022, COMPUT HUM BEHAV REP, V7, P0, DOI 10.1016/j.chbr.2022.100226
   Epstein Z, 2020, ISCIENCE, V23, P0, DOI 10.1016/j.isci.2020.101515
   Evers AWM, 2018, PSYCHOTHER PSYCHOSOM, V87, P204, DOI 10.1159/000490354
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Finn E, 2017, WHAT ALGORITHMS WANT, V0, P0
   Finn E, 2021, FUTURES, V132, P0, DOI 10.1016/j.futures.2021.102788
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, P0, DOI 10.2196/mental.7785
   Friedrich A, 2015, CONTEMP EDUC PSYCHOL, V41, P1, DOI 10.1016/j.cedpsych.2014.10.006
   Gero KI, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI20), V0, P0, DOI DOI 10.1145/3313831.3376316
   Gill KS, 2018, AI SOC, V33, P459, DOI 10.1007/s00146-018-0866-0
   Groh M, 2022, INT CONF AFFECT, V0, P0, DOI DOI 10.1109/ACII55700.2022.9953869
   Harrington A, 2006, BIOSOCIETIES, V1, P181, DOI 10.1017/S1745855206050216
   Harrington A, 1999, PLACEBO EFFECT INTER, V8, P0
   Hildt E, 2019, FRONT PSYCHOL, V10, P0, DOI 10.3389/fpsyg.2019.01535
   Hoy Matthew B, 2018, MEDICAL REFERENCE SERVICES QUARTERLY, V37, P81, DOI 10.1080/02763869.2018.1404391
   Hudson AD, 2023, AI SOC, V38, P197, DOI 10.1007/s00146-021-01273-2
   Hutto CJ, 2014, ICWSM, V0, P0, DOI DOI 10.1609/ICWSM.V8I1.14550
   Hwang AH-C, 2022, CHI C HUM FACT COMP, V0, P1
   Jasanoff S, 2015, DREAMSCAPES MODERNIT, V0, P0, DOI DOI 10.7208/chicago/9780226276663.003.0001
   Jeong S, 2023, USER MODEL USER-ADAP, V33, P571, DOI 10.1007/s11257-022-09337-8
   Johnson-Laird PN, 1983, MENTAL MODELS COGNIT, V0, P0
   KIERAS DE, 1984, COGNITIVE SCI, V8, P255, DOI 10.1016/S0364-0213(84)80003-8
   Kim H, 2019, 2019 CHI C HUM FACT, V0, P1
   Kim Y, 2021, P 2021 CHI C HUM FAC, V0, P1
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, P0, DOI 10.1145/2963106
   Koda T, 1996, RO-MAN 96 - 5TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, V0, P189, DOI 10.1109/ROMAN.1996.568812
   Komatsu T, 2008, CHI 08 HUM FACT COMP, V0, P2919
   Kosch T, 2022, ACM T COMPUT-HUM INT, V29, P0, DOI 10.1145/3529225
   Kounev Samuel, 2017, SELFAWARE COMPUTING, V0, PP3, DOI 10.1007/978-3-319-47474-8_1
   Kraus M, 2020, UMAP20: PROCEEDINGS OF THE 28TH ACM CONFERENCE ON USER MODELING, V0, P107, DOI 10.1145/3340631.3394840
   Kulesza Todd, 2012, P SIGCHI C HUM FACT, V0, PP1, DOI 10.1145/2207676.2207678
   Leibowitz KA, 2019, HEALTH PSYCHOL, V38, P613, DOI 10.1037/hea0000751
   Lewis JR, 2015, INT J SPEECH TECHNOL, V18, P479, DOI 10.1007/s10772-015-9289-1
   Li DJ, 2010, INT J SOC ROBOT, V2, P175, DOI 10.1007/s12369-010-0056-9
   Martinez E, 2021, FRONT ROBOT AI, V8, P0, DOI 10.3389/frobt.2021.788355
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Mueller ST, 2019, ARXIV, V0, P0
   Natale S, 2019, NEW MEDIA SOC, V21, P712, DOI 10.1177/1461444818804980
   Nickerson RS, 1998, REV GEN PSYCHOL, V2, P175
   Norman Donald A, 2014, MENTAL MODELS, V0, PP15, DOI 10.5555/58076.58097
   Paetzel M, 2016, ICMI16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP522, DOI 10.1145/2993148.2997612
   Paiva A, 2017, ACM T INTERACT INTEL, V7, P0, DOI 10.1145/2912150
   Paradeda RB, 2016, LECT NOTES ARTIF INT, V9979, P169, DOI 10.1007/978-3-319-47437-3_17
   Pataranutaporn P, 2021, NAT MACH INTELL, V3, P1013, DOI 10.1038/s42256-021-00417-9
   Pi ZL, 2022, J COMPUT ASSIST LEAR, V38, P1703, DOI 10.1111/jcal.12704
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1, DOI 10.1017/S0140525X02000018
   Reeves Byron, 1996, MEDIA EQUATION PEOPL, V10, P0
   Rosenthal R, 2002, IMPROVING ACAD ACHIE, V0, P25
   Rutjes H, 2019, CHI 2019 WORKSH IS H, V0, P0
   Schepman A, 2020, COMPUT HUM BEHAV REP, V1, P0, DOI 10.1016/j.chbr.2020.100014
   Seaborn K, 2021, 2021 CHI C HUM FACT, V0, P1
   Seaborn K, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3386867
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Song SC, 2017, ACMIEEE INT CONF HUM, V0, PP2, DOI 10.1145/2909824.3020239
   Ta V, 2020, J MED INTERNET RES, V22, P0, DOI 10.2196/16235
   Thoppilan R, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2201.08239
   Touvron H, 2023, ARXIV, V0, P0
   van den Brule R, 2014, INT J SOC ROBOT, V6, P519, DOI 10.1007/s12369-014-0231-5
   Vaswani A, 2017, ARXIV, V30, P5998
   Volkel ST, 2021, P 2021 CHI C HUM FAC, V0, P1
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Winkler R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI20), V0, P0, DOI DOI 10.1145/3313831.3376781
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI17), V0, PP3506, DOI 10.1145/3025453.3025496
   Xu Y, 2022, CHI C HUM FACT COMP, V0, P1
   Yalcin ÖN, 2018, BIOL INSPIR COGN ARC, V26, P20, DOI 10.1016/j.bica.2018.07.010
   Yampolskiy RV, 2016, WORKSH 30 AAAI C ART, V0, P0
   Zlotowski J, 2016, PALADYN, V7, P55
   2023, 1900, DOI ARXIV:2303.08774, V0, P0
NR 95
TC 0
Z9 0
U1 23
U2 23
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1038/s42256-023-00720-7
EA OCT 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA S8NE6
UT WOS:001073673100001
DA 2023-11-10
ER

PT J
AU Dimlioglu, T
   Wang, J
   Bisla, D
   Choromanska, A
   Odie, S
   Bukhman, L
   Olomola, A
   Wong, JM
AF Dimlioglu, Tolga
   Wang, Jing
   Bisla, Devansh
   Choromanska, Anna
   Odie, Simon
   Bukhman, Leon
   Olomola, Afolabi D.
   Wong, James
TI Automatic document classification via transformers for regulations compliance management in large utility companies
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Document classification; Machine learning; BERT; Natural language processing
ID artificial-intelligence; tutorial
AB The operation of large utility companies such as Consolidated Edison Company of New York, Inc. (Con Edison) typically rely on large quantities of regulation documents from external institutions which inform the company of upcoming or ongoing policy changes or new requirements the company might need to comply with if deemed applicable. As a concrete example, if a recent regulatory publication mentions that the timeframe for the Company to respond to a reported system emergency in its service territory changes from within X time to within Y time-then the affected operating groups will be notified, and internal Company operating procedures may need to be reviewed and updated accordingly to comply with the new regulatory requirement. Each such regulation document needs to be reviewed manually by an expert to determine if the document is relevant to the company and, if so, which department it is relevant to. In order to help enterprises improve the efficiency of their operation, we propose an automatic document classification pipeline that determines whether a document is important for the company or not, and if deemed important it forwards those documents to the departments within the company for further review. Binary classification task of determining the importance of a document is done via ensembling the Naive Bayes (NB), support vector machine (SVM), random forest (RF), and artificial neural network (ANN) together for the final prediction, whereas the multi-label classification problem of identifying the relevant departments for a document is executed by the transformer-based DocBERT model. We apply our pipeline to a large corpus of tens of thousands of text data provided by Con Edison and achieve an accuracy score over 80%. Compared with existing solutions for document classification which rely on a single classifier, our paper i) ensemble multiple classifiers for better accuracy results and escaping from the problem of overfitting, ii) utilize pretrained transformer-based DocBERT model to achieve ideal performance for multi-label classification task and iii) introduce a bi-level structure to improve the performance of the whole pipeline where the binary classification module works as a rough filter before finally distributing the text to corresponding departments through the multi-label classification module.
C1 [Dimlioglu, Tolga; Wang, Jing; Bisla, Devansh; Choromanska, Anna] NYU, Dept Elect & Comp Engn, 5 Metro Tech, Brooklyn, NY 11201 USA.
   [Odie, Simon; Bukhman, Leon; Olomola, Afolabi D.; Wong, James] Consolidated Edison Co New York Inc Con Edison, Res & Dev Dept, 4 Irving Pl, New York, NY 10003 USA.
C3 New York University; New York University Tandon School of Engineering
RP Wang, J (通讯作者)，NYU, Dept Elect & Comp Engn, 5 Metro Tech, Brooklyn, NY 11201 USA.
EM td2249@nyu.edu; jw5665@nyu.edu; bisla@nyu.edu; ac5455@nyu.edu; ODIES@coned.com; BukhmanL@coned.com; OLOMOLAA@coned.com; WONGJA@coned.com
CR Abiodun OI, 2018, HELIYON, V4, P0, DOI 10.1016/j.heliyon.2018.e00938
   Adhikari A, 2019, DOCBERT BERT DOCUMEN, V0, P0
   Adhikari A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4046
   Aly M, 2005, NEURAL NETWORKS, V19, P1
   Anandarajan M, 2019, PRACTICAL TEXT ANALY, V0, PP45, DOI 10.1007/978-3-319-95663-3_4
   [Anonymous], 2010, MANY LANGUAGES ARE T, V0, P0
   [Anonymous], 1996, FOUND DISTRIB ARTIF, V0, P0
   Arévalo A, 2016, LECT NOTES ARTIF INT, V9773, P424, DOI 10.1007/978-3-319-42297-8_40
   Babbar R, 2019, MACH LEARN, V108, P1329, DOI 10.1007/s10994-019-05791-5
   Babbar R, 2017, WSDM17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP721, DOI 10.1145/3018661.3018741
   Bahrammirzaee A, 2010, NEURAL COMPUT APPL, V19, P1165, DOI 10.1007/s00521-010-0362-z
   Bakator Mihalj, 2018, MULTIMODAL TECHNOLOGIES AND INTERACTION, V2, P0, DOI 10.3390/mti2030047
   Behera B, 2019, INT CONF ADV COMPU, V0, PP220, DOI 10.1109/icoac48765.2019.246843
   Ben-Baruch E, 2020, ARXIV, V0, P0
   Bhatia K, 2015, ADV NEURAL INFORM PR, V0, P730
   Black M, 2019, IMPORTANCE LANGUAGE, V0, P0, DOI DOI 10.7591/9781501741319
   Bland M, 2015, AN INTRODUCTION TO MEDICAL STATISTICS, V0, P0
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Breiman L, 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Cerri R, 2016, BMC BIOINFORMATICS, V17, P0, DOI 10.1186/s12859-016-1232-1
   Chalkidis I, 2020, ARXIV, V0, P0
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Chen XY, 2020, ACMIEEE INT CONF HUM, V0, PP160, DOI 10.1145/3371382.3378355
   Cherman EA, 2011, CLEI ELECT J, V14, P4, DOI 10.19153/CLEIEJ.14.1.4
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Chowdhary K, 2020, FUNDAMENTALS ARTIFIC, V0, PP603, DOI 10.1007/978-81-322-3972-7_19
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Davidson James, 2010, P 4 ACM C REC SYST, V0, PP293, DOI 10.1145/1864708.1864770
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Desatnick RL, 1987, MANAGING KEEP CUSTOM, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Evans N, 2009, BEHAV BRAIN SCI, V32, P429, DOI 10.1017/S0140525X0999094X
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, V0, PP6201, DOI 10.1109/ICCV.2019.00630
   Gevrey M, 2003, ECOL MODEL, V160, P249, DOI 10.1016/S0304-3800(02)00257-0
   Goralski MA, 2020, INT J MANAG EDUC-OXF, V18, P0, DOI 10.1016/j.ijme.2019.100330
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gunasekara I, 2018, P 2 WORKSHOP ABUSIVE, V0, P21
   Hamet P, 2017, METABOLISM, V69, PS36, DOI 10.1016/j.metabol.2017.01.011
   Hasan K, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2019), V0, PP354, DOI 10.1109/CIC48465.2019.00049
   Hashimoto TB, 2019, ARXIV, V0, P0
   Haykin S, 2009, NEURAL NETWORKS LEAR, V3/E, P0
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   He P, 2020, ARXIV, V0, P0
   He Yun, 2022, INT C MACHINE LEARNI, V0, P8678
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   House W, 2016, ARTIF INTELL, V0, P0
   Hu DC, 2020, ADV INTELL SYST COMP, V1038, P432, DOI 10.1007/978-3-030-29513-4_31
   Huang Zhiheng, 2015, ARXIV, V0, P0
   Iqbal Touseef, 2020, J KING SAUD U COMPUT, V0, P0
   Jain H, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP935, DOI 10.1145/2939672.2939756
   Jalan A, 2019, ARXIV, V0, P0
   Jun Xu, 2007, 30TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P391
   Ke GL, 2017, ADV NEUR IN, V30, P0
   Kim Y, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kumar Pushpendra, 2018, INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY, V10, P495, DOI 10.1007/s41870-018-0138-8
   LeCun Y, 1995, CONVOLUTIONAL NETWOR, V3361, P1995, DOI 10.5555/303568.303704
   Lee J, 2018, MANUF LETT, V18, P20, DOI 10.1016/j.mfglet.2018.09.002
   Lee SM, 2020, SERV BUS, V14, P1, DOI 10.1007/s11628-019-00408-2
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3045
   Lewis M, 2019, ARXIV, V0, P0
   Li Tao, 2003, P 26 ANN INT ACM SIG, V0, PP282, DOI 10.1145/860435.860487
   Liu JZ, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP115, DOI 10.1145/3077136.3080834
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Luo X, 2005, LECT NOTES COMPUT SC, V3488, P161
   Lv DD, 2019, MATH PROBL ENG, V2019, P0, DOI 10.1155/2019/7816154
   McCann B, 2017, ADV NEURAL INFORM PR, V0, P0
   Medsker LR, 2001, INT SER COMPUTAT INT, V5, P64
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mishra M, 2020, ENG APPL ARTIF INTEL, V96, P0, DOI 10.1016/j.engappai.2020.104000
   Momoh JA, 2018, ELECT SYSTEMS DYNAMI, V0, P0, DOI DOI 10.1201/9781482270099
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Nallapati R, 2004, PROCEEDINGS OF SHEFFIELD SIGIR 2004. THE TWENTY-SEVENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP64, DOI 10.1145/1008992.1009006
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Oramas S, 2017, ARXIV, V0, P0
   Pappagari R, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP838, DOI 10.1109/asru46091.2019.9003958
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Prabhu Y, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP263, DOI 10.1145/2623330.2623651
   Prajapati P, 2012, INT J SOFT COMPUT EN, V2, P248
   Qi XM, 2020, ISPRS J PHOTOGRAMM, V169, P337, DOI 10.1016/j.isprsjprs.2020.09.020
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rahman S, 2021, P INT C MACH INT DAT, V0, P507
   Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290
   Read J, 2008, P 2008 NZ COMP SCI R, V0, P143
   Rish I, 2001, IN IJCAI 2001 WORKSH, V3, P41, DOI 10.1214/088342306000000060
   Roberts A, 2022, ARXIV, V0, P0
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Russell, 2010, ARTIF INTELL, V0, P0
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Santos Araken M, 2011, INTERNATIONAL JOURNAL OF COMPUTER INFORMATION SYSTEMS AND INDUSTRIAL MANAGEMENT APPLICATIONS, V3, P218
   Schapire RE, 2013, EMPIRICAL INFERENCE, V0, P37
   Smagulova K, 2019, EUR PHYS J-SPEC TOP, V228, P2313, DOI 10.1140/epjst/e2019-900046-x
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Spolaór N, 2013, ELECTRON NOTES THEOR, V292, P135, DOI 10.1016/j.entcs.2013.02.010
   Tang YC, 2004, PROCEEDINGS OF THE 2004 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, V0, P73
   Tarca AL, 2007, PLOS COMPUT BIOL, V3, P953, DOI 10.1371/journal.pcbi.0030116
   Tarekegn AN, 2021, PATTERN RECOGN, V118, P0, DOI 10.1016/j.patcog.2021.107965
   Taylor RH, 2016, SPRINGER HANDBOOK OF ROBOTICS, V0, P1657
   Trohidis K, 2011, EURASIP J AUDIO SPEE, V0, P0, DOI DOI 10.1186/1687-4722-2011-426793
   Tsoumakas G, 2007, INT J DATA WAREHOUS, V3, P1, DOI 10.4018/JDWM.2007070101
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Villalba-Diez J, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19183987
   Xue LT, 2022, T ASSOC COMPUT LING, V10, P291, DOI 10.1162/tacl_a_00461
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   You R, 2020, ADV MATER, V32, P0, DOI 10.1002/adma.201901981
   Yu C, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP1865, DOI 10.1145/3477495.3531765
   Zhang ML, 2018, FRONT COMPUT SCI-CHI, V12, P191, DOI 10.1007/s11704-017-7031-7
   Zhang WJ, 2018, ICMR 18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP100, DOI 10.1145/3206025.3206030
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhang Y, 2020, PATTERN RECOGN, V99, P0, DOI 10.1016/j.patcog.2019.107100
   Zhang Z-Li, 2006, ADV NEURAL INFORM PR, V19, P0
   Zhuang H, 2022, ARXIV, V0, P0
NR 117
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD AUG 15
PY 2023
VL 35
IS 23
BP 17167
EP 17185
DI 10.1007/s00521-023-08555-4
EA APR 2023
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA M0ME7
UT WOS:000980150300005
DA 2023-11-10
ER

PT J
AU Lee, SJ
   Lim, J
   Paas, L
   Ahn, HS
AF Lee, Sanghyub John
   Lim, JongYoon
   Paas, Leo
   Ahn, Ho Seok
TI Transformer transfer learning emotion detection model: synchronizing socially agreed and self-reported emotions in big data
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Emotion data sets; Emotion detection model; Transformer-based language model; Constructed emotion theory
AB Tactics to determine the emotions of authors of texts such as Twitter messages often rely on multiple annotators who label relatively small data sets of text passages. An alternative method gathers large text databases that contain the authors' selfreported emotions, to which artificial intelligence, machine learning, and natural language processing tools can be applied. Both approaches have strength and weaknesses. Emotions evaluated by a few human annotators are susceptible to idiosyncratic biases that reflect the characteristics of the annotators. But models based on large, self-reported emotion data sets may overlook subtle, social emotions that human annotators can recognize. In seeking to establish a means to train emotion detection models so that they can achieve good performance in different contexts, the current study proposes a novel transformer transfer learning approach that parallels human development stages: (1) detect emotions reported by the texts' authors and (2) synchronize the model with social emotions identified in annotator-rated emotion data sets. The analysis, based on a large, novel, self-reported emotion data set (n = 3,654,544) and applied to 10 previously published data sets, shows that the transfer learning emotion model achieves relatively strong performance.
C1 [Lee, Sanghyub John; Paas, Leo] Univ Auckland, Mkt Dept, Business Sch, Auckland 1142, New Zealand.
   [Lim, JongYoon; Ahn, Ho Seok] Univ Auckland, Dept Elect Comp & Software Engn, CARES, Auckland 1142, New Zealand.
C3 University of Auckland; University of Auckland
RP Lee, SJ (通讯作者)，Univ Auckland, Mkt Dept, Business Sch, Auckland 1142, New Zealand.
EM sanghyub.lee@auckland.ac.nz; jy.lim@auckland.ac.nz; leo.paas@auckland.ac.nz; hs.ahn@auckland.ac.nz
FU CAUL
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Agirre Eneko, 2007, P 4 INT WORKSH SEM E, V0, P0
   Al-Omari H, 2020, INT CONF INFORM COMM, V0, PP226, DOI 10.1109/ICICS49469.2020.239539
   Balahur A, 2011, LECT NOTES COMPUT SC, V6716, P27, DOI 10.1007/978-3-642-22327-3_4
   Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154
   Barrett LF, 2017, PSYCHOL INQ, V28, P20, DOI 10.1080/1047840X.2017.1261581
   Chatterjee A, 2019, P 13 INT WORKSH SEM, V0, P39
   Crowdflower, 2017, CROWDFL DAT SETS, V0, P0
   Demszky D, 2020, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Dunfield K, 2011, INFANCY, V16, P227, DOI 10.1111/j.1532-7078.2010.00041.x
   DUTTON DG, 1974, J PERS SOC PSYCHOL, V30, P510, DOI 10.1037/h0037031
   Ekman Paul, 1972, NEBRASKA S MOTIVATIO, V19, P207, DOI 10.1037/0022-3514.53.4.712
   Ghazi D, 2015, LECT NOTES COMPUT SC, V9042, P152, DOI 10.1007/978-3-319-18117-2_12
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Kitayama S, 2006, J PERS SOC PSYCHOL, V91, P890, DOI 10.1037/0022-3514.91.5.890
   Kumar N, 2019, NATURAL LANGUAGE PRO, V0, P0
   Lee SJ, 2021, 2021 IEEE REGION 10 CONFERENCE (TENCON 2021), V0, PP429, DOI 10.1109/TENCON54134.2021.9707441
   Lim J, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21082712
   Liu CH, 2017, THESIS MIT, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Mohammad SM, 2017, ARXIV, V0, P0
   Malik F, 2018, DEV STAGES SOCIAL EM, V0, P0
   MCCONATHA JT, 1994, J SOC BEHAV PERS, V9, P481
   Mesquita B, 2003, BEHAV RES THER, V41, P777, DOI 10.1016/S0005-7967(02)00189-4
   Mohammad S, 2018, P 12 INT WORKSH SEM, V0, PP1, DOI 10.18653/V1/S18-1001
   Mohammad S, 2012, P 1 JOINT C LEXICAL, V0, P246
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, P0, DOI 10.1145/3003433
   Mohammad SM, 2015, COMPUT INTELL-US, V31, P301, DOI 10.1111/coin.12024
   Sailunaz K, 2018, SOC NETW ANAL MIN, V8, P0, DOI 10.1007/s13278-018-0505-2
   Salehan M, 2016, DECIS SUPPORT SYST, V81, P30, DOI 10.1016/j.dss.2015.10.006
   Saravia E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3687
   SCHERER KR, 1994, J PERS SOC PSYCHOL, V66, P310, DOI 10.1037/0022-3514.66.2.310
   Schuff H, 2017, P 8 WORKSHOP COMPUTA, V0, P13
   Siegel EH, 2018, PSYCHOL BULL, V144, P343, DOI 10.1037/bul0000128
   Tenney I, 2019, ARXIV, V0, P0
   Tian G, 2021, FOOD QUAL PREFER, V88, P0, DOI 10.1016/j.foodqual.2020.104060
   Uhls YT, 2014, COMPUT HUM BEHAV, V39, P387, DOI 10.1016/j.chb.2014.05.036
   Vinodhini G, 2012, INT J-TORONTO, V2, P282
   Volkova S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1567
   Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, V0, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Zhang Y, 2021, ORG CHEM FRONT, V8, P0, DOI 10.1039/d0qo01636e
NR 43
TC 2
Z9 2
U1 6
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD MAY 15
PY 2023
VL 35
IS 15
BP 10945
EP 10956
DI 10.1007/s00521-023-08276-8
EA JAN 2023
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA P9VF6
UT WOS:000922941100002
PM 36718270
DA 2023-11-10
ER

PT J
AU Sener, F
   Saraf, R
   Yao, A
AF Sener, Fadime
   Saraf, Rishabh
   Yao, Angela
TI Transferring Knowledge From Text to Video: Zero-Shot Anticipation for Procedural Actions
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Visualization; Robots; Data models; Task analysis; Predictive models; Natural languages; Text recognition; Deep learning; action anticipation; zero-shot learning; video analysis
AB Can we teach a robot to recognize and make predictions for activities that it has never seen before? We tackle this problem by learning models for video from text. This paper presents a hierarchical model that generalizes instructional knowledge from large-scale text corpora and transfers the knowledge to video. Given a portion of an instructional video, our model recognizes and predicts coherent and plausible actions multiple steps into the future, all in rich natural language. To demonstrate the capabilities of our model, we introduce the Tasty Videos Dataset V2, a collection of 4022 recipes for zero-shot learning, recognition and anticipation. Extensive experiments with various evaluation metrics demonstrate the potential of our method for generalization, given limited video data for training models.
C1 [Sener, Fadime] Univ Bonn, D-53113 Bonn, Germany.
   [Saraf, Rishabh] Indian Inst Technol ISM Dhanbad, Dhanbad 826004, Jharkhand, India.
   [Yao, Angela] Natl Univ Singapore, Singapore 119077, Singapore.
C3 University of Bonn; Indian Institute of Technology System (IIT System); Indian Institute of Technology (Indian School of Mines) Dhanbad; National University of Singapore
RP Sener, F (通讯作者)，Univ Bonn, D-53113 Bonn, Germany.
EM sener@cs.uni-bonn.de; rishabh.15je001745@am.iitism.ac.in; ayao@comp.nus.edu.sg
FU National Research Foundation, Singapore [NRF-NRFFAI1-2019-0001]
CR Abu Farha Y, 2019, PROC CVPR IEEE, V0, PP3570, DOI 10.1109/CVPR.2019.00369
   Abu Farha Y, 2018, PROC CVPR IEEE, V0, PP5343, DOI 10.1109/CVPR.2018.00560
   Alayrac JB, 2016, PROC CVPR IEEE, V0, PP4575, DOI 10.1109/CVPR.2016.495
   [Anonymous], 2016, P 2016 C N AM ASS CO, V0, P0
   [Anonymous], 1977, SPEECH UNDERSTANDING, V0, P0
   Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, V0, PP65, DOI 10.3115/1626355.1626389
   Beetz Michael, 2011, 2011 11TH IEEE-RAS INTERNATIONAL CONFERENCE ON HUMANOID ROBOTS (HUMANOIDS 2011), V0, PP529, DOI 10.1109/Humanoids.2011.6100855
   Bengio S, 2015, ADV NEUR IN, V28, P0
   Bosselut A, 2018, P 2018 C N AM CHAPTE, V0, PP173, DOI 10.18653/V1/N18-1016
   Brattoli B, 2020, PROC CVPR IEEE, V0, PP4612, DOI 10.1109/CVPR42600.2020.00467
   Camporese G, 2020, ARXIV, V0, P0
   Carvalho M, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP35, DOI 10.1145/3209978.3210036
   Chang CY, 2019, PROC CVPR IEEE, V0, PP3541, DOI 10.1109/CVPR.2019.00366
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   DALE R, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P68
   Damen D, 2020, RESCALING EGOCENTRIC, V0, P0
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Dessalene E, 2020, ARXIV, V0, P0
   Finn Chelsea, 2017, C ROB LEARN, V0, P357
   Freitag M, 2017, ARXIV, V0, P0
   Furnari A, 2019, IEEE I CONF COMP VIS, V0, PP6261, DOI 10.1109/ICCV.2019.00635
   Gan C, 2016, PROC CVPR IEEE, V0, PP87, DOI 10.1109/CVPR.2016.17
   Gao J, 2017, PROC BRIT MACH VIS C, V0, P0
   Hahn M, 2019, ARXIV, V0, P0
   Hammond KJ, 1986, PROCEEDINGS AAAI-86: FIFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P267
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2018, ARXIV, V0, P0
   Holtzman A, 2020, ARXIV, V0, P0
   Huang DA, 2016, LECT NOTES COMPUT SC, V9908, P137, DOI 10.1007/978-3-319-46493-0_9
   Jermsurawong J, 2015, P 2015 C EMPIRICAL M, V0, PP781, DOI 10.18653/V1/D15-1090
   Ke QH, 2019, PROC CVPR IEEE, V0, PP9917, DOI 10.1109/CVPR.2019.01016
   Kiddon C, 2015, EMNLP, V0, PP982, DOI 10.18653/v1/D15-1114
   Kiddon C, 2016, P 2016 C EMP METH NA, V0, PP329, DOI 10.18653/V1/D16-1032
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V28, P3, DOI 10.48550/ARXIV.1506.06726
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Kuehne H, 2014, PROC CVPR IEEE, V0, PP780, DOI 10.1109/CVPR.2014.105
   Kukleva A, 2019, PROC CVPR IEEE, V0, PP12058, DOI 10.1109/CVPR.2019.01234
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Lea C, 2017, PROC CVPR IEEE, V0, PP1003, DOI 10.1109/CVPR.2017.113
   Lea C, 2016, LECT NOTES COMPUT SC, V9907, P36, DOI 10.1007/978-3-319-46487-9_3
   Lee HH, 2020, WWW20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, V0, PP181, DOI 10.1145/3366424.3383536
   Li Y, 2018, PROC CVPR IEEE, V0, PP7492, DOI 10.1109/CVPR.2018.00782
   Lin D, 2015, PROC BRIT MACH VIS C, V0, P0
   Liu C, 2016, PROC C EMPIR METHODS, V0, P0
   Lopez A, 2008, ACM COMPUT SURV, V40, P0, DOI 10.1145/1380584.1380586
   Mahmud T, 2021, ARXIV, V0, P0
   Mahmud T, 2017, IEEE I CONF COMP VIS, V0, PP5784, DOI 10.1109/ICCV.2017.616
   Malmaud Jonathan, 2014, P ACL 2014 WORKSH SE, V0, PP33, DOI 10.3115/V1/W14-2407
   Malmaud Jonathan, 2015, NAACL, V0, P0
   Miao Liu, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12346), V0, PP704, DOI 10.1007/978-3-030-58452-8_41
   Miech Antoine, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9876, DOI 10.1109/CVPR42600.2020.00990
   Miech A, 2019, IEEE I CONF COMP VIS, V0, PP2630, DOI 10.1109/ICCV.2019.00272
   Miech A, 2019, IEEE COMPUT SOC CONF, V0, PP2915, DOI 10.1109/CVPRW.2019.00351
   Min WQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP402, DOI 10.1145/3123266.3123272
   Hoai M, 2011, PROC CVPR IEEE, V0, P0
   Ngiam J, 2011, P 28 INT C INT C MAC, V0, P689
   NLTK, 2018, NATURAL LANGUAGE TOO, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Regneri M, 2013, TACL, V1, P25, DOI 10.1162/TACL_A_00207
   Richard A, 2017, PROC CVPR IEEE, V0, PP1273, DOI 10.1109/CVPR.2017.140
   Richard A, 2016, PROC CVPR IEEE, V0, PP3131, DOI 10.1109/CVPR.2016.341
   Rohrbach M, 2013, IEEE I CONF COMP VIS, V0, PP433, DOI 10.1109/ICCV.2013.61
   Rohrbach M, 2012, PROC CVPR IEEE, V0, PP1194, DOI 10.1109/CVPR.2012.6247801
   Lin AS, 2020, ARXIV, V0, P0
   Salvador A, 2019, PROC CVPR IEEE, V0, PP10445, DOI 10.1109/CVPR.2019.01070
   Salvador A, 2017, PROC CVPR IEEE, V0, PP3068, DOI 10.1109/CVPR.2017.327
   Sener Fadime, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12361), V0, PP154, DOI 10.1007/978-3-030-58517-4_10
   Sener F, 2019, IEEE I CONF COMP VIS, V0, PP862, DOI 10.1109/ICCV.2019.00095
   Sener F, 2018, PROC CVPR IEEE, V0, PP8368, DOI 10.1109/CVPR.2018.00873
   Sener O, 2015, IEEE I CONF COMP VIS, V0, PP4480, DOI 10.1109/ICCV.2015.509
   Shen Y, 2018, LECT NOTES COMPUT SC, V11206, P202, DOI 10.1007/978-3-030-01216-8_13
   Singh B, 2016, PROC CVPR IEEE, V0, PP1961, DOI 10.1109/CVPR.2016.216
   Srivastava N, 2012, ADV NEURAL INF PROCE, V25, P2222, DOI 10.1109/CVPR.2013.49
   Sünderhauf N, 2018, INT J ROBOT RES, V37, P405, DOI 10.1177/0278364918770733
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tang YS, 2019, PROC CVPR IEEE, V0, PP1207, DOI 10.1109/CVPR.2019.00130
   Tenorth M, 2010, IEEE INT CONF ROBOT, V0, PP1499, DOI 10.1109/ROBOT.2010.5509161
   Tran V, 2019, CORR, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, V0, PP4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC INT C MACH LEAR, V0, P0
   Vondrick C, 2016, PROC CVPR IEEE, V0, PP98, DOI 10.1109/CVPR.2016.18
   Wang H, 2022, ARXIV, V0, P0
   Wang H, 2019, PROC CVPR IEEE, V0, PP11564, DOI 10.1109/CVPR.2019.01184
   Wang W, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3293318
   Wang YQ, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3386252
   Wikihow, 2005, ANYTHING, V0, P0
   Wu CX, 2016, IEEE INT CONF ROBOT, V0, PP2479, DOI 10.1109/ICRA.2016.7487401
   Yao L, 2015, IEEE I CONF COMP VIS, V0, PP4507, DOI 10.1109/ICCV.2015.512
   Zhang BW, 2018, LECT NOTES COMPUT SC, V11217, P385, DOI 10.1007/978-3-030-01261-8_23
   Zhou LW, 2018, AAAI CONF ARTIF INTE, V0, P7590
   Zhou LW, 2018, PROC CVPR IEEE, V0, PP8739, DOI 10.1109/CVPR.2018.00911
   Zhou YP, 2015, IEEE I CONF COMP VIS, V0, PP4498, DOI 10.1109/ICCV.2015.511
   Zhu B, 2020, PROC CVPR IEEE, V0, PP5518, DOI 10.1109/CVPR42600.2020.00556
   Zhu Y, 2018, PROC CVPR IEEE, V0, PP9436, DOI 10.1109/CVPR.2018.00983
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
   Zhukov D, 2019, PROC CVPR IEEE, V0, PP3532, DOI 10.1109/CVPR.2019.00365
   Zolfaghari M, 2019, ARXIV, V0, P0
NR 104
TC 0
Z9 0
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUN 1
PY 2023
VL 45
IS 6
BP 7836
EP 7852
DI 10.1109/TPAMI.2022.3218596
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA F5AO9
UT WOS:000982475600081
PM 36318562
DA 2023-11-10
ER

PT J
AU Das, SB
   Biradar, A
   Mishra, TK
   Patra, BK
AF Das, Sudhansu Bala
   Biradar, Atharv
   Mishra, Tapas Kumar
   Patra, Bidyut Kr.
TI Improving Multilingual Neural Machine Translation System for Indic Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Multilingual neuralmachine translation system (MNMT); Indic languages (ILs); low resource language; corpus; BLEU score
AB The Machine Translation System (MTS) serves as effective tool for communication by translating text or speech from one language to another language. Recently, neural machine translation (NMT) has become popular for its performance and cost-effectiveness. However, NMT systems are restricted in translating low-resource languages as a huge quantity of data is required to learn useful mappings across languages. The need for an efficient translation system becomes obvious in a large multilingual environment like India. Indian languages (ILs) are still treated as low-resource languages due to unavailability of corpora. In order to address such an asymmetric nature, the multilingual neural machine translation (MNMT) system evolves as an ideal approach in this direction. The MNMT converts many languages using a single model, which is extremely useful in terms of training process and lowering online maintenance costs. It is also helpful for improving low-resource translation. In this article, we propose an MNMT system to address the issues related to low-resource language translation. Our model comprises two MNMT systems, i.e., for English-Indic (one-to-many) and for Indic-English (many-to-one) with a shared encoder-decoder containing 15 language pairs (30 translation directions). Since most of IL pairs have a scanty amount of parallel corpora, not sufficient for training any machine translation model, we explore various augmentation strategies to improve overall translation quality through the proposed model. A state-of-the-art transformer architecture is used to realize the proposed model. In addition, the article addresses the use of language relationships (in terms of dialect, script, etc.), particularly about the role of high-resource languages of the same family in boosting the performance of low-resource languages. Moreover, the experimental results also show the advantage of back-translation and domain adaptation for ILs to enhance the translation quality of both source and target languages. Using all these key approaches, our proposed model emerges to be more efficient than the baseline model in terms of evaluation metrics, i.e., BLEU (BiLingual Evaluation Understudy) score for a set of ILs.
C1 [Das, Sudhansu Bala; Mishra, Tapas Kumar] Natl Inst Technol NIT, Rourkela 769008, Odisha, India.
   [Biradar, Atharv] Pune Inst Comp Technol PICT, Pune, Maharashtra, India.
   [Patra, Bidyut Kr.] Indian Inst Technol IIT, Varanasi, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Rourkela; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras; Indian Institute of Technology BHU Varanasi (IIT BHU Varanasi)
RP Das, SB (通讯作者)，Natl Inst Technol NIT, Rourkela 769008, Odisha, India.
EM baladas.sudhansu@gmail.com; mishrat@nitrkl.ac.in; bidyut.cse@iitbhu.ac.in
FU Meity (Ministry of Electronics and Information Technology, Government Of India) [13 (12)/2020-CC BT]
CR Aggarwal D, 2022, ARXIV, V0, P0
   Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   Amini Hessam, 2019, FRONTIERS PATTERN RE, V1, P35
   [Anonymous], 2015, P INT WORKSHOP SPOKE, V0, P0
   [Anonymous], 2009, RECENT ADV NAT LANG, V0, P0, DOI DOI 10.1075/CILT.309
   Arivazhagan N, 2019, ARXIV, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Belinkov Y, 2018, ARXIV, V0, P0
   Cho KYHY, 2014, ARXIV, V0, P0
   Dabre R, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3406095
   Dabre Raj, 2015, P 29 PACIFIC ASIA C, V0, P289
   Das Sudhansu Bala, 2022, P 9 WORKSHOP ASIAN T, V0, P73
   Dash Niladri Sekhar, 2008, LANGUAGE FORUM, V34, P5
   Dash Niladri Sekhar, 2009, TRANSLATION TODAY, V6, P134
   Domingo M, 2019, ARXIV, V0, P0
   Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723
   Fan A, 2021, J MACH LEARN RES, V22, P0
   Firat O, 2016, ARXIV, V0, P0
   Genzel Dmitriy, 2010, P 23 INT C COMPUTATI, V0, P376
   Goyal N, 2022, T ASSOC COMPUT LING, V10, P522, DOI 10.1162/tacl_a_00474
   Goyal V, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, V0, P162
   Goyal V, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P191
   Guzman F, 2019, ARXIV, V0, P0
   Haddow B, 2022, COMPUT LINGUIST, V48, P673, DOI 10.1162/coli_a_00446
   Haddow Barry, 2020, PREPRINTS, V0, P0
   Haddow Barry, 2018, P 3 C MACHINE TRANSL, V0, P399
   Hutchins W, 2000, EARLY YEARS MACHINE, V1, P1
   Isahara, 2007, HUMAN LANGUAGE TECHN, V0, P484
   Jamwal Shubhnandan S, 2022, MACHINE INTELLIGENCE AND DATA SCIENCE APPLICATIONS: PROCEEDINGS OF MIDAS 2021. LECTURE NOTES ON DATA ENGINEERING AND COMMUNICATIONS TECHNOLOGIES (132), V0, PP843, DOI 10.1007/978-981-19-2347-0_65
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Junczys-Dowmunt M, 2018, ARXIV, V0, P0
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, V0, P4948
   Khayrallah Huda, 2018, ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Knight Kevin, 2016, ABS160402201 CORR, V0, P0
   Koehn Philipp, 2009, STAT MACHINE TRANSLA, V0, P0
   Kosaraju Prudhvi, 2010, P NLP TOOLS CONTEST, V0, P40
   Kudo T, 2018, ARXIV, V0, P0
   Kunchukuttan A, 2020, INDICNLP LIB, V0, P0
   Kunchukuttan Anoop, 2020, ARXIV, V0, P0
   Lample G, 2018, ARXIV, V0, P0
   Lee Jason, 2017, T ASSOC COMPUT LING, V5, P365, DOI 10.1162/tacl_a_00067
   Li B, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P257
   Lin ZH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P293
   Liu HR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3044
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   More Rohit, 2015, P 12 INT C NATURAL L, V0, P303
   Nakazawa T, 2021, WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION, V0, P1
   Nakazawa Toshiaki, 2022, P 9 WORKSHOP ASIAN T, V0, P0
   Nguyen TQ, 2017, P 8 INT JOINT C NAT, V2, P296
   Ott M, 2019, ARXIV, V0, P0
   Pan X, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P244
   Paolillo John C, 2006, EVALUATING LANGUAGE, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pinnis Marcis, 2018, P 3 C MACHINE TRANSL, V0, P939
   Rajan A, 2020, COMPUT SCI REV, V38, P0, DOI 10.1016/j.cosrev.2020.100299
   Ramesh G, 2022, T ASSOC COMPUT LING, V10, P145, DOI 10.1162/tacl_a_00452
   Sangeetha J, 2014, INT J ENG TECHNOLOGY, V6, P1909
   Sengupta Debapriya, 2015, ADV ARTIFICIAL INTEL, V2015, P0
   Sennrich R, 2016, ARXIV, V0, P0
   Sennrich R, 2016, ARXIV, V0, P0
   Silberztein Max, 2016, FORMALIZING NATURAL, V0, P0
   Singh M, 2020, PROCEDIA COMPUT SCI, V167, P2534, DOI 10.1016/j.procs.2020.03.306
   Siripragada S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P3743
   Sreelekha S, 2018, ADV INTELL SYST, V632, P663, DOI 10.1007/978-981-10-5520-1_59
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Tiedemann Jorg, 2020, P 22 ANN C EUR ASS M, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vikram S, 2013, INT J SCI RES PUBLIC, V3, P1
   Wang YR, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1022
   Wei HP, 2022, J COMPUT SCI TECH-CH, V37, P601, DOI 10.1007/s11390-022-2140-7
NR 72
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN 15
PY 2023
VL 22
IS 6
BP 
EP 
DI 10.1145/3587932
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K7YR0
UT WOS:001018562700015
DA 2023-11-10
ER

PT J
AU Zhu, EW
   Sheng, QL
   Yang, HW
   Liu, YY
   Cai, T
   Li, JP
AF Zhu, Enwei
   Sheng, Qilin
   Yang, Huanwan
   Liu, Yiyang
   Cai, Ting
   Li, Jinpeng
TI A unified framework of medical information annotation and extraction for Chinese clinical text
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Information extraction; Annotation scheme; Electronic medical record; Chinese clinical text
ID neural-networks; corpus
AB Medical information extraction consists of a group of natural language processing (NLP) tasks, which collaboratively convert clinical text to pre-defined structured formats. This is a critical step to exploit electronic medical records (EMRs). Given the recent thriving NLP technologies, model implementation and performance seem no longer an obstacle, whereas the bottleneck locates on a high-quality annotated corpus and the whole engineering workflow. This study presents an engineering framework consisting of three tasks, i.e., medical entity recognition, relation extraction and attribute extraction. Within this framework, the whole workflow is demonstrated from EMR data collection through model performance evaluation. Our annotation scheme is designed to be comprehensive and compatible between the multiple tasks. With the EMRs from a general hospital in Ningbo, China, and the manual annotation by experienced physicians, our corpus is of large scale and high quality. Built upon this Chinese clinical corpus, the medical information extraction system show performance that approaches human annotation. The annotation scheme, (a subset of) the annotated corpus, and the code are all publicly released, to facilitate further research.
C1 [Zhu, Enwei; Sheng, Qilin; Yang, Huanwan; Liu, Yiyang; Cai, Ting; Li, Jinpeng] Ningbo 2 Hosp, Ningbo 315010, Zhejiang, Peoples R China.
   [Zhu, Enwei; Liu, Yiyang; Cai, Ting; Li, Jinpeng] Univ Chinese Acad Sci, Ningbo Inst Life & Hlth Ind, Ningbo 315016, Zhejiang, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Cai, T; Li, JP (通讯作者)，Ningbo 2 Hosp, Ningbo 315010, Zhejiang, Peoples R China.; Cai, T; Li, JP (通讯作者)，Univ Chinese Acad Sci, Ningbo Inst Life & Hlth Ind, Ningbo 315016, Zhejiang, Peoples R China.
EM zhuenwei@ucas.ac.cn; shengqilin0106@163.com; yanghuanw@163.com; liuyiyang@ucas.ac.cn; caiting@ucas.ac.cn; shengqilin0106@163.com
FU Zhejiang Provincial Natural Science Foundation of China [LQ23F020005]; National Natural Science Foun-dation of China [62106248]; Ningbo Science and Technology Service Industry Demonstration Project, China [2020F041]; Ningbo Public Service Technology Foundation, China [2021S152]
CR Albright D, 2013, J AM MED INFORM ASSN, V20, P922, DOI 10.1136/amiajnl-2012-001317
   [Anonymous], 2010, P 13 INT C ART INT S, V0, P0
   Campillos L, 2018, LANG RESOUR EVAL, V52, P571, DOI 10.1007/s10579-017-9382-y
   Casillas A, 2016, EXPERT SYST APPL, V61, P235, DOI 10.1016/j.eswa.2016.05.034
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Cui Yiming, 2020, FINDINGS ASS COMPUTA, V0, PP657, DOI 10.18653/V1/2020.FINDINGS-EMNLP.58
   de Bruijn B, 2011, J AM MED INFORM ASSN, V18, P557, DOI 10.1136/amiajnl-2011-000150
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006
   Eberts M, 2020, FRONT ARTIF INTEL AP, V325, P2006, DOI 10.3233/FAIA200321
   Gao Y, 2019, BMC MED INFORM DECIS, V19, P0, DOI 10.1186/s12911-019-0759-2
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   He B, 2017, J BIOMED INFORM, V69, P203, DOI 10.1016/j.jbi.2017.04.006
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Kaiming He, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV). PROCEEDINGS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Kim JD, 2003, BIOINFORMATICS, V19, Pi180, DOI 10.1093/bioinformatics/btg1023
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee LH, 2021, IEEE J BIOMED HEALTH, V25, P2801, DOI 10.1109/JBHI.2020.3048700
   Li J, 2016, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/baw068
   Liang HY, 2019, NAT MED, V25, P433, DOI 10.1038/s41591-018-0335-9
   Liu YH, 2019, ARXIV, V0, P0
   Meystre S, 2006, J BIOMED INFORM, V39, P589, DOI 10.1016/j.jbi.2005.11.004
   Ogren PV, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3143
   Pascanu R, 2013, P 30 INT C MACHINE L, V0, P0
   Peng M, 2020, P 58 ANN M ASS COMP, V0, PP5951, DOI 10.18653/v1/2020.acl-main.528
   Pramanik MI, 2020, EXPERT SYST APPL, V152, P0, DOI 10.1016/j.eswa.2020.113388
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Roberts A, 2009, J BIOMED INFORM, V42, P950, DOI 10.1016/j.jbi.2008.12.013
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Savkov A, 2016, LANG RESOUR EVAL, V50, P523, DOI 10.1007/s10579-015-9330-7
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stenetorp P, 2012, P DEMONSTRATIONS 13, V0, P102
   Sun WY, 2013, J AM MED INFORM ASSN, V20, P806, DOI 10.1136/amiajnl-2013-001628
   Sun Y, 2019, ARXIV, V0, P0
   Sung SF, 2020, IEEE J BIOMED HEALTH, V24, P2922, DOI 10.1109/JBHI.2020.2976931
   Tongfeng Guan, 2020, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 9TH CCF INTERNATIONAL CONFERENCE, V0, P270, DOI 10.1007/978-3-030-60450-9_22
   Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203
   Uzuner Ö, 2010, J AM MED INFORM ASSN, V17, P514, DOI 10.1136/jamia.2010.003947
   Uzuner Ö, 2009, J AM MED INFORM ASSN, V16, P561, DOI 10.1197/jamia.M3115
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zhong ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P50
   Zhu EW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7096
NR 46
TC 0
Z9 0
U1 14
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD AUG 15
PY 2023
VL 142
IS 
BP 
EP 
DI 10.1016/j.artmed.2023.102573
EA MAY 2023
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA J5QE0
UT WOS:001010153700001
PM 37316096
DA 2023-11-10
ER

PT J
AU Wu, TJ
   Ling, Q
AF Wu, Tangjie
   Ling, Qiang
TI Fusing hybrid attentive network with self-supervised dual-channel heterogeneous graph for knowledge tracing
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Heterogeneous graph neural network; Contrastive learning; Self-supervised learning; Attention mechanism; Knowledge tracing
ID tests
AB Recently the large-scale influence of Covid-19 promoted the fast development of intelligent tutoring systems (ITS). As a major task of ITS, Knowledge Tracing (KT) aims to capture a student's dynamic knowledge state based on his historical response sequences and provide personalized learning assistance to him. However, most existing KT methods have encountered the data sparsity problem. In real scenarios, an online tutoring system usually has an extensive collection of questions while each student can only interact with a limited number of questions. As a result, the records of some questions could be extremely sparse, which degrades the performance of traditional KT models. To resolve this issue, we propose a Dual-channel Heterogeneous Graph Network (DHGN) to learn informative representations of questions from students' records by capturing both the high-order heterogeneous and local relations. As the supervised learning manner applied in previous methods is incapable of exploiting unobserved relations between questions, we innovatively integrate a self-supervised framework into the KT task and employ contrastive learning via the two channels of DHGN, supplementing as an auxiliary task to improve the KT performance. Moreover, we adopt the attention mechanism, which has achieved impressive performance in natural language processing tasks, to effectively capture students' knowledge state. But the standard attention network is inapplicable to the KT task because the current knowledge state of a student usually shows strong dependency on his recently interactive questions, unlike the situation of language processing tasks, which focus more on the long-term dependency. To avoid the inefficiency of standard attention networks in the KT task, we further devise a novel Hybrid Attentive Network (HAN), which produces both the global attention and the hierarchical local attention to model the long-term and short-term intents, respectively. Then, by the gating network, a student's long-term and short-term intents are combined for efficient prediction. We conduct extensive experiments on several real-world datasets. Experimental results demonstrate that our proposed methods achieve significant performance improvement compared to existing state-of-the-art baselines, which validates the effectiveness of the proposed dual-channel framework and attentive network.
C1 [Wu, Tangjie; Ling, Qiang] Univ Sci & Technol China, 440 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of China, CAS
RP Ling, Q (通讯作者)，Univ Sci & Technol China, 440 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
EM wtj1999@mail.ustc.edu.cn; qling@ustc.edu.cn
FU Provincial Quality Program of High Education Schools of Anhui Province, China [2021jyxm1743]; Key Science and Technology Program of Anhui, China [202203f07020002, 202203a05020012]; Applied Science and Technology Achievement Cul-tivation Project of Institute of Advanced Technology, University of Science and Technology of China
CR Abdelrahman G, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP175, DOI 10.1145/3331184.3331195
   Adesope OO, 2017, REV EDUC RES, V87, P659, DOI 10.3102/0034654316689306
   Carpenter SK, 2008, MEM COGNITION, V36, P438, DOI 10.3758/MC.36.2.438
   Chung JY, 2014, ARXIV, V0, P0
   Collobert R, 2008, P 25 INT C MACH LEAR, V0, PP160, DOI 10.1145/1390156.1390177
   CORBETT AT, 1994, USER MODEL USER-ADAP, V4, P253, DOI 10.1007/BF01099821
   Dong W, 2022, KNOWL-BASED SYST, V254, P0, DOI 10.1016/j.knosys.2022.109616
   Dong W, 2023, IEEE T IND INFORM, V19, P2385, DOI 10.1109/TII.2022.3156658
   Fersini E, 2014, BMC BIOINFORMATICS, V15, P0, DOI 10.1186/s12859-014-0353-7
   Ghosh A, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2330, DOI 10.1145/3394486.3403282
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Hassani K, 2020, P ICML 2020, VVolume 119, P4116, DOI 10.48550/ARXIV.2006.05582
   Hu ZN, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2704, DOI 10.1145/3366423.3380027
   Ji WD, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP565, DOI 10.1145/3340531.3411869
   Jiang H, 2023, PATTERN RECOGN LETT, V165, P25, DOI 10.1016/j.patrec.2022.11.016
   Kasurinen J, 2009, ITICSE 2009: PROCEEDING OF THE 2009 ACM SIGSE ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, V0, PP313, DOI 10.1145/1595496.1562972
   Kingma DP, 2014, C TRACK P, V0, P0
   Lindsey RV, 2014, PSYCHOL SCI, V25, P639, DOI 10.1177/0956797613504302
   Liu S, 2021, EXPERT SYST APPL, V177, P0, DOI 10.1016/j.eswa.2021.114935
   Lu YF, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1563, DOI 10.1145/3394486.3403207
   Minn S, 2019, LECT NOTES ARTIF INT, V11440, P163, DOI 10.1007/978-3-030-16145-3_13
   Kipf TN, 2017, ARXIV, V0, P0
   Nagatani K, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP3101, DOI 10.1145/3308558.3313565
   Ni Q, 2023, EXPERT SYST APPL, V215, P0
   Pandey S, 2019, ARXIV, V0, P0
   Peng Z, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP259, DOI 10.1145/3366423.3380112
   Peters B, 2019, ARXIV, V0, P0
   Piech C, 2015, ARXIV, V0, P0
   Pozna C, 2010, KNOWL-BASED SYST, V23, P182, DOI 10.1016/j.knosys.2009.11.015
   Precup RE, 2021, ROM J INF SCI TECH, V24, P353
   Ren YX, 2020, ARXIV, V0, P0
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Shang JB, 2016, ARXIV, V0, P0
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Song XY, 2021, INFORM SCIENCES, V580, P510, DOI 10.1016/j.ins.2021.08.100
   Su Y, 2018, AAAI CONF ARTIF INTE, V0, P2435
   Sun Fan-Yun, 2019, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1908.01000
   Sun J, 2022, EXPERT SYST APPL, V0, P0
   Sun Y, 2013, SIGKDD EXPLOR NEWSL, V14, P20, DOI 10.1145/2481244.2481248
   Sunt YZ, 2011, PROC VLDB ENDOW, V4, P992
   Tong HS, 2021, ARXIV, V0, P0
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Van den Oord Aaron, 2018, ARXIV, V0, P0
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Velickovic P, 2019, ICLR, V2, P4, DOI 10.1007/S11222-007-9033-Z
   Veličkovic P, 2018, ARXIV, V0, P0
   Wang CY, 2021, WSDM 21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP517, DOI 10.1145/3437963.3441802
   Wang WT, 2022, EXPERT SYST APPL, V192, P0, DOI 10.1016/j.eswa.2021.116454
   Wang X, 2021, KDD 21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1726, DOI 10.1145/3447548.3467415
   Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2022, DOI 10.1145/3308558.3313562
   Wang YF, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP1605, DOI 10.1145/3340531.3411996
   Wei LT, 2022, COMPUT ELECTR ENG, V102, P0, DOI 10.1016/j.compeleceng.2022.108179
   Wu TJ, 2023, INFORM SCIENCES, V624, P200, DOI 10.1016/j.ins.2022.12.075
   Wu ZY, 2022, EXPERT SYST APPL, V206, P0, DOI 10.1016/j.eswa.2022.117681
   Xu K, 2018, ARXIV PREPRINT ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1810.00826
   Yang Y, 2020, ARXIV, V0, P0
   Yudelson Michael V, 2013, ARTIFICIAL INTELLIGENCE IN EDUCATION. PROCEEDINGS OF 16TH INTERNATIONAL CONFERENCE (AIED 2013): LNCS 7926, V0, PP171, DOI 10.1007/978-3-642-39112-5_18
   Zhang CX, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP793, DOI 10.1145/3292500.3330961
   Zhang JN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP765, DOI 10.1145/3038912.3052580
   Zhu YQ, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), V0, PP2069, DOI 10.1145/3442381.3449802
NR 62
TC 0
Z9 0
U1 12
U2 12
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 1
PY 2023
VL 225
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120212
EA APR 2023
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA G3GA2
UT WOS:000988069400001
DA 2023-11-10
ER

PT J
AU Fernando, A
   Ranathunga, S
   Sachintha, D
   Piyarathna, L
   Rajitha, C
AF Fernando, Aloka
   Ranathunga, Surangika
   Sachintha, Dilan
   Piyarathna, Lakmali
   Rajitha, Charith
TI Exploiting bilingual lexicons to improve multilingual embedding-based document and sentence alignment for low-resource languages
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Document alignment; Sentence alignment; Low-resource languages; Neural machine translation; Parallel corpus mining
ID web
AB Neural machine translation systems trained on low-resource languages produce sub-optimal results due to the scarcity of large parallel datasets. To alleviate this problem, parallel corpora can be mined from the web. Two key tasks in a parallel corpus mining pipeline are web document alignment and sentence alignment. Effective approaches for these tasks obtained vector representations of the documents (or sentences) belonging to the two languages and determine the alignment between the documents (or sentences) based on a semantic similarity scoring mechanism. Recently, document or sentence representations obtained from pre-trained multilingual language models (PMLMs) such as LASER, XLM-R and LaBSE have significantly improved the benchmark scores in diverse natural language processing tasks. In this study, we carry out an empirical analysis of the effectiveness of these PMLMs of the document and sentence alignment tasks in the context of the low-resource language pairs Sinhala-English, Tamil-English and Sinhala-Tamil. Further, we introduce a weighting mechanism based on small-scale bilingual lexicons to improve the semantic similarity measurement between sentences and documents. Our results show that both document and sentence alignment can be further improved using our weighting mechanism. We have also compiled a gold-standard evaluation benchmark dataset for document alignment and sentence alignment tasks for the considered language pairs. This dataset (https://github.com/kdissa/comparable-corpus) and the source code (https://github.com/nIpcuom/parallel_corpus_mining) are publicly released.
C1 [Fernando, Aloka; Ranathunga, Surangika; Sachintha, Dilan; Piyarathna, Lakmali; Rajitha, Charith] Univ Moratuwa, Dept Comp Sci & Engn, Katubedda, Sri Lanka.
C3 University Moratuwa
RP Fernando, A (通讯作者)，Univ Moratuwa, Dept Comp Sci & Engn, Katubedda, Sri Lanka.
EM alokaf@cse.mrt.ac.lk; surangika@cse.mrt.ac.lk; dilansachintha.16@cse.mrt.ac.lk; lakmali.16@cse.mrt.ac.lk; rajitha.16@cse.mrt.ac.lk
FU Higher Education Expansion and Development (AHEAD); Senate Research Committee (SRC) Grant University of Moratuwa
CR [Anonymous], 2009, EACL, V0, P0
   [Anonymous], 2015, P 8 WORKSHOP BUILDIN, V0, P0
   [Anonymous], 2018, P 3 C MACHINE TRANSL, V0, P0, DOI DOI 10.18653/V1/W18-6317
   [Anonymous], 2000, P RIAO 2000 CONT BAS, V0, P0
   [Anonymous], 2004, P 2004 C EMP METH NA, V0, P0
   [Anonymous], 2016, SHARED TASK PAPERS, V0, P0
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Artetxe M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3197
   Azpeitia A, 2018, P 11 WORKSH BUILD US, V0, P48
   Azpeitia Andoni, 2017, P 10 WORKSH BUILD US, V0, PP41, DOI 10.18653/v1/W17-2508
   Bañón M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4555
   Bouamor H, 2018, P 11 WORKSH BUILD US, V0, P43
   BROWN PF, 1991, P 29 ANN M ASS COMP, V0, PP169, DOI 10.3115/981344.981366
   Buck Christian, 2016, P 1 C MACHINE TRANSL, V0, PP672, DOI 10.18653/v1/W16-2365
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Dara Aswarth Abhilash, 2016, P 1 C MACHINE TRANSL, V0, PP679, DOI 10.18653/v1/W16-2366
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   El-Kishky A, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P616
   Espla-Gomis M, 2016, P 1 C MACHINE TRANSL, V0, PP685, DOI 10.18653/v1/w16-2367
   Etchegoyhen T, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P3799
   Farhath F, 2018, 2018 MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON) 4TH INTERNATIONAL MULTIDISCIPLINARY ENGINEERING RESEARCH CONFERENCE, V0, PP538, DOI 10.1109/MERCon.2018.8421901
   Feng F, 2020, ARXIV, V0, P0
   Fernando A, 2020, ARXIV, V0, P0
   Gale WA, 1993, COMPUTATIONAL LINGUISTICS, V19, P75
   Germann Ulrich, 2016, P 1 C MACH TRANSL, V0, PP692, DOI 10.18653/v1/W16-2368
   Gomes L, 2016, SHARED TASK PAPERS, V2, P697
   Goyal N, 2021, ARXIV, V0, P0
   Gregoire F, 2017, P 10 WORKSH BUILD US, V0, PP46, DOI 10.18653/V1/W17-2509
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6098
   Hall KB, 2021, ARXIV, V0, P0
   Hangya V, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1224
   Ion R, 2011, P 4 WORKSH BUILD US, V0, P128
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Jakubina L, 2016, P 1 C MACHINE TRANSL, V2, P703
   Joshi Pratik, 2020, P 58 ANN M ASS COMP, V0, PP6282, DOI 10.18653/V1/2020.ACL-MAIN.560
   Koehn P, 2017, WMT, V0, P28
   Koehn P, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, P0
   Koehn Philipp, 2018, P 3 C MACH TRANSL SH, V0, PP726, DOI 10.18653/V1/W18-6453
   Kreutzer Julia, 2022, TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V10, P50, DOI 10.1162/tacl_a_00447
   Kvapilíková I, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, V0, P255
   Lee EJ, 2022, ARXIV, V0, P0
   Leong C, 2018, 11 WORKSH BUILD US C, V0, P0
   Li B, 2013, BUILDING USING COMP, V0, P131
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Ma X, 1999, MACHINE TRANSLATION, V0, P538
   Ma Xiaoyi, 2006, P 5 INT C LANG RES A, V0, P0
   Mahata S, 2017, P 10 WORKSHOP BUILDI, V0, PP56, DOI 10.18653/V1/W17-2511
   Medved Marek, 2016, P 1 C MACHINE TRANSL, V0, PP728, DOI 10.18653/v1/W16-2374
   Morin E, 2015, P 8 WORKSHOP BUILDIN, V0, P88
   Munteanu DS, 2005, COMPUT LINGUIST, V31, P477, DOI 10.1162/089120105775299168
   Munteanu DS, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, P289
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Papavassiliou V, 2016, P 1 C MACH TRANSL, V2, P733
   Post Matt, 2018, P 3 C MACH TRANSL RE, V0, PP186, DOI 10.18653/v1/W18-6319
   Priyadarshani HS, 2019, INT CONF ASIAN LANG, V0, PP244, DOI 10.1109/ialp48816.2019.9037651
   Rajitha Charith, 2021, P INT C RECENT ADV N, V0, P1150
   Rajitha MDC, 2020, INT CONF ADV ICT, V0, PP29, DOI 10.1109/ICTer51097.2020.9325462
   Ranathunga S, 2021, ARXIV, V0, P0
   Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578
   Resnik P, 1998, LECT NOTES ARTIF INT, V1529, P72
   Sarikaya R, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P432
   Schwenk H, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1351
   Schwenk Holger, 2021, P 59 ANN M ASS COMPU, V0, PP6490, DOI 10.18653/V1/2021.ACL-LONG.507
   Shi L, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Stefanescu D, 2012, P 16 C EUR ASS MACH, V0, P137
   Thillainathan S, 2021, MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON 2021) / 7TH INTERNATIONAL MULTIDISCIPLINARY ENGINEERING RESEARCH CONFERENCE, V0, PP432, DOI 10.1109/MERCON52712.2021.9525720
   Thompson B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1342
   Uszkoreit Jakob, 2010, P 23 INT C COMPUTATI, V0, P1101
   Varga D, 2007, RECENT ADV NATURAL L, VIV, P247, DOI 10.1075/CILT.292.32VAR
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Yang YF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5370
   Zweigenbaum P, 2018, P 11 WORKSH BUILD US, V0, P39
NR 73
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD FEB 15
PY 2023
VL 65
IS 2
BP 571
EP 612
DI 10.1007/s10115-022-01761-x
EA OCT 2022
PG 42
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 8E2EU
UT WOS:000869320800001
DA 2023-11-10
ER

PT J
AU Zhou, JF
   Zhu, YP
   Zhang, YA
   Yang, C
   Pan, H
AF Zhou, Jinfei
   Zhu, Yaping
   Zhang, Yana
   Yang, Cheng
   Pan, Hong
TI Spatial-aware topic-driven-based image Chinese caption for disaster news
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Image caption; Dataset of disaster news; Gaussian mixture model; News topic classification
ID generation; language
AB Automatically generating descriptions for disaster news images could effectively accelerate the spread of disaster message and lighten the burden of news editors from tedious news materials. Image caption algorithms are remarkable for generating captions directly from the content of the image. However, current image caption algorithms trained on existing image caption datasets fail to describe the disaster images with fundamental news elements. In this paper, we developed a large-scale disaster news image Chinese caption dataset (DNICC19k), which collected and annotated enormous news images related to disaster. Furthermore, we proposed a spatial-aware topic driven caption network (STCNet) to encode the interrelationships between these news objects and generate descriptive sentences related to news topics. STCNet firstly constructs a graph representation based on objects feature similarity. The graph reasoning module uses the spatial information to infer the weights of aggregated adjacent nodes according to a learnable Gaussian kernel function. Finally, the generation of news sentences are driven by the spatial-aware graph representations and the news topics distribution. Experimental results demonstrate that STCNet trained on DNICC19k could not only automatically creates descriptive sentences related to news topics for disaster news images, but also outperforms benchmark models such as Bottom-up, NIC, Show attend and AoANet on multiple evaluation metrics, achieving CIDEr/BLEU-4 scores of 60.26 and 17.01, respectively.
C1 [Zhou, Jinfei; Zhu, Yaping; Zhang, Yana; Yang, Cheng] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
   [Pan, Hong] Swinburne Univ Technol, Data Sci Res Inst, Melbourne 3122, Australia.
C3 Communication University of China; Swinburne University of Technology
RP Zhu, YP (通讯作者)，Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
EM zhoujinfei@cuc.edu.cn; zhuyaping@cuc.edu.cn; zynjenny@cuc.edu.cn; chy@cuc.edu.cn; hpan@swin.edu.au
FU Fundamental Research Funds for the Central Universities [CUC210B018]
CR Agrawal H, 2019, IEEE I CONF COMP VIS, V0, PP8947, DOI 10.1109/ICCV.2019.00904
   Anderson P, 2018, PROC CVPR IEEE, V0, PP3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Bai L, 2016, NEURAL COMPUT APPL, V27, P335, DOI 10.1007/s00521-015-1846-7
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, V0, PP65, DOI 10.3115/1626355.1626389
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng YS, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P1239
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Biten AF, 2019, PROC CVPR IEEE, V0, PP12458, DOI 10.1109/CVPR.2019.01275
   Gan Z, 2017, PROC CVPR IEEE, V0, PP1141, DOI 10.1109/CVPR.2017.127
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   Hodosh M, 2010, P NAACL HLT 2010 WOR, V0, P0
   Hodosh M, 2014, P TACL, V7, P67, DOI 10.1162/tacl_a_00166
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Jing Y, 2020, IEEE ACCESS, V8, P143584, DOI 10.1109/ACCESS.2020.3013321
   Johnson J, 2015, PROC CVPR IEEE, V0, PP3668, DOI 10.1109/CVPR.2015.7298990
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Kingma DP, 2014, C TRACK P, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li LJ, 2019, IEEE I CONF COMP VIS, V0, PP10312, DOI 10.1109/ICCV.2019.01041
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Lin TY, 2017, PROC IEEE C COMPUT V, V0, P2117
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MF, 2022, IEEE T CYBERNETICS, V52, P1247, DOI 10.1109/TCYB.2020.2997034
   Liu MF, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102178
   Lu D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4013
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Lu JS, 2018, PROC CVPR IEEE, V0, PP7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, V0, PP3242, DOI 10.1109/CVPR.2017.345
   Monti F, 2017, PROC CVPR IEEE, V0, PP5425, DOI 10.1109/CVPR.2017.576
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Ramos Juan, 2003, P 1 INSTR C MACH LEA, V242, P29, DOI 10.15804/TNER.2015.42.4.03
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Tran A, 2020, P IEEECVF C COMPUTER, V0, P13035
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   VEDANTAM R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vijay K, 2015, INT CONF COMPUT POW, V0, PP536, DOI 10.1109/ICCPEIC.2015.7259513
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wang B, 2020, IEEE ACCESS, V8, P104543, DOI 10.1109/ACCESS.2020.2999568
   Wu JH, 2019, IEEE INT CON MULTI, V0, PP1480, DOI 10.1109/ICME.2019.00256
   Wu Q, 2016, PROC CVPR IEEE, V0, PP203, DOI 10.1109/CVPR.2016.29
   Xiujun I, 2020, ECCV, V0, P0
   Xu H, 2019, PROC CVPR IEEE, V0, PP9290, DOI 10.1109/CVPR.2019.00952
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, V0, PP10677, DOI 10.1109/CVPR.2019.01094
   Yang Y, 2011, P C EMP METH NAT LAN, V0, PP444, DOI 10.5555/2145432.2145484
   Yang Z, 2020, P 28 INT C COMP LING, V0, P1941
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   You QZ, 2016, PROC CVPR IEEE, V0, PP4651, DOI 10.1109/CVPR.2016.503
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
NR 56
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD MAY 15
PY 2023
VL 35
IS 13
BP 9481
EP 9500
DI 10.1007/s00521-022-08072-w
EA MAR 2023
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA D5DN0
UT WOS:000949264800001
PM 37077618
DA 2023-11-10
ER

PT J
AU Ahmed, M
   Khan, H
   Iqbal, T
   Alarfaj, FK
   Alomair, A
   Almusallam, N
AF Ahmed, Muzamil
   Khan, Hikmat
   Iqbal, Tassawar
   Alarfaj, Fawaz Khaled
   Alomair, Abdullah
   Almusallam, Naif
TI On solving textual ambiguities and semantic vagueness in MRC based question answering using generative pre-trained transformers
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Machine reading comprehension; Natural language understanding; Generative pretrained transformers; Question answering; Textual ambiguities
AB Machine reading comprehension (MRC) is one of the most challenging tasks and active fields in natural language processing (NLP). MRC systems aim to enable a machine to understand a given context in natural language and to answer a series of questions about it. With the advent of bi-directional deep learning algorithms and large-scale datasets, MRC achieved improved results. However, these models are still suffering from two research issues: textual ambiguities and semantic vagueness to comprehend the long passages and generate answers for abstractive MRC systems. To address these issues, this paper proposes a novel Extended Generative Pretrained Transformers-based Question Answering (ExtGPT-QA) model to generate precise and relevant answers to questions about a given context. The proposed architecture comprises two modified forms of encoder and decoder as compared to GPT. The encoder uses a positional encoder to assign a unique representation with each word in the sentence for reference to address the textual ambiguities. Subsequently, the decoder module involves a multihead attention mechanism along with affine and aggregation layers to mitigate semantic vagueness with MRC systems. Additionally, we applied syntax and semantic feature engineering techniques to enhance the effectiveness of the proposed model. To validate the proposed model's effectiveness, a comprehensive empirical analysis is carried out using three benchmark datasets including SQuAD, Wiki-QA, and News-QA. The results of the proposed ExtGPT-QA outperformed state of art MRC techniques and obtained 93.25% and 90.52% F1-score and exact match, respectively. The results confirm the effectiveness of the ExtGPT-QA model to address textual ambiguities and semantic vagueness issues in MRC systems.
C1 [Ahmed, Muzamil; Khan, Hikmat; Iqbal, Tassawar] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
   [Alarfaj, Fawaz Khaled; Alomair, Abdullah; Almusallam, Naif] King Faisal Univ, Sch Business, Dept Management Informat Syst, Al Hufuf, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); King Faisal University
RP Khan, H (通讯作者)，COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
EM hikmat.ullah@ciitwah.edu.pk
FU Deanship of Scientific Research, Vice Presidency for Graduate Studies and Scientific Research, King Faisal University, Saudi Arabia [2051]
CR Aithal SG, 2021, APPL INTELL, V51, P8484, DOI 10.1007/s10489-021-02348-9
   Back S, 2020, INT C LEARNING REPRE, V0, P0
   Bai ZW, 2022, NEUROCOMPUTING, V509, P46, DOI 10.1016/j.neucom.2022.08.057
   Baradaran R, 2022, NAT LANG ENG, V28, P683, DOI 10.1017/S1351324921000395
   Bi M, 2021, T ASIAN LOW RESOUR L, V20, P1
   Soares MAC, 2020, J KING SAUD UNIV-COM, V32, P635, DOI 10.1016/j.jksuci.2018.08.005
   Chen DG, 2021, COMPUT INTEL NEUROSC, V2021, P0, DOI 10.1155/2021/8810366
   Chen N, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7833, DOI 10.1109/ICASSP39728.2021.9414067
   Chen P, 2022, COMPUT INTEL NEUROSC, V2022, P0, DOI 10.1155/2022/5755327
   Galitsky B, 2021, P INT C RECENT ADV N, V0, P444
   Reddy RG, 2020, ARXIV, V0, P0
   Garg S, 2019, ARXIV, V0, P0
   Gharagozlou H, 2022, COMPUT INTEL NEUROSC, V2022, P0, DOI 10.1155/2022/7839840
   Guo SR, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P891
   He J, 2022, INT J PATTERN RECOGN, V36, P0, DOI 10.1142/S0218001422510041
   Ji YJ, 2022, ARXIV, V0, P0
   Jiang C, 2021, J CIRCUIT SYST COMP, V30, P0, DOI 10.1142/S0218126621500134
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Lapchaicharoenkit Theerit, 2020, ICCCM20: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS MANAGEMENT, V0, PP3, DOI 10.1145/3411174.3411184
   Le Hang Thi-Thu, 2022, 2022 9TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), V0, PP53, DOI 10.1109/NICS56915.2022.10013390
   Li FF, 2022, NEUROCOMPUTING, V488, P66, DOI 10.1016/j.neucom.2022.02.082
   Liao JZ, 2022, WORLD WIDE WEB, V25, P1469, DOI 10.1007/s11280-021-00980-6
   Lin D, 2019, SELECTING PARAGRAPHS, V0, P121
   Liu J, 2020, ARXIV, V0, P0
   Liu J, 2022, NEUROCOMPUTING, V488, P414, DOI 10.1016/j.neucom.2022.03.016
   Loginova E, 2021, INFORM SYST FRONT, V23, P227, DOI 10.1007/s10796-020-09996-1
   Manjunath TN, 2023, MATERIALS TODAY: PROCEEDINGS, V0, PP3719, DOI 10.1016/j.matpr.2021.07.369
   Matsubara Y, 2022, ARXIV, V0, P0
   Mishra A, 2016, J KING SAUD UNIV-COM, V28, P345, DOI 10.1016/j.jksuci.2014.10.007
   Mohammadi A, 2022, ARXIV, V0, P0
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Sang YS, 2022, ARXIV, V0, P0
   Turing AM, 1950, COMPUTING MACHINERY, V0, P23
   Xu XB, 2022, INT CONF ASIAN LANG, V0, PP312, DOI 10.1109/IALP57159.2022.9961260
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, P0, DOI DOI 10.18653/V1/D15-1237
   Yang ZM, 2022, CONCURR COMP-PRACT E, V34, P0, DOI 10.1002/cpe.5828
   Yu JX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2241
   Yuan SY, 2021, LECT NOTES COMPUT SC, V12922, P93, DOI 10.1007/978-3-030-88361-4_6
   Zeng CC, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10217640
   Zihayat M, 2021, EXPERT SYST APPL, V177, P0, DOI 10.1016/j.eswa.2021.114910
NR 40
TC 0
Z9 0
U1 4
U2 4
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 24
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1422
PG 31
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA O0DX1
UT WOS:001040622600001
PM 37547420
DA 2023-11-10
ER

PT J
AU Jain, N
   Sierra-Múnera, A
   Ehmueller, J
   Krestel, R
AF Jain, Nitisha
   Sierra-Munera, Alejandro
   Ehmueller, Jan
   Krestel, Ralf
TI Generation of training data for named entity recognition of artworks
SO SEMANTIC WEB
LA English
DT Article
DE Training data generation; named entity recognition; cultural heritage data; weakly-supervised learning
AB As machine learning techniques are being increasingly employed for text processing tasks, the need for training data has become a major bottleneck for their application. Manual generation of large scale training datasets tailored to each task is a time consuming and expensive process, which necessitates their automated generation. In this work, we turn our attention towards creation of training datasets for named entity recognition (NER) in the context of the cultural heritage domain. NER plays an important role in many natural language processing systems. Most NER systems are typically limited to a few common named entity types, such as person, location, and organization. However, for cultural heritage resources, such as digitized art archives, the recognition of fine-grained entity types such as titles of artworks is of high importance. Current state of the art tools are unable to adequately identify artwork titles due to unavailability of relevant training datasets. We analyse the particular difficulties presented by this domain and motivate the need for quality annotations to train machine learning models for identification of artwork titles. We present a framework with heuristic based approach to create high-quality training data by leveraging existing cultural heritage resources from knowledge bases such as Wikidata. Experimental evaluation shows significant improvement over the baseline for NER performance for artwork titles when models are trained on the dataset generated using our framework.
C1 [Jain, Nitisha; Sierra-Munera, Alejandro; Ehmueller, Jan; Krestel, Ralf] Univ Potsdam, Hasso Plattner Inst, Potsdam, Germany.
C3 University of Potsdam
RP Jain, N (通讯作者)，Univ Potsdam, Hasso Plattner Inst, Potsdam, Germany.
EM Nitisha.Jain@hpi.de; Alejandro.Sierra@hpi.de; Jan.Ehmueller@student.hpi.uni-potsdam.de; Ralf.Krestel@hpi.de
FU HPI Research School on Data Science and Engineering
CR Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   Akbik A, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P54
   Al-Rfou Rami, 2015, P 2015 SIAM INT C DA, V0, PP586, DOI 10.1137/1.9781611974010.66
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], 2016, P 13 C NATURAL LANGU, V0, P0
   Bogers T, 2016, C LABS EVALUATION FO, V0, P1053
   Bunescu Razvan C, 2007, ANN M ASS COMPUTATIO, V45, P576
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/TACL_A_00104
   Choi E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P87
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   de Boer Victor, 2012, THE SEMANTIC WEB: RESEARCH AND APPLICATIONS. PROCEEDINGS 9TH EXTENDED SEMANTIC WEB CONFERENCE (ESWC 2012), V0, PP733, DOI 10.1007/978-3-642-30284-8_56
   Deleger Louise, 2016, P 4 BIONLP SHAR TASK, V0, PP12, DOI 10.18653/V1/W16-3002
   Devlin J, 2019, P 2019 C N AM ASS CO, V1, P4171
   Dijkshoorn C, 2018, SEMANT WEB, V9, P221, DOI 10.3233/SW-170257
   Dong L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1243
   Dong XL, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP601, DOI 10.1145/2623330.2623623
   Fleiss J, 1971, PSYCHOL BULL, V76, P378
   Freire Nuno, 2012, THE SEMANTIC WEB: RESEARCH AND APPLICATIONS. PROCEEDINGS 9TH EXTENDED SEMANTIC WEB CONFERENCE (ESWC 2012), V0, PP718, DOI 10.1007/978-3-642-30284-8_55
   Ghaddar A, 2018, P 11 INT C LANGUAGE, V0, P0
   Ghaddar Abbas, 2017, P 8 INT JOINT C NAT, V1, P413
   Gillick D, 2014, ARXIV, V0, P0
   Gillick Dan, 2016, P 2016 C N AM CHAPT, V0, PP1296, DOI 10.18653/V1/N16-1155
   Harpring P, 2010, ART DOC, V29, P67, DOI 10.1086/adx.29.1.27949541
   Hearst M, 1992, COLING 1992 VOLUME 2, V0, P539
   Hirschman L, 2005, BMC BIOINFORMATICS, V6, P0, DOI 10.1186/1471-2105-6-S1-S1
   Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001
   Huang Zhiheng, 2015, ARXIV, V0, P0
   Hyvönen E, 2005, J WEB SEMANT, V3, P224, DOI 10.1016/j.websem.2005.05.008
   Jain N, 2019, LECT NOTES COMPUT SC, V11799, P115, DOI 10.1007/978-3-030-30760-8_10
   Kettunen K, 2017, P 2 INT C DIG ACC TE, V0, PP181, DOI 10.1145/3078081.3078084
   Kim J-D, 2004, P INT JOINT WORKSH N, V0, PP70, DOI 10.3115/1567594.1567610
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Knox C, 2011, NUCLEIC ACIDS RES, V39, PD1035, DOI 10.1093/nar/gkq1126
   Koch M, 2014, P C EMPIRICAL METHOD, V0, P1891
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Krallinger M, 2015, J CHEMINFORMATICS, V7, P0, DOI 10.1186/1758-2946-7-S1-S2
   KRIPPENDK, 1970, EDUC PSYCHOL MEAS, V30, P61, DOI 10.1177/001316447003000105
   Kuru O, 2016, P COLING 2016 26 INT, V0, P911
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS
   Li YY, 2005, LECT NOTES ARTIF INT, V3635, P319
   Lin T, 2012, P 2012 JOINT C EMP M, V0, P893
   Ling Xiao, 2012, P 26 AAAI C ARTIFICI, V0, P0
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Malouf R, 2002, P 6 C NATURAL LANGUA, V0, P0
   Meroño-Peñuela A, 2015, SEMANT WEB, V6, P539, DOI 10.3233/SW-140158
   Mintz M, 2009, P JOINT C 47 ANN M A, V0, PP1003, DOI 10.3115/1690219.1690287
   Nothman J, 2008, LEARNING NAMED ENTIT, V0, P0
   Nothman J, 2008, THESIS U SYDNEY AUST, V0, P0
   Nothman J, 2013, ARTIF INTELL, V194, P151, DOI 10.1016/j.artint.2012.03.006
   Ollagnier A, 2016, CLEF WORKING NOTES, V0, P1064
   Oomen J, 2012, MUSEUMS WEB 2012, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Poibeau T, 2001, LANG COMPUT, V0, P144
   Pradhan Sameer, 2013, P 17 C COMPUTATIONAL, V0, P143
   Prokofyev R, 2014, WWW14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP397, DOI 10.1145/2566486.2568013
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Ratner A, 2017, PROC VLDB ENDOW, V11, P269, DOI 10.14778/3157794.3157797
   Rodriquez Kepa Joseba, 2012, P KONFERENZ VERARBEI, V0, P410
   Saleh B, 2016, INT J DIGITAL ART HI, V0, P0, DOI DOI 10.11588/dah.2016.2.23376
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Segers R, 2011, P 6 INT C KNOWLEDGE, V0, P26
   Shao Y, 2016, 6 SWEDISH LANGUAGE T, V0, P0
   Socher Richard, 2012, TUTORIAL ABSTRACTS A, V0, P5
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Sun C, 2017, IEEE I CONF COMP VIS, V0, PP843, DOI 10.1109/ICCV.2017.97
   Szekely Pedro, 2013, SEMANTIC WEB: SEMANTICS AND BIG DATA. PROCEEDINGS OF 10TH INTERNATIONAL CONFERENCE (ESWC 2013): LNCS 7882, V0, P593
   Tjong Kim Sang EF, 2002, COLING 02 6 C NATURA, V0, P0
   Tsai C-T, 2016, P 20 SIGNLL C COMP N, V0, P0, DOI DOI 10.18653/V1/K16-1022
   Türker R, 2020, LECT NOTES COMPUT SC, V12506, P584, DOI 10.1007/978-3-030-62419-4_33
   Uzuner Ö, 2007, J AM MED INFORM ASSN, V14, P550, DOI 10.1197/jamia.M2444
   Van Hooland S, 2014, LINKED DATA LIB ARCH, V0, P0
   van Hooland S, 2015, DIGIT SCHOLARSH HUM, V30, P262, DOI 10.1093/llc/fqt067
   Varma P, 2018, PROC VLDB ENDOW, V12, P223, DOI 10.14778/3291264.3291268
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Yadav V, 2018, P 27 INT C COMP LING, V0, P2145
   Yadav Vikas, 2018, P 7 JOINT C LEX COMP, V0, P167
   Yosef MA, 2012, COLING 2012 24 INT C, V0, P1361
   Zhou GD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P473
NR 81
TC 0
Z9 0
U1 1
U2 6
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1570-0844
EI 2210-4968
J9 SEMANT WEB
JI Semant. Web
PD JUN 15
PY 2023
VL 14
IS 2
BP 239
EP 260
DI 10.3233/SW-223177
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 7H7XM
UT WOS:000903411900006
DA 2023-11-10
ER

PT J
AU Yuan, ZC
   Ma, ZM
AF Yuan, Zhongchen
   Ma, Zongmin
TI Supervised Classification of UML Class Diagrams Based on F-KNB
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE Software reuse; software design; UML class diagram; classification; similarity; features; classifier
ID feature-selection; reuse; retrieval; svm
AB Often most software development doesn't start from scratch but applies previously developed artifacts. These reusable artifacts are involved in various phases of the software life cycle, ranging from requirements to maintenance. Software design as the high level of software development process has an important impact on the following stages, so its reuse is gaining more and more attention. Unified modeling language (UML) class diagram as a modeling tool has become a de facto standard of software design, and thus its reuse also becomes a concern accordingly. So far, the related research on the reuse of UML class diagrams has focused on matching and retrieval. As a large number of class diagrams enter the repository for reuse, classification has become an essential task. The classification is divided into unsupervised classification (also known as clustering) and supervised classification. In our previous work, we discussed the clustering of UML class diagrams. In this paper, we focus on only the supervised classification of UML class diagrams and propose a supervised classification method. A novel ensemble classifier F-KNB combining both dependent and independent construction ideas is built. The similarity of class diagrams is described, in which the semantic, structural and hybrid matching is defined, respectively. The extracted feature elements are used in base classifiers F-KNN and F-NBs that are constructed based on improved K-nearest neighbors (KNNs) and Naive Bayes (NB), respectively. A series of experimental results show that the proposed ensemble classifier F-KNB shows a good classification quality and efficiency under the condition of variable size and distribution of training samples.
C1 [Yuan, Zhongchen] Shenyang Univ Technol, Sch Chem Proc Automat, Liaoyang 111004, Peoples R China.
   [Ma, Zongmin] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
C3 Shenyang University of Technology; Nanjing University of Aeronautics & Astronautics
RP Yuan, ZC (通讯作者)，Shenyang Univ Technol, Sch Chem Proc Automat, Liaoyang 111004, Peoples R China.
EM yuanzhongchen@163.com
FU National Nature Science Foundation of China [61772269, 62176121]; Basic Research Project Foundation of the Education Department of Liaoning Province, China [LJKZ0165]
CR ADAMU A, 2016, INDIAN J SCI TECHNOL, V9, PNIL68, DOI 10.17485/ijst/2016/v9i46/106918
   Adjandra W, 2021, P 2021 INT C COMP SC, V0, P1
   Agarwal R, 2003, COMMUN ACM, V46, P248, DOI 10.1145/903893.903944
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, V0, P457
   Ahmmed R, 2018, ADV SCI TECHNOL ENG, V3, P40
   Al-Baity AA, 2013, PROC INT C SOFTWARE, V0, P1
   Al-Khiaty Mojeeb Al-Rhman, 2016, LECTURE NOTES ON SOFTWARE ENGINEERING, V4, P41, DOI 10.7763/LNSE.2016.V4.221
   Al-Khiaty MA, 2017, PROCEEDINGS OF THE 2017 12TH INTERNATIONAL SCIENTIFIC AND TECHNICAL CONFERENCE ON COMPUTER SCIENCES AND INFORMATION TECHNOLOGIES (CSIT 2017), VOL. 1, P161, DOI 10.1109/STC-CSIT.2017.8098759
   Ali FM, 2004, INFORM SOFTWARE TECH, V46, P499, DOI 10.1016/S0950-5849(03)00089-2
   Almeida, 2019, HDB SOFTWARE ENG, V0, P321
   Anas O, 2021, INT J ELECTR COMPUT, V11, P1578
   [Anonymous], 2000, PROC VISION INTERFAC, V0, P0
   Barros-Justo JL, 2019, COMPUT STAND INTER, V66, P0, DOI 10.1016/j.csi.2019.04.011
   Basu JK, 2010, INT J SOFTWARE ENG A, V4, P23, DOI 10.48550/ARXIV.1705.05690
   Belgiu M, 2014, REMOTE SENS-BASEL, V6, P1347, DOI 10.3390/rs6021347
   Capilla R, 2019, J SOFTW EVOL PROCESS, V31, P2221
   Devi RG, 2015, PRACTICAL MANUAL PHY, V0, P1
   Fauzan Reza, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, V0, P215, DOI 10.1109/ICITISEE.2018.8721021
   Ferdousy EZ, 2013, COMPUT INF SCI, V6, P48, DOI 10.5539/cis.v6n3p48
   Frakes WB, 2005, IEEE T SOFTWARE ENG, V31, P529, DOI 10.1109/TSE.2005.85
   Gomes P, 2004, AI COMMUN, V17, P13
   Gomes P, 2006, LECT NOTES ARTIF INT, V4248, P381
   Guan D, 2014, IETE TECH REV, V31, P190, DOI 10.1080/02564602.2014.906859
   Harrington P, 2012, MACHINE LEARNING ACT, V0, P0
   Hossin M, 2015, INT J DATA MINING KN, V5, P1, DOI 10.5121/ijdkp.2015.5201
   Hussain J, 2016, INT J COMPUT INT SYS, V9, P863, DOI 10.1080/18756891.2016.1237186
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   KRUEGER CW, 1992, COMPUT SURV, V24, P131, DOI 10.1145/130844.130856
   Kulkarni RN, 2021, INTERNATIONAL JOURNAL OF ADVANCED NETWORKING AND APPLICATIONS, V12, P4644
   Kyriakou H, 2017, MIS QUART, V41, P315, DOI 10.25300/MISQ/2017/41.1.17
   Lewis WD, 2001, COYOTE PAPERS WORKIN, V0, P0
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, V0, PP1, DOI 10.1007/978-1-4419-9326-7
   Ma ZM, 2021, INFORM SOFTWARE TECH, V130, P0, DOI 10.1016/j.infsof.2020.106456
   Malakoff D, 1999, SCIENCE, V286, P1461, DOI 10.1126/science.286.5444.1461
   Marianingsih S, 2019, INT J ADV SOFT COMPU, V11, P15
   Medvidovic N, 2002, ACM T SOFTW ENG METH, V11, P2, DOI 10.1145/504087.504088
   Meng L, 2013, INT J HYBRID INF TEC, V6, P1
   Miller GA, 1998, WORDNET ELECT LEXICA, V0, P0
   More AS, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), V0, PP72, DOI 10.1109/ICISIM.2017.8122151
   Munawaroh H, 2020, P 2020 2 INT C CYB I, V0, P1
   Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9
   Nikiforova O, 2015, P 10 INT C SOFTW ENG, V0, P147
   Olaode A, 2014, INT J IMAGE PROCESSI, V8, P325
   Otto Lena, 2020, STUD HEALTH TECHNOL INFORM, V268, P113, DOI 10.3233/SHTI200010
   Patil RN, 2018, INTERNATIONAL JOURNA, V3, P1371
   Pise N, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), V0, PP203, DOI 10.1109/SAI.2016.7555983
   Rish I, 2001, IN IJCAI 2001 WORKSH, V3, P41, DOI 10.1214/088342306000000060
   Robles K, 2012, INFORM SOFTWARE TECH, V54, P72, DOI 10.1016/j.infsof.2011.07.003
   Sadowski C, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, V0, PP191, DOI 10.1145/2786805.2786855
   Salami HO, 2014, INT JOINT CONF COMP, V0, PP324, DOI 10.1109/JCSSE.2014.6841889
   Sathya R, 2013, INTERNATIONAL JOURNAL OF ADVANCED RESEARCH IN ARTIFICIAL INTELLIGENCE, V2, P34
   Song MH, 2005, 12TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, V0, P645
   Soofi AA, 2017, J BASIC APPL SCI, V13, P459, DOI 10.6000/1927-5129.2017.13.76
   Taghva K, 2003, P INT C INF TECHN CO, V0, P0
   Thiagarajan R, 2008, HPL200887, V0, P0
   Vens C, 2008, MACH LEARN, V73, P185, DOI 10.1007/s10994-008-5077-3
   Wang D, 2018, 2018 INT JOINT C NEU, V0, PP1, DOI 10.1109/IJCNN.2018.8489530
   West Douglas Brent, 1996, INTRO GRAPH THEORY, V2, P0
   Xiao JL, 2019, PHYSICA A, V517, P29, DOI 10.1016/j.physa.2018.10.060
   Yuan ZC, 2020, REQUIR ENG, V25, P213, DOI 10.1007/s00766-019-00317-w
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2009, INFORM SCIENCES, V179, P3218, DOI 10.1016/j.ins.2009.06.010
   Zhang ML, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, VOLS 1 AND 2, P718
   Zhang W, 2010, KNOWL-BASED SYST, V23, P379, DOI 10.1016/j.knosys.2010.01.011
   Zhang X, 2012, P INT C TRUSTW COMP, V0, P506
NR 65
TC 0
Z9 0
U1 1
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD AUG 15
PY 2023
VL 33
IS 08
BP 1169
EP 1210
DI 10.1142/S0218194023500286
EA JUL 2023
PG 42
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA P1QD1
UT WOS:001026818700001
DA 2023-11-10
ER

PT J
AU Naous, T
   Bassyouni, Z
   Mousi, B
   Hajj, H
   El Hajj, W
   Shaban, K
AF Naous, Tarek
   Bassyouni, Zahraa
   Mousi, Bassel
   Hajj, Hazem
   El Hajj, Wassim
   Shaban, Khaled
TI Open-Domain Response Generation in Low-Resource Settings using Self-Supervised Pre-Training of Warm-Started Transformers
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Response generation; Arabic dialect; language models
AB Learning response generation models constitute the main component of building open-domain dialogue systems. However, training open-domain response generation models requires large amounts of labeled data and pre-trained language generation models that are often nonexistent for low-resource languages. In this article, we propose a framework for training open-domain response generation models in low-resource settings. We consider Dialectal Arabic (DA) as a working example. The framework starts by warm-starting a transformer-based encoder-decoder with pre-trained language model parameters. Next, the resultant encoder-decoder model is adapted to DA by employing self-supervised pre-training on large-scale unlabeled data in the desired dialect. Finally, the model is fine-tuned on a very small labeled dataset for open-domain response generation. The results show significant performance improvements on three spoken Arabic dialects after adopting the framework's three stages, highlighted by higher BLEU and lower Perplexity scores compared with multiple baseline models. Specifically, our models are capable of generating fluent responses in multiple dialects with an average human-evaluated fluency score above 4. Our data is made publicly available.
C1 [Naous, Tarek] Amer Univ Beirut, 351 Ferst Dr NW, Atlanta, GA 30332 USA.
   [Bassyouni, Zahraa; Mousi, Bassel; Hajj, Hazem; El Hajj, Wassim] Amer Univ Beirut, Bliss St,POB 11-0236, Beirut, Lebanon.
   [Naous, Tarek; Shaban, Khaled] Qatar Univ, Univ St POB, Doha 2713, Qatar.
C3 American University of Beirut; Qatar University
RP Naous, T (通讯作者)，Amer Univ Beirut, 351 Ferst Dr NW, Atlanta, GA 30332 USA.; Naous, T (通讯作者)，Qatar Univ, Univ St POB, Doha 2713, Qatar.
EM tnn11@aub.edu.lb
FU Qatar National Research Fund (Qatar Foundation) [NPRP13S-0112-200037]
CR Abdelali A, 2016, P 2016 C N AM CHAPT, V0, PP11, DOI 10.18653/v1/N16
   Abdul-Mageed M, 2020, P 5 ARABIC NATURAL L, V0, P97
   Abdul-Mageed M, 2021, ARXIV, V0, P0
   Abdul-Mageed M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5855
   Abu Ali D, 2016, P COLING 2016 26 INT, V0, P208
   Adiwardana D, 2020, ARXIV, V0, P0
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Bahdanau D, 2016, ARXIV, V0, P0
   Basu Sourya, 2020, P INT C LEARNING REP, V0, P0
   Bouamor H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), V0, P199
   Dinan Emily, 2018, P INT C LEARNING REP, V0, P0
   Eskander R, 2013, P 2013 C N AM CHAPT, V0, P585
   Fadhil Ahmed, 2019, P INT C REC ADV NAT, V0, P295
   Hedderich MA, 2021, ARXIV, V0, P0
   Higashinaka R, 2014, PROC INT C COMPUTATI, V0, P928
   Huang ML, 2020, ACM T INFORM SYST, V38, P0, DOI 10.1145/3383123
   Ippolito Daphne, 2018, P 57 C ASS COMPUTATI, V0, P0
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li Yanran, 2017, IJCNLP, V0, P0
   Lin ZJ, 2020, AAAI CONF ARTIF INTE, V34, P13622
   Mao ZY, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3491065
   Murthy R, 2019, ACM T ASIAN LOW-RESO, V18, P0, DOI 10.1145/3238797
   Naous T, 2020, P 5 ARABIC NATURAL L, V0, P58
   Naous T, 2021, P 6 ARABIC NATURAL L, V0, P164
   Otegi A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P436
   Ranasinghe T, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3457610
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5370
   Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P300
   Roller S, 2020, ARXIV, V0, P0
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI 10.1162/tacl_a_.00313
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xiang L, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3457571
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Yang Z, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1886
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
   Zhong PX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6556
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI 10.1162/COLI_a_00368
NR 40
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR 15
PY 2023
VL 22
IS 4
BP 
EP 
DI 10.1145/3579164
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FI3
UT WOS:000998929700005
DA 2023-11-10
ER

PT J
AU Zahir, J
AF Zahir, Jihad
TI Prediction of court decision from Arabic documents using deep learning
SO EXPERT SYSTEMS
LA English
DT Article
DE AI in law; case outcome prediction; deep learning; natural language processing; predictive justice; text mining
ID outcm
AB The increasing amount of electronic legal documents represents a great opportunity for the development of intelligent computational systems for legal texts processing and classification. Most of these systems use classical machine learning and large datasets in English. This paper proposes an approach to automatically predict legal case outcome from written description of the events in Arabic using deep learning. An in-house corpus from the decisions of the Moroccan Court of Cassation is built and used to train a deep learning model that predicts judgement. As the created corpus is of limited size, a new data augmentation method is proposed to boost the prediction performance. Two settings for text representation are tested, namely FastText and GloVe embeddings, and multiple deep learning models architectures are tested. The proposed approach succeeds in predicting judicial decisions of the Moroccan Court of Cassation with an accuracy of 80.51% on six classes. Even with a small dataset, the proposed data augmentation method was helpful in improving the overall models' performance. Despite the advancement in the area of legal judgement prediction over the years, this work is the first attempt to predict legal outcome using the documents of the Moroccan Cassation court. The corpus created in the context of this work will be made publicly available to the community.
C1 [Zahir, Jihad] Cadi Ayyad Univ, Fac Sci Semlalia, LISI Lab, Marrakech, Morocco.
C3 Cadi Ayyad University of Marrakech
RP Zahir, J (通讯作者)，Cadi Ayyad Univ, Fac Sci Semlalia, LISI Lab, Marrakech, Morocco.
EM j.zahir@uca.ac.ma
CR Aissa H, 2021, PROCEDIA COMPUT SCI, V184, P829, DOI 10.1016/j.procs.2021.03.103
   Aletras N, 2016, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.93
   Berrazega I, 2016, ADV INTELL SYST, V464, P415, DOI 10.1007/978-3-319-33625-1_37
   Bertalan VGF, 2020, DHANDNLP PROPOR, V0, P22
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bouhyaoui Nasria, 2018, INTERNATIONAL JOURNAL OF METADATA, V0, P0
   Branting LK, 2017, 3 WORKSHOP AUTOMATED, V0, P0
   Do P-K, 2017, PREPRINT, V0, P0
   Frolova Evgenia E, 2022, SMART TECHNOLOGIES FOR THE DIGITISATION OF INDUSTRY: ENTREPRENEURIAL ENVIRONMENT. SMART INNOVATION, V0, P17, DOI 10.1007/978-981-16-4621-8_2
   GELBART D, 1991, THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE & LAW, V0, PP225, DOI 10.1145/112646.112674
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3483
   Haidar A, 2022, INFOMAT, V26, P1103
   Hassan FU, 2020, J LEG AFF DISPUTE RE, V12, P0, DOI 10.1061/(ASCE)LA.1943-4170.0000379
   Ilkou E, 2020, P CIKM WORKSH, V0, P1
   Kim Y, 2014, INT CONF ACOUST SPEE, V0, P0
   Lage-Freitas A, 2022, PEERJ COMPUT SCI, V8, P0, DOI 10.7717/peerj-cs.904
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Li GD, 2019, IEEE ACCESS, V7, P139616, DOI 10.1109/ACCESS.2019.2943668
   Lima Gabriel, 2022, FACCT 22: 2022 ACM CONFERENCE ON FAIRNESS, V0, P0
   Liu YH, 2018, J INF SCI, V44, P594, DOI 10.1177/0165551517722741
   Liu ZY, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), V0, P2968
   Luo B, 2017, PREPRINT, V0, P0
   de Araujo PHL, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P1449
   Medvedeva M, 2020, ARTIF INTELL LAW, V28, P237, DOI 10.1007/s10506-019-09255-y
   Metsker O, 2019, PROCEDIA COMPUT SCI, V156, P264, DOI 10.1016/j.procs.2019.08.202
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Morimoto A, 2017, EPIC SERIES COMPUTIN, V2017, P79, DOI 10.29007/4L2Q
   Mumcuoglu E, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102684
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Polsley S, 2016, PROC INT C COMPUTATI, V0, P258
   Sert MF, 2021, SOC SCI COMPUT REV, V08944393211010398, P1416
   Shaikh RA, 2020, PROCEDIA COMPUT SCI, V167, P2393, DOI 10.1016/j.procs.2020.03.292
   Sulea O-M, 2017, PREPRINT, V0, P0
   Surden H, 2022, IEEE TECHNOL SOC MAG, V41, P66, DOI 10.1109/MTS.2022.3147542
   Taniguchi R, 2018, JSAI INT S ARTIFICIA, V0, P193
NR 37
TC 0
Z9 0
U1 5
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JUL 15
PY 2023
VL 40
IS 6
BP 
EP 
DI 10.1111/exsy.13236
EA FEB 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA I1QT5
UT WOS:000931573900001
DA 2023-11-10
ER

PT J
AU Sharma, A
   Lin, IW
   Miner, AS
   Atkins, DC
   Althoff, T
AF Sharma, Ashish
   Lin, Inna W.
   Miner, Adam S.
   Atkins, David C.
   Althoff, Tim
TI Human-AI collaboration enables more empathic conversations in text-based peer-to-peer mental health support
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID psychotherapy-research; challenges; prediction; suicide; burden; media
AB Advances in artificial intelligence (AI) are enabling systems that augment and collaborate with humans to perform simple, mechanistic tasks such as scheduling meetings and grammar-checking text. However, such human-AI collaboration poses challenges for more complex tasks, such as carrying out empathic conversations, due to the difficulties that AI systems face in navigating complex human emotions and the open-ended nature of these tasks. Here we focus on peer-to-peer mental health support, a setting in which empathy is critical for success, and examine how AI can collaborate with humans to facilitate peer empathy during textual, online supportive conversations. We develop HAILEY, an AI-in-the-loop agent that provides just-in-time feedback to help participants who provide support (peer supporters) respond more empathically to those seeking help (support seekers). We evaluate HAILEY in a non-clinical randomized controlled trial with real-world peer supporters on TalkLife (N = 300), a large online peer-to-peer support platform. We show that our human-AI collaboration approach leads to a 19.6% increase in conversational empathy between peers overall. Furthermore, we find a larger, 38.9% increase in empathy within the subsample of peer supporters who self-identify as experiencing difficulty providing support. We systematically analyse the human-AI collaboration patterns and find that peer supporters are able to use the AI feedback both directly and indirectly without becoming overly reliant on AI while reporting improved self-efficacy post-feedback. Our findings demonstrate the potential of feedback-driven, AI-in-the-loop writing systems to empower humans in open-ended, social and high-stakes tasks such as empathic conversations. AI language modelling and generation approaches have developed fast in the last decade, opening promising new directions in human-AI collaboration. An AI-in-the loop conversational system called HAILEY is developed to empower peer supporters in providing empathic responses to mental health support seekers.
C1 [Sharma, Ashish; Lin, Inna W.; Althoff, Tim] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
   [Miner, Adam S.] Stanford Univ, Dept Psychiat & Behav Sci, Stanford, CA USA.
   [Miner, Adam S.] Stanford Univ, Ctr Biomed Informat Res, Stanford, CA USA.
   [Atkins, David C.] Univ Washington, Dept Psychiat & Behav Sci, Seattle, WA USA.
C3 University of Washington; University of Washington Seattle; Stanford University; Stanford University; University of Washington; University of Washington Seattle
RP Althoff, T (通讯作者)，Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
EM althoff@cs.washington.edu
FU NSF [CNS-2025022, IIS-1901386]; NSF CAREER [IIS-2142794]; NIH [K02 AA023814, R01MH125179]; Bill & Melinda Gates Foundation [INV-004841]; Office of Naval Research [N00014-21-1-2154]; Microsoft AI for Accessibility grant; Garvey Institute Innovation grant; National Institutes of Health, National Center for Advancing Translational Science, Clinical and Translational Science Award [KL2TR001083, UL1TR001085]; Stanford Human-Centered AI Institute; Bill and Melinda Gates Foundation [INV-004841] Funding Source: Bill and Melinda Gates Foundation
CR Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290605.3300233
   [Anonymous], 2022, WIKIPEDIA, V0, P0
   Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754
   Bansal Gagan, 2021, CHI 21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3411764.3445717
   BARRETTLENNARD GT, 1981, J COUNS PSYCHOL, V28, P91, DOI 10.1037/0022-0167.28.2.91
   Blease C, 2020, DIGIT HEALTH, V6, P0, DOI 10.1177/2055207620968355
   Bohart AC, 2002, PSYCHOTHERAPY RELATI, V452, P89
   Bolukbasi T, 2016, ADV NEUR IN, V29, P0
   Buschek D, 2021, CHI 21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3411764.3445372
   Cai Carrie J, 2019, PROCEEDINGS OF THE ACM ON HUMAN-COMPUTER INTERACTION, V3, P0, DOI 10.1145/3359206
   Cauce AM, 2002, J CONSULT CLIN PSYCH, V70, P44, DOI 10.1037//0022-006X.70.1.44
   Chen JH, 2017, NEW ENGL J MED, V376, P2507, DOI 10.1056/NEJMp1702071
   Chilton LB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290605.3300402
   Clark E, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP329, DOI 10.1145/3172944.3172983
   Collings S, 2012, CRISIS, V33, P1, DOI 10.1027/0227-5910/a000141
   Collins PY, 2011, NATURE, V475, P27, DOI 10.1038/475027a
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Daws R, 2020, NEWS, V0, P0
   De Choudhury M, 2017, CSCW17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, V0, PP353, DOI 10.1145/2998181.2998220
   Doraiswamy PM, 2020, ARTIF INTELL MED, V102, P0, DOI 10.1016/j.artmed.2019.101753
   Elliott R, 2018, PSYCHOTHERAPY, V55, P399, DOI 10.1037/pst0000175
   Elliott R, 2011, PSYCHOTHERAPY, V48, P43, DOI 10.1037/a0022187
   Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, V0, P1002, DOI 10.1145/3532106.3533533
   Gillies M, 2016, CHI C EXTENDED ABSTR, V0, PP3558, DOI 10.1145/2851581.2856492
   Goldberg SB, 2016, J COUNS PSYCHOL, V63, P1, DOI 10.1037/cou0000131
   Hernandez-Boussard T, 2020, J AM MED INFORM ASSN, V27, P2011, DOI 10.1093/jamia/ocaa088
   Hirsch T, 2017, DIS17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, V0, PP95, DOI 10.1145/3064663.3064703
   Hojat M, 2009, ACAD MED, V84, P1182, DOI 10.1097/ACM.0b013e3181b17e55
   Hosny A, 2019, SCIENCE, V366, P955, DOI 10.1126/science.aay5189
   Hui JS, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), V0, P0, DOI DOI 10.1145/3173574.3173596
   Imel ZE, 2015, PSYCHOTHERAPY, V52, P19, DOI 10.1037/a0036841
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kaplan B H, 1977, MED CARE, V15, P47, DOI 10.1097/00005650-197705001-00006
   Kazdin AE, 2011, PERSPECT PSYCHOL SCI, V6, P21, DOI 10.1177/1745691610393527
   Kelly Ryan, 2018, PROCEEDINGS OF THE ACM ON HUMAN-COMPUTER INTERACTION, V2, P0, DOI 10.1145/3274356
   Kemp V, 2012, PSYCHIATR REHABIL J, V35, P337, DOI 10.2975/35.4.2012.337.340
   Lee ELE, 2021, BIOL PSYCHIAT-COGN N, V6, P856, DOI 10.1016/j.bpsc.2021.02.001
   Lee F-T, 2019, P 6 WORKSH COMP LING, V0, P12
   Lee K, 2019, P C N AM CHAPT ASS C, V0, PP4171, DOI 10.18653/V1/N19-1423
   Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 22), V0, P0, DOI DOI 10.1145/3491102.3502030
   Li J, 2016, DIVERSITY PROMOTING, V0, P0
   Li RC, 2020, NPJ DIGIT MED, V3, P0, DOI 10.1038/s41746-020-00318-y
   Lin ZJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P121
   Luxton DD, 2012, AM J PUBLIC HEALTH, V102, PS195, DOI 10.2105/AJPH.2011.300608
   Mahlke CI, 2014, CURR OPIN PSYCHIATR, V27, P276, DOI 10.1097/YCO.0000000000000074
   Majumder N, 2022, IEEE ACCESS, V10, P77176, DOI 10.1109/ACCESS.2022.3193159
   Majumder N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8968
   Martinez-Martin N, 2018, JMIR MENT HEALTH, V5, P0, DOI 10.2196/mental.9423
   Miner AS, 2019, FRONT PSYCHIATRY, V10, P0, DOI 10.3389/fpsyt.2019.00746
   Naslund JA, 2016, EPIDEMIOL PSYCH SCI, V25, P113, DOI 10.1017/S2045796015001067
   NORMAN DA, 1994, COMMUN ACM, V37, P68, DOI 10.1145/176789.176796
   Nunes P, 2011, INT J MED EDUC, V2, P12, DOI 10.5116/ijme.4d47.ddb0
   Olfson M, 2016, HEALTH AFFAIR, V35, P983, DOI 10.1377/hlthaff.2015.1619
   Paraphrasing tool, 2022, QUILLBOT, V0, P0
   Patel BN, 2019, NPJ DIGIT MED, V2, P0, DOI 10.1038/s41746-019-0189-7
   Peng Z, 2020, CHI C HUMAN FACTORS, V0, P1
   Qian Yang, 2020, CHI 20: PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3313831.3376301
   Radford A, 2022, LANGUAGE MODELS ARE, V0, P0
   Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5370
   Rathod S, 2017, HEALTH SERV INSIGHTS, V10, P1, DOI 10.1177/1178632917694350
   Richardson JP, 2021, NPJ DIGIT MED, V4, P0, DOI 10.1038/s41746-021-00509-1
   Riess Helen, 2017, J PATIENT EXP, V4, P74, DOI 10.1177/2374373517699267
   Roemmele M, 2018, COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI18), V0, P0, DOI DOI 10.1145/3180308.3180329
   Schwalbe CS, 2014, ADDICTION, V109, P1287, DOI 10.1111/add.12558
   Sharma A, 2022, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.7061732
   Sharma A, 2022, BEHAV DATA PARTNER C, V0, P0, DOI DOI 10.5281/ZENODO.7053967
   Sharma Ashish, 2022, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.7295902
   Sharma A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5263
   Sharma A, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), V0, PP194, DOI 10.1145/3442381.3450097
   Stebnicki MA, 2007, AM J PSYCHIATR REHAB, V10, P317, DOI 10.1080/15487760701680570
   Suh M, 2021, CHI 21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3411764.3445219
   Tanana M, 2016, J SUBST ABUSE TREAT, V65, P43, DOI 10.1016/j.jsat.2016.01.006
   Tanana MJ, 2019, J MED INTERNET RES, V21, P0, DOI 10.2196/12529
   Tschandl P, 2020, NAT MED, V26, P1229, DOI 10.1038/s41591-020-0942-0
   United States Department of Health and Human Services, 2001, MENT HLTH CULT RAC E, V0, P0
   Vaidyam AN, 2021, CAN J PSYCHIAT, V66, P339, DOI 10.1177/0706743720966429
   Verghese A, 2018, JAMA-J AM MED ASSOC, V319, P19, DOI 10.1001/jama.2017.19198
   Wambsganss T, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4063
   Watson JC, 2002, CLIENT CTR EXPT PSYC, V0, P0
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   Wolf MJ, 2017, ACM SIGCAS COMPUTERS AND SOCIETY, V47, P54, DOI 10.1145/3144592.3144598
   World Health Organization, 2022, MENT DIS, V0, P0
   Zheng C, 2021, FINDINGS ASS COMPUTA, V0, PP813, DOI 10.18653/V1/2021.FINDINGS-ACL.72
NR 84
TC 13
Z9 13
U1 41
U2 58
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD JAN 15
PY 2023
VL 5
IS 1
BP 46
EP 57
DI 10.1038/s42256-022-00593-2
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 8G0YR
UT WOS:000920078200008
DA 2023-11-10
ER

PT J
AU Mehmood, F
   Shahzadi, R
   Ghafoor, H
   Asim, MN
   Ghani, MU
   Mahmood, W
   Dengel, A
AF Mehmood, Faiza
   Shahzadi, Rehab
   Ghafoor, Hina
   Asim, Muhammad Nabeel
   Ghani, Muhammad Usman
   Mahmood, Waqar
   Dengel, Andreas
TI EnML: Multi-label Ensemble Learning for Urdu Text Classification
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Multi-label Urdu text classification; multi-label Urdu news dataset; traditional machine learning; deep learning; language models; multi-label ensemble learning; data transformation methods
ID ranking; algorithm
AB Exponential growth of electronic data requires advanced multi-label classification approaches for the development of natural language processing (NLP) applications such as recommendation systems, drug reaction detection, hate speech detection, and opinion recognition/mining. To date, several machine and deep learning-based multi-label classification methodologies have been proposed for English, French, German, Chinese, Arabic, and other developed languages. Urdu is the 11th largest language in the world and has no computer-aided multi-label textual news classification approach. Unlike other languages, Urdu is lacking multi-label text classification datasets that can be used to benchmark the performance of existing machine and deep learning methodologies. With an aim to accelerate and expedite research for the development of Urdu multi-label text classification-based applications, this article provides multiple contributions as follows: First, it provides a manually annotated multi-label textual news classification dataset for the Urdu language. Second, it benchmarks the performance of traditional machine learning approaches particularly by adapting three data transformation approaches along with three top-performing machine learning classifiers and four algorithm adaptation-based approaches. Third, it benchmarks performance of 16 existing deep learning approaches and the four most widely used language models. Finally, it provides an ensemble approach that reaps the benefits of three different deep learning architectures to precisely predict different classes associated with a particular Urdu textual document. Experimental results reveal that proposed ensemble approach performance values (87% accuracy, 92% F1-score, and 8% hamming loss) are significantly higher than adapted machine and deep learning-based approaches.
C1 [Mehmood, Faiza; Shahzadi, Rehab; Ghafoor, Hina; Mahmood, Waqar] Univ Engn & Technol, Al Khawarizmi Inst Comp Sci KICS, Lahore, Pakistan.
   [Mehmood, Faiza; Ghani, Muhammad Usman] Univ Engn & Technol, Dept Comp Sci, Faisalabad Campus, Lahore, Pakistan.
   [Ghafoor, Hina; Asim, Muhammad Nabeel; Dengel, Andreas] German Res Ctr Artificial Intelligence DFKI, D-67663 Kaiserslautern, Germany.
   [Ghafoor, Hina; Dengel, Andreas] Rheinland Pfalz Tech Univ, Dept Comp Sci, D-67663 Kaiserslautern, Germany.
C3 University of Engineering & Technology Lahore; University of Engineering & Technology Lahore; German Research Center for Artificial Intelligence (DFKI)
RP Asim, MN (通讯作者)，German Res Ctr Artificial Intelligence DFKI, D-67663 Kaiserslautern, Germany.
EM faiza.mehmood@kics.edu.pk; rehab.shahzadi@kics.edu.pk; hina.ghafoor@kics.edu.pk; nabeel.asim@dfki.de; usman.ghani@kics.edu.pk; director@kics.edu.pk; andreas.dengel@dfki.de
FU Higher Education Commission Pakistan [NRPU-20-16560]
CR Abbasi A, 2022, SCI REP-UK, V12, P0, DOI 10.1038/s41598-022-22523-3
   Ahmed Kashif, 2016, J APPL COMPUT SCI MA, V21, P17
   Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   Al-Salemi B, 2019, INFORM PROCESS MANAG, V56, P212, DOI 10.1016/j.ipm.2018.09.008
   Al-Salemi B, 2016, KNOWL-BASED SYST, V103, P104, DOI 10.1016/j.knosys.2016.03.029
   Albawi S, 2017, I C ENG TECHNOL, V0, P0
   Ali Abbas Raza, 2009, P 7 INT C FRONT INF, V0, P21
   Aljedani N, 2021, EGYPT INFORM J, V22, P225, DOI 10.1016/j.eij.2020.08.004
   Almeida AMG, 2018, NEUROCOMPUTING, V320, P35, DOI 10.1016/j.neucom.2018.08.053
   Ameer I, 2022, IEEE ACCESS, V10, P8779, DOI 10.1109/ACCESS.2022.3143819
   Amin Saadullah, 2019, CLEF WORKING NOTES, V0, P0
   Ashraf N, 2022, PEERJ COMPUT SCI, V8, P0, DOI 10.7717/peerj-cs.896
   Asim MN, 2020, GENES-BASEL, V11, P0, DOI 10.3390/genes11121475
   Asim MN, 2021, NEURAL COMPUT APPL, V33, P5437, DOI 10.1007/s00521-020-05321-8
   Asim MN, 2017, INT J COMPUT SCI NET, V17, P135
   Asim MN, 2017, INT J ADV COMPUT SC, V8, P369, DOI 10.14569/IJACSA.2017.081048
   Benites F, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), V0, PP847, DOI 10.1109/ICDMW.2015.14
   Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   Bogaert M, 2019, EUR J OPER RES, V279, P620, DOI 10.1016/j.ejor.2019.05.037
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Boros Martin, 2012, INT J COMPUT COMMUN, V1, P62, DOI 10.7763/IJCCE.2012.V1.18
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brown I, 2012, EXPERT SYST APPL, V39, P3446, DOI 10.1016/j.eswa.2011.09.033
   Cave Andrew, 2017, WHAT WILL WE DO WORL, V0, P0
   Chang WC, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP3163, DOI 10.1145/3394486.3403368
   Chen WJ, 2016, PATTERN RECOGN, V52, P61, DOI 10.1016/j.patcog.2015.10.008
   Chen Y, 2018, IEEE I C NETW INFRAS, V0, PP409, DOI 10.1109/ICNIDC.2018.8525817
   Cheng WW, 2009, MACH LEARN, V76, P211, DOI 10.1007/s10994-009-5127-5
   Chitrakar R, 2012, ASIAN HIMAL INT CONF, V0, P0
   Christopher John Cornish HellabyWatkins, 1989, LEARNING DELAYED REW, V0, P0
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A, 2016, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1606.01781
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Curi Z, 2018, ARXIV, V0, P0
   Dai ZH, 2019, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Dilawari A, 2023, IEEE ACCESS, V11, P23557, DOI 10.1109/ACCESS.2023.3249783
   Du CX, 2019, AAAI CONF ARTIF INTE, V0, P6359
   Du JC, 2019, J AM MED INFORM ASSN, V26, P1279, DOI 10.1093/jamia/ocz085
   El Kafrawy Passent, 2015, INT J COMPUT APPL, V114, P1, DOI 10.5120/20083-1666
   Elghazel H, 2016, EXPERT SYST APPL, V57, P1, DOI 10.1016/j.eswa.2016.03.041
   Esuli A, 2006, LECT NOTES COMPUT SC, V4209, P1
   Fiallos A, 2019, INT CONF EDEMOC EGOV, V0, PP324, DOI 10.1109/icedeg.2019.8734365
   Fitriawan A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTER, V0, P0
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fürnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8
   Gargiulo Francesco, 2018, P 11 INT JOINT C BIO, V0, PP641, DOI 10.5220/0006730506410650
   Guo Q, 2019, STAR TRANSFORMER, V0, P0
   Halawi B, 2018, IEEE ACCESS, V6, P63890, DOI 10.1109/ACCESS.2018.2877685
   He Jiahui, 2019, J NEW MEDIA, V1, P51
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hüllermeier E, 2008, ARTIF INTELL, V172, P1897, DOI 10.1016/j.artint.2008.08.002
   Hussain S, 2016, P C LANG TECHN CLT 1, V0, P0
   Ibrahim MA, 2021, J BIOMED INFORM, V116, P0, DOI 10.1016/j.jbi.2021.103699
   Jabreel M, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9061123
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Joulin A, 2016, ARXIV, V0, P0
   Kalchbrenner N, 2014, ARXIV, V0, P0
   Kashif M, 2021, ARXIV, V0, P0
   Kim Y, 2014, ARXIV, V0, P0
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kurata Gakuto, 2016, P C N AM CHAPT ASS C, V0, PP521, DOI 10.18653/v1/N16-1063
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Li ML, 2017, IEEE T AFFECT COMPUT, V8, P443, DOI 10.1109/TAFFC.2017.2723012
   Li SJ, 2002, J COMPUT SCI TECHNOL, V17, P933, DOI 10.1007/BF02960786
   Liu JZ, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP115, DOI 10.1145/3077136.3080834
   Liu PF, 2016, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Marr Bernard, 2015, BIG DATA 20 MIND BOG, V0, P0
   Matthijs J, 2015, J PSYCHOL PSYCHOTHER, V5, P1, DOI 10.4172/2161-0487.1000197
   Mehmood F, 2022, APPL ENERG, V324, P0, DOI 10.1016/j.apenergy.2022.119754
   Mehmood F, 2021, RENEW SUST ENERG REV, V151, P0, DOI 10.1016/j.rser.2021.111559
   Mehmood F, 2020, IEEE ACCESS, V8, P192740, DOI 10.1109/ACCESS.2020.3030885
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Moyano JM, 2018, INFORM FUSION, V44, P33, DOI 10.1016/j.inffus.2017.12.001
   Mulcahy Mark, 2017, BIG DATA STAT FACTS, V0, P0
   Muñoz E, 2019, BRIEF BIOINFORM, V20, P190, DOI 10.1093/bib/bbx099
   Pappas N, 2019, T ASSOC COMPUT LING, V7, P139, DOI 10.1162/tacl_a_00259
   Peng H, 2019, ARXIV, V0, P0
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1063, DOI 10.1145/3178876.3186005
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pinter Y, 2017, ARXIV, V0, P0
   Prabhu Y, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP441, DOI 10.1145/3159652.3159660
   Qiao Chao, 2018, ICLR, V0, P0
   Quan Chanqin, 2016, BIOMED RES INT-UK, V0, P0
   Raghavan AK, 2019, P 15 C NAT LANG PROC, V0, P0
   Read J, 2014, ARXIV, V0, P0
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Rish I, 2001, IN IJCAI 2001 WORKSH, V3, P41, DOI 10.1214/088342306000000060
   Rojarath A, 2016, INT CONF SOFTW ENG, V0, PP107, DOI 10.1109/ICSESS.2016.7883026
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Roxas Rachel Edita O, 2011, P 9 WORKSH AS LANG R, V0, P0
   Rusland NF, 2017, IOP CONF SER-MAT SCI, V226, P0, DOI 10.1088/1757-899X/226/1/012091
   Saleem S, 2022, CMC-COMPUT MATER CON, V70, P505, DOI 10.32604/cmc.2022.018871
   Sanh V, 2020, ARXIV, V0, P0
   Sattar Sohail Abdul, 2017, IND J SCI TECHNOL, V10, P29
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Shehab MA, 2016, INT CONF COMP SCI, V0, P0
   Shen YL, 2014, WWW14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP373, DOI 10.1145/2567948.2577348
   Shimura K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P811
   Simonyan K, 2015, ARXIV, V0, P0
   Spyromitros E, 2008, LECT NOTES ARTIF INT, V5138, P401, DOI 10.1007/978-3-540-87881-0_40
   Summra S, 2021, 2021 18TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, V0, P0, DOI 10.1109/CCE53527.2021.9632882
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P1602, DOI 10.1109/TKDE.2016.2522427
   Tang BZ, 2018, WIREL COMMUN MOB COM, V0, P0, DOI DOI 10.1155/2018/2379208
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Tripathy A, 2016, EXPERT SYST APPL, V57, P117, DOI 10.1016/j.eswa.2016.03.028
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Usman M, 2016, INT J ADV COMPUT SC, V7, P265
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang BX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2311
   Wang YQ, 2016, LECT NOTES COMPUT SC, V9931, P567, DOI 10.1007/978-3-319-45814-4_46
   Wasim M, 2019, IEEE ACCESS, V7, P3882, DOI 10.1109/ACCESS.2018.2887165
   Wei LW, 2019, LECT NOTES COMPUT SC, V11536, P548, DOI 10.1007/978-3-030-22734-0_40
   Wu QY, 2014, KNOWL-BASED SYST, V67, P105, DOI 10.1016/j.knosys.2014.06.004
   Xu G, 2017, INT CONF BIG DATA, V0, PP126, DOI 10.1109/BIGCOMP.2017.7881727
   Yang PC, 2018, ARXIV, V0, P0
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yang ZL, 2020, ARXIV, V0, P0
   Yih WT, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P643
   Yin WP, 2017, ARXIV, V0, P0
   Yin Wenpeng, 2018, T ASS COMPUT LING, V6, P687, DOI 10.1162/TACL_A_00249
   You RH, 2019, ARXIV, V0, P0
   You Ronghui, 2019, NEURIPS, V0, P5812
   Zahid R, 2020, 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING WORKSHOPS (ASEW 2020), V0, PP138, DOI 10.1145/3417113.3423377
   Zenobi Gabriele, 2001, MACHINE LEARNING ECM, V0, PP576, DOI 10.1007/3-540-44795-4_
   Zhang LJ, 2018, IOP CONF SER-MAT SCI, V322, P0, DOI 10.1088/1757-899X/322/6/062007
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang W, 2015, BMC BIOINFORMATICS, V16, P0, DOI 10.1186/s12859-015-0774-y
   Zhang WJ, 2018, ICMR 18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP100, DOI 10.1145/3206025.3206030
   Zia Tehseen, 2015, INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS AND APPLICATIONS, V7, P33, DOI 10.5815/ijisa.2015.06.03
NR 134
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2023
VL 22
IS 9
BP 
EP 
DI 10.1145/3616111
PG 31
WC Computer Science, Artificial Intelligence
SC Computer Science
GA T7EN7
UT WOS:001079577300007
DA 2023-11-10
ER

PT J
AU Özdemir, O
   Kerzel, M
   Weber, C
   Lee, JH
   Hafez, MB
   Bruns, P
   Wermter, S
AF Oezdemir, Ozan
   Kerzel, Matthias
   Weber, Cornelius
   Lee, Jae Hee
   Hafez, Muhammad Burhan
   Bruns, Patrick
   Wermter, Stefan
TI Learning Bidirectional Action-Language Translation with Limited Supervision and Testing with Incongruent Input
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
ID motor; nico
AB Human infant learning happens during exploration of the environment, by interaction with objects, and by listening to and repeating utterances casually, which is analogous to unsupervised learning. Only occasionally, a learning infant would receive a matching verbal description of an action it is committing, which is similar to supervised learning. Such a learning mechanism can be mimicked with deep learning. We model this weakly supervised learning paradigm using our Paired Gated Autoencoders (PGAE) model, which combines an action and a language autoencoder. After observing a performance drop when reducing the proportion of supervised training, we introduce the Paired Transformed Autoencoders (PTAE) model, using Transformer-based crossmodal attention. PTAE achieves significantly higher accuracy in language-to-action and action-to-language translations, particularly in realistic but difficult cases when only few supervised training samples are available. We also test whether the trained model behaves realistically with conflicting multimodal input. In accordance with the concept of incongruence in psychology, conflict deteriorates the model output. Conflicting action input has a more severe impact than conflicting language input, and more conflicting features lead to larger interference. PTAE can be trained on mostly unlabeled data where labeled data is scarce, and it behaves plausibly when tested with incongruent input.
C1 [Oezdemir, Ozan; Kerzel, Matthias; Weber, Cornelius; Lee, Jae Hee; Hafez, Muhammad Burhan; Wermter, Stefan] Univ Hamburg, Dept Informat, Knowledge Technol, Hamburg, Germany.
   [Bruns, Patrick] Univ Hamburg, Biol Psychol & Neuropsychol, Hamburg, Germany.
C3 University of Hamburg; University of Hamburg
RP Özdemir, O (通讯作者)，Univ Hamburg, Dept Informat, Knowledge Technol, Vogt Koelln Str 30, D-22527 Hamburg, Germany.
EM ozan.oezdemir@uni-hamburg.de
FU German Research Foundation (DFG) [TRR 169]; IDEAS; TRR 169 Crossmodal Learning (CML); LeCareBot; MoReSpace
CR Abramson Josh, 2020, ARXIV201205672, V0, P0
   Ahn M, 2022, ARXIV, V0, P0
   Antunes A, 2019, IEEE INT C INT ROBOT, V0, PP2614, DOI 10.1109/iros40897.2019.8967799
   Aravena P, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0011751
   Arevalo J, 2020, NEURAL COMPUT APPL, V32, P10209, DOI 10.1007/s00521-019-04559-1
   Bisk Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8718
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Canals L, 2023, RECALL, V35, P4, DOI 10.1017/S0958344022000118
   Devlin J, 2018, ARXIV, V1, P4171
   Eisermann A, 2021, IEEE IJCNN, V0, P0, DOI DOI 10.1109/IJCNN52387.2021.9534275
   Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hatori J, 2018, IEEE INT CONF ROBOT, V0, P3774
   Hauk O, 2004, NEURON, V41, P301, DOI 10.1016/S0896-6273(03)00838-9
   Heinrich S, 2020, FRONT NEUROROBOTICS, V14, P0, DOI 10.3389/fnbot.2020.00052
   Irshad Muhammad Zubair, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP13238, DOI 10.1109/ICRA48506.2021.9561806
   Jaegle Andrew, 2021, ARXIV210714795, V0, P0
   Jang Eric, 2021, 5 ANN C ROBOT LEARNI, V0, P0
   Jiang Y, 2022, VIMA GEN ROBOT MANIP, V0, P0
   Kanda H, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1852
   Kaschak MP, 2005, COGNITION, V94, PB79, DOI 10.1016/j.cognition.2004.06.005
   Kerzel M, 2020, FRONT NEUROROBOTICS, V14, P0, DOI 10.3389/fnbot.2020.00028
   Kerzel M, 2017, IEEE ROMAN, V0, PP113, DOI 10.1109/ROMAN.2017.8172289
   Kingma DP, 2014, C TRACK P, V0, P0
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Lynch C, 2021, ROBOTICS SCI SYSTEM, V0, P1
   Meteyard L, 2007, PSYCHOL SCI, V18, P1007, DOI 10.1111/j.1467-9280.2007.02016.x
   Özdemir O, 2022, LECT NOTES COMPUT SC, V13530, P246, DOI 10.1007/978-3-031-15931-2_21
   Ozdemir O, 2021, 2021 IEEE INT C DEV, V0, P1
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Reed S, 2022, T MACHINE LEARNING R, V11/2022, P1
   Shao L, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI, V0, P0
   Shridhar M, 2022, P 6 C ROBOT LEARNING, V0, P0
   Shridhar M, 2021, P 5 C ROBOT LEARNING, V0, P0
   Shridhar M, 2020, INT J ROBOT RES, V39, P217, DOI 10.1177/0278364919897133
   van Elk M, 2010, NEUROIMAGE, V50, P665, DOI 10.1016/j.neuroimage.2009.12.123
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Winter A, 2022, ACTA PSYCHOL, V230, P0, DOI 10.1016/j.actpsy.2022.103712
   Yamada T, 2018, IEEE ROBOT AUTOM LET, V3, P3441, DOI 10.1109/LRA.2018.2852838
   Zeng Andy, 2020, CORL, V0, P0
NR 42
TC 0
Z9 0
U1 10
U2 13
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD DEC 31
PY 2023
VL 37
IS 1
BP 
EP 
DI 10.1080/08839514.2023.2179167
PG 24
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 9K2CI
UT WOS:000940678800001
DA 2023-11-10
ER

PT J
AU Chung, PL
   Boodoo, M
   Doboli, S
AF Chung, Paul
   Boodoo, Michael
   Doboli, Simona
TI Case scenario generators for trauma surgery simulation utilizing autoregressive language models
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Language models; Medical simulation generation; Medical education; Trauma surgery
AB Trauma is the leading cause of death in adults under the age of 45 and the fourth leading cause of death in the United States. Effective delivery of trauma care centers on being well versed in the Advanced Trauma Life Support (ATLS) protocol, which requires high levels of clinical experience. Often this comes from having been exposed to the many permutations of common types of injuries as well as exposed to rarer scenarios, but with potential harm to patients. Case scenarios, which are sequential representations of clinical events, can help trainees receive clinical exposure without harming patients. However authoring case scenarios requires domain expertise, wide experience, and the ability to intelligently respond to inputs, and as such is currently an arduous task. Autoregressive generative models trained on large amounts of clinical data, such as the National Trauma Data Bank (NTDB), pose a possible solution to overcome the cost of authorship while providing broad and accessible clinical experience to trainees. We have developed a Trauma AI model composed of an autoregressive generative model based on the transformer architecture for generating potential case scenario combined with an out-of-domain detection for filtering out less plausible scenarios. The GPT2 model is trained on 1.1 million case scenarios derived from the NTDB data. We demonstrate that Trauma AI is capable of generating realistic case scenarios that encode the ATLS protocol as a latent feature of the sequence of provider interventions, including scenarios that do not have any parallels in the original dataset. We also present an unsupervised means of filtering out unrealistic sequences by identifying out-of-domain sequences, and demonstrate that this improves the realism of the generated case scenarios.
C1 [Chung, Paul] Zucker Sch Med Hofstra Northwell, Dept Surg, Hempstead, NY 11549 USA.
   [Boodoo, Michael; Doboli, Simona] Hofstra Univ, Comp Sci Dept, Hempstead, NY 11549 USA.
C3 Northwell Health; Hofstra University
RP Chung, PL (通讯作者)，Zucker Sch Med Hofstra Northwell, Dept Surg, Hempstead, NY 11549 USA.
EM pchung2@northwell.edu
FU National Board of Medical Examiners, USA Stemmler [1920-2805]
CR AAST, 2022, TRAUM FACTS, V0, P0
   Allen CJ, 2014, J TRAUMA ACUTE CARE, V77, P859, DOI 10.1097/TA.0000000000000422
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Biswal S, 2021, MACH LEARN HEALTHC C, V0, P260
   Brasel KJ, 2013, J TRAUMA ACUTE CARE, V74, P1363, DOI 10.1097/TA.0b013e31828b82f5
   Buczak AL, 2010, BMC MED INFORM DECIS, V10, P0, DOI 10.1186/1472-6947-10-59
   Chen S, 2018, J CONTRIBUTION, V0, PP6, DOI 10.1184/R1/6605324.v1
   Choi E, 2017, MACH LEARN HEALTHC C, V0, P286
   Choi Edward, 2016, JMLR WORKSHOP CONF PROC, V56, P301
   Fitch CDRJL, 2019, AM J SURG, V218, P1201, DOI 10.1016/j.amjsurg.2019.08.018
   Gardner AK, 2016, SURGERY, V160, P546, DOI 10.1016/j.surg.2016.03.028
   Goncalves A, 2020, BMC MED RES METHODOL, V20, P0, DOI 10.1186/s12874-020-00977-1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2014, ARXIV, V0, P0
   Hammond Jeffrey, 2004, CURR OPIN CRIT CARE, V10, P325, DOI 10.1097/01.ccx.0000140950.47361.c9
   Iyer R, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, V0, P254, DOI 10.1109/ASRU.1997.659013
   Li Yujia, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2203.07814
   Liang SY, 2020, ARXIV, V0, P0
   McInnes Leland, 2020, ARXIV, V0, P0
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Motola I, 2013, MED TEACH, V35, PE1511, DOI 10.3109/0142159X.2013.818632
   National Trauma Data Bank, 2022, NTDB, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Schölkopf B, 2000, ADV NEUR IN, V12, P582
   SCORE, 2022, SCORE CURR OUTL, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Walonoski J, 2018, J AM MED INFORM ASSN, V25, P230, DOI 10.1093/jamia/ocx079
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xu KY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1052
   Zugarini A, 2019, LECT NOTES COMPUT SC, V11730, P313, DOI 10.1007/978-3-030-30490-4_26
NR 30
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD OCT 15
PY 2023
VL 144
IS 
BP 
EP 
DI 10.1016/j.artmed.2023.102635
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA T8MA4
UT WOS:001080457200001
PM 37783535
DA 2023-11-10
ER

PT J
AU Oh, BD
   Schuler, W
AF Oh, Byung-Doh
   Schuler, William
TI Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID names
AB This work presents a linguistic analysis into why larger Transformer-based pre-trained language models with more parameters and lower perplexity nonetheless yield surprisal estimates that are less predictive of human reading times. First, regression analyses show a strictly monotonic, positive log-linear relationship between perplexity and fit to reading times for the more recently released five GPT-Neo variants and eight OPT variants on two separate datasets, replicating earlier results limited to just GPT-2 (Oh et al., 2022). Subsequently, analysis of residual errors reveals a systematic deviation of the larger variants, such as underpredicting reading times of named entities and making compensatory overpredictions for reading times of function words such as modals and conjunctions. These results suggest that the propensity of larger Transformer-based models to 'memorize' sequences during training makes their surprisal estimates diverge from humanlike expectations, which warrants caution in using pre-trained language models to study human language processing.
C1 [Oh, Byung-Doh; Schuler, William] Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Oh, BD (通讯作者)，Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
EM oh.531@osu.edu; schuler.77@osu.edu
FU National Science Foundation [1816891]; Direct For Computer & Info Scie & Enginr; Div Of Information & Intelligent Systems [1816891] Funding Source: National Science Foundation
CR Aran Wang, 2021, GPTJ6B, V0, P0
   Arehalli Suhas, 2022, P 26 C COMP NAT LANG, V0, P301
   Aurnhammer Christoph, 2019, P 41 ANN M COGNITIVE, V0, P112
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Black S, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), V0, P95
   Black Sid, 2021, ZENODO, V0, P0
   Byung-Doh Oh, 2022, P 2022 C EMPIRICAL M, V0, P9324
   Carlini N, 2022, ARXIV, V0, P0
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Clark Christian, 2022, 35 ANN C HUM SENT PR, V0, P0
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008
   Devlin J, 1900, P4171, V0, P0, DOI DOI 10.18653/v1/N19-1423
   Dyer C, 2016, P 2016 C N AM CHAPT, V0, PP199, DOI 10.18653/v1/N16-1024
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844
   Futrell R, 2021, LANG RESOUR EVAL, V55, P63, DOI 10.1007/s10579-020-09503-7
   Gibson E, 2000, IMAGE, V0, P0
   Goodkind A, 2018, P 8 WORKSHOP COGNITI, V0, PP10, DOI 10.18653/V1/W18-0102
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hahn M, 2022, P NATL ACAD SCI USA, V119, P0, DOI 10.1073/pnas.2122602119
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P159
   Hale J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2727
   Hao Yiding, 2020, PROC WORKSHOP COGNIT, V0, P75
   Hollenstein N, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P141
   Johnson-Laird PN, 1983, MENTAL MODELS COGNIT, V0, P0
   Kennedy A, 2003, P 12 EUROPEAN C EYE, V0, P0
   Kuribayashi T, 2021, P 59 ANN M ASS COMPU, V0, P0, DOI DOI 10.18653/v1/2021.acl-long.405
   Kuribayashi Tatsuki, 2022, P 2022 C EMPIRICAL M, V0, P0
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Lewis RL, 2006, TRENDS COGN SCI, V10, P447, DOI 10.1016/j.tics.2006.08.007
   Merkx D, 2021, P WORKSH COGN MOD CO, V0, PP12, DOI 10.18653/V1/2021.CMCL-1.2
   Nelson Elhage Neel, 2021, MATH FRAMEWORK TRANS, V0, P0
   Nguyen Luan, 2012, P 24 INT C COMPUTATI, V0, P2125
   Oh BD, 2022, FRONT ARTIF INTELL, V5, P0, DOI 10.3389/frai.2022.777963
   Oh BD, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3746
   Proverbio AM, 2001, NEUROPSYCHOLOGIA, V39, P815, DOI 10.1016/S0028-3932(01)00003-3
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0
   Ryu SH, 2021, P WORKSH COGN MOD CO, V0, P0
   Ryu Soo Hyun, 2022, 35 ANN C HUM SENT PR, V0, P0
   Sanh V, 2019, ARXIV, V0, P0
   Schrimpf M, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2105646118
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shain C, 2021, COGNITION, V215, P0, DOI 10.1016/j.cognition.2021.104735
   Shain C, 2020, NEUROPSYCHOLOGIA, V138, P0, DOI 10.1016/j.neuropsychologia.2019.107307
   Shain Cory, 2018, WORKSHOP LINGUISTIC, V0, P0
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013
   Thompson Alan D, 2022, LIFEARCHITECTAI REPO, V0, P0
   van Schijndel M, 2021, COGNITIVE SCI, V45, P0, DOI 10.1111/cogs.12988
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang L, 2013, BRAIN LANG, V125, P118, DOI 10.1016/j.bandl.2013.01.006
   Wilcox Ethan Gotlieb, 2020, P 42 ANN M COGNITIVE, V0, P1707
   Zhang SS, 2022, ARXIV, V0, P0
NR 52
TC 0
Z9 0
U1 5
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 27
PY 2023
VL 11
IS 
BP 336
EP 350
DI 10.1162/tacl_a_00548
PG 15
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA C1JR6
UT WOS:000959570700002
DA 2023-11-10
ER

PT J
AU Wang, Y
   Wu, LJ
   Li, JT
   Liang, XB
   Zhang, M
AF Wang, Yue
   Wu, Lijun
   Li, Juntao
   Liang, Xiaobo
   Zhang, Min
TI Are the BERT family zero-shot learners? A study on their potential and limitations
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Pre-trained language model; Zero-shot text classification; Prompt-based learning
AB Starting from the resurgence of deep learning, language models (LMs) have never been so popular. Through simply increasing model scale and data size, large LMs pre-trained with self-supervision objectives demonstrate awe-inspiring results on both task performance and generalization. At the early stage, supervised fine-tuning is indispensable in adapting pre-trained language models (PLMs) to downstream tasks. Later on, the sustained growth of model capacity and data size, as well as newly presented pre-training techniques, make the PLMs perform well under the few-shot setting, especially in the recent paradigm of prompt-based learning. After witnessing the success of PLMs for few-shot tasks, we propose to further study the potential and limitations of PLMs for the zero-shot setting. We utilize 3 models from the most popular BERT family to launch the empirical study on 20 different datasets. We are surprised to find that some simple strategies (without the need of human efforts or unsupervised data) can yield very promising results on a few widely-used datasets, e.g., 88.34%(& PLUSMN;0.60) accuracy on the IMDB dataset, and 84.88%(& PLUSMN;2.83) accuracy on the Amazon dataset, which outperforms manually created prompts without engineering in achieving much better and stable performance with the accuracy of 74.06%(& PLUSMN;13.04), 75.54%(& PLUSMN;11.77) for comparison. However, we also observe some limitations of PLMs under the zero-shot setting, particularly for the language understanding tasks (e.g., GLUE, SuperGLUE).2 & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Wang, Yue; Li, Juntao; Liang, Xiaobo; Zhang, Min] Soochow Univ, Suzhou, Peoples R China.
   [Wu, Lijun] Microsoft Res Asia, Beijing, Peoples R China.
   [Zhang, Min] Harbin Inst Technol, Shenzhen, Peoples R China.
C3 Soochow University - China; Microsoft; Microsoft Research Asia; Harbin Institute of Technology
RP Li, JT (通讯作者)，Soochow Univ, Suzhou, Peoples R China.
EM ywangnlp@stu.suda.edu.cn; lijuwu@microsoft.com; ljt@suda.edu.cn; xbliang3@stu.suda.edu.cn; minzhang@suda.edu.cn
FU National Science Foundation of China (NSFC) [62206194]; Natural Science Foundation of Jiangsu Province, China [BK20220488, JSSCBS20210661]; Beijing Academy of Artificial Intelligence (BAAI)
CR [Anonymous], 2008, P 31 ANN INT ACM SIG, V0, P0, DOI DOI 10.1145/1390334.1390436
   Chan Ying-Hong, 2019, P 2 WORKSH MACH READ, V0, PP154, DOI 10.18653/V1/D19-5821
   Chang Ming-Wei, 2008, P NAT C ART INT, V0, P830
   Chen XY, 2015, AAAI CONF ARTIF INTE, V0, P2224
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Feldman J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1173
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1606
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Gu JT, 2018, ARXIV, V0, P0
   Hambardzumyan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4921
   Haviv A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P3618
   Huang J, 2021, FINDINGS ASS COMPUTA, V0, PP238, DOI 10.18653/V1/2021.FINDINGS-EMNLP.23
   Huang XS, 2021, INT C LEARNING REPRE, V0, P0
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Jin YP, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P112
   Khashabi Daniel, 2020, FINDINGS ASS COMPUTA, V0, PP1896, DOI 10.18653/V1/2020.FINDINGS-EMNLP.171
   Lan Z, 2020, ARXIV, V0, P0
   Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2627
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Lewis M, 2020, P 58 ANN M ASS COMP, V0, P0
   Lhoest Quentin, 2021, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.5148649
   Li CL, 2019, ACM T INFORM SYST, V37, P0, DOI 10.1145/3238250
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Liu H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4799
   Liu P, 2021, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Lu X, 2021, ARXIV, V0, P0
   Ma TT, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P786
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   McAuley J, 2013, P 7 ACM C RECOMMENDE, V0, P165
   Mekala D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P323
   Meng Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9006
   Meng Y, 2019, AAAI CONF ARTIF INTE, V0, P6826
   Mishra S, 2022, P 60 ANN M ASS COMPU, V1, P3470
   Nam J, 2016, AAAI CONF ARTIF INTE, V0, P1948
   Perez E, 2021, ADV NEUR IN, V0, P0
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Qin GH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5203
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Schick T, 2020, P 28 INT C COMP LING, V0, P5569
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P255
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2339
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Song YQ, 2014, AAAI CONF ARTIF INTE, V0, P1579
   Su YX, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P234
   Thoppilan R, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2201.08239
   Wang Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P3043
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xu H, 2022, ARXIV, V0, P0
   Yan GF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1050
   Ye ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3014
   Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3914
   Zhang J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1031
   Zhang Xiang, 2015, NEURIPS, V0, P0, DOI DOI 10.5555/2969239.2969312
   Zhao XD, 2022, ARXIV, V0, P0
   Zhong RQ, 2021, ARXIV, V0, P0
   Zhong Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5017
   2023, 1900, DOI ARXIV:2303.08774, V0, P0
NR 81
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD SEP 15
PY 2023
VL 322
IS 
BP 
EP 
DI 10.1016/j.artint.2023.103953
EA JUN 2023
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA O0TL1
UT WOS:001041031600001
DA 2023-11-10
ER

PT J
AU Fu, NH
   Wei, L
   Song, YQ
   Li, QY
   Xin, R
   Omee, SS
   Dong, RZ
   Siriwardane, EMD
   Hu, JJ
AF Fu, Nihang
   Wei, Lai
   Song, Yuqi
   Li, Qinyang
   Xin, Rui
   Omee, Sadman Sadeed
   Dong, Rongzhi
   Siriwardane, Edirisuriya M. Dilanga
   Hu, Jianjun
TI Material transformers: deep learning language models for generative materials design
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE deep learning; language models; generative design; materials discovery; transformer
ID total-energy calculations; wave
AB Pre-trained transformer language models (LMs) on large unlabeled corpus have produced state-of-the-art results in natural language processing, organic molecule design, and protein sequence generation. However, no such models have been applied to learn the composition patterns for the generative design of material compositions. Here we train a series of seven modern transformer models (GPT, GPT-2, GPT-Neo, GPT-J, BLMM, BART, and RoBERTa) for materials design using the expanded formulas of the ICSD, OQMD, and Materials Projects databases. Six different datasets with/out non-charge-neutral or EB samples are used to benchmark the generative design performances and uncover the biases of modern transformer models for the generative design of materials compositions. Our experiments show that the materials transformers based on causal LMs can generate chemically valid material compositions with as high as 97.61% to be charge neutral and 91.22% to be electronegativity balanced, which has more than six times higher enrichment compared to the baseline pseudo-random sampling algorithm. Our LMs also demonstrate high generation novelty and their potential in new materials discovery is proved by their capability to recover the leave-out materials. We also find that the properties of the generated compositions can be tailored by training the models with selected training sets such as high-bandgap samples. Our experiments also show that different models each have their own preference in terms of the properties of the generated samples and their running time complexity varies a lot. We have applied our materials transformers to discover a set of new materials as validated using density functional theory calculations.
C1 [Fu, Nihang; Wei, Lai; Song, Yuqi; Li, Qinyang; Xin, Rui; Omee, Sadman Sadeed; Dong, Rongzhi; Hu, Jianjun] Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29201 USA.
   [Siriwardane, Edirisuriya M. Dilanga] Univ Colombo, Dept Phys, Colombo 03, Sri Lanka.
C3 University of South Carolina System; University of South Carolina Columbia; University of Colombo
RP Hu, JJ (通讯作者)，Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29201 USA.
EM jianjunh@cse.sc.edu
FU National Science Foundation [1940099, 1905775, 2110033]; Direct For Mathematical & Physical Scien; Division Of Materials Research [1905775] Funding Source: National Science Foundation; Div Of Electrical, Commun & Cyber Sys; Directorate For Engineering [2110033] Funding Source: National Science Foundation; Office of Advanced Cyberinfrastructure (OAC); Direct For Computer & Info Scie & Enginr [1940099] Funding Source: National Science Foundation
CR Bagal V, 2022, J CHEM INF MODEL, V62, P2064, DOI 10.1021/acs.jcim.1c00600
   Black Sid, 2021, ZENODO, V0, P0
   BLOCHL PE, 1994, PHYS REV B, V50, P17953, DOI 10.1103/PhysRevB.50.17953
   Brown TB, 2020, P 34 INT C NEUR INF, V0, P0
   Dan YB, 2019, ARXIV, V0, P0
   Dan YB, 2020, NPJ COMPUT MATER, V6, P0, DOI 10.1038/s41524-020-00352-0
   Davies D W, 2019, J OPEN SOURCE SOFTW, V41361, P0
   De Cao N, 2018, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Dollar O, 2021, CHEM SCI, V12, P8362, DOI 10.1039/d1sc01050f
   Dong L, 2019, ADV NEUR IN, V32, P0
   Ferruz N, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-32007-7
   Flam-Shepherd D, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-30839-x
   Gao L, 2020, ARXIV, V0, P0
   Goodall REA, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-19964-7
   Guimaraes GL, 2018, ARXIV, V0, P0
   Hautier G, 2011, INORG CHEM, V50, P656, DOI 10.1021/ic102031h
   Hesslow D, 2022, ARXIV, V0, P0
   Hu JJ, 2023, ARXIV, V0, P0
   Ingraham J, 2019, ADV NEUR IN, V32, P0
   Jain A, 2013, APL MATER, V1, P0, DOI 10.1063/1.4812323
   Jang J, 2020, J AM CHEM SOC, V142, P18836, DOI 10.1021/jacs.0c07384
   Kim H, 2021, J CHEM INF MODEL, V61, P5804, DOI 10.1021/acs.jcim.1c01289
   Kresse G, 1996, PHYS REV B, V54, P11169, DOI 10.1103/PhysRevB.54.11169
   KRESSE G, 1993, PHYS REV B, V47, P558, DOI 10.1103/PhysRevB.47.558
   Kresse G, 1999, PHYS REV B, V59, P1758, DOI 10.1103/PhysRevB.59.1758
   Kresse G, 1996, COMP MATER SCI, V6, P15, DOI 10.1016/0927-0256(96)00008-0
   Kusaba M, 2022, ARXIV, V0, P0
   Lewis M, 2019, ARXIV, V0, P0
   Li J, 2022, ARXIV, V0, P0
   Li JY, 2021, ARXIV, V0, P0
   Linder J, 2020, CELL SYST, V11, P49, DOI 10.1016/j.cels.2020.05.007
   Liu YH, 2019, ARXIV, V0, P0
   Madani A, 2020, ARXIV, V0, P0
   Oganov AR, 2012, CECAM WORKSH LAUS 20, V0, P22
   Omee SS, 2022, PATTERNS, V3, P0, DOI 10.1016/j.patter.2022.100491
   Osadchy M, 2021, J PHYS CHEM B, V125, P6440, DOI 10.1021/acs.jpcb.1c02449
   Perdew JP, 1996, PHYS REV LETT, V77, P3865, DOI 10.1103/PhysRevLett.77.3865
   Polykovskiy D, 2020, FRONT PHARMACOL, V11, P0, DOI 10.3389/fphar.2020.565644
   Radford A, 2019, OPENAI BLOG, V19, P0
   Raffel C, 2020, ARXIV, V0, P0
   Rothchild D, 2021, ARXIV, V0, P0
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI 10.1162/tacl_a_.00313
   Shao XC, 2022, J CHEM PHYS, V156, P0, DOI 10.1063/5.0074677
   Shen T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5186
   Sun WH, 2019, NAT MATER, V18, P732, DOI 10.1038/s41563-019-0396-2
   Wang Ben, 2021, GPT J 6B 6 BILLION P, V0, P0
   Wei J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P932
   Wei L, 2022, ARXIV, V0, P0
   Wei L, 2022, INORG CHEM, V61, P8431, DOI 10.1021/acs.inorgchem.1c03879
   Wu Z, 2020, ACS SYNTH BIOL, V9, P2154, DOI 10.1021/acssynbio.0c00219
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zagorac D, 2019, J APPL CRYSTALLOGR, V52, P918, DOI 10.1107/S160057671900997X
   Zhao Y, 2021, ADV SCI, V8, P0, DOI 10.1002/advs.202100566
   Zunger A, 2021, CHEM REV, V121, P3031, DOI 10.1021/acs.chemrev.0c00608
NR 56
TC 3
Z9 3
U1 14
U2 47
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR 1
PY 2023
VL 4
IS 1
BP 
EP 
DI 10.1088/2632-2153/acadcd
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences
SC Computer Science; Science & Technology - Other Topics
GA 7P0UQ
UT WOS:000908430900001
DA 2023-11-10
ER

PT J
AU Défossez, A
   Caucheteux, C
   Rapin, J
   Kabeli, O
   King, JR
AF Defossez, Alexandre
   Caucheteux, Charlotte
   Rapin, Jeremy
   Kabeli, Ori
   King, Jean-Remi
TI Decoding speech perception from non-invasive brain recordings
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID convolutional neural-networks; magnetoencephalography; communication; awareness
AB Decoding speech from brain activity is a long-awaited goal in both healthcare and neuroscience. Invasive devices have recently led to major milestones in this regard: deep-learning algorithms trained on intracranial recordings can now start to decode elementary linguistic features such as letters, words and audio-spectrograms. However, extending this approach to natural speech and non-invasive brain recordings remains a major challenge. Here we introduce a model trained with contrastive learning to decode self-supervised representations of perceived speech from the non-invasive recordings of a large cohort of healthy individuals. To evaluate this approach, we curate and integrate four public datasets, encompassing 175 volunteers recorded with magneto-encephalography or electro-encephalography while they listened to short stories and isolated sentences. The results show that our model can identify, from 3 seconds of magneto-encephalography signals, the corresponding speech segment with up to 41% accuracy out of more than 1,000 distinct possibilities on average across participants, and with up to 80% in the best participants-a performance that allows the decoding of words and phrases absent from the training set. The comparison of our model with a variety of baselines highlights the importance of a contrastive objective, pretrained representations of speech and a common convolutional architecture simultaneously trained across multiple participants. Finally, the analysis of the decoder's predictions suggests that they primarily depend on lexical and contextual semantic representations. Overall, this effective decoding of perceived speech from non-invasive recordings delineates a promising path to decode language from brain activity, without putting patients at risk of brain surgery. Deep learning can help develop non-invasive technology for decoding speech from brain activity, which could improve the lives of patients with brain injuries. Defossez et al. report a contrastive-learning approach to decode speech listening from human participants, using public databases of recordings based on non-invasive magnetic and electrical measurements.
C1 [Defossez, Alexandre; Caucheteux, Charlotte; Rapin, Jeremy; King, Jean-Remi] Meta AI, Paris, France.
   [Caucheteux, Charlotte] INRIA Saclay, Saclay, France.
   [Kabeli, Ori] Meta AI, Tel Aviv, Israel.
   [King, Jean-Remi] PSL Univ, Ecole Normale Super, Dept Etud Cognit, LSP, Paris, France.
C3 Universite PSL; Ecole Normale Superieure (ENS)
RP Défossez, A; King, JR (通讯作者)，Meta AI, Paris, France.; King, JR (通讯作者)，PSL Univ, Ecole Normale Super, Dept Etud Cognit, LSP, Paris, France.
EM defossez@meta.com; jeanremi@meta.com
FU This work was funded in part by FrontCog grant ANR-17-EURE-0017 to J.R.K. for his work at PSL. [ANR-17-EURE-0017]
CR Adolfi F, 2023, NEURAL NETWORKS, V162, P199, DOI 10.1016/j.neunet.2023.02.032
   Affolter N, 2020, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2009.04765
   Akbari H, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-018-37359-z
   Ali O, 2022, SCI REP-UK, V12, P0, DOI 10.1038/s41598-022-07992-w
   Angrick M, 2021, COMMUN BIOL, V4, P0, DOI 10.1038/s42003-021-02578-0
   Angrick M, 2019, NEUROCOMPUTING, V342, P145, DOI 10.1016/j.neucom.2018.10.080
   Angrick M, 2019, J NEURAL ENG, V16, P0, DOI 10.1088/1741-2552/ab0c59
   Anumanchipalli GK, 2019, NATURE, V568, P493, DOI 10.1038/s41586-019-1119-1
   Baevski Alexei, 2020, P ADV NEUR INF PROC, V33, P12449
   Banville H, 2021, J NEURAL ENG, V18, P0, DOI 10.1088/1741-2552/abca18
   Bernard Mathieu, 2021, J OPEN SOURCE SOFTW, V6, P3958, DOI 10.21105/JOSS.03958
   Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581
   Boto E, 2018, NATURE, V555, P657, DOI 10.1038/nature26147
   Brennan JR, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0207741
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Brumberg JS, 2009, 10 ANN C INT SPEECH, V0, P0
   Caucheteux C, 2022, SCI REP-UK, V12, P0, DOI 10.1038/s41598-022-20460-9
   Caucheteux C, 2022, COMMUN BIOL, V5, P0, DOI 10.1038/s42003-022-03036-1
   Chan AM, 2011, NEUROIMAGE, V54, P3028, DOI 10.1016/j.neuroimage.2010.10.073
   Chehab O, 2022, NEURONS BEHAV DATA A, V0, P0, DOI DOI 10.51628/001c.38668
   Claassen J, 2019, NEW ENGL J MED, V380, P2497, DOI 10.1056/NEJMoa1812757
   Cruse D, 2011, LANCET, V378, P2088, DOI 10.1016/S0140-6736(11)61224-5
   Dash D, 2019, IEEE ENG MED BIO, V0, PP5531, DOI 10.1109/EMBC.2019.8857874
   Dash D, 2018, LECT NOTES ARTIF INT, V11309, P163, DOI 10.1007/978-3-030-05587-5_16
   Dauphin YN, 2017, PR MACH LEARN RES, V70, P0
   Fernandino L, 2022, P NATL ACAD SCI USA, V119, P0, DOI 10.1073/pnas.2108091119
   Ganesh A, 2022, FRONT HUM NEUROSCI, V16, P0, DOI 10.3389/fnhum.2022.874199
   García-Salinas JS, 2019, BIOMED SIGNAL PROCES, V50, P151, DOI 10.1016/j.bspc.2019.01.006
   Gauthier J, 2019, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.1910.01244
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, P0, DOI 10.3389/fnins.2013.00267
   Gwilliams L, 2022, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2208.11488
   Gwilliams L, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-34326-1
   HAMALAINEN M, 1993, REV MOD PHYS, V65, P413, DOI 10.1103/RevModPhys.65.413
   Haxby JV, 2020, ELIFE, V9, P0, DOI 10.7554/eLife.56601
   Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736
   He Xu, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS AND NETWORK TECHNOLOGIES (CSNT 2012), V0, PP229, DOI 10.1109/CSNT.2012.57
   Hendrycks D, 2016, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1606.08415
   Herff C, 2015, FRONT NEUROSCI-SWITZ, V9, P0, DOI 10.3389/fnins.2015.00217
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Horikawa T, 2017, NAT COMMUN, V8, P0, DOI 10.1038/ncomms15037
   Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637
   Ide N, 2010, P ACL 2010 C SHORT P, V0, P68
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Jahangiri A, 2018, 2018 40 ANN INT C IE, V0, P0
   Jas M, 2017, NEUROIMAGE, V159, P417, DOI 10.1016/j.neuroimage.2017.06.030
   Jayaram V, 2018, J NEURAL ENG, V15, P0, DOI 10.1088/1741-2552/aadea0
   Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444
   King JR, 2013, NEUROIMAGE, V83, P726, DOI 10.1016/j.neuroimage.2013.07.013
   King Jean-Remi, 2020, COGNI NEUROSCI, V6, P691
   Kingma DP, 2014, C TRACK P, V0, P0
   Kohler J, 2021, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2111.01457
   Koizumi K, 2018, IEEE ENG MED BIO, V0, PP1062, DOI 10.1109/EMBC.2018.8512520
   Komeiji S, 2022, INT CONF ACOUST SPEE, V0, PP1311, DOI 10.1109/ICASSP43922.2022.9747443
   Krishna G, 2020, INT CONF ACOUST SPEE, V0, PP1235, DOI 10.1109/icassp40776.2020.9053340
   Kübler A, 2001, PSYCHOL BULL, V127, P358, DOI 10.1037//0033-2909.127.3.358
   LAWHERN VJ, 2018, J NEURAL ENG, V15, P0, DOI 10.1088/1741-2552/AACE8C
   Lopopolo A, 2020, PREPRINT, V0, P0, DOI DOI 10.31234/osf.io/6gqj8
   Martin S, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep25803
   Mermelstein P, 1976, 1976 JOINT WORKSHOP ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V0, P0
   Metzger SL, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-33611-3
   Millet J, 2022, ADV NEURAL INF PROCE, V35, P33428
   Millet J, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7591
   Miyawaki Y, 2008, NEURON, V60, P915, DOI 10.1016/j.neuron.2008.11.004
   Moinnereau M-A, 2018, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.1804.10322
   Moses DA, 2021, NEW ENGL J MED, V385, P217, DOI 10.1056/NEJMoa2027540
   Murphy A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2201
   Nguyen CH, 2018, J NEURAL ENG, V15, P0, DOI 10.1088/1741-2552/aa8235
   Nishimoto S, 2011, CURR BIOL, V21, P1641, DOI 10.1016/j.cub.2011.08.031
   Orpella J, 2022, BIORXIV, V0, P0, DOI DOI 10.1101/2022.05.30.494046
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Owen AM, 2006, SCIENCE, V313, P1402, DOI 10.1126/science.1130197
   Ozcelik F, 2023, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2303.05334
   Panachakel JT, 2021, FRONT NEUROSCI-SWITZ, V15, P0, DOI 10.3389/fnins.2021.642251
   Pascual D, 2022, INT CONF ACOUST SPEE, V0, PP1476, DOI 10.1109/ICASSP43922.2022.9747137
   Pasley BN, 2012, PLOS BIOL, V10, P0, DOI 10.1371/journal.pbio.1001251
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pei XM, 2011, J NEURAL ENG, V8, P0, DOI 10.1088/1741-2560/8/4/046028
   Pels EGM, 2017, NEUROREHAB NEURAL RE, V31, P677, DOI 10.1177/1545968317714577
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Roy Y, 2019, J NEURAL ENG, V16, P0, DOI 10.1088/1741-2552/ab260c
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Schoffelen JM, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0020-y
   Schwenk H, 2017, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.1704.04154
   Sree RA, 2017, 2017 4 INT C SIGN PR, V0, P1
   STANGER CA, 1996, TECHNOL DISABIL, V5, P125
   Stavisky SD, 2018, IEEE ENG MED BIO, V0, PP93, DOI 10.1109/EMBC.2018.8512199
   Sun P, 2016, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.1612.05369
   Tang JRY, 2023, NAT NEUROSCI, V0, P0, DOI DOI 10.1038/s41593-023-01304-9
   Thomas A, 2022, ADV NEURAL INF PROCE, V35, P21255
   Vaidya AR, 2022, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2205.14252
   Willett FR, 2021, NATURE, V593, P249, DOI 10.1038/s41586-021-03506-2
   Yang YY, 2022, INT CONF ACOUST SPEE, V0, PP6982, DOI 10.1109/ICASSP43922.2022.9747236
   Young S, 2002, HTK BOOK, V0, P0
NR 94
TC 1
Z9 1
U1 4
U2 4
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD OCT 15
PY 2023
VL 5
IS 10
BP 1097
EP +
DI 10.1038/s42256-023-00714-5
EA OCT 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA U6NR3
UT WOS:001076205100003
DA 2023-11-10
ER

PT J
AU Demir, S
AF Demir, Seniz
TI Turkish Data-to-Text Generation Using Sequence-to-Sequence Neural Networks
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Data-to-text generation; sequence-to-sequence model; Turkish; Wikipedia
ID natural-language generation; of-the-art
AB End-to-end data-driven approaches lead to rapid development of language generation and dialogue systems. Despite the need for large amounts of well-organized data, these approaches jointly learn multiple components of the traditional generation pipeline without requiring costly human intervention. End-to-end approaches also enable the use of loosely aligned parallel datasets in system development by relaxing the degree of semantic correspondences between training data representations and text spans. However, their potential in Turkish language generation has not yet been fully exploited. In this work, we apply sequenceto-sequence (Seq2Seq) neural models to Turkish data-to-text generation where the input data given in the form of a meaning representation is verbalized. We explore encoder-decoder architectures with attention mechanism in unidirectional, bidirectional, and stacked recurrent neural network (RNN) models. Our models generate one-sentence biographies and dining venue descriptions using a crowdsourced dataset where all field value pairs that appear in meaning representations are fully captured in reference sentences. To support this work, we also explore the performances of our models on a more challenging dataset, where the content of a meaning representation is too large to fit into a single sentence, and hence content selection and surface realization need to be learned jointly. This dataset is retrieved by coupling introductory sentences of person-related Turkish Wikipedia articles with their contained infobox tables. Our empirical experiments on both datasets demonstrate that Seq2Seq models are capable of generating coherent and fluent biographies and venue descriptions from field value pairs. We argue that the wealth of knowledge residing in our datasets and the insights obtained fromthis study hold the potential to give rise to the development of new end-to-end generation approaches for Turkish and other morphologically rich languages.
C1 [Demir, Seniz] MEF Univ, Dept Comp Engn, Maslak Ayazaga Caddesi, TR-34396 Istanbul, Turkiye.
C3 MEF Universitesi
RP Demir, S (通讯作者)，MEF Univ, Dept Comp Engn, Maslak Ayazaga Caddesi, TR-34396 Istanbul, Turkiye.
EM demirse@mef.edu.tr
FU TUBITAK-ARDEB [117E977]
CR Angeli G, 2010, P 2010 C EMPIRICAL M, V0, P502
   [Anonymous], 2002, P 2 INT C HUMAN LANG, V0, P0
   Ayan Burcu Karagol, 2000, P COLING STUDENT SES, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, V0, PP65, DOI 10.3115/1626355.1626389
   Barzilay R, 2005, P C HUM LANG TECHN E, V0, PP331, DOI 10.3115/1220575.1220617
   Bateman John A, 1990, P INF SCI I, V0, P0
   Belz Anja, 2005, P 10 EUROPEAN WORKSH, V0, P15
   Birant Cagdas Can, 2016, INT J COMPUTER APPL, V144, P23
   Biswas Russa, 2018, P 1STWORKSHOP DEEP L, V0, P0
   Channarukul S, 2001, INT J UNCERTAIN FUZZ, V9, P649
   Chen DL, 2008, P 25 INT C MACH LEAR, V0, PP128, DOI 10.1145/1390156.1390173
   Chen Shuang, 2018, P E2E NLG CHALL SYST, V0, P0
   Chen ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P183
   Chisholm A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P633
   Cicekli Ilyas, 1998, P JOINT C NEW METHOD, V0, P165
   Colin E, 2016, P 9 INT NAT LANG GEN, V0, P163
   Daza A, 2018, REPRESENTATION LEARNING FOR NLP, V0, P207
   Demir Seniz, 2022, COMPUT SPEECH LANG, V0, P0
   Dogan E, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP), V0, P0
   Duma Daniel, 2013, P 10 INT C COMPUTATI, V0, P83
   Dusek O, 2020, COMPUT SPEECH LANG, V59, P123, DOI 10.1016/j.csl.2019.06.009
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Ferreira TC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P552
   Fuad TA, 2019, COMPUT SPEECH LANG, V58, P216, DOI 10.1016/j.csl.2019.04.006
   Gao Hanning, 2021, P 29 INT JOINT C ART, V0, P0
   Gardent C, 2017, P 10 INT C NAT LANG, V0, P0
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gehrmann S, 2018, P 11 INT C NATURAL L, V0, P46
   Ghaddar A, 2016, CONLL, V0, PP229, DOI 10.18653/V1/K16-1023
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Gong H, 2020, P 28 INT C COMP LING, V0, PP1978, DOI 10.18653/V1/2020.COLING-MAIN.179
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Güran A, 2013, TURK J ELECTR ENG CO, V21, P1411, DOI 10.3906/elk-1201-15
   Hakkani Dilek Zeynep, 1996, DESIGN IMPLEMENTATIO, V0, P0
   Harris M, 2008, P 5 INT NAT LANG GEN, V0, P157
   Hewlett D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1535
   Hsu WN, 2016, IEEE W SP LANG TECH, V0, PP467, DOI 10.1109/SLT.2016.7846305
   Kawashima T, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), V0, PP43, DOI 10.1145/3350546.3352499
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Konstas I, 2013, P 2013 C EMPIRICAL M, V0, P1503
   Kutlu M, 2010, COMPUT J, V53, P1315, DOI 10.1093/comjnl/bxp124
   Kutlugun Mehmet Ali, 2018, P 26 SIGNAL PROCESSI, V0, P1
   Kuyu M, 2018, SIG PROCESS COMMUN, V0, P0
   Kuyu Menekse, 2019, SIG PROCESS COMMUN, V0, P0
   Lampouras G, 2018, ARXIV, V0, P0
   Lange D, 2010, P 19 ACM INT C INFOR, V0, P1661
   Langkilde-Geary Irene, 2002, P INT C NAT LANG GEN, V0, P17
   Lebret Remi, 2016, P 2016 C EMP METH NA, V0, PP1203, DOI 10.18653/v1/D16-1128
   Li G, 2019, P 3 WORKSH NEUR GEN, V0, P148
   Li J, 2021, P 30 INT JOINT C ART, V0, P4492
   Liang P, 2009, P JOINT C 47 ANN M A, V0, PP91, DOI 10.1007/978-3-642-02374-3_6
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu TY, 2018, AAAI CONF ARTIF INTE, V0, P4881
   Mahapatra J, 2016, P 9 INT NATURAL LANG, V0, P143
   Mairesse F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P1552
   Mairesse F, 2014, COMPUT LINGUIST, V40, P763, DOI 10.1162/coli_a_00199
   Malouf R, 2017, MORPHOLOGY, V27, P431, DOI 10.1007/s11525-017-9307-x
   Mangrulkar S, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), V0, P191
   Manishina E, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3624
   Manishina Elena, 2016, THESIS U AVIGNON FRA, V0, P0
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Mrabet Yassine, 2016, P 2 INT WORKSHOP NAT, V0, P29
   Nokinova J, 2016, P 9 INT NATURAL LANG, V0, P265
   Nuzumlali MY, 2014, P C EMPIRICAL METHOD, V0, P702
   ODonnell M, 2001, NATURAL LANGUAGE ENGINEERING, V7, P225
   Oflazer Kemal, 2018, TURKISH NATURAL LANG, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Perez-Beltrachini Laura, 2018, P 2018 C N AM CHAPT, V1, P1516, DOI 10.18653/V1/N18-1137
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, V0, PP392, DOI 10.1080/1472586x.2015.1113070.
   Portet F, 2009, ARTIF INTELL, V173, P789, DOI 10.1016/j.artint.2008.12.002
   Prabhavalkar R, 2017, INTERSPEECH, V0, PP939, DOI 10.21437/Interspeech.2017-233
   Puduppully R, 2019, AAAI CONF ARTIF INTE, V0, P6908
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rebuffel Clement, 2020, P ADV INF RETR, V0, P65
   Reiter E, 1997, NATURAL LANGUAGE ENGINEERING, V3, P57, DOI 10.1017/S1351324997001502
   Ritter A, 2011, P C EMPIRICAL METHOD, V0, P583
   Sankarasubramaniam Y, 2014, INFORM PROCESS MANAG, V50, P443, DOI 10.1016/j.ipm.2014.02.001
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sha L, 2018, AAAI CONF ARTIF INTE, V0, P5414
   Shimorina A, 2018, PROC 11 INT C NATURA, V0, P360
   Socher R, 2011, P 28 INT C MACHINE L, V0, P129
   Sripada Somayajulu, 2003, P CORPUS LINGUISTICS, V0, P734
   Suadaa LH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1451
   Temizsoy Murat, 1998, P NATURAL LANGUAGE G, V0, P188
   Tran VK, 2018, P 27 INT C COMPUTATI, V0, P1205
   Trisedya Bayu Distiawan, 2021, IEEE T PATTERN ANAL, V0, P1
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   Tran VK, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), V0, P231
   Vardar UF, 2019, P 27 SIGNAL PROCESSI, V0, P1
   Vaswani A, 2017, P 31 INT C NEUR INF, V0, P6000
   Wang R, 2018, ACM T ASIAN LOW-RESO, V17, P0, DOI 10.1145/3203078
   Wen TH, 2020, COMPUT SPEECH LANG, V63, P0, DOI 10.1016/j.csl.2019.06.008
   Wen Tsung-Hsien, 2015, P 2015 C EMPIRICAL M, V0, PP1711, DOI 10.18653/v1/D15-1199
   Yermakov Ruslan, 2021, INLG, V0, P364
   Yildiz T, 2019, TURK J ELECTR ENG CO, V27, P1052, DOI 10.3906/elk-1806-185
   Yu Seunghak, 2017, P 1 WORKSHOP SUBWORD, V0, P92
   Zhang X, 2014, P 2014 C EMP METH NA, V0, PP670, DOI 10.3115/V1/D14-1074
   Zhou LW, 2018, PROC CVPR IEEE, V0, PP8739, DOI 10.1109/CVPR.2018.00911
   Zhu CG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1261
NR 103
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB 15
PY 2023
VL 22
IS 2
BP 
EP 
DI 10.1145/3543826
PG 27
WC Computer Science, Artificial Intelligence
SC Computer Science
GA C7AF6
UT WOS:000963394900006
DA 2023-11-10
ER

PT J
AU Cao, FF
   Huang, XM
AF Cao, Feifei
   Huang, Xiaomin
TI Performance analysis of aspect-level sentiment classification task based on different deep learning models
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Deep learning; Aspect-based sentiment classification; Comment datasets; Perfor-mance analysis; Neural network models; Pre-trained language models
AB Aspect-level sentiment classification task (ASCT) is a natural language processing task that aims to correctly identify specific aspects and determine their sentiment polarity from a given target sentence. Deep learning models have been proven to be effective in aspect-based sentiment classification tasks, and the mainstream Aspect level sentiment classification (ASC) models currently constructed generally assume that the training and test datasets are Gaussian distribution (e.g., the same language). Once the data distribution changes, the ASC model must be retrained on the new distribution data to achieve good performance. However, acquiring a large amount of labeled data again typically requires a lot of manpower and money, which seems unlikely, especially for the ASC task, as it requires aspect-level annotation. This article analyzes the performance of sequence-based models, graph-based convolutional neural networks, and pre-training language models on the aspect-level sentiment classification task using two sets of comment datasets in Chinese and English, from four perspectives: classification performance, performance with different aspect numbers, specific case performance, and computational cost. In this article, we design a state-of-the-art ASCbased classification method and conduct a systematic study on eight public standard English and Chinese datasets with various commonly used assessment measures that provide directions for cross-language migration. Finally, we discuss the limitations of the study as well as future research directions.
C1 [Cao, Feifei; Huang, Xiaomin] Guangdong Peizheng Coll, Sch Econ, Guangzhou, Peoples R China.
RP Cao, FF; Huang, XM (通讯作者)，Guangdong Peizheng Coll, Sch Econ, Guangzhou, Peoples R China.
EM caoff16@lzu.edu.cn; hxmzy315@126.com
CR Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549
   Brun C, 2014, PROC SEMEVAL WORKSHO, V0, P838
   Bu JH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2069
   Cai HJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P340
   Chen CH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5596
   Chen Peng, 2017, P 2017 C EMP METH NA, V0, PP452, DOI 10.18653/V1/D17-1047
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai JQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P1816
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Gu S, 2018, P 27 INT C COMPUTATI, V0, P774
   Jiang L, 2011, PROC 49 ANN M ASS CO, V0, P151
   Jiang QN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6280
   Kim Y, 2014, ARXIV, V0, P0
   Kiritchenko S, 2014, PROC 8 INT WORKSHOP, V0, PP437, DOI 10.3115/V1/S14-2076
   Li CL, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P180, DOI 10.1109/WI-IAT.2014.96
   Li R, 2021, P 59 ANN M ASS COMP, V1, P6319, DOI 10.18653/V1/2021.ACL-LONG.494
   Li X, 2019, PROC 5 WORKSHOP NOIS, V0, P34
   Li X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P946
   Liu B, 2011, DATA CENTRIC SYST AP, V0, PP459, DOI 10.1007/978-3-642-19460-3_11
   Liu HY, 2020, IEEE T COMPUT SOC SY, V7, P1358, DOI 10.1109/TCSS.2020.3033302
   Liu J, 2017, PROC IEEE 31 INT C T, V2, P572
   Liu Q, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1023, DOI 10.1145/3178876.3186001
   Liu T, 2016, PROC INT C COMPUT LI, V0, P0
   Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4068
   Ma YK, 2018, AAAI CONF ARTIF INTE, V0, P5876
   Majumdert N, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3402
   Marcheggiani Diego, 2014, ADVANCES IN INFORMATION RETRIEVAL. 36TH EUROPEAN CONFERENCE ON IR RESEARCH, V0, P273, DOI 10.1007/978-3-319-06028-6_23
   Nazir A, 2022, IEEE T AFFECT COMPUT, V13, P845, DOI 10.1109/TAFFC.2020.2970399
   Nguyen TH, 2015, P 2016 C EMP METH NA, V0, P2509
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pontiki M, 2014, P 8 INT WORKSHOP SEM, V0, PP27, DOI 10.3115/v1/s14-2004
   Pontiki M, 2016, P 10 INT WORKSH SEM, V0, PP19, DOI 10.18653/V1/S16-1002
   Pontiki Maria, 2015, P 9 INT WORKSH SEM E, V0, PP486, DOI 10.18653/v1/s15-2082
   Poria S, 2023, IEEE T AFFECT COMPUT, V14, P108, DOI 10.1109/TAFFC.2020.3038167
   Qiu XP, 2021, ARXIV, V0, P0
   Ruder S, 2016, PROC C EMPIRICAL MET, V0, P999
   Sabour S, 2017, ADV NEURAL INFORM PR, V1, P3856, DOI 10.5555/3294996.3295142
   Saeidi M, 2016, P COLING 2016 26 INT, V0, P1546
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Sun C, 2019, ARXIV, V0, P0
   Tan SB, 2008, EXPERT SYST APPL, V34, P2622, DOI 10.1016/j.eswa.2007.05.028
   Tang Hao, 2020, P 58 ANN M ASS COMP, V0, PP6578, DOI 10.18653/V1/2020.ACL-MAIN.588
   Tay Y, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP107, DOI 10.1145/3132847.3132936
   Tian YH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2910
   Toh Z, 2016, PROC 10 INT WORKSHOP, V0, PP282, DOI 10.18653/V1/S16-1045
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P417
   Wang JJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3548
   Wang Y, 2016, PROCEEDINGS OF THE 2016 SECOND CONFERENCE ON MOBILE AND SECURE SERVICES (MOBISECSERV), V0, P0
   WenyaWang Sinno Jialin Pan, 2016, ARXIV160306679, V0, P0
   Wu ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4166
   Xing BW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5313
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   Zagibalov T, 2008, P 3 INT JOINT C NAT, V0, P0
   Zeng JF, 2019, IEEE ACCESS, V7, P20462, DOI 10.1109/ACCESS.2019.2893806
   Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4568
   Zhang M, 2015, PROC C EMPIRICAL MET, V0, PP612, DOI 10.18653/v1/d15-1073
   Zhang MS, 2016, AAAI CONF ARTIF INTE, V0, P3087
   Zhang W, 2022, IEEE T AFFECT COMPUT, V0, P0
   Zhang WX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P9209
   Zheng SL, 2018, ARXIV, V0, P0
   Zhou J, 2019, IEEE ACCESS, V7, P78454, DOI 10.1109/ACCESS.2019.2920075
NR 62
TC 0
Z9 0
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD OCT 9
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1578
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA U6UB2
UT WOS:001086124900003
PM 37869455
DA 2023-11-10
ER

PT J
AU Maurya, KK
   Desarkar, MS
   Gupta, M
   Agrawal, P
AF Maurya, Kaushal Kumar
   Desarkar, Maunendra Sankar
   Gupta, Manish
   Agrawal, Puneet
TI TRIE-NLG: trie context augmentation to improve personalized query auto-completion for short and unseen prefixes
SO DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Article
DE TRIE-NLG; Natural Language Generation; Query Auto Completion; AutoSuggest; Transformers; Pre-trained Models
ID information
AB Query auto-completion (QAC) aims at suggesting plausible completions for a given query prefix. Traditionally, QAC systems have leveraged tries curated from historical query logs to suggest most popular completions. In this context, there are two specific scenarios that are difficult to handle for any QAC system: short prefixes (which are inherently ambiguous) and unseen prefixes. Recently, personalized Natural Language Generation (NLG) models have been proposed to leverage previous session queries as context for addressing these two challenges. However, such NLG models suffer from two drawbacks: (1) some of the previous session queries could be noisy and irrelevant to the user intent for the current prefix, and (2) NLG models cannot directly incorporate historical query popularity. This motivates us to propose a novel NLG model for QAC, TRiE-NLG, which jointly leverages popularity signals from trie and personalization signals from previous session queries. We train the TRiE-NLG model by augmenting the prefix with rich context comprising of recent session queries and top trie completions. This simple modeling approach overcomes the limitations of trie-based and NLG-based approaches, and leads to state-of-theart performance. We evaluate the TRiE-NLG model using two large QAC datasets. On average, our model achieves huge similar to 57% and similar to 14% boost in MRR over the popular trie-based lookup and the strong BART-based baseline methods, respectively. We make our code publicly available at https://github.com/kaushal0494/Trie-NLG.
C1 [Maurya, Kaushal Kumar; Desarkar, Maunendra Sankar] IIT Hyderabad, Hyderabad 502284, Telangana, India.
   [Gupta, Manish; Agrawal, Puneet] Microsoft India, Hyderabad 500032, Telangana, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Hyderabad
RP Maurya, KK (通讯作者)，IIT Hyderabad, Hyderabad 502284, Telangana, India.
EM cs18resch11003@iith.ac.in; maunendra@cse.iith.ac.in; gmanish@microsoft.com; punagr@microsoft.com
FU Microsoft Academic Partnership Grant 2022
CR Bar-Yossef Z, 2011, P 20 INT C WORLD WID, V0, PP107, DOI 10.1145/1963405.1963424
   Bhatia S, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR11), V0, P795
   Bonchi F, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP345, DOI 10.1145/2348283.2348332
   Burges Christopher, 2010, LEARNING, V11, P0, DOI 10.1111/J.1467-8535.2010.01085.X
   Cai F, 2016, QUERY AUTOCOMPLETION, V0, P0
   Cai F, 2014, P 23 ACM INT C C INF, V0, PP1599, DOI 10.1145/2661829.2661921
   Dehghani M, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP1747, DOI 10.1145/3132847.3133010
   Gehman Samuel, 2020, FINDINGS ASS COMPUTA, V0, P3356
   Hofmann K, 2014, P 23 ACM INT C C INF, V0, PP549, DOI 10.1145/2661829.2661922
   Hsu B-J, 2013, P 22 INT C WORLD WID, V0, P583
   Huang CK, 2003, J AM SOC INF SCI TEC, V54, P638, DOI 10.1002/asi.10256
   Jiang JY, 2014, SIGIR14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P445
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Lewis Patrick, 2020, ADV NEURAL INFORM PR, V33, P9459, DOI 10.48550/ARXIV.2005.11401
   Maxwell D, 2017, P AUSTR DOC COMP S, V0, P1
   Mei Qiaozhu, 2008, P 17 ACM C INF KNOWL, V0, PP469, DOI 10.1145/1458082.1458145
   Mitra B, 2015, P 24 ACM INT C INF K, V0, PP1755, DOI 10.1145/2806416.2806599
   Mitra B, 2014, SIGIR14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1055, DOI 10.1145/2600428.2609508
   Mustar Agnes, 2020, JOINT C INF RETR COM, V0, P0
   Park DH, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1189, DOI 10.1145/3077136.3080758
   Pass G, 2006, INFOSCALE 06, V0, P1
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rosset C, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1193, DOI 10.1145/3209978.3210127
   Sadikov Eldar, 2010, P 19 INT C WORLD WID, V0, PP841, DOI 10.1145/1772690.1772776
   Shokouhi M, 2013, SIGIR13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P103
   Shokouhi M, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP601, DOI 10.1145/2348283.2348364
   Sordoni Alessandro, 2015, P 24 ACM INT C INFOR, V0, P553
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang P-W, 2018, ECOM SIGIR, V0, P0
   Wu QA, 2010, INFORM RETRIEVAL, V13, P254, DOI 10.1007/s10791-009-9112-1
   Yadav N, 2021, KDD 21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP3835, DOI 10.1145/3447548.3467087
   Yin D, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2998, DOI 10.1145/3394486.3403350
   Zhou GR, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1059, DOI 10.1145/3219819.3219823
NR 33
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1384-5810
EI 1573-756X
J9 DATA MIN KNOWL DISC
JI Data Min. Knowl. Discov.
PD NOV 15
PY 2023
VL 37
IS 6
BP 2306
EP 2329
DI 10.1007/s10618-023-00966-0
EA AUG 2023
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA U2YC6
UT WOS:001044191200002
DA 2023-11-10
ER

PT J
AU Zhang, ZH
   Liang, XN
   Zuo, Y
   Li, ZJ
AF Zhang, Zhihao
   Liang, Xinnian
   Zuo, Yuan
   Li, Zhoujun
TI Unsupervised abstractive summarization via sentence rewriting
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Unsupervised abstractive summarization; Sentence rewrite model; Pre-trained language model; Coherence text
AB Unsupervised extractive summarization aims to extract salient sentences from the document without labeled corpus. Existing methods have achieved promising progress, thanks to the power of large-scale pre-trained language models and high-quality contextualized represen-tations. However, extractive summaries often fail to maintain smooth transitions between sentences and struggle to form a coherent and fluent text due to splicing of sentences. Nevertheless, to the best of our knowledge, very few studies currently focus on unsupervised abstractive summarization. Inspired by the intuitive human process of writing summaries, which involves extracting salient sentences first and then reconstructing them, in this paper, we propose an Extract-then-Abstract framework to generate more coherent and human-like summary. Specifically, we first adopt extractive summarization model as summarizer to generate extractive summary in the extraction stage. Then in the abstraction stage, we propose a BART-based sentence write model to generate more coherent and fluent abstractive summary. To this end, we design a novel parallel data creation method for our rewrite model by proposing an effective sentence sampling strategy without any manual annotation cost. Extensive experi-ments including automatic evaluation and human evaluation demonstrate that our framework consistently outperforms strong baselines for unsupervised abstractive summarization and can generate more coherent and human-like summary while maintaining in competitive ROUGE scores for unsupervised extractive summarization.
C1 [Zhang, Zhihao; Zuo, Yuan] Beihang Univ, Sch Econ & Management, Beijing, Peoples R China.
   [Liang, Xinnian; Li, Zhoujun] Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Zuo, Y (通讯作者)，Beihang Univ, Sch Econ & Management, Beijing, Peoples R China.
EM zuoyuan@buaa.edu.cn
CR Baziotis C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P673
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cheng JP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P484
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Gehrmann S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4098
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Jing HY, 1999, SIGIR99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP129, DOI 10.1145/312624.312666
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li JJ, 2016, P 17 ANN M SPECIAL I, V0, P137
   Liang X, 2021, IEEE ACM T AUDIO SPE, V0, P0
   Liang Xinnian, 2021, FINDINGS ASS COMPUTA, V0, P1685
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P150
   Liu Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1745
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3730
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Nallapati R, 2017, AAAI CONF ARTIF INTE, V0, P3075
   Narayan S, 2018, P 2018 C N AM CHAPT, V1, P1747, DOI 10.18653/V1/N18-1158
   Petroni F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2523
   Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang D, 2020, P 58 ANN M ASS COMP, V0, PP6209, DOI 10.18653/V1/2020.ACL-MAIN.553
   Wang YS, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4187
   Yang Z, 2020, FINDINGS ASS COMPUTA, V0, P0, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.168
   Zhang XX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5059
   Zheng H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6236
NR 27
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR 15
PY 2023
VL 78
IS 
BP 
EP 
DI 10.1016/j.csl.2022.101467
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K6VE2
UT WOS:001017792100001
DA 2023-11-10
ER

PT J
AU Fang, LT
   Luo, Y
   Feng, KY
   Zhao, KQ
   Hu, AQ
AF Fang, Lanting
   Luo, Yong
   Feng, Kaiyu
   Zhao, Kaiqi
   Hu, Aiqun
TI A Knowledge-Enriched Ensemble Method for Word Embedding and Multi-Sense Embedding
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Task analysis; Context modeling; Semantics; Bit error rate; Knowledge engineering; Wheels; Vocabulary; Word embedding; multi-sense embedding; knowledge graph; ensemble model
AB Representing words as embeddings has been proven to be successful in improving the performance in many natural language processing tasks. Different from the traditional methods that learn the embeddings from large text corpora, ensemble methods have been proposed to leverage the merits of pre-trained word embeddings as well as external semantic sources. In this paper, we propose a knowledge-enriched ensemble method to combine information from both knowledge graphs and pre-trained word embeddings. Specifically, we propose an attention network to retrofit the semantic information in the lexical knowledge graph into the pre-trained word embeddings. In addition, we further extend our method to contextual word embeddings and multi-sense embeddings. Extensive experiments demonstrate that the proposed word embeddings outperform the state-of-the-art models in word analogy, word similarity and several downstream tasks. The proposed word sense embeddings outperform the state-of-the-art models in word similarity and word sense induction tasks.
C1 [Fang, Lanting; Hu, Aiqun] Southeast Univ, Sch Cyber Sci & Engn, Purple Mt Labs, Nanjing 211189, Peoples R China.
   [Luo, Yong] Wuhan Univ, Inst Artificial Intelligence, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
   [Luo, Yong] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Hubei, Peoples R China.
   [Feng, Kaiyu] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100811, Peoples R China.
   [Zhao, Kaiqi] Univ Auckland, Sch Comp Sci, Auckland 1010, New Zealand.
C3 Southeast University - China; Wuhan University; Wuhan University; Beijing Institute of Technology; University of Auckland
RP Fang, LT (通讯作者)，Southeast Univ, Sch Cyber Sci & Engn, Purple Mt Labs, Nanjing 211189, Peoples R China.; Feng, KY (通讯作者)，Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100811, Peoples R China.
EM lantingf@outlook.com; yluo180@gmail.com; kaiyufeng@outlook.com; kaiqi.zhao@auckland.ac.nz; aqhu@seu.edu.cn
FU National Natural Science Foundation of China [61906039]; Youth Scholar Program of SEU; Jiangsu Provincial Key Laboratory of Network and Information Security
CR [Anonymous], 2015, P 2015 C N AM CHAPTE, V0, P0, DOI DOI 10.3115/V1/N15-1070
   [Anonymous], 1995, RES DESIGN STAT ANAL, V0, P0
   [Anonymous], 2003, SIGIR 03 P 26 ANN IN, V0, P0, DOI DOI 10.1145/860435.860445
   Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Cam LML, 1967, P 5 BERK S MATH STAT, V0, P0
   Cao YX, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1623, DOI 10.18653/v1/P17-1149
   Chang Kai-Wei, 2013, P 2013 C EMP METH NA, V0, P1602
   Chen YQ, 2013, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   Fang LT, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP427, DOI 10.1145/3308558.3313425
   Faruqui Manaal, 2015, P 2015 C N AM CHAPT, V0, PP1606, DOI 10.3115/v1/N15-1184
   Finkelstein L, 2001, WWW, V0, P0
   Ganesh P, 2020, ARXIV, V0, P0
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Gong Y, 2016, AAAI CONF ARTIF INTE, V0, P2615
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Hill F, 2014, ARXIV, V0, P0
   Hu LM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4821
   Huang EH, 2012, ACL, V1, P873
   Huang WB, 2018, ADV NEUR IN, V31, P0
   Jurgens David, 2013, 2 JOINT C LEXICAL CO, V2, P290
   Khamsi MA, 2011, INTRO METRIC SPACES, V53, P0
   Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP39, DOI 10.1145/3397271.3401075
   Lee Y-Y, 2018, PROC 27 INT C COMPUT, V0, P1662
   Levy Omer, 2014, P COMPUTATIONAL NATU, V0, P0, DOI DOI 10.3115/V1/W14-1618
   Li YJ, 2017, ARXIV, V0, P0
   Luo Y, 2014, AAAI CONF ARTIF INTE, V0, P1982
   Luong T, 2013, P 17 C COMP NAT LANG, V0, PP104, DOI 10.1007/BF02579642
   Mikolov T, 2013, ARXIV, V0, P0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Mitra B, 2016, ARXIV, V0, P0
   Murom„gi A, 2017, ARXIV, V0, P0
   Nakov P, 2019, ARXIV, V0, P0
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, V0, PP1059, DOI 10.3115/V1/D14-1113
   Nickel M, 2011, ICML, V0, PP809, DOI 10.5555/3104482.3104584
   Panigrahi A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5692
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Phan X-H, 2008, P 17 INT C WORLD WID, V0, P91
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P567
   Reisinger J, 2010, HUMAN LANGUAGE TECHN, V0, P109
   Rosenberg A, 2007, EMNLP, V0, P410
   Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793
   Roy A, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4929
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sia S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1728
   Socher R, 2013, LONG PAPERS, V1, P455
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Xu C, 2014, P 23 ACM INT C CONFE, V0, PP1219, DOI 10.1145/2661829.2662038
   Xu J, 2015, P 1 WORKSHOP VECTOR, V0, P62
   Yang L, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP287, DOI 10.1145/2983323.2983818
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, PP2013, DOI 10.18653/V1/D15-1237
   Yin WP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1351
   Yu M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P545, DOI 10.3115/v1/p14-2089
   Zhou J, 2021, ARXIV, V0, P0
NR 60
TC 0
Z9 0
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD JUN 1
PY 2023
VL 35
IS 6
BP 5534
EP 5549
DI 10.1109/TKDE.2022.3159539
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA F4GJ7
UT WOS:000981944600007
DA 2023-11-10
ER

PT J
AU Sachan, DS
   Lewis, M
   Yogatama, D
   Zettlemoyer, L
   Pineau, J
   Zaheer, M
AF Sachan, Devendra Singh
   Lewis, Mike
   Yogatama, Dani
   Zettlemoyer, Luke
   Pineau, Joelle
   Zaheer, Manzil
TI Questions Are All You Need to Train a Dense Passage Retriever
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We introduce ART, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data. Dense retrieval is a central challenge for open-domain tasks, such as Open QA, where state-of-the-art methods typically require large supervised datasets with custom hard-negative mining and denoising of positive examples. ART, in contrast, only requires access to unpaired inputs and outputs (e.g., questions and potential answer passages). It uses a new passage-retrieval autoencoding scheme, where (1) an input question is used to retrieve a set of evidence passages, and (2) the passages are then used to compute the probability of reconstructing the original question. Training for retrieval based on question reconstruction enables effective unsupervised learning of both passage and question encoders, which can be later incorporated into complete Open QA systems without any further finetuning. Extensive experiments demonstrate that ART obtains state-of-the-art results on multiple QA retrieval benchmarks with only generic initialization from a pre-trained language model, removing the need for labeled data and task-specific losses.(1)
C1 [Sachan, Devendra Singh; Pineau, Joelle] McGill Univ, Montreal, PQ, Canada.
   [Sachan, Devendra Singh; Pineau, Joelle] Mila Quebec AI Inst, Montreal, PQ, Canada.
   [Lewis, Mike; Zettlemoyer, Luke; Pineau, Joelle] Meta AI, New York, NY USA.
   [Yogatama, Dani; Zaheer, Manzil] Google DeepMind, Mountain View, CA USA.
   [Zettlemoyer, Luke] Univ Washington, Seattle, WA USA.
C3 McGill University; University of Washington; University of Washington Seattle
RP Sachan, DS (通讯作者)，McGill Univ, Montreal, PQ, Canada.; Sachan, DS (通讯作者)，Mila Quebec AI Inst, Montreal, PQ, Canada.
EM sachande@mila.quebec; mikelewis@meta.com; dyogatama@google.com; lsz@meta.com; jpineau@meta.com; manzilzaheer@google.com
CR Asai A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P547
   Bajaj P, 2018, ARXIV, V0, P0
   Berant J, 2013, P 2013 C EMPIRICAL M, V0, P0
   Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP2387, DOI 10.1145/3477495.3531863
   Bromley J, 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Chowdhery A, 2022, ARXIV, V0, P0
   Clark JH, 2020, T ASSOC COMPUT LING, V8, P454, DOI 10.1162/tacl_a_00317
   Dai Z, 2022, INT C MACH LEARN, V0, P4558
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gao Luyu, 2022, P 60 ANN M ASS COMP, V0, P0, DOI DOI 10.18653/v1/2022.acl-long.203
   Gillick Daniel, 2019, P 23 C COMP NAT LANG, V0, PP528, DOI 10.18653/V1/K19-1049
   Guu K, 2020, PR MACH LEARN RES, V119, P0
   Humeau Samuel, 2020, 8 INT C LEARN REPR I, V0, P0
   Izacard Gautier, 2021, ICLR, V0, P0
   Izacard Gautier, 2022, T MACHINE LEARNING R, V0, P0
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Khattab O, 2021, T ASSOC COMPUT LING, V9, P929, DOI 10.1162/tacl_a_00405
   Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP39, DOI 10.1145/3397271.3401075
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6086
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3045
   Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158
   Lindgren Erik, 2021, ADV NEURAL INFORM PR, V0, P0
   Luan Y, 2021, T ASSOC COMPUT LING, V9, P329, DOI 10.1162/tacl_a_00369
   Ma J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1075
   Mao YN, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4089
   Neelakantan A, 2022, ARXIV, V0, P0
   Nogueira R, 2020, ARXIV, V0, P0
   Nogueira Rodrigo, 2020, FINDINGS ASS COMPUTA, V0, PP708, DOI 10.18653/V1/2020.FINDINGS-EMNLP.63
   Qu YQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5835
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Ram Ori, 2022, P 2022 C N AM CHAPT, V0, P0, DOI DOI 10.18653/v1/2022.naacl-main.193
   Ren RY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P2825
   Robertson Stephen, 2009, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V3, P333, DOI 10.1561/1500000019
   Sachan D, 2021, P 59 ANN M ASS COMPU, V1, P6648
   Sachan Devendra Singh, 2022, P 2022 C EMPIRICAL M, V0, P0, DOI DOI 10.48550/arXiv.2204.07496
   Sachan DS, 2021, ADV NEURAL INFORM PR, V0, P0
   Sanh Victor, 2022, INT C LEARN REPR, V0, P0
   Santos CNdos, 2020, P 2020 C EMP METH NA, V0, P0, DOI DOI 10.18653/v1/2020.emnlp-main.134
   Sciavolino Christopher, 2021, P 2021 C EMP METH NA, V0, P0, DOI DOI 10.18653/v1/2021.emnlp-main.496
   Thakur Nandan, 2021, 35 C NEUR INF PROC S, V0, P0
   van den Oord A, 2019, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Xiong Lee, 2021, INT C LEARN REPR, V0, P0
   Yates A, 2021, SIGIR 21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP2666, DOI 10.1145/3404835.3462812
   Zhang H, 2022, INT C LEARNING REPRE, V0, P0
   Zhou Jiawei, 2022, P 60 ANN M ASS COMP, V0, P0, DOI DOI 10.18653/v1/2022.acl-long.493
NR 49
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 20
PY 2023
VL 11
IS 
BP 600
EP 616
DI 10.1162/tacl_a_00564
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA K6WM4
UT WOS:001017826500003
DA 2023-11-10
ER

PT J
AU Moon, J
   Posada-Quintero, HF
   Chon, KH
AF Moon, Jihye
   Posada-Quintero, Hugo F.
   Chon, Ki H.
TI Genetic data visualization using literature text-based neural networks: Examples associated with myocardial infarction
SO NEURAL NETWORKS
LA English
DT Article
DE Explainable Artificial Intelligence; Natural language processing; Unsupervised learning; Cross -modal representation; Data visualization; Cardiovascular Disease risk prediction
ID dimensionality reduction; metaanalysis; model
AB Data visualization is critical to unraveling hidden information from complex and high-dimensional data. Interpretable visualization methods are critical, especially in the biology and medical fields, however, there are limited effective visualization methods for large genetic data. Current visualization methods are limited to lower-dimensional data and their performance suffers if there is missing data. In this study, we propose a literature-based visualization method to reduce high-dimensional data without compromising the dynamics of the single nucleotide polymorphisms (SNP) and textual interpretability. Our method is innovative because it is shown to (1) preserves both global and local structures of SNP while reducing the dimension of the data using literature text representations, and (2) enables interpretable visualizations using textual information. For performance evaluations, we examined the proposed approach to classify various classification categories including race, myocardial infarction event age groups, and sex using several machine learning models on the literature-derived SNP data. We used visualization approaches to examine clustering of data as well as quantitative performance metrics for the classification of the risk factors examined above. Our method outperformed all popular dimensionality reduction and visualization methods for both classification and visualization, and it is robust against missing and higher-dimensional data. Moreover, we found it feasible to incorporate both genetic and other risk information obtained from literature with our method.& COPY; 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Moon, Jihye; Posada-Quintero, Hugo F.; Chon, Ki H.] Univ Connecticut, Dept Biomed Engn, Storrs, CT 06269 USA.
   [Moon, Jihye] Univ Connecticut Storrs, Biomed Engn Dept, Engn & Sci Bldg ESB,Room 407, Storrs, CT 06269 USA.
C3 University of Connecticut; University of Connecticut
RP Moon, J (通讯作者)，Univ Connecticut Storrs, Biomed Engn Dept, Engn & Sci Bldg ESB,Room 407, Storrs, CT 06269 USA.
EM jihye.moon@uconn.edu; hugo.posada-quintero@uconn.edu; ki.chon@uconn.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Al-Husain L, 2015, 2015 IEEE C COMPUTAT, V0, PP1, DOI 10.1109/CIBCB.2015.7300305
   Allaoui M, 2020, INT C IM SIGN PROC, V5, P317, DOI 10.1007/978-3-030-51935-3_34
   Allen L, 2021, PATTERNS, V2, P0, DOI 10.1016/j.patter.2021.100266
   Amalia Amalia, 2020, 2020 INTERNATIONAL CONFERENCE ON DATA SCIENCE, V0, P0
   Ambroziak M, 2020, BMC CARDIOVASC DISOR, V20, P0, DOI 10.1186/s12872-020-01677-w
   Bang JU, 2022, INT CONF ACOUST SPEE, V0, PP6227, DOI 10.1109/ICASSP43922.2022.9746117
   Baud A, 2017, PLOS GENET, V13, P0, DOI 10.1371/journal.pgen.1006498
   Bingham E, 2001, KDD-2001. PROCEEDINGS OF THE SEVENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP245, DOI 10.1145/502512.502546
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Borah A, 2021, PROCEEDINGS OF THE 32ND ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT 21), V0, PP45, DOI 10.1145/3465336.3475098
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Chen IY, 2006, J BIOL CHEM, V281, P19369, DOI 10.1074/jbc.M601443200
   Cheng LM, 2022, J PHARMACOKINET PHAR, V49, P39, DOI 10.1007/s10928-021-09785-6
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   de Bakker PIW, 2008, HUM MOL GENET, V17, PR122, DOI 10.1093/hmg/ddn288
   De R, 2015, BIODATA MIN, V8, P0, DOI 10.1186/s13040-015-0074-0
   Deagen ME, 2022, SCI DATA, V9, P0, DOI 10.1038/s41597-022-01352-z
   Devore JL, 1995, PROBABILITY STAT ENG, V0, P0
   Diaz-Papkovich A, 2021, J HUM GENET, V66, P85, DOI 10.1038/s10038-020-00851-4
   Diaz-Papkovich A, 2019, PLOS GENET, V15, P0, DOI 10.1371/journal.pgen.1008432
   Dong FN, 2018, AM J HUM GENET, V102, P636, DOI 10.1016/j.ajhg.2018.03.007
   Dong W, 2023, IEEE T IND INFORM, V19, P2385, DOI 10.1109/TII.2022.3156658
   Dong YP, 2017, PROC CVPR IEEE, V0, PP975, DOI 10.1109/CVPR.2017.110
   Dorrity MW, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-15351-4
   Duan W, 2020, AM J PHYSIOL-HEART C, V318, PH566, DOI 10.1152/ajpheart.00739.2018
   Durrschnabel D, 2022, COMPLEX DATA ANALYTI, V0, PP47, DOI 10.1007/978-3-030-93278-7_3
   Egecioglu Ö, 2004, IEEE T KNOWL DATA EN, V16, P714, DOI 10.1109/TKDE.2004.9
   Elgart M, 2022, COMMUN BIOL, V5, P0, DOI 10.1038/s42003-022-03812-z
   Foody GM, 2009, REMOTE SENS ENVIRON, V113, P1658, DOI 10.1016/j.rse.2009.03.014
   Fuhrman JD, 2022, MED PHYS, V49, P1, DOI 10.1002/mp.15359
   Garcia M, 2021, J AM HEART ASSOC, V10, P0, DOI 10.1161/JAHA.121.020828
   Gola D, 2020, GENET EPIDEMIOL, V44, P125, DOI 10.1002/gepi.22279
   GOLUB GH, 1996, MATRIX COMPUTATIONS, V0, P0, DOI DOI 10.56021/9781421407944
   Gould DB, 2000, GENOMICS, V68, P336, DOI 10.1006/geno.2000.6307
   Hajar Rachel, 2017, HEART VIEWS, V18, P109, DOI 10.4103/HEARTVIEWS.HEARTVIEWS_106_17
   Huang HY, 2022, COMMUN BIOL, V5, P0, DOI 10.1038/s42003-022-03628-x
   Jayasena CN, 2021, DIAGNOSTICS, V11, P0, DOI 10.3390/diagnostics11091550
   Johnson W, 1984, EXTENSIONS LIPSCHITZ, V0, PP189, DOI 10.1090/CONM/026/737400
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, P0, DOI 10.1098/rsta.2015.0202
   Jombart T, 2008, HEREDITY, V101, P92, DOI 10.1038/hdy.2008.34
   Kowsher M, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12062848
   Kramer Andreas, 2022, BIOINFORM ADV, V2, Pvbac022, DOI 10.1093/bioadv/vbac022
   Kuyumcu B, 2019, NLPIR 2019: 2019 3RD INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, V0, PP1, DOI 10.1145/3342827.3342828
   Lan ZZ, 2020, ARXIV, V0, P0
   Lee AK, 2016, PSYCHOL HEALTH, V31, P578, DOI 10.1080/08870446.2015.1127373
   Lee SR, 2019, CARCINOGENESIS, V40, P1031, DOI 10.1093/carcin/bgz107
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Li JH, 2014, BRIEF BIOINFORM, V15, P1057, DOI 10.1093/bib/bbt082
   Li WT, 2017, J BIOINF COMPUT BIOL, V15, P0, DOI 10.1142/S0219720017500172
   Li XM, 2021, MACH LEARN, V110, P1029, DOI 10.1007/s10994-021-05962-3
   Locke S, 2021, TRENDS ANAESTH CRIT, V38, P4, DOI 10.1016/j.tacc.2021.02.007
   Martinez-Rico JR, 2019, ENG APPL ARTIF INTEL, V78, P248, DOI 10.1016/j.engappai.2018.11.012
   McInnes Leland, 2020, ARXIV, V0, P0
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mimno David, 2017, P 2017 C EMPIRICAL M, V0, PP2873, DOI 10.18653/v1/D17-1308
   Monk B, 2021, FRONT GENET, V12, P0, DOI 10.3389/fgene.2021.647436
   Moon J, 2023, EXPERT SYST APPL, V213, P0, DOI 10.1016/j.eswa.2022.118930
   Moon J, 2021, IEEE ENG MED BIO, V0, PP1946, DOI 10.1109/EMBC46164.2021.9630039
   Moon J, 2019, 2019 34TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, V0, P537, DOI 10.1109/itc-cscc.2019.8793299
   Moon KR, 2019, NAT BIOTECHNOL, V37, P1482, DOI 10.1038/s41587-019-0336-3
   Morris JA, 2010, BIOINFORMATICS, V26, P1786, DOI 10.1093/bioinformatics/btq280
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   ODonoghue SI, 2018, ANNU REV BIOMED DA S, V1, P275, DOI 10.1146/annurev-biodatasci-080917-013424
   Pan ZW, 2012, CIRCULATION, V126, P840, DOI 10.1161/CIRCULATIONAHA.112.094524
   Patel N, 2015, IEEE INT C BIOINFORM, V0, PP1367, DOI 10.1109/BIBM.2015.7359878
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Peterson RE, 2019, CELL, V179, P589, DOI 10.1016/j.cell.2019.08.051
   Pottmeier P, 2020, STEM CELLS DEV, V29, P1497, DOI 10.1089/scd.2020.0138
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Raucci A, 2019, CELL MOL LIFE SCI, V76, P211, DOI 10.1007/s00018-018-2930-9
   Reisberg S, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0179238
   Roy D, 2018, CIKM18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP1835, DOI 10.1145/3269206.3269277
   Rozanec JM, 2022, INFORM FUSION, V81, P91, DOI 10.1016/j.inffus.2021.11.015
   Sakaue S, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-15194-z
   Sang ST, 2022, IEEE ACM T COMPUT BI, V19, P1294, DOI 10.1109/TCBB.2020.3003947
   Seda O, 2005, FOLIA BIOL-PRAGUE, V51, P53
   Shanks MO, 2012, PLOS ONE, V7, P0, DOI 10.1371/journal.pone.0046316
   Shibata N, 2022, HEART VESSELS, V37, P1363, DOI 10.1007/s00380-022-02035-w
   Shimizu R, 2022, KNOWL-BASED SYST, V239, P0, DOI 10.1016/j.knosys.2021.107970
   Silva PP, 2022, SCI REP-UK, V12, P0, DOI 10.1038/s41598-022-19708-1
   Song XY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P2089
   Soumare H, 2021, BIODATA MIN, V14, P0, DOI 10.1186/s13040-021-00258-7
   Spencer R, 2020, DIGIT HEALTH, V6, P0, DOI 10.1177/2055207620914777
   Suhaili SM, 2021, EXPERT SYST APPL, V184, P0, DOI 10.1016/j.eswa.2021.115461
   Thioulouse J, 1995, ENVIRON ECOL STAT, V2, P1, DOI 10.1007/BF00452928
   Tiddi I, 2022, ARTIF INTELL, V302, P0, DOI 10.1016/j.artint.2021.103627
   van der Ende MY, 2018, CARDIOVASC RES, V114, P1209, DOI 10.1093/cvr/cvy083
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Dyke M, 2018, MMWR SURVEILL SUMM, V67, P1, DOI 10.15585/mmwr.ss6705a1
   Van Wyngene L, 2021, ISCIENCE, V24, P0, DOI 10.1016/j.isci.2021.102790
   Wang B, 2019, APSIPA TRANS SIGNAL, V8, P0, DOI 10.1017/ATSIP.2019.12
   Wang SR, 2020, COMPUTING, V102, P717, DOI 10.1007/s00607-019-00768-7
   Wendlandt L, 2018, P NAACL HLT, V0, PP2092, DOI 10.18653/v1/N18-1190
   Wolf T, 2020, PROCESSING, V0, P0
   Wu Yonghui, 2022, T MACHINE LEARNING R, V3, P8
   Yang CH, 2018, BIOINFORMATICS, V34, P2228, DOI 10.1093/bioinformatics/bty076
   Yao L, 2017, ENG APPL ARTIF INTEL, V64, P432, DOI 10.1016/j.engappai.2017.06.024
   Yin Z, 2006, AM J PHYSIOL-LUNG C, V291, PL191, DOI 10.1152/ajplung.00385.2005
   Zhang Y, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW22), V0, PP912, DOI 10.1145/3485447.3512008
   Zhou B, 2023, INT J PROD RES, V61, P4117, DOI 10.1080/00207543.2021.2022803
NR 105
TC 0
Z9 0
U1 1
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD AUG 15
PY 2023
VL 165
IS 
BP 562
EP 595
DI 10.1016/j.neunet.2023.05.015
PG 34
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA Q5YO0
UT WOS:001058278800001
PM 37364469
DA 2023-11-10
ER

PT J
AU Li, GM
   Wang, H
   Ding, Y
   Zhou, KG
   Yan, XW
AF Li, Guangmin
   Wang, Hui
   Ding, Yi
   Zhou, Kangan
   Yan, Xiaowei
TI Data augmentation for aspect-based sentiment analysis
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Sentiment analysis; Text classification; Data augmentation; Deep learning; Dependency syntax
AB In recent years, deep learning has been widely used in the field of natural language processing (NLP), achieving spectacular successes in various NLP tasks. These successes are largely due to its capability to automatically learn feature representations from text data. However, the performance of deep learning in NLP can be negatively affected by a lack of sufficiently large labeled corpus for training, resulting in limited improvement in performance. Data augmentation overcomes this small data problem by expanding the sample size for the classes of data in the training corpus. This paper introduces the data augmentation for aspect-based sentiment analysis (ABSA), a classical research topic in NLP that has been applied in various fileds. The study aims to enhance the classification performance of ABSA through various augmentation strategies. Two specific augmentation strategies are presented, part-of-speech (PoS) wise synonym substitution (PWSS) and dependency relation-based word swap (DRAWS), which augment data using PoS, external domain knowledge, and syntactic dependency. These strategies are evaluated through extensive experimentation on four public datasets using three representative deep learning models-aspect-specific graph convolutional network (ASGCN), content attention-based aspect-based sentiment classification (CABASC), and long short-term memory (LSTM) network. Compared with the results without data augmentation, our augmentation strategies achieve a performance gain of up to 11.49% on Macro-F1, with the lowest gain being 2.9%. The experimental results demonstrate that the proposed data augmentation strategies are very useful for training deep learning models on small data corpus.
C1 [Li, Guangmin; Ding, Yi; Zhou, Kangan] Hubei Normal Univ, Sch Comp & Informat Engn, Huangshi, Hubei, Peoples R China.
   [Li, Guangmin] Hubei Normal Univ, Sch Arts & Sci, Huangshi, Hubei, Peoples R China.
   [Wang, Hui] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast, Antrim, North Ireland.
   [Yan, Xiaowei] China Univ Geosci, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
C3 Hubei Normal University; Hubei Normal University; Queens University Belfast; China University of Geosciences
RP Li, GM (通讯作者)，Hubei Normal Univ, Sch Comp & Informat Engn, Huangshi, Hubei, Peoples R China.; Li, GM (通讯作者)，Hubei Normal Univ, Sch Arts & Sci, Huangshi, Hubei, Peoples R China.
EM finsite@gmail.com
FU Natural Science Foundation of Hubei Province of China [2020CFB828]; Hubei Normal University Research Project on Teaching Reform [XJ202001]; Teaching Research Project of Hubei Normal University [2019030]; Research Project of Young Teachers in Hubei Normal University [HS2020QN029]; Science and Technology Research Project of Hubei Department of Education
CR Anaby-Tavor A, 2010, P AAAI C ARTIFICIAL, V4, P0
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Fellbaum C, 2012, ENCY APPL LINGUISTIC, V0, P0, DOI DOI 10.1002/9781405198431.wbeal1285
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hu Z, 2017, PR MACH LEARN RES, V0, P0
   Jeni LA, 2013, INT CONF AFFECT, V0, PP245, DOI 10.1109/ACII.2013.47
   Johnson JM, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0192-5
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Liu Q, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1023, DOI 10.1145/3178876.3186001
   López V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Miao Z, 2010, P WEB C 2020, V0, P0
   Mueller J, 2016, AAAI CONF ARTIF INTE, V0, P2786
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   ROBINSON JJ, 1970, LANGUAGE, V46, P259, DOI 10.2307/412278
   Thabtah F, 2020, INFORM SCIENCES, V513, P429, DOI 10.1016/j.ins.2019.11.004
   Wang, 1900, V11, V0, P0
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6382
   Xu CL, 2021, NEUROCOMPUTING, V434, P11, DOI 10.1016/j.neucom.2020.12.074
NR 30
TC 4
Z9 4
U1 1
U2 17
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD JAN 15
PY 2023
VL 14
IS 1
BP 125
EP 133
DI 10.1007/s13042-022-01535-5
EA MAY 2022
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 8C1OT
UT WOS:000797269800002
DA 2023-11-10
ER

PT J
AU Dimitriadis, D
   Tsoumakas, G
AF Dimitriadis, Dimitris
   Tsoumakas, Grigorios
TI Enhancing yes/no question answering with weak supervision via extractive question answering
SO APPLIED INTELLIGENCE
LA English
DT Article; Early Access
DE Question answering; Yes/no question answering; Extractive question answering; Transformers
AB The effectiveness of natural language processing models relies on various factors, including the architecture, number of parameters, data used during training, and the tasks they were trained on. Recent studies indicate that models pre-trained on large corpora and fine-tuned on task-specific datasets, covering multiple tasks, can generate remarkable results across various benchmarks. We propose a new approach based on a straightforward hypothesis: improving model performance on a target task by considering other artificial tasks defined on the same training dataset. By doing so, the model can gain further insights into the training dataset and attain a greater understanding, improving efficiency on the target task. This approach differs from others that consider multiple pre-existing tasks on different datasets. We validate this hypothesis by focusing on the problem of answering yes/no questions and introducing a multi-task model that outputs a span of the reference text, serving as evidence for answering the question. The task of span extraction is an artificial one, designed to benefit the performance of the model answering yes/no questions. We acquire weak supervision for these spans, by using a pre-trained extractive question answering model, dispensing the need for costly human annotation. Our experiments, using modern transformer-based language models, demonstrate that this method outperforms the standard approach of training models to answer yes/no questions. Although the primary objective was to enhance the performance of the model in answering yes/no questions, it was discovered that span texts are a significant source of information. These spans, derived from the question reference texts, provided valuable insights for the users to better comprehend the answers to the questions. The model's improved accuracy in answering yes/no questions, coupled with the supplementary information provided by the span texts, led to a more comprehensive and informative user experience.
C1 [Dimitriadis, Dimitris; Tsoumakas, Grigorios] Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Dimitriadis, D (通讯作者)，Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki 54124, Greece.
EM dndimitri@csd.auth.gr; greg@csd.auth.gr
FU National Infrastructures for Research and Technology S.A.
CR Arora S, 2022, ARXIV, V0, P0
   Black S, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), V0, P95
   Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gao L, 2020, ARXIV, V0, P0
   He Pengcheng, 2020, ARXIV200603654, V0, P0
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Luo M, 2022, ARXIV, V0, P0
   Martin JH, 2009, SPEECH LANGUAGE PROC, V0, P0
   Nishida K, 2019, ANSWERING SUMMARIZIN, V0, P0
   Paramasivam A, 2022, J KING SAUD UNIV-COM, V34, P9644, DOI 10.1016/j.jksuci.2021.11.017
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Phang J, 2019, ARXIV, V0, P0
   Poli M, 2023, ARXIV, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar P, 2016, ARXIV, V0, P0
   Rajpurkar P, 2018, ARXIV, V0, P0
   Roy A, 2022, ARXIV, V0, P0
   Soltan S, 2022, ARXIV, V0, P0
   Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3645
   Tam D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P4980
   Touvron H, 2023, ARXIV, V0, P0
   Wang AL, 2019, ARXIV, V0, P0
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wang HF, 2023, ENGINEERING-PRC, V25, P51, DOI 10.1016/j.eng.2022.04.024
   Wang SN, 2021, ARXIV, V0, P0
   Wei J, 2022, INT C LEARN REPR, V0, P0
   Wolf T, 2020, ARXIV, V0, P0
   Wu SJ, 2023, ARXIV, V0, P0
   Zhao WX, 2023, ARXIV, V0, P0
NR 32
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10489-023-04751
EA SEP 2023
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA R9SA0
UT WOS:001067664200001
DA 2023-11-10
ER

PT J
AU Nguyen, NH
   Vo, DTD
   Nguyen, KV
   Nguyen, NLT
AF Nguyen, Nghia Hieu
   Vo, Duong T. D.
   Nguyen, Kiet Van
   Nguyen, Ngan Luu-Thuy
TI OpenViVQA: Task, dataset, and multimodal fusion models for visual question answering in Vietnamese
SO INFORMATION FUSION
LA English
DT Article
DE Visual question answering; Vision-language understanding; Low-resource languages; Information fusion; Multimodal representation
ID attention
AB In recent years, visual question answering (VQA) has attracted attention from the research community because of its highly potential applications (such as virtual assistance on intelligent cars, assistant devices for blind people, or information retrieval from document images using natural language as queries) and challenge. The VQA task requires methods that have the ability to fuse the information from questions and images to produce appropriate answers. Neural visual question answering models have achieved tremendous growth on large-scale datasets which are mostly for resource-rich languages such as English. However, available datasets narrow the VQA task as the answers selection task or answer classification task. We argue that this form of VQA is far from human ability and eliminates the challenge of the answering aspect in the VQA task by just selecting answers rather than generating them. In this paper, we introduce the OpenViVQA (Open-domain Vietnamese Visual Question Answering) dataset, the first large-scale dataset for VQA with open-ended answers in Vietnamese, consists of 11,000+ images associated with 37,000+ question-answer pairs (QAs). Moreover, we proposed FST, QuMLAG, and MLPAG which fuse information from images and questions, then use these fused features to construct answers as humans iteratively. Our proposed methods achieve results that are competitive with SOTA models such as SAAA, MCAN, LORA, and M4C. The dataset1 is available to encourage the research community to develop more generalized algorithms including transformers for low-resource languages such as Vietnamese.
C1 Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.
   Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
   [Nguyen, Kiet Van] Vietnam Natl Univ, Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City; Vietnam National University Hochiminh City
RP Nguyen, KV (通讯作者)，Vietnam Natl Univ, Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.
EM kietvn@uit.edu.vn
FU Vietnam National University HoChiMinh City (VNU-HCM) [C2023-26-08]
CR Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2005, P ACL WORKSHOP INTRI, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, ARXIV, V0, P0
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Borisyuk F, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP71, DOI 10.1145/3219819.3219861
   Changpinyo S, 2023, ARXIV, V0, P0
   Cho JM, 2020, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Ganesan Kavita, 2018, ARXIV, V0, P0
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Li LH, 2019, ARXIV, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Honnibal Matthew, 2017, SPACY 2 NATURAL LANG, V0, P0
   Hu R, 2020, P IEEE CVF C COMP VI, V0, PP9992, DOI 10.1109/CVPR42600.2020.01001
   Huang MX, 2022, PROC CVPR IEEE, V0, PP4583, DOI 10.1109/CVPR52688.2022.00455
   Huang ZC, 2020, ARXIV, V0, P0
   Jiang H, 2020, P IEEE CVF C COMP VI, V0, P10267
   Kantharaj S, 2022, ARXIV, V0, P0
   Kazemi V, 2017, SHOW ASK ATTEND ANSW, V0, P0
   Iwana BK, 2017, ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Nguyen LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), V0, P1
   Lu JS, 2022, ARXIV, V0, P0
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Lu JS, 2016, ADV NEUR IN, V29, P0
   Luong MT, 2015, ARXIV, V0, P0
   Mathew M, 2021, IEEE WINT CONF APPL, V0, PP2199, DOI 10.1109/WACV48630.2021.00225
   Mishra A, 2019, 2019 INT C DOC AN RE, V0, PP947, DOI 10.1109/ICDAR.2019.00156
   Nguyen N, 2021, P IEEE C COMPUTER VI, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Ren S, 2015, P ADV NEUR INF PROC, V28, P1, DOI 10.1109/TPAMI.2016.2577031
   Singh A, 2019, PROC CVPR IEEE, V0, PP8309, DOI 10.1109/CVPR.2019.00851
   Su WJ, 2020, ARXIV, V0, P0
   Tan H, 2019, ARXIV, V0, P0
   Tanaka R, 2021, AAAI CONF ARTIF INTE, V35, P13878
   Teney D, 2018, PROC CVPR IEEE, V0, PP4223, DOI 10.1109/CVPR.2018.00444
   Tran KQ, 2021, P 35 PACIFIC ASIA C, V0, P546
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vu T, 2018, P 2018 C N AM CHAPT, V0, P56
   Wang ZR, 2022, ARXIV, V0, P0
   Worley P, 2015, J PHILOS SCH, V0, P0
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Zhang DX, 2019, INFORM FUSION, V52, P268, DOI 10.1016/j.inffus.2019.03.005
   Zhang PC, 2021, PROC CVPR IEEE, V0, PP5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhang WF, 2020, INFORM FUSION, V55, P116, DOI 10.1016/j.inffus.2019.08.009
   Zheng WB, 2021, INFORM FUSION, V67, P14, DOI 10.1016/j.inffus.2020.10.007
NR 59
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD DEC 15
PY 2023
VL 100
IS 
BP 
EP 
DI 10.1016/j.inffus.2023.101868
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA P5DF2
UT WOS:001050867700001
DA 2023-11-10
ER

PT J
AU Xu, FZ
   Lin, QK
   Liu, J
   Zhang, LL
   Zhao, TZ
   Chai, Q
   Pan, YD
   Huang, Y
   Wang, QY
AF Xu, Fangzhi
   Lin, Qika
   Liu, Jun
   Zhang, Lingling
   Zhao, Tianzhe
   Chai, Qi
   Pan, Yudai
   Huang, Yi
   Wang, Qianying
TI MoCA: Incorporating domain pretraining and cross attention for textbook question answering
SO PATTERN RECOGNITION
LA English
DT Article
DE Textbook question answering; Multimodal; Pretraining; Attention
AB Textbook Question Answering (TQA) is a complex multimodal task to infer answers given large context descriptions and abundant diagrams. Compared with Visual Question Answering (VQA), TQA contains a large number of uncommon terminologies and various diagram inputs. It brings new challenges to the representation capability of language model for domain-specific spans. Also, it requires the model to take fully advantage of the complementary information of different diagram types, which pushes the multimodal fusion task to a more complex level. To tackle the above issues, we propose a novel model named MoCA, which incorporates M ulti-stage d o main pretraining and C ross-guided multimodal A ttention for the TQA task. Firstly, we introduce a multi-stage domain pretraining module to conduct unsupervised post-pretraining with a span mask strategy and supervised pre-finetune. Especially for domain postpretraining, we propose a heuristic generation algorithm to employ the terminology corpus. Secondly, to fully consider the rich inputs of context and diagrams, we propose a cross-guided multimodal attention mechanism to update the features of text, question diagram and instructional diagram based on a progressive strategy. Further, a dual gating mechanism is adopted to improve the model ensemble of three background retrievals. The experimental results show the superiority of our model, which outperforms the state-of-the-art methods on the validation and test split respectively. Also, ablation and comparison experiments verify the effectiveness of each module proposed in our model. (c) 2023 Elsevier Ltd. All rights reserved.
C1 [Xu, Fangzhi; Lin, Qika; Liu, Jun; Zhang, Lingling; Zhao, Tianzhe; Chai, Qi; Pan, Yudai] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian 710049, Shaanxi, Peoples R China.
   [Liu, Jun; Zhang, Lingling; Chai, Qi; Pan, Yudai] Xi An Jiao Tong Univ, Shaanxi Prov Key Lab Big Data Knowledge Engn, Xian 710049, Shaanxi, Peoples R China.
   [Xu, Fangzhi; Lin, Qika; Zhao, Tianzhe] Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian 710049, Shaanxi, Peoples R China.
   [Huang, Yi] JIUTIAN Team, China Mobile Res, Singapore, Singapore.
   [Wang, Qianying] Lenovo Res, Beijing, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University; Legend Holdings; Lenovo
RP Liu, J (通讯作者)，Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian 710049, Shaanxi, Peoples R China.; Liu, J (通讯作者)，Xi An Jiao Tong Univ, Shaanxi Prov Key Lab Big Data Knowledge Engn, Xian 710049, Shaanxi, Peoples R China.
EM Leo981106@stu.xjtu.edu.cn; liukeen@xjtu.edu.cn
FU National Key Research and Development Program of China [2022YFC3303600]; National Natu- ral Science Foundation of China [62137002, 62293550, 62293553, 62277042, 619370 01, 62250 0 6 6, 62176209, 62106190]; Innovative Research Group of the National Natural Science Foundation of China [61721002]; Intelligent Industry Joint Laboratory Project; CCF-Lenovo Blue Ocean Research Fund, Foundation of Key National Defense Science and Technology Laboratory [6142101210201]; Natural Science Basic Research Program of Shaanxi [2023-JC-YB-293]; Youth Innovation Team of Shaanxi Universities; Fundamental Research Funds for the Central Universities [xhj032021013-02]; XJTU Teaching Reform Research Project
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Brown TB, 2020, ARXIV, V0, P0
   Ben-younes H, 2017, IEEE I CONF COMP VIS, V0, PP2631, DOI 10.1109/ICCV.2017.285
   Cao QX, 2021, IEEE T PATTERN ANAL, V43, P887, DOI 10.1109/TPAMI.2019.2943456
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy Alexey, 2021, ICLR, V0, P0
   Gomez-Perez JM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5469
   Gu YX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6966
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, V0, PP8342, DOI 10.18653/V1/2020.ACL-MAIN.740
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Kembhavi A, 2017, PROC CVPR IEEE, V0, PP5376, DOI 10.1109/CVPR.2017.571
   Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15
   Kim D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3568
   Kim JH, 2016, ADV NEURAL INFORM PR, V0, PP361, DOI 10.48550/ARXIV.1606.01455
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3045
   Li JZ, 2018, PROC CVPR IEEE, V0, PP3655, DOI 10.1109/CVPR.2018.00385
   Liu YH, 2019, ARXIV, V0, P0
   Ma J, 2020, ABS201112662 CORR, V0, P0
   Ma J, 2022, IEEE T IMAGE PROCESS, V31, P7378, DOI 10.1109/TIP.2022.3180563
   Ma J, 2023, IEEE T NEUR NET LEAR, V34, P15, DOI 10.1109/TNNLS.2021.3089140
   Manmadhan S, 2020, ARTIF INTELL REV, V53, P5705, DOI 10.1007/s10462-020-09832-7
   Gomez-Perez JM, 2019, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE (K-CAP 19), V0, PP101, DOI 10.1145/3360901.3364420
   Ngiam Jiquan, 2011, ICML, V0, PP2, DOI 10.5555/3104482.3104569
   Noh H, 2016, PROC CVPR IEEE, V0, PP30, DOI 10.1109/CVPR.2016.11
   Saito K, 2017, IEEE INT CON MULTI, V0, PP829, DOI 10.1109/ICME.2017.8019436
   Vaswani A, 2017, ARXIV, V30, P5998
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Yu J, 2020, PATTERN RECOGN, V108, P0, DOI 10.1016/j.patcog.2020.107563
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Zheng WF, 2021, PATTERN RECOGN, V120, P0, DOI 10.1016/j.patcog.2021.108153
NR 34
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD AUG 15
PY 2023
VL 140
IS 
BP 
EP 
DI 10.1016/j.patcog.2023.109588
EA APR 2023
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA F3MC1
UT WOS:000981408300001
DA 2023-11-10
ER

PT J
AU Huang, B
   Zhang, S
   Huang, JT
   Yu, YJ
   Shi, ZC
   Xiong, YJ
AF Huang, Bo
   Zhang, Shuai
   Huang, Jitao
   Yu, Yijun
   Shi, Zhicai
   Xiong, Yujie
TI Knowledge distilled pre-training model for vision-language-navigation
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Natural language processing; Computer vision; Cross-modality; Deep learning
AB Vision-language-navigation(VLN) is a challenging task that requires a robot to autonomously move to a destination based on visual observation following a human's natural language instructions. To improve the performance and generalization ability, the pre-training model based on the transformer is used instead of the traditional methods. However, the pre-training model is not suitable for sustainable computing and practical application because of its complex computations and large amount of hardware occupation. Therefore, we propose a slight pre-training model through knowledge distillation. Through knowledge distillation, the plenty of knowledge encoded in a large "teacher" model can be well transferred to a small "student" model, which greatly reduces the model parameters and inference time while maintaining the original performance. In the experiments, the model size is reduced by 87%, and the average inference time is reduced by approximately 86%. It can be trained and run much faster. At the same time, 95% performance of the original model was maintained, which is still better than the traditional VLN models.
C1 [Huang, Bo; Zhang, Shuai; Yu, Yijun; Xiong, Yujie] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai, Peoples R China.
   [Huang, Jitao; Shi, Zhicai] China Telecom Corp Ltd, Shanghai Branch, Shanghai, Peoples R China.
   Shanghai Key Lab Integrated Adm Technol Informat, Shanghai, Peoples R China.
C3 Shanghai University of Engineering Science; China Telecom Corp. Ltd.
RP Huang, B (通讯作者)，Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai, Peoples R China.
EM huangbosues@sues.edu.cn; 854400656@qq.com; 421024976@qq.com; 1210947362@qq.com; szc1964@163.com; xiong@sues.edu.cn
FU Scientific and Technological Innovation 2030 - Major Project of New Generation Artificial Intelligence [2020AAA0109300]; Shanghai Science and Technology Young Talents Sailing Program [19YF1418400]; National Natural Science Foundation of China [62006150]; Shanghai Science and Technology Innovation Action Plan [22S31903700, 21S31904200]; Songjiang District Science and Technology Research Project [19SJKJGG83]; Shanghai Local Capacity Enhancement Project [21010501500]
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP3674, DOI 10.1109/CVPR.2018.00387
   Cao J, 2020, EUROPEAN C COMPUTER, V0, P0
   Catelli R, 2020, APPL SOFT COMPUT, V97, P0, DOI 10.1016/j.asoc.2020.106779
   Chi PH, 2021, IEEE W SP LANG TECH, V0, PP344, DOI 10.1109/SLT48900.2021.9383575
   Fried D, 2018, ARXIV 180602724, V0, P0
   Ganesh P, 2021, T ASSOC COMPUT LING, V9, P1061, DOI 10.1162/tacl_a_00413
   Guarasci R, 2021, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-021-03297-4
   Hao Weituo, 2020, P IEEE CVF C COMP VI, V0, PP13137, DOI 10.1109/CVPR42600.2020.01315
   He Y, 2020, PROC CVPR IEEE, V0, PP2006, DOI 10.1109/CVPR42600.2020.00208
   Hinton G, 2014, NEURIPS DEEP LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1503.02531
   Hubara I, 2018, J MACH LEARN RES, V18, P0
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Landi F, 2021, COMPUT VIS IMAGE UND, V210, P0, DOI 10.1016/j.cviu.2021.103255
   Li X, 2019, ARXIV 190902244, V0, P0
   Liu GY, 2021, IEEE T NEUR NET LEAR, V32, P3786, DOI 10.1109/TNNLS.2021.3099165
   Liu Wenjie, 2021, IEEE T NEUR NET LEAR, V0, P0
   Liu Y, 2020, NEUROCOMPUTING, V415, P106, DOI 10.1016/j.neucom.2020.07.048
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Nguyen K, 2019, ARXIV 190901871, V0, P0
   Pota M, 2021, EXPERT SYST APPL, V181, P0, DOI 10.1016/j.eswa.2021.115119
   Riaz N, 2021, 2021 INTERNATIONAL CONFERENCE ON DIGITAL FUTURES AND TRANSFORMATIVE TECHNOLOGIES (ICODT2), V0, P0, DOI DOI 10.1109/ICoDT252288.2021.9441516
   Sanh V, 2019, ARXIV 191001108, V0, P0
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Tan H, 2019, ARXIV 190404195, V0, P0
   Vapnik V, 2015, J MACH LEARN RES, V16, P2023
   Wang XD, 2022, IEEE T CYBERNETICS, V52, P13293, DOI 10.1109/TCYB.2021.3130047
   Wu MC, 2020, J SYST ARCHITECT, V103, P0, DOI 10.1016/j.sysarc.2019.101695
   Xin Wang, 2019, 2019 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP6622, DOI 10.1109/CVPR.2019.00679
   Yeom SK, 2021, PATTERN RECOGN, V115, P0, DOI 10.1016/j.patcog.2021.107899
   Yi Zhu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10727, DOI 10.1109/CVPR42600.2020.01074
   Zhang LF, 2019, IEEE I CONF COMP VIS, V0, PP3712, DOI 10.1109/ICCV.2019.00381
NR 31
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD MAR 15
PY 2023
VL 53
IS 5
BP 5607
EP 5619
DI 10.1007/s10489-022-03779-8
EA JUN 2022
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA A3ZV8
UT WOS:000819298900002
DA 2023-11-10
ER

PT J
AU Liu, S
   Zhou, G
   Xia, Y
   Wu, H
   Li, ZF
AF Liu, Shuo
   Zhou, Gang
   Xia, Yi
   Wu, Hao
   Li, Zhufeng
TI A data-centric way to improve entity linking in knowledge-based question answering
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Entity linking; Negative sampling; Natural language processing; Knowledge-based question answering
AB Entity linking in knowledge-based question answering (KBQA) is intended to construct a mapping relation between a mention in a natural language question and an entity in the knowledge base. Most research in entity linking focuses on long text, but entity linking in open domain KBQA is more concerned with short text. Many recent models have tried to extract the features of raw data by adjusting the neural network structure. However, the models only perform well with several datasets. We therefore concentrate on the data rather than the model itself and created a model DME (Domain information Mining and Explicit expressing) to extract domain information from short text and append it to the data. The entity linking model will be enhanced by training with DME-processed data. Besides, we also developed a novel negative sampling approach to make the model more robust. We conducted experiments using the large Chinese open source benchmark KgCLUE to assess model performance with DME-processed data. The experiments showed that our approach can improve entity linking in the baseline models without the need to change their structure and our approach is demonstrably transferable to other datasets.
C1 [Liu, Shuo; Zhou, Gang; Xia, Yi; Wu, Hao; Li, Zhufeng] Informat Engn Univ, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Li, ZF (通讯作者)，Informat Engn Univ, Zhengzhou, Henan, Peoples R China.
EM 20086538@qq.com
FU Science and Technology Research Program of the Department of Science and Technology of Henan Province [222102210081]
CR [Anonymous], 2016, HLT NAACL, V0, P0, DOI DOI 10.18653/V1/N16-1150
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Besancon R, 2017, ACTES 24 ME C RENCE, V1, P182
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Chen S, 2020, AAAI CONF ARTIF INTE, V34, P7529
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Peters ME, 2019, ARXIV, V0, P0
   Fang Z, 2019, ARXIV, V0, P0
   Huang XF, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.667
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Le P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4081
   Levy Omer, 2017, P 21 C COMPUTATIONAL, V0, P58
   Logeswaran L, 2019, ARXIV, V0, P0
   Lu X, 2022, APPL INTELL, V52, P1878, DOI 10.1007/s10489-021-02306-5
   McIlwaine IC, 1997, J AM SOC INFORM SCI, V48, P331, DOI 10.1002/(SICI)1097-4571(199704)48:4<331::AID-ASI6>3.3.CO;2-B
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mulang IO, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP2157, DOI 10.1145/3340531.3412159
   Ng A, 2021, CHAT ANDREW MLOPS MO, V0, P0
   Nie F, 2018, AAAI CONF ARTIF INTE, V0, P5908
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rao JF, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP1913, DOI 10.1145/2983323.2983872
   Schindler D, 2022, PEERJ COMPUT SCI, V8, P0, DOI 10.7717/peerj-cs.835
   Sevgili Ö, 2022, SEMANT WEB, V13, P527, DOI 10.3233/SW-222986
   Shen W, 2015, IEEE T KNOWL DATA EN, V27, P443, DOI 10.1109/TKDE.2014.2327028
   Sil A, 2018, AAAI CONF ARTIF INTE, V0, P5464
   Cai TT, 2020, ARXIV, V0, P0
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang JP, 2020, INFORMATION, V11, P0, DOI 10.3390/info11090421
   Wu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6397
   Xu Liang, 2020, CLUE CHINESE LANGUAG, V0, P0
   Yamada I, 2022, ARXIV, V0, P0
   Zhang YQ, 2019, PROC INT CONF DATA, V0, PP614, DOI 10.1109/ICDE.2019.00061
   Zwicklbauer S, 2016, SIGIR16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP425, DOI 10.1145/2911451.2911535
NR 33
TC 1
Z9 1
U1 2
U2 2
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD FEB 9
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1233
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA C8DK0
UT WOS:000964157000003
PM 37346650
DA 2023-11-10
ER

PT J
AU Kumar, S
   Solanki, A
AF Kumar, Sandeep
   Solanki, Arun
TI An abstractive text summarization technique using transformer model with self-attention mechanism
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Abstractive text summarization; Encoder-decoder; Self-attention mechanism; Rouge metrics; Transformer architecture; T2SAM
ID neural-network; document
AB Creating a summarized version of a text document that still conveys precise meaning is an incredibly complex endeavor in natural language processing (NLP). Abstract text summarization (ATS) is the process of using facts from source sentences and merging them into concise representations while maintaining the content and intent of the text. Manually summarizing large amounts of text are challenging and time-consuming for humans. Therefore, text summarization has become an exciting research focus in NLP. This research paper proposed an ATS model using a Transformer Technique with Self-Attention Mechanism (T2SAM). The self-attention mechanism is added to the transformer to solve the problem of coreference in text. This makes the system to understand the text better. The proposed T2SAM model improves the performance of text summarization. It is trained on the Inshorts News dataset combined with the DUC-2004 shared tasks dataset. The performance of the proposed model has been evaluated using the ROUGE metrics, and it has been shown to outperform the existing state-of-the-art baseline models. The proposed model gives the training loss minimum to 1.8220 from 10.3058 (at the starting point) up to 30 epochs, and it achieved model accuracy 48.50% F1-Score on both the Inshorts and DUC-2004 news datasets.
C1 [Kumar, Sandeep; Solanki, Arun] Gautam Buddha Univ, Dept Comp Sci & Engn, Greater Noida 201312, Uttar Pradesh, India.
C3 Gautam Buddha University
RP Kumar, S (通讯作者)，Gautam Buddha Univ, Dept Comp Sci & Engn, Greater Noida 201312, Uttar Pradesh, India.
EM phdict2012@gbu.ac.in; asolanki@gbu.ac.in
CR Abdi A, 2018, INFORM PROCESS MANAG, V54, P318, DOI 10.1016/j.ipm.2017.12.002
   Aghajanyan A, 2020, ARXIV, V0, P0
   Al-Radaideh QA, 2018, COGN COMPUT, V10, P651, DOI 10.1007/s12559-018-9547-z
   Al-Sabahi K, 2018, IEEE ACCESS, V6, P24205, DOI 10.1109/ACCESS.2018.2829199
   Andhale N, 2016, OVERVIEW TEXT SUMMAR, V0, PP1, DOI 10.1109/ICCUBEA.2016.7860024
   Bisht Paritosh, 2022, APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING: SELECT PROCEEDINGS OF ICAAAIML 2021. LECTURE NOTES IN ELECTRICAL ENGINEERING (925), V0, PP47, DOI 10.1007/978-981-19-4831-2_5
   Chen DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2358
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Choudhary Rohan, 2022, ADVANCES IN DATA COMPUTING, V0, P51, DOI 10.1007/978-981-16-8403-6_5
   Costa-jussà MR, 2018, COMPUT SIST, V22, P1233, DOI 10.13053/CyS-22-4-3060
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Ding JL, 2020, IEEE ACCESS, V8, P92659, DOI 10.1109/ACCESS.2020.2994092
   Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.113679
   Gasparetto A, 2022, INFORMATION, V13, P0, DOI 10.3390/info13020083
   Goularte FB, 2019, EXPERT SYST APPL, V115, P264, DOI 10.1016/j.eswa.2018.07.047
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hernández-Castañeda A, 2020, IEEE ACCESS, V8, P49896, DOI 10.1109/ACCESS.2020.2980226
   Hirao T, 2015, IEEE-ACM T AUDIO SPE, V23, P2081, DOI 10.1109/TASLP.2015.2465150
   Hu D, 2018, ARXIV, V0, P0
   Kumar Sandeep, 2023, PROCEDIA COMPUTER SCIENCE, V0, PP1768, DOI 10.1016/j.procs.2023.01.155
   Lee GH, 2017, P 8 INT JOINT C NAT, V0, P193
   Li Haoran, 2018, P 27 INT C COMP LING, V0, P1430
   Li P, 2017, ARXIV, V0, P0
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Liu CY, 2015, IEEE T KNOWL DATA EN, V27, P2986, DOI 10.1109/TKDE.2015.2405553
   Liu WF, 2021, IEEE ACCESS, V9, P43970, DOI 10.1109/ACCESS.2021.3066484
   Liu Y, 2021, ARXIV, V0, P0
   Mehta P, 2018, INFORM PROCESS MANAG, V54, P145, DOI 10.1016/j.ipm.2017.11.002
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Moratanch N, 2016, PROCEEDINGS OF IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, V0, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2016)
   Nallapati R, 2016, ARXIV, V0, P0
   Patil MM, 2022, CMC-COMPUT MATER CON, V71, P2347, DOI 10.32604/cmc.2022.021447
   Paulus R, 2017, DEEP REINFORCED MODE, V0, P0
   RAJPUT R, 2016, INT J COMPUTER SCI M, V5, P159
   Rodriguez P, 1999, CONNECT SCI, V11, P5, DOI 10.1080/095400999116340
   Saeed A, 2018, UKH J SCI ENG, V0, P0, DOI DOI 10.25079/UKHJSE.V2N1Y2018
   Saggion H, 2013, MULTISOURCE MULTILIN, V0, PP3, DOI 10.1007/978-3-642-28569-1_1
   Sajjan R, 2019, INT J COMPUT SCI ENG, V7, P991, DOI 10.26438/ijcse/v7i6.991998
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   [石磊 Shi Lei], 2020, 数据分析与知识发现 DATA ANALYSIS AND KNOWLEDGE DISCOVERY, V4, P1
   Sindhu K, 2022, TEXT SUMMARIZATION T, V0, PP261, DOI 10.1002/9781119792642.ch13
   Singh G, 2016, SELFORGANIZOLOGY, V3, P100
   Singh Tarana, 2020, PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE ON COMPUTING, V0, P0
   Smagulova K, 2020, DEEP LEARNING CLASSI, V0, PP139, DOI 10.1007/978-3-030-14524-8_11
   Solanki A, 2021, EMERGING TECHNOLOGIE, V0, P57
   Solanki A, 2018, INT J INF TECHNOL, V0, P1
   Suleiman D, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/9365340
   Sun XB, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3418
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Suzuki J, 2016, ARXIV, V0, P0
   Syed AA, 2021, IEEE ACCESS, V9, P13248, DOI 10.1109/ACCESS.2021.3052783
   Takase S, 2021, ARXIV, V0, P0
   Takase S, 2019, ARXIV, V0, P0
   Tayal A, 2020, SUSTAIN CITIES SOC, V62, P0, DOI 10.1016/j.scs.2020.102383
   Vaswani A, 2017, ARXIV, V30, P5998
   Vetriselvi T, 2022, INTELL AUTOM SOFT CO, V34, P1537, DOI 10.32604/iasc.2022.025235
   Wu SZ, 2020, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR42600.2020.00008
   Yang M, 2021, IEEE T NEUR NET LEAR, V32, P2744, DOI 10.1109/TNNLS.2020.3008037
   Yang S, 2022, FRONT NEUROSCI, V16, P0
   Yang SM, 2023, IEEE T INTELL TRANSP, V0, P0, DOI DOI 10.1109/TITS.2022.3232231
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P2801, DOI 10.1109/TNNLS.2020.3045492
   Yang SM, 2022, ENTROPY-SWITZ, V24, P0, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Zhang J, 2019, ARXIV, V0, P0
   Zhao Y, 2022, ARXIV, V0, P0
   Zhuang HJ, 2019, IEEE ACCESS, V7, P169426, DOI 10.1109/ACCESS.2019.2955087
NR 80
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD SEP 15
PY 2023
VL 35
IS 25
BP 18603
EP 18622
DI 10.1007/s00521-023-08687-7
EA JUN 2023
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA P2WY3
UT WOS:000999530500006
DA 2023-11-10
ER

PT J
AU Awiszus, M
   Schubert, F
   Rosenhahn, B
AF Awiszus, Maren
   Schubert, Frederik
   Rosenhahn, Bodo
TI Wor(l)d-GAN: Toward Natural-Language-Based PCG in Minecraft
SO IEEE TRANSACTIONS ON GAMES
LA English
DT Article
DE Index Terms-BERT; generation; generative adversarial network (GAN); level; Minecraft; natural language processing (NLP); procedural content generation (PCG); representation; scales; SinGAN; single example; style
AB This article presents Wor(l)d-GAN, a method to perform data-driven procedural content generation via machine learning in Minecraft from a single example. Based on a 3-D generative adversarial network (GAN) architecture, we are able to create arbitrarily sized world snippets from a given sample. Our method applies dense representations used in natural language processing in two ways. First, we propose block2vec representations based on word2vec. Second, we use the pretrained large language model bidirectional encoder representations from transformers (BERT) to generate representations directly from the token names. These representations make Wor(l)d-GAN independent of the number of different blocks, which can vary a lot in Minecraft, and enable the generation of larger levels. We evaluate our approach on creations from the community as well as structures generated with the Minecraft World Generator under several metrics. Wor(l)d-GAN enables its users to generate Minecraft worlds based on parts of their creations.
C1 [Awiszus, Maren; Schubert, Frederik; Rosenhahn, Bodo] Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany.
C3 Leibniz University Hannover
RP Schubert, F (通讯作者)，Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany.
EM awiszus@tnt.uni-hannover.de; schubert@tnt.uni-hannover.de; rosenhahn@tnt.uni-hannover.de
FU Federal Ministry of Education and Research, Germany [01DD20003]; Deutsche Forschungsgemeinschaft [EXC 2122]
CR Agrawal A, 2021, FOUND TRENDS MACH LE, V14, P211, DOI 10.1561/2200000090
   [Anonymous], 2020, MIN GAN CIT GEN, V0, P0
   [Anonymous], 2009, MIN VERS 1 16, V0, P0
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Awiszus M, 2020, P 16 ANN AAAI C ART, V0, P0
   Awiszus M, 2021, IEEE CONF COMPU INTE, V0, PP71, DOI 10.1109/COG52621.2021.9619133
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Freiknecht J, 2020, PROC INT C FOUND DIG, V0, PP1, DOI 10.1145/3402942.3409599
   Giacomello E, 2018, 2018 IEEE GAMES, V0, P0
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grbic D, 2021, LECT NOTES COMPUT SC, V12694, P325, DOI 10.1007/978-3-030-72699-7_21
   Green MC, 2019, P 14 INT C FDN DIG G, V0, P1
   Gutierrez J, 2020, IEEE C EVOL COMPUTAT, V0, P0
   Herve J-B, 2021, P 16 INT C FDN DIG G, V0, P1
   Gulrajani I, 2017, ADV NEUR IN, V30, P0
   Kano AM, 2020, THESIS U CALIFORNIA, V0, P0
   Karavolos D, 2021, IEEE T GAMES, V13, P11, DOI 10.1109/TG.2019.2931044
   Khalifa A, 2020, P AAAI C ART INT INT, VVolume 16, P95
   Khameneh NY, 2020, PROC 2 WORKSHOP EXP, V0, P0
   LEVENSHTVI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Levy O, 2014, ADV NEUR IN, V27, P0
   Lucas SM, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO19), V0, PP170, DOI 10.1145/3321707.3321781
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Patrascu C, 2016, PROC IEEE C COMPUT I, V0, P1
   Rabii Y, 2021, P AAAI C ART INT INT, V0, P187
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Rudolph M, 2022, IEEE WINT CONF APPL, V0, PP1829, DOI 10.1109/WACV51458.2022.00189
   Salge C, 2018, PROC 13 INT C FOUND, V0, P1
   Salge C, 2019, PROC 10 INT C COMPUT, V0, P311
   Salge C, 2020, KUNSTL INTELL, V34, P19, DOI 10.1007/s13218-020-00635-0
   Schubert F, 2022, IEEE T GAMES, V14, P284, DOI 10.1109/TG.2021.3069833
   Shaham TR, 2019, IEEE I CONF COMP VIS, V0, PP4569, DOI 10.1109/ICCV.2019.00467
   Snodgrass S, 2013, PROC 9 ARTIF INTELL, V0, P25
   Soros LB, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCO17 COMPANION), V0, PP95, DOI 10.1145/3067695.3075605
   Sudhakaran S, 2021, ARXIV, V0, P0
   Summerville A, 2018, IEEE T GAMES, V10, P257, DOI 10.1109/TG.2018.2846639
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Volz V, 2020, IEEE CONF COMPU INTE, V0, PP399, DOI 10.1109/CoG47356.2020.9231944
   Volz V, 2018, GECCO18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, V0, PP221, DOI 10.1145/3205455.3205517
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yoon E, 2018, P 14 ART INT INT DIG, V0, P250
NR 43
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2475-1502
EI 2475-1510
J9 IEEE T GAMES
JI IEEE Trans. Gamres
PD JUN 15
PY 2023
VL 15
IS 2
BP 182
EP 192
DI 10.1109/TG.2022.3153206
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering
SC Computer Science
GA J9LE5
UT WOS:001012760400006
DA 2023-11-10
ER

PT J
AU Berrimi, M
   Oussalah, M
   Moussaoui, A
   Saidi, M
AF Berrimi, Mohamed
   Oussalah, Mourad
   Moussaoui, Abdelouahab
   Saidi, Mohamed
TI Attention Mechanism Architecture for Arabic Sentiment Analysis
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Arabic sentiment analysis; attention mechanism; pretrained word embeddings; language understanding
AB This article tackles the problem of sentiment analysis in the Arabic language where a new deep learning model has been put forward. The proposed model uses a hybrid bidirectional gated recurrent unit (BiGRU) and bidirectional long short-term memory (BiLSTM) additive-attention model where the Bidirectional GRU/LSTM reads the individual sentence input from left to right and vice versa, enabling the capture of the contextual information. However, the model is trained on two types of embeddings: FastText and local learnable embeddings. The BiLSTM and BiGRU architectures are put into competition to identify the best hyperparameter set for the model. The developed model has been tested on three large-scale commonly employed Arabic sentiment dataset: large-scale Arabic Book Reviews Dataset (ABRD), Hotel Arabic-Reviews Dataset (HARD), and Books Reviews in the Arabic Dataset (BRAD). The testing results demonstrate that our model outperforms both the baseline models and the state-of-the-art models reported in the original references of these datasets, achieving accuracy scores of 98.6%, 96.19%, 95.65% for LARB, HARD, and BRAD, respectively. Furthermore, to demonstrate the generalization capabilities of our model, the performances of the model have been evaluated on three other natural language processing tasks: news categorization, offensive speech detection, and Russian sentiment analysis. The results demonstrated the developed model is language- and task-independent, which offers new perspectives for the application of the developed models in several other natural language processing challenges.
C1 [Berrimi, Mohamed; Moussaoui, Abdelouahab; Saidi, Mohamed] Univ Ferhat Abbas 1, Dept Comp Sci, Setif, Algeria.
   [Oussalah, Mourad] CMVS Univ Oulu, Fac ITEE, Oulu, Finland.
RP Berrimi, M (通讯作者)，Univ Ferhat Abbas 1, Dept Comp Sci, Setif, Algeria.
EM Mohamed.Berrimi@univ-setif.dz; Mourad.oussalah@oulu.fi; Abdelouahab.Moussaoui@univ-setif.dz; Mohamed.Saidi@univ-setif.dz
CR Abbes I, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6265
   Abdaoui A, 2022, ARXIV, V0, P0
   Abdul-Mageed M, 2020, P 5 ARABIC NATURAL L, V0, P97
   Abdul-Mageed M, 2021, ACL IJCNLP 2021 59 A, Vi, P7088, DOI 10.18653/V1/2021.ACL-LONG.551
   Abdulla NA, 2013, 2013 IEEE JORDAN CONFERENCE ON APPLIED ELECTRICAL ENGINEERING AND COMPUTING TECHNOLOGIES (AEECT), V0, P0
   Abu Farha I, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102438
   Abu Farha I, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), V0, P192
   Abu Kwaik K, 2019, COMM COM INF SC, V1108, P108, DOI 10.1007/978-3-030-32959-4_8
   Abualigah LMQ, 2019, FEATURE SELECTION EN, V0, P0
   Abualigah L, 2021, COMPUT IND ENG, V157, P0, DOI 10.1016/j.cie.2021.107250
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, P0, DOI 10.1016/j.cma.2020.113609
   Abualigah L, 2021, ARTIF INTELL REV, V54, P2567, DOI 10.1007/s10462-020-09909-3
   Abualigah LM, 2016, 2016 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), V0, PP67, DOI 10.1109/ISCAIE.2016.7575039
   Al-Azani S, 2018, PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON COMPUTING SCIENCES AND ENGINEERING (ICCSE), V0, P0
   Al-Dabet S, 2019, 2019 2 INT C NEW TRE, V0, PP1, DOI 10.1109/ICTCS.2019
   Alamro Hind, 2021, ARXIV, V0, P0
   Alayba AM, 2018, LECT NOTES COMPUT SC, V11015, P179, DOI 10.1007/978-3-319-99740-7_12
   Alharbi AI, 2021, PROCEDIA COMPUT SCI, V189, P258, DOI 10.1016/j.procs.2021.05.089
   Alharbi B, 2021, ARXIV, V0, P0
   Almani Nada Mohammed, 2020, 2020 6TH CONFERENCE ON DATA SCIENCE AND MACHINE LEARNING APPLICATIONS (CDMA), V0, PP47, DOI 10.1109/CDMA47397.2020.00014
   Altowayan AA, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), V0, PP3820, DOI 10.1109/BigData.2016.7841054
   Aly M, 2013, P 51 ANN M ASS COMP, V2, P494
   [Anonymous], 2016, INT RES J ENG TECHNO, V0, P0
   [Anonymous], 2016, P 26 INT C COMPUTATI, V0, P0
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Bahdanau D, 2016, ARXIV, V0, P0
   Barhoumi A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P4955
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Britto AS, 2014, PATTERN RECOGN, V47, P3665, DOI 10.1016/j.patcog.2014.05.003
   Cavalin PR, 2013, NEURAL COMPUT APPL, V22, P673, DOI 10.1007/s00521-011-0737-9
   Chung J, 2014, NIPS 2014 WORKSH DEE, V0, PP1, DOI 10.48550/ARXIV.1412.3555
   Dahou A, 2019, ACM T ASIAN LOW-RESO, V18, P0, DOI 10.1145/3314941
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dieng Adji Bousso, 2017, P 5 INT C LEARNING R, V0, P0
   Einea O, 2019, DATA BRIEF, V25, P0, DOI 10.1016/j.dib.2019.104076
   El-Beltagy SR, 2017, P 11 INT WORKSH SEM, V0, PP790, DOI 10.18653/V1/S17-2133
   ElJundi O, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), V0, P68
   Elmallah A, 2018, IEEE CUST INTEGR CIR, V0, P0
   Elnagar A, 2018, COMPUTATIONAL INTELL, V0, PP35, DOI 10.1007/978-3-319-67056-0_3
   Elnagar Ashraf, 2016, 2016 IEEEACS 13 INT, V0, PP1, DOI 10.1109/AICCSA.2016.7945800
   Elnagar Ashraf, 2019, P 2 WORKSHOP MULTILI, V0, P0
   ElSahar H, 2015, LECT NOTES COMPUT SC, V9042, P23, DOI 10.1007/978-3-319-18117-2_2
   Fan H, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10111332
   Farghaly A, 2009, ACM T ASIAN LANGUAGE, V8, P1, DOI 10.1145/1644879.1644881
   Farha A, 2021, P 6 AR NAT LANG PROC, V0, P296
   Gamal D, 2019, PROCEDIA COMPUT SCI, V154, P332, DOI 10.1016/j.procs.2019.06.048
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Guellil I, 2021, J KING SAUD UNIV-COM, V33, P497, DOI 10.1016/j.jksuci.2019.02.006
   Han Y, 2020, IEEE ACCESS, V8, P21314, DOI 10.1109/ACCESS.2020.2969473
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Hossain MZ, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3295748
   Khalifa S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P3895
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Kuncheva LI, 2014, COMBINING PATTERN CL, V2nd ed., P0
   Li BF, 2017, AAAI CONF ARTIF INTE, V0, P3067
   Liu B, 2016, SENTIMENT ANAL MININ, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Maas Andrew, 2011, P 49 ANN M ASS COMPU, V0, P142
   Mataoui M, 2016, RES COMPUT SCI, V110, P55, DOI 10.13053/rcs-110-1-5
   Meftouh K, 2015, P 29 PACIFIC ASIA C, V0, P26
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2013, ARXIV, V0, P0
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P52
   Moudjari Leila, 2020, PROCEDIA COMPUTER SCIENCE, V176, P1151, DOI 10.1016/j.procs.2020.09.111
   Nabil M, 2015, P 2015 C EMP METH NA, V0, PP2515, DOI 10.18653/V1/D15-1299
   Ombabi AH, 2020, SOC NETW ANAL MIN, V10, P0, DOI 10.1007/s13278-020-00668-1
   Oueslati O, 2020, FUTURE GENER COMP SY, V112, P408, DOI 10.1016/j.future.2020.05.034
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Rebiai Zinedine, 2019, P 13 INT WORKSHOP SE, V0, P297
   Rosenthal S, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/v1/S17-2088
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Soumeur A, 2018, PROCEDIA COMPUT SCI, V142, P26, DOI 10.1016/j.procs.2018.10.458
   Thongtan T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P407
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Xie Qizhe, 2020, P 34 C NEURAL INFORM, V0, P0
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang L, 2011, COMBINING LEXICON BA, V89, P1
   Zitouni I, 2014, NATURAL LANGUAGE PRO, V0, P0
NR 82
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR 15
PY 2023
VL 22
IS 4
BP 
EP 
DI 10.1145/3578265
PG 26
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FI3
UT WOS:000998929700015
DA 2023-11-10
ER

PT J
AU Qin, C
   Yao, KC
   Zhu, HS
   Xu, T
   Shen, DZ
   Chen, EH
   Xiong, H
AF Qin, Chuan
   Yao, Kaichun
   Zhu, Hengshu
   Xu, Tong
   Shen, Dazhong
   Chen, Enhong
   Xiong, Hui
TI Towards Automatic Job Description Generation With Capability-Aware Neural Networks
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Recruitment; Data models; Task analysis; Writing; Training; Natural languages; Web and internet services; Job description generation; recruitment analysis; topic model
AB A job description shows the responsibilities of the job position and the skill requirements for the job. An effective job description will help employers to identify the right talents for the job, and give a clear understanding to candidates of what their duties and qualifications for a particular position would be. However, due to the variation in experiences, it is always a challenge for both hiring managers and recruiters to decide what capabilities the job requires and prioritize them accordingly on the job description. Also, tedious and expensive human efforts are usually required to prepare a job description. Therefore, in this paper, we investigate how to automate the process to generate job descriptions with less human intervention. To this end, we propose an end-to-end capability-aware neural job description generation framework, namely Cajon, to facilitate the writing of job description. Specifically, we first propose a novel capability-aware neural topic model to distill the various capability information from the larger-scale recruitment data. Also, an encoder-decoder recurrent neural network is designed for enabling the job description generation. In particular, the capability-aware attention mechanism and copy mechanism are proposed to guide the generation process to ensure the generated job descriptions can comprehensively cover relevant and representative capability requirements for the job. Moreover, we propose a capability-aware policy gradient training algorithm to further enhance the rationality of the generated job description. Finally, extensive experiments on real-world recruitment data clearly show our Cajon framework can help to generate more effective job descriptions in an interpretable way. In particular, our Cajon framework has been deployed in Baidu as an intelligent tool for talent recruitment.
C1 [Qin, Chuan; Yao, Kaichun; Zhu, Hengshu] Baidu Inc, Talent Intelligence Ctr, Beijing 100085, Peoples R China.
   [Xu, Tong; Shen, Dazhong; Chen, Enhong] Univ Sci & Technol China, Sch Comp Sci, Hefei 230027, Peoples R China.
   [Xiong, Hui] Hong Kong Univ Sci & Technol, Artificial Intelligence Thrust, Guangzhou 511458, Peoples R China.
C3 Baidu; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Hong Kong University of Science & Technology
RP Zhu, HS (通讯作者)，Baidu Inc, Talent Intelligence Ctr, Beijing 100085, Peoples R China.; Xiong, H (通讯作者)，Hong Kong Univ Sci & Technol, Artificial Intelligence Thrust, Guangzhou 511458, Peoples R China.
EM chuanqin0426@gmail.com; yaokaichun@outlook.com; zhuhengshu@gmail.com; tongxu@ustc.edu.cn; sdz@mail.ustc.edu.cn; cheneh@ustc.edu.cn; xionghui@gmail.com
FU National Natural Science Foundation of China [61836013, 91746301, 62072423]
CR Allegis Group, 2017, LETS TALK FOC CONV T, V0, P0
   [Anonymous], 2015, INT C MACHINE LEARNI, V0, P0
   Ba J, 2015, P 3 INT C LEARN REPR, V0, P0
   Bahdanau D, 2017, ICLR, V0, P1
   Bahdanau D, 2016, ARXIV, V0, P0
   Bahuleyan H, 2018, COLING, V0, P0
   Blei DM, 2008, ADV NEURAL INFORM PR, V20, P121, DOI 10.1109/MWSCAS.2011.6026348
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen YC, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P675
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Diao QM, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP193, DOI 10.1145/2623330.2623758
   Dong L, 2019, ADV NEUR IN, V32, P0
   Elhadad M, 1996, P DEM POST INT WORKS, V0, P1
   Glorot X, 2010, 13 INT C ARTIFICIAL, V0, PP249, DOI 10.4236/JSIP.2015.62006
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Hu MH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4099
   IESolutions, 2013, CHALL OF WRIT A JOB, V0, P0
   Kurashima T, 2013, P 6 ACM INT C WEB SE, V0, P375
   Le R, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP1883, DOI 10.1145/3357384.3357949
   Li HY, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP917, DOI 10.1145/3097983.3098107
   Li Jiwei, 2016, EMNLP, V0, P0
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3774
   Liu LT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3096
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   McAuley J, 2013, P 7 ACM C RECOMMENDE, V0, P165
   Meng QX, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP14, DOI 10.1145/3292500.3330969
   Miao YS, 2017, PR MACH LEARN RES, V70, P0
   Mimno David, 2009, P 2009 C EMPIRICAL M, V2, P880, DOI 10.3115/1699571.1699627
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paulus R, 2017, ARXIV170504304, V0, P1
   Qin C, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2165, DOI 10.1145/3292500.3330706
   Qin C, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP25, DOI 10.1145/3209978.3210025
   Ramage Daniel, 2009, EMNLP, V0, PP248, DOI 10.3115/1699510.1699543
   Ranzato M, 2016, 4 INT C LEARN REPR I, V0, P0
   Reiter E, 2000, BUILDING NATURAL LAN, V0, P41
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Rosen-Zvi Michal, 2004, P 20 C UNCERTAINTY A, V0, PP487, DOI 10.5555/1036843.1036902
   Schlee RP, 2010, J MARKET EDUC, V32, P341, DOI 10.1177/0273475310380881
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shen DZ, 2022, ACM T INFORM SYST, V40, P0, DOI 10.1145/3469654
   Shen DZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3542
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Srivastava A, 2017, 5 INT C LEARN REPR I, V0, P0
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Wade MR, 2001, J MANAGE INFORM SYST, V18, P71, DOI 10.1080/07421222.2002.11045694
   Wang Y, 2012, P 18 ACM SIGKDD INT, V0, P0, DOI DOI 10.1145/2339530.2339552
   Wang Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2516
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wu XX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3891
   Xia YC, 2017, ADV NEUR IN, V30, P0
   Xu T, 2018, AAAI CONF ARTIF INTE, V0, P2572
   Xu T, 2014, KNOWL INF SYST, V41, P251, DOI 10.1007/s10115-013-0717-8
   Yan X, 2013, P 22 INT C WORLD WID, V0, PP1445, DOI 10.1145/2488388.2488514
   Zeng JC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3120
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
   Zhou L, 2004, P ACL WORKSH TEXT SU, V0, P56
   Zhu C, 2018, ACM TRANS MANAG INF, V9, P0, DOI 10.1145/3234465
   Zhu C, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP383, DOI 10.1145/2939672.2939689
   Zhu QL, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2636
NR 62
TC 1
Z9 1
U1 10
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD MAY 1
PY 2023
VL 35
IS 5
BP 5341
EP 5355
DI 10.1109/TKDE.2022.3145396
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA C9FA3
UT WOS:000964880800068
DA 2023-11-10
ER

PT J
AU Hamza, HM
   Wali, A
AF Hamza, Hafiz Muhammad
   Wali, Aamir
TI Pakistan sign language recognition: leveraging deep learning models with limited dataset
SO MACHINE VISION AND APPLICATIONS
LA English
DT Article
DE Sign language recognition; Pakistan Sign Language; PSL data dictionary; C3D; Data augmentation
AB Sign language is the predominant form of communication among a large group of society. The nature of sign languages is visual. This makes them very different from spoken languages. Unfortunately, very few able people can understand sign language making communication with the hearing-impaired extremely difficult. Research in the field of sign language recognition can help reduce the barrier between deaf and able people. A lot of work has been done on sign language recognition for numerous languages such as American sign language and Chinese sign language. Unfortunately, very little to no work has been done for Pakistan Sign Language. Any contribution in Pakistan Sign Language recognition is limited to static images instead of gestures. Furthermore, the dataset available for this language is very small in terms of the number of examples per word which makes it very difficult to train deep networks that require a considerable amount of training data. Data Augmentation techniques help the network generalize better by providing more variety in the training data. In this paper, a pipeline for the Pakistan Sign Language recognition system is proposed that incorporates an augmentation unit. To validate the effectiveness of the proposed pipeline, three deep learning models, C3D, I3D, and TSM are used. Results show that translation and rotation are the two best augmentation techniques for the Pakistan Sign Language dataset. The models trained using our data-augment-supported pipeline outperform other methods that only used the original data. The most suitable model is C3D which not only produced an accuracy of 93.33% but also has a low training time as compared to other models.
C1 [Hamza, Hafiz Muhammad; Wali, Aamir] Natl Univ Comp & Emerging Sci, FAST Sch Comp, 852-B, Lahore, Pakistan.
RP Wali, A (通讯作者)，Natl Univ Comp & Emerging Sci, FAST Sch Comp, 852-B, Lahore, Pakistan.
EM l202058@lhr.nu.edu.pk; aamir.wali@nu.edu.pk
CR Adaloglou N, 2021, ARXIV, V0, P0
   Ahamed KU, 2021, COMPUT BIOL MED, V139, P0, DOI 10.1016/j.compbiomed.2021.105014
   Ahmed MA, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18072208
   Alvi AK, 2004, INT J INF TECHNOL, V1, P1
   AnithaSheela K, 2022, INDIAN SIGN LANGUAGE, V0, P7
   Ben Slimane F, 2021, ARXIV, V0, P0
   Bohácek M, 2022, IEEE WINT CONF APPL, V0, PP182, DOI 10.1109/WACVW54805.2022.00024
   Boukdir A, 2022, ARAB J SCI ENG, V47, P2187, DOI 10.1007/s13369-021-06167-5
   Cao Z, 2019, ARXIV, V0, P0
   Carreira J, 2018, ARXIV, V0, P0
   Contributors M, 2020, OPENMMLABS NEXT GENE, V0, P0
   Damaneh MM, 2023, EXPERT SYST APPL, V211, P0, DOI 10.1016/j.eswa.2022.118559
   De Coster M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6018
   Tran D, 2015, IEEE I CONF COMP VIS, V0, PP4489, DOI 10.1109/ICCV.2015.510
   Gao Q, 2022, AM SIGN LANGUAGE FIN, V0, P3151
   Graves Alex, 2006, P 23 INT C MACH LEAR, V0, P369
   Hu JW, 2023, IEEE ACCESS, V11, P46204, DOI 10.1109/ACCESS.2023.3234743
   Javaid S, 2023, CMC-COMPUT MATER CON, V74, P523, DOI 10.32604/cmc.2023.031924
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang SY, 2021, ARXIV, V0, P0
   Kamal SM, 2019, IEEE ACCESS, V7, P96926, DOI 10.1109/ACCESS.2019.2929174
   Karpathy A, 2014, PROC CVPR IEEE, V0, PP1725, DOI 10.1109/CVPR.2014.223
   Kindiroglu AA, 2023, MACH VISION APPL, V34, P0, DOI 10.1007/s00138-022-01367-x
   Kumar CA, 2023, DEV SPEECH INDIAN SI, V0, P341
   Li DX, 2020, ARXIV, V0, P0
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Lin J, 2019, IEEE I CONF COMP VIS, V0, PP7082, DOI 10.1109/ICCV.2019.00718
   Lokhande P, 2015, P IJCA NAT C EM TREN, V0, P11
   Malik MSA, 2018, INT J ADV COMPUT SC, V9, P0, DOI 10.14569/IJACSA.2018.090414
   Maruyama M, 2021, ARXIV, V0, P0
   Mirza MS, 2022, SCI REP-UK, V12, P0, DOI 10.1038/s41598-022-15864-6
   Naseem M, 2019, J ED PRACT, V10, P0
   Nikam AS, 2016, SIGN LANGUAGE RECOGN, V0, P1
   psl, 2020, PSL DICT, V0, P0
   Pu J, 2016, PCM-PREM PERS COMPUT, V0, P252
   Qiu ZF, 2017, ARXIV, V0, P0
   Raees M, 2016, J ENG RES-KUWAIT, V4, P22
   Raziq N, 2017, LECT NOTE DATA ENG, V1, P895, DOI 10.1007/978-3-319-49109-7_87
   Sandler M, 2019, ARXIV, V0, P0
   Sethia D, 2023, LECT NOTES ELECTR EN, V959, P307, DOI 10.1007/978-981-19-6581-4_24
   Shah FR, 2021, IEEE ACCESS, V9, P67548, DOI 10.1109/ACCESS.2021.3077386
   Shah SMS, 2023, NEURAL COMPUT APPL, V35, P949, DOI 10.1007/s00521-022-07804-2
   Sincan OM, 2021, CORR, V0, P0
   Sun L, 2015, ARXIV, V0, P0
   Tongi R, 2021, ARXIV, V0, P0
   Tran D, 2018, ARXIV, V0, P0
   Vaswani A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1706.03762
   Xie P, 2023, PATTERN RECOGN, V136, P0, DOI 10.1016/j.patcog.2022.109233
   Xie SN, 2018, ARXIV, V0, P0
   Zhang Y, 2022, RES IMPROVEMENT CHIN, V0, P577
NR 54
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0932-8092
EI 1432-1769
J9 MACH VISION APPL
JI Mach. Vis. Appl.
PD SEP 15
PY 2023
VL 34
IS 5
BP 
EP 
DI 10.1007/s00138-023-01429-8
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA M6KZ0
UT WOS:001031297700003
DA 2023-11-10
ER

PT J
AU Ali, S
   Aslam, N
   Kim, D
   Abbas, A
   Tufail, S
   Azhar, B
AF Ali, Safdar
   Aslam, Nouraiz
   Kim, DoHyeun
   Abbas, Asad
   Tufail, Sania
   Azhar, Beenish
TI Context awareness based Sketch-DeepNet architecture for hand-drawn sketches classification and recognition in AIoT
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Convolutional neural networks (CNNs); Deep neural networks (DNNs); Sketch recognition; TU-Berlin
AB A sketch is a black-and-white, 2-D graphical representation of an object and contains fewer visual details as compared to a colored image. Despite fewer details, humans can recognize a sketch and its context very efficiently and consistently across languages, cultures, and age groups, but it is a difficult task for computers to recognize such low-detail sketches and get context out of them. With the tremendous increase in popularity of IoT devices such as smartphones and smart cameras, etc., it has become more critical to recognize free hand-drawn sketches in computer vision and human-computer interaction in order to build a successful artificial intelligence of things (AIoT) system that can first recognize the sketches and then understand the context of multiple drawings. Earlier models which addressed this problem are scale-invariant feature transform (SIFT) and bag-of-words (BoW). Both SIFT and BoW used hand-crafted features and scale-invariant algorithms to address this issue. But these models are complex and time-consuming due to the manual process of features setup. The deep neural networks (DNNs) performed well with object recognition on many large-scale datasets such as ImageNet and CIFAR-10. However, the DDN approach cannot be carried out for hand-drawn sketches problems. The reason is that the data source is images, and all sketches in the images are, for example, 'birds' instead of their specific category (e.g., 'sparrow'). Some deep learning approaches for sketch recognition problems exist in the literature, but the results are not promising because there is still room for improvement. This article proposed a convolutional neural network (CNN) architecture called Sketch-DeepNet for the sketch recognition task. The proposed Sketch-DeepNet architecture used the TU-Berlin dataset for classification. The experimental results show that the proposed method beats the performance of the state-of-the-art sketch classification methods. The proposed model achieved 95.05% accuracy as compared to existing models DeformNet (62.6%), Sketch-DNN (72.2%), Sketch-a-Net (77.95%), SketchNet (80.42%), Thinning-DNN (74.3%), CNN-PCA-SVM (72.5%), Hybrid-CNN (84.42%), and human recognition accuracy of 73% on the TU-Berlin dataset.
C1 [Ali, Safdar; Aslam, Nouraiz; Tufail, Sania; Azhar, Beenish] Univ Lahore, Dept Software Engn, Lahore, Punjab, Pakistan.
   [Kim, DoHyeun] Jeju Natl Univ, Dept Comp Engn, Jeju, South Korea.
   [Abbas, Asad] Univ Cent Punjab, Dept Comp Sci, Lahore, Punjab, Pakistan.
C3 University of Lahore; Jeju National University; University of Central Punjab
RP Kim, D (通讯作者)，Jeju Natl Univ, Dept Comp Engn, Jeju, South Korea.
EM kimdh@jejunu.ac.kr
FU Institute for Information & Communications Technology Promotion (IITP) [2022-0-00980]; Institute of Information & Communications Technology Planning & Evaluation (IITP) - Korean government (MSIT) [2021-0-00188]
CR Ahn P, 2016, 2016 AS PAC SIGN INF, V0, P1
   [Anonymous], 2013, PROC 3 ACM C INT C M, V0, P0
   Bui T, 2018, COMPUT GRAPH-UK, V71, P77, DOI 10.1016/j.cag.2017.12.006
   Dahl GE, 2013, INT CONF ACOUST SPEE, V0, PP8609, DOI 10.1109/ICASSP.2013.6639346
   Dai JF, 2017, IEEE I CONF COMP VIS, V0, PP764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, V0, PP886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Eitz M, 2012, ACM T GRAPHIC, V31, P0, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Glorot Xavier, 2011, P 14 INT C ART INT S, V0, PP315, DOI 10.1002/ECS2.1832
   Google, 2017, QUICK DRAW DAT, V0, P0
   Joachims T, 1998, P 10 EUR C MACH LEAR, V0, PP137, DOI 10.1007/BFB0026683
   Kabakus AT, 2020, 2ND INTERNATIONAL CONGRESS ON HUMAN-COMPUTER INTERACTION, V0, P101, DOI 10.1109/hora49412.2020.9152911
   Kingma DP, 2014, C TRACK P, V0, P0
   Sarvadevabhatla RK, 2015, ARXIV, V0, P0
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Krizhevsky A, 2009, TECH REP T 2009, V0, P0
   Krizhevsky A, 2012, NIPS, V0, P0, DOI DOI 10.1061/(ASCE)GT.1943-5606.0001284
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li L, 2021, IEEE T VIS COMPUT GR, V27, P3745, DOI 10.1109/TVCG.2020.2987626
   Li Q, 2014, I C CONT AUTOMAT ROB, V0, PP844, DOI 10.1109/ICARCV.2014.7064414
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, V0, PP730, DOI 10.1109/ACPR.2015.7486599
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McCallum A, 1998, AAAI 98 WORKSH LEARN, V0, PP41, DOI 10.1109/TSMC.1985.6313426
   Phu NM, 2018, DRAWING NEW WAY SEAR, V0, P0
   Sangkloy P, 2016, ACM T GRAPHIC, V35, P0, DOI 10.1145/2897824.2925954
   Schneider RG, 2014, ACM T GRAPHIC, V33, P0, DOI 10.1145/2661229.2661231
   Sert M, 2019, MULTIMED TOOLS APPL, V78, P17095, DOI 10.1007/s11042-018-7067-1
   Shechtman E, 2007, PROC CVPR IEEE, V0, P1744
   Singh A, 2018, PROCEEDINGS OF THE 2018 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2018), V0, PP26, DOI 10.1109/ISED.2018.8703997
   VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025
   Xu P, 2022, IEEE T NEUR NET LEAR, V33, P5150, DOI 10.1109/TNNLS.2021.3069230
   Yang Y, 2015, ARXIV PREPRINT, V1, P3, DOI 10.48550/ARXIV.1501.07873
   Yesilbek KT, 2017, COMPUT GRAPH-UK, V69, P80, DOI 10.1016/j.cag.2017.08.016
   Yu Q, 2015, ARXIV, V0, P0
   Yu Q, 2017, INT J COMPUT VISION, V122, P411, DOI 10.1007/s11263-016-0932-3
   Zhang H, 2016, PROC CVPR IEEE, V0, PP1105, DOI 10.1109/CVPR.2016.125
   Zhang XY, 2020, PATTERN RECOGN LETT, V130, P73, DOI 10.1016/j.patrec.2019.01.006
   Zhou W, 2020, INT ARAB J INF TECHN, V17, P82, DOI 10.34028/iajit/17/1/10
NR 40
TC 0
Z9 0
U1 1
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD APR 27
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1186
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA H5ES5
UT WOS:000996199000004
PM 37346539
DA 2023-11-10
ER

PT J
AU Wang, T
   Hou, BY
   Li, JK
   Shi, P
   Zhang, BC
   Snoussi, H
AF Wang, Tian
   Hou, Boyao
   Li, Jiakun
   Shi, Peng
   Zhang, Baochang
   Snoussi, Hichem
TI TASTA: Text-Assisted Spatial and Temporal Attention Network for Video Question Answering
SO ADVANCED INTELLIGENT SYSTEMS
LA English
DT Article
DE attention mechanism; video question answering; visual question answering
AB Video question answering (VideoQA) is a typical task that integrates language and vision. The key for VideoQA is to extract relevant and effective visual information for answering a specific question. Information selection is believed to be necessary for this task due to the large amount of irrelevant information in the video, and explicitly learning an attention model can be a reasonable and effective solution for the selection. Herein, a novel VideoQA model called Text-Assisted Spatial and Temporal Attention Network (TASTA) is proposed, which shows the great potential of explicitly modeling attention. TASTA is made to be simple, small, clean, and efficient for clear performance justification and possible easy extension. Its success is mainly from two new strategies of better using the textual information. Experimental results on a large and most representative dataset, TGIF-QA, show the significant superiority of TASTA w.r.t. the state-of-the-art and demonstrate the effectiveness of its key components via ablation studies.
C1 [Wang, Tian; Zhang, Baochang] Beihang Univ, Inst Artificial Intelligence, Beijing 100083, Peoples R China.
   [Hou, Boyao; Li, Jiakun] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100083, Peoples R China.
   [Shi, Peng] Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Fujian, Peoples R China.
   [Snoussi, Hichem] Univ Technol Troyes, Inst Charles Delaunay, F-10004 Troyes, France.
C3 Beihang University; Beihang University; Fujian Normal University; Universite de Technologie de Troyes
RP Wang, T (通讯作者)，Beihang Univ, Inst Artificial Intelligence, Beijing 100083, Peoples R China.
EM wangtian@buaa.edu.cn
FU National Key Research and Development Program of China [2018AAA0101400]; National Natural Science Foundation of China [61972016, 62032016]; Natural Science Foundation of Beijing Municipality [L191007]; Open Research Fund of Digital Fujian Environment Monitoring Internet of Things Laboratory Foundation [202004]; Fundamental Research Funds for the Central Universities [YWF-22-L-610]
CR Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Ba Jimmy Lei, 2016, ARXIV160706450, V0, P0
   Chen Z, 2021, INT J MACH LEARN CYB, V12, P1803, DOI 10.1007/s13042-021-01275-y
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Chung Junyoung, 2014, NIPS 2014 WORKSH DEE, V0, P0
   Ding Mingyu, 2021, PROC NEURIPS, V34, P887
   Tran D, 2015, IEEE I CONF COMP VIS, V0, PP4489, DOI 10.1109/ICCV.2015.510
   Fukui Akira, 2016, ARXIV160601847, V0, PP457, DOI 10.18653/V1/D16-1044
   Gao H, 2015, P 28 INT C NEURAL IN, V2, P2296, DOI 10.1145/2733373.2807418
   Gao JY, 2018, PROC CVPR IEEE, V0, PP6576, DOI 10.1109/CVPR.2018.00688
   GAO L, 2019, PROC AAAI C ARTIFICI, V33, P6391
   Gao LL, 2022, IEEE T IMAGE PROCESS, V31, P202, DOI 10.1109/TIP.2021.3120867
   Gao Y, 2016, PROC CVPR IEEE, V0, PP317, DOI 10.1109/CVPR.2016.41
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Jang Y, 2017, PROC CVPR IEEE, V0, PP1359, DOI 10.1109/CVPR.2017.149
   Jin T, 2022, APPL PHYS LETT, V492, P496
   Jin WK, 2021, IEEE T IMAGE PROCESS, V30, P5477, DOI 10.1109/TIP.2021.3076556
   Jin WK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1193, DOI 10.1145/3343031.3351065
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Karpathy A, 2014, PROC CVPR IEEE, V0, PP1725, DOI 10.1109/CVPR.2014.223
   Kim JH, 2016, ADV NEURAL INFORM PR, V0, PP361, DOI 10.48550/ARXIV.1606.01455
   Lei J, 2021, PROC CVPR IEEE, V0, PP7327, DOI 10.1109/CVPR46437.2021.00725
   Lei J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1369
   Li L, 2022, IEEE T IMAGE PROCESS, V31, P2726, DOI 10.1109/TIP.2022.3158546
   Li XP, 2019, AAAI CONF ARTIF INTE, V0, P8658
   Limnios N, 2021, STAT INFER STOCH PRO, V0, P0, DOI DOI 10.1007/s11203-021.09255-3
   Lu JS, 2016, ADV NEUR IN, V29, P0
   Malinowski Mateusz, 2014, NEURIPS, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rahman T, 2021, IEEE COMPUT SOC CONF, V0, PP1653, DOI 10.1109/CVPRW53098.2021.00181
   Ren M, 2015, ADV NEURAL INFORM PR, V0, P0
   Suvarna M, 2020, ADV INTELL SYST-GER, V2, P0, DOI 10.1002/aisy.202000043
   Tapaswi M, 2016, PROC CVPR IEEE, V0, PP4631, DOI 10.1109/CVPR.2016.501
   Teney D, 2018, PROC CVPR IEEE, V0, PP4223, DOI 10.1109/CVPR.2018.00444
   Pham V, 2014, INT CONF FRONT HAND, V0, PP285, DOI 10.1109/ICFHR.2014.55
   Wolpert DH, 1997, IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, V1, P67, DOI 10.1109/4235.585893
   Yi K, 2020, 8 INT C LEARN REPR I, V0, P0
   Yu XT, 2022, PATTERN RECOGN, V125, P0, DOI 10.1016/j.patcog.2022.108540
   Yu Y, 2017, PROC CVPR IEEE, V0, PP3261, DOI 10.1109/CVPR.2017.347
   Yun H, 2021, P IEEE CVF INT C COM, V0, P2031 2041
   Yusuf AA, 2022, ARTIF INTELL REV, V55, P6277, DOI 10.1007/s10462-022-10151-2
   Zhang ZX, 2022, ADV INTELL SYST-GER, V4, P0, DOI 10.1002/aisy.202100228
NR 43
TC 0
Z9 0
U1 3
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 
EI 2640-4567
J9 ADV INTELL SYST-GER
JI Adv. Intell. Syst.
PD APR 15
PY 2023
VL 5
IS 4
BP 
EP 
DI 10.1002/aisy.202200131
EA FEB 2023
PG 10
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA F9CR2
UT WOS:000935228300001
DA 2023-11-10
ER

PT J
AU Chu, JS
   Pyo, B
   Parth, V
   Hussein, A
   Wang, PT
AF Chu, Jung Soo
   Pyo, Bryan
   Parth, Vik
   Hussein, Ahmed
   Wang, Patrick
TI Key-Value Pair Identification from Tables Using Multimodal Learning
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Machine learning; multimodal learning; computer vision; natural language processing; document image understanding; table data extraction
AB Computer vision and optical character recognition techniques have rapidly advanced in order to accurately capture text and other features from paper documents. While state-of-the-art tools in these fields now yield high accuracy, analyzing their outputs requires more research. Since tables are common in such documents, a new pipeline, based on multimodal learning, is proposed to better extract key-value pairs from tables. Its performance is evaluated with a synthetically generated dataset with randomly generated tables and a dataset of mechanical part documents provided by SiliconExpert Technologies. Its performance is also compared with another state-of-the-art model built for similar tasks, LayoutLM. The proposed pipeline provides a fully automated, end-to-end scalable solution, beginning with image processing and computer vision components to a machine learning model that uses data from optical character recognition and natural language processing to make the final decisions. In the best configuration, the pipeline achieved a 96.26% accuracy on a large, synthetically generated training and test set. When comparing the proposed pipeline with LayoutLM, the proposed pipeline performed similarly on the synthetic dataset and better on the real dataset. These results show the potential of the multimodal approach in extracting key-value pairs from tables from real paper documents.
C1 [Chu, Jung Soo; Pyo, Bryan] MIT, CSAIL, 32 Vassar St, Cambridge, MA 02139 USA.
   [Parth, Vik] MIT, Cambridge, MA USA.
   [Hussein, Ahmed] SiliconExpert Technol, Santa Clara, CA USA.
   [Wang, Patrick] Northeastern Univ, Comp & Informat Sci, 440 Huntington Ave, Boston, MA 02115 USA.
C3 Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Northeastern University
RP Chu, JS (通讯作者)，MIT, CSAIL, 32 Vassar St, Cambridge, MA 02139 USA.
EM jschu99@mit.edu; bpyo@mit.edu; vparth@mit.edu; ahmedh@siliconexpert.com; mozart200@gmail.com
FU Arrow Electronics and Silicon Expert; FinTech@CSAIL alliance
CR Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bourbakis N, 2020, INT J ARTIF INTELL T, V29, P0, DOI 10.1142/S0218213020500074
   Bousbai K, 2022, INT J PATTERN RECOGN, V36, P0, DOI 10.1142/S0218001422560158
   Bukhari SS, 2017, PROC INT CONF DOC, V0, PP305, DOI 10.1109/ICDAR.2017.58
   Burie JC, 2015, PROC INT CONF DOC, V0, PP1161, DOI 10.1109/ICDAR.2015.7333943
   Chakraborty S, 2014, AAAI FALL S SERIE, V0, P10
   Cheng T, 2021, NANONETS AI MACHINE, V0, P0
   Culjak I, 2012, 2012 35TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, V0, P1725
   Halder C, 2018, INT J PATTERN RECOGN, V32, P0, DOI 10.1142/S0218001418560116
   Li BL, 2013, LECT NOTES COMPUT SC, V8206, P611, DOI 10.1007/978-3-642-41278-3_74
   Liu YC, 2022, INT J DOC ANAL RECOG, V25, P29, DOI 10.1007/s10032-021-00384-2
   Martínek J, 2020, NEURAL COMPUT APPL, V32, P17209, DOI 10.1007/s00521-020-04910-x
   Milosevic N, 2019, INT J DOC ANAL RECOG, V22, P55, DOI 10.1007/s10032-019-00317-0
   Patel C, 2012, INT J COMPUT APPL, V55, P50, DOI 10.5120/8794-2784
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rasheed AS, 2020, INT J PATTERN RECOGN, V34, P0, DOI 10.1142/S0218001420500342
   Smith R, 2007, PROC INT CONF DOC, V0, PP629, DOI 10.1109/icdar.2007.4376991
   Tata S, 2007, SIGMOD RECORD, V36, P7, DOI 10.1145/1328854.1328855
   Wang Zilong, 2020, FINDINGS ASS COMPUTA, V0, PP898, DOI 10.18653/V1/2020.FINDINGSEMNLP.80
   Xia PP, 2015, INFORM SCIENCES, V307, P39, DOI 10.1016/j.ins.2015.02.024
NR 20
TC 0
Z9 0
U1 2
U2 2
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD JUN 15
PY 2023
VL 37
IS 07
BP 
EP 
DI 10.1142/S0218001423520092
EA APR 2023
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K8GO1
UT WOS:000980466100002
DA 2023-11-10
ER

PT J
AU Stefanini, M
   Cornia, M
   Baraldi, L
   Cascianelli, S
   Fiameni, G
   Cucchiara, R
AF Stefanini, Matteo
   Cornia, Marcella
   Baraldi, Lorenzo
   Cascianelli, Silvia
   Fiameni, Giuseppe
   Cucchiara, Rita
TI From Show to Tell: A Survey on Deep Learning-Based Image Captioning
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Image captioning; vision-and-language; deep learning; survey
ID transformer; generation; language; models
AB Connecting Vision and Language plays an essential role in Generative Intelligence. For this reason, large research efforts have been devoted to image captioning, i.e. describing images with syntactically and semantically meaningful sentences. Starting from 2015 the task has generally been addressed with pipelines composed of a visual encoder and a language model for text generation. During these years, both components have evolved considerably through the exploitation of object regions, attributes, the introduction of multi-modal connections, fully-attentive approaches, and BERT-like early-fusion strategies. However, regardless of the impressive results, research in image captioning has not reached a conclusive answer yet. This work aims at providing a comprehensive overview of image captioning approaches, from visual encoding and text generation to training strategies, datasets, and evaluation metrics. In this respect, we quantitatively compare many relevant state-of-the-art approaches to identify the most impactful technical innovations in architectures and training strategies. Moreover, many variants of the problem and its open challenges are discussed. The final goal of this work is to serve as a tool for understanding the existing literature and highlighting the future directions for a research area where Computer Vision and Natural Language Processing can find an optimal synergy.
C1 [Stefanini, Matteo; Cornia, Marcella; Baraldi, Lorenzo; Cascianelli, Silvia; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, Italy.
   [Fiameni, Giuseppe] NVIDIA AI Technol Ctr, I-21024 Milan, Italy.
   [Fiameni, Giuseppe] CINECA, HPC specialist, Casalecchio Di Reno, Italy.
C3 Universita di Modena e Reggio Emilia; CINECA, Italy
RP Cornia, M (通讯作者)，Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, Italy.
EM matteo.stefanini@unimore.it; marcella.cornia@unimore.it; lorenzo.baraldi@unimore.it; silvia.cascianelli@unimore.it; gfiameni@nvidia.com; rita.cucchiara@unimore.it
CR Agrawal H, 2019, IEEE I CONF COMP VIS, V0, PP8947, DOI 10.1109/ICCV.2019.00904
   Aker A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P1250
   Alikhani M, 2020, P 58 ANN M ASS COMP, V0, P6525
   Anderson P, 2017, P 2017 C EMP METH NA, V0, PP936, DOI 10.18653/v1/D17-1098
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2019, IEEE I CONF COMP VIS, V0, PP4260, DOI 10.1109/ICCV.2019.00436
   Aneja J, 2018, PROC CVPR IEEE, V0, PP5561, DOI 10.1109/CVPR.2018.00583
   [Anonymous], 2014, 3 INT C LEARN REPR, V0, P0
   [Anonymous], 2015, SHOW TELL NEURAL IMA, V0, P0
   Ardila A, 2015, BEHAV NEUROL, V2015, P0, DOI 10.1155/2015/565871
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Bai Z, 2021, P IEEE CVF INT C COM, V0, P5422
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, V0, PP65, DOI 10.3115/1626355.1626389
   Ben HX, 2022, IEEE T MULTIMEDIA, V24, P904, DOI 10.1109/TMM.2021.3060948
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Bigazzi Roberto, 2020, 2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR), V0, PP1152, DOI 10.1109/ICPR48806.2021.9412628
   Caglayan O, 2020, P 28 INT C COMPUTATI, V0, P2322
   Changpinyo S, 2021, PROC CVPR IEEE, V0, PP3557, DOI 10.1109/CVPR46437.2021.00356
   Chaorui Deng, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12358), V0, PP712, DOI 10.1007/978-3-030-58601-0_42
   Chatterjee M, 2018, LECT NOTES COMPUT SC, V11206, P747, DOI 10.1007/978-3-030-01216-8_45
   Chen FH, 2019, ADV NEUR IN, V32, P0
   Chen FH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP46, DOI 10.1145/3123266.3123275
   Chen FH, 2018, PROC CVPR IEEE, V0, PP1345, DOI 10.1109/CVPR.2018.00146
   Chen L, 2021, PROC CVPR IEEE, V0, PP16841, DOI 10.1109/CVPR46437.2021.01657
   Chen L, 2017, PROC CVPR IEEE, V0, PP6298, DOI 10.1109/CVPR.2017.667
   Chen S, 2018, LECT NOTES COMPUT SC, V11215, P72, DOI 10.1007/978-3-030-01252-6_5
   Chen TH, 2017, IEEE I CONF COMP VIS, V0, PP521, DOI 10.1109/ICCV.2017.64
   Chen X, 2015, PROC CVPR IEEE, V0, PP2422, DOI 10.1109/CVPR.2015.7298856
   Chen XP, 2018, PROC CVPR IEEE, V0, PP7995, DOI 10.1109/CVPR.2018.00834
   Cornia Marcella, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10575, DOI 10.1109/CVPR42600.2020.01059
   Cornia M, 2022, ARXIV, V0, P0
   Cornia M, 2020, IEEE INT CONF ROBOT, V0, PP1128, DOI 10.1109/icra40945.2020.9196653
   Cornia M, 2019, PROC CVPR IEEE, V0, PP8299, DOI 10.1109/CVPR.2019.00850
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, P0, DOI 10.1145/3177745
   Cui Y, 2018, PROC CVPR IEEE, V0, PP5804, DOI 10.1109/CVPR.2018.00608
   Dai B, 2018, P EUROPEAN C COMPUTE, V0, P294
   Dai B, 2018, ADV NEUR IN, V31, P0
   Dai B, 2017, ADV NEUR IN, V30, P0
   Dai B, 2017, IEEE I CONF COMP VIS, V0, PP2989, DOI 10.1109/ICCV.2017.323
   Del Chiaro R, 2020, PROC 34 INT C NEURAL, V0, P0
   Desai K, 2021, PROC CVPR IEEE, V0, PP11157, DOI 10.1109/CVPR46437.2021.01101
   Deshpande A, 2019, PROC CVPR IEEE, V0, PP10687, DOI 10.1109/CVPR.2019.01095
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Donahue J, 2015, PROC CVPR IEEE, V0, PP2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R, V0, P0
   Elliott D, 2016, P ACL 2016, V0, P70
   Elliott D, 2015, ARXIV151004709, V0, P0
   Fang H, 2015, PROC CVPR IEEE, V0, PP1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fei Zhengcong, 2019, P AAAI C ART INT WOR, V0, P0
   Feng Y, 2019, PROC CVPR IEEE, V0, PP4120, DOI 10.1109/CVPR.2019.00425
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Biten AF, 2019, PROC CVPR IEEE, V0, PP12458, DOI 10.1109/CVPR.2019.01275
   Gan C, 2017, PROC CVPR IEEE, V0, PP955, DOI 10.1109/CVPR.2017.108
   Gan Z, 2017, PROC CVPR IEEE, V0, PP1141, DOI 10.1109/CVPR.2017.127
   Gao JL, 2019, PROC CVPR IEEE, V0, PP6293, DOI 10.1109/CVPR.2019.00646
   Ge HW, 2019, IEEE I CONF COMP VIS, V0, PP1754, DOI 10.1109/ICCV.2019.00184
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu JX, 2018, LECT NOTES COMPUT SC, V11205, P519, DOI 10.1007/978-3-030-01246-5_31
   Gu JX, 2019, IEEE I CONF COMP VIS, V0, PP10322, DOI 10.1109/ICCV.2019.01042
   Gu JX, 2018, AAAI CONF ARTIF INTE, V0, P6837
   Gu JX, 2017, IEEE I CONF COMP VIS, V0, PP1231, DOI 10.1109/ICCV.2017.138
   Guo D, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P920
   Guo L, 2020, PROC 29 INT JOINT C, V0, P0
   Guo L, 2021, ARXIV, V0, P0
   Guo LT, 2019, PROC CVPR IEEE, V0, PP4199, DOI 10.1109/CVPR.2019.00433
   Guo LT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP765, DOI 10.1145/3343031.3350943
   Gupta A, 2012, P 26 AAAI C ARTIFICI, V0, P606
   Gurari Danna, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12362), V0, PP417, DOI 10.1007/978-3-030-58520-4_25
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He S, 2020, P AS C COMP VIS, V0, P153
   Hendricks LA, 2018, LECT NOTES COMPUT SC, V11206, P269, DOI 10.1007/978-3-030-01216-8_17
   Hendricks LA, 2016, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2016.8
   Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1
   Herdade S, 2019, ADV NEUR IN, V32, P0
   Hessel J, 2021, ARXIV, V0, P0
   Hodosh M, 2016, P 5 WORKSHOP VISION, V0, P19
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hossain MZ, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3295748
   Hosseinzadeh M, 2021, PROC CVPR IEEE, V0, PP2724, DOI 10.1109/CVPR46437.2021.00275
   Hu X, 2021, ARXIV, V0, P0
   Hu XW, 2021, AAAI CONF ARTIF INTE, V35, P1575
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Huang L, 2019, ADV NEUR IN, V32, P0
   Huang QB, 2022, IEEE T MULTIMEDIA, V24, P2004, DOI 10.1109/TMM.2021.3074803
   Jhamtani H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4024
   Ji JY, 2021, AAAI CONF ARTIF INTE, V35, P1655
   Jia C, 2021, PR MACH LEARN RES, V139, P0
   Jia X, 2015, IEEE I CONF COMP VIS, V0, PP2407, DOI 10.1109/ICCV.2015.277
   Jiang Huaizu, 2020, IEEE CVF C COMP VIS, V0, P0
   Jiang M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1475
   Jiang M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2141
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Jing BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2577
   Jing Wang, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP4337, DOI 10.1145/3394171.3413753
   Johnson J, 2016, PROC CVPR IEEE, V0, PP4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2014, ADV NEUR IN, V27, P0
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kasai J, 2021, TRANSPARENT HUMAN EV, V0, P0
   Ke L, 2019, IEEE I CONF COMP VIS, V0, PP8887, DOI 10.1109/ICCV.2019.00898
   Kilickaya M, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P199
   Kim DJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2012
   Kim DJ, 2019, PROC CVPR IEEE, V0, PP6264, DOI 10.1109/CVPR.2019.00643
   Kim H, 2021, P IEEECVF INT C COMP, V0, P2095
   Kipf T N, 2016, ICLR, V0, P0
   Kiros R, 2014, PROC INT C NEURAL IN, V0, P0
   Koehn Philipp, 2009, STAT MACHINE TRANSLA, V0, P0
   Krause J, 2017, PROC CVPR IEEE, V0, PP3337, DOI 10.1109/CVPR.2017.356
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Kuznetsova P, 2014, J T ASS COMPUT LINGU, V2, P351, DOI 10.1162/tacl_a_00188
   Laina I, 2019, IEEE I CONF COMP VIS, V0, PP7413, DOI 10.1109/ICCV.2019.00751
   Lan WY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1549, DOI 10.1145/3123266.3123366
   Lee H, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P220
   Lee Hwanhee, 2020, P 1 WORKSH EV COMP N, V0, P34
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li G, 2019, IEEE I CONF COMP VIS, V0, PP8927, DOI 10.1109/ICCV.2019.00902
   Li S, 2011, P C COMP NAT LANG LE, V0, P220
   Li XY, 2019, AAAI CONF ARTIF INTE, V0, P8650
   Li XR, 2019, IEEE T MULTIMEDIA, V21, P2347, DOI 10.1109/TMM.2019.2896494
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Li YH, 2019, PROC CVPR IEEE, V0, PP12489, DOI 10.1109/CVPR.2019.01278
   Liang XD, 2017, IEEE I CONF COMP VIS, V0, PP3382, DOI 10.1109/ICCV.2017.364
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu F, 2020, ADV NEURAL INFORM PR, V0, P0
   Liu FL, 2021, PROC CVPR IEEE, V0, PP13748, DOI 10.1109/CVPR46437.2021.01354
   Liu FL, 2019, ADV NEUR IN, V32, P0
   Liu FX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6761
   Liu LX, 2019, IEEE I CONF COMP VIS, V0, PP4239, DOI 10.1109/ICCV.2019.00434
   Liu SQ, 2017, IEEE I CONF COMP VIS, V0, PP873, DOI 10.1109/ICCV.2017.100
   Liu W, 2021, ARXIV, V0, P0, DOI DOI 10.48550/arxiv.2101.10804
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Longteng Guo, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Lu JS, 2018, PROC CVPR IEEE, V0, PP7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, V0, PP3242, DOI 10.1109/CVPR.2017.345
   Luo YD, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP2341, DOI 10.1145/3343031.3350961
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Mahajan Shweta, 2020, ADV NEURAL INFORM PR, V33, P3613
   Mao J, 2015, PROC INT C LEARN REP, V0, P0
   Mao YZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4258
   Mathews A, 2018, PROC CVPR IEEE, V0, PP8591, DOI 10.1109/CVPR.2018.00896
   Meng ZH, 2021, PROC CVPR IEEE, V0, PP12674, DOI 10.1109/CVPR46437.2021.01249
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, V0, P747
   Miyazaki T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1780
   Mokady Ron, 2021, ARXIV, V0, P0
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Pan JY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1987, DOI 10.1109/ICME.2004.1394652
   Papineni K, 2002, BLEU METHOD AUTOMATI, V0, P311
   Park CC, 2019, IEEE T PATTERN ANAL, V41, P999, DOI 10.1109/TPAMI.2018.2824816
   Park CC, 2017, PROC CVPR IEEE, V0, PP6432, DOI 10.1109/CVPR.2017.681
   Park DH, 2019, IEEE I CONF COMP VIS, V0, PP4623, DOI 10.1109/ICCV.2019.00472
   Pedersoli M, 2017, IEEE I CONF COMP VIS, V0, PP1251, DOI 10.1109/ICCV.2017.140
   Pont-Tuset Jordi, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12350), V0, PP647, DOI 10.1007/978-3-030-58558-7_38
   Qin Y, 2019, PROC CVPR IEEE, V0, PP8359, DOI 10.1109/CVPR.2019.00856
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Radford Alec, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2103.00020
   Ramanishka V, 2017, PROC CVPR IEEE, V0, PP3135, DOI 10.1109/CVPR.2017.334
   Ramesh A, 2021, ARXIV, V0, P0
   Ramisa A, 2018, IEEE T PATTERN ANAL, V40, P1072, DOI 10.1109/TPAMI.2017.2721945
   Ranzato M, 2016, ICLR, V0, P1
   Reed S, 2016, PR MACH LEARN RES, V48, P0
   Reed S, 2016, PROC CVPR IEEE, V0, PP49, DOI 10.1109/CVPR.2016.13
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2017, PROC CVPR IEEE, V0, PP1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Rohrbach A, 2018, P C EMP METH NAT LAN, V0, P4035
   Sammani F, 2020, PROC CVPR IEEE, V0, PP4807, DOI 10.1109/CVPR42600.2020.00486
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sharif N, 2020, MACHINE LEARNING PAR, V0, P9
   Sharif N, 2018, LECT NOTES COMPUT SC, V11212, P39, DOI 10.1007/978-3-030-01237-3_3
   Sharma Himanshu, 2020, 2020 INTERNATIONAL CONFERENCE ON POWER ELECTRONICS & IOT APPLICATIONS IN RENEWABLE ENERGY AND ITS CONTROL (PARC), V0, PP325, DOI 10.1109/PARC49193.2020.236619
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shen S, 2021, ARXIV, V0, P0
   Shetty R, 2017, IEEE I CONF COMP VIS, V0, PP4155, DOI 10.1109/ICCV.2017.445
   Shi Zhan, 2020, P 58 ANN M ASS COMP, V0, PP7454, DOI 10.18653/V1/2020.ACL-MAIN.664
   Shizhe Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9959, DOI 10.1109/CVPR42600.2020.00998
   Shuster K, 2019, PROC CVPR IEEE, V0, PP12508, DOI 10.1109/CVPR.2019.01280
   Sidorov O, 2020, EUR C COMP VIS, V0, PP742, DOI 10.1007/978-3-030-58536-5_44
   Simonyan K, 2015, P 3 INT C LEARN REPR, V0, P0
   Song YQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP784, DOI 10.1145/3343031.3350996
   Srinivasan K, 2021, ARXIV, V0, P0
   Sugano Y, 2016, ARXIV, V0, P0
   Sundararajan M, 2017, PR MACH LEARN RES, V70, P0
   Szegedy C, 2015, P IEEE C COMPUTER VI, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Tavakoli HR, 2017, IEEE I CONF COMP VIS, V0, PP2506, DOI 10.1109/ICCV.2017.272
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tran Alasdair, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP13032, DOI 10.1109/CVPR42600.2020.01305
   Unanue IJ, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P915
   Van Miltenburg Emiel, 2018, COLING, V0, P0
   Vaswani A, 2017, P 31 INT C NEUR INF, V0, P6000
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2017, PROC CVPR IEEE, V0, PP1170, DOI 10.1109/CVPR.2017.130
   Vijayakumar AK, 2018, AAAI CONF ARTIF INTE, V0, P7371
   Wang J, 2021, PROC CVPR IEEE, V0, PP1306, DOI 10.1109/CVPR46437.2021.00136
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang LW, 2017, ADV NEUR IN, V30, P0
   Wang QZ, 2022, IEEE T PATTERN ANAL, V44, P1035, DOI 10.1109/TPAMI.2020.3013834
   Wang QZ, 2019, PROC CVPR IEEE, V0, PP4190, DOI 10.1109/CVPR.2019.00432
   Wang SJ, 2021, PROC CVPR IEEE, V0, PP14045, DOI 10.1109/CVPR46437.2021.01383
   Wang YF, 2017, PROC CVPR IEEE, V0, PP7378, DOI 10.1109/CVPR.2017.780
   Wang ZR, 2022, ARXIV, V0, P0
   Welinder Peter, 2010, CALTECH UCSD BIRDS 2, V0, P0
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu Q, 2016, PROC CVPR IEEE, V0, PP203, DOI 10.1109/CVPR.2016.29
   Wu SM, 2017, CSCW17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, V0, PP1180, DOI 10.1145/2998181.2998364
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP1029, DOI 10.1145/3240508.3240640
   Xia QL, 2020, ARXIV, V0, P0
   Xiangxi Shi, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP574, DOI 10.1007/978-3-030-58568-6_34
   Xie HY, 2019, ARXIV, V0, P0
   Xu GH, 2021, PROC CVPR IEEE, V0, PP12632, DOI 10.1109/CVPR46437.2021.01245
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang LJ, 2017, PROC CVPR IEEE, V0, PP1978, DOI 10.1109/CVPR.2017.214
   Yang XY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5000
   Yang X, 2019, IEEE I CONF COMP VIS, V0, PP4249, DOI 10.1109/ICCV.2019.00435
   Yang X, 2019, PROC CVPR IEEE, V0, PP10677, DOI 10.1109/CVPR.2019.01094
   Yang XW, 2021, ARXIV, V0, P0
   Yang Xuewen, 2020, COMPUTER VISION ECCV, V0, P1
   Yang Y, 2011, P C EMP METH NAT LAN, V0, PP444, DOI 10.5555/2145432.2145484
   Yang Z, 2016, P 30 INT C NEUR INF, V29, P2369
   Yang ZY, 2021, PROC CVPR IEEE, V0, PP8747, DOI 10.1109/CVPR46437.2021.00864
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Yao T, 2019, IEEE I CONF COMP VIS, V0, PP2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao T, 2017, IEEE I CONF COMP VIS, V0, PP4904, DOI 10.1109/ICCV.2017.524
   Yao T, 2017, PROC CVPR IEEE, V0, PP5263, DOI 10.1109/CVPR.2017.559
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yi YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P985
   Yin GJ, 2019, PROC CVPR IEEE, V0, PP6234, DOI 10.1109/CVPR.2019.00640
   Yingwei Pan, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10968, DOI 10.1109/CVPR42600.2020.01098
   Yiwu Zhong, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP211, DOI 10.1007/978-3-030-58568-6_13
   You QZ, 2016, PROC CVPR IEEE, V0, PP4651, DOI 10.1109/CVPR.2016.503
   Young P, 2014, T ASSOC COMPUT LING, V2, P67
   Zeyu Wang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12352), V0, PP629, DOI 10.1007/978-3-030-58571-6_37
   Zha ZJ, 2022, IEEE T PATTERN ANAL, V44, P710, DOI 10.1109/TPAMI.2019.2909864
   Zhang L, 2017, PROC INT C NEURAL IN, V0, P0
   Zhang PC, 2021, PROC CVPR IEEE, V0, PP5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang T, 2020, PROC INT C LEARN REP, V0, P0
   Zhang W, 2020, AAAI CONF ARTIF INTE, V34, P9571
   Zhang XY, 2021, PROC CVPR IEEE, V0, PP15460, DOI 10.1109/CVPR46437.2021.01521
   Zhao WT, 2020, AAAI CONF ARTIF INTE, V34, P12984
   Zheng Y, 2019, PROC CVPR IEEE, V0, PP8387, DOI 10.1109/CVPR.2019.00859
   Zhengcong Fei, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP3182, DOI 10.1145/3394171.3413901
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu Q, 2021, AAAI CONF ARTIF INTE, V35, P3608
   Zhu XX, 2021, ARXIV, V0, P0
NR 254
TC 19
Z9 19
U1 57
U2 81
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JAN 1
PY 2023
VL 45
IS 1
BP 539
EP 559
DI 10.1109/TPAMI.2022.3148210
PG 21
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 7B9BG
UT WOS:000899419900033
PM 35130142
DA 2023-11-10
ER

PT J
AU Liu, FY
   Emerson, G
   Collier, N
AF Liu, Fangyu
   Emerson, Guy
   Collier, Nigel
TI Visual Spatial Reasoning
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Spatial relations are a basic part of human cognition. However, they are expressed in natural language in a variety of ways, and previous work has suggested that current vision-and-language models (VLMs) struggle to capture relational information. In this paper, we present Visual Spatial Reasoning (VSR), a dataset containing more than 10k natural text-image pairs with 66 types of spatial relations in English (e.g., under, in front of, facing). While using a seemingly simple annotation format, we show how the dataset includes challenging linguistic phenomena, such as varying reference frames. We demonstrate a large gap between human and model performance: The human ceiling is above 95%, while state-of-the-art models only achieve around 70%. We observe that VLMs' by-relation performances have little correlation with the number of training examples and the tested models are in general incapable of recognising relations concerning the orientations of objects.(1)
C1 [Liu, Fangyu; Emerson, Guy; Collier, Nigel] Univ Cambridge, Cambridge, England.
C3 University of Cambridge
RP Liu, FY (通讯作者)，Univ Cambridge, Cambridge, England.
EM fl399@cam.ac.uk; gete2@cam.ac.uk; nhc30@cam.ac.uk
FU Cambridge Language Sciences Incubator Fund; Grace amp; Thomas C.H. Chan Cambridge Scholarship
CR Akula Arjun, 2020, P 58 ANN M ASS COMP, V0, PP6555, DOI 10.18653/v1/2020.acl-main.586
   Alayrac Jean-Baptiste, 2022, ADV NEURAL INFORM PR, V0, P0
   Andreas J, 2016, PROC CVPR IEEE, V0, PP39, DOI 10.1109/CVPR.2016.12
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Bugliarello E, 2021, T ASSOC COMPUT LING, V9, P978, DOI 10.1162/tacl_a_00408
   Bugliarello Emanuele, 2022, P 39 INT C MACH LEAR, V162 of Proceedings of Machine Learning Research, P2370
   Christie G, 2016, P 2016 C EMPIRICAL M, V0, P1493
   Cirik Volkan, 2018, P C N AM CHAPT ASS C, V0, P781
   Collell G, 2018, AAAI CONF ARTIF INTE, V0, P6765
   Edmonds-Wathen Cris, 2012, 12 INT C MATH ED TOP, V0, P5857
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Li LH, 2019, ARXIV, V0, P0
   Hendricks Lisa Anne, 2021, FINDINGS ASS COMPUTA, V0, PP3635, DOI 10.18653/v1/2021.findings-acl.318
   Huang SH, 2023, ARXIV, V0, P0
   Hudson DA, 2019, PROC CVPR IEEE, V0, PP6693, DOI 10.1109/CVPR.2019.00686
   Jia C, 2021, PR MACH LEARN RES, V139, P0
   Joe Booth, 2023, CLIP VISUAL SPATIAL, V0, P0
   Johnson J, 2017, PROC CVPR IEEE, V0, PP1988, DOI 10.1109/CVPR.2017.215
   Kim W, 2021, PR MACH LEARN RES, V139, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuhnle A, 2019, LECT NOTES COMPUT SC, V11132, P162, DOI 10.1007/978-3-030-11018-5_15
   Kuhnle Alexander, 2018, P WORKSHOP GENERALIZ, V0, P17
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lei J, 2020, P 58 ANN M ASS COMP, V0, PP8211, DOI 10.18653/V1/2020.ACL-MAIN.730
   Levinson S, 2003, SPACE LANGUAGE COGNI, V0, P0, DOI DOI 10.1017/CBO9780511613609
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P10467
   Liu RT, 2019, PROC CVPR IEEE, V0, PP4180, DOI 10.1109/CVPR.2019.00431
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2365
   Liu YH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3976
   Fagundes CKM, 2021, T GIS, V25, P3159, DOI 10.1111/tgis.12815
   Mirzaee R, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P4582
   Parcalabescu L, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8253
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Rosch Philipp J, 2022, FIND ASS COMP LING N, V0, PP1031, DOI 10.18653/v1/2022.findings-naacl.77
   Subramanian S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5198
   Suhr A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6418
   Suhr A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P217, DOI 10.18653/v1/P17-2034
   Talmy L, 1983, SPATIAL ORIENTATION, V0, PP225, DOI 10.1007/978-1-4615-9325-6_11
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Vaswani A, 2017, ARXIV, V30, P5998
   Vukovic N, 2015, COGNITION, V142, P110, DOI 10.1016/j.cognition.2015.05.017
   Xi Chen, 2023, 11 INT C LEARNING RE, V0, P0
   Xie Ning, 2019, NEURIPS 2018 VIGIL W, V0, P0
   Yatskar Mark, 2016, P 2016 C N AM CHAPT, V0, PP193, DOI 10.18653/V1/N16-1023
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zellers R, 2019, PROC CVPR IEEE, V0, PP6713, DOI 10.1109/CVPR.2019.00688
   Zhai XH, 2022, PROC CVPR IEEE, V0, PP18102, DOI 10.1109/CVPR52688.2022.01759
NR 49
TC 0
Z9 0
U1 1
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 20
PY 2023
VL 11
IS 
BP 635
EP 651
DI 10.1162/tacl_a_00566
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA K7VI6
UT WOS:001018475800002
DA 2023-11-10
ER

PT J
AU de Castro, GZ
   Guerra, RR
   Guimaraes, FG
AF de Castro, Giulia Zanon
   Guerra, Rubia Reis
   Guimaraes, Frederico Gadelha
TI Automatic translation of sign language with multi-stream 3D CNN and generation of artificial depth maps
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Sign language recognition; Gesture recognition; Deep learning; 3D convolutional neural networks; Computer vision; Generative adversarial networks
AB Sign languages play an essential role in the cognitive and social development of the deaf, consisting of a natural form of communication and being a symbol of identity and culture. However, hearing loss has a severe social impact due to an existing communication barrier, preventing access to essential services such as education and health. A bi-directional sign language translation may be the solution to bridging the communication gap between the deaf and the listener, completing a two-way communication cycle. Virtual personal assistants can benefit from this technology by extending how users interact with the intelligent system. With this idea, in this work we develop a multi-stream deep learning model to recognize signs of Brazilian (BSL), Indian (ISL), and Korean (KSL) Sign Languages. We combine different types of information for the classification task, using single-stream and multi-stream 3D Convolutional Neural Networks. In addition, considering the largest source of sign data globally - the internet - we propose a depth sensor-free classification method, with depth maps artificially generated through Generative Adversarial Networks. In order to consider the main parameters that encode sign languages, the final architecture is composed of a multi-stream network that receives the segmented hands, the faces, the distances and speeds of the points of articulation, and the RGB frames associated with artificial depth maps. Finally, we provide a visual explanation to understand which regions were important for model decision-making. The best models were obtained using the multi-stream network, presenting an accuracy of 0.91 +/- 0.07, and f1-score of 0.90 +/- 0.08 on publicly available BSL data set. The results suggest that the multi-stream network with artificially generated depth maps is suitable for the task of sign recognition in different languages.
C1 [de Castro, Giulia Zanon; Guerra, Rubia Reis; Guimaraes, Frederico Gadelha] Univ Fed Minas Gerais, Dept Elect Engn, Machine Intelligence & Data Sci Lab MINDS, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
   [de Castro, Giulia Zanon] Univ Fed Minas Gerais, Grad Program Elect Engn, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais; Universidade Federal de Minas Gerais
RP Guimaraes, FG (通讯作者)，Univ Fed Minas Gerais, Dept Elect Engn, Machine Intelligence & Data Sci Lab MINDS, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
EM giuliaz@ufmg.br; rubiarg@cs.ubc.ca; fredericoguimaraes@ufmg.br
FU Coordination for the Im-provement of Higher Education Personnel (CAPES, Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior); Foundation for Re-search of the State of Minas Gerais (FAPEMIG, Fundacao de Amparo a Pesquisa do Estado de Minas Gerais); National Council for Scientific and Technological Development (CNPq), Brazil [306850/2016-8, 312991/2020-7]
CR Almeida Silvia GM, 2019, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.2667329
   Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   Amrutha K, 2021, 2021 INT C INNOVATIV, V0, P1
   Bai Y, 2000, COLUMBIA SOCIAL WORK, V18, P37, DOI 10.7916/CSWR.V18I1.5928
   Barnett S, 2011, AM J PUBLIC HEALTH, V101, P2235, DOI 10.2105/AJPH.2011.300247
   Bilge YC, 2022, IEEE T PATTERN ANAL, V0, P0
   Bragg D, 2019, ASSETS19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, V0, PP16, DOI 10.1145/3308561.3353774
   Brito LF, 2010, GRAMATICA LINGUAS SI, V0, P0
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cerna LR, 2021, EXPERT SYST APPL, V167, P0, DOI 10.1016/j.eswa.2020.114179
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chong TW, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18103554
   Cui RP, 2017, PROC CVPR IEEE, V0, PP1610, DOI 10.1109/CVPR.2017.175
   Zeiler MD, 2013, ARXIV, V0, P0
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Das A, 2018, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2018.00008
   Dhanjal AS, 2022, MULTIMED TOOLS APPL, V81, P4283, DOI 10.1007/s11042-021-11706-1
   Du Y, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17030458
   Escalera S, 2017, GESTURE RECOGNITION, V0, P0
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Forshay Lance, 2016, SIGNALOUD OPEN LETT, V0, P0
   Fuhl W, 2019, IEEE INT CONF COMP V, V0, PP4406, DOI 10.1109/ICCVW.2019.00541
   Geng WD, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep36571
   Goodfellow I, 2014, ADV NEURAL INFORM PR, V27, P0
   Guzsvinecz T, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19051072
   Hosain A, 2019, PR INT CONF DATA SC, V0, PP203, DOI 10.1109/DSAA.2019.00035
   Hoy Matthew B, 2018, MEDICAL REFERENCE SERVICES QUARTERLY, V37, P81, DOI 10.1080/02763869.2018.1404391
   Huang J, 2018, 32 AAAI C ART INT, V0, P0
   Isola Phillip, 2017, IEEE C COMP VIS PATT, V0, P0, DOI DOI 10.1109/CVPR.2017.632
   Jadon S, 2020, VIDEO SUMMARIZATION, V0, P0
   Kaiming He, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV). PROCEEDINGS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Katilmis Z, 2021, EXPERT SYST APPL, V182, P0, DOI 10.1016/j.eswa.2021.115213
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Kushalnagar P, 2018, PUBLIC HEALTH NUTR, V21, P912, DOI 10.1017/S1368980017002865
   Lampert CH, 2009, PROC CVPR IEEE, V0, PP951, DOI 10.1109/CVPRW.2009.5206594
   Lee CKM, 2021, EXPERT SYST APPL, V167, P0, DOI 10.1016/j.eswa.2020.114403
   Li HS, 2020, MULTIMED TOOLS APPL, V79, P27583, DOI 10.1007/s11042-020-09299-2
   Liang ZJ, 2018, COMPUT J, V61, P1724, DOI 10.1093/comjnl/bxy049
   Lupinetti K, 2020, LECT NOTES COMPUT SC, V12242, P420, DOI 10.1007/978-3-030-58465-8_31
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), V0, PP1, DOI 10.1109/SmartCity.2015.38
   Marin G, 2014, IEEE IMAGE PROC, V0, PP1565, DOI 10.1109/ICIP.2014.7025313
   Masood Sarfaraz, 2018, INTELLIGENT ENGINEERING INFORMATICS. PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON FICTA. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 695), V0, PP623, DOI 10.1007/978-981-10-7566-7_63
   Meulder M, 2019, LEGAL RECOGNITION SI, V0, P0
   Passos WL, 2021, IEEE T CIRCUITS-I, V68, P4761, DOI 10.1109/TCSI.2021.3091001
   Qin XB, 2020, PATTERN RECOGN, V106, P0, DOI 10.1016/j.patcog.2020.107404
   Raghuveera T, 2020, SADHANA-ACAD P ENG S, V45, P0, DOI 10.1007/s12046-019-1250-6
   Rastgoo R, 2021, IEEE COMPUT SOC CONF, V0, PP3446, DOI 10.1109/CVPRW53098.2021.00384
   Rastgoo R, 2021, EXPERT SYST APPL, V164, P0, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2021, MULTIMED TOOLS APPL, V80, P127, DOI 10.1007/s11042-020-09700-0
   Rezende T, 2016, 29 SIBGRAPI WORKSH F, V0, P1
   Rezende TM, 2021, NEURAL COMPUT APPL, V33, P10449, DOI 10.1007/s00521-021-05802-4
   Santos AS, 2019, REV LAT-AM ENFERM, V27, P0, DOI 10.1590/1518-8345.2612.3127
   Seredin OS, 2019, INT ARCH PHOTOGRAMM, V42-2, P189, DOI 10.5194/isprs-archives-XLII-2-W12-189-2019
   Sharma S, 2021, EXPERT SYST APPL, V182, P0, DOI 10.1016/j.eswa.2021.115657
   Sridhar A, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1366, DOI 10.1145/3394171.3413528
   Stergiou A, 2019, IEEE IMAGE PROC, V0, PP1830, DOI 10.1109/icip.2019.8803153
   Tahir Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), V0, PP823, DOI 10.1109/ICDSP.2015.7251991
   Tyrone ME, 2010, J PHONETICS, V38, P317, DOI 10.1016/j.wocn.2010.02.003
   Vahdani E, 2022, RECOGNIZING AM SIGN, V0, P0
   Venugopalan A, 2021, EXPERT SYST APPL, V185, P0, DOI 10.1016/j.eswa.2021.115601
   Vogler C, 2003, THESIS CITESEER, V0, P0
   Wadhawan A, 2021, ARCH COMPUT METHOD E, V28, P785, DOI 10.1007/s11831-019-09384-2
   Wan J, 2016, IEEE COMPUT SOC CONF, V0, PP761, DOI 10.1109/CVPRW.2016.100
   Wang HG, 2006, J INF SCI ENG, V22, P1109
   Wang TC, 2018, PROC CVPR IEEE, V0, PP8798, DOI 10.1109/CVPR.2018.00917
   Wei SE, 2016, PROC CVPR IEEE, V0, PP4724, DOI 10.1109/CVPR.2016.511
   Yan JL, 2022, INT J PATTERN RECOGN, V36, P0, DOI 10.1142/S0218001422550035
   Yang S, 2020, LECT NOTES COMPUT SC, V11961, P532, DOI 10.1007/978-3-030-37731-1_43
   Yongsen Ma, 2018, PROCEEDINGS OF THE ACM ON INTERACTIVE, V0, P0
   Zhang L, 2020, ACM T INTEL SYST TEC, V11, P0, DOI 10.1145/3377553
NR 71
TC 1
Z9 1
U1 5
U2 26
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD APR 1
PY 2023
VL 215
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.119394
EA DEC 2022
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 6V8QC
UT WOS:000895304000003
DA 2023-11-10
ER

PT J
AU Kocon, J
   Cichecki, I
   Kaszyca, O
   Kochanek, M
   Szydlo, D
   Baran, J
   Bielaniewicz, J
   Gruza, M
   Janz, A
   Kanclerz, K
   Kocon, A
   Koptyra, B
   Mieleszczenko-Kowszewicz, W
   Milkowski, P
   Oleksy, M
   Piasecki, M
   Radlinski, L
   Wojtasik, K
   Wozniak, S
   Kazienko, P
AF Kocon, Jan
   Cichecki, Igor
   Kaszyca, Oliwier
   Kochanek, Mateusz
   Szydlo, Dominika
   Baran, Joanna
   Bielaniewicz, Julita
   Gruza, Marcin
   Janz, Arkadiusz
   Kanclerz, Kamil
   Kocon, Anna
   Koptyra, Bartlomiej
   Mieleszczenko-Kowszewicz, Wiktoria
   Milkowski, Piotr
   Oleksy, Marcin
   Piasecki, Maciej
   Radlinski, Lukasz
   Wojtasik, Konrad
   Wozniak, Stanislaw
   Kazienko, Przemyslaw
TI ChatGPT: Jack of all trades, master of none
SO INFORMATION FUSION
LA English
DT Article
DE ChatGPT; GPT-4; Natural language processing (NLP); Semantic NLP tasks; Pragmatic NLP tasks; Subjective NLP tasks; Natural language inference (NLI); Sentiment analysis; Offensive content; Emotion recognition; Humor detection; Stance detection; Word sense disambiguation (WSD); Question answering (QA); Model personalization; Text classification; SOTA analysis; Large language model; Prompting
AB OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few -shot evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower than for ChatGPT. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability to personalize ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established.
C1 [Kocon, Jan; Cichecki, Igor; Kaszyca, Oliwier; Kochanek, Mateusz; Szydlo, Dominika; Baran, Joanna; Bielaniewicz, Julita; Gruza, Marcin; Janz, Arkadiusz; Kanclerz, Kamil; Kocon, Anna; Koptyra, Bartlomiej; Mieleszczenko-Kowszewicz, Wiktoria; Milkowski, Piotr; Oleksy, Marcin; Piasecki, Maciej; Radlinski, Lukasz; Wojtasik, Konrad; Wozniak, Stanislaw; Kazienko, Przemyslaw] Wroclaw Univ Sci & Technol, Dept Artificial Intelligence, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.
C3 Wroclaw University of Science & Technology
RP Kocon, J (通讯作者)，Wroclaw Univ Sci & Technol, Dept Artificial Intelligence, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM jan.kocon@pwr.edu.pl; kazienko@pwr.edu.pl
FU National Science Centre, Poland [2021/41/B/ST6/04471]; Polish Ministry of Education and Science, CLARIN-PL; European Regional Development Fund; Department of Artificial Intelligence, Wroclaw University of Science and Technology; Polish Ministry of Education and Science; European Union under the Horizon Europe;  [POIR.04.02.00-00C002/19];  [POIR.01.01. 01-00-0288/22];  [101086321]
CR Alshemali B, 2020, KNOWL-BASED SYST, V191, P0, DOI 10.1016/j.knosys.2019.105210
   Amin MM, 2023, ARXIV, V0, P0
   Annamoradnejad I, 2022, ARXIV, V0, P0
   [Anonymous], 2011, DISCOURSE STUDIES MU, V0, P0
   Antaki F, 2023, MEDRXIV, V0, P0, DOI DOI 10.1101/2023.01.22.23284882
   Aydin O, 2022, OPENAI CHATGPT GENER, V0, P0, DOI DOI 10.2139/SSRN.4308687
   Azaria A, 2022, CHATGPT USAGE LIMITA, V0, P0
   Bang Y, 2023, ARXIV, V0, P0
   Barba E, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1492
   Barbieri F, 2020, FINDINGS ASS COMPUTA, V0, P0, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.148
   Bielaniewicz J, 2022, INT CONF DAT MIN WOR, V0, PP967, DOI 10.1109/ICDMW58026.2022.00125
   Bommarito II M, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2212.14402
   Borji A, 2023, ARXIV, V0, P0
   Brown Tom, 2020, NIPS, V33, P1877
   Lipton ZC, 2015, ARXIV, V0, P0
   Castillo-Gonzalez W, 2022, METAVERSE BASIC APPL, V2, P29
   Chen Y, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2212.10522
   Cobbe K, 2021, ARXIV, V0, P0
   Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4040
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Edmonds P, 2001, P SENSEVAL 2 2 INT W, V0, P1
   Ferrara E, 2023, ARXIV, V0, P0
   Firth JR, 1957, STUDIES LINGUISTIC A, V0, P10
   Ganegedara T, 2018, NATURAL LANGUAGE PRO, V0, P0
   Gao CA, 2022, BIORXIV, V0, P0, DOI DOI 10.1101/2022.12.23.521610
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Gillioz Anthony, 2020, 2020 15TH CONFERENCE ON COMPUTER SCIENCE AND INFORMATION SYSTEMS (FEDCSIS), V0, PP179, DOI 10.15439/2020F20
   Gilson A, 2022, MEDRXIV, V0, P0, DOI DOI 10.1101/2022.12.23.22283901
   Hidalgo JMG, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P240, DOI 10.1109/ICMLA.2012.211
   Goyal T, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2209.12356
   Guo BY, 2023, ARXIV, V0, P0
   Hagendorff T, 2020, MIND MACH, V30, P99, DOI 10.1007/s11023-020-09517-8
   He P, 2021, ARXIV, V0, P0
   Jeblick K, 2022, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2212.14882
   Jiao WX, 2023, ARXIV, V0, P0
   Johnson R, 2016, PR MACH LEARN RES, V48, P0
   Kanclerz K, 2022, P 1 WORKSH PERSP APP, V0, P37
   Kanclerz K, 2021, P 59 ANN M ASS COMP, V1, P5915, DOI 10.18653/V1
   Karanjai R, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arxiv.2301.00665
   Karfi IE, 2022, INT J ADV COMPUT SC, V13, P0
   Kazienko P, 2023, INFORM FUSION, V94, P43, DOI 10.1016/j.inffus.2023.01.010
   Kilgarriff A, 2000, LANGUAGE, V76, P706, DOI 10.2307/417141
   Kivlichan ID, 2021, ARXIV, V0, P0
   Kocon J, 2019, P 23 C COMPUTATIONAL, V0, PP980, DOI 10.18653/v1/K19-1092
   Kocon J, 2021, IEEE DATA MINING, V0, PP1168, DOI 10.1109/ICDM51629.2021.00140
   Kocon J, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102643
   Korczynski W, 2022, INT CONF DAT MIN WOR, V0, PP419, DOI 10.1109/ICDMW58026.2022.00062
   Kosinski M, 2023, ARXIV, V0, P0
   Kumar P, 2022, ONLINE INFORM REV, V46, P1242, DOI 10.1108/OIR-03-2021-0184
   Kung TH, 2022, MEDRXIV, V0, P0
   Kutela Boniphace, 2023, CHATGPTS SCI WRITING, V0, P0
   Levesque HJ, 2012, P INT WORKSHOP TEMPO, V0, P552
   Li YF, 2023, ARXIV, V0, P0
   Liang Percy, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2211.09110
   LIn T, 2022, OPEN, V3, P111, DOI 10.1016/J.AIOPEN.2022.10.001
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu PF, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3560815
   Liu PJ, 2018, 6 INT C LEARNING REP, V0, P0
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Loureiro D, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P251
   Lund B, 2023, CHATTING CHATGPT MAY, V0, P0
   Milkowski P, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS AND OTHER AFFILIATED EVENTS (PERCOM WORKSHOPS), V0, P0, DOI DOI 10.1109/PerComWorkshops53856.2022.9767502
   Milkowski P, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P248
   Moro Andrea, 2015, P 9 INT WORKSH SEM E, V0, PP288, DOI 10.18653/V1/S15-2049
   Morris Charles William, 1938, INT ENCY UNIFIED SCI, V0, P1
   Navigli R, 2013, P 7 INT WORKSH SEM E, V2, P222
   Ngo A, 2022, P 1 WORKSH PERSP APP, V0, P46
   Ni JJ, 2023, ARTIF INTELL REV, V56, P3055, DOI 10.1007/s10462-022-10248-8
   Nori H, 2023, ARXIV, V0, P0
   OpenAI, 2023, GPT4 OPENAI, V0, P0
   Ouyang L, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2203.02155
   Patra B, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2210.14867
   Peng BL, 2023, ARXIV, V0, P0
   Perlman AM, 2022, IMPLICATIONS OPENAIS, V0, P0
   Phillips T, 2022, EXAMINING PEDAGOGICA, V0, P54
   Pilehvar MT, 2019, P 2019 C N AM CHAPT, V1, P2
   Pradhan Sameer, 2007, P 4 INT WORKSH SEM E, V0, P87
   Price I, 2020, P 4 WORKSH ONL AB HA, V0, PP114, DOI 10.18653/v1/2020.alw-1.15
   Puerto H, 2023, ARXIV, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99
   Rahman W, 2020, P 58 ANN M ASS COMP, V0, P5
   Rajpurkar P, 2018, ARXIV, V0, P0
   Sahmoud T, 2022, ARXIV, V0, P0
   Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8
   Siddiqui R, 2019, SARCASMANIA SARCASM, V0, P0
   Snyder Benjamin, 2004, SENSEVAL 3, V0, P41
   Srivastava Aarohi, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2206.04615
   Susnjak T, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2212.09292
   Tabone W, 2023, USING CHATGPT HUMAN, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang JD, 2023, ARXIV, V0, P0
   Wang SN, 2021, ARXIV, V0, P0
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   Wenzlaff Karsten, 2022, SMARTER HUMANS VALID, V0, P0, DOI DOI 10.2139/ssrn.4302443
   White J, 2023, ARXIV, V0, P0
   Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1391, DOI 10.1145/3038912.3052591
   Xu YC, 2018, ARXIV, V0, P0
   Zhao L, 2022, ARXIV, V0, P0
   Zhuo TY, 2023, ARXIV, V0, P0
   Zoph Barret, 2022, ARXIV, V0, P0
NR 105
TC 6
Z9 6
U1 74
U2 74
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD NOV 15
PY 2023
VL 99
IS 
BP 
EP 
DI 10.1016/j.inffus.2023.101861
EA JUN 2023
PG 37
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA L7RA5
UT WOS:001025183100001
DA 2023-11-10
ER

PT J
AU Pham, NT
   Dang, DNM
   Nguyen, ND
   Nguyen, TT
   Nguyen, H
   Manavalan, B
   Lim, CP
   Nguyen, SD
AF Pham, Nhat Truong
   Dang, Duc Ngoc Minh
   Nguyen, Ngoc Duy
   Nguyen, Thanh Thi
   Nguyen, Hai
   Manavalan, Balachandran
   Lim, Chee Peng
   Nguyen, Sy Dzung
TI Hybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks for speech emotion recognition
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Mel spectrogram features; Generative adversarial networks; Attention mechanism; Dilated convolutional neural networks; Dilated recurrent neural networks; Long short-term memory; Hybrid data augmentation; Short-time Fourier transform
ID model
AB Recently, speech emotion recognition (SER) has become an active research area in speech processing, particularly with the advent of deep learning (DL). Numerous DL-based methods have been proposed for SER. However, most of the existing DL-based models are complex and require a large amounts of data to achieve a good performance. In this study, a new framework of deep attention-based dilated convolutional -recurrent neural networks coupled with a hybrid data augmentation method was proposed for addressing SER tasks. The hybrid data augmentation method constitutes an upsampling technique for generating more speech data samples based on the traditional and generative adversarial network approaches. By leveraging both convolutional and recurrent neural networks in a dilated form along with an attention mechanism, the proposed DL framework can extract high-level representations from three-dimensional log Mel spectrogram features. Dilated convolutional neural networks acquire larger receptive fields, whereas dilated recurrent neural networks overcome complex dependencies as well as the vanishing and exploding gradient issues. Furthermore, the loss functions are reconfigured by combining the SoftMax loss and the center-based losses to classify various emotional states. The proposed framework was implemented using the Python programming language and the TensorFlow deep learning library. To validate the proposed framework, the EmoDB and ERC benchmark datasets, which are imbalanced and/or small datasets, were employed. The experimental results indicate that the proposed framework outperforms other related state-of-the-art methods, yielding the highest unweighted recall rates of 88.03 & PLUSMN; 1.39 (%) and 66.56 & PLUSMN; 0.67 (%) for the EmoDB and ERC datasets, respectively.
C1 [Pham, Nhat Truong; Manavalan, Balachandran] Sungkyunkwan Univ, Coll Biotechnol & Bioengn, Dept Integrat Biotechnol, Computat Biol & Bioinformat Lab, Suwon 16419, Gyeonggi Do, South Korea.
   [Dang, Duc Ngoc Minh] FPT Univ, Comp Fundamental Dept, Ho Chi Minh, Vietnam.
   [Nguyen, Ngoc Duy] Inveto Res, Brisbane, Qld, Australia.
   [Nguyen, Thanh Thi] Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   [Nguyen, Hai] Northeastern Univ, Khoury Coll, Comp Sci, Boston, MA USA.
   [Lim, Chee Peng] Deakin Univ, Inst Intelligent Syst Res & Innovat, Geelong, Vic, Australia.
   [Nguyen, Sy Dzung] Van Lang Univ, Inst Computat Sci & Artificial Intelligence, Lab Computat Mechatron, Ho Chi Minh City, Vietnam.
   [Nguyen, Sy Dzung] Van Lang Univ, Fac Mech Elect & Comp Engn, Sch Technol, Ho Chi Minh City, Vietnam.
   [Nguyen, Sy Dzung] Van Lang Univ, Inst Computat Sci & Artificial Intelligence, Lab Computat Mechatron, Ho Chi Minh City, Vietnam.
C3 Sungkyunkwan University (SKKU); FPT University; Deakin University; Northeastern University; Deakin University; Van Lang University; Van Lang University; Van Lang University
RP Nguyen, SD (通讯作者)，Van Lang Univ, Inst Computat Sci & Artificial Intelligence, Lab Computat Mechatron, Ho Chi Minh City, Vietnam.
EM truongpham96@skku.edu; ducdnm2@fe.edu.vn; duy.nguyen@inveto.ai; thanh.nguyen@deakin.edu.au; nguyen.hai1@northeastern.edu; bala2022@skku.edu; chee.lim@deakin.edu.au; duy.nguyen@inveto.ai
FU Vietnam National Foundation for Science and Technology Development (NAFOSTED) [107.01-2019.328]
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Albornoz EM, 2011, COMPUT SPEECH LANG, V25, P556, DOI 10.1016/j.csl.2010.10.001
   Alzubi JA, 2020, J INTELL FUZZY SYST, V39, P1021, DOI 10.3233/JIFS-191933
   Alzubi OA, 2020, NEURAL COMPUT APPL, V32, P16091, DOI 10.1007/s00521-020-04761-6
   Arias JP, 2014, COMPUT SPEECH LANG, V28, P278, DOI 10.1016/j.csl.2013.07.002
   Bao F, 2019, INTERSPEECH, V0, PP2828, DOI 10.21437/Interspeech.2019-2293
   Burkhardt F, 2005, INTERSPEECH, V0, P1517
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Cao HW, 2015, COMPUT SPEECH LANG, V29, P186, DOI 10.1016/j.csl.2014.01.003
   Cen L, 2016, EMOTIONS TECHNOLOGY, V0, PP27, DOI 10.1016/B978-0-12-801856-9.00002-5
   Chang SY, 2017, ADV NEUR IN, V30, P0
   Chen LJ, 2012, DIGIT SIGNAL PROCESS, V22, P1154, DOI 10.1016/j.dsp.2012.05.007
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Dai WH, 2015, INFORM MANAGE-AMSTER, V52, P777, DOI 10.1016/j.im.2015.02.003
   Donahue C, 2019, 7 INT C LEARNING REP, V0, P6
   Haghparast A, 2007, P INT C DIG AUD EFF, V0, P10
   Huang YM, 2019, J AMB INTEL HUM COMP, V10, P1787, DOI 10.1007/s12652-017-0644-8
   Gulrajani I, 2017, ADV NEUR IN, V30, P0
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, P0, DOI 10.1016/j.bspc.2020.101894
   Jeon YJ, 2022, BRIEF BIOINFORM, V23, P0, DOI 10.1093/bib/bbac243
   Kingma DP, 2014, C TRACK P, V0, P0
   Lalitha S, 2020, APPL ACOUST, V170, P0, DOI 10.1016/j.apacoust.2020.107519
   Lee CC, 2011, SPEECH COMMUN, V53, P1162, DOI 10.1016/j.specom.2011.06.004
   LENT K, 1989, COMPUT MUSIC J, V13, P65, DOI 10.2307/3679554
   Li YX, 2020, INT CONF ACOUST SPEE, V0, PP286, DOI 10.1109/icassp40776.2020.9054433
   Lyons James, 2020, JAMESLYONS PYTHON SP, V0, P0, DOI DOI 10.5281/zenodo.3607820
   McFee Brian, 2015, P 14 PYTHON SCI C, V8, P18
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Movassagh AA, 2021, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-020-02623-6
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Ho NH, 2020, IEEE ACCESS, V8, P61672, DOI 10.1109/ACCESS.2020.2984368
   Park DS, 2019, INTERSPEECH, V0, PP2613, DOI 10.21437/Interspeech.2019-2680
   Peng ZC, 2020, IEEE ACCESS, V8, P16560, DOI 10.1109/ACCESS.2020.2967791
   Pham NT, 2023, J INFORM TELECOMMUN, V7, P317, DOI 10.1080/24751839.2023.2187278
   Pham Nhat Truong, 2020, J ADV ENG COMPUTATIO, V0, P273
   Pham Nhat Truong, 2022, INT C ADV ENG THEOR, V0, P563
   Qian YM, 2019, SPEECH COMMUN, V114, P1, DOI 10.1016/j.specom.2019.08.006
   Radford Alec, 2016, ICLR, V0, P0, DOI DOI 10.48550/ARXIV.1511.06434
   Rebai I, 2017, PROCEDIA COMPUT SCI, V112, P316, DOI 10.1016/j.procs.2017.08.003
   Nguyen SD, 2022, IEEE T FUZZY SYST, V30, P3514, DOI 10.1109/TFUZZ.2021.3118113
   Nguyen SD, 2018, IEEE T FUZZY SYST, V26, P985, DOI 10.1109/TFUZZ.2017.2701313
   Tiwari U, 2020, INT CONF ACOUST SPEE, V0, PP7194, DOI 10.1109/icassp40776.2020.9053581
   Tzirakis P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5089, DOI 10.1109/ICASSP.2018.8462677
   Wu CH, 2011, IEEE T AFFECT COMPUT, V2, P10, DOI 10.1109/T-AFFC.2010.16
   Xu Huahu, 2010, 2010 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE (AICI 2010), V0, PP537, DOI 10.1109/AICI.2010.118
   Yeh JH, 2011, COMPUT HUM BEHAV, V27, P1545, DOI 10.1016/j.chb.2010.10.027
   Yi L, 2022, IEEE T NEUR NET LEAR, V33, P172, DOI 10.1109/TNNLS.2020.3027600
   Yoon WJ, 2007, LECT NOTES COMPUT SC, V4611, P758
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang X, 2022, BRIEF BIOINFORM, V0, P0, DOI DOI 10.1093/bib/bbac545
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhu TY, 2020, J HEALTHC INFORM RES, V4, P308, DOI 10.1007/s41666-020-00068-2
NR 52
TC 0
Z9 0
U1 3
U2 3
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 15
PY 2023
VL 230
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120608
EA JUN 2023
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA L0LI1
UT WOS:001020251500001
DA 2023-11-10
ER

PT J
AU Garimella, A
   Banea, C
   Mihalcea, R
AF Garimella, Aparna
   Banea, Carmen
   Mihalcea, Rada
TI Reflection of Demographic Background on Word Usage
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID behavior
AB The availability of personal writings in electronic format provides researchers in the fields of linguistics, psychology, and computational linguistics with an unprecedented chance to study, on a large scale, the relationship between language use and the demographic background of writers, allowing us to better understand people across different demographics. In this article, we analyze the relation between language and demographics by developing cross-demographic word models to identify words with usage bias, or words that are used in significantly different ways by speakers of different demographics. Focusing on three demographic categories, namely, location, gender, and industry, we identify words with significant usage differences in each category and investigate various approaches of encoding a word's usage, allowing us to identify language aspects that contribute to the differences. Our word models using topic-based features achieve at least 20% improvement in accuracy over the baseline for all demographic categories, even for scenarios with classification into 15 categories, illustrating the usefulness of topic-based features in identifying word usage differences. Further, we note that for location and industry, topics extracted from immediate context are the best predictors of word usages, hinting at the importance of word meaning and its grammatical function for these demographics, while for gender, topics obtained from longer contexts are better predictors for word usage.
C1 [Garimella, Aparna] Adobe Res, Adobe Big Data Experience Lab, Bangalore, India.
   [Banea, Carmen; Mihalcea, Rada] Univ Michigan, Comp Sci & Engn, Ann Arbor, MI USA.
C3 Adobe Systems Inc.; University of Michigan System; University of Michigan
RP Garimella, A (通讯作者)，Adobe Res, Adobe Big Data Experience Lab, Bangalore, India.
EM garimell@adobe.com; carmen.banea@gmail.com; mihalcea@umich.edu
FU John Templeton Foundation [48503, 62256]
CR [Anonymous], 2009, SIGKDD EXPLOR NEWSL, V11, P10, DOI 10.1145/1656274.1656278
   [Anonymous], 2010, LREC, V0, P0
   [Anonymous], 1991, THINKING CULTURES EX, V0, P0
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boroditsky L, 2001, COGNITIVE PSYCHOL, V43, P1, DOI 10.1006/cogp.2001.0748
   Boroditsky L, 2003, BRADFORD BOOKS, V0, P61
   Cohen D, 1996, J PERS SOC PSYCHOL, V70, P945, DOI 10.1037/0022-3514.70.5.945
   DESECONDAT C, 1748, SPIRIT LAWS, V0, P0
   FURNHAM A, 1983, PSYCHOL MED, V13, P829, DOI 10.1017/S0033291700051540
   Garimella A, 2016, P COLING 2016 26 INT, V0, P674
   Garimella Aparna, 2017, P 2017 C EMPIRICAL M, V0, P2275
   Ignatow Gabe, 2012, AM SOC ASS ANN M, V0, P0
   Kern Stephen, 2003, CULTURE TIME SPACE 1, V0, P0
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   MCCARTY JA, 1993, J ADVERTISING, V22, P77, DOI 10.1080/00913367.1993.10673420
   NEWCOMER S, 1992, J SCHOOL HEALTH, V62, P265, DOI 10.1111/j.1746-1561.1992.tb01242.x
   Paul MJ, 2009, P 2009 C EMP METH NA, V0, P1408
   Pennebaker JW, 1996, J PERS SOC PSYCHOL, V70, P372, DOI 10.1037/0022-3514.70.2.372
   Pennebaker JW, 2001, LINGUISTIC INQUIRY W, V0, P0, DOI DOI 10.4018/978-1-60960-741-8.CH012
   Shwartz V, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P2842
   Shweder RA, 2006, HDB CHILD PSYCHOL, V1, P716
   Strapparava C, 2004, P 4 INT C LANGUAGE R, V0, P0
   STREET BV, 1993, BRIT S AP L, V7, P23
   Vilares David, 2018, P 2 WORKSHOP COMPUTA, V0, PP123, DOI 10.18653/v1/W18-1116
   Wilson Theresa, 2005, P HLTEMNLP INTERACTI, V0, PP34, DOI 10.3115/1225733.1225751
   Yin Zh, 2011, WWW, V0, PP247, DOI 10.1145/1963405.1963443
NR 26
TC 0
Z9 0
U1 3
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN 1
PY 2023
VL 49
IS 2
BP 373
EP 394
DI 10.1162/coli_a_00475
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA L1IC1
UT WOS:001020851700004
DA 2023-11-10
ER

PT J
AU Qu, LY
   Weber, C
   Wermter, S
AF Qu, Leyuan
   Weber, Cornelius
   Wermter, Stefan
TI Emphasizing unseen words: New vocabulary acquisition for end-to-end speech recognition
SO NEURAL NETWORKS
LA English
DT Article
DE Automatic speech recognition; Continual learning; Out-of-vocabulary word recognition; End-to-end learning; Loss rescaling
ID neural-networks; attention
AB Due to the dynamic nature of human language, automatic speech recognition (ASR) systems need to continuously acquire new vocabulary. Out-Of-Vocabulary (OOV) words, such as trending words and new named entities, pose problems to modern ASR systems that require long training times to adapt their large numbers of parameters. Different from most previous research focusing on language model post-processing, we tackle this problem on an earlier processing level and eliminate the bias in acoustic modeling to recognize OOV words acoustically. We propose to generate OOV words using text-to -speech systems and to rescale losses to encourage neural networks to pay more attention to OOV words. Specifically, we enlarge the classification loss used for training neural networks' parameters of utterances containing OOV words (sentence-level), or rescale the gradient used for back-propagation for OOV words (word-level), when fine-tuning a previously trained model on synthetic audio. To overcome catastrophic forgetting, we also explore the combination of loss rescaling and model regularization, i.e. L2 regularization and elastic weight consolidation (EWC). Compared with previous methods that just fine-tune synthetic audio with EWC, the experimental results on the LibriSpeech benchmark reveal that our proposed loss rescaling approach can achieve significant improvement on the recall rate with only a slight decrease on word error rate. Moreover, word-level rescaling is more stable than utterance-level rescaling and leads to higher recall rates and precision rates on OOV word recognition. Furthermore, our proposed combined loss rescaling and weight consolidation methods can support continual learning of an ASR system.(c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Qu, Leyuan; Weber, Cornelius; Wermter, Stefan] Univ Hamburg, Dept Informat, Knowledge Technol, Hamburg, Germany.
   [Qu, Leyuan] Zhejiang Lab, Dept Artificial Intelligence, Hangzhou, Peoples R China.
C3 University of Hamburg; Zhejiang Laboratory
RP Qu, LY (通讯作者)，Univ Hamburg, Dept Informat, Knowledge Technol, Hamburg, Germany.
EM qu@informatik.uni-hamburg.de; cornelius.weber@uni-hamburg.de; stefan.wermter@uni-hamburg.de
FU China Scholarship Council (CSC); Youth Foundation Project of Zhejiang Lab [K2023KH0AA01]; German Research Foundation DFG [TRR 169]
CR Afouras T, 2018, ARXIV, V0, P0
   Ahrens K, 2021, LECT NOTES COMPUT SC, V12892, P409, DOI 10.1007/978-3-030-86340-1_33
   Aleksic P, 2015, INT CONF ACOUST SPEE, V0, PP5172, DOI 10.1109/ICASSP.2015.7178957
   Amodei D, 2016, PR MACH LEARN RES, V48, P0
   [Anonymous], 2013, PROC 30 INT C MACH L, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bandanau D, 2016, INT CONF ACOUST SPEE, V0, PP4945, DOI 10.1109/ICASSP.2016.7472618
   Braun S, 2018, INTERSPEECH, V0, P17
   Brown PF, 1992, COMPUTATIONAL LINGUISTICS, V18, P467
   Chan W, 2016, INT CONF ACOUST SPEE, V0, PP4960, DOI 10.1109/ICASSP.2016.7472621
   Chorowski J, 2015, ADV NEUR IN, V28, P0
   Cossu A, 2021, NEURAL NETWORKS, V143, P607, DOI 10.1016/j.neunet.2021.07.021
   Dean J, 2012, P NIPS, V0, P1232
   Ehret B, 2021, ARXIV, V0, P0
   Fan RC, 2019, INTERSPEECH, V0, PP4390, DOI 10.21437/Interspeech.2019-2218
   Graves A, 2008, THESIS, V0, P0
   Graves A, 2012, P 23 INT C MACHINE L, V0, P0
   Graves Alex, 2006, P 23 INT C MACH LEAR, V0, P369
   Gulati A, 2020, INTERSPEECH, V0, PP5036, DOI 10.21437/Interspeech.2020-3015
   Guo JX, 2019, INT CONF ACOUST SPEE, V0, PP5651, DOI 10.1109/ICASSP.2019.8683745
   Han W, 2020, INTERSPEECH, V0, PP3610, DOI 10.21437/Interspeech.2020-2059
   Hayashi T, 2018, IEEE W SP LANG TECH, V0, PP426, DOI 10.1109/SLT.2018.8639619
   Hori T, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP287, DOI 10.1109/ASRU.2017.8268948
   Hori T, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P518, DOI 10.18653/v1/P17-1048
   Hwang K, 2016, INT CONF ACOUST SPEE, V0, PP5335, DOI 10.1109/ICASSP.2016.7472696
   Kannan A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5824, DOI 10.1109/ICASSP.2018.8462682
   Kim S, 2017, INT CONF ACOUST SPEE, V0, PP4835, DOI 10.1109/ICASSP.2017.7953075
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Knill KM, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP138, DOI 10.1109/ASRU.2013.6707719
   Ko T, 2017, INT CONF ACOUST SPEE, V0, PP5220, DOI 10.1109/ICASSP.2017.7953152
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kriman S, 2020, INT CONF ACOUST SPEE, V0, PP6124, DOI 10.1109/ICASSP40776.2020.9053889
   Laptev A, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, V0, P439, DOI 10.1109/CISP-BMEI51763.2020.9263564
   Leang I, 2020, IEEE INT C INTELL TR, V0, P0, DOI DOI 10.1109/itsc45102.2020.9294676
   Li J, 2019, INTERSPEECH, V0, PP71, DOI 10.21437/Interspeech.2019-1819
   Li JY, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP111, DOI 10.1109/ASRU.2017.8268924
   Likhomanenko T, 2019, INTERSPEECH, V0, PP3915, DOI 10.21437/Interspeech.2019-3107
   Mang Q, 2020, INT CONF ACOUST SPEE, V0, PP7829, DOI 10.1109/ICASSP40776.2020.9053896
   Maskey SR, 2004, IEEE INT C AC SPEECH, V1, P0
   Meng ZO, 2021, IEEE W SP LANG TECH, V0, PP243, DOI 10.1109/SLT48900.2021.9383515
   Miao HR, 2020, INT CONF ACOUST SPEE, V0, PP6084, DOI 10.1109/ICASSP40776.2020.9053165
   Miao HR, 2019, INTERSPEECH, V0, PP2623, DOI 10.21437/Interspeech.2019-2018
   Miao YJ, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP398, DOI 10.1109/ASRU.2013.6707763
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Park DS, 2019, INTERSPEECH, V0, PP2613, DOI 10.21437/Interspeech.2019-2680
   Ping Wei, 2018, ICLR, V0, P0
   Povey D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5874, DOI 10.1109/ICASSP.2018.8462497
   Prabhavalkar R, 2017, INTERSPEECH, V0, PP3702, DOI 10.21437/Interspeech.2017-232
   Rao K, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP193, DOI 10.1109/ASRU.2017.8268935
   Reddy CKA, 2019, INTERSPEECH, V0, PP1816, DOI 10.21437/Interspeech.2019-3087
   Rosenberg A, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP996, DOI 10.1109/asru46091.2019.9003990
   Rossenbach N, 2020, INT CONF ACOUST SPEE, V0, PP7069, DOI 10.1109/ICASSP40776.2020.9053008
   Sheikh I, 2017, IEEE-ACM T AUDIO SPE, V25, P598, DOI 10.1109/TASLP.2017.2651361
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4779, DOI 10.1109/ICASSP.2018.8461368
   Sim KC, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP23, DOI 10.1109/asru46091.2019.9003775
   Tjandra A, 2017, INT JOINT C NATURAL, V0, P0
   Valin JM, 2019, INT CONF ACOUST SPEE, V0, PP5891, DOI 10.1109/ICASSP.2019.8682804
   Valle R, 2020, INT C LEARNING REPRE, V0, P0
   Variani E, 2020, INT CONF ACOUST SPEE, V0, PP6139, DOI 10.1109/icassp40776.2020.9053600
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Williams I, 2018, INTERSPEECH, V0, PP2227, DOI 10.21437/Interspeech.2018-2416
   Hannun AY, 2014, ARXIV, V0, P0
   Zhang B, 2021, P INTERSPEECH, V0, P0
   Zhang BB, 2021, ARXIV, V0, P0
   Zhao D, 2019, INTERSPEECH, V0, PP1418, DOI 10.21437/Interspeech.2019-1209
   Zheng XR, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5674, DOI 10.1109/ICASSP39728.2021.9414778
NR 66
TC 1
Z9 1
U1 4
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD APR 15
PY 2023
VL 161
IS 
BP 494
EP 504
DI 10.1016/j.neunet.2023.01.027
EA FEB 2023
PG 11
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA D0CP2
UT WOS:000965496000001
PM 36805264
DA 2023-11-10
ER

PT J
AU Mahsuli, MM
   Khadivi, S
   Homayounpour, MM
AF Mahsuli, Mohammad Mahdi
   Khadivi, Shahram
   Homayounpour, Mohammad Mehdi
TI LenM: Improving Low-Resource Neural Machine Translation Using Target Length Modeling
SO NEURAL PROCESSING LETTERS
LA English
DT Article; Early Access
DE Deep learning; Natural language processing; Neural machine translation; Recurrent neural network; Sequence-to-sequence mapping; Sequence length modeling; Multiplicative residual connection
AB Neural machine translation (NMT) is a hot field in artificial intelligence which aims at translating a text from a source language into a different target language. Although NMT systems perform quite well in high-resource setup, but their performance for low-resource data is low. One aspect of data scarcity is the lack of diversity in the sentence length of training data. Also, since we usually set a maximum sentence length during training, we observe degeneration in the translation of sentences longer than the max length. In this paper, we propose LenM-a method to model the length of a target (translated) sentence given the source sentence using a deep recurrent neural structure-and apply it to the decoder side of neural machine translation systems to generate translation sentences with appropriate lengths which have a better quality. Our proposed method helps to fix some drawbacks of NMT like output degradation on unseen sentence lengths, and the limitation of using larger beam sizes in the decoding phase of translation. This method can be applied to any NMT model regardless of the structure and does not slow down the translation speed. Moreover, it can be used efficiently in non-autoregressive machine translation systems which need to know the target length before decoding. The final outcome of this paper is improving the output quality of neural machine translation systems when trained on low-resource corpora. Our experiments show the superior performance of the proposed method compared to the state-of-the-art neural machine translation systems when facing target length mismatch in training and inference, with up to 9.82 BLEU points improvement for German-to-English translation and up to 6.28 BLEU points improvement for Arabic-to-English translation.
C1 [Mahsuli, Mohammad Mahdi; Khadivi, Shahram; Homayounpour, Mohammad Mehdi] Amirkabir Univ Technol, Dept Comp Engn, Tehran Polytech, Tehran, Iran.
C3 Amirkabir University of Technology
RP Homayounpour, MM (通讯作者)，Amirkabir Univ Technol, Dept Comp Engn, Tehran Polytech, Tehran, Iran.
EM mahsuli@aut.ac.ir; khadivi@aut.ac.ir; homayoun@aut.ac.ir
CR [Anonymous], 2016, P 1 C MACHINE TRANSL, V0, P0, DOI DOI 10.18653/V1/W16-2341
   [Anonymous], 2015, P 10 WORKSHOP STAT M, V0, P0
   Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Boulanger-Lewandowski N, 2013, ISMIR, V0, P335
   Cettolo M, 2016, INT WORKSH SPOK LANG, V0, P0
   Cettolo M, 2012, PROC EUR ASS MACH TR, V0, P261
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dufter P, 2022, COMPUT LINGUIST, V48, P733, DOI 10.1162/coli_a_00445
   Fu SW, 2018, ARXIV, V0, P0
   Ghazvininejad M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6112
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2014, ARXIV, V0, P0
   Graves A, 2014, ARXIV, V0, P0
   Gu J, 2018, ICLR, V0, P0
   Haddow B, 2022, COMPUT LINGUIST, V48, P673, DOI 10.1162/coli_a_00446
   He K, 2015, P IEEE C COMP VIS PA, V0, Patent No. 2015
   He W, 2016, AAAI CONF ARTIF INTE, V0, P151
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Klein G, 2020, P 14 C ASS MACH TRAN, V0, P102
   Koehn P, 2017, WMT, V0, P28
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lee J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1173
   LEFEBVRE G, 2013, INT C ART NEUR NETW, V0, P0
   Murray K, 2018, P 3 C MACHINE TRANSL, V0, PP212, DOI 10.18653/V1/W18-6322
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, V0, PP392, DOI 10.1080/1472586x.2015.1113070.
   Ray A, 2015, 2015 8 INT C ADV PAT, V0, P0
   Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2685
   Rosendahl J, 2019, P 16 INT C SPOK LANG, V0, P0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shaw Peter, 2018, NAACL, V0, PP5, DOI 10.18653/V1/N18-2074
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, V0, P223
   Stahlberg F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3356
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wu CH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2059
   Wu YH, 2016, ARXIV, V0, P0
NR 43
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s11063-023-11208-1
EA MAR 2023
PG 32
WC Computer Science, Artificial Intelligence
SC Computer Science
GA C3UJ9
UT WOS:000961202900002
DA 2023-11-10
ER

PT J
AU Ren, H
AF Ren, Hao
TI Sports video athlete detection based on deep learning
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Deep learning; Sports video athlete detection technology; Time-sharing memory algorithm; Deep selection network; Feature extraction and enhancement algorithm
ID feature-extraction; motion tracking; classification
AB The deep fusion of sports and machine vision has become a research hot spot in sports video target detection, athlete state recovery and sports promotion. On the basis of in-depth study, it can detect a large number of sports videos, complete the drawing and analysis of human body detection model, and detect and evaluate the posture of corresponding athletes in the video, which can save a lot of costs and maximize the more professional training of athletes. In order to solve the above problems, this paper innovatively completes the automatic language description of sports video based on time-sharing memory algorithm. Its principle is to realize the accurate decomposition of athletes' sports data through the mapping relationship between the corresponding letter sequence and video sequence in time-sharing memory. In order to capture the key posture of athletes' sports video, this paper innovatively proposes an object extraction algorithm based on athletes' skeleton motion enhancement. In practical application, based on the key pose capture, it is necessary to train the depth selection network in time to extract the key pose of the skeleton. Based on this network, it can enhance the key posture of bone information and accurately express its related features. After extracting the actual athlete's bone information, we need to fine-tune the training network to realize the accurate recognition of key features. Based on the above key algorithms, this paper designs a sports video athlete detection system based on deep learning and makes an experimental research on the related sports video. The experimental results show that the detection accuracy of athletes' sports video is improved by nearly 10% compared with the traditional convolution network recognition algorithm, so the algorithm has obvious advantages in recognition accuracy.
C1 [Ren, Hao] Xinxiang Med Univ, Dept Sports, Xinxiang 453003, Henan, Peoples R China.
C3 Xinxiang Medical University
RP Ren, H (通讯作者)，Xinxiang Med Univ, Dept Sports, Xinxiang 453003, Henan, Peoples R China.
EM 201051@xxmu.edu.cn
CR Chen YH, 2021, MATH PROBL ENG, V2021, P0, DOI 10.1155/2021/3326847
   Couceiro R, 2014, PHYSIOL MEAS, V35, P2369, DOI 10.1088/0967-3334/35/12/2369
   Pham DS, 2015, IEEE T IMAGE PROCESS, V24, P332, DOI 10.1109/TIP.2014.2378034
   Fu J, 2013, AUTOMATICA, V49, P3682, DOI 10.1016/j.automatica.2013.09.004
   Goldman GH, 2013, J ACOUST SOC AM, V133, P688, DOI 10.1121/1.4773273
   Hungr N, 2012, IEEE T ROBOT, V28, P1382, DOI 10.1109/TRO.2012.2203051
   Inoue Y, 2014, HUM MOVEMENT SCI, V33, P211, DOI 10.1016/j.humov.2013.10.002
   Ji SB, 2014, MED IMAGE ANAL, V18, P1169, DOI 10.1016/j.media.2014.07.001
   Kim SK, 2013, IEEE T CONSUM ELECTR, V59, P267, DOI 10.1109/TCE.2013.6490269
   Koh YJ, 2015, IEEE T IMAGE PROCESS, V24, P5260, DOI 10.1109/TIP.2015.2479918
   Liu Y, 2012, OPT ENG, V51, P0, DOI 10.1117/1.OE.51.4.047203
   Liu YZ, 2021, J INTELL FUZZY SYST, V40, P2253, DOI 10.3233/JIFS-189223
   Luo XB, 2012, MED IMAGE ANAL, V16, P577, DOI 10.1016/j.media.2010.11.001
   Olesen OV, 2012, IEEE T MED IMAGING, V31, P79, DOI 10.1109/TMI.2011.2165157
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Stancic I, 2013, IET SCI MEAS TECHNOL, V7, P206, DOI 10.1049/iet-smt.2012.0157
   Thanjavur K, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-91614-4
   Thesen S, 2000, MAGNET RESON MED, V44, P457, DOI 10.1002/1522-2594(200009)44:3<457::AID-MRM17>3.0.CO;2-R
   Torheim G, 2001, IEEE T MED IMAGING, V20, P1293, DOI 10.1109/42.974924
   Wang N, 2019, ELECTRON LETT, V55, P554, DOI 10.1049/el.2019.0253
   Wang P, 2021, J INTELL FUZZY SYST, V11, P1, DOI 10.3233/JIFS-219014
   Wu JN, 2007, HUM MOVEMENT SCI, V26, P393, DOI 10.1016/j.humov.2007.01.015
   Yamins DLK, 2016, NAT NEUROSCI, V19, P356, DOI 10.1038/nn.4244
   ZHU Y, 2015, MAGN RESONAN MED, V35, P0
NR 24
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD FEB 15
PY 2023
VL 35
IS 6
BP 4201
EP 4210
DI 10.1007/s00521-022-07077-9
EA MAR 2022
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 8L2VY
UT WOS:000777218600005
DA 2023-11-10
ER

PT J
AU Wang, ZK
   Zhu, HC
   Liu, M
   Qin, B
AF Wang, Zekun
   Zhu, Haichao
   Liu, Ming
   Qin, Bing
TI TAGNet: a tiny answer-guided network for conversational question generation
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Conversational Question Generation; Sequence-to-Sequence Model; Knowledge Distillation; Model Compression
AB Conversational Question Generation (CQG) aims to generate conversational questions with the given passage and conversa-tion history. Previous work of CQG presumes a contiguous span as the answer and generates a question targeting it. However, this limits the application scenarios because answers in practical conversations are usually abstractive free-form text instead of extractive spans. In addition, most state-of-the-art CQG systems are based on pretrained language models consisting of hundreds of millions of parameters, bringing challenges to real-life applications due to latency and capacity constraints. To elegantly address these problems, in this work, we introduce the Tiny Answer-Guided Network (TAGNET) based on the lightweight module (Bi-LSTM) for CQG. We explicitly take the target answers as input, which interacts with the passages and conversation history in the encoder and guides the question generation through the gated attention mechanism in the decoder. Besides, we distill the knowledge from larger pretrained language models into our smaller network to make the trade-off between performance and efficiency. Experimental results show that our TAGNET achieves a comparable perfor-mance with large pretrained language models (retaining 95.9% of teacher performance) while using 5.7x fewer parameters and 10.4x faster inference latency. TAGNET outperforms the previous best-performing model with similar parameter size by a large margin, and further analysis shows that TAGNET generates more answer-specific conversational questions.
C1 [Wang, Zekun; Zhu, Haichao; Liu, Ming; Qin, Bing] Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin, Peoples R China.
   [Liu, Ming; Qin, Bing] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; Peng Cheng Laboratory
RP Wang, ZK; Liu, M (通讯作者)，Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin, Peoples R China.; Liu, M (通讯作者)，Peng Cheng Lab, Shenzhen, Peoples R China.
EM mliu@ir.hit.edu.cn
FU National Key Research and Development Project [2021YFF0901600]; National Science Foundation of China [U22B2059, 61976073, 62276083]; Shenzhen Foundational Research Funding [JCYJ20200109113441941]; Project of State Key Laboratory of Communication Content Cognition [A02101]; Major Key Project of PCL [PCL2021A06]
CR Ba J, 2014, ADV NEURAL INFORM PR, V0, P2654
   Bahdanau D, 2016, ARXIV, V0, P0
   Bao H, 2021, ARXIV, V0, P0
   Bao HB, 2020, PR MACH LEARN RES, V119, P0
   Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2174
   Cunningham JP, 2007, ADV NEURAL INFORM PR, V20, P329
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong L, 2019, ADV NEUR IN, V32, P0
   Du XY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1342, DOI 10.18653/v1/P17-1123
   Du XY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1907
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Gao YF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4853
   Gu J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2061
   Heilman M, 2010, HUMAN LANGUAGE TECHN, V0, P609
   Hinton Geoffrey, 2015, ARXIV150302531, V0, P0
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/NECO.1997.9.8.1735
   Huang H-Y, 2019, INT C LEARNING REPRE, V0, P0
   Jiao X, 2019, ARXIV, V0, P0
   Kim Y, 2019, AAAI CONF ARTIF INTE, V0, P6602
   Kim Yoon, 2016, ARXIV160607947, V0, P0, DOI DOI 10.18653/V1
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li J, 2020, CORR, V0, PP2642, DOI 10.18653/V1/2020.COLING-MAIN.238
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Nakanishi Mao, 2019, P 2 WORKSH MACH READ, V0, PP63, DOI 10.18653/V1/D19-5809
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Pan BY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2114
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Puri R, 2020, ARXIV, V0, P0
   Qi P, 2020, ARXIV, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Richardson M, 2013, P 2013 C EMPIRICAL M, V0, P193
   Romero Adriana, 2015, ICLR, V0, P0
   Sanh V, 2019, ARXIV, V0, P0
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shleifer Sam, 2020, ARXIV, V0, P0
   Song L, 2018, P 2018 C N AM CHAP A, V2, P569
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun XW, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3930
   Tang D, 2017, ARXIV, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang W, 2020, ADV NEURAL INFORM PR, V33, P0
   Wang YS, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2193
   Wang Z, 2021, ARXIV, V0, P0
   Welbl J, 2017, P 3 WORKSHOP NOISY U, V0, PP94, DOI 10.18653/v1/W17-4413
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yuan X, 2017, P 2 WORKSH REPR LEAR, V0, PP15, DOI 10.18653/v1/w17-2603
   Zagoruyko S, 2017, 5 INT C LEARN REPR I, V0, P0
   Zaheer M, 2020, ADV NEUR IN, V33, P0
   Zhang SQ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P127
   Zhao Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3901
   Zhou QY, 2018, LECT NOTES ARTIF INT, V10619, P662, DOI 10.1007/978-3-319-73618-1_56
   Zhu HC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4238
NR 59
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD MAY 15
PY 2023
VL 14
IS 5
BP 1921
EP 1932
DI 10.1007/s13042-022-01737-x
EA DEC 2022
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA E4QJ0
UT WOS:000900811200001
DA 2023-11-10
ER

PT J
AU Guimaraes, N
   Campos, R
   Jorge, A
AF Guimaraes, Nuno
   Campos, Ricardo
   Jorge, Alipio
TI Pre-trained language models: What do they know?
SO WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Article; Early Access
DE large language models; natural language; pretrained language models; processing
AB Large language models (LLMs) have substantially pushed artificial intelligence (AI) research and applications in the last few years. They are currently able to achieve high effectiveness in different natural language processing (NLP) tasks, such as machine translation, named entity recognition, text classification, question answering, or text summarization. Recently, significant attention has been drawn to OpenAI's GPT models' capabilities and extremely accessible interface. LLMs are nowadays routinely used and studied for downstream tasks and specific applications with great success, pushing forward the state of the art in almost all of them. However, they also exhibit impressive inference capabilities when used off the shelf without further training. In this paper, we aim to study the behavior of pre-trained language models (PLMs) in some inference tasks they were not initially trained for. Therefore, we focus our attention on very recent research works related to the inference capabilities of PLMs in some selected tasks such as factual probing and common-sense reasoning. We highlight relevant achievements made by these models, as well as some of their current limitations that open opportunities for further research.This article is categorized under:Fundamental Concepts of Data and Knowledge > Key Design Issues in DataMiningTechnologies > Artificial Intelligence
C1 [Guimaraes, Nuno; Campos, Ricardo; Jorge, Alipio] LIAAD INESCTEC, Porto, Portugal.
   [Guimaraes, Nuno; Jorge, Alipio] Univ Porto, Porto, Portugal.
   [Campos, Ricardo] Univ Beira Interior, Covilha, Portugal.
   [Campos, Ricardo] Polytech Inst Tomar, Ci2 Smart Cities Res Ctr, Tomar, Portugal.
C3 Universidade do Porto; INESC TEC; Universidade do Porto; Universidade da Beira Interior; Instituto Politecnico de Tomar
RP Guimaraes, N (通讯作者)，LIAAD INESCTEC, Porto, Portugal.
EM nuno.r.guimaraes@inesctec.pt
FU FCT-Fundacao para a Ciencia e a Tecnologia; Component 5-Capitalization and Business Innovation [2022.09312]; European Union (EU); Next Generation EU;  [41]
CR Brown TB, 2020, ARXIV, V0, P0
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Bian N, 2023, ARXIV, V0, P0
   Cheng L, 2023, ARXIV, V0, P0
   Clark P, 2018, ARXIV, V0, P0
   Cong Y, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON COMMONSENSE REPRESENTATION AND REASONING (CSRR 2022), V0, P17
   Garcez AD, 2019, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Frith C, 2005, CURR BIOL, V15, PR644, DOI 10.1016/j.cub.2005.08.041
   Ganguly D, 2023, LECT NOTES COMPUT SC, V13982, P331, DOI 10.1007/978-3-031-28241-6_34
   Gao Leo, 2021, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.5371629
   Guo TC, 2023, ARXIV, V0, P0
   Hendrycks D, 2021, P INT C LEARN REPR I, V0, P0
   Jiang ZB, 2021, ARXIV, V0, P0
   Jiang ZB, 2021, T ASSOC COMPUT LING, V9, P962, DOI 10.1162/tacl_a_00407
   Kaneda Y, 2023, CUREUS J MED SCIENCE, V15, P0, DOI 10.7759/cureus.42924
   Kasai J, 2023, ARXIV, V0, P0
   Kassner N, 2020, PROC 58 ANN M ASS CO, V0, PP7811, DOI 10.18653/v1/2020.acl-main.698
   Katz DM, 2023, GPT 4 PASSES BAR EXA, V0, P0, DOI DOI 10.2139/ssrn.4389233
   Kosinski M, 2023, ARXIV, V0, P0
   Kung TH, 2023, PLOS DIGIT HLTH, V2, P0, DOI 10.1101/2022.12.19.22283643
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lamichhane B, 2023, ARXIV, V0, P0
   Levine DM, 2023, MEDRXIV, V0, P0, DOI DOI 10.1101/2023.01.30.23285067
   Lin BY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6862
   Lin S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3214
   Liu P, 2022, PRETRAIN PROMPT PRED, V0, P0
   Liu ZL, 2023, ARXIV, V0, P0
   Loem M, 2023, P 18 WORKSH INN US N, V0, P205
   Lu P, 2023, LONG PAPERS, V0, P14605
   Lu YQ, 2023, ANN BIOMED ENG, V51, P1898, DOI 10.1007/s10439-023-03234-w
   Lyu Q, 2023, VIS COMPUT IND BIOME, V6, P0, DOI 10.1186/s42492-023-00136-5
   Macneil Stephen, 2022, ICER 2022 V2: PROCEEDINGS OF THE 2022 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, V0, PP37, DOI 10.1145/3501709.3544280
   Nori H, 2023, ARXIV, V0, P0
   Nunes D, 2023, ARXIV, V0, P0
   Pelrine K, 2023, ARXIV, V0, P0
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   Raunak V, 2023, ARXIV, V0, P0
   Redford A, 2018, IMPROVING LANGUAGE U, V0, P0
   Savelka J, 2023, ARXIV, V0, P0
   Savelka J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, V0, P0
   Savelka J, 2023, ARXIV, V0, P0
   Savelka J, 2023, ARXIV, V0, P0
   Singh R, 2016, COGNITIVE SCI, V40, P607, DOI 10.1111/cogs.12260
   Sobania D, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR, V0, P23, DOI 10.1109/APR59189.2023.00012
   Stolfo A, 2023, P 61 ANN M ASS COMP, V0, P545
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang H, 2023, P INT JOINT C ART IN, V0, P0
   Weir N, 2020, 42 ANN VIRT M COGN S, V0, P0
   Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4791
   Zhang H, 2022, P 32 INT JOINT C ART, V0, P0
   Zhou A, 2023, ARXIV, V0, P0
   Zhu YK, 2015, ARXIV, V0, P0
   2023, 1900, DOI ARXIV:2303.08774, V0, P0
NR 56
TC 0
Z9 0
U1 6
U2 6
PU WILEY PERIODICALS, INC
PI SAN FRANCISCO
PA ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA
SN 1942-4787
EI 1942-4795
J9 WIRES DATA MIN KNOWL
JI Wiley Interdiscip. Rev.-Data Mining Knowl. Discov.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1002/widm.1518
EA SEP 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA S4BK3
UT WOS:001070635500001
DA 2023-11-10
ER

PT J
AU Zhang, JK
   Mazurowski, MA
   Allen, BC
   Wildman-Tobriner, B
AF Zhang, Jikai
   Mazurowski, Maciej A.
   Allen, Brian C.
   Wildman-Tobriner, Benjamin
TI Multistep Automated Data Labelling Procedure (MADLaP) for thyroid nodules on ultrasound: An artificial intelligence approach for automating image annotation
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Data processing; EHR; Image segmentation; NLP; OCR
ID machine; radiology; classification
AB Machine learning (ML) for diagnosis of thyroid nodules on ultrasound is an active area of research. However, ML tools require large, well-labeled datasets, the curation of which is time-consuming and labor-intensive. The purpose of our study was to develop and test a deep-learning-based tool to facilitate and automate the data annotation process for thyroid nodules; we named our tool Multistep Automated Data Labelling Procedure (MADLaP). MADLaP was designed to take multiple inputs including pathology reports, ultrasound images, and radiology reports. Using multiple step-wise 'modules' including rule-based natural language processing, deeplearning-based imaging segmentation, and optical character recognition, MADLaP automatically identified images of a specific thyroid nodule and correctly assigned a pathology label. The model was developed using a training set of 378 patients across our health system and tested on a separate set of 93 patients. Ground truths for both sets were selected by an experienced radiologist. Performance metrics including yield (how many labeled images the model produced) and accuracy (percentage correct) were measured using the test set. MADLaP achieved a yield of 63 % and an accuracy of 83 %. The yield progressively increased as the input data moved through each module, while accuracy peaked part way through. Error analysis showed that inputs from certain examination sites had lower accuracy (40 %) than the other sites (90 %, 100 %). MADLaP successfully created curated datasets of labeled ultrasound images of thyroid nodules. While accurate, the relatively suboptimal yield of MADLaP exposed some challenges when trying to automatically label radiology images from heterogeneous sources. The complex task of image curation and annotation could be automated, allowing for enrichment of larger datasets for use in machine learning development.
C1 [Zhang, Jikai] Duke Univ, Dept Elect & Comp Engn, Room 10070,2424 Erwin Rd, Durham, NC 27705 USA.
   [Mazurowski, Maciej A.; Allen, Brian C.; Wildman-Tobriner, Benjamin] Duke Univ, Med Ctr, Dept Radiol, Durham, NC USA.
   [Mazurowski, Maciej A.] Duke Univ, Dept Elect & Comp Engn, Dept Biostat & Bioinformat, Dept Comp Sci, Room 9044, 2424 Erwin Rd, Durham, NC 27705 USA.
C3 Duke University; Duke University; Duke University
RP Zhang, JK (通讯作者)，Duke Univ, Dept Elect & Comp Engn, Room 10070,2424 Erwin Rd, Durham, NC 27705 USA.
EM jikai.zhang@duke.edu
FU AI SPARK Award from Duke Center for Artificial Intelligence in Radiology
CR Buda M, 2019, RADIOLOGY, V292, P695, DOI 10.1148/radiol.2019181343
   Chen KJ, 2020, J SURG RES, V256, P557, DOI 10.1016/j.jss.2020.07.015
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820
   Demner-Fushman D, 2009, INT J MED INFORM, V78, PE59, DOI 10.1016/j.ijmedinf.2009.05.003
   Diamant I, 2016, IEEE J BIOMED HEALTH, V20, P1585, DOI 10.1109/JBHI.2015.2478255
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Grupp RB, 2020, INT J COMPUT ASS RAD, V15, P759, DOI 10.1007/s11548-020-02162-7
   Kalra A, 2020, J AM COLL RADIOL, V17, P1149, DOI 10.1016/j.jacr.2020.03.012
   Krsnik I, 2020, DIAGNOSTICS, V10, P0, DOI 10.3390/diagnostics10040196
   Langlotz CP, 2019, RADIOLOGY, V291, P781, DOI 10.1148/radiol.2019190613
   Li HL, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-25005-7
   Li XC, 2019, LANCET ONCOL, V20, P193, DOI 10.1016/S1470-2045(18)30762-9
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770
   Rasoulian A, 2014, PROC SPIE, V9036, P0, DOI 10.1117/12.2043256
   Shin HC, 2016, PROC CVPR IEEE, V0, PP2497, DOI 10.1109/CVPR.2016.274
   Skeppstedt M, 2014, J BIOMED INFORM, V49, P148, DOI 10.1016/j.jbi.2014.01.012
   Smit A, 2020, EMNLP, V0, P0
   Smith R, 2007, PROC INT CONF DOC, V0, PP629, DOI 10.1109/icdar.2007.4376991
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Trivedi HM, 2019, J DIGIT IMAGING, V32, P30, DOI 10.1007/s10278-018-0105-8
   Wang SJ, 2012, MED IMAGE ANAL, V16, P933, DOI 10.1016/j.media.2012.02.005
   Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224
   Wood DA, 2020, P MACHINE LEARNING R, V0, P811
   Yu C, 2020, ARXIV, V0, P0
   Zech J, 2018, RADIOLOGY, V287, P570, DOI 10.1148/radiol.2018171093
   Zhang LC, 2016, MED PHYS, V43, P1175, DOI 10.1118/1.4941011
   Zhou ZW, 2021, MED IMAGE ANAL, V71, P0, DOI 10.1016/j.media.2021.101997
NR 29
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JUL 15
PY 2023
VL 141
IS 
BP 
EP 
DI 10.1016/j.artmed.2023.102553
EA MAY 2023
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA H1ZU2
UT WOS:000994025600001
PM 37295897
DA 2023-11-10
ER

PT J
AU de Varda, AG
   Marelli, M
AF de Varda, Andrea Gregor
   Marelli, Marco
TI Data-driven Cross-lingual Syntax: An Agreement Study with Massively Multilingual Models
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID networks
AB Massively multilingual models such as mBERT and XLM-R are increasingly valued in Natural Language Processing research and applications, due to their ability to tackle the uneven distribution of resources available for different languages. The models' ability to process multiple languages relying on a shared set of parameters raises the question of whether the grammatical knowledge they extracted during pre-training can be considered as a data-driven cross-lingual grammar. The present work studies the inner workings of mBERT and XLM-R in order to test the cross-lingual consistency of the individual neural units that respond to a precise syntactic phenomenon, that is, number agreement, in five languages (English, German, French, Hebrew, Russian). We found that there is a significant overlap in the latent dimensions that encode agreement across the languages we considered. This overlap is larger (a) for long- vis-a-vis short-distance agreement and (b) when considering XLM-R as compared to mBERT, and peaks in the intermediate layers of the network. We further show that a small set of syntax-sensitive neurons can capture agreement violations across languages; however, their contribution is not decisive in agreement processing.
C1 [de Varda, Andrea Gregor; Marelli, Marco] Univ Milano Bicocca, Milan, Italy.
C3 University of Milano-Bicocca
RP de Varda, AG (通讯作者)，Univ Milano Bicocca, Milan, Italy.
EM a.devarda@campus.unimib.it; m.marelli@unimib.it
CR Abutalebi Jubin, 2001, BILING-LANG COGN, V4, P179, DOI 10.1017/S136672890100027X
   Alain G, 2018, ARXIV, V0, P0
   Antverg Omer, 2021, INT C LEARNING REPRE, V0, P0
   Bacon Geoff, 2019, ARXIV, V0, P0
   Bau D, 2019, INT C LEARN REPR ICL, V0, P0
   Belinkov Y, 2022, COMPUT LINGUIST, V48, P207, DOI 10.1162/coli_a_00422
   Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254
   Bernardy Jean Philippe, 2017, LINGUISTIC ISSUES LA, V0, P0, DOI DOI 10.33011/lilt.v15i.1413
   Chi EA, 2020, P 58 ANN M ASS COMP, V0, PP5564, DOI 10.18653/V1/2020.ACL-MAIN.493
   Conneau Alexis, 2020, ASS COMPUT LINGUIST, V0, PP8440, DOI 10.18653/v1/2020.acl-main.747
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP6022, DOI 10.18653/V1/2020.ACL-MAIN.536
   Cummins Robert, 1988, SOUTHERN J PHILOS, V26, P43, DOI 10.1111/j.2041-6962.1988.tb00462.x
   Dalvi F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4908
   Dalvi F, 2019, AAAI CONF ARTIF INTE, V0, P6309
   Dalvi F, 2019, AAAI CONF ARTIF INTE, V0, P9851
   Del M, 2022, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhar Prajit, 2021, P 23 NORDIC C COMPUT, V0, P74
   Doddapaneni Sumanth, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2107.00676
   Dufter P, 2021, ARXIV, V0, P0
   Finlayson M, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1828
   Goldberg Yoav, 2019, ABS190105287 ARXIV, V0, P0
   Gonen H, 2022, PROCEEDINGS OF THE 7TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, V0, P67
   Green DW, 2008, ANNU REV APPL LINGUI, V28, P25, DOI 10.1017/S0267190508080057
   Guarasci R, 2022, COMPUT SPEECH LANG, V71, P0, DOI 10.1016/j.csl.2021.101261
   Gulordava K, 2018, P 2018 C N AM CHAPT, V1, P1195, DOI 10.18653/V1/N18-1108
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Joshi Pratik, 2020, P 58 ANN M ASS COMP, V0, PP6282, DOI 10.18653/V1/2020.ACL-MAIN.560
   Karpathy A, 2015, ARXIV, V0, P0
   Karthikeyan K, 2020, INT C LEARN REPR, V0, P0
   Kementchedjhieva Yova, 2018, P 2018 EMNLP WORKSHO, V0, PP145, DOI 10.18653/v1/W18-5417
   Kim KHS, 1997, NATURE, V388, P171, DOI 10.1038/40623
   Klein S, 2020, 17TH SIGMORPHON WORKSHOP ON COMPUTATIONAL RESEARCH IN PHONETICS PHONOLOGY, V0, P204
   Kuncoro A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1426
   Lakretz Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P11
   Lasri K, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P2309
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4483
   Li JW, 2016, ARXIV, V0, P0
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI 10.1353/LAN.2019.0015
   Liu ZH, 2020, ARXIV, V0, P0
   Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1192
   MCCLOSKEY M, 1991, PSYCHOL SCI, V2, P387, DOI 10.1111/j.1467-9280.1991.tb00173.x
   Mueller A, 2020, P 58 ANN M ASS COMPU, V0, P5523
   Muller B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2214
   Perani D, 2005, CURR OPIN NEUROBIOL, V15, P202, DOI 10.1016/j.conb.2005.03.007
   Perani D, 1998, BRAIN, V121, P1841, DOI 10.1093/brain/121.10.1841
   Pinter Y, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, P95
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Radford A, 2017, ARXIV, V0, P0
   Serrano S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2931
   Singh Jasdeep, 2019, P 2 WORKSH DEEP LEAR, V0, PP47, DOI 10.18653/v1/D19- 6106
   Stanczak K, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P1589
   Tan LH, 2011, P NATL ACAD SCI USA, V108, P2540, DOI 10.1073/pnas.0909623108
   Tang ZY, 2017, INT CONF ACOUST SPEE, V0, PP2736, DOI 10.1109/ICASSP.2017.7952654
   Tham WWP, 2005, NEUROIMAGE, V28, P579, DOI 10.1016/j.neuroimage.2005.06.057
   van Schijndel M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5831
   Wang MH, 2015, SCI REP-UK, V5, P0, DOI 10.1038/srep16923
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P833
   Wu SJ, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P120
   Xu M, 2017, SCI ADV, V3, P0, DOI 10.1126/sciadv.1603309
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zuckermann Ghilad, 2006, J MOD JEW STUD, V5, P57
NR 62
TC 0
Z9 0
U1 6
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN 1
PY 2023
VL 49
IS 2
BP 261
EP 299
DI 10.1162/coli_a_00472
PG 39
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA L1IC1
UT WOS:001020851700001
DA 2023-11-10
ER

PT J
AU Liu, YG
   Chen, WY
   Liu, HW
   Zhang, Y
   Zhang, ML
   Qu, H
AF Liu, Yuguo
   Chen, Wenyu
   Liu, Hanwen
   Zhang, Yun
   Zhang, Malu
   Qu, Hong
TI Biologically Plausible Sparse Temporal Word Representations
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Sparse coding; spiking neuron model; word representation
ID spiking; recognition
AB Word representations, usually derived from a large corpus and endowed with rich semantic information, have been widely applied to natural language tasks. Traditional deep language models, on the basis of dense word representations, requires large memory space and computing resource. The brain-inspired neuromorphic computing systems, with the advantages of better biological interpretability and less energy consumption, still have major difficulties in the representation of words in terms of neuronal activities, which has restricted their further application in more complicated downstream language tasks. Comprehensively exploring the diverse neuronal dynamics of both integration and resonance, we probe into three spiking neuron models to post-process the original dense word embeddings, and test the generated sparse temporal codes on several tasks concerning both word-level and sentence-level semantics. The experimental results show that our sparse binary word representations could perform on par with or even better than original word embeddings in capturing semantic information, while requiring less storage. Our methods provide a robust representation foundation of language in terms of neuronal activities, which could potentially be applied to future downstream natural language tasks under neuromorphic computing systems.
C1 [Liu, Yuguo; Chen, Wenyu; Liu, Hanwen; Zhang, Yun; Zhang, Malu; Qu, Hong] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Qu, H (通讯作者)，Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
EM liuyuguo@std.uestc.edu.cn; cwy@uestc.edu.cn; lhwen1998@std.uestc.edu.cn; zhangyun@std.uestc.edu.cn; maluzhang@uestc.edu.cn; hongqu@uestc.edu.cn
FU National Key Research and Development Program of China [2018AAA0100202]; National Science Foundation of China [62236007, 61976043]; Science and Technology Support Program of Sichuan Province [2022YFG0313]
CR Agirre E, 2009, HUMAN LANGUAGE TECHN, V0, P0
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   [Anonymous], 2010, DYNAMICAL SYSTEMS NE, V0, P0
   Auge D, 2021, LECT NOTES COMPUT SC, V12895, P245, DOI 10.1007/978-3-030-86383-8_20
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bhatia P, 2019, PLASMONICS, V14, P611, DOI 10.1007/s11468-018-0839-7
   Bialas Marcin, 2020, PARALLEL PROBLEM SOLVING FROM NATURE - PPSN XVI. 16TH INTERNATIONAL CONFERENCE, V0, P433, DOI 10.1007/978-3-030-58112-1_30
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Chang J, 2009, NEURAL INFORM PROCES, V22, P288
   Chen Y, 2021, AAAI CONF ARTIF INTE, V35, P7073
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Devlin J, 2019, ARXIV, V0, P0
   Eguíluz VM, 2000, PHYS REV LETT, V84, P5232, DOI 10.1103/PhysRevLett.84.5232
   Faruqui M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1491
   Frady EP, 2022, J SIGNAL PROCESS SYS, V94, P917, DOI 10.1007/s11265-022-01772-5
   Frady EP, 2019, P NATL ACAD SCI USA, V116, P18050, DOI 10.1073/pnas.1902653116
   Gerstner W, 2014, NEURONAL DYNAMICS: FROM SINGLE NEURONS TO NETWORKS AND MODELS OF COGNITION, V0, PP1, DOI 10.1017/CBO9781107447615
   Gerz D, 2016, ARXIV, V0, P0
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Hinton GE, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI 10.1109/69.917563
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Hoppensteadt FC, 1998, BIOSYSTEMS, V48, P85, DOI 10.1016/S0303-2647(98)00053-7
   Hoppensteadt FC, 2000, IEEE T NEURAL NETWOR, V11, P734, DOI 10.1109/72.846744
   Huang L, 2022, IEEE T CYBERNETICS, V52, P5828, DOI 10.1109/TCYB.2020.3042230
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Izhikevich EM, 2000, INT J BIFURCAT CHAOS, V10, P1171, DOI 10.1142/S0218127400000840
   Izhikevich EM, 2001, NEURAL NETWORKS, V14, P883, DOI 10.1016/S0893-6080(01)00078-8
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Kern A, 2003, PHYS REV LETT, V91, P0, DOI 10.1103/PhysRevLett.91.128101
   Kramer O, 2013, DIMENSIONALITY REDUC, V0, P0, DOI DOI 10.1007/978-3-642-38652-7_2
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Lapique L, 1907, J PHYSL PATHOL GEN, V9, P620, DOI 10.1007/S00422-007-0189-6
   Lerman P, 1980, GRID SEARCH, V29, P77, DOI 10.2307/2346413
   Liu HH, 2021, COGN NEURODYNAMICS, V15, P191, DOI 10.1007/s11571-020-09594-6
   Luong T, 2013, P 17 C COMP NAT LANG, V0, PP104, DOI 10.1007/BF02579642
   Marelli M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Monteiro LHA, 2003, IEEE T NEURAL NETWOR, V14, P1572, DOI 10.1109/TNN.2003.820441
   Murphy E, 2018, TALKING SPECIES PERS, V0, P251
   Neftci EO, 2019, IEEE SIGNAL PROC MAG, V36, P51, DOI 10.1109/MSP.2019.2931595
   OKEEFE J, 1993, HIPPOCAMPUS, V3, P317, DOI 10.1002/hipo.450030307
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Pina JE, 2018, PLOS COMPUT BIOL, V14, P0, DOI 10.1371/journal.pcbi.1006517
   Subramanian A, 2018, AAAI CONF ARTIF INTE, V0, P4921
   Tiesinga PHE, 2002, NEURAL COMPUT, V14, P1629, DOI 10.1162/08997660260028647
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang AL, 2019, ARXIV, V0, P0
   Wang L, 2018, J COGNITIVE NEUROSCI, V30, P432, DOI 10.1162/jocn_a_01190
   Wang YW, 2019, COGN COMPUT, V11, P676, DOI 10.1007/s12559-019-09643-1
   Wolfe J, 2010, CURR OPIN NEUROBIOL, V20, P306, DOI 10.1016/j.conb.2010.03.006
   Zhang ML, 2022, IEEE T NEUR NET LEAR, V33, P1947, DOI 10.1109/TNNLS.2021.3110991
   Zhang ML, 2019, IEEE T NEUR NET LEAR, V30, P123, DOI 10.1109/TNNLS.2018.2833077
   Zhang Yun, 2022, IEEE TRANS NEURAL NETW LEARN SYST, VPP, P0, DOI 10.1109/TNNLS.2022.3213688
NR 53
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2023.3290004
EA JUL 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA L8FD5
UT WOS:001025554600001
PM 37410643
DA 2023-11-10
ER

PT J
AU Shen, WX
   Song, JK
   Zhu, XS
   Li, GF
   Shen, HT
AF Shen, Wenxue
   Song, Jingkuan
   Zhu, Xiaosu
   Li, Gongfu
   Shen, Heng Tao
TI End-to-End Pre-Training With Hierarchical Matching and Momentum Contrast for Text-Video Retrieval
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Videos; Hidden Markov models; Semantics; Task analysis; Transformers; Training; Feature extraction; Multimodal pre-training; video retrieval; contrastive learning
AB Lately, video-language pre-training and text-video retrieval have attracted significant attention with the explosion of multimedia data on the Internet. However, existing approaches for video-language pre-training typically limit the exploitation of the hierarchical semantic information in videos, such as frame semantic information and global video semantic information. In this work, we present an end-to-end pre-training network with Hierarchical Matching and Momentum Contrast named HMMC. The key idea is to explore the hierarchical semantic information in videos via multilevel semantic matching between videos and texts. This design is motivated by the observation that if a video semantically matches a text (can be a title, tag or caption), the frames in this video usually have semantic connections with the text and show higher similarity than frames in other videos. Hierarchical matching is mainly realized by two proxy tasks: Video-Text Matching (VTM) and Frame-Text Matching (FTM). Another proxy task: Frame Adjacency Matching (FAM) is proposed to enhance the single visual modality representations while training from scratch. Furthermore, momentum contrast framework was introduced into HMMC to form a multimodal momentum contrast framework, enabling HMMC to incorporate more negative samples for contrastive learning which contributes to the generalization of representations. We also collected a large-scale Chinese video-language dataset (over 763k unique videos) named CHVTT to explore the multilevel semantic connections between videos and texts. Experimental results on two major Text-video retrieval benchmark datasets demonstrate the advantages of our methods. We release our code at https://github.com/cheetah003/HMMC.
C1 [Shen, Wenxue; Zhu, Xiaosu; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Song, Jingkuan] Univ Elect Sci & Technol China, Shenzhen Inst Adv Study, Shenzhen 518110, Peoples R China.
   [Song, Jingkuan; Shen, Heng Tao] Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Li, Gongfu] Tencent Inc, Corp Dev Grp, Shenzhen 518057, Peoples R China.
C3 University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; Shenzhen Institute for Advanced Study, UESTC; Peng Cheng Laboratory; Tencent
RP Song, JK (通讯作者)，Univ Elect Sci & Technol China, Shenzhen Inst Adv Study, Shenzhen 518110, Peoples R China.
EM jingkuan.song@gmail.com
FU National Key Research and Development Program of China [2018AAA0102200]; National Natural Science Foundation of China [62122018, U22A2097, 62020106008, 61872064]; Fok Ying-Tong Education Foundation [171106]
CR Akbari H, 2021, P ADV NEUR INF PROC, V34, P24206, DOI 10.48550/ARXIV.2104.11178
   Bain M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP1708, DOI 10.1109/ICCV48922.2021.00175
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen FL, 2023, MACH INTELL RES, V20, P38, DOI 10.1007/s11633-022-1369-5
   Chen PF, 2022, IEEE T IMAGE PROCESS, V31, P458, DOI 10.1109/TIP.2021.3130536
   Chen S, 2020, CVPR, V0, P10638
   Chen T, 2020, P INT C MACH LEARN, V0, P1597
   Chen Xinlei, 2020, ARXIV, V0, P0
   Chen XL, 2021, PROC CVPR IEEE, V0, PP15745, DOI 10.1109/CVPR46437.2021.01549
   Chen Xinlei, 2021, P IEEE CVF INT C COM, V0, P9640
   Cheng X, 2021, IMPROVING VIDEO TEXT, V0, P0
   Chenyi Lei, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP2567, DOI 10.1145/3474085.3475431
   Croitoru I, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP11563, DOI 10.1109/ICCV48922.2021.01138
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong JF, 2019, PROC CVPR IEEE, V0, PP9338, DOI 10.1109/CVPR.2019.00957
   Dosovitskiy A, 2021, P INT C LEARN REPR I, V0, P0
   Dzabraev M, 2021, IEEE COMPUT SOC CONF, V0, PP3349, DOI 10.1109/CVPRW53098.2021.00374
   Fang Han, 2021, ARXIV, V0, P0
   Gabeur Valentin, 2020, ECCV, V0, PP2, DOI 10.1007/978-3-030-58548-8_13
   Gao LL, 2022, IEEE T IMAGE PROCESS, V31, P202, DOI 10.1109/TIP.2021.3120867
   Gao ZJ, 2022, ARXIV, V0, P0
   Ging Simon, 2020, ADV NEURAL INFORM PR, V0, P0
   Gorti SK, 2022, PROC CVPR IEEE, V0, PP4996, DOI 10.1109/CVPR52688.2022.00495
   Grill J, 2020, ADV NEURAL INF PROCE, V33, P21271
   Hadsell R, 2006, P 2006 IEEE COMP SOC, V2, P1735, DOI 10.1109/CVPR.2006.100
   Han X, 2021, OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang PY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2443
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kaiming He, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9726, DOI 10.1109/CVPR42600.2020.00975
   Kiros R, 2014, ARXIV, V0, P0
   Krishna R, 2017, IEEE I CONF COMP VIS, V0, PP706, DOI 10.1109/ICCV.2017.83
   Lei J, 2021, PROC CVPR IEEE, V0, PP7327, DOI 10.1109/CVPR46437.2021.00725
   Li LJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2046
   Li Y, 2021, P ICLR, V0, P2443
   Li YC, 2016, PROC CVPR IEEE, V0, PP4641, DOI 10.1109/CVPR.2016.502
   Liu R, 2022, FRONT COMPUT SCI-CHI, V16, P0, DOI 10.1007/s11704-021-1248-1
   Liu S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP11895, DOI 10.1109/ICCV48922.2021.01170
   Liu Ting, 2004, ADV NEURAL INFORM PR, V0, PP825, DOI 10.1109/ICPR.2014.591
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P1978, DOI 10.1109/TIP.2022.3147032
   Liu Yang, 2019, 30 BRIT MACH VIS C 2, V0, P279
   Liu YH, 2019, ARXIV, V0, P0
   Long S, 2022, P 31 INT JOINT C ART, V0, P5530
   Loshchilov I, 2017, P 5 INT C LEARN REPR, V0, P0
   Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028
   Luo HS, 2020, ARXIV, V0, P0
   Madhusudana PC, 2022, IEEE T IMAGE PROCESS, V31, P4149, DOI 10.1109/TIP.2022.3181496
   Miech Antoine, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9876, DOI 10.1109/CVPR42600.2020.00990
   Miech A, 2019, IEEE I CONF COMP VIS, V0, PP2630, DOI 10.1109/ICCV.2019.00272
   Pan T, 2021, PROC CVPR IEEE, V0, PP11200, DOI 10.1109/CVPR46437.2021.01105
   Patrick Mandela, 2020, ARXIV201002824, V0, P0
   Portillo-Quintero JA, 2021, LECT NOTES COMPUT SC, V12725, P3, DOI 10.1007/978-3-030-77004-4_1
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1
   Ruan L, 2022, OPEN, V3, P1
   Shvetsova N, 2022, PROC CVPR IEEE, V0, PP19988, DOI 10.1109/CVPR52688.2022.01939
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Sun C, 2019, ARXIV, V0, P0
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Tang ZN, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2415
   Phan TC, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12136753
   van den Oord A, 2019, ARXIV, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang Xiao, 2023, IEEE TRANSACTIONS ON MULTIMEDIA, V0, PP4335, DOI 10.1109/TMM.2022.3174341
   Wang XH, 2021, PROC CVPR IEEE, V0, PP5075, DOI 10.1109/CVPR46437.2021.00504
   Wang X, 2019, IEEE I CONF COMP VIS, V0, PP4580, DOI 10.1109/ICCV.2019.00468
   Wu ZR, 2018, PROC CVPR IEEE, V0, PP3733, DOI 10.1109/CVPR.2018.00393
   Xie ZD, 2021, ARXIV, V0, P0
   Xu H, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6787
   Xu Hu, 2021, FINDINGS ASS COMPUTA, V0, P4227
   Xu J, 2016, PROC CVPR IEEE, V0, PP5288, DOI 10.1109/CVPR.2016.571
   Yamaguchi M, 2017, IEEE I CONF COMP VIS, V0, PP1462, DOI 10.1109/ICCV.2017.162
   Ye M, 2019, PROC CVPR IEEE, V0, PP6203, DOI 10.1109/CVPR.2019.00637
   Yiwei Ma, 2022, MM 22: PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP638, DOI 10.1145/3503161.3547910
   Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29
   Zeng PP, 2022, IEEE T IMAGE PROCESS, V31, P5936, DOI 10.1109/TIP.2022.3205212
   Zhao S, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP970, DOI 10.1145/3477495.3531950
   Zhou LW, 2018, AAAI CONF ARTIF INTE, V0, P7590
   Zhu Linchao, 2020, P IEEE CVF C COMP VI, V0, PP8746, DOI 10.1109/CVPR42600.2020.00877
NR 81
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PD JUN 15
PY 2023
VL 32
IS 
BP 5017
EP 5030
DI 10.1109/TIP.2023.3275071
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA R5CA8
UT WOS:001064516200004
PM 37186535
DA 2023-11-10
ER

PT J
AU Karyukin, V
   Rakhimova, D
   Karibayeva, A
   Turganbayeva, A
   Turarbek, A
AF Karyukin, Vladislav
   Rakhimova, Diana
   Karibayeva, Aidana
   Turganbayeva, Aliya
   Turarbek, Asem
TI The neural machine translation models for the low-resource Kazakh-English language pair
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Neural machine translation; Forward translation; Backward translation; Seq2Seq; RNN; BRNN; Transformer; OpenNMT; English; Kazakh
AB The development of the machine translation field was driven by people's need to communicate with each other globally by automatically translating words, sentences, and texts from one language into another. The neural machine translation approach has become one of the most significant in recent years. This approach requires large parallel corpora not available for low-resource languages, such as the Kazakh language, which makes it difficult to achieve the high performance of the neural machine translation models. This article explores the existing methods for dealing with low-resource languages by artificially increasing the size of the corpora and improving the performance of the Kazakh-English machine translation models. These methods are called forward translation, backward translation, and transfer learning. Then the Sequence-to-Sequence (recurrent neural network and bidirectional recurrent neural network) and Transformer neural machine translation architectures with their features and specifications are concerned for conducting experiments in training models on parallel corpora. The experimental part focuses on building translation models for the high-quality translation of formal social, political, and scientific texts with the synthetic parallel sentences from existing monolingual data in the Kazakh language using the forward translation approach and combining them with the parallel corpora parsed from the official government websites. The total corpora of 380,000 parallel Kazakh-English sentences are trained on the recurrent neural network, bidirectional recurrent neural network, and Transformer models of the OpenNMT framework. The quality of the trained model is evaluated with the BLEU, WER, and TER metrics. Moreover, the sample translations were also analyzed. The RNN and BRNN models showed a more precise translation than the Transformer model. The Byte-Pair Encoding tokenization technique showed better metrics scores and translation than the word tokenization technique. The Bidirectional recurrent neural network with the Byte-Pair Encoding technique showed the best performance with 0.49 BLEU, 0.51 WER, and 0.45 TER.
C1 [Karyukin, Vladislav; Rakhimova, Diana; Karibayeva, Aidana; Turganbayeva, Aliya; Turarbek, Asem] Al Farabi Kazakh Natl Univ, Dept Informat Syst, Alma Ata, Kazakhstan.
   [Rakhimova, Diana] Inst Informat & Computat Technol, Alma Ata, Kazakhstan.
C3 Al-Farabi Kazakh National University; Institute of Information & Computational Technologies
RP Karyukin, V (通讯作者)，Al Farabi Kazakh Natl Univ, Dept Informat Syst, Alma Ata, Kazakhstan.
EM vladislav.karyukin@gmail.com
FU Ministry of Science and Higher Education of the Republic of Kazakhstan [IRN AP 09259556]
CR Abdulmumin I, 2020, J COMPUT PHYS, V29, P1478, DOI 10.13140/RG.2.2.11076.55687
   Abdulmumin I, 2020, P INFORM COMMUNICATI, V0, P355
   Ahmadnia B, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 1, V0, PP475, DOI 10.5220/0010362604750481
   [Anonymous], 2015, P 10 WORKSHOP STAT M, V0, P0, DOI DOI 10.18653/V1/W15-3031
   Babhulgaonkar AR, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), V0, PP62, DOI 10.1109/ICISIM.2017.8122149
   Bojar Ondej, 2017, P 2 C MACH TRANSL, V0, PP489, DOI 10.18653/V1/W17-4755
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P489
   Gongora S, 2022, PROCEEDINGS OF THE FIFTH WORKSHOP ON THE USE OF COMPUTATIONAL METHODS IN THE STUDY OF ENDANGERED LANGUAGES (COMPUTEL-5 2022), V0, P127
   Ha TL, 2016, ARXIV, V0, P0
   Islam MA, 2021, NEURAL COMPUT APPL, V33, P12141, DOI 10.1007/s00521-021-05895-x
   Jooste W, 2022, INFORMATION, V13, P0, DOI 10.3390/info13020088
   Kalekeyeva M, 2021, IEEE INFOCOM SER, V0, P0
   Kandimalla A, 2022, INFORMATION, V13, P0, DOI 10.3390/info13050245
   Karyukin V, 2022, PARALLEL CORPORA ENG, V0, P0
   Karyukin V, 2022, OPENNMT KAZAKH ENGLI, V0, P0
   Khusainov A, 2018, SPRINGERBRIEF MATH, V11107, P0
   Koehn P, 2022, WORLD MACHINE TRANSL, V0, P0
   Lankford S, 2022, INFORMATION, V13, P0, DOI 10.3390/info13070309
   Mohamed SA, 2021, NEURAL COMPUT APPL, V33, P15919, DOI 10.1007/s00521-021-06268-0
   Mouratidis D, 2020, ARTIF INTELL, V584, P76, DOI 10.1007/978-3-030-49186-4_7
   Niyazbek M, 2021, 3 INT C ENV PREVENTI, V687, P1
   Nonaka K, 2022, ELECTRONICS-SWITZ, V11, P0, DOI 10.3390/electronics11071014
   Primeminister, 2022, OFF INF SOURC PRIM M, V0, P0
   Rakhimova D, 2021, 7 INT C ENG ETMIS 20, V0, P1
   Rubino R, 2020, MACH TRANSL, V34, P347, DOI 10.1007/s10590-020-09258-6
   Sapakova S, 2022, B PHYS MATH ABAI KAZ, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Shanmugavadivel K, 2022, COMPUT SPEECH LANG, V76, P0, DOI 10.1016/j.csl.2022.101407
   Sharma S, 2020, INNOVATIVE APPL NANO, V0, PP1, DOI 10.1109/TEM.2020.3019033
   Sindhu C, 2022, 2022 8TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATION SYSTEMS (ICACCS), V0, PP266, DOI 10.1109/ICACCS54159.2022.9785158
   Singh SA, 2019, IEEE IMTC P, V0, P1
   Strategy, 2022, ADDR PRES REP KAZ, V0, P0
   The Republic of Kazakhstan, 2023, OFF WEBS PRES REP KA, V0, P0
   Ngo TV, 2022, APPL ARTIF INTELL, V36, P0, DOI 10.1080/08839514.2022.2101755
   Tiedemann J, 2022, OPUS OPEN PARALLEL C, V0, P0
   Toral A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P386
   Tukeyev U, 2020, COGENT ENG, V7, P0, DOI 10.1080/23311916.2020.1856500
   Tukeyev U, 2018, MATEC WEB C 3 INT C, V0, P0
   Turganbayeva A, 2022, INFORMATION, V13, P0, DOI 10.3390/info13090411
   Van der Linde J, 2022, PARACRAWL, V0, P0
   Wan Y, 2022, COMPUT LINGUIST, V48, P321, DOI 10.1162/coli_a_00435
   Wu CK, 2022, COMPUT SPEECH LANG, V72, P0, DOI 10.1016/j.csl.2021.101283
   Zhanabergenova D, 2021, LECT NOTES ARTIF INT, V12876, P629, DOI 10.1007/978-3-030-88081-1_47
   Zhang JJ, 2020, SCI CHINA TECHNOL SC, V63, P2028, DOI 10.1007/s11431-020-1632-x
   Zhao LX, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app112210915
NR 45
TC 0
Z9 0
U1 6
U2 9
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD FEB 8
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1224
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 8Y9NQ
UT WOS:000933018100005
PM 37346576
DA 2023-11-10
ER

PT J
AU Zheng, BY
   Xia, P
   Yarmohammadi, M
   Van Durme, B
AF Zheng, Boyuan
   Xia, Patrick
   Yarmohammadi, Mahsa
   Van Durme, Benjamin
TI Multilingual Coreference Resolution in Multiparty Dialogue
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Existing multiparty dialogue datasets for entity coreference resolution are nascent, and many challenges are still unaddressed. We create a large-scale dataset, Multilingual Multiparty Coref (MMC), for this task based on TV transcripts. Due to the availability of gold-quality subtitles in multiple languages, we propose reusing the annotations to create silver coreference resolution data in other languages (Chinese and Farsi) via annotation projection. On the gold (English) data, off-the-shelf models perform relatively poorly on MMC, suggesting that MMC has broader coverage of multiparty coreference than prior datasets. On the silver data, we find success both using it for data augmentation and training from scratch, which effectively simulates the zero-shot cross-lingual setting.
C1 [Zheng, Boyuan; Yarmohammadi, Mahsa; Van Durme, Benjamin] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Xia, Patrick] Microsoft Semant Machines, Berkeley, CA USA.
   [Xia, Patrick] JHU HLTCOE, Baltimore, MD USA.
C3 Johns Hopkins University
RP Zheng, BY (通讯作者)，Johns Hopkins Univ, Baltimore, MD 21218 USA.
EM bzheng12@jhu.edu; mahsa@jhu.edu; vandurme@jhu.edu
FU JHU + Amazon Initiative for Interactive AI(AI2AI); DARPAAIDA [FA8750-18-2-0015]; IARPA BETTER [201919051600005]
CR Abadji Julien, 2022, CLEANER DOCUMENT ORI, V0, ParXiv:2201.06642
   Akbik A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P397
   Aminian Maryam, 2019, P 13 INT C COMPUTATI, V0, PP200, DOI 10.18653/v1/W19-0417
   [Anonymous], 2006, 11 C EUROPEAN CHAPTE, V0, P0
   [Anonymous], 2015, P 2015 C EMPIRICAL M, V0, P0
   Asher N, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2721
   Bagga Amit, 1998, P 1 INT C LANG RES E, V0, P563
   Bamman D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P44
   Bernd Bohnet, 2022, C RES SEQ2SEQ TRANS, V0, P0
   Chen H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P172
   Chen Y-H, 2016, P 17 ANN M SPEC INT, V0, P90
   Choi JD, 2018, P 12 INT WORKSH SEM, V0, P57
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Creutz Mathias, 2018, P 11 INT C LANGUAGE, V0, P0
   Cui YM, 2020, ARXIV, V0, P0
   Dazat A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3904
   Donna K, 1998, RESOLVING DEMONSTRAT, V0, P0
   Dou ZY, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2112
   Etezadi Romina, 2022, P 2022 C N AM CHAPT, V0, P0, DOI DOI 10.18653/v1/2022.naacl-demo.13
   Fei H, 2020, P 58 ANN M ASS COMP, V0, P7014
   Frampton Matthew, 2009, EACL, V0, P0, DOI DOI 10.3115/1609067.1609097
   Gabi Rolih, 2018, APPL C RES US DIAL S, V0, P0
   Ghaddar A, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P136
   Iain McCowan Jean, 2005, AM M CORPUS, V0, P0
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Jovanovic N, 2006, LANG RESOUR EVAL, V40, P5, DOI 10.1007/s10579-006-9006-4
   Khosla S, 2021, P CODI CRAC 2021 SHA, V0, P1
   Kim Hongjin, 2021, P CODI CRAC 2021 SHA, V0, P43
   Kitaev N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3499
   Kitaev N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2676
   Kobayashi Hideo, 2021, P CODI CRAC 2021 SHA, V0, P16
   Lee Kenton, 2018, P 2018 C NAACL HUM L, V0, PP687, DOI 10.18653/v1/N18-2108
   Lee Kenton, 2017, P 2017 C EMP METH NA, V0, PP188, DOI 10.18653/V1/D17-1018
   Li J, 2020, CORR, V0, PP2642, DOI 10.18653/V1/2020.COLING-MAIN.238
   Li ML, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P77
   Li XS, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P906
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P923
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Liu Z, 2021, PROC 2 WORKSHOP COMP, V0, PP122, DOI 10.18653/V1/2021.CODIMAIN.11
   Liu ZY, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), V0, P509
   Liyan Xu, 2021, P CODI CRAC 2021 SHA, V0, P55
   Luo X, 2005, P HUM LANG TECHN C C, V0, P25
   Manuvinakurike R, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), V0, P530
   Marilyn A, 1997, STANDARDS DIALOGUE C, V0, P0
   Muzerelle J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P843
   Ozaki H, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2586
   Pradhan S, 2012, JOINT C EMNLP CONLL, V0, P1
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rameshkumar R, 2020, P 58 ANN M ASS COMP, V0, PP5121, DOI 10.18653/v1/2020.acl-main.459
   Recasens M, 2010, P 5 INT WORKSH SEM E, V0, P1
   Riloff Ellen, 2002, COLING 2002 19 INT C, V0, P0, DOI DOI 10.3115/1072228.1072298
   Roesiger I, 2018, P 1 WORKSHOP COMPUTA, V0, P11
   Roy A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P418
   Sang Yisi, 2022, P 2022 C N AM CHAPT, V0, PP4267, DOI 10.18653/v1/2022.naacl-main.317
   Schwenk Holger, 2017, P 2 WORKSH REPR LEAR, V0, PP157, DOI 10.18653/V1/W17-2619
   Shwartz V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6850
   Stengel-Estrin E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P910
   Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737
   Tavakoli Leila, 2014, INT J INFORM COMMUNI, V6, P63
   Thompson B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P90
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Toshniwal S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8519
   Toshniwal Shubham, 2021, P 4 WORKSH COMP MOD, V0, PP111, DOI 10.18653/V1/2021.CRAC-1.12
   Urbanek J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P673
   Vilain M, 1995, P 6 MESS UND C MUC 6, V0, P0
   Wang XW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5635
   Weischedel Ralph, 2013, ONTONOTES RELEASE 50, V0, P0
   Wu W, 2020, P 58 ANN M ASS COMPU, V0, P6953
   Xia P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5241
   Xia P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8617
   Xu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8527
   Xuansong Li Stephen, 2015, GALE CHINESE ENGLISH, V0, P0
   Yarmohammadi M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1950
   Yarowsky D, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P200
   Yuan M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7533
   Zhou Ethan, 2018, P 27 INT C COMPUTATI, V0, P24
NR 76
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD AUG 7
PY 2023
VL 11
IS 
BP 922
EP 940
DI 10.1162/tacl_a_00581
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA O6QL7
UT WOS:001045029700002
DA 2023-11-10
ER

PT J
AU Fernandes, MB
   Valizadeh, N
   Alabsi, HS
   Quadri, SA
   Tesh, RA
   Bucklin, AA
   Sun, H
   Jain, A
   Brenner, LN
   Ye, E
   Ge, WD
   Collens, SI
   Lin, S
   Das, S
   Robbins, GK
   Zafar, SF
   Mukerji, SS
   Westover, MB
AF Fernandes, Marta B.
   Valizadeh, Navid
   Alabsi, Haitham S.
   Quadri, Syed A.
   Tesh, Ryan A.
   Bucklin, Abigail A.
   Sun, Haoqi
   Jain, Aayushee
   Brenner, Laura N.
   Ye, Elissa
   Ge, Wendong
   Collens, Sarah, I
   Lin, Stacie
   Das, Sudeshna
   Robbins, Gregory K.
   Zafar, Sahar F.
   Mukerji, Shibani S.
   Westover, M. Brandon
TI Classification of neurologic outcomes from medical notes using natural language processing
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Intensive care unit; Coronavirus; Glasgow outcome scale; Modified Rankin Scale; Natural language processing; Machine learning
ID de-identification; prediction; extraction; documents; stay
AB Neurologic disability level at hospital discharge is an important outcome in many clinical research studies. Outside of clinical trials, neurologic outcomes must typically be extracted by labor intensive manual review of clinical notes in the electronic health record (EHR). To overcome this challenge, we set out to develop a natural language processing (NLP) approach that automatically reads clinical notes to determine neurologic outcomes, to make it possible to conduct larger scale neurologic outcomes studies. We obtained 7314 notes from 3632 patients hospitalized at two large Boston hospitals between January 2012 and June 2020, including discharge summaries (3485), occupational therapy (1472) and physical therapy (2357) notes. Fourteen clinical experts reviewed notes to assign scores on the Glasgow Outcome Scale (GOS) with 4 classes, namely 'good recovery', `moderate disability', 'severe disability', and 'death' and on the Modified Rankin Scale (mRS), with 7 classes, namely 'no symptoms', 'no significant disability', 'slight disability', `moderate disability', 'moderately severe disability', 'severe disability', and 'death'. For 428 patients' notes, 2 experts scored the cases generating interrater reliability estimates for GOS and mRS. After preprocessing and extracting features from the notes, we trained a multiclass logistic regression model using LASSO regularization and 5-fold cross validation for hyperparameter tuning. The model performed well on the test set, achieving a micro average area under the receiver operating characteristic and F-score of 0.94 (95% CI 0.93-0.95) and 0.77 (0.75-0.80) for GOS, and 0.90 (0.89-0.91) and 0.59 (0.57-0.62) for mRS, respectively. Our work demonstrates that an NLP algorithm can accurately assign neurologic outcomes based on free text clinical notes. This algorithm increases the scale of research on neurological outcomes that is possible with EHR data.
C1 [Fernandes, Marta B.; Valizadeh, Navid; Alabsi, Haitham S.; Quadri, Syed A.; Tesh, Ryan A.; Bucklin, Abigail A.; Sun, Haoqi; Jain, Aayushee; Ye, Elissa; Ge, Wendong; Collens, Sarah, I; Das, Sudeshna; Zafar, Sahar F.; Mukerji, Shibani S.; Westover, M. Brandon] Massachusetts Gen Hosp MGH, Dept Neurol, Boston, MA USA.
   [Fernandes, Marta B.; Valizadeh, Navid; Alabsi, Haitham S.; Quadri, Syed A.; Tesh, Ryan A.; Bucklin, Abigail A.; Sun, Haoqi; Brenner, Laura N.; Ge, Wendong; Lin, Stacie; Das, Sudeshna; Robbins, Gregory K.; Zafar, Sahar F.; Mukerji, Shibani S.; Westover, M. Brandon] Harvard Med Sch, Boston, MA 02115 USA.
   [Fernandes, Marta B.; Quadri, Syed A.; Tesh, Ryan A.; Bucklin, Abigail A.; Sun, Haoqi; Jain, Aayushee; Ye, Elissa; Ge, Wendong; Westover, M. Brandon] MGH, Clin Data Animat Ctr CDAC, Boston, MA USA.
   [Brenner, Laura N.] MGH, Div Pulm & Crit Care Med, Boston, MA USA.
   [Brenner, Laura N.] MGH, Div Gen Internal Med, Boston, MA USA.
   [Robbins, Gregory K.] MGH, Div Infect Dis, Boston, MA USA.
   [Mukerji, Shibani S.] MGH, Div Infect Dis, Vaccine & Immunotherapy Ctr, Boston, MA USA.
   [Westover, M. Brandon] MGH, McCance Ctr Brain Hlth, Boston, MA USA.
C3 Harvard University; Massachusetts General Hospital; Harvard University; Harvard Medical School
RP Fernandes, MB (通讯作者)，55 Fruit St, Boston, MA 02114 USA.
EM mbentofernandes@mgh.harvard.edu; nvalizadeh@mgh.harvard.edu; alabsi@mgh.harvard.edu; saquadri@mgh.harvard.edu; ryan.tesh@mgh.harvard.edu; abucklin@partners.org; hsun8@mgh.harvard.edu; ajain11@mgh.harvard.edu; lnbrenner@partners.org; emye@mgh.harvard.edu; wendong.ge@mgh.harvard.edu; stacie.lin@hms.harvard.edu; sdas5@mgh.harvard.edu; grobbins@mgh.harvard.edu; sfzafar@mgh.harvard.edu; smukerji@partners.org; mwestover@mgh.harvard.edu
FU Glenn Foundation for Medical Research; American Federation for Aging Research; American Academy of Sleep Medicine (AASM Foundation Strategic Research Award); Football Players Health Study (FPHS) at Harvard University; Department of Defense through a subcontract from Moberg ICU Solutions, Inc; National Institutes of Health (NIH) [R01NS102190, R01NS102574, R01NS107291, RF1AG064312, R01AG062989, K23NS114201, R01MH131194, K23MH115812]; National Science Foundation (NSF) [2014431]; James S. McDonnell Foundation; Rappaport Fellowship; Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr [2014431] Funding Source: National Science Foundation
CR Agarwala S, 2021, PROCEDIA COMPUT SCI, V189, P128, DOI 10.1016/j.procs.2021.05.076
   Alawad M, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), V0, P0, DOI DOI 10.1109/bhi.2019.8834586
   Alfattni G, 2021, JMIR MED INF, V9, P0, DOI 10.2196/24678
   Azari A, 2015, IEEE INT C BIOINFORM, V0, PP807, DOI 10.1109/BIBM.2015.7359790
   Bai T, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP72, DOI 10.1145/3308558.3313485
   Ben Abacha A, 2019, BMC BIOINFORMATICS, V20, P0, DOI 10.1186/s12859-019-3119-4
   Biggin F, 2020, BMC NEUROL, V20, P0, DOI 10.1186/s12883-020-01993-w
   BOTTORFF JL, 2013, HARM REDUCT J, V10, P0, DOI https://doi.org/10.1186/1477-7517-10-2
   Buchan NS, 2011, DRUG DISCOV TODAY, V16, P426, DOI 10.1016/j.drudis.2011.03.002
   Buckland Ryan S, 2020, AMIA ANNU SYMP PROC, V2020, P273
   Chen CH, 2020, AM J EMERG MED, V38, P2368, DOI 10.1016/j.ajem.2020.03.019
   Chen L, 2018, J BIOMED INFORM, V87, P108, DOI 10.1016/j.jbi.2018.09.013
   Choi E, 2017, J AM MED INFORM ASSN, V24, P361, DOI 10.1093/jamia/ocw112
   Chu JB, 2018, J BIOMED INFORM, V87, P118, DOI 10.1016/j.jbi.2018.10.002
   Clapp MA, 2022, AM J OBSTET GYNECOL, V227, P0, DOI 10.1016/j.ajog.2022.04.008
   Danilov G, 2019, STUD HEALTH TECHNOL, V258, P125, DOI 10.3233/978-1-61499-959-1-125
   De Silva K, 2021, COMPUT BIOL MED, V132, P0, DOI 10.1016/j.compbiomed.2021.104305
   Deng YH, 2017, STUD HEALTH TECHNOL, V245, P1260, DOI 10.3233/978-1-61499-830-3-1260
   Fernandes M, 2021, JMIR MED INF, V9, P0, DOI 10.2196/25457
   Gao S, 2021, IEEE J BIOMED HEALTH, V25, P3596, DOI 10.1109/JBHI.2021.3062322
   Gao S, 2018, J AM MED INFORM ASSN, V25, P321, DOI 10.1093/jamia/ocx131
   Gordon AJ, 2022, AM J EMERG MED, V51, P388, DOI 10.1016/j.ajem.2021.11.001
   Gupta MR, 2014, J MACH LEARN RES, V15, P1461
   Hu Y, 2018, J BIOMED INFORM, V82, P154, DOI 10.1016/j.jbi.2018.04.011
   Huang JM, 2019, COMPUT METH PROG BIO, V177, P141, DOI 10.1016/j.cmpb.2019.05.024
   JENNETT B, 1975, LANCET, V1, P480
   Joopudi V, 2018, J BIOMED INFORM, V86, P71, DOI 10.1016/j.jbi.2018.07.025
   Ju XL, 2021, EXPERT SYST APPL, V171, P0, DOI 10.1016/j.eswa.2021.114565
   Kang Y, 2020, J CARD FAIL, V26, P0
   Kim YJ, 2019, STUD HEALTH TECHNOL, V264, P193, DOI 10.3233/SHTI190210
   Lee K, 2019, STUD HEALTH TECHNOL, V264, P218, DOI 10.3233/SHTI190215
   Lehman Li-wei, 2012, AMIA ANNU SYMP PROC, V2012, P505
   Li M, 2019, IEEE ACM T COMPUT BI, V16, P1193, DOI 10.1109/TCBB.2018.2817488
   Li ZH, 2019, BMC MED INFORM DECIS, V19, P0, DOI 10.1186/s12911-019-0736-9
   Liu JH, 2021, NPJ DIGIT MED, V4, P0, DOI 10.1038/s41746-021-00474-9
   Liu YJ, 2019, EXPERT SYST APPL, V131, P288, DOI 10.1016/j.eswa.2019.04.063
   Liu ZJ, 2017, BMC MED INFORM DECIS, V17, P0, DOI 10.1186/s12911-017-0468-7
   Locke S, 2021, TRENDS ANAESTH CRIT, V38, P4, DOI 10.1016/j.tacc.2021.02.007
   Luneburg Noel, 2019, STUD HEALTH TECHNOL INFORM, V260, P192
   Marafino BJ, 2018, JAMA NETW OPEN, V1, P0, DOI 10.1001/jamanetworkopen.2018.5097
   Meystre Stephane, 2006, AMIA ANNU SYMP PROC, V0, P554
   Munkhdalai T, 2018, JMIR PUBLIC HLTH SUR, V4, P277, DOI 10.2196/publichealth.9361
   Murff HJ, 2003, J AM MED INFORM ASSN, V10, P339, DOI 10.1197/jamia.M1201
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Newman-Griffis D, 2021, FRONT DIGIT HEALTH, V3, P0, DOI 10.3389/fdgth.2021.620828
   Obeid JS, 2019, STUD HEALTH TECHNOL, V264, P283, DOI 10.3233/SHTI190228
   Parvin T, 2021, PROCEDIA COMPUT SCI, V193, P72, DOI 10.1016/j.procs.2021.10.008
   Pesaranghader A, 2019, J AM MED INFORM ASSN, V26, P438, DOI 10.1093/jamia/ocy189
   Qiu JX, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), V0, P0, DOI DOI 10.1109/bhi.2019.8834470
   Richter-Pechanski P, 2019, STUD HEALTH TECHNOL, V267, P101, DOI 10.3233/SHTI190813
   Santiso S, 2019, IEEE J BIOMED HEALTH, V23, P2148, DOI 10.1109/JBHI.2018.2879744
   Selby LV, 2018, SURGERY, V164, P1300, DOI 10.1016/j.surg.2018.05.008
   Sheikhalishahi S, 2019, JMIR MED INF, V7, P15, DOI 10.2196/12239
   Shi X, 2019, J AM MED INFORM ASSN, V26, P1584, DOI 10.1093/jamia/ocz158
   Sterling NW, 2019, INT J MED INFORM, V129, P184, DOI 10.1016/j.ijmedinf.2019.06.008
   Sun MX, 2019, STUD HEALTH TECHNOL, V264, P368, DOI 10.3233/SHTI190245
   Thieu T, 2021, INT J MED INFORM, V147, P0, DOI 10.1016/j.ijmedinf.2020.104351
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Uyeda AM, 2022, J PAIN SYMPTOM MANAG, V63, PE713, DOI 10.1016/j.jpainsymman.2022.02.006
   Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203
   von Elm E, 2007, PLOS MED, V4, P1623, DOI 10.1371/journal.pmed.0040297
   Wang YH, 2019, STUD HEALTH TECHNOL, V264, P438, DOI 10.3233/SHTI190259
   Wei CH, 2019, ACM-BCB19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, V0, P307, DOI 10.1145/3307339.3342162
   Weissenbacher D, 2019, J AM MED INFORM ASSN, V26, P1618, DOI 10.1093/jamia/ocz156
   Weissman GE, 2016, ANN AM THORAC SOC, V13, P1538, DOI 10.1513/AnnalsATS.201602-131OC
   Wilbur WJ, 2006, BMC BIOINFORMATICS, V7, P0, DOI 10.1186/1471-2105-7-356
   Wilson JTL, 2002, STROKE, V33, P2243, DOI 10.1161/01.STR.0000027437.22450.BD
   Yang H, 2010, J AM MED INFORM ASSN, V17, P545, DOI 10.1136/jamia.2010.003863
   Yang JL, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9183658
   Yoon HJ, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), V0, P0, DOI DOI 10.1109/bhi.2019.8834674
   Yuvaraj D, 2021, MATER TODAY-PROC, V0, P0, DOI DOI 10.1016/j.matpr.2021.02.080
   Zafar SF, 2021, ANN NEUROL, V90, P300, DOI 10.1002/ana.26161
   Zhan XH, 2021, PATTERNS, V2, P0, DOI 10.1016/j.patter.2021.100289
   Zhang ZC, 2019, MATH BIOSCI ENG, V16, P1966, DOI 10.3934/mbe.2019096
NR 74
TC 2
Z9 2
U1 8
U2 16
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 15
PY 2023
VL 214
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.119171
EA NOV 2022
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 6P1BO
UT WOS:000890669800009
PM 36865787
DA 2023-11-10
ER

PT J
AU Pugh, K
   Musavi, M
   Johnson, T
   Burke, C
   Yoeli, E
   Currie, E
   Pugh, B
AF Pugh, Katrina
   Musavi, Mohamad
   Johnson, Teresa
   Burke, Christopher
   Yoeli, Erez
   Currie, Emily
   Pugh, Benjamin
TI Neural nets for sustainability conversations: modeling discussion disciplines and their impacts
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article; Early Access
DE Aquaculture; Conversational intelligence; Neural networks; Natural language processing; Modeling
AB We live in the age polarization, where conversations on matters of sustainability more often produce acrimony or stalemate than productive action. Better understanding conversation features and their impacts may lead to better innovation, solution-design, and ongoing collaboration. We describe a study to test alternate machine learning models for classifying six "discussion disciplines", which are conversation features associated with rhetorical intent. The model providing the best outcome used the Bi-directional Encoder Representations from Transformers (BERT) layered with a Residual Network (ResNet). The training data were 1135 utterances from Maine aquaculture town hall-like meetings and similar conversations, which had been hand-coded for the discussion disciplines. In addition, we generated 300 phrases corresponding to three conversation outcomes: Intent-to-Act, Options-Generation, and Relationship-Building. We then used the trained model and information retrieval to classify a large corpus of 591 open-source transcripts, containing over 21,000 utterances. A binary logistic regression analysis showed that two discussion disciplines, "Inclusion" and "Courtesy," had positive, statistically significant, impacts on Intent-to-act: a 10 percentage point increase in the share of the Inclusion or Courtesy yielded a 45% or 34% increase, respectively, in the likelihood of Intent-to-Act. This study shows the applicability of neural networks in modeling conversations and identifying the dialog acts that can provide measurable and predictable impact on conversation outcomes. Conversational intelligence can support a variety of human interactions, such as town halls, policy-deliberations, private-public partnerships, and sustainability teamwork.
C1 [Pugh, Katrina] Columbia Univ, New York, NY 10027 USA.
   [Musavi, Mohamad; Johnson, Teresa; Burke, Christopher; Currie, Emily] Univ Maine, Orono, ME USA.
   [Yoeli, Erez] MIT, Sloan Sch Management, Cambridge, MA USA.
   [Pugh, Benjamin] Olin Coll, Needham, MA USA.
C3 Columbia University; University of Maine System; University of Maine Orono; Massachusetts Institute of Technology (MIT); Franklin W. Olin College of Engineering
RP Pugh, K (通讯作者)，Columbia Univ, New York, NY 10027 USA.
EM kp2462@columbia.edu
FU National Oceanographic and Atmospheric Association (NOAA) National Sea [NA18OAR4170103]; USDA National Institute of Food and Agriculture, Hatch project [ME022012]; University of Maine School of Marine Sciences and Maine College of Engineering and Computing
CR Almaatouq A, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2101062118
   [Anonymous], 2012, P 21 INT C WORLD WID, V0, P0
   [Anonymous], 2022, PREP, V0, P0
   Bago B, 2021, PSYARXIV, V0, P1
   Chang J, 2022, P CSCW 2022, V0, P0
   Chang J, 2020, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2005.0424
   Devlin Jacob, 2018, GOOGLE AI BLOG, V0, P0
   Google, 2021, GOOGL ML TECH TALKS, V0, P0
   Goralewicz B, 2021, TF IDF ALGORITHM EXP, V0, P0
   Hansen M, 2009, COLLABORATION LEADER, V0, P0
   Hart D, 2018, MAINE POLICY REV, V27, P0
   Isaacs W, 2016, WORLD NEEDS DIALOGUE, V0, P1
   Isaacs W, 1999, DIALOGUE ART THINKIN, V0, P0
   Jurafsky D, 2014, COGNITIVE TECHNOLOGI, V9783642414633, P403, DOI 10.1007/978-3-642-41464-0_13
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Maine Department of Marine Resources, 2023, CHAPT 2 AQ LEAS REG, V0, P0
   Mihalcea R, 2006, AAAI, V0, PP775, DOI 10.5555/1597538.1597662
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Pennycook G, 2021, TRENDS COGN SCI, V25, P388, DOI 10.1016/j.tics.2021.02.007
   Pinker S, 2008, P NATL ACAD SCI USA, V105, P833, DOI 10.1073/pnas.0707192105
   Pugh K, 2022, THESIS, V3608, P3608
   Sadusky H, 2022, MAINE AQUACULTURE RO, V0, P0
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Skifstad S, 2014, SMARTER INNOVATION U, V0, P0
   SPENCE M, 1973, Q J ECON, V87, P355, DOI 10.2307/1882010
   Zelasko P, 2021, T ASSOC COMPUT LING, V9, P1163, DOI 10.1162/tacl_a_00420
   Zhang A, 2017, P 11 INT AAAI C WEB, V0, P357
   Zhang Justine, 2020, PROCEEDINGS OF THE ACM ON HUMAN-COMPUTER INTERACTION, V4, P0, DOI 10.1145/3415202
   Zhang J, 2021, ACTIONABLE UNDERSTAN, V0, P0
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s00521-023-08819
EA SEP 2023
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q4CB1
UT WOS:001057002900001
DA 2023-11-10
ER

PT J
AU Sejnowski, TJ
AF Sejnowski, Terrence J.
TI Large Language Models and the Reverse Turing Test
SO NEURAL COMPUTATION
LA English
DT Article
ID learning algorithm; neuroscience
AB Large language models (LLMs) have been transformative. They are pretrained foundational models that are self-supervised and can be adapted with fine-tuning to a wide range of natural language tasks, each of which previously would have required a separate network model. This is one step closer to the extraordinary versatility of human language. GPT-3 and, more recently, LaMDA, both of them LLMs, can carry on dialogs with humans on many topics after minimal priming with a few examples. However, there has been a wide range of reactions and debate on whether these LLMs understand what they are saying or exhibit signs of intelligence. This high variance is exhibited in three interviews with LLMs reaching wildly different conclusions. A new possibility was uncovered that could explain this divergence. What appears to be intelligence in LLMs may in fact be a mirror that reflects the intelligence of the interviewer, a remarkable twist that could be considered a reverse Turing test. If so, then by studying interviews, we may be learning more about the intelligence and beliefs of the interviewer than the intelligence of the LLMs. As LLMs become more capable, they may transform the way we interact with machines and how they interact with each other. Increasingly, LLMs are being coupled with sensorimotor devices. LLMs can talk the talk, but can they walk the walk? A road map for achieving artificial general autonomy is outlined with seven major improvements inspired by brain systems and how LLMs could in turn be used to uncover new insights into brain function.
C1 [Sejnowski, Terrence J.] Salk Inst Biol Studies, La Jolla, CA 92093 USA.
   [Sejnowski, Terrence J.] Univ Calif San Diego, Div Biol Sci, La Jolla, CA 92037 USA.
C3 Salk Institute; University of California System; University of California San Diego
RP Sejnowski, TJ (通讯作者)，Salk Inst Biol Studies, La Jolla, CA 92093 USA.; Sejnowski, TJ (通讯作者)，Univ Calif San Diego, Div Biol Sci, La Jolla, CA 92037 USA.
EM terry@salk.edu
FU CIFAR
CR Abbott E, 1884, FLATLAND ROMANCE MAN, V0, P0
   ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Aguera y Arcas B, 2022, ECONOMIST, V0, P0
   Aguera y Arcas B, 2022, NEURAL COMPUT, V0, P0
   Allman JM, 1999, SCI AM LIB, V0, P0
   Amodei Dario, 2018, AI AND COMPUTE, V0, P0
   Anderson Stephen R, 2002, LANGUAGE ORGAN LINGU, V0, P0
   [Anonymous], 1999, SCI CRIB WHAT EARLY, V0, P0
   Arbib MA, 2006, ACTION TO LANGUAGE VIA THE MIRROR NEURON SYSTEM, V0, PP3, DOI 10.1017/CBO9780511541599.002
   Bartlett PL, 2019, J MACH LEARN RES, V20, P1
   Berner C, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1912.06680
   Bjorklund DF, 2007, WHY YOUTH IS NOT WAS, V0, P0
   Bratton B, 2022, NOEMA MAGAZINE, V0, P0
   Brenner S, 1996, CURR BIOL, V6, P1202, DOI 10.1016/S0960-9822(02)70689-1
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chomsky Noam, 1986, LANGUAGE PROBLEMS KN, V0, P0
   Chomsky Noam, 1971, NEW YORK REV BOOKS, V17, P18
   Chowdhery A, 2022, ARXIV, V0, P0
   Churchland PS, 2019, CONSCIENCE ORIGINS M, V0, P0
   Dasgupta I, 2022, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2207.07051
   de Waal F, 2016, ARE WE SMART ENOUGH, V0, P0
   Dehaene S, 2001, COGNITION, V79, P1, DOI 10.1016/S0010-0277(00)00123-2
   Devlin J, 2019, ARXIV, V0, P0
   Fourier J, 1808, MEMOIRE PROPAGATION, V1, P0
   Gao P, 2017, BIORXIV, V0, P0, DOI DOI 10.1101/214262
   Graybiel AM, 1997, SCHIZOPHRENIA BULL, V23, P459, DOI 10.1093/schbul/23.3.459
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011
   Hayes TL, 2021, NEURAL COMPUT, V33, P2908, DOI 10.1162/neco_a_01433
   Hoffmann J, 2022, ARXIV, V0, P0
   Hofstadter D, 2022, ECONOMIST, V0, P0
   Huang WL, 2022, ARXIV, V0, P0
   Karra SR, 2023, ARXIV, V0, P0
   Kilner JM, 2013, CURR BIOL, V23, PR1057, DOI 10.1016/j.cub.2013.10.051
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lemoine B, 2022, MEDIUM, V0, P0
   Li H, 2022, COMMUN ACM, V65, P56, DOI 10.1145/3490443
   Li JS, 2022, ARXIV, V0, P0
   Lighthill, 1973, ARTIFICIAL INTELLIGE, V0, P0
   Lister R, 2013, SCIENCE, V341, P629, DOI 10.1126/science.1237905
   Liu SQ, 2022, SCI ROBOT, V7, P0, DOI 10.1126/scirobotics.abo0235
   Marcus G, 2022, SCI AM, V0, P44
   Mehonic A, 2022, NATURE, V604, P255, DOI 10.1038/s41586-021-04362-w
   Morin F, 2005, AISTATS, V5, P246
   Nakahira Y, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.1916367118
   Navlakha S, 2018, WIRED, V0, P0
   NETtalk, 1986, US, V0, P0
   Ngai J, 2022, CELL, V185, P4, DOI 10.1016/j.cell.2021.11.037
   Nishimura T, 2022, SCIENCE, V377, P760, DOI 10.1126/science.abm1574
   OpenAI, 2022, FIN TUN, V0, P0
   Piloto LS, 2022, NAT HUM BEHAV, V6, P1257, DOI 10.1038/s41562-022-01394-8
   QUARTZ SR, 1994, BEHAV BRAIN SCI, V17, P725, DOI 10.1017/S0140525X00036839
   Quinn T, 2018, TLS-TIMES LIT SUPPL, V0, P31
   Richards B, 2022, CELL, V185, P2640, DOI 10.1016/j.cell.2022.06.047
   Ritter SM, 2014, FRONT HUM NEUROSCI, V8, P0, DOI 10.3389/fnhum.2014.00215
   Rosenblatt F, 1961, PRINCIPLES NEURODYNA, V0, P0
   Rowling JK, 1997, H POTTER SORCERERS S, V0, P0
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sejnowski TJ, 1987, COMPLEX SYSTEMS, V1, P145
   Sejnowski TJ, 2019, THINK TANK 40 NEUROS, V0, P257
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Sejnowski T, 2012, SCI AM, V307, P54, DOI 10.1038/scientificamerican1012-54
   Sejnowski TJ, 2018, DEEP LEARNING REVOLUTION, V0, P1
   Sevilla J, 2022, ARXIV, V0, P0
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Simonyan K, 2011, NEUROSCIENTIST, V17, P197, DOI 10.1177/1073858410386727
   Sokolov AA, 2017, TRENDS COGN SCI, V21, P313, DOI 10.1016/j.tics.2017.02.005
   Sterling P, 2012, PHYSIOL BEHAV, V106, P5, DOI 10.1016/j.physbeh.2011.06.004
   Strobelt H, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2208.07852
   Sutton RS, 1988, MACHINE LEARNING, V3, P9, DOI 10.1007/BF00115009
   TESAURO G, 1989, ARTIF INTELL, V39, P357, DOI 10.1016/0004-3702(89)90017-9
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343
   Thoppilan R, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2201.08239
   Ullman TD, 2017, TRENDS COGN SCI, V21, P649, DOI 10.1016/j.tics.2017.05.012
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang XJ, 2022, ANNU REV NEUROSCI, V45, P533, DOI 10.1146/annurev-neuro-110920-035434
   Wei JS, 2022, ARXIV, V0, P0
   Weinberg J, 2020, DAILY NOUS, V0, P0
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wolfram S, 2016, FAREWELL M MINSKY 19, V0, P0
NR 80
TC 7
Z9 7
U1 16
U2 30
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0899-7667
EI 1530-888X
J9 NEURAL COMPUT
JI Neural Comput.
PD FEB 17
PY 2023
VL 35
IS 3
BP 309
EP 342
DI 10.1162/neco_a_01563
PG 34
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA 9D4FQ
UT WOS:000936055200003
PM 36746144
DA 2023-11-10
ER

PT J
AU Pugh, K
   Musavi, M
   Johnson, T
   Burke, C
   Yoeli, E
   Currie, E
   Pugh, B
AF Pugh, Katrina
   Musavi, Mohamad
   Johnson, Teresa
   Burke, Christopher
   Yoeli, Erez
   Currie, Emily
   Pugh, Benjamin
TI Neural nets for sustainability conversations: modeling discussion disciplines and their impacts
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Aquaculture; Conversational intelligence; Neural networks; Natural language processing; Modeling
AB We live in the age polarization, where conversations on matters of sustainability more often produce acrimony or stalemate than productive action. Better understanding conversation features and their impacts may lead to better innovation, solution-design, and ongoing collaboration. We describe a study to test alternate machine learning models for classifying six "discussion disciplines", which are conversation features associated with rhetorical intent. The model providing the best outcome used the Bi-directional Encoder Representations from Transformers (BERT) layered with a Residual Network (ResNet). The training data were 1135 utterances from Maine aquaculture town hall-like meetings and similar conversations, which had been hand-coded for the discussion disciplines. In addition, we generated 300 phrases corresponding to three conversation outcomes: Intent-to-Act, Options-Generation, and Relationship-Building. We then used the trained model and information retrieval to classify a large corpus of 591 open-source transcripts, containing over 21,000 utterances. A binary logistic regression analysis showed that two discussion disciplines, "Inclusion" and "Courtesy," had positive, statistically significant, impacts on Intent-to-act: a 10 percentage point increase in the share of the Inclusion or Courtesy yielded a 45% or 34% increase, respectively, in the likelihood of Intent-to-Act. This study shows the applicability of neural networks in modeling conversations and identifying the dialog acts that can provide measurable and predictable impact on conversation outcomes. Conversational intelligence can support a variety of human interactions, such as town halls, policy-deliberations, private-public partnerships, and sustainability teamwork.
C1 [Pugh, Katrina] Columbia Univ, New York, NY 10027 USA.
   [Musavi, Mohamad; Johnson, Teresa; Burke, Christopher; Currie, Emily] Univ Maine, Orono, ME USA.
   [Yoeli, Erez] MIT, Sloan Sch Management, Cambridge, MA USA.
   [Pugh, Benjamin] Olin Coll, Needham, MA USA.
C3 Columbia University; University of Maine System; University of Maine Orono; Massachusetts Institute of Technology (MIT); Franklin W. Olin College of Engineering
RP Pugh, K (通讯作者)，Columbia Univ, New York, NY 10027 USA.
EM kp2462@columbia.edu
CR Almaatouq A, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2101062118
   [Anonymous], 2012, P 21 INT C WORLD WID, V0, P0
   [Anonymous], 2022, PREP, V0, P0
   Bago B, 2021, PSYARXIV, V0, P1
   Chang J, 2022, P CSCW 2022, V0, P0
   Chang J, 2020, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2005.0424
   Devlin J, 2018, OPEN SOURCING BERT S, V0, P0
   Google, 2021, TRANSF LEARN TRANSF, V0, P0
   Goralewicz B, 2021, TF IDF ALGORITHM EXP, V0, P0
   Hansen M, 2009, COLLABORATION LEADER, V0, P0
   Hart D, 2018, MAINE POLICY REV, V27, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Isaacs W, 2016, WORLD NEEDS DIALOGUE, V0, P1
   Isaacs W, 1999, DIALOGUE ART THINKIN, V0, P0
   Jurafsky D, 2014, COGNITIVE TECHNOLOGI, V9783642414633, P403, DOI 10.1007/978-3-642-41464-0_13
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Maine Department of Marine Resources, 2023, AQ LEAS REG, V0, P0
   Mihalcea R, 2006, AAAI, V0, PP775, DOI 10.5555/1597538.1597662
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Pennycook G, 2021, TRENDS COGN SCI, V25, P388, DOI 10.1016/j.tics.2021.02.007
   Pinker S, 2008, P NATL ACAD SCI USA, V105, P833, DOI 10.1073/pnas.0707192105
   Pugh K, 2022, SUSTAINABILITY CONVE, V0, P0
   Sadusky H, 2022, MAINE AQUACULTURE RO, V0, P0
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Skifstad S, 2014, SMARTER INNOVATION U, V0, P0
   SPENCE M, 1973, Q J ECON, V87, P355, DOI 10.2307/1882010
   Zelasko P, 2021, T ASSOC COMPUT LING, V9, P1163, DOI 10.1162/tacl_a_00420
   Zhang A, 2017, P 11 INT AAAI C WEB, V0, P357
   Zhang Justine, 2020, PROCEEDINGS OF THE ACM ON HUMAN-COMPUTER INTERACTION, V4, P0, DOI 10.1145/3415202
   Zhang J, 2021, ACTIONABLE UNDERSTAN, V0, P0
NR 30
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD OCT 15
PY 2023
VL 35
IS 29
BP 21935
EP 21947
DI 10.1007/s00521-023-08819-z
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA R8RE5
UT WOS:001066965500034
DA 2023-11-10
ER

PT J
AU Wu, WH
   Sun, Z
   Song, YX
   Wang, JD
   Ouyang, WL
AF Wu, Wenhao
   Sun, Zhun
   Song, Yuxin
   Wang, Jingdong
   Ouyang, Wanli
TI Transferring Vision-Language Models for Visual Recognition: A Classifier Perspective
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article; Early Access
DE Visual recognition; Large vision model; Transfer learning
AB Transferring knowledge from pre-trained deep models for downstream tasks, particularly with limited labeled samples, is a fundamental problem in computer vision research. Recent advances in large-scale, task-agnostic vision-language pre-trained models, which are learned with billions of samples, have shed new light on this problem. In this study, we investigate how to efficiently transfer aligned visual and textual knowledge for downstream visual recognition tasks. We first revisit the role of the linear classifier in the vanilla transfer learning framework, and then propose a new paradigm where the parameters of the classifier are initialized with semantic targets from the textual encoder and remain fixed during optimization. To provide a comparison, we also initialize the classifier with knowledge from various resources. In the empirical study, we demonstrate that our paradigm improves the performance and training speed of transfer learning tasks. With only minor modifications, our approach proves effective across 17 visual datasets that span three different data domains: image, video, and 3D point cloud.
C1 [Wu, Wenhao] Univ Sydney, Darlington, Australia.
   [Sun, Zhun; Song, Yuxin; Wang, Jingdong] Baidu Inc, Dept Comp Vis Technol, Beijing, Peoples R China.
   [Ouyang, Wanli] Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China.
C3 University of Sydney; Baidu
RP Wu, WH (通讯作者)，Univ Sydney, Darlington, Australia.
EM wenhao.wu@sydney.edu.au; sunzhun@baidu.com; songyuxin02@baidu.com; wangjingdong@baidu.com; ouyangwanli@pjlab.org.cn
FU Australian Research Council [DP200103223]; Australian Medical Research Future Fund [MRFAI000085]; CRC-P Smart Material Recovery Facility (SMRF) - Curby Soft Plastics; CRC-P ARIA - Bionic Visual-Spatial Prosthesis for the Blind; Australian Research Council [DP200103223] Funding Source: Australian Research Council
CR Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP6816, DOI 10.1109/ICCV48922.2021.00676
   Bertasius G, 2021, PR MACH LEARN RES, V139, P0
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Brattoli B, 2020, PROC CVPR IEEE, V0, PP4612, DOI 10.1109/CVPR42600.2020.00467
   Byeon Minwoo, 2022, COYO 700M IMAGE TEXT, V0, P0
   Carreira J, 2018, ARXIV, V0, P0
   Carreira J, 2017, PROC CVPR IEEE, V0, PP4724, DOI 10.1109/CVPR.2017.502
   Chen Shizhe, 2021, P IEEECVF INT C COMP, V0, P13638
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP9620, DOI 10.1109/ICCV48922.2021.00950
   Chuanqi Tan, 2018, ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2018. 27TH INTERNATIONAL CONFERENCE ON ARTIFICIAL NEURAL NETWORKS. PROCEEDINGS: LECTURE NOTES IN COMPUTER SCIENCE (LNCS 11141), V0, PP270, DOI 10.1007/978-3-030-01424-7_27
   Cimpoi M, 2014, PROC CVPR IEEE, V0, PP3606, DOI 10.1109/CVPR.2014.461
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2021, ARXIV, V0, P0
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP6804, DOI 10.1109/ICCV48922.2021.00675
   Feichtenhofer C, 2020, PROC CVPR IEEE, V0, PP200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, V0, PP6201, DOI 10.1109/ICCV.2019.00630
   Gao JY, 2019, AAAI CONF ARTIF INTE, V0, P8303
   Gao P, 2021, ARXIV, V0, P0, DOI DOI 10.1007/S11263-023-01891-X
   Gao RH, 2020, PROC CVPR IEEE, V0, PP10454, DOI 10.1109/CVPR42600.2020.01047
   Ghadiyaram D, 2019, PROC CVPR IEEE, V0, PP12038, DOI 10.1109/CVPR.2019.01232
   Goyal Ankit, 2021, INT C MACHINE LEARNI, V0, PP3809, DOI 10.48550/ARXIV.2106.05304
   Han Kai, 2021, ADV NEURAL INFORM PR, V34, P15908
   He KM, 2022, PROC CVPR IEEE, V0, PP15979, DOI 10.1109/CVPR52688.2022.01553
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   HEILBRON FC, 2015, PROC CVPR IEEE, V0, PP961, DOI 10.1109/CVPR.2015.7298698
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Jia C, 2021, PR MACH LEARN RES, V139, P0
   Jiang BY, 2019, IEEE I CONF COMP VIS, V0, PP2000, DOI 10.1109/ICCV.2019.00209
   Ju C, 2022, LECT NOTES COMPUT SC, V13695, P105, DOI 10.1007/978-3-031-19833-5_7
   Kaiming He, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9726, DOI 10.1109/CVPR42600.2020.00975
   Kay W, 2017, ARXIV, V0, P0
   Kim TS, 2021, AAAI CONF ARTIF INTE, V35, P1817
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), V0, PP554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky Alex, 2012, NEURIPS, V25, P0
   Kuehne H, 2011, IEEE I CONF COMP VIS, V0, PP2556, DOI 10.1109/ICCV.2011.6126543
   Li Boyi, 2022, ARXIV, V0, P0
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li JN, 2022, ARXIV, V0, P0
   Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y
   Lin C-C, 2022, P IEEECVF C COMPUTER, V0, P19978
   Lin J, 2019, IEEE I CONF COMP VIS, V0, PP7082, DOI 10.1109/ICCV.2019.00718
   Lin ZY, 2022, LECT NOTES COMPUT SC, V13695, P388, DOI 10.1007/978-3-031-19833-5_23
   Liu Z, 2022, PROC CVPR IEEE, V0, PP3192, DOI 10.1109/CVPR52688.2022.00320
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Lüddecke T, 2022, PROC CVPR IEEE, V0, PP7076, DOI 10.1109/CVPR52688.2022.00695
   Luo HS, 2021, ARXIV, V0, P0
   Maji S, 2013, ARXIV, V0, P0
   Mishra A, 2018, IEEE WINT CONF APPL, V0, PP372, DOI 10.1109/WACV.2018.00047
   Mokady Ron, 2021, ARXIV, V0, P0
   Ni B, 2022, LECT NOTES COMPUT SC, V13664, P1, DOI 10.1007/978-3-031-19772-7_1
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Pan JT, 2022, ARXIV, V0, P0
   Parkhi OM, 2012, PROC CVPR IEEE, V0, PP3498, DOI 10.1109/CVPR.2012.6248092
   Qiu ZF, 2017, IEEE I CONF COMP VIS, V0, PP5534, DOI 10.1109/ICCV.2017.590
   Radford Alec, 2021, P INT C MACH LEARN I, V0, PP8748, DOI 10.48550/ARXIV.2103.00020
   Ramesh A, 2021, PR MACH LEARN RES, V139, P0
   Rao YM, 2022, PROC CVPR IEEE, V0, PP18061, DOI 10.1109/CVPR52688.2022.01755
   Ribani Ricardo, 2019, 2019 32ND SIBGRAPI CONFERENCE ON GRAPHICS, V0, P47, DOI 10.1109/SIBGRAPI-T.2019.00010
   Ryoo MSS, 2022, ARXIV, V0, P0
   Sanh V, 2020, ARXIV, V0, P0
   Schuhmann Christoph, 2022, ARXIV, V0, P0
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Simonyan K, 2015, ARXIV, V0, P0
   Soomro K, 2012, ARXIV, V0, P0
   Sun C, 2017, IEEE I CONF COMP VIS, V0, PP843, DOI 10.1109/ICCV.2017.97
   Sun Q, 2023, ARXIV, V0, P0
   Sun Z, 2022, ARXIV, V0, P0
   Tran D, 2019, IEEE I CONF COMP VIS, V0, PP5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2018.00675
   van den Oord Aaron, 2018, ARXIV180703748, V0, P0
   Wang LM, 2021, PROC CVPR IEEE, V0, PP1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2018, PROC CVPR IEEE, V0, PP1430, DOI 10.1109/CVPR.2018.00155
   Wang Mengmeng, 2021, ARXIV, V0, P0
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Wenhao Wu, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1903, DOI 10.1145/3474085.3475344
   Wu CY, 2019, PROC CVPR IEEE, V0, PP284, DOI 10.1109/CVPR.2019.00037
   Wu WH, 2021, AAAI CONF ARTIF INTE, V35, P2943
   Wu WH, 2019, IEEE I CONF COMP VIS, V0, PP6231, DOI 10.1109/ICCV.2019.00632
   Wu ZR, 2015, PROC CVPR IEEE, V0, PP1912, DOI 10.1109/CVPR.2015.7298801
   Xia BY, 2022, LECT NOTES COMPUT SC, V13694, P705, DOI 10.1007/978-3-031-19830-4_40
   Xia BY, 2022, LECT NOTES COMPUT SC, V13694, P741, DOI 10.1007/978-3-031-19830-4_42
   Xiao JX, 2010, PROC CVPR IEEE, V0, PP3485, DOI 10.1109/CVPR.2010.5539970
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yan S, 2022, CVPR, V0, P3333
   Yang J, 2022, P IEEECVF C COMPUTER, V0, P19163
   Yu JH, 2022, ARXIV, V0, P0
   Yuan L, 2021, ARXIV, V0, P0
   Zhai XH, 2022, ARXIV, V0, P0
   Zhang B, 2021, ARXIV, V0, P0
   Zhang RR, 2021, ARXIV, V0, P0
   Zhang RR, 2022, PROC CVPR IEEE, V0, PP8542, DOI 10.1109/CVPR52688.2022.00836
   Zhao S, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP970, DOI 10.1145/3477495.3531950
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou KY, 2022, ARXIV, V0, P0
   Zhou Kaiyang, 2022, P IEEE CVF C COMP VI, V0, P16816
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 98
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s11263-023-01876
EA SEP 2023
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q9PG4
UT WOS:001060757900002
DA 2023-11-10
ER

PT J
AU Demir, S
   Oktem, S
AF Demir, Seniz
   Oktem, Seza
TI A benchmark dataset for Turkish data-to-text generation
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Data-to-text generation; Neural Models; Biography domain; Dining venue domain; Turkish; Crowdsourcing
ID natural-language generation; of-the-art
AB In the last decades, data-to-text (D2T) systems that directly learn from data have gained a lot of attention in natural language generation. These systems need data with high quality and large volume, but unfortunately some natural languages suffer from the lack of readily available generation datasets. This article describes our efforts to create a new Turkish dataset (Tr-D2T) that consists of meaning representation and reference sentence pairs without fine-grained word alignments. We utilize Turkish web resources and existing datasets in other languages for producing meaning representations and collect reference sentences by crowdsourcing native speakers. We particularly focus on the generation of single-sentence biographies and dining venue descriptions. In order to motivate future Turkish D2T studies, we present detailed benchmarking results of different sequence-to-sequence neural models trained on this dataset. To the best of our knowledge, this work is the first of its kind that provides preliminary findings and lessons learned from the creation of a new Turkish D2T dataset. Moreover, our work is the first extensive study that presents generation performances of transformer and recurrent neural network models from meaning representations in this morphologically-rich language.
C1 [Demir, Seniz] MEF Univ, Dept Comp Engn, Istanbul, Turkiye.
   [Oktem, Seza] MEF Univ, Dept English Language Teaching, Istanbul, Turkiye.
C3 MEF Universitesi; MEF Universitesi
RP Demir, S (通讯作者)，MEF Univ, Dept Comp Engn, Istanbul, Turkiye.
EM demirse@mef.edu.tr; oktemse@mef.edu.tr
FU TUBITAK-ARDEB, Turkey [117E977]
CR Altan A, 2016, DIL EDEB DERG, V13, P1
   [Anonymous], 2010, P 2010 C EMP METH NA, V0, P0
   [Anonymous], 2005, P ACL WORKSHOP INTRI, V0, P0
   [Anonymous], 2002, P 2 INT C HUMAN LANG, V0, P0
   Ayan Burcu Karagol, 2000, P COLING STUDENT SES, V0, P0
   Barzilay R, 2005, P HUM LANG TECHN C C, V0, P331
   Belz A, 2009, PRODIGY METEO PREALP, V0, P0
   Bocklisch T, 2017, ARXIV, V0, P0
   Castro Ferreira T, 2018, P 11 INT C NATURAL L, V0, PP171, DOI 10.18653/v1/W18-6521
   Chen DL, 2008, P 25 INT C MACH LEAR, V0, PP128, DOI 10.1145/1390156.1390173
   Chisholm A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P633
   Dusek O, 2020, COMPUT SPEECH LANG, V59, P123, DOI 10.1016/j.csl.2019.06.009
   Ferreira TC, 2019, P 2019 C EMP METH NA, V0, P0
   Gardent C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P179, DOI 10.18653/v1/P17-1017
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gehrmann S, 2018, P 11 INT C NATURAL L, V0, P46
   Hakkani Dilek Zeynep, 1996, DESIGN IMPLEMENTATIO, V0, P0
   Hakkani-Tür DZ, 2002, COMPUT HUMANITIES, V36, P381, DOI 10.1023/A:1020271707826
   Jagfeld Glorianna, 2018, INLG 2018 11 INT NAT, V0, PP221, DOI 10.18653/V1/W18-6529
   Jarvis S, 2013, LANG LEARN, V63, P87, DOI 10.1111/j.1467-9922.2012.00739.x
   Kaffee LA, 2018, SHORT PAPERS, V0, P640
   Kim M, 2018, MOD LANG J, V102, P120, DOI 10.1111/modl.12447
   Kutlugun MA, 2018, 2018 26 SIGNAL PROCE, V0, P0
   Lampouras G, 2018, ARXIV, V0, P0
   Lebret Remi, 2016, P 2016 C EMP METH NA, V0, PP1203, DOI 10.18653/v1/D16-1128
   Liang P, 2009, P JOINT C 47 ANN M A, V0, PP91, DOI 10.1007/978-3-642-02374-3_6
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu TY, 2018, AAAI CONF ARTIF INTE, V0, P4881
   Luckman C, 2020, J FLUENCY DISORD, V63, P0, DOI 10.1016/j.jfludis.2020.105747
   Mahapatra J, 2016, P 9 INT NATURAL LANG, V0, P143
   Mairesse F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P1552
   Malvern D, 2004, LEXICAL DIVERSITY AND LANGUAGE DEVELOPMENT: QUANTIFICATION AND ASSESSMENT, V0, P121
   Manishina E, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3624
   McCarthy PM, 2007, LANG TEST, V24, P459, DOI 10.1177/0265532207080767
   Mecik AB, 2020, P 2020 ECAI WORKSHOP, V0, P0
   Mei Hongyuan, 2016, P 2016 C N AM CHAPTE, V0, P720
   Moryossef A, 2019, P 2019 C N AM CHAPT, V1, P2267
   Nema P, 2018, P 2018 C N AM CHAPTE, V0, P0, DOI DOI 10.18653/V1/N18-1139
   Novikova J, 2019, P 5 WORKSHOP NOISY U, V0, P431
   Nuzumlali MY, 2014, P C EMPIRICAL METHOD, V0, P702
   Ondrej Dusek, 2019, P 12 INT C NATURAL L, V0, P563
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Perez-Beltrachini L, 2017, P 10 INT C NATURAL L, V0, P238
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, V0, PP392, DOI 10.1080/1472586x.2015.1113070.
   Portet F, 2009, ARTIF INTELL, V173, P789, DOI 10.1016/j.artint.2008.12.002
   Puduppully R, 2019, AAAI CONF ARTIF INTE, V0, P6908
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Rao Jinfeng, 2019, P 12 INT C NAT LANG, V0, P95
   Reiter E, 2005, ARTIF INTELL, V167, P137, DOI 10.1016/j.artint.2005.06.006
   Reiter E, 1997, NATURAL LANGUAGE ENGINEERING, V3, P57, DOI 10.1017/S1351324997001502
   Shahidi H, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3864
   Sharma S, 2017, ARXIV, V0, P0
   Shimorina A, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP2019), V0, P44
   Shimorina Anastasia, 2020, P 3 INT WORKSHOP NAT, V0, P55
   Sutskever I, 2011, ICML, V0, P0
   Taylan Erguvanli, 1984, FUNCTION WORD ORDER, V0, P0
   Torruella J, 2013, PROCD SOC BEHV, V95, P447, DOI 10.1016/j.sbspro.2013.10.668
   van der Lee C, 2021, COMPUT SPEECH LANG, V67, P0, DOI 10.1016/j.csl.2020.101151
   Vardar UF, 2019, P 27 SIGNAL PROCESSI, V0, P1
   Varshney D, 2020, LECT NOTES COMPUT SC, V12089, P82, DOI 10.1007/978-3-030-51310-8_8
   Vaswani A, 2017, ARXIV, V30, P5998
   Vougiouklis P, 2018, J WEB SEMANT, V52-53, P1, DOI 10.1016/j.websem.2018.07.002
   Wen TH, 2020, COMPUT SPEECH LANG, V63, P0, DOI 10.1016/j.csl.2019.06.008
   Wen Tsung-Hsien, 2015, P 2015 C EMPIRICAL M, V0, PP1711, DOI 10.18653/v1/D15-1199
   Wiseman S, 2017, P 2017 C EMPIRICAL M, V0, P0
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
NR 67
TC 0
Z9 0
U1 2
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN 15
PY 2023
VL 77
IS 
BP 
EP 
DI 10.1016/j.csl.2022.101433
EA JUL 2022
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3L2LI
UT WOS:000834597200001
DA 2023-11-10
ER

PT J
AU Wang, B
   Li, WZ
   Bradlow, A
   Bazuaye, E
   Chan, ATY
AF Wang, Bing
   Li, Weizi
   Bradlow, Anthony
   Bazuaye, Eghosa
   Chan, Antoni T. Y.
TI Improving triaging from primary care into secondary care using heterogeneous data-driven hybrid machine learning
SO DECISION SUPPORT SYSTEMS
LA English
DT Article
DE Machine learning; Primary to secondary care triage; Ensemble method for heterogeneous data; Prediction explanation; NLP
ID early warning score; emergency-department; rheumatoid-arthritis; inflammatory polyarthritis; validation; prediction; system; scale; performance; algorithm
AB Effective and rapid triaging from primary care into secondary care plays a pivotal role in providing patients with timely treatment and managing increasing demands for healthcare resources. Existing triaging methods from primary care to secondary care are labor-intensive processes that involve manually reviewing referral data from multiple sources and can cause long referral to treatment time. There has been no research using machine learning methods that automatically analyzes heterogeneous data including referral letters to recognize regu-larities to support the primary to secondary care triage. In this paper, we propose a heterogeneous data-driven hybrid machine learning model including Natural Language Processing (NLP) to improve hospital triage effi-ciency at the point of triage. The proposed model achieved a precision of 0.83, recall of 0.82, F1-Score of 0.83, accuracy of 0.82, AUC of 0.90 in identifying patients with non-inflammatory conditions (NIC) and inflammatory arthritis (IA) at the point of triage with explainable risk stratifications. Our model is piloted in a real-world trial in a large secondary care hospital in the UK to compare referral accuracy and time saved between our model and clinicians, and evaluate its acceptability by users. Our model achieved precision and recall of 0.83 and 0.81, compared with the precision and recall of 0.80 and 0.78 by clinicians. The research also shows that our model enabled decision support can save clinicians 8 h per week in assessing the referral assessment. This paper is the first study to streamline hospital triage from primary care to secondary care using machine learning.
C1 [Wang, Bing; Li, Weizi] Univ Reading, Informat Res Ctr, Henley Business Sch, Reading RG6 6UD, England.
   [Bradlow, Anthony; Chan, Antoni T. Y.] Royal Berkshire NHS Fdn Trust, Rheumatol Dept, Reading RG1 5AN, England.
   [Bazuaye, Eghosa] Royal Berkshire NHS Fdn Trust, Informat Dept, Reading RG1 5AN, England.
C3 University of Reading; Royal Berkshire Hospital; Royal Berkshire Hospital
RP Li, WZ (通讯作者)，Univ Reading, Informat Res Ctr, Henley Business Sch, Reading RG6 6UD, England.
EM weizi.li@henley.ac.uk
FU Health Innovation Partnership fund of Royal Berkshire NHS Foundation Trust; University of Reading; UK Engineering and Physical Sciences Research Council (EPSRC) [EP/W000652/1]; Economic and Social Science Research Council (ESRC) [ES/S501785/1]
CR Aletaha D, 2018, JAMA-J AM MED ASSOC, V320, P1360, DOI 10.1001/jama.2018.13103
   Alves C, 2011, ANN RHEUM DIS, V70, P1645, DOI 10.1136/ard.2010.142299
   Arnaud É, 2020, IEEE INT CONF BIG DA, V0, PP4836, DOI 10.1109/BigData50022.2020.9378073
   Azari A, 2015, IEEE INT C BIOINFORM, V0, PP807, DOI 10.1109/BIBM.2015.7359790
   Beveridge R, 1998, J EMERG MED, V16, P507
   Boggan JC, 2020, J GEN INTERN MED, V35, P2136, DOI 10.1007/s11606-019-05585-4
   Bukhari MAS, 2003, ARTHRITIS RHEUM-US, V48, P46, DOI 10.1002/art.10727
   Carroll RJ, 2012, J AM MED INFORM ASSN, V19, PE162, DOI 10.1136/amiajnl-2011-000583
   Choi DH, 2022, AM J EMERG MED, V53, P86, DOI 10.1016/j.ajem.2021.12.065
   Eccles A, 2019, BRIT J GEN PRACT, V69, PE336, DOI 10.3399/bjgp19X702197
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Eitel DR, 2003, ACAD EMERG MED, V10, P1070, DOI 10.1197/S1069-6563(03)00350-6
   Feng Y, 2022, IEEE J BIOMED HEALTH, V26, P1472, DOI 10.1109/JBHI.2021.3073056
   Finnikin S, 2020, BRIT J GEN PRACT, V70, P272, DOI 10.3399/bjgp20X709361
   FitzGerald G, 2010, EMERG MED J, V27, P86, DOI 10.1136/emj.2009.077081
   Fletcher E, 2017, BMJ OPEN, V7, P0, DOI 10.1136/bmjopen-2017-015853
   Foot C, 2010, QUALITY GP DIAGNOSIS, V0, P0
   Ganaie MA, 2022, ARXIV, V0, P0
   Gerry S, 2020, BMJ-BRIT MED J, V369, P0, DOI 10.1136/bmj.m1501
   Gligorijevic D, 2022, DEEP ATTENTION MODEL, V0, P297
   Hobbs FDR, 2016, LANCET, V387, P2323, DOI 10.1016/S0140-6736(16)00620-6
   Hodge A, 2013, AUSTRALAS EMERG NURS, V16, P21, DOI 10.1016/j.aenj.2012.12.003
   Hong WS, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0201016
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Jernite Y, 2022, PREDICTING CHIEF COM, V0, P0
   Joseph JW, 2020, JACEP OPEN, V1, P773, DOI 10.1002/emp2.12218
   Kay L, 2021, RHEUMATOLOGY GIRFT P, V0, P0
   Kenyon S, 2017, BMC PREGNANCY CHILDB, V17, P0, DOI 10.1186/s12884-017-1503-5
   Kijpaisalratana N, 2022, INT J MED INFORM, V160, P0, DOI 10.1016/j.ijmedinf.2022.104689
   Klug M, 2020, J GEN INTERN MED, V35, P220, DOI 10.1007/s11606-019-05512-7
   Kwon JM, 2021, PEDIATR EMERG CARE, V37, PE988, DOI 10.1097/PEC.0000000000001858
   Lauritsen SM, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17431-x
   Levin S, 2018, ANN EMERG MED, V71, P565, DOI 10.1016/j.annemergmed.2017.08.005
   MClinic, 2022, RHEUMATOID ARTHRITIS, V0, P0
   Mackway-Jones K, 2013, EMERGENCY TRIAGE, V0, P0
   Mahajan V, 2020, INDIAN PEDIATR, V57, P658, DOI 10.1007/s13312-020-1895-6
   Miotto R, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep26094
   Morgan RJM, 1997, CLIN INTENSIVE CARE, V8, P100, DOI 10.3109/TCIC.8.2.93.110
   Moudi A, 2022, J MATERN-FETAL NEO M, V35, P1719, DOI 10.1080/14767058.2020.1768239
   Moxham L, 2020, J CLIN NURS, V29, P3679, DOI 10.1111/jocn.15392
   NDigital,, 2022, REF ASS SERV NHS E R, V0, P0
   Nell VPK, 2004, RHEUMATOLOGY, V43, P906, DOI 10.1093/rheumatology/keh199
   NHS, 2022, RHEUMATOID ARTHRITIS, V0, P0
   Nice, 2020, RHEUMATOID ARTHRITIS, V0, P0
   Norgeot B, 2019, JAMA NETW OPEN, V2, P0, DOI 10.1001/jamanetworkopen.2019.0606
   NRAS, 2021, ANN REPORT, VSecond, P0
   ONeill SM, 2021, BMC EMERG MED, V21, P0, DOI 10.1186/s12873-021-00403-9
   PULSE, 2022, CP CLIN JUDG LEADS 2, V0, P0
   RCoGPractitioners, 2013, 2022 GP VIS GEN PRAC, V0, P0
   Raita Y, 2019, CRIT CARE, V23, P0, DOI 10.1186/s13054-019-2351-7
   RCGP, 2018, QUAL PAT REF RIGHT S, V0, P0
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Roukema J, 2006, EMERG MED J, V23, P906, DOI 10.1136/emj.2006.038877
   Ruhl C, 2015, JOGNN-J OBST GYN NEO, V44, P701, DOI 10.1111/1552-6909.12763
   Sanchez Velarde ES, 2022, FUZZY STATE MACHINE, V0, P1488
   Sánchez-Salmerón R, 2022, INT EMERG NURS, V60, P0, DOI 10.1016/j.ienj.2021.101109
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Smith GB, 2013, RESUSCITATION, V84, P465, DOI 10.1016/j.resuscitation.2012.12.016
   Smithson DS, 2013, AM J OBSTET GYNECOL, V209, P287, DOI 10.1016/j.ajog.2013.03.031
   Stack RJ, 2013, ARTHRIT CARE RES, V65, P1916, DOI 10.1002/acr.22097
   Sterling NW, 2020, JACEP OPEN, V1, P1676, DOI 10.1002/emp2.12253
   Sterling NW, 2019, INT J MED INFORM, V129, P184, DOI 10.1016/j.ijmedinf.2019.06.008
   Subbe CP, 2001, QJM-MON J ASSOC PHYS, V94, P521, DOI 10.1093/qjmed/94.10.521
   Swaminathan S, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0188532
   Tahayori B, 2021, EMERG MED AUSTRALAS, V33, P480, DOI 10.1111/1742-6723.13656
   Teubner DJO, 2015, EMERG MED AUSTRALAS, V27, P300, DOI 10.1111/1742-6723.12425
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520
   Tsai FS, 2017, INT CONF AFFECT, V0, PP313, DOI 10.1109/ACII.2017.8273618
   van Buuren S, 2011, J STAT SOFTW, V45, P1
   Veit-Rubin N, 2017, BJOG-INT J OBSTET GY, V124, P1867, DOI 10.1111/1471-0528.14535
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6382
   WEINERMAN ER, 1966, AM J PUBLIC HEALTH N, V56, P1037, DOI 10.2105/AJPH.56.7.1037
   Wiles NJ, 2001, ARTHRITIS RHEUM-US, V44, P1033, DOI 10.1002/1529-0131(200105)44:5<1033::AID-ANR182>3.0.CO;2-G
   Yu JY, 2020, HEALTHC INFORM RES, V26, P13, DOI 10.4258/hir.2020.26.1.13
   Zlotnik A, 2016, CIN-COMPUT INFORM NU, V34, P224, DOI 10.1097/CIN.0000000000000230
   Zmiri D, 2012, J EVAL CLIN PRACT, V18, P378, DOI 10.1111/j.1365-2753.2010.01592.x
NR 77
TC 1
Z9 1
U1 12
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-9236
EI 1873-5797
J9 DECIS SUPPORT SYST
JI Decis. Support Syst.
PD MAR 15
PY 2023
VL 166
IS 
BP 
EP 
DI 10.1016/j.dss.2022.113899
EA JAN 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science
SC Computer Science; Operations Research & Management Science
GA 8R3BH
UT WOS:000927769100001
DA 2023-11-10
ER

PT J
AU Li, R
   Liu, C
   Jiang, DZ
AF Li, Rui
   Liu, Cheng
   Jiang, Dazhi
TI Efficient dynamic feature adaptation for cross language sentiment analysis with biased adversarial training
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Pre-trained language model; Cross-language understanding; Sentiment analysis; Efficient domain adaptation; Adversarial training
AB Fine-tuning a large multi-lingual pretrained language model demonstrates impressive results in crosslanguage understanding. However, it still suffers when the training and test data have different distributions owing to various languages and domains. On one hand, annotating target data for different languages or domains is time-consuming or infeasible. On the other hand, fine-tuning a large language model often incurs high computational costs. In this paper, we aim to develop an efficient and effective adaptation framework for cross-language sentiment analysis based on a fixed pretrained multi-lingual model. Specifically, we propose a Dynamic Feature Adaptation (DFA) module to fully leverage the features from different layers of the pretrained model such that its large backbone is not involved during adaptation training. Furthermore, we observe that traditional adversarial domain adaptation training could compromise the discriminative information of the model by pushing source and target features towards each other. The source features obtained with supervised training preserved the discriminability of the model, which should be less affected. Therefore, we propose a novel Biased Adversarial Training (BAT) method, that encourages only the target features towards source features. Extensive experimental results on various cross-lingual and cross-lingual-and-domain sentiment analysis tasks demonstrate the superiority of the proposed framework. Additionally, several ablation studies are conducted to validate the effectiveness of each proposed module. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Li, Rui; Liu, Cheng; Jiang, Dazhi] Shantou Univ, Dept Comp Sci, Shantou 515063, Guangdong, Peoples R China.
C3 Shantou University
RP Li, R (通讯作者)，Shantou Univ, Dept Comp Sci, Shantou 515063, Guangdong, Peoples R China.
EM ruili@stu.edu.cn; chengliu10@gmail.com; dzjiang@stu.edu.cn
FU National Natural Science Foundation of China [62106136]; Natural Science Foundation of Guangdong Province, China [2022A1515010434]; Shantou University, China [NTF20007, NTF22012]
CR Brown TB, 2020, ARXIV, V0, P0
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Benedetto F, 2016, STUD COMPUT INTELL, V639, P341, DOI 10.1007/978-3-319-30319-2_14
   Birjali M, 2021, KNOWL-BASED SYST, V226, P0, DOI 10.1016/j.knosys.2021.107134
   Cambria E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3829
   Chen CQ, 2022, KNOWL-BASED SYST, V239, P0, DOI 10.1016/j.knosys.2021.107982
   Chen ST, 2023, PATTERN RECOGN, V137, P0, DOI 10.1016/j.patcog.2022.109271
   Chen X, 2018, T ASSOC COMPUT LING, V6, P557, DOI 10.1162/TACL_A_00039
   Chen YM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P9125
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Dang NC, 2020, ARXIV, V0, P0
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du CN, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4019
   Fu YP, 2022, NEUROCOMPUTING, V494, P56, DOI 10.1016/j.neucom.2022.04.092
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He K, 2023, IEEE T AFFECT COMPUT, V14, P1731, DOI 10.1109/TAFFC.2022.3202831
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3467
   Jianfei Yang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12369), V0, PP589, DOI 10.1007/978-3-030-58586-0_35
   Kingma DP, 2017, PROC 3 INT C LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Kundu JN, 2022, PR MACH LEARN RES, V0, P0
   Li B, 2021, PROC CVPR IEEE, V0, PP1104, DOI 10.1109/CVPR46437.2021.00116
   Li JC, 2018, AAAI CONF ARTIF INTE, V0, P5213
   Li JT, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3672
   Li R, 2022, P 29 INT C COMP LING, V0, P6934
   Li YS, 2021, PROC CVPR IEEE, V0, PP10993, DOI 10.1109/CVPR46437.2021.01085
   Liang X, 2022, KNOWL-BASED SYST, V250, P0, DOI 10.1016/j.knosys.2022.108982
   Liu C, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP3377, DOI 10.1145/3394486.3403390
   Liu H, 2019, INT C MACH LEARN, V0, P4013
   Long MS, 2018, ADV NEUR IN, V31, P0
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685
   Mao R, 2023, IEEE T AFFECT COMPUT, V14, P1743, DOI 10.1109/TAFFC.2022.3204972
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Prettenhofer P, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P1118
   Radford Alec, 2016, ICLR, V0, P0, DOI DOI 10.48550/ARXIV.1511.06434
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tian Q, 2022, KNOWL-BASED SYST, V248, P0, DOI 10.1016/j.knosys.2022.108903
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Wilson G, 2020, ACM T INTEL SYST TEC, V11, P0, DOI 10.1145/3400066
   Yang B, 2019, ADV NEUR IN, V32, P0
   Yang ZL, 2019, ADV NEUR IN, V32, P0
   Ye H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7386
   Yi CA, 2022, KNOWL-BASED SYST, V250, P0, DOI 10.1016/j.knosys.2022.108831
   Yinpeng Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP11027, DOI 10.1109/CVPR42600.2020.01104
   Zaheer M, 2020, ADV NEUR IN, V33, P0
   Zellinger W, 2017, ARXIV170208811, V0, P1
   Zhang H, 2018, P INT C LEARN REPR, V0, PP1, DOI 10.48550/ARXIV.1710.09412
   Zhang SS, 2022, ARXIV, V0, P0
   Zhao CJ, 2020, KNOWL-BASED SYST, V191, P0, DOI 10.1016/j.knosys.2019.105254
   Zhou Q, 2021, KNOWL-BASED SYST, V212, P0, DOI 10.1016/j.knosys.2020.106606
NR 56
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 4
PY 2023
VL 279
IS 
BP 
EP 
DI 10.1016/j.knosys.2023.110957
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA T5XB2
UT WOS:001078705700001
DA 2023-11-10
ER

PT J
AU Pan, RH
   García-Díaz, JA
   Garcia-Sanchez, F
   Valencia-García, R
AF Pan, Ronghao
   Garcia-Diaz, Jose Antonio
   Garcia-Sanchez, Francisco
   Valencia-Garcia, Rafael
TI Evaluation of transformer models for financial targeted sentiment analysis in Spanish
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Natural language processing; Financial domain; Targeted sentiment analysis
ID language
AB Nowadays, financial data from social media plays an important role to predict the stock market. However, the exponential growth of financial information and the different polarities of sentiment that other sectors or stakeholders may have on the same information has led to the need for new technologies that automatically collect and classify large volumes of information quickly and easily for each stakeholder. In this scenario, we conduct a targeted sentiment analysis that can automatically extract the main economic target from financial texts and obtain the polarity of a text towards such main economic target, other companies and society in general. To this end, we have compiled a novel corpus of financial tweets and news headlines in Spanish, constituting a valuable resource for the Spanish-focused research community. In addition, we have carried out a performance comparison of different Spanish-specific large language models, with MarIA and BETO achieving the best results. Our best result has an overall performance of 76.04%, 74.16%, and 68.07% in macro F1-score for the sentiment classification towards the main economic target, society, and other companies, respectively, and an accuracy of 69.74% for target detection. We have also evaluated the performance of multi-label classification models in this context and obtained a performance of 71.13%.
C1 [Pan, Ronghao; Garcia-Diaz, Jose Antonio; Garcia-Sanchez, Francisco; Valencia-Garcia, Rafael] Univ Murcia, Fac Informat, Murcia, Spain.
C3 University of Murcia
RP Valencia-García, R (通讯作者)，Univ Murcia, Fac Informat, Murcia, Spain.
EM valencia@um.es
FU MCIN/AEI [PDC2021-121112-I00, TED2021-131167B-I00]; European Union NextGenerationEU/PRTR; Seneca Foundation-the Regional Agency for Science and Technology of Murcia (Spain); Banco Santander; University of Murcia;  [20963/PI/18];  [PID2019-107652RB-I00/AEI]
CR Paredes-Valverde MA, 2017, SCI PROGRAMMING-NETH, V2017, P0, DOI 10.1155/2017/1329281
   García-Díaz JA, 2022, FUTURE GENER COMP SY, V130, P59, DOI 10.1016/j.future.2021.12.011
   García-Díaz JA, 2020, PROCES LENG NAT, V0, PP139, DOI 10.26342/2020-65-22
   Arratia-Quesada AA, 2021, PREDICCIONESFINANCIE, V0, P137
   Barnes J, 2022, P 16 INT WORKSHOP SE, V0, P0
   Bo Pang, 2008, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V2, P1, DOI 10.1561/1500000001
   Bozinovski S, 2020, INFORM-INT J COMPUT, V44, P291, DOI 10.31449/inf.v44i3.2828
   Brauwers G, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3503044
   Canete J, 2020, PML4DC ICLR, V0, P0
   Cañete J, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P4291
   Chiang CH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6813
   Martínez-Seis BC, 2022, COMPUT SIST, V26, P899, DOI 10.13053/CyS-26-2-4258
   Conneau Alexis, 2019, ARXIV191102116, V0, P0
   de la Rosa J, 2022, PROCES LENG NAT, V0, PP13, DOI 10.26342/2022-68-1
   Salas-Zárate MD, 2017, COMPUT MATH METHOD M, V2017, P0, DOI 10.1155/2017/5140631
   Salas-Zárate MD, 2017, J INF SCI, V43, P458, DOI 10.1177/0165551516645528
   Salas-Zárate MD, 2014, J INF SCI, V40, P749, DOI 10.1177/0165551514547842
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du N, 2022, INT C MACHINE LEARNI, V162, P5547
   Garcia-Diaz JA, 2023, IEEE ACCESS, V11, P14211, DOI 10.1109/ACCESS.2023.3244065
   Goodell JW, 2023, J BEHAV EXP FINANC, V37, P0, DOI 10.1016/j.jbef.2022.100722
   Gutiérrez-Fandiño A, 2022, PROCES LENG NAT, V0, PP39, DOI 10.26342/2022-68-3
   Hamborg F, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1663
   Kalyan KS, 2021, ARXIV, V0, P0
   Kharde V, 2016, INT J COMPUTER APPL, V139, P5, DOI 10.5120/IJCA2016908625
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Liaw R, 2018, ARXIV, V0, P0
   Ligthart A, 2021, ARTIF INTELL REV, V54, P4997, DOI 10.1007/s10462-021-09973-3
   Liu YH, 2019, ARXIV, V0, P0
   Milne A, 2013, SSRN ELECT J, V1, P9, DOI 10.2139/ssrn.2325362
   Mutlu MM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): STUDENT RESEARCH WORKSHOP, V0, P467
   Nemes L, 2021, J INFORM TELECOMMUN, V5, P375, DOI 10.1080/24751839.2021.1874252
   Orbach M, 2021, P 2021 C EMP METH NA, V0, P0
   Angel SO, 2021, DATA TECHNOL APPL, V55, P461, DOI 10.1108/DTA-09-2020-0200
   Othan D, 2019, PROC ICIIT, V0, P30
   Paul A, 2016, IEEE WIREL COMMUN, V23, P68, DOI 10.1109/MWC.2016.7721744
   Peñalver-Martinez I, 2014, EXPERT SYST APPL, V41, P5995, DOI 10.1016/j.eswa.2014.03.022
   Pilar GD, 2023, EXPERT SYST APPL, V212, P0, DOI 10.1016/j.eswa.2022.118817
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Sanh V, 2020, ARXIV, V0, P0
   Sonkiya P, 2021, ARXIV, V0, P0
   Tetlock PC, 2007, J FINANC, V62, P1139, DOI 10.1111/j.1540-6261.2007.01232.x
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Veres C, 2022, IEEE ACCESS, V10, P61970, DOI 10.1109/ACCESS.2022.3182505
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Yang K, 2022, EXPERT SYST APPL, V198, P0, DOI 10.1016/j.eswa.2022.116847
   Yi JY, 2019, INT CONF ACOUST SPEE, V0, PP7270, DOI 10.1109/ICASSP.2019.8682260
NR 49
TC 0
Z9 0
U1 3
U2 3
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD MAY 9
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1377
PG 33
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA H5LY1
UT WOS:000996387100005
PM 37346571
DA 2023-11-10
ER

PT J
AU Hu, HX
   Sener, O
   Sha, F
   Koltun, V
AF Hu, Hexiang
   Sener, Ozan
   Sha, Fei
   Koltun, Vladlen
TI Drinking From a Firehose: Continual Learning With Web-Scale Natural Language
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Task analysis; Benchmark testing; Learning systems; Multitasking; Social networking (online); Neural networks; Data models; Continual learning; lifelong learning; personalized language modelling; online multi-task learning; web-scale datasets
ID knowledge
AB Continual learning systems will interact with humans, with each other, and with the physical world through time - and continue to learn and adapt as they do. An important open problem for continual learning is a large-scale benchmark which enables realistic evaluation of algorithms. In this paper, we study a natural setting for continual learning on a massive scale. We introduce the problem of personalized online language learning (POLL), which involves fitting personalized language models to a population of users that evolves over time. To facilitate research on POLL, we collect massive datasets of Twitter posts. These datasets, Firehose10 M and Firehose100 M, comprise 100 million tweets, posted by one million users over six years. Enabled by the Firehose datasets, we present a rigorous evaluation of continual learning algorithms on an unprecedented scale. Based on this analysis, we develop a simple algorithm for continual gradient descent (ConGraD) that outperforms prior continual learning methods on the Firehose datasets as well as earlier benchmarks. Collectively, the POLL problem setting, the Firehose datasets, and the ConGraD algorithm enable a complete benchmark for reproducible research on web-scale continual learning.
C1 [Hu, Hexiang; Sha, Fei] Univ Southern Calif, Viterbi Sch Engn, Dept Comp Sci, Los Angeles, CA 90007 USA.
   [Sener, Ozan; Koltun, Vladlen] Intel Labs, Santa Clara, CA 95054 USA.
C3 University of Southern California; Intel Corporation
RP Sener, O (通讯作者)，Intel Labs, Santa Clara, CA 95054 USA.
EM hexiang.frank.hu@gmail.com; ozansener@cs.stanford.edu; feisha@usc.edu; vkoltun@gmail.com
CR Ahn Hongjoon, 2019, ADV NEUR IN, V0, P4392
   Ajalloeian A, 2021, ARXIV, V0, P0
   Aljundi R, 2019, ARXIV, V0, P0
   Aljundi R, 2013, GRADIENT BASED SAMPL, V0, P0
   Aljundi R, 2019, ADV NEUR IN, V32, P0
   Aljundi R, 2019, PROC CVPR IEEE, V0, PP11246, DOI 10.1109/CVPR.2019.01151
   Aljundi R, 2017, PROC CVPR IEEE, V0, PP7120, DOI 10.1109/CVPR.2017.753
   [Anonymous], 2017, ADV NEURAL INFORM PR, V0, P0
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Brown TB, 2020, ARXIV, V0, P0
   Biesialska M, 2020, P 28 INT C COMPUTATI, V0, PP6523, DOI 10.18653/V1/2020.COLING-MAIN.574
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Buzzega P, 2020, PROC 34 INT C NEURAL, V0, P0
   Carlson A, 2010, AAAI CONF ARTIF INTE, V0, P1306
   Changpinyo S, 2018, P 27 INT C COMP LING, V0, P2965
   Chaudhry A, 2019, PROC INT C LEARN REP, V0, P1
   Chaudhry A, 2018, LECT NOTES COMPUT SC, V11215, P556, DOI 10.1007/978-3-030-01252-6_33
   Chaudhry Arslan, 2019, ARXIV, V0, P0
   Chen XL, 2013, IEEE I CONF COMP VIS, V0, PP1409, DOI 10.1109/ICCV.2013.178
   Chen Y, 2019, ARXIV, V0, P0
   Chen Z, 2018, LIFELONG MACHINE LEA, V0, P0
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Dathathri S, 2020, PROC INT C LEARN REP, V0, P0
   De Lange M, 2021, ARXIV, V0, P0
   Ficler Jessica, 2017, P WORKSH STYL VAR, V0, PP94, DOI 10.18653/V1/W17-4912
   Grossberg ST, 2012, STUDIES MIND BRAIN, V0, P0
   Hazan E, 2016, FDN TRENDS OPTIM, V2, P157, DOI 10.1561/2400000013
   Hazan E, 2017, PR MACH LEARN RES, V70, P0
   Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Hu Z, 2017, PR MACH LEARN RES, V0, P0
   Isele D, 2018, AAAI CONF ARTIF INTE, V0, P3302
   Jin XS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2018
   Jung HC, 2016, ARXIV, V0, P0
   Ke Z, 2020, PROC 34 INT C NEURAL, V0, P0
   Kingma DP, 2015, ABS14126980 CORR, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Lample G, 2019, P INT C LEARN REPR, V0, P0
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   Logeswaran L, 2018, ADV NEURAL INFORM PR, V0, P5108
   Lopez-Paz D, 2017, ADV NEUR IN, V30, P0
   Madotto A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P7452
   Mallya A, 2018, PROC CVPR IEEE, V0, PP7765, DOI 10.1109/CVPR.2018.00810
   McCloskey M, 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI 10.1016/S0079-7421(08)60536-8
   Nguyen CV, 2018, PROC INT C LEARN REP, V0, P1
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Prabhu Ameya, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12347), V0, PP524, DOI 10.1007/978-3-030-58536-5_31
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Rannen A, 2017, IEEE I CONF COMP VIS, V0, PP1329, DOI 10.1109/ICCV.2017.148
   Rebuffi S, 2017, ADV NEURAL INFORM PR, V0, P506
   Rebuffi SA, 2017, PROC CVPR IEEE, V0, PP5533, DOI 10.1109/CVPR.2017.587
   Ritter H, 2018, ADV NEUR IN, V31, P0
   Robins A, 1995, CONNECTION SCIENCE, V7, P123, DOI 10.1080/09540099550039318
   Rolnick D, 2019, PROC 33 INT C NEURAL, V0, P0
   Rusu AA, 2016, PROC INT C NEURAL IN, V0, P0
   Saxena A, 2015, ARXIV, V0, P0
   Schmidhuber J, 1997, NEURAL NETWORKS, V10, P857, DOI 10.1016/S0893-6080(96)00127-X
   Schwarz J, 2018, PR MACH LEARN RES, V80, P0
   Sener O, 2020, PROC INT C LEARN REP, V0, P0
   Serrà J, 2018, PR MACH LEARN RES, V80, P0
   Shalev-Shwartz S, 2012, FOUND TRENDS MACH LE, V4, P107, DOI 10.1561/2200000018
   Shin H, 2017, ADV NEUR IN, V30, P0
   Keskar NS, 2019, ARXIV, V0, P0
   Silver DL, 2002, ADV ARTIFICIAL INTEL, V15, P90, DOI 10.1007/3-540-47922-8_8
   Socher Richard, 2017, P 2017 C EMP METH NA, V0, PP1923, DOI 10.18653/V1/D17-1206
   Suchanek F, 2007, P 16 INT C WORLD WID, V0, P0, DOI DOI 10.1145/1242572.1242667
   Swaroop S, 2019, ARXIV, V0, P0
   Thrun S, 1996, ADV NEUR IN, V8, P640
   Vaswani A, 2017, P ADV NEUR INF PROC, V0, P0
   Wang A, 2019, PROC INT C LEARN REP, V0, P1
   Wang A, 2019, PROC 33 INT CONFNEUR, V0, P0
   Wu YH, 2016, ARXIV, V0, P0
   Yao Y, 2007, CONSTR APPROX, V26, P289, DOI 10.1007/s00365-006-0663-2
   Zenke F, 2017, PR MACH LEARN RES, V70, P0
   Zhang JT, 2020, IEEE WINT CONF APPL, V0, PP1120, DOI 10.1109/WACV45572.2020.9093365
NR 79
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD MAY 1
PY 2023
VL 45
IS 5
BP 5684
EP 5696
DI 10.1109/TPAMI.2022.3218265
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA C9BQ7
UT WOS:000964792800022
PM 36315549
DA 2023-11-10
ER

PT J
AU Zhou, CL
   Liang, YL
   Meng, FD
   Zhou, J
   Xu, JA
   Wang, HJ
   Zhang, M
   Su, JS
AF Zhou, Chulun
   Liang, Yunlong
   Meng, Fandong
   Zhou, Jie
   Xu, Jinan
   Wang, Hongji
   Zhang, Min
   Su, Jinsong
TI A Multi-Task Multi-Stage Transitional Training Framework for Neural Chat Translation
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Training; Task analysis; Context modeling; History; Coherence; Electronic mail; Multitasking; Dialogue coherence; gradual transition; monolingual dialogue; neural chat translation; speaker characteristic
AB Neural chat translation (NCT) aims to translate a cross-lingual chat between speakers of different languages. Existing context-aware NMT models cannot achieve satisfactory performances due to the following inherent problems: 1) limited resources of annotated bilingual dialogues; 2) the neglect of modelling conversational properties; 3) training discrepancy between different stages. To address these issues, in this paper, we propose a multi-task multi-stage transitional (MMT) training framework, where an NCT model is trained using the bilingual chat translation dataset and additional monolingual dialogues. We elaborately design two auxiliary tasks, namely utterance discrimination and speaker discrimination, to introduce the modelling of dialogue coherence and speaker characteristic into the NCT model. The training process consists of three stages: 1) sentence-level pre-training on large-scale parallel corpus; 2) intermediate training with auxiliary tasks using additional monolingual dialogues; 3) context-aware fine-tuning with gradual transition. Particularly, the second stage serves as an intermediate phase that alleviates the training discrepancy between the pre-training and fine-tuning stages. Moreover, to make the stage transition smoother, we train the NCT model using a gradual transition strategy, i.e., gradually transiting from using monolingual to bilingual dialogues. Extensive experiments on two language pairs demonstrate the effectiveness and superiority of our proposed training framework.
C1 [Zhou, Chulun; Wang, Hongji; Su, Jinsong] Xiamen Univ, Sch Informat, Xiamen 361005, Fujian, Peoples R China.
   [Liang, Yunlong; Xu, Jinan] Beijing Jiaotong Univ, Beijing 100044, Peoples R China.
   [Meng, Fandong; Zhou, Jie] Tencent Inc, Pattern Recognit Ctr, WeChat AI, Beijing 100080, Peoples R China.
   [Zhang, Min] Soochow Univ, Suzhou 215031, Jiangsu, Peoples R China.
   [Su, Jinsong] Xiamen Univ, Inst Artificial Intelligence, Xiamen 361005, Fujian, Peoples R China.
   [Su, Jinsong] Lab Digital Protect & Intelligent Proc Intangibl, Fuzhou, Fujian, Peoples R China.
   [Su, Jinsong] Taiwan Xiamen Univ, Minist Culture & Tourism, Fuzhou 361005, Fujian, Peoples R China.
   [Su, Jinsong] Pengcheng Lab, Shenzhen 518066, Guangdong, Peoples R China.
C3 Xiamen University; Beijing Jiaotong University; Tencent; Soochow University - China; Xiamen University
RP Su, JS (通讯作者)，Xiamen Univ, Sch Informat, Xiamen 361005, Fujian, Peoples R China.; Su, JS (通讯作者)，Xiamen Univ, Inst Artificial Intelligence, Xiamen 361005, Fujian, Peoples R China.; Su, JS (通讯作者)，Lab Digital Protect & Intelligent Proc Intangibl, Fuzhou, Fujian, Peoples R China.; Su, JS (通讯作者)，Taiwan Xiamen Univ, Minist Culture & Tourism, Fuzhou 361005, Fujian, Peoples R China.; Su, JS (通讯作者)，Pengcheng Lab, Shenzhen 518066, Guangdong, Peoples R China.
EM clzhou@stu.xmu.edu.cn; yunlongliang@bjtu.edu.cn; fandongmeng@tencent.com; withtomzhou@tencent.com; jaxu@bjtu.edu.cn; whj@xmu.edu.cn; minzhang@suda.edu.cn; jssu@xmu.edu.cn
FU National Natural Science Foundation of China [62036004, 61672440]; Natural Science Foundation of Fujian Province of China [2020J06001]; Youth Innovation Fund of Xiamen [3502Z20206059]
CR Agrawal RR, 2018, 21 ANN C EUR ASS MAC, V0, P11
   [Anonymous], 2020, PROC 5 C MACH TRANSL, V0, P0
   [Anonymous], 2020, PROC 5 C MACH TRANSL, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bawden R, 2018, P 2018 C N AM CHAPT, V1, P1304, DOI 10.18653/V1/N18-1118
   Berard A, 2020, PROC 5 C MACH TRANSL, V0, P462
   Byrne B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4516
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Farajian MA, 2020, PROC 5 C MACH TRANSL, V0, P65
   FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309
   Huang LS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9230
   Jean S, 2017, ARXIV, V0, P0
   Kang XM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2242
   Kingma DP, 2017, PROC 3 INT C LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Koehn Philipp, 2004, P 2004 C EMPIRICAL M, V0, P388
   Kuang S, 2018, P 27 INT C COMP LING, V0, P596
   Lapata M, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), V0, P1085
   Li B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3512
   Liang YL, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2601
   Liang Yunlong, 2021, PROC ANN M ASS COMPU, V0, P5711
   LongyueWang Zhaopeng Tu, 2017, EMNLP, V0, P0, DOI DOI 10.18653/v1/d17-1301
   Ma SM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3505
   Maruf S, 2018, PROC 3 C MACH TRANSL, V0, P101
   Maruf S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3092
   Maruf S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1275
   Miculicich L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2947
   Mikolov T, 2013, PROC 1 INT C LEARN R, V1301, P3781
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P527
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tan Z, 2020, P 14 C ASS MACHINE T, V0, P116
   Tiedemann J, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Tu Zhaopeng, 2018, T ASSOC COMPUT LING, V6, P407
   Vaswani A, 2017, ARXIV, V30, P5998
   Voita E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P877
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1198
   Voita E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1264
   Wang, 2020, P 5 C MACHINE TRANSL, V0, P483
   Wang LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P921
   Wang LY, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2748
   Wang T, 2021, PROC C N AM CHAPTER, V0, PP105, DOI 10.18653/v1/2021.naacl-industry.14
   Wang TM, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5233
   Wang WC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5066
   Xiong H, 2019, AAAI CONF ARTIF INTE, V0, P7338
   Zhang JC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P533
   Zhang LL, 2019, ASIAPAC SIGN INFO PR, V0, PP1029, DOI 10.1109/APSIPAASC47483.2019.9023129
   Zheng ZX, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3983
NR 47
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUL 1
PY 2023
VL 45
IS 7
BP 7970
EP 7985
DI 10.1109/TPAMI.2022.3233226
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA I7PI8
UT WOS:001004665900003
PM 37015651
DA 2023-11-10
ER

PT J
AU Drozdova, A
   Trofimova, E
   Guseva, P
   Scherbakova, A
   Ustyuzhanin, A
AF Drozdova, Anastasia
   Trofimova, Ekaterina
   Guseva, Polina
   Scherbakova, Anna
   Ustyuzhanin, Andrey
TI Code4ML: a large-scale dataset of annotated Machine Learning code
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE ML code dataset; Jupyter code snippets
ID software
AB The use of program code as a data source is increasingly expanding among data scientists. The purpose of the usage varies from the semantic classification of code to the automatic generation of programs. However, the machine learning model application is somewhat limited without annotating the code snippets. To address the lack of annotated datasets, we present the Code4ML corpus. It contains code snippets, task summaries, competitions, and dataset descriptions publicly available from Kaggle-the leading platform for hosting data science competitions. The corpus consists of similar to 2.5 million snippets of ML code collected from similar to 100 thousand Jupyter notebooks. A representative fraction of the snippets is annotated by human assessors through a user-friendly interface specially designed for that purpose. Code4ML dataset can help address a number of software engineering or data science challenges through a data-driven approach. For example, it can be helpful for semantic code classification, code auto-completion, and code generation for an ML task specified in natural language.
C1 [Drozdova, Anastasia; Trofimova, Ekaterina; Guseva, Polina; Scherbakova, Anna; Ustyuzhanin, Andrey] NRU Higher Sch Econ, Dept Comp Sci, Moscow, Russia.
   [Ustyuzhanin, Andrey] Natl Univ Sci & Technol MISIS, Moscow, Russia.
   [Ustyuzhanin, Andrey] Constructor Univ, Bremen, Germany.
   [Ustyuzhanin, Andrey] Natl Univ Singapore, Inst Funct Intelligent Mat, Singapore, Singapore.
C3 HSE University (National Research University Higher School of Economics); National University of Science & Technology (MISIS); National University of Singapore; Institute for Functional Intelligent Materials (I-FIM)
RP Trofimova, E (通讯作者)，NRU Higher Sch Econ, Dept Comp Sci, Moscow, Russia.
EM etrofimova@hse.ru
FU Analytical Center for the Government of the Russian Federation (ACRF) [000000D730321P5Q0002]; HSE University [70-2021-00139]
CR Agashe R, 2019, ARXIV, V0, P0
   Akiba T, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2623, DOI 10.1145/3292500.3330701
   Allamanis M, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3212695
   Alsolai H, 2020, INFORM SOFTWARE TECH, V119, P0, DOI 10.1016/j.infsof.2019.106214
   [Anonymous], 2021, 2402912021 ISOIEC TR, V0, P0
   Austin J, 2021, ARXIV, V0, P0
   Bilgin Z, 2020, IEEE ACCESS, V8, P150672, DOI 10.1109/ACCESS.2020.3016774
   Biswas Sumon, 2019, 2019 IEEE/ACM 16TH INTERNATIONAL CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR), V0, PP577, DOI 10.1109/MSR.2019.00086
   Boser BE, 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP144, DOI 10.1145/130385.130401
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1961189.1961199
   Chen Mark, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2107.03374
   Drozdova Anastasia, 2022, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.7312803
   Gretton A, 2006, ADV NEURAL INFORM PR, V19, P513
   Hellendoorn VJ, 2019, PROC INT CONF SOFTW, V0, PP960, DOI 10.1109/ICSE.2019.00101
   Husain H, 2020, ARXIV, V0, P0
   Iyer S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1643
   Le Goues C, 2019, COMMUN ACM, V62, P56, DOI 10.1145/3318162
   Liu F, 2020, INT C PROGRAM COMPRE, V0, PP37, DOI 10.1145/3387904.3389261
   Lu S, 2021, ARXIV, V0, P0
   Murphy GC, 2006, IEEE SOFTWARE, V23, P76, DOI 10.1109/MS.2006.105
   Papineni K, 2001, 2 M N AM CHAPT ASS C, V0, P0
   Puri Ruchir, 2021, ARXIV, V0, P0
   Qizhe Xie, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10684, DOI 10.1109/CVPR42600.2020.01070
   Quaranta L, 2021, IEEE WORK CONF MIN S, V0, PP550, DOI 10.1109/MSR52588.2021.00072
   Raychev V, 2016, ACM SIGPLAN NOTICES, V51, P731, DOI 10.1145/3022671.2984041
   Roziere B, 2020, NIPS 20 P 34 INT C N, V0, P0
   Shearer C, 2000, J DATA WAREHOUSING, V5, P13
   Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 20), V0, PP1433, DOI 10.1145/3368089.3417058
   Xu Frank F, 2022, ARXIV, V0, P0
   Yang Y, 2021, IEEE T SOFTWARE ENG, V0, P0
   Yin PC, 2018, IEEE WORK CONF MIN S, V0, PP476, DOI 10.1145/3196398.3196408
   Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3911
NR 32
TC 0
Z9 0
U1 0
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD FEB 23
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1230
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA C8JS1
UT WOS:000964321900001
PM 37346615
DA 2023-11-10
ER

PT J
AU Yu, ZT
   Zhao, J
   Guo, CL
   Yang, Y
AF Yu, Zhengtao
   Zhao, Jia
   Guo, Chenliang
   Yang, Ying
TI StableNet: Distinguishing the hard samples to overcome language priors in visual question answering
SO IET COMPUTER VISION
LA English
DT Article; Early Access
DE computer vision; multimedia systems
AB With the booming fields of computer vision and natural language processing, cross-modal intersections such as visual question answering (VQA) have become very popular. However, several studies have shown that many VQA models suffer from severe language prior problems. After a series of experiments, the authors found that previous VQA models are in an unstable state, that is, when training is repeated several times on the same dataset, there are significant differences between the distributions of the predicted answers given by the models each time, and these models also perform unsatisfactorily in terms of accuracy. The reason for model instability is that some of the difficult samples bring serious interference to model training, so we design a method to measure model stability quantitatively and further propose a method that can alleviate both model imbalance and instability phenomena. Precisely, the question types are classified into simple and difficult ones different weighting measures are applied. By imposing constraints on the training process for both types of questions, the stability and accuracy of the model improve. Experimental results demonstrate the effectiveness of our method, which achieves 63.11% on VQA-CP v2 and 75.49% with the addition of the pre-trained model. The authors found that some more complex questions cause instability in the visual question answering model. For this reason, metrics are designed to measure the questions' complexity and the model's stability, and incorporated the weights into the loss function. A large number of experiments demonstrated the superiority of our method.image
C1 [Yu, Zhengtao; Zhao, Jia; Guo, Chenliang; Yang, Ying] Fuyang Normal Univ, Sch Comp & Informat Engn, Fuyang, Anhui, Peoples R China.
C3 Fuyang Normal University
RP Zhao, J (通讯作者)，Fuyang Normal Univ, Sch Comp & Informat Engn, Fuyang, Anhui, Peoples R China.
EM zhaojia11b@mails.ucas.ac.cn
FU This work is supported in part by the National Natural Science Foundation of China under Grant 61906044, in part by the China Postdoctoral Science Foundation under Grant 2020M681984, and in part by the key projects of natural science research in Anhui coll [61906044]; National Natural Science Foundation of China [2020M681984]; China Postdoctoral Science Foundation [2023AH050406, 2023AH050418, KJ2020ZD48, gxgwfx2021034]; key projects of natural science research in Anhui colleges and universities
CR Agrawal A, 2016, EMNLP, V0, P1955
   Agrawal A, 2018, PROC CVPR IEEE, V0, PP4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Bao H, 2021, 2021 NEURAL INFORM P, V0, P0
   Cadene Remi, 2019, ADV NEUR IN, V0, P841
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Clark C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4069
   Gokhale T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P878
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Grzyb J, 2021, J COMPUT SCI-NETH, V51, P0, DOI 10.1016/j.jocs.2021.101314
   Guo YY, 2022, IEEE T IMAGE PROCESS, V31, P227, DOI 10.1109/TIP.2021.3128322
   Han YD, 2022, ARXIV, V0, P0
   Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Li LJ, 2019, IEEE I CONF COMP VIS, V0, PP10312, DOI 10.1109/ICCV.2019.01041
   Liang ZJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3285
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Liu YB, 2022, ACM T MULTIM COMPUT, V18, P0, DOI 10.1145/3498340
   Long Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10797, DOI 10.1109/CVPR42600.2020.01081
   Luo Z, 2023, ARXIV, V0, P0
   Niu Y, 2021, ADV NEURAL INFORM PR, V0, P0
   Niu YL, 2021, PROC CVPR IEEE, V0, PP12695, DOI 10.1109/CVPR46437.2021.01251
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Selvaraju RR, 2019, IEEE I CONF COMP VIS, V0, PP2591, DOI 10.1109/ICCV.2019.00268
   Shu XY, 2023, ARXIV, V0, P0
   Si Q, 2022, C EMP METH NAT LANG, V0, P0
   Si QY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4101
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Tan HH, 2019, C EMP METH NAT LANG, V0, P0
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Techapanurak Engkarat, 2021, COMPUTER VISION - ACCV 2020. 15TH ASIAN CONFERENCE ON COMPUTER VISION. REVISED SELECTED PAPERS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12625), V0, PP53, DOI 10.1007/978-3-030-69538-5_4
   Vaishnav M, 2022, NEURAL COMPUT, V34, P1075, DOI 10.1162/neco_a_01485
   Wu Y, 2022, INT C COMP LING, V0, P5721
   Xue H, 2021, ADV NEURAL INFORM PR, V34, P4514
   Yang ZY, 2021, ARXIV, V0, P0
   Zhang P, 2016, PROC CVPR IEEE, V0, PP5014, DOI 10.1109/CVPR.2016.542
   Zhao J, 2022, NEURAL COMPUT APPL, V34, P9015, DOI 10.1007/s00521-022-06923-0
   Zhu X, 2021, P 20 9 INT JOINT C A, V0, P0
NR 40
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9632
EI 1751-9640
J9 IET COMPUT VIS
JI IET Comput. Vis.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1049/cvi2.12249
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA U9YV2
UT WOS:001088300100001
DA 2023-11-10
ER

PT J
AU Zhao, QH
   Lei, YX
   Wang, Q
   Kang, ZF
   Liu, JF
AF Zhao, Qinghua
   Lei, Yuxuan
   Wang, Qiang
   Kang, Zhongfeng
   Liu, Junfeng
TI Enhancing text representations separately with entity descriptions
SO NEUROCOMPUTING
LA English
DT Article
DE Knowledge enhancement; Entity; Entity description
AB Several studies have focused on incorporating language models with entity descriptions to facilitate the model with a better understanding of knowledge. Existing methods usually either integrate descriptions in the pre-training stage by designing description-related tasks, or in the fine-tuning stage by directly appending description strings to the original input, this paper falls into the latter group. We separate entity descriptions from the original text and process them by another lighter module. Specifically, we use the original large model to encode the original input, while the lighter module processes the entity descriptions. We also propose a layer-wise fusion strategy to deeply couple the representations of the input and descriptions. To further improve the fusion of the two representations, we explore two auxil-iary tasks: the entity-description enhancement task and the entity contrastive task. Experiments on (Open Entity, FIGER, FewRel, TACRED, SST) datasets yield respective improvements of (0.9, 1.4, 0.6, 0.5, 0.3). Utilizing ChatGPT as the description embedding method holds the potential for even more promis-ing results. & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Zhao, Qinghua; Liu, Junfeng] Beihang Univ, SKLSDE Lab, 37 Xueyuan Rd, Beijing, Peoples R China.
   [Lei, Yuxuan] Univ Sci & Technol China, Hefei, Peoples R China.
   [Wang, Qiang] Tencent, Beijing, Peoples R China.
   [Kang, Zhongfeng] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Peoples R China.
   [Zhao, Qinghua] Univ Copenhagen, Dept Comp Sci, Copenhagen, Denmark.
C3 Beihang University; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Tencent; Lanzhou University; University of Copenhagen
RP Liu, JF (通讯作者)，Beihang Univ, SKLSDE Lab, 37 Xueyuan Rd, Beijing, Peoples R China.
EM liujunfeng@buaa.edu.cn
FU National Natural Science Foundation of China (NSFC) [61925203]
CR Arora S, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P1733
   Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   Borgeaud S, 2022, INT C MACHINE LEARNI, V162, P2206
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Brümmer M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3339
   Choi E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P87
   Chuang YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P4207
   Cui XD, 2023, APPL SCI-BASEL, V13, P0, DOI 10.3390/app13074458
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fan M, 2017, PATTERN RECOGN LETT, V93, P31, DOI 10.1016/j.patrec.2016.09.005
   Ferragina Paolo, 2010, P 19 ACM INT C INF K, V0, PP1625, DOI 10.1145/1871437.1871689
   Han X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4803
   Idelbayev Y, 2021, IEEE IMAGE PROC, V0, PP2843, DOI 10.1109/ICIP42928.2021.9506665
   Jiang JC, 2021, NEUROCOMPUTING, V440, P12, DOI 10.1016/j.neucom.2021.01.103
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Liang B, 2022, KNOWL-BASED SYST, V235, P0, DOI 10.1016/j.knosys.2021.107643
   Lietard B, 2021, P 4 BLACKBOXNLP WORK, V0, PP510, DOI 10.18653/v1/2021.blackboxnlp
   Lin CH, 2022, NEUROCOMPUTING, V487, P9, DOI 10.1016/j.neucom.2022.02.009
   Lin Y, 2021, KNOWL-BASED SYST, V233, P0, DOI 10.1016/j.knosys.2021.107484
   Ling X, 2015, T ASS COMPUT LING, V3, P315, DOI 10.1162/TACL_A_-00141
   Liu B, 2023, KNOWL-BASED SYST, V264, P0, DOI 10.1016/j.knosys.2023.110339
   Liu Y, 2021, P 4 WORKSHOP FACT EX, V0, PP50, DOI 10.18653/v1/2021.fever-1.6
   Liu YH, 2019, ARXIV, V0, P0
   Micikevicius Paulius, 2018, ICLR, V0, P0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P43
   Pu X, 2023, KNOWL-BASED SYST, V263, P0, DOI 10.1016/j.knosys.2023.110282
   Sanh V, 2020, ARXIV, V0, P0
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Tang X, 2019, INFORM PROCESS MANAG, V56, P809, DOI 10.1016/j.ipm.2019.01.005
   Vaswani A, 2017, ARXIV, V30, P5998
   von Rueden L, 2023, IEEE T KNOWL DATA EN, V35, P614, DOI 10.1109/TKDE.2021.3079836
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wang A, 1900, P353, V0, P0, DOI DOI 10.18653/V1/W18-5446
   Wang Ruize, 2021, FINDINGS ASS COMPUTA, V0, P1405
   Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360
   Xiong W, 2019, INT C LEARNING REPRE, V0, P0
   Xu RC, 2021, ARXIV, V0, P0
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
   Yang J, 2021, ADV NEURAL INFORM PR, V34, P28798
   Yu CL, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P1175
   Yu WH, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3512467
   Zhang Y, 2017, P 2017 C EMPIRICAL M, V0, P35
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
   Zhao Q, 2022, P 2 C AS PAC CHAPT A, V1, P766
NR 46
TC 0
Z9 0
U1 20
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 1
PY 2023
VL 552
IS 
BP 
EP 
DI 10.1016/j.neucom.2023.126511
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA P0VB2
UT WOS:001047891600001
DA 2023-11-10
ER

PT J
AU Wang, X
   Zhao, Y
   Zeng, GP
   Xiao, P
   Wang, ZL
AF Wang, Xi
   Zhao, Yu
   Zeng, Guangping
   Xiao, Peng
   Wang, Zhiliang
TI Study on the classification problem of the coping stances in the Satir model based on machine learning
SO JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE The coping stances; the ICTCLAS; Satir model; psychological counselling database
AB This paper applies machine learning technology to the Satir theory model and intelligently classifies the communication stances of the second layer according to the language and behaviour information of the first layer. We arranged a large number of dialogical language materials from a TV interview programme and used the ICTCLAS Chinese word segmentation system to create a 'psychological consultation database'. We construct the word training set by part of making use of speech filtering and text word vectorisation, and construct the semantic training set by annotating the original data with the Satir model. These two sets form the Satir communication posture classification training set. Experimental results show that the success rate of classification of four inconsistent coping stances reached 70.37%, 75.92%, 83.33%, and 77.78%.
C1 [Wang, Xi; Zhao, Yu; Zeng, Guangping; Xiao, Peng; Wang, Zhiliang] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Wang, ZL (通讯作者)，Univ Sci & Technol Beijing, Sch Comp & Commun Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
EM wzl@ustb.edu.cn
CR Abdollahi R, 2014, J ELECTR ENG-SLOVAK, V65, P228, DOI 10.2478/jee-2014-0035
   Asano M, 2015, FOUND PHYS, V45, P1362, DOI 10.1007/s10701-015-9929-y
   Endres-Niggemeyer B, 2013, INFORM-WISS PRAX, V64, P311, DOI 10.1515/iwp-2013-0047
   Fitter MJ, 1982, BEHAVIOUR AND INFORMATION TECHNOLOGY, V1, P81, DOI 10.1080/01449298208914438
   Ismail Issham, 2010, INTERNATIONAL JOURNAL OF INTERACTIVE MOBILE TECHNOLOGIES, V4, P31, DOI 10.3991/ijim.v4i4.1408
   Rajan K, 2015, ANNU REV MATER RES, V45, P153, DOI 10.1146/annurev-matsci-070214-021132
   Riva G, 2007, STUD HEALTH TECHNOL, V125, P394
   Satir V, 1991, SATIR MODEL FAMILY T, V0, P0
   Schiaffonati V, 2003, MIND MACH, V13, P537, DOI 10.1023/A:1026252817929
   Tai K, 2009, J NEUROENG REHABIL, V6, P0, DOI 10.1186/1743-0003-6-39
   Wang ZL, 2006, ARTIFICAL PSYCHOL, V0, P0
   Wang ZL, 2006, CAAI T INTELLIGENT S, V1, P38, DOI https://doi.org/10.3969/j.issn.1673-4785.2006.01.006
   Yanco HA, 2015, J FIELD ROBOT, V32, P420, DOI 10.1002/rob.21568
NR 13
TC 0
Z9 0
U1 1
U2 10
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0952-813X
EI 1362-3079
J9 J EXP THEOR ARTIF IN
JI J. Exp. Theor. Artif. Intell.
PD JAN 2
PY 2023
VL 35
IS 1
BP 129
EP 149
DI 10.1080/0952813X.2021.1960628
EA FEB 2022
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 7C9YG
UT WOS:000754507700001
DA 2023-11-10
ER

PT J
AU Lalrempuii, C
   Soni, B
AF Lalrempuii, Candy
   Soni, Badal
TI Investigating Unsupervised Neural Machine Translation for Low-resource Language Pair English-Mizo via Lexically Enhanced Pre-trained Language Models
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Unsupervised neuralmachine translation; cross-lingualword embeddings; low resource languages; Mizo
AB The vast majority of languages in the world at present are considered to be low-resource languages. Since the availability of large parallel data is crucial for the success of most modern machine translation approaches, improving machine translation for low-resource languages is a key challenge. Most unsupervised techniques for translation benefit closely related languages with monolingual data of substantial quantity. To facilitate research in this direction for the extremely low resource language pair English (en) and Mizo (lus), we have developed a parallel and monolingual corpus for the Mizo language from various news websites. We explore Unsupervised NeuralMachine Translation ( UNMT) based on the developed monolingual data. We observe that cross-lingual embedding (CLWE) initializations on subword segmented data during pre-training, based on both masked language modelling and sequence-to-sequence generation tasks, improve translation performance. We experiment with cross-lingual alignment and combined alignment and joint training for learning the cross-lingual embedding representations. We also report baseline performances and the impact of CLWE initialization using semi-supervised and supervised neural machine translation. Empirical results show that both CLWE initializations work well for the distant pair English-Mizo compared to the baselines.
C1 [Lalrempuii, Candy; Soni, Badal] Natl Inst Technol, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Silchar
RP Lalrempuii, C (通讯作者)，Natl Inst Technol, Silchar 788010, Assam, India.
EM candy_rs@cse.nits.ac.in; badal@cse.nits.ac.in
CR Ahmadnia B, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP1209, DOI 10.1109/ICMLA.2018.00196
   Ahmadnia Benyamin, 2017, P INT C RECENT ADV N, V0, PP24, DOI 10.26615/978-954-452-049-6_004
   Artetxe M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P194
   Artetxe M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P789
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Artetxe Mikel, 2018, P 6 INT C LEARNING R, V0, P0, DOI DOI 10.18653/V1/D18-1399
   Artetxe Mikel, 2020, P 58 ANN M ASS COMP, V0, P7375
   Banerjee Tamali, 2021, P MACHINE TRANSLATIO, V0, P23
   Bentham J, 2016, MEX INT CONF ARTIF I, V0, PP8, DOI 10.1109/MICAI-2016.2016.00010
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Chronopoulou A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P173
   Conneau Alexis, 2018, P INT C LEARNING REP, V0, P0
   Dai AM, 2015, ADV NEUR IN, V28, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Faruqui Manaal, 2014, P EACL, V0, P0, DOI DOI 10.3115/v1/E14-1049
   Firat O, 2016, P 2016 C N AM CHAPT, V0, P866
   Gulcehre C, 2015, ARXIV, V0, P0
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6098
   Hoshen Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P469
   Jawanpuria P, 2019, T ASSOC COMPUT LING, V7, P107, DOI 10.1162/tacl_a_00257
   Joulin A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2979
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Khatri J, 2021, MACH TRANSL, V35, P711, DOI 10.1007/s10590-021-09292-y
   Khenglawt Vanlalmuansangi, 2022, P WILDRE 6WORKSHOP 1, V0, P48
   Knight Kevin, 2016, ABS160402201 CORR, V0, P0
   Koehn P, 2017, WMT, V0, P28
   Lalrempuii Candy, 2023, IEEE DATAPORT, V0, P0, DOI DOI 10.21227/4KX5-WC43
   Lalrempuii C, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3445974
   Lalrempuii Candy, 2020, MACHINE LEARNING IMA, V0, P193
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Luong M-T, 2015, P 2015 C EMP METH NA, V0, P0, DOI DOI 10.18653/V1/D15-1166
   Luong Thang, 2015, P 1 WORKSHOP VECTOR, V0, PP151, DOI 10.3115/V1/W15-1521
   Majumder G, 2018, LECT NOTES COMPUT SC, V9623, P623, DOI 10.1007/978-3-319-75477-2_45
   Marchisio Kelly, 2020, P 5 C MACHINE TRANSL, V0, P571
   Melamed IDan, 1995, P 3 WORKSH VER LARG, V0, P0
   More Rohit, 2015, P 12 INT C NATURAL L, V0, P303
   Pakray P, 2015, 2015 FOURTEENTH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI), V0, PP3, DOI 10.1109/MICAI.2015.7
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pathak A, 2019, NEURAL COMPUT APPL, V31, P7615, DOI 10.1007/s00521-018-3601-3
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, V0, PP392, DOI 10.1080/1472586x.2015.1113070.
   Post Matt, 2018, P 3 C MACH TRANSL RE, V0, PP186, DOI 10.18653/v1/W18-6319
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Siddhant A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2827
   Song KT, 2019, PR MACH LEARN RES, V97, P0
   Sun HP, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3418059
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vincent Pascal, 2008, P 25 INT C MACH LEAR, V0, P1096
   Xing Chao, 2015, PROC 2015 C N AM CHA, V0, PP1006, DOI 10.3115/V1/N15-1104
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Zhang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1959, DOI 10.18653/v1/P17-1179
   ZiruiWang Jiateng Xie, 2020, P 8 INT C LEARNING R, V0, P0
NR 55
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG 15
PY 2023
VL 22
IS 8
BP 
EP 
DI 10.1145/3609222
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q7NS7
UT WOS:001059361200007
DA 2023-11-10
ER

PT J
AU Liu, JX
   Hu, TX
   Zhang, Y
   Feng, Y
   Hao, J
   Lv, JH
   Liu, ZZ
AF Liu, Jiaxiang
   Hu, Tianxiang
   Zhang, Yan
   Feng, Yang
   Hao, Jin
   Lv, Junhui
   Liu, Zuozhu
TI Parameter-Efficient Transfer Learning for Medical Visual Question Answering
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
LA English
DT Article; Early Access
DE Visualization; Task analysis; Adaptation models; Training; Computational modeling; Feature extraction; Transfer learning; Parameter-Efficient transfer learning; Adapter; CLIP; multi-stage label smoothing; medical visual question answering
ID model
AB The Contrastive Language-Image Pre-Training (CLIP) model, pretrained on large visual text corpora, has demonstrated significant improvements in visual and linguistic tasks and has been applied to various downstream tasks. At least two issues, however, hinder the transfer learning with such powerful pretrained models in the field of medical visual question answering (Med-VQA). That current methods tend to full fine-tune these large-scale models are suffering from increasingly expensive computational cost as the model size grows in development. Additionally, published Med-VQA datasets are small that may lead to overfitting when directly fine-tuning on them. In this article, we integrate two designs and propose an efficient transfer learning method for Med-VQA named VQA-Adapter. To alleviate training costs, we introduce a novel and parameter-efficient adapter component into Med-VQA. During training, only the proposed light-weight adapter needs to be tuned, while all parameters in the large-scale visual model of CLIP could be kept frozen. We further design a multi-stage label smoothing paradigm for Med-VQA to deal with the overfitting issue in small Med-VQA datasets. Experimental results on two popular Med-VQA datasets, i.e., VQA-RAD and SLAKE, demonstrate that our method can significantly outperform existing state-of-the-art methods on both open-ended and closed-ended question answering tasks. Furthermore, compared to directly fine-tuning the entire CLIP model, our approach only requires to update 2.38% of the parameters. Extensive ablation studies, analysis and visualizations convincingly demonstrate the great potential of designing light-weight frameworks to transfer large-scale pretrained models from natural vision-language tasks to domain-specific medical applications.
C1 [Liu, Jiaxiang; Liu, Zuozhu] Zhejiang Univ, Engn Res Ctr Oral Biomat & Devices Zhejiang Prov, Zhejiang Prov Clin Res Ctr Oral Dis, Stomatol Hosp,Sch Stomatol,Sch Med,Key Lab Oral Bi, Hangzhou 310000, Peoples R China.
   [Liu, Jiaxiang; Hu, Tianxiang; Liu, Zuozhu] Zhejiang Univ, Univ Illinois Urbana Champaign Inst, Haining 314400, Zhejiang, Peoples R China.
   [Zhang, Yan] Natl Univ Singapore, Singapore 117583, Singapore.
   [Feng, Yang] Angelalign Technol inc, Shanghai 200135, Peoples R China.
   [Hao, Jin] ChohoTech Inc, Hangzhou 310011, Peoples R China.
   [Lv, Junhui] Zhejiang Univ, Sir Run Run Shaw Hosp, Coll Med, Hangzhou 310016, Peoples R China.
C3 Zhejiang University; Zhejiang University; National University of Singapore; Zhejiang University
RP Liu, ZZ (通讯作者)，Zhejiang Univ, Engn Res Ctr Oral Biomat & Devices Zhejiang Prov, Zhejiang Prov Clin Res Ctr Oral Dis, Stomatol Hosp,Sch Stomatol,Sch Med,Key Lab Oral Bi, Hangzhou 310000, Peoples R China.; Lv, JH (通讯作者)，Zhejiang Univ, Sir Run Run Shaw Hosp, Coll Med, Hangzhou 310016, Peoples R China.
EM jiaxiang.21@intl.zju.edu.cn; tianxianghu@intl.zju.edu.cn; eleyanz@nus.edu.sg; fengyang@angelalign.com; jin_hao@g.harvard.edu; 3415030@zju.edu.cn; zuozhuliu@intl.zju.edu.cn
FU National Natural Science Foundation of China [62106222]; Natural Science Foundation of Zhejiang Province, China [LZ23F020008]; Zhejiang University-Angelalign Inc. Ramp;D Center for Intelligent Healthcare
CR Abacha AB, 2018, CLEF WORKING NOTES, V0, P0
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Banerjee P, 2021, P FINDINGS ASS COMPU, V0, P3420
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Changpinyo S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P1947
   Chefer H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP387, DOI 10.1109/ICCV48922.2021.00045
   Chen Zhihong, 2022, MM 22: PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP5152, DOI 10.1145/3503161.3547948
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Do T, 2021, LECT NOTES COMPUT SC, V12905, P64, DOI 10.1007/978-3-030-87240-3_7
   Dosovitskiy A, 2020, ARXIV, V0, P1
   Eslami S, 2021, ARXIV, V0, P0
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Fukui Akira, 2016, ARXIV160601847, V0, PP457, DOI 10.18653/V1/D16-1044
   Gao P, 2021, ARXIV, V0, P0, DOI DOI 10.1007/S11263-023-01891-X
   Gong HF, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR 21), V0, PP456, DOI 10.1145/3460426.3463584
   Guo DM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4884
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Hu EJ, 2022, P INT C LEARN REPR, V0, P0
   Jia C, 2021, SCALING VISUAL VISIO, V0, P4904
   Karimi Mahabadi R, 2021, ADV NEURAL INFORM PR, V0, P1022
   Khare Y, 2021, I S BIOMED IMAGING, V0, PP1033, DOI 10.1109/ISBI48211.2021.9434063
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Lau JJ, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2018.251
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3045
   Li J, 2022, INT C MACHINE LEARNI, V0, P12888
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Liu B, 2021, LECT NOTES COMPUT SC, V12902, P210, DOI 10.1007/978-3-030-87196-3_20
   Liu B, 2021, I S BIOMED IMAGING, V0, PP1650, DOI 10.1109/ISBI48211.2021.9434010
   Liu F, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1175, DOI 10.1145/3343031.3350993
   Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028
   Mahabadi RK, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P565
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Müller R, 2019, ADV NEUR IN, V32, P0
   Nguyen BD, 2019, LECT NOTES COMPUT SC, V11767, P522, DOI 10.1007/978-3-030-32251-9_57
   Pantazis O, 2022, P BRIT MACH VIS C, V0, P01
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pereyra Gabriel, 2017, REGULARIZING NEURAL, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2021, P INT C MACH LEARN I, V0, PP8748, DOI 10.48550/ARXIV.2103.00020
   Ramesh A, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2204.06125
   Rebuffi SA, 2017, ADV NEUR IN, V30, P0
   Rebuffi SA, 2018, PROC CVPR IEEE, V0, PP8119, DOI 10.1109/CVPR.2018.00847
   Ren FJ, 2020, IEEE ACCESS, V8, P50626, DOI 10.1109/ACCESS.2020.2980024
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shen S, 2022, P INT C LEARN REPR, V0, P0
   Shi L, 2019, CLEF, V0, P0
   Song HY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6088
   Sung YL, 2022, PROC CVPR IEEE, V0, PP5217, DOI 10.1109/CVPR52688.2022.00516
   Tiong AMH, 2022, P FINDINGS ASS COMPU, V0, P951
   Wang ZQ, 2022, PROC CVPR IEEE, V0, PP11676, DOI 10.1109/CVPR52688.2022.01139
   Wang ZC, 2022, ARXIV, V0, P0
   Xie LX, 2016, PROC CVPR IEEE, V0, PP4753, DOI 10.1109/CVPR.2016.514
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yu Z, 2017, IEEE I CONF COMP VIS, V0, PP1839, DOI 10.1109/ICCV.2017.202
   Zhan LM, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP2345, DOI 10.1145/3394171.3413761
   Zhang R, 2022, P IEEECVF C COMPUTER, V0, P8552
NR 59
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2471-285X
EI 
J9 IEEE TETCI
JI IEEE Trans. Emerg. Top. Comput. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1109/TETCI.2023.3311333
EA SEP 2023
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA S6BM2
UT WOS:001071996400001
DA 2023-11-10
ER

PT J
AU Kaur, K
   Kaur, P
AF Kaur, Kamaljit
   Kaur, Parminder
TI MNoR-BERT: multi-label classification of non-functional requirements using BERT
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Requirements engineering; Non-functional requirements; Transfer learning; BERT
AB In the era of Internet access, software is easily available on digital distribution platforms such as app stores. The distribution of software on these platforms makes user feedback more accessible and can be used from requirements engineering to software maintenance context. However, such user reviews might contain technical information about the app that can be valuable for developers and software companies. Due to pervasive use of mobile apps, a large amount of data is created by users on daily basis. Manual identification and classification of such reviews are time-consuming and laborious tasks. Hence, automating this process is essential for assisting developers in managing these reviews efficiently. Prior studies have focused on classification of these reviews into bug reports, user experience, and feature requests. Nevertheless to date, a very few research papers have extracted Non-Functional Requirements (NFRs) present in these reviews. NFRs are considered as the set of quality attributes such as reliability, performance, security and usability of the software. Previous studies have utilized machine learning techniques to classify these reviews into their respective classes. However, it was observed that existing studies treat review classification problems as single-label classification problem, and also underestimate the contextual relationship between the words of review statements. To alleviate this limitation, the proposed research work used a transfer learning model to classify multi-label app reviews into four NFRs: Dependability, Performance, Supportability, and Usability. The proposed approach evaluates the performance of the pre-trained language model for multi-label review classification. In this paper, a set of experiments are conducted to compare the performance of the proposed model against the baseline machine learning with binary relevance and keyword based approach. We evaluated our approach over a dataset of 6000 user reviews of 24 iOS apps. Experimental results show that the proposed model outperforms state-of-the-art baseline techniques with respect to precision, recall, and F1-measure.
C1 [Kaur, Kamaljit; Kaur, Parminder] Guru Nanak Dev Univ, Dept Comp Sci, Amritsar, India.
C3 Guru Nanak Dev University
RP Kaur, K (通讯作者)，Guru Nanak Dev Univ, Dept Comp Sci, Amritsar, India.
EM Kamaljitcs.rsh@gndu.ac.in; Parminder.dcse@gndu.ac.in
CR Achimugu P, 2014, INFORM SOFTWARE TECH, V56, P568, DOI 10.1016/j.infsof.2014.02.001
   Adami D, 2013, IEEE ICC, V0, P0
   Araujo A, 2020, AN 17 ENC NAC INT AR, V0, P378
   Aslam N, 2020, IEEE ACCESS, V8, P185619, DOI 10.1109/ACCESS.2020.3029634
   Baker C, 2019, P INT COMP SOFTW APP, V0, PP610, DOI 10.1109/COMPSAC.2019.10275
   Benites F, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), V0, PP847, DOI 10.1109/ICDMW.2015.14
   Binkhonain M, 2019, EXPERT SYST APPL, V1, P0, DOI 10.1016/J.ESWAX.2019.100001
   Boehm B, 1996, IEEE SOFTWARE, V13, P25, DOI 10.1109/52.506460
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   CHEN N, 2014, P 36 INT C SOFTW ENG, V0, P767
   Chollet F, 2021, DEEP LEARNING PYTHON, V2nd, P0
   Chung L, 2009, LECT NOTES COMPUT SC, V5600, P363, DOI 10.1007/978-3-642-02463-4_19
   Ciurumelea A, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Clare A, 2001, PRINCIPLES DATA MINI, V0, P42
   Cleland-Huang J, 2007, 15 IEEE INT REQ ENG, V0, P0, DOI DOI 10.1109/RE.2007.45
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   De araujo Adailton F, 2021, SAC 21: PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, V0, PP1321, DOI 10.1145/3412841.3442006
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Di Sorbo A, 2017, PROC IEEE ACM INT C, V0, PP55, DOI 10.1109/ICSE-C.2017.5
   Elisseeff A, 2002, ADV NEUR IN, V14, P681
   Genc-Nayebi N, 2017, J SYST SOFTWARE, V125, P207, DOI 10.1016/j.jss.2016.11.027
   Gibaja E, 2014, WIRES DATA MIN KNOWL, V4, P411, DOI 10.1002/widm.1139
   Gnanasekaran RK, 2021, REFSQ WORKSH, V0, P0
   Groen EC, 2017, INT REQUIR ENG CONF, V0, PP80, DOI 10.1109/RE.2017.73
   Guzman E, 2014, INT REQUIR ENG CONF, V0, PP153, DOI 10.1109/RE.2014.6912257
   Jha N, 2019, EMPIR SOFTW ENG, V24, P3659, DOI 10.1007/s10664-019-09716-7
   Kurtanovic Z, 2018, REQUIR ENG, V23, P357, DOI 10.1007/s00766-018-0293-2
   Kurtanovic Z, 2017, INT REQUIR ENG CONF, V0, PP490, DOI 10.1109/RE.2017.82
   Liu SM, 2015, EXPERT SYST APPL, V42, P1083, DOI 10.1016/j.eswa.2014.08.036
   Lu M, 2017, P 21 INT C EVALUATIO, V0, PP344, DOI 10.1145/3084226.3084241
   Maalej W, 2016, REQUIR ENG, V21, P311, DOI 10.1007/s00766-016-0251-9
   Maalej W, 2015, INT REQUIR ENG CONF, V0, PP116, DOI 10.1109/RE.2015.7320414
   Madjarov G, 2012, PATTERN RECOGN, V45, P3084, DOI 10.1016/j.patcog.2012.03.004
   McIlroy S, 2016, EMPIR SOFTW ENG, V21, P1067, DOI 10.1007/s10664-015-9375-7
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Navarro-Almanza R, 2017, 2017 5TH INTERNATIONAL CONFERENCE IN SOFTWARE ENGINEERING RESEARCH AND INNOVATION (CONISOFT 2017), V0, PP116, DOI 10.1109/CONISOFT.2017.00021
   Palomba F, 2018, J SYST SOFTWARE, V137, P143, DOI 10.1016/j.jss.2017.11.043
   PANICHELLA S, 2015, 2015 IEEE INT C SOFT, V0, P0, DOI DOI 10.1109/ICSM.2015.7332474
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Sechidis K, 2011, LECT NOTES ARTIF INT, V6913, P145, DOI 10.1007/978-3-642-23808-6_10
   Stanik C, 2019, 2019 IEEE 27TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2019), V0, PP220, DOI 10.1109/REW.2019.00046
   Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164
   Vaswani A, 2017, ARXIV, V30, P5998
   Winkler J, 2016, 2016 IEEE 24TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW), V0, PP39, DOI 10.1109/REW.2016.021
   Wu J, 2009, LECT NOTES COMPUT SC, V5821, P276
   Yang H, 2015, P 27 INT C SOFTW ENG, V0, P0, DOI DOI 10.18293/SEKE2015-063
NR 49
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD OCT 15
PY 2023
VL 35
IS 30
BP 22487
EP 22509
DI 10.1007/s00521-023-08833-1
EA AUG 2023
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA T0OW4
UT WOS:001046940800001
DA 2023-11-10
ER

PT J
AU Zietsch, J
   Kulaga, R
   Held, H
   Herrmann, C
   Thiede, S
AF Zietsch, Jakob
   Kulaga, Rafal
   Held, Harald
   Herrmann, Christoph
   Thiede, Sebastian
TI Multi-layer edge resource placement optimization for factories
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article; Early Access
DE Edge computing; Resource placement; IT infrastructure optimization; Application allocation
ID fog; algorithms; deployment; internet; systems; things
AB Introducing distributed computing paradigms to the manufacturing domain increases the difficulty of designing and planning an appropriate IT infrastructure. This paper proposes a model and solution approach addressing the conjoint application and IT resource placement problem in a factory context. Instead of aiming to create an exact model, resource requirements and capabilities are simplified, focusing on usability in the planning and design phase for industrial use cases. Three objective functions are implemented: minimizing overall cost, environmental impact, and the number of devices. The implications of edge and fog computing are considered in a multi-layer model by introducing five resource placement levels ranging from on-device, within the production system, within the production section, within the factory (on-premise), to the cloud (off-premise). The model is implemented using the open-source modeling language Pyomo. The solver SCIP is used to solve the NP-hard integer programming problem. For the evaluation of the optimization implementation a benchmark is created using a sample set of scenarios varying the number of possible placement locations, applications, and the distribution of assigned edge recommendations. The resulting execution times demonstrate the viability of the proposed approach for small (100 applications; 100 locations) and large (1000 applications, 1000 scenarios) instances. A case study for a section of a factory producing electronic components demonstrates the practical application of the proposed approach.
C1 [Zietsch, Jakob; Herrmann, Christoph] Tech Univ Carolo Wilhelmina Braunschweig, Inst Machine Tools & Prod Technol, Chair Sustainable Mfg & Life Cycle Engn, Braunschweig, Germany.
   [Kulaga, Rafal; Held, Harald] Corp Technol, Siemens AG, Munich, Germany.
   [Thiede, Sebastian] Univ Twente, Chair Mfg Syst, Dept Design Prod & Management, Enschede, Netherlands.
C3 Braunschweig University of Technology; Siemens AG; Siemens Germany; University of Twente
RP Zietsch, J (通讯作者)，Tech Univ Carolo Wilhelmina Braunschweig, Inst Machine Tools & Prod Technol, Chair Sustainable Mfg & Life Cycle Engn, Braunschweig, Germany.
EM j.zietsch@tu-braunschweig.de; rafal.kulaga@tum.de; harald.held@siemens.com; c.herrmann@tu-braunschweig.de; s.thiede@utwente.nl
FU Projekt DEAL
CR Aazam M, 2018, IEEE T IND INFORM, V14, P4674, DOI 10.1109/TII.2018.2855198
   Basir R, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19214807
   Beitinger G, 2021, DIGITALIZATION AUTOM, V0, P0
   Brettel M, 2016, PROC CIRP, V41, P105, DOI 10.1016/j.procir.2015.12.047
   Chen BT, 2018, IEEE COMMUN MAG, V56, P103, DOI 10.1109/MCOM.2018.1701231
   Filz Marc-Andre, 2020, PROCEDIA CIRP, V0, PP777, DOI 10.1016/j.procir.2020.04.069
   Ghobaei-Arani M, 2020, J GRID COMPUT, V18, P1, DOI 10.1007/s10723-019-09491-1
   Gleixner A, 2018, TECHNICAL REPORT, V0, P0
   Guo P, 2016, IEEE TRUST BIG, V0, PP2058, DOI 10.1109/TrustCom.2016.0315
   Gupta H, 2017, SOFTWARE PRACT EXPER, V47, P1275, DOI 10.1002/spe.2509
   Hart WE, 2011, MATH PROGRAM COMPUT, V3, P219, DOI 10.1007/s12532-011-0026-8
   Hertel M, 2013, INFORM SYST FRONT, V15, P815, DOI 10.1007/s10796-013-9417-x
   Hischier R, 2015, ADV INTELL SYST COMP, V310, P171, DOI 10.1007/978-3-319-09228-7_10
   Hong CH, 2019, ACM COMPUT SURV, V52, P0, DOI 10.1145/3326066
   Ismail BI, 2015, IEEE CONF OPEN SYST, V0, PP130, DOI 10.1109/ICOS.2015.7377291
   Jiang C, 2021, IEEE SYST J, V15, P2230, DOI 10.1109/JSYST.2020.2986649
   Kumar D, 2022, J GRID COMPUT, V20, P0, DOI 10.1007/s10723-021-09593-9
   Lin CC, 2018, IEEE T IND INFORM, V14, P4603, DOI 10.1109/TII.2018.2827920
   Mao WC, 2022, IEEE INTERNET THINGS, V9, P13179, DOI 10.1109/JIOT.2022.3143872
   Mourtzis D, 2016, PROC CIRP, V55, P290, DOI 10.1016/j.procir.2016.07.038
   Noghabi SA, 2019, GETMOBILE-MOB COMPU, V23, P11, DOI 10.1145/3400713.3400717
   Qi QL, 2019, IEEE ACCESS, V7, P86769, DOI 10.1109/ACCESS.2019.2923610
   Schulte Lukas, 2020, ADVANCES IN HUMAN FACTORS AND SYSTEMS INTERACTION. PROCEEDINGS OF THE AHFE 2020 VIRTUAL CONFERENCE ON HUMAN FACTORS AND SYSTEMS INTERACTION. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1207), V0, PP3, DOI 10.1007/978-3-030-51369-6_1
   Thiede S, 2021, PROCEDIA CIRP, V98, P1, DOI 10.1016/j.procir.2021.02.001
   Trinks S, 2018, IEEE INT CONF BIG DA, V0, PP2930, DOI 10.1109/BigData.2018.8622649
   Vogel-Heuser B, 2015, J SYST SOFTWARE, V110, P54, DOI 10.1016/j.jss.2015.08.026
   Wang SG, 2019, J PARALLEL DISTR COM, V127, P160, DOI 10.1016/j.jpdc.2018.06.008
   Wescott B, 2013, EVERY COMPUTER PERFO, V0, P0
   Xu ZC, 2016, IEEE T PARALL DISTR, V27, P2866, DOI 10.1109/TPDS.2015.2510638
   Yin H, 2017, IEEE T PARALL DISTR, V28, P1031, DOI 10.1109/TPDS.2016.2604803
   Yin SY, 2020, J INTELL MANUF, V31, P2069, DOI 10.1007/s10845-020-01553-6
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Zhang DC, 2019, IEEE INTERNET THINGS, V6, P3873, DOI 10.1109/JIOT.2019.2892940
   Zietsch J, 2020, CIRP J MANUF SCI TEC, V31, P351, DOI 10.1016/j.cirpj.2020.06.010
   Zietsch J, 2019, IEEE INTL CONF IND I, V0, PP733, DOI 10.1109/INDIN41052.2019.8972193
NR 35
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10845-022-02071-3
EA JAN 2023
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
SC Computer Science; Engineering
GA 8H4JU
UT WOS:000921000600001
DA 2023-11-10
ER

PT J
AU Liu, CM
   Yu, JQ
AF Liu, Chuanming
   Yu, Jingqi
TI Uncertainty-aware non-autoregressive neural machine translation
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Bayesian deep learning; Non-autoregressive; Machine translation; Active learning; Monte Carlo dropout
AB Most existing non-autoregressive neural machine translation (NAT) models generally employ the posterior probability to indicate the model confidence during training, which seems to lag behind the novel uncertainty estimations (UEs) methods successfully deployed in other natural language processing (NLP) tasks. Previous research has practically ignored the large-scale exploration of UE methods in the NAT problem. In this paper, we propose a strategy based on Active Learning employed to investigate whether these sophisticated uncertainty -aware methods are more effective in the NAT problem. Besides, we provide an in-depth analysis of the impact of different widely employed UE methods and propose several tailored ones. In the end, we incorporate these exceptional ones into the practical one-pass GLAT model to obtain enhanced performance. Experimental results demonstrate that sophisticated uncertainty-aware UE methods with the two-step training paradigm are potentially superior to represent the model confidence in facilitating token-level decision-making compared to the posterior probability in NAT to a certain extent.
C1 [Liu, Chuanming] Shanghai Jiao Tong Univ, 800, Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Yu, Jingqi] CCB Fintech, 99, Yincheng Rd, Shanghai 200120, Peoples R China.
C3 Shanghai Jiao Tong University
RP Liu, CM (通讯作者)，Shanghai Jiao Tong Univ, 800, Dongchuan Rd, Shanghai 200240, Peoples R China.
EM liuchuanming@outlook.com
CR Bahdanau D, 2016, ARXIV, V0, P0
   Cho KYHY, 2016, ARXIV, V0, P0
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Gal Y, 2017, PR MACH LEARN RES, V70, P0
   Gal Y, 2016, PR MACH LEARN RES, V48, P0
   Ghazvininejad M, 2019, ARXIV PREPRINT ARXIV, V0, P6112
   Gu J, 2018, INT C LEARNING REPRE, V0, P0
   Gu J, 2021, FINDINGS ASS COMPUTA, V0, P120
   Gu JT, 2019, ADV NEUR IN, V32, P0
   Guo JL, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P376
   Guo JL, 2019, AAAI CONF ARTIF INTE, V0, P3723
   Houlsby N, 2011, ARXIV, V0, P0
   Kim Yoon, 2016, ARXIV160607947, V0, P0, DOI DOI 10.18653/V1
   Kochkina E, 2020, ACL, V0, P6964
   Lee J, 2020, 2018 EMNLP, V0, P1173
   Lee J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1173
   Libovicky J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3016
   Liu Y, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1235
   Malinin A, 2021, 9 INT C LEARNING REP, V0, P0
   Ott M, 2019, FAIRSEQ FAST EXTENSI, V0, P0
   Ott M, 2018, PR MACH LEARN RES, V80, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Qian LH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1993
   Ran Q, 2021, AAAI CONF ARTIF INTE, V35, P13727
   Saharia C, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1098
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shelmanov A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1833
   Shu R, 2020, AAAI CONF ARTIF INTE, V34, P8846
   Stahlberg F, 2020, J ARTIF INTELL RES, V69, P343, DOI 10.1613/jair.1.12007
   Stern Mitchell, 2019, PR MACH LEARN RES, V97, P5976
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P791
   Wang YR, 2019, AAAI CONF ARTIF INTE, V0, P5377
   Wei BZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1304
   Wiseman Sam, 2016, P 2016 C EMPIRICAL M, V0, PP1296, DOI 10.18653/V1/D16-1137
   Zhao Y, 2020, FINDINGS ASS COMPUTA, V0, PP1796, DOI 10.18653/v1/2020.findingsemnlp.162
   Zhou Chunting, 2019, ARXIV191102727, V0, P0
   Zhou Yikai, 2020, ACL, V0, P0
NR 40
TC 0
Z9 0
U1 4
U2 12
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR 15
PY 2023
VL 78
IS 
BP 
EP 
DI 10.1016/j.csl.2022.101444
EA SEP 2022
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5D0QX
UT WOS:000864656900001
DA 2023-11-10
ER

PT J
AU Jaimovitch-López, G
   Ferri, C
   Hernández-Orallo, J
   Martínez-Plumed, F
   Ramírez-Quintana, MJ
AF Jaimovitch-Lopez, Gonzalo
   Ferri, Cesar
   Hernandez-Orallo, Jose
   Martinez-Plumed, Fernando
   Ramirez-Quintana, Maria Jose
TI Can language models automate data wrangling?
SO MACHINE LEARNING
LA English
DT Article
DE Data science automation; Data wrangling; Language models; Machine learning pipelines
AB The automation of data science and other data manipulation processes depend on the integration and formatting of 'messy' data. Data wrangling is an umbrella term for these tedious and time-consuming tasks. Tasks such as transforming dates, units or names expressed in different formats have been challenging for machine learning because (1) users expect to solve them with short cues or few examples, and (2) the problems depend heavily on domain knowledge. Interestingly, large language models today (1) can infer from very few examples or even a short clue in natural language, and (2) can integrate vast amounts of domain knowledge. It is then an important research question to analyse whether language models are a promising approach for data wrangling, especially as their capabilities continue growing. In this paper we apply different variants of the language model Generative Pre-trained Transformer (GPT) to five batteries covering a wide range of data wrangling problems. We compare the effect of prompts and few-shot regimes on their results and how they compare with specialised data wrangling systems and other tools. Our major finding is that they appear as a powerful tool for a wide range of data wrangling tasks. We provide some guidelines about how they can be integrated into data processing pipelines, provided the users can take advantage of their flexibility and the diversity of tasks to be addressed. However, reliability is still an important issue to overcome.
C1 [Jaimovitch-Lopez, Gonzalo; Ferri, Cesar; Hernandez-Orallo, Jose; Martinez-Plumed, Fernando; Ramirez-Quintana, Maria Jose] Univ Politecn Valencia, VRAIN, Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Martínez-Plumed, F (通讯作者)，Univ Politecn Valencia, VRAIN, Valencia, Spain.
EM gonjailo@dsic.upv.es; cferri@dsic.upv.es; jorallo@dsic.upv.es; fmartinez@dsic.upv.es; mramirez@dsic.upv.es
FU [ADS2021]
CR [Anonymous], 2005, COMPUT SCI INF SYST, V0, P0, DOI DOI 10.2298/CSIS0501103H
   Ashok P, 2016, DEFENCE SCI J, V66, P113
   Bellmann P, 2020, IEEE ACCESS, V8, P164380, DOI 10.1109/ACCESS.2020.3021596
   Ben-Gal I, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, V0, PP131, DOI 10.1007/0-387-25465-X_7
   Bender Emily M, 2021, FACCT 21: PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, V0, P0
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bhupatiraju S, 2017, ARXIV, V0, P0
   BIG-bench collaboration, 2022, ARXIV, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen YX, 2009, IEEE T PATTERN ANAL, V31, P288, DOI 10.1109/TPAMI.2008.72
   Contreras-Ochando L, 2020, COMM COM INF SC, V1167, P17, DOI 10.1007/978-3-030-43823-4_2
   Contreras-Ochando L, 2020, LECT NOTES ARTIF INT, V11908, P735, DOI 10.1007/978-3-030-46133-1_44
   Cropper A, 2016, LECT NOTES ARTIF INT, V9575, P46, DOI 10.1007/978-3-319-40566-7_4
   Das K, 2008, PROCEEDING 14 ACM SI, V0, P169
   Das K, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P220
   De Bie T, 2022, COMMUN ACM, V65, P76, DOI 10.1145/3495256
   Devlin J, 2018, ARXIV, V1, P4171
   Dua D, 2017, UCI MACHINE LEARNING, V0, P0
   Ellis K, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1638
   Fernando MP, 2021, INT J INTELL SYST, V36, P3217, DOI 10.1002/int.22415
   Ferrari Alberto, 2016, INTRO MICROSOFT POWE, V0, P0
   Furche T, 2016, 19 INT C EXTENDING D, VVolume 16, P473
   Gao T, 2020, ARXIV, V0, P0
   Garcia S, 2016, BIG DATA ANAL, V1, P9, DOI 10.1186/s41044-016-0014-0
   Gulwani S, 2015, COMMUN ACM, V58, P90, DOI 10.1145/2736282
   Gulwani S, 2011, POPL 11: PROCEEDINGS OF THE 38TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, V0, PP317, DOI 10.1145/1926385.1926423
   Ham K, 2013, J MED LIB ASS JMLA, V101, P233, DOI 10.3163/1536-5050.101.3.020
   Hendrycks D, 2021, ICLR, V0, P0
   Hendrycks D, 2021, ARXIV, V0, P0
   Hulsebos M, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1500, DOI 10.1145/3292500.3330993
   Izacard G, 2020, ARXIV, V0, P0
   Jaimovitch-Lopez G, 2021, ECMLPKDD WORKSHOP AU, V0, P0
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P3363
   Lazarevic A, 2005, P 11 ACM SIGKDD INT, V0, PP157, DOI 10.1145/1081870.1081891
   Lu Yao, 2021, ARXIV, V0, P0
   Lu Yiping, 2019, ARXIV, V0, P0
   Nazabal A, 2020, ARXIV, V0, P0
   Noto K, 2012, DATA MIN KNOWL DISC, V25, P109, DOI 10.1007/s10618-011-0234-x
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petrova-Antonova D, 2020, QUALITY INFORM COMMU, V0, P32
   Porwal U, 2017, ARXIV, V0, P0
   Puri Raul, 2019, ARXIV, V0, P0
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raman V, 2001, PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, V0, P381
   Reed S, 2022, ARXIV, V0, P0
   RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581
   Schick Timo, 2020, ARXIV, V0, P0
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shi Y, 2016, AAAI CONF ARTIF INTE, V0, P2030
   Singh R, 2016, ACM SIGPLAN NOTICES, V51, P343, DOI 10.1145/2914770.2837668
   Singh R, 2015, LECT NOTES COMPUT SC, V9206, P398, DOI 10.1007/978-3-319-21690-4_23
   Sleeper R, 2021, TABLEAU DESKTOP POCK, V0, P0
   Smith S, 2022, ARXIV, V0, P0
   Tamkin A, 2021, ARXIV, V0, P0
   Terrizzano Ignacio, 2015, 7 BIENN C INN DAT SY, V0, P0
   Trifacta, 2022, TRIFACTA WRANGLER, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wu B, 2012, INFORM INTEGRATION W, V0, P8
   Xu SL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P422
   Zeng W, 2021, ARXIV, V0, P0
   Zoph B, 2022, ARXIV, V0, P0
NR 62
TC 1
Z9 1
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD JUN 15
PY 2023
VL 112
IS 6
BP 2053
EP 2082
DI 10.1007/s10994-022-06259-9
EA DEC 2022
PG 30
WC Computer Science, Artificial Intelligence
SC Computer Science
GA I6KH7
UT WOS:000911298300001
DA 2023-11-10
ER

PT J
AU Sun, L
   Wang, P
   Wang, LA
   Sun, J
   Okatani, T
AF Sun, Li
   Wang, Ping
   Wang, Liuan
   Sun, Jun
   Okatani, Takayuki
TI Zero-shot temporal event localisation: Label-free, training-free, domain-free
SO IET COMPUTER VISION
LA English
DT Article
DE computer vision; video retrieval
AB Temporal event localisation (TEL) has recently attracted increasing attention due to the rapid development of video platforms. Existing methods are based on either fully/weakly supervised or unsupervised learning, and thus they rely on expensive data annotation and time-consuming training. Moreover, these models, which are trained on specific domain data, limit the model generalisation to data distribution shifts. To cope with these difficulties, the authors propose a zero-shot TEL method that can operate without training data or annotations. Leveraging large-scale vision and language pre-trained models, for example, CLIP, we solve the two key problems: (1) how to find the relevant region where the event is likely to occur; (2) how to determine event duration after we find the relevant region. Query guided optimisation for local frame relevance relying on the query-to-frame relationship is proposed to find the most relevant frame region where the event is most likely to occur. Proposal generation method relying on the frame-to-frame relationship is proposed to determine the event duration. The authors also propose a greedy event sampling strategy to predict multiple durations with high reliability for the given event. The authors' methodology is unique, offering a label-free, training-free, and domain-free approach. It enables the application of TEL purely at the testing stage. The practical results show it achieves competitive performance on the standard Charades-STA and ActivityCaptions datasets.
C1 [Sun, Li; Wang, Ping; Wang, Liuan; Sun, Jun] Fujitsu R&D Ctr, Beijing, Peoples R China.
   [Sun, Li; Okatani, Takayuki] Tohoku Univ, Grad Sch Informat Sci, Sendai, Japan.
   [Okatani, Takayuki] RIKEN, Ctr AIP, Sendai, Japan.
   [Okatani, Takayuki] Tohoku Univ, Grad Sch Informat Sci, Sendai 9808579, Japan.
C3 Fujitsu Ltd; Fujitsu Laboratories Ltd; Tohoku University; RIKEN; Tohoku University
RP Okatani, T (通讯作者)，Tohoku Univ, Grad Sch Informat Sci, Sendai 9808579, Japan.
EM okatani@vision.is.tohoku.ac.jp
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, P0, DOI 10.1109/TPAMI.2015.2487986
   Bansal A, 2018, LECT NOTES COMPUT SC, V11205, P397, DOI 10.1007/978-3-030-01246-5_24
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   Gao JY, 2017, IEEE I CONF COMP VIS, V0, PP5277, DOI 10.1109/ICCV.2017.563
   Hendricks LA, 2017, IEEE I CONF COMP VIS, V0, PP5804, DOI 10.1109/ICCV.2017.618
   Kim D, 2023, IEEE WINT CONF APPL, V0, PP2538, DOI 10.1109/WACV56688.2023.00257
   Krishna R, 2017, IEEE I CONF COMP VIS, V0, PP706, DOI 10.1109/ICCV.2017.83
   Li J, 2022, INT C MACHINE LEARNI, V0, P12888
   Liang C, 2023, IEEE T PATTERN ANAL, V45, P10055, DOI 10.1109/TPAMI.2023.3262578
   Lin ZJ, 2020, AAAI CONF ARTIF INTE, V34, P11539
   Liu DZ, 2022, AAAI CONF ARTIF INTE, V0, P1674
   Liu DZ, 2022, AAAI CONF ARTIF INTE, V0, P1665
   Liu DZ, 2022, AAAI CONF ARTIF INTE, V0, P1683
   Liu DZ, 2021, PROC CVPR IEEE, V0, PP11230, DOI 10.1109/CVPR46437.2021.01108
   Nam Jinwoo, 2021, P IEEECVF INT C COMP, V0, P1470
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Palatucci Mark, 2009, NEURIPS, V0, P1410
   Parikh D, 2011, IEEE I CONF COMP VIS, V0, PP503, DOI 10.1109/ICCV.2011.6126281
   Nguyen P, 2018, PROC CVPR IEEE, V0, PP6752, DOI 10.1109/CVPR.2018.00706
   Portillo-Quintero JA, 2021, LECT NOTES COMPUT SC, V12725, P3, DOI 10.1007/978-3-030-77004-4_1
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1109/ICCV.2017.74
   Shou Zheng, 2017, P IEEE C COMP VIS PA, V0, P5734
   Wang P, 2023, SUSTAINABILITY-BASEL, V15, P0, DOI 10.3390/su15010153
   Xiao SN, 2021, AAAI CONF ARTIF INTE, V35, P2986
   Xu H, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6787
   Xu HJ, 2019, AAAI CONF ARTIF INTE, V0, P9062
   Yuan YT, 2019, AAAI CONF ARTIF INTE, V0, P9159
   Zhang LL, 2020, PROC CVPR IEEE, V0, PP876, DOI 10.1109/CVPR42600.2020.00096
   Zhang SY, 2022, IEEE T PATTERN ANAL, V44, P9073, DOI 10.1109/TPAMI.2021.3120745
   Zhang SY, 2020, AAAI CONF ARTIF INTE, V34, P12870
   Zhang Z, 2020, ADV NEUR IN, V0, P18123
   Zhang Z, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP4098, DOI 10.1145/3394171.3413967
   Zheng M, 2022, P IEEE CVF C COMP VI, V0, P15555
   Zheng MH, 2022, AAAI CONF ARTIF INTE, V0, P3517
NR 35
TC 0
Z9 0
U1 4
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9632
EI 1751-9640
J9 IET COMPUT VIS
JI IET Comput. Vis.
PD AUG 15
PY 2023
VL 17
IS 5
BP 599
EP 613
DI 10.1049/cvi2.12224
EA AUG 2023
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA P7DP5
UT WOS:001040090600001
DA 2023-11-10
ER

PT J
AU Wang, HB
AF Wang, Haibo
TI A novel algorithm for the construction of fast English sentence retrieval model using a combination of ontology and advanced machine learning techniques
SO SOFT COMPUTING
LA English
DT Article
DE Machine learning; English sentences; N-gram model; TF-IDF algorithm; Quick retrieval; Semantic similarity
ID semantic similarity; knowledge
AB These days, exploring information retrieval models is one of the most essential aspects of English sentence retrieval research. These models are driven by diverse retrieval mechanisms that offer varying similarity calculations and directly influence the final result ranking. However, despite decades of work due to technical constraints, deep semantic analysis has been challenging. This gap emphasizes the importance of a precise semantic understanding of information acquisition through learning approaches. Based on the above opening, this paper establishes a fast retrieval model of English sentences based on the statistical language model (SLM). First, the proposed method utilizes SLM to extract significant feature words from the corpus. These feature words are identified by analyzing co-occurrence patterns and frequency distributions within the standard. Second, it employs the N-gram model to calculate the probabilities of word occurrences based on their contextual dependencies. This framework represents feature words and their associated probabilities in a structured manner by capturing the intricate nuances of language semantics. Third, the model integrates ontology to bridge the gap between human language and machine understanding by enabling the mapping natural language expressions to conceptual entities. Finally, the suggested model retrieves English sentences through semantic matching by leveraging the comprehensive semantic framework and ontology-based search. The experimental study revealed that the proposed model demonstrated an impressive retrieval ratio of 98.5% by outperforming existing models in the comparison. Moreover, these results show that the proposed algorithm performs better than the Term Frequency-Inverse Document Frequency (TF-IDF) algorithm, and the accuracy of this algorithm is improved by 7.52% compared with TF-IDF. When the labelled corpus is very small and the unlabeled corpus is relatively large, the algorithm enhances the classifier's performance by 12.6%. This shows that the algorithm used in this paper reduces the influence of the synonym processing stage on the overall performance while retaining the advantages of high precision and accuracy of calculation results.
C1 [Wang, Haibo] Xinyang Vocat & Tech Coll, Xinyang 464000, Henan, Peoples R China.
RP Wang, HB (通讯作者)，Xinyang Vocat & Tech Coll, Xinyang 464000, Henan, Peoples R China.
EM amyzonelove@163.com
CR Adel E, 2022, IEEE ACCESS, V10, P126161, DOI 10.1109/ACCESS.2022.3223676
   Ali M, 2020, CHIN CONTR CONF, V0, PP7406, DOI 10.23919/CCC50068.2020.9188843
   Aslam MS, 2021, IET CONTROL THEORY A, V15, P1461, DOI 10.1049/cth2.12136
   Aslam MS, 2020, IET CONTROL THEORY A, V14, P2429, DOI 10.1049/iet-cta.2018.5469
   Aslam MS, 2020, INT J ROBUST NONLIN, V30, P1622, DOI 10.1002/rnc.4839
   Aslam MS, 2019, NONLINEAR DYNAM, V95, P2923, DOI 10.1007/s11071-018-4732-x
   Atabuzzaman M, 2021, IEEE ACCESS, V9, P62972, DOI 10.1109/ACCESS.2021.3074747
   Bilal H, 2023, SOFT COMPUT, V27, P4987, DOI 10.1007/s00500-023-08026-x
   Bilal H, 2023, SOFT COMPUT, V27, P4029, DOI 10.1007/s00500-023-07923-5
   Bilal H, 2019, CHIN CONTR CONF, V0, PP6772, DOI 10.23919/chicc.2019.8866334
   Bilal H, 2017, CHIN CONTR CONF, V0, PP4192, DOI 10.23919/ChiCC.2017.8028015
   Bova VV, 2017, ADV INTELL SYST, V573, P74, DOI 10.1007/978-3-319-57261-1_8
   Chen GM, 2022, MATH PROBL ENG, V2022, P0, DOI 10.1155/2022/3215337
   Daniali M, 2023, ARTIF INTELL MED, V139, P0, DOI 10.1016/j.artmed.2023.102523
   Hussain MJ, 2023, INFORM SCIENCES, V625, P673, DOI 10.1016/j.ins.2023.01.007
   Kumar A, 2021, APPL INTELL, V51, P1152, DOI 10.1007/s10489-020-01894-y
   Li DM, 2023, SYSTEMS-BASEL, V11, P0, DOI 10.3390/systems11070319
   Li L, 2023, INFORM FUSION, V99, P0, DOI 10.1016/j.inffus.2023.101862
   Li WH, 2023, IEEE T MULTIMEDIA, V25, P543, DOI 10.1109/TMM.2021.3128744
   Lima E, 2019, ACM T INTERNET TECHN, V19, P0, DOI 10.1145/3319528
   Liu X, 2023, SYSTEMS-BASEL, V11, P0, DOI 10.3390/systems11080390
   Liu X, 2023, HUM SOC SCI COMMUN, V10, P0, DOI 10.1057/s41599-023-01816-6
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P1978, DOI 10.1109/TIP.2022.3147032
   Lu SY, 2023, INT J COMPUT INT SYS, V16, P0, DOI 10.1007/s44196-023-00233-6
   Ma Yan, 2022, 2022 5TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND INFORMATION TECHNOLOGY (DSIT), V0, PP01, DOI 10.1109/DSIT55514.2022.9943949
   Ru CS, 2018, INFORM PROCESS MANAG, V54, P593, DOI 10.1016/j.ipm.2018.04.002
   Aslam MS, 2023, ASIAN J CONTROL, V25, P213, DOI 10.1002/asjc.2762
   Wang LY, 2019, PROC SPIE, V11198, P0, DOI 10.1117/12.2540362
   Wang Yan, 2023, IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, V0, PP6144, DOI 10.1109/TCSVT.2023.3254530
   Wulff P, 2022, J SCI EDUC TECHNOL, V31, P490, DOI 10.1007/s10956-022-09969-w
   Xiong Y, 2021, J CHIN HUM RESOUR MA, V12, P16, DOI 10.47297/wspchrmWSP2040-800502.20211202
   Xu H, 2023, SOFT COMPUT, V27, P14469, DOI 10.1007/s00500-023-09037-4
   Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426
   Zhang PY, 2021, IEEE ACCESS, V9, P8433, DOI 10.1109/ACCESS.2021.3049378
   Zhu GG, 2018, EXPERT SYST APPL, V101, P8, DOI 10.1016/j.eswa.2018.02.011
   Zhuang Y, 2022, WIREL COMMUN MOB COM, V2022, P0, DOI 10.1155/2022/6458350
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD DEC 15
PY 2023
VL 27
IS 23
BP 18129
EP 18146
DI 10.1007/s00500-023-09224-3
EA SEP 2023
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA T9PD8
UT WOS:001070379600002
DA 2023-11-10
ER

PT J
AU Balkus, SV
   Yan, DH
AF Balkus, Salvador V.
   Yan, Donghui
TI Improving short text classification with augmented data using GPT-3
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE GPT-3; Data augmentation; Text classification; Machine learning
ID ensemble
AB GPT-3 is a large-scale natural language model developed by OpenAI that can perform many different tasks, including topic classification. Although researchers claim that it requires only a small number of in-context examples to learn a task, in practice GPT-3 requires these training examples to be either of exceptional quality or a higher quantity than easily created by hand. To address this issue, this study teaches GPT-3 to classify whether a question is related to data science by augmenting a small training set with additional examples generated by GPT-3 itself. This study compares two augmented classifiers: the Classification Endpoint with an increased training set size and the Completion Endpoint with an augmented prompt optimized using a genetic algorithm. We find that data augmentation significantly increases the accuracy of both classifiers, and that the embedding-based Classification Endpoint achieves the best accuracy of about 76%, compared to human accuracy of 85%. In this way, giving large language models like GPT-3 the ability to propose their own training examples can improve short text classification performance.
C1 [Balkus, Salvador V.] Univ Massachusetts, Program Data Sci, Dartmouth, MA 20452 USA.
   [Yan, Donghui] Univ Massachusetts, Dept Math, Dartmouth, MA USA.
C3 University of Massachusetts System; University Massachusetts Dartmouth; University of Massachusetts System; University Massachusetts Dartmouth
RP Balkus, SV (通讯作者)，Univ Massachusetts, Program Data Sci, Dartmouth, MA 20452 USA.
EM sbalkus@g.harvard.edu
FU First, we must thank the Program in Data Science at the University of Massachusetts Dartmouth for financially supporting this project. In addition, we would also like to thank members of the University of Massachusetts Dartmouth Big Data Club for contribut; Program in Data Science at the University of Massachusetts Dartmouth
CR Adhikari A, 2019, ARXIV, V0, P0
   Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Brown TB, 2020, ARXIV, V0, P0
   Bajaj P, 2022, ARXIV, V0, P0
   Bischl B, 2023, WIRES DATA MIN KNOWL, V13, P0, DOI 10.1002/widm.1484
   Chen WL, 2022, ARXIV, V0, P0
   Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Devlin J, 2019, ARXIV, V0, P0
   Du J, 2020, N AM CHAPTER ASS COM, V0, P0
   Feng SY, 2021, FINDINGS ASS COMPUTA, V0, PP968, DOI 10.18653/V1/2021.FINDINGS-ACL.84
   Gerz D, 2018, T ASSOC COMPUT LING, V6, P451, DOI 10.1162/TACL_A_00032
   GPT-3, 2020, GUARDIAN, V0, P0
   Guo X, 2022, ARXIV, V0, P0
   Hestness J, 2017, ARXIV, V0, P0
   Jiang Z, 2022, INT C COMP LING, V0, P0
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Kobayashi S, 2018, P 2018 C N AM CHAPTE, V2, P452, DOI 10.18653/v1/N18-2072
   Kowsari K, 2019, INFORMATION, V10, P0, DOI 10.3390/info10040150
   Kumar V, 2020, P 2 WORKSH LIF LONG, V0, P0
   Li Q, 2020, ACM T INTEL SYST TEC, V13, P1
   Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, V0, P100
   Liu RB, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9031
   Liu YH, 2019, ARXIV, V0, P0
   Dai AM, 2015, ARXIV, V0, P0
   Minaee S, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3439726
   Onan A, 2019, IEEE ACCESS, V7, P145614, DOI 10.1109/ACCESS.2019.2945911
   Onan A, 2019, SCI PROGRAMMING-NETH, V2019, P0, DOI 10.1155/2019/5901087
   Onan A, 2018, COMPUT MATH METHOD M, V2018, P0, DOI 10.1155/2018/2497471
   Onan A, 2017, INFORM PROCESS MANAG, V53, P814, DOI 10.1016/j.ipm.2017.02.008
   Onan A, 2017, J INF SCI, V43, P25, DOI 10.1177/0165551515613226
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   OpenAI, 2021, CLASS OPENAI DOC, V0, P0
   OpenAI, 2022, EMB OPENAI DOC, V0, P0
   OpenAI, 2021, COMPL OPENAI DOC, V0, P0
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pilipiszyn A, 2021, GPT 3 POWERS NEXT GE, V0, P0
   Qu YR, 2020, ARXIV, V0, P0
   Quteineh H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7400
   Radford Alec, 2018, OPENAI BLOG, V0, P0
   Raffel C, 2022, J MACH LEARN RES, V21, P5
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Song G, 2014, J MULTIMED, V9, P1
   SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849
   Sun Y, 2021, ARXIV, V0, P0
   Thiergart J, 2021, ARXIV, V0, P0
   Vaswani A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1706.03762
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wen Xian Yang, 2004, INTELLIGENT DATA ANALYSIS, V8, P385
   Yoo KM, 2021, FINDINGS ASS COMPUTA, V0, P0
   Zhang H, 2018, P INT C LEARN REPR, V0, PP1, DOI 10.48550/ARXIV.1710.09412
   Zhao T, 2021, ARXIV, V0, P0
   Zoph B, 2022, 2022 IEEE INT PAR DI, V0, P1044
   Zulqarnain M, 2020, INDONESIAN J ELECT E, V19, P325, DOI 10.11591/IJEECS.V19.I1.PP325-335
NR 56
TC 0
Z9 0
U1 4
U2 4
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324923000438
EA AUG 2023
PG 30
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA T3MO0
UT WOS:001077062200001
DA 2023-11-10
ER

PT J
AU Zhang, ZH
   Yu, WH
   Ning, Z
   Ju, MX
   Jiang, M
AF Zhang, Zhihan
   Yu, Wenhao
   Ning, Zheng
   Ju, Mingxuan
   Jiang, Meng
TI Exploring Contrast Consistency of Open-Domain Question Answering Systems on Minimally Edited Questions
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Contrast consistency, the ability of a model to make consistently correct predictions in the presence of perturbations, is an essential aspect in NLP. While studied in tasks such as sentiment analysis and reading comprehension, it remains unexplored in open-domain question answering (OpenQA) due to the difficulty of collecting perturbed questions that satisfy factuality requirements. In this work, we collect minimally edited questions as challenging contrast sets to evaluate OpenQA models. Our collection approach combines both human annotation and large language model generation. We find that the widely used dense passage retriever (DPR) performs poorly on our contrast sets, despite fitting the training set well and performing competitively on standard test sets. To address this issue, we introduce a simple and effective query-side contrastive loss with the aid of data augmentation to improve DPR training. Our experiments on the contrast sets demonstrate that DPR's contrast consistency is improved without sacrificing its accuracy on the standard test sets.(1)
C1 [Zhang, Zhihan; Yu, Wenhao; Ning, Zheng; Ju, Mingxuan; Jiang, Meng] Univ Notre Dame, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Zhang, ZH (通讯作者)，Univ Notre Dame, Notre Dame, IN 46556 USA.
EM zzhang23@nd.edu; wyu1@nd.edu; zning@nd.edu; mju2@nd.edu; mjiang2@nd.edu
FU NSF [IIS-2119531, IIS-2137396, IIS-2142827, CCF-1901059, ONR N00014-22-1-2507]; Bloomberg Data Science PhD Fellowship
CR Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fajcik Martin, 2021, FINDINGS ASS COMPUTA, V0, PP854, DOI 10.18653/V1/2021.FINDINGS-EMNLP.73
   Gao LY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P981
   Gardner Matt, 2020, FINDINGS ASS COMPUTA, V0, P1307
   Izacard G, 2022, ARXIV, V0, P0
   Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P874
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Kaushik Divyansh, 2020, 8 INT C LEARN REPR I, V0, P0
   Kedia Akhil, 2022, P 2022 C EMP METH NA, V0, P0
   Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP39, DOI 10.1145/3397271.3401075
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lewis P, 2021, T ASSOC COMPUT LING, V9, P1098, DOI 10.1162/tacl_a_00415
   Lewis Patrick, 2020, ADV NEURAL INFORM PR, V33, P9459, DOI 10.48550/ARXIV.2005.11401
   Li D, 2022, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Longpre S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P7052
   Min S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5783
   Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P314
   Ni Jianmo, 2022, P 2022 C EMPIRICAL M, V0, P9844
   Ouyang L, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2203.02155
   Paranjape B, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1670
   Park JS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P3574
   Robertson Stephen, 2009, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V3, P333, DOI 10.1561/1500000019
   Ross A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3194
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Tiedemann Jorg, 2020, P 22 ANN C EUR ASS M, V0, P0
   van den Oord A, 2019, ARXIV, V0, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang X, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2203.11171
   Wenhao Yu, 2023, 11 INT C LEARNING RE, V0, P0
   Wu Tongshuang, 2021, P 59 ANN M ASS COMP, V1, P0, DOI 10.18653/v1/2021.acl long. 523
   Ye X, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5496
   Zhu FB, 2021, ARXIV, V0, P0
NR 35
TC 0
Z9 0
U1 1
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD AUG 15
PY 2023
VL 11
IS 
BP 1082
EP 1096
DI 10.1162/tacl_a_00591
PG 15
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA P3AF0
UT WOS:001049392500008
DA 2023-11-10
ER

PT J
AU Stappen, L
   Baird, A
   Schumann, L
   Schuller, B
AF Stappen, Lukas
   Baird, Alice
   Schumann, Lea
   Schuller, Bjoern
TI The Multimodal Sentiment Analysis in Car Reviews (MuSe-CaR) Dataset: Collection, Insights and Improvements
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Sentiment analysis; Annotations; Task analysis; Databases; Affective computing; Social networking (online); Computational modeling; affective computing; database; mutlimedia retrieval; trustworthiness
ID facial expression recognition; database; trustworthiness; annotation; trust
AB Truly real-life data presents a strong, but exciting challenge for sentiment and emotion research. The high variety of possible 'in-the-wild' properties makes large datasets such as these indispensable with respect to building robust machine learning models. A sufficient quantity of data covering a deep variety in the challenges of each modality to force the exploratory analysis of the interplay of all modalities has not yet been made available in this context. In this contribution, we present MuSe-CaR, a first of its kind multimodal dataset. The data is publicly available as it recently served as the testing bed for the 1st Multimodal Sentiment Analysis Challenge, and focused on the tasks of emotion, emotion-target engagement, and trustworthiness recognition by means of comprehensively integrating the audio-visual and language modalities. Furthermore, we give a thorough overview of the dataset in terms of collection and annotation, including annotation tiers not used in this year's MuSe 2020. In addition, for one of the sub-challenges - predicting the level of trustworthiness - no participant outperformed the baseline model, and so we propose a simple, but highly efficient Multi-Head-Attention network that exceeds using multimodal fusion the baseline by around 0.2 CCC (almost 50 percent improvement).
C1 [Stappen, Lukas; Baird, Alice; Schumann, Lea; Schuller, Bjoern] Univ Augsburg, EIHW Chair Embedded Intelligence Hlth Care & Wellb, D-86159 Augsburg, Germany.
   [Schuller, Bjoern] Imperial Coll, GLAM Grp Language Audio & Mus, London SW7 2BX, England.
C3 University of Augsburg; Imperial College London
RP Stappen, L (通讯作者)，Univ Augsburg, EIHW Chair Embedded Intelligence Hlth Care & Wellb, D-86159 Augsburg, Germany.
EM stappen@ieee.org; alice.baird@informatik.uni-augsburg.de; lea.schumann@student.uni-augsburg.de; schuller@ieee.org
FU DFG [442218748]; European Union Horizon 2020 research and innovation programme [856879]; European Union [115902, 826506]; EPSRC [2021037]; BMW Group
CR Afouras T, 2018, ARXIV, V0, P0
   [Anonymous], 2012, MINING TEXT DATA, V0, P0
   Arevalo J, 2020, NEURAL COMPUT APPL, V32, P10209, DOI 10.1007/s00521-019-04559-1
   Atallah RR, 2018, IEEE ACCESS, V6, P28290, DOI 10.1109/ACCESS.2018.2836924
   Baird A, 2020, FRONT BIG DATA, V3, P0, DOI 10.3389/fdata.2020.00025
   Baltrusaitis T, 2016, IEEE WINT CONF APPL, V0, P0
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P286, DOI 10.1177/0963721411422522
   Bhardwaj B, 2016, INT J COMPUT APPL, V135, P975
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Borth Damian, 2013, ACM MM, V0, P2
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Camacho-Collados J, 2018, P 2018 EMNLP WORKSH, V0, PP40, DOI 10.18653/V1/W18-5406
   Cevher D, 2019, PROC C NAT LANG PROC, V0, P79
   Chen XY, 2017, IEEE IMAGE PROC, V0, PP1557, DOI 10.1109/ICIP.2017.8296543
   Colquitt JA, 2007, J APPL PSYCHOL, V92, P909, DOI 10.1037/0021-9010.92.4.909
   Cox JC, 2016, GAME ECON BEHAV, V98, P197, DOI 10.1016/j.geb.2016.05.008
   De Silva LC, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, V0, P0
   Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007
   Douglas-Cowie E, 2005, 9 EUR C SPEECH COMM, V0, P0
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Fortin MP, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, V0, PP368, DOI 10.5220/0007313503680376
   Garcia A, 2021, ARXIV, V0, P0
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, V0, PP776, DOI 10.1109/ICASSP.2017.7952261
   Girard JM, 2018, BEHAV RES METHODS, V50, P902, DOI 10.3758/s13428-017-0915-5
   Gomez R, 2020, IEEE WINT CONF APPL, V0, PP1459, DOI 10.1109/WACV45572.2020.9093414
   Grimm M, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, P381
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Hamann S, 2012, TRENDS COGN SCI, V16, P458, DOI 10.1016/j.tics.2012.07.006
   Hantke S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2156
   Hasan MK, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2046
   Hershey S, 2017, INT CONF ACOUST SPEE, V0, PP131, DOI 10.1109/ICASSP.2017.7952132
   HORSBURGH HJN, 1961, ETHICS, V72, P28, DOI 10.1086/291373
   Jian Huang, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII). PROCEEDINGS, V0, PP185, DOI 10.1109/ACII.2019.8925452
   Karas V, 2020, NATURAL LANGUAGE PRO, V0, P0
   Kollias D, 2019, PROC BRIT MACH VIS C, V0, P1
   Kollias D, 2020, ARXIV, V0, P0
   Kollias D, 2019, INT J COMPUT VISION, V127, P907, DOI 10.1007/s11263-019-01158-4
   Konyushkova K, 2018, PROC CVPR IEEE, V0, PP9175, DOI 10.1109/CVPR.2018.00956
   Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808
   Kossaifi J, 2017, IMAGE VISION COMPUT, V65, P23, DOI 10.1016/j.imavis.2017.02.001
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Licai Sun, 2020, MUSE20: PROCEEDINGS OF THE 1ST INTERNATIONAL MULTIMODAL SENTIMENT ANALYSIS IN REAL-LIFE MEDIA CHALLENGE AND WORKSHOP, V0, PP27, DOI 10.1145/3423327.3423672
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   Liu ZW, 2015, IEEE I CONF COMP VIS, V0, PP3730, DOI 10.1109/ICCV.2015.425
   Luneski A, 2010, METHOD INFORM MED, V49, P207, DOI 10.3414/ME0617
   Mäntylä MV, 2018, COMPUT SCI REV, V27, P16, DOI 10.1016/j.cosrev.2017.10.002
   Marrese-Taylor E, 2020, ARXIV, V0, P0
   Marrese-Taylor Edison, 2017, P 8 WORKSH COMP APPR, V0, PP102, DOI 10.18653/V1/W17-5213
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mohammad SM, 2016, EMOTION MEASUREMENT, V0, PP201, DOI 10.1016/B978-0-08-100508-8.00009-6
   Morency L-P, 2011, P 13 INT C MULT INT, V0, PP169, DOI 10.1145/2070481.2070509
   Moturu ST, 2011, DISTRIB PARALLEL DAT, V29, P239, DOI 10.1007/s10619-010-7077-0
   Panagakis Y, 2016, IEEE T PATTERN ANAL, V38, P1665, DOI 10.1109/TPAMI.2015.2497700
   Pandit V, 2020, ARXIV, V0, P0
   Park S, 2014, P 16 INT C MULT INT, V0, PP50, DOI 10.1145/2663204.2663260
   Parkhi OM, 2015, P BRIT MACHINE VISIO, V0, P0, DOI DOI 10.5244/C.29.41
   Perez-Rosas V, 2013, ACL, V0, P973
   Preotiuc-Pietro D, 2016, P 7 WORKSH COMP APPR, V0, P9
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Ringeval F, 2017, P 7 ANN WORKSHOP AUD, V0, P3
   Ringeval F, 2013, IEEE INT CONF AUTOMA, V0, P0
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sajjad M, 2018, CLUSTER COMPUT, V21, P549, DOI 10.1007/s10586-017-0935-z
   Schuller B, 2013, INTELLIGENT AUDIO AN, V1, P17
   Schuller BW, 2018, INTERSPEECH, V0, P122
   Schwemmer C, 2018, SOC MEDIA SOC, V4, P0, DOI 10.1177/2056305118786720
   Slucki A, 2018, LECT NOTES COMPUT SC, V11114, P287, DOI 10.1007/978-3-030-00692-1_25
   Sneddon I, 2012, IEEE T AFFECT COMPUT, V3, P32, DOI 10.1109/T-AFFC.2011.26
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Stappen L, 2020, PROC INT MULTIMODAL, V0, P35
   Stappen L, 2020, ARXIV0 200608521, V0, P0
   Stappen L, 2019, IEEE INT WORKSH MULT, V0, P0, DOI DOI 10.1109/mmsp.2019.8901779
   Stappen L, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP4769, DOI 10.1145/3394171.3421901
   Su Hao, 2012, P WORKSH 26 AAAI C A, V0, P0
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Tian SX, 2015, IEEE I CONF COMP VIS, V0, PP4651, DOI 10.1109/ICCV.2015.528
   Trigeorgis G, 2016, PROC CVPR IEEE, V0, PP5110, DOI 10.1109/CVPR.2016.552
   Valstar M, 2013, P 3 ACM INT WORKSH A, V0, PP3, DOI 10.1145/2512530.2512533
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wittenburg Peter, 2006, P LREC 2006 5 INT C, V0, P1556
   Wöllmer M, 2013, IEEE INTELL SYST, V28, P46, DOI 10.1109/MIS.2013.34
   Xiaoyu Qiu, 2020, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1453, P0, DOI 10.1088/1742-6596/1453/1/012092
   Yang H, 2016, P 24 ACM INT C MULT, V0, P698
   Yang H-J, 2020, P 9 INT C SMART MED, V0, P0
   Yu WM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3718
   Zadeh A, 2018, P GRAND CHALL WORKSH, V0, P0
   Zadeh A, 2016, ARXIV, V0, P0
   Zadeh A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, PP1801, DOI 10.18653/v1/2020.emnlp-main.141
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2018, AAAI CONF ARTIF INTE, V0, P5642
   Zadeh Amir, 2017, EMPIRICAL METHODS NA, V0, P0, DOI DOI 10.18653/V1/D17-1115
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P0, DOI 10.1109/TIP.2016.2549360
NR 104
TC 4
Z9 4
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
EI 
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD APR-JUN 15
PY 2023
VL 14
IS 2
BP 1334
EP 1350
DI 10.1109/TAFFC.2021.3097002
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA I1FK2
UT WOS:001000299100036
DA 2023-11-10
ER

PT J
AU Zi, YF
   Xiong, SW
AF Zi, Yunfei
   Xiong, Shengwu
TI BSML: Bidirectional Sampling Aggregation-based Metric Learning for Low-resource Uyghur Few-shot Speaker Verification
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Uyghur; bidirectional sampling; metric learning; few-shot; speaker verification; low-resource language; limited data
ID recognition
AB In recent years, text-independent speaker verification has remained a hot research topic, especially for the limited enrollment and/or test data. At the same time, due to the lack of sufficient training data, the study of low-resource few-shot speaker verification makes the models prone to overfitting and low accuracy of recognition. Therefore, a bidirectional sampling aggregation-based meta-metric learning method is proposed to solve the low-accuracy problem of speaker recognition in a low-resource environment with limited data, termed bidirectional sampling multi-scale Fisher feature fusion (BSML). First, the BSML method was used for effective feature enhancement in the feature extraction stage; second, a large number of similar and disjoint tasks were used to train the models to learn how to compare sample similarity; finally, new tasks were used to identify unknown samples by calculating the similarity of the samples. Extensive experiments are conducted on a short-duration text-independent speaker verification dataset generated from the THUYG-20 low-resource Uyghur with limited data, which comprised speech samples of diverse lengths. The experimental result has shown that the metric learning approach is effective in avoiding model overfitting and improving model generalization, with significant results in the identification of short-duration speaker verification in low-resource Uyghur with few-shot. It also demonstrates that BSML outperforms the state-of-the-art deep-embedding speaker recognition architectures and recent metric learning approach by at least 18%-67% in the few-shot test set. The ablation experiments further illustrate that our proposed approaches can achieve substantial improvement over prior methods and achieves better performance and generalization ability.
C1 [Zi, Yunfei; Xiong, Shengwu] Wuhan Univ Technol, Sch Comp & Artificial Intelligence, 122 Luoshi Rd, Wuhan 430070, Hubei, Peoples R China.
C3 Wuhan University of Technology
RP Xiong, SW (通讯作者)，Wuhan Univ Technol, Sch Comp & Artificial Intelligence, 122 Luoshi Rd, Wuhan 430070, Hubei, Peoples R China.
EM yfzi@whut.edu.cn; xiongsw@whut.edu.cn
FU NSFC [62176194, 62101393]; Major project of IoV [2020AAA001]; Sanya Science and Education Innovation Park of Wuhan University of Technology [2021KF0031]; CSTC [cstc2021jcyj-msxmX1148]; Open Project of Wuhan University of Technology Chongqing Research Institute [ZL2021-6]
CR [艾斯卡尔·肉孜 Aisikaer Rouzi], 2017, 清华大学学报. 自然科学版 JOURNAL OF TSINGHUA UNIVERSITY. SCIENCE AND TECHNOLOGY, V57, P182
   Anand P, 2019, ARXIV, V0, P0
   [Anonymous], 1926, J AM I CRIM LAW CRIM, V0, P0, DOI DOI 10.2307/1134501
   Bromley J, 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Bu H, 2017, 2017 20TH CONFERENCE OF THE ORIENTAL CHAPTER OF THE INTERNATIONAL COORDINATING COMMITTEE ON SPEECH DATABASES AND SPEECH I/O SYSTEMS AND ASSESSMENT (O-COCOSDA), V0, PP58, DOI 10.1109/ICSDA.2017.8384449
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   Chowdhury A, 2020, IEEE T INF FOREN SEC, V15, P1616, DOI 10.1109/TIFS.2019.2941773
   Counter Peter B, 2015, MORPHO AGNITIO PARTN, V0, P0
   Dai YM, 2021, IEEE WINT CONF APPL, V0, PP3559, DOI 10.1109/WACV48630.2021.00360
   Das RK, 2016, J ACOUST SOC AM, V140, P184, DOI 10.1121/1.4954653
   Dehak N, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, V0, P71
   Desplanques B, 2020, INTERSPEECH, V0, PP3830, DOI 10.21437/Interspeech.2020-2650
   Enzinger E, 2016, THESIS U NEW S WALES, V0, P0
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Greenberg CS, 2013, INTERSPEECH, V0, P1970
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Jung Y, 2020, INTERSPEECH, V0, PP1501, DOI 10.21437/Interspeech.2020-1025
   Kanagasundaram A, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2352
   Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940
   Kim Ju-Ho, 2022, ICASSP 2022 - 2022 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7647, DOI 10.1109/ICASSP43922.2022.9747594
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Li LT, 2016, IEEE-ACM T AUDIO SPE, V24, P1129, DOI 10.1109/TASLP.2016.2544660
   Li RR, 2020, INT CONF ACOUST SPEE, V0, PP3522, DOI 10.1109/ICASSP40776.2020.9054111
   Li RR, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM 20), V0, PP340, DOI 10.1145/3336191.3371802
   Li WB, 2019, AAAI CONF ARTIF INTE, V0, P8642
   Liu TC, 2022, INT CONF ACOUST SPEE, V0, PP7517, DOI 10.1109/ICASSP43922.2022.9747021
   Liu ZL, 2018, IEEE T IND INFORM, V14, P3244, DOI 10.1109/TII.2018.2799928
   Marcus G, 2018, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1801.00631
   Mishra Prateek, 2020, ARXIV, V0, P0
   Nagrani A, 2017, INTERSPEECH, V0, PP2616, DOI 10.21437/Interspeech.2017-950
   Nosratighods M, 2010, SPEECH COMMUN, V52, P753, DOI 10.1016/j.specom.2010.04.007
   Paszke Adam, 2017, NIPS W, V0, P0
   Povey D, 2018, INTERSPEECH, V0, PP3743, DOI 10.21437/Interspeech.2018-1417
   Sabour S, 2017, ADV NEUR IN, V30, P0
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Snell J, 2017, ADV NEUR IN, V30, P0
   Snyder D, 2019, INT CONF ACOUST SPEE, V0, PP5796, DOI 10.1109/ICASSP.2019.8683760
   Sung F, 2018, PROC CVPR IEEE, V0, PP1199, DOI 10.1109/CVPR.2018.00131
   Vélez I, 2020, APPL SOFT COMPUT, V95, P0, DOI 10.1016/j.asoc.2020.106704
   Villalba J, 2020, COMPUT SPEECH LANG, V60, P0, DOI 10.1016/j.csl.2019.101026
   Vinyals Oriol, 2016, ADV NEURAL INFORM PR, V29, P0, DOI 10.48550/ARXIV.1606.04080
   Vogt R, 2010, IEEE T AUDIO SPEECH, V18, P1182, DOI 10.1109/TASL.2009.2031505
   Wang JX, 2019, INT CONF ACOUST SPEE, V0, PP3652, DOI 10.1109/ICASSP.2019.8683393
   Wang Junchao, 2018, COMPUTER ENGINEERING, V44, P281, DOI 10.19678/j.issn.1000-3428.0048134
   Wang S, 2019, IEEE-ACM T AUDIO SPE, V27, P1686, DOI 10.1109/TASLP.2019.2928128
   Wang XM, 2022, NEUROCOMPUTING, V490, P283, DOI 10.1016/j.neucom.2021.11.092
   Zeinali H, 2019, ARXIV, V0, P0
   Zhang CL, 2018, IEEE-ACM T AUDIO SPE, V26, P1633, DOI 10.1109/TASLP.2018.2831456
   Zhang XT, 2020, ARXIV, V0, P0
   Zhao Y, 2020, INT CONF ACOUST SPEE, V0, PP6834, DOI 10.1109/ICASSP40776.2020.9053767
   Zinchenko K, 2017, IEEE T IND INFORM, V13, P607, DOI 10.1109/TII.2016.2625818
NR 51
TC 0
Z9 0
U1 5
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2023
VL 22
IS 3
BP 
EP 
DI 10.1145/3564782
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FA8
UT WOS:000998922200018
DA 2023-11-10
ER

PT J
AU Ciravegna, G
   Barbiero, P
   Giannini, F
   Gori, M
   Liò, P
   Maggini, M
   Melacci, S
AF Ciravegna, Gabriele
   Barbiero, Pietro
   Giannini, Francesco
   Gori, Marco
   Lio, Pietro
   Maggini, Marco
   Melacci, Stefano
TI Logic Explained Networks
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Explainable AI; Neural networks; Logic Explained Networks
ID black-box; selection; models
AB The large and still increasing popularity of deep learning clashes with a major limit of neural network architectures, that consists in their lack of capability in providing human-understandable motivations of their decisions. In situations in which the machine is expected to support the decision of human experts, providing a comprehensible explanation is a feature of crucial importance. The language used to communicate the explanations must be formal enough to be implementable in a machine and friendly enough to be understandable by a wide audience. In this paper, we propose a general approach to Explainable Artificial Intelligence in the case of neural architectures, showing how a mindful design of the networks leads to a family of interpretable deep learning models called Logic Explained Networks (LENs). LENs only require their inputs to be human-understandable predicates, and they provide explanations in terms of simple First -Order Logic (FOL) formulas involving such predicates. LENs are general enough to cover a large number of scenarios. Amongst them, we consider the case in which LENs are directly used as special classifiers with the capability of being explainable, or when they act as additional networks with the role of creating the conditions for making a black-box classifier explainable by FOL formulas. Despite supervised learning problems are mostly emphasized, we also show that LENs can learn and provide explanations in unsupervised learning settings. Experimental results on several datasets and tasks show that LENs may yield better classifications than established white-box models, such as decision trees and Bayesian rule lists, while providing more compact and meaningful explanations.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Ciravegna, Gabriele] Univ Florence, Dept Informat Engn, Florence, Italy.
   [Ciravegna, Gabriele; Giannini, Francesco; Gori, Marco; Maggini, Marco; Melacci, Stefano] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Barbiero, Pietro; Lio, Pietro] Univ Cambridge, Dept Comp Sci & Technol, Cambridge, England.
   [Ciravegna, Gabriele; Gori, Marco] Univ Cote Azur, Maasai, Inria, CNRS,I3S, Nice, France.
C3 University of Florence; University of Siena; University of Cambridge; Inria; Universite Cote d'Azur; Centre National de la Recherche Scientifique (CNRS)
RP Melacci, S (通讯作者)，Univ Siena, Dept Informat Engn & Math, Siena, Italy.
EM gabriele.ciravegna@unifi.it; pb737@cam.ac.uk; francesco.giannini@unisi.it; marco.gori@unisi.it; pl219@cam.ac.uk; marco.maggini@unisi.it; mela@diism.unisi.it
FU European Union [848077]; Italian Ministry of Education, University and Research [2017TWNMH2]; EU [952215, 952026, 951911]; French government [ANR-19-P3IA-0002]
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Agarwal R, 2021, ARXIV, V0, P0
   Ahmad MA, 2018, ACM-BCB18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, V0, P0
   Angelino E, 2018, PREPRINT, V0, P0, DOI DOI 10.48550/arXiv.1704.01701
   [Anonymous], 2014, EUR C COMP VIS, V0, P0
   [Anonymous], 1990, ADV NEURAL INFORM PR, V0, P0
   Bach SH, 2015, ARXIV, V0, P0
   Barbiero P, 2021, ARXIV, V0, P0
   Bessiere C, 2017, ARTIF INTELL, V244, P315, DOI 10.1016/j.artint.2015.08.001
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Brundage M, 2020, ARXIV, V0, P0
   Campigotto P, 2015, ARXIV, V0, P0
   Caruana R, 2015, KDD15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1721, DOI 10.1145/2783258.2788613
   Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8080832
   Chander Ajay, 2018, IUI WORKSH, V0, P0
   Ciravegna G, 2020, AAAI CONF ARTIF INTE, V34, P3658
   Ciravegna G, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2234
   Cohen William W, 1995, P 12 INT C MACH LEAR, V0, PP115, DOI 10.1016/B978-1-55860-377-6.50023-2
   Coppedge Michael, 2021, V DEM CODEBOOK V11, V0, P0
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Croce F, 2020, ARXIV, V0, P0
   Cranmer MD, 2019, ARXIV, V0, P0
   Das A, 2020, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2006.11371
   De Raedt L, 2016, LECT NOTES COMPUT SC, V10101, P96, DOI 10.1007/978-3-319-50137-6_5
   De Raedt L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1835
   Devlin J, 2019, ARXIV, V0, P0
   Domingos P, 2009, SYNTHESIS LECT ARTIF, V3, P1
   Doshi-Velez F, 2017, ARXIV, V0, P0
   Dosovitskiy A, 2021, ARXIV, V0, P0
   Erhan D, 2010, 13551 U MONTREAL DEP, V0, P0
   EUGDPR, 2017, GDPR GEN DAT PROT RE, V0, P0
   Frankle Jonathan, 2019, ARXIV, V0, P0
   Ghorbani A, 2019, ADV NEUR IN, V32, P0
   Gilpin LH, 2018, PR INT CONF DATA SC, V0, PP80, DOI 10.1109/DSAA.2018.00018
   Glorot Xavier, 2011, P 14 INT C ART INT S, V0, PP315, DOI 10.1002/ECS2.1832
   Gnecco G, 2015, NEURAL COMPUT, V27, P388, DOI 10.1162/NECO_a_00686
   Goddard M, 2017, INT J MARKET RES, V59, P703, DOI 10.2501/IJMR-2017-050
   Goldberger AL, 2000, CIRCULATION, V101, PE215, DOI 10.1161/01.CIR.101.23.e215
   Wilson AG, 2020, ARXIV, V0, P0
   Gori M, 2013, IEEE T NEUR NET LEAR, V24, P825, DOI 10.1109/TNNLS.2013.2241787
   Guidotti R, 2018, ARXIV, V0, P0
   Gunning D, 2017, EXPLAINABLE ARTIFICI, V2, P2, DOI 10.1126/SCIROBOTICS.AAY7120
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Hassibi B, 1993, 2 ORDER DERIVATIVES, V0, P0
   HASTIE T, 1987, J AM STAT ASSOC, V82, P371, DOI 10.2307/2289439
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Izza Y, 2021, ARXIV, V0, P0
   Kazhdan D, 2020, ARXIV, V0, P0
   Kim B, 2018, EXPLAINABLE INTERPRE, V0, PP3, DOI 10.1007/978-3-319-98131-4_1
   Kim B, 2018, PR MACH LEARN RES, V80, P0
   Koh PW, 2020, PR MACH LEARN RES, V119, P0
   Kolb S, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2333
   Kukacka J, 2017, ARXIV, V0, P0
   LeCun Yann, 1998, MNIST DATABASE HANDW, V0, P0, DOI DOI 10.1561/2400000035
   Letham B, 2015, ANN APPL STAT, V9, P1350, DOI 10.1214/15-AOAS848
   Lever J, 2016, NAT METHODS, V13, P703, DOI 10.1038/nmeth.3968
   Lipton ZC, 2018, QUEUE, V16, P31, DOI 10.1145/32363863241340.
   Lundberg S, 2017, ARXIV, V0, P0
   Ma WJ, 2014, NAT NEUROSCI, V17, P347, DOI 10.1038/nn.3655
   MacKay DJC, 2003, INFORM THEORY INFERE, V0, P0
   Marcinkevics R, 2023, ARXIV, V0, P0
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   MCCLUSKEY EJ, 1956, BELL SYST TECH J, V35, P1417, DOI 10.1002/j.1538-7305.1956.tb03835.x
   McColl H, 1878, P LOND MATH SOC, V0, P16
   Melacci S, 2022, IEEE T PATTERN ANAL, V44, P9944, DOI 10.1109/TPAMI.2021.3137564
   Melacci S, 2012, IEEE T NEUR NET LEAR, V23, P1849, DOI 10.1109/TNNLS.2012.2216899
   Mendelson E, 2009, INTRO MATH LOGIC, V0, P0
   Miller DJ, 2020, P IEEE, V108, P402, DOI 10.1109/JPROC.2020.2970615
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Molnar C, 2020, COMM COM INF SC, V0, P0, DOI DOI 10.1007/978-3-030-65965-3_28
   MUGGLETON S, 1990, NEW GENERAT COMPUT, V8, P295
   Ozdag M, 2018, PROCEDIA COMPUT SCI, V140, P152, DOI 10.1016/j.procs.2018.10.315
   Paszke A, 2019, ARXIV, V0, P0
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pemstein Daniel, 2018, SSRN SCHOLARLY PAPER, V0, P0, DOI DOI 10.2139/SSRN.3167764
   Qizhe Xie, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10684, DOI 10.1109/CVPR42600.2020.01070
   Quine Willard V, 1952, AM MATH MON, V59, P521, DOI 10.1080/00029890.1952.11988183
   QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6
   QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105
   Tavares AR, 2021, ARXIV, V0, P0
   Ramachandran P, 2017, ARXIV, V0, P0
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, V0, P1527
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1
   Rudin C, 2021, ARXIV, V0, P0
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Russell, 2010, ARTIF INTELL, V0, P0
   Saeed M, 2011, CRIT CARE MED, V39, P952, DOI 10.1097/CCM.0b013e31820a92c6
   Samek W, 2021, ARXIV, V0, P0
   SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087
   Sato M, 2001, IEEE IJCNN, V0, PP1870, DOI 10.1109/IJCNN.2001.938448
   Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, V0, PP618, DOI 10.1109/ICCV.2017.74
   Shih A, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5103
   SIMON HA, 1979, AM ECON REV, V69, P493
   SIMON HA, 1956, PSYCHOL REV, V63, P129, DOI 10.1037/h0042769
   Simonyan K, 2014, ARXIV, V0, P0
   Srinivasan R, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4812
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Ribeiro MT, 2016, ARXIV, V0, P0
   VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972
   Battaglia PW, 2018, ARXIV, V0, P0
   Wäldchen S, 2021, J ARTIF INTELL RES, V70, P351
   Wah C, 2011, CNSTR2011001 CALTECH, V0, P0
   Yang F, 2017, ADV NEURAL INFORM PR, V0, P0
   Zilke JR, 2016, LECT NOTES ARTIF INT, V9956, P457, DOI 10.1007/978-3-319-46307-0_29
NR 109
TC 1
Z9 1
U1 9
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD JAN 15
PY 2023
VL 314
IS 
BP 
EP 
DI 10.1016/j.artint.2022.103822
EA NOV 2022
PG 30
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6R2FN
UT WOS:000892123700002
DA 2023-11-10
ER

PT J
AU Yirmibesoglu, Z
   Güngör, T
AF Yirmibesoglu, Zeynep
   Gungor, Tunga
TI Morphologically Motivated Input Variations and Data Augmentation in Turkish-English Neural Machine Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Neural machine translation; morphology; low-resource; Transformer; encoder-decoder; attention; data augmentation; word segmentation
AB Success of neural networks in natural language processing has paved the way for neural machine translation (NMT), which rapidly became the mainstream approach in machine translation. Significant improvement in translation performance has been achieved with breakthroughs such as encoder-decoder networks, attention mechanism, and Transformer architecture. However, the necessity of large amounts of parallel data for training an NMT system and rare words in translation corpora are issues yet to be overcome. In this article, we approach NMT of the low-resource Turkish-English language pair. We employ state-of-the-art NMT architectures and data augmentationmethods that exploit monolingual corpora. We point out the importance of input representation for the morphologically rich Turkish language and make a comprehensive analysis of linguistically and non-linguistically motivated input segmentation approaches. We prove the effectiveness of morphologically motivated input segmentation for the Turkish language. Moreover, we show the superiority of the Transformer architecture over attentional encoder-decoder models for the Turkish-English language pair. Among the employed data augmentation approaches, we observe back-translation to be the most effective and confirm the benefit of increasing the amount of parallel data on translation quality. This research demonstrates a comprehensive analysis on NMT architectures with different hyperparameters, data augmentation methods, and input representation techniques, and proposes ways of tackling the low-resource setting of Turkish-English NMT.
C1 [Yirmibesoglu, Zeynep; Gungor, Tunga] Bogazici Univ, Comp Engn, Istanbul, Turkiye.
C3 Bogazici University
RP Yirmibesoglu, Z (通讯作者)，Bogazici Univ, Comp Engn, Istanbul, Turkiye.
EM zeynep.yirmibesoglu@boun.edu.tr; gungort@boun.edu.tr
CR [Anonymous], 2015, P 10 WORKSHOP STAT M, V0, P0
   Ataman Duygu, 2017, PRAGUE BULLETIN OF MATHEMATICAL LINGUISTICS, V0, PP331, DOI 10.1515/pralin-2017-0031
   Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bapna A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3028
   Barro L, 2021, PLATELETS, V32, P153, DOI 10.1080/09537104.2020.1849602
   Bektas Emre, 2016, SHARED TASK PAPERS, V2, P246, DOI 10.18653/v1/W16-2305
   Bojar, 2018, P 3 C MACH TRANSL SH, V2, P272, DOI 10.18653/V1/W18-6401
   Bojar O, 2017, P 2 C MACH TRANSL, V2, P169, DOI 10.18653/V1/W17-4717
   Caswell I, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P53
   Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76
   Cheng Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1965
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Currey A, 2017, P 2 C MACH TRANSL, V0, PP148, DOI 10.18653/V1/W17-4715
   Devlin J, 2019, ARXIV, V0, P0
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P489
   El-Kahlout ID, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), V0, P158
   Forcada ML, 1997, LECT NOTES COMPUT SC, V1240, P453, DOI 10.1007/BFb0032504
   Garcia-Martinez Mercedes, 2017, SHARED TASK PAPERS, V0, P288
   Gulcehre C, 2015, ARXIV, V0, P0
   Gwinnup Jeremy, 2017, P 2 C MACHINE TRANSL, V0, PP303, DOI 10.18653/v1/W17-4728
   Haddow Barry, 2018, P 3 C MACHINE TRANSL, V0, P399
   He D, 2016, ADV NEUR IN, V29, P0
   He JX, 2020, ARXIV, V0, P0
   Hoang CDV, 2017, P 2017 C EMP METH NA, V0, PP146, DOI 10.18653/V1/D17-1014
   Imamura K, 2017, P 4 WORKSH AS TRANSL, V0, P0
   Imamura K, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, V0, P55
   Jean S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1
   Jiao Wenxiang, 2021, ARXIV, V0, P0
   Junczys-Dowmunt M, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P116
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kingma DP, 2017, PROC 3 INT C LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Liu L M, 2016, P 2016 C N AM CHAPT, V0, PP411, DOI 10.18653/V1/N16-1046
   Luo GX, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/6140153
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Marie B, 2018, P 3 C MACH TRANSL SH, V0, PP449, DOI 10.18653/V1/W18-6419
   Miceli Barone AV, 2017, P 2 C MACHINE TRANSL, V0, PP99, DOI 10.18653/V1/W17-4710
   Luong MT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1054
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Oflazer K, 2003, TREEBANKS, V0, P261
   Oflazer Kemal, 1993, P 6 C EUROPEAN CHAPT, V0, P0
   Pan YR, 2020, FUTURE INTERNET, V12, P0, DOI 10.3390/fi12060096
   Poncelas A, 2018, ARXIV, V0, P0
   Press O, 2017, P 15 C EUROPEAN CHAP, V2, P157, DOI 10.18653/V1/E17-2025
   So DR, 2019, ARXIV, V0, P0
   Sak H, 2007, LECT NOTES COMPUT SC, V4394, P107
   Sanh V, 2020, ARXIV, V0, P0
   Sennrich R, 2017, P 2 C MACH TRANSL SH, V2, P389, DOI 10.18653/V1/W17-4739
   Sennrich R, 2017, P SOFTW DEM 15 C EUR, V0, PP65, DOI 10.18653/V1/E17-3017
   Sennrich R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P211
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sennrich Rico, 2016, P 1 C MACHINE TRANSL, V2, P371, DOI 10.18653/V1/W16-2323
   Shen Y, 2018, P 2018 C N AM CHAPT, V1, P1294, DOI 10.18653/V1/N18-1117
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Tyers Francis M, 2010, P LRECWORKSHOP EXPLO, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vidal, 1997, THEORETICAL METHODOL, V0, P160
   Hoang VCD, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, V0, P18
   Wang Q, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1810
   Wang S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P791
   Wolf T, 2020, ARXIV, V0, P0
   Wu LJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4207
   Wu YH, 2016, ARXIV, V0, P0
   Zhang XW, 2018, ARXIV, V0, P0
   Zheng Zaixiang, 2020, P INT C LEARNING REP, V0, P0
   Zhou J, 2016, T ASSOC COMPUT LING, V4, P371, DOI 10.1162/tacl_a_00105
   Zhou L, 2019, T ASSOC COMPUT LING, V7, P91, DOI 10.1162/tacl_a_00256
   Zong, 2016, P 2016 C EMP METH NA, V0, PP1535, DOI 10.18653/V1/D16-1160
NR 76
TC 0
Z9 0
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2023
VL 22
IS 3
BP 
EP 
DI 10.1145/3571073
PG 31
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FA8
UT WOS:000998922200030
DA 2023-11-10
ER

PT J
AU Latif, S
   Rana, R
   Khalifa, S
   Jurdak, R
   Schuller, B
AF Latif, Siddique
   Rana, Rajib
   Khalifa, Sara
   Jurdak, Raja
   Schuller, Bjorn
TI Self Supervised Adversarial Domain Adaptation for Cross-Corpus and Cross-Language Speech Emotion Recognition
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Training; Adaptation models; Emotion recognition; Speech recognition; Australia; Task analysis; Generators; Speech emotion recognition; self-supervised learning; domain adaptation; adversarial learning
ID networks
AB Despite the recent advancement in speech emotion recognition (SER) within a single corpus setting, the performance of these SER systems degrades significantly for cross-corpus and cross-language scenarios. The key reason is the lack of generalisation in SER systems towards unseen conditions, which causes them to perform poorly in cross-corpus and cross-language settings. Recent studies focus on utilising adversarial methods to learn domain generalised representation for improving cross-corpus and cross-language SER to address this issue. However, many of these methods only focus on cross-corpus SER without addressing the cross-language SER performance degradation due to a larger domain gap between source and target language data. This contribution proposes an adversarial dual discriminator (ADDi) network that uses the three-players adversarial game to learn generalised representations without requiring any target data labels. We also introduce a self-supervised ADDi (sADDi) network that utilises self-supervised pre-training with unlabelled data. We propose synthetic data generation as a pretext task in sADDi, enabling the network to produce emotionally discriminative and domain invariant representations and providing complementary synthetic data to augment the system. The proposed model is rigorously evaluated using five publicly available datasets in three languages and compared with multiple studies on cross-corpus and cross-language SER. Experimental results demonstrate that the proposed model achieves improved performance compared to the state-of-the-art methods.
C1 [Latif, Siddique; Rana, Rajib] Univ Southern Queensland USQ, Springfield, Qld 4301, Australia.
   [Latif, Siddique; Khalifa, Sara] CSIRO, Distributed Sensing Syst Grp, Data61, Pullenvale, Qld 4069, Australia.
   [Jurdak, Raja] Queensland Univ Technol QUT, TruNets Trusted Networks Lab, Brisbane, Qld 4000, Australia.
   [Schuller, Bjorn] Imperial Coll London, GLAM Grp Language Audio & Mus, London SW7 2BX, England.
   [Schuller, Bjorn] Univ Augsburg, ZDB Chair Embedded Intelligence Hlth Care & Wellbe, D-86159 Augsburg, Germany.
C3 University of Southern Queensland; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Queensland University of Technology (QUT); Imperial College London; University of Augsburg
RP Latif, S (通讯作者)，Univ Southern Queensland USQ, Springfield, Qld 4301, Australia.
EM siddique.latif@usq.edu.au; rajib.rana@usq.edu.au; sara.khalifa@data61.csiro.au; r.jurdak@qut.edu.au; schuller@tum.de
CR Abdelwahab M, 2018, IEEE-ACM T AUDIO SPE, V26, P2423, DOI 10.1109/TASLP.2018.2867099
   Abdelwahab M, 2015, INT CONF ACOUST SPEE, V0, PP5058, DOI 10.1109/ICASSP.2015.7178934
   Ahn Y, 2021, IEEE SIGNAL PROC LET, V28, P1190, DOI 10.1109/LSP.2021.3086395
   Albornoz EM, 2017, IEEE T AFFECT COMPUT, V8, P43, DOI 10.1109/TAFFC.2015.2503757
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Baevski A, 2019, P ICLR, V0, P0
   Bao F, 2019, INTERSPEECH, V0, PP2828, DOI 10.21437/Interspeech.2019-2293
   Bérard A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6224, DOI 10.1109/ICASSP.2018.8461690
   Brock Andrew, 2018, INT C LEARN REPR, V0, P0
   Burkhardt F, 2005, INTERSPEECH, V0, P1517
   Burmania A, 2016, IEEE T AFFECT COMPUT, V7, P374, DOI 10.1109/TAFFC.2015.2493525
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chatziagapi A, 2019, INTERSPEECH, V0, PP171, DOI 10.21437/Interspeech.2019-2561
   Choi Y, 2018, PROC CVPR IEEE, V0, PP8789, DOI 10.1109/CVPR.2018.00916
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   Deng J, 2014, IEEE SIGNAL PROC LET, V21, P1068, DOI 10.1109/LSP.2014.2324759
   Deng J, 2013, INT CONF AFFECT, V0, PP511, DOI 10.1109/ACII.2013.90
   Detjen H, 2021, INT J HUM-COMPUT INT, V37, P308, DOI 10.1080/10447318.2020.1860517
   Dubey H, 2019, INT CONF ACOUST SPEE, V0, PP6296, DOI 10.1109/ICASSP.2019.8683023
   Eskimez SE, 2020, INTERSPEECH, V0, PP3446, DOI 10.21437/Interspeech.2020-2898
   Eyben F, 2010, P INT WORKSHOP EMOTI, V0, P77
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Feraru SM, 2015, INT CONF AFFECT, V0, PP125, DOI 10.1109/ACII.2015.7344561
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Ghifary M, 2015, IEEE I CONF COMP VIS, V0, PP2551, DOI 10.1109/ICCV.2015.293
   Gideon J, 2017, ARXIV, V0, P0
   Gideon J, 2021, IEEE T AFFECT COMPUT, V12, P1055, DOI 10.1109/TAFFC.2019.2916092
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393
   Jing TT, 2021, IEEE WINT CONF APPL, V0, PP605, DOI 10.1109/WACV48630.2021.00065
   Khare A, 2021, IEEE W SP LANG TECH, V0, PP381, DOI 10.1109/SLT48900.2021.9383618
   Kim J, 2017, INTERSPEECH, V0, PP1113, DOI 10.21437/Interspeech.2017-736
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Latif S, 2023, IEEE T AFFECT COMPUT, V14, P1634, DOI 10.1109/TAFFC.2021.3114365
   Latif S, 2020, INTERSPEECH, V0, PP521, DOI 10.21437/Interspeech.2020-3194
   Latif S, 2022, IEEE T AFFECT COMPUT, V13, P992, DOI 10.1109/TAFFC.2020.2983669
   Latif S, 2021, IEEE REV BIOMED ENG, V14, P342, DOI 10.1109/RBME.2020.3006860
   Latif S, 2019, INTERSPEECH, V0, PP3920, DOI 10.21437/Interspeech.2019-3252
   Latif S, 2019, INT CONF AFFECT, V0, P0, DOI DOI 10.1109/acii.2019.8925513
   Latif S, 2018, INTERSPEECH, V0, PP257, DOI 10.21437/Interspeech.2018-1625
   Latif S, 2018, INTERSPEECH, V0, PP3107, DOI 10.21437/Interspeech.2018-1568
   Latif S, 2018, INT CONF FRONT INFO, V0, PP88, DOI 10.1109/FIT.2018.00023
   Le Cun Y, 1989, ADV NEURAL INFORM PR, V2, P396, DOI 10.1111/DSU.12130
   Leshem R, 2020, FRONT PSYCHIATRY, V11, P0, DOI 10.3389/fpsyt.2020.601763
   Li XF, 2019, SPEECH COMMUN, V110, P1, DOI 10.1016/j.specom.2019.04.004
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lotfian R, 2019, IEEE T AFFECT COMPUT, V10, P471, DOI 10.1109/TAFFC.2017.2736999
   Luo H, 2020, IEEE-ACM T AUDIO SPE, V28, P2047, DOI 10.1109/TASLP.2020.3006331
   Macary M, 2021, IEEE W SP LANG TECH, V0, PP373, DOI 10.1109/SLT48900.2021.9383456
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mariani G, 2018, ARXIV, V0, P0
   Mirza M, 2014, ARXIV, V0, P0
   Neumann M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5769, DOI 10.1109/ICASSP.2018.8462162
   Ng Andrew Y, 2007, LEARNING, V0, PP759, DOI 10.1145/1273496.1273592
   Ning YS, 2017, INT CONF ACOUST SPEE, V0, PP5615, DOI 10.1109/ICASSP.2017.7953231
   Ocquaye ENN, 2019, IEEE ACCESS, V7, P93847, DOI 10.1109/ACCESS.2019.2924597
   Panayotov V, 2015, INT CONF ACOUST SPEE, V0, PP5206, DOI 10.1109/ICASSP.2015.7178964
   Parry J, 2019, INTERSPEECH, V0, PP1656, DOI 10.21437/Interspeech.2019-2753
   Pascual S, 2019, INTERSPEECH, V0, PP161, DOI 10.21437/Interspeech.2019-2605
   Povey D, 2011, IEEE 2011 WORKSHOP A, V0, P0
   Rana R, 2019, EUR J CANCER CARE, V28, P0, DOI 10.1111/ecc.13033
   Ringeval F, 2013, IEEE INT CONF AUTOMA, V0, P0
   Sahu S, 2018, INTERSPEECH, V0, PP3693, DOI 10.21437/Interspeech.2018-1883
   Schuller B, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1564
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   Shukla A, 2020, P SIGHT SOUND WORKSH, V0, P0
   Shukla A, 2020, INT CONF ACOUST SPEE, V0, PP6299, DOI 10.1109/icassp40776.2020.9053415
   Song P, 2019, IEEE T AFFECT COMPUT, V10, P265, DOI 10.1109/TAFFC.2017.2705696
   Steidl S, 2009, AUTOMATIC CLASSIFICA, V0, P0
   Sun BC, 2016, AAAI CONF ARTIF INTE, V0, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P936, DOI 10.1109/TMM.2008.927665
   Xiao L, 2021, INT C PATT RECOG, V0, PP6874, DOI 10.1109/ICPR48806.2021.9412592
   Xiao YF, 2020, IEEE TETCI, V4, P480, DOI 10.1109/TETCI.2020.2972926
   Xu Y, 2017, IEEE IJCNN, V0, PP3461, DOI 10.1109/IJCNN.2017.7966291
   Yadegaridehkordi E, 2019, COMPUT EDUC, V142, P0, DOI 10.1016/j.compedu.2019.103649
   Yan HL, 2017, PROC CVPR IEEE, V0, PP945, DOI 10.1109/CVPR.2017.107
   Yufeng Yin, 2020, ICMI 20: PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP481, DOI 10.1145/3382507.3418813
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zhang H, 2018, P INT C LEARN REPR, V0, PP1, DOI 10.48550/ARXIV.1710.09412
   Zhang R, 2017, PROC CVPR IEEE, V0, PP645, DOI 10.1109/CVPR.2017.76
   Zhang Y, 2017, INT CONF ACOUST SPEE, V0, PP4990, DOI 10.1109/ICASSP.2017.7953106
   Zhou H, 2019, INT CONF ACOUST SPEE, V0, PP3732, DOI 10.1109/ICASSP.2019.8683299
   Zixing Zhang, 2011, 2011 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU), V0, PP523, DOI 10.1109/ASRU.2011.6163986
NR 89
TC 5
Z9 5
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
EI 
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD JUL-SEP 15
PY 2023
VL 14
IS 3
BP 1912
EP 1926
DI 10.1109/TAFFC.2022.3167013
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA T0NN8
UT WOS:001075041900016
DA 2023-11-10
ER

PT J
AU Bidgoly, AJ
   Amirkhani, H
   Baradaran, R
AF Bidgoly, Amir Jalaly
   Amirkhani, Hossein
   Baradaran, Razieh
TI Clustering-based Sequence to Sequence Model for GenerativeQuestion Answering in a Low-resource Language
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Generative question answering; low-resource language; clustering; deep learning; encoder-decoder model
AB Despite the impressive success of sequence to sequence models for generative question answering, they need a vast amount of question-answer pairs during training, which is hard and expensive to obtain, especially for low-resource languages. In this article, we present a framework that exploits the semantic clusters among the question-answer pairs to compensate for the lack of enough training data. In the training phase, the questionanswer pairs are clustered, and a cluster predictor is trained to identify the cluster each question belongs to. Then, a sequence to sequence model is trained, where there is a different generator for each cluster in the decoder component. During the test phase, the cluster of the input question is first identified using the trained cluster predictor, and the appropriate decoder is exploited. Our experiments on a Persian religious dataset show that the proposed method outperforms the standard sequence to sequence model by a large margin in terms of ROUGE and BLEU scores. This is traced back to the lower number of words in each cluster, leading to a reduction in the number of effective parameters each generator needs to learn, which help the model learn from fewer training data with less overfitting.
C1 [Bidgoly, Amir Jalaly; Amirkhani, Hossein; Baradaran, Razieh] Univ Qom, Dept Informat Technol & Comp Engn, PO 3716146611, Qom, Iran.
RP Bidgoly, AJ (通讯作者)，Univ Qom, Dept Informat Technol & Comp Engn, PO 3716146611, Qom, Iran.
EM Ajalaly@qom.ac.ir; amirkhani@qom.ac.ir; R.Baradaran@stu.qom.ac.ir
CR Abdi A, 2020, COMPUT SPEECH LANG, V60, P0, DOI 10.1016/j.csl.2019.101023
   Amirkhani H, 2021, ARXIV, V0, P0
   [Anonymous], 2016, P C EMPIRICAL METHOD, V0, P0
   Baranova-Bolotova V, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP2477, DOI 10.1145/3397271.3401449
   Bi B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2521
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boyd A, 2018, P 2018 EMNLP WORKSHO, V0, P79
   Cho KYHY, 2014, ARXIV, V0, P0
   Dabre R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1410
   Daniel JE, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P948
   Das R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P358, DOI 10.18653/v1/P17-2057
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhingra Bhuwan, 2018, P 2018 C N AM CHAPT, V2, P582, DOI 10.18653/V1/N18-2092
   Dong X, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6306
   Fajcik Martin, 2021, P 3 WORKSHOP MACHINE, V0, P0
   Fu Y, 2018, P 2018 C N AM CHAPTE, V0, P185
   Gupta D, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3359988
   He SZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P199, DOI 10.18653/v1/P17-1019
   Huang YZ, 2018, MACH VISION APPL, V29, P1009, DOI 10.1007/s00138-018-0908-0
   Karpagam K, 2019, SADHANA-ACAD P ENG S, V44, P0, DOI 10.1007/s12046-018-1022-8
   Khalil Talaat, 2019, P C EMPIRICAL METHOD, V0, P6420
   Lang Q, 2021, APPL SOFT COMPUT, V111, P0, DOI 10.1016/j.asoc.2021.107858
   Lee K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2840
   Lewis M, 2018, GENERATIVE QUESTION, V0, P0
   Lewis P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4896
   LijunWu Jinhua Zhu, 2019, P C EMPIRICAL METHOD, V0, P4366
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4223
   Louvan Samuel, 2018, P 2018 EMNLP WORKSHO, V0, P74
   Mishra A, 2016, J KING SAUD UNIV-COM, V28, P345, DOI 10.1016/j.jksuci.2014.10.007
   Momtazi S, 2009, P 18 ACM C INF KNOWL, V0, PP1911, DOI 10.1145/1645953.1646263
   Nakatsuji M, 2020, AAAI CONF ARTIF INTE, V34, P8520
   Otegi A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P436
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Parida S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5994
   Perera R, 2012, 2012 IEEE FOURTH INTERNATIONAL CONFERENCE ON TECHNOLOGY FOR EDUCATION (T4E), V0, PP245, DOI 10.1109/T4E.2012.48
   Rajpurkar P, 2016, ARXIV, V0, P0
   Rajpurkar P, 2018, ARXIV, V0, P0
   Sondhi P, 2007, EURASIP J BIOINFORM, V0, P0, DOI DOI 10.1155/2007/28576
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Tan CQ, 2018, AAAI CONF ARTIF INTE, V0, P5940
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Shuohang, 2021, FINDINGS ASS COMPUTA, V0, P3958
   Wang SN, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2209
   Wei MX, 2019, IEEE ACCESS, V7, P61008, DOI 10.1109/ACCESS.2019.2904337
   Xu W, 2003, P 26 SIGIR TOR ON CA, V0, P267
   Yang JY, 2020, LECT NOTES COMPUT SC, V12454, P340, DOI 10.1007/978-3-030-60248-2_23
   Yin Jun, 2016, P INT JOINT C ARTIFI, V0, P0
   Yoon S, 2018, ARXIV, V0, P0
   Yoon S, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2093, DOI 10.1145/3357384.3358148
   Zhang MS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P997
   Zuin G, 2018, 2018 INT JOINT C NEU, V0, P1
NR 53
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB 15
PY 2023
VL 22
IS 2
BP 
EP 
DI 10.1145/3563036
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA C7AF6
UT WOS:000963394900026
DA 2023-11-10
ER

PT J
AU Faal, F
   Schmitt, K
   Yu, JY
AF Faal, Farshid
   Schmitt, Ketra
   Yu, Jia Yuan
TI Reward modeling for mitigating toxicity in transformer-based language models
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Language models; Transformers; Reinforcement learning; Toxic language mitigation; Natural language generation
AB Transformer-based language models can generate fluent text and be efficiently adapted across various natural language generation tasks. However, language models that are pretrained on large unlabeled web text corpora have been shown to suffer from degenerating toxic content and social bias behaviors, consequently hindering their safe deployment. Various detoxification methods have been proposed to mitigate language model toxicity; however, these methods struggle to detoxify language models when conditioned on prompts that contain specific social identities related to gender, race, or religion. In this study, we propose Reinforce-Detoxify, a reinforcement learning-based method for mitigating toxicity in language models. We address the challenge of safety in language models and propose a new reward model that can detect toxic content and mitigate unintended bias towards social identities in toxicity prediction. The experiments demonstrate that the Reinforce-Detoxify method for language model detoxification outperforms existing detoxification approaches in automatic evaluation metrics, indicating that our approach in language model detoxification is less prone to unintended bias toward social identities in generated content.
C1 [Faal, Farshid; Schmitt, Ketra; Yu, Jia Yuan] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
   [Schmitt, Ketra] Concordia Univ, Ctr Engn Soc, Montreal, PQ, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Faal, F (通讯作者)，Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM f_faal@encs.concordia.ca; ketra.schmitt@concordia.ca; jiayuan.yu@concordia.ca
CR Bengio Y, 2009, P 26 ANN INT C MACHI, V0, P0, DOI DOI 10.1145/1553374.1553380
   Böhm F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3110
   Boyd-Graber Jordan L, 2017, P 2017 C EMP METH NA, V0, PP1464, DOI 10.18653/V1/D17-1153
   Dathathri S, 2020, ICLR, V0, P0
   Davidson T, 2017, ICWSM, V0, P0
   Dhamala J, 2021, P 2021 ACM C FAIRN A, V0, PP862, DOI 10.1145/3442188.3445924
   Dhariwal Prafulla, 2017, OPENAI BASELINES, V0, P0
   Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, V0, P0
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Gao Y, 2020, INFORM RETRIEVAL J, V23, P555, DOI 10.1007/s10791-019-09367-8
   Gehman Samuel, 2020, FINDINGS ASS COMPUTA, V0, P3356
   Gokaslan Aaron, 2019, OPENWEBTEXT CORPUS, V0, P0
   Gururangan Suchin, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Holtzman Ari, 2020, ICLR, V0, P0
   Krause B, 2021, GEDI GENERATIVE DISC, V0, P0
   Li Jiwei, 2016, EMNLP, V0, P0
   Li M, 2021, APPL INTELL, V51, P7109, DOI 10.1007/s10489-021-02188-7
   Liu A, 2021, P 59 ANN M ASS COMPU, V0, P6691
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   Niven T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4658
   Paulus Romain, 2018, 6 INT C LEARN REPR I, V0, P0
   Do P, 2022, APPL INTELL, V52, P636, DOI 10.1007/s10489-021-02460-w
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ranzato M, 2016, ICLR, V0, P1
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Schulman John, 2017, ARXIV170706347, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3407
   Stiennon N, 2020, P 34 INT C NEUR INF, V0, P3008
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2153
   Welbl J, 2021, FINDINGS ASS COMPUTA, V2021, P2447, DOI 10.18653/V1/2021.FINDINGS-EMNLP.210
   Wiegand M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P602
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu YX, 2018, AAAI CONF ARTIF INTE, V0, P5602
   Xu A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2390
   Yang S, 2022, APPL INTELL, V52, P1672, DOI 10.1007/s10489-021-02431-1
   Yi Sanghyun, 2019, P 12 INT C NAT LANG, V0, P65
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
   Ziegler DM, 2019, FINE TUNING LANGUAGE, V0, P0
NR 45
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD APR 15
PY 2023
VL 53
IS 7
BP 8421
EP 8435
DI 10.1007/s10489-022-03944-z
EA JUL 2022
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA A9OT4
UT WOS:000827937500006
DA 2023-11-10
ER

PT J
AU Karra, R
   Lasfar, A
AF Karra, Rachid
   Lasfar, Abdelali
TI Impact of Data Quality on Question Answering System Performances
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE DataOps; data quality; QA system; nlp; context simplification
ID simplification
AB In contrast with the research of new models, little attention has been paid to the impact of low or high-quality data feeding a dialogue system. The present paper makes the first attempt to fill this gap by extending our previous work on question-answering (QA) systems by investigating the effect of misspelling on QA agents and how context changes can enhance the responses. Instead of using large language models trained on huge datasets, we propose a method that enhances the model's score by modifying only the quality and structure of the data feed to the model. It is important to identify the features that modify the agent performance because a high rate of wrong answers can make the students lose their interest in using the QA agent as an additional tool for distant learning. The results demonstrate the accuracy of the proposed context simplification exceeds 85%. These findings shed light on the importance of question data quality and context complexity construct as key dimensions of the QA system. In conclusion, the experimental results on questions and contexts showed that controlling and improving the various aspects of data quality around the QA system can significantly enhance his robustness and performance.
C1 [Karra, Rachid; Lasfar, Abdelali] Mohammed V Univ Rabat, Mohammadia Sch Engineers, LASTIMI Lab, Rabat, Morocco.
C3 Mohammed V University in Rabat
RP Karra, R (通讯作者)，Mohammed V Univ Rabat, Mohammadia Sch Engineers, LASTIMI Lab, Rabat, Morocco.
EM rachid.karra@est.um5.ac.ma
CR Allen D, 2009, SYSTEM, V37, P585, DOI 10.1016/j.system.2009.09.004
   [Anonymous], 2016, INDIAN J SCI TECHNOL, V0, P0
   Azeroual O, 2018, SCIENTOMETRICS, V115, P1271, DOI 10.1007/s11192-018-2735-5
   Bradbury BL, 2020, INTERACTIVE J GLOBAL, V0, P80
   Brill E, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P286, DOI 10.3115/1075218.1075255
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chaabi Y, 2021, J KING SAUD UNIV-COM, V34, P0
   Costa P, 2018, J SCI TECHNOL ARTS, V10, P59, DOI 10.7559/citarj.v10i3.563
   Crossley SA, 2007, MOD LANG J, V91, P15, DOI 10.1111/j.1540-4781.2007.00507.x
   Crossley SA, 2012, LANG TEACH RES, V16, P89, DOI 10.1177/1362168811423456
   Davis J, 2016, EFFECTIVE DEVOPS, V2nd, P37
   Deutsch A, 2007, J COMPUT SYST SCI, V73, P442, DOI 10.1016/j.jcss.2006.10.006
   Devlin J, 2018, ARXIV, V1, P4171
   Guo JF, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102067
   Jia Robin, 2017, P 2017 C EMP METH NA, V0, PP2021, DOI 10.18653/V1/D17-1215
   Jin T, 2018, TESOL QUART, V52, P457, DOI 10.1002/tesq.434
   Karra Rachid, 2021, DIGITAL TECHNOLOGIES AND APPLICATIONS. PROCEEDINGS OF ICDTA 21. LECTURE NOTES IN NETWORKS AND SYSTEMS (LNNS 211), V0, PP655, DOI 10.1007/978-3-030-73882-2_59
   Lee YW, 2006, JOURNEY DATA QUALITY, V0, P0
   Liu Z, 2020, PROC 2020 C EMPIRICA, V0, P0
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P52
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Niu Tong, 2018, P 22 C COMP NAT LANG, V0, P486
   Osman A, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0215516
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rapanta C, 2020, POSTDIGITAL SCI EDUC, V2, P923, DOI 10.1007/S42438-020-00155-Y
   Re C, 2019, ARXIV190905372, V0, P0
   Renggli C, 2021, IEEE DATA ENG B, V44, P11
   Robinson D, 2007, ASPECT ORIENTED PROG, V0, P0
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Savary A, 2001, P 6 INT C IMPL APPL, V0, P251
   Schmarje L, 2021, P NEURIPS DAT AI WOR, V0, P7
   Trewin S, 2021, DATAOPS REVOLUTION D, V1st, P115
   Vilares J, 2016, INFORM PROCESS MANAG, V52, P646, DOI 10.1016/j.ipm.2015.12.010
   Vilares J, 2011, INFORM PROCESS MANAG, V47, P263, DOI 10.1016/j.ipm.2010.08.004
   Wambsganss T, 2021, 29 EUROPEAN C INFORM, V0, P1
   Wang BN, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP85, DOI 10.1145/3331184.3331190
   Wang RY, 1996, JOURNAL OF MANAGEMENT INFORMATION SYSTEMS, V12, P5
   Wint ZZ, 2017, 2017 TWELFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), V0, PP209, DOI 10.1109/ICDIM.2017.8244677
   Young DJ, 1999, MOD LANG J, V83, P350, DOI 10.1111/0026-7902.00027
   Zhang WE, 2020, ACM T INTEL SYST TEC, V11, P0, DOI 10.1145/3374217
   Zhao Z, 2018, P 6 INT C LEARN REPR, V0, P0
NR 41
TC 0
Z9 0
U1 4
U2 14
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD JUN 15
PY 2023
VL 35
IS 1
BP 335
EP 349
DI 10.32604/iasc.2023.026695
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA 2J7AN
UT WOS:000815805200007
DA 2023-11-10
ER

PT J
AU Chari, S
   Acharya, P
   Gruen, DM
   Zhang, OLV
   Eyigoz, EK
   Ghalwash, M
   Seneviratne, O
   Saiz, FS
   Meyer, P
   Chakraborty, P
   McGuinness, DL
AF Chari, Shruthi
   Acharya, Prasant
   Gruen, Daniel M.
   Zhang, Olivia
   Eyigoz, Elif K.
   Ghalwash, Mohamed
   Seneviratne, Oshani
   Saiz, Fernando Suarez
   Meyer, Pablo
   Chakraborty, Prithwish
   McGuinness, Deborah L.
TI Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE User-driven; Clinical explainability; Contextual explanations; Question-answering approach; Type-2 diabetes comorbidity risk prediction
ID advanced terminology; practice guidelines
AB Medical experts may use Artificial Intelligence (AI) systems with greater trust if these are supported by 'contextual explanations' that let the practitioner connect system inferences to their context of use. However, their importance in improving model usage and understanding has not been extensively studied. Hence, we consider a comorbidity risk prediction scenario and focus on contexts regarding the patients' clinical state, AI predictions about their risk of complications, and algorithmic explanations supporting the predictions. We explore how relevant information for such dimensions can be extracted from Medical guidelines to answer typical questions from clinical practitioners. We identify this as a question answering (QA) task and employ several state-of-the-art Large Language Models (LLM) to present contexts around risk prediction model inferences and evaluate their acceptability. Finally, we study the benefits of contextual explanations by building an end-to-end AI pipeline including data cohorting, AI risk modeling, post-hoc model explanations, and prototyped a visual dashboard to present the combined insights from different context dimensions and data sources, while predicting and identifying the drivers of risk of Chronic Kidney Disease (CKD) -a common type-2 diabetes (T2DM) comorbidity. All of these steps were performed in deep engagement with medical experts, including a final evaluation of the dashboard results by an expert medical panel. We show that LLMs, in particular BERT and SciBERT, can be readily deployed to extract some relevant explanations to support clinical usage. To understand the value-add of the contextual explanations, the expert panel evaluated these regarding actionable insights in the relevant clinical setting. Overall, our paper is one of the first end-to-end analyses identifying the feasibility and benefits of contextual explanations in a real-world clinical use case. Our findings can help improve clinicians' usage of AI models.
C1 [Chari, Shruthi; Acharya, Prasant; Gruen, Daniel M.; Seneviratne, Oshani; McGuinness, Deborah L.] Rensselaer Polytech Inst, 110 8th St, Troy, NY 12180 USA.
   [Zhang, Olivia; Eyigoz, Elif K.; Ghalwash, Mohamed; Meyer, Pablo; Chakraborty, Prithwish] IBM Res, Ctr Computat Hlth, 1101 Kitchawan Rd, Yorktown Hts, NY 10598 USA.
   [Saiz, Fernando Suarez] IBM Watson Hlth, 75 Binney St, Cambridge, MA 02142 USA.
C3 Rensselaer Polytechnic Institute; International Business Machines (IBM)
RP Chari, S (通讯作者)，Rensselaer Polytech Inst, 110 8th St, Troy, NY 12180 USA.
EM charis@rpi.edu
CR Agosti M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP973, DOI 10.1145/3331184.3331289
   Amer Diabet Assoc, 2014, DIABETES CARE, V37, PS14, DOI 10.2337/dc14-S014
   [Anonymous], 2021, CHRONIC KIDNEY DIS B, V0, P0
   [Anonymous], 2021, CHRONIC DIS, V0, P0
   Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733
   Arya V, 2019, ARXIV, V0, P0
   Banning M, 2008, J CLIN NURS, V17, P187, DOI 10.1111/j.1365-2702.2006.01791.x
   Briganti G, 2020, FRONT MED-LAUSANNE, V7, P0, DOI 10.3389/fmed.2020.00027
   Chakraborty P, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP3547, DOI 10.1145/3394486.3406470
   Challener DW, 2019, JAMA-J AM MED ASSOC, V321, P2405, DOI 10.1001/jama.2019.5284
   Chari Shruthi, 2020, THE SEMANTIC WEB - ISWC 2020. 19TH INTERNATIONAL SEMANTIC WEB CONFERENCE. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12507), V0, PP228, DOI 10.1007/978-3-030-62466-8_15
   Chari S, 2020, STUD SEMANTIC WEB, V47, P245, DOI 10.3233/SSW200022
   Chari S, 2020, STUD SEMANTIC WEB, V47, P23, DOI 10.3233/SSW200010
   Chari S, 2019, LECT NOTES COMPUT SC, V11779, P53, DOI 10.1007/978-3-030-30796-7_4
   Devlin J, 2018, ACL ANTHOL, V0, P0
   Dey AK, 1998, KNOWL-BASED SYST, V11, P3, DOI 10.1016/S0950-7051(98)00053-7
   Dey S, 2022, PATTERNS, V3, P0, DOI 10.1016/j.patter.2022.100493
   Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390
   Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279
   Doshi-Velez F, 2017, ARXIV, V0, P0
   Främling K, 2020, LECT NOTES ARTIF INT, V12175, P57, DOI 10.1007/978-3-030-51924-7_4
   Gatta R, 2019, LECT NOTES BUS INF P, V362, P545, DOI 10.1007/978-3-030-37453-2_44
   Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, PE745, DOI 10.1016/S2589-7500(21)00208-9
   Gilpin LH, 2018, PR INT CONF DATA SC, V0, PP80, DOI 10.1109/DSAA.2018.00018
   Graham R, 2011, CLINICAL PRACTICE GUIDELINES WE CAN TRUST, V0, P1
   Gunning D, 2017, EXPLAINABLE ARTIFICI, V2, P2, DOI 10.1126/SCIROBOTICS.AAY7120
   Gurumoorthy KS, 2019, IEEE DATA MINING, V0, PP260, DOI 10.1109/ICDM.2019.00036
   Hagberg AA, 2008, P PYTH SCI C, V0, P0
   Hematialam H, 2021, IDENTIFYING CONDITIO, V0, P0
   HuggingFace, 2022, BIOCLINICALBERT ADR, V0, P0
   Hussain M, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11083296
   Knoll T, 2022, ARXIV, V0, P0
   Lakkaraju Himabindu, 2022, ARXIV, V0, P0
   Lamy JB, 2015, STUD HEALTH TECHNOL, V210, P924, DOI 10.3233/978-1-61499-512-8-924
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Liao QV, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI20), V0, P0, DOI DOI 10.1145/3313831.3376590
   Lieberman H, 2000, IBM SYST J, V39, P617, DOI 10.1147/sj.393.0617
   Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0
   McKinney W, 2011, PYTHON HIGH PERFORM, V14, P1, DOI 10.1002/MMCE.20381
   Murad MH, 2017, MAYO CLIN PROC, V92, P423, DOI 10.1016/j.mayocp.2017.01.001
   Natarajan K, 2010, INT J MED INFORM, V79, P515, DOI 10.1016/j.ijmedinf.2010.03.004
   Otegi A, 2020, P 1 WORKSHOP NLP COV, V0, P0, DOI DOI 10.18653/v1/2020.nlpcovid19-2.15
   Patel C, 2007, LECT NOTES COMPUT SC, V4825, P816
   Pollard TJ, 2018, JAMIA OPEN, V1, P26, DOI 10.1093/jamiaopen/ooy012
   Raghu Aniruddh, 2021, CHIL 21: PROCEEDINGS OF THE CONFERENCE ON HEALTH, V0, P0
   Riaño D, 2019, ARTIF INTELL MED, V100, P0, DOI 10.1016/j.artmed.2019.101713
   Richardson Leonard, 2007, BEAUTIFUL SOUP DOCUM, V0, P0
   Rieger Laura, 2020, INT C MACH LEARN, V0, PP8116, DOI 10.1109/ICPR56361.2022.9956427
   Rosner AL, 2012, J BODYW MOV THER, V16, P42, DOI 10.1016/j.jbmt.2011.05.003
   Rufibach K, 2010, J CLIN EPIDEMIOL, V63, P938, DOI 10.1016/j.jclinepi.2009.11.009
   Sarrouti M, 2020, ARTIF INTELL MED, V102, P0, DOI 10.1016/j.artmed.2019.101767
   Schlegel Daniel R, 2019, AMIA ANNU SYMP PROC, V2019, P784
   Seroussi B, 2018, STUD HEALTH TECHNOL, V255, P190, DOI 10.3233/978-1-61499-921-8-190
   Shortliffe EH, 1974, MYCIN RULE BASTED CO, V0, P0
   Sittig DF, 2008, J BIOMED INFORM, V41, P387, DOI 10.1016/j.jbi.2007.09.003
   Suryanarayanan P, 2021, ARXIV, V0, P0
   SWARTOUT W, 1991, IEEE EXPERT, V6, P58, DOI 10.1109/64.87686
   Müller ST, 2021, ARXIV, V0, P0
   Teufel S, 2007, TEXT SPEECH LANG TEC, V37, P163
   Tonekaboni S, 2019, P 4 MACH LEARN HEALT, V0, P359
   Videha Sharma IA, 2021, BMJ HEALTH CARE INFO, V28, P0
   Wang DD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290605.3300831
   Weber R, 2021, ARXIV, V0, P0
   Wolf T, 2020, ARXIV, V0, P0
   Yao H, 2021, ADV NEURAL INF PROCE, V34, P0
   Yoon W, 2019, PKDDECML WORKSHOPS, V0, P0
   Yu Chen, 2021, WSDM 21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP544, DOI 10.1145/3437963.3441816
   Yu Gu, 2022, ACM TRANSACTIONS ON COMPUTING AND HEALTHCARE, V3, P0, DOI 10.1145/3458754
   Zhang X, 2021, IEEE T NEUR NET LEAR, V0, P0
NR 69
TC 1
Z9 1
U1 4
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD MAR 15
PY 2023
VL 137
IS 
BP 
EP 
DI 10.1016/j.artmed.2023.102498
EA FEB 2023
PG 25
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA 8Z3AV
UT WOS:000933256300001
PM 36868690
DA 2023-11-10
ER

PT J
AU Li, L
   Tayir, T
   Han, YF
   Tao, XH
   Velásquez, JD
AF Li, Lin
   Tayir, Turghun
   Han, Yifeng
   Tao, Xiaohui
   Velasquez, Juan D.
TI Multimodality information fusion for automated machine translation
SO INFORMATION FUSION
LA English
DT Article
DE Multimodal fusion; Machine translation; Multimodal alignment; Semi-supervised learning
ID network
AB Machine translation is a popular automation approach for translating texts between different languages. Although traditionally it has a strong focus on natural language, images can potentially provide an additional source of information in machine translation. However, there are presently two challenges: (i) the lack of an effective fusion method to handle the triangular-mapping function between image, text, and semantic knowledge; and (ii) the accessibility of large-scale parallel corpus to train a model for generating accurate machine translations. To address these challenges, this work proposes an effective multimodality information fusion method for automated machine translation based on semi-supervised learning. The method fuses multimodality information, texts and images to deliver automated machine translation. Specifically, our objective fuses multimodalities with alignment in a multimodal attention network, which advances the method through the power of mapping text and image features to their semantic information with accuracy. Moreover, a semi-supervised learning method is utilized for its capability in using a small number of parallel corpus for supervised training on the basis of unsupervised training. Conducted on the Multi30k dataset, the experimental results shows the promising performance of our proposed fusion method compared with state-of-the-art approaches.
C1 [Li, Lin; Tayir, Turghun; Han, Yifeng] Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan, Peoples R China.
   [Tao, Xiaohui] Univ Southern Queensland, Sch Math Phys & Comp, Toowoomba, Australia.
   [Velasquez, Juan D.] Inst Sistemas Complejos Ingn, ISCI, Santiago Centro, Chile.
   [Velasquez, Juan D.] Univ Chile, Fac Phys & Math Sci, Dept Ind Engn, Santiago, Chile.
C3 Wuhan University of Technology; University of Southern Queensland; Universidad de Chile
RP Li, L (通讯作者)，Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan, Peoples R China.
EM cathylilin@whut.edu.cn; hotpes@whut.edu.cn; tahanyifeng1110@whut.edu.cn; xiaohui.tao@usq.edu.au; jvelasqu@dii.uchile.cl
FU National Natural Science Foundation of China [2021BAA030]; Department of Science and Technology of Hubei Province, China [PIA/APOYO AFB180003]; Australian Research Council [DP220101360];  [62276196]
CR Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Bahdanau D, 2015, P 3 ICLR SAN DIEG CA, V0, P1
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Brown PF, 1993, COMPUTATIONAL LINGUISTICS, V19, P263
   Brown PF, 1990, COMPUTATIONAL LINGUISTICS, V16, P79
   Caglayan O, 2016, 1 C MACH TRANSL, V0, P627
   Caglayan O, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1317
   Caglayan O, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4159
   Calixto I, 2017, P 2017 C EMP METH NA, V0, PP992, DOI 10.18653/V1/D17-1105
   Calixto I, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1913, DOI 10.18653/v1/P17-1175
   Chen F, 2021, P FINDINGS ASS COMPU, V0, P436
   Chen SZ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4932
   Cheng Y, 2016, P 25 INT JOINT C ART, V0, P2761
   Cheng Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1965
   Deng J, 2009, COMPUTER VISION PATT, V0, PP248, DOI 10.1109/CVPR.2009.5206848
   Elliott D, 2017, 2 C MACHINE TRANSLAT, V0, P215
   Elliott D, 2016, P ACL 2016, V0, P70
   Gehring J, 2017, PR MACH LEARN RES, V70, P0
   Gronroos S, 2018, 3 C MACH TRANSL, V0, P603
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Helcl Jindrich, 2018, P WMT 2018, V0, P616
   Hokamp Chris, 2017, P 2 C MACH TRANSL, V0, PP647, DOI 10.18653/V1/W17-4775
   Huang P, 2021, ICASSP 2021 2021 IEE, V0, P7548
   Huang P-Y, 2016, P 1 C MACH TRANSL, V2, P639, DOI 10.18653/V1/W16-2360
   Huang Po-Yao, 2020, P 58 ANN M ASS COMP, V0, PP8226, DOI 10.18653/V1/2020.ACL-MAIN.731
   Imamura K, 2017, P 4 WORKSH AS TRANSL, V0, P0
   Johnson R, 2015, P 2015 C N AM CHAPTE, V0, P103
   Kalchbrenner N, 2013, RECURRENT CONTINUOUS, V0, P0
   Kingma DP, 2015, PROC ICLR 2015, V0, P0
   Lample G, 2018, INT C LEARNING REPRE, V0, P0
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5039
   Lavie A, 2007, P 2 WORKSHOP STAT MA, V0, P228
   Li B, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6327
   Li L, 2021, PACIFIC RIM INT C AR, V0, P311
   Li Y, 2021, BMC GENOMICS, V22, P1, DOI 10.1186/S12859-016-1414-X
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Lin H, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1320, DOI 10.1145/3394171.3413715
   Lin Li, 2021, 2021 IEEE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR), V0, PP267, DOI 10.1109/MIPR51284.2021.00050
   Liu P, 2021, ARXIV, V0, P0
   Liu X, 2021, INFORM FUSION, V69, P73, DOI 10.1016/j.inffus.2020.11.011
   Madhyastha Pranava Swaroop, 2017, SHARED TASK PAPERS A, V0, P470
   Mohiuddin T, 2020, COMPUT LINGUIST, V46, P257, DOI 10.1162/coli_a_00374
   Papineni K, 2002, BLEU METHOD AUTOMATI, V0, P311
   Qian X, 2018, ARXIV, V0, P0
   Sennrich Rico, 2016, P 1 C MACHINE TRANSL, V2, P371, DOI 10.18653/V1/W16-2323
   Simonyan K, 2015, ARXIV, V0, P0
   Skorokhodov I, 2018, P AMTA 2018 WORKSH T, V0, P37
   Specia Lucia, 2016, P 1 C MACH TRANSL, V0, PP543, DOI 10.18653/V1/W16-2346
   Su YH, 2019, PROC CVPR IEEE, V0, PP10474, DOI 10.1109/CVPR.2019.01073
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Szegedy C, 2016, RETHINKING INCEPTION, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan L, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), V0, PP63, DOI 10.1109/BigMM50055.2020.00019
   Vaswani A, 2017, ARXIV, V30, P5998
   Vincent P, 2008, P 25 INT C MACH LEAR, V0, P1096
   Wang WL, 2018, PR MACH LEARN RES, V84, P0
   Wang YR, 2020, AAAI CONF ARTIF INTE, V34, P6291
   Wang YH, 2021, AAAI CONF ARTIF INTE, V35, P10236
   Wu Zhiyong, 2021, P 59 ANN M ASS COMP, V1, P6153, DOI 10.18653/V1/2021.ACL-LONG
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu Weijia, 2020, FINDINGS ASS COMPUTA, V0, P2006
   Yanan Shi, 2021, CHINESE COMPUTATIONAL LINGUISTICS: 20TH CHINA NATIONAL CONFERENCE, V0, Proceedings. Lecture Notes in Computer Science
   Yao SW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4346
   Yifeng Han, 2020, ICMR 20: PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP571, DOI 10.1145/3372278.3390717
   Young P, 2014, T ASSOC COMPUT LING, V2, P67
   Yu J, 2021, IEEE T IMAGE PROCESS, V30, P220, DOI 10.1109/TIP.2020.3034494
   Yuan GR, 2020, 2020 12TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), V0, PP269, DOI 10.1109/icaci49185.2020.9177805
   Yupan Huang, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1138, DOI 10.1145/3474085.3481540
   Zhang WF, 2020, INFORM FUSION, V55, P116, DOI 10.1016/j.inffus.2019.08.009
   Zhang Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P155, DOI 10.18653/v1/P17-2024
   Zhang ZX, 2022, NEUROCOMPUTING, V473, P182, DOI 10.1016/j.neucom.2021.12.005
   Zhao R, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3068391
   Zhou M, 2018, P EMPIRICAL METHODS, V0, PP3643, DOI 10.18653/v1/D18-1400
NR 72
TC 2
Z9 2
U1 13
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD MAR 15
PY 2023
VL 91
IS 
BP 352
EP 363
DI 10.1016/j.inffus.2022.10.018
EA NOV 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA 6Q9FK
UT WOS:000891915100006
DA 2023-11-10
ER

PT J
AU Qiao, SJ
   Liu, CX
   Yang, GP
   Han, N
   Peng, YH
   Wu, LC
   Li, H
   Yuan, G
AF Qiao, Shaojie
   Liu, Chenxu
   Yang, Guoping
   Han, Nan
   Peng, Yuhan
   Wu, Lingchun
   Li, He
   Yuan, Guan
TI GTR: An SQL Generator With Transition Representation in Cross-Domain Database Systems
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Automatic SQL generator; cross-domain database; grammar-based neural model; natural language (NL); NL-to-SQL learning system; transition representation (TR)
ID text-to-sql; natural-language
AB Recent studies have focused on using natural language (NL) to automatically retrieve useful data from database (DB) systems. As an important component of autonomous DB systems, the NL-to-SQL technique can assist DB administrators in writing high-quality SQL statements and make persons with no SQL background knowledge learn complex SQL languages. However, existing studies cannot deal with the issue that the expression of NL inevitably mismatches the implementation details of SQLs, and the large number of out-of-domain (OOD) words makes it difficult to predict table columns. In particular, it is difficult to accurately convert NL into SQL in an end-to-end fashion. Intuitively, it facilitates the model to understand the relations if a "bridge" transition representation (TR) is employed to make it compatible with both NL and SQL in the phase of conversion. In this article, we propose an automatic SQL generator with TR called GTR in cross-domain DB systems. Specifically, GTR contains three SQL generation steps: 1) GTR learns the relation between questions and DB schemas; 2) GTR uses a grammar-based model to synthesize a TR; and 3) GTR predicts SQL from TR based on the rules. We conduct extensive experiments on two commonly used datasets, that is, WikiSQL and Spider. On the testing set of the Spider and WikiSQL datasets, the results show that GTR achieves 58.32% and 71.29% exact matching accuracy which outperforms the state-of-the-art methods, respectively.
C1 [Qiao, Shaojie; Liu, Chenxu; Yang, Guoping; Peng, Yuhan; Wu, Lingchun] Chengdu Univ Informat Technol, Sch Software Engn, Chengdu 610225, Peoples R China.
   [Han, Nan] Chengdu Univ Informat Technol, Sch Management, Chengdu 610225, Peoples R China.
   [Li, He] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
   [Yuan, Guan] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
C3 Chengdu University of Information Technology; Chengdu University of Information Technology; Xidian University; China University of Mining & Technology
RP Han, N (通讯作者)，Chengdu Univ Informat Technol, Sch Management, Chengdu 610225, Peoples R China.
EM shaojieqiao@163.com; liuchenxv@foxmail.com; 3200706035@stu.cuit.edu.cn; hannan@cuit.edu.cn; 782690133@qq.com; wulingchun1021@gmail.com; heli@xidian.edu.cn; yuanguan@cumt.edu.cn
FU National Natural Science Foundation of China [62272066, 61962006]; Sichuan Science and Technology Program [2021JDJQ0021, 2022YFG0186, 2022NSFSC0511, 2023YFG0027]; Planning Foundation for Humanities and Social Sciences of Ministry of Education of China [22YJAZH088]; Chengdu Major Science and Technology Innovation Project [2021-YF08-00156-GX]; High-LevelTalent Introduction Project of Yibin [2022YG02]; Chengdu Technology Innovation and Research and Development Project [2021-YF05-02413-GX, 2021-YF05-02414-GX]; Chengdu "Take the Lead" Science and Technology Project [2022-JB00-00002-GX, 2021-JB00-00025-GX]; National Intelligent Society Governance Experimental Base Foundation of Chengdu University of Information Technology [ZNZL2023B05]; Humanities and Social Science Research Base of the Sichuan Provincial Education Department [WLWH22-1]; Science and Technology Innovation Capability Improvement Project of Chengdu University of Information Technology [KYTD202222]
CR Abbas S, 2022, IEEE ACCESS, V10, P14927, DOI 10.1109/ACCESS.2022.3147586
   Bogin B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3659
   Bukhari SAC, 2021, INT J DATA WAREHOUS, V17, P21, DOI 10.4018/IJDWM.2021040102
   Chang SC, 2020, AAAI CONF ARTIF INTE, V34, P7488
   Choi D, 2021, COMPUT LINGUIST, V47, P309, DOI 10.1162/coli_a_00403
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   GROSZ BJ, 1987, ARTIF INTELL, V32, P173, DOI 10.1016/0004-3702(87)90011-7
   Gui T, 2019, AAAI CONF ARTIF INTE, V0, P6481
   Guo AB, 2021, NEUROCOMPUTING, V465, P359, DOI 10.1016/j.neucom.2021.08.134
   Guo JQ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2316
   Guo JQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4524
   Hendrix GG, 1978, ACM TRANSACTIONS ON DATABASE SYSTEMS, V3, P105, DOI 10.1145/320251.320253
   Hwang W, 2019, ARXIV, V0, P0
   Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089
   José MM, 2022, LECT NOTES ARTIF INT, V13208, P278, DOI 10.1007/978-3-030-98305-5_26
   Kingma DP, 2015, PROC ICLR 2015, V0, P0
   Liu HT, 2020, IEEE T NEUR NET LEAR, V31, P4405, DOI 10.1109/TNNLS.2019.2957109
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Qiao SJ, 2021, J COMPUT SCI TECH-CH, V36, P762, DOI 10.1007/s11390-021-1351-7
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3679
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tang LR, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, V0, P133
   Usta A, 2021, PROC VLDB ENDOW, V14, P813, DOI 10.14778/3446095.3446103
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang B, 2020, P 58 ANN M ASS COMP, V0, P7567
   Warren DHD, 1982, AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS, V8, P110
   Xu XJ, 2017, ARXIV, V0, P0
   Yang HF, 2020, IEEE T NEUR NET LEAR, V31, P3145, DOI 10.1109/TNNLS.2019.2936876
   Yin PC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P440, DOI 10.18653/v1/P17-1041
   Yu T, 2018, P 2018 C N AM CHAPT, V2, P588
   Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1653
   Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3911
   Zhong VC, 2017, ARXIV, V0, P0
   Zhong V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6869
NR 35
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2023.3309824
EA SEP 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA R5FQ0
UT WOS:001064610000001
PM 37672375
DA 2023-11-10
ER

PT J
AU Ackerman, S
   Alexander, L
   Bennett, M
   Chen, DL
   Farchi, E
   Houseknecht, A
   Santhanam, P
AF Ackerman, Samuel
   Alexander, Lincoln
   Bennett, Margaret
   Chen, Donglin
   Farchi, Eitan
   Houseknecht, Autumn
   Santhanam, Padmanabhan
TI Deploying automated ticket router across the enterprise
SO AI MAGAZINE
LA English
DT Article
AB With the recent advances in machine learning, the use of natural language processing (NLP) technology to support various business processes has been increasing. This paper discusses the use of NLP to route more than one million live client tickets annually to the appropriate service personnel in 67 support missions across IBM. Each mission supports a product family with multiple support teams, each requiring different skills for the engineers. We discuss three important aspects of such a large-scale deployment: (i) The use of a centralized team with a common machine learning infrastructure and practices to support the entire enterprise. (ii) The processes and quality of such a deployment from the perspective of one support mission, namely, IBM's z/OS family. (iii) Careful monitoring of the deployed models to detect drifts in the routing behavior. Despite vast differences in the technical contents of the support missions, it is possible to define common processes and metrics across the enterprise, without requiring a dedicated machine learning team for each mission. In addition, we provide examples of the business policies and metrics from the perspective of the z/OS mission to demonstrate the utility of the approach and the outcome.
C1 [Ackerman, Samuel; Farchi, Eitan] IBM Haifa Res Labs, Haifa, Israel.
   [Alexander, Lincoln; Chen, Donglin] IBM Corp, Armonk, NY USA.
   [Bennett, Margaret] IBM Infrastruct, Markham, ON, Canada.
   [Houseknecht, Autumn] IBM Infrastruct, Poughkeepsie, NY USA.
   [Santhanam, Padmanabhan] IBM Res, Yorktown Hts, NY 10598 USA.
C3 International Business Machines (IBM); International Business Machines (IBM); International Business Machines (IBM)
RP Santhanam, P (通讯作者)，IBM Res, Yorktown Hts, NY 10598 USA.
EM pasanth@us.ibm.com
CR Chen Donglin, 2020, MEDIUM, V0, P0
   Cristian Matei, 2019, INT C SOFTW TEL COMP, V0, P1893
   DataBricks, 2018, ENT AI AD, V0, P0
   Fuchs S, 2022, P 55 HAW INT C SYST, V0, P1893
   Gama J, 2004, LECT NOTES ARTIF INT, V3171, P286
   Han Jianglei, 2020, IEEE INT C SERV COMP, V0, P0
   Hill Steve, 2019, TRANSFORMING ENTERPR, V0, P0
   IBM, 2022, IBM COD ENG, V0, P0
   Lorica Ben, 2019, AI ADOPTION ENTERPRI, V0, P0
   Montiel J, 2021, J MACH LEARN RES, V22, P0
   Paramesh SP, 2018, P DATA ANAL LEARNING, V0, P0
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Powell Michael, 2020, P AAAI C ART INT, V34, P0
   Reichheld FF, 2003, HARVARD BUS REV, V81, P46
   Reinecke Thomas, 2018, MEDIUM, V0, P0
   Reza Motahari-Nezhad Hamid, 2011, INT C BUS PROC MAN, V0, P0
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Xu J, 2018, DATA KNOWL ENG, V116, P205, DOI 10.1016/j.datak.2018.06.004
   Zhang D, 2022, AI INDEX 2022 ANN RE, V0, P0
NR 19
TC 0
Z9 0
U1 0
U2 0
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
EI 2371-9621
J9 AI MAG
JI AI Mag.
PD MAR 15
PY 2023
VL 44
IS 1
BP 97
EP 111
DI 10.1002/aaai.12079
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA C6PB3
UT WOS:000963102400009
DA 2023-11-10
ER

PT J
AU Hanzlícek, Z
   Matousek, J
   Vít, J
AF Hanzlicek, Zdenek
   Matousek, Jindrich
   Vit, Jakub
TI Using LSTM neural networks for cross-lingual phonetic speech segmentation with an iterative correction procedure
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article; Early Access
DE LSTM neural networks; multi-lingual and cross-lingual modeling; speech segmentation
ID automatic segmentation; alignment
AB This article describes experiments on speech segmentation using long short-term memory recurrent neural networks. The main part of the paper deals with multi-lingual and cross-lingual segmentation, that is, it is performed on a language different from the one on which the model was trained. The experimental data involves large Czech, English, German, and Russian speech corpora designated for speech synthesis. For optimal multi-lingual modeling, a compact phonetic alphabet was proposed by sharing and clustering phones of particular languages. Many experiments were performed exploring various experimental conditions and data combinations. We proposed a simple procedure that iteratively adapts the inaccurate default model to the new voice/language. The segmentation accuracy was evaluated by comparison with reference segmentation created by a well-tuned hidden Markov model-based framework with additional manual corrections. The resulting segmentation was also employed in a unit selection text-to-speech system. The generated speech quality was compared with the reference segmentation by a preference listening test.
C1 [Hanzlicek, Zdenek; Matousek, Jindrich; Vit, Jakub] Univ West Bohemia, Fac Appl Sci, NTIS New Technol Informat Soc, Plzen, Czech Republic.
   [Hanzlicek, Zdenek] Univ West Bohemia, Fac Appl Sci, NTIS New Technol Informat Soc, Tech 8, Plzen 30100, Czech Republic.
C3 University of West Bohemia Pilsen; University of West Bohemia Pilsen
RP Hanzlícek, Z (通讯作者)，Univ West Bohemia, Fac Appl Sci, NTIS New Technol Informat Soc, Tech 8, Plzen 30100, Czech Republic.
EM zhanzlic@ntis.zcu.cz
FU Grantova Agentura Ceske Republiky
CR Adell J, 2005, INT CONF ACOUST SPEE, V0, P309
   Adell J, 2004, P 5 ISCA WORKSH SPEE, V0, P139
   Anderson O, 1994, P ICASSP 94 IEEE INT, V0, P121
   Ball MJ, 2018, J INT PHON ASSOC, V48, P155, DOI 10.1017/S0025100317000147
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bhagath P, 2019, TENCON IEEE REGION, V0, PP1764, DOI 10.1109/TENCON.2019.8929673
   Brognaux S, 2016, IEEE-ACM T AUDIO SPE, V24, P5, DOI 10.1109/TASLP.2015.2456421
   BRUGNARA F, 1993, SPEECH COMMUN, V12, P357, DOI 10.1016/0167-6393(93)90083-W
   Dong L, 2014, THESIS, V0, P0
   Dusan S, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P645
   Finster H, 1992, IJCNN INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (CAT. NO.92CH3114-6), V0, PP734, DOI 10.1109/IJCNN.1992.227231
   Franke J, 2016, ITG S, V0, P1
   Garofolo J, 1990, DARPA TIMIT ACOUSTIC, V0, P0
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hanzlicek Z, 2020, LECT NOTES ARTIF INT, V12284, P456, DOI 10.1007/978-3-030-58323-1_49
   Haubold A, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P224
   Hieronymus JL, 1994, ASCII PHONETIC SYMBO, V0, P0
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hoffmann S, 2013, TEXT TO SPEECH ALIGN, V0, PP1520, DOI 10.21437/Interspeech.2013-307
   Hoffmann S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1389
   Horak P, 2001, 33 IMPROVEMENTS SPEE, V0, P328
   Hosom JP, 2009, SPEECH COMMUN, V51, P352, DOI 10.1016/j.specom.2008.11.003
   Hunt MJ, 1984, ICASSP 84 IEEE INT C, V0, P251
   International Phonetic Association, 1999, HDB INT PHON ASS GUI, V0, P0
   Kalinli O, 2012, AUTOMATIC PHONEME SE, V0, P2270
   Karafiát M, 2016, IEEE W SP LANG TECH, V0, PP637, DOI 10.1109/SLT.2016.7846330
   Kawai H, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P677
   Kelley MC, 2018, INTERSPEECH, V0, P1205
   Keshet J, 2005, PROC INTERSPEECH 200, V0, PP2961, DOI 10.21437/Interspeech.2005-129
   Kingma DP, 2014, C TRACK P, V0, P0
   Kirshenbaum E, 2011, REPRESENTING IPA PHO, V0, P0
   Kiss G, 2013, INT CONF COGN INFO, V0, PP579, DOI 10.1109/CogInfoCom.2013.6719169
   Kominek J, 2003, P 8 EUR C SPEECH COM, V0, PP313, DOI 10.21437/Eurospeech.2003-127
   Kominek J, 2004, P INTERSPEECH 2004 I, V0, PP1385, DOI 10.21437/Interspeech.2004-458
   Kreuk F, 2020, INT CONF ACOUST SPEE, V0, PP8089, DOI 10.1109/ICASSP40776.2020.9053053
   Lachachi N, 2017, J TELECOMMUN INFORM, V1, P12
   Le VB, 2009, IEEE T AUDIO SPEECH, V17, P1471, DOI 10.1109/TASL.2009.2021723
   LENNIG M, 1983, SPEECH COMMUN, V2, P190, DOI 10.1016/0167-6393(83)90025-0
   Leontiev NA, 2019, INT MULTI C IND ENG, V0, PP1, DOI 10.1109/FarEastCon.2019.8934239
   Leow SJ, 2015, INT CONF ACOUST SPEE, V0, PP5813, DOI 10.1109/ICASSP.2015.7179086
   Li M, 2016, 9 ISCA SPEECH SYNTHE, V0, PP196, DOI 10.21437/SSW.2016-32
   Liu CJ, 2016, INT CONF ACOUST SPEE, V0, PP5020, DOI 10.1109/ICASSP.2016.7472633
   LJOLJE A, 1991, INT CONF ACOUST SPEE, V0, PP473, DOI 10.1109/ICASSP.1991.150379
   Lo HY, 2007, INT CONF ACOUST SPEE, V0, P933
   Luo JQ, 2021, INT J ELEC ENG EDUC, V0, P0, DOI DOI 10.1177/0020720920983554
   MacKenzie L, 2020, LINGUIST VANGUARD, V6, P0, DOI 10.1515/lingvan-2018-0061
   Malfrère F, 2003, SPEECH COMMUN, V40, P503, DOI 10.1016/S0167-6393(02)00131-0
   Matouesek J, 2003, P EUROSPEECH 2003, V0, P301
   Matousek J, 2003, LECT NOTES ARTIF INT, V2807, P287
   Matousek J, 2008, P 6 INT C LANG RES E, V0, P0
   Matousek J, 2017, LECT NOTES ARTIF INT, V10415, P138, DOI 10.1007/978-3-319-64206-2_16
   Matousek J, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1626
   Mizera P, 2018, LECT NOTES ARTIF INT, V11096, P419, DOI 10.1007/978-3-319-99579-3_44
   Vu NT, 2014, INT CONF ACOUST SPEE, V0, P0, DOI DOI 10.1109/ICASSP.2014.6855086
   Park SS, 2007, IEEE T AUDIO SPEECH, V15, P2202, DOI 10.1109/TASL.2007.903933
   Park SS, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2066
   Paulo S, 2003, P EUROSPEECH 2003, V0, PP309, DOI 10.21437/Eurospeech.2003-126
   Peng WJ, 2021, 2021 12TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), V0, P0, DOI DOI 10.1109/ISCSLP49672.2021.9362107
   Povey Daniel, 2011, IEEE 2011 WORKSH AUT, V0, P0
   Qiao Y, 2008, INT CONF ACOUST SPEE, V0, P3989
   Ramteke PB, 2019, SPEECH COMMUN, V107, P1, DOI 10.1016/j.specom.2019.01.003
   Räsänen OJ, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1811
   Reddi SJ, 2018, P 6 INT C LEARN REPR, V0, P0
   Reichl W, 1993, P EUR 1993 ISCA, V0, P1771
   Rendel A, 2012, INT CONF ACOUST SPEE, V0, PP4533, DOI 10.1109/ICASSP.2012.6288926
   Sangeetha S, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, V0, P864, DOI 10.1109/ICICICT46008.2019.8993408
   Saon G, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP55, DOI 10.1109/ASRU.2013.6707705
   Scharenborg O, 2010, J ACOUST SOC AM, V127, P1084, DOI 10.1121/1.3277194
   Schultz T, 2001, SPEECH COMMUN, V35, P31, DOI 10.1016/S0167-6393(00)00094-7
   Schultz T, 2013, INT CONF ACOUST SPEE, V0, PP8126, DOI 10.1109/ICASSP.2013.6639248
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Smirnov VM, 2019, 2019 WAVE ELECTRONICS AND ITS APPLICATION IN INFORMATION AND TELECOMMUNICATION SYSTEMS (WECONF), V0, P0
   Smith LN, 2017, IEEE WINT CONF APPL, V0, PP464, DOI 10.1109/WACV.2017.58
   Stolcke Andreas, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5552, DOI 10.1109/ICASSP.2014.6854665
   Tihelka D, 2018, LECT NOTES ARTIF INT, V11107, P369, DOI 10.1007/978-3-030-00794-2_40
   Tihelka D, 2013, LECT NOTES COMPUT SC, V8082, P442, DOI 10.1007/978-3-642-40585-3_56
   Toledano DT, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0205355
   Toledano DT, 2000, INT CONF ACOUST SPEE, V0, PP3438, DOI 10.1109/ICASSP.2000.860140
   Torre Toledano D, 1998, P 3 ESCA COCOSDA WOR, V0, P207
   Vachhani B, 1900, V10415, V0, P0, DOI DOI 10.1007/978-3-319-64206-2_44
   Vít J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5684, DOI 10.1109/ICASSP.2018.8461960
   Wagner M, 1981, ICASSP 81. PROCEEDINGS OF THE 1981 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P1156
   Wells JC, 2016, COMPUTER CODING IPA, V0, P0
   Wells John C, 1997, HDB STANDARDS RESOUR, V0, P0
   Wightman CW, 1900, DOI 10.1007/978-1-4612-1894-4_25, V0, P0
   Wong JHM, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6768, DOI 10.1109/ICASSP39728.2021.9413819
   Yuan JH, 2013, INTERSPEECH, V0, P2305
   Ziolko M, 2010, PERCEPTUAL WAVELET D, V0, P2234
   Zue VW, 1996, RECENT RESEARCH TOWARDS ADVANCED MAN-MACHINE INTERFACE THROUGH SPOKEN LANGUAGE, V0, PP515, DOI 10.1016/B978-044481607-8/50088-8
NR 92
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0824-7935
EI 1467-8640
J9 COMPUT INTELL-US
JI Comput. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1111/coin.12602
EA SEP 2023
PG 36
WC Computer Science, Artificial Intelligence
SC Computer Science
GA R8GA8
UT WOS:001066674400001
DA 2023-11-10
ER

PT J
AU Tang, XY
   Zeng, S
   Yu, F
   Yu, W
   Sheng, ZY
   Kang, Z
AF Tang, Xiaoyue
   Zeng, Shan
   Yu, Fang
   Yu, Wei
   Sheng, Zhongyin
   Kang, Zhen
TI Self-supervised anomaly pattern detection for large scale industrial data
SO NEUROCOMPUTING
LA English
DT Article
DE Data augmentation; Anomaly detection; Industrial data
AB Detecting the anomalies in a large amounts of high-dimensional data has been a challenging task. In the Industry 4.0 environment, large-scale high-dimensional monitoring data features the complex pattern of high level semantics. In order to provide enterprise-wide monitoring solutions, it is necessary to identify the high-level semantic patterns of the anomalies in these data without splitting them. Existing end-to-end deep neural networks for time series are capable of recognizing the high-level semantics in natural language or speech signals, but they are barely applied in real-time anomaly detection of industrial data because of the large time costs. In this paper, we leverage the self-supervised contrastive learning methodology and propose a Composite Semantic Augmentation Encoder (CSAE) to provide an appropriate representation of industrial data and implement quick detection of anomalies in industrial application environments. CSAE is a non-sequential deep neural network with two augmentation layers and a mandatory layer. The two layers of data-augmentation are built to expand the size of samples of both low-level semantic anomalies and high-level semantic anomalies, which enables CSAE to discover diverse anomalies and improves its accuracy of high-level semantic pattern recognition. The mandatory layer is built to compress and reserve the temporal information in the industrial data to accelerate the anomaly detection. Therefore, as a non-sequential contrastive learning model, CSAE has faster training convergence than the usual sequence models. The experiment results have verified that CSAE can achieve higher prediction accuracy with less time consumption than existing machine learning models in the tasks of high dimensional anomaly pattern detection. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Tang, Xiaoyue; Zeng, Shan; Sheng, Zhongyin; Kang, Zhen] Wuhan Polytechn Univ, Sch Math & Comp Sci, Wuhan 430023, Hubei, Peoples R China.
   [Yu, Fang; Yu, Wei] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan Polytechnic University; Wuhan University
RP Zeng, S (通讯作者)，Wuhan Polytechn Univ, Sch Math & Comp Sci, Wuhan 430023, Hubei, Peoples R China.
EM zengshan1981@whpu.edu.cn
FU Hubei Natural Science Foundation for Distinguished Young Scholars [U1833119]; excellent young and middle-aged scientific and technological innovation teams in colleges and universities of Hubei Province [2020CFA063];  [T2021009]
CR Boschert S, 2016, MECHATRONIC FUTURES, V0, PP59, DOI 10.1007/978-3-319-32156-1_5
   Chen Ting, 2020, ICML, V0, P0
   Cheng P, 2022, IEEE T CYBERNETICS, V52, P13623, DOI 10.1109/TCYB.2021.3112699
   Cheng PY, 2020, PR MACH LEARN RES, V119, P0
   Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334
   Ding SX, 2009, J PROCESS CONTR, V19, P1496, DOI 10.1016/j.jprocont.2009.07.005
   Djordjevic V, 2022, DISCRETE CONT DYN-S, V15, P1633, DOI 10.3934/dcdss.2021145
   Edwards C, 2021, COMMUN ACM, V64, P9
   Guo Y, 2022, P 39 INT C MACHINE L, V0, P8109
   Hou ZS, 2013, INFORM SCIENCES, V235, P3, DOI 10.1016/j.ins.2012.07.014
   Jaiswal A, 2021, TECHNOLOGIES, V9, P0, DOI 10.3390/technologies9010002
   Jiang QC, 2019, IND ENG CHEM RES, V58, P12899, DOI 10.1021/acs.iecr.9b02391
   Jiang YZ, 2021, IEEE T INTELL TRANSP, V22, P1752, DOI 10.1109/TITS.2020.2973673
   Jiang YC, 2021, IEEE T IND INFORM, V17, P1449, DOI 10.1109/TII.2020.2987840
   Keliris A, 2016, INT TEST CONF P, V0, P0
   Lasi H, 2014, BUS INFORM SYST ENG+, V6, P239, DOI 10.1007/s12599-014-0334-4
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Sun ZY, 2020, IEEE ACCESS, V8, P42141, DOI 10.1109/ACCESS.2020.2977643
   TongzhouWang Phillip, 2020, INT C MACH LEARN, V0, P9929
   Wang F, 2021, PROC CVPR IEEE, V0, PP2495, DOI 10.1109/CVPR46437.2021.00252
   Weiwei Zhu, 2021, JOURNAL OF INTELLIGENT AND CONNECTED VEHICLES, V4, P80, DOI 10.1108/JICV-03-2021-0004
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), V0, P0, DOI DOI 10.1109/IWQoS.2018.8624183
NR 22
TC 2
Z9 2
U1 7
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 1
PY 2023
VL 515
IS 
BP 1
EP 12
DI 10.1016/j.neucom.2022.09.069
EA OCT 2022
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6J6LV
UT WOS:000886934800001
DA 2023-11-10
ER

PT J
AU Agüero-Torales, M
   López-Herrera, AG
   Vilares, D
AF Aguero-Torales, Marvin M.
   Lopez-Herrera, Antonio G.
   Vilares, David
TI Multidimensional Affective Analysis for Low-Resource Languages: A Use Case with Guarani-Spanish Code-Switching Language
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Natural language processing; Sentiment analysis; Affective analysis; Code-switching; Low-resource languages
ID sentiment analysis
AB This paper focuses on text-based affective computing for Jopara, a code-switching language that combines Guarani and Spanish. First, we collected a dataset of tweets primarily written in Guarani and annotated them for three widely used dimensions in sentiment analysis: (a) emotion recognition, (b) humor detection, and (c) offensive language identification. Then, we developed several neural network models, including large language models specifically designed for Guarani, and compared their performance against off-the-shelf multilingual and Spanish pre-trained models for the aforementioned dimensions. Our experiments show that language models incorporating Guarani during pre-training or pre-fine-tuning consistently achieve the best results, despite limited resources (a single 24-GB GPU and only 800K tokens). Notably, even a Guarani BERT model with just two layers of Transformers shows a favorable balance between accuracy and computational power, likely due to the inherent low-resource nature of the task. We present a comprehensive overview of corpus creation and model development for low-resource languages like Guarani, particularly in the context of its code-switching with Spanish, resulting in Jopara. Our findings shed light on the challenges and strategies involved in analyzing affective language in such linguistic contexts.
C1 [Aguero-Torales, Marvin M.; Lopez-Herrera, Antonio G.] Univ Granada, Dept Comp Sci & Artificial Intelligence, Calle Daniel Saucedo Aranda S-N, Granada 18071, Granada, Spain.
   [Vilares, David] Univ A Coruna, Dept Comp Sci & Informat Technol, CITIC, Campus Elvina S-N, La Coruna 15008, A Coruna, Spain.
   [Aguero-Torales, Marvin M.] Global CoE Data Intelligence, Camino Cerro Gamos 1, Madrid 28224, Spain.
C3 University of Granada; Universidade da Coruna
RP Agüero-Torales, M (通讯作者)，Univ Granada, Dept Comp Sci & Artificial Intelligence, Calle Daniel Saucedo Aranda S-N, Granada 18071, Granada, Spain.; Agüero-Torales, M (通讯作者)，Global CoE Data Intelligence, Camino Cerro Gamos 1, Madrid 28224, Spain.
EM maguero@correo.ugr.es; lopez-herrera@decsai.ugr.es; david.vilares@udc.es
FU FBBVA; SCANNER-UDC [PID2020-113230RB-C21]; MCIN/AEI; European Research Council (ERC); European Union [101100615]; Xunta de Galicia [ED431C 2020/11]; European Union (ERDF - Galicia 2014-2020 Program) [ED431G 2019/01]; University of Granada; Generalitat Valenciana; University of Alicante [IDIFEDER/2020/003]; European Research Council (ERC) [101100615] Funding Source: European Research Council (ERC)
CR Abdellaoui H, 2018, COMPUT SIST, V22, P777, DOI 10.13053/CyS-22-3-3031
   Adelani DI, 2021, T ASSOC COMPUT LING, V9, P1116, DOI 10.1162/tacl_a_00416
   Adwan OY, 2020, INT J EMERG TECHNOL, V15, P79, DOI 10.3991/ijet.v15i15.14467
   Afli H, 2017, P 18 INT C COMP LING, V0, P0
   Agerri R, 2020, P 12 LANGUAGE RESOUR, V0, P0
   Aguero-Torales MM, 2021, P 5 WORKSHOP COMPUTA, V0, P95
   Aguero-Torales MM, 2022, MACHINE LEARNING APP, V0, P0
   Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2
   Asgari E, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P4113
   Babu A, 2022, INTERSPEECH, V0, PP2278, DOI 10.21437/Interspeech.2022-143
   Baevski Alexei, 2020, P ADV NEUR INF PROC, V33, P12449
   BittarPrieto J, 2016, THESIS U NEW MEXICO, V0, P0
   BittarPrieto J, 2020, CONSTRUCTIONIST APPR, V0, P0
   Boidin C, 2005, REGIONALWISSENSCHAFT, V11, P303
   Borges Y, 2021, PROCES LENG NAT, V0, PP89, DOI 10.26342/2021-66-7
   Cambria E, 2015, COGN COMPUT, V7, P183, DOI 10.1007/s12559-015-9325-0
   Canete J, 2020, PML4DC ICLR 2020, V0, P1
   Chatterjee A, 2019, P 13 INT WORKSH SEM, V0, P39
   Chen YQ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383
   Chiruzzo L, 2023, P 12 INT GLOB WORDN, V0, P0
   Chiruzzo L, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2098
   Chiruzzo L, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5106
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP6022, DOI 10.18653/V1/2020.ACL-MAIN.536
   Cordova J, 2019, INFORM MANAGEMENT BI, V0, PP198, DOI 10.1007/978-3-030-11680-4_20
   de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI 10.1162/coli_a_00402
   Devi MD, 2020, MACHINE LEARNING IMA, V0, PP411, DOI 10.1007/978-981-15-6318-8_34
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duran M, 2021, FORMALISING NATURAL, V0, PP61, DOI 10.1007/978-3-030-70629-6_6
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Estigarribia B, 2020, GRAMMAR PARAGUAYAN G, V0, P0
   Estigarribia B, 2015, J LANG CONTACT, V8, P183, DOI 10.1163/19552629-00802002
   GarciaTrillo MA, 2021, PROCESAMIENTO LENGUA, V1, P0
   Ghosh S, 2022, COGN COMPUT, V14, P110, DOI 10.1007/s12559-021-09828-7
   Giossa N, 2021, THESIS U REPUBLICA U, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Green DW, 2011, FRONT PSYCHOL, V2, P0, DOI 10.3389/fpsyg.2011.00103
   Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2545
   Hossain N, 2020, P 14 WORKSHOP SEMANT, V0, PP746, DOI 10.18653/V1/2020.SEMEVAL-1.98
   Jain DK, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2021.102758
   Jakobsen AL, 2017, TRANSLATION TRANSITI, V133, P0
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kann K, 2022, FRONT ARTIF INTELL, V5, P0, DOI 10.3389/frai.2022.995667
   Kann K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3342
   Khan Mansoor, 2020, 2020 IEEE 8TH INTERNATIONAL CONFERENCE ON PHOTONICS (ICP), V0, PP1, DOI 10.1109/ICP46580.2020.9206421
   Kuratov Y, 2019, ABS190507213 CORR, V0, P0
   Kuznetsova A, 2021, P 1 WORKSH NAT LANG, V0, P81
   Lamprinidis S, 2021, P 11 WORKSHOP COMPUT, V0, P62
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4483
   LeCun Y, 1995, CONVOLUTIONAL NETWOR, V3361, P1995, DOI 10.5555/303568.303704
   Lieberman MD, 2019, NAT HUM BEHAV, V3, P20, DOI 10.1038/s41562-018-0487-0
   Mager M, 2018, P 27 INT C COMP LING, V0, PP55, DOI 10.48550/ARXIV.1806.04291
   Mager M, 2021, P 1 WORKSH NAT LANG, V0, PP202, DOI 10.18653/V1/2021.AMERICASNLP-1.23
   Magooda A, 2021, FINDINGS ASS COMPUTA, V0, P1652
   Mamta, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3514498
   Mazumder M, 2021, 35 C NEURAL INFORM P, V0, P0
   Mihalcea R, 2006, COMPUT INTELL-US, V22, P126, DOI 10.1111/j.1467-8640.2006.00278.x
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3434237
   Novak PK, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0144296
   Ogueji K, 2021, P 1 WORKSH MULT REPR, V0, P116
   Pajupuu H, 2016, FOLKLORE-EL J FOLKL, V0, PP125, DOI 10.7592/FEJF2016.64.polarity
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7654
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Plaza-Del-Arco FM, 2021, IEEE ACCESS, V9, P112478, DOI 10.1109/ACCESS.2021.3103697
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.28.739
   Ranasinghe T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5838
   Ríos AA, 2014, 2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), V0, PP37, DOI 10.1109/BRACIS.2014.18
   Schulz C, 2018, P 2018 C N AM CHAPT, V2, P35
   Souza Fabio, 2020, INTELLIGENT SYSTEMS. 9TH BRAZILIAN CONFERENCE, V0, P403, DOI 10.1007/978-3-030-61377-8_28
   Strapparava C, 2015, OXFORD HDB AFFECTIVE, V0, P0
   Vilares D, 2021, PROCES LENG NAT, V0, PP13, DOI 10.26342/2021-66-1
   Wang M, 2020, P 22 ANN C EUROPEAN, V0, P53
   Wang Z, 2020, INT C LEARNING REPRE, V0, P0
   Winata GI, 2021, P 1 WORKSHOP MULTILI, V0, PP1, DOI 10.18653/V1/2021.MRL-1.1
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P833
   Wu Y, 2016, ARXIV, V0, P0
   Xu QT, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P3030, DOI 10.1109/ICASSP39728.2021.9414641
   YANG J, 2018, P ACL 2018 SYST DEM, V0, PP74, DOI 10.18653/V1/P18-4013
   Yen MF, 2022, COMPUT ECON, V59, P1677, DOI 10.1007/s10614-021-10111-y
   Yong Hu, 2020, WEB AND BIG DATA. 4TH INTERNATIONAL JOINT CONFERENCE, V0, P603, DOI 10.1007/978-3-030-60259-8_44
   Yue L, 2019, KNOWL INF SYST, V60, P617, DOI 10.1007/s10115-018-1236-4
   Zampieri M, 2020, P 14 WORKSH SEM EV I, V0, PP1425, DOI 10.18653/v1/2020.semeval-1.188
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
NR 93
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD JUL 15
PY 2023
VL 15
IS 4
BP 1391
EP 1406
DI 10.1007/s12559-023-10165-0
EA JUN 2023
PG 16
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA O3JP9
UT WOS:001020154100001
DA 2023-11-10
ER

PT J
AU Han, PF
   Li, HK
   Xue, G
   Zhang, C
AF Han, Pengfei
   Li, Huakang
   Xue, Gang
   Zhang, Chao
TI Distributed system anomaly detection using deep learning-based log analysis
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article
DE deep learning; distributed system; spatiotemporal feature extraction; system anomaly detection; system logs analysis
AB Anomaly detection is a key step in ensuring the security and reliability of large-scale distributed systems. Analyzing system logs through artificial intelligence methods can quickly detect anomalies and thus help maintenance personnel to maintain system security. Most of the current works only focus on the temporal or spatial features of distributed system logs, and they cannot sufficiently extract the global features of distributed system logs to achieve a good correct rate of anomaly detection. To further address the shortcomings of existing methods, this paper proposes a deep learning model with global spatiotemporal features to detect the presence of anomalies in distributed system logs. First, we extract semi-structured log events from log templates and model them as natural language. In addition, we focus on the temporal characteristics of logs using the bidirectional long short-term memory network and the spatial invocation characteristics of logs using the Transformer. Extensive experimental evaluations show the advantages of our proposed model for distributed system log anomaly detection tasks. The optimal F1-Score on three open-source datasets and our own collected distributed system datasets reach 98.04%, 94.34%, 88.16%, and 97.40%, respectively.
C1 [Han, Pengfei; Xue, Gang; Zhang, Chao] Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.
   [Li, Huakang] Xian Jiaotong Liverpool Univ, Sch Artificial Intelligence & Adv Comp, Suzhou, Jiangsu, Peoples R China.
C3 Yunnan University; Xi'an Jiaotong-Liverpool University
RP Xue, G (通讯作者)，Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.
EM hill@ynu.edu.cn
FU Open Foundation of Key Laboratory in Software Engineering of Yunnan Province [2020SE318]; Science and Technology Plan in Key Fields of Yunnan Province [202202AD080002]
CR Agnes Lydia A, 2019, INT J COMPUT INF SCI, V6, P566
   Agrawal A, 2019, PROC INT CONF DATA, V0, PP1946, DOI 10.1109/ICDE.2019.00211
   Aksu D, 2018, 2018 INTERNATIONAL CONGRESS ON BIG DATA, V0, P77, DOI 10.1109/IBIGDELFT.2018.8625370
   Beutel DJ, 2020, FLOWER FRIENDLY FEDE, V0, P0
   Bottou L, 2012, NEURAL NETWORKS TRIC, V0, P421
   Du M, 2017, CCS17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, V0, PP1285, DOI 10.1145/3133956.3134015
   Du M, 2016, IEEE DATA MINING, V0, PP859, DOI 10.1109/ICDM.2016.160
   Du S, 2015, 2015 INT C BEH EC SO, V0, P188
   Eskin Eleazar, 2000, P INT C MACH LEARN, V0, P0
   Farzad A, 2020, ICT EXPRESS, V6, P229, DOI 10.1016/j.icte.2020.06.003
   George V, 2013, INT J ADV RES COMPUT, V4, P34
   He PJ, 2018, IEEE T DEPEND SECURE, V15, P931, DOI 10.1109/TDSC.2017.2762673
   He PJ, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), V0, PP33, DOI 10.1109/ICWS.2017.13
   He S, 2020, LOGHUB LARGE COLLECT, V0, P0
   He SL, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3460345
   He SL, 2016, PROC INT SYMP SOFTW, V0, PP207, DOI 10.1109/ISSRE.2016.21
   Huang SH, 2020, IEEE T NETW SERV MAN, V17, P2064, DOI 10.1109/TNSM.2020.3034647
   Huang Z, 2015, BIDIRECTIONAL LSTM C, V34, P01991
   [贾统 Jia Tong], 2020, 软件学报 JOURNAL OF SOFTWARE, V31, P1997
   Kawakami K, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), V0, PP418, DOI 10.1109/ICCE.2012.6161956
   Kingma DP, 2014, C TRACK P, V0, P0
   Liu J, 2019, INT C DAT EXP SYST A, V0, P63
   Liu XG, 2021, MATH PROBL ENG, V2021, P0, DOI 10.1155/2021/6655346
   Lu SY, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, V0, P0
   Makanju A, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P1255
   Meng WB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4739
   Nandi A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP215, DOI 10.1145/2939672.2939712
   Paszke Adam, 2019, NEURIPS, V0, P0
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   POLYAK BT, 1992, SIAM J CONTROL OPTIM, V30, P838, DOI 10.1137/0330046
   Ramos J, 2003, P 1 INSTR C MACH LEA, VVolume 242, P29
   REN R, 2018, DEEP CONVOLUTIONAL N, V0, P1639
   Tang L, 2011, P 20 ACM INT C INF K, V0, PP785, DOI 10.1145/2063576.2063690
   Tao L, 2005, P 11 ACM SIGKDD INT, V0, P776
   Vaarandi R, 2015, INT CONF NETW SER, V0, PP1, DOI 10.1109/CNSM.2015.7367331
   Vaswani A, 2017, ARXIV, V30, P5998
   Wittkopp T, 1900, P700, V0, P0
   Xu W, 2009, SOSP09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, V0, P117
   Zeiler Matthew D, 2012, ARXIV12125701, V0, P0
   Zhu JM, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P415, DOI 10.1109/ICSE.2015.60
NR 41
TC 0
Z9 0
U1 13
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0824-7935
EI 1467-8640
J9 COMPUT INTELL-US
JI Comput. Intell.
PD JUN 15
PY 2023
VL 39
IS 3
BP 433
EP 455
DI 10.1111/coin.12573
EA APR 2023
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K6MU9
UT WOS:000972529500001
DA 2023-11-10
ER

PT J
AU Huang, H
   Zhang, BW
   Li, YY
   Zhang, BQ
   Sun, YX
   Luo, CY
   Peng, C
AF Huang, Hu
   Zhang, Bowen
   Li, Yangyang
   Zhang, Baoquan
   Sun, Yuxi
   Luo, Chuyao
   Peng, Cheng
TI Knowledge-enhanced Prompt-tuning for Stance Detection
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Stance detection; deep learning; prompt-tuning framework
AB Investigating public attitudes on social media is important in opinion mining systems. Stance detection aims to analyze the attitude of an opinionated text (e.g., favor, neutral, or against) toward a given target. Existing methods mainly address this problem from the perspective of fine-tuning. Recently, prompt-tuning has achieved success in natural language processing tasks. However, conducting prompt-tuning methods for stance detection in real-world remains a challenge for several reasons: (1) The text form of stance detection is usually short and informal, which makes it difficult to design label words for the verbalizer. (2) The tweet text may not explicitly give the attitude. Instead, users may use various hashtags or background knowledge to express stance-aware perspectives. In this article, we first propose a prompt-tuning-based framework that performs stance detection in a cloze question manner. Specifically, a knowledge-enhanced prompt-tuning framework (KEprompt) method is designed, which consists of an automatic verbalizer (AutoV) and background knowledge injection (BKI). Specifically, in AutoV, we introduce a semantic graph to build a better mapping from the predicted word of the pretrained language model and detection labels. In BKI, we first propose a topic model for learning hashtag representation and introduce ConceptGraph as the supplement of the target. At last, we present a challenging dataset for stance detection, where all stance categories are expressed in an implicit manner. Extensive experiments on a large real-world dataset demonstrate the superiority of KEprompt over state-of-the-art methods.
C1 [Huang, Hu] Univ Sci & Technol China, Sch Cyberspace Sci & Technol, Hefei 230000, Peoples R China.
   [Zhang, Bowen] Shenzhen Technol Univ, Coll Big Data & Internet, Shenzhen 518000, Peoples R China.
   [Li, Yangyang] Acad Cyber, CAEIT, Natl Engn Res Ctr Risk Percept & Prevent, Beijing 100000, Peoples R China.
   [Zhang, Baoquan; Sun, Yuxi] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen 518000, Peoples R China.
   [Peng, Cheng] Univ Elect Sci & Technol China, Zhongshan Inst, Zhongshan 528400, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of China, CAS; Shenzhen Technology University; Harbin Institute of Technology; University of Electronic Science & Technology of China
RP Zhang, BW (通讯作者)，Shenzhen Technol Univ, Coll Big Data & Internet, Shenzhen 518000, Peoples R China.
EM zhang_bo_wen@foxmail.com
FU Stable Support Project for Shenzhen Higher Education Institutions [SZWD2021011]; Research Promotion Project of Key Construction Discipline in Guangdong Province [2022ZDJS112]
CR Allaway E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8913
   Augenstein I, 2016, P C EMP METH NAT LAN, V0, P0
   Cambria E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3829
   Cambria E, 2018, AAAI CONF ARTIF INTE, V0, P1795
   Cignarella AT, 2022, PROCEEDINGS OF THE THIRD WORKSHOP ON INSIGHTS FROM NEGATIVE RESULTS IN NLP (INSIGHTS 2022), V0, P10
   Conforti C, 2021, P 11 WORKSH COMP APP, V0, P181
   Conforti C, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1715
   Dan YH, 2022, INT CONF ACOUST SPEE, V0, PP4303, DOI 10.1109/ICASSP43922.2022.9746200
   Dev K, 2018, LECT NOTES COMPUT SC, V10772, P529, DOI 10.1007/978-3-319-76941-7_40
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du JC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3988
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Hardalov M, 2022, AAAI CONF ARTIF INTE, V0, P10729
   He Zihao, 2022, ARXIV, V0, P0
   Hu S, 2022, ARXIV, V0, P0
   Hu SD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2225
   Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22
   Jain R, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3447650
   Jiang Y, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP837, DOI 10.1145/3477495.3531979
   Küçük D, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3369026
   Li C, 2021, ARXIV, V0, P0, DOI DOI 10.48550/arxiv.2109.08306
   Li C, 2022, IEEE T NEUR NET LEAR, V33, P2530, DOI 10.1109/TNNLS.2021.3114027
   Li Y, 2021, FINDINGS ASS COMPUTA, VACL, P0
   Li YJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6299
   Liang B, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW22), V0, PP2738, DOI 10.1145/3485447.3511994
   Liang B, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), V0, PP3453, DOI 10.1145/3442381.3449790
   Liu R, 2021, FINDINGS ASS COMPUTA, V0, PP3152, DOI 10.18653/V1/2021.FINDINGS-ACL.278
   Mohammad S, 2016, P 10 INT WORKSH SEM, V0, P31
   Popat K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6413
   Rani S, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3485243
   Schick T, 2020, P 28 INT C COMP LING, V0, P5569
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P255
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Sobhani P, 2017, P EACL, V0, P551
   Somasundaran S, 2009, P JOINT C 47 ANN M A, V0, P226
   Sun Qingying, 2018, P 27 INT C COMP LING, V0, P2399
   Tang Duyu, 2016, P 2016 C EMP METH NA, V0, PP214, DOI 10.18653/v1/D16-1021
   Walker MA, 2012, P 2012 C N AM CHAPTE, V0, P592
   Wang Limin, 2021, IEEE ACCESS, V9, P0
   Wei PH, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1173, DOI 10.1145/3331184.3331367
   Wei PH, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1229, DOI 10.1145/3209978.3210145
   Xu C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P778
   Yang M, 2019, NEURAL NETWORKS, V118, P247, DOI 10.1016/j.neunet.2019.06.014
   Yang M, 2019, NEURAL NETWORKS, V117, P240, DOI 10.1016/j.neunet.2019.05.021
   Zhang BW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3188
   Zhang C, 2019, ARXIV, V0, P0
   Zhang X, 2021, COMM COM INF SC, V1466, P171, DOI 10.1007/978-981-16-6471-7_13
   Zhang YZ, 2021, NEURAL NETWORKS, V133, P40, DOI 10.1016/j.neunet.2020.10.001
NR 48
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN 15
PY 2023
VL 22
IS 6
BP 
EP 
DI 10.1145/3588767
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K7YR0
UT WOS:001018562700005
DA 2023-11-10
ER

PT J
AU Pratihar, J
   Dey, A
   Khan, A
   Banerjee, P
   Pal, RK
AF Pratihar, Jayanta
   Dey, Arindam
   Khan, Abhinandan
   Banerjee, Pritha
   Pal, Rajat Kumar
TI Computing with words for solving the fuzzy transportation problem
SO SOFT COMPUTING
LA English
DT Article; Early Access
DE Fuzzy transportation problem; Natural language; Interval type-2 fuzzy set; Computing with words
ID interval type-2; model; sets
AB Computing with words is a soft computing technique in which computational objects are natural words and propositions are taken from some natural language. It offers a significant ability of computing human knowledge/information present in natural language. The main idea of computing with words is based on the remarkable ability of human beings to deal with several types of real-world decision-making problems without any measurements or computations. One of the most significant and fundamental fuzzy optimisation problems that appear as a sub-problem in several real-world applications is the fuzzy environment-oriented transportation problem, sometimes known as the fuzzy transportation problem. In fuzzy transportation problems, we use type-1 fuzzy set or fuzzy numbers to represent the transportation cost, supply or demand. However, humans describe these variables in their daily life using terms like large, medium, small, some, etc., which do not supply any real or fuzzy number. In this article, the motivation is to find an algorithm for transportation problems that is simple enough and effective in real-world scenarios. Hence, we propose an algorithm to solve the transportation problem based on computing with words, where some realistic words (e.g. large, medium, small, or tiny) are considered for representing transportation cost, supply, and demand. The efficiency of our suggested approach is demonstrated with a few numerical examples.
C1 [Pratihar, Jayanta] Budge Budge Inst Technol, Dept Comp Sci & Engn, Kolkata 700137, West Bengal, India.
   [Pratihar, Jayanta; Khan, Abhinandan; Banerjee, Pritha; Pal, Rajat Kumar] Univ Calcutta, Dept Comp Sci & Engn, Acharya Prafulla Chandra Roy Siksha Prangan, JD-2,Sect 3, Kolkata 700106, West Bengal, India.
   [Dey, Arindam] VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Pradesh, India.
   [Khan, Abhinandan] ARP Engn, Prod Dev & Diversificat, 147 Nilgunj Rd, Kolkata 700056, West Bengal, India.
C3 University of Calcutta; VIT-AP University; VIT Bhopal University
RP Dey, A (通讯作者)，VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Pradesh, India.
EM jpratihar7974@gmail.com; arindam84nit@gmail.com; khan.abhinandan@gmail.com; banerjee.pritha74@gmail.com; pal.rajatk@gmail.com
CR Akram M, 2022, AIMS MATH, V8, P924, DOI 10.3934/math.2023045
   Biglarbegian M, 2011, INFORM SCIENCES, V181, P1325, DOI 10.1016/j.ins.2010.11.003
   Biswas A, 2022, APPL SOFT COMPUT, V129, P0, DOI 10.1016/j.asoc.2022.109576
   Das M, 2023, ADV ENG INFORM, V55, P0, DOI 10.1016/j.aei.2022.101816
   Demir E, 2022, INT J FUZZY SYST, V0, P0, DOI DOI 10.1007/s40815-022-01404-x
   Ebrahimnejad A, 2013, 2013 13 IR C FUZZ SY, V0, P1
   Escobar-Gómez E, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11236665
   Fazayeli S, 2018, COMPUT IND ENG, V119, P233, DOI 10.1016/j.cie.2018.03.041
   Gupta P, 2022, INT J PROD RES, V60, P2369, DOI 10.1080/00207543.2021.1888392
   Hao MS, 2016, IEEE T FUZZY SYST, V24, P865, DOI 10.1109/TFUZZ.2015.2486814
   Kane L, 2021, J FUZZY EXTENS APPL, V2, P204
   Kane L, 2021, J FUZZY EXT APPL, V2, P89
   Karnik NN, 2001, INFORM SCIENCES, V132, P195, DOI 10.1016/S0020-0255(01)00069-X
   Kaur A, 2012, APPL SOFT COMPUT, V12, P1201, DOI 10.1016/j.asoc.2011.10.014
   Kaur Dalbinder, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON BUSINESS AND INFORMATION MANAGEMENT (ICBIM), V0, PP144, DOI 10.1109/ICBIM.2014.6970977
   Kumar R, 2019, COMPLEX INTELL SYST, V5, P255, DOI 10.1007/s40747-019-0108-1
   Lee LW, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3084, DOI 10.1109/ICMLC.2008.4620938
   Lin FT, 2010, CONF TECHNOL APPL, V0, PP299, DOI 10.1109/TAAI.2010.56
   Lin FT, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P1468, DOI 10.1109/FUZZY.2009.5277202
   Liu F, 2008, IEEE T FUZZY SYST, V16, P1503, DOI 10.1109/TFUZZ.2008.2005002
   Madani Mohamed Amine, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY (IAS). PROCEEDINGS, V0, PP1, DOI 10.1109/ISIAS.2015.7492757
   Mendel JM, 2002, INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE, V12, P325
   Mendel JM, 2017, UNCERTAIN RULE BASED, V0, P0, DOI DOI 10.1007/978-3-319-51370-6
   Mendel JM, 2007, GRC: 2007 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, V0, P446, DOI 10.1109/GrC.2007.55
   Mendel JM, 2007, IEEE T FUZZY SYST, V15, P309, DOI 10.1109/TFUZZ.2006.882463
   Mendel JM, 2021, IEEE T FUZZY SYST, V29, P3579, DOI 10.1109/TFUZZ.2021.3079503
   Mendel JM, 2020, IEEE T FUZZY SYST, V28, P783, DOI 10.1109/TFUZZ.2019.2916103
   Mendel JM, 2019, IEEE COMPUT INTELL M, V14, P82, DOI 10.1109/MCI.2018.2881646
   Mendel JM, 2016, GRANULAR COMPUT, V1, P59, DOI 10.1007/s41066-015-0009-7
   Mendel JM, 2012, IEEE COMPUT INTELL M, V7, P36, DOI 10.1109/MCI.2012.2200627
   Mendel JM, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P35, DOI 10.1109/FUZZ.2001.1007239
   Mendel JM, 2013, ADV TYPE 2 FUZZY SET, V0, P3
   Mendel JM, 2018, INFORM SPEKTRUM, V41, P15, DOI 10.1007/s00287-018-1088-z
   Mendel JM, 2001, UNCERTAIN RULE BASED, V0, P0
   Moreira AV, 2012, THESIS DEP CIVIL ENG, V0, P7
   Muhuri PK, 2018, IEEE T FUZZY SYST, V26, P2311, DOI 10.1109/TFUZZ.2017.2773020
   Rajati MR, 2014, IEEE T FUZZY SYST, V22, P1245, DOI 10.1109/TFUZZ.2013.2287028
   Ranjan K, 2017, J APPL RES IND ENG, V4, P1
   Rao KRamanuja, 2016, 2016 3RD ASIA-PACIFIC WORLD CONGRESS ON COMPUTER SCIENCE AND ENGINEERING (APWC ON CSE), V0, PP271, DOI 10.1109/APWC-on-CSE.2016.051
   Sengupta D, 2016, 2016 INT C REC ADV I, V0, P1
   Sharma D, 2021, 2021 IEEE INT C FUZZ, V0, P1
   Sori AA, 2020, J INTELL FUZZY SYST, V38, P4711, DOI 10.3233/JIFS-191413
   Veeramani C, 2021, DISCRETE DYN NAT SOC, V2021, P0, DOI 10.1155/2021/7308042
   Wang JH, 2006, IEEE T FUZZY SYST, V14, P435, DOI 10.1109/TFUZZ.2006.876337
   Wu D, 2008, INFORM SCIENCES, V178, P381, DOI 10.1016/j.ins.2007.04.014
   Wu DR, 2009, IEEE T FUZZY SYST, V17, P923, DOI 10.1109/TFUZZ.2008.924329
   Wu DR, 2009, INFORM SCIENCES, V179, P1169, DOI 10.1016/j.ins.2008.12.010
   Zadeh LA, 1999, IEEE T CIRCUITS-I, V46, P105, DOI 10.1109/81.739259
   Zadeh LA, 2012, COMPUTING WORDS PRIN, V0, P0, DOI DOI 10.1007/978-3-642-27473-2
   Zimmermann H-J, 1978, FUZZY SETS AND SYSTEMS, V1, P45, DOI 10.1016/0165-0114(78)90031-3
NR 50
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s00500-023-08958-4
EA JUL 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA N1ER7
UT WOS:001034534900006
DA 2023-11-10
ER

PT J
AU Petitpierre, R
   Kramer, M
   Rappo, L
AF Petitpierre, Remi
   Kramer, Marion
   Rappo, Lucas
TI An end-to-end pipeline for historical censuses processing
SO INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION
LA English
DT Article
DE Historical document processing; Layout analysis; Tabular document understanding; Handwritten text recognition; OCR post-correction
AB Censuses are structured documents of great value for social and demographic history, which became widespread from the nineteenth century on. However, the plurality of formats and the natural variability of historical data make their extraction arduous and often lead to ungeneric recognition algorithms. We propose an end-to-end processing pipeline, based on optimization, in an attempt to reduce the number of free parameters. The layout analysis is based on semantic segmentation using neural networks for a generic recognition of the explicit column structure. The implicit row structure is deduced directly from the position of the text segments. The handwritten text detection is complemented by an intelligent framing method which significantly improves the quality of the HTR. In the end, we propose to combine several post-correction approaches, neural networks, and language models, to further improve the performance. Ultimately, our flexible methods make it possible to accurately detect more than 98% of the columns and 88% of the rows, despite the lack of graphical separator and the diversity of formats. Thanks to various reframing and post-correction strategies, HTR results reach the excellent performance of 3.44% character error rate on these noisy nineteenth century data. In total, more than 18,831 pages were extracted in 72 censuses over a century. This large historical dataset, as well as training data, is made open-access and released along with this article.
C1 [Petitpierre, Remi; Kramer, Marion; Rappo, Lucas] Ecole Polytech Fed Lausanne, Digital Humanities Inst, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne
RP Petitpierre, R (通讯作者)，Ecole Polytech Fed Lausanne, Digital Humanities Inst, Lausanne, Switzerland.
EM remi.petitpierre@epfl.ch; marion.kramer@epfl.ch; lucas.rappo@epfl.ch
FU EPFL; Collaborative Research on Science and Society [CROSS 2021]; College of Humanities
CR Andres Moreno J, 2021, THESIS U POLITECNICA, V0, P0
   [Anonymous], 2021, REGISTER SWISS SURNA, V0, P0
   [Anonymous], 2020, COMPUTER VISION ANNO, V0, P0
   [Anonymous], 2021, FICHIER PRENOMS ETAT, V0, P0
   [Anonymous], 2021, THE HIST OF WORK, V0, P0
   Bell S, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0220219
   Berenbaum D, 2019, J ENVIRON INFORM, V34, P28, DOI 10.3808/jei.201700381
   Bergstra J, 2011, ADV NEURAL INFORM PR, V24, P1, DOI 10.5555/2986459.2986743
   Bluche T, 2017, PROC INT CONF DOC, V0, PP646, DOI 10.1109/ICDAR.2017.111
   Breuel TM, 2008, PROC SPIE, V6815, P0, DOI 10.1117/12.783598
   Cao HG, 2017, PROC INT CONF DOC, V0, PP977, DOI 10.1109/ICDAR.2017.163
   Aradillas JC, 2018, INT CONF FRONT HAND, V0, PP429, DOI 10.1109/ICFHR-2018.2018.00081
   Clawson R, 2013, PROC SPIE, V8658, P0, DOI 10.1117/12.2004788
   Clinchant S, 2019, ARXIV, V0, P0
   Colutto Sebastian, 2019, 2019 15TH INTERNATIONAL CONFERENCE ON ESCIENCE (ESCIENCE). PROCEEDINGS, V0, PP463, DOI 10.1109/eScience.2019.00060
   Corps de police, 1898, REC COMM 1804 1813 1, V0, P0
   Couasnon B, 2014, HDB DOCUMENT IMAGE P, V0, PP647, DOI 10.1007/978-0-85729-859-1_20
   Neto AFD, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10217711
   deSousaNeto AF, 2020, P ACM S DOCUMENT ENG, V0, PP1, DOI 10.1145/3395027.3419603
   deSousaNeto AF, 2020, ARTHURFLOR23 SPELLIN, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Diem M, 2017, PROC INT CONF DOC, V0, PP1355, DOI 10.1109/ICDAR.2017.222
   Garbe W, 2012, 1000X FASTER SPELLIN, V0, P0
   Grüning T, 2019, INT J DOC ANAL RECOG, V22, P285, DOI 10.1007/s10032-019-00332-1
   Guerry Camille, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP858, DOI 10.1109/ICDAR.2019.00142
   Hakala K, 2019, ARXIV, V0, P0
   Halainen M, 2019, P INT C REC ADV NAT, V0, PP431, DOI 10.26615/978-954-452-056-4_051
   Haldar R, 2011, ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Kissos I, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, V0, P198, DOI 10.1109/DAS.2016.44
   Lang E, 2018, INT CONF FRONT HAND, V0, PP44, DOI 10.1109/ICFHR-2018.2018.00017
   LEVENSHTVI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Li MH, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P1918
   Liang XS, 2021, BIG DATA RES, V24, P0, DOI 10.1016/j.bdr.2021.100195
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Luong Minh-Thang, 2015, EMNLP, V0, P3
   Meunier Jean-Luc, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP461, DOI 10.1109/ICDAR.2019.00080
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Municipalite, 1828, LAUSANNE AVL RB 14 0, V0, P376
   Nion T, 2013, PROC INT CONF DOC, V0, PP822, DOI 10.1109/ICDAR.2013.168
   Norvig P, 2007, WRITE SPELLING CORRE, V0, P0
   Oliveira SA, 2018, INT CONF FRONT HAND, V0, PP7, DOI 10.1109/ICFHR-2018.2018.00011
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pedersen BR, 2022, HIST LIFE COURSE STU, V12, P87, DOI 10.51964/hlcs11331
   Petitpierre R, 2023, 1805 1898 CENSUS REC, V0, P0, DOI DOI 10.5281/zenodo.7711640
   Priambada S, 2017, P 2017 2 INT C INF C, V0, PP1, DOI 10.1109/IAC.2017.8280534
   Puigcerver J, 2017, PROC INT CONF DOC, V0, PP67, DOI 10.1109/ICDAR.2017.20
   Rappo L, 2023, LAUSANNE HIST CENSUS, V35k, P0, DOI 10.5281/zenodo.7711178
   Rigaud Christophe, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1588, DOI 10.1109/ICDAR.2019.00255
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy A, 2021, UNSUPERVISED NORMALI, V0, P0
   Ruggles S, 2014, DEMOGRAPHY, V51, P287, DOI 10.1007/s13524-013-0240-2
   Schreiber S, 2017, PROC INT CONF DOC, V0, PP1162, DOI 10.1109/ICDAR.2017.192
   Shen Z, 2021, ARXIV, V0, P0
   Sibade C, 2011, P 2011 WORKSH HIST D, V0, PP51, DOI 10.1145/2037342.2037352
   Simistira F, 2017, PROC INT CONF DOC, V0, PP1361, DOI 10.1109/ICDAR.2017.223
   Stefanovic P, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9091870
   Williams L, 2016, AUST HISTORICAL STUD, V47, P398, DOI 10.1080/1031461X.2016.1208258
   Zucker A, 2021, MOBILE NETW APPL, V26, P1765, DOI 10.1007/s11036-021-01759-9
   Zuiderveld K, 1994, GRAPHICS GEMS, V0, PP474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 61
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1433-2833
EI 1433-2825
J9 INT J DOC ANAL RECOG
JI Int. J. Doc. Anal. Recognit.
PD DEC 15
PY 2023
VL 26
IS 4
BP 419
EP 432
DI 10.1007/s10032-023-00428-9
EA MAR 2023
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA U3JV7
UT WOS:000952045100001
DA 2023-11-10
ER

PT J
AU Guo, ZH
   Hou, YH
   Li, WQ
AF Guo, Zihui
   Hou, Yonghong
   Li, Wanqing
TI Sign language recognition via dimensional global-local shift and cross-scale aggregation
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Sign language recognition; Global-local representation; Shift operation; Cross-scale aggregation
AB Sign languages generally consist of a sequence of upper body gestures and are cooperative processes among various parts such as the hands, arms, and face. Therefore, the dynamics of the parts as well as the holistic appearance of the upper body and individual parts are essential for robust recognition. In this paper, a global-local representation (GLR) module is proposed to boost the spatiotemporal feature modeling. The GLR module is composed of global shift and local shift along the height, width, and temporal dimensions. Specifically, the global shift is applied to the entire feature map for holistic representation, while the local shift restricts itself to local patches to capture detailed features. Furthermore, a novel cross-scale aggregation module is designed to combine the global and local information in different dimensions. Extensive experimental results on three large-scale benchmarks, including WLASL, INCLUDE and LSA64, demonstrate that the proposed method achieves state-of-the-art recognition performance.
C1 [Guo, Zihui; Hou, Yonghong] Tianjin Univ, Sch Elect & Automation Engn, Tianjin, Peoples R China.
   [Li, Wanqing] Univ Wollongong, Adv Multimedia Res Lab, Wollongong, Australia.
C3 Tianjin University; University of Wollongong
RP Guo, ZH (通讯作者)，Tianjin Univ, Sch Elect & Automation Engn, Tianjin, Peoples R China.
EM gzihui@tju.edu.cn
CR Bohácek M, 2022, IEEE WINT CONF APPL, V0, PP182, DOI 10.1109/WACVW54805.2022.00024
   Brown A, 2019, P IEEECVF INT C COMP, V0, P0
   Carreira J, 2017, PROC CVPR IEEE, V0, PP4724, DOI 10.1109/CVPR.2017.502
   Chen WJ, 2019, PROC CVPR IEEE, V0, PP7234, DOI 10.1109/CVPR.2019.00741
   Cheng K, 2020, PROC CVPR IEEE, V0, PP180, DOI 10.1109/CVPR42600.2020.00026
   De Coster M, 2021, IEEE COMPUT SOC CONF, V0, PP3436, DOI 10.1109/CVPRW53098.2021.00383
   Guney S, 2021, NEURAL COMPUT APPL, V34, P1
   Hosain A, 2021, IEEE WINT CONF APPL, V0, PP3428, DOI 10.1109/WACV48630.2021.00347
   Hu HZ, 2021, AAAI CONF ARTIF INTE, V35, P1558
   Hu HZ, 2021, ACM T MULTIM COMPUT, V17, P0, DOI 10.1145/3436754
   Hu Hezhen, 2021, P IEEECVF INT C COMP, V0, P11087
   Imran J, 2020, VISUAL COMPUT, V36, P1233, DOI 10.1007/s00371-019-01725-3
   Jeon Y, 2018, ADV NEUR IN, V31, P0
   Jeon Y, 2018, ARXIV, V0, P0
   Jiancheng Yang, 2020, MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI 2020. 23RD INTERNATIONAL CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12264), V0, PP562, DOI 10.1007/978-3-030-59719-1_55
   Jiang SY, 2021, IEEE COMPUT SOC CONF, V0, PP3408, DOI 10.1109/CVPRW53098.2021.00380
   Joze HRV, 2018, ARXIV, V0, P0
   Konstantinidis D, 2018, 2018 IEEE INT C IMAG, V0, P1
   Konstantinidis D, 2018, 3DTV CONF, V0, P0
   Li CK, 2022, IEEE T COGN DEV SYST, V14, P1594, DOI 10.1109/TCDS.2021.3126637
   Li DX, 2020, PROC CVPR IEEE, V0, PP6204, DOI 10.1109/CVPR42600.2020.00624
   Li DX, 2020, IEEE WINT CONF APPL, V0, PP1448, DOI 10.1109/WACV45572.2020.9093512
   Li MP, 2022, APPL SOFT COMPUT, V117, P0, DOI 10.1016/j.asoc.2022.108419
   Li YH, 2019, AAAI CONF ARTIF INTE, V0, P8674
   Lin J, 2019, IEEE I CONF COMP VIS, V0, PP7082, DOI 10.1109/ICCV.2019.00718
   Maruyama M, 2021, ARXIV, V0, P0
   Moryossef A, 2021, IEEE COMPUT SOC CONF, V0, PP3429, DOI 10.1109/CVPRW53098.2021.00382
   Paoletti ME, 2021, IEEE T GEOSCI REMOTE, V59, P5938, DOI 10.1109/TGRS.2020.3024730
   Praveen RG, 2022, P IEEECVF C COMPUTER, V0, P2486
   Rezende TM, 2021, NEURAL COMPUT APPL, V33, P10449, DOI 10.1007/s00521-021-05802-4
   Ronchetti F, 2016, 22 CONGRESO ARGENTIN, V0, P0
   Shang R, 2022, IEEE T GEOSCI ELECT, V60, P1, DOI 10.1109/TGRS.2022.3217053
   Sridhar A, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1366, DOI 10.1145/3394171.3413528
   Sudhakaran S, 2020, PROC CVPR IEEE, V0, PP1099, DOI 10.1109/CVPR42600.2020.00118
   Tunga A, 2021, IEEE WINT CONF APPL, V0, PP31, DOI 10.1109/WACVW52041.2021.00008
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vazquez-Enriquez M, 2021, P IEEECVF C COMPUTER, V0, P3462
   Venugopalan A, 2021, EXPERT SYST APPL, V185, P0, DOI 10.1016/j.eswa.2021.115601
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wang F, 2022, NEURAL COMPUT APPL, V34, P2413, DOI 10.1007/s00521-021-06467-9
   Wang HG, 2017, IEEE INT CONF COMP V, V0, PP3138, DOI 10.1109/ICCVW.2017.371
   Wang PC, 2016, INT C PATT RECOG, V0, PP7, DOI 10.1109/ICPR.2016.7899599
   Wu BC, 2018, PROC CVPR IEEE, V0, PP9127, DOI 10.1109/CVPR.2018.00951
   Wu JG, 2022, NEURAL COMPUT APPL, V34, P5397, DOI 10.1007/s00521-021-06696-y
   Xiao S, 2021, 2021 INT JOINT C NEU, V0, P1
   Yan SJ, 2018, AAAI CONF ARTIF INTE, V0, P7444
   Yang JY, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3131615
   Zhang SJ, 2021, J VIS COMMUN IMAGE R, V80, P0, DOI 10.1016/j.jvcir.2021.103280
   Zhang XY, 2019, FUTURE INTERNET, V11, P0, DOI 10.3390/fi11040091
   Zhou ZX, 2021, INT C PATT RECOG, V0, PP4296, DOI 10.1109/ICPR48806.2021.9412075
NR 50
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUN 15
PY 2023
VL 35
IS 17
BP 12481
EP 12493
DI 10.1007/s00521-023-08380-9
EA MAR 2023
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA F9GM0
UT WOS:000942148000005
DA 2023-11-10
ER

PT J
AU Lo, PC
   Lim, EP
AF Lo, Pei-Chi
   Lim, Ee-Peng
TI A transformer framework for generating context-aware knowledge graph paths
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Knowledge graph; Contextual path generation; Information retrieval; Language model
AB Contextual Path Generation (CPG) refers to the task of generating knowledge path(s) between a pair of entities mentioned in an input textual context to determine the semantic connection between them. Such knowledge paths, also called contextual paths, can be very useful in many advanced information retrieval applications. Nevertheless, CPG involves several technical challenges, namely, sparse and noisy input context, missing relations in knowledge graphs, and generation of ill-formed and irrelevant knowledge paths. In this paper, we propose a transformer-based model architecture. In this approach, we leverage a mixture of pre-trained word and knowledge graph embeddings to encode the semantics of input context, a transformer decoder to perform path generation controlled by encoded input context and head entity to stay relevant to the context, and scaling methods to sample a well-formed path. We evaluate our proposed CPG models derived using the above architecture on two real datasets, both consisting of Wikinews articles as input context documents and ground truth contextual paths, as well as a large synthetic dataset to conduct larger-scale experiments. Our experiments show that our proposed models outperform the baseline models, and the scaling methods contribute to better quality contextual paths. We further analyze how CPG accuracy can be affected by different amount of context data, and missing relations in the knowledge graph. Finally, we demonstrate that an answer model for knowledge graph questions adapted for CPG could not perform well due to the lack of an effective path generation module.
C1 [Lo, Pei-Chi; Lim, Ee-Peng] Singapore Management Univ, Sch Comp & Informat Syst, 80 Stamford Rd, Singapore 178902, Singapore.
C3 Singapore Management University
RP Lo, PC (通讯作者)，Singapore Management Univ, Sch Comp & Informat Syst, 80 Stamford Rd, Singapore 178902, Singapore.
EM pclo.2017@phdcs.smu.edu.sg; eplim@smu.edu.sg
FU Lee Kong Chian Professorship; National Research Foundation, Singapore under its Strategic Capabilities Research Centres Funding Initiative
CR Asai A, 2020, ICLR, V0, P0
   Bach SH, 2017, J MACH LEARN RES, V18, P0
   Baghershahi P, 2023, KNOWL-BASED SYST, V260, P0, DOI 10.1016/j.knosys.2022.110124
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bhatia S, 2018, ISWC, V0, P0, DOI DOI 10.1007/978-3-030-00671-6_{1}5
   Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   Cai XJ, 2022, EXPERT SYST APPL, V200, P0, DOI 10.1016/j.eswa.2022.117035
   Chatterjee S, 2022, LECT NOTES COMPUT SC, V13186, P463, DOI 10.1007/978-3-030-99739-7_57
   Chatterjee S, 2021, SIGIR 21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1662, DOI 10.1145/3404835.3463035
   Chatterjee S, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR19), V0, PP220, DOI 10.1145/3341981.3344243
   Chen JG, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP2184, DOI 10.1145/3477495.3531827
   Chen L, 2022, ACM T KNOWL DISCOV D, V16, P0, DOI 10.1145/3477051
   Chen L, 2022, APPL INTELL, V52, P4715, DOI 10.1007/s10489-021-02672-0
   Chen T, 2022, LECT NOTES COMPUT SC, V13185, P95, DOI 10.1007/978-3-030-99736-6_7
   Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW22), V0, PP2778, DOI 10.1145/3485447.3511998
   Chen ZY, 2022, KNOWL-BASED SYST, V251, P0, DOI 10.1016/j.knosys.2022.109134
   Cui H, 2023, INFORM SCIENCES, V619, P745, DOI 10.1016/j.ins.2022.11.042
   Cui ZH, 2022, WORLD WIDE WEB, V25, P631, DOI 10.1007/s11280-021-00902-6
   Das R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P358, DOI 10.18653/v1/P17-2057
   Dathathri S, 2020, ICLR, V0, P0
   Deng Y, 2022, ACM T INFORM SYST, V40, P0, DOI 10.1145/3457533
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Djenouri Y, 2021, APPL INTELL, V51, P1888, DOI 10.1007/s10489-020-01922-x
   Djenouri Y, 2018, EXPERT SYST APPL, V94, P126, DOI 10.1016/j.eswa.2017.10.042
   Du KZ, 2022, KNOWL-BASED SYST, V255, P0, DOI 10.1016/j.knosys.2022.109703
   Fu C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2672
   Geng ZQ, 2021, NEUROCOMPUTING, V429, P132, DOI 10.1016/j.neucom.2020.12.037
   Han X, 2012, EMNLP, V0, P0
   Hu Z, 2017, ICML, V0, P0
   Huang J, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P297
   Kadry A, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1149, DOI 10.1145/3077136.3080744
   Khan N, 2022, INFORM SCIENCES, V613, P69, DOI 10.1016/j.ins.2022.08.124
   Krötzsch M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5309
   Kumar A, 2020, T ASSOC COMPUT LING, V8, P330, DOI 10.1162/tacl_a_00318
   Laban P, 2022, T ASSOC COMPUT LING, V10, P163, DOI 10.1162/tacl_a_00453
   Li C, 2021, NEUROCOMPUTING, V461, P516, DOI 10.1016/j.neucom.2021.01.139
   Li ZX, 2021, SIGIR 21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP408, DOI 10.1145/3404835.3462963
   Li ZX, 2018, INT CONF DAT MIN WOR, V0, PP929, DOI 10.1109/ICDMW.2018.00135
   Liang B, 2022, KNOWL-BASED SYST, V235, P0, DOI 10.1016/j.knosys.2021.107643
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2829
   Liu Q, 2021, KNOWL-BASED SYST, V224, P0, DOI 10.1016/j.knosys.2021.107082
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu Y, 2021, AAAI CONF ARTIF INTE, V35, P6418
   Lu XY, 2022, APPL INTELL, V52, P7480, DOI 10.1007/s10489-021-02693-9
   Ma T, 2023, ACM T INFORM SYST, V41, P0, DOI 10.1145/3511019
   Peng H, 2019, NAACL, V0, P0, DOI DOI 10.18653/v1/N19-1263
   Qu M, 2019, ADV NEUR IN, V32, P0
   Reiter R, 1981, READINGS ARTIFICIAL, V0, PP119, DOI 10.1016/B978-0-934613-03-3.50014-3
   Ren H, 2021, P MACHINE LEARNING R, V0, P8959
   Rossi A, 2021, ACM T KNOWL DISCOV D, V15, P0, DOI 10.1145/3424672
   Saxena A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4498
   Shen TX, 2017, ADV NEUR IN, V30, P0
   Sun Q, 2022, EXPERT SYST APPL, V205, P0, DOI 10.1016/j.eswa.2022.117678
   Tang RX, 2022, KNOWL-BASED SYST, V250, P0, DOI 10.1016/j.knosys.2022.109129
   Tang X, 2019, INFORM PROCESS MANAG, V56, P809, DOI 10.1016/j.ipm.2019.01.005
   Vaswani A, 2017, ARXIV, V30, P5998
   Voskarides N, 2017, ECIR, V0, P0, DOI DOI 10.1007/978-3-319-56608-5_{2}5
   Wan G, 2021, AAAI, V0, P0
   Wang, 2019, PROC AAAI C ARTIF IN, V0, P0, DOI DOI 10.1609/aaai.v33i01.33015329
   Wang JA, 2022, T ASSOC COMPUT LING, V10, P1304, DOI 10.1162/tacl_a_00520
   Wang Q, 2021, NEUROCOMPUTING, V429, P101, DOI 10.1016/j.neucom.2020.12.040
   Wu X, 2022, KNOWL-BASED SYST, V254, P0, DOI 10.1016/j.knosys.2022.109661
   Xia Y, 2023, APPL INTELL, V53, P13293, DOI 10.1007/s10489-022-04147-2
   Xia Y, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.103040
   Xie ZW, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.103076
   Yamada I, 2016, CONLL, V0, P0, DOI DOI 10.18653/v1/K16-1025
   Yang K, 2020, IEEE ACCESS, V8, P85348, DOI 10.1109/ACCESS.2020.2991257
   Yang Z, 2018, NEURIPS, V0, P0
   Zhang QX, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.102933
   Zhang RC, 2020, INFORM SCIENCES, V521, P144, DOI 10.1016/j.ins.2020.02.016
   Zhang WX, 2023, IEEE T PATTERN ANAL, V45, P2864, DOI 10.1109/TPAMI.2022.3178874
   Zhang W, 2022, DECIS SUPPORT SYST, V157, P0, DOI 10.1016/j.dss.2022.113765
   Zhang YY, 2018, AAAI CONF ARTIF INTE, V0, P6069
   Zhang Z, 2021, ADV NEURAL INFORM PR, V0, P19172
   Zhang ZY, 2022, ACM T KNOWL DISCOV D, V16, P0, DOI 10.1145/3470783
   Zhao YY, 2023, ACM T INFORM SYST, V41, P0, DOI 10.1145/3531267
   Zheng WG, 2016, PROC VLDB ENDOW, V9, P840, DOI 10.14778/2983200.2983201
   Zhou QJ, 2023, KNOWL-BASED SYST, V260, P0, DOI 10.1016/j.knosys.2022.110108
   Zhu CY, 2022, BIOINFORMATICS, V38, P2235, DOI 10.1093/bioinformatics/btac085
   Zhu J, 2020, ICLR, V0, P0
   Zhu ZF, 2023, INFORM PROCESS MANAG, V60, P0, DOI 10.1016/j.ipm.2022.103223
   Zhuang L, 2021, P 20 CHINESE NATL C, V0, P1218
NR 82
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD OCT 15
PY 2023
VL 53
IS 20
BP 23740
EP 23767
DI 10.1007/s10489-023-04588-3
EA JUL 2023
PG 28
WC Computer Science, Artificial Intelligence
SC Computer Science
GA U9LK5
UT WOS:001030448400001
DA 2023-11-10
ER

PT J
AU Zuheros, C
   Martínez-Cámara, E
   Herrera-Viedma, E
   Katib, IA
   Herrera, F
AF Zuheros, Cristina
   Martinez-Camara, Eugenio
   Herrera-Viedma, Enrique
   Katib, Iyad A.
   Herrera, Francisco
TI Explainable Crowd Decision Making methodology guided by expert natural language opinions based on Sentiment Analysis with Attention-based Deep Learning and Subgroup Discovery
SO INFORMATION FUSION
LA English
DT Article
DE Crowd decision making; Explainability; Attention mechanisms; Subgroup discovery; Social media opinions
ID large-scale group; fuzzy; challenges; model
AB There exist a high demand to provide explainability to artificial intelligence systems, where decision making models are included. This paper focuses on crowd decision making using natural language evaluations from social media with the aim to provide explainability. We present the Explainable Crowd Decision Making based on Subgroup Discovery and Attention Mechanisms (ECDM-SDAM) methodology as an a posteriori explainable process that captures the wisdom of crowds that is naturally provided in social media opinions. It extracts the opinions from social media texts using a deep learning based sentiment analysis approach called Attention based Sentiment Analysis Method. The methodology includes a backward process that provides explanations to justify its sense-making procedure by applying mainly the attention mechanism on texts and subgroup discovery on opinions. We evaluate the methodology in the real case study of the TripR-2020Large dataset for restaurant choice. The results show that the ECDM-SDAM methodology provides easy understandable explanations that elucidates the key reasons that support the output of the decision process.
C1 [Zuheros, Cristina; Martinez-Camara, Eugenio; Herrera-Viedma, Enrique; Herrera, Francisco] Univ Granada, Andalusian Res Inst Data Sci & Computat Intellige, Dept Comp Sci & Artificial Intelligence, Granada 18071, Spain.
   [Katib, Iyad A.] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah 21589, Saudi Arabia.
C3 University of Granada; King Abdulaziz University
RP Zuheros, C (通讯作者)，Univ Granada, Andalusian Res Inst Data Sci & Computat Intellige, Dept Comp Sci & Artificial Intelligence, Granada 18071, Spain.
EM czuheros@ugr.es; emcamara@decsai.ugr.es; viedma@decsai.ugr.es; iakatib@kau.edu.sa; herrera@decsai.ugr.es
FU MCIN/AEI [PID2020-119478GB-I00, PID2019-103880RB-I00, PID2020-116118GA-I00, PRE2018-083884]; ERDF A way of making Europe; ESF Investing in your future; Universidad de Granada/CBUA
CR Amann Julia, 2022, PLOS DIGIT HEALTH, V1, Pe0000016, DOI 10.1371/journal.pdig.0000016
   Bahdanau D, 2016, ARXIV, V0, P0
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Chowdhery A, 2022, ARXIV, V0, P0
   Dian sano Albert Verasius, 2022, 2022 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND TECHNOLOGY (ICIMTECH), V0, PP634, DOI 10.1109/ICIMTech55957.2022.9915213
   Fan XY, 2022, ARXIV, V0, P0
   Feng JY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1478
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Guidotti R, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3236009
   Herrera F, 2011, KNOWL INF SYST, V29, P495, DOI 10.1007/s10115-010-0356-2
   Herrera-Viedma E, 2021, IEEE T SYST MAN CY-S, V51, P191, DOI 10.1109/TSMC.2020.3043016
   Huang T, 2020, NEUROCOMPUTING, V375, P25, DOI 10.1016/j.neucom.2019.09.024
   Kavsek B, 2006, APPL ARTIF INTELL, V20, P543, DOI 10.1080/08839510600779688
   Li MQ, 2023, IEEE T CYBERNETICS, V53, P3399, DOI 10.1109/TCYB.2022.3159866
   Liang YY, 2023, INFORM SCIENCES, V622, P808, DOI 10.1016/j.ins.2022.11.147
   López M, 2021, KNOWL-BASED SYST, V231, P0, DOI 10.1016/j.knosys.2021.107455
   Morente-Molinera JA, 2019, KNOWL-BASED SYST, V165, P335, DOI 10.1016/j.knosys.2018.12.006
   Morente-Molinera JA, 2018, INFORM SCIENCES, V447, P157, DOI 10.1016/j.ins.2018.03.020
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Pontiki M, 2016, P 10 INT WORKSH SEM, V0, PP19, DOI 10.18653/V1/S16-1002
   Prabadevi Boopathy, 2023, ACM T ASIAN LOW-RESO, V22, P1
   Punetha N, 2023, APPL INTELL, V53, P20152, DOI 10.1007/s10489-023-04471-1
   Ren PJ, 2017, IEEE T CYBERNETICS, V47, P2531, DOI 10.1109/TCYB.2016.2638498
   Serrano S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2931
   Simkute A, 2021, J RESPONSIB TECHNOL, V7, P0, DOI 10.1016/j.jrt.2021.100017
   Surowiecki J, 2005, WISDOM CROWDS ANCHOR, V0, P0
   Tayal DK, 2023, MULTIMED TOOLS APPL, V82, P1261, DOI 10.1007/s11042-022-13315-y
   Touvron H, 2023, ARXIV, V0, P0
   Trillo JR, 2023, INFORM FUSION, V91, P633, DOI 10.1016/j.inffus.2022.11.009
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Wang ZC, 2022, IEEE T CYBERNETICS, V52, P12501, DOI 10.1109/TCYB.2021.3072364
   Wu W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3729
   Wu YZ, 2021, INFORM FUSION, V65, P165, DOI 10.1016/j.inffus.2020.08.018
   Yadav RK, 2021, KNOWL-BASED SYST, V226, P0, DOI 10.1016/j.knosys.2021.107136
   Zhang T, 2022, IEEE T CYBERNETICS, V52, P6232, DOI 10.1109/TCYB.2021.3050508
   Zhong QT, 2019, EXPERT SYST APPL, V117, P42, DOI 10.1016/j.eswa.2018.09.038
   Zhu B, 2014, IEEE T CYBERNETICS, V44, P1328, DOI 10.1109/TCYB.2013.2283021
   Zhu RJ, 2023, ARXIV, V0, P0
   Zhu YC, 2023, COMPUT IND ENG, V176, P0, DOI 10.1016/j.cie.2022.108943
   Zuheros C, 2023, IEEE T SYST MAN CY-S, V53, P369, DOI 10.1109/TSMC.2022.3180938
   Zuheros C, 2021, INFORM FUSION, V68, P22, DOI 10.1016/j.inffus.2020.10.019
NR 42
TC 0
Z9 0
U1 23
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD SEP 15
PY 2023
VL 97
IS 
BP 
EP 
DI 10.1016/j.inffus.2023.101821
EA MAY 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA H8XF2
UT WOS:000998717700001
DA 2023-11-10
ER

PT J
AU Shafi, J
   Iqbal, HR
   Nawab, RMA
   Rayson, P
AF Shafi, Jawad
   Iqbal, Hafiz Rizwan
   Nawab, Rao Muhammad Adeel
   Rayson, Paul
TI UNLT: Urdu Natural Language Toolkit
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Word segmentation; Text segmentation; Part-of-speech tagging; Urdu NLP toolkit; Urdu corpora
AB This study describes a Natural Language Processing (NLP) toolkit, as the first contribution of a larger project, for an under-resourced language-Urdu. In previous studies, standard NLP toolkits have been developed for English and many other languages. There is also a dire need for standard text processing tools and methods for Urdu, despite it being widely spoken in different parts of the world with a large amount of digital text being readily available. This study presents the first version of the UNLT (Urdu Natural Language Toolkit) which contains three key text processing tools required for an Urdu NLP pipeline; word tokenizer, sentence tokenizer, and part-of-speech (POS) tagger. The UNLT word tokenizer employs a morpheme matching algorithm coupled with a state-of-the-art stochastic n-gram language model with back-off and smoothing characteristics for the space omission problem. The space insertion problem for compound words is tackled using a dictionary look-up technique. The UNLT sentence tokenizer is a combination of various machine learning, rule-based, regular-expressions, and dictionary look-up techniques. Finally, the UNLT POS taggers are based on Hidden Markov Model and Maximum Entropy-based stochastic techniques. In addition, we have developed large gold standard training and testing data sets to improve and evaluate the performance of new techniques for Urdu word tokenization, sentence tokenization, and POS tagging. For comparison purposes, we have compared the proposed approaches with several methods. Our proposed UNLT, the training and testing data sets, and supporting resources are all free and publicly available for academic use.
C1 [Shafi, Jawad; Rayson, Paul] Univ Lancaster, Sch Comp & Commun SCC, Lancaster, England.
   [Shafi, Jawad; Nawab, Rao Muhammad Adeel] COMSATS Univ Islamabad, Lahore Campus, Islamabad, Pakistan.
   [Iqbal, Hafiz Rizwan] Informat Technol Univ, Lahore, Pakistan.
C3 Lancaster University; COMSATS University Islamabad (CUI)
RP Shafi, J (通讯作者)，Univ Lancaster, Sch Comp & Commun SCC, Lancaster, England.; Shafi, J (通讯作者)，COMSATS Univ Islamabad, Lahore Campus, Islamabad, Pakistan.
EM jawadshafi@cuilahore.edu.pk
FU COMSATS University Islamabad, Lahore Campus, Pakistan; Lancaster University, U.K. under the Split-Site Ph.D. programme
CR Abdelhamid AA, 2012, P INT C IM SIGN PROC, V0, P150
   Ahmed T, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2920
   Akita Y, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1033
   Albared M, 2010, LECT NOTES ARTIF INT, V6401, P361, DOI 10.1007/978-3-642-16248-0_52
   [Anonymous], 2010, P 2010 NAMED ENTITIE, V0, P0
   [Anonymous], 2010, ANN C N AM CHAPT ACL, V0, P0
   [Anonymous], 1997, CORPUS ANNOTATION LI, V0, P0
   [Anonymous], 2002, P 37 ANN M ASS COMPU, V0, P0, DOI DOI 10.3115/1034678.1034712
   [Anonymous], 2008, ADV NATURAL LANGUAGE, V0, P0
   [Anonymous], 2008, P 22 INT C COMPUTATI, V0, P0, DOI DOI 10.3115/1599081.1599179
   [Anonymous], 2009, P 12 C EUROPEAN CHAP, V0, P0
   Anwar Waqas, 2007, INFORMATION TECHNOLOGY JOURNAL, V6, P1190
   Anwar W, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3418
   Azimizadeh A, 2008, 9 JADT, V0, P121
   Bhat Riyaz Ahmad, 2012, P 6 LINGUISTIC ANNOT, V0, P157
   Bird S, 2008, P 3 WORKSH ISS TEACH, V13, P62, DOI 10.3115/1627306.1627317
   Bird Steven, 2009, NATURAL LANGUAGE PRO, V0, P0
   Bogel T, 2007, FINITE STATE METHODS, V0, P86
   Brants T, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P224
   Butt, 1995, STRUCTURE COMPLEX PR, V0, P0
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Christensen H, 2014, HC CORPORA, V0, P0
   Christer S, 1996, 16 C COMPUTATIONAL L, V0, P895
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Cunningham H, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P168
   Cunningham H, 2013, PLOS COMPUT BIOL, V9, P0, DOI 10.1371/journal.pcbi.1002854
   Curran JR, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P91
   Dandapat S, 2008, P IJCAI WORKSH SHALL, V0, P29
   Daud A, 2017, ARTIF INTELL REV, V47, P279, DOI 10.1007/s10462-016-9482-x
   DERMATAS E, 1995, COMPUT LINGUIST, V21, P137
   Dietzel A, 2015, P POL STUD ASS 65 AN, V0, P1
   Ferrucci D, 2004, NATURAL LANGUAGE ENGINEERING, V10, P327, DOI 10.1017/S1351324904003523
   Fu GH, 2008, INFORM SCIENCES, V178, P2282, DOI 10.1016/j.ins.2008.01.001
   Gimenez J, 2004, P 4 INT C LANG RES E, V0, P0
   Gries ST, 2014, RES METHODS LINGUIST, V0, P257
   Hardie, 2004, THESIS LANCASTER U U, V0, P0
   Hardie Andrew, 2003, P CORPUS LINGUISTICS, V0, P298
   Hautli Annette, 2011, P ACL HLT STUDENT SE, V0, P24
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Javed, 1985, NAI URDU QAWAID, V0, P0
   Jawaid B, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2938
   Jeffreys H, 1961, THEORY PROBABILITY, V0, P0
   Joshi N, 2013, P 2013 INT C ART INT, V0, PP341, DOI 10.5121/CSIT.2013.3639
   Jurafsky D, 2014, SPEECH LANGUAGE PROC, V3, P0
   Khan SA, 2012, 24 INT C COMP LING, V0, P69
   Kreuzthaler M, 2015, BMC MED INFORM DECIS, V15, P0, DOI 10.1186/1472-6947-15-S2-S4
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Kwartler, 2017, TEXT MIN PRACT R, V0, PP237, DOI 10.1002/9781119282105.CH8
   Lehal GS, 2010, P 1 WORKSH S SE AS N, V0, P43
   Malik A, 2009, P NAM ENT WORKSH SIN, V0, P177
   Manning Christopher, 1999, FDN STAT NATURAL LAN, V0, P3
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Maynard D, 2015, P ACM WEB SCI C WEBS, V0, P46
   Nguyen MV, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, V0, P80
   Muaz A, 2009, P 7 WORKSH AS LANG R, V0, P24
   Mukund S, 2010, ACM T ASIAN LANG INF, V9, P1, DOI 10.1145/1838751.1838754
   Naz F, 2012, WORLD APPL SCI J, V16, P437
   Platts John, 1909, GRAMMAR HINDUSTANI U, V0, P0
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raj S, 2015, INT ARAB J INF TECHN, V12, P395
   Rashid R, 2012, INT CONF ASIAN LANG, V0, PP101, DOI 10.1109/IALP.2012.11
   Ratnaparkhi A, 1996, P C EMP METH NAT LAN, V1, P133
   Rehman Z, 2011, P 2 WORKSHOP S SE AS, V0, P40
   Rehman Z, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0068178
   Rehman Z, 2012, INT ARAB J INF TECHN, V9, P250
   Riaz K, 2012, IJCLNLP, V1, P92
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Saeed A, 2018, LANG RESOUR EVAL, V1, P1
   Sajjad H, 2007, THESIS NATL U COMPUT, V0, P0
   SCHMID LA, 1994, INT CONF ACOUST SPEE, V0, P41
   Schmidt RL, 1999, ROUTLEDGE ESSENTIAL, V1, P0
   Shafi, 2020, THESIS LANCASTER U U, V0, P0
   Sharjeel M, 2017, LANG RESOUR EVAL, V51, P777, DOI 10.1007/s10579-016-9367-2
   Tafseer A, 2009, P C LANG TECHN CLT 0, V0, P1
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Wicaksono AF, 2010, 4 INY MALINDO WORKSH, V0, P0
   Yi C, 2016, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION, V0, P81, DOI 10.1109/ICITBS.2015.26
NR 79
TC 3
Z9 3
U1 2
U2 10
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUL 15
PY 2023
VL 29
IS 4
BP 942
EP 977
DI 10.1017/S1351324921000425
EA JAN 2022
PG 36
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA M8CH8
UT WOS:000744337800001
DA 2023-11-10
ER

PT J
AU Yan, J
   Xie, YX
   Guo, YM
   Wei, YM
   Zhang, XP
   Luan, XD
AF Yan, Jie
   Xie, Yuxiang
   Guo, Yanming
   Wei, Yingmei
   Zhang, Xiaoping
   Luan, Xidao
TI CoCoOpter: Pre-train, prompt, and fine-tune the vision-language model for few-shot image classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Few-shot image classification; Contrastive vision-language pre-training; Prompt tuning; Multi-modal
ID network
AB Few-shot image classification aims at learning to generalize to unseen new categories from a few training samples. Transfer learning is one prominent approach to the task, which first learns a backbone from the base classes and then trains a classifier on new classes with the prior learned knowledge. Typically, the convolutional neural network (CNN) is the preferred backbone. However, when the samples are limited, the representation ability of the feature extracted by CNN will decrease, thus leading to the performance degradation of few-shot image classification. Recently, the pre-trained large-scale vision-language model like CLIP has shown non-trivial potential, which can be used as a backbone for zero or few-shot transfer on a series of downstream tasks with the prompt. To fully explore the few-shot image classification performance of vision-language models, we propose CoCoOpter, a novel "pre-training + prompt tuning + fine-tuning" paradigm based on CLIP. CoCoOpter alleviates the overfitting and ensures generalizability in unseen new categories. Specifically, it learns an input-specific neural network to relieve overfitting by drawing attention away from a specific category to each specific input sample. Then, to establish connection between the visual and textual signals, it introduces the previously learned visual representations to perform automatic prompt tuning in the middle of the pre-trained CLIP, enabling learning input-specified prompt vectors. Moreover, two learnable lightweight neural networks are added at the end of CLIP to guide information propagation between different classes by fine-tuning both the visual and textual features. We perform extensive experiments on 11 image classification datasets. The results show that CoCoOpter is more generalizable in unseen classes and achieves superior few-shot classification performance with a straightforward design.
C1 [Yan, Jie; Xie, Yuxiang; Guo, Yanming; Wei, Yingmei] Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Peoples R China.
   [Zhang, Xiaoping] Toronto Metropolitan Univ, Ryerson Univ, Finance Dept, Dept Elect Comp & Biomed Engn,Ted Rogers Sch Manag, Toronto, ON, Canada.
   [Luan, Xidao] Changsha Univ, Coll Comp Engn & Appl Math, Changsha 410000, Peoples R China.
C3 National University of Defense Technology - China; Toronto Metropolitan University; Changsha University
RP Wei, YM (通讯作者)，Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Peoples R China.
EM yjierrr@163.com; xyx89@163.com; guoyanming@nudt.edu.cn; weiyingmei@nudt.edu.cn; xzhang@ee.ryerson.ca; xidaoluan@ccsu.cn
FU This work was partially supported by the National Natural Science Foundation of China No. 61806218, the National Key Research and Development Program of China No. 2021YFB3100800, and the Ministry of Science and Technology of China No. 2020AAA0108800. [2021YFB3100800]; National Natural Science Foundation of China [2020AAA0108800]; National Key Research and Development Program of China; Ministry of Science and Technology of China;  [61806218]
CR Azizi S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP3458, DOI 10.1109/ICCV48922.2021.00346
   Bertinetto L, 2016, ADV NEU INF PROC SYS, V0, P523
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP347, DOI 10.1109/ICCV48922.2021.00041
   Chen MT, 2020, AAAI CONF ARTIF INTE, V34, P10559
   Chen T, 2020, P INT C MACH LEARN, V0, P1597
   Chen Wenhu, 2019, P INT C LEARNING REP, V0, P0
   Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW22), V0, PP2778, DOI 10.1145/3485447.3511998
   Chen ZT, 2019, PROC CVPR IEEE, V0, PP8672, DOI 10.1109/CVPR.2019.00888
   Cimpoi M, 2014, PROC CVPR IEEE, V0, PP3606, DOI 10.1109/CVPR.2014.461
   Dai XY, 2021, PROC CVPR IEEE, V0, PP7369, DOI 10.1109/CVPR46437.2021.00729
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, ARXIV, V0, P0
   Dosovitskiy A, 2021, P INT C LEARN REPR I, V0, P0
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Gao P, 2021, ARXIV, V0, P0, DOI DOI 10.1007/S11263-023-01891-X
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Jia C, 2021, PR MACH LEARN RES, V139, P0
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), V0, PP554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lee Yoonho, 2018, PR MACH LEARN RES, V0, PP2927, DOI 10.48550/ARXIV.1801.05558
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li M, 2022, CVPR, V0, P19880
   Li WB, 2019, PROC CVPR IEEE, V0, PP7253, DOI 10.1109/CVPR.2019.00743
   Li XX, 2021, IEEE T IMAGE PROCESS, V30, P1318, DOI 10.1109/TIP.2020.3043128
   Lifchitz Y, 2019, PROC CVPR IEEE, V0, PP9250, DOI 10.1109/CVPR.2019.00948
   Lin CC, 2021, IEEE T IMAGE PROCESS, V30, P9245, DOI 10.1109/TIP.2021.3124322
   Lin CC, 2019, IEEE IMAGE PROC, V0, PP3302, DOI 10.1109/ICIP.2019.8803420
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Maji S, 2013, ARXIV, V0, P0
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Parkhi OM, 2012, PROC CVPR IEEE, V0, PP3498, DOI 10.1109/CVPR.2012.6248092
   Pei YT, 2021, IEEE T CIRC SYST VID, V31, P2231, DOI 10.1109/TCSVT.2020.3016863
   Qi H, 2018, PROC CVPR IEEE, V0, PP5822, DOI 10.1109/CVPR.2018.00610
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rao YM, 2022, PROC CVPR IEEE, V0, PP18061, DOI 10.1109/CVPR52688.2022.01755
   Ravi Sachin, 2017, P ICLR, V0, P0
   Soomro K, 2012, ARXIV, V0, P0
   Sung F, 2018, PROC CVPR IEEE, V0, PP1199, DOI 10.1109/CVPR.2018.00131
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang WH, 2022, ARXIV, V0, P0
   Xiao JX, 2010, PROC CVPR IEEE, V0, PP3485, DOI 10.1109/CVPR.2010.5539970
   Xie XX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP3500, DOI 10.1109/ICCV48922.2021.00350
   Yaoyao Liu, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12361), V0, PP404, DOI 10.1007/978-3-030-58517-4_24
   Yin CX, 2022, IEEE T MULTIMEDIA, V24, P4183, DOI 10.1109/TMM.2021.3114541
   Yonglong Tian, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP266, DOI 10.1007/978-3-030-58568-6_16
   Zeng YW, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP2003, DOI 10.1145/3477495.3531795
   Zhang HG, 2019, PROC CVPR IEEE, V0, PP2765, DOI 10.1109/CVPR.2019.00288
   Zhao TZ, 2021, PR MACH LEARN RES, V139, P0
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
   Zhou Kaiyang, 2022, P IEEE CVF C COMP VI, V0, P16816
   Zhou L, 2021, IEEE T MULTIMEDIA, V23, P1035, DOI 10.1109/TMM.2020.2991592
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
   Zhu YH, 2021, IEEE T MULTIMEDIA, V23, P1200, DOI 10.1109/TMM.2020.2993952
NR 60
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC 15
PY 2023
VL 12
IS 2
BP 
EP 
DI 10.1007/s13735-023-00286-5
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering
SC Computer Science
GA P9KN6
UT WOS:001053793800002
DA 2023-11-10
ER

PT J
AU Chakraborty, K
   Bhattacharyya, S
   Bag, R
   Mrsic, L
AF Chakraborty, Koyel
   Bhattacharyya, Siddhartha
   Bag, Rajib
   Mrsic, Leo
TI Sentiment analysis on labeled and unlabeled datasets using BERT architecture
SO SOFT COMPUTING
LA English
DT Article; Early Access
DE Sentiment; Labeled; Unlabeled; BERT; Fuzzy; LAMB optimizer; Proximity
AB Sentiment analysis (SA) is the study of human perception in any subject of practice. It retrieves data from datasets using natural language processing (NLP) methodologies and algorithms that are either regulation-based, blended, or rely on machine learning approaches. SA is garnering fame for its capacity to fit in a large chunk of data with user evaluations, uncover a trend, and come to a consensus derived from real facts rather than hypotheses established on a limited number of observations. The flexible nature of sentiment gathering has helped in playing a critical role in both commercial and research applications in the last few years. This study presents new sentiment analysis models based on Bidirectional Encoder Representations from Transformers (BERT) for both labeled and unlabeled datasets. The labeled datasets using supervised learning are modeled in a hybrid architecture of fine-tuned BERT and interval Type-2 fuzzy sets. The inclusion of interval Type-2 fuzzy logic for handling reluctance or inaccuracy in data shows commendable results for the labeled datasets. For the prediction of sentiments in unlabeled datasets, they are embedded through a BERT tokenizer with the help of a threshold and activation functions. The coupling of a multi-layer perceptron with the BERT parser substantially decreases the time and complexity compared to supervised learning. Both the models have been implemented on multiple datasets and have outperformed existing state-of-the-art techniques in this field.
C1 [Chakraborty, Koyel] Supreme Knowledge Fdn Grp Inst, Mankundu, India.
   [Bhattacharyya, Siddhartha] Rajnagar Mahavidyalaya, Rajnagar, India.
   [Bag, Rajib] Indas Mahavidyalaya, Indas, Bankura, India.
   [Bhattacharyya, Siddhartha; Mrsic, Leo] Algebra Univ Coll, Zagreb, Croatia.
   [Mrsic, Leo] Rudolfovo Sci & Technol Ctr, Podbreznik 15, Novo Mesto 8000, Slovenia.
RP Bhattacharyya, S (通讯作者)，Rajnagar Mahavidyalaya, Rajnagar, India.; Bhattacharyya, S (通讯作者)，Algebra Univ Coll, Zagreb, Croatia.
EM koyel.chak88@gmail.com; dr.siddhartha.bhattacharyya@gmail.com; rajib.bag@gmail.com; leo.mrsic@algebra.hr
CR Abirami AM, 2017, INT CONF ADV COMPU, V0, PP72, DOI 10.1109/ICoAC.2017.7951748
   Aguzzoli S, 2011, HDB MATH FUZZY LOGIC, V0, P713
   Ahmad M, 2017, INT J MULTIDISCIPLIN, V8, P27
   Bachina S, 2021, P 1 WORKSH DOC GROUN, V0, P63
   Calhoun Vince D, 2016, BIOL PSYCHIATRY COGN NEUROSCI NEUROIMAGING, V1, P230
   Chakraborty K, 2022, INTELLIGENCE ENABLED, V0, PP41, DOI 10.1007/978-981-19-0489-9_4
   Chakraborty K, 2020, APPL SOFT COMPUT, V97, P0, DOI 10.1016/j.asoc.2020.106754
   Chakraborty K, 2020, IEEE T COMPUT SOC SY, V7, P450, DOI 10.1109/TCSS.2019.2956957
   Chowdhary K, 2020, FUNDAM ARTIF INTELL, V0, PP603, DOI 10.1007/978-81-322-3972-7_19
   COVER TM, 1969, ANN MATH STAT, V40, P828, DOI 10.1214/aoms/1177697590
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9030483
   Devlin J, 2019, ARXIV, V0, P0
   Dharma EM, 2022, J THEOR APPL INF TEC, V100, P31
   Gon?alves P, 1900, P27, V0, P0, DOI DOI 10.1145/2512938.2512951
   Goularas Dionysis, 2019, 2019 INTERNATIONAL CONFERENCE ON DEEP LEARNING AND MACHINE LEARNING IN EMERGING APPLICATIONS (DEEP-ML). PROCEEDINGS, V0, PP12, DOI 10.1109/Deep-ML.2019.00011
   Grasso M, 2015, QUAL RELIAB ENG INT, V31, P75, DOI 10.1002/qre.1708
   Hameed IA, 2011, EXPERT SYST APPL, V38, P7135, DOI 10.1016/j.eswa.2010.12.048
   Hutto CJ, 2014, ICWSM, V0, P0, DOI DOI 10.1609/ICWSM.V8I1.14550
   Kim TK, 2017, KOREAN J ANESTHESIOL, V70, P22, DOI 10.4097/kjae.2017.70.1.22
   Kim TK, 2015, KOREAN J ANESTHESIOL, V68, P540, DOI 10.4097/kjae.2015.68.6.540
   Li W, 2022, NEUROCOMPUTING, V467, P73, DOI 10.1016/j.neucom.2021.09.057
   Liu B, 2020, J AMB INTEL HUM COMP, V11, P451, DOI 10.1007/s12652-018-1095-6
   McCormick C, 2016, WORD2VEC TUTORIAL SK, V0, P0
   Mejova Y, 2009, SENTIMENT ANAL OVERV, V0, P0
   Mohammed M, 2022, SOFT COMPUT, V0, P0, DOI DOI 10.21203/rs.3.rs-1216679/v1
   Park CW, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), V0, PP495, DOI 10.1109/IEA.2018.8387151
   Ray B, 2021, APPL SOFT COMPUT, V98, P0, DOI 10.1016/j.asoc.2020.106935
   Ren X, 2015, IND ENG CHEM RES, V54, P10001, DOI 10.1021/acs.iecr.5b01267
   Richardson Leonard, 2007, BEAUTIFUL SOUP DOCUM, V0, P0
   Rodrigues AP, 2022, COMPUT INTEL NEUROSC, V2022, P0, DOI 10.1155/2022/5211949
   Ross TJ, 2010, FUZZY LOGIC ENG APPL, V0, P0, DOI DOI 10.1002/9781119994374
   Saif H, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P810
   Serrano-Guerrero J, 2022, INT J INTELL SYST, V37, P2885, DOI 10.1002/int.22634
   Singh C, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12083709
   Nguyen T, 2015, EXPERT SYST APPL, V42, P4370, DOI 10.1016/j.eswa.2015.01.036
   Valle-Cruz D, 2022, COGN COMPUT, V14, P372, DOI 10.1007/s12559-021-09819-8
   Wu ST, 2022, CONNECT SCI, V34, P44, DOI 10.1080/09540091.2021.1940101
   Xiaoting Guo, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1757, P0, DOI 10.1088/1742-6596/1757/1/012038
   Yahia NB, 2012, INT J COMPUT SCI ISS, V9, P117
   You Y, 2020, ARXIV, V0, P0
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang BJ, 2022, COMPUT INTEL NEUROSC, V2022, P0, DOI 10.1155/2022/9308236
   Zhang W, 2022, IEEE T KNOWL DATA EN, V0, P0, DOI DOI 10.1109/TKDE.2022.3230975
   Zhang ZY, 2022, COMPLEX INTELL SYST, V8, P3349, DOI 10.1007/s40747-022-00678-w
NR 51
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s00500-023-08876-5
EA JUL 2023
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA L6TB4
UT WOS:001024555100002
DA 2023-11-10
ER

PT J
AU Rodler, P
AF Rodler, Patrick
TI Sequential model-based diagnosis by systematic search
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Model-based diagnosis; Sequential diagnosis; Query-based debugging; Interactive debugging; Combinatorial search; Diagnostic decision-making; Fault localization; Measurement selection; Knowledge-base debugging; Ontologies; Query computation; Active learning; Heuristics
ID ontology; owl; algorithm
AB Model-based diagnosis aims at identifying the real cause of a system's malfunction based on a formal system model and observations of the system behavior. To discriminate between multiple fault hypotheses (diagnoses), sequential diagnosis approaches iteratively pose queries to an oracle to acquire additional knowledge about the diagnosed system. Depending on the system type, queries can capture, e.g., system tests, probes, measurements, or expert questions. As the determination of optimal queries is NP-hard, state-of-the-art sequential diagnosis methods rely on a myopic one-step-lookahead analysis which has proven to constitute a particularly favorable trade-off between computational efficiency and diagnostic effectivity. Yet, this solves only a part of the problem, as various sources of complexity, such as the reliance on costly reasoning services and large numbers of or not explicitly given query candidates, remain. To deal with such issues, existing approaches often make assumptions about the (i) type of diagnosed system, (ii) formalism to describe the system, (iii) inference engine, (iv) type of query to be of interest, (v) query quality criterion to be adopted, or (vi) diagnosis computation algorithm to be employed. Moreover, they (vii) often cannot deal with large or implicit query spaces or with expressive logics, or (viii) require inputs that cannot always be provided. As a remedy, we propose a novel one-step lookahead query computation technique for sequential diagnosis that overcomes the said issues of existing methods. Our approach (1) is based on a solid theory, (2) involves a systematic search for optimal queries, (3) can operate on implicit and huge query spaces, (4) allows for a two-stage optimization of queries (wrt. their number and cost), (5) is designed to reduce expensive logical inferences to a minimum, and (6) is generally applicable. The latter means that it can deal with any type of diagnosis problem as per Reiter's theory, is applicable with any monotonic knowledge representation language, can interact with a multitude of diagnosis engines and logical reasoners, and allows for a quality optimization of queries based on any of the common criteria in the literature. We extensively study the performance of the novel technique using a benchmark of real-world diagnosis problems. Our findings are that our approach enables the computation of optimal queries with hardly any delay, independently of the size and complexity of the considered benchmark problem. Moreover, it proves to be highly scalable, and it outperforms the state-of-the-art method in the domain of our benchmarks by orders of magnitude in terms of computation time while always returning a qualitatively as good or better query. (c) 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Rodler, Patrick] Univ Klagenfurt, Univ Str 65-67, Klagenfurt, Austria.
C3 University of Klagenfurt
RP Rodler, P (通讯作者)，Univ Klagenfurt, Univ Str 65-67, Klagenfurt, Austria.
EM patrick.rodler@aau.at
FU Austrian Science Fund (FWF);  [P -32445-N38]
CR Abburu Sunitha, 2012, INT J COMPUTER APPL, V57, P0
   Abreu Rui, 2009, SARA, V0, P0
   Abu-Khzam FN, 2010, J COMPUT SYST SCI, V76, P524, DOI 10.1016/j.jcss.2009.09.002
   [Anonymous], 2020, ECAI, V0, P0
   Baader Franz, 2007, DESCRIPTION LOGIC HD, V2nd, P0
   Bagchi TP, 2001, LECT NOTES COMPUT SC, V1993, P458
   Bail Samantha, 2013, OWL REAS EV ORE WORK, V0, P0
   Blanco C, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, V0, P813, DOI 10.1109/ARES.2008.33
   Brewka Gerhard, 1989, IJCAI, V0, P0
   CERASO J, 1971, COGNITIVE PSYCHOL, V2, P400, DOI 10.1016/0010-0285(71)90023-5
   Ceri Stefano, 1989, IEEE T KNOWL DATA EN, VI, P0
   Chandrasekaran K, 2011, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, V0, P614
   Cook SA, 1971, PROCEEDINGS OF THE 3RD ANNUAL ACM SYMPOSIUM ON THEORY OF COMPUTING, V0, P151
   Darwiche Adnan, 1996, DX, V0, P0
   Davis Randall, 1988, ARTIF INTELL, V8, P297
   de Kleer Johan, 1989, IJCAI, V0, P0
   de Kleer Johan, 1992, READINGS MODEL BASED, V0, P138
   de Kleer Johan, 1993, 5, V0, P0
   de Kleer Johan, 1991, AAAI, V0, P0
   de Kleer Johan, 2004, SAFEPROCESS, V0, P0
   de Kleer Johan, 1995, IJCAI, V0, P0
   de Kleer Johan, 1987, AAAI, V0, P0
   Dechter R, 2003, CONSTRAINT PROCESSIN, V0, P0
   DEKLEER J, 1992, ARTIF INTELL, V56, P197, DOI 10.1016/0004-3702(92)90027-U
   DEKLEER J, 1987, ARTIF INTELL, V32, P97, DOI 10.1016/0004-3702(87)90063-4
   Del Vescovo C, 2010, FRONT ARTIF INTEL AP, V210, P11, DOI 10.3233/978-1-60750-544-0-11
   Do Minh Binh, 2008, AAAI, V0, P0
   Downey Rodney, 2013, FUNDAMENTALS PARAMET, V4, P0
   Dressler Oskar, 1996, KR, V0, P0
   Feldman A, 2010, J ARTIF INTELL RES, V39, P301, DOI 10.1613/jair.3031
   Feldman Alexander, 2008, AAAI, V0, P0
   Felfernig A, 2004, ARTIF INTELL, V152, P213, DOI 10.1016/S0004-3702(03)00117-6
   Felfernig A, 2009, APPL INTELL, V31, P1, DOI 10.1007/s10489-007-0105-8
   Gonzalez-Sanchez A, 2011, SOFTWARE PRACT EXPER, V41, P1105, DOI 10.1002/spe.1065
   Gonzalez-Sanchez Alberto, 2011, AAAI, V0, P0
   Gonzalez-Sanchez Alberto, 2010, ICQS, V0, P0
   Gonzalez-Sanchez Alberto, 2011, ASE, V0, P0
   Grau BC, 2008, J WEB SEMANT, V6, P309, DOI 10.1016/j.websem.2008.05.001
   GREINER R, 1989, ARTIF INTELL, V41, P79, DOI 10.1016/0004-3702(89)90079-9
   Han B, 1999, INFORM SCIENCES, V120, P223, DOI 10.1016/S0020-0255(99)00071-7
   HECKERMAN D, 1995, COMMUN ACM, V38, P49, DOI 10.1145/203330.203341
   Heiner Stuckenschmidt, 2008, EON, V0, P0
   Hofmann Martin, 1993, CAIA, V0, P0
   Horridge M, 2011, LECT NOTES COMPUT SC, V7031, P241, DOI 10.1007/978-3-642-25073-6_16
   Horridge M, 2008, LECT NOTES COMPUT SC, V5318, P323, DOI 10.1007/978-3-540-88564-1_21
   Horridge Matthew, 2011, THESIS U MANCHESTER, V0, P0
   Hyafil L, 1976, INFORMATION PROCESSING LETTERS, V5, P15, DOI 10.1016/0020-0190(76)90095-8
   Jannach Dietmar, 2016, JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH, V55, P835
   Jiang Yun-Fei, 2003, CHINESE JOURNAL OF COMPUTERS, V26, P919
   Junker U, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, V0, P167
   Kalyanpur A, 2006, LECT NOTES COMPUT SC, V4011, P170
   Kalyanpur Aditya, 2006, THESIS U MARYLAND CO, V0, P0
   Karp RM, 1972, REDUCIBILITY COMBINA, V0, PP85, DOI 10.1007/978-1-4684-2001-2_9
   Kazakov Y, 2014, J AUTOM REASONING, V53, P1, DOI 10.1007/s10817-013-9296-3
   Klischewski R, 2003, LECT NOTES COMPUT SC, V2739, P288
   Knuth DE, 1997, ART COMPUTER PROGRAM, V1, P0
   Marques-Silva Joao, 2013, CAV, V0, P0
   Mateis Cristinel, 2000, AADEBUG, V0, P0
   Meilicke C, 2011, THESIS U MANNHEIM, V0, P0
   MORET BME, 1982, COMPUT SURV, V14, P593, DOI 10.1145/356893.356898
   Motik Boris, 2009, W3C RECOMMENDATION, V0, P1
   Musen Mark A, 2015, AI MATTERS, V1, P4
   Nica Iulia, 2013, IJCAI, V0, P0
   Noy NF, 2009, NUCLEIC ACIDS RES, V37, PW170, DOI 10.1093/nar/gkp440
   Odintsova Natalia, 2003, IJCAI, V0, P0
   Parsia Bijan, 2005, WWW, V0, P0
   Patel-Schneider Peter F, 2004, W3C RECOMMENDATION, V0, P0
   Patrick Rodler DynamicHS, 2023, INFORM SCIENCES, V627, P251
   PATTIPATI KR, 1990, IEEE T SYST MAN CYB, V20, P872, DOI 10.1109/21.105086
   Penaloza Rafael, 2019, MDAI, V0, P0
   Pencolé Y, 2005, ARTIF INTELL, V164, P121, DOI 10.1016/j.artint.2005.01.002
   Pietersma J, 2005, IEEE AUTOTESTCON, V0, P621
   Pill I, 2012, FRONT ARTIF INTEL AP, V242, P648, DOI 10.3233/978-1-61499-098-7-648
   Qi GL, 2007, LECT NOTES COMPUT SC, V4825, P381
   Quine Willard V, 1952, AM MATH MON, V59, P521, DOI 10.1080/00029890.1952.11988183
   Quinlan JR, 1986, MACHINE LEARNING, V1, P81, DOI 10.1023/A:1022643204877
   REITER R, 1987, ARTIF INTELL, V32, P57, DOI 10.1016/0004-3702(87)90062-2
   Rodler P, 2017, ARXIV, V0, P0
   Rodler P, 2022, KNOWL-BASED SYST, V251, P0, DOI 10.1016/j.knosys.2022.108987
   Rodler P, 2022, ARTIF INTELL REV, V55, P6185, DOI 10.1007/s10462-022-10149-w
   Rodler P, 2022, ARTIF INTELL, V305, P0, DOI 10.1016/j.artint.2022.103681
   Rodler P, 2019, KNOWL-BASED SYST, V179, P92, DOI 10.1016/j.knosys.2019.05.006
   Rodler P, 2018, LECT NOTES COMPUT SC, V11092, P164, DOI 10.1007/978-3-319-99906-7_11
   Rodler Patrick, 2015, THESIS, V0, P0
   Rodler Patrick, 2023, ECAI, V0, P0
   Rodler Patrick, 2019, IEA AIE, V0, P0
   Rodler Patrick, 2018, SOCS, V0, P0
   Rodler Patrick, 2021, SOCS, V0, P0
   Rodler Patrick, 2022, AAAI, V0, P0
   Rodler Patrick, 2022, APPENDIX PAPER SEQUE, V0, P0
   Rodler Patrick, 2017, DX, V0, P0
   Rodler Patrick, 2021, KR, V0, P0
   Rodler Patrick, 2013, RR, V0, P0
   Rossi F, 2006, FOUND ARTIF INTELL, V0, P1
   Roussey C, 2009, K-CAP09: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, V0, P205
   Russell, 2010, ARTIF INTELL, V0, P0
   Schekotihin Konstantin, 2018, FOIKS, V0, P0
   Schekotihin Konstantin, 2018, ICBO, V0, P0
   Schlobach S, 2007, J AUTOM REASONING, V39, P317, DOI 10.1007/s10817-007-9076-z
   Shakeri M, 2000, IEEE T SYST MAN CY A, V30, P1, DOI 10.1109/3468.823474
   Shchekotykhin K, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P3221
   Shchekotykhin K, 2014, FRONT ARTIF INTEL AP, V263, P813, DOI 10.3233/978-1-61499-419-0-813
   Shchekotykhin K, 2012, J WEB SEMANT, V12-13, P88, DOI 10.1016/j.websem.2011.12.006
   Shearer Rob, 2008, OWLED, V0, P0
   Siddiqi S, 2011, J ARTIF INTELL RES, V41, P329, DOI 10.1613/jair.3296
   Siddiqi Sajjad, 2008, ISAIM, V0, P0
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   Steinbauer G, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), V0, P1742
   Stumptner M, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1074
   Tsarkov D, 2006, LECT NOTES ARTIF INT, V4130, P292
   White J, 2010, J SYST SOFTWARE, V83, P1094, DOI 10.1016/j.jss.2010.02.017
   Wotawa F, 2002, ARTIF INTELL, V135, P125, DOI 10.1016/S0004-3702(01)00161-8
   Zamir T, 2014, AAAI CONF ARTIF INTE, V0, P1135
   Zenuni X, 2015, WORLD CONFERENCE ON TECHNOLOGY, V0, P1990, DOI 10.1016/j.sbspro.2015.06.213
   Zolin Evgeny, 2021, COMPLEXITY REASONING, V0, P0
   Zuzek A, 2000, MICROPROCESS MICROSY, V24, P191, DOI 10.1016/S0141-9331(00)00073-9
NR 116
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL-AMST
JI Artif. Intell.
PD OCT 15
PY 2023
VL 323
IS 
BP 
EP 
DI 10.1016/j.artint.2023.103988
PG 52
WC Computer Science, Artificial Intelligence
SC Computer Science
GA R9HK1
UT WOS:001067387600001
DA 2023-11-10
ER

PT J
AU Munir, K
   Zhao, H
   Li, ZC
AF Munir, Kashif
   Zhao, Hai
   Li, Zuchao
TI Semi-Supervised Semantic Role Labeling with Bidirectional Language Models
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Semantic role labeling; semantic parsing; syntax; language models; dependency; contextualized representations; path embedding; unsupervised; CoNLL-2008; CoNLL-2009; semi-supervised
ID neural-networks
AB The recent success of neural networks in NLP applications has provided a strong impetus to develop supervised models for semantic role labeling (SRL) that forego the requirement for extensive feature engineering. Recent state-of-the-art approaches require high-quality annotated datasets that are costly to obtain and almost unavailable for low-resource languages. We present a semi-supervised approach that utilizes both labeled and unlabeled data to provide performance improvement over a mere supervised SRL model. We show that our proposed semi-supervised SRL model provides larger improvement over a supervised model in the scenario where labeled training data size is small. Our SRL system leverages unlabeled data under the language modeling paradigm. We demonstrate that the incorporation of a self pretrained bidirectional language model (S-PrLM) into a SRL system can help in SRL performance improvement by learning composition functions from the unlabeled data. Previous researches have concluded that syntax information is very useful for high-performing SRL systems, so we incorporate syntax information by employing an unsupervised approach to leverage dependency path information to connect argument candidates in vector space, which helps in distinguishing arguments with similar contexts but different syntactic functions. The basic idea is to connect predicate (w(p)) with argument candidate (w(a)) with the dependency path (r) between them in the embedding space. Experiments on the CoNLL-2008 and CoNLL-2009 datasets confirm that our full SRL model outperforms previous best models in terms of F-1 score.
C1 [Munir, Kashif; Zhao, Hai; Li, Zuchao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
   [Munir, Kashif; Zhao, Hai; Li, Zuchao] Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interac, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
   [Munir, Kashif; Zhao, Hai; Li, Zuchao] Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.; Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interac, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.; Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
EM kashifmunir92@sjtu.edu.cn; zhaohai@cs.sjtu.edu.cn; charlee@sjtu.edu.cn
FU Key Projects of National Natural Science Foundation of China [U1836222, 61733011]
CR Abualigah LMQ, 2019, FEATURE SELECTION EN, V0, P0
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   [Anonymous], 2010, P 23 INT C COMPUTATI, V0, P0
   [Anonymous], 2015, P 2015 C EMPIRICAL M, V0, P0
   [Anonymous], 2005, P 43 ANN M ASS COMPU, V0, P0, DOI DOI 10.3115/1219840.1219912
   [Anonymous], 2017, P 21 C COMP NAT LANG, V0, P0, DOI DOI 10.18653/V1/K17-1041
   [Anonymous], 2015, ASS COMPUTATIONAL LI, V0, P0
   Antiqueira L, 2009, INFORM SCIENCES, V179, P584, DOI 10.1016/j.ins.2008.10.032
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Berant J, 2013, P 2013 C EMPIRICAL M, V0, P0
   Bjorkelund A, 2009, P 13 C COMP NAT LANG, V0, P43
   Bordes Antoine, 2011, AAAI, V25, P0
   Cai D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P409
   Cai Jiaxun, 2018, P 27 INT C COMP LING, V0, P2753
   Cai R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1018
   Chelba C, 2014, ARXIV, V0, P0
   Chen CT, 2019, INFORM SCIENCES, V502, P268, DOI 10.1016/j.ins.2019.06.050
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/TACL_A_00104
   Chung-HsienWu Ze-Jing, 2006, ACM T ASIAN LANGUAGE, V5, P165, DOI 10.1145/1165255.1165259
   Clark K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1914
   Devlin J, 2019, ARXIV, V0, P0
   Devlin J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1370
   Dozat T, 2017, ARXIV, V0, P0
   Frinken V, 2012, LECT NOTES COMPUT SC, V7626, P611, DOI 10.1007/978-3-642-34166-3_67
   Fürstenau H, 2012, COMPUT LINGUIST, V38, P135
   Geng ZQ, 2020, INFORM SCIENCES, V509, P183, DOI 10.1016/j.ins.2019.09.006
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hajic J, 2009, P 13 C COMP NAT LANG, V0, PP1, DOI 10.3115/1596409.1596411
   He LH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P473, DOI 10.18653/v1/P17-1044
   He SX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2061
   Johansson R, 2008, P 12 C COMPUTATIONAL, V0, P183
   Jozefowicz R, 2016, ARXIV, V0, P0
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Koehn P, 2009, STAT MACHINE TRANSLA, V0, P0, DOI DOI 10.1017/CBO9780511815829
   Kombrink S, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2888
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Lang Joel, 1900, P1320, V0, P0
   Lang Joel, 2011, P 49 ANN M ASS COMPU, V0, P1117
   Lei Tao, 2015, P 2015 C N AM CHAPTE, V0, P1150
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Li Junhui, 2009, P 2009 C EMPIRICAL M, V0, P1280
   Li Z, 2018, P 27 INT C COMP LING, V0, P3203
   Li ZC, 2019, AAAI CONF ARTIF INTE, V0, P6730
   Liu WY, 2010, INFORM SCIENCES, V180, P4031, DOI 10.1016/j.ins.2010.06.021
   Luan Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P118
   Marcheggiani D, 2017, ARXIV170304826, V0, P0, DOI DOI 10.18653/V1/D17-1159
   Mehta SV, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4958
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, ARXIV, V0, P0
   Mirowski P, 2015, ARXIV, V0, P0
   Munir K, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3461613
   Munir K, 2021, IEEE-ACM T AUDIO SPE, V29, P782, DOI 10.1109/TASLP.2020.3048665
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Oh HJ, 2007, INFORM SCIENCES, V177, P3696, DOI 10.1016/j.ins.2007.02.038
   Peris A, 2015, PROCES LENG NAT, V0, P109
   Peters ME, 2017, SEMISUPERVISED SEQUE, V0, P0
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   Qian Feng, 2017, P 2 WORKSHOP STRUCTU, V0, P27
   Qin L, 2016, P 26 INT C COMPUTATI, V0, P1914
   Do QTN, 2015, IEEE-ACM T AUDIO SPE, V23, P1812, DOI 10.1109/TASLP.2015.2449072
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Roth M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1192
   RuiWang Hai Zhao, 2016, P 26 INT C COMPUTATI, V0, P3135
   Shi C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2245
   Shi P, 2019, ARXIV, V0, P0
   Sogaard A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P231
   Surdeanu M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P8
   Surdeanu M, 2008, P 12 C COMP NAT LANG, V0, PP159, DOI 10.3115/1596324.1596352
   Titov Ivan, 2012, P 24 INT C COMPUTATI, V0, P2635
   Yan S, 2014, IEEE-ACM T AUDIO SPE, V22, P2048, DOI 10.1109/TASLP.2014.2360461
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yang ZL, 2017, ARXIV, V0, P0
   Yin YC, 2016, ARXIV, V0, P0
   Zhang YB, 2019, INFORM SCIENCES, V477, P55, DOI 10.1016/j.ins.2018.10.030
   Zhang ZS, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1382
   Zhang Zhuosheng, 2018, P 27 INT C COMPUTATI, V0, P1802
   Zhao H, 2013, J ARTIF INTELL RES, V46, P203, DOI 10.1613/jair.3717
   Zhao Hai, 2009, P 13 C COMP NAT LANG, V0, P61
   Zhao Hai, 2009, P 2009 C EMPIRICAL M, V0, P30
   Zhao Hongzhong, 2009, PROCEEDINGS OF THE 2009 2ND ASIAN-PACIFIC CONFERENCE ON SYNTHETIC APERTURE RADAR (APSAR 2009), V0, PP55, DOI 10.1109/APSAR.2009.5374342
   Zhou J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1127
   Zhou Junru, 2020, FINDINGS ASS COMPUTA, V0, P4438
   Zuchao L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2401
NR 84
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN 15
PY 2023
VL 22
IS 6
BP 
EP 
DI 10.1145/3587160
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K7YR0
UT WOS:001018562700008
DA 2023-11-10
ER

PT J
AU Zheng, QH
   Peng, Z
   Dang, ZH
   Zhu, LC
   Liu, ZQ
   Zhang, ZQ
   Zhou, J
AF Zheng, Qinghua
   Peng, Zhen
   Dang, Zhuohang
   Zhu, Linchao
   Liu, Ziqi
   Zhang, Zhiqiang
   Zhou, Jun
TI Deep Tabular Data Modeling With Dual-Route Structure-Adaptive Graph Networks
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Feature interactions; graph neural networks; graph structure learning; message passing; tabular data
AB Thanks to the inherent spatial or sequential structures underlying the data like images and texts, deep architectures such as convolutional neural networks (CNNs) and the Transformer have been recognized as the preeminent approaches in image processing and language modeling. In the real world, there are a large number of tabular data without any explicit structures, which breaks the inductive bias of most neural networks like CNNs. Although multi-layer perceptrons (MLPs) obtain empirical success on tabular data, they cannot well explain the underlying relationship between multiple variables. Compared with other fields, research on deep models toward tabular data has received relatively less scrutiny. To bridge this gap, we propose Dual-Route Structure-Adaptive Graph Networks (DRSA-Net) to model the nonlinearity in tabular feature vectors without any prior. DRSA-Net adaptively learns a sparse graph structure between variables and then characterizes interactions between them from the view of dual-route message passing. We demonstrate that DRSA-Net could easily degenerate into the typical MLPs and factorization machines (FMs). Extensive experiments on recommendations, images (no spatial information after preprocessing), and some benchmark machine learning datasets show that DRSA-Net achieves comparable or superior performance with many classic algorithms and recently proposed deep models.
C1 [Zheng, Qinghua; Peng, Zhen; Dang, Zhuohang] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Natl Engn Lab Big Data Analyt, Minist Educ,Key Lab Intelligent Networks & Network, Xian 710049, Peoples R China.
   [Zhu, Linchao] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310058, Peoples R China.
   [Liu, Ziqi; Zhang, Zhiqiang; Zhou, Jun] Ant Grp, AI Dept, Hangzhou 310013, Zhejiang, Peoples R China.
C3 Xi'an Jiaotong University; Zhejiang University
RP Zheng, QH (通讯作者)，Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Natl Engn Lab Big Data Analyt, Minist Educ,Key Lab Intelligent Networks & Network, Xian 710049, Peoples R China.
EM qhzheng@xjtu.edu.cn; zhenpeng27@outlook.com; dangzhuohang@stu.xjtu.edu.cn; linchao.zhu@uts.edu.au; ziqiliu@antgroup.com; lingyao.zzq@antgroup.com; jun.zhoujun@antgroup.com
FU National Key Research and Development Program of China [2020AAA0108800]; National Nature Science Foundation of China [62192781, 62272374, 62250009, 62137002, 61937001, 61721002]; Innovative Research Group of the National Natural Science Foundation of China [IRT_17R86]; Innovation Research Team of Ministry of Education; CCF-AFSG Research Fund; Project of China Knowledge Center for Engineering Science and Technology; Project of Chinese academy of engineering;  [62202367]
CR [Anonymous], 2010, PROC IEEE INT C DATA, V0, P0
   Arik SO, 2021, AAAI CONF ARTIF INTE, V35, P6679
   Bello I, 2019, IEEE I CONF COMP VIS, V0, PP3285, DOI 10.1109/ICCV.2019.00338
   Borisov V, 2022, ARXIV, V0, P0
   Buza K, 2014, STUD CLASS DATA ANAL, V0, PP145, DOI 10.1007/978-3-319-01595-8_16
   Cai SF, 2021, INT CONF MANAGE DATA, V0, PP207, DOI 10.1145/3448016.3457321
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1961189.1961199
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Chen Yu, 2020, NEURIPS, V33, P19314
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Franceschi Luca, 2019, INT C MACH LEARN, V0, P1972
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao X, 2020, PROC IEEE INT C MULT, V0, P1
   Gilmer J, 2017, PR MACH LEARN RES, V70, P0
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   Graf F, 2011, LECT NOTES COMPUT SC, V6892, P607, DOI 10.1007/978-3-642-23629-7_74
   Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1725
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Harper FM, 2016, ACM T INTERACT INTEL, V5, P0, DOI 10.1145/2827872
   He Kaiming, 2015, P IEEE INT C COMPUTE, V0, PP1026, DOI 10.1109/ICCV.2015.123
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang X, 2020, ARXIV, V0, P0
   Huynh NA, 2017, LECT NOTES ARTIF INT, V10558, P18, DOI 10.1007/978-3-319-67786-6_2
   Jin W, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP66, DOI 10.1145/3394486.3403049
   Juan YC, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS16), V0, PP43, DOI 10.1145/2959100.2959134
   Kadra A, 2021, ADV NEURAL INF PROCE, V34, P23928, DOI 10.48550/ARXIV.2106.11189
   Katzir L, 2021, INT C LEARN REPR, V0, P0
   Ke GL, 2017, ADV NEUR IN, V30, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Krizhevsky A, 2009, CIFAR 10, V0, P0
   Le Cun Y, 1989, ADV NEURAL INFORM PR, V2, P396, DOI 10.1111/DSU.12130
   Li RY, 2018, AAAI CONF ARTIF INTE, V0, P3546
   Li ZK, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP539, DOI 10.1145/3357384.3357951
   Li ZY, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM 20), V0, PP313, DOI 10.1145/3336191.3371785
   Liu ZQ, 2019, AAAI CONF ARTIF INTE, V0, P4424
   Louizos Christos, 2018, P 6 INT C LEARN REPR, V0, P0
   Luo DS, 2021, WSDM 21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP779, DOI 10.1145/3437963.3441734
   Pedregosa F, 2011, J MACHINE LEARNING R, V12, P2825
   Prokhorenkova L, 2018, ADV NEUR IN, V31, P0
   Rahimi Ali, 2007, ADV NEURAL INFORM PR, V20, P4, DOI 10.5555/2981562.2981710
   Rendle Steffen, 2010, PROCEEDINGS 2010 10TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING (ICDM 2010), V0, PP995, DOI 10.1109/ICDM.2010.127
   Scholkopf B, 2002, LEARNING KERNELS SUP, V0, P0
   Shi LS, 2021, PROC CVPR IEEE, V0, PP8990, DOI 10.1109/CVPR46437.2021.00888
   Song WP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP1161, DOI 10.1145/3357384.3357925
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Vaswani A, 2017, ARXIV, V30, P5998
   Velickovi P, 2018, INT C LEARNING REPRE, V0, P0
   Velickovie P, 2020, P ADV NEUR INF PROC, V0, P2232
   Wang K, 2011, IEEE I CONF COMP VIS, V0, PP1457, DOI 10.1109/ICCV.2011.6126402
   Wang S, 2017, SIAM INT C DAT MIN S, V0, PP1, DOI 10.1038/s41598-016-0028-x
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xiao J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3119
   Xu K, 2018, IEEE INT SYMP CIRC S, V0, P0, DOI DOI 10.1109/ISCAS.2018.8350934
   Yang C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P2111
   Yang YX, 2018, ARXIV, V0, P0
   Ye Y, 2023, IEEE T KNOWL DATA EN, V35, P905, DOI 10.1109/TKDE.2021.3072345
   Yu DH, 2021, LECT NOTES ARTIF INT, V12459, P378, DOI 10.1007/978-3-030-67664-3_23
   Zhang JN, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, V0, P339
   Zhang YX, 2019, AAAI CONF ARTIF INTE, V0, P5829
   Zhao T, 2021, AAAI CONF ARTIF INTE, V35, P11015
   Zhu Y, 2021, DEEP GRAPH STRUCTURE, V0, P0
NR 62
TC 0
Z9 0
U1 8
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD SEPT 1
PY 2023
VL 35
IS 9
BP 9715
EP 9727
DI 10.1109/TKDE.2023.3249186
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA O7QE8
UT WOS:001045704800073
DA 2023-11-10
ER

PT J
AU Bawa, P
   Kadyan, V
   Tripathy, A
   Singh, TP
AF Bawa, Puneet
   Kadyan, Virender
   Tripathy, Abinash
   Singh, Thipendra P.
TI Developing sequentially trained robust Punjabi speech recognition system under matched and mismatched conditions
SO COMPLEX & INTELLIGENT SYSTEMS
LA English
DT Article
DE Sequence discriminative training; Children speech recognition; Data augmentation; Mismatched conditions
ID noise; model
AB Development of a native language robust ASR framework is very challenging as well as an active area of research. Although an urge for investigation of effective front-end as well as back-end approaches are required for tackling environment differences, large training complexity and inter-speaker variability in achieving success of a recognition system. In this paper, four front-end approaches: mel-frequency cepstral coefficients (MFCC), Gammatone frequency cepstral coefficients (GFCC), relative spectral-perceptual linear prediction (RASTA-PLP) and power-normalized cepstral coefficients (PNCC) have been investigated to generate unique and robust feature vectors at different SNR values. Furthermore, to handle the large training data complexity, parameter optimization has been performed with sequence-discriminative training techniques: maximum mutual information (MMI), minimum phone error (MPE), boosted-MMI (bMMI), and state-level minimum Bayes risk (sMBR). It has been demonstrated by selection of an optimal value of parameters using lattice generation, and adjustments of learning rates. In proposed framework, four different systems have been tested by analyzing various feature extraction approaches (with or without speaker normalization through Vocal Tract Length Normalization (VTLN) approach in test set) and classification strategy on with or without artificial extension of train dataset. To compare each system performance, true matched (adult train and test-S1, child train and test-S2) and mismatched (adult train and child test-S3, adult + child train and child test-S4) systems on large adult and very small Punjabi clean speech corpus have been demonstrated. Consequently, gender-based in-domain data augmented is used to moderate acoustic and phonetic variations throughout adult and children's speech under mismatched conditions. The experiment result shows that an effective framework developed on PNCC + VTLN front-end approach using TDNN-sMBR-based model through parameter optimization technique yields a relative improvement (RI) of 40.18%, 47.51%, and 49.87% in matched, mismatched and gender-based in-domain augmented system under typical clean and noisy conditions, respectively.
C1 [Bawa, Puneet] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Ctr Excellence Speech & Multimodal Lab, Rajpura, Punjab, India.
   [Kadyan, Virender; Singh, Thipendra P.] Univ Petr & Energy Studies UPES, Speech & Language Res Ctr, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
   [Tripathy, Abinash] Raghu Engn Coll, Dept Comp Sci & Engn, Visakhapatnam, Andhra Pradesh, India.
C3 Chitkara University, Punjab; University of Petroleum & Energy Studies (UPES)
RP Kadyan, V (通讯作者)，Univ Petr & Energy Studies UPES, Speech & Language Res Ctr, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
EM puneet.bawa@chitkara.edu.in; vkadyan@ddn.upes.ac.in; abi.tripathy@gmail.com; tpsingh@ddn.upes.ac.in
CR Bahl LR, 1986, ICASSP 86 PROCEEDINGS. IEEE-IECEJ-ASJ INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P49
   Bawa P, 2021, APPL ACOUST, V175, P0, DOI 10.1016/j.apacoust.2020.107810
   Bittner R, 2016, P 17 INT SOC MUS INF, V0, P0
   Boersma P, 2001, PRAAT DOING PHONETIC, V5, P341
   Chien JT, 1999, IEEE T SPEECH AUDI P, V7, P656, DOI 10.1109/89.799691
   Diethorn EJ, 2004, AUDIO SIGNAL PROCESSING: FOR NEXT-GENERATION MULTIMEDIA COMMUNICATION SYSTEMS, V0, PP91, DOI 10.1007/1-4020-7769-6_4
   Dua M, 2019, NEURAL COMPUT APPL, V31, P6747, DOI 10.1007/s00521-018-3499-9
   Dua M, 2020, J INTELL SYST, V29, P327, DOI 10.1515/jisys-2017-0618
   Dua M, 2019, J AMB INTEL HUM COMP, V10, P2301, DOI 10.1007/s12652-018-0828-x
   Fainberg J, 2016, INTERSPEECH, V0, PP1598, DOI 10.21437/Interspeech.2016-1348
   FARAHANI G, 2006, INT WORKSHOP MULTIME, V0, PP466, DOI 10.1007/11848035_62
   GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J
   Goyal K, 2021, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-021-03235-4
   Gretter R, 2020, PROC LREC, V0, P0
   Hoy Matthew B, 2018, MEDICAL REFERENCE SERVICES QUARTERLY, V37, P81, DOI 10.1080/02763869.2018.1404391
   Kadyan V, 2021, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-021-03468-3
   Kadyan V, 2021, APPL ACOUST, V178, P0, DOI 10.1016/j.apacoust.2021.108002
   Kadyan V, 2021, INT J SPEECH TECHNOL, V24, P473, DOI 10.1007/s10772-021-09797-0
   Kadyan V, 2020, INT J SPEECH TECHNOL, V23, P87, DOI 10.1007/s10772-019-09654-1
   Kadyan V, 2019, INT J SPEECH TECHNOL, V22, P111, DOI 10.1007/s10772-018-09577-3
   Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928
   KOEHLER J, 1994, INT CONF ACOUST SPEE, V0, P421
   Kumar Ankit, 2022, JOURNAL OF RELIABLE INTELLIGENT ENVIRONMENTS, V8, P117, DOI 10.1007/s40860-021-00140-7
   Kumar A, 2021, J INTELL SYST, V30, P165, DOI 10.1515/jisys-2018-0417
   Kumar A, 2021, ADV SPEECH MUSIC TEC, V0, PP409, DOI 10.1007/978-981-33-6881-1_33
   Kumar M, 2020, COMPUT SPEECH LANG, V63, P0, DOI 10.1016/j.csl.2020.101101
   Kumar Y, 2021, SOFT COMPUT, V25, P1617, DOI 10.1007/s00500-020-05248-1
   Leibold LJ, 2019, FRONT PSYCHOL, V10, P0, DOI 10.3389/fpsyg.2019.01981
   López G, 2018, ADV INTELL SYST, V592, P241, DOI 10.1007/978-3-319-60366-7_23
   M?ller T, 2019, LARYNGO RHINO OTOL, V98, P10859
   Ma YN, 2014, EURASIP J AUDIO SPEE, V0, P0, DOI DOI 10.1186/s13636-014-0032-7
   NADAS A, 1988, IEEE T ACOUST SPEECH, V36, P1432, DOI 10.1109/29.90371
   Poorjam AH, 2017, INTERSPEECH, V0, PP289, DOI 10.21437/Interspeech.2017-378
   Povey D, 2002, INT CONF ACOUST SPEE, V0, P105
   Povey D, 2001, INT CONF ACOUST SPEE, V0, PP45, DOI 10.1109/ICASSP.2001.940763
   Povey D, 2011, IEEE 2011 WORKSHOP A, V0, P0
   Povey D, 2008, INT CONF ACOUST SPEE, V0, PP4057, DOI 10.1109/ICASSP.2008.4518545
   Rao K, 2016, INT CONF ACOUST SPEE, V0, PP5405, DOI 10.1109/ICASSP.2016.7472710
   Serizel R, 2014, IEEE W SP LANG TECH, V0, PP135, DOI 10.1109/SLT.2014.7078563
   Shahnawazuddin S, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1630
   Shahnawazuddin S, 2020, 2020 INT C SIGNAL PR, V0, P15
   Shivakumar PG, 2020, COMPUT SPEECH LANG, V63, P0, DOI 10.1016/j.csl.2020.101077
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vesely K, 2013, INTERSPEECH, V0, P2344
   Vesely K, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP267, DOI 10.1109/ASRU.2013.6707741
   Zhang SL, 2019, INT CONF ACOUST SPEE, V0, PP7085, DOI 10.1109/ICASSP.2019.8683859
   Zhang YF, 2018, INT CONF SIGN PROCES, V0, PP90, DOI 10.1109/ICSP.2018.8652434
   Zhao XJ, 2013, INT CONF ACOUST SPEE, V0, PP7204, DOI 10.1109/ICASSP.2013.6639061
NR 48
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2199-4536
EI 2198-6053
J9 COMPLEX INTELL SYST
JI COMPLEX INTELL. SYST.
PD FEB 15
PY 2023
VL 9
IS 1
BP 1
EP 23
DI 10.1007/s40747-022-00651-7
EA JUN 2022
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9Q3RQ
UT WOS:000805068000002
PM 35668730
DA 2023-11-10
ER

PT J
AU Huang, Y
   Wang, YM
   Wang, L
AF Huang, Yan
   Wang, Yuming
   Wang, Liang
TI Efficient Image and Sentence Matching
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Matrix decomposition; Symmetric matrices; Computational modeling; Predictive models; Analytical models; Task analysis; Context modeling; Efficient image and sentence matching; cross-modal similarity distillation; vision and language
AB Recently the accuracy of image and sentence matching has been continuously improved by larger and larger models. However, such large models not only need huge storage space but also slow down inference speed, which are not very suitable for low-cost devices in real-world applications. To our knowledge, this work makes the first attempt to improve the model efficiency in the context of image and sentence matching, and accordingly proposes a simple yet effective Whitened Similarity Distillation (WSD) method, which can distill cross-modal knowledge from a large teacher model to a small student model of both high efficiency and accuracy. The high efficiency is achieved by performing: 1) feature representation based on efficient backbone networks; and 2) similarity measurement in a fast N-to-N manner. However, the accuracy of such a student model is much worse than that of teacher model, because there exists very large variation inconsistency between two cross-modal similarity matrices of teacher and student models, which is hard to reduce during the similarity distillation. By performing two whitening-like transformations in the orthogonal space, the proposed WSD can reduce the large variation inconsistency more isotropically and is able to improve the accuracy of student model. We perform extensive experiments on two benchmark datasets and demonstrate the effectiveness of the proposed WSD. Compared with the teacher model, our distilled student model is 7x smaller (in model size) and 9x faster (in testing speed), only at the cost of < 2% accuracy decrease.
C1 [Huang, Yan; Wang, Yuming; Wang, Liang] Chinese Acad Sci CASIA, Inst Automat, Ctr Excellence Brain Sci & Intelligence Technol CE, Natl Lab Pattern Recognit NLPR,Ctr Res Intelligent, Beijing 100045, Peoples R China.
   [Huang, Yan; Wang, Yuming; Wang, Liang] Univ Chinese Acad Sci UCAS, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Huang, Y (通讯作者)，Chinese Acad Sci CASIA, Inst Automat, Ctr Excellence Brain Sci & Intelligence Technol CE, Natl Lab Pattern Recognit NLPR,Ctr Res Intelligent, Beijing 100045, Peoples R China.; Huang, Y (通讯作者)，Univ Chinese Acad Sci UCAS, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
EM yhuang@nlpr.ia.ac.cn; yuming.wang@cripac.ia.ac.cn; wangliang@nlpr.ia.ac.cn
FU National Key Research and Development Program of China [2018AAA0100400]; Key Research Program of Frontier Sciences CAS [ZDBS-LY-JSC032]; National Natural Science Foundation of China [61721004, U1803261, 61976132]; Beijing Nova Program [Z201100006820079]; CAS-AIR
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Chen D, 2020, ARXIV, V0, P0
   Chen Guobin, 2017, ADV NEUR IN, V0, P742
   Chen JC, 2021, PROC CVPR IEEE, V0, PP15784, DOI 10.1109/CVPR46437.2021.01553
   Chung JY, 2014, ARXIV, V0, P0
   Croitoru I, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP11563, DOI 10.1109/ICCV48922.2021.01138
   Devlin J, 2019, ARXIV, V0, P0
   Domingos P, 2000, P 17 INT C MACHINE L, V0, PP231, DOI 10.5555/645529.657784
   Duan KW, 2019, IEEE I CONF COMP VIS, V0, PP6568, DOI 10.1109/ICCV.2019.00667
   Faghri F, 2018, ARXIV, V0, P0
   Feng Y, 2019, PROC CVPR IEEE, V0, PP4120, DOI 10.1109/CVPR.2019.00425
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Geigle G, 2022, ARXIV, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu JX, 2018, PROC CVPR IEEE, V0, PP7181, DOI 10.1109/CVPR.2018.00750
   Haohan Wang, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8681, DOI 10.1109/CVPR42600.2020.00871
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2015, ARXIV, V0, P0
   Hodosh M, 2014, P TACL, V7, P67, DOI 10.1162/tacl_a_00166
   Howard A, 2019, IEEE I CONF COMP VIS, V0, PP1314, DOI 10.1109/ICCV.2019.00140
   Huang Y, 2022, IEEE T PATTERN ANAL, V44, P2968, DOI 10.1109/TPAMI.2021.3052490
   Huang Y, 2019, IEEE I CONF COMP VIS, V0, PP5773, DOI 10.1109/ICCV.2019.00587
   Huang Y, 2019, AAAI CONF ARTIF INTE, V0, P8489
   Huang Y, 2018, PROC CVPR IEEE, V0, PP6163, DOI 10.1109/CVPR.2018.00645
   Huang Y, 2020, IEEE T PATTERN ANAL, V42, P636, DOI 10.1109/TPAMI.2018.2883466
   Huang Y, 2017, PROC CVPR IEEE, V0, PP7254, DOI 10.1109/CVPR.2017.767
   Hui Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP12652, DOI 10.1109/CVPR42600.2020.01267
   Jiao XQ, 2020, ARXIV, V0, P0
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Karpathy A, 2014, ADV NEURAL INFORM PR, V27, P1889
   Kessy A, 2018, AM STAT, V72, P309, DOI 10.1080/00031305.2016.1277159
   Kim Y, 2016, ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiros R, 2014, ARXIV, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kunran Xu, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12370), V0, PP664, DOI 10.1007/978-3-030-58595-2_40
   Lan ZZ, 2020, ARXIV, V0, P0
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Lev G, 2016, LECT NOTES COMPUT SC, V9910, P833, DOI 10.1007/978-3-319-46466-4_50
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li KP, 2019, IEEE I CONF COMP VIS, V0, PP4653, DOI 10.1109/ICCV.2019.00475
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Chunxiao, 2020, P IEEE CVF C COMP VI, V0, PP10918, DOI 10.1109/CVPR42600.2020.01093
   Liu HX, 2019, ARXIV, V0, P0
   Liu YF, 2019, PROC CVPR IEEE, V0, PP2599, DOI 10.1109/CVPR.2019.00271
   Lu J, 2019, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1908.02265
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Park W, 2019, PROC CVPR IEEE, V0, PP3962, DOI 10.1109/CVPR.2019.00409
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Peng BY, 2019, IEEE I CONF COMP VIS, V0, PP5006, DOI 10.1109/ICCV.2019.00511
   Peng H, 2020, PROC INT C NEURAL IN, V0, P0
   Perronnin F, 2007, PROC CVPR IEEE, V0, P2272
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Qu LG, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1047, DOI 10.1145/3394171.3413961
   Radford Alec, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2103.00020
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shi BT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5182
   Shuster K, 2019, PROC CVPR IEEE, V0, PP12508, DOI 10.1109/CVPR.2019.01280
   Sukmin Yun, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP13873, DOI 10.1109/CVPR42600.2020.01389
   Sun ZQ, 2020, ARXIV, V0, P0
   Tan MX, 2020, ARXIV, V0, P0
   Tung F, 2019, IEEE I CONF COMP VIS, V0, PP1365, DOI 10.1109/ICCV.2019.00145
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang L, 2016, PROC CVPR IEEE, V0, PP5005, DOI 10.1109/CVPR.2016.541
   Wang Wenhui, 2020, ARXIV200210957, V0, P0, DOI DOI 10.1145/3308558.3313562
   Wang YX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3792
   Wang ZH, 2019, IEEE I CONF COMP VIS, V0, PP5763, DOI 10.1109/ICCV.2019.00586
   Wehrmann J, 2019, IEEE I CONF COMP VIS, V0, PP5803, DOI 10.1109/ICCV.2019.00590
   Wehrmann P, 2020, AAAI CONF ARTIF INTE, V34, P12313
   Wen KY, 2021, IEEE T CIRC SYST VID, V31, P2866, DOI 10.1109/TCSVT.2020.3030656
   Wu AC, 2019, PROC CVPR IEEE, V0, PP1187, DOI 10.1109/CVPR.2019.00128
   Wu YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP2088, DOI 10.1145/3343031.3350940
   Xi Wei, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10938, DOI 10.1109/CVPR42600.2020.01095
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Yan F, 2015, PROC CVPR IEEE, V0, PP3441, DOI 10.1109/CVPR.2015.7298966
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yu L, 2019, PROC CVPR IEEE, V0, PP2902, DOI 10.1109/CVPR.2019.00302
   Yufan Liu, 2019, 2019 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP7089, DOI 10.1109/CVPR.2019.00726
   Yalniz IZ, 2019, ARXIV, V0, P0
   Zhang LF, 2019, IEEE I CONF COMP VIS, V0, PP3712, DOI 10.1109/ICCV.2019.00381
   Zhang Q, 2020, PROC CVPR IEEE, V0, PP3533, DOI 10.1109/CVPR42600.2020.00359
NR 85
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD MAR 1
PY 2023
VL 45
IS 3
BP 2970
EP 2983
DI 10.1109/TPAMI.2022.3178485
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA D1BV8
UT WOS:000966154400001
PM 35622793
DA 2023-11-10
ER

PT J
AU Buchberger, B
AF Buchberger, Bruno
TI Automated programming, symbolic computation, machine learning: my personal view
SO ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE
LA English
DT Article; Early Access
DE Automated programming; Symbolic computation; Automated reasoning; Machine learning; Artificial intelligence; Artificial general intelligence; Pretrained large language models; Software industry; Programming assistant.; .
AB In this note, I present my personal view on the interaction of the three areas Automated Programming, Symbolic Computation, and Machine Learning. Programming is the activity of finding a (hopefully) correct program (algorithm) for a given problem. Programming is central to automation in all areas and is considered one of the most creative human activities. However, already very early in the history of programming, people started to "jump to the meta-level" of programming, i.e., started to develop procedures that automate, or semi-automate, (various aspects or parts of) the process of programming. This area has various names like "Automated Programming", "Automated Algorithm Synthesis", etc. Developing compilers can be considered an early example of a problem in automated programming. Automated reasoners for proving the correctness of programs with respect to a specification is an advanced example of a topic in automated programming. ChatGPT producing (amazingly good) programs from problem specifications in natural language is a recent example of automated programming. Programming tends to become the most important activity as the level of technological sophistication increases. Therefore, automating programming is maybe the most exciting and relevant technological endeavor today. It also will have enormous impact on the global job market in the software industry. Roughly, I see two main approaches to automated programming:symbolic computationand machine learning. In this note, I explain how the two approaches work and that they are fundamentally different because they address two completely different ways of how problems are specified. Together, the two approaches constitute (part of) what some people like to call "artificial intelligence". In my analysis, both approaches are just part of (algorithmic) mathematics. The approaches, like all non-trivial mathematical methods, need quite some intelligence on the side of the human inventors of the methods. However, applying the methods is just "machine execution" of algorithms. It is misleading to call the application "machine intelligence" or "artificial intelligence". The analysis of the two approaches to automated programming also suggests that the two approaches, in the future, should be combined to achieve even higher levels of sophistication. At the end of this note, I propose some research questions for this new direction.
C1 [Buchberger, Bruno] Johannes Kepler Univ Linz, Res Inst Symbol Computat RISC, Linz, Austria.
C3 Johannes Kepler University Linz
RP Buchberger, B (通讯作者)，Johannes Kepler Univ Linz, Res Inst Symbol Computat RISC, Linz, Austria.
EM bruno.buchberger@jku.at
FU Johannes Kepler University Linz
CR [Anonymous], 1985, J SYMB COMPUT, V1, P1
   [Anonymous], 2022, CHATGPT OPT LAANG MO, V0, P0
   Buchberger B, 2023, RISC REPORT SERIES, V23-04, P0
   Buchberger B, 2003, EPTCS, V93, P24
   Buchberger B, 1982, INFORM FACHBERICHTE, V59, P141
   Buchberger B, 2003, P SYNASC 2003 5 INT, V0, P2
   Buchberger B, 2022, MEDITATION TODAYS WO, V0, P0
   Buchberger B, 2021, ELECTRON P THEOR COM, V0, PP1, DOI 10.4204/EPTCS.342.1
   Buchberger B, 2016, J FORMALIZ REASON, V9, P149
   Coquand T, 2022, COQ PROOF ASSISTANT, V0, P0
   Grover A, 2021, ACM COMPUT SURV, V54, P1
   Jain N, 2022, PROC INT CONF SOFTW, V0, PP1219, DOI 10.1145/3510003.3510203
   Kaufmann D, 2019, 2019 FORMAL METHODS IN COMPUTER AIDED DESIGN (FMCAD), V0, PP28, DOI 10.23919/FMCAD.2019.8894250
   Marcus G, 2023, COMMUNICATION, V0, P0
   Nipkov T, 2022, ISABELLE PROOF ASSIS, V0, P0
   openai, 2022, CODEX, V0, P0
NR 16
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1012-2443
EI 1573-7470
J9 ANN MATH ARTIF INTEL
JI Ann. Math. Artif. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10472-023-09894-7
EA OCT 2023
PG 21
WC Computer Science, Artificial Intelligence; Mathematics, Applied
SC Computer Science; Mathematics
GA T8PZ2
UT WOS:001080562200001
DA 2023-11-10
ER

PT J
AU Lukauskas, M
   Rasymas, T
   Minelga, M
   Vaitmonas, D
AF Lukauskas, Mantas
   Rasymas, Tomas
   Minelga, Matas
   Vaitmonas, Domas
TI LARGE SCALE FINE-TUNED TRANSFORMERS MODELS APPLICATION FOR BUSINESS NAMES GENERATION
SO COMPUTING AND INFORMATICS
LA English
DT Article
DE Natural language processing; NLP; natural language generation; NLG; transformers
AB Natural language processing (NLP) involves the computer analysis and processing of human languages using a variety of techniques aimed at adapting various tasks or computer programs to linguistically process natural language. Currently, NLP is increasingly applied to a wide range of real-world problems. These tasks can vary from extracting meaningful information from unstructured data, analyzing sentiment, translating text between languages, to generating human-level text autonomously. The goal of this study is to employ transformer-based natural language models to generate high-quality business names. Specifically, this work investigates whether larger models, which require more training time, yield better results for generating relatively short texts, such as business names. To achieve this, we utilize different transformer architectures, including both freely available and proprietary models, and compare their performance. Our dataset comprises 250 928 observations of business names. Based on the perplexity metric, the top performing model in our study is the GPT2-Medium model. However, our findings reveal a discrepancy between human evaluation and perplexity-based assessment. According to human evaluation, the best results are obtained using the GPT-Neo1.3B model. Interestingly, the larger GPT-Neo-2.7B model yields poorer results, with its performance not being statistically different from that of the GPT-Neo125M model, which is 20 times smaller.
C1 [Lukauskas, Mantas] Kaunas Univ Technol, Dept Appl Math, K Donelaicio St 73, LT-44249 Kaunas, Lithuania.
   [Rasymas, Tomas] UAB, Hostinger, Jonavos St 60C, LT-44192 Kaunas, Lithuania.
   [Minelga, Matas; Vaitmonas, Domas] UAB, Zyro Inc, Jonavos St 60C, LT-44192 Kaunas, Lithuania.
C3 Kaunas University of Technology
RP Lukauskas, M (通讯作者)，Kaunas Univ Technol, Dept Appl Math, K Donelaicio St 73, LT-44249 Kaunas, Lithuania.
EM mantas.lukauskas@ktu.lt; tomas.rasymas@hostinger.com; matas@zyro.com; domas@zyro.com
CR Adhikari A, 2019, ARXIV, V0, P0
   AMIDEI J, 2019, P 12 INT C NATURAL L, V0, PP397, DOI 10.18653/V1/W19-8648
   [Anonymous], 2013, ADV NEURAL INFORM PR, V0, P0
   Bojar O, 2017, P 2 C MACH TRANSL, V0, PP169, DOI 10.18653/v1/W17-4717
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   COCH J, 1996, P 16 C COMPUTATIONAL, V0, PP249, DOI 10.3115/992628.992673
   Dai ZH, 2019, ARXIV, V0, P0
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9030483
   DE COSTER M, 2021, P 1 INT WORKSH AUT T, V0, P88
   Devlin J, 2018, OPEN SOURCING BERT S, V0, P0
   Fan A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3558
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   GAuTAM A, 2021, COMMUNICATIONS COMPU, V1402, P189, DOI 10.1007/978-3-030-73696-5_18
   GKATZIA D, 2015, P 15 EUROPEAN WORKSH, V0, P57
   GRAHAM Y, 2013, P 7 LINGUISTIC ANNOT, V0, P33
   Hendrycks D, 2020, ARXIV, V0, P0
   JONES KS, 1995, EVALUATING NATURAL L, V0, P0, DOI DOI 10.1007/BFb0027470
   Joshi A, 2015, BRIT J APPL SCI TECH, V7, P396, DOI 10.9734/BJAST/2015/14975
   Lan ZZ, 2020, ARXIV, V0, P0
   Lester JC, 1997, COMPUT LINGUIST, V23, P65
   Lewis M, 2020, P 58 ANN M ASS COMP, V0, P0
   Li JY, 2021, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Lu Y, 2022, IEEE-ACM T AUDIO SPE, V30, P1927, DOI 10.1109/TASLP.2022.3180678
   Mellish C, 1998, COMPUT SPEECH LANG, V12, P349, DOI 10.1006/csla.1998.0106
   Merchant K, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P1803, DOI 10.1109/ICACCI.2018.8554831
   Mishev K, 2020, IEEE ACCESS, V8, P131662, DOI 10.1109/ACCESS.2020.3009626
   Pan LM, 2019, ARXIV, V0, P0
   Radford A, 2019, BETTER LANGUAGE MODE, V1, P2
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, V0, P0, DOI 10.1109/SC41405.2020.00024
   Salvagno M, 2023, CRIT CARE, V27, P0, DOI 10.1186/s13054-023-04380-2
   Sanh V, 2020, ARXIV, V0, P0
   Tevet G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P326
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xia YC, 2019, AAAI CONF ARTIF INTE, V0, P5466
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Yang ZL, 2020, ARXIV, V0, P0
NR 39
TC 0
Z9 0
U1 2
U2 2
PU SLOVAK ACAD SCIENCES INST INFORMATICS
PI BRATISLAVA
PA DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA
SN 1335-9150
EI 
J9 COMPUT INFORM
JI Comput. Inform.
PD JUN 15
PY 2023
VL 42
IS 3
BP 525
EP 545
DI 10.31577/cai20233525
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA S4MF6
UT WOS:001070918300001
DA 2023-11-10
ER

PT J
AU Varshney, D
   Zafar, A
   Behera, NK
   Ekbal, A
AF Varshney, Deeksha
   Zafar, Aizan
   Behera, Niranshu Kumar
   Ekbal, Asif
TI Knowledge graph assisted end-to-end medical dialog generation
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Medical dialog generation; Knowledge graph; Pretrained language models
ID system
AB Medical dialog systems have the potential to assist e-medicine in improving access to healthcare services, improving patient treatment quality, and lowering medical expenses. In this research, we describe a knowledge -grounded conversation generation model that demonstrates how large-scale medical information in the form of knowledge graphs can aid in language comprehension and generation in medical dialog systems. Generic responses are often produced by existing generative dialog systems, resulting in monotonous and uninteresting conversations. To solve this problem, we combine various pre-trained language models with a medical knowledge base (UMLS) to generate clinically correct and human-like medical conversations using the recently released MedDialog-EN dataset. The medical-specific knowledge graph contains broadly 3 types of medical-related information, including disease, symptom and laboratory test. We perform reasoning over the retrieved knowledge graph by reading the triples in each graph using MedFact attention, which allows us to use semantic information from the graphs for better response generation. In order to preserve medical information, we employ a policy network, which effectively injects relevant entities associated with each dialog into the response. We also study how transfer learning can significantly improve the performance by utilizing a relatively small corpus, created by extending the recently released CovidDialog dataset, containing the dialogs for diseases that are symptoms of Covid-19. Empirical results on the MedDialog corpus and the extended CovidDialog dataset demonstrate that our proposed model significantly outperforms the state-of-the-art methods in terms of both automatic evaluation and human judgment.
C1 [Varshney, Deeksha; Zafar, Aizan; Behera, Niranshu Kumar; Ekbal, Asif] IIT Patna, Dept Comp Sci & Engn, Patna, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Patna
RP Varshney, D; Ekbal, A (通讯作者)，IIT Patna, Dept Comp Sci & Engn, Patna, India.
EM 1821cs13@iitp.ac.in; asif@iitp.ac.in
CR Alsentzer E, 2019, ARXIV, V0, P0
   Brown TB, 2020, ARXIV, V0, P0
   Bansal T, 2020, ARXIV, V0, P0
   Blanc C, 2022, ARTIF INTELL MED, V127, P0, DOI 10.1016/j.artmed.2022.102264
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, PD267, DOI 10.1093/nar/gkh061
   Chen Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5033
   Chien-ShengWu Richard, 2019, ARXIV190104713, V0, P0
   Coronato A, 2020, ARTIF INTELL MED, V109, P0, DOI 10.1016/j.artmed.2020.101964
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhingra B, 2017, ARXIV, V0, P0
   Dou ZY, 2019, ARXIV, V0, P0
   Du N, 2019, ARXIV, V0, P0
   Du N, 2019, ARXIV, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gopalakrishnan K, 2019, TOPICAL CHAT KNOWLED, V0, P0
   Gulcehre C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P140, DOI 10.18653/v1/p16-1014
   Hua K, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP525, DOI 10.1145/3340531.3411967
   Kingma DP, 2014, C TRACK P, V0, P0
   Kraljevic Z, 2021, ARTIF INTELL MED, V117, P0, DOI 10.1016/j.artmed.2021.102083
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li Jiwei, 2016, NAACL, V0, PP110, DOI 10.18653/V1/N16-1014
   Li XJ, 2018, ARXIV, V0, P0
   Liang K, 2021, COMPUT MATH METHOD M, V2021, P0, DOI 10.1155/2021/5294627
   Lin S, 2021, AAAI CONF ARTIF INTE, V35, P13362
   Liu Chia-Wei, 2016, P C EMP METH NAT LAN, V0, PP2122, DOI 10.18653/v1/D16-1230
   Liu QL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P201
   Liu SM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1489
   Liu WE, 2022, ARXIV, V0, P0
   Liu WG, 2021, NEUROCOMPUTING, V442, P260, DOI 10.1016/j.neucom.2021.02.021
   Liu ZB, 2019, ARXIV, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paulus R, 2017, ARXIV, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Ranzato M, 2016, ARXIV, V0, P0
   Reddy R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3744
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Serban IV, 2017, AAAI CONF ARTIF INTE, V0, P3295
   Shang LF, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1577
   Shi XM, 2020, AAAI CONF ARTIF INTE, V34, P8838
   Soldaini Luca, 2016, MEDIR WORKSHOP, V0, P1
   Song KT, 2019, ARXIV, V0, P0
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tang C, 2023, ARXIV, V0, P0
   Tao CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4418
   Vakulenko S, 2020, P 43 INT ACM SIGIR C, V0, P2085
   Varshney D, 2022, ARXIV, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Vinyals O, 2015, ARXIV, V0, P0
   Wang Jetal, 2020, P 28 INT C COMPUTATI, V0, PP4100, DOI 10.18653/V1/2020.COLING-MAIN.362
   Woo CW, 2006, ARTIF INTELL MED, V38, P25, DOI 10.1016/j.artmed.2005.10.004
   Wu S, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.515
   Wu SX, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3766
   Xia Y, 2020, AAAI CONF ARTIF INTE, V34, P1062
   Xing C, 2017, AAAI CONF ARTIF INTE, V0, P3351
   Xu L, 2019, AAAI CONF ARTIF INTE, V0, P7346
   Yang WM, 2020, ARXIV, V0, P0
   Yang Z, 1900, V32, V0, P0
   Young T, 2018, AAAI CONF ARTIF INTE, V0, P4970
   Zeng GT, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9241
   Zhang HN, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3721
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
   Zhao TC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P654, DOI 10.18653/v1/P17-1061
   Zhao YF, 2020, ARXIV, V0, P0
   Zhou H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4623
NR 70
TC 0
Z9 0
U1 21
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD MAY 15
PY 2023
VL 139
IS 
BP 
EP 
DI 10.1016/j.artmed.2023.102535
EA APR 2023
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA F5VF5
UT WOS:000983014100001
PM 37100505
DA 2023-11-10
ER

PT J
AU Scaboro, S
   Portelli, B
   Chersoni, E
   Santus, E
   Serra, G
AF Scaboro, Simone
   Portelli, Beatrice
   Chersoni, Emmanuele
   Santus, Enrico
   Serra, Giuseppe
TI Extensive evaluation of transformer-based architectures for adverse drug events extraction
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Adverse drug events; Transformers; Side effects; Extraction
ID pharmacovigilance; classification; mentions; corpus
AB Adverse Drug Event (ADE) extraction is one of the core tasks in digital pharmacovigilance, especially when applied to informal texts. This task has been addressed by the Natural Language Processing community using large pre-trained language models, such as BERT. Despite the great number of Transformer-based architectures used in the literature, it is unclear which of them has better performances and why. Therefore, in this paper we perform an extensive evaluation and analysis of 19 Transformer-based models for ADE extraction on informal texts. We compare the performance of all the considered models on two datasets with increasing levels of informality (forums posts and tweets). We also combine the purely Transformer-based models with two commonly-used additional processing layers (CRF and LSTM), and analyze their effect on the models performance. Furthermore, we use a well-established feature importance technique (SHAP) to correlate the performance of the models with a set of features that describe them: model category (AutoEncoding, AutoRegressive, Text-to-Text), pre-training domain, training from scratch, and model size in number of parameters. At the end of our analyses, we identify a list of take-home messages that can be derived from the experimental data.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Scaboro, Simone; Portelli, Beatrice; Serra, Giuseppe] Univ Udine, Dept Math Comp Sci & Phys, AILAB Udine, via Sci 206, I-33100 Udine, Friuli Venezia, Italy.
   [Portelli, Beatrice] Univ Naples Federico II, Dept Biol, Corso Umberto 140, I-80138 Campania, Italy.
   [Chersoni, Emmanuele] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies CBS, Hung Hom, Hong Kong, Peoples R China.
   [Santus, Enrico] Bayer, Whippany, NJ USA.
C3 University of Udine; University of Naples Federico II; Hong Kong Polytechnic University; Bayer AG
RP Portelli, B (通讯作者)，Univ Udine, Dept Math Comp Sci & Phys, AILAB Udine, via Sci 206, I-33100 Udine, Friuli Venezia, Italy.
EM scaboro.simone@spes.uniud.it; portelli.beatrice@spes.uniud.it; emmanuele.chersoni@polyu.edu.hk; esantus@bloomberg.net; giuseppe.serra@uniud.it
FU Department Strategic Plan (PSD) of the University of Udine-Interdepartmental Project on Artificial Intelligence
CR Alsentzer E, 2019, P NAACL WORKSHOP CLI, V0, P0
   Alvaro Nestor, 2017, JMIR PUBLIC HEALTH SURVEILL, V3, Pe24, DOI 10.2196/publichealth.6396
   Ammar W, 2018, P NAACL, V0, P0
   [Anonymous], 2022, TEXTSTAT, V0, P0
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3615
   Candidato AL, 2022, P COLING WORKSHOP SO, V0, P0
   Chinchor N, 1993, 5 MESSAGE UNDERSTAND, V0, P0
   Clark Kevin, 2020, ICLR, V0, P0
   Dai X, 2018, P ACL STUDENT RES WO, V0, P0
   Dai X, 2020, P 58 ANN M ASS COMPU, V0, P0
   Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P9
   de la Torre BG, 2022, MOLECULES, V27, P0, DOI 10.3390/molecules27031075
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dietrich J, 2020, DRUG SAFETY, V43, P467, DOI 10.1007/s40264-020-00912-9
   Dima G-A, 2021, P NAACL SOCIAL MEDIA, V0, P0
   Dodge J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1286
   European Medicines Agency, 2022, HUM MED HIGHL 2021, V0, P0
   Feng CC, 2019, APPL CLIN INFORM, V10, P123, DOI 10.1055/s-0039-1677738
   Gattepaille L, 2020, P COLING SOCIAL MEDI, V0, P0
   Ge SY, 2019, SOCIAL MEDIA MINING FOR HEALTH APPLICATIONS (#SMM4H) WORKSHOP & SHARED TASK, V0, P96
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Guellil I, 2022, P COLING WORKSHOP SO, V0, P0
   Gururangan Suchin, 2020, P ANN M ASS COMPUTAT, V0, P0
   Johnson AEW, 2016, SCI DATA, V3, P0, DOI 10.1038/sdata.2016.35
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kalyan KS, 2020, P COLING SOCIAL MEDI, V0, P0
   Kanakarajan KR, 2021, P 20 WORKSH BIOM LAN, V0, P0
   Karimi S, 2015, ACM COMPUT SURV, V47, P0, DOI 10.1145/2719920
   Karimi S, 2015, J BIOMED INFORM, V55, P73, DOI 10.1016/j.jbi.2015.03.010
   Klein A, 2020, P 5 SOC MED MIN HLTH, V0, P27
   Kraljevic Z, 2021, ARXIV, V0, P0
   Lafferty J, 2001, CONDITIONAL RANDOM F, V0, P282
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lewis M, 2020, P 58 ANN M ASS COMP, V0, P0
   Liu X, 2022, P COLING WORKSHOP SO, V0, P0
   Lo K, 2020, S2ORC SEMANTIC SCHOL, V0, P0
   López-Ubeda P, 2019, SOCIAL MEDIA MINING FOR HEALTH APPLICATIONS (#SMM4H) WORKSHOP & SHARED TASK, V0, P102
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Magge A, 2021, P 6 SOCIAL MEDIA MIN, V0, P0
   Magge A, 2021, J AM MED INFORM ASSN, V28, P2184, DOI 10.1093/jamia/ocab114
   Miftahutdinov Z, 2019, P ACL SOCIAL MEDIA M, V0, P0
   Miftahutdinov Z, 2020, P COLING SOCIAL MEDI, V0, P0
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nikfarjam A, 2015, J AM MED INFORM ASSN, V22, P671, DOI 10.1093/jamia/ocu041
   Papay S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4881
   Paul MJ, 2016, BIOCOMPUT-PAC SYM, V0, P468
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Phan LN, 2021, ARXIV, V0, P0
   Portelli B, 2022, J MED INTERNET RES, V24, P0, DOI 10.2196/35115
   Portelli B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1740
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Raval S, 2021, FINDINGS EMNLP, V0, P0
   Sakhovskiy A, 2022, J BIOMED INFORM, V135, P0, DOI 10.1016/j.jbi.2022.104182
   Sanh V, 2019, ARXIV, V0, P0
   Sarabadani S, 2019, SOCIAL MEDIA MINING FOR HEALTH APPLICATIONS (#SMM4H) WORKSHOP & SHARED TASK, V0, P120
   Sarker A, 2017, TRAINING, V1, P1239
   Sarker A, 2015, J BIOMED INFORM, V54, P202, DOI 10.1016/j.jbi.2015.02.004
   Sarker A, 2015, J BIOMED INFORM, V53, P196, DOI 10.1016/j.jbi.2014.11.002
   Scaboro, 2021, P EMNLP WORKSHOP NOI, V0, P0
   Scaboro S, 2022, EXP BIOL MED, V247, P2003, DOI 10.1177/15353702221128577
   Segura Bedmar I, 2013, SEMEVAL 2013 TASK 9, V0, P0
   Stanovsky G, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P142
   Tutubalina EV, 2017, RUSS CHEM B+, V66, P2180, DOI 10.1007/s11172-017-2000-8
   Uludogan G, 2022, P COLING WORKSHOP SO, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wadman M, 2005, NAT MED, V11, P465, DOI 10.1038/nm0505-465
   Wang B, 2021, ARXIV, V0, P0
   Weissenbacher D, 2022, P COLING SOCIAL MEDI, V0, P0
   Weissenbacher D, 2018, P EMNLP WORKSHOP SOC, V0, P0
   Weissenbacher D, 2019, SOCIAL MEDIA MINING FOR HEALTH APPLICATIONS (#SMM4H) WORKSHOP & SHARED TASK, V0, P21
   Yang Z, 2019, INT C NEURAL INFORM, V0, P0
   Yaseen U, 2021, P NAACL SOCIAL MEDIA, V0, P0
   Yu Gu, 2022, ACM TRANSACTIONS ON COMPUTING AND HEALTHCARE, V3, P0, DOI 10.1145/3458754
   Zhang J, 2020, P INT C MACHINE LEAR, V0, P0
NR 77
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD SEP 5
PY 2023
VL 275
IS 
BP 
EP 
DI 10.1016/j.knosys.2023.110675
EA JUN 2023
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA N0PH0
UT WOS:001034133500001
DA 2023-11-10
ER

PT J
AU Chen, Z
   Liu, YC
   Chen, L
   Zhu, S
   Wu, MY
   Yu, K
AF Chen, Zhi
   Liu, Yuncong
   Chen, Lu
   Zhu, Su
   Wu, Mengyue
   Yu, Kai
TI OPAL: Ontology-Aware Pretrained Language Model for End-to-End Task-Oriented Dialogue
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper presents an ontology-aware pretrained language model (OPAL) for end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models, task-oriented dialogue models fulfill at least two task-specific modules: Dialogue state tracker (DST) and response generator (RG). The dialogue state consists of the domain-slot-value triples, which are regarded as the user's constraints to search the domain-related databases. The large-scale task-oriented dialogue data with the annotated structured dialogue state usually are inaccessible. It prevents the development of the pretrained language model for the task-oriented dialogue. We propose a simple yet effective pretraining method to alleviate this problem, which consists of two pretraining phases. The first phase is to pretrain on large-scale contextual text data, where the structured information of the text is extracted by the information extracting tool. To bridge the gap between the pretraining method and downstream tasks, we design two pretraining tasks: ontology-like triple recovery and next-text generation, which simulates the DST and RG, respectively. The second phase is to fine-tune the pretrained model on the TOD data. The experimental results show that our proposed method achieves an exciting boost and obtains competitive performance even without any TOD data on CamRest676 and MultiWOZ benchmarks.
C1 [Chen, Zhi; Liu, Yuncong; Chen, Lu; Wu, Mengyue; Yu, Kai] Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, X LANCE Lab,MoE Key Lab Artificial Intelligence,St, Beijing, Peoples R China.
   [Zhu, Su] AISpeech Co Ltd, Suzhou, Peoples R China.
C3 Shanghai Jiao Tong University
RP Chen, L; Yu, K (通讯作者)，Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, X LANCE Lab,MoE Key Lab Artificial Intelligence,St, Beijing, Peoples R China.
EM zhenchi713@sjtu.edu.cn; chenlusz@sjtu.edu.cn; kai.yu@sjtu.edu.cn
FU China NSFC Projects [62106142, 92048205]; Shanghai Municipal Science and Technology Major Project [2021SHZDZX0102]; CCF-Tencent Open Fund; Startup Fund for Youngman Research at SJTU
CR Adiwardana D, 2020, ARXIV, V0, P0
   Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   Balaraman V, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP830, DOI 10.1109/asru46091.2019.9003911
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P85
   Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5016
   Byrne B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4516
   Chen L, 2020, AAAI CONF ARTIF INTE, V34, P7521
   Chen L, 2019, IEEE-ACM T AUDIO SPE, V27, P1378, DOI 10.1109/TASLP.2019.2919872
   Chen L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6074, DOI 10.1109/ICASSP.2018.8462272
   Chen Z, 2020, ARXIV, V0, P0
   Chen Z, 2020, IEEE-ACM T AUDIO SPE, V28, P2400, DOI 10.1109/TASLP.2020.3013392
   Dai Y, 2021, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Eric M, 2019, ARXIV, V0, P0
   Eric M, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), V0, P37
   Goel R, 2019, ARXIV, V0, P0
   Ham D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P583
   He Wanwei, 2021, ARXIV, V0, P0
   Heck M, 2020, SIGDIAL 2020: 21ST ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2020), V0, P35
   Hosseini-Asl Ehsan, 2020, ARXIV, V0, P0
   Iyyer M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1821, DOI 10.18653/v1/P17-1167
   Jiang Z, 2020, ADV NEURAL INFORM PR, V0, P0
   Kim S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P567
   Koehn Philipp, 2004, P 2004 C EMPIRICAL M, V0, P388
   Kolluru K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3748
   Le Hung, 2020, INT C LEARNING REPRE, V0, P0
   Lee H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5478
   Lee SJ, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, P64
   Lei WQ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1437
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li Jiwei, 2016, EMNLP, V0, P0
   Li S, 2020, INT C LEARNING REPRE, V0, P0
   Lin ZJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3391
   Liu Q, 2021, ARXIV, V0, P0
   Mehri S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3836
   Mrksic N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1777, DOI 10.18653/v1/P17-1163
   Nouri Elnaz, 2018, NEURIPS 2018, V0, P0
   Peng B, 2020, FINDINGS ASS COMPUTA, V0, P172
   Peng Bei, 2020, ARXIV E PRINTS, V0, P0
   Peng SK, 2020, ARXIV, V0, P0
   Quirk C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P878
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rastogi A, 2020, AAAI CONF ARTIF INTE, V34, P8689
   Ren LL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1876
   Ren LL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2780
   Rosset C, 2021, ARXIV, V0, P0
   Santra B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5649
   Su YX, 2022, ARXIV, V0, P0
   Tao Yu, 2020, INT C LEARNING REPRE, V0, P0
   Tsung-HsienWen Milica, 2016, P 2016 C EMP METH NA, V0, PP2153, DOI 10.18653/V1/D16-1233
   Lai TM, 2020, INT CONF ACOUST SPEE, V0, PP8034, DOI 10.1109/icassp40776.2020.9053975
   Ultes S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP73, DOI 10.18653/v1/P17-4013
   Volske Michael, 2017, P WORKSH NEW FRONT S, V0, PP59, DOI 10.18653/V1/W17-4508
   Weisz G, 2018, IEEE-ACM T AUDIO SPE, V26, P2083, DOI 10.1109/TASLP.2018.2851664
   Wen Tsung-Hsien, 2015, P 2015 C EMPIRICAL M, V0, PP1711, DOI 10.18653/v1/D15-1199
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P917
   Wu CS, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P808
   Yang YY, 2021, AAAI CONF ARTIF INTE, V35, P14230
   Zhang J, 2020, P JOINT C LEX COMP S, V0, P154
   Zhang T, 2021, LONG PAPERS, V1, P5882, DOI 10.18653/v1/
   Zhang YC, 2020, AAAI CONF ARTIF INTE, V34, P9604
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
   Zhao TC, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1208
   Zhao TC, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), V0, P1
   Zhao TC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P654, DOI 10.18653/v1/P17-1061
   Zhong V, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1458
   Zhou JY, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), V0, P228
   Zhou L, 2020, ARXIV, V0, P0
   Zihan Xu, 2020, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 9TH CCF INTERNATIONAL CONFERENCE, V0, P41, DOI 10.1007/978-3-030-60450-9_4
NR 72
TC 0
Z9 0
U1 9
U2 19
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JAN 12
PY 2023
VL 11
IS 
BP 68
EP 84
DI 10.1162/tacl_a_00534
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8J8EU
UT WOS:000922645500005
DA 2023-11-10
ER

PT J
AU Li, MY
   Jiang, Z
   Zhao, ZW
   Ma, LF
AF Li, Mingyong
   Jiang, Zheng
   Zhao, Zongwei
   Ma, Longfei
TI A PERT-BiLSTM-Att Model for Online Public Opinion Text Sentiment Analysis
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Natural language processing; PERT; pre-training model; emotional~analysis; BiLSTM
AB As an essential category of public event management and control, sentiment analysis of online public opinion text plays a vital role in public opinion early warning, network rumor management, and netizens' personality portraits under massive public opinion data. The traditional sentiment analysis model is not sensitive to the location information of words, it is difficult to solve the problem of polysemy, and the learning representation ability of long and short sentences is very different, which leads to the low accuracy of sentiment classification. This paper proposes a sentiment analysis model PERT-BiLSTM-Att for public opinion text based on the pre-training model of the disordered language model, bidirectional long-term and short-term memory network and attention mechanism. The model first uses the PERT model pre-trained from the lexical location information of a large amount of corpus to process the text data and obtain the dynamic feature representation of the text. Then the semantic features are input into BiLSTM to learn context sequence information and enhance the model's ability to represent long sequences. Finally, the attention mechanism is used to focus on the words that contribute more to the overall emotional tendency to make up for the lack of short text representation ability of the traditional model, and then the classification results are output through the fully connected network. The experimental results show that the classification accuracy of the model on NLPCC14 and weibo_senti_100k public data sets reach 88.56% and 97.05%, respectively, and the accuracy reaches 95.95% on the data set MDC22 composed of Meituan, Dianping and Ctrip comment. It proves that the model has a good effect on sentiment analysis of online public opinion texts on different platforms. The experimental results on different datasets verify the model's effectiveness in applying sentiment analysis of texts. At the same time, the model has a strong generalization ability and can achieve good results for sentiment analysis of datasets in different fields.
C1 [Li, Mingyong; Jiang, Zheng; Zhao, Zongwei; Ma, Longfei] Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University
RP Jiang, Z (通讯作者)，Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
EM jiangzheng941@126.com
FU Chongqing Natural Science Foundation of China [CSTB2022NSCQ-MSX1417]; Science and Technology Research Program of Chongqing Municipal Education Commission [KJZD-K202200513]; Chongqing Normal University Fund [22XLB003]
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 1964, AUTOMAT REM CONTR+, V0, P0
   Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Cheng JP, 2016, ARXIV, V0, P0
   Cho KYHY, 2014, ARXIV, V0, P0
   Cui Y, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2203.06906
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Devlin J, 2019, ARXIV, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2014, ARXIV, V0, P0
   Kim Y, 2017, ARXIV, V0, P0
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   KingaD A, 2015, INT C LEARNING REPRE, V0, P0
   Lin ZH, 2017, ARXIV, V0, P0
   Liu S, 2022, SOFTWARE GUIDE, V17, P4
   Martins AFT, 2016, PR MACH LEARN RES, V48, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mnih V, 2014, ADV NEUR IN, V27, P0
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Peng S, 2022, J SICHUAN U NATURAL, V59, P13004
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Shi XJ, 2015, ADV NEUR IN, V28, P0
   Song G, 2021, CHINA COMPUTER COMMU, V33, P56
   Sun Y, 2019, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   [王剑 Wang Jian], 2022, 计算机科学 COMPUTER SCIENCE, V49, P279
   Wang S, 2012, P 50 ANN M ASS COMP, V2, P90, DOI 10.5555/2390665.2390688
   Wu YH, 2016, ARXIV, V0, P0
   Xiao DL, 2021, ARXIV, V0, P0
   XU Guan-hua, 2018, SOFTWARE GUIDE, V17, P13
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   [殷昊 Yin Hao], 2018, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V32, P139
   Yongping D, 2019, J BEIJING U TECHNOLO, V45, P662
   [赵妍妍 Zhao Yanyan], 2017, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V31, P187
   Zhu J, 2018, J COMPUT APPL, V6, P95
NR 37
TC 0
Z9 0
U1 3
U2 3
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD JUN 15
PY 2023
VL 37
IS 2
BP 2387
EP 2406
DI 10.32604/iasc.2023.037900
PG 20
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA M8DM8
UT WOS:001032466700064
DA 2023-11-10
ER

PT J
AU Li, ZZ
   Ren, FJ
   Sun, X
   Huang, DG
   Shi, P
AF Li, Zezhong
   Ren, Fuji
   Sun, Xiao
   Huang, Degen
   Shi, Piao
TI Exploiting Japanese-Chinese Cognates with Shared Private Representations for NMT
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Cognate; Chinese character; Japanese-Chinese
AB Neural machine translation has achieved remarkable progress over the past several years; however, little attention has been paid to machine translation (MT) between Japanese and Chinese, which share a large proportion of cognate words that can be utilized as additional linguistic knowledge to enhance translation performance. In this article, we seek to strengthen the semantic correlation between Japanese and Chinese by leveraging cognate words that share common Chinese characters. Specifically, we experiment with three strategies: (1) a shared vocabulary with cognate lexicon induction, which models the commonality between source and target cognates; (2) a shared private representation with a dynamic gating mechanism, which models the language-specific features on the source side; and (3) an embedding shortcut, which enables the decoder to access the shared private representation with shortest distance and aids the training process. The experiments and analysis presented in this article demonstrate that our proposed approaches can significantly improve the performance of both Japanese-to-Chinese and Chinese-to-Japanese translations and verify the effectiveness of exploiting Japanese-Chinese cognates for MT.
C1 [Li, Zezhong; Sun, Xiao; Shi, Piao] Hefei Univ Technol, Hefei 230009, Anhui, Peoples R China.
   [Ren, Fuji] Univ Elect Sci & Technol China, Chengdu 610000, Sichuan, Peoples R China.
   [Huang, Degen] Dalian Univ Technol, Dalian, Liaoning, Peoples R China.
C3 Hefei University of Technology; University of Electronic Science & Technology of China; Dalian University of Technology
RP Sun, X (通讯作者)，Hefei Univ Technol, Hefei 230009, Anhui, Peoples R China.
EM lizezhonglaile@163.com; ren2fuji@gmail.com; sunx@hfut.edu.cn; huangdg@dlut.edu.cn; shipiao@mail.hfut.edu.cn
FU National Key Research and Development Program of China [2020AAA0108004]
CR Ashokkumar P, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3425781
   Bahdanau D, 2016, ARXIV, V0, P0
   Chenhui Chu, 2013, ACM TRANSACTIONS ON ASIAN LANGUAGE INFORMATION PROCESSING, V12, P0, DOI 10.1145/2523057.2523059
   Chu CH, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2149
   Dabre R, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3406095
   Dhall S, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3467019
   Emelin D, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P102
   Gehring J, 2017, PR MACH LEARN RES, V70, P0
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Kuang SH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1767
   Kurosawa M, 2018, ARXIV, V0, P0
   Lee CY, 2014, ARXIV, V0, P0
   Liu XB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3613
   Nakazawa T, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2204
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Park J, 2019, ARXIV, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Srivastava RK, 2015, CORR, V1505, P387
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang CH, 2020, AAAI CONF ARTIF INTE, V34, P9154
   Wang JL, 2018, REPRESENTATION LEARNING FOR NLP, V0, P113
   Wang R, 2018, ACM T ASIAN LOW-RESO, V17, P0, DOI 10.1145/3203078
   Wu LJ, 2018, AAAI CONF ARTIF INTE, V0, P5578
   Chen MX, 2018, ARXIV, V0, P0
   Zhang LT, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3431727
NR 26
TC 1
Z9 1
U1 5
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JAN 15
PY 2023
VL 22
IS 1
BP 
EP 
DI 10.1145/3533429
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9D8UM
UT WOS:000936372200003
DA 2023-11-10
ER

PT J
AU Gao, W
   Ni, MY
   Deng, HT
   Zhu, X
   Zeng, P
   Hu, X
AF Gao, Wang
   Ni, Mingyuan
   Deng, Hongtao
   Zhu, Xun
   Zeng, Peng
   Hu, Xi
TI Few-shot fake news detection via prompt-based tuning
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Fake news detection; few-shot; prompt-based tuning; pre-trained language model
AB As people increasingly use social media to read news, fake news has become a major problem for the public and government. One of the main challenges in fake news detection is how to identify them in the early stage of propagation. Another challenge is that detection model training requires large amounts of labeled data, which are often unavailable or expensive to acquire. To address these challenges, we propose a novel Fake News Detection model based on Prompt Tuning (FNDPT). FNDPT first designs a prompt-based template for early fake news detection. This mechanism incorporates contextual information into textual content and extracts relevant knowledge from pre-trained language models. Furthermore, our model utilizes prompt-based tuning to enhance the performance in a few-shot setting. Experimental results on two real-world datasets verify the effectiveness of FNDPT.
C1 [Gao, Wang; Ni, Mingyuan; Deng, Hongtao; Zhu, Xun; Zeng, Peng; Hu, Xi] Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
   Jianghan Univ, Engn Res Ctr Intelligent Decis & Informat, Wuhan, Peoples R China.
C3 Jianghan University; Jianghan University
RP Gao, W (通讯作者)，Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
EM gaow@jhun.edu.cn
FU Industry-University-Research Project of Wuhan Education Bureau [CXY202208]; Special Research Fund for Discipline Characteristics of Jianghan University [2022XKZK10]
CR Boididou C, 2015, MEDIAEVAL, V3, P7, DOI 10.1145/1235
   Bovet A, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-018-07761-2
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW22), V0, PP2778, DOI 10.1145/3485447.3511998
   Chen Y, 2022, ADAPROMPT ADAPTIVE M, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gao W, 2020, NEURAL NETW WORLD, V30, P145, DOI 10.14311/NNW.2020.30.011
   Gao W, 2023, WORLD WIDE WEB, V26, P55, DOI 10.1007/s11280-022-01034-1
   Gao W, 2021, LECT NOTES COMPUT SC, V13080, P370, DOI 10.1007/978-3-030-90888-1_28
   Gao W, 2020, IEEE MULTIMEDIA, V27, P28, DOI 10.1109/MMUL.2020.3012675
   Gao W, 2019, KNOWL INF SYST, V61, P1123, DOI 10.1007/s10115-018-1314-7
   Gong J, 2021, PROMPT BASED ZERO SH, V0, P0
   Gu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8410
   Han X, 2022, OPEN, V3, P182, DOI 10.1016/J.AIOPEN.2022.11.003
   Jiang GY, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.103029
   Jwa H, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9194062
   Kai Shu, 2017, ACM SIGKDD EXPLORATIONS NEWSLETTER, V19, P22, DOI 10.1145/3137597.3137600
   Karnyoto A, 2022, COMPUT SCI INF SYST, V19, P639, DOI 10.2298/CSIS210501053K
   Liu C, 2019, LECT NOTES ARTIF INT, V11776, P172, DOI 10.1007/978-3-030-29563-9_17
   Liu JS, 2021, J WEB SEMANT, V70, P0, DOI 10.1016/j.websem.2021.100646
   Liu Pengfei, 2021, PRETRAIN PROMPT PRED, V0, P0
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P505
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Minaee S, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3439726
   Popat K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P22
   Przybyla P, 2020, AAAI CONF ARTIF INTE, V34, P490
   Raza S, 2022, INT J DATA SCI ANAL, V0, P0, DOI DOI 10.1007/s41060-022-00359-4
   Schucher N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P148
   Seoh R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6311
   Sheng Q, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, P1640, DOI 10.1145/3459637.3482440
   Sun AX, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1145, DOI 10.1145/2348283.2348511
   Wanda P, 2020, J INF SECUR APPL, V52, P0, DOI 10.1016/j.jisa.2020.102465
   Wang CY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P2792
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2020, AAAI CONF ARTIF INTE, V34, P516
   Yanagi Y, 2020, IEEE INT CONF INTELL, V0, PP85, DOI 10.1109/ines49302.2020.9147195
   Zellers Rowan, 2019, NEURIPS, V0, P0
   Zhou XY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM19), V0, PP836, DOI 10.1145/3289600.3291382
   Zhu Q, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1124
NR 39
TC 0
Z9 0
U1 6
U2 6
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2023
VL 44
IS 6
BP 9933
EP 9942
DI 10.3233/JIFS-221647
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA I6WU1
UT WOS:001004176300070
DA 2023-11-10
ER

PT J
AU Wu, ZF
   Merrill, W
   Peng, H
   Beltagy, I
   Smith, NA
AF Wu, Zhaofeng
   Merrill, William
   Peng, Hao
   Beltagy, Iz
   Smith, Noah A. A.
TI Transparency Helps Reveal When Language Models Learn Meaning
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Many current NLP systems are built from language models trained to optimize unsupervised objectives on large amounts of raw text. Under what conditions might such a procedure acquire meaning? Our systematic experiments with synthetic data reveal that, with languages where all expressions have context-independent denotations (i.e., languages with strong transparency), both autoregressive and masked language models successfully learn to emulate semantic relations between expressions. However, when denotations are changed to be context-dependent with the language otherwise unmodified, this ability degrades. Turning to natural language, our experiments with a specific phenomenon-referential opacity-add to the growing body of evidence that current language models do not represent natural language semantics well. We show this failure relates to the context-dependent nature of natural language form-meaning mappings.
C1 [Wu, Zhaofeng] MIT, Cambridge, MA 02139 USA.
   [Merrill, William] NYU, New York, NY USA.
   [Peng, Hao; Beltagy, Iz; Smith, Noah A. A.] Allen Inst Artificial Intelligence, Seattle, WA USA.
   [Smith, Noah A. A.] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA USA.
C3 Massachusetts Institute of Technology (MIT); New York University; University of Washington; University of Washington Seattle
RP Wu, ZF (通讯作者)，MIT, Cambridge, MA 02139 USA.
EM zfw@csail.mit.edu; willm@nyu.edu; haop@allenai.org; beltagy@allenai.org; noah@allenai.org
CR Alain G, 2017, 5 INT C LEARNING REP, V0, P0
   Alec Radford, 2019, LANGUAGE MODELS ARE, V0, P0
   Andreas Jacob, 2019, P INT C LEARNING REP, V0, P0
   [Anonymous], 2010, RECURSION HUMAN LANG, V0, P0, DOI DOI 10.1515/9783110219258.43
   [Anonymous], 2011, INT SEMANTICS UNPUB, V0, P0
   Bender EM, 2020, C SESSION P 58 ANN M, V0, P0
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Cao BX, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1860
   Carnap R, 1947, MEANING NECESSITY ST, V0, P0
   Chomsky N, 1995, LECT GOVT BINDING, V0, P0
   Chomsky Noam, 1983, SOME CONCEPTS CONSEQ, V0, P0
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Daniel S, 2018, THESIS CUNY, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dufter P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2353
   Efron B, 1993, INTRO BOOTSTRAP, V0, P0, DOI DOI 10.1201/9780429246593
   Elsahar H, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3448
   Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P55
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   FISHER RA, 1937, THE DESIGN OF EXPERIMENTS., V0, P0
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5
   Frege Gottlob, 1892, Z PHILOS PHILOS KRIT, V0, P0
   Grice P, 1975, SYNTAX SEMANTICS, V3, P0, DOI 10.1163/9789004368811_003
   GROENENDIJK J, 1991, LINGUIST PHILOS, V14, P39, DOI 10.1007/BF00628304
   Gulordava K, 2018, P 2018 C N AM CHAPT, V1, P1195, DOI 10.18653/V1/N18-1108
   Haviv A, 2022, ARXIV, V0, P0
   Heim I, 1982, SEMANTICS DEFINITE I, V0, P0
   Heim Irene, 1998, SEMANTICS GENERATIVE, V0, P0
   Hewitt J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2733
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Kamp Hans, 1981, FORMAL METHODS STUDY, V0, P277
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Kearns Kate, 2011, SEMANTICS, V0, P0
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4365
   Kripke Saul A, 1972, SEMANTICS NATURAL LA, V0, P253
   Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813
   Li BH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9119
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI 10.1353/LAN.2019.0015
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2171
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu YH, 2019, ARXIV, V0, P0
   Lyu Qing, 2022, P 2022 C N AM CHAPT, V0, PP5286, DOI 10.18653/v1/2022.naacl-main.388
   Merrill W, 2021, T ASSOC COMPUT LING, V9, P1047, DOI 10.1162/tacl_a_00412
   Pandia L, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1583
   Patel R, 2022, INT C LEARNING REPRE, V0, P0
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Poerner Nina, 2020, FINDINGS ASS COMPUTA, V0, PP803, DOI 10.18653/V1/2020.FINDINGS-EMNLP.71
   QUINE WV, 1956, J PHILOS, V53, P177, DOI 10.2307/2022451
   Ravichander A, 2020, P 9 JOINT C LEX COMP, V0, P88
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Salmon Nathan, 1990, PROPOSITIONAL ATTITU, V0, P215
   SHIEBER SM, 1985, LINGUIST PHILOS, V8, P333, DOI 10.1007/BF00630917
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Soler AG, 2021, T ASSOC COMPUT LING, V9, P825, DOI 10.1162/tacl_a_00400
   Speaks J, 2021, STANFORD ENCY PHILOS, V0, P0
   Tanya Reinhart, 1976, SYNTACTIC DOMAIN ANA, V0, P0
   Tenney Ian, 2019, P INT C LEARNING REP, V0, P0
   Traylor A, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P158
   Voita E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4396
   Vulie I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7222
   Wu ZF, 2021, T ASSOC COMPUT LING, V9, P226, DOI 10.1162/tacl_a_00363
   Yu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4896
   Yu Lang, 2021, FINDINGS ASS COMPUTA, V0, P2279
   Zhong Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5017
NR 68
TC 0
Z9 0
U1 2
U2 2
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 20
PY 2023
VL 11
IS 
BP 617
EP 634
DI 10.1162/tacl_a_00565
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA K7VI6
UT WOS:001018475800001
DA 2023-11-10
ER

PT J
AU Deng, JW
   Ren, FJ
AF Deng, Jiawen
   Ren, Fuji
TI A Survey of Textual Emotion Recognition and Its Challenges
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Emotion recognition; Deep learning; Task analysis; Social networking (online); Databases; Systematics; Computer architecture; Textual emotion recognition; deep learning; emotional resources; challenges; review
ID pleasure-arousal-dominance; multi-label classification; recognizing emotions; neural-network; sentiment; ensemble; model; corpus
AB Textual language is the most natural carrier of human emotion. In natural language processing, textual emotion recognition (TER) has become an important topic due to its significant academic and commercial potential. With the advanced development of deep learning technologies, TER has attracted growing attention and has significantly been promoted in recent years. This article provides a systematic survey of the latest TER advances, focusing on approaches using deep neural networks. According to how deep learning works at each stage, TER approaches are reviewed on word embedding, architecture, and training levels, respectively. We discussed the remaining challenges and opportunities from four aspects: the shortage of large-scale and high-quality datasets, fuzzy emotional boundaries, incomplete extractable emotional information in texts, and TER in dialogue. This article creates a systematic and in-depth overview of deep TER technologies. It provides the necessary knowledge and new insights for relevant researchers to understand better the research state, remaining challenges, and future directions in this field.
C1 [Deng, Jiawen; Ren, Fuji] Tokushima Univ, Fac Engn, Tokushima 7708506, Japan.
C3 Tokushima University
RP Deng, JW (通讯作者)，Tokushima Univ, Fac Engn, Tokushima 7708506, Japan.
EM c501847002@tokushima-u.ac.jp; ren@is.tokushima-u.ac.jp
FU Research Clusters program of Tokushima University [2003002]; NSFC-Shenzhen Joint Foundation Key Project [U1613217]
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Agrawal P, 2019, P 13 INT WORKSHOP SE, V0, P266
   Ahmad Z, 2020, EXPERT SYST APPL, V139, P0, DOI 10.1016/j.eswa.2019.112851
   Alm CO, 2005, P HUM LANG TECHN C C, V0, P0
   Alswaidan N, 2020, KNOWL INF SYST, V62, P2937, DOI 10.1007/s10115-020-01449-0
   Anjaria M, 2014, INT CONF COMMUN SYST, V0, P0
   [Anonymous], 2018, LONG PAPERS, V0, P0
   Araque O, 2022, IEEE T AFFECT COMPUT, V13, P496, DOI 10.1109/TAFFC.2019.2934444
   Arifin S, 2008, IEEE T MULTIMEDIA, V10, P1325, DOI 10.1109/TMM.2008.2004911
   Augenstein I, 2018, P NAACL, V1, P1896, DOI 10.18653/V1/N18-1172
   Brown TB, 2020, ARXIV, V0, P0
   Balazs J, 2018, ARXIV PREPRINT ARXIV, V0, P50
   Balikas G, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1005, DOI 10.1145/3077136.3080702
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Basile A, 2019, P 13 INT WORKSHOP SE, V0, P330
   Baziotis C, 2018, P 12 INT WORKSH SEM, V0, PP245, DOI 10.18653/V1/S18-1037
   Bhaskar J, 2015, PROCEDIA COMPUT SCI, V46, P635, DOI 10.1016/j.procs.2015.02.112
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Bradley MM, 1999, AFFECTIVE NORMS ENGL, V0, P0, DOI DOI 10.1109/MIC.2008.114
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Buechel S, 2017, SHORT PAPERS, V0, P578
   Buitinck Lars, 2015, ADVANCES IN INFORMATION RETRIEVAL. 37TH EUROPEAN CONFERENCE ON IR RESEARCH (ECIR 2015). PROCEEDINGS: LNCS 9022, V0, PP43, DOI 10.1007/978-3-319-16354-3_5
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cabrera-Quiros L, 2022, IEEE T AFFECT COMPUT, V13, P46, DOI 10.1109/TAFFC.2019.2930605
   Camacho-Collados J, 2018, J ARTIF INTELL RES, V63, P743, DOI 10.1613/jair.1.11259
   Cambria E, 2018, AAAI CONF ARTIF INTE, V0, P1795
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Canales L, 2022, IEEE T AFFECT COMPUT, V13, P579, DOI 10.1109/TAFFC.2019.2927564
   de Albornoz JC, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3562
   Chatterjee A, 2019, P 13 INT WORKSH SEM, V0, P39
   Chatterjee A, 2019, COMPUT HUM BEHAV, V93, P309, DOI 10.1016/j.chb.2018.12.029
   Chawla NV, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, V0, P875, DOI 10.1007/978-0-387-09823-4_45
   Chen CT, 2019, INFORM SCIENCES, V502, P268, DOI 10.1016/j.ins.2019.06.050
   Chen CH, 2018, INFORM PROCESS MANAG, V54, P1325, DOI 10.1016/j.ipm.2018.05.008
   Chen S-Y, 2018, EMOTIONLINES EMOTION, V0, P0
   Chronopoulou A, 2018, P 9 WORKSHOP COMPUTA, V0, P57
   Collobert R, 2008, P 25 INT C MACH LEAR, V0, PP160, DOI 10.1145/1390156.1390177
   Colneric N, 2020, IEEE T AFFECT COMPUT, V11, P433, DOI 10.1109/TAFFC.2018.2807817
   Corchs S, 2019, INT J MACH LEARN CYB, V10, P2057, DOI 10.1007/s13042-017-0734-0
   Dai ZH, 2019, ARXIV, V0, P0
   Deng JW, 2023, IEEE T AFFECT COMPUT, V14, P475, DOI 10.1109/TAFFC.2020.3034215
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Donahue J, 2015, PROC CVPR IEEE, V0, PP2625, DOI 10.1109/CVPR.2015.7298878
   Dong L, 2019, ADV NEUR IN, V32, P0
   Du P, 2018, PROC 12 INT WORKSHOP, V0, PP345, DOI 10.18653/v1/S18-1052
   Phan DA, 2021, IEEE T AFFECT COMPUT, V12, P682, DOI 10.1109/TAFFC.2018.2885304
   Eisner B, 2016, P 4 INT WORKSH NAT L, V0, P0
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Felbo B, 2017, P 2017 C EMP METH NA, V0, P1615
   Fersini E, 2014, DECIS SUPPORT SYST, V68, P26, DOI 10.1016/j.dss.2014.10.004
   Gao W, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, PP1505, DOI 10.1145/2505515.2507830
   García-Martínez B, 2021, IEEE T AFFECT COMPUT, V12, P801, DOI 10.1109/TAFFC.2018.2890636
   Gideon J, 2021, IEEE T AFFECT COMPUT, V12, P1055, DOI 10.1109/TAFFC.2019.2916092
   Goel P, 2017, P 8 WORKSH COMP APPR, V0, P58
   Golder SA, 2011, SCIENCE, V333, P1878, DOI 10.1126/science.1202775
   Gupta R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5109, DOI 10.1109/ICASSP.2018.8461414
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2594
   Hazarika Devamanyu, 2018, PROC CONF, V2018, P2122, DOI 10.18653/v1/n18-1193
   He HH, 2018, LECT NOTES ARTIF INT, V11108, P250, DOI 10.1007/978-3-319-99495-6_21
   He ZF, 2019, KNOWL-BASED SYST, V163, P145, DOI 10.1016/j.knosys.2018.08.018
   Huang CK, 2019, PROCEEDINGS OF THE 2019 ACM MOBIHOCWORKSHOP ON PERVASIVE SYSTEMS IN THE IOT ERA (PERSIST-IOT 19), V0, PP49, DOI 10.1145/3331052.3332478
   Huang HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290605.3300851
   Imani M, 2019, J NETW COMPUT APPL, V147, P0, DOI 10.1016/j.jnca.2019.102423
   Jabreel M, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9061123
   Kang X, 2018, IEEE-CAA J AUTOMATIC, V5, P204, DOI 10.1109/JAS.2017.7510421
   Khanpour H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1160
   Khuong Vo, 2017, MULTI-DISCIPLINARY TRENDS IN ARTIFICIAL INTELLIGENCE. 11TH INTERNATIONAL WORKSHOP, V0, P162, DOI 10.1007/978-3-319-69456-6_14
   Kim S, 2015, AAAI CONF ARTIF INTE, V0, P168
   Kim Y, 2018, PROC 12 INT WORKSHOP, V0, PP141, DOI 10.18653/V1/S18-1019
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kiritchenko Svetlana, 2018, P 7 JOINT C LEX COMP, V0, PP43, DOI 10.18653/V1/S18-2005
   Ko BC, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18020401
   Kowsari K, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP364, DOI 10.1109/ICMLA.2017.0-134
   Kratzwald B, 2018, DECIS SUPPORT SYST, V115, P24, DOI 10.1016/j.dss.2018.09.002
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Kurohashi S, 2018, PROC C N AM CHAPTER, V2, P253, DOI 10.18653/V1/N18-2041
   [李霞 Li Xia], 2018, 自动化学报 ACTA AUTOMATICA SINICA, V44, P2142
   Li Y, 2022, IEEE T AFFECT COMPUT, V13, P568, DOI 10.1109/TAFFC.2019.2922912
   Li Yanran, 2017, IJCNLP, V0, P0
   Li ZY, 2022, IEEE T AFFECT COMPUT, V13, P519, DOI 10.1109/TAFFC.2019.2936198
   Lian SM, 2019, APPL SOFT COMPUT, V74, P709, DOI 10.1016/j.asoc.2018.10.035
   Liao W, 2019, NEUROCOMPUTING, V32, P188
   Lingren T, 2014, J AM MED INFORM ASSN, V21, P406, DOI 10.1136/amiajnl-2013-001837
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Liu SM, 2015, EXPERT SYST APPL, V42, P1083, DOI 10.1016/j.eswa.2014.08.036
   Majumder N, 2019, AAAI CONF ARTIF INTE, V0, P6818
   McCann B, 2017, ADV NEURAL INFORM PR, V0, P0
   McCann B, 2018, ARXIV, V0, P0
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Meisheri H, 2018, P 12 INT WORKSH SEM, V0, PP291, DOI 10.18653/V1/S18-1043
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, ARXIV, V0, P0
   Mohammad S, 2018, P 12 INT WORKSH SEM, V0, PP1, DOI 10.18653/V1/S18-1001
   Mohammad S, 2012, P 1 JOINT C LEXICAL, V0, P246
   Mohammad SM, 2010, P NAACL HLT 2010 WOR, V0, P0
   Mohammad SM, 2017, P 8 WORKSH COMP APPR, V0, P0
   Mohammad SM, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P174
   Mohammad SM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P174
   Montero Calkin Suero, 2014, P 14 KOLI CALLING IN, V0, P165
   Munezero M, 2014, IEEE T AFFECT COMPUT, V5, P101, DOI 10.1109/TAFFC.2014.2317187
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pennebaker JW, 2015, DEV PSYCHOMETRIC PRO, V0, P0
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Perikos I, 2016, ENG APPL ARTIF INTEL, V51, P191, DOI 10.1016/j.engappai.2016.01.012
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.28.739
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P527
   Poria S, 2019, IEEE ACCESS, V7, P100943, DOI 10.1109/ACCESS.2019.2929050
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Qian Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1679, DOI 10.18653/v1/P17-1154
   Quan C, 2010, INT J ADV INTELL, V2, P105
   Quan CQ, 2010, COMPUT SPEECH LANG, V24, P726, DOI 10.1016/j.csl.2010.02.002
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rao TR, 2019, NEUROCOMPUTING, V333, P429, DOI 10.1016/j.neucom.2018.12.053
   Rei M, 2019, AAAI CONF ARTIF INTE, V0, P6916
   Ren FJ, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8122472
   Ren FJ, 2016, IEEE J BIOMED HEALTH, V20, P1384, DOI 10.1109/JBHI.2015.2459683
   Ren F, 2016, J INTELL FUZZY SYST, V31, P127, DOI 10.3233/IFS-162126
   Ren F, 2016, IEEE T AFFECT COMPUT, V7, P176, DOI 10.1109/TAFFC.2015.2457915
   Ren FJ, 2013, IEEE T AFFECT COMPUT, V4, P412, DOI 10.1109/T-AFFC.2013.22
   Rouast PV, 2021, IEEE T AFFECT COMPUT, V12, P524, DOI 10.1109/TAFFC.2018.2890471
   Ruder S, 2017, ARXIV, V0, P0
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sagot Benoit, 2010, P 4 LING ANN WORKSH, V0, P56
   Sailunaz K, 2018, SOC NETW ANAL MIN, V8, P0, DOI 10.1007/s13278-018-0505-2
   Sanghwan B, 2019, PROC 13 INT WORKSHOP, V0, P312
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Seyeditabari A, 2018, ARXIV, V0, P0
   Akhtar MS, 2018, ARXIV, V0, P0
   Shen DH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P440
   Shi B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2494
   Shi Y, 2019, INT J INF TECH DECIS, V18, P1243, DOI 10.1142/S0219622019300015
   Shoumy NJ, 2020, J NETW COMPUT APPL, V149, P0, DOI 10.1016/j.jnca.2019.102447
   Smith SL, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Song KT, 2019, ARXIV, V0, P0
   Sordoni Alessandro, 2015, P 24 ACM INT C INFOR, V0, P553
   Strapparava C, 2004, P 4 INT C LANGUAGE R, V0, P0
   Strapparava C, 2015, OXFORD HDB AFFECTIVE, V0, P184
   Strapparava Carlo, 2007, P 4 INT WORKSH SEM E, V0, PP70, DOI 10.3115/1621474.1621487
   Sun X, 2019, INFORM FUSION, V46, P11, DOI 10.1016/j.inffus.2018.04.001
   Susanto Y, 2020, IEEE INTELL SYST, V35, P96, DOI 10.1109/MIS.2020.2992799
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Tang Duyu, 2016, P 2016 C EMP METH NA, V0, PP214, DOI 10.18653/v1/D16-1021
   Teik-Toe Teoh, 2011, 2011 SEVENTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC 2011), V0, PP908, DOI 10.1109/ICNC.2011.6022189
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Vaswani A, 2017, ARXIV, V30, P5998
   Vo K, 2019, ARXIV, V0, P0
   Wang H, 2018, INT C PATT RECOG, V0, PP824, DOI 10.1109/ICPR.2018.8545379
   Wang K, 2018, ASIAN C MACHINE LEAR, V0, P1
   Wang XH, 2018, ARXIV, V0, P0
   Wang ZQ, 2018, LECT NOTES ARTIF INT, V11109, P429, DOI 10.1007/978-3-319-99501-4_39
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6382
   Wiedemann G, 2018, ARXIV, V0, P0
   Winata GIndra, 2019, P 13 INT WORKSH SEM, V0, P0
   Wu DR, 2022, IEEE T AFFECT COMPUT, V13, P16, DOI 10.1109/TAFFC.2019.2916040
   Xie QZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P950, DOI 10.18653/v1/P17-1088
   Xinyue Zhu, 2018, ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING. 22ND PACIFIC-ASIA CONFERENCE, V0, P349, DOI 10.1007/978-3-319-93040-4_28
   Xu GX, 2020, FUTURE GENER COMP SY, V102, P347, DOI 10.1016/j.future.2019.07.007
   Xu P, 2018, P 9 WORKSH COMP APPR, V0, PP292, DOI 10.18653/V1/W18-6243
   Xu T, 2018, PROCEDIA COMPUT SCI, V130, P376, DOI 10.1016/j.procs.2018.04.056
   Yadollahi A, 2017, ACM COMPUT SURV, V50, P0, DOI 10.1145/3057270
   Yan JLS, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1149
   [杨亮 YANG Liang], 2011, 计算机工程与科学 COMPUTER ENGINEERING AND SCIENCE, V33, P123
   Yang M, 2021, IEEE T AFFECT COMPUT, V12, P761, DOI 10.1109/TAFFC.2019.2897093
   Yang P, 2018, P 27 INT C COMPUTATI, V0, P3915
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yeh CK, 2017, AAAI CONF ARTIF INTE, V0, P2838
   Ying W, 2019, P 5 WORKSH NOIS US G, V0, PP316, DOI 10.18653/V1/D19-5541
   Yu JF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1097
   Zahiri SM, 2018, P WORKSH 32 AAAI C A, V0, P44
   Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338, DOI 10.1109/TKDE.2006.162
   Zhang ML, 2018, FRONT COMPUT SCI-CHI, V12, P191, DOI 10.1007/s11704-017-7031-7
   Zhang Y, 2014, SIGIR14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP627, DOI 10.1145/2600428.2609587
   Zhang YX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4595
   Zheng WL, 2019, IEEE T AFFECT COMPUT, V10, P417, DOI 10.1109/TAFFC.2017.2712143
   Zhong PX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P165
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
   Zhu SY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P471
NR 184
TC 14
Z9 14
U1 17
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
EI 
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD JAN 1
PY 2023
VL 14
IS 1
BP 49
EP 67
DI 10.1109/TAFFC.2021.3053275
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA D0WE4
UT WOS:000966007000001
DA 2023-11-10
ER

PT J
AU Bakkali, S
   Ming, ZH
   Coustaty, M
   Rusiñol, M
   Terrades, OR
AF Bakkali, Souhail
   Ming, Zuheng
   Coustaty, Mickael
   Rusinol, Marcal
   Ramos Terrades, Oriol
TI VLCDoC: Vision-Language contrastive pre-training model for cross-Modal document classification
SO PATTERN RECOGNITION
LA English
DT Article
DE Multimodal document representation; learning; Document classification; Contrastive learning; Self-Attention; Transformers
AB Multimodal learning from document data has achieved great success lately as it allows to pre-train se-mantically meaningful features as a prior into a learnable downstream task. In this paper, we approach the document classification problem by learning cross-modal representations through language and vi-sion cues, considering intra-and inter-modality relationships. Instead of merging features from different modalities into a joint representation space, the proposed method exploits high-level interactions and learns relevant semantic information from effective attention flows within and across modalities. The proposed learning objective is devised between intra-and inter-modality alignment tasks, where the similarity distribution per task is computed by contracting positive sample pairs while simultaneously contrasting negative ones in the joint representation space. Extensive experiments on public benchmark datasets demonstrate the effectiveness and the generality of our model both on low-scale and large-scale datasets. (c) 2023 Elsevier Ltd. All rights reserved.
C1 [Bakkali, Souhail; Ming, Zuheng; Coustaty, Mickael] La Rochelle Univ, L3i, La Rochelle, France.
   [Ming, Zuheng] Univ Sorbonne Paris Nord, L2TI, Villetaneuse, France.
   [Rusinol, Marcal; Ramos Terrades, Oriol] Univ Autonoma Barcelona, CVC, Barcelona, Spain.
   [Rusinol, Marcal] AllRead MLT, Barcelona, Spain.
C3 Autonomous University of Barcelona; Centre de Visio per Computador (CVC)
RP Bakkali, S (通讯作者)，La Rochelle Univ, L3i, La Rochelle, France.
EM souhail.bakkali@univ-lr.fr; zuheng.ming@univparis13.fr; mickael.coustaty@univ-lr.fr; marcal@allread.ai; oriolrt@cvc.uab.cat
FU French National Research Agency (ANR); Catalan project [RTI2018-095645-B-C21]; CERCA Program/Generalitat de Catalunya; Spanish project;  [2017-SGR-1783]
CR Afzal MZ, 2017, PROC INT CONF DOC, V0, PP883, DOI 10.1109/ICDAR.2017.149
   Appalaraju Srikar, 2021, P IEEECVF INT C COMP, V0, P993
   Audebert N, 2020, COMM COM INF SC, V1167, P427, DOI 10.1007/978-3-030-43823-4_35
   Bahdanau D, 2016, ARXIV, V0, P0
   Bakkali S, 2021, INT J DOC ANAL RECOG, V24, P251, DOI 10.1007/s10032-021-00378-0
   Bakkali S, 2020, IEEE IMAGE PROC, V0, PP2556, DOI 10.1109/ICIP40778.2020.9191268
   Bakkali S, 2020, IEEE COMPUT SOC CONF, V0, PP2394, DOI 10.1109/CVPRW50498.2020.00289
   Chen T, 2020, P INT C MACH LEARN, V0, P1597
   Das A, 2018, INT C PATT RECOG, V0, PP3180, DOI 10.1109/ICPR.2018.8545630
   Dauphinee T, 2019, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dimmick D, 1991, NIST SPECIAL DATABAS, V0, P0
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R, V0, P0
   Gu J, 2020, ADV NEURAL INFORM PR, V33, P1841
   Harley AW, 2015, PROC INT CONF DOC, V0, PP991, DOI 10.1109/ICDAR.2015.7333910
   Huang Y, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2204.08387
   Krishnan P, 2016, LECT NOTES COMPUT SC, V9905, P766, DOI 10.1007/978-3-319-46448-0_46
   Kumar J, 2014, PATTERN RECOGN LETT, V43, P119, DOI 10.1016/j.patrec.2013.10.030
   Li J, 2022, ARXIV, V0, P0
   Li PZ, 2021, PROC CVPR IEEE, V0, PP5648, DOI 10.1109/CVPR46437.2021.00560
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Nam H, 2017, PROC CVPR IEEE, V0, PP2156, DOI 10.1109/CVPR.2017.232
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Tito R, 2021, LECT NOTES COMPUT SC, V12824, P635, DOI 10.1007/978-3-030-86337-1_42
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Verma Y, 2018, INT J MULTIMED INF R, V7, P139, DOI 10.1007/s13735-017-0138-7
   Wang J, 2022, ARXIV, V0, P0
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP22, DOI 10.1109/ICCV48922.2021.00009
   Xu Y, 2022, ARXIV, V0, P0
   Xu YH, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1192, DOI 10.1145/3394486.3403172
   Yuan X, 2021, PROC CVPR IEEE, V0, PP6991, DOI 10.1109/CVPR46437.2021.00692
   Zhang P, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1413, DOI 10.1145/3394171.3413900
NR 33
TC 1
Z9 1
U1 7
U2 7
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD JUL 15
PY 2023
VL 139
IS 
BP 
EP 
DI 10.1016/j.patcog.2023.109419
EA FEB 2023
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 9X6ZX
UT WOS:000949916600001
DA 2023-11-10
ER

PT J
AU Zhang, WZ
   Yang, HW
AF Zhang, Weizhao
   Yang, Hongwu
TI Improving Sequence-to-sequence Tibetan Speech Synthesis with Prosodic Information
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Sequence-to-sequence speech synthesis; Tibetan speech synthesis; prosodic information fusion; low-resource language
ID adaptation; speaker
AB There are about 6,000 languages worldwide, most of which are low-resource languages. Although the current speech synthesis (or text-to-speech, TTS) for major languages (e.g., Mandarin, English, French) has achieved good results, the voice quality of TTS for low-resource languages (e.g., Tibetan) still needs to be further improved. Because prosody plays a significant role in natural speech, the article proposes two sequence-tosequence (seq2seq) Tibetan TTS models with prosodic information fusion to improve the voice quality of synthesized Tibetan speech. We first constructed a large-scale Tibetan corpus for seq2seq TTS. Then we designed a prosody generator to extract prosodic information from the Tibetan sentences. Finally, we trained two seq2seq Tibetan TTS models by fusing prosodic information, including feature-level and model-level prosodic information fusion. The experimental results showed that the proposed two seq2seq Tibetan TTS models, which fuse prosodic information, could effectively improve the voice quality of synthesized speech. Furthermore, the model-level prosodic information fusion only needs 60% similar to 70% of the training data to synthesize a voice similar to the baseline seq2seq Tibetan TTS. Therefore, the proposed prosodic information fusion methods can improve the voice quality of synthesized speech for low-resource languages.
C1 [Zhang, Weizhao] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Yang, Hongwu] Northwest Normal Univ, Sch Educ Technol, Lanzhou, Peoples R China.
C3 Northwest Normal University - China; Northwest Normal University - China
RP Yang, HW (通讯作者)，Northwest Normal Univ, Sch Educ Technol, Lanzhou, Peoples R China.
EM zhangweizhao@nwnu.edu.cn; yanghw@nwnu.edu.cn
FU National Natural Science Foundation of China [62067008, 11664036, 62267008]; Science and Technology Program of Gansu Province [20JR10RA095, 21JR7RA117]; University Innovation Foundation of Gansu Province [2022B-091, 2023B-239]
CR Bahdanau D, 2016, ARXIV, V0, P0
   [才让卓玛 Cai Rangzhuoma], 2017, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V31, P59
   Chorowski J, 2015, ADV NEUR IN, V28, P0
   Chorowski Jan, 2014, P NIPS 2014 WORKSH D, V0, P0
   [都格草 Dou Gecao], 2019, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V33, P75
   Fan Yuchen, 2014, 15 ANN C INT SPEECH, V0, P1964
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Hayashi T, 2019, INTERSPEECH, V0, PP4430, DOI 10.21437/Interspeech.2019-3177
   Hunt AJ, 1996, INT CONF ACOUST SPEE, V0, PP373, DOI 10.1109/ICASSP.1996.541110
   Kang SY, 2013, INT CONF ACOUST SPEE, V0, PP8012, DOI 10.1109/ICASSP.2013.6639225
   Lee Y, 2019, INT CONF ACOUST SPEE, V0, PP5911, DOI 10.1109/ICASSP.2019.8683501
   Li JB, 2019, INTERSPEECH, V0, PP4494, DOI 10.21437/Interspeech.2019-1118
   Ling ZH, 2015, IEEE SIGNAL PROC MAG, V32, P35, DOI 10.1109/MSP.2014.2359987
   Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291
   Lu YF, 2019, INT CONF ACOUST SPEE, V0, PP7050, DOI 10.1109/ICASSP.2019.8682368
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Mohammadi A, 2014, IEEE-ACM T AUDIO SPE, V22, P2146, DOI 10.1109/TASLP.2014.2362009
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4779, DOI 10.1109/ICASSP.2018.8461368
   Skerry-Ryan RJ, 2018, P 35 INT C MACHINE L, V0, P4700
   Song E, 2017, IEEE-ACM T AUDIO SPE, V25, P2152, DOI 10.1109/TASLP.2017.2746264
   Sotelo Jose, 2017, P 5 INT C LEARN REPR, V0, P0
   Sun GZ, 2020, INT CONF ACOUST SPEE, V0, PP6264, DOI 10.1109/icassp40776.2020.9053520
   Tachibana M, 2008, INT CONF ACOUST SPEE, V0, P4633
   Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852
   Valle R, 2020, INT CONF ACOUST SPEE, V0, PP6189, DOI 10.1109/icassp40776.2020.9054556
   van den Oord Aaron, 2016, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1609.03499
   Wang WF, 2016, INTERSPEECH, V0, PP2243, DOI 10.21437/Interspeech.2016-134
   Wang Y, 2018, P INT C MACH LEARN, V0, P5167
   Wang YX, 2017, INTERSPEECH, V0, PP4006, DOI 10.21437/Interspeech.2017-1452
   Wu ZQ, 2013, 2013 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), V0, PP92, DOI 10.1109/ICCSNT.2013.6967070
   Xiao YJ, 2020, INT CONF ACOUST SPEE, V0, PP6704, DOI 10.1109/ICASSP40776.2020.9054337
   Yang HW, 2015, MULTIMED TOOLS APPL, V74, P9927, DOI 10.1007/s11042-014-2117-9
   Yoshimura T, 2000, JOURNAL OF THE ACOUSTICAL SOCIETY OF JAPAN (E), V21, P199, DOI 10.1250/ast.21.199
   Zen HG, 2013, INT CONF ACOUST SPEE, V0, PP7962, DOI 10.1109/ICASSP.2013.6639215
   Zhang WZ, 2019, IEEE ACCESS, V7, P167884, DOI 10.1109/ACCESS.2019.2954342
   Zhang YJ, 2019, INT CONF ACOUST SPEE, V0, PP6945, DOI 10.1109/ICASSP.2019.8683623
NR 36
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2023
VL 22
IS 9
BP 
EP 
DI 10.1145/3616012
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA T7EN7
UT WOS:001079577300005
DA 2023-11-10
ER

PT J
AU Liu, JP
   Liu, JT
   Chen, LH
   Liang, JQ
   Xiao, YH
   Xu, HM
   Zhang, FB
   Wang, ZY
   Xie, R
AF Liu, Jingping
   Liu, Juntao
   Chen, Lihan
   Liang, Jiaqing
   Xiao, Yanghua
   Xu, Huimin
   Zhang, Fubao
   Wang, Zongyu
   Xie, Rui
TI Noun Compound Interpretation With Relation Classification and Paraphrasing
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Noun compound interpretation; relation classification; paraphrasing
AB Noun compounds are abundant in various languages and their interpretations have been applied in a wide range of NLP tasks. However, most existing work only uses relation classification- or paraphrasing-based methods to model this problem, failing in coverage or accuracy. We argue that the above two approaches are complementary to each other for the noun compound interpretation. In this paper, we propose a two-phase strategy to solve this task. The first phase is to perform the relation classification sub-task with a novel multi-view representation learning model. When noun compounds are predicted as the non-semantic relation, i.e., NA, or the confidence scores are below the threshold, the second phase, namely paraphrasing, will be triggered to interpret noun compounds with a contrastive slot filling method. To evaluate the effectiveness of our methods, we construct the largest Chinese dataset for noun compound interpretation in the life service domain. The experimental results on our constructed and public datasets prove the effectiveness of our solution. Furthermore, the online A/B testing on Meituan APP suggests that the Query View Click-Through Rate increases by 0.91% when noun compounds are used to enrich semantic information of items with the help of their interpretations on the platform.
C1 [Liu, Jingping] East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200231, Peoples R China.
   [Liu, Juntao; Chen, Lihan; Liang, Jiaqing; Xiao, Yanghua] Fudan Univ, Sch Comp Sci, Shanghai 200437, Peoples R China.
   [Xu, Huimin; Zhang, Fubao; Wang, Zongyu; Xie, Rui] Meituan, Shanghai 20035, Peoples R China.
C3 East China University of Science & Technology; Fudan University
RP Liu, JP (通讯作者)，East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200231, Peoples R China.; Xiao, YH (通讯作者)，Fudan Univ, Sch Comp Sci, Shanghai 200437, Peoples R China.
EM jingpingliu@ecust.edu.cn; jtliu19@fudan.edu.cn; lhc825@gmail.com; l.j.q.light@gmail.com; shawyh@fudan.edu.cn; xuhuimin04@meituan.com; zhangfubao@meituan.com; wangzongyu02@meituan.com; rui.xie@meituan.com
FU National Key Research and Development Project [2020AAA0109302]; Shanghai Science and Technology Innovation Action Plan [19511120400]; Shanghai Municipal Science and Technology Major Project [2021SHZDZX0103]
CR [Anonymous], 2009, PROC C EUR CHAPTER A, V0, P0
   Soares LB, 2019, ARXIV, V0, P0
   Che W, 2020, ARXIV, V0, P0
   Chen JD, 2019, PROC INT CONF DATA, V0, PP1706, DOI 10.1109/ICDE.2019.00178
   Chen JK, 2018, AAAI CONF ARTIF INTE, V0, P5070
   Chowdhury JR, 2022, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   DOWNING P, 1977, LANGUAGE, V53, P810, DOI 10.2307/412913
   Dumitrache A, 2018, ARXIV, V0, P0
   Fares M, 2018, ARXIV, V0, P0
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Hadsell R, 2006, P 2006 IEEE COMP SOC, V2, P1735, DOI 10.1109/CVPR.2006.100
   Hendrickx I, 2019, ARXIV, V0, P0
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Mesquita F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P749
   Mikolov T, 2013, ARXIV, V0, P0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Peng H, 2020, ARXIV, V0, P0
   Ponkiya G, 2018, P 27 INT C COMPUTATI, V0, P1827
   Ponkiya G, 2020, PROC FINDINGS ASS CO, V0, P4313
   Qun N, 2020, J COMPUT SCI TECH-CH, V35, P1115, DOI 10.1007/s11390-020-9576-4
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Rosario B, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, P82
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Shao YF, 2022, ARXIV, V0, P0
   Shwartz V, 2018, ARXIV, V0, P0
   Shwartz V, 2018, ARXIV, V0, P0
   Sun J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5176
   Tratz S, 2011, SEMANTICALLY ENRICHE, V0, P0
   Tratz S, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P678
   Vaswani A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1706.03762
   Versley Y, 2013, PROC 7 INT WORKSHOP, V0, P148
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Yan H, 2019, ARXIV, V0, P0
   Zhang Y, 2017, P 2017 C EMPIRICAL M, V0, P35
NR 36
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD SEPT 1
PY 2023
VL 35
IS 9
BP 8757
EP 8769
DI 10.1109/TKDE.2022.3208617
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA O7QE8
UT WOS:001045704800005
DA 2023-11-10
ER

PT J
AU Schepers, I
   Medvedeva, M
   Bruijn, M
   Wieling, M
   Vols, M
AF Schepers, Iris
   Medvedeva, Masha
   Bruijn, Michelle
   Wieling, Martijn
   Vols, Michel
TI Predicting citations in Dutch case law with natural language processing
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article; Early Access
DE Machine learning; Case law; Natural language processing; Citation analysis; Judicial decisions
ID network analysis
AB With the ever-growing accessibility of case law online, it has become challenging to manually identify case law relevant to one's legal issue. In the Netherlands, the planned increase in the online publication of case law is expected to exacerbate this challenge. In this paper, we tried to predict whether court decisions are cited by other courts or not after being published, thus in a way distinguishing between more and less authoritative cases. This type of system may be used to process the large amounts of available data by filtering out large quantities of non-authoritative decisions, thus helping legal practitioners and scholars to find relevant decisions more easily, and drastically reducing the time spent on preparation and analysis. For the Dutch Supreme Court, the match between our prediction and the actual data was relatively strong (with a Matthews Correlation Coefficient of 0.60). Our results were less successful for the Council of State and the district courts (MCC scores of 0.26 and 0.17, relatively). We also attempted to identify the most informative characteristics of a decision. We found that a completely explainable model, consisting only of handcrafted metadata features, performs almost as well as a less well-explainable system based on all text of the decision.
C1 [Schepers, Iris; Bruijn, Michelle; Vols, Michel] Univ Groningen, Fac Law, Dept Legal Methods, Groningen, Netherlands.
   [Schepers, Iris; Wieling, Martijn] Univ Groningen, Fac Arts, Ctr Language & Cognit Groningen, Groningen, Netherlands.
   [Medvedeva, Masha] Leiden Univ, Fac Law, Ctr Law & Digital Technol, Leiden, Netherlands.
C3 University of Groningen; University of Groningen; Leiden University; Leiden University - Excl LUMC
RP Schepers, I (通讯作者)，Univ Groningen, Fac Law, Dept Legal Methods, Groningen, Netherlands.; Schepers, I (通讯作者)，Univ Groningen, Fac Arts, Ctr Language & Cognit Groningen, Groningen, Netherlands.
EM i.schepers@rug.nl
FU European Union [949316]; Center for Information Technology of the University of Groningen; European Research Council (ERC) [949316] Funding Source: European Research Council (ERC)
CR Ashley KD, 2017, ARTIFICIAL INTELLIGENCE AND LEGAL ANALYTICS: NEW TOOLS FOR LAW PRACTICE IN THE DIGITAL AGE, V0, PP1, DOI 10.1017/9781316761380
   Barabási AL, 2003, SCI AM, V288, P60, DOI 10.1038/scientificamerican0503-60
   Chalkidis I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4317
   Chicco D, 2020, BMC GENOMICS, V21, P0, DOI 10.1186/s12864-019-6413-7
   Derlén M, 2017, J INT ECON LAW, V20, P257, DOI 10.1093/jiel/jgx011
   Fowler JH, 2008, SOC NETWORKS, V30, P16, DOI 10.1016/j.socnet.2007.05.001
   Gholamy A, 2018, UTEPCS1809, V0, P0
   Hernandez Serrano PV, 2020, FRONT ARTIF INTEL AP, V334, P231, DOI 10.3233/FAIA200871
   Katz DM, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0174698
   Kaur A, 2019, IR C ART INT COGN SC, V0, P0
   Ke Q, 2015, P NATL ACAD SCI USA, V112, P7426, DOI 10.1073/pnas.1424329112
   Leitao JC, 2019, APPL NETW SCI, V4, P0, DOI 10.1007/s41109-018-0110-3
   Lippi M, 2019, ARTIF INTELL LAW, V27, P117, DOI 10.1007/s10506-019-09243-2
   Medvedeva M, 2021, ASAILLEGALAIIA ICAIL, V0, P0
   Medvedeva M, 2021, LEGAL KNOWLEDGE INFO, V0, P13
   Medvedeva M, 2023, ARTIF INTELL LAW, V31, P195, DOI 10.1007/s10506-021-09306-3
   Medvedeva M, 2020, ARTIF INTELL LAW, V28, P237, DOI 10.1007/s10506-019-09255-y
   Moens MF, 1997, P 6 INT C ARTIFICIAL, V0, P114
   Mones E, 2021, SCI REP-UK, V11, P1
   Montemagni, 2009, P 12 INT C ARTIFICIA, V0, PP40, DOI 10.1145/1568234.1568240
   OSullivan C, 2019, 27 AIAI IR C ART INT, V0, P0
   Pandya V, 2019, CS IT C P CS IT C P, V9, P0
   Sadl U, 2020, RELEVANCE NETWORK AP, V0, P0
   Sartor G, 2023, ADV CONCEPTUAL MODEL, V0, P102
   Sleimi A, 2021, EMPIR SOFTW ENG, V26, P0, DOI 10.1007/s10664-020-09933-5
   Sleimi A, 2018, INT REQUIR ENG CONF, V0, PP124, DOI 10.1109/RE.2018.00022
   Strickson Benjamin, 2020, ICISS 2020: PROCEEDINGS OF THE 2020 THE 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEM, V0, PP204, DOI 10.1145/3388176.3388183
   Sulea O, 2017, P INT C REC ADV NAT, V0, PP716, DOI 10.26615/978-954-452-049-6_092
   Sulea OM, 2017, 2 WORKSHOP AUTOMATED, V0, P0
   Van Kuppevelt D, 2017, FRONT ARTIF INTEL AP, V302, P95, DOI 10.3233/978-1-61499-838-9-95
   van Opijnen M, 2016, FRONT ARTIF INTEL AP, V294, P155, DOI 10.3233/978-1-61499-726-9-155
   Van Opijnen M, 2012, FRONT ARTIF INTEL AP, V250, P95, DOI 10.3233/978-1-61499-167-0-95
   VanOpijnen M, 2018, COMPUTERRECHT, V51, P0
   VanOpijnen M, 2013, P 14 INT C ARTIFICIA, V0, P140
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Verheugt J, 2020, INLEIDING NEDERLANDS, V0, P0
   Virtucio MBL, 2018, P INT COMP SOFTW APP, V0, PP130, DOI 10.1109/COMPSAC.2018.10348
   Vols M, 2021, LEGAL RES 100 QUESTI, V0, P0
   Vols M, 2021, METHODEN SYSTEMATISC, V0, P125
   Whalen R, 2020, COMPUTATIONAL LEGAL, V0, P0
   Whalen R, 2016, MICHIGAN STATE LAW R, V0, P539
   Winkels R, 2011, INT WORKSHOP APPROAC, V0, P106
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Zhong HX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3540
   Zweigert Konrad, 1998, INTRO COMP LAW, V0, P0
NR 45
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10506-023-09368-5
EA JUN 2023
PG 31
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law
SC Computer Science; Government & Law
GA K7HC8
UT WOS:001018103700001
DA 2023-11-10
ER

PT J
AU Kondo, R
   Yoshida, T
   Hisano, R
AF Kondo, Ryoma
   Yoshida, Takahiro
   Hisano, Ryohei
TI Masked prediction and interdependence network of the law using data from large-scale Japanese court judgments
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article
DE Legal code prediction; Court judgments; Text mining; Network mining
ID french system; legal
AB Court judgments contain valuable information on how statutory laws and past court precedents are interpreted and how the interdependence structure among them evolves in the courtroom. Data-mining the evolving structure of such customs and norms that reflect myriad social values from a large-scale court judgment corpus is an essential task from both the academic and industrial perspectives. In this paper, using data from approximately 110,000 court judgments from Japan spanning the period 1998-2018 from the district to the supreme court level, we propose two tasks that grasp such a structure from court judgments and highlight the strengths and weaknesses of major machine learning models. One is a prediction task based on masked language modeling that connects textual information to legal codes and past court precedents. Another is a dynamic link prediction task where we predict the hidden interdependence structure in the law. We make quantitative and qualitative comparisons among major machine learning models to obtain insights for future developments.
C1 [Kondo, Ryoma] Univ Tokyo, Grad Sch Engn, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1130033, Japan.
   [Kondo, Ryoma; Yoshida, Takahiro; Hisano, Ryohei] Canon Inst Global Studies, Chiyoda Ku, 5-1,Marunouchi 1 Chome, Tokyo 1006511, Japan.
   [Hisano, Ryohei] Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1130033, Japan.
C3 University of Tokyo; University of Tokyo
RP Hisano, R (通讯作者)，Canon Inst Global Studies, Chiyoda Ku, 5-1,Marunouchi 1 Chome, Tokyo 1006511, Japan.; Hisano, R (通讯作者)，Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1130033, Japan.
EM kondo@mlab.t.u-tokyo.ac.jp; t_yoshida_74@outlook.com; hisanor@g.ecc.u-tokyo.ac.jp
FU JST FOREST Program (Japan) [JPMJFR216Q]; UTEC-UTokyo FSI Research Grant Program
CR Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1
   Alex L, 2020, US PATENT, V0, Patent No. [10,776,891, 10776891]
   [Anonymous], 2017, JUDGMENT GRAND BENCH, V71, P0
   [Anonymous], 1975, KEISHU, V29, P489
   [Anonymous], 2007, JUDGMENT 2 PETTY BEN, V61, P0
   [Anonymous], 1900, V60, V0, P0
   [Anonymous], 1988, HUSTLER MAGAZINE INC, V0, P0
   Badawi AB, 2019, LAW DATA COMPUTATION, V2019, P339
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boulet R, 2018, ARTIF INTELL LAW, V26, P23, DOI 10.1007/s10506-017-9204-y
   Boulet R, 2011, ARTIF INTELL LAW, V19, P333, DOI 10.1007/s10506-011-9116-1
   Chalkidis I, 2020, ARXIV, V0, P0
   Chalkidis I, 2019, ARTIF INTELL LAW, V27, P171, DOI 10.1007/s10506-018-9238-9
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Coupette C, 2021, FRONT PHYS-LAUSANNE, V9, P0, DOI 10.3389/fphy.2021.658463
   Dadgosari F, 2021, ARTIF INTELL LAW, V29, P3, DOI 10.1007/s10506-020-09261-5
   Fowler JH, 2008, SOC NETWORKS, V30, P16, DOI 10.1016/j.socnet.2007.05.001
   Grover A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP855, DOI 10.1145/2939672.2939754
   Hayek FA, 1973, LAW LEGISLATION LIBE, V1, P0
   HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7
   Jacomy M, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0098679
   Jones CPA, 2020, JAPANESE LEGAL SYSTE, V0, P0
   Karrer B, 2011, PHYS REV E, V83, P0, DOI 10.1103/PhysRevE.83.016107
   Kipf T N, 2016, ICLR, V0, P0
   Koniaris M, 2018, J COMPLEX NETW, V6, P243, DOI 10.1093/comnet/cnx029
   LaCava L, 2021, ITALIAN CIVIL CODE N, V0, P0
   Liu YH, 2015, INFORM PROCESS MANAG, V51, P194, DOI 10.1016/j.ipm.2014.07.003
   Lyte A, 2015, NETWORK MEASURES US, V0, P0
   Mazzega P, 2009, P 12 INT C ART INT L, V0, PP236, DOI 10.1145/1568234.1568271
   Medvedeva M, 2020, ARTIF INTELL LAW, V28, P237, DOI 10.1007/s10506-019-09255-y
   Morimoto A, 2017, EPIC SERIES COMPUTIN, V2017, P79, DOI 10.29007/4L2Q
   Nanda R, 2017, COLIEE ICAIL, V0, PP68, DOI 10.29007/PSGX
   Nguyen H-T, 2021, ARXIV, V0, P0
   Page L, 1999, PAGERANK CITATION RA, V0, P0, DOI DOI 10.1109/IISWC.2012.6402911
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Raffel C, 2019, ARXIV, V0, P0
   Sadeghian A, 2018, ARTIF INTELL LAW, V26, P127, DOI 10.1007/s10506-018-9217-1
   Sakhaee N, 2021, ARTIF INTELL LAW, V29, P35, DOI 10.1007/s10506-020-09263-3
   Shulayeva O, 2017, ARTIF INTELL LAW, V25, P107, DOI 10.1007/s10506-017-9197-6
   Smith A, 1982, GLASGOW EDITION WORK, V0, P0
   Sulea O-M, 2017, ARXIV, V0, P0
   Tagarelli A, 2022, ARTIF INTELL LAW, V30, P417, DOI 10.1007/s10506-021-09301-8
   Tamanaha BZ, 2017, REALISTIC THEORY OF LAW, V0, PP1, DOI 10.1017/9781316979778
   Tamanaha BZ, 2004, RULE LAW HIST POLITI, V0, P0
   Nguyen TS, 2018, ARTIF INTELL LAW, V26, P169, DOI 10.1007/s10506-018-9225-1
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang PF, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP485, DOI 10.1145/3209978.3210057
   Yamakoshi T, 2019, IEEE INT CONF BIG DA, V0, PP4342, DOI 10.1109/BigData47090.2019.9006511
   Yang Y, 2019, ARXIV, V0, P0
   Yoshioka Masaharu, 2021, ICAIL 21: PROCEEDINGS OF THE EIGHTEENTH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, V0, PP278, DOI 10.1145/3462757.3466105
   Zhang DK, 2019, DATA MIN KNOWL DISC, V33, P1953, DOI 10.1007/s10618-019-00650-2
   Zhang P, 2007, SEMANTICS BASED LEGA, V0, P123
NR 53
TC 0
Z9 0
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD DEC 15
PY 2023
VL 31
IS 4
BP 739
EP 771
DI 10.1007/s10506-022-09336-5
EA OCT 2022
PG 33
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law
SC Computer Science; Government & Law
GA W1XC7
UT WOS:000870935000001
DA 2023-11-10
ER

PT J
AU Xu, X
   Chang, Y
   An, JY
   Du, YQ
AF Xu, Xue
   Chang, Yu
   An, Jianye
   Du, Yongqiang
TI Chinese text classification by combining Chinese-BERTology-wwm and GCN
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Chinese text classification; GCN; Chinese-BRRTology-wwm; Pointwise mutual information; Loss function; Transductive learning
AB Text classification is an important and classic application in natural language processing (NLP). Recent studies have shown that graph neural networks (GNNs) are effective in tasks with rich structural relationships and serve as effective transductive learning approaches. Text representation learning methods based on large-scale pretraining can learn implicit but rich semantic information from text. However, few studies have comprehensively utilized the contextual semantic and structural information for Chinese text classification. Moreover, the existing GNN methods for text classification did not consider the applicability of their graph construction methods to long or short texts. In this work, we propose Chinese-BERTology-wwm-GCN, a framework that combines Chinese bidirectional encoder representations from transformers (BERT) series models with whole word masking (Chinese-BERTology-wwm) and the graph convolutional network (GCN) for Chinese text classification. When building text graph, we use documents and words as nodes to construct a heterogeneous graph for the entire corpus. Specifically, we use the term frequency-inverse document frequency (TF-IDF) to construct the word-document edge weights. For long text corpora, we propose an improved pointwise mutual information (PMI & DBLBOND;) measure for words according to their word co-occurrence distances to represent the weights of word-word edges. For short text corpora, the co-occurrence information between words is often limited. Therefore, we utilize cosine similarity to represent the word-word edge weights. During the training stage, we effectively combine the cross-entropy and hinge losses and use them to jointly train Chinese-BERTology-wwm and GCN. Experiments show that our proposed framework significantly outperforms the baselines on three Chinese benchmark datasets and achieves good performance even with few labeled training sets.
C1 [Xu, Xue; Chang, Yu; An, Jianye; Du, Yongqiang] Tianjin Univ Commerce, Coll Sci, Tianjin, Peoples R China.
C3 Tianjin University of Commerce
RP Xu, X (通讯作者)，Tianjin Univ Commerce, Coll Sci, Tianjin, Peoples R China.
EM xuxue@tjcu.edu.cn
FU Tianjin Social Science Foundation of China (Youth Program) [TJTJQN19-001]
CR Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Chen L -C, 2022, COMPUTER ENG DESIGN, V43, P728, DOI 10.16208/j.issn1000-7024.2022.03.018
   Chung JY, 2014, ARXIV, V0, P0
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   da Costa LS, 2023, KNOWL INF SYST, V65, P2761, DOI 10.1007/s10115-023-01856-z
   De Cao N, 2018, ARXIV, V0, P0
   Defferrard M, 2016, ADV NEUR IN, V29, P0
   Devlin J, 2019, ARXIV, V0, P0
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Huang C, 2007, CHINESE J INFORM, V21, P8, DOI 10.3969/j.issn.1003-0077.2007.03.002
   Huang LZ, 2019, ARXIV, V0, P0
   Huang Y, 2023, APPL SCI-BASEL, V13, P0, DOI 10.3390/app13031296
   Joachims T, 1998, P 10 EUR C MACH LEAR, V0, PP137, DOI 10.1007/BFB0026683
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Lan ZZ, 2020, ARXIV, V0, P0
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P150
   Lin YX, 2022, ARXIV, V0, P0
   [刘建伟 Liu Jianwei], 2022, 控制与决策 CONTROL AND DECISION, V37, P2753
   Liu PF, 2016, ARXIV, V0, P0
   Liu XE, 2020, AAAI CONF ARTIF INTE, V34, P8409
   Liu YH, 2019, ARXIV, V0, P0
   McCallum A, 1998, AAAI 98 WORKSH LEARN, V0, PP41, DOI 10.1109/TSMC.1985.6313426
   Mousa AED, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1023
   Kipf TN, 2017, ARXIV, V0, P0
   Sun Y, 2019, ARXIV, V0, P0
   Ullah A, 2023, MULTIMED TOOLS APPL, V82, P8137, DOI 10.1007/s11042-022-14112-3
   Vapnik Vladimir N, 1998, STAT LEARNING THEORY, V0, P0
   Veličkovic P, 2018, ARXIV, V0, P0
   Wang AH, 2010, SECRYPT 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY, V0, P142
   [王超凡 Wang Chaofan], 2022, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V36, P65
   Wang YZ, 2023, EXPERT SYST APPL, V219, P0, DOI 10.1016/j.eswa.2023.119658
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu L, 2020, ARXIV, V0, P0
   Yang TC, 2021, ACM T INFORM SYST, V39, P0, DOI 10.1145/3450352
   Yang YP, 2021, ENTROPY-SWITZ, V23, P0, DOI 10.3390/e23111536
   Yao L, 2019, AAAI CONF ARTIF INTE, V0, P7370
   Zhai Z -L, 2023, MULTIMED TOOLS APPL, V82, P1, DOI 10.1007/s11042-023-14450-w
   Zhang W, 2008, IEEE SYS MAN CYBERN, V0, PP108, DOI 10.1109/ICSMC.2008.4811259
   Zhao W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3110
NR 39
TC 0
Z9 0
U1 12
U2 12
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD AUG 17
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1544
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA P7RE3
UT WOS:001052600400005
PM 37705631
DA 2023-11-10
ER

PT J
AU Frey, NC
   Soklaski, R
   Axelrod, S
   Samsi, S
   Gómez-Bombarelli, R
   Coley, CW
   Gadepally, V
AF Frey, Nathan C.
   Soklaski, Ryan
   Axelrod, Simon
   Samsi, Siddharth
   Gomez-Bombarelli, Rafael
   Coley, Connor W.
   Gadepally, Vijay
TI Neural scaling of deep chemical models
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article; Early Access
AB Massive scale, in terms of both data availability and computation, enables important breakthroughs in key application areas of deep learning such as natural language processing and computer vision. There is emerging evidence that scale may be a key ingredient in scientific deep learning, but the importance of physical priors in scientific domains makes the strategies and benefits of scaling uncertain. Here we investigate neural-scaling behaviour in large chemical models by varying model and dataset sizes over many orders of magnitude, studying models with over one billion parameters, pre-trained on datasets of up to ten million datapoints. We consider large language models for generative chemistry and graph neural networks for machine-learned interatomic potentials. We investigate the interplay between physical priors and scale and discover empirical neural-scaling relations for language models in chemistry with a scaling exponent of 0.17 for the largest dataset size considered, and a scaling exponent of 0.26 for equivariant graph neural network interatomic potentials.
C1 [Frey, Nathan C.; Soklaski, Ryan; Samsi, Siddharth; Gadepally, Vijay] MIT, Lincoln Lab, Lexington, MA 02421 USA.
   [Axelrod, Simon; Gomez-Bombarelli, Rafael] MIT, Dept Mat Sci & Engn, Cambridge, MA USA.
   [Axelrod, Simon] Harvard Univ, Dept Chem & Chem Biol, Cambridge, MA USA.
   [Coley, Connor W.] MIT, Dept Chem Engn, Cambridge, MA USA.
   [Coley, Connor W.] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA USA.
   [Frey, Nathan C.] Genentech Inc, Prescient Design, New York, NY 10001 USA.
   [Soklaski, Ryan] Anthropic, San Francisco, CA USA.
C3 Massachusetts Institute of Technology (MIT); Lincoln Laboratory; Massachusetts Institute of Technology (MIT); Harvard University; Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Roche Holding; Genentech
RP Frey, NC (通讯作者)，MIT, Lincoln Lab, Lexington, MA 02421 USA.; Frey, NC (通讯作者)，Genentech Inc, Prescient Design, New York, NY 10001 USA.
EM freyn6@gene.com
FU We acknowledge the MIT SuperCloud and the Lincoln Laboratory Supercomputing Center for providing HPC and consultation resources that contributed to the research results reported within this paper. We acknowledge the MIT SuperCloud team: W. Arcand, D. Besto [FA8702-15-D-0001]; Assistant Secretary of Defense for Research and Engineering under Air Force [FA8750-19-2-1000]; United States Air Force Research Laboratory
CR Ahmad W, 2022, ARXIV, V0, P0
   Axelrod S, 2023, MACH LEARN-SCI TECHN, V4, P0, DOI 10.1088/2632-2153/acefa7
   Axelrod S, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-30999-w
   Bahri Y, 2021, ARXIV, V0, P0
   Batatia I, 2022, ADV NEURAL INFORM PR, V35, P11423
   Batzner S, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-29939-5
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Black Sid, 2021, ZENODO, V0, P0
   Bommasani Rishi, 2021, ARXIV, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Caballero E, 2022, ARXIV, V0, P0
   Chanussot L, 2021, ACS CATAL, V11, P6059, DOI 10.1021/acscatal.0c04525
   Chithrananda S, 2020, ARXIV, V0, P0
   Chmiela S, 2017, SCI ADV, V3, P0, DOI 10.1126/sciadv.1603015
   Christensen AS, 2020, MACH LEARN-SCI TECHN, V1, P0, DOI 10.1088/2632-2153/abba6f
   Coley CW, 2021, TRENDS CHEM, V3, P133, DOI 10.1016/j.trechm.2020.11.004
   Devlin J, 2019, ARXIV, V0, P0
   Falcon W, 2019, PYTORCH LIGHTNING, V0, P0
   Flam-Shepherd D, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-30839-x
   Frey NC, 2021, NEURIPS 2021 AI SCI, V0, P0
   Gao L, 2020, ARXIV, V0, P0
   Gasteiger J, 2022, ARXIV, V0, P0
   Graff DE, 2023, ARXIV, V0, P0
   Gruver N, 2022, ARXIV, V0, P0
   Henighan T, 2020, ARXIV, V0, P0
   Hoffmann J, 2022, ARXIV, V0, P0
   Honda S, 2019, SMILES TRANSFORMER P, V0, P0
   Huang B, 2016, J CHEM PHYS, V145, P0, DOI 10.1063/1.4964627
   Huang K, 2021, P NEUR INF PROC SYST, V1, P0
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kalinin SV, 2022, PREPRINT, V0, P0
   Kaplan J, 2020, ARXIV, V0, P0
   Kim S, 2021, NUCLEIC ACIDS RES, V49, PD1388, DOI 10.1093/nar/gkaa971
   Kingma DP, 2014, C TRACK P, V0, P0
   Krenn M, 2022, PATTERNS, V3, P0, DOI 10.1016/j.patter.2022.100588
   Krenn M, 2020, MACH LEARN-SCI TECHN, V1, P0, DOI 10.1088/2632-2153/aba947
   Li LS, 2018, J MACH LEARN RES, V18, P0
   Li S, 2020, ARXIV, V0, P0
   Loshchilov Ilya, 2019, ARXIV, V0, P0
   Loukas A, 2020, ARXIV, V0, P0
   McCandlish S, 2018, ARXIV, V0, P0
   Mobley DL, 2014, J COMPUT AID MOL DES, V28, P711, DOI 10.1007/s10822-014-9747-x
   Musaelian A, 2023, ARXIV, V0, P0
   Musaelian A, 2023, NAT COMMUN, V14, P0, DOI 10.1038/s41467-023-36329-y
   Noutahi E, 2023, RBYRNE MOMATX DATAMO, V0, P0, DOI DOI 10.5281/zenodo.7955465
   Pappu A, 2020, ARXIV, V0, P0
   Paszke Adam, 2019, NEURIPS, V0, P0
   Polykovskiy D, 2020, FRONT PHARMACOL, V11, P0, DOI 10.3389/fphar.2020.565644
   Rackers JA, 2022, PREPRINT, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Ramesh A, 2021, PR MACH LEARN RES, V139, P0
   Ramsundar B, 2019, DEEP LEARNING LIFE S, V0, P0
   Ross J, 2022, NAT MACH INTELL, V4, P0, DOI 10.1038/s42256-022-00580-7
   Ru R, 2021, ADV NEURAL INFORM PR, V0, P4079
   Schütt KT, 2018, J CHEM PHYS, V148, P0, DOI 10.1063/1.5019779
   Schutt K, 2021, INT C MACH LEARN, V0, P9377
   Schutt KT, 2017, ADV NEURAL INFORM PR, V30, P992
   Schwalbe-Koda D, 2021, NAT COMMUN, V12, P0, DOI 10.1038/s41467-021-25342-8
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Sevilla J, 2022, IEEE IJCNN, V0, P0, DOI DOI 10.1109/IJCNN55064.2022.9891914
   Skinnider MA, 2021, NAT MACH INTELL, V3, P759, DOI 10.1038/s42256-021-00368-1
   Smith JS, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-0473-z
   Smith JS, 2018, J CHEM PHYS, V148, P0, DOI 10.1063/1.5023802
   Trewartha A, 2022, PATTERNS, V3, P0, DOI 10.1016/j.patter.2022.100488
   Unke OT, 2021, NAT COMMUN, V12, P0, DOI 10.1038/s41467-021-27504-0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wolf T, 2020, ARXIV, V0, P0
   Wood BM, 2022, ARXIV, V0, P0
   Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a
   Yang G, 2022, ARXIV, V0, P0
NR 70
TC 0
Z9 0
U1 0
U2 0
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1038/s42256-023-00740-3
EA OCT 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA U7VY4
UT WOS:001086857000001
DA 2023-11-10
ER

PT J
AU Ren, YT
   Xiao, YJ
   Zhou, YH
   Zhang, ZY
   Tian, ZH
AF Ren, Yitong
   Xiao, Yanjun
   Zhou, Yinghai
   Zhang, Zhiyong
   Tian, Zhihong
TI CSKG4APT: A Cybersecurity Knowledge Graph for Advanced Persistent Threat Organization Attribution
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Computer security; Organizations; Data mining; Network security; Standards organizations; Behavioral sciences; Natural language processing; Cyber threat intelligence; cybersecurity knowledge graph; APT organization attribution; diamond model
ID framework
AB Open-source cyber threat intelligence (OSCTI) is becoming more influential in obtaining current network security information. Most studies on cyber threat intelligence (CTI) focus on automating the extraction of threat entities from public sources that describe attack events. The cybersecurity knowledge graph aims to change the expression of threat knowledge so that security researchers can accurately and ef?ciently obtain various types of threat information for preliminary intelligent decisions. The attribution technology can not only assist security analysts in detecting advanced persistent threats, but can also identify the same threat from different attack events. Therefore, it is important to trace the attack threat actor. In this study, we used the knowledge graph technology, considered the latest research on cyber threat attack attribution, and thoroughly examined key related technologies and theories in the process of constructing and applying the advanced persistent threat (APT) knowledge graph from OSCTI. We designed a cybersecurity platform named CSKG4APT based on a knowledge graph. Inspired by the theory of ontology, we constructed CSKG4APT as an APT knowledge graph model based on real APT attack scenarios. We then designed an APT threat knowledge extraction algorithm for completing and updating the knowledge graph using deep learning and expert knowledge. Finally, we proposed a practical APT attack attribution method with attribution and countermeasures. CSKG4APT is not a passive defense method in traditional network confrontation but one that integrates a large amount of fragmented intelligence and can actively adjust its defense strategy. It lays the foundation for further dominance in network attack and defense.
C1 [Ren, Yitong; Zhou, Yinghai; Zhang, Zhiyong; Tian, Zhihong] Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Xiao, Yanjun] Nsfocus Technol Grp Co, PINGXING Lab, Beijing 510663, Guangdong, Peoples R China.
C3 Guangzhou University
RP Tian, ZH (通讯作者)，Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM renyitong@e.gzhu.edu.cn; xiaoyanjun@nsfocus.com; zyh369898622@163.com; zhangzhiyong1@e.gzhu.edu.cn; tianzhihong@gzhu.edu.cn
FU National Natural Science Foundation of China [U20B2046]; National Key Research and Development Program of China [2021YFB2012402]; Guangdong Province Universities and Colleges Pearl River Scholar Funded Scheme; Guangzhou University Graduate Student Innovation Ability Training Funding Program [2021GDJC-D17]
CR Alsaheel A, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, V0, P3005
   [Anonymous], 2019, CAPEC, V0, P0
   [Anonymous], 2020, CYBOX, V0, P0
   [Anonymous], 2019, TAXII, V0, P0
   [Anonymous], 2022, STIX, V0, P0
   [Anonymous], 2022, ABOUT US, V0, P0
   [Anonymous], 2021, APT ANN REV, V0, P0
   [Anonymous], 2020, ADV PERSISTENT THREA, V0, P0
   Belaoued M, 2016, J INF PROCESS SYST, V12, P644, DOI 10.3745/JIPS.03.0058
   Booth H, 2013, NATL VULNERABILITY D, V0, P0
   Caltagirone S, 2013, DIAMOND MODEL INTRUS, V0, P0
   CVE, 2021, US, V0, P0
   Deng YL, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED 19), V0, PP194, DOI 10.1145/3300115.3309531
   Devlin J, 2019, ARXIV, V0, P0
   Dionísio N, 2019, IEEE IJCNN, V0, P0
   Du M, 2019, LECT NOTES ARTIF INT, V11775, P47, DOI 10.1007/978-3-030-29551-6_5
   Gao YL, 2022, IEEE T KNOWL DATA EN, V34, P708, DOI 10.1109/TKDE.2020.2987019
   Gasmi H, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9193945
   Ghazi Y, 2018, INT CONF FRONT INFO, V0, PP129, DOI 10.1109/FIT.2018.00030
   Guo YY, 2021, LECT NOTES COMPUT SC, V12918, P447, DOI 10.1007/978-3-030-86890-1_25
   Haofen W, 2019, KNOWLEDGE GRAPH METH, V0, P0
   Hettema H, 2021, COMPUT SECUR, V109, P0, DOI 10.1016/j.cose.2021.102396
   Husari G, 2017, ANN COMPUT SECURITY, V0, PP103, DOI 10.1145/3134600.3134646
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Joshi A, 2013, IEEE INT C SEMANT CO, V0, PP252, DOI 10.1109/ICSC.2013.50
   Kiesling E, 2019, LECT NOTES COMPUT SC, V11779, P198, DOI 10.1007/978-3-030-30796-7_13
   Li CN, 1989, J ASIAN STUD, V42, P10
   Li Q, 2017, L N INST COMP SCI SO, V190, P92, DOI 10.1007/978-3-319-52727-7_11
   Li T, 2019, 2019 15TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2019), V0, PP147, DOI 10.1109/CIS.2019.00039
   Li Z, 2021, ARXIV, V0, P0
   Liao XJ, 2016, CCS16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, V0, PP755, DOI 10.1145/2976749.2978315
   MOSTIPlatform, 2020, OP STAND THREAT INF, V0, P0
   MAEC, 2020, US, V0, P0
   MANDIANT, 2017, CISC VIS NETW IND GL, V0, P0
   Mozzaquatro BA, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18093053
   Mulwad V, 2011, 2011 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES, V0, PP257, DOI 10.1109/WI-IAT.2011.26
   Noor U, 2019, FUTURE GENER COMP SY, V96, P227, DOI 10.1016/j.future.2019.02.013
   Saha S, 2018, P 12 INT WORKSH SEM, V0, P868
   Sahoo D, 2022, HDB BIG DATA ANALYTI, V0, PP53, DOI 10.1007/978-3-030-74753-4_4
   Satvat K, 2021, 2021 IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2021), V0, PP598, DOI 10.1109/EuroSP51992.2021.00046
   Satyapanich T, 2020, AAAI CONF ARTIF INTE, V34, P8749
   Shakarian P, 2015, ADV INFORM SECUR, V56, P151, DOI 10.1007/978-3-319-14039-1_8
   Singhal A, 2012, OFFICIAL BLOG, V0, P0
   Warikoo A, 2021, J CYBER SECUR TECHNO, V0, P1
   Weibo, 2022, US, V0, P0
   Yang J, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P31
   Yue L, 2020, COMPUT RES DEV, V57, P2052
   Zhao J, 2020, COMPUT SECUR, V95, P0, DOI 10.1016/j.cose.2020.101867
   Zhao YS, 2017, PROC INT CONF ANTI, V0, PP11, DOI 10.1109/ICASID.2017.8285734
   Zhihong T, 2020, INF COMMUN TECHNOL, V14, P4
   Zhou YH, 2022, SECUR COMMUN NETW, V2022, P0, DOI 10.1155/2022/9875199
   Zhu ZY, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), V0, PP458, DOI 10.1109/EuroSP.2018.00039
NR 54
TC 7
Z9 7
U1 24
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD JUN 1
PY 2023
VL 35
IS 6
BP 5695
EP 5709
DI 10.1109/TKDE.2022.3175719
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA F4GJ7
UT WOS:000981944600018
DA 2023-11-10
ER

PT J
AU Hossain, MR
   Hoque, MM
   Siddique, N
   Sarker, IH
AF Hossain, Md. Rajib
   Hoque, Mohammed Moshiul
   Siddique, Nazmul
   Sarker, Iqbal H. H.
TI CovTiNet: Covid text identification network using attention-based positional embedding feature fusion
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Natural language processing; Covid text identification; Positional encoding; Self-attention; Embedding feature fusion; Deep learning; Transformers; Low-resource languages
ID models
AB Covid text identification (CTI) is a crucial research concern in natural language processing (NLP). Social and electronic media are simultaneously adding a large volume of Covid-affiliated text on the World Wide Web due to the effortless access to the Internet, electronic gadgets and the Covid outbreak. Most of these texts are uninformative and contain misinformation, disinformation and malinformation that create an infodemic. Thus, Covid text identification is essential for controlling societal distrust and panic. Though very little Covid-related research (such as Covid disinformation, misinformation and fake news) has been reported in high-resource languages (e.g. English), CTI in low-resource languages (like Bengali) is in the preliminary stage to date. However, automatic CTI in Bengali text is challenging due to the deficit of benchmark corpora, complex linguistic constructs, immense verb inflexions and scarcity of NLP tools. On the other hand, the manual processing of Bengali Covid texts is arduous and costly due to their messy or unstructured forms. This research proposes a deep learning-based network (CovTiNet) to identify Covid text in Bengali. The CovTiNet incorporates an attention-based position embedding feature fusion for text-to-feature representation and attention-based CNN for Covid text identification. Experimental results show that the proposed CovTiNet achieved the highest accuracy of 96.61 +/-.001% on the developed dataset (BCovC) compared to the other methods and baselines (i.e. BERT-M, IndicBERT, ELECTRA-Bengali, DistilBERT-M, BiLSTM, DCNN, CNN, LSTM, VDCNN and ACNN).
C1 [Hossain, Md. Rajib; Hoque, Mohammed Moshiul; Sarker, Iqbal H. H.] Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong 4349, Bangladesh.
   [Siddique, Nazmul] Ulster Univ, Sch Comp Engn & Intelligent Syst, Derry, North Ireland.
   [Sarker, Iqbal H. H.] Edith Cowan Univ, Secur Res Inst, Joondalup, WA 6027, Australia.
C3 Chittagong University of Engineering & Technology (CUET); Ulster University; Edith Cowan University
RP Hoque, MM (通讯作者)，Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong 4349, Bangladesh.
EM rajcsecuet@gmail.com; moshiul_240@cuet.ac.bd; nh.siddique@ulster.ac.uk; m.sarker@ecu.edu.au
CR Abiodun EO, 2021, NEURAL COMPUT APPL, V33, P15091, DOI 10.1007/s00521-021-06406-8
   Afroze Sadia, 2023, INTELLIGENT COMPUTING & OPTIMIZATION: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND OPTIMIZATION 2022 (ICO2022). LECTURE NOTES IN NETWORKS AND SYSTEMS (569), V0, PP242, DOI 10.1007/978-3-031-19958-5_23
   Alissa M, 2022, NEURAL COMPUT APPL, V34, P1433, DOI 10.1007/s00521-021-06469-7
   Alsinglawi B, 2021, NEURAL COMPUT APPL, V0, P0, DOI DOI 10.1007/s00521-021-06579-2
   Asim MN, 2021, NEURAL COMPUT APPL, V33, P2157, DOI 10.1007/s00521-020-05435-z
   Bhowmick RS, 2022, NEURAL COMPUT APPL, V0, P0, DOI DOI 10.1007/s00521-022-06983-2
   Bhowmik NR, 2022, ARRAY, V13, P0, DOI 10.1016/j.array.2021.100123
   Bi JY, 2022, NEURAL COMPUT APPL, V34, P22241, DOI 10.1007/s00521-022-07643-1
   Sphaier PB, 2022, NEURAL COMPUT APPL, V34, P17381, DOI 10.1007/s00521-022-07383-2
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Cadoni M, 2021, NEURAL COMPUT APPL, V33, P11905, DOI 10.1007/s00521-021-05863-5
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   DAngelo G, 2023, NEURAL COMPUT APPL, V35, P13861, DOI 10.1007/s00521-021-05913-y
   Dasari SK, 2022, NEURAL COMPUT APPL, V0, P0, DOI DOI 10.1007/s00521-022-07347-6
   Dhar A, 2021, ARTIF INTELL REV, V54, P3007, DOI 10.1007/s10462-020-09919-1
   Elhadad MK, 2020, IEEE ACCESS, V8, P165201, DOI 10.1109/ACCESS.2020.3022867
   Ghasiya P, 2021, IEEE ACCESS, V9, P36645, DOI 10.1109/ACCESS.2021.3062875
   Hajek P, 2020, NEURAL COMPUT APPL, V32, P17259, DOI 10.1007/s00521-020-04757-2
   Harakawa R, 2021, IEEE T COMPUT SOC SY, V8, P1030, DOI 10.1109/TCSS.2021.3063820
   Hasni S, 2021, SOC NETW ANAL MIN, V11, P0, DOI 10.1007/s13278-021-00777-5
   He JF, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8362
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Hossain Md Rajib, 2023, INTELLIGENT COMPUTING & OPTIMIZATION: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND OPTIMIZATION 2022 (ICO2022). LECTURE NOTES IN NETWORKS AND SYSTEMS (569), V0, PP65, DOI 10.1007/978-3-031-19958-5_7
   Hossain Md Rajib, 2021, HYBRID INTELLIGENT SYSTEMS. 20TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS 2020). ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1375), V0, PP103, DOI 10.1007/978-3-030-73050-5_11
   Hossain MR, 2020, P 17 INT C NATURAL L, V0, P453
   Hossain MR, 2021, EXPERT SYST APPL, V184, P0, DOI 10.1016/j.eswa.2021.115394
   Hossain MR, 2021, IEEE ACCESS, V9, P100319, DOI 10.1109/ACCESS.2021.3095967
   Hossain Md Rajib, 2019, ADV INTELL SYST COMP, V882, P513, DOI 10.1007/978-981-13-5953-8_43
   Hossiny MH, 2018, PROCEEDINGS OF 2018 FIRST INTERNATIONAL WORKSHOP ON DEEP AND REPRESENTATION LEARNING (IWDRL), V0, PP1, DOI 10.1109/IWDRL.2018.8358207
   Huan JL, 2022, NEURAL COMPUT APPL, V34, P2341, DOI 10.1007/s00521-021-06542-1
   Huang J, 2021, NEURAL COMPUT APPL, V33, P9751, DOI 10.1007/s00521-021-05742-z
   Hussein A, 2021, P 4 WORKSHOP NLP INT, V0, PP93, DOI 10.18653/v1/2021.nlp4if-1.13
   Islam K, 2021, FIND ASS COMP LING E, V0, PP3265, DOI 10.18653/V1/2021.NDINGS-EMNLP.278
   Jadoon NK, 2019, NEURAL COMPUT APPL, V31, P2455, DOI 10.1007/s00521-017-3206-2
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, V0, P4948
   Koh JX, 2022, J PSYCHIATR RES, V145, P317, DOI 10.1016/j.jpsychires.2020.11.015
   Kolluri Nikhil L, 2021, ONLINE SOC NETW MEDIA, V22, P100123, DOI 10.1016/j.osnem.2021.100123
   Kropat E, 2016, RAIRO-OPER RES, V50, P413, DOI 10.1051/ro/2015044
   Kropat E, 2014, P ANN HICSS, V0, PP1153, DOI 10.1109/HICSS.2014.149
   Kula S, 2022, NEURAL COMPUT APPL, V34, P20449, DOI 10.1007/s00521-021-06276-0
   Levy Omer, 2014, P COMPUTATIONAL NATU, V0, P0, DOI DOI 10.3115/V1/W14-1618
   Li JQ, 2020, NEURAL COMPUT APPL, V32, P7759, DOI 10.1007/s00521-019-04071-6
   Lotfi R, 2022, ANN OPER RES, V0, P0, DOI DOI 10.1007/s10479-021-04490-6
   Mattern J, 2021, P 4 WORKSHOP FACT EX, V0, P78
   Miao L, 2022, EXPERT SYST APPL, V187, P0, DOI 10.1016/j.eswa.2021.115797
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nassif AB, 2022, NEURAL COMPUT APPL, V34, P16019, DOI 10.1007/s00521-022-07206-4
   Ng R, 2021, PLOS ONE, V16, P0, DOI 10.1371/journal.pone.0256358
   Özmen A, 2014, OPTIM METHOD SOFTW, V29, P515, DOI 10.1080/10556788.2013.821611
   Özmen A, 2011, COMMUN NONLINEAR SCI, V16, P4780, DOI 10.1016/j.cnsns.2011.04.001
   Paka WS, 2021, APPL SOFT COMPUT, V107, P0, DOI 10.1016/j.asoc.2021.107393
   Patwa P, 2021, COMBATING ONLINE HOS, V0, P42
   Paul S, 2023, MULTIMED TOOLS APPL, V82, P8773, DOI 10.1007/s11042-021-11601-9
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Potamias RA, 2020, NEURAL COMPUT APPL, V32, P17309, DOI 10.1007/s00521-020-05102-3
   Rahimi I, 2023, NEURAL COMPUT APPL, V35, P23671, DOI 10.1007/s00521-020-05626-8
   Rahman MM, 2020, 2020 2ND INTERNATIONAL CONFERENCE ON SUSTAINABLE TECHNOLOGIES FOR INDUSTRY 4.0 (STI), V0, P0, DOI DOI 10.1109/STI50764.2020.9350394
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Saghayan MH, 2021, IRAN CONF ELECTR ENG, V0, PP540, DOI 10.1109/ICEE52715.2021.9544409
   Singh SM, 2022, NEURAL COMPUT APPL, V34, P14823, DOI 10.1007/s00521-022-07337-8
   Song SL, 2019, NEURAL COMPUT APPL, V31, P4563, DOI 10.1007/s00521-018-3453-x
   Song XY, 2021, PLOS ONE, V16, P0, DOI 10.1371/journal.pone.0247086
   Wang B, 2019, APSIPA TRANS SIGNAL, V8, P0, DOI 10.1017/ATSIP.2019.12
   Weber GW, 2011, EUR J OPER RES, V211, P1, DOI 10.1016/j.ejor.2010.06.038
   Williams J, 2018, FIRST GRAND CHALLENGE AND WORKSHOP ON HUMAN MULTIMODAL LANGUAGE (CHALLENGE-HML), V0, P64
NR 66
TC 3
Z9 3
U1 2
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUN 15
PY 2023
VL 35
IS 18
BP 13503
EP 13527
DI 10.1007/s00521-023-08442-y
EA MAR 2023
PG 25
WC Computer Science, Artificial Intelligence
SC Computer Science
GA G5UN3
UT WOS:000951853900008
PM 37213320
DA 2023-11-10
ER

PT J
AU Ding, YX
   Liu, LQ
   Tian, CN
   Zhang, XN
   Tian, XL
AF Ding, Yuxuan
   Liu, Lingqiao
   Tian, Chunna
   Zhang, Xiangnan
   Tian, Xilan
TI Balanced image captioning with task-aware decoupled learning and fusion
SO NEUROCOMPUTING
LA English
DT Article
DE Vision -and -language; Image captioning; Imbalance learning; Multi -task learning
AB Image captioning aims to generate natural language descriptions for images. Word occurrences usually obey Zipf's Law, the imbalance phenomenon makes the conventional training bias to majority data. However, this imbalance distribution has not been considered adequately in captioning works. In this paper, we match the imbalance learning methods in classification with image captioning, making the empirical study. We also propose a Task-aware Decoupled Learning and Fusion (TDLF) approach, which outperforms the former. Image captioning differs from classification in three main aspects: 1) captions are sequential labels that exist co-occurrence, 2) the generation methods usually follow the autoregres-sive manner, 3) the imbalance ratio is extremely large. To deal with these problems, our TDLF method introduces multi-task learning into the re-balancing approach. The model is composed of a shared autoregressor and two task classifiers, i.e., a conventional training classifier, and a balance-training clas-sifier. The model is further equipped with a task-aware decoupling strategy, we propose the Task Perception Indication (TPI) to measure whether the conventional training is shifted. The balance -training classifier is trained by the biased data separately and the generations of two tasks are fused according to the TPI. Experiments on the MSCOCO database show that our model outperforms the state-of-the-art methods on generation accuracy and word diversity, demonstrating the effectiveness of the proposed method. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Ding, Yuxuan; Tian, Chunna; Zhang, Xiangnan] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Liu, Lingqiao] Univ Adelaide, Australian Inst Machine Learning, Adelaide 5005, Australia.
   [Tian, Xilan] China Elect Technol Grp Corp 38th Res Inst, Digital Tech Res & Dev Ctr, Hefei 230088, Peoples R China.
C3 Xidian University; University of Adelaide; China Electronics Technology Group
RP Tian, CN (通讯作者)，Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM chnatian@xidian.edu.cn
FU National Natural Science Founda-tion of China [62173265]
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2019, IEEE I CONF COMP VIS, V0, PP4260, DOI 10.1109/ICCV.2019.00436
   Awan SE, 2021, NEUROCOMPUTING, V453, P164, DOI 10.1016/j.neucom.2021.04.010
   Boyan Zhou, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9716, DOI 10.1109/CVPR42600.2020.00974
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Cai WJ, 2020, NEUROCOMPUTING, V413, P31, DOI 10.1016/j.neucom.2020.06.112
   Cao KD, 2019, ADV NEUR IN, V32, P0
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Cui Y, 2019, PROC CVPR IEEE, V0, PP9260, DOI 10.1109/CVPR.2019.00949
   Dai B, 2017, IEEE I CONF COMP VIS, V0, PP2989, DOI 10.1109/ICCV.2017.323
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   Deshpande A, 2019, PROC CVPR IEEE, V0, PP10687, DOI 10.1109/CVPR.2019.01095
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Drumnond C, 2003, ICML KDD 2003 WORKSH, V0, P0
   Goodfellow IJ, 2014, ARXIV, V0, P0
   Gowda Thamme, 2020, FINDINGS ASS COMPUTA, VEMNLP 2020, P3955, DOI 10.18653/v1/2020.findingsemnlp.352
   Gu SH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1035
   Hoyos-Osorio J, 2021, NEUROCOMPUTING, V436, P136, DOI 10.1016/j.neucom.2021.01.033
   Huang C, 2016, PROC CVPR IEEE, V0, PP5375, DOI 10.1109/CVPR.2016.580
   Japkowicz N, 2002, INTELLIGENT DATA ANALYSIS, V6, P429
   Jiang SJ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2879, DOI 10.1145/3308558.3313415
   Vijayakumar AK, 2018, ARXIV, V0, P0
   Kang B, 2020, ICLR, V0, PP1, DOI 10.48550/ARXIV.1910.09217
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Kingma DP, 2014, C TRACK P, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu B, 2020, ARXIV, V0, P0
   Liu ZW, 2019, PROC CVPR IEEE, V0, PP2532, DOI 10.1109/CVPR.2019.00264
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Longadge R, 2013, ARXIV, V0, P0
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   More A, 2016, ARXIV, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Rao TR, 2019, NEUROCOMPUTING, V333, P429, DOI 10.1016/j.neucom.2018.12.053
   Ren J, 2020, ADV NEURAL INFORM PR, V0, P0
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Tang Kaihua, 2020, NEURIPS, V0, P0
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang HZ, 2020, NEUROCOMPUTING, V401, P249, DOI 10.1016/j.neucom.2020.03.087
   Wu Q, 2016, PROC CVPR IEEE, V0, PP203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, JMLR WORKSHOP C P, V37, P0
   Yang Shuo, 2021, ARXIV210106395, V0, P0
   Yang X, 2019, PROC CVPR IEEE, V0, PP10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Zhang JJ, 2021, NEUROCOMPUTING, V449, P303, DOI 10.1016/j.neucom.2021.03.096
   Zhang XD, 2020, NEUROCOMPUTING, V395, P212, DOI 10.1016/j.neucom.2018.02.112
   Ziqi Zhang, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP13275, DOI 10.1109/CVPR42600.2020.01329
NR 57
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUN 14
PY 2023
VL 538
IS 
BP 
EP 
DI 10.1016/j.neucom.2023.03.020
EA APR 2023
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA F1XK2
UT WOS:000980344300001
DA 2023-11-10
ER

PT J
AU Fernández-Pichel, M
   Prada-Corral, M
   Losada, DE
   Pichel, JC
   Gamallo, P
AF Fernandez-Pichel, Marcos
   Prada-Corral, Manuel
   Losada, David E. E.
   Pichel, Juan C.
   Gamallo, Pablo
TI An unsupervised perplexity-based method for boilerplate removal
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Perplexity; Boilerplate removal; Information Retrieval; Text classification; Text Pre-processing
AB The availability of large web-based corpora has led to significant advances in a wide range of technologies, including massive retrieval systems or deep neural networks. However, leveraging this data is challenging, since web content is plagued by the so-called boilerplate: ads, incomplete or noisy text and rests of the navigation structure, such as menus or navigation bars. In this work, we present a novel and efficient approach to extract useful and well-formed content from web-scraped data. Our approach takes advantage of Language Models and their implicit knowledge about correctly formed text, and we demonstrate here that perplexity is a valuable artefact that can contribute in terms of effectiveness and efficiency. As a matter of fact, the removal of noisy parts leads to lighter AI or search solutions that are effective and entail important reductions in resources spent. We exemplify here the usefulness of our method with two downstream tasks, search and classification, and a cleaning task. We also provide a Python package with pre-trained models and a web demo demonstrating the capabilities of our approach.
C1 [Fernandez-Pichel, Marcos; Prada-Corral, Manuel; Losada, David E. E.; Pichel, Juan C.; Gamallo, Pablo] Univ Santiago Compostela, Ctr Singular Invest Tecnoloxas Intelixentes CiTIU, Santiago De Compostela 15782, Spain.
C3 Universidade de Santiago de Compostela
RP Fernández-Pichel, M (通讯作者)，Univ Santiago Compostela, Ctr Singular Invest Tecnoloxas Intelixentes CiTIU, Santiago De Compostela 15782, Spain.
EM marcosfernandez.pichel@usc.es
FU Ministerio de Ciencia e Innovacion [PLEC2021-007662, MCIN/AEI/10.13039/ 501100011033]; European Regional Development Fund [ED431G-2019/04, ED431C 2022/19]; Ministerio de Ciencia e Innovacion, Agencia Estatal de Investigacion, Plan de Recuperacion, Transformacion y Resiliencia, Union Europea-Next GenerationEU) [PLEC2021-007662, MCIN/AEI/10.13039/ 501100011033]; Conselleria de Educacion, Universidade e Formacion Profesional [ED431G-2019/04, ED431C 2022/19]; European Regional Development Fund
CR Abualsaud M, 2019, P 28 TEXT RETRIEVAL, V0, P0
   [Anonymous], 2010, WSDM 2010 P 3 ACM IN, V0, P0, DOI DOI 10.1145/1718487.1718542
   [Anonymous], 2003, KDD 03, V0, P0
   [Anonymous], 2012, P 13 C EUR CHAPT ASS, V0, P0
   Baroni M, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P638
   Bauer D, 2007, BUILDING EXPLORING W, V4, P111
   Bruce Croft W, 2010, SEARCH ENGINES INFOR, V520, P0
   Campos JRP, 2020, NAT LANG ENG, V26, P433, DOI 10.1017/S1351324919000378
   Collins-Thompson K, 2013, P 22 TEXT RETRIEVAL, V0, P0
   Consortium B, 2007, BRIT NATL CORPUS, V0, P0
   CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454
   Devlin J, 2019, ARXIV, V0, P0
   Duhart C, 2019, 36 INT C MACHINE LEA, V5, P0
   Finn A, 2001, DELOS, V0, P0
   Gamallo P, 2017, PHYSICA A, V484, P152, DOI 10.1016/j.physa.2017.05.011
   Gonzalez M, 2015, 2015 IEEE SENSORS. PROCEEDINGS, V0, PP1, DOI 10.1109/ICSENS.2015.7370266
   Henderson P, 2020, J MACH LEARN RES, V21, P0
   Kannan S, 2014, INT J COMPUTER SCI C, V5, P7
   Kohlschutter Christian, 2009, P 18 INT C WORLD WID, V0, PP1165, DOI 10.1145/1526709.1526909
   Lacoste A, 2019, ARXIV, V0, P0
   Lee NY, 2020, ARXIV, V0, P0
   Leonhardt J, 2020, WWW20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, V0, PP226, DOI 10.1145/3366424.3383547
   Liu YH, 2019, ARXIV, V0, P0
   Losada DE, 2008, INFORM RETRIEVAL, V11, P109, DOI 10.1007/s10791-007-9040-x
   Moro A, 2018, TRANSPORT RES D-TR E, V64, P5, DOI 10.1016/j.trd.2017.07.012
   Parapar Javier, 2021, SAC 21: PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, V0, PP655, DOI 10.1145/3412841.3441945
   Parapar J, 2020, J ASSOC INF SCI TECH, V71, P98, DOI 10.1002/asi.24203
   Pomikalek J, 2011, THESIS MASARYKOVA U, V0, P0
   Ponte JM, 2017, ACM SIGIR FORUM, V51, P202, DOI 10.1145/3130348.3130368
   Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831
   Solorio T, 2011, NAT LANG ENG, V17, P367, DOI 10.1017/S1351324910000252
   Spousta M, 2008, 4 WEB CORPUS WORKSHO, V0, P12
   Sun A, 2002, P 4 INT WORKSH WEB I, V0, PP96, DOI 10.1145/584931.584952
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vieira K, 2006, P 15 ACM INT C INF K, V0, P258
   Vogels T, 2018, LECT NOTES COMPUT SC, V10772, P167, DOI 10.1007/978-3-319-76941-7_13
   Wang LL, 2020, P 1 WORKSHOP NLP COV, V0, P0
   Wenzek G, 2019, ARXIV, V0, P0
   Wu C, 2020, NAT LANG ENG, V26, P531, DOI 10.1017/S1351324919000585
   Yang PL, 2018, ACM J DATA INF QUAL, V10, P0, DOI 10.1145/3239571
NR 40
TC 0
Z9 0
U1 2
U2 2
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324923000049
EA FEB 2023
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 9D4KY
UT WOS:000936069000001
DA 2023-11-10
ER

PT J
AU Chen, YP
   Zhong, XY
   Liu, YJ
   Dong, B
   Zheng, QH
AF Chen, Yanping
   Zhong, Xinyang
   Liu, Yijun
   Dong, Bo
   Zheng, Qinghua
TI A deep penetration network for sentence classification
SO INFORMATION FUSION
LA English
DT Article
DE Sentence classification; Text classification; Natural language processing; Feature extraction
ID neural-network; learning-model; cnn
AB Sentence classification is an important task in natural language processing. The task makes use of deep networks to enclose a mass of features with different granularities in a sentence. However, the classification usually suffer from severe performance degradation when stacking a large number of networks. The main reason is that, in a deep architecture, the silent feature representations are easily weakened and mixed with noisy information, which is not effective in learning contextual features and constructing semantic dependencies in a sentence. In this paper, a deep penetration network (DPN) is designed to improve deep architectures' ability to preserve the favourable semantic features. The DPN enables salient features to penetrate through a deeper architecture and to construct long semantic dependencies between them. This approach is evaluated on seven public datasets. Our experiments show that the DPN exhibits a stable performance with deeper architectures. It improves the performance on three types of sentence classification tasks, outperforming the existing state-of-the-art models.
C1 [Chen, Yanping; Zhong, Xinyang; Liu, Yijun] Guizhou Univ, Coll Comp Sci & Technol, Engn Res Ctr, Text Comp & Cognit Intelligence Lab, Guiyang 550025, Guizhou, Peoples R China.
   [Liu, Yijun; Dong, Bo] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Shanxi, Peoples R China.
C3 Guizhou University; Xi'an Jiaotong University
RP Chen, YP (通讯作者)，Guizhou Univ, Coll Comp Sci & Technol, Engn Res Ctr, Text Comp & Cognit Intelligence Lab, Guiyang 550025, Guizhou, Peoples R China.
EM ypench@gmail.com; 1017745548@qq.com; gs.liuyj20@gzu.edu.cn; dong.bo@xjtu.edu.cn; qhzheng@mail.xjtu.edu.cn
FU National Natural Science Founda-tion of China [62166007, 62050194, 62037001]
CR Alamoudi ES, 2021, J DECIS SYST, V30, P259, DOI 10.1080/12460125.2020.1864106
   Estrada MLB, 2020, EXPERT SYST APPL, V150, P0, DOI 10.1016/j.eswa.2020.113265
   Chen Y, 2015, CONVOLUTIONAL NEURAL, V0, P0
   Chen YP, 2021, NEURAL NETWORKS, V141, P249, DOI 10.1016/j.neunet.2021.04.010
   Chen YP, 2020, IEEE INTELL SYST, V35, P74, DOI 10.1109/MIS.2019.2952334
   Chen YP, 2020, IEEE ACCESS, V8, P13195, DOI 10.1109/ACCESS.2020.2966303
   Chia YK, 2019, ARXIV, V0, P0
   Choi E, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P209, DOI 10.18653/v1/P17-1020
   Choudhary A, 2021, EXPERT SYST APPL, V169, P0, DOI 10.1016/j.eswa.2020.114171
   Choudhary M, 2021, APPL SOFT COMPUT, V110, P0, DOI 10.1016/j.asoc.2021.107614
   De A, 2021, T ASIAN LOW RESOUR L, V21, P1
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doddington G, 2004, P LREC 04, V2, P837
   Fattoh IE, 2022, COMPUT INTEL NEUROSC, V2022, P0
   Gulli A, 2005, WWWW, V0, P880
   Han S, 2022, P 29 INT C COMPUTATI, V0, P94
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Jaiswal AK, 2021, FUTURE GENER COMP SY, V117, P1, DOI 10.1016/j.future.2020.11.012
   Jang B, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0220976
   Jiang D, 2021, COMPUT INTEL NEUROSC, V2021, P0
   Jin N, 2020, IEEE ACCESS, V8, P77060, DOI 10.1109/ACCESS.2020.2989428
   Jin WZ, 2019, J PHYS CONF SER, V1229, P0, DOI 10.1088/1742-6596/1229/1/012057
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Koloski Boshko, 2022, NEUROCOMPUTING, V0, P0
   Kucuktunc Onur, 2012, P 5 ACM INT C WEB SE, V0, PP633, DOI 10.1145/2124295.2124371
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Lee LH, 2021, P 6 SOCIAL MEDIA MIN, V0, PP98, DOI 10.18653/v1/2021.smm4h-1.18
   Li YM, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON COMPLEXITY, V0, P53, DOI 10.5220/0009582700530060
   Lin M, 2014, ARXIV, V0, P0
   Liu Z, 2020, IEEE ACCESS, V8, P0
   Liu ZY, 2020, ARXIV, V0, P0
   Madabushi HT, 2019, P 2 WORKSHOP NATURAL, V0, P125
   Mao R, 2022, IEEE T AFFECT COMPUT, V0, P0
   Mao R, 2022, INFORM FUSION, V86-87, P30, DOI 10.1016/j.inffus.2022.06.002
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Qin YB, 2021, SYMMETRY-BASEL, V13, P0, DOI 10.3390/sym13040539
   Salur MU, 2020, IEEE ACCESS, V8, P58080, DOI 10.1109/ACCESS.2020.2982538
   Sohrab MG, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2843
   Tan ZP, 2022, IEEE T NEUR NET LEAR, V33, P973, DOI 10.1109/TNNLS.2020.3036192
   Tao HQ, 2019, AAAI CONF ARTIF INTE, V0, P5125
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang RS, 2019, IEEE IJCNN, V0, P0
   Xu H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Xu JJ, 2019, ARXIV, V0, P0
   Xu JL, 2021, SYMMETRY-BASEL, V13, P0, DOI 10.3390/sym13081458
   Xu MB, 2016, ARXIV, V0, P0
   Yin WP, 2017, ARXIV, V0, P0
   Yu FS, 2016, ARXIV, V0, P0
   Zaidi SSA, 2022, DIGIT SIGNAL PROCESS, V126, P0, DOI 10.1016/j.dsp.2022.103514
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zhang NY, 2022, EXPERT SYST APPL, V187, P0, DOI 10.1016/j.eswa.2021.115806
   Zhao He, 2021, ARXIV210300498, V0, P0
   Zhao M, 2022, INFORM SCIENCES, V600, P73, DOI 10.1016/j.ins.2022.03.082
   Zhao WD, 2022, CONNECT SCI, V34, P2291, DOI 10.1080/09540091.2022.2117274
NR 54
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD JUL 15
PY 2023
VL 95
IS 
BP 174
EP 185
DI 10.1016/j.inffus.2023.02.015
EA FEB 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA G8QZ0
UT WOS:000991750300001
DA 2023-11-10
ER

PT J
AU Bhattacharya, P
   Gupta, RK
   Yang, YP
AF Bhattacharya, Prasanta
   Gupta, Raj Kumar
   Yang, Yinping
TI Exploring the Contextual Factors Affecting Multimodal Emotion Recognition in Videos
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Emotion recognition; Videos; Visualization; Feature extraction; Physiology; High performance computing; Distance measurement; Affective computing; affect sensing and analysis; modelling human emotions; multi-modal recognition; sentiment analysis; technology & devices for affective computing
ID sex-differences; facial expressions; languages; selection; model
AB Emotional expressions form a key part of user behavior on today's digital platforms. While multimodal emotion recognition techniques are gaining research attention, there is a lack of deeper understanding on how visual and non-visual features can be used to better recognize emotions in certain contexts, but not others. This study analyzes the interplay between the effects of multimodal emotion features derived from facial expressions, tone and text in conjunction with two key contextual factors: i) gender of the speaker, and ii) duration of the emotional episode. Using a large public dataset of 2,176 manually annotated YouTube videos, we found that while multimodal features consistently outperformed bimodal and unimodal features, their performance varied significantly across different emotions, gender and duration contexts. Multimodal features performed particularly better for male speakers in recognizing most emotions. Furthermore, multimodal features performed particularly better for shorter than for longer videos in recognizing neutral and happiness, but not sadness and anger. These findings offer new insights towards the development of more context-aware emotion recognition and empathetic systems.
C1 [Bhattacharya, Prasanta; Gupta, Raj Kumar; Yang, Yinping] Agcy Sci Technol & Res STAR, Inst High Performance Comp, Singapore 138632, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC)
RP Bhattacharya, P; Yang, YP (通讯作者)，Agcy Sci Technol & Res STAR, Inst High Performance Comp, Singapore 138632, Singapore.
EM prasanta_bhattacharya@ihpc.a-star.edu.sg; gupta-rk@ihpc.a-star.edu.sg; yangyp@ihpc.a-star.edu.sg
FU Agency for Science, Technology and Research (A*STAR) [a1718g0046, accl18022 2]
CR Al-Shawaf L, 2018, EMOT REV, V10, P149, DOI 10.1177/1754073917709940
   Alghowinem S, 2016, INTERSPEECH, V0, PP1943, DOI 10.21437/Interspeech.2016-1339
   AlZoubi O, 2012, IEEE T AFFECT COMPUT, V3, P298, DOI 10.1109/T-AFFC.2012.4
   [Anonymous], 2012, PROC 20 ACM INT C MU, V0, P0, DOI DOI 10.1145/2393347.2396490
   [Anonymous], 2006, P AAAI C ARTIFICIAL, V0, P0
   [Anonymous], 2013, 10 IEEE INT C WORKSH, V0, P0
   Aviezer H, 2008, PSYCHOL SCI, V19, P724, DOI 10.1111/j.1467-9280.2008.02148.x
   BABCHUK WA, 1985, ETHOL SOCIOBIOL, V6, P89, DOI 10.1016/0162-3095(85)90002-0
   Bajorek JP, 2019, HARVARD BUS REV, V0, P0
   Barros P, 2018, 2018 INT JOINT C NEU, V0, PP1, DOI 10.1109/IJCNN.2018.8489099
   Barros P, 2015, NEURAL NETWORKS, V72, P140, DOI 10.1016/j.neunet.2015.09.009
   Brans K, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0092410
   Brebner J, 2003, PERS INDIV DIFFER, V34, P387, DOI 10.1016/S0191-8869(02)00059-4
   Brody LR, 2008, HDB EMOTIONS, V3rd, P395, DOI 10.1007/978-1-4419-1465-1_21
   Busso C, 2004, P 6 INT C MULT INT, V0, PP205, DOI 10.1145/1027933.1027968
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cannon WB, 1927, AM J PSYCHOL, V39, P106, DOI 10.2307/1415404
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen Nancy F, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4121, DOI 10.1109/ICASSP.2014.6854377
   Clore GL, 2001, HANDBOOK OF AFFECT AND SOCIAL COGNITION, V0, P121
   Costa-jussà MR, 2019, NAT MACH INTELL, V1, P495, DOI 10.1038/s42256-019-0105-5
   DMello SK, 2015, ACM COMPUT SURV, V47, P0, DOI 10.1145/2682899
   DMello SK, 2013, IEEE T AFFECT COMPUT, V4, P452, DOI 10.1109/T-AFFC.2013.19
   DMello SK, 2010, USER MODEL USER-ADAP, V20, P147, DOI 10.1007/s11257-010-9074-4
   Darwin C, 1872, P374, V0, P0
   de Gelder B, 2006, PROG BRAIN RES, V155, P37, DOI 10.1016/S0079-6123(06)55003-4
   Dennis J, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP518, DOI 10.1109/ASRU.2015.7404839
   Ding W, 2016, ICMI16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP506, DOI 10.1145/2993148.2997637
   Duan R, 2021, P INT C AC SPEECH SI, V0, P0
   Duan RC, 2020, INTERSPEECH, V0, PP3037, DOI 10.21437/Interspeech.2020-1657
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Frijda, 1986, EMOTIONS, V0, P0
   Frijda NH, 1993, HDB EMOTIONS, V0, P381
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Glowinski D, 2011, IEEE T AFFECT COMPUT, V2, P106, DOI 10.1109/T-AFFC.2011.7
   Gupta RK, 2019, P AAAI WORKSH AFF CO, V0, P0
   Gupta RK, 2018, P 12 INT WORKSH SEM, V0, P256
   Gupta RK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP139, DOI 10.1145/3343031.3351048
   Hampson E, 2006, EVOL HUM BEHAV, V27, P401, DOI 10.1016/j.evolhumbehav.2006.05.002
   Ng HW, 2015, ICMI15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP443, DOI 10.1145/2818346.2830593
   Huang DY, 2017, INTERSPEECH, V0, PP162, DOI 10.21437/Interspeech.2017-1088
   Huang DY, 2018, PROCEEDINGS OF THE JOINT WORKSHOP OF THE 4TH WORKSHOP ON AFFECTIVE SOCIAL MULTIMEDIA COMPUTING AND FIRST MULTI-MODAL AFFECTIVE COMPUTING OF LARGE-SCALE MULTIMEDIA DATA (ASMMC-MMAC18), V0, PP7, DOI 10.1145/3267935.3267950
   Hussain MS, 2012, P 10 AUSTR DAT MIN C, V134, P103
   James W, 1890, PRINCIPLES PSYCHOL, V0, P0
   James William, 1884, MIND, V9, P188, DOI 10.1093/MIND/OS-IX.34.188
   Jenkins JM, 2000, HUMAN EMOTIONS READE, V0, P0
   Kagan J, 2007, WHAT IS EMOTION HIST, V0, P0
   Keltner D, 1999, COGNITION EMOTION, V13, P505, DOI 10.1080/026999399379168
   Kessous L, 2010, J MULTIMODAL USER IN, V3, P33, DOI 10.1007/s12193-009-0025-5
   Kim JC, 2015, IEEE T AFFECT COMPUT, V6, P371, DOI 10.1109/TAFFC.2015.2411273
   Krell G, 2012, PROC IAPR WORKSHOP M, V0, P116
   Lee CM, 2004, PROC INT C SPOKEN LA, V0, P889
   Lin JC, 2012, IEEE T MULTIMEDIA, V14, P142, DOI 10.1109/TMM.2011.2171334
   Lingenfelser F, 2018, IEEE T AFFECT COMPUT, V9, P410, DOI 10.1109/TAFFC.2016.2635124
   Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110
   Lu K, 2012, INT C PATT RECOG, V0, P1148
   McClure EB, 2000, PSYCHOL BULL, V126, P424, DOI 10.1037/0033-2909.126.3.424
   McDuff D, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0173942
   Metallinou A, 2012, IEEE T AFFECT COMPUT, V3, P184, DOI 10.1109/T-AFFC.2011.40
   Nguyen M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2916
   Nguyen M, 2020, IEEE-ACM T AUDIO SPE, V28, P461, DOI 10.1109/TASLP.2019.2955246
   Mohammad S, 2017, P 6 JOINT C LEXICAL, V0, P65
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Ni CJ, 2015, INT CONF ACOUST SPEE, V0, PP4714, DOI 10.1109/ICASSP.2015.7178865
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Ortony Andrew, 1988, COGNITIVE STRUCTURE, V0, P0
   Ouyang X, 2017, ICMI 2017 P 19 ACM I, V0, PP577, DOI 10.1145/3136755.3143012
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Peng SY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP1226, DOI 10.1145/3240508.3241384
   Poon-Feng K, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), V0, PP584, DOI 10.1109/ISCSLP.2014.6936696
   Quek WY, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), V0, PP170, DOI 10.1109/TENCON.2016.7847983
   Rashid M, 2013, VISUAL COMPUT, V29, P1269, DOI 10.1007/s00371-012-0768-y
   Robbins SP, 2017, ORG BEHAV, V0, P0
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schuller B, 2011, LECT NOTES COMPUT SC, V6975, P415, DOI 10.1007/978-3-642-24571-8_53
   Schuller B, 2011, IEEE T AFFECT COMPUT, V2, P192, DOI 10.1109/T-AFFC.2011.17
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   SONNEMANS J, 1994, COGNITION EMOTION, V8, P329, DOI 10.1080/02699939408408945
   Tong R, 2017, INTERSPEECH, V0, PP2193, DOI 10.21437/Interspeech.2017-520
   TURNER TJ, 1992, PSYCHOL REV, V99, P566
   Uljarevic M, 2013, J AUTISM DEV DISORD, V43, P1517, DOI 10.1007/s10803-012-1695-5
   Do VH, 2018, IEEE-ACM T AUDIO SPE, V26, P501, DOI 10.1109/TASLP.2017.2782360
   Verduyn P, 2015, MOTIV EMOTION, V39, P119, DOI 10.1007/s11031-014-9445-y
   Vonikakis V, 2017, IEEE T MULTIMEDIA, V19, P2609, DOI 10.1109/TMM.2017.2699859
   Vonikakis V, 2016, ICMI16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP479, DOI 10.1145/2993148.2997633
   Wang SF, 2014, MULTIMED TOOLS APPL, V72, P1257, DOI 10.1007/s11042-013-1450-8
   Wöllmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001
   Wu CH, 2011, IEEE T AFFECT COMPUT, V2, P10, DOI 10.1109/T-AFFC.2010.16
   Zemach EM, 2001, AM PHILOS QUART, V38, P197
NR 91
TC 4
Z9 4
U1 22
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
EI 
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD APR-JUN 15
PY 2023
VL 14
IS 2
BP 1547
EP 1557
DI 10.1109/TAFFC.2021.3071503
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA I1FK2
UT WOS:001000299100051
DA 2023-11-10
ER

PT J
AU Li, LX
   Li, J
   Xu, YH
   Zhu, H
   Zhang, XF
AF Li, Lixuan
   Li, Jie
   Xu, Yihui
   Zhu, Hao
   Zhang, Xiaofang
TI Enhancing Code Summarization with Graph Embedding and Pre-trained Model
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article; Early Access
DE Code summarization; pre-trained model; code structure; deep learning
AB Code summarization is a task that aims at automatically producing descriptions of source code. Recently many deep-learning-based approaches have been proposed to generate accurate code summaries, among which pre-trained models (PTMs) for programming languages have achieved promising results. It is well known that source code written in programming languages is highly structured and unambiguous. Though previous work pre-trained the model with well-design tasks to learn universal representation from a large scale of data, they have not considered structure information during the fine-tuning stage. To make full use of both the pre-trained programming language model and the structure information of source code, we utilize Flow-Augmented Abstract Syntax Tree (FA-AST) of source code for structure information and propose GraphPLBART - Graph-augmented Programming Language and Bi-directional Auto-Regressive Transformer, which can effectively introduce structure information to a well PTM through a cross attention layer. Compared with the best-performing baselines, GraphPLBART still improves by 3.2%, 7.1%, and 1.2% in terms of BLEU, METEOR, and ROUGE-L, respectively, on Java dataset, and also improves by 4.0%, 6.3%, and 2.1% on Python dataset. Further experiment shows that the structure information from FA-AST has significant benefits for the performance of GraphPLBART. In addition, our meticulous manual evaluation experiment further reinforces the superiority of our proposed approach. This demonstrates its remarkable abstract quality and solidifies its position as a promising solution in the field of code summarization.
C1 [Li, Lixuan; Li, Jie; Xu, Yihui; Zhu, Hao; Zhang, Xiaofang] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
C3 Soochow University - China
RP Zhang, XF (通讯作者)，Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
EM li_lixuan@outlook.com; 2027407061@stu.suda.edu.cn; 20234227080@stu.suda.edu.cn; 2027406032@stu.suda.edu.cn; xfzhang@suda.edu.cn
FU National Natural Science Foundation of China [62172202]; Collaborative Innovation Center of Novel Software Technology and Industrialization; Major Program of the Natural Science Foundation of Jiangsu Higher Education Institutions of China [22KJA520008]; Priority Academic Program Development of Jiangsu Higher Education Institutions; Undergraduate Training Program for Innovation and Entrepreneurship, Soochow University [202210285197H]
CR Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2655
   Ahmad Wasi Uddin, 2020, P 58 ANN M ASS COMP, V0, P4998
   Alon U, 2019, P ACM PROGRAM LANG, V3, P0, DOI 10.1145/3290353
   An B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P236
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, V0, PP65, DOI 10.3115/1626355.1626389
   Choi Y, 2021, FINDINGS ASS COMPUTA, V0, P2842
   Chunrong Fang, 2020, ISSTA 20: PROCEEDINGS OF THE 29TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, V0, PP516, DOI 10.1145/3395363.3397362
   Clark K, 2020, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dey R, 2017, MIDWEST SYMP CIRCUIT, V0, PP1597, DOI 10.1109/MWSCAS.2017.8053243
   Feng Zhangyin, 2020, FIND ASS COMP LING E, V0, PP1536, DOI 10.18653/V1/2020.FINDINGS-EMNLP.139
   Gao SZ, 2023, ACM T SOFTW ENG METH, V32, P0, DOI 10.1145/3522674
   Gao YX, 2022, INT C PROGRAM COMPRE, V0, PP24, DOI 10.1145/3524610.3527907
   Guo DY, 2021, ARXIV, V0, P0
   Guo QP, 2020, AAAI CONF ARTIF INTE, V34, P7847
   Hu X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2269
   Hu X, 2018, INT C PROGRAM COMPRE, V0, PP200, DOI 10.1145/3196321.3196334
   Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073
   Kudo T, 2018, ARXIV, V0, P0
   Li YJ, 2017, ARXIV, V0, P0
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   See A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1704.04368
   Sun ZY, 2020, AAAI CONF ARTIF INTE, V34, P8984
   Taud H, 2018, GEOMATIC APPROACHES, V0, P451
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wan Y, 2018, IEEE INT CONF AUTOM, V0, PP397, DOI 10.1145/3238147.3238206
   Wang WH, 2020, PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Wang Y, 2022, INT C PROGRAM COMPRE, V0, PP12, DOI 10.1145/3524610.3527903
   Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P8696
   Wei BL, 2019, ADV NEUR IN, V32, P0
   Wu H, 2021, FINDINGS ASS COMPUTA, V0, PP1078, DOI 10.18653/v1/2021.findings-acl.93
NR 33
TC 0
Z9 0
U1 0
U2 0
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1142/S0218194023410024
EA OCT 2023
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA U4NU5
UT WOS:001084591200002
DA 2023-11-10
ER

PT J
AU Lin, X
   Huang, ZY
   Zhao, HK
   Chen, EH
   Liu, Q
   Lian, DF
   Li, X
   Wang, H
AF Lin, Xin
   Huang, Zhenya
   Zhao, Hongke
   Chen, Enhong
   Liu, Qi
   Lian, Defu
   Li, Xin
   Wang, Hao
TI Learning Relation-Enhanced Hierarchical Solver for Math Word Problems
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Human-like comprehension; math word problem (MWP); natural language processing (NLP); relation learning; structure-based association
AB Automatically solving math word problems (MWPs) is a challenging task for artificial intelligence (AI) and machine learning (ML) research, which aims to answer the problem with a mathematical expression. Many existing solutions simply model the MWP as a sequence of words, which is far from precise solving. To this end, we turn to how humans solve MWPs. Humans read the problem part-by-part and capture dependencies between words for a thorough understanding and infer the expression precisely in a goal-driven manner with knowledge. Moreover, humans can associate different MWPs to help solve the target with related experience. In this article, we present a focused study on an MWP solver by imitating such procedure. Specifically, we first propose a novel hierarchical math solver (HMS) to exploit semantics in one MWP. First, to imitate human reading habits, we propose a novel encoder to learn the semantics guided by dependencies between words following a hierarchical "word-clause-problem" paradigm. Next, we develop a goal-driven tree-based decoder with knowledge application to generate the expression. One step further, to imitate human associating different MWPs for related experience in problemsolving, we extend HMS to the Relation-enHanced Math Solver (RHMS) to utilize the relation between MWPs. First, to capture the structural similarity relation, we develop a meta-structure tool to measure the similarity based on the logical structure of MWPs and construct a graph to associate related MWPs. Then, based on the graph, we learn an improved solver to exploit related experience for higher accuracy and robustness. Finally, we conduct extensive experiments on two large datasets, which demonstrates the effectiveness of the two proposed methods and the superiority of RHMS.
C1 [Lin, Xin; Huang, Zhenya; Chen, Enhong; Liu, Qi; Lian, Defu; Wang, Hao] Univ Sci & Technol China, Sch Comp Sci & Technol, Anhui Prov Key Lab Big Data Anal & Applicat, Hefei, Peoples R China.
   [Lin, Xin; Huang, Zhenya; Chen, Enhong; Liu, Qi; Lian, Defu; Wang, Hao] State Key Lab Cognit Intelligence, Hefei 230088, Peoples R China.
   [Zhao, Hongke; Liu, Qi] Tianjin Univ, Coll Management & Econ, Tianjin 300072, Peoples R China.
   [Li, Xin] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Peoples R China.
   [Li, Xin] iFLYTEK Co Ltd, Artificial Intelligence Res Inst, Hefei 230088, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of China, CAS; Tianjin University; Chinese Academy of Sciences; University of Science & Technology of China, CAS
RP Huang, ZY; Chen, EH (通讯作者)，Univ Sci & Technol China, Sch Comp Sci & Technol, Anhui Prov Key Lab Big Data Anal & Applicat, Hefei, Peoples R China.
EM linx@mail.ustc.edu.cn; huangzhy@ustc.edu.cn; hongke@tju.edu.cn; cheneh@ustc.edu.cn; qiliuql@ustc.edu.cn; liandefu@ustc.edu.cn; eexin@ustc.edu.cn; wanghao3@ustc.edu.cn
FU National Key Research and Development Program of China [2021YFF0901005]; National Natural Science Foundation of China [62106244, U20A20229, 72101176]; University Synergy Innovation Program of Anhui Province [GXXT-2022-042]
CR [Anonymous], 1963, COMPUT THOUGHT, V0, P0
   Bobrow DG, 1964, THESIS MIT, V0, P0
   Cao YX, 2021, AAAI CONF ARTIF INTE, V35, P39
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong YX, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP135, DOI 10.1145/3097983.3098036
   Gilmer J, 2017, PR MACH LEARN RES, V70, P0
   Hong YN, 2021, AAAI CONF ARTIF INTE, V35, P4959
   Hosseini MJ, 2014, 2014EMNLP, V0, P523
   Huang D, 2017, P 2017 C EMPIRICAL M, V0, PP805, DOI 10.18653/v1/d17-1084
   Huang D, 2018, P 27 INT C COMP LING, V0, PP213, DOI 10.1016/B978-0-12-809641-3.00011-9
   Huang ZY, 2021, KDD 21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP696, DOI 10.1145/3447548.3467347
   Huang ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP1729, DOI 10.1145/3397271.3401227
   Huang ZY, 2017, AAAI CONF ARTIF INTE, V0, P1352
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Kaiming He, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV). PROCEEDINGS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Kingma DP, 2014, C TRACK P, V0, P0
   Koncel-Kedziorski R, 2016, P 2016 C N AM CHAPTE, V0, PP1152, DOI 10.18653/VLIN16-1136
   Koncel-Kedziorski Rik, 2015, T ASSOC COMPUT LING, V3, P585, DOI 10.1162/TACL_A_00160
   Li JR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6162
   Li RX, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP2601, DOI 10.1145/3477495.3531903
   Li S, 2020, P C EMP METH NAT LAN, V0, PP2841, DOI 10.18653/V1/2020.FINDINGS-EMNLP.255
   Liang ZW, 2022, ARXIV, V0, P0
   Lin X, 2021, AAAI CONF ARTIF INTE, V35, P4232
   Liu J, 2023, ARXIV, V0, P0
   Liu JY, 2022, IEEE DATA MINING, V0, PP269, DOI 10.1109/ICDM54844.2022.00037
   Liu Q, 2021, IEEE T KNOWL DATA EN, V33, P100, DOI 10.1109/TKDE.2019.2924374
   Liu QY, 2022, IEEE-ACM T AUDIO SPE, V30, P1, DOI 10.1109/TASLP.2021.3126932
   Luo HS, 2019, IEEE-ACM T AUDIO SPE, V27, P1201, DOI 10.1109/TASLP.2019.2913094
   Ma Yuhui, 2010, 2010 2ND INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE (ETCS), V0, PP476, DOI 10.1109/ETCS.2010.316
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Kipf TN, 2017, ARXIV, V0, P0
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Roy S, 2016, PROC C EMPIRICAL MET, V0, P1088
   Roy S, 2017, AAAI CONF ARTIF INTE, V0, P3082
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Shen J, 2021, FINDINGS EMNLP, V0, P2269
   Shen Yibin, 2020, P 28 INT C COMP LING, V0, PP2924, DOI 10.18653/v1/2020.coling-main.262
   Shi M, 2020, IEEE T NEUR NET LEAR, V31, P3682, DOI 10.1109/TNNLS.2019.2945869
   Shi S, 2015, P 2015 C EMP METH NA, V0, PP1132, DOI 10.18653/v1/d15-1135
   Tesniere L, 1959, ELEMENTS SYNTAXE STR, V0, P0
   Veličkovic P, 2018, ARXIV, V0, P0
   Wang H, 2023, IEEE T KNOWL DATA EN, V35, P2430, DOI 10.1109/TKDE.2021.3114444
   Wang L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1064
   Wang L, 2019, AAAI CONF ARTIF INTE, V0, P7144
   Wang Y, 2017, P 2017 C EMPIRICAL M, V0, P0
   Wu Q, 2021, P FIND ASS COMP LING, V0, PP1473, DOI 10.18653/V1/2021.FINDINGS-EMNLP.127
   Wu Q, 2021, P 59 ANN M ASS COMP, V0, P5859
   Wu QZ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7137
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie ZP, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5299
   Yang BS, 2020, KNOWL-BASED SYST, V188, P0, DOI 10.1016/j.knosys.2019.105042
   Yang X, 2019, IEEE T NEUR NET LEAR, V30, P2987, DOI 10.1109/TNNLS.2018.2861991
   Yin Y, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1328, DOI 10.1145/3292500.3330900
   Zhang DX, 2020, IEEE T PATTERN ANAL, V42, P2287, DOI 10.1109/TPAMI.2019.2914054
   Zhang JP, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4011
   Zhang JP, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3928
   Zhang Y, 2022, IEEE-ACM T AUDIO SPE, V30, P816, DOI 10.1109/TASLP.2022.3145314
   Zhao HK, 2020, IEEE T KNOWL DATA EN, V32, P1652, DOI 10.1109/TKDE.2019.2906199
   Zhao XJ, 2023, IEEE T NEUR NET LEAR, V34, P4386, DOI 10.1109/TNNLS.2021.3113026
   Zhao Z, 2019, BIOMED CIRC SYST C, V0, P0, DOI DOI 10.1109/biocas.2019.8918995
NR 63
TC 0
Z9 0
U1 16
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2023.3272114
EA MAY 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA I9LH3
UT WOS:001005917300001
PM 37235466
DA 2023-11-10
ER

PT J
AU Davani, AM
   Atari, M
   Kennedy, B
   Dehghani, M
AF Davani, Aida Mostafazadeh
   Atari, Mohammad
   Kennedy, Brendan
   Dehghani, Morteza
TI Hate Speech Classifiers Learn Normative Social Stereotypes
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID model; bias; competence; warmth; racism
AB Social stereotypes negatively impact individuals' judgments about different groups and may have a critical role in understanding language directed toward marginalized groups. Here, we assess the role of social stereotypes in the automated detection of hate speech in the English language by examining the impact of social stereotypes on annotation behaviors, annotated datasets, and hate speech classifiers. Specifically, we first investigate the impact of novice annotators' stereotypes on their hate-speech-annotation behavior. Then, we examine the effect of normative stereotypes in language on the aggregated annotators' judgments in a large annotated corpus. Finally, we demonstrate how normative stereotypes embedded in language resources are associated with systematic prediction errors in a hate-speech classifier. The results demonstrate that hate-speech classifiers reflect social stereotypes against marginalized groups, which can perpetuate social inequalities when propagated at scale. This framework, combining social-psychological and computational-linguistic methods, provides insights into sources of bias in hate-speech moderation, informing ongoing debates regarding machine learning fairness.
C1 [Davani, Aida Mostafazadeh; Atari, Mohammad; Kennedy, Brendan; Dehghani, Morteza] Univ Southern Calif, Los Angeles, CA 90007 USA.
C3 University of Southern California
RP Davani, AM (通讯作者)，Univ Southern Calif, Los Angeles, CA 90007 USA.
EM mostafaz@usc.edu; atari@usc.edu; btkenned@usc.edu; mdehghan@usc.edu
CR Ahmed Z, 2022, EPJ DATA SCI, V11, P0, DOI 10.1140/epjds/s13688-022-00319-9
   Akhtar Sohail, 2021, ARXIV PREPRINT ARXIV, V0, P0
   [Anonymous], 1960, PROBABILISTIC MODELS, V0, P0
   Arhin Kofi, 2021, ARXIV, V0, P0
   Aroyo L, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), V0, PP1100, DOI 10.1145/3308560.3317083
   Badjatiya P, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP49, DOI 10.1145/3308558.3313504
   Ben Hutchinson, 2020, ACL, V0, PP5491, DOI 10.18653/V1/2020.ACL-MAIN.487
   Bender Emily M, 2021, FACCT 21: PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, V0, P0
   Blodgett Su Lin, 2020, P 58 ANN M ASS COMPU, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.485
   Blodgett Su Lin, 2017, ARXIV170700061, V0, P0
   Bolukbasi T, 2016, NEURAL INFORM PROCES, V0, PP4349, DOI 10.5555/3157382
   Borkan D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), V0, PP491, DOI 10.1145/3308560.3317593
   Caliskan A, 2017, SCIENCE, V356, P0, DOI 10.1126/science.aal4230
   Carter ER, 2015, SOC PERSONAL PSYCHOL, V9, P269, DOI 10.1111/spc3.12181
   Chang Ming-Wei, 2019, NAACL HLT, V0, P0
   Charlesworth TES, 2021, PSYCHOL SCI, V32, P218, DOI 10.1177/0956797620963619
   Chuang YS, 2021, WOAH 2021: THE 5TH WORKSHOP ON ONLINE ABUSE AND HARMS, V0, P114
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cowan G, 2002, J SOC ISSUES, V58, P247, DOI 10.1111/1540-4560.00259
   Crawford Kate, 2017, C NEURAL INFORM PROC, V0, P0
   Cuddy AJC, 2008, ADV EXP SOC PSYCHOL, V40, P61, DOI 10.1016/S0065-2601(07)00002-0
   Cuddy AJC, 2007, J PERS SOC PSYCHOL, V92, P631, DOI 10.1037/0022-3514.92.4.631
   Czarnowska P, 2021, T ASSOC COMPUT LING, V9, P1249, DOI 10.1162/tacl_a_00425
   Davani AM, 2022, T ASSOC COMPUT LING, V10, P92, DOI 10.1162/tacl_a_00449
   Davani AM, 2021, WOAH 2021: THE 5TH WORKSHOP ON ONLINE ABUSE AND HARMS, V0, P92
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Davidson T, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, V0, P25
   Diaz Mark, 2022, FACCT 22: 2022 ACM CONFERENCE ON FAIRNESS, V0, P0
   Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, V0, P0
   Feldman M, 2015, KDD15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP259, DOI 10.1145/2783258.2783311
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Garg N, 2018, P NATL ACAD SCI USA, V115, PE3635, DOI 10.1073/pnas.1720347115
   Garg S, 2019, AIES 19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, V0, P0
   Gavin Gaffney, 2018, PUSHSHIFT GAB CORPUS, V0, P0
   Geva M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1161
   Gong L, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP937, DOI 10.1145/3038912.3052693
   Gultchin L, 2019, PMLR, V97, P2474
   Hardt Moritz, 2016, NEURIPS, V0, P0
   Hofmann W, 2005, PERS SOC PSYCHOL B, V31, P1369, DOI 10.1177/0146167205275613
   Hovy D, 2013, P 2013 C N AM CHAPT, V0, PP1120, DOI 10.1145/1148170.1148215
   Hovy D, 2021, LANG LINGUIST COMPAS, V15, P0, DOI 10.1111/lnc3.12432
   Huesmann LR, 2012, J RES ADOLESCENCE, V22, P556, DOI 10.1111/j.1532-7795.2012.00785.x
   Ji Ho Park, 2018, P 2018 C EMP METH NA, V0, P0
   Jiang JA, 2021, PLOS ONE, V16, P0, DOI 10.1371/journal.pone.0256762
   Kennedy B, 2018, PSYARXIV, V0, P0
   Kennedy B, 2022, LANG RESOUR EVAL, V56, P79, DOI 10.1007/s10579-021-09569-x
   Kennedy Brendan, 2020, P 58 ANN M ASS COMP, V0, PP5435, DOI 10.18653/V1/2020.ACL-MAIN.483
   Kiritchenko Svetlana, 2021, JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH, V71, P431
   Koch A, 2016, J PERS SOC PSYCHOL, V110, P675, DOI 10.1037/pspa0000046
   Kocon J, 2021, IEEE DATA MINING, V0, PP1168, DOI 10.1109/ICDM51629.2021.00140
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, V0, PP1621, DOI 10.5555/2891460.2891697
   Lalor John P, 2016, PROC CONF EMPIR METHODS NAT LANG PROCESS, V2016, P648
   Manzinit T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P615
   McCradden MD, 2020, J AM MED INFORM ASSN, V27, P2024, DOI 10.1093/jamia/ocaa085
   Mehrabi N, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3457607
   Mozafari M, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0237861
   Norton MI, 2011, PERSPECT PSYCHOL SCI, V6, P215, DOI 10.1177/1745691611406922
   Nozza D, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), V0, PP149, DOI 10.1145/3350546.3352512
   Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342
   Patton Desmond, 2019, P 52 HAWAII INT C SY, V0, P0, DOI DOI 10.24251/HICSS.2019.260
   Pavlick E, 2019, T ASSOC COMPUT LING, V7, P677, DOI 10.1162/tacl_a_00293
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pietraszkiewicz A, 2019, EUR J SOC PSYCHOL, V49, P871, DOI 10.1002/ejsp.2561
   Posch Lisa, 2018, 11 INT AAAI C WEB SO, V0, P0
   Prabhakaran V, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5740
   Prabhakaran Vinodkumar, 2021, P JOINT 15 LINGUISTI, V0, PP133, DOI 10.18653/v1/2021.law-1.14
   Rajadesingan A, 2015, WSDM15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP97, DOI 10.1145/2684822.2685316
   Ross Bjorn, 2016, P NLP4CMC 3 3 WORKSH, V17, P0, DOI 10.17185/duepublico/42132
   Rottger Paul, 2022, P 2022 C N AM CHAPTE, V0, PP175, DOI 10.18653/v1/2022.naacl-main.13
   Sap M, 2022, P 2022 C N AM CHAPT, V0, P5884
   Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1668
   Stemler SE, 2021, PRACTICAL ASSESS RES, V26, P1, DOI 10.7275/v2gd-4441
   Swinger N, 2019, AIES 19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, V0, P0
   Uma AN, 2021, J ARTIF INTELL RES, V72, P1385
   Vaidya Ameya, 2020, P INT AAAI C WEB SOC, V14, P683
   Vidgen B, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1667
   Wagner C, 2021, NATURE, V595, P197, DOI 10.1038/s41586-021-03666-1
   Waseem Z, 2016, WORKSH NLP COMP SOC, V0, P138
   Wich Maximilian, 2020, P 4 WORKSHOP ONLINE, V0, P191
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xia Mengzhou, 2020, P 8 INT WORKSH NAT L, V0, PP7, DOI 10.18653/V1/2020.SOCIALNLP-1.2
   Zeerak Talat, 2021, DISEMBODIED MACHINE, V0, P0
   Zhuang L, 2021, P 20 CHINESE NATL C, V0, P1218
   Zou LX, 2017, J PERS SOC PSYCHOL, V112, P696, DOI 10.1037/pspa0000080
NR 86
TC 0
Z9 0
U1 9
U2 12
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 22
PY 2023
VL 11
IS 
BP 300
EP 319
DI 10.1162/tacl_a_00550
PG 20
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA A3SB5
UT WOS:000954352100003
DA 2023-11-10
ER

PT J
AU Xu, JJ
AF Xu, Jingjing
TI A natural language processing based technique for sentiment analysis of college english corpus
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Natural language; English corpus; Cluster analysis; TF-IDF
ID networks
AB The college English corpus can help us better master English, but how to obtain the desired information from a large number of English corpus has become the focus of information technology. Based on the natural language processing (NLP) technology, a sentiment analysis model is built in this article. An improved term frequency-inverse document frequency (TF-IDF) algorithm is proposed in this article, where the weighted average method is used to determine the emotional value of each emotional word. The inspirational words are used to obtain the English corpus's emotional tendency and emotional value. The results show that the model has high classification accuracy and operation efficiency when selecting feature words. Compared with the TF-IDF, the improved TF-IDF algorithm added the necessary information weight processing and word density weight processing to two new processing links, which can significantly improve the efficiency of college English learning.
C1 [Xu, Jingjing] Anhui Univ Chinese Med, Sch Humanities & Int Educ & Exchange, Hefei, Peoples R China.
C3 Anhui University of Chinese Medicine
RP Xu, JJ (通讯作者)，Anhui Univ Chinese Med, Sch Humanities & Int Educ & Exchange, Hefei, Peoples R China.
EM jingjingxu@ahtcm.edu.cn
CR Abe H, 2010, IEEE INT C DATA MINI, V0, P1743
   Fang Q, 2018, TEXT DETECTION RECOG, V0, P0
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gui Z, 2018, RES TEXT DETECTION R, V0, P0
   Hasan Sadid A, 2019, DATA SCI HEALTHCARE, V0, PP147, DOI 10.1007/978-3-030-05249-2_5
   Hu ZT, 2020, ARXIV, V0, P0
   Li B, 2018, COMPUTER SCI, V35, P132
   Liu Y, 2014, J COMMUNICATIONS, V7, P78
   Luo BF, 2018, ARXIV, V0, P0
   Mikolov T, 2017, ARXIV, V0, P0
   Peng GF, 2019, CONF TECHNOL APPL, V0, P0, DOI DOI 10.1109/taai48200.2019.8959907
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sun X, 2019, RES MULTIDIRECTION T, V0, P0
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   [奚雪峰 Xi Xuefeng], 2016, 自动化学报 ACTA AUTOMATICA SINICA, V42, P1445
   Xu K, 2020, ELECT DESIGN ENG, V28, P82
   Yang H, 2019, TEXT RECOGNITION NAT, V0, P0
   Yin Bao-cai, 2015, JOURNAL OF BEIJING UNIVERSITY OF TECHNOLOGY, V41, P48, DOI 10.11936/bjutxb2014100026
   Zhou P, 2019, RES TEXT DETECTION R, V0, P0
NR 19
TC 0
Z9 0
U1 9
U2 9
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD FEB 17
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1235
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA H2NR9
UT WOS:000994390500002
PM 37346685
DA 2023-11-10
ER

PT J
AU Lu, XL
   Chow, TWS
AF Lu, Xiaolei
   Chow, Tommy W. S.
TI Modeling Sequential Annotations for Sequence Labeling With Crowds
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article
DE Annotations; Labeling; Hidden Markov models; Task analysis; Reliability; Probabilistic logic; Data models; Crowdsourcing; labeling consistency; nonlocal label dependency; sequential annotations
AB Crowd sequential annotations can be an efficient and cost-effective way to build large datasets for sequence labeling. Different from tagging independent instances, for crowd sequential annotations, the quality of label sequence relies on the expertise level of annotators in capturing internal dependencies for each token in the sequence. In this article, we propose modeling sequential annotation for sequence labeling with crowds (SA-SLC). First, a conditional probabilistic model is developed to jointly model sequential data and annotators' expertise, in which categorical distribution is introduced to estimate the reliability of each annotator in capturing local and nonlocal label dependencies for sequential annotation. To accelerate the marginalization of the proposed model, a valid label sequence inference (VLSE) method is proposed to derive the valid ground-truth label sequences from crowd sequential annotations. VLSE derives possible ground-truth labels from the tokenwise level and further prunes subpaths in the forward inference for label sequence decoding. VLSE reduces the number of candidate label sequences and improves the quality of possible ground-truth label sequences. The experimental results on several sequence labeling tasks of Natural Language Processing show the effectiveness of the proposed model.
C1 [Lu, Xiaolei; Chow, Tommy W. S.] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Chow, TWS (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM xiaoleilu2-c@my.cityu.edu.hk; eetchow@cityu.edu.hk
FU Hong Kong Research Grants Council (RGC) General Research Fund (GRF) [9042996]
CR Brefeld U, 2006, P 23 INT C MACH LEAR, V0, PP145, DOI 10.1145/1143844.1143863
   Cheng J, 2020, IEEE T CYBERNETICS, V50, P1900, DOI 10.1109/TCYB.2019.2909748
   Chu X, 2016, ADV NEURAL INFORM PR, V0, P316
   DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1
   Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006
   Dong SL, 2019, IEEE T CYBERNETICS, V49, P2294, DOI 10.1109/TCYB.2018.2824799
   Finkel Jenny Rose, 2005, P 43 ANN M ASS COMP, V0, PP363, DOI 10.3115/1219840.1219885
   Hovy D, 2013, P 2013 C N AM CHAPT, V0, PP1120, DOI 10.1145/1148170.1148215
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jiao F, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   JUANG BH, 1991, TECHNOMETRICS, V33, P251, DOI 10.2307/1268779
   Kim J-D, 2004, P INT JOINT WORKSH N, V0, PP70, DOI 10.3115/1567594.1567610
   Krishnan V, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lan O, 2019, LEARNING CONTEXTUALL, V0, P0
   Leaman Robert, 2008, PAC SYMP BIOCOMPUT, V0, P652
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Nefian AV, 2002, INT CONF ACOUST SPEE, V0, P2013
   Nguyen AT, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P299, DOI 10.18653/v1/P17-1028
   Raykar VC, 2012, J MACH LEARN RES, V13, P491
   Raykar VC, 2010, J MACH LEARN RES, V11, P1297
   Rodrigues F, 2014, MACH LEARN, V95, P165, DOI 10.1007/s10994-013-5411-2
   Sang EFTK, 2003, INTRO CONLL2003 SHAR, V0, P0
   Sarawagi S, 2005, ADV NEURAL INFORM PR, V0, P1185
   Sha F, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P213
   Simpson E, 2018, BAYESIAN APPROACH SE, V0, P0
   Snow R, 2008, P 2008 C EMP METH NA, V0, P254
   Wu X, 2012, P 26 AAAI C ART INT, V0, P1713
   Yan Y, 2010, J MAC LEARN RES P TR, V0, P932
   Yin YJ, 2015, IEEE T CYBERNETICS, V45, P1988, DOI 10.1109/TCYB.2014.2363078
   Zhang J, 2016, ARTIF INTELL REV, V46, P543, DOI 10.1007/s10462-016-9491-9
   Zhong ZL, 2020, IEEE T CYBERNETICS, V50, P3318, DOI 10.1109/TCYB.2019.2915094
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P1360, DOI 10.1109/TPAMI.2014.2369044
NR 33
TC 0
Z9 0
U1 1
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD APR 15
PY 2023
VL 53
IS 4
BP 2335
EP 2345
DI 10.1109/TCYB.2021.3117700
EA OCT 2021
PG 11
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Automation & Control Systems; Computer Science
GA U1PD7
UT WOS:000733531300001
PM 34665752
DA 2023-11-10
ER

PT J
AU Huertas-Tato, J
   Martín, A
   Camacho, D
AF Huertas-Tato, Javier
   Martin, Alejandro
   Camacho, David
TI BERTuit: Understanding Spanish language in Twitter with transformers
SO EXPERT SYSTEMS
LA English
DT Article
DE misinformation; online social networks; transformers; Twitter
AB The appearance of complex attention-based language models such as BERT, RoBERTa or GPT-3 has allowed to address highly complex tasks in a plethora of scenarios. However, when applied to specific domains, these models encounter considerable difficulties. This is the case of Social Networks such as Twitter, an ever-changing stream of information written with informal and complex language, where each message requires careful evaluation to be understood even by humans given the important role that context plays. Addressing tasks in this domain through Natural Language Processing involves severe challenges. When powerful state-of-the-art multilingual language models are applied to this scenario, language specific nuances get lost in translation. To face these challenges we present BERTuit, the largest transformer proposed so far for Spanish language, pre-trained on a massive dataset of 230 M Spanish tweets using RoBERTa optimization. Our motivation is to provide a powerful resource to better understand Spanish Twitter and to be used on applications focused on this social network, with special emphasis on solutions devoted to tackle the spreading of misinformation in this platform. BERTuit is evaluated on several tasks and compared against M-BERT, XLM-RoBERTa and XLM-T, very competitive multilingual transformers. The utility of our approach is shown with applications, in this case: an unsupervised methodology to visualize groups of hoaxes; and supervised profiling of authors spreading disinformation.
C1 [Huertas-Tato, Javier; Martin, Alejandro; Camacho, David] Univ Politecn Madrid, Dept Informat, Madrid 28031, Spain.
C3 Universidad Politecnica de Madrid
RP Huertas-Tato, J (通讯作者)，Univ Politecn Madrid, Dept Informat, Madrid 28031, Spain.
EM javier.huertas.tato@upm.es
FU Spanish Ministry of Science and Innovation [PID2020-117263GB-100]; Comunidad Autonoma de Madrid [S2018/TCS-4566]; European Commission [2020-EU-IA-0252]; Digital Future Society; MCIN/AEI; European Union NextGeneration/PRTR
CR Ahuja R, 2022, ARAB J SCI ENG, V47, P9379, DOI 10.1007/s13369-021-06193-3
   González JA, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102262
   Babieno M, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12042081
   Barbieri F, 2021, XLM T MULTILINGUAL L, V0, P0
   Baviera Puig T, 2019, TWITTER DATASET 2015, V0, P0
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Canete J, 2020, SPANISH PRE TRAINED, V0, P0
   Chanda AK, 2021, EFFICACY BERT EMBEDD, V0, P0
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2475
   Conneau Alexis, 2019, ARXIV191102116, V0, P0
   de Arruda HFR, 2022, INFORM SCIENCES, V588, P265, DOI 10.1016/j.ins.2021.12.069
   Deb S, 2022, MACHINE LEARNING APP, V7, P0
   Delobelle P, 2020, ROBBERT DUTCH ROBERT, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dukic D, 2020, 2020 IEEE 7 INT C DA, V0, P0
   Farzindar A, 2015, SYNTH LECT HUM LANG, V8, P1, DOI 10.2200/S00659ED1V01Y201508HLT030
   González JA, 2021, NEUROCOMPUTING, V426, P58, DOI 10.1016/j.neucom.2020.09.078
   Gregory H, 2020, P 2 WORKSH FIG LANG, V0, P0
   Huertas-Garc├a┬a A, 2021, PROFILING HATE SPEEC, V0, P0
   Jwa H, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9194062
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Larson HJ, 2018, NATURE, V562, P309, DOI 10.1038/d41586-018-07034-4
   Lewis M, 2019, BART DENOISING SEQUE, V0, P0
   Lewis P, 2019, MLQA EVALUATING CROS, V0, P0
   Liu PJ, 2018, ARXIV180110198, V0, P1
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   McInnes Leland, 2020, ARXIV, V0, P0
   Mozafari M, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0237861
   Mozetic I, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0194317
   Mozetic I, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0155036
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Nguyen DQ, 2020, BERTWEET PRE TRAINED, V0, P0
   PIRES T, 2019, P 57 ANN M ASS COMP, V0, P0
   Polignano M, 2019, 6 IT C COMP LING CLC, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2019, EXPLORING LIMITS TRA, V0, P0
   Rangel F, 2020, PROFILING FAKE NEWS, V0, P0
   Rei L, 2016, XLIME TWITTER CORPUS, V0, P0
   Ruiz IVM, 2017, CORPUS TUITS IRONICO, V0, P0
   Sang EFTK, 2002, COLING 02 6 C NAT LA, V0, P0, DOI DOI 10.3115/1118853.1118877
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Scott J, 2022, ARCH TEAM TWITTER ST, V0, P0
   Singh M, 2021, SOC NETW ANAL MIN, V11, P0, DOI 10.1007/s13278-021-00737-z
   Son H, 2018, 2018 IEEE INT C DAT, V0, P0
   Straka M, 2021, INT C TEXT SPEECH DI, V0, P0
   Tahir B, 2020, IEEE ICC, V0, P0, DOI DOI 10.1109/icc40277.2020.9149154
   Tay Y, 2020, EFFICIENT TRANSFORME, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Virtanen A, 2019, MULTILINGUAL IS NOT, V0, P0
NR 51
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD NOV 15
PY 2023
VL 40
IS 9
BP 
EP 
DI 10.1111/exsy.13404
EA JUL 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA U1FX9
UT WOS:001033742500001
DA 2023-11-10
ER

PT J
AU Iferroudjene, M
   Lonjarret, C
   Robardet, C
   Plantevit, M
   Atzmueller, M
AF Iferroudjene, Mouloud
   Lonjarret, Corentin
   Robardet, Celine
   Plantevit, Marc
   Atzmueller, Martin
TI Methods for explaining Top-<i>N</i> recommendations through subgroup discovery
SO DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Article
ID mining sequential patterns; algorithm; explanation; prefixspan
AB Explainable Artificial Intelligence (XAI) has received a lot of attention over the past decade, with the proposal of many methods explaining black box classifiers such as neural networks. Despite the ubiquity of recommender systems in the digital world, only few researchers have attempted to explain their functioning, whereas one major obstacle to their use is the problem of societal acceptability and trustworthiness. Indeed, recommender systems direct user choices to a large extent and their impact is important as they give access to only a small part of the range of items (e.g., products and/or services), as the submerged part of the iceberg. Consequently, they limit access to other resources. The potentially negative effects of these systems have been pointed out as phenomena like echo chambers and winner-take-all effects, because the internal logic of these systems is to likely enclose the consumer in a "deja vu" loop. Therefore, it is crucial to provide explanations of such recommender systems and to identify the user data that led the respective system to make the individual recommendations. This then makes it possible to evaluate recommender systems not only regarding their effectiveness (i.e., their capability to recommend an item that was actually chosen by the user), but also with respect to the diversity, relevance and timeliness of the active data used for the recommendation. In this paper, we propose a deep analysis of two state-of-the-art models learnt on four datasets based on the identification of the items or the sequences of items actively used by the models. Our proposed methods are based on subgroup discovery with different pattern languages (i.e., itemsets and sequences). Specifically, we provide interpretable explanations of the recommendations of the Top-N items, which are useful to compare different models. Ultimately, these can then be used to present simple and understandable patterns to explain the reasons behind a generated recommendation to the user.
C1 [Iferroudjene, Mouloud] Ecole Natl Super Informat ESI, Algiers, Algeria.
   [Lonjarret, Corentin; Robardet, Celine] Univ Lyon, INSA Lyon, CNRS, LIRIS UMR 5205, F-69621 Villeurbanne, France.
   [Plantevit, Marc] Lab Rech lEPITA LRE, F-94276 Le Kremlin Bicetre, France.
   [Atzmueller, Martin] Osnabruck Univ, Semant Informat Syst Grp, Osnabruck, Germany.
   [Atzmueller, Martin] German Res Ctr Artificial Intelligence DFKI, Osnabruck, Germany.
C3 Ecole Nationale Superieure d'Informatique; Centre National de la Recherche Scientifique (CNRS); Institut National des Sciences Appliquees de Lyon - INSA Lyon; University Osnabruck; German Research Center for Artificial Intelligence (DFKI)
RP Robardet, C (通讯作者)，Univ Lyon, INSA Lyon, CNRS, LIRIS UMR 5205, F-69621 Villeurbanne, France.
EM gm_iferroudjene@esi.dz; celine.robardet@insa-lyon.fr; martin.atzmueller@uni-osnabrueck.de
FU ACADEMICS grant of the IDEXLYON project of the University of Lyon [ANR-16-IDEX-0005]; CAF AMERICA [OPE2020-0041]
CR [Anonymous], 2007, PSYCHOL COUNTERFACTU, V0, P0
   [Anonymous], 2007, AI MAG, V0, P0
   [Anonymous], 1986, EXPLANATION PATTERNS, V0, P0
   Atzmueller M, 2006, LECT NOTES ARTIF INT, V4213, P6
   Atzmueller M, 2009, LECT NOTES COMPUT SC, V5722, P35, DOI 10.1007/978-3-642-04125-9_7
   Atzmueller M, 2015, WIRES DATA MIN KNOWL, V5, P35, DOI 10.1002/widm.1144
   Bloemheuvel S, 2019, P DUTCH BELG DAT DAY, V0, P0
   Duivesteijn W, 2014, IEEE DATA MINING, V0, PP809, DOI 10.1109/ICDM.2014.10
   Fournier-Viger P, 2017, DATA SCI PATTERN REC, V1, P54, DOI https://doi.org/10.1007/978-3-030-04921-8_4
   Fürnkranz J, 2020, MACH LEARN, V109, P853, DOI 10.1007/s10994-019-05856-5
   Gulla JA, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), V0, PP1042, DOI 10.1145/3106426.3109436
   Harper FM, 2016, ACM T INTERACT INTEL, V5, P0, DOI 10.1145/2827872
   Henelius A, 2014, DATA MIN KNOWL DISC, V28, P1503, DOI 10.1007/s10618-014-0368-8
   Jiawei Han, 2000, SIGMOD RECORD, V29, P1, DOI 10.1145/335191.335372
   Kang WC, 2018, IEEE DATA MINING, V0, PP197, DOI 10.1109/ICDM.2018.00035
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Klosgen W, 1996, ADV KNOWLEDGE DISCOV, V0, PP249, DOI 10.1016/j.bbi.2007.12.007
   Le Falher G, 2015, P INT AAAI C WEB SOC, V0, P228
   Lemmerich F, 2012, P ECML PKDD, V0, P0
   Lemmerich F, 2016, DATA MIN KNOWL DISC, V30, P711, DOI 10.1007/s10618-015-0436-8
   Lonjarret C, 2021, DATA MIN KNOWL DISC, V35, P1087, DOI 10.1007/s10618-021-00744-w
   Lonjarret C, 2020, PR INT CONF DATA SC, V0, PP526, DOI 10.1109/DSAA49011.2020.00067
   Mabroukeh NR, 2010, ACM COMPUT SURV, V43, P0, DOI 10.1145/1824795.1824798
   Mathonat R, 2019, PR INT CONF DATA SC, V0, PP81, DOI 10.1109/DSAA.2019.00022
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP43, DOI 10.1145/2766462.2767755
   Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x
   Mollenhauer D, 2020, INT WORKSH EXPL INT, V2796, P0
   Pei J, 2004, IEEE T KNOWL DATA EN, V16, P1424, DOI 10.1109/TKDE.2004.77
   Pei J, 2001, PROC INT CONF DATA, V0, P215
   Pope PE, 2019, PROC CVPR IEEE, V0, PP10764, DOI 10.1109/CVPR.2019.01103
   Pu P, 2006, 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP93, DOI 10.1145/1111449.1111475
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, V0, P1527
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Roth-Berghofer TR, 2005, LECT NOTES ARTIF INT, V3620, P451, DOI 10.1007/11536406_35
   Sormo F, 2005, ARTIF INTELL REV, V24, P109, DOI 10.1007/s10462-005-4607-7
   Tang JX, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP565, DOI 10.1145/3159652.3159656
   Tintarev N, 2011, RECOMMENDER SYSTEMS HANDBOOK, V0, PP479, DOI 10.1007/978-0-387-85820-3_15
   Tolomei G, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP465, DOI 10.1145/3097983.3098039
   WICK MR, 1992, ARTIF INTELL, V54, P33, DOI 10.1016/0004-3702(92)90087-E
   Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78
   Zaki MJ, 2001, MACH LEARN, V42, P31, DOI 10.1023/A:1007652502315
NR 41
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1384-5810
EI 1573-756X
J9 DATA MIN KNOWL DISC
JI Data Min. Knowl. Discov.
PD MAR 15
PY 2023
VL 37
IS 2
BP 833
EP 872
DI 10.1007/s10618-022-00897-2
EA NOV 2022
PG 40
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 9D8DH
UT WOS:000889424300003
DA 2023-11-10
ER

PT J
AU Hiratani, N
   Sompolinsky, H
AF Hiratani, Naoki
   Sompolinsky, Haim
TI Optimal Quadratic Binding for Relational Reasoning in Vector Symbolic Neural Architectures
SO NEURAL COMPUTATION
LA English
DT Article
ID storage; memory
AB Binding operation is fundamental to many cognitive processes, such as cognitive map formation, relational reasoning, and language comprehension. In these processes, two different modalities, such as location and objects, events and their contextual cues, and words and their roles, need to be bound together, but little is known about the underlying neural mechanisms. Previous work has introduced a binding model based on quadratic functions of bound pairs, followed by vector summation of multiple pairs. Based on this framework, we address the following questions: Which classes of quadratic matrices are optimal for decoding relational structures? And what is the resultant accuracy? We introduce a new class of binding matrices based on a matrix representation of octonion algebra, an eight-dimensional extension of complex numbers. We show that these matrices enable a more accurate unbinding than previously known methods when a small number of pairs are present. Moreover, numerical optimization of a binding operator converges to this octonion binding. We also show that when there are a large number of bound pairs, however, a random quadratic binding performs, as well as the octonion and previously proposed binding methods. This study thus provides new insight into potential neural mechanisms of binding operations in the brain.
C1 [Hiratani, Naoki; Sompolinsky, Haim] Harvard Univ, Ctr Brain Sci, Cambridge, MA 02138 USA.
   [Sompolinsky, Haim] Hebrew Univ Jerusalem, Edmond & Lily Safra Ctr Brain Sci, IL-91904 Jerusalem, Israel.
C3 Harvard University; Hebrew University of Jerusalem
RP Hiratani, N (通讯作者)，Harvard Univ, Ctr Brain Sci, Cambridge, MA 02138 USA.
EM n.hiratani@gmail.com; haim@fiz.huji.ac.il
CR Aerts D, 2009, J MATH PSYCHOL, V53, P389, DOI 10.1016/j.jmp.2009.02.005
   [Anonymous], 1997, CONNECTIONIST SYSTEM, V0, P0
   [Anonymous], 2000, MATRIX REPRESENTATIO, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Baez JC, 2002, B AM MATH SOC, V39, P145
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266
   Feldman J, 2013, COGN NEURODYNAMICS, V7, P1, DOI 10.1007/s11571-012-9219-8
   Frady EP, 2020, NEURAL COMPUT, V32, P2311, DOI 10.1162/neco_a_01331
   Frady EP, 2018, NEURAL COMPUT, V30, P1449, DOI 10.1162/neco_a_01084
   Frady EP, 2023, IEEE T NEUR NET LEAR, V34, P2191, DOI 10.1109/TNNLS.2021.3105949
   Gallant SI, 2013, NEURAL COMPUT, V25, P2038, DOI 10.1162/NECO_a_00467
   Ganesan A, 2021, ADV NEURAL INFORM PR, V34, P0
   Gayler RW, 1998, ADV ANALOGY RES INTE, V0, P1
   Gayler Ross W, 2003, ICCSASCS INT C COGNI, V0, P133
   Gosmann J, 2019, NEURAL COMPUT, V31, P849, DOI 10.1162/neco_a_01179
   Greff K, 2020, ARXIV, V0, P0
   Hirokawa J, 2019, NATURE, V576, P446, DOI 10.1038/s41586-019-1816-9
   Jackendoff R, 2003, BEHAV BRAIN SCI, V26, P651, DOI 10.1017/S0140525X03000153
   Johnson J, 2017, PROC CVPR IEEE, V0, PP1988, DOI 10.1109/CVPR.2017.215
   Kanerva P, 1997, P 1997 REAL WORLD CO, V0, P0
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Kent SJ, 2020, NEURAL COMPUT, V32, P2332, DOI 10.1162/neco_a_01329
   Kleyko D, 2021, ARXIV, V0, P0
   Kleyko D, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3538531
   Ma YP, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, V0, P403
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   MURDOCK BB, 1982, PSYCHOL REV, V89, P609, DOI 10.1037/0033-295X.89.6.609
   Nickel M, 2016, AAAI CONF ARTIF INTE, V0, P1955
   Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592
   Nieh EH, 2021, NATURE, V595, P80, DOI 10.1038/s41586-021-03652-7
   Plate T, 1994, THESIS, V0, P0
   PLATE TA, 1995, IEEE T NEURAL NETWOR, V6, P623, DOI 10.1109/72.377968
   Rachkovskij DA, 2001, NEURAL COMPUT, V13, P411, DOI 10.1162/089976601300014592
   Rigotti M, 2013, NATURE, V497, P585, DOI 10.1038/nature12160
   Santoro A, 2017, ARXIV, V0, P0
   Schlegel K, 2022, ARTIF INTELL REV, V55, P4523, DOI 10.1007/s10462-021-10110-3
   Shapiro DB, 2011, COMPOSITIONS QUADRAT, V0, P0
   SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M
   Smolensky P, 2014, COGNITIVE SCI, V38, P1102, DOI 10.1111/cogs.12047
   Socher R, 2013, ADV NEURAL INFORM PR, V0, PP926, DOI 10.1109/ICICIP.2013.6568119
   Steinberg J, 2022, BIORXIV, V0, P0
   Teney D, 2018, PROC CVPR IEEE, V0, PP4223, DOI 10.1109/CVPR.2018.00444
   Whittington JCR, 2020, CELL, V183, P1249, DOI 10.1016/j.cell.2020.10.024
NR 44
TC 1
Z9 1
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0899-7667
EI 1530-888X
J9 NEURAL COMPUT
JI Neural Comput.
PD JAN 20
PY 2023
VL 35
IS 2
BP 105
EP 155
DI 10.1162/neco_a_01558
PG 51
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA 8H0SR
UT WOS:000920749400001
PM 36543330
DA 2023-11-10
ER

PT J
AU Al-Thani, H
   Jansen, BJ
   Elsayed, T
AF Al-Thani, Haya
   Jansen, Bernard J.
   Elsayed, Tamer
TI ECAsT: a large dataset for conversational search and an evaluation of metric robustness
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Conversational search; Paraphrasing; Conversational evaluation; Open-domain
AB The Text REtrieval Conference Conversational assistance track (CAsT) is an annual conversational passage retrieval challenge to create a large-scale open-domain conversational search benchmarking. However, as of yet, the datasets used are small, with just more than 1,000 turns and 100 conversation topics. In the first part of this research, we address the dataset limitation by building a much larger novel multi-turn conversation dataset for conversation search benchmarking called Expanded-CAsT (ECAsT). ECAsT is built using a multi-stage solution that uses a combination of conversational query reformulation and neural paraphrasing and also includes a new model to create multi-turn paraphrases. The meaning and diversity of paraphrases are evaluated with human and automatic evaluation. Using this methodology, we produce and release to the research community a conversational search dataset that is 665% more extensive in terms of size and language diversity than is available at the time of this study, with more than 9,200 turns. The augmented dataset not only provides more data but also more language diversity to improve conversational search neural model training and testing. In the second part of the research, we use ECAsT to assess the robustness of traditional metrics for conversational evaluation used in CAsT and identify its bias toward language diversity. Results show the benefits of adding language diversity for improving the collection of pooled passages and reducing evaluation bias. We found that introducing language diversity via paraphrases returned up to 24% new passages compared to only 2% using CAsT baseline.
C1 [Al-Thani, Haya] Hamad Bin Khalifa Univ, Doha, Qatar.
   [Jansen, Bernard J.] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
   [Elsayed, Tamer] Qatar Univ, Comp Sci & Engn Dept, Doha, Qatar.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Computing Research Institute; Qatar University
RP Al-Thani, H (通讯作者)，Hamad Bin Khalifa Univ, Doha, Qatar.
EM hayaalthani@hbku.edu.qa
CR Aliannejadi M, 2020, CHIIR20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, V0, PP33, DOI 10.1145/3343413.3377968
   Aliannejadi M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP475, DOI 10.1145/3331184.3331265
   Anand A, 2020, DAGSTUHL REPORTS, V9, P0, DOI 10.4230/DAGREP.9.11.34
   Ashraf N, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.742
   Bailey P, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP395, DOI 10.1145/3077136.3080839
   Barzilay R, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P50
   Bondarenko A, 2018, TREC, V0, P0
   Buckley C, 2004, PROCEEDINGS OF SHEFFIELD SIGIR 2004. THE TWENTY-SEVENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP25, DOI 10.1145/1008992.1009000
   Buttcher Stefan, 2007, 30TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP63, DOI 10.1145/1277741.1277755
   Chen David, 2011, P 49 ANN M ASS COMP, V0, P190
   Chklovski T, 2005, P 3 INT C KNOWL CAPT, V0, PP115, DOI 10.1145/1088622.1088644
   Clarke CLA, 2021, ACM T INFORM SYST, V39, P0, DOI 10.1145/3451161
   Culpepper JS, 2018, SIGIR FORUM, V52, P34, DOI 10.1145/3274784.3274788
   Dalton J, 2021, P 30 TEXT RETRIEVAL, V0, P0
   Dalton J, 2020, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dietz L, 2017, TREC, V0, P0
   Duboue Pablo, 2006, P HUMAN LANGUAGE TEC, V0, P33
   Duta IC, 2016, INT WORK CONTENT MUL, V0, P0
   Elgohary A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5918
   Falotico R, 2015, QUAL QUANT, V49, P463, DOI 10.1007/s11135-014-0003-1
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Feng SY, 2021, FINDINGS ASS COMPUTA, V0, PP968, DOI 10.18653/V1/2021.FINDINGS-ACL.84
   Fishkin R, 2020, 2020 2 3S GOOGLE SEA, V0, P0
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gan WC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6065
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1371, DOI 10.1145/3209978.3210183
   Guichard J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE TESTING (AITEST), V0, PP55, DOI 10.1109/AITest.2019.000-7
   Gupta A, 2018, AAAI CONF ARTIF INTE, V0, P5149
   Hassan Samer, 2007, P 4 INT WORKSHOP SEM, V0, P410
   Holtzman Ari, 2020, ICLR, V0, P0
   Iyyer M, 2018, P 2018 C N AM CHAPT, V1, P1875, DOI 10.18653/V1/N18-1170
   Kacupaj E, 2021, LECT NOTES COMPUT SC, V12731, P598, DOI 10.1007/978-3-030-77385-4_36
   Kauchak David, 2006, HLT NAACL 06, V0, P455
   Keyvan K, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3534965
   Kobayashi S, 2018, P 2018 C N AM CHAPTE, V2, P452, DOI 10.18653/v1/N18-2072
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li SK, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.103067
   Lin SC, 2021, ARXIV, V0, P0
   Lipani A, 2021, ACM T INFORM SYST, V39, P0, DOI 10.1145/3451160
   Liu BL, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.103051
   Mudrakarta PK, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1896
   Niu T, 2021, ARXIV, V0, P0
   Nogueira Rodrigo, 2020, FINDINGS ASS COMPUTA, V0, PP708, DOI 10.18653/V1/2020.FINDINGS-EMNLP.63
   Onal KD, 2018, INFORM RETRIEVAL J, V21, P111, DOI 10.1007/s10791-017-9321-y
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Penha G, 2022, LECT NOTES COMPUT SC, V13185, P397, DOI 10.1007/978-3-030-99736-6_27
   Petroni F, 2021, ARXIV, V0, P0
   Ponkiya G, 2020, FINDINGS ASS COMPUTA, V0, P4313
   Prakash A, 2016, ARXIV161003098, V0, P2923
   Quirk C, 2004, P 2004 C EMP METH NA, V0, P142
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Robertson Stephen, 2009, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V3, P333, DOI 10.1561/1500000019
   Rosset C, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP1160, DOI 10.1145/3366423.3380193
   Shen TS, 2023, INFORM PROCESS MANAG, V60, P0, DOI 10.1016/j.ipm.2022.103139
   Srinivasa-Desikan B, 2018, NATURAL LANGUAGE PRO, V0, P0
   Voorhees EM, 2002, LECT NOTES COMPUT SC, V2406, P355
   Vtyurina Alexandra, 2017, P 2017 CHI C EXTENDE, V0, P2187
   Wallace E, 2019, T ASSOC COMPUT LING, V7, P387, DOI 10.1162/tacl_a_00279/1923125
   Wang WY, 2015, P 2015 C EMP METH NA, V0, P2557
   Yaghoub-Zadeh-Fard MA, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, P55, DOI 10.1145/3377325.3377486
   Yilmaz E, 2006, P 15 ACM INT C INF K, V0, PP102, DOI 10.1145/1183614.1183633
   Zhou JN, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5075
   Zuccon G, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP691, DOI 10.1145/2983323.2983723
NR 66
TC 1
Z9 1
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD APR 17
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1328
PG 33
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA P8TE7
UT WOS:001053334400004
PM 37346722
DA 2023-11-10
ER

PT J
AU Ma, RX
   Mei, B
   Ma, YL
   Zhang, HY
   Liu, MH
   Zhao, L
AF Ma, Ruixin
   Mei, Biao
   Ma, Yunlong
   Zhang, Hongyan
   Liu, Meihong
   Zhao, Liang
TI One-shot relational learning for extrapolation reasoning on temporal knowledge graphs
SO DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Article
DE One-shot; Temporal knowledge graphs; Knowledge graph reasoning; Temporal convolutional network
AB In recent years, temporal knowledge graph reasoning has been a critical task in natural language processing. Temporal knowledge graphs store temporal facts that model dynamic relationships or interactions between entities along the timeline. Most existing temporal knowledge graph reasoning methods need a large number of training instances (i.e. support entity facts) for each relation. However, the same as traditional knowledge graphs, temporal knowledge graphs also exhibit long-tailed relational frequency distribution, in which most relationships often do not have many support entity pairs for training. To address this problem, in this paper, we propose a one-shot learning framework (OSLT) applied to temporal knowledge graph link prediction, which aims to predict new relational facts with only one support instance. Specifically, OSLT employs an fact encoder based on Temporal Convolutional Network to encode historical information and model connection of facts at the same timestamp by the aggregator with an attention mechanism. After that, a matching network is employed to compute the similarity score between support fact and query fact. Experiments show that the proposed method outperforms the state-of-the-art baselines on two benchmark datasets.
C1 [Ma, Ruixin; Mei, Biao; Ma, Yunlong; Zhang, Hongyan; Zhao, Liang] Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.
   [Ma, Ruixin; Mei, Biao; Ma, Yunlong; Zhang, Hongyan; Zhao, Liang] Key Lab Ubiquitous Network & Serv Liaoning Prov, Dalian, Peoples R China.
   [Liu, Meihong] Dalian Med Univ, Dalian, Peoples R China.
C3 Dalian University of Technology; Dalian Medical University
RP Zhao, L (通讯作者)，Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.; Zhao, L (通讯作者)，Key Lab Ubiquitous Network & Serv Liaoning Prov, Dalian, Peoples R China.
EM maruixin@dlut.edu.cn; aliezc0411@163.com; m1804069847@mail.dlut.edu.cn; zhy_1996@126.com; 1412988386@qq.com; liangzhao@dlut.edu.cn
FU National Natural Science Foundation of China [61906030]; Science and Technology Project of Liaoning Province [2021JH2/10300064]; Youth Science and Technology Star Support Program of Dalian City [2021RQ057]; Fundamental Research Funds for the Central Universities [DUT22YG241]
CR Abboud Ralph, 2020, ADV NEURAL INFORM PR, V33, P9649
   Bai S, 2018, ARXIV180301271, V0, P0
   Barracchia EP, 2022, INFORM SCIENCES, V606, P702, DOI 10.1016/j.ins.2022.05.079
   Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   Chen JA, 2019, AAAI CONF ARTIF INTE, V0, P6244
   Chen MY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4217
   Chen YT, 2020, NEUROCOMPUTING, V399, P491, DOI 10.1016/j.neucom.2020.03.011
   Dasgupta SS, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2001
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   García-Durán A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4816
   Goyal P, 2020, KNOWL-BASED SYST, V187, P0, DOI 10.1016/j.knosys.2019.06.024
   He H, 2017, ARXIV, V0, P0
   Jiang Tingsong, 2016, P COLING 2016 26 INT, V0, P1715
   Jin W, 2019, RECURRENT EVENT NETW, V0, P0
   Junheng Hao, 2020, BCB 20: PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS, V0, P0, DOI 10.1145/3388440.3412477
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Koren Y, 2018, COMPUT INF SCI, V11, P1
   Leblay J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP1771, DOI 10.1145/3184558.3191639
   Leetaru K, 2013, GDELT GLOBAL DATA EV, V2, P1, DOI 10.1038/NATURE14539
   Liu ZH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2395
   Messner J, 2022, AAAI CONF ARTIF INTE, V0, P7779
   Mirtaheri M, 2021, 3 C AUTOMATED KNOWLE, V0, P0
   Ravi Sachin, 2017, P ICLR, V0, P0
   Sadeghian A, 2021, AAAI CONF ARTIF INTE, V35, P6471
   Salimans T, 2016, ADV NEUR IN, V29, P0
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Snell Jake, 2017, NEURIPS, V0, P0
   Sun ZC, 2019, 2019 20TH INTERNATIONAL CONFERENCE ON THERMAL, V0, P0, DOI 10.1109/eurosime.2019.8724592
   Trivedi R, 2017, PR MACH LEARN RES, V70, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Vinyals Oriol, 2016, ADV NEURAL INFORM PR, V29, P0, DOI 10.48550/ARXIV.1606.04080
   Xiong WH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1980
   Yang Bishan, 2015, EMBEDDING ENTITIES R, V0, P0
   Zhang CX, 2020, AAAI CONF ARTIF INTE, V34, P3041
   Zhu CC, 2021, AAAI CONF ARTIF INTE, V35, P4732
NR 35
TC 0
Z9 0
U1 11
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1384-5810
EI 1573-756X
J9 DATA MIN KNOWL DISC
JI Data Min. Knowl. Discov.
PD JUL 15
PY 2023
VL 37
IS 4
BP 1591
EP 1608
DI 10.1007/s10618-023-00935-7
EA APR 2023
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA L1IR6
UT WOS:000965208300001
DA 2023-11-10
ER

PT J
AU Veres, C
   Sampson, J
AF Veres, Csaba
   Sampson, Jennifer
TI Self supervised learning and the poverty of the stimulus
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article
DE Classification; Learnability; Text mining; Machine Learning; NLP; Language
ID natural-language
AB Diathesis alternations are the possible expressions of the arguments of verbs in different, systematically related subcategorization frames. Semantically similar verbs such as spill and spray can behave differently with respect to the alternations they can participate in. For example one can "spill/spray water on the plant", but while one can "spray the plant with water", it is odd to say "spill the plant with water". "Spray"is a verb which can alternate between syntactic frames while "spill"is not alternating. How human speakers learn the difference between such verbs is not clearly understood, because the primary linguistic data (PLD) they receive does not appear sufficient to infer the knowledge required for adult competence. More generally the poverty of the stimulus (POS) hypothesis states that the PLD is not sufficient for a learner to infer full adult competence of language. That is, learning relies on prior constraints introduced by the language faculty. We tested state-of-the-art machine learning models trained by self supervision, and found some evidence that they could in fact learn the correct pattern of acceptability judgement in the locative alternation. However, we argued that this was partially a result of fine-tuning which introduced negative evidence into the learning data, which facilitated shortcut learning. Large language models (LLMs) cannot learn some linguistic facts from normal language data, but they can compensate to some extent by learning spurious correlated features when negative feedback is introduced during the training cycle.
C1 [Veres, Csaba] Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway.
   [Sampson, Jennifer] Equinor UK Ltd, London, England.
C3 University of Bergen; Equinor
RP Veres, C (通讯作者)，Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway.
EM csaba.veres@uib.no
CR Alom MZ, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8030292
   Brown TB, 2020, ARXIV, V0, P0
   BAKER CL, 1979, LINGUIST INQ, V10, P533
   Bender EM, 2020, P 58 ANN M ASS COMPU, V0, PP5185, DOI 10.18653/V1/2020.ACL-MAIN.463
   Berwick RC, 2011, COGNITIVE SCI, V35, P1207, DOI 10.1111/j.1551-6709.2011.01189.x
   Bley-Vroman Robert, 2001, STUD SECOND LANG ACQ, V23, P207
   Brooks PJ, 1999, LANGUAGE, V75, P720, DOI 10.2307/417731
   Chen LJ, 2023, ARXIV, V0, P0
   CHOI S, 1991, COGNITION, V41, P83, DOI 10.1016/0010-0277(91)90033-Z
   Chomsky N, 1965, ASPECTS THEORY SYNTA, V0, P0
   Chomsky Noam, 1980, COLUMBIA CLASSICS PH, V0, P0
   Cowie Fiona, 2017, STANFORD ENCY PHILOS, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Grechishnikova D, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-020-79682-4
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Jackendoff Ray, 1983, SEMANTICS COGNITION, V0, P283
   Jackendoff Ray, 1990, SEMANTIC STRUCTURES, V0, P322
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kann Katharina, 2019, P SOC COMPUTATION LI, V0, P287
   Kassner N, 2020, PROC 58 ANN M ASS CO, V0, PP7811, DOI 10.18653/v1/2020.acl-main.698
   Levin Beth, 1993, ENGLISH VERB CLASSES, V0, P0
   Li Yujia, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2203.07814
   Liu P, 2021, ARXIV, V0, P0
   Liu YH, 2023, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Merriman WE, 1995, NAMES THINGS YOUNG C, V0, P353
   Mitchell Melanie, 2023, SCIENCE, V381, Padj5957, DOI 10.1126/science.adj5957
   Perfors A, 2010, J CHILD LANG, V37, P607, DOI 10.1017/S0305000910000012
   PINKER S, 1990, BEHAV BRAIN SCI, V13, P707, DOI 10.1017/S0140525X00081061
   Pinker S, 2007, STUFF THOUGHT LANGUA, V0, P0
   Pinker Steven, 1989, LEARNABILITY COGNITI, V0, P0
   Quinn T, 2018, TLS-TIMES LIT SUPPL, V0, P31
   Ruis Laura, 2022, ARXIV, V0, P0
   Sahlgren M, 2008, ITAL J LINGUIST, V20, P33
   Sanh V, 2020, ARXIV, V0, P0
   Scholkopf B, 2021, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Veres C, 2022, IEEE ACCESS, V10, P61970, DOI 10.1109/ACCESS.2022.3182505
   Veres C, 2019, LECT NOTES ARTIF INT, V11919, P369, DOI 10.1007/978-3-030-35288-2_30
   Wang A, 2019, INT C LEARNING REPRE, V0, P0
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wang W, 2019, ARXIV, V0, P0
   Warstadt A, 2018, NEURAL NETWORK ACCEP, V0, P0
   Wikipedia contributors, 2023, INSTR CAS WIK FREE E, V0, P0
   Yang ZL, 2020, ARXIV, V0, P0
NR 48
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-023X
EI 1872-6933
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD SEP 15
PY 2023
VL 147
IS 
BP 
EP 
DI 10.1016/j.datak.2023.102208
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA Q7YO7
UT WOS:001059645300001
DA 2023-11-10
ER

PT J
AU Johns, BT
AF Johns, Brendan T.
TI Computing word meanings by aggregating individualized distributional models: Wisdom of the crowds in lexical semantic memory
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Lexical semantics; Distributional modeling; Cognitive modeling; Machine learning; Big data
ID cooccurrence statistics; recognition memory; representations; lists; association; diversity; judgment
AB Linguistic experience varies across individuals and is impacted by both demography and personal preferences, leading to differences in word meanings across languages (Thompson et al., 2020) and people (Johns, 2022). An active area of study in the cognitive sciences that examines the impact of varied knowledge across individuals is the wisdom of the crowd effect, where it is found that the aggregate judgement of a group of individuals is often better than the judgement of the best individual in the group (Surowiecki, 2004). The goal of this article was to determine if there is a wisdom of the crowd effect in lexical semantic memory, such that the aggregated word similarity values from many individual language users exceeds the fit of the best fitting individual. This was accomplished by training 500 different distributional models from 500 high-level commenters on the internet forum Reddit. By deriving aggregated word similarity values from these individuals, a strong wisdom of the crowd effect was found where the aggregated similarity values far exceeded the performance of the best fitting individual for each dataset tested. Additionally, it was found that even aggregating only a small number of users provided a large increase in fit relative to the individual corpora, but with the best fitting measure including word similarity values from all possible users. The results of this article provide an avenue for future distributional model development by demonstrating that the best pathway towards better distributional models may lie in the aggregation of multiple representations attained from individual users of a language.
C1 [Johns, Brendan T.] McGill Univ, Montreal, PQ, Canada.
   [Johns, Brendan T.] McGill Univ, Dept Psychol, 2001 McGill Coll Ave, Montreal, PQ H3A 1G1, Canada.
C3 McGill University; McGill University
RP Johns, BT (通讯作者)，McGill Univ, Dept Psychol, 2001 McGill Coll Ave, Montreal, PQ H3A 1G1, Canada.
EM brendan.johns@mcgill.ca
FU Natural Science and Engineering Research Council of Canada (NSERC) [RGPIN-2020- 04727]
CR [Anonymous], 2012, P 18 ACM SIGKDD INT, V0, P0, DOI DOI 10.1145/2339530.2339751
   [Anonymous], 2015, T ASSOC COMPUT LING, V0, P0, DOI DOI 10.1162/TACL_A_00134
   Armstrong JS, 2001, INT SER OPER RES MAN, V30, P417
   Aujla H, 2021, CAN J EXP PSYCHOL, V75, P235, DOI 10.1037/cep0000255
   Bartlett, 1932, REMEMBERING STUDY EX, V0, P0, DOI DOI 10.1111/j.2044-8279.1933.tb02913.x
   Bartlett FC, 1928, J GEN PSYCHOL, V1, P56
   Baumgartner J, 2020, INT AAAI ASS ADV ART, V0, PP830, DOI 10.1609/ICWSM.V14I1.7347
   Bennett ST, 2018, COMPUTATIONAL BRAIN, V1, P90, DOI 10.1007/S42113-018-0006-4
   Bergman ET, 1999, MEM COGNITION, V27, P937, DOI 10.3758/BF03201224
   Bhatia S, 2022, CURR DIR PSYCHOL SCI, V31, P207, DOI 10.1177/09637214211068113
   Bhatia S, 2019, CURR OPIN BEHAV SCI, V29, P31, DOI 10.1016/j.cobeha.2019.01.020
   Bhatia S, 2019, J EXP PSYCHOL LEARN, V45, P627, DOI 10.1037/xlm0000618
   Bhatia S, 2019, MEM COGNITION, V47, P292, DOI 10.3758/s13421-018-0869-6
   Bhatia S, 2017, PSYCHOL REV, V124, P1, DOI 10.1037/rev0000047
   Bruni E, 2012, DISTRIBUTIONAL SEMAN, V0, P136
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   Bullinaria JA, 2012, BEHAV RES METHODS, V44, P890, DOI 10.3758/s13428-011-0183-8
   Cortese MJ, 2015, Q J EXP PSYCHOL, V68, P1489, DOI 10.1080/17470218.2014.945096
   Cortese MJ, 2010, MEMORY, V18, P595, DOI 10.1080/09658211.2010.493892
   Davies M, 2009, INT J CORPUS LINGUIS, V14, P159, DOI 10.1075/ijcl.14.2.02dav
   De Deyne S, 2016, COLING, V0, P1861
   Finkelstein L, 2001, WWW, V0, P0
   Gallo DA, 2002, J MEM LANG, V47, P469, DOI 10.1016/S0749-596X(02)00013-X
   Galton F, 1907, NATURE, V75, P450, DOI 10.1038/075450a0
   Gordon K, 1924, J EXP PSYCHOL, V7, P398, DOI 10.1037/h0065015
   Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211
   Günther F, 2019, PERSPECT PSYCHOL SCI, V14, P1006, DOI 10.1177/1745691619861372
   Herdagdelen A, 2017, COGNITIVE SCI, V41, P976, DOI 10.1111/cogs.12392
   Hollis G, 2020, J MEM LANG, V114, P0, DOI 10.1016/j.jml.2020.104146
   Jamieson RK, 2018, COMPUTATIONAL BRAIN, V1, P119, DOI 10.1007/s42113-018-0008-2
   Johns BT, 2020, BIG DATA METHODS PSY, V0, P0
   Johns BT, 2022, PSYARXIV, V0, P0
   Johns BT, 2022, J MEM LANG, V123, P0, DOI 10.1016/j.jml.2021.104313
   Johns BT, 2021, COGNITIVE PSYCHOL, V131, P0, DOI 10.1016/j.cogpsych.2021.101441
   Johns BT, 2021, PSYCHOL REV, V128, P525, DOI 10.1037/rev0000265
   Johns BT, 2021, CAN J EXP PSYCHOL, V75, P1, DOI 10.1037/cep0000237
   Johns BT, 2020, Q J EXP PSYCHOL, V73, P841, DOI 10.1177/1747021819897560
   Johns BT, 2019, BEHAV RES METHODS, V51, P2438, DOI 10.3758/s13428-019-01289-z
   Johns BT, 2019, COGNITIVE SCI, V43, P0, DOI 10.1111/cogs.12730
   Johns BT, 2019, FRONT PSYCHOL, V10, P0, DOI 10.3389/fpsyg.2019.00268
   Johns BT, 2019, PSYCHON B REV, V26, P103, DOI 10.3758/s13423-018-1501-2
   Johns BT, 2018, COGNITIVE SCI, V42, P1360, DOI 10.1111/cogs.12583
   Johns BT, 2012, COGNITIVE PSYCHOL, V65, P486, DOI 10.1016/j.cogpsych.2012.07.002
   Jones MN, 2007, PSYCHOL REV, V114, P1, DOI 10.1037/0033-295X.114.1.1
   Kumar AA, 2021, PSYCHON B REV, V28, P40, DOI 10.3758/s13423-020-01792-x
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Lee MD, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0096431
   Lee MD, 2014, JUDGM DECIS MAK, V9, P259
   Lee MD, 2011, MEM COGNITION, V39, P914, DOI 10.3758/s13421-010-0059-7
   Lenhart A, 2015, TEENS SOCIAL MEDIA T, V0, P0
   Levy O, 2014, ADV NEUR IN, V27, P0
   Maki WS, 2008, BEHAV RES METHODS, V40, P232, DOI 10.3758/BRM.40.1.232
   Mandera P, 2017, J MEM LANG, V92, P57, DOI 10.1016/j.jml.2016.04.001
   Mannes AE, 2014, J PERS SOC PSYCHOL, V107, P276, DOI 10.1037/a0036677
   Merkle EC, 2017, INT J FORECASTING, V33, P817, DOI 10.1016/j.ijforecast.2017.04.002
   Mewhort DJK, 2018, PSYCHON B REV, V25, P932, DOI 10.3758/s13423-017-1327-3
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Nelson DL, 2004, BEHAV RES METH INS C, V36, P402, DOI 10.3758/BF03195588
   Osth AF, 2020, J MEM LANG, V111, P0, DOI 10.1016/j.jml.2019.104071
   Otto AR, 2022, BIORXIV, V0, P0
   Otto AR, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0206923
   Reid JN, 2023, J MEM LANG, V128, P0, DOI 10.1016/j.jml.2022.104397
   Shabahang KD, 2022, COMPUTATIONAL BRAIN, V5, P124
   Shaoul C, 2010, WESTBURY LAB WIKIPED, V0, P0
   Singh M, 2022, COMPUTATIONAL BRAIN, V5, P1
   Stadler MA, 1999, MEM COGNITION, V27, P494, DOI 10.3758/BF03211543
   Stanovich KE, 1999, WHO IS RATIONAL STUD, V0, P0
   Steyvers M, 2009, ADV NEURAL INFORM PR, V22, P1785
   Steyvers M, 2015, HANDBOOK OF COLLECTIVE INTELLIGENCE, V0, P119
   Surowiecki J, 2004, WISDOM CROWDS WHY MA, V0, P296
   Thompson B, 2020, NAT HUM BEHAV, V4, P1029, DOI 10.1038/s41562-020-0924-8
   Yaniv I, 2004, CURR DIR PSYCHOL SCI, V13, P75, DOI 10.1111/j.0963-7214.2004.00278.x
   Yi SKM, 2012, COGNITIVE SCI, V36, P452, DOI 10.1111/j.1551-6709.2011.01223.x
   Zou WL, 2021, COGNITION, V211, P0, DOI 10.1016/j.cognition.2021.104647
NR 75
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-4366
EI 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD AUG 15
PY 2023
VL 80
IS 
BP 90
EP 102
DI 10.1016/j.cogsys.2023.02.009
PG 13
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology, Experimental
SC Computer Science; Neurosciences & Neurology; Psychology
GA Q0PZ0
UT WOS:001054633600001
DA 2023-11-10
ER

PT J
AU Liao, JW
   Cheng, S
   Tan, MH
AF Liao, Junwei
   Cheng, Shuai
   Tan, Minghuan
TI Text Polishing with Chinese Idiom: Task, Datasets and Pre-trained Baselines
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Intelligent writing assistance; text polishing; Chinese idiom; backtranslation; pre-trained language model
AB This work presents the task of text polishing, which generates a sentence that is more graceful than the input sentence while retaining its semantic meaning. Text polishing has great value in real usage and is an important component in modern writing assistance systems. However, the task is still not well studied in the literature. Further research in this important direction requires more formal task definitions, benchmark datasets, and powerful baseline models. In this work, we formulate the task as a context-dependent text generation problem and conduct a case study on the text polishing with Chinese idiom. To circumvent the difficulties of task data annotation, we propose a semi-automatic data construction pipeline based on human-machine collaboration, and establish a large-scale text polishing dataset consisting of 1.5 million instances. We propose two types of task-specific pre-training objectives for the text polishing task and implement a series of Transformer based models pre-trained on a massive Chinese corpus as baselines. We conduct extensive experiments with the baseline models on the constructed text polishing datasets and have some major findings. The human evaluation further reveals the polishing ability of the final system.
C1 [Liao, Junwei; Cheng, Shuai] Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
   [Tan, Minghuan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
C3 University of Electronic Science & Technology of China; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS
RP Liao, JW (通讯作者)，Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
EM liaojunwei@std.uestc.edu.cn; scheng@uestc.edu.cn; mh.tan@siat.ac.cn
CR [Anonymous], 2000, HDB NATURAL LANGUAGE, V0, P0
   Bryant C, 2022, ARXIV, V0, P0
   Bryant C, 2019, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, V0, P52
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Cui Yiming, 2020, FINDINGS ASS COMPUTA, V0, PP657, DOI 10.18653/V1/2020.FINDINGS-EMNLP.58
   Dahlmeier D, 2013, P 8 WORKSHOP INNOVAT, V0, P0
   Dai XJ, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, P25
   Dale R, 2021, NAT LANG ENG, V27, P511, DOI 10.1017/S1351324921000164
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Donahue C, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2492
   Du WY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3573
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Ganitkevitch Juri, 2011, P 2011 C EMPIRICAL M, V0, P1168
   Ho WY, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P716
   Kingma DP, 2015, P INT C LEARN REPR J, V0, P1
   KOWALSKI CJ, 1972, J ROY STAT SOC C-APP, V21, P1
   Lewis M, 2019, ARXIV, V0, P0
   Li Jiwei, 2016, NAACL, V0, PP110, DOI 10.18653/V1/N16-1014
   Liu Chia-Wei, 2016, P C EMP METH NAT LAN, V0, PP2122, DOI 10.18653/v1/D16-1230
   Liu YC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5522
   Liu YC, 2018, NEUROCOMPUTING, V275, P2287, DOI 10.1016/j.neucom.2017.11.005
   Madnani N, 2010, COMPUT LINGUIST, V36, P341, DOI 10.1162/coli_a_00002
   Mallinson J, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P881
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Napoles Courtney, 2017, P 15 C EUR CHAPT ASS, V2, P229
   Omelianchuk K, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, V0, P163
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Prabhumoye S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P866
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Sakaguchi Keisuke, 2016, T ASS COMPUTATIONAL, V4, P169, DOI 10.1162/TACL_A_00091
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Shao YT, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P31
   Shen T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5186
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tan MH, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3453185
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Yingying, 2021, ARXIV, V0, P0
   Wieting John, 2017, P 2017 C EMP METH NA, V0, PP274, DOI 10.18653/V1/D17-1026
   Wolf T, 2020, ARXIV, V0, P0
   Wu YH, 2016, ARXIV, V0, P0
   Yannakoudakis H, 2011, P 49 ANN M ASS COMPU, V0, P0
   Ying Hu, 2017, SYNONYMS, V0, P0
   Zhang Bowei, 2019, NATURAL LANGUAGE PRO, V0, P814
   Zhang Tianyi, 2020, ICLR, V0, P0
   Zhang Y, 2022, P 2022 C N AM CHAPTE, V0, P3118
   Zhu WR, 2019, ARXIV, V0, P0
   Ziemski M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3530
   Zwillinger D, 1999, CRC STANDARD PROBABI, V0, P0
NR 52
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN 15
PY 2023
VL 22
IS 6
BP 
EP 
DI 10.1145/3593806
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K7YR0
UT WOS:001018562700023
DA 2023-11-10
ER

PT J
AU Trillo, JR
   Herrera-Viedma, E
   Morente-Molinera, JA
   Cabrerizo, FJ
AF Trillo, Jose Ramon
   Herrera-Viedma, Enrique
   Morente-Molinera, Juan Antonio
   Cabrerizo, Francisco Javier
TI A large scale group decision making system based on sentiment analysis cluster
SO INFORMATION FUSION
LA English
DT Article
DE Large scale group decision making; Sentiment analysis; Natural language processing; Classification
ID consensus model; preference relations; self-confidence; information; consistency
AB Nowadays, group decision making is an everyday occurrence in different scenarios, such as marketing or social networks. These social networks have facilitated communication between experts because they do not need to meet in person. However, communication between experts through the internet generates three problems: the management of large amounts of information, the fact that experts often provide their information using natural language, and the lack of analysis of experts' intentions. In this paper, we propose a novel large scale group decision making method to manage the information generated by a large number of experts, using the natural language processing approach, specifically sentiment analysis. This approach makes it possible to detect the degree of positivity and aggressiveness of each expert and thus proceed to a classification. Once the behaviours are detected, the experts are grouped according to them and, for each group, a weight and a unique preference relation is obtained. In addition, we propose an optimised consensus analysis process, in which it is not necessary to compare all experts with each other, but only groups of experts.
C1 [Trillo, Jose Ramon; Herrera-Viedma, Enrique; Morente-Molinera, Juan Antonio; Cabrerizo, Francisco Javier] Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Dept Comp Sci & Artificial Intelligence, DaSCI, Granada 18071, Spain.
C3 University of Granada
RP Trillo, JR (通讯作者)，Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Dept Comp Sci & Artificial Intelligence, DaSCI, Granada 18071, Spain.
EM jrtrillo@ugr.es; viedma@decsai.ugr.es; jamoren@decsai.ugr.es; cabrerizo@decsai.ugr.es
FU FEDER/Junta de Andalucia-Consejeriade Transformacion Economica, Industria, Conocimiento y Universidades [B-TIC-590-UGR20]; Andalusian government [P20_00673]; MCIN / AEI [PID2019-103880RB-I00]
CR Akram M, 2020, COMPUT APPL MATH, V39, P0, DOI 10.1007/s40314-020-01251-2
   Alshalabi H, 2022, J KING SAUD UNIV-COM, V34, P6635, DOI 10.1016/j.jksuci.2021.08.017
   Blanco-Mesa F, 2019, APPL SOFT COMPUT, V81, P0, DOI 10.1016/j.asoc.2019.105488
   Cabrerizo FJ, 2017, SOFT COMPUT, V21, P3037, DOI 10.1007/s00500-015-1989-6
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Castillo-Zúñiga I, 2020, INT J SEMANT WEB INF, V16, P69, DOI 10.4018/IJSWIS.2020010104
   Cavaliere D, 2020, IEEE T FUZZY SYST, V28, P1984, DOI 10.1109/TFUZZ.2019.2928787
   Chao XR, 2021, INFORM SCIENCES, V575, P499, DOI 10.1016/j.ins.2021.06.047
   Chao XR, 2021, EUR J OPER RES, V288, P271, DOI 10.1016/j.ejor.2020.05.047
   Chao XR, 2018, EUR J OPER RES, V265, P239, DOI 10.1016/j.ejor.2017.07.030
   Chavent M, 2021, COMMUN STAT-SIMUL C, V50, P426, DOI 10.1080/03610918.2018.1563145
   Chen Xiao-hong, 2006, SYSTEMS ENGINEERING AND ELECTRONICS, V28, P1695
   Dahl FA, 2021, BMC MED INFORM DECIS, V21, P0, DOI 10.1186/s12911-021-01451-8
   Dror R, 2020, SYNTHESIS LECT HUM L, V13, P1
   Du ZJ, 2020, INFORM FUSION, V63, P13, DOI 10.1016/j.inffus.2020.05.004
   Escadas M, 2019, BUS ETHICS, V28, P529, DOI 10.1111/beer.12237
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Gao PQ, 2020, COMPUT IND ENG, V150, P0, DOI 10.1016/j.cie.2020.106842
   Georgiadou E, 2020, INT J INFORM MANAGE, V51, P0, DOI 10.1016/j.ijinfomgt.2019.102048
   Herrera F, 1996, FUZZY SET SYST, V79, P175, DOI 10.1016/0165-0114(95)00162-X
   Herrera-Viedma E, 2014, INFORM FUSION, V17, P4, DOI 10.1016/j.inffus.2013.04.002
   Cabrerizo FJ, 2015, J INTELL FUZZY SYST, V29, P1109, DOI 10.3233/IFS-151719
   Cabrerizo FJ, 2014, FUZZY SET SYST, V255, P115, DOI 10.1016/j.fss.2014.03.016
   Cabrerizo FJ, 2013, EUR J OPER RES, V230, P624, DOI 10.1016/j.ejor.2013.04.046
   Li CC, 2019, INFORM FUSION, V52, P143, DOI 10.1016/j.inffus.2018.12.004
   Li CC, 2019, IEEE T FUZZY SYST, V27, P221, DOI 10.1109/TFUZZ.2018.2857720
   Li Q, 2022, COMPLEX INTELL SYST, V0, P0
   Liu BS, 2019, EUR J OPER RES, V275, P737, DOI 10.1016/j.ejor.2018.11.075
   Liu X, 2019, INFORM FUSION, V52, P245, DOI 10.1016/j.inffus.2019.03.001
   Liu X, 2019, IEEE T FUZZY SYST, V27, P159, DOI 10.1109/TFUZZ.2018.2876655
   López M, 2021, KNOWL-BASED SYST, V231, P0, DOI 10.1016/j.knosys.2021.107455
   Lu YL, 2022, APPL SOFT COMPUT, V126, P0, DOI 10.1016/j.asoc.2022.109249
   Mendi AF, 2022, SENSORS-BASEL, V22, P0, DOI 10.3390/s22124419
   Morente-Molinera JA, 2020, KNOWL-BASED SYST, V195, P0, DOI 10.1016/j.knosys.2020.105657
   Morente-Molinera JA, 2020, INFORM FUSION, V53, P240, DOI 10.1016/j.inffus.2019.06.028
   Morente-Molinera JA, 2019, EXPERT SYST APPL, V127, P187, DOI 10.1016/j.eswa.2019.03.023
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Pérez IJ, 2013, SOFT COMPUT, V17, P1617, DOI 10.1007/s00500-012-0975-5
   Trillo JR, 2022, MATHEMATICS-BASEL, V10, P0, DOI 10.3390/math10122035
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Razno M, 2019, COMPUT LINGUIST, V2, P71
   Riaz S, 2019, CLUSTER COMPUT, V22, PS7149, DOI 10.1007/s10586-017-1077-z
   Roubens M, 1997, FUZZY SET SYST, V90, P199, DOI 10.1016/S0165-0114(97)00087-0
   Sambrano D, 2021, LEGAL CRIMINOL PSYCH, V26, P62, DOI 10.1111/lcrp.12181
   Song YM, 2019, J OPER RES SOC, V70, P827, DOI 10.1080/01605682.2018.1458017
   Sun Q, 2022, IEEE T FUZZY SYST, V30, P1287, DOI 10.1109/TFUZZ.2021.3057705
   Tang M, 2020, EUR J OPER RES, V282, P957, DOI 10.1016/j.ejor.2019.10.006
   Wan BT, 2022, GRANULAR COMPUT, V7, P489, DOI 10.1007/s41066-021-00280-4
   Wu ZB, 2018, INFORM FUSION, V41, P217, DOI 10.1016/j.inffus.2017.09.011
   Xu WJ, 2021, GROUP DECIS NEGOT, V30, P1239, DOI 10.1007/s10726-020-09653-7
   Xu XH, 2019, INFORM SCIENCES, V477, P410, DOI 10.1016/j.ins.2018.10.058
   Xu XH, 2019, KNOWL-BASED SYST, V163, P495, DOI 10.1016/j.knosys.2018.09.010
   Xu YJ, 2021, IEEE T SYST MAN CY-S, V51, P3498, DOI 10.1109/TSMC.2019.2931536
   Xu YJ, 2018, COMPUT IND ENG, V116, P113, DOI 10.1016/j.cie.2017.11.025
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Zampieri M, 2019, ARXIV, V0, P0
   Zha QB, 2019, IEEE T COMPUT SOC SY, V6, P994, DOI 10.1109/TCSS.2019.2938258
   Zhang Z, 2021, J OPER RES SOC, V72, P1914, DOI 10.1080/01605682.2020.1748529
   Zhang Z, 2020, IEEE T FUZZY SYST, V28, P2875, DOI 10.1109/TFUZZ.2019.2949758
   Zheng YH, 2021, EXPERT SYST APPL, V168, P0, DOI 10.1016/j.eswa.2020.114355
   Zhong XY, 2020, APPL SOFT COMPUT, V87, P0, DOI 10.1016/j.asoc.2019.105973
NR 62
TC 6
Z9 6
U1 20
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD MAR 15
PY 2023
VL 91
IS 
BP 633
EP 643
DI 10.1016/j.inffus.2022.11.009
EA NOV 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA 6Q9EF
UT WOS:000891912000007
DA 2023-11-10
ER

PT J
AU Pavlopoulos, J
   Romell, A
   Curman, J
   Steinert, O
   Lindgren, T
   Borg, M
   Randl, K
AF Pavlopoulos, John
   Romell, Alv
   Curman, Jacob
   Steinert, Olof
   Lindgren, Tony
   Borg, Markus
   Randl, Korbinian
TI Automotive fault nowcasting with machine learning and natural language processing
SO MACHINE LEARNING
LA English
DT Article; Early Access
DE Automotive fault nowcasting; Natural language processing; Multilingual text classification
AB Automated fault diagnosis can facilitate diagnostics assistance, speedier troubleshooting, and better-organised logistics. Currently, most AI-based prognostics and health management in the automotive industry ignore textual descriptions of the experienced problems or symptoms. With this study, however, we propose an ML-assisted workflow for automotive fault nowcasting that improves on current industry standards. We show that a multilingual pre-trained Transformer model can effectively classify the textual symptom claims from a large company with vehicle fleets, despite the task's challenging nature due to the 38 languages and 1357 classes involved. Overall, we report an accuracy of more than 80% for high-frequency classes and above 60% for classes with reasonable minimum support, bringing novel evidence that automotive troubleshooting management can benefit from multilingual symptom text classification.
C1 [Pavlopoulos, John; Lindgren, Tony; Randl, Korbinian] Stockholm Univ, Dept Comp & Syst Sci, Stockholm, Sweden.
   [Steinert, Olof; Lindgren, Tony] Scania CV, Strateg Prod Planning & Adv Analyt, Sodertalje, Sweden.
   [Romell, Alv; Curman, Jacob; Borg, Markus] Lund Univ, Dept Comp Sci, Lund, Sweden.
C3 Stockholm University; Scania; Lund University
RP Pavlopoulos, J (通讯作者)，Stockholm Univ, Dept Comp & Syst Sci, Stockholm, Sweden.
EM ioannis@dsv.su.se; alvromell@gmail.com; curmanjacob@gmail.com; olof.steinert@scania.com; tony@dsv.su.se; markus.borg@cs.lth.se; korbinian.randl@dsv.su.se
FU Stockholm University; European Union [101093026]
CR Adamopoulou E, 2020, OVERVIEW CHATBOT TEC, V0, PP373, DOI 10.1007/978-3-030-49186-4_31
   Aktas EU, 2020, EMPIR SOFTW ENG, V25, P3544, DOI 10.1007/s10664-020-09846-3
   Biteus J, 2017, SAE INT J MATER MANU, V10, P306, DOI 10.4271/2017-01-0237
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borg M, 2014, RECOMMENDATION SYSTE, V0, P477
   Borsci Simone, 2022, PERSONAL AND UBIQUITOUS COMPUTING, V26, P95, DOI 10.1007/s00779-021-01582-9
   Carvalho TP, 2019, COMPUT IND ENG, V137, P0, DOI 10.1016/j.cie.2019.106024
   Conneau A, 2020, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Fink O, 2020, ENG APPL ARTIF INTEL, V92, P0, DOI 10.1016/j.engappai.2020.103678
   Irving J, 2021, SCHIZOPHRENIA BULL, V47, P405, DOI 10.1093/schbul/sbaa126
   Jonsson L, 2016, EMPIR SOFTW ENG, V21, P1533, DOI 10.1007/s10664-015-9401-9
   Joulin A, 2016, ARXIV, V0, P0
   Izquierdo JL, 2020, J MED INTERNET RES, V22, P0, DOI 10.2196/21801
   Minaee S, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3439726
   Nath AG, 2021, ARTIF INTELL REV, V54, P2609, DOI 10.1007/s10462-020-09910-w
   Qian CH, 2022, NEURAL PROCESS LETT, V54, P2509, DOI 10.1007/s11063-021-10719-z
   Safaeipour H, 2021, J PROCESS CONTR, V97, P1, DOI 10.1016/j.jprocont.2020.11.005
   Sanh V, 2020, ARXIV, V0, P0
   Shaheen Z, 2020, ARXIV, V0, P0
   Theissler A, 2021, RELIAB ENG SYST SAFE, V215, P0, DOI 10.1016/j.ress.2021.107864
   Thorne C, 2017, LANG LINGUIST COMPAS, V11, P0, DOI 10.1111/lnc3.12253
   Vaish R, 2021, ENG APPL ARTIF INTEL, V106, P0, DOI 10.1016/j.engappai.2021.104504
   Wang W, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER AIDED EDUCATION (ICISCAE 2018), V0, PP64, DOI 10.1109/ICISCAE.2018.8666928
   Zhang TC, 2022, ISA T, V119, P152, DOI 10.1016/j.isatra.2021.02.042
   Zhao ZB, 2021, CHIN J MECH ENG-EN, V34, P0, DOI 10.1186/s10033-021-00570-7
NR 26
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10994-023-06398-7
EA OCT 2023
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA T1WZ1
UT WOS:001075969400001
DA 2023-11-10
ER

PT J
AU Al-Omari, H
   Duwairi, R
AF Al-Omari, Hani
   Duwairi, Rehab
TI So2al-wa-Gwab: A New ArabicQuestion-Answering Dataset Trained on Answer Extraction Models
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Question answering datasets; neural networks; Arabic question answering; QANet; BiDAF; BERT
AB Question answering (QA) is the task of responding to questions posed by users automatically. A questionanswering system is divided into three main components: question analysis, information retrieval, and answer extraction. This paper has focused only on the answer extraction part. In the past couple of years, many QA systems have been developed and become mature and ready for use in different languages. Nevertheless, the advancement of Arabic QA systems still faces different obstacles and a lack of relevant resources and tools for researchers. This paper presents the So2al-wa-Gwab dataset since the publicly available datasets include various faults, such as the use of machine translation to build the data, a short context size, and a small number of question-answer pairings. Thus, this new dataset avoids the aforementioned drawbacks. Furthermore, in this paper, we have trained three deep learning models, namely, Bi-Directional flow network (BiDAF), QA Network (QANet), and BERT model, and tested them on seven different datasets, thus providing a comprehensive comparison between existing Arabic QA datasets. The obtained results emphasize that machine-translated datasets fall backwhen comparedwith human-annotated data. Also, the QA task becomes harder as the context, from which to extract the answer, becomes larger.
C1 [Al-Omari, Hani; Duwairi, Rehab] Jordan Univ Sci & Technol, Dept Comp Informat Syst, POB 3030, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Al-Omari, H (通讯作者)，Jordan Univ Sci & Technol, Dept Comp Informat Syst, POB 3030, Irbid 22110, Jordan.
EM hbalomari19@cit.just.edu.jo; rehab@just.edu.jo
FU Jordan University of Science and Technology [20220095]
CR Abdelnasser Heba, 2014, P EMNLP 2014 WORKSHO, V0, P57
   Abdi A, 2020, COMPUT SPEECH LANG, V60, P0, DOI 10.1016/j.csl.2019.101023
   Ahmed Waheeb, 2017, INT J ENG RES, V6, P142
   Ahmed Waheeb, 2016, INT J COMPUTATIONAL, V12, P18
   Aizouky Zeina, 2020, THESIS U ALBERTA, V0, P0
   Akour Mohammed, 2011, AMERICAN JOURNAL OF APPLIED SCIENCES, V8, P652, DOI 10.3844/ajassp.2011.652.661
   Al-Asad Muntaha, 2021, THESIS JORDAN U SCI, V0, P0
   Al-Dabbagh Ula, 2010, 2 JORD INT C TRANSL, V0, P0
   Al-Shenak Moayeah, 2019, J THEOR APPL INF TEC, V97, P681
   Alqudsi A, 2014, ARTIF INTELL REV, V42, P549, DOI 10.1007/s10462-012-9351-1
   Alwaneen TH, 2022, ARTIF INTELL REV, V55, P207, DOI 10.1007/s10462-021-10031-1
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Antoun Wissam, 2021, P 6 AR NAT LANG PROC, V0, P191
   Ashi MM, 2019, ADV INTELL SYST COMP, V845, P241, DOI 10.1007/978-3-319-99010-1_22
   Atef Adel, 2020, 2020 IEEE ACS 17 INT, V0, P1
   Bekhti Sman, 2013, P RECENT ADV COMPUTE, V25, P19
   Benajiba Yassine, 2007, P WORKSH AR NAT LANG, V0, P3
   Biltawi MM, 2021, IEEE ACCESS, V9, P63876, DOI 10.1109/ACCESS.2021.3074950
   Brini Wissal, 2009, 2009 INT C NATURAL L, V0, P1
   Soares MAC, 2020, J KING SAUD UNIV-COM, V32, P635, DOI 10.1016/j.jksuci.2018.08.005
   Clark JH, 2020, T ASSOC COMPUT LING, V8, P454, DOI 10.1162/tacl_a_00317
   Devlin J, 2019, ARXIV, V0, P0
   Ezzeldin AM, 2013, LECT NOTES COMPUT SC, V8138, P100, DOI 10.1007/978-3-642-40802-1_12
   Hammo Bassam, 2002, P ACL 02 WORKSHOP CO, V0, P0
   Izwaini Sattar, 2006, P INT C CHALLENGE AR, V0, P0
   Jabak Omar, 2019, INT J LINGUISTICS LI, V0, P2617
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kaltenbacher M, 2000, BENJAMIN TRANSL LIB, V39, P221
   Kamal AI, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, V0, PP641, DOI 10.1109/CICN.2014.143
   Kurdi H, 2014, COMPUTER SCI INFORM, V4, P187
   Lewis P, 2020, P 58 ANN M ASS COMPU, V0, PP7315, DOI 10.18653/V1/2020.ACL-MAIN.653
   Mozannar H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), V0, P108
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Safaya A, 2020, P 14 WORKSH SEM EV, V0, P2054
   Seo M, 2018, ARXIV, V0, P0
   Shaalan Khaled, 2019, COMPUT LINGUIST, V0, P59
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu YH, 2016, ARXIV, V0, P0
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
   Yang ZL, 2019, ADV NEUR IN, V32, P0
   Yu Adams Wei, 2018, ARXIV180409541, V0, P0
NR 43
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG 15
PY 2023
VL 22
IS 8
BP 
EP 
DI 10.1145/3605550
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q7NS7
UT WOS:001059361200003
DA 2023-11-10
ER

PT J
AU Pan, M
   Li, T
   Liu, Y
   Pei, QL
   Huang, EA
   Huang, JX
AF Pan, Min
   Li, Teng
   Liu, Yu
   Pei, Quanli
   Huang, Ellen Anne
   Huang, Jimmy X.
TI A semantically enhanced text retrieval framework with abstractive summarization
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article; Early Access
DE BERT; document re-ranking; passage-level relevance; pretrained language models; semantic search
AB Recently, large pretrained language models (PLMs) have led a revolution in the information retrieval community. In most PLMs-based retrieval frameworks, the ranking performance broadly depends on the model structure and the semantic complexity of the input text. Sequence-to-sequence generative models for question answering or text generation have proven to be competitive, so we wonder whether these models can improve ranking effectiveness by enhancing input semantics. This article introduces SE-BERT, a semantically enhanced bidirectional encoder representation from transformers (BERT) based ranking framework that captures more semantic information by modifying the input text. SE-BERT utilizes a pretrained generative language model to summarize both sides of the candidate passage and concatenate them into a new input sequence, allowing BERT to acquire more semantic information within the constraints of the input sequence's length. Experimental results from two Text Retrieval Conference datasets demonstrate that our approach's effectiveness increasing as the length of the input text increases.
C1 [Pan, Min; Li, Teng; Liu, Yu] Hubei Normal Univ, Sch Comp & Informat Engn, Huangshi, Hubei, Peoples R China.
   [Pei, Quanli; Huang, Jimmy X.] York Univ, Sch Informat Technol, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
   [Huang, Ellen Anne] Western Univ, Dept Comp Sci, London, ON, Canada.
C3 Hubei Normal University; York University - Canada; Western University (University of Western Ontario)
RP Huang, JX (通讯作者)，York Univ, Sch Informat Technol, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
EM jhuang@yorku.ca
FU This research is supported by the Natural Sciences and Engineering Research Council (NSERC) of Canada, the York Research Chairs (YRC) program and an ORF-RE (Ontario Research Fund- Research Excellence) award in BRAIN Alliance. This research is also supporte; Natural Sciences and Engineering Research Council (NSERC) of Canada; York Research Chairs (YRC) program; ORF-RE (Ontario Research Fund- Research Excellence) award in BRAIN Alliance [62172144]; National Natural Science Foundation of China [2023AFB981]; Hubei Provincial Natural Science Foundation of China; China Scholarship Council (CSC), Innovation Fund [D20222501]; Hubei Normal University and Educational Commission of Hubei Province of China
CR Ai QY, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP135, DOI 10.1145/3209978.3209985
   Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP2387, DOI 10.1145/3477495.3531863
   Chen XY, 2021, ARXIV, V0, P0
   Dai ZY, 2019, ARXIV, V0, P0
   Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP985, DOI 10.1145/3331184.3331303
   Dong L, 2019, ADV NEUR IN, V32, P0
   Fan YX, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP375, DOI 10.1145/3209978.3209980
   Hofstätter S, 2021, SIGIR 21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1349, DOI 10.1145/3404835.3462889
   Huang XJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP307, DOI 10.1145/1571941.1571995
   Jian FH, 2020, COMPUT INTELL-US, V36, P486, DOI 10.1111/coin.12248
   Lewis M, 2019, ARXIV, V0, P0
   MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1101, DOI 10.1145/3331184.3331317
   Nallapati R, 2016, ARXIV, V0, P0
   Nogueira R, 2020, ARXIV, V0, P0
   Pan M, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2021.102734
   Pan M, 2020, J ASSOC INF SCI TECH, V71, P264, DOI 10.1002/asi.24241
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   ROBERTSON SE, 1977, J DOC, V33, P294, DOI 10.1108/eb026647
   Suleiman D, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/9365340
   Wang JM, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102342
   Wang PF, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP209, DOI 10.1145/3397271.3401134
   Wu ZJ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP605, DOI 10.1145/3331184.3331233
   Xia LH, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP70, DOI 10.1145/3477495.3532058
   Yang PL, 2018, ACM J DATA INF QUAL, V10, P0, DOI 10.1145/3239571
   Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P19
   Zhang Jingqing, 2020, P INT C MACH LEARN, V0, PP11328, DOI 10.1038/S41746-021-00437-0
   Zhao JS, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR11), V0, P155
   Zheng Z, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102672
NR 42
TC 0
Z9 0
U1 6
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0824-7935
EI 1467-8640
J9 COMPUT INTELL-US
JI Comput. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1111/coin.12603
EA SEP 2023
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA S7DN0
UT WOS:001072737300001
DA 2023-11-10
ER

PT J
AU Ksieniewicz, P
   Zyblewski, P
   Borek-Marciniec, W
   Kozik, R
   Choras, M
   Wozniak, M
AF Ksieniewicz, Pawel
   Zyblewski, Pawel
   Borek-Marciniec, Weronika
   Kozik, Rafal
   Choras, Michal
   Wozniak, Michal
TI <i>Alphabet</i><i> Flatting</i> as a variant of n-gram feature extraction method in ensemble classification of fake news
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Natural language processing; Pattern recognition; Fake news; Classifier ensemble; n-gram
AB The detection of disinformation becomes a significant challenge in the modern world. Most of our communica-tion media and most of the sources of information about reality are located on the distributed network services, where the published content is usually not a subject to any initial verification. One of the few tools that seem to be able to process such large volumes of data efficiently are pattern recognition methods employing extraction of features obtained through the Natural Language Processing models and procedures. The following paper is proposing an Alphabet Flatting - a modification of the preprocessing method for the feature extraction from large language corpora - allowing the construction of diverse classifier ensembles integrated by the support accumulation, the generalization power of which may compete with quality of the STATE-of-ThE-ART models in environments with strict time constraints. The proposed method has been thoroughly evaluated with the set of computer experiments, the results of which allow us to conclude its potential usefulness in the solutions of the automatic systems for preventing the spread of fake news.
C1 [Ksieniewicz, Pawel; Zyblewski, Pawel; Borek-Marciniec, Weronika; Wozniak, Michal] Wroclaw Univ Sci & Technol, Fac Informat & Commun Technol, Dept Syst & Comp Networks, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
   [Kozik, Rafal; Choras, Michal] Bydgoszcz Univ Sci & Technol, Inst Telecommun & Comp Sci, Bydgoszcz, Poland.
C3 Wroclaw University of Science & Technology; Bydgoszcz University of Science & Technology
RP Ksieniewicz, P (通讯作者)，Wroclaw Univ Sci & Technol, Fac Informat & Commun Technol, Dept Syst & Comp Networks, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM pawel.ksieniewicz@pwr.edu.pl; pawel.zyblewski@pwr.edu.pl; weronika.borek@pwr.edu.pl; rkozik@pbs.edu.pl; chorasm@pbs.edu.pl; michal.wozniak@pwr.edu.pl
FU Department of Systems and Computer Networks, Faculty of Information and Communication Technology, Wroclaw University of Science and Technology; Institute of Telecommunications and Computer Science, Bydgoszcz University of Science and Technology; National Center for Research and Development within INFOSTRATEG program [INFOSTRATEG-I/0019/2021-00]
CR Ahmed H, 2018, SECUR PRIVACY, V1, P0, DOI 10.1002/spy2.9
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   [Anonymous], 2019, ENISA STRENGTHENING, V0, P0
   Atodiresei CS, 2018, PROCEDIA COMPUT SCI, V126, P451, DOI 10.1016/j.procs.2018.07.279
   Barrón-Cedeño A, 2019, INFORM PROCESS MANAG, V56, P1849, DOI 10.1016/j.ipm.2019.03.005
   Bharadwaj P, 2019, INT J NAT LANG COMPU, V8, P0
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Brodersen Kay H, 2010, PROCEEDINGS OF THE 2010 20TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR 2010), V0, PP3121, DOI 10.1109/ICPR.2010.764
   Castillo C, 2011, P 20 INT C WORLD WID, V0, P675
   Choras M, 2021, APPL SOFT COMPUT, V101, P0, DOI 10.1016/j.asoc.2020.107050
   Dentith MRX, 2016, PROBLEM FAKE NEWS, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   Gereme F, 2021, INFORMATION, V12, P0, DOI 10.3390/info12010020
   Ghosh Souvick, 2018, PROCEEDINGS OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY, V55, P0, DOI 10.1002/pra2.2018.14505501125
   Giachanou A, 2020, LECT NOTES ARTIF INT, V12284, P30, DOI 10.1007/978-3-030-58323-1_3
   Giachanou A, 2020, LECT NOTES COMPUT SC, V12089, P181, DOI 10.1007/978-3-030-51310-8_17
   Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP877, DOI 10.1145/3331184.3331285
   Gomes HM, 2017, ACM COMPUT SURV, V50, P0, DOI 10.1145/3054925
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gruppi M, 2021, ARXIV, V0, P0
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hassan N, 2020, INT J INTELL ENG SYS, V13, P291, DOI 10.22266/IJIES2020.0229.27
   Hesse G, 2015, INT C PAR DISTRIB SY, V0, PP797, DOI 10.1109/ICPADS.2015.106
   Horne BD, 2017, P INT AAAI C WEB SOC, V0, P1
   Joulin A, 2016, ARXIV, V0, P0
   Jwa H, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9194062
   Kaur S, 2020, SOFT COMPUT, V24, P9049, DOI 10.1007/s00500-019-04436-y
   Kong SH, 2020, IEEE 10TH SYMPOSIUM ON COMPUTER APPLICATIONS AND INDUSTRIAL ELECTRONICS (ISCAIE 2020), V0, PP102, DOI 10.1109/iscaie47305.2020.9108841
   Ksieniewicz P, 2020, IEEE IJCNN, V0, P0, DOI DOI 10.1109/ijcnn48605.2020.9207498
   Ksieniewicz P, 2019, LECT NOTES COMPUT SC, V11872, P332, DOI 10.1007/978-3-030-33617-2_34
   Ksieniewicz P, 2019, NEUROCOMPUTING, V353, P74, DOI 10.1016/j.neucom.2018.05.130
   Kula Sebastian, 2021, 13TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN SECURITY FOR INFORMATION SYSTEMS (CISIS 2020). ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1267), V0, PP239, DOI 10.1007/978-3-030-57805-3_23
   Kumar S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5047
   Kurup L, 2019, P 2019 3 IEEE INT C, V0, P0, DOI DOI 10.1109/ICECCT. 2019.8869504
   Liu C, 2019, J BIOMED INFORM, V100, P0, DOI 10.1016/j.jbi.2019.103318
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Roy A, 2018, ARXIV, V0, P0
   Santafe G, 2015, ARTIF INTELL REV, V44, P467, DOI 10.1007/s10462-015-9433-y
   Saquete E, 2020, EXPERT SYST APPL, V141, P0, DOI 10.1016/j.eswa.2019.112943
   Tai KS, 2015, ARXIV, V0, P0
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM19), V0, PP312, DOI 10.1145/3289600.3290994
   Silva RM, 2020, EXPERT SYST APPL, V146, P0, DOI 10.1016/j.eswa.2020.113199
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Thelwall M, 2017, CYBEREMOTIONS, V0, PP119, DOI 10.1007/978-3-319-43639-5_7
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wynne HE, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, V0, PP669, DOI 10.1145/3366030.3366116
   Yang KC, 2019, ARXIV, V0, P0
   Zubiaga A, 2016, PHEME DATASET RUMOUR, V0, P0
NR 50
TC 1
Z9 1
U1 3
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD APR 15
PY 2023
VL 120
IS 
BP 
EP 
DI 10.1016/j.engappai.2023.105882
PG 11
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA 8P1HY
UT WOS:000926281900001
DA 2023-11-10
ER

PT J
AU Ivgi, M
   Shaham, U
   Berant, J
AF Ivgi, Maor
   Shaham, Uri
   Berant, Jonathan
TI Efficient Long-Text Understanding with Short-Text Models
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Transformer-based pretrained language models (LMs) are ubiquitous across natural language understanding, but cannot be applied to long sequences such as stories, scientific articles, and long documents due to their quadratic complexity. While a myriad of efficient transformer variants have been proposed, they are typically based on custom implementations that require expensive pretraining from scratch. In this work, we propose SLED: SLiding-Encoder and Decoder, a simple approach for processing long sequences that re-uses and leverages battle-tested short-text pretrained LMs. Specifically, we partition the input into overlapping chunks, encode each with a short-text LM encoder and use the pretrained decoder to fuse information across chunks (fusion-in-decoder). We illustrate through controlled experiments that SLED offers a viable strategy for long text understanding and evaluate our approach on SCROLLS, a benchmark with seven datasets across a wide range of language understanding tasks. We find that SLED is competitive with specialized models that are up to 50x larger and require a dedicated and expensive pretraining step.
C1 [Ivgi, Maor; Shaham, Uri; Berant, Jonathan] Tel Aviv Univ, Blavatnik Sch Comp Sci, Tel Aviv, Israel.
C3 Tel Aviv University
RP Ivgi, M (通讯作者)，Tel Aviv Univ, Blavatnik Sch Comp Sci, Tel Aviv, Israel.
EM maor.ivgi@cs.tau.ac.il; uri.shaham@cs.tau.ac.il; joberant@cs.tau.ac.il
FU Yandex Initiative for Machine Learning; Shashua Fellowship; Blavatnik Family Foundation; European Research Council (ERC) under the European Union Horizons 2020 research and innovation programme [802800]; European Research Council (ERC) [802800] Funding Source: European Research Council (ERC)
CR Ainslie J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P268
   Albert Gu, 2021, ARXIV, V0, P0
   Amouyal Samuel, 2022, ARXIV, V0, P0
   Beltagy I, 2020, ARXIV, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen MD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8602
   Choromanski Krzysztof, 2020, ARXIV200914794, V0, P0
   Conneau Alexis, 2020, ASS COMPUT LINGUIST, V0, PP8440, DOI 10.18653/v1/2020.acl-main.747
   Cui P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5881
   Dasigi P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P4599
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Guo Mandy, 2022, FINDINGS ASS COMPUTA, V0, PP724, DOI 10.18653/v1/2022.findings-naacl.55
   Gupta A, 2022, ARXIV, V0, P0
   Gupta A, 2020, ARXIV, V0, P0
   Huang L, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P1419
   Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P874
   Jiang YC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2726
   Kitaev Nikita, 2020, ARXIV200104451, V0, P0
   Kocisky T, 2018, T ASSOC COMPUT LING, V6, P317, DOI 10.1162/TACL_A_00023
   Koreeda Y, 2021, FINDINGS ASS COMPUTA, V0, PP1907, DOI 10.18653/v1/2021.findings-emnlp.164
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Ma X, 2021, ADV NEURAL INFORM PR, V0, P0
   Mehta Harsh, 2022, ARXIV, V0, P0
   Pang RY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P5336
   Peng H, 2021, 9 INT C LEARN REPR I, V0, P0
   Quentin Fournier Gaetan, 2021, PRACTICAL SURVEY FAS, V0, P0
   Raffel C, 2020, ARXIV, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Roy A, 2021, T ASSOC COMPUT LING, V9, P53, DOI 10.1162/tacl_a_00353
   Shaham Uri, 2022, ARXIV, V0, P0
   Sinong Wang, 2020, LINFORMER SELF ATTEN, V0, P0
   Tay Y, 2020, EFFICIENT TRANSFORME, V0, P0
   Tay Yi, 2021, INT C LEARN REPR, V1, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vig J, 2022, FINDINGS ASS COMPUTA, V0, P1455
   Wang ZG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5878
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xiong WH, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P1975
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2369
   Yavuz S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P974
   Yi Tay, 2022, ARXIV, V0, P0
   Zaheer M, 2020, ADV NEUR IN, V33, P0
   Zhong M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5905
NR 46
TC 0
Z9 0
U1 6
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 22
PY 2023
VL 11
IS 
BP 284
EP 299
DI 10.1162/tacl_a_00547
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA A3SB5
UT WOS:000954352100002
DA 2023-11-10
ER

PT J
AU Zamorski, M
   Stypulkowski, M
   Karanowski, K
   Trzcinski, T
   Zieba, M
AF Zamorski, Maciej
   Stypulkowski, Michal
   Karanowski, Konrad
   Trzcinski, Tomasz
   Zieba, Maciej
TI Continual learning on 3D point clouds with random compressed rehearsal
SO COMPUTER VISION AND IMAGE UNDERSTANDING
LA English
DT Article
DE Continual learning; Point cloud; Deep learning; Data compression
AB Contemporary deep neural networks offer state-of-the-art results when applied to visual reasoning, e.g., in the context of 3D point cloud data. Point clouds are an important data type for the precise modeling of three-dimensional environments, but effective processing of this type of data proves to be challenging. In the world of large, heavily-parameterized network architectures and continuously-streamed data, there is an increasing need for machine learning models that can be trained on additional data. Unfortunately, currently available models cannot fully leverage training on additional data without losing their past knowledge. Combating this phenomenon, called catastrophic forgetting, is one of the main objectives of continual learning. Continual learning for deep neural networks has been an active field of research, primarily in 2D computer vision, natural language processing, reinforcement learning, and robotics. However, in 3D computer vision, there are hardly any continual learning solutions specifically designed to take advantage of point cloud structure. This work proposes a novel neural network architecture capable of continual learning on 3D point cloud data. We utilize point cloud structure properties for preserving a heavily compressed set of past data. By using rehearsal and reconstruction as regularization methods of the learning process, our approach achieves a significant decrease of catastrophic forgetting compared to the existing solutions on several most popular point cloud datasets considering two continual learning settings: when a task is known beforehand, and in the challenging scenario of when task information is unknown to the model.
C1 [Zamorski, Maciej; Karanowski, Konrad; Zieba, Maciej] Wroclaw Univ Sci & Technol, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.
   [Stypulkowski, Michal] Univ Wroclaw, Pl Uniwersytecki 1, PL-50137 Wroclaw, Poland.
   [Trzcinski, Tomasz] Warsaw Univ Technol, Pl Politech 1, PL-00661 Warsaw, Poland.
   [Trzcinski, Tomasz; Zieba, Maciej] Tooploox, Teczowa 7, PL-53601 Wroclaw, Poland.
   [Trzcinski, Tomasz] Jaigellonian Univ Cracow, Lojasiewicza 6, PL-30348 Krakow, Poland.
C3 Wroclaw University of Science & Technology; University of Wroclaw; Warsaw University of Technology; Jagiellonian University
RP Zamorski, M (通讯作者)，Wroclaw Univ Sci & Technol, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM maciej.zamorski@pwr.edu.pl
FU National Centre of Science (Poland) [2020/37/B/ST6/03463]; Foundation for Polish Science - European Union under the European Regional Development Fund [2020/39/B/ST6/01511]; European Union under the European Regional Development Fund;  [POIR.04.04.00-00-14DE/18-00]
CR Rusu AA, 2016, ARXIV, V0, P0
   Belouadah E, 2021, NEURAL NETWORKS, V135, P38, DOI 10.1016/j.neunet.2020.12.003
   Chowdhury T, 2021, LECT NOTES COMPUT SC, V12861, P484, DOI 10.1007/978-3-030-85030-2_40
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   De Lange M, 2022, IEEE T PATTERN ANAL, V44, P3366, DOI 10.1109/TPAMI.2021.3057446
   Dong JH, 2021, AAAI CONF ARTIF INTE, V35, P6066
   Doshi K, 2022, P IEEE CVF WINT C AP, V0, P39613970
   Doshi Keval, 2020, P IEEE CVF C COMP VI, V0, P254
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R, V0, P0
   Ha David, 2017, ICLR, V1, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hsu Y-C, 2018, ADV NEURAL INFORM PR, V0, P0
   Kirichenko P, 2021, P ICML WORKSH INNF, V0, P0
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kolouri S, 2017, IEEE SIGNAL PROC MAG, V34, P43, DOI 10.1109/MSP.2017.2695801
   Li Z, 2017, 43RD EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC 2017), V0, P0, DOI DOI 10.1109/TPAMI.2017.2773081
   van de Ven GM, 2019, ARXIV, V0, P0
   Mai ZD, 2022, NEUROCOMPUTING, V469, P28, DOI 10.1016/j.neucom.2021.10.021
   Masana M, 2022, ARXIV, V0, P0
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Qi CR, 2017, ADV NEUR IN, V30, P5099
   Rebuffi S-A, 2017, PROC CVPR IEEE, V0, P0, DOI DOI 10.1109/CVPR.2017.587
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Shin H, 2017, ADV NEUR IN, V30, P0
   von Oswald J, 2020, INT C LEARNING REPRE, V0, P0
   Wu WW, 2019, IEEE INT NEW CIRC, V0, P0, DOI DOI 10.1109/newcas44328.2019.8961273
   Wu ZR, 2015, PROC CVPR IEEE, V0, PP1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, ARXIV, V0, P0
   Yang GD, 2019, IEEE I CONF COMP VIS, V0, PP4540, DOI 10.1109/ICCV.2019.00464
   Yoon J, 2022, INT C LEARNING REPRE, V0, P0
   Zenke F, 2017, PR MACH LEARN RES, V70, P0
NR 31
TC 1
Z9 1
U1 4
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1077-3142
EI 1090-235X
J9 COMPUT VIS IMAGE UND
JI Comput. Vis. Image Underst.
PD FEB 15
PY 2023
VL 228
IS 
BP 
EP 
DI 10.1016/j.cviu.2023.103621
EA JAN 2023
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 8J9NR
UT WOS:000922738500001
DA 2023-11-10
ER

PT J
AU Nareshkumar, MD
   Jaison, B
AF Nareshkumar, M. Daniel
   Jaison, B.
TI A Light-Weight Deep Learning-Based Architecture for Sign Language Classification
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Deep learning; machine learning; classification; filters; american sign language
ID model
AB With advancements in computing powers and the overall quality of images captured on everyday cameras, a much wider range of possibilities has opened in various scenarios. This fact has several implications for deaf and dumb people as they have a chance to communicate with a greater number of people much easier. More than ever before, there is a plethora of info about sign language usage in the real world. Sign languages, and by extension the datasets available, are of two forms, isolated sign language and continuous sign language. The main difference between the two types is that in isolated sign language, the hand signs cover individual letters of the alphabet. In continuous sign language, entire words' hand signs are used. This paper will explore a novel deep learning architecture that will use recently published large pre-trained image models to quickly and accurately recognize the alphabets in the American Sign Language (ASL). The study will focus on isolated sign language to demonstrate that it is possible to achieve a high level of classification accuracy on the data, thereby showing that interpreters can be implemented in the real world. The newly proposed MobileNetV2 architecture serves as the backbone of this study. It is designed to run on end devices like mobile phones and infer signals (what does it infer) from images in a relatively short amount of time. With the proposed architecture in this paper, the classification accuracy of 98.77% in the Indian Sign Language (ISL) and American Sign Language (ASL) is achieved, outperforming the existing state-of-the-art systems.
C1 [Nareshkumar, M. Daniel] RMK Engn Coll, Dept Elect & Commun Engn, Kavaraipettai 601206, India.
   [Jaison, B.] RMK Engn Coll, Dept Comp Sci & Engn, Kavaraipettai 601206, India.
C3 R.M.K. Engineering College; R.M.K. Engineering College
RP Nareshkumar, MD (通讯作者)，RMK Engn Coll, Dept Elect & Commun Engn, Kavaraipettai 601206, India.
EM mnr.ece@rmkec.ac.in
CR Alashhab S, 2019, ADV INTELL SYST COMP, V800, P45, DOI 10.1007/978-3-319-94649-8_6
   Ameen S, 2017, EXPERT SYST, V34, P0, DOI 10.1111/exsy.12197
   Anitha G, 2021, COMPUTER SYSTEMS SCI, V42, P7
   [Anonymous], 2018, AKASH ASL ALPHABET, V0, P0
   Bheda V, 2017, ARXIV, V0, P0
   Bousbai K, 2019, 2019 6 INT C IMAGE S, V0, PP1, DOI 10.1109/ISPA48434.2019.8966918
   Das A, 2018, P 2018 INT C SMART C, V0, PP1, DOI 10.1109/ICSCET.2018.8537248
   Elakkiya R, 2021, ISL CSLTR INDIAN SIG, V0, P0
   Ewald HM, 2016, REPORTS-BASEL, V0, P0
   Farah Sayeed R, 2015, INT J APPL ENG RES, V10, P8121
   Garcia B, 2016, CONVOLUTIONAL NEURAL, V2, P225
   Gowshika U, 2015, INT J APPL ENG RES, V10, P8125
   Jain DK, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2021.102758
   Jaishankar B, 2022, INTELL AUTOM SOFT CO, V32, P1815, DOI 10.32604/iasc.2022.021822
   Kanagavalli N, 2022, INTELL AUTOM SOFT CO, V33, P191, DOI 10.32604/iasc.2022.022720
   Kompally P, 2021, APPL SCI, V11, P1
   Mohan Prakash, 2013, AMERICAN JOURNAL OF APPLIED SCIENCES, V10, P924, DOI 10.3844/ajassp.2013.924.930
   Neelakandan S, 2022, INTELL AUTOM SOFT CO, V32, P1617, DOI 10.32604/iasc.2022.022209
   Neelakandan S, 2022, VIRTUAL AUGMENTED RE, V0, PP111, DOI 10.1007/978-3-030-94102-46
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Prakash M, 2012, EUR J SCI RES, V81, P450
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), V0, P0, DOI DOI 10.1109/ICCVW.2011.6130290
   Rajaraman PV, 2021, PATTERN RECOGN LETT, V152, P340, DOI 10.1016/j.patrec.2021.10.021
   Safaya K, 2013, IPASJ INT J INFORM T, V1, P1
   Satish Kumar T, 2022, INT J IMAGE GRAPH, V26, P1
   Satpathy S, 2019, J INTELL FUZZY SYST, V37, P7039, DOI 10.3233/JIFS-181577
   Sethuraman SC, 2021, IEEE CONSUM ELECTR M, V10, P17, DOI 10.1109/MCE.2020.3029769
   Singh H, 2022, OPTIK, V257, P0, DOI 10.1016/j.ijleo.2022.168789
   Sunitha G, 2022, IMAGE VISION COMPUT, V121, P0, DOI 10.1016/j.imavis.2022.104404
   Tripathy JK, 2021, COMPUT SCI REV, V42, P0, DOI 10.1016/j.cosrev.2021.100433
   Venu D, 2022, OPTIK, V252, P0, DOI 10.1016/j.ijleo.2021.168545
   Wathugala DM, 2002, P 4 INT INF TECHN C, V0, P72
NR 32
TC 0
Z9 0
U1 4
U2 8
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD JUN 15
PY 2023
VL 35
IS 3
BP 3501
EP 3515
DI 10.32604/iasc.2023.027848
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA 4Y2MA
UT WOS:000861363100014
DA 2023-11-10
ER

PT J
AU Zhou, J
   Li, F
   Teng, C
   Liu, YJ
   Xiang, CL
   Ji, DH
AF Zhou, Jun
   Li, Fei
   Teng, Chong
   Liu, Yijiang
   Xiang, Chunli
   Ji, Donghong
TI MOIT: A Novel task for mining opinions towards implicit targets
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Opinion mining; Implicit target; Sequence labeling; Question answering; Generation
ID network
AB The extraction of opinions and their corresponding targets has gained significant interest recently, as it offers valuable insights into Opinion Mining (OM) at a granular level. Opinion and target terms to be extracted by existing OM tasks need to be explicitly present in reviews. Targets that are not present but implied in contextual semantics, are neglected by existing OM tasks, even though an investigation reported that about 60% of reviews contain implicit targets. To enable implicit target extraction, a novel task named Mining Opinions towards Implicit Targets (MOIT) under the fine-grained OM, is proposed to extract both opinions and their corresponding implicit targets, enabling a more comprehensive analysis of reviews. To set up the basis for follow-up research on MOIT, two large-scale datasets were constructed as resources in two languages, where the Chinese dataset was built from scratch via a standard human annotation process, and the English dataset was built semi-automatically through machine translation and manual checking. Furthermore, three baseline models adapting three representative paradigms of information extraction, namely sequence labeling, question answering, and text generation, were proposed to solve MOIT. Extensive experiments demonstrated the effectiveness of the models. The proposed MOIT task extends the field of OM research, and the datasets and models establish a foundation for future studies in this area.
C1 [Zhou, Jun; Li, Fei; Teng, Chong; Liu, Yijiang; Xiang, Chunli; Ji, Donghong] Wuhan Univ, Sch Cyber Sci & Engn, Key Lab Aerosp Informat Secur & Trusted Comp, Minist Educ, Wuhan, Peoples R China.
C3 Wuhan University
RP Ji, DH (通讯作者)，Wuhan Univ, Sch Cyber Sci & Engn, Key Lab Aerosp Informat Secur & Trusted Comp, Minist Educ, Wuhan, Peoples R China.
EM dhji@whu.edu.cn
CR Akhtar MS, 2020, NEUROCOMPUTING, V398, P247, DOI 10.1016/j.neucom.2020.02.093
   Asheghi R, 2020, J HYDROINFORM, V22, P562, DOI 10.2166/hydro.2020.098
   Bashir U, 2013, APPL MATH COMPUT, V219, P10183, DOI 10.1016/j.amc.2013.03.110
   Breck E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2683
   Chen S, 2020, P 58 ANN M ASS COMP, V0, P6515
   Chen Z, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3685
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dai HL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5268
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dyer Chris, 2013, P 2013 C N AM CHAPTE, V0, P644
   Fan ZF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2509
   Frermann L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6263
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Han X, 2021, AI OPEN, V2, P225
   Hartman E, 2022, ARXIV, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Holighaus N, 2023, IEEE-ACM T AUDIO SPE, V31, P789, DOI 10.1109/TASLP.2023.3235197
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Khan K, 2014, J KING SAUD UNIV-COM, V26, P258, DOI 10.1016/j.jksuci.2014.03.009
   Khanna K, 2013, P 3 INT C SOFT COMPU, V0, P459
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lewis M, 2019, ARXIV, V0, P0
   Li K, 2020, P 58 ANN M ASS COMP, V0, PP7056, DOI 10.18653/v1/2020.acl-main.631
   Li X, 1900, P34, V0, P0
   Li X, 2019, AAAI CONF ARTIF INTE, V0, P6714
   Li ZH, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1783
   Liu P, 2016, P 25 INT JOINT C ART, V0, PP2873, DOI 10.48550/ARXIV.1605.05101
   Liu YJ, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102729
   Liu YL, 2022, IEEE T PATTERN ANAL, V44, P8048, DOI 10.1109/TPAMI.2021.3107437
   Luo RX, 2022, ARXIV, V0, P0
   Marasovic A, 2018, P 2018 C N AM CHAPTE, V0, P583
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Pang B, 2008, INFORM RETRIEVAL, V2, P1, DOI 10.1561/1500000011
   Peng HY, 2020, AAAI CONF ARTIF INTE, V34, P8600
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Quan W, 2019, IEEE INT CONF BIG DA, V0, PP2438, DOI 10.1109/BigData47090.2019.9006119
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Seo MJ, 2017, 5 INT C LEARNING REP, V0, P0
   Shahri AA, 2022, NAT RESOUR RES, V31, P1351, DOI 10.1007/s11053-022-10051-w
   Shao YF, 2022, ARXIV, V0, P0
   Sobkowicz P, 2012, GOV INFORM Q, V29, P470, DOI 10.1016/j.giq.2012.06.005
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Usman M, 2020, J ADV MECH DES SYST, V14, P0, DOI 10.1299/jamdsm.2020jamdsm0048
   Vaswani A, 2017, ARXIV, V30, P5998
   Wan H, 2020, AAAI CONF ARTIF INTE, V34, P9122
   Wang F, 2022, IEEE T AFFECT COMPUT, V0, P1
   Wang WY, 2019, AAAI CONF ARTIF INTE, V0, P7192
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Wu SQ, 2022, AAAI CONF ARTIF INTE, V0, P11513
   Wu Z, 2020, AAAI CONF ARTIF INTE, V34, P9298
   Xia QR, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P1795
   Xu JJ, 2019, ADV NEUR IN, V32, P0
   Xu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2339
   Yan H, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2416
   Ye CC, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP155, DOI 10.1145/3477495.3532063
   Zhang B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3249
   Zhangi MS, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P641
   Zhao H, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3239
   Zhen RR, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P10139
   Zhu EW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7096
NR 65
TC 0
Z9 0
U1 1
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD NOV 15
PY 2023
VL 126
IS 
BP 
EP 
DI 10.1016/j.engappai.2023.106841
PG 16
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA P7WS1
UT WOS:001052744700001
DA 2023-11-10
ER

PT J
AU Li, JL
   Zhang, ZS
   Zhao, H
AF Li, Junlong
   Zhang, Zhuosheng
   Zhao, Hai
TI Dialogue-adaptive language model pre-training from quality estimation
SO NEUROCOMPUTING
LA English
DT Article
DE Pre-trained language models; Dialogue-adaptive pre-training; Dialogue quality estimation; Open-domain dialogue systems
ID response selection
AB Pre-trained language models (PrLMs) have achieved great success on a wide range of natural language processing tasks by virtue of the universal language representation ability obtained by self-supervised learning on a large corpus. These models are pre-trained on standard plain texts with general language model (LM) training objectives, which would be insufficient to model dialogue-exclusive attributes like specificity and informativeness reflected in these tasks that are not explicitly captured by the pre -trained universal language representations. In this work, we propose dialogue-adaptive pre-training objectives (DAPO) derived from quality estimation to simulate dialogue-specific features, namely coher-ence, specificity, and informativeness. As the foundation for model pre-training, we synthesize a new dia-logue corpus and build our training set with two unsupervised methods: 1) coherence-oriented context corruption, including utterance ordering, insertion, and replacement, to help the model capture the coherence inside the dialogue contexts; and 2) specificity-oriented automatic rescoring, which encourages the model to measure the quality of the synthesized data for dialogue-adaptive pre-training by consid-ering specificity and informativeness. Experimental results on widely used open-domain response selec-tion and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of esti-mating quality evaluation factors into pre-training.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Li, Junlong; Zhang, Zhuosheng; Zhao, Hai] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Li, Junlong; Zhang, Zhuosheng; Zhao, Hai] Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interact, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.; Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interact, Shanghai, Peoples R China.
EM lockonn@sjtu.edu.cn; zhangzs@sjtu.edu.cn; zhaohai@cs.sjtu.edu.cn
FU Key Projects of National Natural Science Foundation of China;  [U1836222];  [61733011]
CR Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, V0, PP65, DOI 10.3115/1626355.1626389
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P85
   Barzilay Regina, 2005, P 43 ANN M ASS COMP, V0, PP141, DOI 10.3115/1219840.1219858
   Cervone A, 2018, INTERSPEECH, V0, P1011
   Clark Kevin, 2020, ICLR, V0, P0
   Cui LY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1406
   Devlin J, 1900, P4171, V0, P0, DOI DOI 10.18653/v1/N19-1423
   Gopalakrishnan K, 2019, INTERSPEECH, V0, PP1891, DOI 10.21437/Interspeech.2019-3079
   Gu JC, 2021, IEEE-ACM T AUDIO SPE, V29, P2443, DOI 10.1109/TASLP.2021.3074788
   Gu XD, 2021, ARXIV, V0, P0
   Henderson Matthew, 2020, FINDINGS ASS COMPUTA, V0, PP2161, DOI 10.18653/V1/2020.FINDINGS-EMNLP.196
   Kingma DP, 2014, C TRACK P, V0, P0
   Kumar P, 2020, AAAI CONF ARTIF INTE, V34, P8115
   Lan Zhenzhong, 2019, ABS190911942, V0, P0
   Le NQK, 2022, METHODS, V204, P199, DOI 10.1016/j.ymeth.2021.12.004
   Le NQK, 2021, BRIEF BIOINFORM, V22, P0, DOI 10.1093/bib/bbab005
   Li Yanran, 2017, IJCNLP, V0, P0
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu LX, 2021, AAAI CONF ARTIF INTE, V35, P13406
   Liu YH, 2019, ARXIV, V0, P0
   Liu YK, 2021, AAAI CONF ARTIF INTE, V35, P13433
   Lowe R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1116, DOI 10.18653/v1/P17-1103
   Lowe Ryan, 2015, P 16 ANN M SPECIAL I, V0, PP285, DOI 10.18653/v1/W15-4640
   Mehri S, 2020, SIGDIAL 2020: 21ST ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2020), V0, P225
   Mehri S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P681
   Mesgar M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1439
   Pang B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3619
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Ran Q, 2019, ARXIV, V0, P0
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Smith EM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2021
   Su YX, 2021, IEEE-ACM T AUDIO SPE, V29, P2152, DOI 10.1109/TASLP.2021.3087948
   Sun Y, 2019, ARXIV, V0, P0
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Tao CY, 2018, AAAI CONF ARTIF INTE, V0, P722
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401
   Voorhees Ellen, 2000, P 2 INT C LANG RES E, V0, P0
   Whang T, 2020, INTERSPEECH, V0, PP1585, DOI 10.21437/Interspeech.2020-2153
   Wolf T, 2019, TRANSFERTRANSFO TRAN, V0, P0
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P917
   Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046
   Xu RJ, 2020, ARXIV, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yeh Y-T, 2021, ARXIV, V0, P0
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang Tianyi, 2020, ICLR, V0, P0
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
   Zhang ZS, 2021, IEEE-ACM T AUDIO SPE, V29, P1161, DOI 10.1109/TASLP.2021.3058616
   Zhao TY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P26
   Zho XY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1118
NR 52
TC 1
Z9 1
U1 4
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 7
PY 2023
VL 516
IS 
BP 27
EP 35
DI 10.1016/j.neucom.2022.10.036
EA OCT 2022
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6N3KQ
UT WOS:000889456900003
DA 2023-11-10
ER

PT J
AU Chen, GY
   van Deemter, K
AF Chen, Guanyi
   van Deemter, Kees
TI Computational Modelling of Quantifier Use: Corpus, Models, and Evaluation
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
LA English
DT Article
ID natural-language generation; referring expressions; semantics; speakers; audience
AB A prominent strand of work in formal semantics investigates the ways in which human languages quantify the elements of a set, as when we say All A are B, Few A are B, and so on. Building on a growing body of empirical studies that shed light on the meaning and the use of quantifiers, we extend this line of work by computationally modelling how human speakers textually describe complex scenes in which quantitative relations play an important role. To this end, we conduct a series of elicitation experiments in which human speakers were asked to perform a linguistic task that invites the use of quantified expressions. The experiments result in a corpus, called QTUNA, made up of short texts that contain a large variety of quantified expressions. We analyse QTUNA, summarise our findings, and explain how we design computational models of human quantifier use accordingly. Finally, we evaluate these models in accordance with QTUNA.
C1 [Chen, Guanyi; van Deemter, Kees] Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
C3 Utrecht University
RP Chen, GY (通讯作者)，Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
EM g.chen@uu.nl; c.j.vandeemter@uu.nl
CR [Anonymous], 2014, THESIS, V0, P0
   Barr D, 2013, P 14 EUROPEAN WORKSH, V0, P157
   BARWISE J, 1981, LINGUIST PHILOS, V4, P159, DOI 10.1007/BF00350139
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Belz A, 2007, P UCNLG MT LANGUAGE, V0, P75
   Busemeyer JR, 2000, J MATH PSYCHOL, V44, P171, DOI 10.1006/jmps.1999.1282
   Chen G, 2020, P 13 INT C NATURAL L, V0, P263
   Chen G, 2022, FINDINGS ASS COMPUTA, V0, P73
   Chen G, 2022, THESIS UTRECHT U, V0, P0
   Chen G, 2019, P 12 INT C NATURAL L, V0, P529
   Chen G, 2019, P 12 INT C NAT LANG, V0, P124
   Coupland N, 2008, SOCIOLINGUISTICS REA, V0, P0
   Creaney N, 1996, 8 INT NAT LANG GEN W, V0, P0
   DALE R, 1995, COGNITIVE SCI, V19, P233, DOI 10.1207/s15516709cog1902_3
   Dale R, 2009, P 12 EUR WORKSH NAT, V0, PP58, DOI 10.3115/1610195.1610204
   Degen J, 2011, P ANN M COGN SCI SOC, V33, P0
   Degen J, 2020, PSYCHOL REV, V127, P591, DOI 10.1037/rev0000186
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Engelhardt PE, 2011, BRAIN COGNITION, V77, P304, DOI 10.1016/j.bandc.2011.07.004
   Engelhardt PE, 2006, J MEM LANG, V54, P554, DOI 10.1016/j.jml.2005.12.009
   Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633
   Franke M, 2014, P ANN M COGN SCI SOC, V0, P0
   Gatt A, 2007, PROCEEDPROCEEDINGS 1, V0, P49
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Geurts B, 2007, LANGUAGE, V83, P533, DOI 10.1353/lan.2007.0115
   Gibbs RW, 2012, TOP COGN SCI, V4, P7, DOI 10.1111/j.1756-8765.2011.01172.x
   Grice P, 1975, SYNTAX SEMANTICS, V3, P0, DOI 10.1163/9789004368811_003
   Herbelot A, 2015, P 2015 C EMPIRICAL M, V0, P22
   Holden JG, 2009, PSYCHOL REV, V116, P318, DOI 10.1037/a0014849
   Horton WS, 1996, COGNITION, V59, P91, DOI 10.1016/0010-0277(96)81418-1
   Howcroft DM, 2017, P 10 INT C NATURAL L, V0, P149
   Kamp H, 1993, DISCOURSE LOGIC INTR, V0, P0
   KAUFMAN EL, 1949, AM J PSYCHOL, V62, P498, DOI 10.2307/1418556
   Kenney R, 1996, VAGUENESS READER, V0, P0
   Koolen R, 2011, J PRAGMATICS, V43, P3231, DOI 10.1016/j.pragma.2011.06.008
   Kotek H, 2015, NAT LANG SEMANT, V23, P119, DOI 10.1007/s11050-015-9113-0
   Krahmer E, 2012, COMPUT LINGUIST, V38, P173, DOI 10.1162/COLI_a_00088
   Kutlak R, 2016, FRONT PSYCHOL, V7, P0, DOI 10.3389/fphyg.2016.01275
   Lappin S, 2000, LINGUIST PHILOS, V23, P599, DOI 10.1023/A:1005638918877
   Levinson Stephen C, 1983, CAMBRIDGE TXB LINGUI, V0, P0
   Lidz J, 2011, NAT LANG SEMANT, V19, P227, DOI 10.1007/s11050-010-9062-6
   Moxey LM, 1993, COMMUNICATING QUANTI, V0, P0
   Nouwen R, 2010, LINGUISTIC ENTERPRIS, V150, P235, DOI 10.1075/la.150.10nou
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   PECHMANN T, 1989, LINGUISTICS, V27, P89, DOI 10.1515/ling.1989.27.1.89
   Peters Stanley, 2006, QUANTIFIERS LANGUAGE, V0, P0
   Pezzelle S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2865
   Pezzelle S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P114
   Qing C, 2014, THESIS U AMSTERDAM, V0, P0
   Reiter E, 2000, BUILDING NATURAL LAN, V0, P41
   Same F, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5554
   Schmuckler MA, 2001, INFANCY, V2, P419, DOI 10.1207/S15327078IN0204_02
   Solt S, 2016, LANGUAGE, V92, P65, DOI 10.1353/lan.2016.0016
   Sorensen R, 2022, STANFORD ENCY PHILOS, V0, P0
   Sorodoc I, 2016, P 5 WORKSHOP VISION, V0, P75
   Sun R, 2008, CAMB HANDB PSYCHOL, V0, PP1, DOI 10.1017/CBO9780511816772
   Testoni A, 2019, P WORKSHOP COGNITIVE, V0, P105
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   van Deemter K, 2016, COMP MOD REF STUD, V0, P0
   van Deemter K, 2017, P 10 INT C NAT LANG, V0, P213
   van Deemter K, 2012, COGNITIVE SCI, V36, P799, DOI 10.1111/j.1551-6709.2011.01205.x
   van Gompel RPG, 2019, PSYCHOL REV, V126, P345, DOI 10.1037/rev0000138
   Viethen J, 2008, P 5 INT NATURAL LANG, V0, P59
   Yildirim I, 2013, P 35 ANN M COGN SCI, V0, P0
   Zajenkowski M, 2013, INTELLIGENCE, V41, P456, DOI 10.1016/j.intell.2013.06.020
NR 65
TC 0
Z9 0
U1 1
U2 1
PU AI ACCESS FOUNDATION
PI MARINA DEL REY
PA USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA
SN 1076-9757
EI 1943-5037
J9 J ARTIF INTELL RES
JI J. Artif. Intell. Res.
PD JUN 15
PY 2023
VL 77
IS 
BP 167
EP 206
DI 
PG 40
WC Computer Science, Artificial Intelligence
SC Computer Science
GA J5IB3
UT WOS:001009942300002
DA 2023-11-10
ER

PT J
AU Angamuthu, S
   Trojovsky, P
AF Angamuthu, Swathi
   Trojovsky, Pavel
TI Integrating multi-criteria decision-making with hybrid deep learning for sentiment analysis in recommender systems
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Multi-criteria decision making; Deep learning; Recommendation; Complex system; Decision making
ID word-of-mouth; evolution
AB Expert assessments with pre-defined numerical or language terms can limit the scope of decision-making models. We propose that decision-making models can incorporate expert judgments expressed in natural language through sentiment analysis. To help make more informed choices, we present the Sentiment Analysis in Recommender Systems with Multi-person, Multi-criteria Decision Making (SAR-MCMD) method. This method compiles the opinions of several experts by analyzing their written reviews and, if applicable, their star ratings. The growth of online applications and the sheer amount of available information have made it difficult for users to decide which information or products to select from the Internet. Intelligent decision-support technologies, known as recommender systems, leverage users' preferences to suggest what they might find interesting. Recommender systems are one of the many approaches to dealing with information overload issues. These systems have traditionally relied on single-grading algorithms to predict and communicate users' opinions for observed items. To boost their predictive and recommendation abilities, multi-criteria recommender systems assign numerous ratings to various qualities of products. We created, manually annotated, and released the technique in a case study of restaurant selection using 'TripAdvisor reviews', 'TMDB 5000 movies', and an 'Amazon dataset'. In various areas, cutting-edge deep learning approaches have led to breakthrough progress. Recently, researchers have begun to focus on applying these methods to recommendation systems, and different deep learning-based recommendation models have been suggested. Due to its proficiency with sparse data in large data systems and its ability to construct complex models that characterize user performance for the recommended procedure, deep learning is a formidable tool. In this article, we introduce a model for a multi-criteria recommender system that combines the best of both deep learning and multi-criteria decision-making. According to our findings, the suggested system may give customers very accurate suggestions with a sentiment analysis accuracy of 98%. Additionally, the metrics, accuracy, precision, recall, and F1 score are where the system truly shines, much above what has been achieved in the past.
C1 [Angamuthu, Swathi; Trojovsky, Pavel] Univ Hradec Kralove, Dept Math, Hradec Kralove, Czech Republic.
C3 University of Hradec Kralove
RP Angamuthu, S (通讯作者)，Univ Hradec Kralove, Dept Math, Hradec Kralove, Czech Republic.
EM swathianga-muthu@gmail.com
FU Project of Excellence, Faculty of Science, University of Hradec Kralove [2210/2023-2024]
CR Aljunid Mohammed Fadhel, 2020, PROCEDIA COMPUTER SCIENCE, V171, P829, DOI 10.1016/j.procs.2020.04.090
   Batmaz Z, 2019, ARTIF INTELL REV, V52, P1, DOI 10.1007/s10462-018-9654-y
   Berdeddouch A, 2020, 2020 INT C INTELLIGE, V0, P1
   Bo Pang, 2008, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V2, P1, DOI 10.1561/1500000001
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Buhalis D, 2008, TOURISM MANAGE, V29, P609, DOI 10.1016/j.tourman.2008.01.005
   Cao B, 2023, IEEE T IND INFORM, V19, P7636, DOI 10.1109/TFUZZ.2022.3141761
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P2133, DOI 10.1109/TITS.2020.3040909
   Cao H, 2022, FRONT PSYCHOL, V13, P0, DOI 10.3389/fpsyg.2022.900195
   Coccia M, 2020, TECHNOL SOC, V60, P0, DOI 10.1016/j.techsoc.2019.101198
   Dang CN, 2021, COMPLEXITY, V2021, P0, DOI 10.1155/2021/9986920
   Dang CN, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21165666
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9030483
   Dashtipour K, 2021, ENTROPY-SWITZ, V23, P0, DOI 10.3390/e23050596
   Dellarocas C, 2003, MANAGE SCI, V49, P1407, DOI 10.1287/mnsc.49.10.1407.17308
   Huang CQ, 2021, AUSTRALAS J EDUC TEC, V37, P81, DOI 10.14742/ajet.6749
   Indurkhya N, 2010, HDB NATURAL LANGUAGE, V2, P0
   Isinkaye FO, 2015, EGYPT INFORM J, V16, P261, DOI 10.1016/j.eij.2015.06.005
   Jeon G, 2020, MULTIMED TOOLS APPL, V79, P34129, DOI 10.1007/s11042-020-09232-7
   Jiang HB, 2021, IEEE ACM T NETWORK, V29, P2228, DOI 10.1109/TNET.2021.3084251
   Kastrati Z, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10101133
   Kastrati Z, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11093986
   Kong H, 2021, IEEE T MOBILE COMPUT, V20, P3148, DOI 10.1109/TMC.2020.2994955
   Kumar S, 2020, IEEE T COMPUT SOC SY, V7, P915, DOI 10.1109/TCSS.2020.2993585
   Li BK, 2023, MEMORY, V31, P918, DOI 10.1080/09658211.2023.2208792
   Li X, 2023, URBAN FOR URBAN GREE, V79, P0, DOI 10.1016/j.ufug.2022.127806
   Litvin SW, 2008, TOURISM MANAGE, V29, P458, DOI 10.1016/j.tourman.2007.05.011
   Liu H, 2023, TUNN UNDERGR SP TECH, V134, P0, DOI 10.1016/j.tust.2022.104861
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, V0, PP73, DOI 10.1007/978-0-387-85820-3_3
   Lu SY, 2023, INT J COMPUT INT SYS, V16, P0, DOI 10.1007/s44196-023-00233-6
   Lv ZH, 2022, ACM T MULTIM COMPUT, V18, P0, DOI 10.1145/3468506
   Lv ZH, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106300
   Mitkov R, 2022, OXFORD HDB COMPUTATI, V0, P0
   Mohammed SM, 2020, 2020 INT C ADV SCI E, V0, P0, DOI DOI 10.1109/ICOASE51841.2020.9436540
   Monti D, 2021, ARTIF INTELL REV, V54, P427, DOI 10.1007/s10462-020-09851-4
   Nassif AB, 2021, APPL SOFT COMPUT, V98, P0, DOI 10.1016/j.asoc.2020.106836
   Ni QF, 2022, IEEE T NETW SCI ENG, V9, P1187, DOI 10.1109/TNSE.2021.3137353
   Ni QF, 2023, IEEE T COMPUT SOC SY, V10, P819, DOI 10.1109/TCSS.2022.3148411
   Peng Y, 2023, INFORM SCIENCES, V621, P672, DOI 10.1016/j.ins.2022.11.101
   Peng ZN, 2020, APPL MATH COMPUT, V369, P0, DOI 10.1016/j.amc.2019.124821
   Quirk R, 1985, COMPREHENSIVE GRAMMA, V0, P0
   Rahman A, 2019, 2019 INT C BANGL SPE, V0, P1
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, V0, PP1, DOI 10.1007/978-0-387-85820-3_1
   Rosa RL, 2015, IEEE T CONSUM ELECTR, V61, P359, DOI 10.1109/TCE.2015.7298296
   Sánchez-Moreno D, 2020, 2020 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2020), V0, PP502, DOI 10.1109/WIIAT50758.2020.00075
   Shen XY, 2022, IEEE INTERNET THINGS, V9, P15538, DOI 10.1109/JIOT.2022.3181607
   Song FZ, 2022, IEEE T IND ELECTRON, V69, P13428, DOI 10.1109/TIE.2022.3142428
   Song FZ, 2022, IEEE T NEUR NET LEAR, V33, P1594, DOI 10.1109/TNNLS.2020.3042975
   Soubraylu S, 2021, COMPUT INTELL-US, V37, P735, DOI 10.1111/coin.12400
   Tian J, 2023, COMPLEX INTELL SYST, V9, P3887, DOI 10.1007/s40747-022-00910-7
   Tifrea A, 2018, ARXIV, V0, P0
   Wang H, 2023, IEEE T KNOWL DATA EN, V0, P1
   Wiebe J, 2004, COMPUT LINGUIST, V30, P277, DOI 10.1162/0891201041850885
   Wu B, 2023, J INT FINANC MARK I, V83, P0, DOI 10.1016/j.intfin.2022.101714
   Xie XL, 2022, NAT HAZARDS, V0, P0, DOI DOI 10.1007/s11069-022-05792-z
   Xiong ZG, 2022, J SIGNAL PROCESS SYS, V94, P1253, DOI 10.1007/s11265-022-01790-3
   Xu XF, 2022, INT J PROD RES, V60, P6772, DOI 10.1080/00207543.2021.1887534
   Yager RR, 1993, GROUP DECIS NEGOT, V2, P0, DOI 10.1007/BF01384404
   Yasen M, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), V0, PP860, DOI 10.1109/JEEIT.2019.8717422
   Yu JD, 2021, IEEE T MOBILE COMPUT, V20, P337, DOI 10.1109/TMC.2019.2947468
   Zhan CJ, 2023, EARTH-SCI REV, V239, P0, DOI 10.1016/j.earscirev.2023.104370
   Zhan CJ, 2022, WATER RESOUR RES, V58, P0, DOI 10.1029/2022WR033241
   Zhang GQ, 2016, OMEGA-INT J MANAGE S, V63, P69, DOI 10.1016/j.omega.2015.10.003
   Zhang JN, 2023, IEEE SYST J, V17, P4371, DOI 10.1109/JSYST.2023.3263865
   Zhang K, 2022, J PETROL SCI ENG, V208, P0, DOI 10.1016/j.petrol.2021.109766
   Zhao CY, 2020, ISA T, V101, P503, DOI 10.1016/j.isatra.2020.01.038
   Zheng WF, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12084059
   Zheng WF, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12073416
NR 68
TC 0
Z9 0
U1 12
U2 12
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD AUG 17
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1497
PG 27
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA P7RE3
UT WOS:001052600400001
PM 37705658
DA 2023-11-10
ER

PT J
AU Das, S
   Biswas, SK
   Purkayastha, B
AF Das, Soumen
   Biswas, Saroj Kr
   Purkayastha, Biswajit
TI A deep sign language recognition system for Indian sign language
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Machine learning; Deep learning; Key-frame; Sign language
ID framework
AB Deaf people face major challenges during communication with normal people. Employing a human interpreter (a person who converts Sign language (SL) into a language that the normal/hearing community can understand) is not an effective solution to this problem due to the unavailability of professional interpreters. Thus, the Sign Language Recognition System (SLRS) is the most efficient and effective choice because it automatically converts SL into text/speech without an interpreter and reduces the communication barrier between deaf and normal people. This paper reports a work on Indian Sign Language (ISL) word recognition using a vision-based technique. The existing vision-based solutions for ISL word recognition are ineffective due to excessive pre-processing such as extracting features from a large sequence of frames. Therefore, a vision-based SLRS named Hybrid CNN-BiLSTM SLR (HCBSLR) is proposed, which overcomes the drawback of excessive pre-processing. The proposed model uses a Histogram Difference (HD) based key-frame extraction method to improve the accuracy and efficiency of the system by eliminating redundant or useless frames. The HCBSLR system uses VGG-19 for spatial feature extraction and Bidirectional Long Short Term Memory (BiLSTM) for temporal feature extraction. The proposed HCBSLR system has achieved an average accuracy of 87.67%, which is compared with some of the existing SLRS. The experimental results show that the proposed HCBSLR system is more accurate and efficient than the existing SLRS.
C1 [Das, Soumen; Biswas, Saroj Kr; Purkayastha, Biswajit] NIT Silchar, Comp Sci & Engn, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Silchar
RP Das, S (通讯作者)，NIT Silchar, Comp Sci & Engn, Silchar, Assam, India.
EM soumen_rs@cse.nits.ac.in; saroj@cse.nits.ac.in; biswajit@nits.ac.in
CR Aly S, 2020, IEEE ACCESS, V8, P83199, DOI 10.1109/ACCESS.2020.2990699
   Aparna, 2020, CNN STACKED LSTM MOD, V0, PP126, DOI 10.1007/978-981-15-4301-2_10
   Aquib, 2019, 2019 IEEE C INFORM C, V0, P0
   Athira PK, 2022, J KING SAUD UNIV-COM, V34, P771, DOI 10.1016/j.jksuci.2019.05.002
   Breland DS, 2021, IEEE SENS J, V21, P10445, DOI 10.1109/JSEN.2021.3061608
   Choudhury A, 2014, INT CONF COMM SYST, V0, PP900, DOI 10.1109/CSNT.2014.185
   Dudhal Abhishek, 2019, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ISMAC IN COMPUTATIONAL VISION AND BIO-ENGINEERING 2018 (ISMAC-CVB).LECTURE NOTES IN COMPUTATIONAL VISION AND BIOMECHANICS (LNCVB 30), V0, PP727, DOI 10.1007/978-3-030-00665-5_72
   Dutta KK, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, V0, P0
   Gupta B, 2016, INT CONF COMP COMMUN, V0, P0
   Hatibaruah D, 2020, 2020 IEEE 17 IND COU, V0, P0
   Hore S, 2017, ADV INTELL SYST, V455, P553, DOI 10.1007/978-3-319-38771-0_54
   Jaiswal, 2020, IEEE 17 INDIA COUNCI, V0, P0
   Jayadeep G, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), V0, PP1228, DOI 10.1109/ICICCS48265.2020.9121144
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kumar NKS, 2020, INT J SPEECH TECHNOL, V23, P373, DOI 10.1007/s10772-020-09716-9
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Likhar P, 2020, IEEE ICCE, V0, P0, DOI DOI 10.1109/ICCE-Berlin50680.2020.9352194
   Mangamuri, 2019, 2 INT C ISSUES CHALL, V0, P0
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Patel U, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, V0, P0
   Raheja JL, 2016, PATTERN RECOGNITION AND IMAGE ANALYSIS, V26, P434, DOI 10.1134/S1054661816020164
   Rastgoo R, 2021, EXPERT SYST APPL, V164, P0, DOI 10.1016/j.eswa.2020.113794
   Sheena CV, 2015, PROCEDIA COMPUT SCI, V70, P36, DOI 10.1016/j.procs.2015.10.021
   Singh DK, 2021, PROCEDIA COMPUT SCI, V189, P76, DOI 10.1016/j.procs.2021.05.071
   Sonare B, 2021, 2 INT C EMERGING TEC, V0, P1
   Sridhar A, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1366, DOI 10.1145/3394171.3413528
   Sruthi CJ, 2019, 2019 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), V0, PP0596, DOI 10.1109/ICCSP.2019.8698006
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Taskiran M, 2018, 2018 41ST INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), V0, PP258, DOI 10.1109/TSP.2018.8441304
   Venugopalan A, 2021, EXPERT SYST APPL, V185, P0, DOI 10.1016/j.eswa.2021.115601
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
NR 31
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JAN 15
PY 2023
VL 35
IS 2
BP 1469
EP 1481
DI 10.1007/s00521-022-07840-y
EA SEP 2022
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 7W3XR
UT WOS:000860423400004
DA 2023-11-10
ER

PT J
AU Saedi, A
   Fatemi, A
   Nematbakhsh, MA
AF Saedi, Arezoo
   Fatemi, Afsaneh
   Nematbakhsh, Mohammad Ali
TI Representation-centric approach for classification of Consumer Health Questions
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Question classification; Consumer health question; Question answering; Natural language processing; Machine learning
ID clinical questions
AB Question Classification is the very first and pivotal step in Question Answering(QA) systems. It maps a given question into a predefined class. Classification of Consumer Health Questions contributes to answering medical queries of non-expert users. It plays a principal role in the performance of Consumer Health Question Answering systems. There are several approaches to the classification of questions. However, they do not consider the nature of Consumer Health Questions. In this study, we perform experiments focusing on the question representation methods to classify Consumer Health Questions accurately. These experiments provide an intuition of practical considerations for Consumer Health Question classification. The questions were represented through certain manually-designed features, word embedding, sentence embedding, and finetuning-based techniques. We create question classifiers that involve designing models for representing and categorizing questions. Based on the result, the fine-tuned Bidirectional Encoder Representations from Transformers(BERT)-large-based model with an accuracy of 86.00% on Genetic and Rare Diseases (GARD) and 80.40% on Yahoo! Answers-based datasets outperform previous works. In addition, the method based on A Robustly Optimized BERT Pretraining Approach(RoBERTa)-large model with 86.20% accuracy surpasses fine-tuned BERT-large model on the GARD dataset. Examining the outcomes of the models gives insight into decisive considerations for representing and classifying Consumer Health Questions.
C1 [Saedi, Arezoo; Fatemi, Afsaneh; Nematbakhsh, Mohammad Ali] Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
   [Saedi, Arezoo] Paris Saclay Univ, Paris, France.
C3 University of Isfahan; Universite Paris Saclay
RP Fatemi, A (通讯作者)，Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
EM a.saedi@eng.ui.ac.ir; a_fatemi@eng.ui.ac.ir; mnematbakhsh@eng.ui.ac.ir
CR Abacha AB, 2017, P 26 TEXT RETR C TRE, V0, P1
   Addair T, 2017, STANFORD U J, V0, P0
   [Anonymous], 2005, P HUMAN LANGUAGE TEC, V0, P0
   [Anonymous], 2021, UMLS METATHESAURUS B, V0, P0
   [Anonymous], 2009, P 2009 C EMPIRICAL M, V0, P0
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Camacho-Collados J, 2018, ARXIV, V0, P0
   Chen QY, 2019, IEEE INT CONF HEALT, V0, P246
   Cronin Robert M, 2015, AMIA ANNU SYMP PROC, V2015, P1861
   Deardorff A, 2017, J ASSOC INF SCI TECH, V68, P1724, DOI 10.1002/asi.23806
   Devlin J, 2019, ARXIV, V0, P0
   Ely JW, 2000, BRIT MED J, V321, P429, DOI 10.1136/bmj.321.7258.429
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Guo HH, 2018, BMC MED INFORM DECIS, V18, P0, DOI 10.1186/s12911-018-0593-y
   Hakim AN, 2017, INT C ADV COMP SCI I, V0, PP222, DOI 10.1109/ICACSIS.2017.8355037
   Hogan D, 2011, DECREASING LEXICAL D, V0, P0
   Houston TK, 2002, J MED INTERNET RES, V4, P0, DOI 10.2196/jmir.4.2.e7
   Huang Z, 2008, P C EMP METH NAT LAN, V0, P927
   Jalan R, 2018, LECT NOTES COMPUT SC, V10772, P45, DOI 10.1007/978-3-319-76941-7_4
   Jurafsky D, 2014, SPEECH LANGUAGE PROC, V2nd, P0
   Kearns William R, 2018, AMIA ANNU SYMP PROC, V2018, P634
   Kim Y, 2014, ARXIV, V0, P0
   Kolomiyets O, 2011, INFORM SCIENCES, V181, P5412, DOI 10.1016/j.ins.2011.07.047
   Kraljevic Z, 2021, ARTIF INTELL MED, V117, P0, DOI 10.1016/j.artmed.2021.102083
   Li X, 2002, P 19 INT C COMPUTATI, V1, P0
   Li X, 2018, LECT NOTES ARTIF INT, V10619, P114, DOI 10.1007/978-3-319-73618-1_10
   Liu FF, 2011, J BIOMED INFORM, V44, P1032, DOI 10.1016/j.jbi.2011.08.008
   Liu YH, 2019, ARXIV, V0, P0
   Llanos LC, 2017, BIONLP, V0, P333
   Loni B, 2011, 2011 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU), V0, PP437, DOI 10.1109/ASRU.2011.6163971
   Loni B, 2011, SURVEY STATE ART MET, V0, P0
   Loni B, 2011, LECT NOTES ARTIF INT, V6836, P243, DOI 10.1007/978-3-642-23538-2_31
   Matsumoto S, 2005, LECT NOTES ARTIF INT, V3518, P301
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Mikolov T, 2013, ARXIV, V0, P0
   Mishra M, 2013, INT J WEB SEMANTIC T, V4, P39, DOI 10.5121/ijwest.2013.4304
   Mohasseb A, 2018, INFORM PROCESS MANAG, V54, P1228, DOI 10.1016/j.ipm.2018.05.001
   Pagliardini M, 2018, ARXIV, V0, P0
   Patrick J, 2012, J BIOMED INFORM, V45, P292, DOI 10.1016/j.jbi.2011.11.008
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Quan XJ, 2011, IEEE T PATTERN ANAL, V33, P1009, DOI 10.1109/TPAMI.2010.154
   Reimers N, 2019, ARXIV, V0, P0
   Rivas R, 2018, J MED INTERNET RES, V20, P0, DOI 10.2196/11141
   Roberts K, 2014, P 4 LREC WORKSH BUIL, V0, P0
   Roberts Kirk, 2014, AMIA ANNU SYMP PROC, V2014, P1018
   Seidakhmetov T, 2020, ARXIV, V0, P0
   Sidorov G, 2012, MEXICAN INT C ARTIFI, V0, PP1, DOI 10.1007/978-3-642-37798-3_1
   Silva J, 2011, ARTIF INTELL REV, V35, P137, DOI 10.1007/s10462-010-9188-4
   Tayyar Madabushi H, 2016, P COLING 2016 26 INT, V0, P1220
   Van-Tu N, 2016, INDIAN J SCI TECHNOL, V9, P1
   Xin Li, 2006, NATURAL LANGUAGE ENGINEERING, V12, P229, DOI 10.1017/S1351324905003955
   Yilmaz T, 2019, INFORM PROCESS MANAG, V56, P228, DOI 10.1016/j.ipm.2018.10.013
   Yu Hong, 2008, AMIA ANNU SYMP PROC, V0, P96
   Zhang D, 2003, P 26 ANN INT ACM SIG, V0, PP26, DOI 10.1145/860435.860443
   Zhang Ye, 2016, ARXIV, V0, P0
   Zhang YJ, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0055-0
NR 56
TC 0
Z9 0
U1 2
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 1
PY 2023
VL 229
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120436
EA MAY 2023
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA J8MX1
UT WOS:001012121200001
DA 2023-11-10
ER

PT J
AU Ma, CP
   Shen, AL
   Yoshikawa, H
   Iwakura, T
   Beck, D
   Baldwin, T
AF Ma, Chunpeng
   Shen, Aili
   Yoshikawa, Hiyori
   Iwakura, Tomoya
   Beck, Daniel
   Baldwin, Timothy
TI On the Effectiveness of Images in Multi-modal Text Classification: An Annotation Study
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Datasets; neural networks; natural language processing; text classification; multi-modality
AB Combining different input modalities beyond text is a key challenge for natural language processing. Previous work has been inconclusive as to the true utility of images as a supplementary information source for text classification tasks, motivating this large-scale human study of labelling performance given text-only, images-only, or both text and images. To this end, we create a new dataset accompanied with a novel annotation method-Japanese Entity Labeling with Dynamic Annotation-to deepen our understanding of the effectiveness of images for multi-modal text classification. By performing careful comparative analysis of human performance and the performance of state-of-the-art multi-modal text classification models, we gain valuable insights into differences between human and model performance, and the conditions under which images are beneficial for text classification.
C1 [Ma, Chunpeng] Fujitsu Ltd, 4-1-1 Kamikodanaka, Kawasaki, Kanagawa 2118588, Japan.
   [Shen, Aili; Yoshikawa, Hiyori; Iwakura, Tomoya] Amazon, Sydney, NSW, Australia.
   [Beck, Daniel; Baldwin, Timothy] Univ Melbourne, Melbourne, Vic, Australia.
   [Baldwin, Timothy] Mohamed Bin Zayed Univ Artificial Intelligence, Abu Dhabi, U Arab Emirates.
C3 Fujitsu Ltd; University of Melbourne; Mohamed Bin Zayed University of Artificial Intelligence
RP Ma, CP (通讯作者)，Fujitsu Ltd, 4-1-1 Kamikodanaka, Kawasaki, Kanagawa 2118588, Japan.
EM chunpeng@fujitsu.com; ailishen@amazon.com; y.hiyori@fujitsu.com; iwakura.tomoya@fujitsu.com; beck.d@unimelb.edu.au; tbaldwin@unimelb.edu.au
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Bin Liang, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP4707, DOI 10.1145/3474085.3475190
   Caglayan O, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4159
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Elliott Desmond, 2016, P 5 WORKSHOP VISION, V0, P0
   Geva M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1161
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lin YK, 2015, AAAI CONF ARTIF INTE, V0, P2181
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Ma CP, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P42
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Sekine Satoshi, 2018, P AUTOMATED KNOWLEDG, V0, P0
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shen AL, 2020, J ARTIF INTELL RES, V68, P607
   Su Weijie, 2020, ICLR, V0, P0
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yoshikawa Hiyori, 2020, P 15 NTCIR C EVALUAT, V0, P201
   Zellers R, 2019, PROC CVPR IEEE, V0, PP6713, DOI 10.1109/CVPR.2019.00688
NR 22
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2023
VL 22
IS 3
BP 
EP 
DI 10.1145/3565572
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FA8
UT WOS:000998922200017
DA 2023-11-10
ER

PT J
AU Ihsan, I
   Rahman, H
   Shaikh, A
   Sulaiman, A
   Rajab, K
   Rajab, A
AF Ihsan, Imran
   Rahman, Hameedur
   Shaikh, Asadullah
   Sulaiman, Adel
   Rajab, Khairan
   Rajab, Adel
TI Improving in-text citation reason extraction and classification using supervised machine learning techniques
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Citation reason classification; Machine learning; Supervised learning
ID agreement
AB In the last decade, automatic extraction and classification of in-text citations have received immense popularity and have become one of the most frequently used techniques to evaluate research. Due to the large volume of in-text citations in various digital libraries such as Web of Science, Scopus, Google Scholar, Microsoft Academic, etc., machine learning models and natural language processing techniques are being used to extract, classify, and analyze them. Typical automatic in-text classification techniques use sentiment-based classes (Positive, Negative, and Neutral). However, there are cognitive-based schemes as well that classify in-text citations based on the author's perspective. In such schemes, extracting citation reasons with high recall is challenging. To address this challenge, we have used eight citations' context and reason classes defined by CCRO (Citation's Context and Reasons Ontology) to develop a machine learning model to achieve high recall without compromising on precision. We have worked on Association for Computational Linguistics Corpus with over 7000 in-text citations, randomly annotated by experts in CCRO classes. Afterwards, an array of machine-learning models is implemented on the annotated dataset: Support Vector Machine (SVM), Naive Bayesian (NB), and Random Forest (RF). We have used various part-of-speech (Nouns, Verbs, Adverbs, and Adjectives) as novel features. Our results show that we have outperformed the three comparative models by achieving 91% accuracy.
C1 [Ihsan, Imran; Rahman, Hameedur] Air Univ, Dept Creat Technol, Islamabad 44000, Punjab, Pakistan.
   [Shaikh, Asadullah] Najran Univ, Coll Comp Sci & Informat Syst, Dept Informat Syst, Najran 61441, Saudi Arabia.
   [Sulaiman, Adel; Rajab, Khairan; Rajab, Adel] Najran Univ, Coll Comp Sci & Informat Syst, Dept Comp Sci, Najran 61441, Saudi Arabia.
C3 Air University Islamabad; Najran University; Najran University
RP Shaikh, A (通讯作者)，Najran Univ, Coll Comp Sci & Informat Syst, Dept Informat Syst, Najran 61441, Saudi Arabia.
EM imranihsan@mail.au.edu.pk; hameed.rahman@mail.au.edu.pk; asshaikh@nu.edu.sa; aaalsulaiman@nu.edu.sa; kdrajab@nu.edu.sa; adrajab@nu.edu.sa
FU Deanship of Scientific Research at Najran University [NU/RG/SERC/12/33]
CR Aljuaid H, 2021, TELEMAT INFORM, V56, P0, DOI 10.1016/j.tele.2020.101492
   Amjad Z, 2020, INT J ADV COMPUT SC, V11, P621
   An X, 2023, J INF SCI, V49, P107, DOI 10.1177/0165551521991034
   [Anonymous], 1973, ESSAYS INFORM SCI, V0, P0
   Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2
   Athar A, 2011, P ACL 2011 STUD SESS, V0, P81
   Athar A, 2012, P 2012 C N AM CHAPT, V0, P597
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Butt BH, 2015, CEUR WORKSHOP PROC, V0, P18
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dong C, 2011, P 5 INT JOINT C NAT, V0, PP623, DOI 10.1177/0306312714522871
   John GH, 2013, ARXIV, V0, P0
   Halil K, 2019, J BIOMED INFORM, V91, P103
   Han Xu EM, 2013, P 13 C PACIFIC ASS C, V0, P1
   Hernandez A, 2014, P 1 WORKSHOP ARGUMEN, V0, P102
   Hernández-Alvarez M, 2017, NAT LANG ENG, V23, P561, DOI 10.1017/S1351324916000346
   Honnibal Matthew, 2017, SPACY 2 NATURAL LANG, V0, P0
   Ihsan I, 2019, CORP J CORPUS LINGUI, V2, P25
   Ihsan I, 2022, IEEE ACCESS, V10, P13525, DOI 10.1109/ACCESS.2022.3145954
   Ihsan I, 2021, SCIENTOMETRICS, V126, P4769, DOI 10.1007/s11192-021-03955-6
   Ihsan I, 2019, IEEE ACCESS, V7, P30423, DOI 10.1109/ACCESS.2019.2903450
   Jha R, 2017, NAT LANG ENG, V23, P93, DOI 10.1017/S1351324915000443
   Jochim C, 2012, P 24 INT C COMP LING, V0, P0
   Jurgens D, 2018, T ASS COMPUT LINGUIS, V6, P391, DOI 10.1162/tacl_a_00028
   Kazi PAH, 2016, P IEEE INT C COMPUTE, V0, P1
   Khadidja B, 2018, P INT C CONTR ART IN, V0, P43
   Kim IC, 2015, IEEE P CIBCB 12 AUG, V0, P1
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li X, 2013, P INT C REC ADV NAT, V0, P402
   Loper E, 2002, P ACL 02 WORKSHOP EF, V1, P63, DOI 10.3115/1118108.1118117
   Lyu D, 2021, SCIENTOMETRICS, V0, P1588
   Meng J, 2018, THESIS U W ONTARIO, V0, P0
   Mingyang W, 2020, SCIENTOMETRICS, V125, P21
   Qayyum F, 2019, SCIENTOMETRICS, V118, P21, DOI 10.1007/s11192-018-2961-x
   Radev DR, 2013, LANG RESOUR EVAL, V47, P919, DOI 10.1007/s10579-012-9211-2
   Stanger N, 2010, P 10 ANN JOINT C DIG, V0, PP293, DOI 10.1145/1816123.1816168
   Taimoor R, 2020, THESIS CAPITAL U SCI, V0, P0
   Tandon N, 2012, 35 GERM C ART INT, V0, P98
   Taskin Z, 2018, SCIENTOMETRICS, V114, P335, DOI 10.1007/s11192-017-2560-2
   Teufel S, 2006, P 7 SIGDIAL WORKSH D, V0, PP80, DOI 10.3115/1654595.1654612
   Tuarob S, 2020, IEEE T KNOWL DATA EN, V32, P1881, DOI 10.1109/TKDE.2019.2913376
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P417
   Valenzuela M, 2015, AAAI WORKSH SCHOL BI, V0, P0
   Wan XJ, 2014, J ASSOC INF SCI TECH, V65, P1929, DOI 10.1002/asi.23083
   Wilson T, 2009, COMPUT LINGUIST, V35, P399, DOI 10.1162/coli.08-012-R1-06-90
   Wilson Theresa, 2005, P HUMAN LANGUAGE TEC, V0, PP347, DOI 10.3115/1220575.1220619
   Xin A, 2022, SCIENTOMETRICS, V0, P0
   Xu Jun, 2015, AMIA ANNU SYMP PROC, V2015, P1334
   Zhao H, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1041, DOI 10.1145/3331184.3331348
NR 50
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL 15
PY 2023
VL 82
IS 
BP 
EP 
DI 10.1016/j.csl.2023.101526
EA JUN 2023
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K5YL6
UT WOS:001017194300001
DA 2023-11-10
ER

PT J
AU Sandouka, R
   Aljamaan, H
AF Sandouka, Rana
   Aljamaan, Hamoud
TI Python code smells detection using conventional machine learning models
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Python; Code smell; Detection; Machine learning; Large class; Long method
AB Code smells are poor code design or implementation that affect the code maintenance process and reduce the software quality. Therefore, code smell detection is important in software building. Recent studies utilized machine learning algorithms for code smell detection. However, most of these studies focused on code smell detection using Java programming language code smell datasets. This article proposes a Python code smell dataset for Large Class and Long Method code smells. The built dataset contains 1,000 samples for each code smell, with 18 features extracted from the source code. Furthermore, we investigated the detection performance of six machine learning models as baselines in Python code smells detection. The baselines were evaluated based on Accuracy and Matthews correlation coefficient (MCC) measures. Results indicate the superiority of Random Forest ensemble in Python Large Class code smell detection by achieving the highest detection performance of 0.77 MCC rate, while decision tree was the best performing model in Python Long Method code smell detection by achieving the highest MCC Rate of 0.89.
C1 [Sandouka, Rana; Aljamaan, Hamoud] King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP Aljamaan, H (通讯作者)，King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran, Saudi Arabia.
EM hjamaan@kfupm.edu.sa
CR Al-Shaaby A, 2020, ARAB J SCI ENG, V45, P2341, DOI 10.1007/s13369-019-04311-w
   Alazba A, 2021, INFORM SOFTWARE TECH, V138, P0, DOI 10.1016/j.infsof.2021.106648
   Aljamaan H, 2021, 20TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2021), V0, PP897, DOI 10.1109/ICMLA52953.2021.00148
   Amorim L, 2015, 2015 IEEE 26TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING (ISSRE), V0, PP261, DOI 10.1109/ISSRE.2015.7381819
   [Anonymous], 2010, INT J INFORM TECHNOL, V0, P0, DOI DOI 10.1007/S12031-014-0367-7
   [Anonymous], 2011, P 2 WORKSHOP MANAGIN, V0, P0, DOI DOI 10.1145/1985362.1985366
   [Anonymous], 2016, INT J COMPUTER SCI S, V0, P0
   Azeem MI, 2019, INFORM SOFTWARE TECH, V108, P115, DOI 10.1016/j.infsof.2018.12.009
   BASILI VR, 1988, IEEE T SOFTWARE ENG, V14, P758, DOI 10.1109/32.6156
   Beazley DM, 2009, PYTHON ESSENTIAL REF, V0, P0
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Chen ZF, 2016, 2016 INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P18, DOI 10.1109/SATE.2016.10
   Chicco D, 2021, IEEE ACCESS, V9, P78368, DOI 10.1109/ACCESS.2021.3084050
   Chicco D, 2020, BMC GENOMICS, V21, P0, DOI 10.1186/s12864-019-6413-7
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dewangan S, 2022, INTELLIGENT SYSTEMS, V0, P257
   Di Nucci D, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P612, DOI 10.1109/SANER.2018.8330266
   Fontana FA, 2016, EMPIR SOFTW ENG, V21, P1143, DOI 10.1007/s10664-015-9378-4
   Fowler M, 2018, REFACTORING IMPROVIN, V0, P0
   Guggulothu T, 2020, SOFTWARE QUAL J, V28, P1063, DOI 10.1007/s11219-020-09498-y
   Jain S, 2021, SCI COMPUT PROGRAM, V212, P0, DOI 10.1016/j.scico.2021.102713
   Khomh F, 2011, J SYST SOFTWARE, V84, P559, DOI 10.1016/j.jss.2010.11.921
   Kim DK, 2017, INT J ELECT COMPUT E, V7, P3613, DOI 10.11591/ijece.v7i6.pp3613-3621
   Kreimer J, 2005, ELECTRON NOTES THEOR, V141, P117, DOI 10.1016/j.entcs.2005.02.059
   Lacerda G, 2020, J SYST SOFTWARE, V167, P0, DOI 10.1016/j.jss.2020.110610
   Lenarduzzi V, 2019, 15TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING (PROMISE19), V0, PP2, DOI 10.1145/3345629.3345630
   Leopold H, 2014, IEEE T SOFTWARE ENG, V40, P818, DOI 10.1109/TSE.2014.2327044
   Lutz M, 2009, PROGRAMMING PYTHON P, V4th, P0
   Madeyski Lech, 2020, EASE2020. PROCEEDINGS OF THE EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING, V0, PP342, DOI 10.1145/3383219.3383264
   Menshawy RS, 2021, 2021 INT MOB INT UB, V0, P78
   Mhawish MY, 2020, J COMPUT SCI TECH-CH, V35, P1428, DOI 10.1007/s11390-020-0323-7
   Moha N, 2010, IEEE T SOFTWARE ENG, V36, P20, DOI 10.1109/TSE.2009.50
   Palomba F, 2018, EMPIR SOFTW ENG, V23, P1188, DOI 10.1007/s10664-017-9535-z
   Sharma T, 2021, IEEE WORK CONF MIN S, V0, PP590, DOI 10.1109/MSR52588.2021.00080
   Sharma T, 2021, J SYST SOFTWARE, V176, P0, DOI 10.1016/j.jss.2021.110936
   Singh D, 2020, APPL SOFT COMPUT, V97, P0, DOI 10.1016/j.asoc.2019.105524
   Srinath KR, 2017, INT RES J ENG TECHNO, V4, P354
   Tantithamthavorn C, 2017, IEEE T SOFTWARE ENG, V43, P1, DOI 10.1109/TSE.2016.2584050
   Tempero E, 2010, ASIA PAC SOFWR ENG, V0, PP336, DOI 10.1109/APSEC.2010.46
   Tomczak M, 2014, TRENDS SPORT SCI, V1, P19, DOI 10.1186/S13054-016-1208-6
   Vaucher S, 2009, WORK CONF REVERSE EN, V0, PP145, DOI 10.1109/WCRE.2009.23
   Vavrova Nicole, 2017, ARXIV, V0, P0
   Walter B, 2018, J SYST SOFTWARE, V144, P1, DOI 10.1016/j.jss.2018.05.057
   Wang GL, 2021, INT J SOFTW ENG KNOW, V31, P1329, DOI 10.1142/S0218194021500431
   Wang T, 1900, P593, V0, P0
   Wang XY, 2012, IEEE INT CONF AUTOM, V0, PP170, DOI 10.1145/2351676.2351701
   Woolson R, 2007, INT ENCY STAT SCI, V0, PP1, DOI 10.1002/9780471462422.EOCT979
   Yadav PS, 2021, 2021 10 INT C INTERN, V0, P1
   Yu S, 2010, 2010 2 IEEE INT C IN, V0, P352
   Yu X, 2023, PREPRINT, V0, P0
   Yuan Tian, 2012, 2012 19TH WORKING CONFERENCE ON REVERSE ENGINEERING (WCRE), V0, PP215, DOI 10.1109/WCRE.2012.31
NR 51
TC 0
Z9 0
U1 5
U2 5
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD MAY 29
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1370
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA I4NB0
UT WOS:001002552600003
PM 37346528
DA 2023-11-10
ER

PT J
AU Zhang, X
   Chen, YM
   He, LJ
AF Zhang, Xiao
   Chen, Yumin
   He, Linjie
TI Information block multi-head subspace based long short-term memory networks for sentiment analysis
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Multi-head subspace; Information block; Self-attention; Bidirectional long short-term memory; A dual fusion mechanism; Sentiment analysis
ID bidirectional lstm; self-attention; neural-networks; classification; mechanism
AB Sentiment analysis is a vital task in the domain of natural language processing for semantic handling. Numerous neural network systems are introduced into sentiment analysis by researchers, some of which deal with textual datasets. These models are frequently built using LSTM sequence models and attention mechanism. However, these models have some obvious flaws. For LSTM family networks, if the sequence is too long, the information about the long-distance sequence will be lost, and the gradient explosion will almost certainly occur. Additionally, these methods directly connect bidirectional hidden vectors, resulting in information redundancy. Multi-head attention is a variant of attention mechanism, and it is also widely used to process textual information in parallel. However, multi-head subspace information is also used in a mixed linear mapping, resulting in insufficient information usage. Further, multi-head attention calculates a long sequence of text, which has a large complexity overhead. To address these issues and boost performance, firstly, a complete sentence is divided into multiple information blocks. Then, we designed a unique model to input the information block into multi-head attention for parallel multi-space feature extraction; Furthermore, the output multi-subspace information is fed into the LSTM network that processes the subspace information to fully flow the message and to obtain the hidden states at each information block time step in each subspace. Blocking the sequence can not only reduce the number of cycles of LSTM, but also reduce the computational complexity of multi-head attention. Eventually, a dual fusion mechanism is presented that allows for the fusion and seizing of each subspace significant information. Experiments on real-world datasets demonstrate that our proposed model outperforms the majority of existing methods.
C1 [Zhang, Xiao; Chen, Yumin; He, Linjie] Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
C3 Xiamen University of Technology
RP Zhang, X (通讯作者)，Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
EM zhangxiaomyz@gmail.com
CR [Anonymous], 2015, P C EMPIRICAL METHOD, V0, P0
   Ba Jimmy Lei, 2016, ARXIV160706450, V0, P0
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Chen YZ, 2021, APPL INTELL, V51, P4287, DOI 10.1007/s10489-020-02069-5
   Chesley P, 2006, P AAAI CAAW 06 SPRIN, V580, P233
   Choi H, 2021, INT C PATT RECOG, V0, PP5482, DOI 10.1109/ICPR48806.2021.9412102
   Cui BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3548
   Vo DT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P219
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   FUNAHASHI K, 1993, NEURAL NETWORKS, V6, P801, DOI 10.1016/S0893-6080(05)80125-X
   Gan CQ, 2020, FUTURE GENER COMP SY, V112, P116, DOI 10.1016/j.future.2020.05.022
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   [关鹏飞 Guan Pengfei], 2019, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V33, P105
   Huang FL, 2022, IEEE T NEUR NET LEAR, V33, P4332, DOI 10.1109/TNNLS.2021.3056664
   Joshi Aditya, 2011, P 49 ANN M ASS COMP, V0, P127
   Kadari R, 2018, NEUROCOMPUTING, V283, P31, DOI 10.1016/j.neucom.2017.12.050
   Kalchbrenner Nal, 2014, CONVOLUTIONAL NEURAL, V0, P0
   Kim Y, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Li WJ, 2020, NEUROCOMPUTING, V387, P63, DOI 10.1016/j.neucom.2020.01.006
   Lin Z, 2017, P ICLR, V0, P0
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu Q, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1023, DOI 10.1145/3178876.3186001
   Liu Y, 2017, INFORM SCIENCES, V394, P38, DOI 10.1016/j.ins.2017.02.016
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Nogueira CSD, 2014, P COLING 2014 25 INT, V0, PP69, DOI 10.1109/ICCAR.2017.7942788
   Parikh A, 2016, PROC C EMPIR METHODS, V0, PP2249, DOI 10.18653/v1/D16-1244
   Paulus R, 2017, ARXIV170504304, V0, P1
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Poria S, 2016, IEEE IJCNN, V0, PP4465, DOI 10.1109/IJCNN.2016.7727784
   Shen T, 2018, AAAI CONF ARTIF INTE, V0, P5446
   Tai KS, 2015, ARXIV, V0, P0
   Tan ZX, 2018, AAAI CONF ARTIF INTE, V0, P4929
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   Zhang X, 2015, ADV NEUR IN, V28, P0
   Zhang YJ, 2020, IEEE-CAA J AUTOMATIC, V7, P1038, DOI 10.1109/JAS.2020.1003243
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zhou X, 2016, P 2016 C EMPIRICAL M, V0, PP247, DOI 10.18653/V1/D16-1024
NR 46
TC 0
Z9 0
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD MAY 15
PY 2023
VL 53
IS 10
BP 12179
EP 12197
DI 10.1007/s10489-022-03998-z
EA SEP 2022
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H0SL1
UT WOS:000857265600001
DA 2023-11-10
ER

PT J
AU Wang, XD
   Liu, JY
AF Wang, Xiaodi
   Liu, Jiayong
TI A novel feature integration and entity boundary detection for named entity recognition in cybersecurity
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Cyber threat intelligence; Named entity recognition; Cybersecurity; PERT; Entity boundary
AB Owing to continuous cyberattacks, a large amount of threat intelligence is generated online every day. However, threat intelligence is mostly unstructured and multisource heterogeneous text. It is difficult for security analysts to understand the implicit threat in time. Knowledge Graph (KG) is an important research topic in recent years, which can perform automated and real-time analysis of threat intelligence in cybersecurity. As one of the critical technologies of KG, named entity recognition (NER) can identify cyberattack-related entities. It has been proved that long-distance structured information captured by dependency trees provides a rich semantic expression for the neural network. However, existing research works are more focused on the simple linear stack of neural networks when utilizing structured features. The interaction between different types of neural networks is vague. In addition, the existing models are insensitive to the boundaries of complex entity terms in cybersecurity. In this study, we propose a new feature integration and entity boundary detection (FIEBD) model. In our model, a new pretrained language model, PERT, is applied to obtain word embedding of cyber texts. Moreover, a novel neural network cell, namely GARU, is developed to incorporate different types of features extracted from graph neural networks and recurrent neural networks. It combines the graph encoder with the gate mechanism, aiming to obtain better hidden representation by explicit interaction. Furthermore, considering a large number of complex entities in cybersecurity, we contribute an entity boundary detection module to perform entity head and tail prediction as an augmentation task. We conduct extensive experiments on cybersecurity datasets. The results demonstrate that the proposed model achieves better performance than existing baseline methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Wang, Xiaodi; Liu, Jiayong] Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610207, Peoples R China.
C3 Sichuan University
RP Liu, JY (通讯作者)，Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610207, Peoples R China.
EM ljy@scu.edu.cn
CR Bridges RA, 2014, ARXIV, V0, P0
   Abdullah MS, 2018, PROCEEDINGS OF THE 2018 CYBER RESILIENCE CONFERENCE (CRC), V0, P0
   Altalhi S, 2021, J AMB INTEL HUM COMP, V12, P10209, DOI 10.1007/s12652-020-02789-z
   An Y, 2022, ARTIF INTELL MED, V127, P0, DOI 10.1016/j.artmed.2022.102282
   Asghari M, 2022, INFORM SCIENCES, V602, P184, DOI 10.1016/j.ins.2022.04.037
   Bhusal D, 2022, ARXIV, V0, P0
   Bi KP, 2021, ARXIV, V0, P0
   Bridges RA, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP437, DOI 10.1109/ICMLA.2017.0-122
   Chen Ming, 2020, PROC INT C MACH LEAR, V0, PP1725, DOI 10.5555/3524938.3525099
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/tacl_a_00104
   Cho KYHY, 2014, ARXIV, V0, P0
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cui LY, 2021, ARXIV, V0, P0
   Cui Y, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2203.06906
   Dasgupta S, 2020, IEEE INT CONF BIG DA, V0, PP2596, DOI 10.1109/BigData50022.2020.9378482
   Devlin J, 2019, ARXIV, V0, P0
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Gao C, 2021, FRONT INFORM TECH EL, V22, P1153, DOI 10.1631/FITEE.2000286
   Gao C, 2021, CYBERSECURITY, V4, P0, DOI 10.1186/s42400-021-00072-y
   Hu LM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4821
   Huang ZH, 2015, ARXIV, V0, P0
   Jia Y, 2018, ENGINEERING-PRC, V4, P53, DOI 10.1016/j.eng.2018.01.004
   Jie Zhanming, 2019, ARXIV, V0, P0
   Joshi A, 2013, IEEE INT C SEMANT CO, V0, PP252, DOI 10.1109/ICSC.2013.50
   Kashihara Kazuaki, 2021, P SAI INT SYST C, V0, P155
   Kim G, 2020, INT J MACH LEARN CYB, V11, P2341, DOI 10.1007/s13042-020-01122-6
   Lafferty J, 2001, P INT C MACHINE LEAR, V0, P0
   Lal R, 2013, INFORM EXTRACTION SE, V0, P0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li F, 2021, ARXIV, V0, P0
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Li T, 2021, CMC-COMPUT MATER CON, V66, P407, DOI 10.32604/cmc.2020.012023
   Liu P, 2022, NEUROCOMPUTING, V473, P37, DOI 10.1016/j.neucom.2021.10.101
   Liu Y, 2022, ARXIV, V0, P0
   Liu ZH, 2021, AAAI CONF ARTIF INTE, V35, P13452
   Lu KD, 2022, IEEE T IND INFORM, V18, P5275, DOI 10.1109/TII.2021.3129487
   Lu Kang-Di, 2022, IEEE T CIRCUITS SYST, VII, P0
   Mansouri A, 2008, INT J COMPUT SCI NET, V8, P320
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Monaikul N, 2021, AAAI CONF ARTIF INTE, V35, P13570
   Morwal S, 2012, INT J NATURAL LANGUA, V1, P15, DOI 10.5121/ijnlc.2012.1402
   Mulwad V, 2011, 2011 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES, V0, PP257, DOI 10.1109/WI-IAT.2011.26
   Kipf TN, 2017, ARXIV, V0, P0
   Panpan Zhang, 2021, ACM ICEA 21: PROCEEDINGS OF THE 2021 ACM INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND ITS EMERGING APPLICATIONS, V0, PP94, DOI 10.1145/3491396.3506525
   Qin Y, 2019, FRONT INFORM TECH EL, V20, P872, DOI 10.1631/FITEE.1800520
   Roy A, 2017, ARXIV, V0, P0
   Sandra Dominiek, 2014, MORPHOLOGICAL STRUCT, V0, P0
   Sarhan I, 2021, KNOWL-BASED SYST, V233, P0, DOI 10.1016/j.knosys.2021.107524
   Shen Y, 2021, PREPRINT, V0, P0
   Shen Yongliang, 2022, ARXIV, V0, P0
   Simran K, 2019, INT S SIGNAL PROCESS, V0, P163
   Song BS, 2021, BRIEF BIOINFORM, V22, P0, DOI 10.1093/bib/bbab282
   Sun YB, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, P4135, DOI 10.1145/3459637.3481924
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Veličkovic P, 2018, ARXIV, V0, P0
   Wang Ning, 2022, ARXIV, V0, P0
   Weber L, 2021, BIOINFORMATICS, V37, P2792, DOI 10.1093/bioinformatics/btab042
   Weerawardhana S, 2015, LECT NOTES COMPUT SC, V8930, P356, DOI 10.1007/978-3-319-17040-4_24
   Wu Linzhi, 2022, ROBUST SELF AUGMENTA, V0, P0
   Wu Xiaojun, 2022, 2022 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND SIGNAL PROCESSING (ICSP), V0, PP728, DOI 10.1109/ICSP54964.2022.9778794
   Xiaoyan Zhu, 2021, 2021 INTERNATIONAL CONFERENCE ON NETWORKING AND NETWORK APPLICATIONS (NANA), V0, PP420, DOI 10.1109/NaNA53684.2021.00079
   Xie Y, 2020, NEURAL NETWORKS, V132, P180, DOI 10.1016/j.neunet.2020.08.021
   Xu QN, 2020, NEUROCOMPUTING, V388, P135, DOI 10.1016/j.neucom.2020.01.024
   Xu SS, 2022, ARXIV, V0, P0
   Xuren Wang, 2022, 2022 IEEE 25TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK IN DESIGN (CSCWD), V0, PP406, DOI 10.1109/CSCWD54268.2022.9776139
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2205
   Zhou SC, 2021, 2021 IEEE 6TH INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS (ICBDA 2021), V0, PP316, DOI 10.1109/ICBDA51983.2021.9403180
NR 67
TC 2
Z9 2
U1 18
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JAN 25
PY 2023
VL 260
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.110114
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA G8LH6
UT WOS:000991602500015
DA 2023-11-10
ER

PT J
AU Xie, ZY
   He, WD
   Xu, T
   Wu, SW
   Zhu, C
   Yang, P
   Chen, E
AF Xie, Zheyong
   He, Weidong
   Xu, Tong
   Wu, Shiwei
   Zhu, Chen
   Yang, Ping
   Chen, Enhong
TI Comprehending the Gossips: Meme Explanation in Time-Sync Video Comment via Multimodal Cues
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Meme explanation; time-sync comment; multimodal analysis
AB Recent years have witnessed the booming of online social media platforms with embracing the popular service called "Time-Sync Comment", which supports the viewers to share their time-sync opinions along with video content. In this way, we observe that numerous semantically-altered terms, or "Memes", were created by niche users to express their unique ideas and emotions, and further attracted a large group of viewers with better activity and enthusiasm. Unfortunately, since the memes were created based on domain-specific knowledge and semantically varied depending on the multimodal context in videos, newcomers may fail to comprehend the semantic connotation of memes, which may severely impair their user-experiences. To deal with this issue, in this article, we propose a novel meme explanation framework, called ProMDE, to automatically capture and comprehend the memes in time-sync comments, which could further benefit the viewers with meme explanation service. Specifically, we first iteratively reconstruct the original time-sync comments compared with visual embedding to detect the semantically-altered terms as meme candidates. Afterward, based on the guides from the domain-specific corpus, visual and textual features will be fused to represent the context-aware multimodal cues. Moreover, to accurately describe the commonly-seen homophones in memes, i.e., they have the same pronunciation but different word-spelling expressions, we integrate the phonetic symbols as an additional modality to enhance the framework. Finally, we utilize a Transformer-based decoder to generate the natural language explanation for captured memes. Extensive experiments on a large real-world dataset prove that our framework could significantly outperform several state-of-the-art baseline methods, demonstrating the efficacy of modeling multimodal context and pronunciation for meme detection and explanation.
C1 [Xie, Zheyong; He, Weidong; Xu, Tong; Chen, Enhong] Univ Sci & Technol China, Sch Comp Sci & Technol, 1129 Huizhou Ave, Hefei 230052, Anhui, Peoples R China.
   [Wu, Shiwei] Univ Sci & Technol China, Sch Data Sci, 1129 Huizhou Ave, Hefei 230052, Anhui, Peoples R China.
   [Zhu, Chen] Univ Sci & Technol China, Sch Management, 1129 Huizhou Ave, Hefei 230052, Anhui, Peoples R China.
   [Yang, Ping] Alibaba Inc, 969 Wenyi West Rd, Hangzhou 311121, Zhejiang, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of China, CAS; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Alibaba Group
RP Xu, T (通讯作者)，Univ Sci & Technol China, Sch Comp Sci & Technol, 1129 Huizhou Ave, Hefei 230052, Anhui, Peoples R China.
EM xiezheyong@mail.ustc.edu.cn; hwd@mail.ustc.edu.cn; tongxu@ustc.edu.cn; dwustc@mail.ustc.edu.cn; zc3930155@gmail.com; ypbjut@163.com; cheneh@ustc.edu.cn
FU National Natural Science Foundation of China [U22B2059, 62222213, 62072423]; USTC Research Funds of the Double First-Class Initiative [YD2150002009]
CR Amirian Soheyla, 2019, 23 INT C IMAGE PROCE, V0, P10
   Bahdanau D, 2016, ARXIV, V0, P0
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Dawkins, 1989, SELFISH GENE, V0, P0
   Desai P, 2022, AAAI CONF ARTIF INTE, V0, P10563
   Dosovitskiy Alexey, 2021, ICLR, V0, P0
   Giulianelli M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3960
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu Jiaxi, 2022, ADV NEURAL INFORM PR, V0, P26418
   Hamilton William L, 2016, P 54 ANN M ASS COMPU, V1, P0
   Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1
   Huang T-H, 2016, P 2016 C N AM CHAPTE, V0, PP1233, DOI 10.18653/v1/N16-1147
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Kim J, 2018, LECT NOTES COMPUT SC, V11206, P577, DOI 10.1007/978-3-030-01216-8_35
   Koch P, 2016, COGN LINGUIST RES, V58, P21
   Lee YC, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, PP689, DOI 10.1145/2702123.2702349
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P138
   Li YQ, 2022, ACM T INFORM SYST, V40, P0, DOI 10.1145/3498557
   Liao ZY, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP641, DOI 10.1145/3172944.3172966
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin X, 2014, 2014 IEEE/ACIS 13TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS), V0, PP163, DOI 10.1109/ICIS.2014.6912126
   Liu MF, 2022, IEEE T CYBERNETICS, V52, P1247, DOI 10.1109/TCYB.2020.2997034
   Liu MF, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102178
   Lv GY, 2022, IEEE T BIG DATA, V8, P535, DOI 10.1109/TBDATA.2019.2950411
   Lv GY, 2019, LECT NOTES ARTIF INT, V11441, P412, DOI 10.1007/978-3-030-16142-2_32
   Lv GY, 2016, AAAI CONF ARTIF INTE, V0, P3000
   Ma SM, 2019, AAAI CONF ARTIF INTE, V0, P6810
   Milo T, 2019, PROC INT CONF DATA, V0, PP974, DOI 10.1109/ICDE.2019.00091
   Mokady Ron, 2021, ARXIV, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Perez-Martin J, 2020, ARXIV, V0, P0
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shoemark P, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P66
   Smith Samuel L, 2017, P 5 INT C LEARNING R, V0, P0
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Tsakalidis A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8485
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wu B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP721, DOI 10.1145/2623330.2623625
   Wu ZC, 2014, 2014 IIAI 3RD INTERNATIONAL CONFERENCE ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2014), V0, PP280, DOI 10.1109/IIAI-AAI.2014.65
   Xian Yikun, 2015, P 7 INT WORKSHOP HOT, V0, P31
   Xu LL, 2017, AAAI CONF ARTIF INTE, V0, P1611
   Zhang Hao, 2020, P 58 ANN M ASS COMP, V0, P6543
   Zhang Meng, 2017, P 2017 C EMP METH NA, V0, P1934
   Zhong H, 2020, FRONT COMPUT SCI-CHI, V14, P0, DOI 10.1007/s11704-019-8457-x
NR 46
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG 15
PY 2023
VL 22
IS 8
BP 
EP 
DI 10.1145/3612920
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q7NS7
UT WOS:001059361200014
DA 2023-11-10
ER

PT J
AU Abdelhakim, M
   Liu, BQ
   Sun, CG
AF Abdelhakim, Mohamed
   Liu, Bingquan
   Sun, Chengie
TI Ar-PuFi: A short-text dataset to identify the offensive messages towards public figures in the Arabian community
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Offensive language detection; Offensive Domain classifcation; Arab Public Figures; Arabic language processing; Active learning; Meta learning
ID language
AB The fight against offensive speech on the Internet necessitates increased efforts from linguistic analysis and artificial intelligence perspectives to develop countermeasures and preventive methods. Reliable predictions can only be obtained if these methods are exposed to a representative sample of the domain or environment under consideration. Datasets serve as the foundation for significant developments in this field because they are the main means of obtaining appropriate instances that reveal the multiple and varied faces of the offensive speech phenomenon. In this sense, we present Ar-PuFi, a dataset of offensive speech towards Public Figures in the Arabian community. With 24,071 comments collected from TV interviews with Egyptian celebrities belonging to six domains of public interest, Ar-PuFi is currently the largest Arabic dataset in terms of its category and size. The examples were annotated by three native speakers over the course of two months and are provided with two-class and six-class annotations based on the presence or absence of explicit and implicit offensive content. We evaluated the performance of a diverse set of classification models employing several text representations of actual examples (e.g., N-gram, TF/IDF, AraVec, and fastText), and AraBERT achieved the baseline for the new dataset in both offensive detection and group classification. Additionally, we apply the Pointwise Mutual In-formation (PMI) technique to comments within the target domain in order to derive a lexicon of offensive terms associated with each domain of ArPuFi. We further explored whether active learning (AL) or meta-learning (ML) frameworks could be used to reduce the labeling effort required for our dataset without affecting prediction quality and found that, though AL can reduce the amount of data annotations by 10% over the ML approach, neither approach requires less than about 70% of the full dataset to achieve baseline performance. Finally, we took advantage of the availability of relevant datasets and conducted a cross-domain experiment to back up our claims not only about the uniqueness of our dataset but also about the difficulty of adapting Arabic dialects against one another.
C1 [Abdelhakim, Mohamed; Liu, Bingquan; Sun, Chengie] Harbin Inst Technol, Fac Comp Sci & Technol, Harbin, Peoples R China.
   [Abdelhakim, Mohamed] Alexandria Univ, Inst Grad Studies & Res, Alexandria, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Alexandria University
RP Abdelhakim, M (通讯作者)，Harbin Inst Technol, Fac Comp Sci & Technol, Harbin, Peoples R China.; Abdelhakim, M (通讯作者)，Alexandria Univ, Inst Grad Studies & Res, Alexandria, Egypt.
EM m_abdelhakeem@insun.hit.edu.cn; liubq@insun.hit.edu.cn; cjsun@insun.hit.edu.cn
FU National key Research and Development Program [2021YFF0901600]; National Natural Science Foundation of China [62176074]; Interdisciplinary Development Program of Harbin Institute of Technology [SYL-JC-202203]; Fundamental Research Funds for the Central Universities [2022FRFK0600XX]
CR Abbes I, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6265
   Abdelali A, 2016, P 2016 C N AM CHAPT, V0, PP11, DOI 10.18653/v1/N16
   Abu Farha I, 2020, P 4 WORKSH OP SOURC, V0, P32
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, V0, P457
   Alakrot A, 2018, PROCEDIA COMPUT SCI, V142, P315, DOI 10.1016/j.procs.2018.10.491
   Albadi N, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), V0, PP69, DOI 10.1109/ASONAM.2018.8508247
   Almanea D, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2282
   Alsafari Safa, 2020, ONLINE SOCIAL NETWORKS AND MEDIA, V0, P0, DOI DOI 10.1016/j.osnem.2020.100096
   Alshalan R, 2020, P 5 ARABIC NATURAL L, V10, P12
   Castaño-Pulgarín SA, 2021, AGGRESS VIOLENT BEH, V58, P0, DOI 10.1016/j.avb.2021.101608
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Aref A, 2020, CS IT C P, V0, P81
   Bassignana E, 2018, P 5 IT C COMP LING C, V0, P0, DOI DOI 10.4000/books.aaccademia.3085
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chowdhury SA, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6203
   Davidson T, 2017, P 11 INT C WEB SOCIA, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Farha A, 2021, P 6 AR NAT LANG PROC, V0, P296
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Fortuna P, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102524
   Fortuna P, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6786
   Fortuna P, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3232676
   Gadavanij S, 2021, LEARN J LANGUAGE ED, V14, P344
   Ghanem B, 2019, ACM INT CONF PR SER, V0, PP10, DOI 10.1145/3368567.3368585
   Guellil I, 2022, P WORKSHOP DATASET C, V0, P68
   Guellil I, 2020, INT J WEB INF SYST, V16, P295, DOI 10.1108/IJWIS-08-2019-0036
   Guellil I, 2021, J KING SAUD UNIV-COM, V33, P497, DOI 10.1016/j.jksuci.2019.02.006
   Haddad H, 2019, COMM COM INF SC, V1108, P251, DOI 10.1007/978-3-030-32959-4_18
   Hegazi MO, 2021, HELIYON, V7, P0, DOI 10.1016/j.heliyon.2021.e06191
   Husain F, 2020, P 4 WORKSHOP OPEN SO, V0, P53
   Jahan MS, 2021, ARXIV, V0, P0
   Jay KL, 2015, LANG SCI, V52, P251, DOI 10.1016/j.langsci.2014.12.003
   Karoui J, 2017, PROCEDIA COMPUT SCI, V117, P161, DOI 10.1016/j.procs.2017.10.105
   Khairy M, 2021, PROCEDIA COMPUT SCI, V189, P156, DOI 10.1016/j.procs.2021.05.080
   Kiritchenko S, 2020, ARXIV, V0, P0
   Kumar Ritesh, 2020, 2020 IEEE INT C POWE, V0, PP1, DOI 10.1109/PEDES49360.2020.9379763
   Madrid JG, 2019, LECT NOTES COMPUT SC, V11896, P107, DOI 10.1007/978-3-030-33904-3_10
   Mandl T, 2020, ACM INT CONF PR SER, V0, PP29, DOI 10.1145/3441501.3441517
   Miaschi A, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P110
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mubarak H, 2022, P 5 WORKSHOP OPEN SO, V0, P162
   Mubarak H, 2017, P 1 WORKSHOP ABUSIVE, V0, P0, DOI DOI 10.18653/v1/W17-3008
   Mubarak H, 2020, P 4 WORKSHOP OPEN SO, V0, P48
   Mubarak H, 2021, P 6 ARABIC NATURAL L, V0, P126
   Mulki H, 2021, P 6 AR NAT LANG PROC, V0, PP154, DOI 10.48550/arXiv.2103.10195
   Mulki H, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, V0, P111
   Nichol A, 2018, ARXIV, V0, P0
   Ousidhoum N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4675
   Poletto F, 2021, LANG RESOUR EVAL, V55, P477, DOI 10.1007/s10579-020-09502-8
   Pradhan Rahul, 2020, ADVANCES IN DATA AND INFORMATION SCIENCES. PROCEEDINGS OF ICDIS 2019. LECTURE NOTES IN NETWORKS AND SYSTEMS (LNNS 94), V0, PP433, DOI 10.1007/978-981-15-0694-9_41
   Radcliffe D, 2021, SSRN ELECT J, V0, P0, DOI DOI 10.2139/ssrn.3826011
   Ren Haoyu, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2103
   Saeidi M, 2020, COMM COM INF SC, V1168, P283, DOI 10.1007/978-3-030-43887-6_22
   Saha K, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI19), V0, PP255, DOI 10.1145/3292522.3326032
   Samghabadi NS, 2020, P 2 WORKSHOP TROLLIN, V0, P144
   Schmidt Anna, 2017, P 5 INT WORKSH NAT L, V0, PP1, DOI 10.18653/V1/W17-1101
   Settles B, 2009, SYNTHESIS LECT ARTIF, V6, P1
   Shannag F, 2022, EDUC INF TECHNOL, V27, P10977, DOI 10.1007/s10639-022-11056-x
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Srivastava Naman Deep, 2020, 2020 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), V0, PP47, DOI 10.1109/RAICS51191.2020.9332469
   Stefanita O, 2021, ROM J COMMUN PUB REL, V23, P47
   Tang X, 2020, LECT NOTES COMPUTER, V0, PP300, DOI 10.1007/978-3-030-63031-7_22
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P417
   Uyheng J, 2021, APPL NETW SCI, V6, P0, DOI 10.1007/s41109-021-00362-x
   Vadesara A, 2020, LECT NOTES DATA ENG, V0, PP225, DOI 10.1007/978-981-15-4474-3_26
   van Aken Betty, 2018, PROC C EMPIRICAL MET, V0, PP33, DOI 10.18653/v1/W18-5105
   WIEGAND M, 2018, P GERMEVAL WORKSHOP, V0, P0
   Yin WJ, 2021, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.598
   Zampieri M, 2019, P 13 INT WORKSHOP SE, V0, PP75, DOI 10.18653/V1/S19-2010
   Zampieri M, 2020, P 14 WORKSHOP SEMANT, V0, P1425
NR 70
TC 0
Z9 0
U1 11
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2023
VL 233
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120888
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA O5DS7
UT WOS:001044021600001
DA 2023-11-10
ER

PT J
AU Huang, ZC
   Li, XT
   Ye, YM
   Zhang, BQ
   Xu, GN
   Gan, WS
AF Huang, Zhichao
   Li, Xutao
   Ye, Yunming
   Zhang, Baoquan
   Xu, Guangning
   Gan, Wensheng
TI Multi-view knowledge graph fusion via knowledge-aware attentional graph neural network
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Multi-view knowledge graph fusion; Entity alignment; Knowledge-aware attention; Multi-view GNN
AB Knowledge graphs (KGs) play a vital role in natural language processing (NLP), which can serve several downstream tasks. Because different views of KGs are usually constructed independently, the multi-view knowledge graph fusion (MVKGF) becomes a hotspot. Although multi-view learning studied very well in past decades, MVKGF is still not well tackled because of the heterogeneous relations and the multi-view KGs. To overcome MVKGF, entity alignment is the most studied. Existing entity alignment methods are dominated by embedding based methods, such as TransE and Graph Neural Networks (GNNs), where the alignment is achieved by measuring the similarities between entity embeddings. However, most previous approaches suffer from the issues of the diverse knowledge facts and the complex neighboring structures. In this paper, we propose a novel K nowledge-aware A ttentional G raph N eural N etwork (KAGNN) model to carefully incorporate both knowledge facts and neighboring structures. In particular, a knowledge-aware attention mechanism is designed to preserve the original semantics and determine the importance of each knowledge fact. Furthermore, a three-layered GCN with highway gates is adopted to learn better entity representations from the neighboring structure information. Thus, our model can be regarded as a multi-view extension of GNN. We validate our model on three cross-lingual datasets and the results show our model beats the state-of-the-art baselines by a large margin.
C1 [Huang, Zhichao; Li, Xutao; Ye, Yunming; Zhang, Baoquan; Xu, Guangning] Harbin Inst Technol, Dept Comp Sci, Shenzhen 518055, Peoples R China.
   [Gan, Wensheng] Jinan Univ, Coll Cyber Secur, Guangzhou 510632, Peoples R China.
C3 Harbin Institute of Technology; Jinan University
RP Li, XT; Ye, YM (通讯作者)，Harbin Inst Technol, Dept Comp Sci, Shenzhen 518055, Peoples R China.
EM iceshzc@stu.hit.edu.cn; lixutao@hit.edu.cn; yeyumning@hit.edu.cn; zhangbaoquan@stu.hitedu.cn; 20B951010@stu.hitedu.cn; wsgan001@gmail.com
FU National Key R&D Program of China [2018YFB2101100, 2018YFB2101101]; NSFC [61972111, U1836107]
CR Belhadi H, 2020, APPL INTELL, V50, P1204, DOI 10.1007/s10489-019-01593-3
   Bordes A, 2013, ADV NEURAL INFORM PR, V0, P0
   Bruna J, 2013, ABS13126203 CORR, V0, P0, DOI DOI 10.48550/ARXIV.1312.6203
   Cao YX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1452
   Chao GQ, 2019, INFORM SCIENCES, V494, P278, DOI 10.1016/j.ins.2019.04.039
   Chao GQ, 2019, INFORM FUSION, V45, P296, DOI 10.1016/j.inffus.2018.03.002
   Chao GQ, 2016, IEEE T NEUR NET LEAR, V27, P1445, DOI 10.1109/TNNLS.2015.2442256
   Chen MH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3998
   Chen MH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1511
   Cui WY, 2017, PROC VLDB ENDOW, V10, P565, DOI 10.14778/3055540.3055549
   Defferrard M, 2016, ADV NEUR IN, V29, P0
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Hao YC, 2016, COMM COM INF SC, V650, P3, DOI 10.1007/978-981-10-3168-7_1
   Huang ZC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1258
   Kipf TN, 2016, P INT C LEARNING REP, V0, P0
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Li CJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2723
   Li CS, 2021, INT J SOFTW ENG KNOW, V31, P533, DOI 10.1142/S0218194021400064
   Li CS, 2020, NEURAL COMPUT APPL, V32, P6383, DOI 10.1007/s00521-019-04145-5
   NEMENYI P, 1962, BIOMETRICS, V18, P263
   Pei SC, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP3130, DOI 10.1145/3308558.3313646
   Rebele T, 2016, LECT NOTES COMPUT SC, V9982, P177, DOI 10.1007/978-3-319-46547-0_19
   Srivastava R K, 2015, ARXIV 150500387, V0, P0
   Sun ZQ, 2020, AAAI CONF ARTIF INTE, V34, P222
   Sun ZQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4396
   Sun ZQ, 2017, LECT NOTES COMPUT SC, V10587, P628, DOI 10.1007/978-3-319-68288-4_37
   Trisedya BD, 2019, AAAI CONF ARTIF INTE, V0, P297
   Velickovi Petar, 2017, ARXIV171010903, V0, P0
   Wang ZC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P349
   Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1437, DOI 10.1145/3343031.3351034
   Wu F, 2019, PR MACH LEARN RES, V97, P0
   Wu YT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5278
   Wu YT, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P240
   Xu K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3156
   Yan ZF, 2020, LECT NOTES ELECTR EN, V589, P19, DOI 10.1007/978-981-32-9441-7_3
   Zhang QH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5429
   Zhu H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4258
   Zhu QN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1943
NR 38
TC 1
Z9 1
U1 8
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD FEB 15
PY 2023
VL 53
IS 4
BP 3652
EP 3671
DI 10.1007/s10489-022-03667-1
EA JUN 2022
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 8N5RL
UT WOS:000805064000003
DA 2023-11-10
ER

PT J
AU Li, ZZ
   Sun, X
   Ren, FJ
   Ma, JJ
   Huang, DG
   Shi, P
AF Li, Zezhong
   Sun, Xiao
   Ren, Fuji
   Ma, Jianjun
   Huang, Degen
   Shi, Piao
TI Multilingual BERT-basedWord Alignment By Incorporating Common Chinese Characters
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Word alignment; common Chinese character; Japanese-Chinese; mBERT
AB Word alignment is an important task of detecting translation equivalents between a sentence pair. Although word alignment is no longer necessarily needed for neural machine translation, it's still useful in a wealth of applications, e.g., bilingual lexicon induction, constraint decoding, and so on. However, the most well-known word aligners are still Giza++ and fastAlign, both of which are implementations of traditional IBM models. To keep pace with the advance in NMT, there has been a surge of interest in replacing the IBM models with neural models. We follow this trend but aim to boost performance of word alignment between Japanese and Chinese, which share a large portion of Chinese characters. Our key idea is to leverage these common Chinese characters in both languages as an indicator for inferring alignment; i.e., the source and target words with the common Chinese characters should be most likely aligned. Following this idea, we propose three methods that leverage common Chinese characters to boost the mBERT-based word alignment, including reward factor, representation alignment, and contrastive training. Furthermore, we annotate and release a golden dataset for Japanese-Chinese word alignment. Experiments on the dataset show that our methods outperform several strong baselines in terms of AER score and verify the effectiveness of exploiting common Chinese characters.
C1 [Li, Zezhong; Sun, Xiao; Shi, Piao] Hefei Univ Technol, Hefei 230009, Anhui, Peoples R China.
   [Ren, Fuji] Univ Elect Sci & Technol China, Chengdu 610000, Sichuan, Peoples R China.
   [Ma, Jianjun; Huang, Degen] Dalian Univ Technol, Dalian, Liaoning, Peoples R China.
C3 Hefei University of Technology; University of Electronic Science & Technology of China; Dalian University of Technology
RP Sun, X (通讯作者)，Hefei Univ Technol, Hefei 230009, Anhui, Peoples R China.
EM lizezhonglaile@163.com; sunx@hfut.edu.cn; ren2fuji@gmail.com; majian@dlut.edu.cn; huangdg@dlut.edu.cn; shipiao@mail.hfut.edu.cn
FU National Key Research and Development Program of China [2020AAA0108004]; General Programmer of the National Natural Science Foundation of China [61976078]
CR Arthur P, 2016, P 2016 C EMP METH NA, V0, PP1557, DOI 10.18653/V1/D16-1162
   Brown PF, 1993, COMPUTATIONAL LINGUISTICS, V19, P263
   Cao Steven, 2020, 8 INT C LEARN REPR I, V0, P0
   Chen C, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4781
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chen Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P566
   Chenhui Chu, 2013, ACM TRANSACTIONS ON ASIAN LANGUAGE INFORMATION PROCESSING, V12, P0, DOI 10.1145/2523057.2523059
   Conneau Alexis, 2019, P NIPS NIPS 19, V1, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou ZY, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2112
   Dyer Chris, 2013, P 2013 C N AM CHAPTE, V0, P644
   Garg S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4453
   Huck Matthias, 2018, P 6 WORKSHOP NLP SIM, V1, P0
   Jalili Sabet Masoud, 2020, FINDINGS ASS COMPUTA, V0, PP1627, DOI 10.18653/V1/2020.FINDINGS-EMNLP.147
   Jun Gao, 2019, ABS190712009 CORR, V0, P0
   Kulshreshtha S, 2020, PROC C EMPIR METHODS, V0, P933
   Li ZZ, 2023, ACM T ASIAN LOW-RESO, V22, P0, DOI 10.1145/3533429
   Nagata M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P555
   Nakazawa T, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2204
   Och FJ, 2003, COMPUT LINGUIST, V29, P0
   Okita Tsuyoshi, 2012, P ELRA ELRA 12, V0, P0
   Pal Santanu, 2017, P 15 C EUR CHAPT ASS, V2, P349
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Su Jinsong, 2016, P COLING COLING 16, V0, P3071
   Xu HR, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6663
   Yujie Zhang, 2008, P LREC LREC 08, V0, P0
   Zenkel Thomas, 2019, ABS190111359 CORR, V0, P0
   Zhang B, 2020, IEEE T CYBERNETICS, V50, P503, DOI 10.1109/TCYB.2018.2868982
   Zhang B, 2017, AAAI CONF ARTIF INTE, V0, P3372
   Zhang T, 2022, AAAI CONF ARTIF INTE, V0, P11712
NR 31
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN 15
PY 2023
VL 22
IS 6
BP 
EP 
DI 10.1145/3594634
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K7YR0
UT WOS:001018562700029
DA 2023-11-10
ER

PT J
AU Ul Hassan, A
   Memon, I
   Choi, J
AF Ul Hassan, Ammar
   Memon, Irfanullah
   Choi, Jaeyoung
TI Real-time high quality font generation with Conditional Font GAN
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Font generation; Generative adversarial networks; Style transfer; Weakly -supervised learning; High resolution font image synthesis
AB Designing and generating novels fonts manually is a laborious and time-consuming process owing to the large number and complexity of characters in the majority of language systems. Recent advancements in generative adversarial networks (GANs) have significantly improved font generation. These GAN-based approaches either handle the font generation as a vanilla GAN problem (that is, by synthesizing characters from a uniform latent vector) or an image-to-image translation problem. While the former approach has no limitation in generating diverse font styles, the generated fonts contain artifacts and can operate only on low-resolution images, thus impairing their usability. The latter approach generates high-quality font images for previously observed fonts, but the quality degrades during the inference phase while designing novel fonts. Furthermore, additional fine-tuning steps are required to achieve photorealistic results, which is computationally expensive and time-consuming. To address the shortcomings of these approaches, we propose a font generation method that employs the vanilla GAN approach to generate an infinite number of font styles but focuses on the real-time generation of photo-realistic font images. Additionally, we strive to create high-resolution images that can be used in practical applications. To accomplish this, we propose a conditional font GAN (CFGAN) with a sophisticated network architecture that is designed to generate novel style-consistent diverse font character sets. We control the generated characters in the proposed network using a non-trainable fixed character vector, while the style variation sampled from a Gaussian distribution is fused at all blocks of the generator through adaptive instance normalization (AdaIN) operation. Thus, the generator architecture can simultaneously generate an infinite number of font styles with style consistency and diversity during inference. We conducted various quantitative and qualitative experiments to demonstrate the effectiveness of the proposed model in terms of both image quality and computational cost.
C1 [Ul Hassan, Ammar; Memon, Irfanullah; Choi, Jaeyoung] Soongsil Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Memon, Irfanullah] MUET, Dept Software Engn, SZAB Campus Khairpur Mirs, Sindh, Pakistan.
C3 Soongsil University
RP Choi, J (通讯作者)，Soongsil Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM ammar.instantsoft@gmail.com; iumemon@gmail.com; choi@ssu.ac.kr
FU Institute of Information & communications Technology Planning & Evaluation (IITP) - Korea government (MSIT) [2016-0-00166]
CR Abe K, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), V0, PP232, DOI 10.1109/ACPR.2017.99
   [Anonymous], 2018, GAN LANDSCAPE LOSSES, V0, P0
   Arjovsky M, 2017, ARXIV, V0, P0
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Azadil S, 2018, PROC CVPR IEEE, V0, PP7564, DOI 10.1109/CVPR.2018.00789
   Cha Junbum, 2020, LNCS, V12364, P2, DOI 10.1007/978-3-030-58529-7_43
   Choi Y, 2018, PROC CVPR IEEE, V0, PP8789, DOI 10.1109/CVPR.2018.00916
   Davis B, 2020, ARXIV, V0, P0
   Gao Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3355089.3356574
   Gatys LA, 2016, PROC CVPR IEEE, V0, PP2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I, 2017, ARXIV, V0, P0
   Hayashi H, 2019, KNOWL-BASED SYST, V186, P0, DOI 10.1016/j.knosys.2019.104927
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30, P0
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, V0, PP1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, V0, PP5967, DOI 10.1109/CVPR.2017.632
   Jiang Y, 2019, AAAI CONF ARTIF INTE, V0, P4015
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA17), V0, P0, DOI DOI 10.1145/3145749.3149440
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Karnewar Animesh, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP7796, DOI 10.1109/CVPR42600.2020.00782
   Karras Tero, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, ARXIV, V0, P0
   Karras T, 2019, PROC CVPR IEEE, V0, PP4396, DOI 10.1109/CVPR.2019.00453
   Kingma DP, 2014, C TRACK P, V0, P0
   Kingma DP, 2016, ADV NEURAL INFORM PR, V0, P4743
   Ko DH, 2021, INT J DOC ANAL RECOG, V24, P325, DOI 10.1007/s10032-021-00374-4
   Ko DH, 2021, J INF PROCESS SYST, V17, P1, DOI 10.3745/JIPS.02.0152
   Li W, 2020, AAAI CONF ARTIF INTE, V34, P1717
   Li Z, 2017, 43RD EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC 2017), V0, P0, DOI DOI 10.1109/TPAMI.2017.2773081
   Liu MY, 2019, IEEE I CONF COMP VIS, V0, PP10550, DOI 10.1109/ICCV.2019.01065
   Lopes RG, 2019, IEEE I CONF COMP VIS, V0, PP7929, DOI 10.1109/ICCV.2019.00802
   Mescheder L, 2018, PR MACH LEARN RES, V80, P0
   Mirza M, 2014, ARXIV, V0, P0
   Odena A, 2017, PR MACH LEARN RES, V70, P0
   Park S, 2020, ARXIV, V0, P0
   Parmar G, 2022, ARXIV, V0, P0
   Radford A, 2016, ARXIV, V0, P0
   Salimans T, 2016, ADV NEUR IN, V29, P0
   Taigman Y, 2016, UNSUPERVISED CROSS D, V0, P0, DOI DOI 10.48550/ARXIV.1611.02200
   Tian Yuchen, 2017, ZI2ZI MASTER CHINESE, V0, P0
   Ul Hassan A, 2021, KNOWL-BASED SYST, V229, P0, DOI 10.1016/j.knosys.2021.107304
   Xie Yangchen, 2021, CVPR, V0, P5130
   Xu B, 2015, ARXIV, V0, P0
   Yunjey Choi, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8185, DOI 10.1109/CVPR42600.2020.00821
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 48
TC 2
Z9 2
U1 6
U2 30
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 1
PY 2023
VL 213
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118907
EA OCT 2022
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 5R7AQ
UT WOS:000874659300003
DA 2023-11-10
ER

PT J
AU Van Nguyen, K
   Do, PNT
   Nguyen, ND
   Nguyen, AGT
   Nguyen, NLT
AF Van Nguyen, Kiet
   Do, Phong Nguyen-Thuan
   Nguyen, Nhat Duy
   Nguyen, Anh Gia-Tuan
   Nguyen, Ngan Luu-Thuy
TI Multi-stage transfer learning with BERTology-based language models for question answering system in vietnamese
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Question Answering; Machine Reading Comprehension; Transfer Learning; BERT; BERTology; SBERT; BiLSTM; Transformer
ID knowledge
AB With the fast growth of information science and engineering, a large number of textual data generated are valuable for natural language processing and its applications. Particularly, finding correct answers to natural language questions or queries requires spending tremendous time and effort in human life. While using search engines to discover information, users manually determine the answer to a given question on a range of retrieved texts or documents. Question answering relies heavily on the capability to automatically comprehend questions in human language and extract meaningful answers from a single text. In recent years, such question-answering systems have become increasingly popular using machine reading comprehension techniques. On the other hand, high-resource languages (e.g., English and Chinese) have witnessed tremendous growth in question-answering methodologies based on various knowledge sources. Besides, powerful BERTology-based language models only encode texts with a limited length. The longer texts contain more distractor sentences that affect the QA system performance. Vietnamese has a variety of question words in the same question type. To address these challenges, we propose ViQAS, a new question-answering system with multi-stage transfer learning using language models based on BERTology for a low-resource language such as Vietnamese. Last but not least, our QA system is integrated with Vietnamese characteristics and transformer-based evidence extraction techniques into an effective contextualized language model-based QA system. As a result, our proposed system outperforms our forty retriever-reader QA configurations and seven state-of-the-art QA systems such as DrQA, BERTserini, BERTBM25, XLMRQA, ORQA, COBERT, and NeuralQA on three Vietnamese benchmark question answering datasets.
C1 [Van Nguyen, Kiet; Do, Phong Nguyen-Thuan; Nguyen, Nhat Duy; Nguyen, Anh Gia-Tuan; Nguyen, Ngan Luu-Thuy] Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Van Nguyen, Kiet; Do, Phong Nguyen-Thuan; Nguyen, Nhat Duy; Nguyen, Anh Gia-Tuan; Nguyen, Ngan Luu-Thuy] Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Nguyen, NLT (通讯作者)，Univ Informat Technol, Ho Chi Minh City, Vietnam.; Nguyen, NLT (通讯作者)，Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
EM ngannlt@uit.edu.vn
CR Alzubi JA, 2023, ARAB J SCI ENG, V48, P11003, DOI 10.1007/s13369-021-05810-5
   [Anonymous], 1961, PROC W JOINT COMPUTE, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Bai Yan, 2021, ARXIV, V0, P0
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Chen D, 2020, P 58 ANN M ASS COMP, V0, PP34, DOI 10.18653/V1/2020.ACL-TUTORIALS.8
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chen DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2358
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Cui YM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5883
   dHoffschmidt M, 2020, FINDINGS ASS COMPUTA, V2020, P1193
   Das Rajarshi, 2018, 6 INT C LEARN REPR I, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dibia V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P15
   Do Phong N-T, 2021, 14 INT C, V0, P0
   Doan AL, 2022, ARXIV, V0, P0
   Dua D, 2019, NAACL HLT 1, V0, P0
   Efimov Pavel, 2020, EXPERIMENTAL IR MEETS MULTILINGUALITY, V0, P0
   Feldman Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2296
   Guu Kelvin, 2020, P MACHINE LEARNING R, V119, P3929
   HARABAGIU S, 2003, P 12 TEXT RETR C TRE, V0, P375
   Harabagiu S, 2000, COLING 2000, V0, P0
   Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2545
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang H-Y, 2018, ICLR FUSIONNET, V0, P0
   Duong HT, 2014, LECT NOTES COMPUT SC, V8838, P186, DOI 10.1007/978-3-662-45237-0_19
   Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P874
   Izacard Gautier, 2021, ICLR, V0, P0
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Nguyen KV, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3527631
   Kratzwald B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6076
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6086
   Lewis Patrick, 2020, ADV NEURAL INFORM PR, V33, P9459, DOI 10.48550/ARXIV.2005.11401
   Lim S, 2019, ADV NEURAL INF PROCE, V32, P6665
   Lin J, 2021, SIGIR 21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP2356, DOI 10.1145/3404835.3463238
   Lin YK, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1736
   Liu SS, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9183698
   Messaoudi A, 2020, 14 WORKSHOP SEMANTIC, V0, P1978
   Min S, 2019, ARXIV, V0, P0
   Bach NX, 2020, CYBERN INF TECHNOL, V20, P112, DOI 10.2478/cait-2020-0008
   Nguyen AT, 2020, FINDINGS ASS COMPUTA, V0, P0, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.92
   Nguyen K, 2020, P 28 INT C COMPUTATI, V0, P2595
   Nguyen KV, 2020, IEEE ACCESS, V8, P201404, DOI 10.1109/ACCESS.2020.3035701
   Nogueira R, 2019, ARXIV, V0, P0
   Noraset T, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102431
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Phan T, 2021, NEURAL COMPUT APPL, V33, P14887, DOI 10.1007/s00521-021-06126-z
   Do PNT, 2021, LECT NOTES ARTIF INT, V12816, P511, DOI 10.1007/978-3-030-82147-0_42
   Do P, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3453651
   Do P, 2022, APPL INTELL, V52, P636, DOI 10.1007/s10489-021-02460-w
   Pyysalo S, 2021, NODALIDA 2021, V0, P0
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Reimers N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4512
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P567
   Richardson M, 2013, P 2013 C EMPIRICAL M, V0, P193
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Seo Min Joon, 2016, ARXIV, V0, P0
   So BH, 2022, ARXIV, V0, P0
   Tapeh AG, 2008, KNOWL-BASED SYST, V21, P946, DOI 10.1016/j.knosys.2008.04.005
   Tran TK, 2015, 2015 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES - RESEARCH, V0, P0
   Tran M-V, 2012, 26 PAC AS C LANG INF, V0, P325
   Trotman A, 2014, ADCS, V0, PP58, DOI 10.1145/2682862.2682863
   Van HT, 2022, 29 INT C COMPUTATION, V0, P3858
   Van Nguyen K, 2021, J INTELL FUZZY SYST, V41, P1
   Van Nguyen K, 2022, 14 ASIAN C INTELLIGE, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Voorhees EM, 1999, NAT LANG ENG, V99, P77, DOI 10.1017/S1351324901002789
   Wang H, 2019, CORR, V0, P696
   Wang S, 2018, AAAI 2018, V0, P0
   Wang ZG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5878
   Woods WA, 1973, AFIPS CONFERENCE PROCEEDINGS VOL.42 1973 NATIONAL COMPUTER COMPOSITION AND EXPOSITION, V0, P441
   Wu BW, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P70
   Xiong W, 2020, ICML 2020, V0, P0
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P72
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2369
   Zhang Z, 2020, COMPUT LINGUIST, V1, P0
   Zhao TC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P565
   Zhu Feng, 2021, ARXIV, V0, P0
NR 82
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD MAY 15
PY 2023
VL 14
IS 5
BP 1877
EP 1902
DI 10.1007/s13042-022-01735-z
EA JAN 2023
PG 26
WC Computer Science, Artificial Intelligence
SC Computer Science
GA E4QJ0
UT WOS:000921809700001
DA 2023-11-10
ER

PT J
AU Mubarak, H
   Hassan, S
   Chowdhury, SA
AF Mubarak, Hamdy
   Hassan, Sabit
   Chowdhury, Shammur Absar
TI Emojis as anchors to detect Arabic offensive language and hate speech
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Offensive language; Hate speech; Emojis; Text classification; Social media analysis
AB We introduce a generic, language-independent method to collect a large percentage of offensive and hate tweets regardless of their topics or genres. We harness the extralinguistic information embedded in the emojis to collect a large number of offensive tweets. We apply the proposed method on Arabic tweets and compare it with English tweets-analyzing key cultural differences. We observed a constant usage of these emojis to represent offensiveness throughout different timespans on Twitter. We manually annotate and publicly release the largest Arabic dataset for offensive, fine-grained hate speech, vulgar, and violence content. Furthermore, we benchmark the dataset for detecting offensiveness and hate speech using different transformer architectures and perform in-depth linguistic analysis. We evaluate our models on external datasets-a Twitter dataset collected using a completely different method, and a multi-platform dataset containing comments from Twitter, YouTube, and Facebook, for assessing generalization capability. Competitive results on these datasets suggest that the data collected using our method capture universal characteristics of offensive language. Our findings also highlight the common words used in offensive communications, common targets for hate speech, specific patterns in violence tweets, and pinpoint common classification errors that can be attributed to limitations of NLP models. We observe that even state-of-the-art transformer models may fail to take into account culture, background, and context or understand nuances present in real-world data such as sarcasm.
C1 [Mubarak, Hamdy; Chowdhury, Shammur Absar] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
   [Hassan, Sabit] Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA USA.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Computing Research Institute; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh
RP Mubarak, H (通讯作者)，Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
EM hmubarak@hbku.edu.qa
CR Abdelali A, 2021, P 6 ARABIC NATURAL L, V0, P1
   Abdelali A, 2021, CORR, V0, P0
   Alami H, 2020, P 14 WORKSHOP SEMANT, V0, P2080
   Albadi N, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), V0, PP69, DOI 10.1109/ASONAM.2018.8508247
   Alhazbi S, 2020, IEEE ACCESS, V8, P195132, DOI 10.1109/ACCESS.2020.3033666
   Alshalan R, 2020, P 5 ARABIC NATURAL L, V10, P12
   Alshehri A, 2018, TA COS 2018 2 WORKSH, V0, P15
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Belcastro L, 2020, IEEE ACCESS, V8, P47177, DOI 10.1109/ACCESS.2020.2978950
   Cheng HQ, 2015, IEEE T KNOWL DATA EN, V27, P1045, DOI 10.1109/TKDE.2014.2357012
   Chowdhury SA, 2020, P 5 ARABIC NATURAL L, V0, P226
   Chowdhury SA, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6203
   Conneau A, 2019, ARXIV, V0, P0
   Conover M, 2011, P INT AAAI C WEB SOC, V5, P89, DOI 10.1609/icwsm.v5i1.14126
   Darwish K, 2017, P 9 INT C SOC INF SO, V0, P91
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dimitrov D, 2021, P JOINT C 59 ANN M A, V0, P0
   Dimitrov D, 2021, P 15 INT WORKSH SEM, V21, P0
   Donato G, 2017, P 8 WORKSH COMP APPR, V0, P118
   Durscheid C, 2017, KURZFASSUNG AUF DEUT, V0, P0
   Gülaçti F, 2010, PROCD SOC BEHV, V2, P3844, DOI 10.1016/j.sbspro.2010.03.602
   Hassan S, 2020, P 14 WORKSHOP SEMANT, V0, P1891
   Hassan S, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, V0, P113
   Husain F, 2020, OSACT, V4, P0
   Intapong P, 2017, LECT NOTES COMPUT SC, V10282, P71, DOI 10.1007/978-3-319-58559-8_7
   Kiela D, 2021, ARXIV, V0, P0
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Ling L, 2023, ARXIV, V0, P0, DOI DOI 10.1214/20-BA1223
   Mei QZ, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), V0, PP417, DOI 10.1145/3308560.3316541
   Mubarak Hamdy, 2020, SOCIAL INFORMATICS. 12TH INTERNATIONAL CONFERENCE, V0, P237, DOI 10.1007/978-3-030-60975-7_18
   Mubarak H, 2020, P 4 WORKSHOP OPEN SO, V0, P0
   Mubarak H, 2016, WEAVING RELATIONS TR, V0, P0
   Mubarak H, 2014, P EMNLP 2014 WORKSHO, V0, P1
   Mubarak H, 2021, P 6 ARABIC NATURAL L, V0, P136
   Mubarak H, 2017, P 1 WORKSHOP ABUSIVE, V0, P0, DOI DOI 10.18653/v1/W17-3008
   Mubarak H, 2021, ARXIV, V0, P0
   Nakov P, 2021, ARXIV, V0, P0
   Ousidhoum N, 2019, ARXIV, V0, P0
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, V0, P185
   Polignano M, 2019, CEUR WORKSHOP PROC, VVolume 2481, P1
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Salminen J, 2020, HUM-CENTRIC COMPUT I, V10, P0, DOI 10.1186/s13673-019-0205-6
   Shaar S, 2021, ARXIV, V0, P0
   Waldron J, 2012, HARM HATE SPEECH, V0, P0
   Wiegand M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P369
   Zampieri M, 2020, P SEMEVAL, V0, P0
NR 47
TC 0
Z9 0
U1 1
U2 1
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324923000402
EA AUG 2023
PG 22
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA O6FS2
UT WOS:001044750000001
DA 2023-11-10
ER

PT J
AU Zhu, SL
   Gu, SW
   Li, SJ
   Xu, L
   Xiong, DY
AF Zhu, Shaolin
   Gu, Shiwei
   Li, Shangjie
   Xu, Lin
   Xiong, Deyi
TI Mining parallel sentences from internet with multi-view knowledge distillation for low-resource language pairs
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article; Early Access
DE Neural machine translation; Bilingual corpus; Low-resource language; Knowledge distillation; Deep learning
AB The neural machine translation (NMT), which relies on a large training data (bilingual parallel sentences, for NMT) to obtain the state-of-the-art performance, is similar with deep learning. In order to construct NMT systems, the number of parallel sentences is very important. However, these bilingual resources are scarce for many low-resource language pairs. Although several works attempt to obtain bilingual parallel data from Internet, the quality and quantity of mined bilingual corpus are limited for low-resource language pairs. To address this problem, we propose the multi-view knowledge distillation model (MvKD) that use the knowledge of high-resource language pairs transfer into low-resource languages by leveraging internal language invariant in different languages. In particular, we treat the mining bilingual parallel sentence pair task as classifying task and use the multi-view classifier to detect bilingual parallel sentence pair. For multi-view classifier, we use two views to recognize the semantic difference of two sentences: (i) word-level representations and (ii) sentence-level representations. We encode sentence-level representations to capture semantically similar of two sentences. Moreover, we encode word-level representations to capture word translations in a pair of parallel sentences to avoid the problem that semantically similar but non-parallel sentences. Experimental results demonstrate that our proposed method can significantly mine amount of bilingual corpus and improve the quality of parallel sentences. In particular, we carry out the experiments on several real-world low-resource situations and achieve excellent results.
C1 [Zhu, Shaolin; Gu, Shiwei; Li, Shangjie; Xiong, Deyi] Tianjin Univ, Coll Intelligence & Comp, Weijin Rd, Tianjin 300072, Peoples R China.
   [Xu, Lin] Chengdu Univ Tradit Chinese Med, Chengdu 610002, Sichuan, Peoples R China.
C3 Tianjin University; Chengdu University of Traditional Chinese Medicine
RP Zhu, SL; Xiong, DY (通讯作者)，Tianjin Univ, Coll Intelligence & Comp, Weijin Rd, Tianjin 300072, Peoples R China.
EM zhushaolin003@163.com; dyxiong@tju.edu.cn
FU Key Research and Development Program of Yunnan Province [202203AA080004]
CR Aghaebrahimian A, 2018, P 27 INT C COMPUTATI, V0, P1372
   [Anonymous], 2018, P 3 C MACHINE TRANSL, V0, P0, DOI DOI 10.18653/V1/W18-6317
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Artetxe M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3197
   Artetxe M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P789
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Chen PZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1672
   Chen XL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P261
   Conneau Alexis, 2018, P ICLR, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duong L, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P894
   Eriguchi A, 2018, ARXIV, V0, P0
   Espla-Gomis M, 2016, P 1 C MACHINE TRANSL, V0, PP685, DOI 10.18653/v1/w16-2367
   Fei Hongliang, 2020, P 58 ANN M ASS COMP, V0, PP5759, DOI 10.18653/V1/2020.ACL-MAIN.510
   Gete H, 2022, LANG RESOUR EVAL, V56, P943, DOI 10.1007/s10579-021-09572-2
   Hangya V, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1224
   Heyman G, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1890
   Kajiwara T, 2016, P COLING 2016 26 INT, V0, P1147
   Keung P, 2020, T ASSOC COMPUT LING, V8, P828, DOI 10.1162/tacl_a_00348
   Kocmi T, 2020, ARXIV, V0, P0
   Koehn P, 2019, P 4 C MACH TRANSL WM, V0, P0
   Krishnan Jitin, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), V0, PP1850, DOI 10.1109/BigData55660.2022.10021079
   Kvapilíková I, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, V0, P255
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lee J, 2023, LECT NOTES COMPUTER, V0, P0
   Paetzold G, 2018, P 3 C MACH TRANSL SH, V0, P923
   Schwenk H, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1351
   Schwenk H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P228
   Schwenk Holger, 2021, P 59 ANN M ASS COMPU, V0, PP6490, DOI 10.18653/V1/2021.ACL-LONG.507
   Sun HP, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3525
   Vo T, 2023, ACM T ASIAN LOW-RESO, V22, P0, DOI 10.1145/3530260
   Wada T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3113
   Wan Y, 2022, COMPUT LINGUIST, V48, P321, DOI 10.1162/coli_a_00435
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P833
   Xu YL, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8141
   Zhang B, 2020, IEEE T PATTERN ANAL, V42, P154, DOI 10.1109/TPAMI.2018.2876404
   Zhang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1959, DOI 10.18653/v1/P17-1179
   Ziser Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P238
   Zweigenbaum P, 2018, 11 WORKSHOP BUILDING, V0, P0
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10115-023-01925-3
EA AUG 2023
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA P4GA5
UT WOS:001050234100001
DA 2023-11-10
ER

PT J
AU Fang, XM
   Wang, F
   Liu, LH
   He, JZ
   Lin, DY
   Xiang, YF
   Zhu, KR
   Zhang, XA
   Wu, H
   Li, H
   Song, L
AF Fang, Xiaomin
   Wang, Fan
   Liu, Lihang
   He, Jingzhou
   Lin, Dayong
   Xiang, Yingfei
   Zhu, Kunrui
   Zhang, Xiaonan
   Wu, Hua
   Li, Hui
   Song, Le
TI A method for multiple-sequence-alignment-free protein structure prediction using a protein language model
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article; Early Access
AB Protein structure prediction pipelines based on artificial intelligence, such as AlphaFold2, have achieved near-experimental accuracy. These advanced pipelines mainly rely on multiple sequence alignments (MSAs) as inputs to learn the co-evolution information from the homologous sequences. Nonetheless, searching MSAs from protein databases is time consuming, usually taking tens of minutes. Consequently, we attempt to explore the limits of fast protein structure prediction by using only primary structures of proteins. Our proposed method, HelixFold-Single, combines a large-scale protein language model with the superior geometric learning capability of AlphaFold2. HelixFold-Single first pre-trains a large-scale protein language model with thousands of millions of primary structures utilizing the self-supervised learning paradigm, which will be used as an alternative to MSAs for learning the co-evolution information. Then, by combining the pre-trained protein language model and the essential components of AlphaFold2, we obtain an end-to-end differentiable model to predict the three-dimensional coordinates of atoms from only the primary structure. HelixFold-Single is validated on datasets CASP14 and CAMEO, achieving competitive accuracy with the MSA-based methods on targets with large homologous families. Furthermore, HelixFold-Single consumes much less time than the mainstream pipelines for protein structure prediction, demonstrating its potential in tasks requiring many predictions. AlphaFold2 has revolutionized bioinformatics, but its ability to predict protein structures with high accuracy comes at the price of a costly database search for multiple sequence alignments. Fang and colleagues pre-train a large-scale protein language model and use it in conjunction with AlphaFold2 as a fully trainable and efficient model for structure prediction.
C1 [Fang, Xiaomin; Wang, Fan; Liu, Lihang; He, Jingzhou; Lin, Dayong; Xiang, Yingfei; Zhu, Kunrui; Zhang, Xiaonan; Wu, Hua] Baidu Inc, NLP, Shenzhen, Peoples R China.
   [Li, Hui; Song, Le] BioMap, Beijing, Peoples R China.
C3 Baidu
RP Wang, F (通讯作者)，Baidu Inc, NLP, Shenzhen, Peoples R China.; Song, L (通讯作者)，BioMap, Beijing, Peoples R China.
EM wang.fan@baidu.com; songle@biomap.com
FU This work is supported by the National Engineering Research Center of Deep Learning Technology and Applications.; National Engineering Research Center of Deep Learning Technology and Applications
CR [Anonymous], 2023, PADDL PADDL V1 2 2, V0, P0
   Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754
   Bateman A, 2023, NUCLEIC ACIDS RES, V51, PD523, DOI 10.1093/nar/gkac1052
   Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235
   Brown PF, 1992, COMPUTATIONAL LINGUISTICS, V18, P31
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Burley SK, 2021, NUCLEIC ACIDS RES, V49, PD437, DOI 10.1093/nar/gkaa1038
   Chowdhury R, 2021, BIORXIV, V0, P0, DOI DOI 10.1101/2021.08.02.454840
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du ZY, 2021, NAT PROTOC, V16, P5634, DOI 10.1038/s41596-021-00628-9
   Elnaggar A, 2021, ARXIV, V0, P0
   He Pengcheng, 2020, ARXIV200603654, V0, P0
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kinch LN, 2021, PROTEINS, V89, P1618, DOI 10.1002/prot.26202
   Kryshtafovych A, 2021, PROTEINS, V89, P1607, DOI 10.1002/prot.26237
   Mirdita M, 2017, NUCLEIC ACIDS RES, V45, PD170, DOI 10.1093/nar/gkw1081
   Moult J, 2005, CURR OPIN STRUC BIOL, V15, P285, DOI 10.1016/j.sbi.2005.05.011
   Peng J, 2011, PROTEINS, V79, P161, DOI 10.1002/prot.23175
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Radford Alec, 2018, OPENAI BLOG, V0, P0
   Rao R, 2021, 9 INT C LEARN REPR I, V0, P0
   Rao R, 2021, PR MACH LEARN RES, V139, P0
   Rao RS, 2019, ADV NEUR IN, V32, P0
   Rives A, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2016239118
   Robin X, 2021, PROTEINS, V89, P1977, DOI 10.1002/prot.26213
   Suzek BE, 2015, BIOINFORMATICS, V31, P926, DOI 10.1093/bioinformatics/btu739
   Varadi M, 2022, NUCLEIC ACIDS RES, V50, PD439, DOI 10.1093/nar/gkab1061
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang WK, 2022, NAT COMPUT SCI, V2, P804, DOI 10.1038/s43588-022-00373-3
   Weissenow K, 2022, STRUCTURE, V30, P1169, DOI 10.1016/j.str.2022.05.001
   Xiao Y, 2021, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2108.07435
   Yang JY, 2020, P NATL ACAD SCI USA, V117, P1496, DOI 10.1073/pnas.1914677117
   Yang JY, 2015, NAT METHODS, V12, P7, DOI 10.1038/nmeth.3213
   Zhang Y, 2004, PROTEINS, V57, P702, DOI 10.1002/prot.20264
NR 34
TC 0
Z9 0
U1 5
U2 5
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1038/s42256-023-00721-6
EA OCT 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA T9PU7
UT WOS:001081239300001
DA 2023-11-10
ER

PT J
AU Touma, R
   Hajj, H
   El-Hajj, W
   Shaban, K
AF Touma, Roudy
   Hajj, Hazem
   El-Hajj, Wassim
   Shaban, Khaled
TI Automated Generation of Human-readable Natural Arabic Text from RDF Data
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Low-resource languages; data-to-text; RDF; language models; neural networks; datasets
AB With the advances in Natural Language Processing (NLP), the industry has been moving towards human-directed artificial intelligence (AI) solutions. Recently, chatbots and automated news generation have captured a lot of attention. The goal is to automatically generate readable text from tabular data or web data commonly represented in Resource Description Framework (RDF) format. The problem can then be formulated as Data-to-text (D2T) generation from structured non-linguistic data into human-readable natural language. Despite the significant work done for the English language, no efforts are being directed towards low-resource languages like the Arabic language. This work promotes the development of the first RDF data-to-text (D2T) generation system for the Arabic language while trying to address the low-resource limitation. We develop several models for the Arabic D2T task using transfer learning from large language models (LLM) such as AraBERT, AraGPT2, and mT5. These models include a baseline Bi-LSTM Sequence-to-Sequence (Seq2Seq) model, as well as encoder-decoder transformers like BERT2BERT, BERT2GPT, and T5. We then provide a detailed comparative study highlighting the strengths and limitations of these methods setting the stage for further advancement in the field. We also introduce a new Arabic dataset (AraWebNLG) that can be used for new model development in the field. To ensure a comprehensive evaluation, general-purpose automated metrics (BLEU and Perplexity scores) are used as well as task-specific human evaluation metrics related to the accuracy of the content selection and fluency of the generated text. The results highlight the importance of pre-training on a large corpus of Arabic data and show that transfer learning from AraBERT gives the best performance. Text-to-text pre-training using mT5 achieves second best performance results even with multilingual weights.
C1 [Touma, Roudy; Hajj, Hazem; El-Hajj, Wassim] Amer Univ Beirut, POB 11-0236, Beirut 1107, Lebanon.
   [Shaban, Khaled] Qatar Univ, POB 2713, Doha, Qatar.
C3 American University of Beirut; Qatar University
RP Touma, R (通讯作者)，Amer Univ Beirut, POB 11-0236, Beirut 1107, Lebanon.
EM rst10@mail.aub.edu; hh63@aub.edu.lb; we07@aub.edu.lb; khaled.shaban@qu.edu.qa
FU Qatar National Research Fund (Qatar Foundation) [NPRP13S-0112-200037]
CR Antoun W, 2021, P 6 ARABIC NATURAL L, V0, P196
   Antoun Wissam, 2020, LREC 2020 WORKSHOP L, V0, P0
   Bizer C, 2009, IEEE INTELL SYST, V24, P87, DOI 10.1109/MIS.2009.102
   Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5016
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Darwish K, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1070
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   ElJundi O, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), V0, P68
   Ferreira Thiago, 2020, P 3 INT WORKSH NAT L, V0, P0
   Ferreira TC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P552
   Gardent C, 2017, P 10 INT C NAT LANG, V0, P0
   Hassan Hany, 2019, P 3RDWORKSHOP NEURAL, V0, P289
   Kale Mihir, 2020, ARXIV200510433, V0, P0
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Li Xintong, 2020, P 3 INT WORKSHOP NAT, V0, P117
   Moryossef A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2267
   Mota Abelardo Vieira, 2020, ADVANCES IN DATABASES AND INFORMATION SYSTEMS. 24TH EUROPEAN CONFERENCE, V0, P157, DOI 10.1007/978-3-030-54832-2_13
   Parikh AP, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1173
   Puduppully R, 2019, AAAI CONF ARTIF INTE, V0, P6908
   Puzikov Y, 2018, P 11 INT C NATURAL L, V0, PP463, DOI 10.18653/v1/w18-6557
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rebuffel Clement, 2020, ADVANCES IN INFORMATION RETRIEVAL, V0, P0
   Ribeiro LFR, 2021, P 3 WORKSH NAT LANG, V11, P211, DOI 10.18653/V1/2021.NLP4CONVAI-1.20
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI 10.1162/tacl_a_.00313
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wiseman S, 2017, P 2017 C EMPIRICAL M, V0, P0
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Ye Rong, 2020, INT C LEARNING REPRE, V0, P0
NR 30
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR 15
PY 2023
VL 22
IS 4
BP 
EP 
DI 10.1145/3582262
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FI3
UT WOS:000998929700006
DA 2023-11-10
ER

PT J
AU Chen, CR
   Bunescu, R
   Marling, C
AF Chen, Charles
   Bunescu, Razvan
   Marling, Cindy
TI A semantic parsing pipeline for context-dependent question answering over temporally structured data
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Semantic Parsing; Question Answering
ID speech; networks
AB We propose a new setting for question answering (QA) in which users can query the system using both natural language and direct interactions within a graphical user interface that displays multiple time series associated with an entity of interest. The user interacts with the interface in order to understand the entity's state and behavior, entailing sequences of actions and questions whose answers may depend on previous factual or navigational interactions. We describe a pipeline implementation where spoken questions are first transcribed into text which is then semantically parsed into logical forms that can be used to automatically extract the answer from the underlying database. The speech recognition module is implemented by adapting a pre-trained long short-term memory (LSTM)-based architecture to the user's speech, whereas for the semantic parsing component we introduce an LSTM-based encoder-decoder architecture that models context dependency through copying mechanisms and multiple levels of attention over inputs and previous outputs. When evaluated separately, with and without data augmentation, both models are shown to substantially outperform several strong baselines. Furthermore, the full pipeline evaluation shows only a small degradation in semantic parsing accuracy, demonstrating that the semantic parser is robust to mistakes in the speech recognition output. The new QA paradigm proposed in this paper has the potential to improve the presentation and navigation of the large amounts of sensor data and life events that are generated in many areas of medicine.
C1 [Chen, Charles; Bunescu, Razvan; Marling, Cindy] Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
C3 University System of Ohio; Ohio University
RP Bunescu, R (通讯作者)，Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
EM razvan.bunescu@uncc.edu
FU National Institutes of Health [1R21EB022356]
CR Artzi Yoav, 2011, P C EMP METH NAT LAN, V0, P421
   Bahdanau D, 2016, ARXIV, V0, P0
   Bai Y, 2019, INTERSPEECH, V0, PP3795, DOI 10.21437/Interspeech.2019-1554
   Baskar MK, 2019, INTERSPEECH, V0, PP3790, DOI 10.21437/Interspeech.2019-3167
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chan W, 2016, INT CONF ACOUST SPEE, V0, PP4960, DOI 10.1109/ICASSP.2016.7472621
   Chen C, 2019, IEEE INT C SEMANT CO, V0, PP371, DOI 10.1109/ICOSC.2019.8665509
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Corona Rodolfo, 2017, P 8 INT JOINT C NAT, V2, P122
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doetsch P, 2017, IEEE J-STSP, V11, P1265, DOI 10.1109/JSTSP.2017.2752691
   Doetsch P, 2016, INT CONF FRONT HAND, V0, PP361, DOI 10.1109/ICFHR.2016.0074
   Dong L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P33
   Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Gulcehre C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P140, DOI 10.18653/v1/p16-1014
   Harabagiu Sanda, 2005, P 43 ANN M ASS COMP, V0, P205
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Iyyer M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1821, DOI 10.18653/v1/P17-1167
   Jia R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P12
   KELLY D, 2007, SIGIR FORUM, V41, P107, DOI 10.1145/1273221.1273231
   Kingma DP, 2014, C TRACK P, V0, P0
   Li J, 2019, INTERSPEECH, V0, PP71, DOI 10.21437/Interspeech.2019-1819
   Liang P, 2016, COMMUN ACM, V59, P68, DOI 10.1145/2866568
   Long R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1456
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Matarneh R, 2017, IOSR J COMPUTER ENG, V19, P71
   Mdhaffar S, 2019, INTERSPEECH, V0, PP569, DOI 10.21437/Interspeech.2019-2661
   Pham NQ, 2019, INTERSPEECH, V0, PP66, DOI 10.21437/Interspeech.2019-2702
   Norouzi M, 2016, ADV NEURAL INFORM PR, V0, P1723
   Paulus Romain, 2018, 6 INT C LEARN REPR I, V0, P0
   Raju A, 2019, INTERSPEECH, V0, PP3910, DOI 10.21437/Interspeech.2019-3060
   Ranzato M, 2016, ICLR, V0, P1
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Sak H, 2017, INTERSPEECH, V0, PP1298, DOI 10.21437/Interspeech.2017-1705
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sigurdsson S, 2006, ISMIR, V0, P286
   Toshniwal S, 2017, INTERSPEECH, V0, PP3532, DOI 10.21437/Interspeech.2017-1118
   Weston J, 2016, ICLR, V0, P1
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wiseman Sam, 2016, P 2016 C EMPIRICAL M, V0, PP1296, DOI 10.18653/V1/D16-1137
   Yin PC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4553
   Zeng W, 2016, ABS161103382 CORR, V0, P0
   Zettlemoyer LS, 2009, ACL, V2, P976
   Zeyer A, 2018, INTERSPEECH, V0, P7
   Zhong Victor, 2017, ARXIV170900103, V0, P0
NR 48
TC 0
Z9 0
U1 1
U2 3
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD MAY 15
PY 2023
VL 29
IS 3
BP 769
EP 793
DI 10.1017/S1351324921000292
EA OCT 2021
PG 25
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA G9DT7
UT WOS:000776657300001
PM 37456861
DA 2023-11-10
ER

PT J
AU Sun, H
   Yang, Z
   Cai, Q
   Wei, GW
   Mo, ZW
AF Sun, Hong
   Yang, Zhen
   Cai, Qiang
   Wei, Guiwu
   Mo, Zhiwen
TI An extended Exp-TODIM method for multiple attribute decision making based on the Z-Wasserstein distance
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Multiple attribute decision making; Z-mixture-number; Wasserstein distance; exp-TODIM method; Carbon storage site selection
ID hesitant fuzzy-sets; intuitionistic fuzzy; aggregation operators; prospect-theory; model
AB Z-numbers, as relatively emerging fuzzy numbers, are to a large extent close to human language. For this reason, the Z-number is a powerful tool for representing expert evaluation information. However, the Z-number is more complex than the general structure of fuzzy numbers since it consists of both the fuzzy restriction A and the reliability measure B. As a result, calculating of the Z-number is a very complex process. This paper uses a modified Wasserstein distance to measure the distance between two Z-numbers, which avoids the loss of in-formation better than the existing metric. Then a new decision model is constructed by combining the Z-Was-serstein distance with the exponential TODIM method(exp-TODIM), which is less susceptible to changes in parameters and has good stability. Next, a detailed example of choosing a reasonable carbon storage site is given to illustrate the feasibility of the exp-TODIM method with wasserstein distance. Finally, a sensitivity analysis is given to illustrate the stability of the method, and a comparative analysis is used to state the advantages of the method.
C1 [Sun, Hong; Yang, Zhen; Wei, Guiwu; Mo, Zhiwen] Sichuan Normal Univ, Sch Math Sci, Chengdu 610101, Peoples R China.
   [Cai, Qiang; Wei, Guiwu] Sichuan Normal Univ, Sch Business, Chengdu 610101, Peoples R China.
C3 Sichuan Normal University; Sichuan Normal University
RP Wei, GW (通讯作者)，Sichuan Normal Univ, Sch Math Sci, Chengdu 610101, Peoples R China.
EM caiqiang@sicnu.edu.cn; weiguiwu@163.com; mozhiwen@263.net
CR Abdullah S, 2022, AIMS MATH, V7, P4735, DOI 10.3934/math.2022263
   Alali F, 2019, EXPERT SYST APPL, V124, P341, DOI 10.1016/j.eswa.2019.01.054
   Ashraf S, 2019, J BIOSTATISTICS BIOM, V4, P0, DOI 10.1016/j.eswa.2019.01.054
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Bernton E, 2019, J R STAT SOC B, V81, P235, DOI 10.1111/rssb.12312
   Chai JH, 2021, FUZZY OPTIM DECIS MA, V20, P529, DOI 10.1007/s10700-021-09351-2
   Cheng RL, 2021, CHIN CONT DECIS CONF, V0, PP3823, DOI 10.1109/CCDC52312.2021.9601658
   Cheng RL, 2022, INT J FUZZY SYST, V24, P2813, DOI 10.1007/s40815-022-01297-w
   Das S, 2022, INT J INTELL SYST, V37, P625, DOI 10.1002/int.22642
   Das S, 2020, IEEE T FUZZY SYST, V28, P2131, DOI 10.1109/TFUZZ.2019.2930935
   Farhadinia B, 2019, APPL SOFT COMPUT, V78, P310, DOI 10.1016/j.asoc.2019.02.024
   Gao J, 2019, INT J MACH LEARN CYB, V10, P1613, DOI 10.1007/s13042-018-0839-0
   Gomes LFAM, 1991, FOUNDATIONS OF COMPUTING AND DECISION SCIENCES, V16, P113
   Gong KX, 2019, ENG APPL ARTIF INTEL, V85, P393, DOI 10.1016/j.engappai.2019.05.008
   Hu JH, 2018, INT J FUZZY SYST, V20, P1240, DOI 10.1007/s40815-017-0320-3
   Huang YH, 2021, TECHNOL ECON DEV ECO, V27, P1019, DOI 10.3846/tede.2021.15038
   Irvanizam I, 2022, IEEE ACCESS, V10, P47476, DOI 10.1109/ACCESS.2022.3170565
   Irvanizam I, 2021, APPL COMPUT INTELL S, V2021, P0, DOI 10.1155/2021/1474629
   Irvanizam I, 2020, ADV FUZZY SYST, V2020, P0, DOI 10.1155/2020/6190149
   Irvanizam I, 2018, INT CONF ELECT ENG, V0, PP122, DOI 10.1109/ICELTICS.2018.8548820
   Jan N, 2019, J INTELL FUZZY SYST, V36, P253, DOI 10.3233/JIFS-181253
   Jiang ZW, 2022, J INTELL FUZZY SYST, V42, P1723, DOI 10.3233/JIFS-211171
   Kang B, 1900, V9, V0, P703
   Khan AA, 2019, MATHEMATICS-BASEL, V7, P0, DOI 10.3390/math7101000
   Khan AA, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11030383
   Lei F, 2022, TECHNOL ECON DEV ECO, V28, P179, DOI 10.3846/tede.2021.15884
   Leoneti AB, 2021, EUR J OPER RES, V295, P1042, DOI 10.1016/j.ejor.2021.03.055
   Li YF, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/8407830
   Liao HC, 2019, INT J DISAST RISK RE, V38, P0, DOI 10.1016/j.ijdrr.2019.101190
   Liao HC, 2019, APPL SOFT COMPUT, V80, P450, DOI 10.1016/j.asoc.2019.04.018
   Lin MW, 2020, ARTIF INTELL REV, V53, P3647, DOI 10.1007/s10462-019-09774-9
   Lin MW, 2018, J OPER RES SOC, V69, P157, DOI 10.1057/s41274-017-0182-y
   Lipman Y, 2013, MATH COMPUT, V82, P331
   Liu BS, 2021, APPL ENERG, V303, P0, DOI 10.1016/j.apenergy.2021.117624
   Liu PD, 2019, IEEE ACCESS, V7, P127728, DOI 10.1109/ACCESS.2019.2937854
   Liu PD, 2019, INT J INTELL SYST, V34, P1755, DOI 10.1002/int.22114
   Liu PD, 2019, COGN SYST RES, V57, P175, DOI 10.1016/j.cogsys.2018.10.005
   Liu PD, 2019, COMPUT IND ENG, V131, P282, DOI 10.1016/j.cie.2019.04.004
   Liu PD, 2019, COGN COMPUT, V11, P125, DOI 10.1007/s12559-018-9597-2
   Liu PD, 2017, GRANULAR COMPUT, V2, P333, DOI 10.1007/s41066-017-0047-4
   Lu ZM, 2020, J CLEAN PROD, V248, P0, DOI 10.1016/j.jclepro.2019.119265
   Mariucci E, 2018, ELECTRON J STAT, V12, P2482, DOI 10.1214/18-EJS1456
   Naeem M, 2021, J INTELL FUZZY SYST, V40, P11479, DOI 10.3233/JIFS-202700
   Ning BQ, 2022, INT J MACH LEARN CYB, V13, P3887, DOI 10.1007/s13042-022-01631-6
   Ning BQ, 2022, INT J FUZZY SYST, V24, P3626, DOI 10.1007/s40815-022-01350-8
   Ning BQ, 2022, EXPERT SYST APPL, V204, P0, DOI 10.1016/j.eswa.2022.117419
   Peng HG, 2019, INFORM SCIENCES, V501, P136, DOI 10.1016/j.ins.2019.05.090
   Peng HG, 2017, INT J FUZZY SYST, V19, P1300, DOI 10.1007/s40815-016-0257-y
   Qiu JD, 2018, KSII T INTERNET INF, V12, P3128, DOI 10.3837/tiis.2018.07.009
   Qiyas M, 2022, J MATH-UK, V2022, P0, DOI 10.1155/2022/4912964
   Qiyas M, 2021, J AMB INTEL HUM COMP, V12, P8285, DOI 10.1007/s12652-020-02563-1
   Qiyas M, 2019, MATH FDN COMPUT, V2, P183, DOI 10.3934/mfc.2019013
   Rahman K, 2018, INT J FUZZY SYST, V20, P1567, DOI 10.1007/s40815-018-0452-0
   Sahin R, 2018, NEURAL COMPUT APPL, V30, P3095, DOI 10.1007/s00521-017-2896-9
   Shen KW, 2020, IEEE T FUZZY SYST, V28, P1851, DOI 10.1109/TFUZZ.2019.2923948
   Shen KW, 2018, IEEE T FUZZY SYST, V26, P3232, DOI 10.1109/TFUZZ.2018.2816581
   Su Z, 2019, IEEE ACCESS, V7, P65714, DOI 10.1109/ACCESS.2019.2916564
   Torra V, 2010, INT J INTELL SYST, V25, P529, DOI 10.1002/int.20418
   Verdinelli I, 2019, ELECTRON J STAT, V13, P5088, DOI 10.1214/19-EJS1639
   Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5
   Wang JQ, 2017, COGN COMPUT, V9, P827, DOI 10.1007/s12559-017-9493-1
   Wang QF, 2019, J INTELL FUZZY SYST, V37, P1639, DOI 10.3233/JIFS-179228
   Wang SQ, 2022, SOFT COMPUT, V26, P237, DOI 10.1007/s00500-021-06429-2
   Wang WZ, 2019, INT J UNCERTAIN FUZZ, V27, P353, DOI 10.1142/S0218488519500168
   Wei GW, 2021, SOFT COMPUT, V0, P0, DOI DOI 10.1007/s00500-021-05842-x
   Wu Q, 2019, COMPUT IND ENG, V127, P954, DOI 10.1016/j.cie.2018.11.029
   Xian SD, 2021, INFORM SCIENCES, V550, P145, DOI 10.1016/j.ins.2020.10.038
   Xian SD, 2019, INT J INTELL SYST, V34, P271, DOI 10.1002/int.22050
   Xiao L, 2021, J INTELL FUZZY SYST, V41, P7031, DOI 10.3233/JIFS-210918
   Xu ZS, 2019, FRONT ENG MANAG, V6, P163, DOI 10.1007/s42524-019-0017-4
   Yahya M, 2021, COMPLEXITY, V2021, P0, DOI 10.1155/2021/5534381
   Ye J, 2021, SOFT COMPUT, V25, P13975, DOI 10.1007/s00500-021-06199-x
   Ye J, 2019, INT J SYST SCI, V50, P152, DOI 10.1080/00207721.2018.1551968
   Ye J, 2019, INT J MACH LEARN CYB, V10, P667, DOI 10.1007/s13042-017-0747-8
   Yin JL, 2019, J CIV ENG MANAG, V25, P673, DOI 10.3846/jcem.2019.10521
   ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4
   Zadeh LA, 2011, INFORM SCIENCES, V181, P2923, DOI 10.1016/j.ins.2011.02.022
   Zha MW, 2021, TECHNOL ECON DEV ECO, V27, P1186, DOI 10.3846/tede.2021.15044
   Zhang D, 2022, TECHNOL ECON DEV ECO, V28, P201, DOI 10.3846/tede.2021.15758
   Zhang HY, 2022, ENG APPL ARTIF INTEL, V110, P0, DOI 10.1016/j.engappai.2022.104679
   Zhang SS, 2021, J INTELL FUZZY SYST, V41, P3783, DOI 10.3233/JIFS-211461
   Zhao JB, 2019, EXPERT SYST APPL, V127, P97, DOI 10.1016/j.eswa.2019.02.034
   Zhao MW, 2021, INT J INTELL SYST, V36, P6337, DOI 10.1002/int.22552
   Zhou W, 2018, IEEE T FUZZY SYST, V26, P1367, DOI 10.1109/TFUZZ.2017.2723349
   Zhu B, 2018, TECHNOL ECON DEV ECO, V24, P1029, DOI 10.3846/20294913.2016.1266529
NR 85
TC 18
Z9 18
U1 23
U2 68
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 15
PY 2023
VL 214
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.119114
EA OCT 2022
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 6F0UO
UT WOS:000883786000010
DA 2023-11-10
ER

PT J
AU Habernal, I
   Faber, D
   Recchia, N
   Bretthauer, S
   Gurevych, I
   Döhmann, ISG
   Burchard, C
AF Habernal, Ivan
   Faber, Daniel
   Recchia, Nicola
   Bretthauer, Sebastian
   Gurevych, Iryna
   Doehmann, Indra Spiecker Genannt
   Burchard, Christoph
TI Mining legal arguments in court decisions
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article; Early Access
DE Argument mining; Legal arguments; ECHR; Tranformers
AB Identifying, classifying, and analyzing arguments in legal discourse has been a prominent area of research since the inception of the argument mining field. How-ever, there has been a major discrepancy between the way natural language process -ing (NLP) researchers model and annotate arguments in court decisions and the way legal experts understand and analyze legal argumentation. While computational approaches typically simplify arguments into generic premises and claims, argu-ments in legal research usually exhibit a rich typology that is important for gain-ing insights into the particular case and applications of law in general. We address this problem and make several substantial contributions to move the field forward. First, we design a new annotation scheme for legal arguments in proceedings of the European Court of Human Rights (ECHR) that is deeply rooted in the theory and practice of legal argumentation research. Second, we compile and annotate a large corpus of 373 court decisions (2.3M tokens and 15k annotated argument spans). Finally, we train an argument mining model that outperforms state-of-the-art models in the legal NLP domain and provide a thorough expert-based evaluation. All data-sets and source codes are available under open lincenses at https://github.com/trust hlt/mining-legal-arguments.
C1 [Habernal, Ivan; Faber, Daniel] Tech Univ Darmstadt, Trustworthy Human Language Technol, Darmstadt, Germany.
   [Bretthauer, Sebastian; Doehmann, Indra Spiecker Genannt; Burchard, Christoph] Goethe Univ Frankfurt Main, Fac Law, Frankfurt, Germany.
   [Gurevych, Iryna] Tech Univ Darmstadt, Ubiquitous Knowledge Proc UKP Lab, Darmstadt, Germany.
   [Recchia, Nicola] Univ Trieste, Dept Legal Language Interpreting & Translat Studi, Trieste, Italy.
C3 Technical University of Darmstadt; Goethe University Frankfurt; Technical University of Darmstadt; University of Trieste
RP Habernal, I (通讯作者)，Tech Univ Darmstadt, Trustworthy Human Language Technol, Darmstadt, Germany.
EM ivan.habernal@tu-darmstadt.de
FU RMU-Initiativsfond Forschung (Forderlinie 2); DFG project ECALP [HA 8018/2-1]; Hessian Ministry of Higher Education, Research, Science and the Arts
CR Ammann O, 2020, DOMESTIC COURTS INTE, V0, P0
   [Anonymous], 2006, P 5 INT C LANG RES E, V0, P0
   Barak A, 2012, PROPORTIONALITY CONS, V0, P0, DOI DOI 10.1017/CBO9781139035293
   Chalkidis I, 2020, FINDINGS ASS COMPUTA, V0, P2898
   Eckart de Castilho R, 2014, P WORKSHOP OPEN INFR, V0, PP1, DOI 10.3115/V1/W14-5201
   Feteris ET, 2017, FUNDAMENTALS LEGAL A, V2, P0, DOI 10.1007/978-94-024-1129-4
   Grabenwarter C, 2021, EUROPAISCHE MENSCHEN, V7th, P0
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, V0, PP8342, DOI 10.18653/V1/2020.ACL-MAIN.740
   Habernal I, 2017, COMPUT LINGUIST, V43, P125, DOI 10.1162/COLI_a_00276
   Klie Jan-Christoph, 2018, P 27 INT C COMP LING, V0, PP5, DOI 10.18653/V1/D18-2022
   Krippendorff K, 2014, CONTENT ANAL INTRO I, V0, P309
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Maultzsch F, 2017, METHODIK ZIVILRECHTS, V0, P0
   Meyer Christian M, 2014, P 25 INT C COMP LING, V0, P105
   Mochales R, 2011, ARTIF INTELL LAW, V19, P1, DOI 10.1007/s10506-010-9104-x
   Mochales R, 2008, FRONT ARTIF INTEL AP, V189, P11, DOI 10.3233/978-1-58603-952-3-11
   Mochales-Palau R, 2007, FRONT ARTIF INTEL AP, V165, P89
   Moens M-F, 2007, P 11 INT C ART INT L, V0, PP225, DOI 10.1145/1276318.1276362
   Mowbray A, 2009, HUM RIGHTS LAW REV, V9, P179, DOI 10.1093/hrlr/ngp006
   Mullerat R, 2008, J MONNET R SCHUMAN P, V8, P3
   Poudyal P, 2020, P 7 WORKSHOP ARGUMEN, V0, P67
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reed C, 2004, INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS (ARCHITECTURES, V0, P0
   Reed C, 2001, P 4 C ONTARIO SOC ST, V0, P1
   Ruthers B, 2022, RECHTSTHEORIE JURIST, V12th, P0
   Schabas W, 2015, EUROPEAN CONVENTION, V0, P0
   Simpson E, 2020, AAAI CONF ARTIF INTE, V34, P8862
   Simpson E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1093
   Skalak David B, 1992, ARTIF INTELL, V1, P3, DOI 10.1007/BF00118477
   Stede M, 2018, ARGUMENTATION MINING, V0, P0
   Toulmin SE, 1958, USES ARGUMENT, V0, P0
   Trachtman JP, 2013, TOOLS ARGUMENT BEST, V0, P0
   Walton, 1996, ARGUMENTATION SCHEME, V0, P0
   Walton D, 2012, P INT C ALT METH ARG, V0, P117
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xu HH, 2020, FRONT ARTIF INTEL AP, V334, P184, DOI 10.3233/FAIA200862
   Yamada H, 2019, FRONT ARTIF INTEL AP, V322, P133, DOI 10.3233/FAIA190314
   Yamada H, 2019, ARTIF INTELL LAW, V27, P141, DOI 10.1007/s10506-019-09242-3
   Yu Gu, 2022, ACM TRANSACTIONS ON COMPUTING AND HEALTHCARE, V3, P0, DOI 10.1145/3458754
   Zheng Lucia, 2021, ICAIL 21: PROCEEDINGS OF THE EIGHTEENTH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, V0, PP159, DOI 10.1145/3462757.3466088
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10506-023-09361-y
EA JUN 2023
PG 38
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law
SC Computer Science; Government & Law
GA K9GE5
UT WOS:001019440000001
DA 2023-11-10
ER

PT J
AU Mujahid, M
   Kanwal, K
   Rustam, F
   Aljadani, W
   Ashraf, I
AF mujahid, Muhammad
   Kanwal, Khadija
   Rustam, Furqan
   Aljadani, Wajdi
   Ashraf, Imran
TI Arabic ChatGPT Tweets Classification Using RoBERTa and BERT Ensemble Model
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Arabic tweets; low-resource language; ChatGPT; OpenAI; transformer models; BERT; sentiment analysis
ID sentiment analysis; impact
AB ChatGPT OpenAI, a large-language chatbot model, has gained a lot of attention due to its popularity and impressive performance in many natural language processing tasks. ChatGPT produces superior answers to a wide range of real-world human questions and generates human-like text. The new OpenAI ChatGPT technology may have some strengths and weaknesses at this early stage. Users have reported early opinions about the ChatGPT features, and their feedback is essential to recognize and fix its shortcomings and issues. This study uses the ChatGPT tweets Arabic dataset to automatically find user opinions and sentiments about ChatGPT technology. The dataset is preprocessed and labeled using the TextBlob Arabic Python library into positive, negative, and neutral tweets. Despite extensive works for the English language, languages like Arabic are less studied regarding tweet analysis. Existing literature about Arabic tweet sentiment analysis has mainly focused on machine learning and deep learning models. We collected a total of 27,780 unstructured tweets from Twitter using the Tweepy SNscrape Python library using various hash-tags such as # Chat-GPT, #OpenAI, #Chatbot, Chat-GPT3, and so on. To enhance the model's performance and reduce computational complexity, unstructured tweets are converted into structured and normalized forms. Tweets contain missing values, URL and HTML tags, stop words, punctuation, diacritics, elongations, and numeric values that have no impact on the model performance; hence, these increase the computational cost. So, these steps are removed with the help of Python preprocessing libraries to enhance text quality and consistency. This study adopts Transformer-based models such as RoBERTa, XLNet, and DistilBERT that automatically classify the tweets. Additionally, a hybrid transformer-based model is proposed to obtain better results. The proposed hybrid model is developed by combining the hidden outputs of the RoBERTA and BERT models using a concatenation layer, then adding dense layers with "Relu" activation employed as a hidden layer to create non-linearity and a "softmax" activation function for multiclass classification. They differ from existing state-of-the-art models due to the enhanced capabilities of both models in text classification. Hybrid models combine the different models to make accurate predictions and reduce bias and enhanced the overall results, while state-of-the-art models are incapable of making accurate predictions. Experiments show that the proposed hybrid model achieves 96.02% accuracy, 100% precision on negative tweets, and 99% recall for neutral tweets. The performance of the proposed model is far better than existing state-of-the-art models.
C1 [mujahid, Muhammad] Khwaja Fareed Univ Engn & Information Technol, Dept Comp Sci, Rahim Yar Khan, Pakistan.
   [Kanwal, Khadija] Women Univ Multan, Inst CS & IT, Multan 6600, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin D04 V1W8, Ireland.
   [Aljadani, Wajdi] Univ North Texas, Dept Comp Sci & Engn, Denton, TX USA.
   [Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 University College Dublin; University of North Texas System; University of North Texas Denton; Yeungnam University
RP Ashraf, I (通讯作者)，Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM mujahidws890@gmail.com; khadijakanwal.6022@wum.edu.pk; furqan.rustam1@gmail.com; wajdi.j1@gmail.com; imranashraf@ynu.ac.kr
CR Abu Farha Ibrahim, 2022, P 7 ARABIC NATURAL L, V0, P399
   Al Shamsi Arwa A, 2021, ADV SCI TECHNOL ENG, V6, P1012
   Al-Hassan A, 2022, MULTIMEDIA SYST, V28, P1963, DOI 10.1007/s00530-020-00742-w
   Aldayel HK, 2016, J INF SCI, V42, P782, DOI 10.1177/0165551515610513
   Alduailaj AM, 2023, MACH LEARN KNOW EXTR, V5, P29, DOI 10.3390/make5010003
   Alqarni A, 2023, BIG DATA COGN COMPUT, V7, P0, DOI 10.3390/bdcc7010016
   AlSalman Hussain, 2020, P 3 INT C COMP APPL, V0, P1
   Anjaria K, 2020, EXPERT SYST APPL, V157, P0, DOI 10.1016/j.eswa.2020.113497
   Antoun W, 2021, ARXIV, V0, P0
   Biau G, 2016, TEST-SPAIN, V25, P264, DOI 10.1007/s11749-016-0488-0
   Biswas S, 2023, RADIOLOGY, V307, P0, DOI 10.1148/radiol.223312
   Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7
   Carrasco XA, 2021, PROCEDIA COMPUT SCI, V189, P92, DOI 10.1016/j.procs.2021.05.072
   Celik B, 2023, RED-REV EDUC DISTANC, V23, P0, DOI 10.6018/red.491551
   Cheng LC, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), V0, PP1001, DOI 10.1145/3341161.3344821
   Chouikhi H, 2021, COMM COM INF SC, V1463, P621, DOI 10.1007/978-3-030-88113-9_50
   Chowdhary K, 2020, FUNDAMENTALS ARTIFIC, V0, PP603, DOI 10.1007/978-81-322-3972-7_19
   Cui JF, 2023, ARTIF INTELL REV, V56, P8469, DOI 10.1007/s10462-022-10386-z
   Dahou Abdelhalim Hafedh, 2023, 12TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND ADVANCED TECHNOLOGIES "ICISAT 2022": INTELLIGENT INFORMATION, V0, P135, DOI 10.1007/978-3-031-25344-7_13
   Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601
   Dang CN, 2021, COMPLEXITY, V2021, P0, DOI 10.1155/2021/9986920
   Das B, 2018, ARXIV, V0, P0
   Fawzy Mohamed, 2022, 2022 20TH INTERNATIONAL CONFERENCE ON LANGUAGE ENGINEERING (ESOLEC), V0, PP24, DOI 10.1109/ESOLEC54569.2022.10009633
   Fsih Emna, 2022, P 7 ARABIC NATURAL L, V0, P431
   Gao CA, 2022, BIORXIV, V0, P0
   Guzman E, 2014, INT REQUIR ENG CONF, V0, PP153, DOI 10.1109/RE.2014.6912257
   Hadhood Haret, 2022, THESIS ITA SUOMEN YL, V0, P0
   Hadwan M, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12115547
   Haider Ahmad S, 2022, J INTERCULT COMMUN R, V51, P628
   Haque MU, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2212.05856
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Hong X, 2019, IEEE ACCESS, V7, P80893, DOI 10.1109/ACCESS.2019.2919385
   Jwa H, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9194062
   Khered Abdullah Salem, 2022, P 7 ARABIC NATURAL L, V0, P479
   Kumar V, 2014, INT J DATABASE THEOR, V7, P61, DOI 10.14257/IJDTA.2014.7.1.06
   Li MY, 2017, BIOMED SIGNAL PROCES, V34, P114, DOI 10.1016/j.bspc.2017.01.010
   Liu YH, 2019, ARXIV, V0, P0
   Lock S, 2022, WHAT IS AI CHATBOT P, V0, P0
   Mayfield A, 2008, WHAT IS SOCIAL MEDIA, V0, P0
   Mujahid M, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11188438
   Nassr Z, 2019, 4TH INTERNATIONAL CONFERENCE ON SMART CITY APPLICATIONS (SCA 19), V0, P0, DOI DOI 10.1145/3368756.3369078
   Pascanu R, 2014, ARXIV, V0, P0
   QusayAl-Bayati Abdulhakeem, 2020, J ENG-NY, V26, P85, DOI 10.31026/J.ENG.2020.06.07
   Rahman W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, PP2359, DOI 10.18653/v1/2020.acl-main.214
   Sajjad H, 2022, COMPUT SPEECH LANG, V77, P0, DOI 10.1016/j.csl.2022.101429
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Wenzlaff Karsten, 2022, SMARTER HUMANS VALID, V0, P0, DOI DOI 10.2139/ssrn.4302443
   Zainuddin N, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, V0, P0
   Zheng WY, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 3, PROCEEDINGS
   Zhou XJ, 2013, INT C COMP SUPP COOP, V0, PP557, DOI 10.1109/CSCWD.2013.6581022
NR 51
TC 1
Z9 1
U1 10
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG 15
PY 2023
VL 22
IS 8
BP 
EP 
DI 10.1145/3605889
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q7NS7
UT WOS:001059361200002
DA 2023-11-10
ER

PT J
AU Zheng, JY
   Liu, Y
AF Zheng, Jianyu
   Liu, Ying
TI What does Chinese BERT learn about syntactic knowledge?
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Chinese; BERT; Syntax; Fine-tune; NLP
AB Pre-trained language models such as Bidirectional Encoder Representations from Transformers (BERT) have been applied to a wide range of natural language processing (NLP) tasks and obtained significantly positive results. A growing body of research has investigated the reason why BERT is so efficient and what language knowledge BERT is able to learn. However, most of these works focused almost exclusively on English. Few studies have explored the language information, particularly syntactic information, that BERT has learned in Chinese, which is written as sequences of characters. In this study, we adopted some probing methods for identifying syntactic knowledge stored in the attention heads and hidden states of Chinese BERT. The results suggest that some individual heads and combination of heads do well in encoding corresponding and overall syntactic relations, respectively. The hidden representation of each layer also contained syntactic information to different degrees. We also analyzed the fine-tuned models of Chinese BERT for different tasks, covering all levels. Our results suggest that these fine-turned models reflect changes in conserving language structure. These findings help explain why Chinese BERT can show such large improvements across many language-processing tasks.
C1 [Zheng, Jianyu; Liu, Ying] Tsinghua Univ, Dept Chinese Language & Literature, Beijing, Peoples R China.
C3 Tsinghua University
RP Liu, Y (通讯作者)，Tsinghua Univ, Dept Chinese Language & Literature, Beijing, Peoples R China.
EM yingliu@tsinghua.edu.cn
FU Major Program of the National Social Science Fund of China [18ZDA238]; Tsinghua University Initiative Scientific Research Program [2019THZWJC38]; Beihang University Sponsored Projects for Core Young Researchers in the Disciplines of Social Sciences and Humanities [KG16183801]; Tianjin Postgraduate Scientific Research Innovation Program [2022BKY024]
CR Che W, 2012, CHINESE DEPENDENCY T, V0, P0
   Chen JD, 2010, APPL PSYCHOLINGUIST, V31, P1, DOI 10.1017/S0142716409990257
   Choenni R, 2020, ARXIV COMPUTATION LA, V0, PP1, DOI 10.48550/arXiv.2009.12862
   Choi H, 2021, INT C PATT RECOG, V0, PP5482, DOI 10.1109/ICPR48806.2021.9412102
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, PP276, DOI 10.18653/v1/w19-4828
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Dai Y, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P6674
   de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI 10.1162/coli_a_00402
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Goldberg Yoav, 2019, ABS190105287 ARXIV, V0, P0
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Htut P, 2019, COMPUTATION LANGUAGE, V0, PP1, DOI 10.48550/arXiv.1911.12246
   Hu H, 2020, P 2020 C EMP METH NA, V0, P3512
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Koto F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P3849
   Liu Xin, 2018, P 27 INT C COMP LING, V0, P1952
   Ningyu X, 2022, P 2022 C EMPIRICAL M, V0, PP8073, DOI 10.48550/arXiv.2212.10879
   Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), V0, P58
   Ranaldi L, 2023, APPL SCI-BASEL, V13, P0, DOI 10.3390/app13020677
   Ranaldi L, 2022, FUTURE INTERNET, V14, P0, DOI 10.3390/fi14010010
   Ravichander A, 2020, P 9 JOINT C LEX COMP, V0, P88
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Tenney Ian, 2019, INT C LEARN REPR, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang Jia, 2015, OPEN J MODERN LINGUI, V05, P213, DOI 10.4236/ojml.2015.52017
   Wang Y, 2020, P 28 INT C COMPUTATI, V0, PP2826, DOI 10.18653/v1/2020.coling-main.254
   Wu ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4166
   Xiang BL, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2784
   Xue N, 2013, CHINESE TREEBANK 80, V0, P0, DOI DOI 10.35111/wygn-4f57
   Ye Z, 2007, BRAIN RES, V1142, P135, DOI 10.1016/j.brainres.2007.01.030
   Zhang H, 2018, P 2018 C N AM CHAPT, V2, P175, DOI 10.18653/v1/N18-2028
NR 33
TC 0
Z9 0
U1 15
U2 15
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 26
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1478
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA O5SZ3
UT WOS:001044418900003
PM 37547407
DA 2023-11-10
ER

PT J
AU Kchaou, S
   Boujelbane, R
   Hadrich, L
AF Kchaou, Sameh
   Boujelbane, Rahma
   Hadrich, Lamia
TI Hybrid Pipeline for Building Arabic Tunisian Dialect-standard Arabic Neural Machine Translation Model from Scratch
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Neural Machine Translation; data augmentation; Arabic Tunisian Dialect; Modern Standard Arabic
AB Deep Learning is one of the most promising technologies compared to other methods in the context of machine translation. It has been proven to achieve impressive results on large amounts of parallel data for well-endowed languages. Nevertheless, for low-resource languages such as the Arabic Dialects, Deep Learning models failed due to the lack of available parallel corpora. In this article, we present a method to create a parallel corpus to build an effective NMT model able to translate into MSA, Tunisian Dialect texts present in social networks. For this, we propose a set of data augmentation methods aiming to increase the size of the state-of-the-art parallel corpus. By evaluating the impact of this step, we noticed that it has effectively boosted both the size and the quality of the corpus. Then, using the resulted corpus, we compare the effectiveness of CNN, RNN and transformers models to translate Tunisian Dialect into MSA. Experiments show that a better translation is achieved by the transformer model with a BLEU score of 60 vs., respectively, 33.36 and 53.98 with RNN and CNN models.
C1 [Kchaou, Sameh; Boujelbane, Rahma; Hadrich, Lamia] Univ Sfax, Sfax, Tunisia.
C3 Universite de Sfax
RP Kchaou, S (通讯作者)，Univ Sfax, Sfax, Tunisia.
EM samehkchaou4@gmail.com; rahma.boujelbane@gmail.com; lamia.belguith@fsegs.usf.tn
CR Al-Ibrahim R, 2020, INT CONF INFORM COMM, V0, PP173, DOI 10.1109/ICICS49469.2020.239505
   Almansor EH, 2018, PROC INT C MACH LEAR, V0, P347
   Almansor Ebtesam H, 2017, P INT C RECENT ADV N, V0, PP52, DOI 10.26615/978-954-452-049-6_008
   Bahdanau D, 2016, ARXIV, V0, P0
   Baniata LH, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/7534712
   Bouamor H, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3387
   Bouamor H, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1240
   Boujelbane Rahma, 2013, P 6 INT JOINT C NATU, V0, P419
   Chen Kehai, 2017, P C EMPIRICAL METHOD, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   El-Taher FE, 2016, INT CONF SEL TOP MOB, V0, P67
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Gao F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5539
   Graja M, 2015, IEEE-ACM T AUDIO SPE, V23, P2311, DOI 10.1109/TASLP.2015.2464687
   Hamdi Ahmed, 2013, P MT SUMMIT, V0, P0
   Jeblee Serena, 2014, P EMNLPWORKSHOP ARAB, V0, PP196, DOI 10.3115/v1/W14
   Karakanta A, 2018, MACH TRANSL, V32, P167, DOI 10.1007/s10590-017-9203-5
   Kchaou Sameh, 2020, P 5 ARABIC NATURAL L, V0, P200
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Kreutzer J, 2020, ARXIV, V0, P0
   Li Y, 2020, INFORMATION, V11, P0, DOI 10.3390/info11050255
   Lakew SM, 2018, ARXIV, V0, P0
   Meftouh K, 2015, P 29 PACIFIC ASIA C, V0, P26
   Paszke A, 2019, ARXIV, V0, P0
   Richburg Aquia, 2020, P THE 4 WIDENING NAT, V0, PP151, DOI 10.18653/v1/2020.winlp-1.40
   Rush AM, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), V0, P52
   Salloum W, 2012, P 2012 INT C COMP LI, V0, P385
   Shaw Peter, 2018, NAACL, V0, PP5, DOI 10.18653/V1/N18-2074
   Talafha B, 2020, ARXIV, V0, P0
   Tapo Allahsera Auguste, 2020, P 3RDWORKSHOP TECHNO, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wu SJ, 2019, ARXIV, V0, P0
   Zhang JY, 2019, ARXIV, V0, P0
   Zribi I, 2017, J KING SAUD UNIV-COM, V29, P147, DOI 10.1016/j.jksuci.2017.01.004
NR 34
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2023
VL 22
IS 3
BP 
EP 
DI 10.1145/3568674
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FA8
UT WOS:000998922200023
DA 2023-11-10
ER

PT J
AU Kumar, S
   Chauhan, A
AF Kumar, Shobhan
   Chauhan, Arun
TI Augmenting Textbooks with cQA Question-Answers and Annotated YouTube Videos to Increase Its Relevance
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Community question-answers (cQA); VCs; Language modeling; Topic modeling; BERT fine tuning; e-books
ID selection
AB The community question-answering (CQA) websites such as Quora(1), and Reddit(2), and YouTube provides a significant resource to the students. However, there is a redundancy issue which results in inadequate search results for a given question. On the other hand, e-book is primary source of knowledge for students. The Latent Dirichlet Allocation (LDA) topic model helps us to find the key topic of the e-book. The major flaw of this LDA is that it can't capture the semantic knowledge in the documents. As a result, it fails to find the semantically cohesive, and meaningful topics. To address this issue, we propose a novel sBERT-LDA model, which augments the e-books with recommended question-answers and videos. We construct SiameseBERT (Bidirectional Encoder Representations from Transformers) network which provides the semantically relevant phrase embeddings. The model identifies the key topics of the e-book, after which sBERT is used to assess the similarity between the question-answers. This effort also provides advanced video indexing methods for each recommended video, allowing videos with "Table of Contents" and "Phrase Cloud" features to make videos more consumable. Experiments were carried out on question-answers datasets (Quora (QQP), TREC QA, and Yahoo Answers) as well as e-books on various subjects and across different grades.The model outperforms previous research by a large margin.
C1 [Kumar, Shobhan; Chauhan, Arun] Indian Inst Informat Technol, Dharwad, Karnataka, India.
RP Kumar, S (通讯作者)，Indian Inst Informat Technol, Dharwad, Karnataka, India.
EM shobhank9@gmail.com
CR Abishek K, 2019, ADV INTELL SYST COMP, V758, P769, DOI 10.1007/978-981-13-0514-6_73
   Agrawal R, 2010, PROCEEDINGS OF THE FIRST ACM SYMPOSIUM ON COMPUTING FOR DEVELOPMENT (ACM DEV 2010), V0, P0
   Angelov D, 2020, ARXIV200809470, V0, P470
   Bishop CM, 2006, PATTERN RECOGN, V0, P738
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bonadiman D, 2017, P 15 C EUR CHAPT ASS, V2, P726
   Campello RJGB, 2013, PACIFIC ASIA C KNOWL, V0, PP160, DOI 10.1007/978-3-642-37456-2_14
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P169
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chen Q, 2018, AAAI CONF ARTIF INTE, V0, P265
   Chen Q, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP815, DOI 10.1145/3209978.3210019
   Chtouki Y, 2012, 2012 INT C INF TECHN, V0, PP1, DOI 10.1109/ITHET.2012.6246045
   Conneau A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1699
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS16), V0, PP191, DOI 10.1145/2959100.2959190
   DeWitt D, 2013, PROCD SOC BEHV, V103, P1118, DOI 10.1016/j.sbspro.2013.10.439
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Gao H, 2021, ABS210200677 CORR, V0, P0
   Guo JH, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP789, DOI 10.1145/3041021.3054216
   Han J, 2012, MOR KAUF D, V0, P1
   Heriyanto, 2018, ETERNAL ENGLISH TEAC, V0, P0
   Hoogeveen D, 2018, 12 INT AAAI C WEB SO, V0, P0
   Hua H, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P3229
   Hutto CJ, 2014, ICWSM, V0, P0, DOI DOI 10.1609/ICWSM.V8I1.14550
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Jackman WMarc, 2013, JOURNAL OF EDUCATIONAL TECHNOLOGY SYSTEMS, V42, P273, DOI 10.2190/ET.42.3.f
   Jelodar H, 2020, J CIRCUIT SYST COMP, V29, P0, DOI 10.1142/S0218126620502485
   Karan M, 2018, EXPERT SYST APPL, V91, P418, DOI 10.1016/j.eswa.2017.09.031
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Kumar S, 2023, COMPUT J, V66, P1139, DOI 10.1093/comjnl/bxac003
   Kumar S, 2019, TENCON IEEE REGION, V0, PP707, DOI 10.1109/tencon.2019.8929272
   Laskar MTR, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5505
   Laskar MTR, 2020, UTILIZING BIDIRECTIO, V0, P0
   Li CM, 2009, FRONT ARTIF INTEL AP, V185, P613, DOI 10.3233/978-1-58603-929-5-613
   Liu FY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1442
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Loria Steven, 2018, TEXTBLOB DOCUMENTATI, V0, P269
   MacKay DJC, 2002, INFORM THEORY INFERE, V0, P0
   Maheshwari P, 2015, 2015 IEEE 3RD INTERNATIONAL CONFERENCE ON MOOCS, V0, P1, DOI 10.1109/MITE.2015.7375276
   McInnes Leland, 2020, ARXIV, V0, P0
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mirakyan, 2019, NATURAL LANGUAGE INF, V0, P0
   Cirne MVM, 2018, MULTIMED TOOLS APPL, V77, P857, DOI 10.1007/s11042-016-4300-7
   Narang K, 2019, INDUCED MULTIRELATIO, V0, P0
   Nie LQ, 2017, IEEE T KNOWL DATA EN, V29, P1186, DOI 10.1109/TKDE.2017.2669982
   Ostendorff M, 2020, ABS200309881 CORR, V0, P0
   Peinelt N, 2020, P 58 ANN M ASS COMPU, V0, PP7047, DOI 10.18653/V1/2020.ACL-MAIN.630
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ranganatha S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATION SYSTEM AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTIONS (CSITSS), V0, PP1, DOI 10.1109/CSITSS.2016.7779430
   Rao JF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5370
   Reimers N, 2016, P COLING 2016 26 INT, V0, P87
   Roy PK, 2021, INFORM MANAGEMENT MA, V0, PP285, DOI 10.1007/978-981-15-4936-6_32
   Shao B, 2017, 12TH CHINESE CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CHINESECSCW 2017), V0, PP80, DOI 10.1145/3127404.3127426
   Su J, 2021, ABS210315316 CORR, V0, P0
   Suneera C, 2021, ADV MACHINE LEARNING, V0, P341
   Syed S, 2017, PR INT CONF DATA SC, V0, PP165, DOI 10.1109/DSAA.2017.61
   Tay Y, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP695, DOI 10.1145/3077136.3080790
   Upadhya BS, 2019, INT CONF COMPUT, V0, P0, DOI DOI 10.1109/icccnt45670.2019.8944861
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wakchaure M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), V0, PP879, DOI 10.1109/ICCS45141.2019.9065834
   Wang L, 2021, ABS210900253 CORR, V0, P0
   Wang LT, 2020, IEEE ACCESS, V8, P25964, DOI 10.1109/ACCESS.2020.2968391
   Wang M, 2007, WHAT IS JEOPARDY MOD, V0, P0
   Williams A, 2018, P C N AM CHAPT ASS C, V1, P1112, DOI 10.18653/V1/N18-1101
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1746
   Xu S, 2020, ABS200105609 CORR, V0, P0
   Yang HJ, 2014, IEEE T LEARN TECHNOL, V7, P142, DOI 10.1109/TLT.2014.2307305
   Yang M, 2020, NEURAL NETWORKS, V132, P53, DOI 10.1016/j.neunet.2020.08.005
   Yang RQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4699
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, PP2013, DOI 10.18653/V1/D15-1237
   Yang Zhengfa, 2019, INTERNATIONAL JOURNAL OF CROWD SCIENCE, V3, P348, DOI 10.1108/IJCS-03-2019-0011
   Yao Y, 2015, INFORM SCIENCES, V302, P70, DOI 10.1016/j.ins.2014.12.038
   Yianilos PN, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, V0, P361
   Zhang WE, 2018, ACM T INTERNET TECHN, V18, P0, DOI 10.1145/3169795
   Zheng QH, 2020, DISCRETE DYN NAT SOC, V2020, P0, DOI 10.1155/2020/4706576
   Zheng QH, 2020, MULTIDIM SYST SIGN P, V31, P793, DOI 10.1007/s11045-019-00686-z
   Zheng QH, 2018, IEEE ACCESS, V6, P15844, DOI 10.1109/ACCESS.2018.2810849
   Zhou XQ, 2018, NEUROCOMPUTING, V274, P8, DOI 10.1016/j.neucom.2016.07.082
NR 81
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD FEB 15
PY 2023
VL 55
IS 1
BP 551
EP 588
DI 10.1007/s11063-022-10897-4
EA JUN 2022
PG 38
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9P3AR
UT WOS:000819302200001
DA 2023-11-10
ER

PT J
AU Tuli, S
   Dedhia, B
   Tuli, S
   Jha, NK
AF Tuli, Shikhar
   Dedhia, Bhishma
   Tuli, Shreshth
   Jha, Niraj K.
TI FlexiBERT: Are Current Transformer Architectures too Homogeneous and Rigid?
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
LA English
DT Article
ID optimization
AB The existence of a plethora of language models makes the problem of selecting the best one for a custom task challenging. Most state-of-the-art methods leverage transformer-based models (e.g., BERT) or their variants. However, training such models and exploring their hyperparameter space is computationally expensive. Prior work proposes several neural architecture search (NAS) methods that employ performance predictors (e.g., surrogate models) to address this issue; however, such works limit analysis to homogeneous models that use fixed dimensionality throughout the network. This leads to sub-optimal architectures. To address this limitation, we propose a suite of heterogeneous and flexible models, namely FlexiBERT, that have varied encoder layers with a diverse set of possible operations and different hidden dimensions. For better-posed surrogate modeling in this expanded design space, we propose a new graph-similarity-based embedding scheme. We also propose a novel NAS policy, called BOSHNAS, that leverages this new scheme, Bayesian modeling, and second-order optimization, to quickly train and use a neural surrogate model to converge to the optimal architecture. A comprehensive set of experiments shows that the proposed policy, when applied to the FlexiBERT design space, pushes the performance frontier upwards compared to traditional models. FlexiBERT-Mini, one of our proposed models, has 3% fewer parameters than BERT-Mini and achieves 8.9% higher GLUE score. A FlexiBERT model with equivalent performance as the best homogeneous model has 2.6x smaller size. FlexiBERT-Large, another proposed model, attains state-of-the-art results, outperforming the baseline models by at least 5.7% on the GLUE benchmark.
C1 [Tuli, Shikhar; Dedhia, Bhishma; Jha, Niraj K.] Princeton Univ Princeton, Dept Elect & Comp Engn, Princeton, NJ 08544 USA.
   [Tuli, Shreshth] Imperial Coll London, Dept Comp, London SW7 2AZ, England.
C3 Imperial College London
RP Tuli, S (通讯作者)，Princeton Univ Princeton, Dept Elect & Comp Engn, Princeton, NJ 08544 USA.
EM STULI@PRINCETON.EDU; BDEDHIA@PRINCETON.EDU; S.TULI20@IMPERIAL.AC.UK; JHA@PRINCETON.EDU
FU NSF [CNS-1907381, CCF-2203399]; Princeton Research Computing at Princeton University
CR Abu-Aisheh Zeina, 2015, 4TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2015). PROCEEDINGS, V0, P271
   Akiba T, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2623, DOI 10.1145/3292500.3330701
   Chen DY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2463
   Cheng HP, 2021, AAAI CONF ARTIF INTE, V35, P7090
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dang DC, 2021, AAAI CONF ARTIF INTE, V35, P12275
   Gal Y, 2016, PR MACH LEARN RES, V48, P0
   Gao JH, 2022, AAAI CONF ARTIF INTE, V0, P10663
   Gokaslan Aaron, 2019, OPENWEBTEXT CORPUS, V0, P0
   HanruiWang ZhanghaoWu, 2020, P 58 ANN M ASS COMPU, V0, PP7675, DOI 10.18653/V1/2020.ACL-MAIN.686
   He X, 2021, KNOWL-BASED SYST, V212, P0, DOI 10.1016/j.knosys.2020.106622
   Hou Lu, 2020, NEURIPS, V33, P9782
   Huang C-ZA, 2018, P INT C LEARNING REP, V0, P0
   Jiang Z-H, 2020, ADV NEURAL INFORM PR, V33, P12837
   Khetan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2807
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lee-Thorp J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P4296
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Lu ZC, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO19), V0, PP419, DOI 10.1145/3321707.3321729
   Luong Minh-Thang, 2015, EMNLP, V0, P3
   Mackenzie J, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP3077, DOI 10.1145/3340531.3412762
   Mazzawi H, 2019, INTERSPEECH, V0, PP1278, DOI 10.21437/Interspeech.2019-1916
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Narayanan A, 2017, GRAPH2VEC LEARNING D, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pham Hieu, 2018, ICML, V0, P0, DOI DOI 10.48550/ARXIV.1802.03268
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Real E, 2019, AAAI CONF ARTIF INTE, V0, P4780
   Ru R, 2020, ADV NEURAL INF PROCE, V33, P12057
   Russell S, 2010, ARTIF INTELL, V3, P0
   Shaw Peter, 2018, NAACL, V0, PP5, DOI 10.18653/V1/N18-2074
   Shervashidze N, 2011, J MACH LEARN RES, V12, P2539
   Siems Julien, 2020, ARXIV200809777, V0, P0
   Snoek J, 2012, ADV NEURAL INFORM PR, V25, P2951
   So D, 2021, ADV NEURAL INFORM PR, V34, P6010
   So DR, 2019, ABS190111117 CORR, V0, P0
   Song Kaitao, 2020, ADV NEURAL INFORM PR, V33, P16857, DOI 10.48550/ARXIV.2004.09297
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2158
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Tuli S, 2022, IEEE T PARALL DISTR, V33, P2821, DOI 10.1109/TPDS.2021.3136672
   Tuli S, 2022, IEEE T PARALL DISTR, V33, P101, DOI 10.1109/TPDS.2021.3087349
   Turc Iulia, 2019, ARXIV190808962, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang H, 2016, ADV NEUR IN, V29, P0
   White C, 2021, ADV NEURAL INFORM PR, V0, P0
   White C, 2021, AAAI CONF ARTIF INTE, V35, P10293
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xu J, 2021, KDD 21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1933, DOI 10.1145/3447548.3467262
   Xu K, 2019, POWERFUL ARE GRAPH N, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yao ZW, 2021, AAAI CONF ARTIF INTE, V35, P10665
   Yin YC, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5146
   Ying Chris, 2019, INT C MACH LEARN, V0, PP7105, DOI 10.1007/978-3-030-05318-5_3
   Yu Y, 2022, IEEE T EMERG TOP COM, V10, P237, DOI 10.1109/TETC.2020.3003328
   Zhang X, 2018, PROC CVPR IEEE, V0, PP6848, DOI 10.1109/CVPR.2018.00716
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
   Zoph B, 2017, P INT C LEARN REPR I, V0, P0
   Zoph B, 2018, PROC CVPR IEEE, V0, PP8697, DOI 10.1109/CVPR.2018.00907
NR 62
TC 0
Z9 0
U1 0
U2 0
PU AI ACCESS FOUNDATION
PI MARINA DEL REY
PA USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA
SN 1076-9757
EI 1943-5037
J9 J ARTIF INTELL RES
JI J. Artif. Intell. Res.
PD JUN 15
PY 2023
VL 77
IS 
BP 39
EP 70
DI 
PG 32
WC Computer Science, Artificial Intelligence
SC Computer Science
GA G5GN6
UT WOS:000989439700002
DA 2023-11-10
ER

PT J
AU Wu, Y
   Jiang, L
   Yang, Y
AF Wu, Yu
   Jiang, Lu
   Yang, Yi
TI Switchable Novel Object Captioner
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Image captioning; novel object captioning; zero-shot learning
AB Image captioning aims at automatically describing images by sentences. It often requires lots of paired image-sentence data for training. However, trained captioning models can hardly be applied to new domains in which some novel words exist. In this paper, we introduce the zero-shot novel object captioning task, where the machine generates descriptions about novel objects without extra training sentences. To tackle the challenging task, we mimic the way that babies talk about something unknown, i.e., using the word of a similar known object. Following this motivation, we build a key-value object memory by detection models, containing visual information and corresponding words for objects in the image. For those novel objects, we use words of most similar seen objects as proxy visual words to solve the out-of-vocabulary issue. We then propose a Switchable LSTM that incorporates knowledge from the object memory into sentence generation. The model has two switchable working modes, i.e., 1) generating the sentences like standard LSTMs and 2) retrieving proper nouns from the key-value memory. Thus our model is learned to fully disentangle language generation from training objects, and requires zero training sentence in describing novel objects. Experiments on three large-scale datasets demonstrate the ability of our method to describe novel concepts.
C1 [Wu, Yu] Baidu Res, Beijing 100000, Peoples R China.
   [Wu, Yu] Princeton Univ, Sch Comp Sci, Princeton, NJ 08540 USA.
   [Jiang, Lu] Google Res, Mountain View 94043, CA USA.
   [Yang, Yi] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Baidu; Princeton University; Google Incorporated; Zhejiang University
RP Yang, Y (通讯作者)，Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310058, Zhejiang, Peoples R China.
EM yw5952@princeton.edu; lujiang@google.com; yangyics@zju.edu.cn
CR Agrawal H, 2019, IEEE I CONF COMP VIS, V0, PP8947, DOI 10.1109/ICCV.2019.00904
   Anderson P, 2017, P 2017 C EMP METH NA, V0, PP936, DOI 10.18653/v1/D17-1098
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2016, 12 USENIX S OP SYST, V0, P0
   [Anonymous], 2015, SHOW TELL NEURAL IMA, V0, P0
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, V0, PP65, DOI 10.3115/1626355.1626389
   Bengio S, 2015, ADV NEUR IN, V28, P0
   Cao TJ, 2020, AAAI CONF ARTIF INTE, V34, P10494
   Donahue J, 2015, PROC CVPR IEEE, V0, PP2625, DOI 10.1109/CVPR.2015.7298878
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng QY, 2020, IEEE T CIRC SYST VID, V30, P3413, DOI 10.1109/TCSVT.2020.2965966
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hendricks LA, 2016, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2016.8
   Huang J, 2017, PROC CVPR IEEE, V0, PP3296, DOI 10.1109/CVPR.2017.351
   Jiang L, 2015, MM15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, V0, PP49, DOI 10.1145/2733373.2806237
   Jiang L, 2015, ICMR15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP27, DOI 10.1145/2671188.2749399
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kingma DP, 2015, ABS14126980 CORR, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Lu JS, 2018, PROC CVPR IEEE, V0, PP7219, DOI 10.1109/CVPR.2018.00754
   Mao J, 2015, PROC INT C LEARN REP, V0, P0
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, V0, P747
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Ranzato M, 2016, ICLR, V0, P1
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Rohrbach M, 2011, PROC CVPR IEEE, V0, PP1641, DOI 10.1109/CVPR.2011.5995627
   Simonyan K, 2015, P 3 INT C LEARN REPR, V0, P0
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Tavakoli HR, 2017, IEEE I CONF COMP VIS, V0, PP2506, DOI 10.1109/ICCV.2017.272
   Venugopalan S, 2017, PROC CVPR IEEE, V0, PP1170, DOI 10.1109/CVPR.2017.130
   Venugopalan S, 2015, IEEE I CONF COMP VIS, V0, PP4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang XH, 2021, PROC CVPR IEEE, V0, PP5075, DOI 10.1109/CVPR46437.2021.00504
   Wang X, 2019, AAAI CONF ARTIF INTE, V0, P8965
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Q, 2016, PROC CVPR IEEE, V0, PP4622, DOI 10.1109/CVPR.2016.500
   Wu Y, 2021, PROC CVPR IEEE, V0, PP1326, DOI 10.1109/CVPR46437.2021.00138
   Wu Y, 2019, IEEE I CONF COMP VIS, V0, PP6301, DOI 10.1109/ICCV.2019.00639
   Wu Y, 2020, IEEE T IMAGE PROCESS, V29, P3984, DOI 10.1109/TIP.2020.2967584
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP1029, DOI 10.1145/3240508.3240640
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yao T, 2017, PROC CVPR IEEE, V0, PP5263, DOI 10.1109/CVPR.2017.559
   You QZ, 2016, PROC CVPR IEEE, V0, PP4651, DOI 10.1109/CVPR.2016.503
   Zhu LC, 2017, INT J COMPUT VISION, V124, P409, DOI 10.1007/s11263-017-1033-7
NR 51
TC 22
Z9 22
U1 14
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JAN 1
PY 2023
VL 45
IS 1
BP 1162
EP 1173
DI 10.1109/TPAMI.2022.3144984
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 7B9BG
UT WOS:000899419900073
PM 35077354
DA 2023-11-10
ER

PT J
AU Yuan, MR
   Kao, B
   Wu, TH
   Cheung, MMK
   Chan, HWH
   Cheung, ASY
   Chan, FWH
   Chen, YX
AF Yuan, Mingruo
   Kao, Ben
   Wu, Tien-Hsuan
   Cheung, Michael M. K.
   Chan, Henry W. H.
   Cheung, Anne S. Y.
   Chan, Felix W. H.
   Chen, Yongxi
TI Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article; Early Access
DE Legal knowledge dissemination; Navigability and comprehensibility of legal information; Machine question generation; Pre-trained language model
ID readability
AB Access to legal information is fundamental to access to justice. Yet accessibility refers not only to making legal documents available to the public, but also rendering legal information comprehensible to them. A vexing problem in bringing legal information to the public is how to turn formal legal documents such as legislation and judgments, which are often highly technical, to easily navigable and comprehensible knowledge to those without legal education. In this study, we formulate a three-step approach for bringing legal knowledge to laypersons, tackling the issues of navigability and comprehensibility. First, we translate selected sections of the law into snippets (called CLIC-pages), each being a small piece of article that focuses on explaining certain technical legal concept in layperson's terms. Second, we construct a Legal Question Bank, which is a collection of legal questions whose answers can be found in the CLIC-pages. Third, we design an interactive CLIC Recommender. Given a user's verbal description of a legal situation that requires a legal solution, CRec interprets the user's input and shortlists questions from the question bank that are most likely relevant to the given legal situation and recommends their corresponding CLIC pages where relevant legal knowledge can be found. In this paper we focus on the technical aspects of creating an LQB. We show how large-scale pre-trained language models, such as GPT-3, can be used to generate legal questions. We compare machine-generated questions against human-composed questions and find that MGQs are more scalable, cost-effective, and more diversified, while HCQs are more precise. We also show a prototype of CRec and illustrate through an example how our 3-step approach effectively brings relevant legal knowledge to the public.
C1 [Yuan, Mingruo; Kao, Ben; Wu, Tien-Hsuan] Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China.
   [Cheung, Michael M. K.; Chan, Henry W. H.; Cheung, Anne S. Y.; Chan, Felix W. H.] Univ Hong Kong, Fac Law, Pokfulam, Hong Kong, Peoples R China.
   [Chen, Yongxi] Australian Natl Univ, Coll Law, Canberra, ACT 2601, Australia.
C3 University of Hong Kong; University of Hong Kong; Australian National University
RP Yuan, MR (通讯作者)，Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China.
EM mryuan@cs.hku.hk; kao@cs.hku.hk; thwu@cs.hku.hk; michaelmkcheung@hku.hk; hwhchan@hku.hk; anne.cheung@hku.hk; fwhchan@hku.hk; yongxi.chen@anu.edu.au
FU Innovation and Technology Fund [ITS/234/20]; WYNG Foundation [HKU KG210018]
CR Becher SI, 2021, CONSUMER LAW EC EC A, V0, PP179, DOI 10.1007/978-3-030-49028-7_9
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Curtotti M, 2015, J OPEN ACCESS L, V3, P57
   Dai Z, 2022, INT C MACH LEARN, V0, P4558
   Das R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P542, DOI 10.1109/ICACCI.2016.7732102
   Du XY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1342, DOI 10.18653/v1/P17-1123
   Dyson DD, 2017, J POVERTY, V21, P142, DOI 10.1080/10875549.2016.1186773
   Heilman M, 2010, HUMAN LANGUAGE TECHN, V0, P609
   Kaplan J, 2020, ARXIV, V0, P0
   Kim Y, 2019, AAAI CONF ARTIF INTE, V0, P6602
   Lindberg D, 2013, P 14 EUR WORKSH NAT, V0, P105
   Liu B, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2032, DOI 10.1145/3366423.3380270
   Min B, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2111.01243
   Mommers L, 2011, INF TECHNOL LAW SER, V20, P383, DOI 10.1007/978-90-6704-731-9_21
   Mommers L, 2009, ARTIF INTELL LAW, V17, P51, DOI 10.1007/s10506-008-9073-5
   New Zealand Law Reform Commission, 2008, PRES NZ STAT LAW NZL, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ruohonen J, 2021, INT CONF EDEMOC EGOV, V0, PP205, DOI 10.1109/ICEDEG52154.2021.9530996
   Schick T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6943
   Song L, 2018, P 2018 C N AM CHAP A, V2, P569
   Steuer T, 2022, FRONT ARTIF INTELL, V5, P0, DOI 10.3389/frai.2022.900304
   Wang SY, 2019, AAAI CONF ARTIF INTE, V0, P7168
   Wang ZC, 2022, LECT NOTES COMPUT SC, V13355, P153, DOI 10.1007/978-3-031-11644-5_13
NR 24
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10506-023-09367-6
EA JUL 2023
PG 37
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law
SC Computer Science; Government & Law
GA L4ZR6
UT WOS:001023368400001
DA 2023-11-10
ER

PT J
AU Milosevic, N
   Thielemann, W
AF Milosevic, Nikola
   Thielemann, Wolfgang
TI Comparison of biomedical relationship extraction methods and models for knowledge graph creation
SO JOURNAL OF WEB SEMANTICS
LA English
DT Article
DE Knowledge graphs; Information extraction; Machine learning; Natural language processing; Text mining; Text-to-text model; Linked data; Transformers; PubMedBERT; T5; SciFive
AB Biomedical research is growing at such an exponential pace that scientists, researchers, and practition-ers are no more able to cope with the amount of published literature in the domain. The knowledge presented in the literature needs to be systematized in such a way that claims and hypotheses can be easily found, accessed, and validated. Knowledge graphs can provide such a framework for semantic knowledge representation from literature. However, in order to build a knowledge graph, it is necessary to extract knowledge as relationships between biomedical entities and normalize both entities and relationship types. In this paper, we present and compare a few rule-based and machine learning-based (Naive Bayes, Random Forests as examples of traditional machine learning methods and DistilBERT, PubMedBERT, T5, and SciFive-based models as examples of modern deep learning transformers) methods for scalable relationship extraction from biomedical literature, and for the integration into the knowledge graphs. We examine how resilient are these various methods to unbalanced and fairly small datasets. Our experiments show that transformer-based models handle well both small (due to pre-training on a large dataset) and unbalanced datasets. The best performing model was the PubMedBERT-based model fine-tuned on balanced data, with a reported F1-score of 0.92. The distilBERT-based model followed with an F1-score of 0.89, performing faster and with lower resource requirements. BERT-based models performed better than T5-based generative models.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Milosevic, Nikola] Univ Manchester, Fac Sci & Engn, Oxford Rd, Manchester M13 9PL, England.
   [Milosevic, Nikola] Bayer Pharmaceut R&D, Mullerstr 178, D-13353 Berlin, Germany.
   [Thielemann, Wolfgang] Bayer Pharmaceut R&D, Friedrich Ebert Str 475, D-42117 Wuppertal, Germany.
C3 University of Manchester
RP Milosevic, N (通讯作者)，Bayer Pharmaceut R&D, Mullerstr 178, D-13353 Berlin, Germany.
EM nikola.milosevic@bayer.com
CR [Anonymous], 2007, P C EMPIRICAL METHOD, V0, P0
   [Anonymous], 2004, 3 INT SEMANTIC WEB C, V0, P0
   Arnold P, 2015, DATENBANKSYSTEME BUS, V0, P0
   Becker KG, 2004, NAT GENET, V36, P431, DOI 10.1038/ng0504-431
   Belousov M, 2019, ARXIV, V0, P0
   Ben Abacha Asma, 2011, J BIOMED SEMANTICS, V2 Suppl 5, PS4, DOI 10.1186/2041-1480-2-S5-S4
   Bhasuran B, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0200699
   Canese K, 2013, NCBI HDB, V0, P0
   Carvalho-Silva D, 2019, NUCLEIC ACIDS RES, V47, PD1056, DOI 10.1093/nar/gky1133
   Cho H, 2017, BMC BIOINFORMATICS, V18, P0, DOI 10.1186/s12859-017-1857-8
   COHEN AM, 2005, P ACL ISMB WORKSH LI, V0, P17
   Collier N, 2000, COLING 2000 VOLUME 1, V0, P0
   Coppernoll-Blach P, 2011, J MED LIBR ASSOC, V99, P176, DOI 10.3163/1536-5050.99.2.017
   Deng P, 2019, P 5 WORKSH BIONLP OP, V0, PP143, DOI 10.18653/V1/D19-5721
   Devlin J, 2019, ARXIV, V0, P0
   Fukuda K, 1998, PAC SYMP BIOCOMPUT, V0, P707
   Gerner M, 2010, BMC BIOINFORMATICS, V11, P0, DOI 10.1186/1471-2105-11-85
   Goertzel B, 2006, P HLT NAACL BIONLP W, V0, P104
   Hakala K, 2016, P 15 WORKSHOP BIOMED, V0, PP102, DOI 10.18653/V1/W16-2913
   Hebbar S, 2021, INT FLAIRS C P, V34, P0
   Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166
   Herrero-Zazo M, 2013, J BIOMED INFORM, V46, P914, DOI 10.1016/j.jbi.2013.07.011
   Hogan A, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3447772
   Ji Zongcheng, 2020, AMIA JT SUMMITS TRANSL SCI PROC, V2020, P269
   Jonnagaddala J, 2015, P 5 BIOCREATIVE CHAL, V0, P9
   Jonnalagadda S, 2010, J BIOMED DISCOV COLL, V5, P50
   Kim J, 2017, SCI REP-UK, V7, P0, DOI 10.1038/srep39768
   Krallinger M, 2020, DRUGPROT SHARED TASK, V0, P0
   Krallinger M, 2017, P 6 BIOCREATIVE CHAL, V0, PP141, DOI 10.1093/DATABASE/BAY073/5055578
   Lan ZZ, 2020, ARXIV, V0, P0
   Leaman R, 2015, J CHEMINFORMATICS, V7, P0, DOI 10.1186/1758-2946-7-S1-S3
   Lee Y, 2022, BERTSRC BERT BASED S, V0, P0
   Li HD, 2017, BMC BIOINFORMATICS, V18, P0, DOI 10.1186/s12859-017-1805-7
   Li J, 2016, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/baw068
   Liu S, 2017, TRAINING, V1020, P4157
   Liu YH, 2019, ARXIV, V0, P0
   Luo L, 2022, BRIEF BIOINFORM, V23, P0, DOI 10.1093/bib/bbac282
   McGuinness DL, 2004, W3C RECOMMENDATION, V10, P0, DOI 10.2004-03
   Messchendorp AL, 2020, NEPHROL DIAL TRANSPL, V35, P1306, DOI 10.1093/ndt/gfz054
   Messina A, 2018, ADV INTELL SYST, V611, P299, DOI 10.1007/978-3-319-61566-0_28
   Miller Justin J, 2013, P SO ASS INF SYST C, V2324, P0
   Milosevic N, 2020, ARXIV, V0, P0
   Mintz M, 2009, P JOINT C 47 ANN M A, V0, PP1003, DOI 10.3115/1690219.1690287
   Miranda A, 2021, P 7 BIOCREATIVE CHAL, V0, P11
   Muzaffar AW, 2015, COMPUT MATH METHOD M, V2015, P0, DOI 10.1155/2015/910423
   National Library of Medicine, 2020, CIT ADD MEDLINE FISC, V0, P0
   Parmar J, 2020, ARXIV, V0, P0
   Peng N, 2017, T ASSOC COMPUT LING, V5, P101, DOI 10.1162/TACL_A_00049
   Peng Y, 2018, ARXIV, V0, P0
   Phan LN, 2021, ABS210603598 CORR, V0, P0
   Piñero J, 2017, NUCLEIC ACIDS RES, V45, PD833, DOI 10.1093/nar/gkw943
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Pyysalo S, 2007, BMC BIOINFORMATICS, V8, P0, DOI 10.1186/1471-2105-8-50
   Qu Meng, 2019, PR MACH LEARN RES, V0, PP5241, DOI 10.48550/ARXIV.1905.06214
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ravikumar KE, 2017, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/baw156
   Khan MR, 2020, ARXIV, V0, P0
   Rindflesch T C, 2000, PAC SYMP BIOCOMPUT, V0, P517
   Roberts RJ, 2001, P NATL ACAD SCI USA, V98, P381, DOI 10.1073/pnas.98.2.381
   Sanh V, 2020, ARXIV, V0, P0
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schneider EW, 1973, COURSE MODULARIZATIO, V0, P0
   Shazeer N, 2018, PR MACH LEARN RES, V80, P0
   Shearer RD, 2008, OWLED, V432, P91
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Speer Robyn, 2013, PEOPLES WEB MEETS NL, V0, PP3, DOI 10.1007/978-3-642-35085-6_6
   Su JH, 2021, NAR GENOM BIOINFORM, V3, P0, DOI 10.1093/nargab/lqab062
   Szklarczyk D, 2019, NUCLEIC ACIDS RES, V47, PD607, DOI 10.1093/nar/gky1131
   Tarawneh AS, 2022, IEEE ACCESS, V0, P0
   Veličkovic P, 2018, ARXIV, V0, P0
   Wang XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP1082, DOI 10.1145/3366423.3380186
   Yang X, 2021, BMC BIOINFORMATICS, V22, P1
   Zhang YY, 2018, AAAI CONF ARTIF INTE, V0, P6069
   Zhou HW, 2020, BMC BIOINFORMATICS, V21, P0, DOI 10.1186/s12859-020-3375-3
   Zitnik M, 2018, BIOINFORMATICS, V34, P457, DOI 10.1093/bioinformatics/bty294
NR 78
TC 5
Z9 5
U1 3
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1570-8268
EI 1873-7749
J9 J WEB SEMANT
JI J. Web Semant.
PD JAN 15
PY 2023
VL 75
IS 
BP 
EP 
DI 10.1016/j.websem.2022.100756
EA SEP 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering
SC Computer Science
GA 6L9VH
UT WOS:000888526400001
DA 2023-11-10
ER

PT J
AU Xu, XH
   Chai, JY
   Chen, XH
AF Xu, Xuanhua
   Chai, Junyi
   Chen, Xiaohong
TI A hesitation-feedback recommendation approach and its application in large-scale group emergency decision making
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Consensus modelling; Decision making; Emergency decision; Large-scale group; Natural language preferences
ID supplier selection; consensus model; fuzzy
AB Group Decision Making (GDM) has been well studied in the last two decades. Yet, two challenges exist: (a) how to resolve large-scale groups in GDM and achieve the consensus of preferences and (b) how to conduct GDM under risk and emergency conditions. In this paper, we develop a complete problem-solving approach for GDM that orients twofold settings of the complex large-scale group and the time-sensitive emergency decision sce-narios. The crux of the matter is to design a feasible mechanism of group consensus strategies in the environment of time pressure and natural language preferences. To solve this problem, we propose a closed-loop mechanism of feedback recommendation strategies accompanied with a new subgroup identification method. This mechanism is underlain by a fourfold decomposition of complex large-scale groups, which entails multiple thresholds of group consensus, group hesitation, and time-related iteration of loops. Our mechanism and the whole GDM approach thoroughly orient the most intuitive representation of preferences -human natural language, which can be elicited and quantitatively formulated in probability linguistic preference systems. We illustrate the proposed approach through a real case study of China's fight against the COVID-19 epidemic. We verify that our mech-anism can perfectly tradeoff between the effectiveness and the efficiency of complex large-scale GDM under risk and emergency. The results of this research provide proposals for mechanisms on large-scale GDM and are ex-pected to contribute to emergency management such as epidemic controls, anti-terrorism, and other man-made or natural hazards.
C1 [Xu, Xuanhua; Chen, Xiaohong] Cent South Univ, Sch Business, Changsha, Peoples R China.
   [Chai, Junyi] BNU HKBU United Int Coll, Fac Business & Management, Zhuhai, Peoples R China.
   [Chen, Xiaohong] Hunan Univ Technol & Business, Sch Frontier Interdisciplinary, Changsha, Peoples R China.
C3 Central South University; Beijing Normal University - Hong Kong Baptist University United International College; Hunan University of Technology & Business
RP Chai, JY (通讯作者)，BNU HKBU United Int Coll, Fac Business & Management, Zhuhai, Peoples R China.
EM xuxh@csu.edu.cn; donchaiam@gmail.com; cxh@csu.edu.cn
FU National Natural Science Foundation of China [71971217, 72271032]; Major Project of the Natural Science Foundation of China [72091515, 71790615]; Independent Exploration of Innovation Project for Postgraduate of Central South University [2018zzts300]; Guangdong Higher Education Upgrading Plan (2021-2025) of "Rushing to the Top, Making Up Shortcomings and Strengthening Special Features" [UICR0400027-21, UICR0400042-21CTL]; 2020 Scientific Research Platforms and Projects of Guangdong Provincial Education Department [2020WQNCX069]
CR [Anonymous], 2008, DECIS ANAL, V0, P0
   Arrow Kenneth J, 1951, SOCIAL CHOICE INDIVI, V0, P0
   Baker RE, 2020, P NATL ACAD SCI USA, V117, P30547, DOI 10.1073/pnas.2013182117
   Bell DE, 1988, DECISION MAKING DESC, V0, P0, DOI DOI 10.1017/CBO9780511598951.003
   Bonacich P, 2001, SOC NETWORKS, V23, P191, DOI 10.1016/S0378-8733(01)00038-7
   Cai CG, 2017, SOFT COMPUT, V21, P5765, DOI 10.1007/s00500-016-2155-5
   Chai J, 2021, INT C IND ENG ENGINE, V0, P0
   Chai J, 2021, MACHINE LEARNING APP, V6, P0
   Chai JY, 2021, J RISK FINANC MANAG, V14, P0, DOI 10.3390/jrfm14100490
   Chai JY, 2021, EUR J OPER RES, V288, P692, DOI 10.1016/j.ejor.2020.06.009
   Chai JY, 2020, DECIS SUPPORT SYST, V128, P0, DOI 10.1016/j.dss.2019.113166
   Chai JY, 2020, EXPERT SYST APPL, V140, P0, DOI 10.1016/j.eswa.2019.112903
   Chai JY, 2016, J MATH PSYCHOL, V75, P10, DOI 10.1016/j.jmp.2015.10.007
   Chai JY, 2016, EXPERT SYST APPL, V45, P223, DOI 10.1016/j.eswa.2015.09.051
   Chai JY, 2015, INT J PROD ECON, V166, P215, DOI 10.1016/j.ijpe.2014.09.035
   Chai JY, 2013, INT J MACH LEARN CYB, V4, P427, DOI 10.1007/s13042-012-0105-9
   Chai JY, 2013, EXPERT SYST APPL, V40, P3872, DOI 10.1016/j.eswa.2012.12.040
   Chai JY, 2013, EXPERT SYST APPL, V40, P1959, DOI 10.1016/j.eswa.2012.10.003
   Chai JY, 2012, INT J UNCERTAIN FUZZ, V20, P451, DOI 10.1142/S0218488512500237
   Chen X, 2021, IEEE T SYST MAN CY-S, V51, P2299, DOI 10.1109/TSMC.2019.2912231
   Chen XF, 2022, INT J FUZZY SYST, V24, P909, DOI 10.1007/s40815-021-01163-1
   Cheng LC, 2016, EUR J OPER RES, V254, P622, DOI 10.1016/j.ejor.2016.04.004
   Dias LC, 2012, DECIS ANAL, V9, P231, DOI 10.1287/deca.1120.0244
   Dong QX, 2016, EUR J OPER RES, V250, P521, DOI 10.1016/j.ejor.2015.09.016
   Dong YC, 2021, IEEE T SYST MAN CY-S, V51, P6304, DOI 10.1109/TSMC.2019.2961752
   Fehr E, 1999, Q J ECON, V114, P817, DOI 10.1162/003355399556151
   Gilboa I, 2009, THEORY DECISION UNCE, V0, P0
   Hausken K, 2009, INT SER OPER RES MAN, V128, P65
   Herrera-Viedma E, 2021, IEEE T SYST MAN CY-S, V51, P191, DOI 10.1109/TSMC.2020.3043016
   Huang J, 2020, FRONT BUS RES CHINA, V14, P0, DOI 10.1186/s11782-020-00082-6
   Keck S, 2014, J ECON BEHAV ORGAN, V103, P60, DOI 10.1016/j.jebo.2014.03.026
   Keeney RL, 2013, DECIS ANAL, V10, P103, DOI 10.1287/deca.2013.0265
   KEENEY RL, 1976, MANAGE SCI, V23, P140, DOI 10.1287/mnsc.23.2.140
   Keynes JM, 1921, TREATISE PROBABILITY, V0, P0
   Knight Frank H, 1971, RISK UNCERTAINTY PRO, V0, P0
   Li AM, 2015, IND MANAGE DATA SYST, V115, P1251, DOI 10.1108/IMDS-04-2015-0130
   Li GX, 2022, IEEE T SYST MAN CY-S, V52, P3391, DOI 10.1109/TSMC.2021.3068759
   Li GX, 2018, IEEE T SYST MAN CY-S, V48, P982, DOI 10.1109/TSMC.2016.2627050
   Li SL, 2020, KNOWL-BASED SYST, V189, P0, DOI 10.1016/j.knosys.2019.105132
   Liu BS, 2019, EUR J OPER RES, V275, P737, DOI 10.1016/j.ejor.2018.11.075
   Liu Y, 2014, COMPUT OPER RES, V42, P75, DOI 10.1016/j.cor.2012.08.008
   Pan XH, 2022, IEEE T FUZZY SYST, V30, P108, DOI 10.1109/TFUZZ.2020.3032794
   Pang Q, 2016, INFORM SCIENCES, V369, P128, DOI 10.1016/j.ins.2016.06.021
   Rodríguez RM, 2018, KNOWL-BASED SYST, V159, P86, DOI 10.1016/j.knosys.2018.06.009
   Sun Q, 2022, IEEE T FUZZY SYST, V30, P1287, DOI 10.1109/TFUZZ.2021.3057705
   Tang M, 2021, J OPER RES SOC, V72, P865, DOI 10.1080/01605682.2019.1708823
   Tang M, 2020, EUR J OPER RES, V282, P957, DOI 10.1016/j.ejor.2019.10.006
   TVERSKY A, 1992, J RISK UNCERTAINTY, V5, P297, DOI 10.1007/BF00122574
   Wakker Peter P, 2010, PROSPECT THEORY RISK, V0, P0, DOI DOI 10.1017/CBO9780511779329
   Wang P, 2018, IEEE T FUZZY SYST, V26, P3314, DOI 10.1109/TFUZZ.2018.2822242
   Wu J, 2022, IEEE T CYBERNETICS, V52, P11081, DOI 10.1109/TCYB.2021.3076420
   Wu J, 2021, IEEE T FUZZY SYST, V29, P1750, DOI 10.1109/TFUZZ.2020.2985331
   Wu ZB, 2018, INFORM FUSION, V41, P217, DOI 10.1016/j.inffus.2017.09.011
   Xiao J, 2020, INFORM FUSION, V53, P20, DOI 10.1016/j.inffus.2019.06.003
   Xu XH, 2015, DECIS SUPPORT SYST, V79, P150, DOI 10.1016/j.dss.2015.08.009
   Xu XH, 2015, KNOWL-BASED SYST, V86, P237, DOI 10.1016/j.knosys.2015.06.006
   Xu XH, 2019, KNOWL-BASED SYST, V163, P495, DOI 10.1016/j.knosys.2018.09.010
   Xu ZS, 2005, OMEGA-INT J MANAGE S, V33, P249, DOI 10.1016/j.omega.2004.04.008
   Zhang HJ, 2018, IEEE T FUZZY SYST, V26, P884, DOI 10.1109/TFUZZ.2017.2697403
NR 59
TC 2
Z9 2
U1 38
U2 102
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 1
PY 2023
VL 213
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118876
EA SEP 2022
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 5H2TX
UT WOS:000867537300013
DA 2023-11-10
ER

PT J
AU Chen, Z
   Lin, HY
AF Chen, Zheng
   Lin, Hongyu
TI Improving named entity correctness of abstractive summarization by generative negative sampling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Abstractive summarization; Factual correctness; Named entity error
AB The problem of factual incorrectness in machine-generated abstractive summarization has received widespread attention in the past few years. Although large-scale neural models show excellent capability in generating fluent and coherent summaries, they still struggle with factual inconsistency, in which the named entity incorrectness is the most frequent and notable one, especially for the character-based languages, such as Chinese. Since abstractive summaries are mostly generated character by character in Chinese, the problem of hallucinated entities is more severe than that of other word-based languages. In this paper, we propose CC-Gens, a novel approach for Correctness Checking based on a Generative negative sampling strategy. Considering that the problem is due to the uncertain nature of the language generation process, we leverage fine-tuned generative language models, i.e., UniLMv2 and mT5, to generate summaries with incorrect entities, thereby constructing a synthetic binary classification dataset for the factuality discriminative model. We propose three strategies: Entity Sampling, Sequence Sampling, and Cloze Sampling, to generate summaries with incorrect entities. With such strategies, the negative samples are much more similar in nature to the output of the neural summarization model. We then train a BERT-based discriminator to identify factually incorrect machine-generated summaries with entity errors based on these generative negative samples. We further propose a novel PU learning algorithm to improve the performance of our approach by iteratively training the discriminator to select high confident negative samples from the unlabeled model generated summaries to replace the former artificially constructed ones. By generating multiple candidate summaries and selecting the one with the highest factual correctness score among them, our approach can significantly reduce the probability that an output summary contains factual errors. According to a comprehensive evaluation, the CC-Gens we proposed outperforms previous works in identifying faithless summaries as well as providing faithful ones.
C1 [Chen, Zheng; Lin, Hongyu] Univ Elect & Sci Technol China, Sch Informat & Software Engn, 4 Sec 2,North Jianshe Rd, Chengdu 610054, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Chen, Z (通讯作者)，Univ Elect & Sci Technol China, Sch Informat & Software Engn, 4 Sec 2,North Jianshe Rd, Chengdu 610054, Sichuan, Peoples R China.
EM zchen@uestc.edu.cn
FU Sichuan Science and Technology Program, China [2022ZHCG0007]; Natural Science Foundation of Sichuan Province [2022NSFSC0503]
CR Alomari A, 2022, COMPUT SPEECH LANG, V71, P0, DOI 10.1016/j.csl.2021.101276
   Bao Hangbo, 2020, P INT C MACHINE LEAR, V0, P642
   Cao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6251
   Cao ZQ, 2018, AAAI CONF ARTIF INTE, V0, P4784
   Che WX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P42
   Chen S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5935
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9320
   Elkan C, 2008, P 14 ACM SIGKDD INT, V0, PP213, DOI 10.1145/1401890.1401920
   Falke T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2214
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gabriel Saadia, 2021, FINDINGS ASS COMPUTA, V0, PP478, DOI 10.18653/V1/2021.FINDINGS-ACL.42
   Goodrich B, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP166, DOI 10.1145/3292500.3330955
   Guo H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P687
   Huang X, 1900, P942, V0, P0
   Vijayakumar AK, 2018, ARXIV, V0, P0
   Kaboutari A, 2014, INT J COMPUT APPL TE, V3, P592, DOI 10.7753/IJCATR0309.1012
   KENDALL MG, 1948, RANK CORRELATION METHODS., V0, P0
   Kryscinski W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1808
   Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9332
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li Haoran, 2018, P 27 INT C COMP LING, V0, P1430
   Li X, 2021, XIANDAI HANYU CHANGY, V2nd, P0
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3730
   Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1906
   Nallapati R, 2016, P 20 SIGNLL C COMPUT, V0, P0
   Nan F, 2021, P 59 ANN M ASS COMPU, V1, P6881
   Nan F, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2727
   Pagnoni A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P4812
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pilault J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9308
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Song KT, 2019, PR MACH LEARN RES, V97, P0
   Stahlberg F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3356
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang A, 2020, ARXIV200404228, V0, P0
   Wei BZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1304
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Zhang Y, 2020, ACL, V0, PP5108, DOI 10.18653/V1/2020.ACL-MAIN.458
   Zhu CG, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P718
NR 43
TC 0
Z9 0
U1 8
U2 8
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUN 15
PY 2023
VL 81
IS 
BP 
EP 
DI 10.1016/j.csl.2023.101504
EA MAR 2023
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0A1RN
UT WOS:000951606700001
DA 2023-11-10
ER

PT J
AU Jebali, M
   Dakhli, A
   Bakari, W
AF Jebali, Maher
   Dakhli, Abdesselem
   Bakari, Wided
TI Deep Learning-Based Sign Language Recognition System for Cognitive Development
SO COGNITIVE COMPUTATION
LA English
DT Article; Early Access
DE Sign language recognition; Deep-learning; Recurrent neural network; Head pose
AB Information in sign language (SL) is transmitted in large part by the movement, positioning, and shape of the hands as well as body language and facial emotions. Systems that recognize sign language can help with the problem that sign language is not widely used despite the large number of individuals who need to use it, and they can give hearing-impaired and deaf people a more practical way of life, employment, and education. Despite the fact that facial features are treated to be fundamental for humans to comprehend sign language, few earlier research work have inspected their cognitive importance for automatic SL recognition systems. To address this problem, this paper comes up with a novel manual and non-manual gesture recognition framework (MNM-VGG16) for the deaf and mute people. The framework employs a convolutional neural network, renowned as VGG-16 net, for implementing a trained model on an amply used video dataset by employing a component that learns the Multimodal Spatial Representation (MSR) of various modalities. The Multimodal Temporal Representation (MTR) component shapes temporal corrections from independent and dependent pathways to analyze the cooperation of different modalities. A cooperative optimization scheme, summarized by the employment of multi-scale perception component, is applied to make the finest of various modalities sources for sign language recognition. To validate the efficiency of MNM-VGG16, we carried out experiments on three large-scale sign language benchmarks: CSL Split II, SIGNUM, and RWTH-PHOENIX-Weather 2014. Experimental results prove that the suggested framework reaches new state-of-the-art achievement on all three benchmarks, and this attainment is noted by the reduction of the word error rate (WER) on test set by 14.2%, 13.7%, and 11.2%, respectively. In this paper, we offer the MNM-VGG16 hybrid method, which recognizes SL words by combining manual and non-manual features. This method demonstrates the significance of jointly modeling various body parts for SL recognition.
C1 [Jebali, Maher] Univ Tunis, LaTICE, 5,Ave Taha Hussein,Bab Menara, Tunis 1008, Tunisia.
   [Dakhli, Abdesselem] Univ Sfax, REGIM, Km 4 Route Soukra, Sfax 3038, Tunisia.
   [Bakari, Wided] Univ Sfax, MIR CL, Km 10 Route Tunis, Sfax 3021, Tunisia.
C3 Universite de Tunis; Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Universite de Sfax
RP Jebali, M (通讯作者)，Univ Tunis, LaTICE, 5,Ave Taha Hussein,Bab Menara, Tunis 1008, Tunisia.
EM maher.jbeli@gmail.com; abdesselemdakhli@gmail.com; wided.bakari@gmail.com
CR Adaloglou N, 2022, IEEE T MULTIMEDIA, V24, P1750, DOI 10.1109/TMM.2021.3070438
   [Anonymous], 2016, P BRIT MACHINE VISIO, V0, P0
   Camgoz NC, 2017, IEEE I CONF COMP VIS, V0, PP3075, DOI 10.1109/ICCV.2017.332
   Chou FH, 2012, IEEE ASME INT C ADV, V0, PP885, DOI 10.1109/AIM.2012.6266025
   Choudhury A, 2017, J INTELL SYST, V26, P471, DOI 10.1515/jisys-2016-0009
   Cui RP, 2017, PROC CVPR IEEE, V0, PP1610, DOI 10.1109/CVPR.2017.175
   ElBadawy Menna, 2017, 2017 EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS). PROCEEDINGS, V0, PP66, DOI 10.1109/INTELCIS.2017.8260028
   Forster J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1911
   Gondu A, 2017, IEEE ANN IND C INDIC, V0, PP1, DOI 10.1109/INDICON.2016.7839069
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves Alex, 2006, P 23 INT C MACH LEAR, V0, P369
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P751
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P744
   Guo D, 2020, IEEE T IMAGE PROCESS, V29, P1575, DOI 10.1109/TIP.2019.2941267
   Imran J, 2020, VISUAL COMPUT, V36, P1233, DOI 10.1007/s00371-019-01725-3
   Jo J, 2019, INTELL AUTOM SOFT CO, V25, P351, DOI 10.31209/2019.100000096
   Ka Leong Cheng, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12369), V0, PP697, DOI 10.1007/978-3-030-58586-0_41
   Khan NS, 2020, COGN COMPUT, V12, P748, DOI 10.1007/s12559-020-09731-7
   Koller O, 2016, 10 ED LANG RES EV C, V0, P0
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Koller O, 2017, PROC CVPR IEEE, V0, PP3416, DOI 10.1109/CVPR.2017.364
   Koller O, 2016, PROC CVPR IEEE, V0, PP3793, DOI 10.1109/CVPR.2016.412
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Kowalski M, 2017, IEEE COMPUT SOC CONF, V0, PP2034, DOI 10.1109/CVPRW.2017.254
   Li R, 2022, ARXIV, V0, P0
   Liwicki M, 2009, PATTERN RECOGN, V42, P3254, DOI 10.1016/j.patcog.2008.10.030
   Mercanoglu Sincan O, 2019, SIG PROCESS COMMUN, V0, P0, DOI DOI 10.1109/siu.2019.8806467
   Moghaddam M, 2011, 7 IRANIAN C MACHINE, V0, P0, DOI DOI 10.1109/IranianMVIP.2011.6121539
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Özdemir O, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), V0, PP1961, DOI 10.1109/SIU.2016.7496151
   Papastratis I, 2020, IEEE ACCESS, V8, P91170, DOI 10.1109/ACCESS.2020.2993650
   Parelli M, 2022, INT CONF ACOUST SPEE, V0, PP8457, DOI 10.1109/ICASSP43922.2022.9746971
   Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7
   Pu JF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P885
   Pu JF, 2019, PROC CVPR IEEE, V0, PP4160, DOI 10.1109/CVPR.2019.00429
   Puri AV, 2012, 2012 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, V0, PP125, DOI 10.1109/CRV.2012.24
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Sharma S, 2021, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-021-03418-z
   Simonyan K, 2015, ARXIV, V0, P0
   Suri K, 2019, COMPUT ELECTR ENG, V78, P493, DOI 10.1016/j.compeleceng.2019.08.006
   Tamer NC, 2020, INT CONF ACOUST SPEE, V0, PP8184, DOI 10.1109/icassp40776.2020.9054678
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP1483, DOI 10.1145/3240508.3240671
   Wang ZR, 2020, PATTERN RECOGN, V100, P0, DOI 10.1016/j.patcog.2019.107102
   Ye LT, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9101577
   Yin F, 2016, LECT NOTES COMPUT SC, V9911, P434, DOI 10.1007/978-3-319-46478-7_27
   Zhou MJ, 2020, FRONT ARTIF INTEL AP, V325, P2832, DOI 10.3233/FAIA200425
NR 48
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s12559-023-10182-z
EA AUG 2023
PG 13
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA P5FV1
UT WOS:001050940600001
DA 2023-11-10
ER

PT J
AU Ragheb, W
   Azé, J
   Bringay, S
   Servajean, M
AF Ragheb, Waleed
   Aze, Jerome
   Bringay, Sandra
   Servajean, Maximilien
TI Negatively Correlated Noisy Learners for At-Risk User Detection on Social Networks: A Study on Depression, Anorexia, Self-Harm, and Suicide
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Social networking (online); Task analysis; Mental disorders; Mental health; Depression; Feature extraction; Mood; social media; deep learning; negative correlation learning; transfer learning; ensemble diversity
ID neural-networks; treatment gap
AB Mental and physical health are strongly linked in a bidirectional relationship. Due to the stigma, ignorance, prejudice, fear, and many other reasons, there exists a large universal treatment gap for people with mental disorders. This could motivate those at-risk individuals to find their way into social networks, asking for information or emotional support. Language could provide a natural eyepiece for the study and detection of such at-risk individuals through their writings on social media platforms. In this paper, we consider the problem of detecting at-risk users with clear signs of depression, anorexia, self-harm, and suicidal thoughts. We introduce NCNL, a novel deep learning ensemble architecture that makes use of multiple noisy base learners in Negative Correlation Learning (NCL) configuration for text classification. NCNL is designed to be, backbone-independent, and we examine it with modern Transformer-based architectures. We evaluate our models on six different tasks for at-risk user detection and classification. Our models achieve significant improvements over existing state-of-the-art results reported for five out of the six tasks. Extensive experiments show how NCNL improves diversity over the classical conventional ensemble and the effect of using noisy base learners.
C1 [Ragheb, Waleed; Aze, Jerome] Univ Montpellier, IUT Balers, CNRS, LIRMM, F-34000 Montpellier, France.
   [Bringay, Sandra; Servajean, Maximilien] Univ Montpellier, CNRS, LIRMM, F-34000 Montpellier, France.
   [Bringay, Sandra; Servajean, Maximilien] Paul Valery Univ Montpellier, AMIS, F-34090 Montpellier, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier; Centre National de la Recherche Scientifique (CNRS); Universite Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier; CIRAD
RP Ragheb, W (通讯作者)，Univ Montpellier, IUT Balers, CNRS, LIRMM, F-34000 Montpellier, France.
EM waleed.ragheb@lirmm.fr; jerome.aze@lirmm.fr; sandra.bringay@lirmm.fr; maximilien.servajean@lirmm.fr
FU La Region Occitanie /Pyrenees-MediterraneeandL'Agglomeration Beziers Mediterranee; INSERM; CNRS; CONTROV project
CR Abdulmalik J, 2013, PLOS MED, V10, P0, DOI 10.1371/journal.pmed.1001501
   American psychiatry association, 2013, DIAGN STAT MAN MENT, V5, P0, DOI 10.1176/appi.books.9780890425596
   [Anonymous], 2014, PREV SUIC GLOB IMP, V0, P7
   Azmy WM, 2010, LECT NOTES COMPUT SC, V5997, P245, DOI 10.1007/978-3-642-12127-2_25
   Azmy WM, 2009, LECT NOTES COMPUT SC, V5519, P428, DOI 10.1007/978-3-642-02326-2_43
   Brown G, 2005, J MACH LEARN RES, V6, P1621
   Brown G, 2003, LECT NOTES COMPUT SC, V2709, P266
   Brown G, 2001, P 1 UK WORKSH COMP I, V0, P57
   Burdisso SG, 2019, P C LABS EV FOR 2019, V2380, P0
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Chen HH, 2010, IEEE T KNOWL DATA EN, V22, P1738, DOI 10.1109/TKDE.2010.26
   Chilimbi T, 2014, 11 USENIX S OPERATIN, V0, PP571, DOI 10.1108/01439911111122716
   Cid YD, 2017, CLEF WORKING NOTES, V0, P0
   Coppersmith G, 2015, P 2 WORKSHOP CLPSYCH, V0, PP31, DOI 10.3115/V1/W15-1204
   Corbitt-Hall DJ, 2016, SUICIDE LIFE-THREAT, V46, P609, DOI 10.1111/sltb.12241
   Coviello L, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0090315
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Dam HH, 2008, IEEE T KNOWL DATA EN, V20, P26, DOI 10.1109/TKDE.2007.190671
   De Choudhury M, 2013, P 7 INT AAAI C WEBL, V0, P1
   De Choudhury Munmun, 2015, P 5 INT C DIGITAL HL, V0, PP43, DOI 10.1145/2750511.2750515
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doyle L, 2015, INT J MENT HEALTH NU, V24, P485, DOI 10.1111/inm.12144
   Dutt A, 2018, 2018 INT C CONTENT B, V0, P1
   Edwards T, 2017, J RES PERS, V68, P63, DOI 10.1016/j.jrp.2017.02.005
   Eichstaedt JC, 2018, P NATL ACAD SCI USA, V115, P11203, DOI 10.1073/pnas.1802331115
   Ellendorff TR, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3723
   Fleiss, 1981, STATISTICAL METHODS, V0, P0
   Funez DG, 2018, CLEF WORKING NOTES, V2125, P0
   GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1
   Gkotsis George, 2016, P 3 WORKSH COMP LING, V0, PP63, DOI 10.18653/V1/W16-0307
   Gutiérrez-Sacristán A, 2017, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/bax043
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Jadayel R, 2017, J TEACH EDUC, V7, P465
   Kantor J, 1936, OBJECTIVE PSYCHOL GR, V0, P0
   Kazdin AE, 2017, BEHAV RES THER, V88, P7, DOI 10.1016/j.brat.2016.06.004
   Kohavi R, 1996, MACHINE LEARNING. PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE (ICML 96), V0, P275
   Kramer ADI, 2014, P NATL ACAD SCI USA, V111, P8788, DOI 10.1073/pnas.1320040111
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Kuncheva LI, 2014, COMBINING PATTERN CL, V2nd ed., P0
   Leite Barroso M, 2018, AMADEUS INT MULTIDIS, V2, P1
   Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Losada DE, 2018, P 9 INT C CLEF ASS C, V0, P1
   Losada DE, 2017, P C LABS EV FOR 2017, V0, P0
   Losada DE, 2019, LECT NOTES COMPUT SC, V11696, P340, DOI 10.1007/978-3-030-28577-7_27
   Losada DE, 2016, LECT NOTES COMPUT SC, V9822, P28, DOI 10.1007/978-3-319-44564-9_3
   Matero M, 2019, P 6 WORKSH COMP LING, V0, PP39, DOI 10.18653/v1/W19-3005
   Merity S, 2018, INT C LEARNING REPRE, V0, P0
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Milne DN, 2016, P 3 WORKSHOP COMPUTA, V0, PP118, DOI 10.18653/V1/W16-0312
   Mohammadi E, 2019, P 6 WORKSH COMP LING, V0, P34
   Mohammadi E, 2019, PROC 10 INT C CLEF A, V0, P0
   Moulahi B, 2017, LECT NOTES COMPUT SC, V10570, P346, DOI 10.1007/978-3-319-68786-5_28
   ODea Bridianne, 2015, INTERNET INTERVENTIONS, V2, P183, DOI 10.1016/j.invent.2015.03.005
   ODea B, 2017, CRISIS, V38, P319, DOI 10.1027/0227-5910/a000443
   Opitz M, 2017, LECT NOTES COMPUT SC, V10112, P205, DOI 10.1007/978-3-319-54184-6_13
   Ortega-Mendoza RM, 2019, PROC C LABS EVAL FOR, V2380, P0
   Paul M, 2021, P 5 INT AAAI C WEBL, V0, PP265, DOI 10.1609/icwsm.v5i1.14137
   Ragheb W, 2018, P C LABS EV FOR 2018, V2125, P0
   Ramírez-Cifuentes D, 2018, LECT NOTES COMPUT SC, V11193, P3, DOI 10.1007/978-3-030-01437-7_1
   Rebello TJ, 2014, CURR OPIN PSYCHIATR, V27, P308, DOI 10.1097/YCO.0000000000000068
   Sadeque F, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP495, DOI 10.1145/3159652.3159725
   Seabrook EM, 2018, J MED INTERNET RES, V20, P0, DOI 10.2196/jmir.9267
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi ZL, 2018, PROC CVPR IEEE, V0, PP5382, DOI 10.1109/CVPR.2018.00564
   Shing H-C, 2018, P 5 WORKSH COMP LING, V0, PP25, DOI 10.18653/V1/W18-0603
   Shuai HH, 2018, IEEE T KNOWL DATA EN, V30, P1212, DOI 10.1109/TKDE.2017.2786695
   Sneath PH, 1973, NUMERICAL TAXONOMY, V0, P0
   Soheylizad M, 2019, HLTH ED HLTH PROMOTI, V7, P57
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   The national eating disorders association (NEDA), 2009, NEWSL NAT EAT DIS AS, V0, P0
   Trotzek M, 2020, IEEE T KNOWL DATA EN, V32, P588, DOI 10.1109/TKDE.2018.2885515
   Tsugawa S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, PP3187, DOI 10.1145/2702123.2702280
   Vaswani A, 2017, ARXIV, V30, P5998
   Vigo D, 2016, LANCET PSYCHIAT, V3, P171, DOI 10.1016/S2215-0366(15)00505-2
   W. H. Organization, 2013, MENT HLTH ACT PLAN 2, V0, P0
   Wilson ML, 2014, P 5 INF INT CONT S, V0, P8
   Wu Y, 2016, GOOGLES NEURAL MACHI, V0, P0
   Xiao T, 2015, PROC CVPR IEEE, V0, PP2691, DOI 10.1109/CVPR.2015.7298885
   Yang ZL, 2019, ADV NEUR IN, V32, P0
   Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019
   Zhang L, 2021, IEEE T PATTERN ANAL, V43, P982, DOI 10.1109/TPAMI.2019.2943860
   Zirikly A, 2019, NAACL HLT 2019, V0, PP24, DOI 10.18653/v1/W19
NR 87
TC 0
Z9 0
U1 2
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD JAN 1
PY 2023
VL 35
IS 1
BP 770
EP 783
DI 10.1109/TKDE.2021.3078898
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 6W0SI
UT WOS:000895445500055
DA 2023-11-10
ER

PT J
AU Lu, SY
   Liu, Z
   Liu, TL
   Zhou, WCS
AF Lu, Siyu
   Liu, Zheng
   Liu, Tianlin
   Zhou, Wangchunshu
TI Scaling-up medical vision-and-language representation learning with federated learning
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Medical vision-and-language; Representation learning; Federated learning
AB Medical Vision-and-Language Pre-training (MedVLP), which learns generic vision-language representations from medical images and texts to benefit various downstream medical tasks, has drawn remarkable attention in both artificial intelligence and clinical medicine. However, existing works ignore the privacy issues and the heavy computation burden in MedVLP. In this study, we propose a FedMedVLP model, which adopts federated learning to unify the datasets from different clients, e.g., centers and hospitals, to form a largescale pre-training dataset. As a result, the unified large-scale pre-training dataset can be used to pre-train the MedVLP to achieve strong performance. Overall, our FedMedVLP can improve the performance of MedVLP while preventing data leakage. Extensive experiments prove that the proposed model sets new state-of-the-art results on five benchmark datasets across three medical mainstream tasks, i.e., medical image-text retrieval, medical text-image retrieval, and medical visual question answering tasks. Besides, we further evaluate our method on our curated well-balanced medical dataset COVID-Fed.
C1 [Lu, Siyu; Liu, Tianlin; Zhou, Wangchunshu] Jinan Univ, Guangzhou, Peoples R China.
   [Liu, Zheng] UCL, London, England.
C3 Jinan University; University of London; University College London
RP Liu, TL; Zhou, WCS (通讯作者)，Jinan Univ, Guangzhou, Peoples R China.
EM tianlinliu95@gmail.com; ericzhou@jun.edu.cn
CR Abacha Asma Ben, 2019, CLEF WORK NOT, V2, P0
   Alberti Chris, 2019, EMPIRICAL METHODS NA, V0, P0
   Alsentzer Emily, 2019, P 2 CLIN NATURAL LAN, V0, P0, DOI DOI 10.18653/V1/W19-1909
   Cadene R, 2019, PROC CVPR IEEE, V0, PP1989, DOI 10.1109/CVPR.2019.00209
   Chen FL, 2023, MACH INTELL RES, V20, P38, DOI 10.1007/s11633-022-1369-5
   Chen H, 2018, AAAI CONF ARTIF INTE, V0, P6706
   Chen Jun, 2021, ARXIV, V0, P0
   Chen YC, 2020, ARXIV, V0, P0
   Cho Jaemin, 2020, EMPIRICAL METHODS NA, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou Zi-Yi, 2022, P IEEE CVF C COMP VI, V0, P0
   Nguyen DK, 2018, PROC CVPR IEEE, V0, PP6087, DOI 10.1109/CVPR.2018.00637
   EWJohnson Alistair, 2019, ARXIV, V0, P0
   Fang H, 2015, PROC CVPR IEEE, V0, PP1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gan Zhe, 2020, ANN C NEUR INF PROC, V0, P0
   Gao Hongyu, 2022, P 30 ACM INT C MULT, V0, P0
   Ging Simon, 2020, ANN C NEUR INF PROC, V0, P0
   Li LH, 2019, ARXIV, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hodosh M, 2014, P TACL, V7, P67, DOI 10.1162/tacl_a_00166
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Huang SC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP3922, DOI 10.1109/ICCV48922.2021.00391
   Huang Ting-Hao, 2016, ANN C N AM CHAPT ASS, V0, P0
   Huang ZC, 2020, ARXIV, V0, P0
   Hui Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP12652, DOI 10.1109/CVPR42600.2020.01267
   Irvin J, 2019, AAAI CONF ARTIF INTE, V0, P590
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Kazemzadeh Sahar, 2014, EMPIRICAL METHODS NA, V0, P0
   Khare Y, 2021, I S BIOMED IMAGING, V0, PP1033, DOI 10.1109/ISBI48211.2021.9434063
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Kim Wonjae, 2021, ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Lau JJ, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2018.251
   Lei J, 2021, ARXIV, V0, P0
   Li G, 2019, ARXIV, V0, P0
   Li G, 2019, IEEE I CONF COMP VIS, V0, PP8927, DOI 10.1109/ICCV.2019.00902
   Li Junnan, 2021, ANN C NEUR INF PROC, V0, P0
   Li Linjie, 2020, ARXIV, V0, P0
   Li Linjie, 2020, EMPIRICAL METHODS NA, V0, P0
   Li LN, 2021, ARXIV, V0, P0
   Li Tian, 2020, PROC MACHINE LEARNIN, V2, P429, DOI 10.48550/arXiv.1812.06127
   Li W, 2022, ARXIV, V0, P0
   Liu B, 2021, LECT NOTES COMPUT SC, V12902, P210, DOI 10.1007/978-3-030-87196-3_20
   Liu B, 2021, I S BIOMED IMAGING, V0, PP1650, DOI 10.1109/ISBI48211.2021.9434010
   Lu JS, 2019, ADV NEUR IN, V32, P0
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Miyazawa Kazuki, 2020, ARXIV, V0, P0
   Nguyen BX, 2022, IEEE COMPUT SOC CONF, V0, PP4557, DOI 10.1109/CVPRW56347.2022.00502
   Ni MH, 2021, ARXIV, V0, P0
   Ordonez Vicente, 2011, ANN C NEUR INF PROC, V0, P0
   Pan YW, 2017, PROC CVPR IEEE, V0, PP984, DOI 10.1109/CVPR.2017.111
   Pelka O, 2018, LECT NOTES COMPUT SC, V11043, P180, DOI 10.1007/978-3-030-01364-6_20
   Radford Alec, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2103.00020
   Rahman W, 2020, ARXIV, V0, P0
   Su Weijie, 2020, ICLR, V0, P0
   Subramanian Sanjay, 2020, EMPIRICAL METHODS NA, V0, P0
   Sun C, 2019, ARXIV, V0, P0
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Wang BR, 2019, AAAI CONF ARTIF INTE, V0, P8909
   Wang JF, 2021, ARXIV, V0, P0
   Wang Zifeng, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2210.10163
   Wu YH, 2016, ARXIV, V0, P0
   Xiujun I, 2020, ECCV, V0, P0
   Yan B, 2022, AAAI CONF ARTIF INTE, V0, P2982
   Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426
   Yu F, 2021, ARXIV, V0, P0
   Yu LC, 2018, PROC CVPR IEEE, V0, PP1307, DOI 10.1109/CVPR.2018.00142
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Zhan LM, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP2345, DOI 10.1145/3394171.3413761
   Zhang Cha, 2006, ANN C NEUR INF PROC, V0, P0
   Zhang PC, 2021, ARXIV, V0, P0
   Zhang Q, 2020, PROC CVPR IEEE, V0, PP3533, DOI 10.1109/CVPR42600.2020.00359
   Zhang YH, 2022, ARXIV, V0, P0
   Zhao GX, 2019, ARXIV, V0, P0
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu HY, 2021, NEUROCOMPUTING, V465, P371, DOI 10.1016/j.neucom.2021.07.098
NR 78
TC 0
Z9 0
U1 0
U2 0
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD NOV 15
PY 2023
VL 126
IS 
BP 
EP 
DI 10.1016/j.engappai.2023.107037
PG 10
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA W0WG2
UT WOS:001088913200001
DA 2023-11-10
ER

PT J
AU Sahu, SS
   Pal, S
AF Sahu, Siba Sankar
   Pal, Sukomal
TI A Study on Corpus-based Stopword Lists in Indian Language IR
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Indian languages; stopword; evaluation
ID words
AB We explore and evaluate the effect of different stopword lists (non-corpus-based and corpus-based) in the information retrieval (IR) tasks with different Indian languages such as Bengali, Marathi, Gujarati, Hindi, and English. The issue was investigated from three viewpoints. Is there any performance difference between non-corpus-based and corpus-based stopword removal in chosen Indian languages? Can corpus-based stopword lists improve performance in Indian languages IR? If yes, to what extent? Among the different corpus-based stopword lists, which stopword list provides the best IR performance? Does the length of a corpus-based stopword list affect the retrieval performance in Indian languages? If yes, to what extent? It was observed that a corpus-based stopword list provides better retrieval performance than a non-corpus-based stopword list in different Indian languages. Among the different corpus-based stopword lists generated and experimented with, Zipf's law-based stopword list (idf-based one) provides the best retrieval performance in various Indian languages. The aggregation1-based stopword list provides better retrieval than the aggregation2-based list in Indian languages, but in English, the aggregation2-based stopword list performs better than the aggregation1-based list. The best performing idf-based stopword list improves MAP score by 5.43% in Bengali, 1.91% in Marathi, 5.4% in Gujarati, 1.5% in Hindi, and 2.12% in English, respectively, over their baseline counterparts. The probabilistic retrieval models (BM25 and TF-IDF) perform best in different Indian languages. A smaller length of corpus-based stopword lists performs better than a larger length of non-corpus-based stopword lists for all the Indian languages considered. The proposed schemes demonstrate that a stopword list can be heuristically generated in a language-independent statistical method and effectively used for IR tasks with performance comparable, to or even better than non-corpus-based stopword lists.
C1 [Sahu, Siba Sankar; Pal, Sukomal] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttarpradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU Varanasi)
RP Sahu, SS (通讯作者)，Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttarpradesh, India.
EM sibasankarsahu.rs.cse17@itbhu.ac.in
FU IIT (B.H.U), Varanasi; PARAM Shivay Facility under the National Supercomputing Mission, Government of India at the IIT (B.H.U), Varanasi
CR Abu El-Khair I, 2017, ARXIV, V0, P0
   Al-Shargabi B, 2011, INT J INF TECHNOL WE, V6, P68, DOI 10.4018/jitwe.2011040106
   Alajmi A, 2012, INT J COMPUT APPL, V46, P8
   Asubiaro Toluwase Victor, 2013, INT J COMPUTER INFOR, V2, P5
   Ayral H, 2011, 2011 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2011), V0, PP500, DOI 10.1109/INISTA.2011.5946149
   BLAIR DC, 1979, J AM SOC INFORM SCI, V30, P374, DOI 10.1002/asi.4630300621
   Buckley Chris, 2017, ACM SIGIR FORUM, V51, P235, DOI 10.1145/3130348.3130373
   Chekima Khalifa, 2016, INT C SOFT COMPUTING, V0, P180
   Choy M, 2012, ARXIV, V0, P0
   Cover T, 2006, ELEMENTS INFORM THEO, V2nd ed., P0
   Davarpanah MR, 2009, LIBR HI TECH, V27, P435, DOI 10.1108/07378830910988559
   Dolamic L, 2010, J AM SOC INF SCI TEC, V61, P200, DOI 10.1002/asi.21186
   Dolamic Ljiljana, 2010, ACM T ASIAN LANGUAGE, V9, P11
   Fox C, 1990, SIGIR FORUM, V24, P19, DOI 10.1145/378881.378888
   Francis W, 1982, FREQUENCY ANAL ENGLI, V0, P0
   Gong Zheng, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS (ICIS 2010), V0, PP71, DOI 10.1109/ICICISYS.2010.5658841
   Harter SP, 1986, ONLINE INFORM RETRIE, V0, P0
   Isik M, 2020, TURK J ELECTR ENG CO, V28, P1405, DOI 10.3906/elk-1907-46
   Jasleen K, 2016, SMART INNOV SYST TEC, V51, P3, DOI 10.1007/978-3-319-30927-9_1
   Jayashree R, 2014, INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING, V4, P264, DOI 10.1504/IJAISC.2014.062824
   Jha V, 2016, 2016 INTERNATIONAL CONFERENCE ON MICROELECTRONICS, V0, P0
   Kaur J, 2016, P ACM S WOM RES MARC, V0, PP32, DOI 10.1145/2909067.2909073
   Kucera H, 1967, COMPUTATIONAL ANAL P, V0, P0
   Kwee AT, 2009, LECT NOTES ARTIF INT, V5476, P40, DOI 10.1007/978-3-642-01307-2_7
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   Makrehchi M, 2008, LECT NOTES COMPUT SC, V4956, P222
   Narang SR, 2021, MULTIMED TOOLS APPL, V80, P20671, DOI 10.1007/s11042-021-10775-6
   Narang SR, 2020, ARTIF INTELL REV, V53, P5517, DOI 10.1007/s10462-020-09827-4
   Rakholia RM, 2017, ADV INTELL SYST, V515, P797, DOI 10.1007/978-981-10-3153-3_79
   Rakholia Rajnish M, 2016, 2016 2 INT C ADV COM, V0, P1
   Rani Ruby, 2018, PROCEDIA COMPUTER SCIENCE, V132, P362, DOI 10.1016/j.procs.2018.05.196
   Raulji JK, 2017, IEEE INT ADV COMPUT, V0, PP799, DOI 10.1109/IACC.2017.0164
   ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302
   Sadeghi M, 2014, J INF SCI, V40, P476, DOI 10.1177/0165551514530655
   Sahu SS, 2023, COMPUT SPEECH LANG, V81, P0, DOI 10.1016/j.csl.2023.101518
   Sahu SS, 2022, SADHANA-ACAD P ENG S, V47, P0, DOI 10.1007/s12046-021-01731-z
   Saini JR, 2016, PROCEDIA COMPUT SCI, V89, P313, DOI 10.1016/j.procs.2016.06.076
   Sarica S, 2020, ARXIV, V0, P0
   Savoy J, 1999, J AM SOC INFORM SCI, V50, P944, DOI 10.1002/(SICI)1097-4571(1999)50:10<944::AID-ASI9>3.0.CO;2-Q
   Schutze H, 2008, INTRO INFORM RETRIEV, V39, P234
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Siddiqi Sifatullah, 2018, INT J ADV COMPUTER R, V8, P35
   Silva C, 2003, IEEE IJCNN, V0, P1661
   Sinka MP, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, V0, P396
   Trumbach CC, 2007, J INF SCI, V33, P660, DOI 10.1177/0165551506076401
   Tsz-Wai Lo R, 2005, JOURNAL OF DIGITAL INFORMATION MANAGEMENT, V3, P3
   Ul Haque R, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, V0, P0
   Yaghoub-Zadeh-Fard MA, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), V0, PP111, DOI 10.1109/KBEI.2015.7436031
   Zipf GK, 1950, J CLIN PSYCHOL, V6, P306
   Zou Feng, 2006, LREC, V0, P2497
   Zou Feng, 2006, P 5 WSEAS INT C APPL, V0, P1010
NR 51
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL 15
PY 2023
VL 22
IS 7
BP 
EP 
DI 10.1145/3606262
PG 22
WC Computer Science, Artificial Intelligence
SC Computer Science
GA O7BM4
UT WOS:001045318300018
DA 2023-11-10
ER

PT J
AU Ferro, M
   Silva, E
   Fidalgo, R
AF Ferro, Marcio
   Silva, Edson
   Fidalgo, Robson
TI AStar: A modeling language for document-oriented geospatial data warehouses
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article
DE Geospatial data warehouse; Document-oriented databases; Logical schemas; DSML; Metamodel
ID big data; physics; databases; systems; design
AB A Geospatial Data Warehouse (GDW) is an extension of a traditional Data Warehouse that includes geospatial data in the decision-making processes. Several studies have proposed the use of document-oriented databases in a GDW as an alternative to relational databases. This is due to the ability of non-relational databases to scale horizontally, allowing for the storage and processing of large volumes of data. In this context, modeling the manner in which facts and dimensions are structured is important in order to understand, maintain, and evolve the Document-oriented GDW (DGDW) through visual analysis. However, to the best of our knowledge, there are no modeling languages that support the design of aggregated data as facts and dimensions, that can be represented as referenced or embedded documents, partitioned into one or more collections. To overcome this lack, we propose Aggregate Star (AStar), a Domain-Specific Modeling Language for designing DGDW logical schemas. AStar is defined from a concrete syntax (graphical notation), an abstract syntax (metamodel), and static semantics (well-formedness rules). In order to describe the semantics of the concepts defined in AStar, translational semantics map the graphical notation to the metamodel and the respective code, to define the schema in MongoDB (using JSON Schema). We evaluate the graphical notation using Physics of Notations (PoN), which provides a set of principles for designing cognitively effective visual notations. This evaluation revealed that AStar is in accordance with seven of the nine PoN principles, an adequate level of cognitive effectiveness. As a proof of concept, the metamodel and well-formedness rules were implemented in a prototype of Computer-Assisted Software Engineering tool, called AStarCASE. In its current version, AStarCASE can be used to design DGDW logical schemas and to generate their corresponding code in the form of JSON Schemas.
C1 [Ferro, Marcio; Silva, Edson; Fidalgo, Robson] Univ Fed Pernambuco, Informat Ctr, BR-50740560 Recife, PE, Brazil.
   [Ferro, Marcio] Fed Inst Alagoas, BR-57035660 Rio Largo, Alagoas, Brazil.
C3 Universidade Federal de Pernambuco; Instituto Federal de Alagoas (IFAL)
RP Ferro, M (通讯作者)，Univ Fed Pernambuco, Informat Ctr, BR-50740560 Recife, PE, Brazil.
EM mrcferro@gmail.com
CR ACoachDB, 2020, DOC DES CONS, V0, P0
   Abdelhedi F, 2017, LECT NOTES COMPUT SC, V10440, P88, DOI 10.1007/978-3-319-64283-3_7
   Abdelhedi F, 2017, ICEIS: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS - VOL 1, V0, PP249, DOI 10.5220/0006311702490256
   Abdelhedi F, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, V0, P0
   Ait Brahim A, 2019, INT CONF KNOWL SYS, V0, PP391, DOI 10.1109/kse.2019.8919400
   Andor CF, 2019, INT CONF SOFTW, V0, PP263, DOI 10.23919/softcom.2019.8903854
   [Anonymous], 2017, THE EPSILON BOOK, V0, P0
   [Anonymous], 1999, OGC STAND, V0, P0
   [Anonymous], 1997, DATA WAREHOUSING DAT, V0, P0
   [Anonymous], 2013, J INF DATA MANAG, V0, P0
   Azure M, 2020, DAT MOD AZ COSM DB, V0, P0
   Banerjee S, 2015, IEEE INTL CONF IND I, V0, PP1665, DOI 10.1109/INDIN.2015.7281984
   Bensalloua CA, 2021, INFORMATICA, V45, P0
   Bertin Jacques, 1983, TECHNICAL REPORT, V0, P0
   Boaventura Filho W, 2015, GEO-PROCESSING, V72, P2015
   Boulil K, 2015, COMPUT STAND INTER, V38, P113, DOI 10.1016/j.csi.2014.06.004
   Brambilla M, 2012, SYNTHESIS LECT SOFTW, V1, P1, DOI 10.2200/S00441ED1V01Y201208SWE001
   Bray T, 2017, 8259 RFC, V0, P0, DOI DOI 10.17487/RFC8259
   Breault JL, 2002, ARTIF INTELL MED, V26, P37, DOI 10.1016/S0933-3657(02)00051-9
   BRUCE TA, 1992, DESIGNING QUALITY DA, V0, P0
   Bruck J, 2007, CUSTOMIZING UML WHIC, V0, P0
   Bryant BR, 2011, COMPUT SCI INF SYST, V8, P225, DOI 10.2298/CSIS110114012B
   Budinsky F, 2004, ECLIPSE SERIES, V0, P0
   Bugiotti F, 2014, LECT NOTES COMPUT SC, V8824, P223, DOI 10.1007/978-3-319-12206-9_18
   Butler H, 2016, 7946 RFC, V0, P0, DOI DOI 10.17487/rfc7946
   Catarci T, 1997, J VISUAL LANG COMPUT, V8, P215, DOI 10.1006/jvlc.1997.0037
   Chaudhuri S, 1997, SIGMOD RECORD, V26, P65, DOI 10.1145/248603.248616
   Chevalier Max, 2015, 17TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS 2015). PROCEEDINGS, V0, P172
   Chevalier M, 2015, LECT NOTES COMPUT SC, V9263, P379, DOI 10.1007/978-3-319-22729-0_29
   Chevalier M, 2017, LECT NOTES ELECTR EN, V397, P671, DOI 10.1007/978-981-10-1627-1_53
   Chevalier M, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL 1 (ICEIS), P142, DOI 10.5220/0005830801420149
   Chevalier M, 2015, LECT NOTES COMPUT SC, V9282, P79, DOI 10.1007/978-3-319-23135-8_6
   Chongxin Li, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCES (ICSESS 2010), V0, PP683, DOI 10.1109/ICSESS.2010.5552465
   Copeland R, 2013, MONGODB APPL DESIGN, V0, P0
   Cuzzocrea A, 2012, CAISE FORUM, V0, P32
   da Silva AR, 2015, COMPUT LANG SYST STR, V43, P139, DOI 10.1016/j.cl.2015.06.001
   Teixeira MDD, 2016, LECT NOTES BUS INF P, V248, P432, DOI 10.1007/978-3-319-39429-9_27
   Davoudian A, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3158661
   DB-Engines, 2020, DB ENG RANK, V0, P0
   de la Vega A, 2020, FUTURE GENER COMP SY, V105, P455, DOI 10.1016/j.future.2019.11.032
   De Lima C, 2015, 17 INT C INFORM INTE, V0, P0, DOI DOI 10.1145/2837185.2837218
   DEHDOUH K, 2015, P INT C PARALLEL DIS, V0, P469
   Dehdouh K, 2014, LECT NOTES COMPUT SC, V8748, P281, DOI 10.1007/978-3-319-11587-0_26
   Del Aguila PSR, 2011, P ACM 14 INT WORKSHO, V0, PP31, DOI 10.1145/2064676.2064682
   DeMarco T, 2001, PIONEERS THEIR CONTR, V0, P255
   Do Nascimento Fidalgo Robson, 2012, CONCEPTUAL MODELING. PROCEEDINGS 31ST INTERNATIONAL CONFERENCE, V0, P515, DOI 10.1007/978-3-642-34002-4_40
   DynamoDB A, 2021, CREATE TABLE, V0, P0
   Elmasri R, 2010, FUNDAMENTALS DATABAS, V0, P0
   Evans E, 2004, DOMAIN DRIVEN DESIGN, V0, P0
   Candel CJF, 2022, INFORM SYST, V104, P0, DOI 10.1016/j.is.2021.101898
   Ferrahi I, 2017, INT C ENT INF SYST, V2, P343
   Ferro M, 2019, CONF BUS INFORM, V0, PP47, DOI 10.1109/CBI.2019.00013
   Ferro M, 2019, LECT NOTES COMPUT SC, V11708, P221, DOI 10.1007/978-3-030-27520-4_16
   Fidalgo RN, 2004, LECT NOTES COMPUT SC, V3181, P26
   Fleck M, 2016, LECT NOTES COMPUT SC, V9765, P79, DOI 10.1007/978-3-319-42064-6_6
   Fontoura M, 2000, UML PROFILE FRAMEWOR, V0, P0
   Gessert F, 2017, COMPUT SCI-RES DEV, V32, P353, DOI 10.1007/s00450-016-0334-3
   Glorio O, 2008, LECT NOTES COMPUT SC, V5182, P23, DOI 10.1007/978-3-540-85836-2_3
   Gómez P, 2021, DATA KNOWL ENG, V134, P0, DOI 10.1016/j.datak.2021.101893
   Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843
   Gupta A, 1999, MAT VIEWS TECHNIQUES, V0, P0
   Guy Clement, 2012, MODELLING FOUNDATIONS AND APPLICATIONS. PROCEEDINGS 8TH EUROPEAN CONFERENCE, V0, P400, DOI 10.1007/978-3-642-31491-9_30
   Hai RH, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP2097, DOI 10.1145/2882903.2899389
   HAREL D, 1988, COMMUN ACM, V31, P514, DOI 10.1145/42411.42414
   Harinarayan V, 1996, SIGMOD RECORD, V25, P205, DOI 10.1145/235968.233333
   Inmon WH, 2005, BUILDING DATA WAREHO, V0, P0
   Jing Han, 2011, PROCEEDINGS 2011 6TH INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND APPLICATIONS (ICPCA 2011), V0, PP363, DOI 10.1109/ICPCA.2011.6106531
   Jovanovic V, 2013, P SO ASS INFORM SYST, V0, P70
   Kanade A, 2014, IEEE INT ADV COMPUT, V0, PP416, DOI 10.1109/IAdCC.2014.6779360
   Kaur Karamjit, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, V0, PP1, DOI 10.1109/BigData.2013.6691765
   Kelly S, 2008, DOMAIN SPECIFIC MODE, V0, P0
   Kimball R, 2013, DATA WAREHOUSE TOOLK, V3rd, P0
   Kleppe A, 2007, 4 INT WORKSH SOFTW L, V1, P1
   LARKIN JH, 1987, COGNITIVE SCI, V11, P65, DOI 10.1016/S0364-0213(87)80026-5
   Lee JG, 2015, BIG DATA RES, V2, P74, DOI 10.1016/j.bdr.2015.01.003
   Li Daqian, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V0, P0, DOI DOI 10.1088/1742-6596/1982/1/012130
   Lopes FA, 2016, IEEE COMMUN SURV TUT, V18, P1255, DOI 10.1109/COMST.2015.2501026
   Lopes Siqueira TL, 2009, P 2009 ACM S APPL CO, V0, PP1336, DOI 10.1145/1529282.1529582
   Siqueira TLL, 2010, LECT NOTES COMPUT SC, V6263, P40, DOI 10.1007/978-3-642-15105-7_4
   Malinowski E, 2004, P 12 ANN ACM INT WOR, V0, PP12, DOI 10.1145/1032222.1032226
   Mateus R, 2010, ASTROPHYS J, V1, P519
   Mateus RC, 2016, DISTRIB PARALLEL DAT, V34, P425, DOI 10.1007/s10619-015-7176-z
   Miloslavskaya N, 2016, PROCEDIA COMPUT SCI, V88, P300, DOI 10.1016/j.procs.2016.07.439
   Mohagheghi P, 2009, INFORM SOFTWARE TECH, V51, P1646, DOI 10.1016/j.infsof.2009.04.004
   MongoDB, 2021, SCHEM VAL, V0, P0
   MongoDB, 2020, INTR MONGODB, V0, P0
   MongoDB, 2022, MOD ON TO MAN REL EM, V0, P0
   Moody DL, 2009, IEEE T SOFTWARE ENG, V35, P756, DOI 10.1109/TSE.2009.67
   Nickerson JV, 1994, PROCEEDINGS. IEEE SYMPOSIUM ON VISUAL LANGUAGES (CAT. NO.94TH8010), V0, PP178, DOI 10.1109/VL.1994.363624
   OMGroup, 2020, MET FAC, V0, P0
   Object Management Group, 2019, UNIFIED MODELING LAN, V0, P0
   Olivera HV, 2015, 2 ANN INT S INF MAN, V1478, P129
   OMG, 2014, OBJECT CONSTRAINT LA, V0, P0
   ONeil PE, 2007, PAT, V0, Patent No. 200
   Sarkar A, 2011, GRAPH SEMANTIC BASED, V0, P0
   Scabora LC, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL 1 (ICEIS), P111, DOI 10.5220/0005815901110118
   Shin K, 2017, INT J APPL ENG RES, V12, P632
   Srai A, 2017, INT J APPL ENG RES, V12, P3532
   Thornthwaite W, 2003, DEALING CONFLICT AFR, V0, P0
   Ting IH, 2010, ONLINE INFORM REV, V34, P509, DOI 10.1108/14684521011054107
   Tsois A, 2001, P INT WORKSH DES MAN, V39, P5
   UIndexes, 2021, UN IND, V0, P0
   UNOon Drugs Crime, 2015, INT CLASS CRIM STAT, V0, P0
   van der Linden D, 2019, IEEE T SOFTWARE ENG, V45, P736, DOI 10.1109/TSE.2018.2802910
   Wright A, 2020, JSON SCHEMA MEDIA TY, V0, P0
   Yangui R, 2016, PROCEDIA COMPUT SCI, V96, P264, DOI 10.1016/j.procs.2016.08.138
   Zecevic I, 2018, ENTERP INF SYST-UK, V12, P1221, DOI 10.1080/17517575.2018.1445295
   Zyp K, 2010, IN PRESS, V0, P0
NR 108
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-023X
EI 1872-6933
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD MAY 15
PY 2023
VL 145
IS 
BP 
EP 
DI 10.1016/j.datak.2023.102174
EA MAR 2023
PG 46
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA E0PS7
UT WOS:000972664900001
DA 2023-11-10
ER

PT J
AU Metawei, MA
   Taher, M
   ElDeeb, H
   Nassar, SM
AF Metawei, Maha A.
   Taher, Mohamed
   ElDeeb, Hesham
   Nassar, Salwa M.
TI A topic-aware classifier based on a hybrid quantum-classical model
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Quantum natural language processing; Quantum neural network; Hybrid quantum-classical; Classification; Supervised learning
AB In the era of Large Language Models, there is still potential for improvement in current Natural Language Processing (NLP) methods in terms of verifiability and consistency. NLP classical approaches are computationally expensive due to their high-power consumption, computing power, and storage requirements. Another computationally efficient approach to NLP is categorical quantum mechanics, which combines grammatical structure and individual word meaning to deduce the sentence meaning. As both quantum theory and natural language use vector space to describe states which are more efficient on quantum hardware, QNLP models can achieve up to quadratic speedup over classical direct calculation methods. In recent years, there is significant progress in utilizing quantum features such as superposition and entanglement to represent linguistic meaning on quantum hardware. Earlier research work has already demonstrated QNLP's potential quantum advantage in terms of speeding up search, enhancing classification tasks' accuracy and providing an exponentially large quantum state space in which complex linguistic structures can be efficiently embedded. In this work, a QNLP model is used to determine if two sentences are related to the same topic or not. By comparing our QNLP model to a classical tensor network-based one, our model improved training accuracy by up to 45% and validation accuracy by 35%, respectively. The QNLP model convergence is also studied when varying: first, the problem size, second, parametrized quantum circuits used for model's training, and last, the backend quantum simulator noise model. The experimental results show that strongly entangled ansatz designs result in fastest model convergence.
C1 [Metawei, Maha A.; Taher, Mohamed] Ain Shams Univ, Fac Engn, Comp & Syst Dept, Cairo, Egypt.
   [Metawei, Maha A.; ElDeeb, Hesham; Nassar, Salwa M.] Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University; Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI)
RP Metawei, MA (通讯作者)，Ain Shams Univ, Fac Engn, Comp & Syst Dept, Cairo, Egypt.; Metawei, MA (通讯作者)，Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
EM maha_metawei@eri.sci.eg; mohamed.taher@eng.asu.edu.eg; eldeeb@eri.sci.eg; salwa@eri.sci.eg
CR Aaronson S, 2016, ARXIV, V0, P0
   Abbas A, 2020, ARXIV, V0, P0
   Abbas A, 2021, NAT COMPUT SCI, V1, P403, DOI 10.1038/s43588-021-00084-1
   Abbas-zadeh M, 2021, ARXIV, V0, P0
   Aleksandrowicz Gadi, 2019, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.2562111
   Arad I, 2010, SIAM J COMPUT, V39, P3089, DOI 10.1137/080739379
   Arthur D, 2022, ARXIV, V0, P0
   Bergholm V, 2018, ARXIV, V0, P0
   Biswas D etal, 2021, ARXIV, V0, P0
   Brakerski Z, 2020, ARXIV, V0, P0
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Casadio C, 2021, JOACHIM LAMBEK INTER, V0, P0
   Chen SYC, 2020, IEEE ACCESS, V8, P141007, DOI 10.1109/ACCESS.2020.3010470
   Coecke B, 2020, ARXIV, V0, P0
   Coecke B, 2022, QUANTUM COMPUTING AR, V0, P277
   Coecke B, 2010, ARXIV, V0, P0
   Corp P, 2022, QML STRONGLYENTANGLI, V0, P0
   deFelice G, 2020, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   El-Mahalawy AM, 2021, OPTIK, V246, P0, DOI 10.1016/j.ijleo.2021.167793
   Farhi E, 2018, ARXIV, V0, P0
   Gambetta J, 2020, IBMS ROADMAP SCALING, V0, P0
   Georgescu IM, 2014, REV MOD PHYS, V86, P153, DOI 10.1103/RevModPhys.86.153
   Guarasci R, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12115651
   Havlícek V, 2019, NATURE, V567, P209, DOI 10.1038/s41586-019-0980-2
   Holmes Z, 2022, PRX QUANTUM, V3, P0, DOI 10.1103/PRXQuantum.3.010313
   Hubregtsen T, 2021, QUANT MACH INTELL, V3, P0, DOI 10.1007/s42484-021-00038-w
   Karamlou A, 2022, ARXIV, V0, P0
   Kartsaklis D, 2021, ARXIV, V0, P0
   Kha QH, 2022, METHODS, V207, P90, DOI 10.1016/j.ymeth.2022.09.007
   Khatri N, 2022, EXPT COMP ANSATZE QU, V0, P0
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Le NQK, 2022, COMPUT BIOL CHEM, V99, P0, DOI 10.1016/j.compbiolchem.2022.107732
   Lorenz R, 2021, ARXIV, V0, P0
   Meichanetzidis K, 2023, QUANT MACH INTELL, V5, P0, DOI 10.1007/s42484-023-00097-1
   Metawei MA, 2022, EVALUATION DIFFERENT, V0, P0
   Metawei MA, 2020, 2020 INT C COMM COMP, V0, P1
   Ragone M, 2022, ARXIV, V0, P0
   Schuld M, 2020, PHYS REV A, V101, P0, DOI 10.1103/PhysRevA.101.032308
   Sim S, 2019, ADV QUANTUM TECHNOL, V2, P0, DOI 10.1002/qute.201900070
   Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486
   Wang-Mascianica V, 2023, ARXIV, V0, P0
   Waseem MH, 2022, ELECT P THEOR COMPUT, V366, P50, DOI 10.4204/eptcs.366.7
   Wiebe N, 2015, QUANTUM INF COMPUT, V15, P316
   Womaniumorg, 2022, WOM QUANT HACK, V0, P0
   Zeng WJ, 2016, SLPCS QPL, V0, P0
   Zyczkowski K, 2005, PHYS REV A, V71, P0, DOI 10.1103/PhysRevA.71.032313
NR 47
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD SEP 15
PY 2023
VL 35
IS 25
BP 18803
EP 18812
DI 10.1007/s00521-023-08706-7
EA JUN 2023
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA P2WY3
UT WOS:001019458000003
DA 2023-11-10
ER

PT J
AU Yu, WY
   Ma, ZJ
   Zhai, XJ
   Zhou, YK
   Zhou, WW
   Liu, Y
AF Yu, Wangyang
   Ma, Zhuojing
   Zhai, Xiaojun
   Zhou, Yuke
   Zhou, Weiwei
   Liu, Yuan
TI MODELING AND ANALYZING USER BEHAVIOR RISKS IN ONLINE SHOPPING PROCESSES BASED ON DATA-DRIVEN AND PETRI-NET METHODS
SO COMPUTING AND INFORMATICS
LA English
DT Article
DE Petri net; data analysis; user behavior
ID security
AB With the rapid spread of e-commerce and e-payment, the increasing number of people choose online shopping instead of traditional buying way. How-ever, the malicious user behaviors have a significant influence on the security of users' accounts and property. In order to guarantee the security of shopping envi-ronment, a method based on Complex Event Process (CEP) and Colored Petri nets (CPN) is proposed in this paper. CEP is a data-driven technology that can corre-late and process a large amount of data according to Event Patterns, and CPN is a formal model that can simulate and verify the specifications of the online shopping processes. In this work, we first define the modeling scheme to depict the user be-haviors and Event Patterns of online shopping processes based on CPN. The Event Patterns can be constructed and verified by formal methods, which guarantees the correctness of Event Patterns. After that, the Event Patterns are translated into Event Pattern Language (EPL) according to the corresponding algorithms. Finally, the EPLs can be inserted into the complex event processing engine to analyze the users' behavior flows in real-time. In this paper, we validate the effectiveness of the proposed method through case studies.
C1 [Yu, Wangyang] Minist Educ, Key Lab Modern Teaching Technol, Xian, Peoples R China.
   [Yu, Wangyang; Ma, Zhuojing; Liu, Yuan] Shaanxi Normal Univ, Sch Comp Sci, Xian, Peoples R China.
   [Zhai, Xiaojun; Zhou, Yuke] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, England.
   [Zhou, Weiwei] Shandong Yingcai Univ China, Business Sch, Jinan, Peoples R China.
C3 Shaanxi Normal University; University of Essex
RP Zhai, XJ; Zhou, YK (通讯作者)，Univ Essex, Sch Comp Sci & Elect Engn, Colchester, England.
EM xzhai@essex.ac.uk
FU Natural Science Foundation of Shaanxi Province [2021JM-205]; Open Research Fund of Anhui Province Engineering Laboratory for Big Data Analysis and Early Warning Technology of Coal Mine Safety [CSBD2022-ZD05]
CR Bhargavi R, 2010, PROCEEDINGS OF THE 2010 IEEE/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE-INTELLIGENT AGENT TECHNOLOGY - WORKSHOPS (WI-IAT 2010), V0, PP211, DOI 10.1109/WI-IAT.2010.70
   Bonino D, 2018, IEEE INTERNET THINGS, V5, P775, DOI 10.1109/JIOT.2017.2728089
   Chen EY, 2015, P IEEE S SECUR PRIV, V0, PP833, DOI 10.1109/SP.2015.56
   Cugola G, 2012, ACM COMPUT SURV, V44, P0, DOI 10.1145/2187671.2187677
   DING W, 2017, 2017 10 INT S COMP I, V0, P0
   Du YH, 2012, IEEE T AUTOM SCI ENG, V9, P429, DOI 10.1109/TASE.2012.2188511
   ENUMERATION CW, 2014, CWE840 MITRE CORP, V0, P0
   Hu HS, 2014, IEEE T AUTOM SCI ENG, V11, P66, DOI 10.1109/TASE.2013.2288645
   Jensen, 2013, COLOURED PETRI NETS, V1, P0
   Jensen K, 2009, COLOURED PETRI NETS: MODELLING AND VALIDATION OF CONCURRENT SYSTEMS, V0, PP1, DOI 10.1007/b95112
   Jiang CJ, 2018, IEEE INTERNET THINGS, V5, P3637, DOI 10.1109/JIOT.2018.2816007
   Li ZC, 2021, EXPERT SYST APPL, V175, P0, DOI 10.1016/j.eswa.2021.114750
   Lili Wu, 2018, 2018 IEEE INTERNATIONAL CONFERENCE OF SAFETY PRODUCE INFORMATIZATION (IICSPI). PROCEEDINGS, V0, PP204, DOI 10.1109/IICSPI.2018.8690463
   Ma ZJ, 2019, IEEE ACCESS, V7, P172088, DOI 10.1109/ACCESS.2019.2955466
   Macià H, 2016, IEEE ACCESS, V4, P7425, DOI 10.1109/ACCESS.2016.2621718
   MATHEW A, 2014, IITBCSE2014APRIL61, V0, P0
   Milosevic Z, 2015, IEEE INT ENTERP DIST, V0, PP122, DOI 10.1109/EDOC.2015.26
   MUNOZ A, 2019, REV DYNAMIC VERIFICA, V0, PP162, DOI 10.4018/978-1-5225-7353-1.ch007
   Phillips ME, 2016, 2016 IEEE SYMPOSIUM ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), V0, P0
   Sadikin MA, 2016, 2016 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA): RECENT TRENDS IN INTELLIGENT COMPUTATIONAL TECHNOLOGIES FOR SUSTAINABLE ENERGY, V0, PP387, DOI 10.1109/ISITIA.2016.7828691
   STA S, 2008, P 1 INT S APPL SCI B, V0, P0
   Sun FQ, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), V0, P0, DOI DOI 10.14722/ndss.2014.23351
   van der Aalst WMP, 2012, INFORM SYST, V37, P574, DOI 10.1016/j.is.2011.08.004
   Wang R, 2011, P IEEE S SECUR PRIV, V0, PP465, DOI 10.1109/SP.2011.26
   Wang SG, 2013, IEEE T SYST MAN CY-S, V43, P1248, DOI 10.1109/TSMC.2012.2235427
   Weidlich M, 2014, IEEE T KNOWL DATA EN, V26, P2759, DOI 10.1109/TKDE.2014.2302306
   Wen S, 2017, INT J AUTOM COMPUT, V14, P106, DOI 10.1007/s11633-016-1051-x
   XIE Y, 2022, IEEE T NEUR NET LEAR, V0, P0
   Xie Y, 2023, IEEE T COMPUT SOC SY, V10, P1004, DOI 10.1109/TCSS.2022.3158318
   XING L, 2013, INTEGUARD AUTOMATIC, V0, P0
   Yan Liu, 2010, 2010 2ND INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE (ETCS), V0, PP429, DOI 10.1109/ETCS.2010.214
   Yu WY, 2020, FUTURE GENER COMP SY, V111, P368, DOI 10.1016/j.future.2020.05.010
   Yu WY, 2020, FUTURE GENER COMP SY, V109, P611, DOI 10.1016/j.future.2018.04.090
   Yu WY, 2018, IEEE T SYST MAN CY-S, V48, P130, DOI 10.1109/TSMC.2016.2598287
   Zheng LT, 2020, IEEE T COMPUT SOC SY, V7, P1304, DOI 10.1109/TCSS.2020.3017013
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SLOVAK ACAD SCIENCES INST INFORMATICS
PI BRATISLAVA
PA DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA
SN 1335-9150
EI 
J9 COMPUT INFORM
JI Comput. Inform.
PD JUN 15
PY 2023
VL 42
IS 2
BP 501
EP 524
DI 10.31577/cai20232501
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K2HE0
UT WOS:001014693900011
DA 2023-11-10
ER

PT J
AU Liu, Y
   Liu, H
   Wang, HQ
   Meng, FY
   Liu, MY
AF Liu, Yang
   Liu, Hong
   Wang, Huaqiu
   Meng, Fanyang
   Liu, Mengyuan
TI BCAN: Bidirectional Correct Attention Network for Cross-Modal Retrieval
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Semantics; Feature extraction; Task analysis; Visualization; Bicycles; Long short term memory; Learning systems; Attention mechanism; cross-modal retrieval; image-text matching; multimodal learning
AB As a fundamental topic in bridging the gap between vision and language, cross-modal retrieval purposes to obtain the correspondences' relationship between fragments, i.e., subregions in images and words in texts. Compared with earlier methods that focus on learning the visual semantic embedding from images and sentences to the shared embedding space, the existing methods tend to learn the correspondences between words and regions via cross-modal attention. However, such attention-based approaches invariably result in semantic misalignment between subfragments for two reasons: 1) without modeling the relationship between subfragments and the semantics of the entire images or sentences, it will be hard for such approaches to distinguish images or sentences with multiple same semantic fragments and 2) such approaches focus attention evenly on all subfragments, including nonvisual words and a lot of redundant regions, which also will face the problem of semantic misalignment. To solve these problems, this article proposes a bidirectional correct attention network (BCAN), which introduces a novel concept of the relevance between subfragments and the semantics of the entire images or sentences and designs a novel correct attention mechanism by modeling the local and global similarity between images and sentences to correct the attention weights focused on the wrong fragments. Specifically, we introduce a concept about the semantic relationship between subfragments and entire images or sentences and use this concept to solve the semantic misalignment from two aspects. In our correct attention mechanism, we design two independent units to correct the weight of attention focused on the wrong fragments. Global correct unit (GCU) with modeling the global similarity between images and sentences into the attention mechanism to solve the semantic misalignment problem caused by focusing attention on relevant subfragments in irrelevant pairs (RI) and the local correct unit (LCU) consider the difference in the attention weights between fragments among two steps to solve the semantic misalignment problem caused by focusing attention on irrelevant subfragments in relevant pairs (IR). Extensive experiments on large-scale MS-COCO and Flickr30K show that our proposed method outperforms all the attention-based methods and is competitive to the state-of-the-art. Our code and pretrained model are publicly available at: https://github.com/liuyyy111/BCAN.
C1 [Liu, Yang; Wang, Huaqiu] Chongqing Univ Technol, Sch Artificial Intelligence, Chongqing 400054, Peoples R China.
   [Liu, Yang] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Liu, Hong; Liu, Mengyuan] Peking Univ, Shenzhen Grad Sch, Key Lab Machine Percept, Shenzhen 518005, Peoples R China.
   [Meng, Fanyang] Peng Cheng Lab, Shenzhen 518038, Peoples R China.
C3 Chongqing University of Technology; Sichuan University; Peking University; Peng Cheng Laboratory
RP Liu, MY (通讯作者)，Peking Univ, Shenzhen Grad Sch, Key Lab Machine Percept, Shenzhen 518005, Peoples R China.
EM nkliuyifang@gmail.com
FU National Natural Science Foundation of China [62203476]
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Ba J, 2015, P 3 INT C LEARN REPR, V0, P0
   Cho KYHY, 2014, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Faghri F, 2018, ARXIV, V0, P0
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Girshick R, 1900, DOI 10.1109/CVPR.2014.81, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu JX, 2018, PROC CVPR IEEE, V0, PP7181, DOI 10.1109/CVPR.2018.00750
   Gu Y, 2021, IEEE T NEUR NET LEAR, V32, P481, DOI 10.1109/TNNLS.2020.2980129
   Haoran Wang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12369), V0, PP18, DOI 10.1007/978-3-030-58586-0_2
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hu J, 2018, P IEEE C COMP VIS PA, V0, P7132
   Huang Y, 2018, PROC CVPR IEEE, V0, PP6163, DOI 10.1109/CVPR.2018.00645
   Huang Y, 2017, PROC CVPR IEEE, V0, PP7254, DOI 10.1109/CVPR.2017.767
   Hui Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP12652, DOI 10.1109/CVPR42600.2020.01267
   Ji Z, 2019, IEEE I CONF COMP VIS, V0, PP5753, DOI 10.1109/ICCV.2019.00585
   Ji Z, 2020, IEEE T NEUR NET LEAR, V31, P321, DOI 10.1109/TNNLS.2019.2904991
   Jin L, 2019, IEEE T NEUR NET LEAR, V30, P1429, DOI 10.1109/TNNLS.2018.2869601
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kaur P, 2021, COMPUT SCI REV, V39, P0, DOI 10.1016/j.cosrev.2020.100336
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kiros R, 2014, ARXIV, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li KP, 2019, IEEE I CONF COMP VIS, V0, PP4653, DOI 10.1109/ICCV.2019.00475
   Li XQ, 2021, NEUROCOMPUTING, V452, P675, DOI 10.1016/j.neucom.2020.07.139
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP3, DOI 10.1145/3343031.3350869
   Liu Chunxiao, 2020, P IEEE CVF C COMP VI, V0, PP10918, DOI 10.1109/CVPR42600.2020.01093
   Liu Y, 2019, PATTERN RECOGN, V93, P365, DOI 10.1016/j.patcog.2019.05.008
   Liu Y, 2021, IEEE T NEUR NET LEAR, V32, P3894, DOI 10.1109/TNNLS.2020.3016083
   Matsubara T, 2021, IEICE T INF SYST, VE104D, P24, DOI 10.1587/transinf.2020MUP0003
   Messina N, 2020, ARXIV, V0, P0
   Messina N, 2021, ACM T MULTIM COMPUT, V17, P0, DOI 10.1145/3451390
   Mikolov T, 2013, ARXIV, V0, P0
   Nam H, 2017, PROC CVPR IEEE, V0, PP2156, DOI 10.1109/CVPR.2017.232
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, P0, DOI 10.1145/3284750
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ranjan V, 2015, IEEE I CONF COMP VIS, V0, PP4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia N, 2010, P 18 ACM INT C MULT, V0, PP251, DOI 10.1145/1873951.1873987
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Shu XB, 2022, IEEE T CIRC SYST VID, V32, P5281, DOI 10.1109/TCSVT.2022.3142771
   Shu XB, 2022, IEEE T PATTERN ANAL, V44, P3300, DOI 10.1109/TPAMI.2021.3050918
   Si JL, 2018, PROC CVPR IEEE, V0, PP5363, DOI 10.1109/CVPR.2018.00562
   Socher R, 2014, J T ASS COMPUT LINGU, V2, P207, DOI 10.1162/TACL_A_00177
   Tang JH, 2022, IEEE T PATTERN ANAL, V44, P636, DOI 10.1109/TPAMI.2019.2928540
   Wang DQ, 2021, IEEE T NEUR NET LEAR, V32, P736, DOI 10.1109/TNNLS.2020.2979225
   Wang T, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP12, DOI 10.1145/3343031.3350875
   Wang Y, 2019, ARXIV, V0, P0
   Wang Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP1793, DOI 10.1109/ICCV48922.2021.00183
   Wei W, 2020, IEEE ACCESS, V8, P84642, DOI 10.1109/ACCESS.2020.2992187
   Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597
   Yu MY, 2017, IEEE T NEUR NET LEAR, V28, P2899, DOI 10.1109/TNNLS.2016.2609463
   Yu Y, 2019, IEEE T NEUR NET LEAR, V30, P1250, DOI 10.1109/TNNLS.2018.2856253
   Zhang LL, 2022, IEEE T CYBERNETICS, V52, P13308, DOI 10.1109/TCYB.2021.3101880
   Zhang Q, 2020, PROC CVPR IEEE, V0, PP3533, DOI 10.1109/CVPR42600.2020.00359
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, P0, DOI 10.1145/3383184
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
NR 62
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2023.3276796
EA MAY 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA I9HB7
UT WOS:001005806900001
PM 37256811
DA 2023-11-10
ER

PT J
AU Peng, JR
   Chang, Q
   Yin, HR
   Bu, XY
   Sun, JJ
   Xie, LX
   Zhang, XP
   Tian, Q
   Zhang, ZX
AF Peng, Junran
   Chang, Qing
   Yin, Haoran
   Bu, Xingyuan
   Sun, Jiajun
   Xie, Lingxi
   Zhang, Xiaopeng
   Tian, Qi
   Zhang, Zhaoxiang
TI GAIA-Universe: Everything is Super-Netify
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Computer vision; object detection; semantic segmentation; AutoML
AB Pre-training on large-scale datasets has played an increasingly significant role in computer vision and natural language processing recently. However, as there exist numerous application scenarios that have distinctive demands such as certain latency constraints and specialized data distributions, it is prohibitively expensive to take advantage of large-scale pre-training for per-task requirements. we focus on two fundamental perception tasks (object detection and semantic segmentation) and present a complete and flexible system named GAIA-Universe(GAIA), which could automatically and efficiently give birth to customized solutions according to heterogeneous downstream needs through data union and super-net training. GAIA is capable of providing powerful pre-trained weights and searching models that conform to downstream demands such as hardware constraints, computation constraints, specified data domains, and telling relevant data for practitioners who have very few datapoints on their tasks. With GAIA, we achieve promising results on COCO, Objects365, Open Images, BDD100 k, and UODB which is a collection of datasets including KITTI, VOC, WiderFace, DOTA, Clipart, Comic, and more. Taking COCO as an example, GAIA is able to efficiently produce models covering a wide range of latency from 16 ms to 53 ms, and yields AP from 38.2 to 46.5 without whistles and bells. GAIA is released at https://github.com/GAIA-vision.
C1 [Peng, Junran; Chang, Qing; Yin, Haoran; Sun, Jiajun; Zhang, Zhaoxiang] Chinese Acad Sci CASIA, Ctr Res Intelligent Percept & Comp CRIPAC, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100045, Peoples R China.
   [Peng, Junran; Chang, Qing; Yin, Haoran; Sun, Jiajun; Zhang, Zhaoxiang] Univ Chinese Acad Sci UCAS, Beijing 100190, Peoples R China.
   [Peng, Junran; Xie, Lingxi; Zhang, Xiaopeng; Tian, Qi] Huawei Technol Inc, Beijing 100190, Peoples R China.
   [Bu, Xingyuan] Beijing Inst Technol, Beijing 100190, Peoples R China.
   [Zhang, Zhaoxiang] Ctr Excellence Brain Sci & Intelligence Technol CE, Ctr Artificial Intelligence & Robot, HKISICAS, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Huawei Technologies; Beijing Institute of Technology
RP Zhang, ZX (通讯作者)，Chinese Acad Sci CASIA, Ctr Res Intelligent Percept & Comp CRIPAC, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100045, Peoples R China.
EM jrpeng4ever@126.com; changqing2020@ia.ac.cn; yinhaoran19@mails.ucas.ac.cn; xingyuanbu@gmail.com; sunjiajun211@mails.ucas.ac.cn; 198808xc@gmail.com; zxphistory@gmail.com; tian.qi1@huawei.com; zhaoxiang.zhang@ia.ac.cn
FU Major Project for New Generation of AI; National Natural Science Foundation of China [2018AAA0100400, 61836014, U21B2042, 62072457]; InnoHK program;  [62006231]
CR Aharoni Roee, 2020, P 58 ANN M ASS COMP, V0, PP7747, DOI 10.18653/v1/2020.acl-main.692
   Brown TB, 2020, ARXIV, V0, P0
   Baker Bowen, 2017, INT C LEARN REPR ICL, V0, P0
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Bu XY, 2021, PROC CVPR IEEE, V0, PP274, DOI 10.1109/CVPR46437.2021.00034
   Cai H, 2018, AAAI CONF ARTIF INTE, V0, P2787
   Cai Han, 2019, INT C LEARN REPR, V0, P0
   Cai Han, 2020, ICLR, V0, P0
   Cai ZW, 2018, PROC CVPR IEEE, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Chang Q, 2022, PROC CVPR IEEE, V0, PP9831, DOI 10.1109/CVPR52688.2022.00961
   Chen BY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP12, DOI 10.1109/ICCV48922.2021.00008
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen MH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP12250, DOI 10.1109/ICCV48922.2021.01205
   Chen Y, 2018, PROC CVPR IEEE, V0, PP3339, DOI 10.1109/CVPR.2018.00352
   Cheng B, 2021, ADV NEURAL INF PROCE, V34, P17864
   Cheng BW, 2022, ARXIV, V0, P0
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, V0, PP3008, DOI 10.1109/CVPRW50498.2020.00359
   Cui Y, 2018, PROC CVPR IEEE, V0, PP4109, DOI 10.1109/CVPR.2018.00432
   Dai JF, 2017, IEEE I CONF COMP VIS, V0, PP764, DOI 10.1109/ICCV.2017.89
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   EVERINGHAM M, 2012, PASCAL VISUAL OBJECT, V2012, P2012, DOI 10.1109/HASE.2017.36
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ge Z, 2021, ARXIV, V0, P0
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Ginsburg B, 2019, STOCHASTIC GRADIENT, V0, P0
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Grill J-B, 2020, P INT C NEUR INF PRO, V0, P0
   Gururangan Suchin, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Hasan I, 2020, ARXIV, V0, P0
   He KM, 2018, ARXIV, V0, P0
   He KM, 2019, IEEE I CONF COMP VIS, V0, PP4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hoffer E, 2019, ARXIV, V0, P0
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Inoue N, 2018, PROC CVPR IEEE, V0, PP5001, DOI 10.1109/CVPR.2018.00525
   Jiahui Yu, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12352), V0, PP702, DOI 10.1007/978-3-030-58571-6_41
   Kaiming He, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9726, DOI 10.1109/CVPR42600.2020.00975
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kirillov A, 2019, PROC CVPR IEEE, V0, PP6392, DOI 10.1109/CVPR.2019.00656
   Kolesnikov Alexander, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12350), V0, PP491, DOI 10.1007/978-3-030-58558-7_29
   Kuznetsova A, 2020, ARXIV, V0, P0
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lambert J, 2020, PROC CVPR IEEE, V0, PP2876, DOI 10.1109/CVPR42600.2020.00295
   Li HD, 2019, ARXIV, V0, P0
   Liang-Chieh Chen, 2018, COMPUTER VISION - ECCV 2018. 15TH EUROPEAN CONFERENCE. PROCEEDINGS: LECTURE NOTES IN COMPUTER SCIENCE (LNCS 11211), V0, PP833, DOI 10.1007/978-3-030-01234-2_49
   Liao Y-L, 2021, ARXIV, V0, P0
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu HX, 2019, ARXIV, V0, P0
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2201.03545
   Liu Z, 2021, ARXIV, V0, P0
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Loshchilov Ilya, 2019, ARXIV, V0, P0
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Neuhold G, 2017, IEEE I CONF COMP VIS, V0, PP5000, DOI 10.1109/ICCV.2017.534
   Pang JM, 2019, PROC CVPR IEEE, V0, PP821, DOI 10.1109/CVPR.2019.00091
   Peng ZL, 2021, ARXIV, V0, P0
   Raffel C, 2020, ARXIV, V0, P0
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Rebuffi Sylvestre-Alvise, 2017, NEURIPS, V0, P0, DOI DOI 10.5555/3294771.3294820
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   robustvision, 2020, ROB VIS CHALL, V0, P0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seita D, 2018, BERKELEY ARTIF INTEL, V511, P0
   Shao S, 2019, IEEE I CONF COMP VIS, V0, PP8429, DOI 10.1109/ICCV.2019.00852
   Shu CY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP5291, DOI 10.1109/ICCV48922.2021.00526
   Su X, 2021, ARXIV, V0, P0
   Sun C, 2017, IEEE I CONF COMP VIS, V0, PP843, DOI 10.1109/ICCV.2017.97
   Toshev A, 2014, PROC CVPR IEEE, V0, PP1653, DOI 10.1109/CVPR.2014.214
   Touvron Hugo, 2021, P INT C MACH LEARN I, V0, P0, DOI DOI 10.48550/arXiv.2012.12877
   Varma G, 2019, IEEE WINT CONF APPL, V0, PP1743, DOI 10.1109/WACV.2019.00190
   Wang WH, 2021, ARXIV, V0, P0
   Wang XD, 2019, PROC CVPR IEEE, V0, PP7281, DOI 10.1109/CVPR.2019.00746
   Wolpert DH, 1997, IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, V1, P67, DOI 10.1109/4235.585893
   Wu Yuxin, 2019, DETECTRON2, V0, P0
   Xiangyun Zhao, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP178, DOI 10.1007/978-3-030-58568-6_11
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Yan X, 2020, PROC CVPR IEEE, V0, PP3892, DOI 10.1109/CVPR42600.2020.00395
   Yu JH, 2019, IEEE I CONF COMP VIS, V0, PP1803, DOI 10.1109/ICCV.2019.00189
   Yuan L, 2021, ARXIV, V0, P0
   Yuan L, 2021, ARXIV, V0, P0
   Yuhui Yuan, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12351), V0, PP173, DOI 10.1007/978-3-030-58539-6_11
   Yun S, 2019, IEEE I CONF COMP VIS, V0, PP6022, DOI 10.1109/ICCV.2019.00612
   Yalniz IZ, 2019, ARXIV, V0, P0
   Zendel O, 2018, LECT NOTES COMPUT SC, V11210, P407, DOI 10.1007/978-3-030-01231-1_25
   Zhai XH, 2020, ARXIV, V0, P0
   Zhang SS, 2017, PROC CVPR IEEE, V0, PP4457, DOI 10.1109/CVPR.2017.474
   Zhao H, 2020, PROC IEEECVF C COMPU, V0, PP10073, DOI 10.1109/CVPR42600.2020.01009
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhaowei Cai, 2018, 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION. PROCEEDINGS, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Zheng M, 2021, ADV NEURAL INFORM PR, V0, P2543
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou BL, 2017, PROC CVPR IEEE, V0, PP5122, DOI 10.1109/CVPR.2017.544
   Zoph B, 2017, P INT C LEARN REPR I, V0, P0
   Zoph B, 2018, PROC CVPR IEEE, V0, PP8697, DOI 10.1109/CVPR.2018.00907
NR 102
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD OCT 15
PY 2023
VL 45
IS 10
BP 11856
EP 11868
DI 10.1109/TPAMI.2023.3276392
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA S1KC4
UT WOS:001068816800023
PM 37192026
DA 2023-11-10
ER

PT J
AU Lv, XQ
   Liu, ZA
   Zhao, Y
   Xu, G
   You, XD
AF Lv, Xueqiang
   Liu, Zhaonan
   Zhao, Ying
   Xu, Ge
   You, Xindong
TI HBert: A Long Text Processing Method Based on BERT and Hierarchical Attention Mechanisms
SO INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS
LA English
DT Article
DE BERT; Hierarchical Attention; Long Text Processing
AB With the emergence of a large-scale pre-training model based on the transformer model, the effect of all-natural language processing tasks has been pushed to a new level. However, due to the high complexity of the transformer's self-attention mechanism, these models have poor processing ability for long text. Aiming at solving this problem, a long text processing method named HBert based on Bert and hierarchical attention neural network is proposed. Firstly, the long text is divided into multiple sentences whose vectors are obtained through the word encoder composed of Bert and the word attention layer. And the article vector is obtained through the sentence encoder that is composed of transformer and sentence attention. Then the article vector is used to complete the subsequent tasks. The experimental results show that the proposed HBert method achieves good results in text classification and QA tasks. The F1 value is 95.7% in longer text classification tasks and 75.2% in QA tasks, which are better than the state-of-the-art model longformer.
C1 [Lv, Xueqiang; Liu, Zhaonan; Zhao, Ying; You, Xindong] Beijing Informat Sci & Technol Univ, Beijing, Peoples R China.
   [Xu, Ge] Minjiang Univ, Fuzhou, Peoples R China.
C3 Beijing Information Science & Technology University; Minjiang University
RP You, XD (通讯作者)，Beijing Informat Sci & Technol Univ, Beijing, Peoples R China.
FU National Natural Science Foundation of China [62171043]; Natural Science Foundation of Beijing [4212020]; Defense-related Science and Technology Key Lab Fund project [6412006200404]; National Language Commission project [ZDI145-10, YB145-3]; Central Leading Local Project "Fujian Mental Health Human-Computer Interaction Technology Research Center" [2020L3024]; R&D Program of Beijing Municipal Education Commission [KM202111232001]
CR Abreu J, 2019, LECT NOTES COMPUT SC, V11731, P396, DOI 10.1007/978-3-030-30493-5_39
   Adhikari A, 2019, ARXIV, V0, P0
   Beltagy I, 2020, ARXIV, V0, P0
   [车蕾 Che Lei], 2019, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V33, P93
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Kiesel J, 2019, P 13 INT WORKSH SEM, V0, PP829, DOI 10.18653/v1/S19-2145
   Liu YH, 2019, ARXIV, V0, P0
   Maas Andrew L, 2011, P 49 ANN M ASS COMP, V0, P142
   Pappagari R, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP838, DOI 10.1109/asru46091.2019.9003958
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang Kun, 2020, JOURNAL OF COMPUTER APPLICATIONS, V0, PP2838, DOI 10.0000/11772/j.issn.1001-9081.2020020164
   Welbl J, 2018, T ASSOC COMPUT LING, V6, P287
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zaheer Manzil, 2020, ADV NEURAL INFORM PR, V33, P17283, DOI 10.5555/3495724.3497174
NR 16
TC 1
Z9 1
U1 13
U2 13
PU IGI GLOBAL
PI HERSHEY
PA 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA
SN 1552-6283
EI 1552-6291
J9 INT J SEMANT WEB INF
JI Int. J. Semant. Web Inf. Syst.
PD JUN 15
PY 2023
VL 19
IS 1
BP 
EP 
DI 10.4018/IJSWIS.322769
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA I2OC7
UT WOS:001001219100009
DA 2023-11-10
ER

PT J
AU Huang, YX
   Liang, Y
   Wu, ZY
   Zhu, EC
   Yu, ZT
AF Huang, Yuxin
   Liang, Yin
   Wu, Zhaoyuan
   Zhu, Enchang
   Yu, Zhengtao
TI Cross-lingual Sentence Embedding for Low-resource Chinese-Vietnamese Based on Contrastive Learning
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Chinese-Vietnamese; low-resource language; cross-lingual sentence embedding; siamese network; mBERT
AB Cross-lingual sentence embedding's goal is mapping sentences with similar semantics but in different languages close together and dissimilar sentences farther apart in the representation space. It is the basis of many downstream tasks such as cross-lingual document matching and cross-lingual summary extraction. At present, the works of cross-lingual sentence embedding tasks mainly focus on languages with large-scale corpus. But low-resource languages such as Chinese-Vietnamese are short of sentence-level parallel corpora and clear cross-lingual monitoring signals, and these works on low-resource languages have poor performances. Therefore, we propose a cross-lingual sentence embedding method based on contrastive learning and effectively fine-tune powerful pretraining mode by constructing sentence-level positive and negative samples to avoid the catastrophic forgetting problem of the traditional fine-tuning pre-trained model based only on small-scale aligned positive samples. First, we construct positive and negative examples by taking parallel Chinese Vietnamese sentences as positive examples and non-parallel sentences as negative examples. Second, we construct a siamese network to get contrastive loss by inputting positive and negative samples and fine-tuning our model. The experimental results show that our method can effectively improve the semantic alignment accuracy of cross-lingual sentence embedding in Chinese and Vietnamese contexts.
C1 [Huang, Yuxin; Liang, Yin; Wu, Zhaoyuan; Zhu, Enchang; Yu, Zhengtao] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Yunnan Key Lab Artificial Intelligence, 727 Jingming South Rd, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology
RP Yu, ZT (通讯作者)，Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Yunnan Key Lab Artificial Intelligence, 727 Jingming South Rd, Kunming 650500, Yunnan, Peoples R China.
EM huangyuxin2004@163.com; 2712653816@qq.com; 978105863@qq.com; ztyu@hotmail.com
FU National Natural Science Foundation of China [U21B2027, 61972186, 62266028, 62266027]; Yunnan Provincial Major Science and Technology Special Plan Projects [202103AA080015, 202202AD080003]; General Projects of Basic Research in Yunnan Province [202201AS070179, 202201AT070915]; Kunming University of Science and Technology "double first-class" joint project [202201BE070001-021]
CR Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bai Y, 2021, LONG PAPERS, V1, P6910, DOI 10.18653/V1/2021.ACL-LONG.538
   Bromley J, 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chuang YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P4207
   Conneau A, 2020, ARXIV, V0, P0
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Constant N, 2020, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   EHinton Geoffrey, 2012, ARXIV, V0, P0
   El-Kishky A, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P616
   Gao J, 2019, P 7 INT C LEARNING R, V0, P0
   Gao Tianyu, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2104.08821
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V0, P8
   Lample G, 2019, ARXIV, V0, P0
   Libovicky Jindrich, 2020, FINDINGS ASS COMPUTA, V0, PP1663, DOI 10.18653/V1/2020.FINDINGS-EMNLP.150
   Lin Huan, 2021, ARXIV, V0, P0
   Liu X, 2021, ARXIV, V0, P0
   Mulcaire P, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3912
   Pagliardini M, 2018, ARXIV, V0, P0
   Papadimitriou I, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2522
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Raffel C, 2020, ARXIV, V0, P0
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Ruckl‚ A, 2018, ARXIV, V0, P0
   Le QV, 2014, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Z, 2021, ARXIV, V0, P0
NR 29
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN 15
PY 2023
VL 22
IS 6
BP 
EP 
DI 10.1145/3589341
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K7YR0
UT WOS:001018562700022
DA 2023-11-10
ER

PT J
AU Shi, SJ
   Nie, FP
   Wang, R
   Li, XL
AF Shi, Shaojun
   Nie, Feiping
   Wang, Rong
   Li, Xuelong
TI Multi-View Clustering via Nonnegative and Orthogonal Graph Reconstruction
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Laplace equations; Clustering methods; Clustering algorithms; Matrix decomposition; Natural language processing; Diseases; Tensors; Multi-view clustering; graph reconstruction; spectral embedding; nonnegative matrix factorizaiton
AB The goal of multi-view clustering is to partition samples into different subsets according to their diverse features. Previous multi-view clustering methods mainly exist two forms: multi-view spectral clustering and multi-view matrix factorization. Although they have shown excellent performance in many occasions, there are still many disadvantages. For example, multi-view spectral clustering usually needs to perform postprocessing. Multi-view matrix factorization directly decomposes the original data features. When the size of features is large, it encounters the expensive time consumption to decompose these data features thoroughly. Therefore, we proposed a novel multi-view clustering approach. The main advantages include the following three aspects: 1) it searches for a common joint graph across multiple views, which fully explores the hidden structure information by utilizing the compatibility among views; 2) the introduced nonnegative constraint manipulates that the final clustering results can be directly obtained; and 3) straightforwardly decomposing the similarity matrix can transform the eigenvalue factorization in spectral clustering with computational complexity O(n(3)) into the singular value decomposition (SVD) with O(nc(2)) time cost, where n and c, respectively, denote the numbers of samples and classes. Thus, the computational efficiency can be improved. Moreover, in order to learn a better clustering model, we set that the constructed similarity graph approximates each view affinity graph as close as possible by adding the constraint as the initial affinity matrices own. Furthermore, substantial experiments are conducted, which verifies the superiority of the proposed two clustering methods comparing with single-view clustering approaches and state-of-the-art multi-view clustering methods.
C1 [Shi, Shaojun; Nie, Feiping; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Shi, Shaojun; Nie, Feiping; Wang, Rong; Li, Xuelong] Northwestern Polytech Univ, Sch Artificial Intelligence Opt & Elect iOPEN, Xian 710072, Shaanxi, Peoples R China.
   [Wang, Rong] Northwestern Polytech Univ, Sch Cybersecur, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University
RP Nie, FP (通讯作者)，Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Nie, FP (通讯作者)，Northwestern Polytech Univ, Sch Artificial Intelligence Opt & Elect iOPEN, Xian 710072, Shaanxi, Peoples R China.
EM shaojunshi@mail.nwpu.edu.cn; feipingnie@gmail.com; wangrong07@tsinghua.org.cn; xuelong_li@opt.ac.cn
FU National Key Research and Development Program of China [2018AAA0101902]; Natural Science Basic Research Program of Shaanxi [2021JM071]; National Natural Science Foundation of China [61936014, 61772427]; Fundamental Research Funds for the Central Universities [G2019KY0501]
CR Akata Z, 2011, 16 COMP VIS WINT WOR, V0, P0
   [Anonymous], 2012, P 2 ACM INT C MULTIM, V0, P0
   [Anonymous], 2013, SIGNAL PROCESSING PA, V0, P0
   Bekkerman R, 2007, PROC CVPR IEEE, V0, P1938
   Cai X, 2013, 23 INT JOINT C ARTIF, V0, P0
   CAO XC, 2015, PROC CVPR IEEE, V0, PP586, DOI 10.1109/CVPR.2015.7298657
   CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898
   Chen C, 2019, NEUROCOMPUTING, V366, P1, DOI 10.1016/j.neucom.2019.06.098
   Chen YY, 2020, PATTERN RECOGN, V106, P0, DOI 10.1016/j.patcog.2020.107441
   Djelouah A, 2013, IEEE I CONF COMP VIS, V0, PP2640, DOI 10.1109/ICCV.2013.328
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Gao HC, 2015, IEEE I CONF COMP VIS, V0, PP4238, DOI 10.1109/ICCV.2015.482
   Han JW, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1809
   Hu ZX, 2020, INFORM FUSION, V55, P251, DOI 10.1016/j.inffus.2019.09.005
   Huang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P3569
   Huang SD, 2018, NEUROCOMPUTING, V311, P197, DOI 10.1016/j.neucom.2018.05.072
   Jiang Y, 2012, INT C PATT RECOG, V0, P2997
   Jin C, 2015, AAAI CONF ARTIF INTE, V0, P151
   Kim YM, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P821
   Kuhn Harold W, 1955, NAV RES LOG, V2, P83, DOI 10.1002/NAV.20053
   Kumar A, 2011, ADV NEURAL INFORM PR, V24, P0, DOI 10.5555/2986459.2986617
   KumarA Daume H, 2011, ICML, V0, PP393, DOI 10.5555/3104482.3104532
   Li DP, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, V0, PP364, DOI 10.1109/BHI.2016.7455910
   Li YQ, 2015, AAAI CONF ARTIF INTE, V0, P2750
   Liu J, 2013, P 2013 SIAM INT C DA, V0, PP252, DOI 10.1137/1.9781611972832.28
   Murase H, 1996, COLUMBIA OBJECT IMAG, V0, P0
   Nie F, 2016, P 25 INT JOINT C ART, V0, PP1881, DOI 10.24963/IJCAI.2018/320
   Nie FP, 2020, PATTERN RECOGN, V102, P0, DOI 10.1016/j.patcog.2020.107207
   Nie FP, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2022, DOI 10.1145/3219819.3220049
   Nie FP, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2564
   Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939
   Nie FP, 2017, SCI CHINA INFORM SCI, V60, P0, DOI 10.1007/s11432-016-9021-9
   Nie FP, 2016, AAAI CONF ARTIF INTE, V0, P1969
   Ren PZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2644
   Ren YZ, 2020, NEUROCOMPUTING, V383, P248, DOI 10.1016/j.neucom.2019.11.104
   Shahnaz F, 2006, INFORM PROCESS MANAG, V42, P373, DOI 10.1016/j.ipm.2004.11.005
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi SJ, 2020, NEUROCOMPUTING, V399, P369, DOI 10.1016/j.neucom.2020.02.071
   Tao H, 2017, AS C MACH LEARN, V0, P113
   Tzortzis G, 2012, IEEE DATA MINING, V0, PP675, DOI 10.1109/ICDM.2012.43
   van Breukelen M, 1998, KYBERNETIKA, V34, P381
   Wang H, 2019, KNOWL-BASED SYST, V163, P1009, DOI 10.1016/j.knosys.2018.10.022
   Wang Q, 2020, IEEE T PATTERN ANAL, V42, P46, DOI 10.1109/TPAMI.2018.2875002
   Wang W, 2010, P 27 INT C MACHINE L, V0, P1135
   Wang Yang, 2016, P INT JOINT C ART IN, V0, P2153
   Wu X, 2008, IEEE T MULTIMEDIA, V10, P188, DOI 10.1109/TMM.2007.911778
   Xia RK, 2014, AAAI CONF ARTIF INTE, V0, P2149
   Xiao Cai, 2011, 2011 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP1977, DOI 10.1109/CVPR.2011.5995740
   Xiao Q, 2019, KNOWL-BASED SYST, V175, P118, DOI 10.1016/j.knosys.2019.03.023
   Xing L, 2021, IEEE T CYBERNETICS, V51, P3298, DOI 10.1109/TCYB.2019.2952398
   Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976
   Xu JL, 2016, PROC CVPR IEEE, V0, PP5356, DOI 10.1109/CVPR.2016.578
   Yang XJ, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3035677
   Yin QY, 2015, NEUROCOMPUTING, V156, P12, DOI 10.1016/j.neucom.2015.01.017
   Zhan K, 2019, IEEE T KNOWL DATA EN, V31, P1984, DOI 10.1109/TKDE.2018.2872061
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646
   Zhang CQ, 2017, PROC CVPR IEEE, V0, PP4333, DOI 10.1109/CVPR.2017.461
   Zhang GY, 2020, KNOWL-BASED SYST, V189, P0, DOI 10.1016/j.knosys.2019.105126
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
   Zhou D, 2007, P 24 INT C MACH LEAR, V0, PP1159, DOI 10.1145/1273496.1273642
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
NR 62
TC 24
Z9 24
U1 5
U2 38
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JAN 15
PY 2023
VL 34
IS 1
BP 201
EP 214
DI 10.1109/TNNLS.2021.3093297
EA JUL 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA L1GT3
UT WOS:000732415200001
PM 34288875
DA 2023-11-10
ER

PT J
AU Jang, Y
   Lee, HG
   Kim, H
AF Jang, Youngjin
   Lee, Hyeon-gu
   Kim, Harksoo
TI Long multispan prediction model for machine reading comprehension in healthcare domain
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Healthcare domain; Long span prediction; Machine reading comprehension; Multispan Prediction; Span matrix
AB Machine reading comprehension (MRC) is a question answering task, in which a system provides appropriate answers to users queries in a given document. With large-scale language models and enough training datasets, recent MRC models have surpassed humans in well-designed intrinsic tests that require short and single span answers. However, they have performed poorly in real world applications that require long and multispan an-swers. In healthcare domain, users want to find long and detailed information (e.g., symptoms of an illness, causes of a disease, and effects of a drug) rather than short and simple ones (e.g., name of an illness, name of a virus, and date of discovery). To satisfy these needs, we propose an MRC model to extract nonconsecutive long text spans from a document. The proposed model detects long candidate answer spans consisting of sentences and determines multiple nonconsecutive spans by using a span matrix. In an experiment using long multispan datasets, namely, MASHQA (a healthcare domain dataset), the proposed model outperformed previous state of the art MRC models in terms of all evaluation parameters.
C1 [Jang, Youngjin] Konkuk Univ, Dept Artificial Intelligence, Seoul, South Korea.
   [Lee, Hyeon-gu] NAVER Corp, Dept Search, Seoul, South Korea.
   [Lee, Hyeon-gu] NAVER Corp, NLP Lab, Seoul, South Korea.
   [Kim, Harksoo] Konkuk Univ, Div Comp Sci & Engn, Seoul, South Korea.
   [Kim, Harksoo] Konkuk Univ, Dept Artificial Intelligence, Seoul, South Korea.
C3 Konkuk University; Naver; Naver; Konkuk University; Konkuk University
RP Kim, H (通讯作者)，Konkuk Univ, Div Comp Sci & Engn, Seoul, South Korea.; Kim, H (通讯作者)，Konkuk Univ, Dept Artificial Intelligence, Seoul, South Korea.
EM danyon@konkuk.ac.kr; hyeongu.lee@navercorp.com; nlpdrkim@konkuk.ac.kr
FU Institute for Information & communications Technology Planning Korea government (MSIT) & Evaluation (IITP) - Korea government (MSIT) [2022-0-00369]; "Automated Extraction System for Custom Answer Snippets for Questions" - Naver corporation
CR Chung JY, 2014, ARXIV, V0, P0
   Clark Kevin, 2020, ICLR, V0, P0
   Dasigi P, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5925
   Devlin J, 1900, P4171, V0, P0, DOI DOI 10.18653/v1/N19-1423
   Garg S, 2020, AAAI CONF ARTIF INTE, V34, P7780
   Hu MH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1596
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kingma DP, 2014, C TRACK P, V0, P0
   Li X, 2020, P 58 ANN M ASS COMPU, V0, PP5849, DOI 10.18653/V1/2020.ACL-MAIN.519
   Liu YH, 2019, ARXIV, V0, P0
   Nguyen T, 2016, P NEURAL INFORM PROC, V0, P0
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Sang EFTK, 2001, LANG COMPUT, V0, P177
   Segal E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3074
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Seo MJ, 2017, 5 INT C LEARNING REP, V0, P0
   Wolf T, 2020, ARXIV, V0, P0
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, PP2013, DOI 10.18653/V1/D15-1237
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yang ZL, 2019, ADV NEUR IN, V32, P0
   Ye DM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7170
   Yu AW, 2018, 6 INT C LEARNING REP, V0, P0
   Zhang ZS, 2021, AAAI CONF ARTIF INTE, V35, P14506
   Zhu M, 2020, FINDINGS ASS COMPUTA, V0, PP3840, DOI 10.18653/V1/2020.FINDINGS-EMNLP.342
NR 24
TC 0
Z9 0
U1 1
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD APR 1
PY 2023
VL 215
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.119300
EA NOV 2022
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 6V8LE
UT WOS:000895291200009
DA 2023-11-10
ER

PT J
AU Callan, D
   Foster, J
AF Callan, Dominic
   Foster, Jennifer
TI How interesting and coherent are the stories generated by a large-scale neural language model? Comparing human and automatic evaluations of machine-generated text
SO EXPERT SYSTEMS
LA English
DT Article
DE evaluation; machine-generated text; natural language generation; transformers
AB Evaluation of the narrative text generated by machines has traditionally been a challenge, particularly when attempting to evaluate subjective elements such as interest or believability. Recent improvements in narrative machine text generation have been largely driven by the emergence of transformer-based language models, trained on massive quantities of data, resulting in higher quality text generation. In this study, a corpus of stories is generated using the pre-trained GPT-Neo transformer model, with human-written prompts as inputs upon which to base the narrative text. The stories generated through this process are subsequently evaluated through both human evaluation and two automated metrics: BERTScore and BERT Next Sentence Prediction, with the aim of determining whether there is a correlation between the automatic scores and the human judgements. The results show variation in human evaluation results in comparison to modern automated metrics, suggesting further work is required to train automated metrics to identify text that is defined as interesting by humans.
C1 [Callan, Dominic; Foster, Jennifer] Dublin City Univ, Sch Comp, Dublin, Ireland.
C3 Dublin City University
RP Callan, D; Foster, J (通讯作者)，Dublin City Univ, Sch Comp, Dublin, Ireland.
EM dominic.callan24@mail.dcu.ie; jennifer.foster@dcu.ie
CR Akoury N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6470
   Black Sid, 2021, GPT NEO LARGE SCALE, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Celikyilmaz A, 2020, PREPRINT, V0, P0
   Chaganty AT, 2018, PREPRINT, V0, P0
   Clark E, 2021, PREPRINT, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Fan A, 2018, PREPRINT, V0, P0
   Gao L, 2020, PREPRINT, V0, P0
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Halliday MAK, 1976, COHESION ENGLISH, V0, P0
   Hashimoto TB, 2019, PREPRINT, V0, P0
   Howcroft DM, 2020, P 13 INT C NAT LANG, V0, P0
   Ji TB, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6416
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Lowe R, 2017, PREPRINT, V0, P0
   McIntyre N, 2009, P JOINT C 47 ANN M A, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pillutla K, 2021, ADV NEURAL INFORM PR, V34, P4816, DOI 10.48550/arXiv.2102.01454
   Purdy C, 2018, 14 ART INT INT DIG E, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Roemmele M, 2017, SIGKDD 2017 WORKSH M, V0, P0
   Sellam Thibault, 2020, P 58 ANN M ASS COMPU, V0, PP7881, DOI 10.18653/V1/2020.ACL-MAIN.704
   van der Lee C, 2019, BEST PRACTICES HUMAN, V0, P0
   van der Lee C, 2021, COMPUT SPEECH LANG, V67, P0, DOI 10.1016/j.csl.2020.101151
   Vaswani A, 2017, ARXIV, V30, P5998
   Yao L, 2019, ARXIV ABS181105701, V0, P0
   Zellers Rowan, 2019, NEURIPS, V0, P0
   Zhang T, 2020, RESCALING BERTSCORE, V0, P0
   Zhang Tianyi, 2020, ICLR, V0, P0
   Zhao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P563
NR 31
TC 0
Z9 0
U1 9
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JUL 15
PY 2023
VL 40
IS 6
BP 
EP 
DI 10.1111/exsy.13292
EA MAR 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA I1QT5
UT WOS:000956803900001
DA 2023-11-10
ER

PT J
AU Yang, L
AF Yang, Liu
TI Unsupervised machine learning and image recognition model application in English part-of-speech feature learning under the open platform environment
SO SOFT COMPUTING
LA English
DT Article
DE Unsupervised learning; Machine learning; Image recognition; Part-of-speech recognition
ID attention mechanism
AB The traditional English part-of-speech analysis model fails to meet people's actual needs due to the fact that the accuracy and other parameters are not up to standard. Facing large-scale English text data, quickly and accurately obtaining the key information needed and improving the efficiency and accuracy of clustering have always been the focus of attention. However, the inherent characteristics of English text make it impossible to accurately calculate the traditional feature weight calculation method, and its part of speech is difficult to recognize. Moreover, in order to obtain a structure closer to the real data, this paper fuses the norm graph and the k-nearest neighbor graph, proposes a new composition framework, and combines it with two common propagation algorithms to complete the classification task. In addition, in order to obtain the improvement effect of the algorithm, the algorithm is tested on the English text classification corpus data set of the natural language processing open platform, and a control experiment is set to analyze the model performance. Finally, this article combines mathematical statistics to process data and draw corresponding charts.
C1 [Yang, Liu] Jiujiang Univ, Sch Foreign Languages, Jiujiang 332005, Peoples R China.
C3 Jiujiang University
RP Yang, L (通讯作者)，Jiujiang Univ, Sch Foreign Languages, Jiujiang 332005, Peoples R China.
EM jxjjlysci@jju.edu.cn
CR Cai YF, 2020, IEEE T IMAGE PROCESS, V29, P4489, DOI 10.1109/TIP.2020.2972692
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Ghaffarian S, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13152965
   Hark C, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102187
   Jetschke G, 2019, DENDROCHRONOLOGIA, V53, P55, DOI 10.1016/j.dendro.2018.11.004
   Xu JY, 2020, NEUROCOMPUTING, V386, P42, DOI 10.1016/j.neucom.2019.08.080
   Luo Yan, 2016, JOURNAL OF COMPUTER APPLICATIONS, V36, P718, DOI 10.11772/j.issn.1001-9081.2016.03.718
   Peng XL, 2021, IEEE T GEOSCI REMOTE, V59, P7296, DOI 10.1109/TGRS.2020.3033009
   Phu VN, 2018, COMPUT MODEL NEW TEC, V22, P20
   Wan QZ, 2020, ENERGY REP, V6, P797, DOI 10.1016/j.egyr.2020.11.129
   Wang SX, 2019, INT J ELEC POWER, V109, P470, DOI 10.1016/j.ijepes.2019.02.022
   Xu Y, 2010, PATTERN RECOGN, V43, P1106, DOI 10.1016/j.patcog.2009.09.013
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang LL, 2013, PROCEDIA COMPUT SCI, V22, P78, DOI 10.1016/j.procs.2013.09.083
   Zhou YJ, 2017, COMPUT SIST, V21, P759, DOI 10.13053/CyS-21-4-2847
NR 15
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD JUL 15
PY 2023
VL 27
IS 14
BP 10013
EP 10023
DI 10.1007/s00500-023-08206-9
EA APR 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA I3HP5
UT WOS:000979478500005
DA 2023-11-10
ER

PT J
AU Chen, DG
   Zhou, J
AF Chen, Deguang
   Zhou, Jie
TI LightMobileBert: A secondary lightweight model based on MobileBert
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Natural language processing; lightweight model; tensor decomposition; supervised contrastive learning
AB MobileBert is a generic lightweight model suffering from a large network depth and parameter cardinality. Therefore, this paper proposes a secondary lightweight model entitled LightMobileBert, which retains the bottom 12 Transformers structure of the pre-trained MobileBert and utilizes the tensor decomposition technique to process the model to skip pretraining and further reduce the parameters. At the same time, the joint loss function is constructed based on the improved Supervised Contrastive Learning loss function and the Cross-Entropy loss function to improve performance and stability. Finally, the LMBert Adam optimizer, an improved Bert Adam optimizer, is used to optimize the model. The experimental results demonstrate that LightMobileBert has a comparatively higher performance than MobileBert and other popular models while requiring 57% fewer network parameters than MobileBert, confirming that LightMobileBert retains a higher performance while being lightweight.
C1 [Chen, Deguang] Shaanxi Normal Univ, Sch Comp Sci, Xian, Peoples R China.
   [Zhou, Jie] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
C3 Shaanxi Normal University; Jiangnan University
RP Chen, DG (通讯作者)，Shaanxi Normal Univ, Sch Comp Sci, Xian, Peoples R China.
EM chendeg4086@163.com
FU National Natural Science Foundation of China [62273219, 62006149, 62003203, 62102239, 61862001]; Natural Science Foundation of Shaanxi Province [2021JM-206, 2021JQ-314]; Fundamental Research Funds For the Central Universities [2021CSLY023, 2021TS035, GK202205038]; Center for Applied Mathematics of Inner Mongolian [ZZYJZD2022003]; Shaanxi Key Science and Technology Innovation Team Project [2022TD-26]
CR Chen D, 2021, COMPUT INTEL NEUROSC, V2021, P1
   Chen DG, 2021, J INTELL FUZZY SYST, V41, P5807, DOI 10.3233/JIFS-200581
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chen Z, 2018, QUORA QUESTION PAIRS, V0, P1
   Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177
   Devlin J, 2018, ARXIV, V1, P4171
   Dolan WB, 2005, P 3 INT WORKSH PAR I, V0, P0
   Fan AEL, 2019, ARXIV, V0, P0
   Gordon MA, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P143
   Gunel B, 2020, C WORKSHOP NEURAL IN, V0, P0
   Guo FM, 2020, INT C LEARNING REPRE, V0, P0
   Haim RB, 2006, P 2 PASCAL CHALLENGE, V0, P7
   Hou L, 2018, 6 INT C LEARN REPR I, V0, P0
   JasonWei Kai, 2019, EDA EASY DATA AUGMEN, V0, P0
   Jiao X, 2020, 2020 C EMPIRICAL MET, V0, P2563
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kingma DP, 2015, PROC ICLR 2015, V0, P0
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lee YH, 2020, ARXIV, V0, P0
   Levesque Hector, 2012, P 13 INT C PRINC KNO, V0, P0
   Li FF, 2016, ARXIV, V0, P0
   Liu YT, 2022, ARXIV, V0, P0
   Liu ZJ, 2021, PROCEEDINGS OF THE 2021 DESIGN, V0, P513, DOI 10.23919/DATE51398.2021.9474043
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Sanh V, 2020, 2020 C EMPIRICAL MET, V0, P38
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Sun Z, 2020, INT C LEARNING REPRE, V0, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, P0
   Xu CW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7859
   Xuanang Chen, 2021, ADVANCES IN INFORMATION RETRIEVAL. 43RD EUROPEAN CONFERENCE ON IR RESEARCH, V0, P241, DOI 10.1007/978-3-030-72240-1_21
   Zafrir O, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), V0, PP36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zhang SK, 2021, ARXIV, V0, P0
   Zhang Tianyi, 2021, P ICLR, V0, P0
   Zhang W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P509
NR 37
TC 0
Z9 0
U1 8
U2 9
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2023
VL 44
IS 2
BP 2117
EP 2129
DI 10.3233/JIFS-221985
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 8N3QB
UT WOS:000925063400046
DA 2023-11-10
ER

PT J
AU Wang, H
   Fu, RL
   Li, CZ
   Zhang, XJ
   Zhou, J
   Bai, X
   Yan, YH
   Zhao, QW
AF Wang, Han
   Fu, Ruiliu
   Li, Chengzhang
   Zhang, Xuejun
   Zhou, Jun
   Bai, Xing
   Yan, Yonghong
   Zhao, Qingwei
TI Reminding the incremental language model via data-free self-distillation
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Incremental language learning; Self-distillation; Hidden data augmentation; Data-free constraint; Pseudo data
ID neural-networks
AB Incremental language learning, which involves retrieving pseudo-data from previous tasks, can alleviate catastrophic forgetting. However, previous methods require a large amount of pseudo-data to approach the performance of multitask learning, and the performance decreases dramatically when there is significantly less pseudo-data than new task data. This decrease occurs because the pseudo-data are learned inefficiently and deviate from the real data. To address these issues, we propose reminding the incremental language model via data-free self-distillation (DFSD), which includes 1) self-distillation based on the Earth mover's distance (SD-EMD) and 2) hidden data augmentation (HDA). SD-EMD can increase the efficiency of the model by adaptively estimating the knowledge distribution in all GPT-2 layers and effectively transferring data from the teacher model to the student model via adaptive self-multilayer-to-multilayer mapping. HDA can reduce deviations by decomposing the generation process via data augmentation and bootstrapping. Our experiments on decaNLP and text classification tasks with low pseudo-data sampling ratios reveal that the DFSD model outperforms previous state-of-the-art incremental methods. The advantages of DFSD become more apparent when there is less pseudo-data and larger deviations.
C1 [Wang, Han; Fu, Ruiliu; Li, Chengzhang; Zhang, Xuejun; Zhou, Jun; Bai, Xing; Yan, Yonghong; Zhao, Qingwei] Chinese Acad Sci, Inst Acoust, Key Lab Speech Acoust & Content Understanding, Beijing, Peoples R China.
   [Wang, Han; Fu, Ruiliu; Li, Chengzhang; Zhang, Xuejun; Zhou, Jun; Bai, Xing; Yan, Yonghong; Zhao, Qingwei] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Acoustics, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Zhao, QW (通讯作者)，Chinese Acad Sci, Inst Acoust, Key Lab Speech Acoust & Content Understanding, Beijing, Peoples R China.; Zhao, QW (通讯作者)，Univ Chinese Acad Sci, Beijing, Peoples R China.
EM wanghan@hccl.ioa.ac.cn; furuiliu@hccl.ioa.ac.cn; lichengzhang@hccl.ioa.ac.cn; zhangxuejun@hccl.ioa.ac.cn; zhoujun@hccl.ioa.ac.cn; baixing@hccl.ioa.ac.cn; yanyonghong@hccl.ioa.ac.cn; zhaoqingwei@hccl.ioa.ac.cn
CR Aljundi R, 2018, LECT NOTES COMPUT SC, V11207, P144, DOI 10.1007/978-3-030-01219-9_9
   Arazo E, 2019, PR MACH LEARN RES, V97, P0
   Capuano N, 2021, APPL INTELL, V51, P3339, DOI 10.1007/s10489-020-01984-x
   Chaudhry Arslan, 2019, 7 INT C LEARNING REP, V0, P0
   Chen Z, 2018, SYNTHESIS LECT ARTIF, V12, P1
   Chuang YS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2914
   Cossu A, 2021, NEURAL NETWORKS, V143, P607, DOI 10.1016/j.neunet.2021.07.021
   dAutume CD, 2019, ADV NEUR IN, V32, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Furlanello T, 2018, INT C MACHINE LEARNI, V0, P1607
   Heinrich S, 2020, FRONT NEUROROBOTICS, V14, P0, DOI 10.3389/fnbot.2020.00052
   Kanwatchara K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2942
   Kemker R, 2018, 6 INT C LEARNING REP, V0, P0
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Lee SW, 2017, ADV NEUR IN, V30, P0
   Li CM, 2021, APPL INTELL, V51, P185, DOI 10.1007/s10489-020-01786-1
   Li JQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3009
   Li Z, 2017, 43RD EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC 2017), V0, P0, DOI DOI 10.1109/TPAMI.2017.2773081
   Lopez-Paz D, 2017, ADV NEUR IN, V30, P0
   McCann Bryan, 2018, ABS180608730 CORR, V0, P0
   McCloskey M, 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI 10.1016/S0079-7421(08)60536-8
   nostalgebraist, 2020, INT GPT LOG LENS, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reed SE, 2015, 3 INT C LEARN REPR I, V0, P0
   Ring MB, 1997, MACH LEARN, V28, P77, DOI 10.1023/A:1007331723572
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schwarz J, 2018, PR MACH LEARN RES, V80, P0
   Shin H, 2017, ADV NEUR IN, V30, P0
   Sun Fan-Yun, 2019, INT C LEARN REPR, V0, P0
   Sun J, 2020, P COLING, V0, PP3569, DOI 10.18653/V1/2020.COLING-MAIN.318
   van de Ven GM, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17866-2
   Wang Z, 2020, EMNLP, V0, P0
   Zenke F, 2017, PR MACH LEARN RES, V70, P0
   Zhai MY, 2019, IEEE I CONF COMP VIS, V0, PP2759, DOI 10.1109/ICCV.2019.00285
   Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776
   Zhang Xiang, 2015, NEURIPS, V0, P0, DOI DOI 10.5555/2969239.2969312
NR 41
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD APR 15
PY 2023
VL 53
IS 8
BP 9298
EP 9320
DI 10.1007/s10489-022-03678-y
EA AUG 2022
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA F2KE9
UT WOS:000837543300001
DA 2023-11-10
ER

PT J
AU Xia, XY
   Dong, GH
   Li, FL
   Zhu, L
   Ying, XM
AF Xia, Xinyu
   Dong, Guohua
   Li, Fengling
   Zhu, Lei
   Ying, Xiaomin
TI When CLIP meets cross-modal hashing retrieval: A new strong baseline
SO INFORMATION FUSION
LA English
DT Article
DE Cross-modal retrieval; Hashing; CLIP; Modality fusion; Contrastive learning
AB Recent days witness significant progress in various multi-modal tasks made by Contrastive Language-Image Pre-training (CLIP), a multi-modal large-scale model that learns visual representations from natural language supervision. However, the potential effects of CLIP on cross-modal hashing retrieval has not been investigated yet. In this paper, we for the first time explore the effects of CLIP on cross-modal hashing retrieval performance and propose a simple but strong baseline Unsupervised Contrastive Multi-modal Fusion Hashing network (UCMFH). We first extract the off-the-shelf visual and linguistic features from the CLIP model, as the input sources for cross-modal hashing functions. To further mitigate the semantic gap between the image and text features, we design an effective contrastive multi-modal learning module that leverages a multi modal fusion transformer encoder supervising by a contrastive loss, to enhance modality interaction while improving the semantic representation of each modality. Furthermore, we design a contrastive hash learning module to produce high-quality modal-correlated hash codes. Experiments show that significant performance improvement can be made by our simple new unsupervised baseline UCMFH compared with state-of-the-art supervised and unsupervised cross-modal hashing methods. Also, our experiments demonstrate the remarkable performance of CLIP features on cross-modal hashing retrieval task compared to deep visual and linguistic features used in existing state-of-the-art methods. The source codes for our approach is publicly available at: https://github.com/XinyuXia97/UCMFH.
C1 [Xia, Xinyu; Dong, Guohua; Ying, Xiaomin] Beijing Inst Basic Med Sci, Ctr Computat Biol, Beijing 100850, Peoples R China.
   [Xia, Xinyu; Zhu, Lei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.
   [Li, Fengling] Univ Technol Sydney, Fac Engn & Informat Technol, Australian Artificial Intelligence Inst, Ultimo, NSW 2007, Australia.
C3 Academy of Military Medical Sciences - China; Shandong Normal University; University of Technology Sydney
RP Dong, GH; Ying, XM (通讯作者)，Beijing Inst Basic Med Sci, Ctr Computat Biol, Beijing 100850, Peoples R China.
EM xiaxinyu97@gmail.com; dgh1991.learn@gmail.com; fenglingli2023@gmail.com; leizhu0608@gmail.com; yingxmbio@foxmail.com
FU National Key Research and Development Program of China [2022YFF1202400]
CR Chen RN, 2023, ARXIV, V0, P0
   Chua T-S, 2009, P ACM INT C IM VID R, V0, P1
   Cong Bai, 2020, ICMR 20: PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP525, DOI 10.1145/3372278.3390711
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Ding GG, 2014, PROC CVPR IEEE, V0, PP2083, DOI 10.1109/CVPR.2014.267
   EHinton Geoffrey, 2012, ARXIV, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   He Shiyuan, 2022, IEEE T KNOWL DATA EN, V0, P0
   Hu HT, 2020, PROC CVPR IEEE, V0, PP3120, DOI 10.1109/CVPR42600.2020.00319
   Huiskes MJ, 2008, P 1 ACM INT C MULT I, V0, P39
   Jiang QY, 2019, IEEE T IMAGE PROCESS, V28, P3490, DOI 10.1109/TIP.2019.2897944
   Jiang QY, 2017, PROC CVPR IEEE, V0, PP3270, DOI 10.1109/CVPR.2017.348
   Kingma DP, 2014, C TRACK P, V0, P0
   Ko Y, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P1029
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2011, INT JOINT C ART INT, V0, P1
   Li HX, 2023, IEEE T KNOWL DATA EN, V35, P1185, DOI 10.1109/TKDE.2021.3102119
   Li K, 2017, IEEE T PATTERN ANAL, V39, P1825, DOI 10.1109/TPAMI.2016.2610969
   Li XL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1398, DOI 10.1145/3123266.3123355
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FC, 2021, IEEE T CIRC SYST VID, V31, P4485, DOI 10.1109/TCSVT.2020.3048945
   Liu S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP1379, DOI 10.1145/3397271.3401086
   Liu X, 2021, IEEE T PATTERN ANAL, V43, P964, DOI 10.1109/TPAMI.2019.2940446
   Liu XW, 2021, PR MACH LEARN RES, V139, P0
   Liu XW, 2019, IEEE T PATTERN ANAL, V41, P2410, DOI 10.1109/TPAMI.2018.2879108
   Liu XW, 2019, AAAI CONF ARTIF INTE, V0, P4400
   Lu X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP715, DOI 10.1145/3331184.3331217
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Sauer A, 2023, STYLEGAN T UNLOCKING, V0, P0
   Shen HT, 2021, IEEE T KNOWL DATA EN, V33, P3351, DOI 10.1109/TKDE.2020.2970050
   Simonyan K, 2015, ARXIV, V0, P0
   Song Jingkuan, 2013, P ACM SIGMOD INT C M, V0, PP785, DOI 10.1145/2463676.2465274
   Su SP, 2019, IEEE I CONF COMP VIS, V0, PP3027, DOI 10.1109/ICCV.2019.00312
   Tan W, 2022, IEEE T MULTIMEDIA, V0, P0
   Tang C, 2020, AAAI CONF ARTIF INTE, V34, P5924
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, P0, DOI 10.1109/TIP.2016.2564638
   Tian Y, 2021, IEEE T KNOWL DATA EN, V33, P1891, DOI 10.1109/TKDE.2019.2948875
   Tu RC, 2022, IEEE T KNOWL DATA EN, V34, P560, DOI 10.1109/TKDE.2020.2987312
   Wang D, 2018, IEEE T CIRC SYST VID, V28, P2703, DOI 10.1109/TCSVT.2017.2723302
   Wang WW, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102374
   Wang YX, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP871, DOI 10.1145/3394171.3413971
   Wang YX, 2021, IEEE T KNOWL DATA EN, V33, P3507, DOI 10.1109/TKDE.2020.2974825
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2854
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Xie D, 2020, IEEE T IMAGE PROCESS, V29, P3626, DOI 10.1109/TIP.2020.2963957
   Xie L, 2016, AAAI CONF ARTIF INTE, V0, P294
   Xu RQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P982
   Yu WW, 2023, ARXIV, V0, P0
   Yudong Chen, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1921, DOI 10.1145/3474085.3475346
   Zhang PF, 2022, IEEE T MULTIMEDIA, V24, P466, DOI 10.1109/TMM.2021.3053766
   Zhang Z, 2022, IEEE T KNOWL DATA EN, V0, P0
   Zheng F, 2018, IEEE T PATTERN ANAL, V40, P1059, DOI 10.1109/TPAMI.2016.2645565
   Zhou JL, 2014, SIGIR14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P415
   Zhu L, 2020, IEEE T IMAGE PROCESS, V29, P4643, DOI 10.1109/TIP.2020.2974065
   Zhu Lei, 2022, IEEE T KNOWL DATA EN, V0, P0
NR 56
TC 0
Z9 0
U1 14
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD DEC 15
PY 2023
VL 100
IS 
BP 
EP 
DI 10.1016/j.inffus.2023.101968
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA R2FN5
UT WOS:001062553800001
DA 2023-11-10
ER

PT J
AU Pandey, AK
   Roy, SS
AF Pandey, Abhishek Kumar
   Roy, Sanjiban Sekhar
TI Natural Language Generation Using Sequential Models: A Survey
SO NEURAL PROCESSING LETTERS
LA English
DT Article; Early Access
DE Natural language processing; Long term short-term memory; Natural language generation; Recurrent neural network; Sequential generative model; Story generation
ID text generation
AB Natural Language Generation (NLG) is one of the most critical yet challenging tasks in all Natural Language Processing applications. It is a process to automate text generation so that humans can understand its meaning. A handful of research articles published in the literature have described how NLG can produce understandable texts in various languages. The use of sequence-to-sequence modeling powered by deep learning techniques such as Long Term Short Term Memory, Recurrent Neural Networks, and Gated Recurrent Units has received much popularity as text generators. This survey provides a comprehensive overview of text generations and their related techniques, such as statistical, traditional, and neural network-based techniques. Generating text using the sequence-to-sequence model is not a simple task as it needs to handle continuous data, such as images, and discrete information, such as text. Therefore, in this study, we have identified some crucial areas for further research on text generation, such as incorporating a large text dataset, identifying and resolving grammatical errors, and generating extensive sentences or paragraphs. This work has also presented a detailed overview of the activation functions used in deep learning-based models and the evaluation metrics used for text generation.
C1 [Pandey, Abhishek Kumar; Roy, Sanjiban Sekhar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Roy, SS (通讯作者)，Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Vellore, India.
EM abhishek.pandey2020@vitstudent.ac.in; s.roy@vit.ac.in
CR Angeli G, 2010, P 2010 C EMPIRICAL M, V0, P502
   [Anonymous], 1981, HANSEL AND GRETEL, V0, P0
   Ayana, 2020, IEEE-ACM T AUDIO SPE, V28, P2572, DOI 10.1109/TASLP.2020.3009487
   Ayana, 2018, IEEE-ACM T AUDIO SPE, V26, P2319, DOI 10.1109/TASLP.2018.2842432
   Bao JW, 2019, IEEE-ACM T AUDIO SPE, V27, P311, DOI 10.1109/TASLP.2018.2878381
   Biswas R, 2020, IJST-T ELECTR ENG, V44, P505, DOI 10.1007/s40998-019-00213-7
   Bouchard G, 2007, NIPS 2007 WORKSH APP, V0, P0
   Bourane S, 2015, SCIENCE, V350, P550, DOI 10.1126/science.aac8653
   Cao J, 2020, IEEE ACCESS, V8, P46206, DOI 10.1109/ACCESS.2020.2979115
   Chakraborty S, 2020, 2020 INT C COMPUTER, V0, P0, DOI DOI 10.1109/ICCSEA49143.2020.9132839
   Colby KM, 1976, ARTIFICIAL PARANOIA, V7, P0
   Dethlefs N, 2021, NEUROCOMPUTING, V433, P300, DOI 10.1016/j.neucom.2020.12.083
   Dharma EM, 2022, J THEOR APPL INF TEC, V100, P349
   Elahi GMME, 2022, PATTERN RECOGN, V122, P0, DOI 10.1016/j.patcog.2021.108273
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gaur M, 2022, ANAL NATURAL LANGUAG, V0, P233
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hoogi A, 2020, MAMMOGRAPHY REPORTS, V24, P2711
   Hossain SA, 2019, 2019 10 INT C COMPUT, V0, PP1, DOI 10.1109/ICCCNT45670.2019.8944784
   Iglesias P, 2023, ELECTRONICS-SWITZ, V12, P0, DOI 10.3390/electronics12030473
   Islam Md Sanzidul, 2019, PROCEDIA COMPUTER SCIENCE, V152, P51, DOI 10.1016/j.procs.2019.05.026
   Jagfeld Glorianna, 2018, INLG 2018 11 INT NAT, V0, PP221, DOI 10.18653/V1/W18-6529
   Jin D, 2022, COMPUT LINGUIST, V48, P155, DOI 10.1162/coli_a_00426
   Kannan Shradha, 2022, EMERGING RESEARCH IN COMPUTING, V0, P0
   Kim Y, 2020, ACM T INFORM SYST, V38, P0, DOI 10.1145/3418052
   Kunhi LM, 2022, INVENT COMMUN COMPUT, V0, P63
   Langkilde I, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P0
   Li Jiwei, 2016, EMNLP, V0, P0
   Li MY, 2022, INFORM SOFTWARE TECH, V143, P0, DOI 10.1016/j.infsof.2021.106770
   Li Z, 2022, 2021 INT C BIG DAT A, V0, P367
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin C-Y, 2004, NTCIR WORK, V0, P1
   Lin JY, 2022, EDUC TECHNOL SOC, V25, P205
   Liu TY, 2018, AAAI CONF ARTIF INTE, V0, P4881
   Liu YX, 2022, INFORM SYST, V103, P0, DOI 10.1016/j.is.2021.101865
   Mann WC, 1987, NATURAL LANGUAGE GENERATION: NEW RESULTS IN ARTIFICIAL INTELLIGENCE, V0, P85
   McShane M, 2022, ADV COGN SYST, V0, P1
   Meister C, 2022, ARXIV, V0, P0
   Minzheong Song, 2021, THE INTERNATIONAL JOURNAL OF ADVANCED SMART CONVERGENCE, V10, P72, DOI 10.7236/IJASC.2021.10.4.72
   Nandanwar AK, 2021, SYMMETRY-BASEL, V13, P0, DOI 10.3390/sym13101772
   PALOMBELLA VJ, 1994, CELL, V78, P773, DOI 10.1016/S0092-8674(94)90482-0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pawade Dipti, 2018, INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, V10, P44, DOI 10.5815/ijitcs.2018.06.05
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Qader R, 2018, P 11 INT C NATURAL L, V0, PP254, DOI 10.18653/V1/W18-6532
   Reiter E, 1997, NATURAL LANGUAGE ENGINEERING, V3, P57, DOI 10.1017/S1351324997001502
   Ren YP, 2021, KNOWL-BASED SYST, V227, P0, DOI 10.1016/j.knosys.2021.107093
   Roy S, 2018, PREDICTION CUSTOMER, V0, P0
   Roy SS, 2016, INT J ENG RES AFR, V22, P152, DOI 10.4028/www.scientific.net/JERA.22.152
   Roy SS, 2016, INT J COMPUT SYST EN, V2, P139, DOI 10.1504/IJCSYSE.2016.079000
   Ruder S, 2019, THESIS NATL U IRELAN, V0, P0
   Santhanam S, 2020, ARXIV, V0, P0
   Schmitt M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7117
   Sha L, 2018, AAAI CONF ARTIF INTE, V0, P5414
   Shi J, 2022, CAN IDENTIFIER SPLIT, V0, P0
   Singh C, 2017, ALICE WONDERLAND GUT, V0, P0
   Sun YQ, 2022, INT J INTELL SYST, V37, P2969, DOI 10.1002/int.22821
   Wang HC, 2020, APPL SOFT COMPUT, V97, P0, DOI 10.1016/j.asoc.2020.106767
   Wang MQ, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), V0, PP223, DOI 10.1109/APCCAS.2018.8605654
   Wei MX, 2019, IEEE ACCESS, V7, P61008, DOI 10.1109/ACCESS.2019.2904337
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xiang LY, 2020, MATHEMATICS-BASEL, V8, P0, DOI 10.3390/math8091558
   Yadav Arun Kumar, 2022, INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY, V0, PP2407, DOI 10.1007/s41870-022-00863-7
   Yadav D, 2022, COMPUT INTEL NEUROSC, V2022, P0, DOI 10.1155/2022/3411881
   Yao T, 2021, LECT NOTES COMPUT SC, V13003, P173, DOI 10.1007/978-3-030-88210-5_16
   Yermakov R, 2021, BIOMEDICAL DATA TO T, V0, P364
   Yin XY, 2003, ANN BOT-LONDON, V91, P361, DOI 10.1093/aob/mcg029
   Zhang X, 2014, P 2014 C EMP METH NA, V0, PP670, DOI 10.3115/V1/D14-1074
   Zhao MY, 2021, LECT NOTES COMPUT SC, V12966, P437, DOI 10.1007/978-3-030-87589-3_45
   Zheng QH, 2018, IEEE ACCESS, V6, P15844, DOI 10.1109/ACCESS.2018.2810849
   Zhu J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5459
NR 73
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s11063-023-11281-6
EA MAY 2023
PG 34
WC Computer Science, Artificial Intelligence
SC Computer Science
GA G0RQ9
UT WOS:000986336700002
DA 2023-11-10
ER

PT J
AU Gezmu, AM
   Nünberger, A
AF Gezmu, Andargachew Mekonnen
   Nuenberger, Andreas
TI Morpheme-Based Neural Machine Translation Models for Low-Resource Fusion Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Neural machine translation; morpheme-based word segmentation; fusion languages; low-resource languages; transformers
AB Neural approaches, which are currently state-of-the-art in many areas, have contributed significantly to the exciting advancements in machine translation. However, Neural Machine Translation (NMT) requires a substantial quantity and good quality parallel training data to train the best model. A large amount of training data, in turn, increases the underlying vocabulary exponentially. Therefore, several proposed methods have been devised for relatively limited vocabulary due to constraints of computing resources such as systemmemory. Encoding words as sequences of subword units for so-called open-vocabulary translation is an effective strategy for solving this problem. However, the conventional methods for splitting words into subwords focus on statistics-based approaches that mainly conform to agglutinative languages. In these languages, the morphemes have relatively clean boundaries. Thesemethods still need to be thoroughly investigated for their applicability to fusion languages, which is the main focus of this article. Phonological and orthographic processes alter the borders of constituent morphemes of aword in fusion languages. Therefore, itmakes it difficult to distinguish the actual morphemes that carry syntactic or semantic information from the word's surface form, the form of the word as it appears in the text. We, thus, resorted to a word segmentation method that segments words by restoring the altered morphemes. We also compared conventional and morpheme-based NMT subword models. We could prove that morpheme-basedmodels outperform conventional subword models on a benchmark dataset.
C1 [Gezmu, Andargachew Mekonnen; Nuenberger, Andreas] Otto von Guericke Univ, Univ Pl 2, D-39106 Magdeburg, Saxony Anhalt, Germany.
C3 Otto von Guericke University
RP Gezmu, AM (通讯作者)，Otto von Guericke Univ, Univ Pl 2, D-39106 Magdeburg, Saxony Anhalt, Germany.
EM andargachew.gezmu@ovgu.de; andreas.nuernberger@ovgu.de
CR Allison B, 2006, LECT NOTES ARTIF INT, V4188, P327
   Araabi Ali, 2020, P 28 INT C COMP LING, V0, PP3429, DOI 10.18653/v1/2020.coling-main.304
   Ataman Duygu, 2017, PRAGUE BULLETIN OF MATHEMATICAL LINGUISTICS, V0, PP331, DOI 10.1515/pralin-2017-0031
   Bahdanau D, 2016, ARXIV, V0, P0
   Batsuren K, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P840
   Beesley Kenneth R, 2003, FINITE STATE MORPHOL, V0, P0
   Bentivogli Luisa, 2016, P 2016 C EMP METH NA, V0, PP257, DOI 10.18653/v1/d16-1025
   Bentz C, 2016, ARXIV, V0, P0
   Bentz C, 2017, ENTROPY-SWITZ, V19, P0, DOI 10.3390/e19060275
   Bostrom Kaj, 2020, ARXIV200403720, V0, P0
   Callison-Burch Chris, 2006, P 11 C EUR CHAP ASS, V0, P0
   Castilho Sheila, 2017, PRAGUE BULLETIN OF MATHEMATICAL LINGUISTICS, V0, PP109, DOI 10.1515/pralin-2017-0013
   Cherry C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4295
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Chollet Francois, 2018, P 13 C ASS MACHINE T, V1, P193
   Costa-jussà MR, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P357
   Cotterell Ryan, 2016, P 2016 C EMP METH NA, V0, PP2325, DOI 10.18653/v1/d16-1256
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V4, P3:1, DOI 10.1145/1217098.1217101
   CROSBIE RE, 1993, EUROSIM 92 - SIMULATION CONGRESS, V0, P1
   Dabre Raj, 2018, P 32 PAC AS C LANG I, V0, P0
   Denkowski Michael J, 2017, P 1 WORKSH NEUR MACH, V0, PP18, DOI 10.18653/v1/w17-3203
   Dhar Prajit, 2020, P 5 C MACH TRANSL WM, V0, P126
   Ding Shuoyang, 2019, P MACHINE TRANSLATIO, V0, P204
   Dorr BJ, 1999, ADV COMPUT, V49, P1, DOI 10.1016/S0065-2458(08)60282-X
   Dror Rotem, 2020, STAT SIGNIFICANCE TE, V0, P0, DOI DOI 10.2200/S00994ED1V01Y202002HLT045
   Eskander R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P7112
   Fabri Ray, 2014, NATURAL LANGUAGE PRO, V0, PP3, DOI 10.1007/978-3-642-45358-8_1
   Freitag Markus, 2021, P 6 C MACHINE TRANSL, V0, P733
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI 10.5555/177910.177914
   Gasser Michael, 2011, C HUM LANG TECHN DEV, V0, P0
   Gezmu AM, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 1, V0, PP526, DOI 10.5220/0010383905260532
   Gezmu AM, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P6644
   Gezmu Andargachew Mekonnen, 2018, P 1 WORKSH LING RES, V0, P65
   Gowda Thamme, 2020, FINDINGS ASS COMPUTA, VEMNLP 2020, P3955, DOI 10.18653/v1/2020.findingsemnlp.352
   Goyal V, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, V0, P162
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI 10.18653/v1/n18
   Gutierrez-Vasques X, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P3454
   Haddow B, 2022, COMPUT LINGUIST, V48, P673, DOI 10.1162/coli_a_00446
   Haspelmath Martin, 2007, LINGUIST TYPOL, V11, P119, DOI 10.1515/LINGTY.2007.011
   Huck Matthias, 2017, P 2 C MACH TRANSL WM, V0, PP56, DOI 10.18653/V1/W17-4706
   Jean S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1
   Kingma DP, 2014, C TRACK P, V0, P0
   Kocmi Tom, 2021, P 6 C MACHINE TRANSL, V0, P478
   Koehn P, 2017, WMT, V0, P28
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Koehn Philipp, 2004, P 2004 C EMPIRICAL M, V0, P388
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Lankford Seamus, 2021, P 18 BIENN MACH TRAN, V0, P48
   Lee Jason, 2017, T ASSOC COMPUT LING, V5, P365, DOI 10.1162/tacl_a_00067
   Loper E, 2002, ETMTNLP 02 P ACL 02, V0, PP63, DOI 10.3115/1118108.1118117
   Machácek D, 2018, LECT NOTES ARTIF INT, V11107, P277, DOI 10.1007/978-3-030-00794-2_30
   Marie Benjamin, 2021, P 59 ANN M ASS COMP, V1, P7297, DOI 10.18653
   Martin JH, 2009, SPEECH LANGUAGE PROC, V0, P0
   Mielke Sabrina J, 2021, ARXIV, V0, P0
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Ortega JE, 2020, MACH TRANSL, V34, P325, DOI 10.1007/s10590-020-09255-9
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Popel Martin, 2018, PRAGUE BULLETIN OF MATHEMATICAL LINGUISTICS, V0, PP43, DOI 10.2478/pralin-2018-0002
   Post Matt, 2018, P 3 C MACH TRANSL RE, V0, PP186, DOI 10.18653/v1/W18-6319
   Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2685
   Reiter E, 2018, COMPUT LINGUIST, V44, P393, DOI 10.1162/COLI.a.00322
   Rissanen Jorma, 1998, WORLD SCI SERIES COM, V15, P0, DOI 10.1142/0822
   Salesky E, 2020, MACH TRANSL, V34, P41, DOI 10.1007/s10590-019-09243-8
   Sälevä J, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P164
   Samuelson PA, 1936, REV ECON STUD, V4, P155
   Sánchez-Cartagena VM, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P356
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Sennrich R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P211
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Smith PS, 2014, PALGRAVE STUD PRISON, V0, P21
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Toral A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P386
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wu YH, 2016, ARXIV, V0, P0
   Xu Jingjing, 2021, P 59 ANN M ASS COMP, V1, P7361
   Zuters Janis, 2018, COMMUNICATIONS COMPU, V838, P289, DOI 10.1007/978-3-319-97571-9_23
NR 80
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2023
VL 22
IS 9
BP 
EP 
DI 10.1145/3610773
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA T7EN7
UT WOS:001079577300011
DA 2023-11-10
ER

PT J
AU Han, X
   Wang, YT
   Feng, JL
   Deng, C
   Chen, ZH
   Huang, YA
   Su, H
   Hu, L
   Hu, PW
AF Han, Xue
   Wang, Yi-Tong
   Feng, Jun-Lan
   Deng, Chao
   Chen, Zhan-Heng
   Huang, Yu-An
   Su, Hui
   Hu, Lun
   Hu, Peng-Wei
TI A survey of transformer-based multimodal pre-trained modals
SO NEUROCOMPUTING
LA English
DT Article
DE Transformer; Pre -trained model; Multimodal; Documet Layout
ID neural-networks; language; model
AB With the broad industrialization of Artificial Intelligence(AI), we observe a large fraction of real-world AI applications are multimodal in nature in terms of relevant data and ways of interaction. Pre-trained big models have been proven as the most effective framework for joint modeling of multi-modality data. This paper provides a thorough account of the opportunities and challenges of Transformer-based multimodal pre-trained model (PTM) in various domains. We begin by reviewing the representative tasks of multi -modal AI applications, ranging from vision-text and audio-text fusion to more complex tasks such as doc-ument layout understanding. We particularly address the new multi-modal research domain of document layout understanding. We further analyze and compare the state-of-the-art Transformer -based multimodal PTMs from multiple aspects, including downstream applications, datasets, input fea-ture embedding, and model architectures. In conclusion, we summarize the key challenges of this field and suggest several future research directions. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Han, Xue; Wang, Yi-Tong; Feng, Jun-Lan; Deng, Chao; Su, Hui] China Mobile Res Inst, JIUTIAN Team, Beijing, Peoples R China.
   [Wang, Yi-Tong] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
   [Chen, Zhan-Heng; Huang, Yu-An] Shenzhen Univ, Shenzhen, Peoples R China.
   [Hu, Peng-Wei] Tencent Inc, Pattern Recognit Ctr, Wechat AI, Shenzhen, Peoples R China.
   [Hu, Lun] Chinese Acad Sci, Xinjiang Tech Inst Phys & Chem, Beijing, Peoples R China.
   [Hu, Peng-Wei] Merck China Innovat Hub, Shanghai, Peoples R China.
C3 China Mobile; Beijing University of Posts & Telecommunications; Shenzhen University; Tencent; Chinese Academy of Sciences; Xinjiang Technical Institute of Physics & Chemistry, CAS
RP Hu, PW (通讯作者)，Merck China Innovat Hub, Shanghai, Peoples R China.
EM hanxueai@chinamobile.com; hupengwei@hotmail.com
CR Akbari H, 2021, ARXIV, V0, P0
   Alberti C, 2019, FUSION DETECTED OBJE, V0, P0
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2018, PROC CVPR IEEE, V0, PP3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Brown TB, 2020, ARXIV, V0, P0
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bayoudh K, 2022, VISUAL COMPUT, V38, P2939, DOI 10.1007/s00371-021-02166-7
   Belinkov Y, 2018, ARXIV, V0, P0
   Bengio Y, 2013, ARXIV, V0, P0
   Calhoun S, 2010, LANG RESOUR EVAL, V44, P387, DOI 10.1007/s10579-010-9120-1
   Carreira J, 2017, PROC CVPR IEEE, V0, PP4724, DOI 10.1109/CVPR.2017.502
   Chen SX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P6283
   Chenhao Lin, 2020, ICMR 20: PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP407, DOI 10.1145/3372278.3391932
   Child R, 2019, ARXIV, V0, P0
   Cho JM, 2020, ARXIV, V0, P0
   Chuang YS, 2020, ARXIV, V0, P0
   Dai ZH, 2020, ARXIV, V0, P0
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Das A, 2017, PROC CVPR IEEE, V0, PP1080, DOI 10.1109/CVPR.2017.121
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Denisov P, 2020, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Ding L, 2018, PROC CVPR IEEE, V0, PP6508, DOI 10.1109/CVPR.2018.00681
   Ding M, 2021, ARXIV, V0, P0
   Du JX, 2007, NEUROCOMPUTING, V70, P896, DOI 10.1016/j.neucom.2006.10.026
   Du JX, 2006, NEUROCOMPUTING, V70, P592, DOI 10.1016/j.neucom.2006.05.003
   Tran D, 2015, IEEE I CONF COMP VIS, V0, PP4489, DOI 10.1109/ICCV.2015.510
   Fang ZY, 2020, ARXIV, V0, P0
   Fedus W, 2022, ARXIV, V0, P0
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, V0, PP6201, DOI 10.1109/ICCV.2019.00630
   Futami H, 2020, ARXIV, V0, P0
   Gabeur Valentin, 2020, ECCV, V0, PP2, DOI 10.1007/978-3-030-58548-8_13
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI 10.5555/177910.177914
   Gao JY, 2017, IEEE I CONF COMP VIS, V0, PP5277, DOI 10.1109/ICCV.2017.563
   Gaonkar A, 2021, 2021 INT C INT TECHN, V0, P1
   Garncarek L, 2020, ARXIV, V0, P0
   Ging S, 2020, ARXIV, V0, P0
   Goel V, 2005, P ICASSP 05 IEEE INT, V1, P0
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Gralinski F, 2020, ARXIV, V0, P0
   Gu CH, 2018, PROC CVPR IEEE, V0, PP6047, DOI 10.1109/CVPR.2018.00633
   Guo WZ, 2019, IEEE ACCESS, V7, P63373, DOI 10.1109/ACCESS.2019.2916887
   Guu Kelvin, 2020, P MACHINE LEARNING R, V119, P3929
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Han TD, 2019, IEEE INT CONF COMP V, V0, PP1483, DOI 10.1109/ICCVW.2019.00186
   Han X, 2020, 2020 IEEE 13TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2020), V0, PP428, DOI 10.1109/ICWS49710.2020.00063
   Han X, 2020, P IEEE I C SERV COMP, V0, PP170, DOI 10.1109/SCC49832.2020.00030
   Han X, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (IEEE ICWS 2019), V0, PP383, DOI 10.1109/ICWS.2019.00068
   Hao Weituo, 2020, P IEEE CVF C COMP VI, V0, PP13137, DOI 10.1109/CVPR42600.2020.01315
   Haodong Duan, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12360), V0, PP670, DOI 10.1007/978-3-030-58555-6_40
   Harley AW, 2015, PROC INT CONF DOC, V0, PP991, DOI 10.1109/ICDAR.2015.7333910
   Li LH, 2019, ARXIV, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hendricks LA, 2017, IEEE I CONF COMP VIS, V0, PP5804, DOI 10.1109/ICCV.2017.618
   Hinton G, 2015, ARXIV, V0, P0
   Hong YC, 2021, PROC CVPR IEEE, V0, PP1643, DOI 10.1109/CVPR46437.2021.00169
   Hu PW, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5252
   Hu PW, 2020, IEEE ACM T COMPUT BI, V17, P1516, DOI 10.1109/TCBB.2019.2957094
   Huang DS, 2008, IEEE T NEURAL NETWOR, V19, P2099, DOI 10.1109/TNN.2008.2004370
   Huang DS, 1999, INT J PATTERN RECOGN, V13, P1083, DOI 10.1142/S0218001499000604
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Huang YH, 2020, INT CONF ACOUST SPEE, V0, PP7984, DOI 10.1109/ICASSP40776.2020.9053281
   Huang ZC, 2020, ARXIV, V0, P0
   Huang ZQ, 2021, AAAI CONF ARTIF INTE, V35, P13098
   Hudson DA, 2019, PROC CVPR IEEE, V0, PP6693, DOI 10.1109/CVPR.2019.00686
   Huo Y, 2021, ARXIV, V0, P0
   Jang E, 2017, ARXIV, V0, P0
   Jang Y, 2017, PROC CVPR IEEE, V0, PP1359, DOI 10.1109/CVPR.2017.149
   Jaume G, 2019, PROC INT CONF DOC, V0, PP1, DOI 10.1109/ICDARW.2019.10029
   Jiang YD, 2021, ARXIV, V0, P0
   Jiao XQ, 2020, ARXIV, V0, P0
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Jie Lei, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12366), V0, PP447, DOI 10.1007/978-3-030-58589-1_27
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kay W, 2017, ARXIV, V0, P0
   Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, V0, PP787, DOI 10.3115/V1/D14-1086
   Khan S, 2021, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2101.01169
   Kim S, 2017, INT CONF ACOUST SPEE, V0, PP4835, DOI 10.1109/ICASSP.2017.7953075
   Krishna R, 2017, IEEE I CONF COMP VIS, V0, PP706, DOI 10.1109/ICCV.2017.83
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Kuehne H, 2011, IEEE I CONF COMP VIS, V0, PP2556, DOI 10.1109/ICCV.2011.6126543
   Kuehne H, 2014, PROC CVPR IEEE, V0, PP780, DOI 10.1109/CVPR.2014.105
   Lee CH, 2018, IEEE W SP LANG TECH, V0, PP949, DOI 10.1109/SLT.2018.8639505
   Lee Young-Koo, 2020, P 3 INT C SMART CITY, V0, P1451
   Lei C, 2021, ARXIV, V0, P0
   Lei J, 2018, TVQA LOCALIZED COMPO, V0, P0
   Lei J, 2020, ARXIV, V0, P0
   Lei J, 2020, ARXIV, V0, P0
   Lei J, 2021, PROC CVPR IEEE, V0, PP7327, DOI 10.1109/CVPR46437.2021.00725
   Lewis D, 2006, PROCEEDINGS OF THE TWENTY-NINTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP665, DOI 10.1145/1148170.1148307
   Lewis M, 2019, ARXIV, V0, P0
   Li B, 2008, PATTERN RECOGN, V41, P3813, DOI 10.1016/j.patcog.2008.05.027
   Li B, 2008, PATTERN RECOGN, V41, P3287, DOI 10.1016/j.patcog.2008.05.014
   Li C, 2021, ARXIV, V0, P0
   Li CH, 2018, ARXIV, V0, P0
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li JY, 2017, ARXIV, V0, P0
   Li LJ, 2020, ARXIV, V0, P0
   Li TH, 2021, ARXIV, V0, P0
   Li W, 2022, ARXIV, V0, P0
   Li X, 2020, ARXIV, V0, P0
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Liang XP, 2018, IET IMAGE PROCESS, V12, P1079, DOI 10.1049/iet-ipr.2017.1061
   Liang XP, 2018, IEEE ACM T COMPUT BI, V15, P1016, DOI 10.1109/TCBB.2017.2690427
   Lin JY, 2021, ARXIV, V0, P0
   Lin TY, 2021, ARXIV, V0, P0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J, 2020, PROC CVPR IEEE, V0, PP2356, DOI 10.1109/CVPR42600.2020.00243
   Liu L, 2019, IEEE J SEL AREA COMM, V37, P1584, DOI 10.1109/JSAC.2019.2916280
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Lu J, 2019, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1908.02265
   Lugosch L, 2019, INTERSPEECH, V0, PP814, DOI 10.21437/Interspeech.2019-2396
   Luo HS, 2020, ARXIV, V0, P0
   Luo X, 2021, IEEE T SYST MAN CY-S, V51, P3522, DOI 10.1109/TSMC.2019.2930525
   Maekawa K, 2003, SSPR, V0, P0
   Maekawa K, 2014, LANG RESOUR EVAL, V48, P345, DOI 10.1007/s10579-013-9261-0
   Maharaj T, 2017, PROC CVPR IEEE, V0, PP7359, DOI 10.1109/CVPR.2017.778
   Mathew M, 2021, IEEE WINT CONF APPL, V0, PP2199, DOI 10.1109/WACV48630.2021.00225
   Mehta S, 2021, ARXIV, V0, P0
   Miech Antoine, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9876, DOI 10.1109/CVPR42600.2020.00990
   Miech A, 2021, PROC CVPR IEEE, V0, PP9821, DOI 10.1109/CVPR46437.2021.00970
   Miech A, 2019, IEEE I CONF COMP VIS, V0, PP2630, DOI 10.1109/ICCV.2019.00272
   Murahari Vishvak, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12363), V0, PP336, DOI 10.1007/978-3-030-58523-5_20
   Nguyen K, 2019, ARXIV, V0, P0
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Park S, 2019, WORKSH DOC INT NEURI, V0, P0
   Peng H, 2021, BMC GASTROENTEROL, V21, P1
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Powalski R, 2021, ARXIV, V0, P0
   Price P, 1990, SPEECH NATURAL LANGU, V0, PP91, DOI 10.3115/116580.116612
   Qi D, 2020, ARXIV, V0, P0
   Qian R, 2021, PROC CVPR IEEE, V0, PP6960, DOI 10.1109/CVPR46437.2021.00689
   Qian Y, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7458, DOI 10.1109/ICASSP39728.2021.9414900
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radfar M, 2020, ARXIV, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Raina V, 2021, ARXIV, V0, P0
   Rajpurkar P, 2016, ARXIV, V0, P0
   Ramesh A, 2021, ARXIV, V0, P0
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rohrbach A, 2015, PROC CVPR IEEE, V0, PP3202, DOI 10.1109/CVPR.2015.7298940
   Ruan L, 2021, ARXIV, V0, P0
   Sharma B, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7498, DOI 10.1109/ICASSP39728.2021.9413388
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Singh A, 2022, P IEEECVF C COMPUTER, V0, P15638
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Soomro K, 2012, ARXIV, V0, P0
   Stein S, 2013, UBICOMP13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, V0, PP729, DOI 10.1145/2493432.2493482
   Su WJ, 2020, ARXIV, V0, P0
   Su YT, 2019, IEEE WIREL COMMUN, V26, P55, DOI 10.1109/MWC.2019.1800299
   Suhr A, 2019, ARXIV, V0, P0
   Sui D, 2021, P 59 ANN M ASS COMP, V0, P0
   Sun C, 2019, ARXIV, V0, P0
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Tan H, 2019, ARXIV, V0, P0
   Tang YS, 2019, PROC CVPR IEEE, V0, PP1207, DOI 10.1109/CVPR.2019.00130
   Tang ZN, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2415
   Thomason Jesse, 2020, C ROB LEARN, V0, P394
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang L, 2016, PROC CVPR IEEE, V0, PP5005, DOI 10.1109/CVPR.2016.541
   Wang YF, 2020, I S BIOMED IMAGING, V0, PP1933, DOI 10.1109/ISBI45749.2020.9098396
   Wang Y, 2020, ARXIV, V0, P0
   Warden P, 2018, ARXIV, V0, P0
   Wu D, 2022, IEEE T NEUR NET LEAR, V33, P5775, DOI 10.1109/TNNLS.2021.3071392
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Wu YH, 2016, ARXIV, V0, P0
   Wu ZH, 2020, ARXIV, V0, P0
   Xia QL, 2020, ARXIV, V0, P0
   Xie N, 2018, ARXIV, V0, P0
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Xin L, 2021, IEEE T SYST MAN CY-S, V51, P4612, DOI 10.1109/TSMC.2019.2931468
   Xu DJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1645, DOI 10.1145/3123266.3123427
   Xu H, 2021, ARXIV, V0, P0
   Xu J, 2016, PROC CVPR IEEE, V0, PP5288, DOI 10.1109/CVPR.2016.571
   Xu Y, 2022, ARXIV, V0, P0
   Xu YH, 2021, ARXIV, V0, P0
   Xu YH, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1192, DOI 10.1145/3394486.3403172
   Yang CY, 2020, ARXIV, V0, P0
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   You C, 2021, ARXIV, V0, P0
   Yu F, 2021, AAAI CONF ARTIF INTE, V35, P3208
   Yu TZ, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3995
   Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29
   Yu-An C, 2021, ARXIV, V0, P0
   Yuankai Qi, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9979, DOI 10.1109/CVPR42600.2020.01000
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zellers R, 2019, PROC CVPR IEEE, V0, PP6713, DOI 10.1109/CVPR.2019.00688
   Zhang C, 2020, IEEE J-STSP, V14, P478, DOI 10.1109/JSTSP.2020.2987728
   Zhang MJ, 2020, ARXIV, V0, P0
   Zhang SY, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP4373, DOI 10.1145/3394171.3413518
   Zhang SY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P1513
   Zhang TY, 2020, ARXIV, V0, P0
   Zheng Huang, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1516, DOI 10.1109/ICDAR.2019.00244
   Zhou L, 2018, 32 AAAI C ARTIFICIAL, V0, P0
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhou LW, 2018, PROC CVPR IEEE, V0, PP8739, DOI 10.1109/CVPR.2018.00911
   Zhu Linchao, 2020, P IEEE CVF C COMP VI, V0, PP8746, DOI 10.1109/CVPR42600.2020.00877
   Zhu YK, 2016, PROC CVPR IEEE, V0, PP4995, DOI 10.1109/CVPR.2016.540
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
   Zhuge MC, 2021, PROC CVPR IEEE, V0, PP12642, DOI 10.1109/CVPR46437.2021.01246
   Zhukov D, 2019, PROC CVPR IEEE, V0, PP3532, DOI 10.1109/CVPR.2019.00365
NR 208
TC 3
Z9 3
U1 11
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 1
PY 2023
VL 515
IS 
BP 89
EP 106
DI 10.1016/j.neucom.2022.09.136
EA OCT 2022
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5W0KU
UT WOS:000877611700004
DA 2023-11-10
ER

PT J
AU Maillot, P
   Corby, O
   Faron, C
   Gandon, F
   Michel, F
AF Maillot, Pierre
   Corby, Olivier
   Faron, Catherine
   Gandon, Fabien
   Michel, Franck
TI IndeGx: A model and a framework for indexing RDF knowledge graphs with SPARQL-based test suits
SO JOURNAL OF WEB SEMANTICS
LA English
DT Article
DE Semantic index; Metadata extraction; Dataset description; Endpoint description; Knowledge graph
ID end-points
AB In recent years, a large number of RDF datasets have been built and published on the Web in fields as diverse as linguistics or life sciences, as well as general datasets such as DBpedia or Wikidata. The joint exploitation of these datasets requires specific knowledge about their content, access points, and commonalities. However, not all datasets contain a self-description, and not all access points can handle the complex queries used to generate such a description.In this article, we provide a standard-based approach to generate the description of a dataset. The generated descriptions as well as the process of their computation are expressed using standard vocabularies and languages. We implemented our approach into a framework, called IndeGx, where each indexing feature and its computation is collaboratively and declaratively defined in a GitHub repository. We have experimented IndeGx on a set of 339 RDF datasets with endpoints listed in public catalogs, over 8 months. The results show that we can collect, as much as possible, important characteristics of the datasets depending on their availability and capacities. The resulting index captures the commonalities, variety and disparity in the offered content and services and it provides an important support to any application designed to query RDF datasets.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Maillot, Pierre; Corby, Olivier; Faron, Catherine; Gandon, Fabien; Michel, Franck] Univ Cote Azur, Inria, CNRS, I3S, Nice, France.
C3 Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Cote d'Azur; Inria
RP Maillot, P (通讯作者)，Univ Cote Azur, Inria, CNRS, I3S, Nice, France.
EM pierre.maillot@inria.fr; olivier.corby@inria.fr; catherine.faron@inria.fr; fabien.gandon@inria.fr; franck.michel@inria.fr
FU ANR DeKaloG (Decentralized Knowledge Graphs) project [ANR-19-CE23-0014]; ANR (Data to Knowledge in Agriculture and Biodiversity) project [D2KAB, ANR-18-CE23-0017]; 3IA Cpte d'Azur [ANR-19-P3IA-0002]
CR Beek W, 2014, LECT NOTES COMPUT SC, V8796, P213, DOI 10.1007/978-3-319-11964-9_14
   Ben Ellefi M, 2018, SEMANT WEB, V9, P677, DOI 10.3233/SW-180294
   Buffa M, 2021, LECT NOTES COMPUT SC, V12731, P515, DOI 10.1007/978-3-030-77385-4_31
   Catania B, 2019, SAC 19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, V0, PP2251, DOI 10.1145/3297280.3297503
   Corby O, 2010, PROCEEDINGS 2010 IEEE/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE-INTELLIGENT AGENT TECHNOLOGY (WI-IAT), V0, PP338, DOI 10.1109/WI-IAT.2010.144
   Corby O, 2021, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES (WEBIST), V0, PP65, DOI 10.5220/0010660300003058
   Corby O, 2017, LECT NOTES COMPUT SC, V10587, P208, DOI 10.1007/978-3-319-68288-4_13
   Corby Olivier, 2021, INT C WEB INFORM SYS, V0, P0
   Cyganiak Richard, 2011, DESCRIBING LINKED DA, V0, P0
   Debattista J, 2016, ACM J DATA INF QUAL, V8, P0, DOI 10.1145/2992786
   Ell B, 2011, LECT NOTES COMPUT SC, V7031, P162, DOI 10.1007/978-3-642-25073-6_11
   Ferré S, 2017, SEMANT WEB, V8, P405, DOI 10.3233/SW-150208
   Gazzotti Raphael, 2021, WEBIST 2021 17 INT C, V0, P0
   Harth A, 2010, WWW, V0, PP411, DOI 10.1145/1772690.1772733
   Hasnain A, 2017, J BIOMED SEMANT, V8, P0, DOI 10.1186/s13326-017-0118-0
   Hasnain A, 2016, INT J SEMANT WEB INF, V12, P134, DOI 10.4018/IJSWIS.2016070105
   Holagh SR, 2019, SN APPL SCI, V1, P0, DOI 10.1007/s42452-019-1598-6
   Hose K, 2006, INT DATABASE ENG APP, V0, P37
   Kaffee LA, 2018, PROCEDIA COMPUT SCI, V137, P66, DOI 10.1016/j.procs.2018.09.007
   Kremen Petr, 2018, CEUR WORKSHOP PROC, V2187, P70
   Maillot Pierre, 2022, EXTENDED SEMANTIC WE, V0, P0
   Mihindukulasooriya Nandana, 2015, CEUR WORKSHOP PROC, V1486, P0
   Molli Pascal, 2020, RES REPORT, V0, P0
   Pietriga E, 2018, LECT NOTES COMPUT SC, V11137, P137, DOI 10.1007/978-3-030-00668-6_9
   Saleem Muhammad, 2014, THE SEMANTIC WEB: TRENDS AND CHALLENGES. 11TH INTERNATIONAL CONFERENCE (ESWC 2014). PROCEEDINGS: LNCS 8465, V0, PP176, DOI 10.1007/978-3-319-07443-6_13
   Vandenbussche PY, 2017, SEMANT WEB, V8, P1049, DOI 10.3233/SW-170254
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wilkinson Mark D, 2016, SCI DATA, V3, P160018, DOI 10.1038/sdata.2016.18
   Williams GT, 2013, SPARQL 1 1 SERVICE D, V0, P0
   Winstanley Peter, 2020, DATA CATALOG VOCABUL, V0, P0
   Yamamoto Y, 2018, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/bay022
   Yumusak S, 2017, IEICE T INF SYST, VE100D, P758, DOI 10.1587/transinf.2016DAP0025
   Zaveri A, 2016, SEMANT WEB, V7, P63, DOI 10.3233/SW-150175
NR 33
TC 1
Z9 1
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1570-8268
EI 1873-7749
J9 J WEB SEMANT
JI J. Web Semant.
PD APR 15
PY 2023
VL 76
IS 
BP 
EP 
DI 10.1016/j.websem.2023.100775
EA JAN 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering
SC Computer Science
GA 8Q5TO
UT WOS:000927269400001
DA 2023-11-10
ER

PT J
AU Zang, SQ
   Han, S
   Yuan, PP
   Shi, XH
   Jin, H
AF Zang, Shaoqi
   Han, Sheng
   Yuan, Pingpeng
   Shi, Xuanhua
   Jin, Hai
TI HyperBit: A temporal graph store for fast answering queries
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article
DE Temporal labeled graph; Graph database; Temporal query; Snapshot
ID rdf
AB Relationships or interactions among entities interactions often have occurrence time. So, temporal graph is becoming a popular model to represent temporal data. Temporal graph is generally much larger than corresponding non-temporal graph because an non-temporal edge may have many corresponding temporal edges. It raises challenges for querying temporal graphs. Here, we present HyperBit, a temporal graph store which can answer temporal queries efficiently. HyperBit models temporal labeled graph as a series of updates or log records on graph. Then we design an efficient partition storage for log. Since it is costly to answer temporal queries using logs due to full scan of log, we propose an optimal algorithm to build some snapshots to speedup query processing. So, HyperBit can answer temporal queries by applying log records on the snapshot close to the time in query. HyperBit employs SPARQL instead of a new language to describe temporal queries. Thus, HyperBit can process non temporal queries on temporal/non-temporal graphs. Extensive experiments show that HyperBit significantly outperforms RDF-3x, Jena-TDB in terms of update speed while it has a compact storage. When querying static graphs, HyperBit also outperforms RDF-3X, Jena-TDB by a wide margin and is on par with TripleBit. For temporal queries, HyperBit can easily handle billion graphs, maintaining linear time growth so that has excellent scalability.
C1 [Zang, Shaoqi; Han, Sheng; Yuan, Pingpeng; Shi, Xuanhua; Jin, Hai] Huazhong Univ Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab,Cluster & Grid Comp L, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Yuan, PP (通讯作者)，Huazhong Univ Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab,Cluster & Grid Comp L, Wuhan 430074, Peoples R China.
EM sqzang@hust.edu.cn; s_han@hust.edu.cn; ppyuan@hust.edu.cn; xhshi@hust.edu.cn; hjin@hust.edu.cn
FU National Key Research and Development Program of China [2020AAA0108501]; NSFC [62072205, 61932004]
CR Abadi DJ, 2008, P ACM SIGMOD INT C M, V0, P0, DOI DOI 10.1145/1376616.1376712
   Abadi DJ, 2007, VLDB, V0, P411
   Ali W, 2022, VLDB J, V31, P603, DOI 10.1007/s00778-021-00711-3
   Andriamampianina L, 2022, LECT NOTES COMPUT SC, V0, PP355, DOI 10.1007/978-3-031-07472-1_21
   Beckmann JL, 2006, P 22 INT C DATA ENG, V0, PP58, DOI 10.1109/ICDE.2006.67
   Bereta Konstantina, 2013, SEMANTIC WEB: SEMANTICS AND BIG DATA. PROCEEDINGS OF 10TH INTERNATIONAL CONFERENCE (ESWC 2013): LNCS 7882, V0, P259
   Broekstra J, 2002, LECT NOTES COMPUT SC, V2342, P54
   Chong EI, 2005, VLDB, V0, P0
   Debrouvier A, 2021, VLDB J, V30, P825, DOI 10.1007/s00778-021-00675-4
   Fernandes D, 2018, DATA-BASEL, V0, PP373, DOI 10.5220/0006910203730380
   Heman S, 2007, P 3 BIENN C INN DAT, V0, P96
   Li Y, 2018, AAAI CONF ARTIF INTE, V0, P338
   Margitus M, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), V0, P200
   Neumann T, 2008, PROC VLDB ENDOW, V1, P647, DOI 10.14778/1453856.1453927
   Sidirourgos L, 2008, PROC VLDB ENDOW, V1, P1553
   Weiss C, 2008, PROC VLDB ENDOW, V1, P1008, DOI 10.14778/1453856.1453965
   Yuan PP, 2013, PROC VLDB ENDOW, V6, P517, DOI 10.14778/2536349.2536352
NR 18
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-023X
EI 1872-6933
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD MAR 15
PY 2023
VL 144
IS 
BP 
EP 
DI 10.1016/j.datak.2022.102128
EA DEC 2022
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 7X3BI
UT WOS:000914076300001
DA 2023-11-10
ER

PT J
AU Ding, N
   Qin, YJ
   Yang, G
   Wei, FC
   Yang, ZH
   Su, YS
   Hu, SD
   Chen, YL
   Chan, CM
   Chen, WZ
   Yi, J
   Zhao, WL
   Wang, XZ
   Liu, ZY
   Zheng, HT
   Chen, JF
   Liu, Y
   Tang, J
   Li, JZ
   Sun, MS
AF Ding, Ning
   Qin, Yujia
   Yang, Guang
   Wei, Fuchao
   Yang, Zonghan
   Su, Yusheng
   Hu, Shengding
   Chen, Yulin
   Chan, Chi-Min
   Chen, Weize
   Yi, Jing
   Zhao, Weilin
   Wang, Xiaozhi
   Liu, Zhiyuan
   Zheng, Hai-Tao
   Chen, Jianfei
   Liu, Yang
   Tang, Jie
   Li, Juanzi
   Sun, Maosong
TI Parameter-efficient fine-tuning of large-scale pre-trained language models
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
AB With the prevalence of pre-trained language models (PLMs) and the pre-training-fine-tuning paradigm, it has been continuously shown that larger models tend to yield better performance. However, as PLMs scale up, fine-tuning and storing all the parameters is prohibitively costly and eventually becomes practically infeasible. This necessitates a new branch of research focusing on the parameter-efficient adaptation of PLMs, which optimizes a small portion of the model parameters while keeping the rest fixed, drastically cutting down computation and storage costs. In general, it demonstrates that large-scale models could be effectively stimulated by the optimization of a few parameters. Despite the various designs, here we discuss and analyse the approaches under a more consistent and accessible term 'delta-tuning', where 'delta' a mathematical notation often used to denote changes, is borrowed to refer to the portion of parameters that are 'changed' during training. We formally describe the problem and propose a unified categorization criterion for existing delta-tuning methods to explore their correlations and differences. We also discuss the theoretical principles underlying the effectiveness of delta-tuning and interpret them from the perspectives of optimization and optimal control. Furthermore, we provide a holistic empirical study on over 100 natural language processing tasks and investigate various aspects of delta-tuning. With comprehensive study and analysis, our research demonstrates the theoretical and practical properties of delta-tuning in the adaptation of PLMs. Training a deep neural network can be costly but training time is reduced when a pre-trained network can be adapted to different use cases. Ideally, only a small number of parameters needs to be changed in this process of fine-tuning, which can then be more easily distributed. In this Analysis, different methods of fine-tuning with only a small number of parameters are compared on a large set of natural language processing tasks.
C1 [Ding, Ning; Qin, Yujia; Yang, Guang; Wei, Fuchao; Yang, Zonghan; Su, Yusheng; Hu, Shengding; Chan, Chi-Min; Chen, Weize; Yi, Jing; Zhao, Weilin; Wang, Xiaozhi; Liu, Zhiyuan; Chen, Jianfei; Liu, Yang; Tang, Jie; Li, Juanzi; Sun, Maosong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Ding, Ning; Qin, Yujia; Su, Yusheng; Hu, Shengding; Chen, Weize; Yi, Jing; Zhao, Weilin; Liu, Zhiyuan; Tang, Jie; Sun, Maosong] Beijing Acad Artificial Intelligence, Beijing, Peoples R China.
   [Chen, Yulin; Zheng, Hai-Tao] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Liu, ZY; Sun, MS (通讯作者)，Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.; Liu, ZY; Sun, MS (通讯作者)，Beijing Acad Artificial Intelligence, Beijing, Peoples R China.; Zheng, HT (通讯作者)，Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.
EM liuzy@tsinghua.edu.cn; zheng.haitao@sz.tsinghua.edu.cn; sms@tsinghua.edu.cn
FU National Key Research and Development Program of China [2020AAA0106500]; National Natural Science Foundation of China [62276154, 62011540405]; Beijing Academy of Artificial Intelligence (BAAI) and the Institute for Guo Qiang at Tsinghua University
CR Ang KH, 2005, IEEE T CONTR SYST T, V13, P559, DOI 10.1109/TCST.2005.847331
   Armen Aghajanyan, 2021, PROC ACLIJCNLP, V1, P7319
   Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Boyd S, 1991, LINEAR CONTROLLER DE, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chowdhery A, 2022, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P105
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8410
   Guo DM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4884
   Han WJ, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P854
   Han X, 2021, OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002
   He J, 2022, INT C LEARN REPR, V0, P0
   He RD, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2208
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Hu Edward J, 2022, INT C LEARNING REPRE, V0, P0
   Hu SD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2225
   Karimi Mahabadi R, 2021, ADV NEURAL INFORM PR, V0, P1022
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2019, WHAT WOULD ELSA DO F, V0, P0
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3045
   Lhoest Q, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P175
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Liu PF, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3560815
   Liu R, 2018, INT C LEARNING REPRE, V0, P0
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61
   Liu X, 2021, CSIAM T APPL MATH, V2, P585, DOI 10.4208/csiam-am.SO-2021-0016
   Liu YH, 2019, ARXIV, V0, P0
   Mahabadi RK, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P565
   Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P487
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P46
   Qin YJ, 2022, ARXIV, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rücklé A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P7930
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P255
   Smith Shaden, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2201.11990
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Stickland AC, 2019, PR MACH LEARN RES, V97, P0
   Su YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P3949
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vu T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5039
   Rae JW, 2022, ARXIV, V0, P0
   Wang A, 2019, INT C LEARNING REPRE, V0, P0
   Williams A, 2018, P C N AM CHAPT ASS C, V1, P1112, DOI 10.18653/V1/N18-1101
   Yang Z, 2022, SIGIR 17 P 40 INT AC, V0, P0
   Yang ZH, 2023, ARXIV, V0, P0
   Zhao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2226
NR 52
TC 4
Z9 4
U1 34
U2 39
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD MAR 15
PY 2023
VL 5
IS 3
BP 220
EP +
DI 10.1038/s42256-023-00626-4
EA MAR 2023
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 9Z6JS
UT WOS:000942663300002
DA 2023-11-10
ER

PT J
AU Yu, SY
   Zhang, ZH
   Liu, HT
AF Yu, Shuiyuan
   Zhang, Zihao
   Liu, Haitao
TI What should be encoded by position embedding for neural network language models?
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Position embedding; transformer; frequency-position relationship; absolute position; relative position
ID long-range correlations
AB Word order is one of the most important grammatical devices and the basis for language understanding. However, as one of the most popular NLP architectures, Transformer does not explicitly encode word order. A solution to this problem is to incorporate position information by means of position encoding/embedding (PE). Although a variety of methods of incorporating position information have been proposed, the NLP community is still in want of detailed statistical researches on position information in real-life language. In order to understand the influence of position information on the correlation between words in more detail, we investigated the factors that affect the frequency of words and word sequences in large corpora. Our results show that absolute position, relative position, being at one of the two ends of a sentence and sentence length all significantly affect the frequency of words and word sequences. Besides, we observed that the frequency distribution of word sequences over relative position carries valuable grammatical information. Our study suggests that in order to accurately capture word-word correlations, it is not enough to focus merely on absolute and relative position. Transformers should have access to more types of position-related information which may require improvements to the current architecture.
C1 [Yu, Shuiyuan; Zhang, Zihao; Liu, Haitao] Beijing Language & Culture Univ, Inst Quantitat Linguist, Beijing 100083, Peoples R China.
   [Liu, Haitao] Zhejiang Univ, Dept Linguist, Hangzhou 310058, Peoples R China.
   [Liu, Haitao] Guangdong Univ Foreign Studies, Ctr Linguist & Appl Linguist, Guangzhou 510006, Peoples R China.
C3 Beijing Language & Culture University; Zhejiang University; Guangdong University of Foreign Studies
RP Liu, HT (通讯作者)，Beijing Language & Culture Univ, Inst Quantitat Linguist, Beijing 100083, Peoples R China.; Liu, HT (通讯作者)，Zhejiang Univ, Dept Linguist, Hangzhou 310058, Peoples R China.; Liu, HT (通讯作者)，Guangdong Univ Foreign Studies, Ctr Linguist & Appl Linguist, Guangzhou 510006, Peoples R China.
EM lhtzju@yeah.net
FU National Social Science Foundation of China [20AYY021]; Science Foundation of Beijing Language and Culture University; Science Foundation of Beijing Language and Culture University - Fundamental Research Funds for the Central Universities [20YJ140010]; MOE Project of Key Research Institute of Humanities and Social Sciences at Universities in China [22JJD740018]
CR Altmann EG, 2012, P NATL ACAD SCI USA, V109, P11582, DOI 10.1073/pnas.1117723109
   Alvarez-Lacalle E, 2006, P NATL ACAD SCI USA, V103, P7956, DOI 10.1073/pnas.0510673103
   [Anonymous], 2008, SYNTHESIS LECT HUMAN, V0, P0
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, ARXIV, V0, P0
   Dufter P, 2021, ARXIV, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   Ebbinghaus H, 2013, ANN NEUROSCI, V20, P155, DOI 10.5214/ans.0972.7531.200408
   EBELING W, 1994, EUROPHYS LETT, V26, P241, DOI 10.1209/0295-5075/26/4/001
   Gehring J, 2017, PR MACH LEARN RES, V70, P0
   Goldberg Y, 2019, ARXIV, V0, P0
   Goldhahn D, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P759
   Guthrie D, 2006, P 5 INT C LANGUAGE R, V0, P1222
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   HASHER L, 1973, AM J PSYCHOL, V86, P389, DOI 10.2307/1421449
   HESS DJ, 1995, J EXP PSYCHOL GEN, V124, P62, DOI 10.1037/0096-3445.124.1.62
   Huang ZH, 2020, ARXIV, V0, P0
   Jelinek F, 1997, STAT METHODS SPEECH, V0, P0
   Lakretz Y, 2019, ARXIV, V0, P0
   LeCun Y, 1995, CONVOLUTIONAL NETWOR, V3361, P1995, DOI 10.5555/303568.303704
   Lin YJ, 2019, ARXIV, V0, P0
   Liu HT, 2010, LINGUA, V120, P1567, DOI 10.1016/j.lingua.2009.10.001
   Liu HT, 2008, J COGN SCI, V9, P159
   Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117
   Mikolov T, 2013, ARXIV, V0, P0
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463
   Park K, 2020, AACL IJCNLP, V0, P0
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Pham TM, 2021, ARXIV, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rosendahl J, 2019, P 16 INT C SPOK LANG, V0, P0
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   Schenkel A, 1993, FRACTALS, V1, P47, DOI 10.1142/S0218348X93000083
   Schmitt M, 2020, ARXIV, V0, P0
   Shaw P, 2018, ARXIV, V0, P0
   Shiv VL, 2019, ADV NEUR IN, V32, P0
   Takase S, 2019, ARXIV, V0, P0
   Vasiu MA, 2020, INT C INTELL COMP CO, V0, PP243, DOI 10.1109/iccp51029.2020.9266140
   Vaswani A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1706.03762
   Wang B, 2021, INT C LEARNING REPRE, V0, P0
   Wang B, 2019, APSIPA TRANS SIGNAL, V8, P0, DOI 10.1017/ATSIP.2019.12
   Wang X, 2019, ARXIV, V0, P0
   Wang YA, 2020, ARXIV, V0, P0
   Wei JQ, 2021, ARXIV, V0, P0
   Yan H, 2019, ARXIV, V0, P0
   Zhu Jie, 2019, MODELING GRAPH STRUC, V0, P0
   Zipf, 1935, PSYCHOBIOLOGY LANGUA, V0, P0
   Zipf GK, 1950, J CLIN PSYCHOL, V6, P306
NR 48
TC 0
Z9 0
U1 7
U2 7
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324923000128
EA MAY 2023
PG 25
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA F9AU9
UT WOS:000985209300001
DA 2023-11-10
ER

PT J
AU Jiang, JJ
   Liu, ZY
   Zheng, NN
AF Jiang, Jingjing
   Liu, Ziyi
   Zheng, Nanning
TI Correlation Information Bottleneck: Towards Adapting Pretrained Multimodal Models for Robust Visual Question Answering
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article
DE Information bottleneck; Robustness; Visual question answering; Vision-language model
ID language
AB Benefiting from large-scale pretrained vision language models (VLMs), the performance of visual question answering (VQA) has approached human oracles. However, finetuning such models on limited data often suffers from overfitting and poor generalization issues, leading to a lack of model robustness. In this paper, we aim to improve input robustness from an information bottleneck perspective when adapting pretrained VLMs to the downstream VQA task. Input robustness refers to the ability of models to defend against visual and linguistic input variations, as well as shortcut learning involved in inputs. Generally, the representations obtained by pretrained VLMs inevitably contain irrelevant and redundant information for a specific downstream task, resulting in statistically spurious correlations and insensitivity to input variations. To encourage representations to converge to a minimal sufficient statistic in multimodal learning, we propose Correlation Information Bottleneck (CIB), which seeks a tradeoff between compression and redundancy in representations by minimizing the mutual information (MI) between inputs and representations while maximizing the MI between outputs and representations. Moreover, we derive a tight theoretical upper bound for the mutual information between multimodal inputs and representations, incorporating different internal correlations that guide models to learn more robust representations and facilitate modality alignment. Extensive experiments consistently demonstrate the effectiveness and superiority of the proposed CIB in terms of input robustness and accuracy.
C1 [Jiang, Jingjing; Liu, Ziyi; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Zheng, NN (通讯作者)，Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM jingjingjiang2017@gmail.com; liuziyi@stu.xjtu.edu.cn; nnzheng@mail.xjtu.edu.cn
FU This work was supported by the National Science Foundation of China (Grant No. 62088102).; National Science Foundation of China;  [62088102]
CR Agarwal Vedika, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9687, DOI 10.1109/CVPR42600.2020.00971
   Agrawal A, 2022, ARXIV, V0, P0
   Ahuja K, 2021, ADV NEURAL INF PROCE, V34, P3438
   Alayrac J-B, 2022, ADV NEURAL INFORM PR, V5, P23716
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Ban Y, 2022, NEURAL INFORM PROCES, V0, P1196
   Bao F, 2021, INT C ARTIFICIAL INT, V0, P91
   Bao HB, 2022, ARXIV, V0, P0
   Barber D, 2004, ADV NEUR IN, V16, P201
   Belghazi MI, 2018, PR MACH LEARN RES, V80, P0
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, V0, P8102
   Bennasar M, 2015, EXPERT SYST APPL, V42, P8520, DOI 10.1016/j.eswa.2015.07.007
   Cadene Remi, 2019, ADV NEUR IN, V0, P841
   Changpinyo S, 2021, PROC CVPR IEEE, V0, PP3557, DOI 10.1109/CVPR46437.2021.00356
   Chen Long, 2020, P IEEE CVF C COMP VI, V0, P10797
   Chen XL, 2015, ARXIV, V0, P0
   Cheng PY, 2020, PR MACH LEARN RES, V119, P0
   Cho J, 2021, PR MACH LEARN RES, V139, P0
   Clark C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4069
   Dancette C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP1554, DOI 10.1109/ICCV48922.2021.00160
   Dong X, 2021, ADV NEURAL INFORM PR, V34, P4356
   Dou ZY, 2022, P IEEECVF C COMPUTER, V0, P18166
   Dubois Yann, 2020, ADV NEURAL INFORM PR, V33, P18674
   Federici M, 2020, INT C LEARNING REPRE, V0, P0
   Gan Zhe, 2020, NEURIPS, V2, P0
   Gat Itai, 2020, ADV NEURAL INF PROCE, V0, P3197
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Li LH, 2019, ARXIV, V0, P0
   Hu R, 2020, P IEEE CVF C COMP VI, V0, PP9992, DOI 10.1109/CVPR42600.2020.01001
   Hu RH, 2018, LECT NOTES COMPUT SC, V11211, P55, DOI 10.1007/978-3-030-01234-2_4
   Huang ZC, 2020, ARXIV, V0, P0
   Huang ZC, 2021, PROC CVPR IEEE, V0, PP12971, DOI 10.1109/CVPR46437.2021.01278
   Hudson DA, 2019, PROC CVPR IEEE, V0, PP6693, DOI 10.1109/CVPR.2019.00686
   Jeon I, 2021, AAAI CONF ARTIF INTE, V35, P7926
   Jiang Y, 2018, ARXIV, V0, P0
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Jingjing Jiang, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP199, DOI 10.1145/3474085.3475350
   Kant Y, 2021, P IEEECVF INT C COMP, V0, P1604
   Kazemi V, 2017, SHOW ASK ATTEND ANSW, V0, P0
   Kervadec C, 2021, PROC CVPR IEEE, V0, PP2775, DOI 10.1109/CVPR46437.2021.00280
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Kim W, 2021, PR MACH LEARN RES, V139, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li B, 2022, AAAI CONF ARTIF INTE, V0, P7399
   Li C, 2022, C EMPIRICAL METHODS, V0, P7241
   Li CL, 2021, ARXIV, V0, P0
   Li J, 2022, INT C MACHINE LEARNI, V0, P12888
   Li Junnan, 2021, ADV NEURAL INF PROCE, V0, PP9694, DOI 10.48550/ARXIV.2107.07651
   Li L, 2021, IEEE C COMP VIS PATT, V0, P2042
   Li Linjie, 2020, ARXIV, V0, P0
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Li YA, 2021, AAAI CONF ARTIF INTE, V35, P8518
   Liu XJ, 2019, IEEE I CONF COMP VIS, V0, PP2611, DOI 10.1109/ICCV.2019.00270
   Lu J, 2015, DEEPER ISTM NORMALIZ, V0, P0
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Mahabadi RK, 2021, INT C LEARN REPR, V0, P0
   Nam Junhyun, 2020, ADV NEURAL INFORM PR, V33, P1
   Nguyen XL, 2010, IEEE T INFORM THEORY, V56, P5847, DOI 10.1109/TIT.2010.2068870
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Pan YH, 2022, ACM T MULTIM COMPUT, V18, P0, DOI 10.1145/3487042
   Pan ZQ, 2021, AAAI CONF ARTIF INTE, V35, P9285
   Poole B, 2019, PR MACH LEARN RES, V97, P0
   Shah M, 2019, PROC CVPR IEEE, V0, PP6642, DOI 10.1109/CVPR.2019.00681
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Sheng S, 2021, P ADV NEUR INF PROC, V34, P20346
   Shi JX, 2019, PROC CVPR IEEE, V0, PP8368, DOI 10.1109/CVPR.2019.00857
   Shi L, 2020, ARXIV, V0, P0
   Shrestha R, 2020, NEGATIVE CASE ANAL V, V0, P8172
   Shwartz-Ziv R, 2017, ARXIV, V0, P0
   Su Weijie, 2020, INT C LEARNING REPRE, V0, P0
   Sun SQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P982
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Teney Damien, 2020, ARXIV200409034, V0, P407
   Tishby N, 2000, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.PHYSICS/0004057
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW), V0, P0
   van den Oord A, 2019, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang B, 2021, INT C LEARNING REPRE, V0, P0
   Wang HQ, 2022, PROC CVPR IEEE, V0, PP16020, DOI 10.1109/CVPR52688.2022.01557
   Wang Peng, 2022, INT C MACHINE LEARNI, V0, P23318
   Wang Wenhui, 2023, 2023 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP19175, DOI 10.1109/CVPR52729.2023.01838
   Wang Z, 2022, INT C LEARNING REPRE, V0, P0
   Whitehead S, 2020, ARXIV, V0, P0
   Xu HY, 2023, ARXIV, V0, P0
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yingjun Du, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12355), V0, PP200, DOI 10.1007/978-3-030-58607-2_12
   Yu F, 2021, AAAI CONF ARTIF INTE, V35, P3208
   Yu JH, 2022, ARXIV, V0, P0
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Yuan L, 2021, ARXIV, V0, P0
   Zeng Y, 2022, ICML, V0, P25994
   Zeng Y, 2023, ARXIV, V0, P0
   Zhang PC, 2021, PROC CVPR IEEE, V0, PP5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang Z, 2020, ADV NEUR IN, V0, P18123
   Zhong Yiwu, 2022, P IEEECVF C COMPUTER, V0, P16793
   Zhou Daquan, 2022, P 39 INT C MACHINE L, V0, P27378
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu YK, 2016, PROC CVPR IEEE, V0, PP4995, DOI 10.1109/CVPR.2016.540
NR 100
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD AUG 28
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s11263-023-01858-y
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q3WR9
UT WOS:001056861100002
DA 2023-11-10
ER

PT J
AU Liu, XY
   Tang, HL
   Zhao, J
   Dou, QS
   Lu, MY
AF Liu, Xiaoyan
   Tang, Huanling
   Zhao, Jie
   Dou, Quansheng
   Lu, Mingyu
TI TCAMixer: A lightweight Mixer based on a novel triple concepts attention mechanism for NLP
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Textual feature representation; Attention mechanism; Deep learning; Modeling lighter
AB Large-scale model sizes and expensive computing costs cause the challenge of deploying and applying large pre-trained models. Hence, this paper presents a novel Triple Concepts Attention Mechanism and a lightweight TCAMixer model for edge devices to classify texts. Furthermore, the TCAMixer abstracts textual concepts in a human way, which is unmatched by other counterparts such as pNLP-Mixer (a projection-based MLP-Mixer model for Nature Language Processing) and HyperMixer (a hyper network using dynamic token-mixing layers). Experimental results on several public datasets demonstrate that the TCAMixer outperforms the counterparts by a significant margin, for example, achieving 3% higher accuracy with a smaller model size of 0.177M. Additionally, the TCAMixer achieves a performance of 85% to 98.7% compared to that of large pre-trained models but only occupies 1/3000 to 1/2000 of their size on most test datasets.
C1 [Liu, Xiaoyan; Tang, Huanling; Dou, Quansheng] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Shandong, Peoples R China.
   [Zhao, Jie] Shandong Technol & Business Univ, Sch Management Sci & Engn, Yantai 264005, Shandong, Peoples R China.
   [Tang, Huanling; Dou, Quansheng] Coinnovat Ctr Shandong Coll & Univ Future Intellig, Yantai 264005, Shandong, Peoples R China.
   [Tang, Huanling; Dou, Quansheng] Shandong Technol & Business Univ, Univ Shandong, Key Lab Intelligent Informat Proc, Yantai 264005, Shandong, Peoples R China.
   [Lu, Mingyu] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116026, Liaoning, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology & Business University; Shandong University; Shandong Technology & Business University; Dalian Maritime University
RP Tang, HL (通讯作者)，Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Shandong, Peoples R China.
EM lxy15058247683@aliyun.com; thL01@163.com; 17832275101@163.com; li_dou@163.com; lumingyu@dlmu.edu.cn
FU National Natural Science Foundation of China [61976124, 61976125, 62176140]
CR Bailin Li, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12347), V0, PP639, DOI 10.1007/978-3-030-58536-5_38
   Beltagy I, 2020, ARXIV, V0, P0
   Chen SF, 2022, ARXIV, V0, P0
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Devlin J, 2018, ARXIV, V1, P4171
   Fusco F, 2023, ARXIV, V0, P0
   Howard AG, 2017, ARXIV, V0, P0
   Guo MH, 2021, ARXIV, V0, P0
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hinton G, 2015, ARXIV, V0, P0
   Ioannou Y, 2017, PROC CVPR IEEE, V0, PP5977, DOI 10.1109/CVPR.2017.633
   Javed U, 2021, INT J EMERG TECHNOL, V16, P274, DOI 10.3991/ijet.v16i03.18851
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lee-Thorp J, 2022, ARXIV, V0, P0
   Lian D, 2021, AS MLP AXIAL SHIFTED, V0, P0, DOI DOI 10.48550/ARXIV.2107.08391
   Lin MB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P673
   Liu Hanxiao, 2021, ADV NEURAL INF PROCE, V34, P9204, DOI 10.48550/ARXIV.2105.08050
   Liu YH, 2019, ARXIV, V0, P0
   Mai FR, 2022, ARXIV, V0, P0
   Sabour S, 2017, P 31 INT C NEUR INF, V0, P3856
   Shaukat K, 2020, ENERGIES, V13, P0, DOI 10.3390/en13102509
   Shazeer N, 2017, OUTRAGEOUSLY LARGE N, V0, P1
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2158
   Tang W, 2022, IEEE T MULTIMED, V0, PP1, DOI 10.1109/TMM.2022.3192661
   Tolstikhin I, 2021, ADV NEURAL INFORM PR, V0, P0
   Touvron Hugo, 2021, P INT C MACH LEARN I, V0, P0, DOI DOI 10.48550/arXiv.2012.12877
   Vaswani A, 2017, ARXIV, V30, P5998
   Wu MC, 2019, INT CONF ACOUST SPEE, V0, PP2202, DOI 10.1109/ICASSP.2019.8682450
   Xie Q, 2020, ADV NEURAL INFORM PR, V33, P6256, DOI 10.5555/3495724.3496249
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu RC, 2018, PROC CVPR IEEE, V0, PP9194, DOI 10.1109/CVPR.2018.00958
   Yu T, 2022, IEEE WINT CONF APPL, V0, PP3615, DOI 10.1109/WACV51458.2022.00367
   Zhang Ye, 2017, P 8 INT JOINT C NAT, V1, P253
   Zhu JM, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP2941, DOI 10.1145/3340531.3412704
   Zhuo HY, 2018, ARXIV, V0, P0
NR 38
TC 0
Z9 0
U1 2
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD AUG 15
PY 2023
VL 123
IS 
BP 
EP 
DI 10.1016/j.engappai.2023.106471
EA MAY 2023
PG 8
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA J7QT4
UT WOS:001011537800001
DA 2023-11-10
ER

PT J
AU Liu, MY
   Zhao, HG
   Ma, LF
   Li, MY
AF Liu, Mingyue
   Zhao, Honggang
   Ma, Longfei
   Li, Mingyong
TI Modal interaction-enhanced prompt learning by transformer decoder for vision-language models
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Modal interaction; CLIP; Prompt learning; Self-attention
AB In the current multimodal retrieval field, CoOp is the preferred approach among many models due to its simplicity and powerful adaptive capability. However, CoOp focuses primarily on optimizing prompts to perform contrast learning, without considering image-text interactions and the impact on the model when visual information is incorporated into the prompts. In this work, we propose a prompt tuning method for simulating image-text interaction based on CoOp: Decoding context optimization (DeCoOp). Through extensive experiments on 11 image classification datasets, seven datasets under the few-shot setting and all 11 datasets under the zero-shot setting are ahead of CoOp in our method. Experiments on four target datasets of ImageNet show a model performance improvement of more than 10%, demonstrating that our approach substantially outperforms the baseline model CoOp in terms of point domain generalization and robustness. In addition, ablation experiments performed on three representative datasets confirmed the effectiveness and further improvement of the accuracy of DeCoOp. Finally, experiments are performed on 11 datasets using different visual backbones, and it is not difficult to find that the gap between our approach and handcrafted prompts is large in all architectures and shows better performance than CoOp.
C1 [Liu, Mingyue; Zhao, Honggang; Ma, Longfei; Li, Mingyong] Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Li, Mingyong] Chongqing Natl Ctr Appl Math, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University
RP Li, MY (通讯作者)，Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.; Li, MY (通讯作者)，Chongqing Natl Ctr Appl Math, Chongqing 401331, Peoples R China.
EM 2021210516057@stu.cqnu.edu.cn; 2021210516098@stu.cqnu.edu.cn; 2021210516063@stu.cqnu.edu.cn; limingyong@cqnu.edu.cn
FU Chongqing Natural Science Foundation of China [CSTB2022NSCQ-MSX1417]; Science and Technology Research Program of Chongqing Municipal Education Commission [KJZD-K202200513]; Chongqing Normal University Fund [22XLB003]
CR [Anonymous], 2004, 2004 C COMP VIS PATT, V0, P0
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Carion Nicolas, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12346), V0, PP213, DOI 10.1007/978-3-030-58452-8_13
   Cimpoi M, 2014, PROC CVPR IEEE, V0, PP3606, DOI 10.1109/CVPR.2014.461
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, ARXIV, V0, P0
   Gao P, 2021, P IEEE CVF INT C COM, V0, P3621
   Gao P, 2021, ARXIV, V0, P0, DOI DOI 10.1007/S11263-023-01891-X
   Ge C, 2022, ARXIV, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Hendrycks D, 2021, PROC CVPR IEEE, V0, PP15257, DOI 10.1109/CVPR46437.2021.01501
   Jia ML, 2022, ARXIV, V0, P0
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), V0, PP554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Li Manling, 2022, P IEEE CVF C COMP VI, V0, P16420
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Maji S, 2013, ARXIV, V0, P0
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Parkhi OM, 2012, PROC CVPR IEEE, V0, PP3498, DOI 10.1109/CVPR.2012.6248092
   Radford Alec, 2021, P INT C MACH LEARN I, V0, PP8748, DOI 10.48550/ARXIV.2103.00020
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rao YM, 2022, PROC CVPR IEEE, V0, PP18061, DOI 10.1109/CVPR52688.2022.01755
   Recht B, 2019, PR MACH LEARN RES, V97, P0
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Soomro K, 2012, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang H, 2019, ADV NEURAL INFORM PR, V0, P0
   Xiao JX, 2010, PROC CVPR IEEE, V0, PP3485, DOI 10.1109/CVPR.2010.5539970
   Zhang RR, 2021, ARXIV, V0, P0
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
   Zhou Kaiyang, 2022, P IEEE CVF C COMP VI, V0, P16816
NR 33
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC 15
PY 2023
VL 12
IS 2
BP 
EP 
DI 10.1007/s13735-023-00287-4
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering
SC Computer Science
GA N9NQ7
UT WOS:001040199300001
DA 2023-11-10
ER

PT J
AU Malakar, M
   Keskar, RB
   Zadgaonkar, A
AF Malakar, Mousumi
   Keskar, Ravindra B.
   Zadgaonkar, Ajit
TI A hierarchical automatic phoneme recognition model for Hindi-Devanagari consonants using machine learning technique
SO EXPERT SYSTEMS
LA English
DT Article
DE automatic phoneme recognition; hierarchical model; machine learning; mutual information; speech recognition
ID classification; features
AB A phoneme is perceptually the smallest distinct sound unit distinguished among words in a particular language. Every language has its own set of phonemes, and all the words are ordered sequences of phonemes. Therefore, phoneme recognition is essential to automatic speech recognition (ASR) systems. Phonemes of a language can be classified together using a single machine learning (ML) model through the direct classification (also known as the baseline or flat classification) approach. However, it is observed that the performance of such phoneme recognition degrades with the increase in the number of phoneme classes. The challenge is pronounced in languages with a larger number of phoneme classes, like Hindi, which has 48 phonemes. In this paper, we propose a speaker-independent hierarchical classification approach for 33 Hindi-Devanagari consonants/phonemes using cepstral features with ML techniques like support vector machine (SVM), random forest (RF) and fully connected deep neural network (DNN). In this hierarchical approach, a given phoneme is classified into successive subgroups until the particular phoneme class is identified. To perform the classification task, a binary or multi-class classifier is invoked for each internal (non-leaf) node in the hierarchy tree. Our model identified pairs of Optimal Feature Sets (based on mutual information) and the best suitable ML classifier for each internal decision node in the hierarchy using 10-fold cross-validation to help in efficient classification. Our proposed hierarchical model leads to better accuracy and 57% improved performance for phoneme recognition compared with the non-hierarchical, that is, the direct classification approach.
C1 [Malakar, Mousumi; Keskar, Ravindra B.] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Technol, Nagpur, India.
   [Zadgaonkar, Ajit] Speech Markers Pvt Ltd, Pune, India.
   [Malakar, Mousumi] Visvesvaraya Natl Inst Technol, Nagpur, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National Institute of Technology, Nagpur; National Institute of Technology (NIT System); Visvesvaraya National Institute of Technology, Nagpur
RP Malakar, M (通讯作者)，Visvesvaraya Natl Inst Technol, Nagpur, India.
EM mala.mou@gmail.com
CR Ali AMA, 1999, ISCAS 99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, P118, DOI 10.1109/ISCAS.1999.778799
   Anjos I, 2020, EXPERT SYST, V37, P0, DOI 10.1111/exsy.12620
   [Anonymous], 2022, PLAC ART, V0, P0
   [Anonymous], 2022, PHON, V0, P0
   [Anonymous], 2022, HINDI, V0, P0
   [Anonymous], 2022, DEV, V0, P0
   [Anonymous], 2011, INT J SIGNAL PROCESS, V0, P0
   [Anonymous], 2022, FEAT SEL, V0, P0
   [Anonymous], 2022, STUDYSMARTER, V0, P0
   ARIKI Y, 1989, ELECTRON LETT, V25, P918, DOI 10.1049/el:19890615
   Azim Mona A, 2021, 2021 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), V0, PP99, DOI 10.1109/ICICIS52592.2021.9694108
   Bhatt S, 2018, HINDI SPEECH VOWEL R, V0, P201
   Bhatt S, 2021, WIRELESS PERS COMMUN, V118, P3303, DOI 10.1007/s11277-021-08181-0
   Bhatt S, 2020, J AMB INTEL HUM COMP, V11, P4213, DOI 10.1007/s12652-020-01703-x
   Clarkson P, 1999, INT CONF ACOUST SPEE, V0, PP585, DOI 10.1109/ICASSP.1999.759734
   Defiyanti S, 2019, 2019 5 INT C SCI TEC, V0, P1
   Driaunys K, 2005, INFORMATION TECHNOLOGY AND CONTROL, V34, P257
   Esposito A, 1999, TRAINING, V2050, P1156
   Fredj IB, 2014, ENERGY ELECT ENG CEE, V1, P57
   FRY DB, 1958, LANG SPEECH, V1, P35, DOI 10.1177/002383095800100104
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Juneja A, 2003, IEEE IJCNN, V0, P675
   Kaewtip Kantapon, 2019, 2019 23RD INTERNATIONAL COMPUTER SCIENCE AND ENGINEERING CONFERENCE (ICSEC), V0, PP18, DOI 10.1109/ICSEC47112.2019.8974726
   Kaur S, 2014, INT J COMPUTER SCI E, V4, P285
   Koizumi T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, V0, P0
   Kuldeep K, 2011, INT J COMPUTING BUSI, V1, P2229
   Kumar M, 2004, IBM J RES DEV, V48, P703, DOI 10.1147/rd.485.0703
   LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546
   Li XJ, 2021, INTERSPEECH, V0, PP2461, DOI 10.21437/Interspeech.2021-1803
   Lopes Carla, 2009, 2009 17TH EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO 2009), V0, P1760
   Malakar M, 2021, SPEECH COMMUN, V0, P0
   Malviya Shrikant, 2016, 2016 CONFERENCE OF THE ORIENTAL CHAPTER OF INTERNATIONAL COMMITTEE FOR COORDINATION AND STANDARDIZATION OF SPEECH DATABASES AND ASSESSMENT TECHNIQUES (O-COCOSDA), V0, PP188, DOI 10.1109/ICSDA.2016.7919009
   Meenakshi GN, 2017, INTERSPEECH, V0, PP503, DOI 10.21437/Interspeech.2017-1388
   Mori RD, 1980, SPOKEN LANGUAGE GENE, V0, P191
   Mukherjee Himadri, 2018, INTELLIGENT ENGINEERING INFORMATICS. PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON FICTA. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 695), V0, PP61, DOI 10.1007/978-981-10-7566-7_7
   Myrvoll TA, 1999, NORSIG 99, V0, P614
   Oh D, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11010428
   Patil VV, 2016, J PHONETICS, V54, P202, DOI 10.1016/j.wocn.2015.11.001
   Rabiner L, 2007, INTRO DIGITAL SPEECH, V0, P0
   Rao KS, 2015, LANGUAGE IDENTIFICAT, V0, P0
   Samudravijaya K, 1998, SADHANA-ACAD P ENG S, V23, P313, DOI 10.1007/BF02745745
   Scanlon P, 2007, IEEE T AUDIO SPEECH, V15, P803, DOI 10.1109/TASL.2006.885907
   SCHMIDBAUER O, 1993, LANG SPEECH, V36, P331, DOI 10.1177/002383099303600311
   Singhvi A, 2008, INT CONF SIGN PROCES, V0, PP571, DOI 10.1109/ICOSP.2008.4697197
   Sinha S, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P1953, DOI 10.1109/ICACCI.2013.6637481
   Waibel A, 1988, ICASSP 88: 1988 INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P0
   Waterhouse S, 1997, ADV NEUR IN, V9, P800
   Yang HH, 2000, SPEECH COMMUN, V31, P35, DOI 10.1016/S0167-6393(00)00007-8
   Zahorian SA, 1997, INT CONF ACOUST SPEE, V0, PP1011, DOI 10.1109/ICASSP.1997.596111
NR 49
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD AUG 15
PY 2023
VL 40
IS 7
BP 
EP 
DI 10.1111/exsy.13288
EA MAR 2023
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA L1ZA1
UT WOS:000950307900001
DA 2023-11-10
ER

PT J
AU Zhang, F
   Qin, JJ
   Cheng, JW
AF Zhang, Fu
   Qin, Jiejie
   Cheng, Jingwei
TI A joint training network for learning more distinguishable relation features in relation classification
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Natural language processing; Relation classification; Self -supervised contrastive learning; Joint training
ID relation extraction
AB Relation classification is an important task in natural language processing, which aims to predict the semantic relation between a given entity pair in a sentence. There are datasets, like TACRED, that contain a large number of "no_relation"type samples. Most existing methods treat "no_relation"and normal relation types equally, and directly apply the softmax function over all relation types. In this paper, we propose a novel joint training network to learn more distinguishable relation features for relation classification. Specially, we convert the original multi-class classification problem into two joint optimized modules, binary classification of whether a relation is "no_relation"and multi-class classification of normal relation types. To further differentiate between similar normal relation types, we introduce a self-supervised contrastive learning method to learn more distinguishable features for them. We jointly optimize the above modules. Experimental results agree well with our design intention and demonstrate that our joint training network not only achieves superior performance against existing competitive models, but also is robust to "no_relation"problem. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Zhang, Fu; Qin, Jiejie; Cheng, Jingwei] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110169, Peoples R China.
C3 Northeastern University - China
RP Zhang, F (通讯作者)，Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110169, Peoples R China.
EM zhangfu@mail.neu.edu.cn; 1984223979@qq.com; chengjingwei@mail.neu.edu.cn
FU National Natural Science Foundation of China [62276057]; Fundamental Research Funds for the Central Universities, China [N2216008]
CR Alt C, 2019, AKBC, V0, P0
   Alt C, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1558
   Bordes A, 2014, QUESTION ANSWERING S, V0, P0, DOI DOI 10.3115/V1/D14-1067
   Chen JQ, 2015, 2015 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT), VOL 1, P225, DOI 10.1109/WI-IAT.2015.150
   Chen T, 2020, P INT C MACH LEARN, V0, P1597
   Eberts M, 2020, FRONT ARTIF INTEL AP, V325, P2006, DOI 10.3233/FAIA200321
   Fader A, 2011, P C EMPIRICAL METHOD, V0, PP1535, DOI 10.1234/12345678
   Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6894
   Gunel B, 2021, PROC 9 INT C LEARN R, V0, P1
   Hendrickx Iris, 2010, P 5 INT WORKSH SEM E, V0, PP33, DOI 10.3115/1621969.1621986
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kaiming He, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9726, DOI 10.1109/CVPR42600.2020.00975
   Kambar MEZN, 2022, 2022 IEEE WORLD AI IOT CONGRESS (AIIOT), V0, PP218, DOI 10.1109/AIIoT54504.2022.9817231
   Kringelum J, 2016, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/bav123
   Lee J, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11060785
   Li B, 2021, AAAI CONF ARTIF INTE, V35, P13234
   Li C, 2020, ARXIV PREPRINT ARXIV, V0, P1
   Li Wei, 2022, IEEE T NEUR NET LEAR, V0, P1
   Loshchilov I, 2018, INT C LEARN REPR ICL, V0, P0
   Lyu S, 2021, FINDINGS ASS COMPUTA, V0, PP390, DOI 10.18653/V1/2021.FINDINGS-ACL.34
   Peng H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3661
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P43
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2895
   Tandon N, 2011, AAAI, V0, P152
   Tao Q, 2020, P 31 INT C TOOLS ART, V0, P1
   van den Oord Aaron, 2018, ARXIV180703748, V0, P0
   Wang CG, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P803
   Wang H, 2019, APPL ENERG, V237, P1, DOI 10.1016/j.apenergy.2018.12.076
   Wang J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1706
   Wang LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1298
   Wolf T, 1900, P38, V0, P0
   Wu SC, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2361, DOI 10.1145/3357384.3358119
   Wu W, 2012, P 2012 ACM SIGMOD IN, V0, PP481, DOI 10.1145/2213836.2213891
   Wu X, 2022, P 29 INT C COMP LING, V0, P3898
   Xu Y, 2015, P 2015 C EMP METH NA, V0, PP1785, DOI 10.18653/V1/D15-1206
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
   Ye DM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7170
   Yu BW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5401
   Zhang K, 2021, AAAI CONF ARTIF INTE, V35, P14411
   Zhang Y, 2017, P 2017 C EMPIRICAL M, V0, P35
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2205
   Zhong ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P50
   Zhou W, 2022, 2 C ASIA PACIFIC CHA, V0, P1
NR 44
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD MAY 23
PY 2023
VL 268
IS 
BP 
EP 
DI 10.1016/j.knosys.2023.110471
EA MAR 2023
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA A6FD7
UT WOS:000956051000001
DA 2023-11-10
ER

PT J
AU Vojnovic, N
   Vidakovic, J
   Vidakovic, M
AF Vojnovic, Nikola
   Vidakovic, Jovana
   Vidakovic, Milan
TI Multi-threaded power flow of large-scale active multiphase distribution networks
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Large-scale active multiphase distribution; network; Multi-threaded power flow; Backward-forward sweep; Distributed energy resources; Unified Modeling Language
ID distribution-systems; algorithm
AB Backward-Forward Sweep is one of the most used procedures for the power flow calculation of large-scale active multiphase distribution networks. This paper introduces the decoupled network model which is suitable for the multi-threaded implementation of the Backward-Forward Sweep procedure. The main objectives of this paper are: (i) to introduce the decoupled new models of traditional and Electronically-coupled Distributed Energy Resources, (ii) to introduce the decoupled models of single-, two- and three-phase line sections, (iii) to give the detailed Unified Modeling Language diagrams of the software model and procedures, (iv) to give a detailed model and a procedure for the single-threaded power flow calculation, and (v) to give a detailed model and a procedure for the multi-threaded power flow calculation of the large-scale active multiphase distribution networks. The results show the advantage of the proposed decoupled single-threaded approach over the traditional coupled-based one - the speedup is up to 160%. Moreover, the speedup of the decoupled multi-threaded calculation of the power flow compared to the single-threaded one goes up to the 200%. This means that the decoupled multi-threaded implementation is up to 300% faster than the coupled one. These results prove that the Backward-Forward Sweep is particularly usable for the multi-threaded implementation.
C1 [Vojnovic, Nikola; Vidakovic, Milan] Univ Novi Sad, Fac Tech Sci, Novi Sad, Serbia.
   [Vidakovic, Jovana] Univ Novi Sad, Fac Sci, Novi Sad, Serbia.
C3 University of Novi Sad; University of Novi Sad
RP Vojnovic, N (通讯作者)，Univ Novi Sad, Fac Tech Sci, Novi Sad, Serbia.
EM nikola.vojnovic@uns.ac.rs
FU Ministry of Science, Techno- logical Development and Innovation, Serbia [451-03-47/2023-01/200125, 451-03-47/2023-01/200156]
CR Anirudh CVS, 2021, IET RENEW POWER GEN, V15, P980, DOI 10.1049/rpg2.12077
   Araújo I, 2019, INT J ELEC POWER, V105, P229, DOI 10.1016/j.ijepes.2018.08.033
   Arboleya P, 2019, IEEE T IND APPL, V55, P7230, DOI 10.1109/TIA.2019.2913825
   Benato R, 2022, IEEE T POWER SYST, V37, P1363, DOI 10.1109/TPWRS.2021.3104097
   Cui HT, 2021, IEEE T POWER SYST, V36, P4872, DOI 10.1109/TPWRS.2021.3073591
   Dash SP, 2022, EXPERT SYST APPL, V200, P0, DOI 10.1016/j.eswa.2022.116776
   Dkhili N, 2020, SUSTAIN ENERGY GRIDS, V21, P0, DOI 10.1016/j.segan.2019.100284
   Hernández-Fuentes HE, 2022, SUSTAIN ENERGY GRIDS, V32, P0, DOI 10.1016/j.segan.2022.100895
   Evangeline SI, 2022, EXPERT SYST APPL, V194, P0, DOI 10.1016/j.eswa.2022.116544
   Feng F, 2020, IEEE T POWER SYST, V35, P4108, DOI 10.1109/TPWRS.2020.3000658
   Gianto R, 2021, IET RENEW POWER GEN, V15, P1724, DOI 10.1049/rpg2.12141
   Karimi M, 2019, INT J ELEC POWER, V113, P298, DOI 10.1016/j.ijepes.2019.05.055
   Koksoy A, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8040502
   Kumar VSS, 2018, ELECTR POW SYST RES, V155, P363, DOI 10.1016/j.epsr.2017.09.011
   Lara JD, 2021, SOFTWAREX, V15, P0, DOI 10.1016/j.softx.2021.100747
   Liu YY, 2022, EXPERT SYST APPL, V196, P0, DOI 10.1016/j.eswa.2022.116557
   Marini A, 2019, ELECTR POW SYST RES, V170, P229, DOI 10.1016/j.epsr.2018.12.026
   Murari K, 2020, IET GENER TRANSM DIS, V14, P1627, DOI 10.1049/iet-gtd.2019.1176
   Neis P, 2019, IEEE ACCESS, V7, P177761, DOI 10.1109/ACCESS.2019.2958275
   Nguyen TT, 2022, EXPERT SYST APPL, V208, P0, DOI 10.1016/j.eswa.2022.118127
   Ouali S, 2020, J ELECTR COMPUT ENG, V2020, P0, DOI 10.1155/2020/5643410
   Pandey A, 2019, IEEE T POWER SYST, V34, P616, DOI 10.1109/TPWRS.2018.2863042
   Qu L, 2019, ENERGIES, V12, P0, DOI 10.3390/en12234455
   Rizvi SMH, 2022, IEEE T POWER SYST, V37, P3, DOI 10.1109/TPWRS.2021.3088903
   Rodrigues Junior Heitor M, 2022, INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS, V0, P0, DOI DOI 10.1016/j.ijepes.2021.107921
   Sereeter B, 2017, ENERGIES, V10, P0, DOI 10.3390/en10101658
   Shen T, 2018, ENERGIES, V11, P0, DOI 10.3390/en11030511
   Strezoski L, 2018, IEEE T POWER SYST, V33, P1891, DOI 10.1109/TPWRS.2017.2742019
   Strezoski LV, 2019, J MOD POWER SYST CLE, V7, P1365, DOI 10.1007/s40565-018-0494-1
   Strezoski VC, 2015, INT T ELECTR ENERGY, V25, P2455, DOI 10.1002/etep.1974
   Svenda G, 2017, INT T ELECTR ENERGY, V27, P0, DOI 10.1002/etep.2296
   Thurner L, 2018, IEEE T POWER SYST, V33, P6510, DOI 10.1109/TPWRS.2018.2829021
   Tyagi Arjun, 2020, JOURNAL OF ELECTRICAL SYSTEMS AND INFORMATION TECHNOLOGY, V7, P0, DOI 10.1186/s43067-020-00014-7
   Verma R, 2019, ELECTR POW SYST RES, V168, P8, DOI 10.1016/j.epsr.2018.11.005
   Vidovic PM, 2022, ELECTR ENG, V104, P473, DOI 10.1007/s00202-021-01313-6
   Vojnovic N, 2022, COMPUT ELECTR ENG, V101, P0, DOI 10.1016/j.compeleceng.2022.108134
   Wang ZQ, 2021, SUSTAIN ENERGY GRIDS, V27, P0, DOI 10.1016/j.segan.2021.100483
   Zeng L, 2021, IEEE ACCESS, V9, P153226, DOI 10.1109/ACCESS.2021.3127393
   Zhao JB, 2021, IET RENEW POWER GEN, V15, P3978, DOI 10.1049/rpg2.12316
NR 42
TC 0
Z9 0
U1 2
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD OCT 1
PY 2023
VL 227
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120313
EA MAY 2023
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA I1PR4
UT WOS:001000578000001
DA 2023-11-10
ER

PT J
AU Mao, R
   Liu, Q
   He, K
   Li, W
   Cambria, E
AF Mao, Rui
   Liu, Qian
   He, Kai
   Li, Wei
   Cambria, Erik
TI The Biases of Pre-Trained Language Models: An Empirical Study on Prompt-Based Sentiment Analysis and Emotion Detection
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Task analysis; Emotion recognition; Sentiment analysis; Computational modeling; Affective computing; Taxonomy; Analytical models; Emotion detection; pre-trained language model; prompt; sentiment analysis
AB Thanks to the breakthrough of large-scale pre-trained language model (PLM) technology, prompt-based classification tasks, e.g., sentiment analysis and emotion detection, have raised increasing attention. Such tasks are formalized as masked language prediction tasks which are in line with the pre-training objects of most language models. Thus, one can use a PLM to infer the masked words in a downstream task, then obtaining label predictions with manually defined label-word mapping templates. Prompt-based affective computing takes the advantages of both neural network modeling and explainable symbolic representations. However, there still remain many unclear issues related to the mechanisms of PLMs and prompt-based classification. We conduct a systematic empirical study on prompt-based sentiment analysis and emotion detection to study the biases of PLMs towards affective computing. We find that PLMs are biased in sentiment analysis and emotion detection tasks with respect to the number of label classes, emotional label-word selections, prompt templates and positions, and the word forms of emotion lexicons.
C1 [Mao, Rui; Liu, Qian; Li, Wei; Cambria, Erik] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [He, Kai] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian 710049, Shanxi, Peoples R China.
C3 Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Xi'an Jiaotong University
RP Cambria, E (通讯作者)，Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
EM rui.mao@ntu.edu.sg; liu.qian@ntu.edu.sg; hk52025804@stu.xjtu.edu.cn; wei008@e.ntu.edu.sg; erik@sentic.net
FU RIE2020 Industry Alignment Fund - Industry Collaboration Projects Funding Initiative
CR Adoma AF, 2020, I COMP CONF WAVELET, V0, PP117, DOI 10.1109/ICCWAMTIP51612.2020.9317379
   Brown TB, 2020, ARXIV, V0, P0
   Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   Cai J, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP1665, DOI 10.1145/3397271.3401195
   Cambria Erik, 2012, COGNITIVE BEHAVIOURAL SYSTEMS (COST 2012). INTERNATIONAL TRAINING SCHOOL. REVISED SELECTED PAPERS, V0, PP144, DOI 10.1007/978-3-642-34584-5_11
   Cambria E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3829
   Cambria E, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP105, DOI 10.1145/3340531.3412003
   Crawford K, 2021, ATLAS AI POWER POLIT, V0, P0, DOI DOI 10.2307/J.CTV1GHV45T
   Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4040
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dredze Mark, 2007, P 45 ANN M ASS COMPU, V0, P440
   Ekman P, 1984, APPROACHES EMOTION, V3, P19, DOI 10.1017/CBO9781107415324.004
   Gao T, 2021, ARXIV, V0, P0
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Gao TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6250
   Guru D, 2017, P INT C INT SYST DES, V0, P337
   Hambardzumyan K, 2021, ARXIV, V0, P0
   Hendrycks D, 2020, ARXIV, V0, P0
   Hutto CJ, 2014, ICWSM, V0, P0, DOI DOI 10.1609/ICWSM.V8I1.14550
   Jain VK, 2017, J COMPUT SCI-NETH, V21, P316, DOI 10.1016/j.jocs.2017.01.010
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li W, 2022, NEUROCOMPUTING, V467, P73, DOI 10.1016/j.neucom.2021.09.057
   Li W, 2018, KNOWL-BASED SYST, V146, P203, DOI 10.1016/j.knosys.2018.02.004
   Liang B, 2022, KNOWL-BASED SYST, V235, P0, DOI 10.1016/j.knosys.2021.107643
   Liu P, 2021, ARXIV, V0, P0
   Liu Q, 2018, PROC INT C COMPUTATI, V0, P2023
   Liu Q, 2023, IEEE T NEUR NET LEAR, V34, P2594, DOI 10.1109/TNNLS.2021.3107029
   Liu Q, 2021, INFORM SCIENCES, V555, P410, DOI 10.1016/j.ins.2020.10.030
   Liu YH, 2019, ARXIV, V0, P0
   Mao R, 2021, ARXIV, V0, P0
   Mao R, 2022, INFORM FUSION, V86-87, P30, DOI 10.1016/j.inffus.2022.06.002
   Mao R, 2021, AAAI CONF ARTIF INTE, V35, P13534
   Mao R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3888
   Mao R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1222
   Mohammad S, 2014, PROC WASSA, V0, P32
   Mohammad SM, 2017, P 8 WORKSH COMP APPR, V0, P0
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Plutchik R, 1980, THEORIES EMOTION, V0, PP3, DOI 10.1016/B978-0-12-558701-3.50007-7
   Puri R, 2019, ARXIV, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Ray B, 2021, APPL SOFT COMPUT, V98, P0, DOI 10.1016/j.asoc.2020.106935
   Rong Xiang, 2021, 2021 INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND ARTIFICIAL INTELLIGENCE (CCAI), V0, PP204, DOI 10.1109/CCAI50917.2021.9447486
   Schick T, 2020, P 28 INT C COMP LING, V0, P5569
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P255
   Strapparava C, 2004, P 4 INT C LANGUAGE R, V0, P0
   Susanto Y, 2020, IEEE INTELL SYST, V35, P96, DOI 10.1109/MIS.2020.2992799
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Vaswani A, 2017, ARXIV, V30, P5998
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu YH, 2016, ARXIV, V0, P0
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
NR 56
TC 21
Z9 21
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
EI 
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD JUL-SEP 15
PY 2023
VL 14
IS 3
BP 1743
EP 1753
DI 10.1109/TAFFC.2022.3204972
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA T0NN8
UT WOS:001075041900004
DA 2023-11-10
ER

PT J
AU Lai, PC
   Ye, FY
   Fu, YG
   Chen, ZW
   Wu, YJ
   Wang, YL
   Chang, VC
AF Lai, Peichao
   Ye, Feiyang
   Fu, Yanggeng
   Chen, Zhiwei
   Wu, Yingjie
   Wang, Yilei
   Chang, Victor
TI CogNLG: Cognitive graph for KG-to-text generation
SO EXPERT SYSTEMS
LA English
DT Article; Early Access
DE cognitive graph; KG-to-text; natural language generation
ID accounts
AB Knowledge graph (KG) has been fully considered in natural language generation (NLG) tasks. A KG can help models generate controllable text and achieve better performance. However, most existing related approaches still lack explainability and scalability in large-scale knowledge reasoning. In this work, we propose a novel CogNLG framework for KG-to-text generation tasks. Our CogNLG is implemented based on the dual-process theory in cognitive science. It consists of two systems: one system acts as the analytic system for knowledge extraction, and another is the perceptual system for text generation by using existing knowledge. During text generation, CogNLG provides a visible and explainable reasoning path. Our framework shows excellent performance on all datasets and achieves a BLEU score of 36.7, which increases by 6.7 compared to the best competitor.
C1 [Lai, Peichao; Ye, Feiyang; Fu, Yanggeng; Chen, Zhiwei; Wu, Yingjie; Wang, Yilei] Fuzhou Univ, Coll Comp & Data Sci, Fuzhou, Peoples R China.
   [Chang, Victor] Aston Univ, Aston Business Sch, Dept Operat & Informat Management, Birmingham, England.
C3 Fuzhou University; Aston University
RP Wang, YL (通讯作者)，Fuzhou Univ, Coll Comp & Data Sci, Fuzhou, Peoples R China.; Chang, VC (通讯作者)，Aston Univ, Aston Business Sch, Dept Operat & Informat Management, Birmingham, England.
EM yilei@fzu.edu.cn; victorchang.research@gmail.com
FU Prof Wangapos;s work is supported by the Natural Science Foundation of Fujian Province, PR China (2022J01120); the Innovation Platform for Academician of Hainan Province (YSPTZX202145); Fujian Province Industrial Guiding Project (2022H0012); Major Special [2022J01120]; Natural Science Foundation of Fujian Province, PR China [YSPTZX202145]; Innovation Platform for Academician of Hainan Province [2022H0012]; Fujian Province Industrial Guiding Project [2022HZ022022]; Major Special Project for Industrial Science and Technology in Fujian Province [VCR 0000183]; VC Research
CR Brown TB, 2020, ARXIV, V0, P0
   Beck D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P273
   Belz A, 2006, 11 C EUR CHAPT ASS C, V0, P0
   Chen WH, 2020, ARXIV, V0, P0
   Cheng LY, 2020, ARXIV, V0, P0
   Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2174
   Denkowski M, 2011, P 6 WORKSH STAT MACH, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhingra B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4884
   Ding M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2694
   Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723
   Duma D, 2013, P 10 INT C COMP SEM, V0, P0
   Evans JSBT, 2008, ANNU REV PSYCHOL, V59, P255, DOI 10.1146/annurev.psych.59.103006.093629
   EVANS JSBT, 1984, BRIT J PSYCHOL, V75, P451, DOI 10.1111/j.2044-8295.1984.tb01915.x
   Evans JST, 2003, TRENDS COGN SCI, V7, P454, DOI 10.1016/j.tics.2003.08.012
   Fu Z, 2020, P 2020 C EMP METH NA, V0, P0
   Gardent C, 2017, P 10 INT C NAT LANG, V0, P0
   Guo ZJ, 2019, T ASSOC COMPUT LING, V7, P297, DOI 10.1162/tacl_a_00269
   Hendrycks Dan, 2016, ARXIV160608415, V0, P0
   Holtzman A, 2019, CEUR WORKSHOP PROC, V2540, P0
   Ji H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P725
   Kahneman D, 2013, THINKING FAST SLOW, V0, P0
   Kingma DP, 2017, PROC 3 INT C LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Lewis M, 2020, P 58 ANN M ASS COMP, V0, P0
   Li WD, 2020, NEUROCOMPUTING, V382, P174, DOI 10.1016/j.neucom.2019.11.079
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lison P, 2020, NAMED ENTITY RECOGNI, V0, P0
   Liu PJ, 2019, EXPLORING LIMITS TRA, V0, P0
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu ZQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1992
   Madotto A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1468
   Marcheggiani D, 2018, P 11 INT C ANT LANG, V0, P0
   Mei H, 2016, P NAACL HLT, V0, P0
   Novikova J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), V0, P201
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Peng B, 2020, P 2020 C EMP METH NA, V0, P0
   Qi W, 2020, P 2020 C EMP METH NA, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, OPENAI BLOG, V0, P0
   Rastogi C, 2020, DECIDING FAST SLOW R, V0, P0
   Serban IV, 2017, AAAI CONF ARTIF INTE, V0, P3295
   Sloman SA, 1996, PSYCHOL BULL, V119, P3, DOI 10.1037/0033-2909.119.1.3
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, V0, P223
   Song KT, 2019, PR MACH LEARN RES, V97, P0
   Sun Y, 2019, ARXIV, V0, P0
   Vashishth S, 2020, COMPOSITION BASED MU, V0, P0
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wiseman S, 2017, P 2017 C EMPIRICAL M, V0, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yang PC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2002
   Zhu C, 2020, BOOSTING FACTUAL COR, V0, P0
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1097, DOI 10.1145/3209978.3210080
NR 53
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1111/exsy.13461
EA OCT 2023
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA T5EA0
UT WOS:001078203600001
DA 2023-11-10
ER

PT J
AU Cao, X
   Liu, Y
   Sun, F
AF Cao, Xing
   Liu, Yun
   Sun, Feng
TI Predict, pretrained, select and answer: Interpretable and scalable complex question answering over knowledge basest
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Complex question answering; Tree structure knowledge graph; Reasoning path prediction; Entity filter; Answer prediction
ID web
AB Complex question answering (CQA) over knowledge bases(KB) is a challenging task that has attracted increasing attention in recent years. Semantic parsing-based methods face challenges such as poor adaptability for incomplete KB, large search spaces, and high costs to label logic forms. The gap between knowledge graph representations and question token embeddings leads to poor generalizability and uninterpretable reasoning of information retrieval-based methods. We propose an interpretable and scalable system called Predict, Pretrained, Select and Answer (PPSA) to solve CQA tasks over KB. Our system first trains a language model to predict the reasoning paths required to answer questions. We select only the entities that the predicted reasoning paths pass through in the knowledge graph as candidate entities to reduce the amount of distracting information. The paths that connect the topic entity and the selected candidate entity along with the question are then fed into another language model for answer prediction. The answer prediction module loads the parameters of the trained path prediction module before training to improve accuracy. The system reduces the search space by predicting the path and does not need expensive logic forms annotation. The textual path is the input to the language model, which bridges the gap between the graph representations and token embeddings. We analyse the system reasoning ability over knowledge graphs with different degrees of sparseness, and evaluate the system generalizability. The results of experiments performed with the Complex WebQuestions and WebQuestionsSP datasets demonstrate the effectiveness of our approach for CQA task.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Cao, Xing; Liu, Yun; Sun, Feng] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
   [Cao, Xing; Liu, Yun; Sun, Feng] Beijing Municipal Commiss Educ, Key Lab Commun & Informat Syst, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Municipal Commission of Education
RP Liu, Y (通讯作者)，Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
EM caoxing@bjtu.edu.cn; liuyun@bjtu.edu.cn; sunfeng@bjtu.edu.cn
FU Fundamental Research Funds for the Central Universities, China;  [2020YJS012]
CR Abujabal A, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1053, DOI 10.1145/3178876.3186004
   Abujabal A, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1191, DOI 10.1145/3038912.3052583
   [Anonymous], 2017, INT C MACHINE LEARNI, V0, P0
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Bordes A, 2013, ADV NEURAL INFORM PR, V26, P0, DOI 10.5555/2999792.2999923
   Cao X, 2023, NEURAL COMPUT APPL, V35, P5513, DOI 10.1007/s00521-022-07965-0
   Cao X, 2023, APPL INTELL, V53, P12032, DOI 10.1007/s10489-022-04123-w
   Cao X, 2021, COMPLEXITY, V2021, P0, DOI 10.1155/2021/7367181
   Cao X, 2022, J INTELL INF SYST, V58, P21, DOI 10.1007/s10844-021-00645-w
   Chen Danqi, 2017, ARXIV, V0, P0
   Chen Y, 2021, ARXIV, V0, P0
   Chen ZY, 2019, ARXIV, V0, P0
   Chung J, 2014, NIPS 2014 WORKSH DEE, V0, PP1, DOI 10.48550/ARXIV.1412.3555
   Fang YW, 2020, ARXIV, V0, P0
   Feng YF, 2019, AAAI CONF ARTIF INTE, V0, P3558
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Han Jiale, 2020, FINDINGS ASS COMPUTA, V0, PP1475, DOI 10.18653/V1/2020.FINDINGS-EMNLP.133
   Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999
   He GL, 2021, WSDM 21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP535, DOI 10.1145/3437963.3441753
   Hu J, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP3505, DOI 10.1145/3394171.3413711
   Hu J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1157, DOI 10.1145/3343031.3350966
   Jain Sarthak, 2016, P NAACL STUD RES WOR, V0, P109
   Jiang YC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2726
   Kapanipathi P, 2021, FINDINGS ASS COMPUTA, V0, P3884
   Kapanipathi Pavan, 2020, ARXIV, V0, P0
   Lin YK, 2015, AAAI CONF ARTIF INTE, V0, P2181
   Liu YH, 2019, ARXIV, V0, P0
   Luo KQ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2185
   Maheshwari G, 2019, LECT NOTES COMPUT SC, V11778, P487, DOI 10.1007/978-3-030-30793-6_28
   Miller Alexander, 2016, ARXIV160603126, V0, P0
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qiu YQ, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP1285, DOI 10.1145/3340531.3411888
   Qiu YQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM 20), V0, PP474, DOI 10.1145/3336191.3371812
   Ren H, 2019, INT C LEARNING REPRE, V0, P0
   Ren H, 2021, P MACHINE LEARNING R, V0, P8959
   Saha A, 2019, T ASSOC COMPUT LING, V7, P185, DOI 10.1162/tacl_a_00262
   Sang L, 2019, NEUROCOMPUTING, V334, P44, DOI 10.1016/j.neucom.2018.12.067
   Saxena A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4498
   Suchanek F, 2007, P 16 INT C WORLD WID, V0, P0, DOI DOI 10.1145/1242572.1242667
   Sun HT, 2019, ARXIV, V0, P0
   Sun HT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4231
   Sun YW, 2020, AAAI CONF ARTIF INTE, V34, P8952
   Trouillon T, 2016, PR MACH LEARN RES, V48, P0
   Wang K, 2021, ARXIV, V0, P0
   Wang Z, 2014, AAAI CONF ARTIF INTE, V0, P1112
   Xiong WH, 2019, ARXIV, V0, P0
   Xu K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2937
   Yam YM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3653
   Yih WT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1321
   Zhang QX, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.102933
   Zhang YY, 2018, AAAI CONF ARTIF INTE, V0, P6069
   Zhou MT, 2018, ARXIV, V0, P0
   Zhu SG, 2020, NEUROCOMPUTING, V372, P64, DOI 10.1016/j.neucom.2019.09.003
NR 55
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD OCT 25
PY 2023
VL 278
IS 
BP 
EP 
DI 10.1016/j.knosys.2023.110820
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA Q7DW7
UT WOS:001059101700001
DA 2023-11-10
ER

PT J
AU Zhu, LJ
   Peng, L
   Zhou, WA
   Yang, JL
AF Zhu, Liangjun
   Peng, Li
   Zhou, Weinan
   Yang, Jielong
TI Dual-decoder transformer network for answer grounding in visual question answering
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Visual question answering; Answer grounding; Dual-decoder transformer
AB Visual Question Answering (VQA) have made stunning advances by exploiting Transformer architecture and large-scale visual-linguistic pretraining. State-of-the-art methods generally require large amounts of data and devices to predict textualized answers and fail to provide visualized evidence of the answers. To mitigate these limitations, we propose a novel dual-decoder Transformer network (DDTN) for pre-dicting the language answer and corresponding vision instance. Specifically, the linguistic features are first embedded by Long Short-Term Memory (LSTM) block and Transformer encoder, which are shared between the Transformer dual-decoder. Then, we introduce object detector to obtain vision region fea-tures and grid features for reducing the size and cost of DDTN. These visual features are combined with the linguistic features and are respectively fed into two decoders. Moreover, we design an in-stance query to guide the fused visual-linguistic features for outputting the instance mask or bounding box. The classification layers aggregate results from decoders and predict answer as well as correspond-ing instance coordinates at last. Without bells and whistles, DDTN achieves state-of-the-art performance and even competitive to pretraining models on VizWizGround and GQA dataset. The code is available at https://github.com/zlj63501/DDTN .(c) 2023 Published by Elsevier B.V.
C1 [Zhu, Liangjun; Peng, Li; Zhou, Weinan; Yang, Jielong] Jiangnan Univ, Engn Res Ctr Internet Things Appl Technol, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Peng, L (通讯作者)，Jiangnan Univ, Engn Res Ctr Internet Things Appl Technol, Wuxi 214122, Peoples R China.
EM zhuliangjun@stu.jiangnan.edu.com; pengli@jiangnan.edu.cn; 6201924224@stu.jiangnan.edu.cn; jyang022@e.ntu.edu.sg
FU National Natural Science Foundation of China [61873112]; Young Scientists Fund of the National Natural Science Foundation of China [62106082]
CR Abacha AB, 2019, CLEF WORKING NOTES, V0, P0
   Al-Sadi A, 2021, PATTERN RECOGN LETT, V150, P57, DOI 10.1016/j.patrec.2021.07.002
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, V0, P8102
   Carion Nicolas, 2020, ECCV, V0, P0, DOI DOI 10.1007/978-3-030-58452-813
   Chen C, 2022, P IEEE CVF C COMP VI, V0, P19098
   Chen T, 2022, ICLR, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy Alexey, 2021, ICLR, V0, P0
   Gurari D, 2018, PROC CVPR IEEE, V0, PP3608, DOI 10.1109/CVPR.2018.00380
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Hudson DA, 2019, PROC CVPR IEEE, V0, PP6693, DOI 10.1109/CVPR.2019.00686
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Kim Wonjae, 2021, P INT C MACH LEARN, V0, P5583
   Li J, 2022, INT C MACHINE LEARNI, V0, P12888
   Li W, 2020, PATTERN RECOGN LETT, V133, P334, DOI 10.1016/j.patrec.2020.02.031
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lioutas V, 2018, PATTERN RECOGN LETT, V111, P51, DOI 10.1016/j.patrec.2018.04.031
   Liu S, 2022, 10 INT C LEARNING RE, V0, P0
   Lu Jiasen, 2022, ABS220608916 CORR, V0, P0
   Lu ZY, 2020, PATTERN RECOGN LETT, V133, P173, DOI 10.1016/j.patrec.2020.03.007
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Niu YL, 2021, PROC CVPR IEEE, V0, PP12695, DOI 10.1109/CVPR46437.2021.01251
   Pan J, 2022, ABS220705703 CORR, V0, P0
   Sharma H, 2021, IMAGE VISION COMPUT, V116, P0, DOI 10.1016/j.imavis.2021.104327
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Teney D, 2018, PROC CVPR IEEE, V0, PP4223, DOI 10.1109/CVPR.2018.00444
   Urooj Aisha, 2021, IEEE C COMP VIS PATT, V0, P8465
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Zirui, 2022, 10 INT C LEARN REPR, V0, P0
   Whitehead S, 2021, PROC CVPR IEEE, V0, PP5628, DOI 10.1109/CVPR46437.2021.00558
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xiujun I, 2020, ECCV, V0, P0
   Zhang G, 2022, ABS220306883 CORR, V0, P0
   Zhang PC, 2021, PROC CVPR IEEE, V0, PP5575, DOI 10.1109/CVPR46437.2021.00553
   Zhong HS, 2021, IEEE T MULTIMEDIA, V23, P1264, DOI 10.1109/TMM.2020.2995278
   Zhou YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP2054, DOI 10.1109/ICCV48922.2021.00208
   Zhu X, 2021, 9 INT C LEARNING REP, V0, P0
NR 38
TC 1
Z9 1
U1 5
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD JUL 15
PY 2023
VL 171
IS 
BP 53
EP 60
DI 10.1016/j.patrec.2023.04.003
EA MAY 2023
PG 8
WC Computer Science, Artificial Intelligence
SC Computer Science
GA I3KA6
UT WOS:001001789700001
DA 2023-11-10
ER

PT J
AU Haq, I
   Qiu, WD
   Guo, J
   Tang, P
AF Haq, Ijazul
   Qiu, Weidong
   Guo, Jie
   Tang, Peng
TI Pashto offensive language detection: a benchmark dataset and monolingual Pashto BERT
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE BERT; Large language models; Low-resource languages; NLP; Offensive language detection; Pashto; Social media; Osn; Text processing; LLMs
AB Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: "offensive"and "not offensive". To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%.
C1 [Haq, Ijazul; Qiu, Weidong; Guo, Jie; Tang, Peng] Shanghai Jiao Tong Univ, Sch Cyber Sci & Engn, Shanghai, Minhang, Peoples R China.
C3 Shanghai Jiao Tong University
RP Haq, I (通讯作者)，Shanghai Jiao Tong Univ, Sch Cyber Sci & Engn, Shanghai, Minhang, Peoples R China.
EM hanjie@sjtu.edu.cn
CR Alakrot A, 2018, PROCEDIA COMPUT SCI, V142, P315, DOI 10.1016/j.procs.2018.10.491
   Benítez-Andrades JA, 2022, PEERJ COMPUT SCI, V8, P0, DOI 10.7717/peerj-cs.906
   Ali R, 2022, COMPUT SPEECH LANG, V74, P0, DOI 10.1016/j.csl.2022.101365
   Allan J, 2013, CONSTITUTIONAL COMME, V29, P59
   Alsafari Safa, 2020, ONLINE SOCIAL NETWORKS AND MEDIA, V0, P0, DOI DOI 10.1016/j.osnem.2020.100096
   Althobaiti MJ, 2022, INT J ADV COMPUT SC, V13, P972
   Anand M, 2023, THEOR COMPUT SCI, V943, P203, DOI 10.1016/j.tcs.2022.06.020
   Aragon ME, 2019, IBERLEF SEPLN, V0, P478
   Ataei TS, 2022, IEEE T AFFECTIVE COM, V0, P0, DOI DOI 10.1109/taffc.2022.3219229
   Basile V, 2019, P 13 INT WORKSH SEM, V0, P54
   Pereira-Kohatsu JC, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19214654
   Chen Y, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, V0, P0
   Cohen-Almagor R, 2011, POLICY INTERNET, V3, P0, DOI 10.2202/1944-2866.1059
   Conneau A, 2020, ARXIV, V0, P0
   Dadvar Maral, 2013, ADVANCES IN INFORMATION RETRIEVAL. 35TH EUROPEAN CONFERENCE ON IR RESEARCH, V0, P693, DOI 10.1007/978-3-642-36973-5_62
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Del Vigna F, 2017, P 1 IT C CYB ITASEC1, V0, PP86, DOI 10.1051/matecconf/201712502035
   Deng JW, 2022, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   El-Alami FZ, 2022, J KING SAUD UNIV-COM, V34, P6048, DOI 10.1016/j.jksuci.2021.07.013
   Haq I, 2023, SPEECH COMMUN, V153, P0, DOI 10.1016/j.specom.2023.102970
   Haq I, 2023, INT J ADV COMPUT SC, V14, P1344
   Husain F, 2022, INT CONF ASIAN LANG, V0, PP196, DOI 10.1109/IALP57159.2022.9961263
   Hussain S, 2022, PEERJ COMPUT SCI, V8, P0, DOI 10.7717/peerj-cs.1169
   Ibrohim MO, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, V0, P46
   Iqbal S, 2022, J INTERNET TECHNOL, V23, P1669, DOI 10.53106/160792642022122307021
   Jay T, 2008, J POLITENESS RES-LAN, V4, P267, DOI 10.1515/JPLR.2008.013
   Khan S, 2022, J KING SAUD UNIV-COM, V34, P4335, DOI 10.1016/j.jksuci.2022.05.006
   Kudo T, 2018, ARXIV, V0, P0
   Kumar R, 2018, P 1 WORKSH TROLL AGG, V0, P1
   Lepe-Faúndez M, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app112210706
   Liu YH, 2019, ARXIV, V0, P0
   Machová K, 2022, SENSORS-BASEL, V22, P0, DOI 10.3390/s22176468
   Mandl T, 2019, ACM INT CONF PR SER, V0, PP14, DOI 10.1145/3368567.3368584
   Mazari AC, 2023, CLUSTER COMPUT, V0, P0, DOI DOI 10.1007/s10586-022-03956-x
   Min CR, 2023, INFORM FUSION, V96, P214, DOI 10.1016/j.inffus.2023.03.015
   Mubarak H, 2017, ALW ACL, V0, P0
   Ozberk Anil, 2021, 2021 6TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), V0, PP517, DOI 10.1109/UBMK52708.2021.9559000
   Pitenis Z, 2020, ARXIV, V0, P0
   Raj C, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10222810
   Ranasinghe T, 2021, T ASIAN LOW RESOURCE, V21, P1
   Risch J, 2021, P GERMEVAL 2021 SHAR, V0, P1
   Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1668
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Subramanian M, 2022, COMPUT SPEECH LANG, V76, P0, DOI 10.1016/j.csl.2022.101404
   Vasantharajan C, 2022, SN COMPUTER SCI, V0, PP94, DOI 10.1007/s42979-021-00977-y
   Wadud MAH, 2023, COMPUT SYST SCI ENG, V44, P1775, DOI 10.32604/csse.2023.027841
   Zampieri M, 2019, ARXIV, V0, P0
NR 48
TC 0
Z9 0
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD OCT 18
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1617
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA U9CW2
UT WOS:001087716100002
DA 2023-11-10
ER

PT J
AU Liguori, P
   Improta, C
   Natella, R
   Cukic, B
   Cotroneo, D
AF Liguori, Pietro
   Improta, Cristina
   Natella, Roberto
   Cukic, Bojan
   Cotroneo, Domenico
TI Who evaluates the evaluators? On automatic metrics for assessing AI-based offensive code generators
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE AI -based code generators; Offensive code; Neural machine translation; Software security; Output similarity metrics
AB AI-based code generators are an emerging solution for automatically writing programs starting from descriptions in natural language, by using deep neural networks (Neural Machine Translation, NMT). In particular, code generators have been used for ethical hacking and offensive security testing by generating proof-ofconcept attacks. Unfortunately, the evaluation of code generators still faces several issues. The current practice uses output similarity metrics, i.e., automatic metrics that compute the textual similarity of generated code with ground-truth references. However, it is not clear what metric to use, and which metric is most suitable for specific contexts. This work analyzes a large set of output similarity metrics on offensive code generators. We apply the metrics on two state-of-the-art NMT models using two datasets containing offensive assembly and Python code with their descriptions in the English language. We compare the estimates from the automatic metrics with human evaluation and provide practical insights into their strengths and limitations.
C1 [Liguori, Pietro; Improta, Cristina; Natella, Roberto; Cotroneo, Domenico] Univ Naples Federico II, Naples, Italy.
   [Cukic, Bojan] Univ N Carolina, Charlotte, NC USA.
C3 University of Naples Federico II; University of North Carolina; University of North Carolina Charlotte
RP Improta, C (通讯作者)，Univ Naples Federico II, Naples, Italy.
EM pietro.liguori@unina.it; cristina.improta@unina.it; roberto.natella@unina.it; bcukic@uncc.edu; cotroneo@unina.it
FU University of Naples Federico II [PROT: 34938_07_04_2021, UGOV: 000010-ALTRI_CdA_75_2021_FRA_ LINEA_B_001_002];  [CUP: E55F21000340005]
CR Agashe R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5436
   Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2655
   Ahmed T, 2022, PROC INT CONF SOFTW, V0, PP1443, DOI 10.1145/3510003.3510049
   Akinobu Yuka, 2021, BCNC 2021: PROCEEDINGS OF THE 1ST ACM SIGPLAN INTERNATIONAL WORKSHOP ON BEYOND CODE: NO CODE, V0, PP23, DOI 10.1145/3486949.3486966
   Akinobu Y, 2022, J INF PROCESS SYST, V30, P443
   [Anonymous], 1895, P R SOC LONDON, V0, P0, DOI DOI 10.1098/RSPL.1895.0041
   [Anonymous], 2008, P 4 INT WORKSHOP PRE, V0, P0
   Arce I, 2004, IEEE SECUR PRIV, V2, P72, DOI 10.1109/MSP.2004.87
   Bahdanau D, 2016, ARXIV, V0, P0
   Bao T, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, V0, P845
   Bird Steven, 2006, P COLING ACL 2006 IN, V0, PP69, DOI 10.3115/1225403.1225421
   Chakraborty Saikat, 2022, ESEC/FSE 2022: PROCEEDINGS OF THE 30TH ACM JOINT EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP18, DOI 10.1145/3540250.3549162
   Check Point Blog, 2023, CHECK POINT BLOG, V0, P0
   Chen M, 2021, ARXIV, V0, P0
   Clement CB, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9052
   Ding SHH, 2019, P IEEE S SECUR PRIV, V0, PP472, DOI 10.1109/SP.2019.00003
   evaluate, 2022, PYTH LIB EV, V0, P0
   Evtikhiev M, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2208.03133
   Feng Zhangyin, 2020, FIND ASS COMP LING E, V0, PP1536, DOI 10.18653/V1/2020.FINDINGS-EMNLP.139
   Gemmell C, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP2005, DOI 10.1145/3397271.3401215
   Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212
   Han L, 2016, ARXIV, V0, P0
   Han L, 2021, P 1 WORKSH MOD TRANS, V0, P15
   Hu X, 2022, ACM T SOFTW ENG METH, V31, P1
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kim DH, 2018, CLIN RADIOL, V73, P439, DOI 10.1016/j.crad.2017.11.015
   Kingma DP, 2014, C TRACK P, V0, P0
   Kulal S, 2019, ADV NEUR IN, V32, P0
   Lavie A, 2007, P 2 WORKSHOP STAT MA, V0, P228
   Li ZW, 2018, NAMED ENTITIES, V0, P41
   Liguori P, 2021, PROC INT SYMP SOFTW, V0, PP321, DOI 10.1109/ISSRE52982.2021.00042
   Liguori P, 2022, AUTOMAT SOFTW ENG, V29, P0, DOI 10.1007/s10515-022-00331-3
   Liguori P, 2021, NLP4PROG 2021: THE 1ST WORKSHOP ON NATURAL LANGUAGE PROCESSING FOR PROGRAMMING (NLP4PROG 2021), V0, P58
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Lin GJ, 2020, P IEEE, V108, P1825, DOI 10.1109/JPROC.2020.2993293
   Ling W, 2016, P 54 ANN M ASS COMP, V1, P0, DOI 10.18653/v1/p16-1057
   Liu H, 2022, IEEE T SOFTWARE ENG, V48, P1268, DOI 10.1109/TSE.2020.3018481
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Mashhadi E, 2021, IEEE WORK CONF MIN S, V0, PP505, DOI 10.1109/MSR52588.2021.00063
   Mirsky Y, 2022, COMPUT SECUR, V0, P0
   Mirsky Y, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3425780
   Modrzejewski M, 2020, P 22 ANN C EUR ASS M, V0, P45
   Mokhov SA, 2014, LECT NOTES COMPUT SC, V8436, P326, DOI 10.1007/978-3-319-06483-3_33
   Moramarco F, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5739
   Munkova Dasa, 2020, PROCEDIA COMPUTER SCIENCE, V171, P1327, DOI 10.1016/j.procs.2020.04.142
   NASM, 2022, NETW ASS NASM, V0, P0
   Neubig G, 2018, C ASS MACH TRANSL AM, V0, P0
   Tran N, 2019, INT C PROGRAM COMPRE, V0, PP165, DOI 10.1109/ICPC.2019.00034
   nltk, 2023, NATURAL LANGUAGE TOO, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Phan LN, 2021, ARXIV, V0, P0
   py_compile, 2023, PYTH COMP PY COMP, V0, P0
   pylcs, 2023, PYTH LIB PYLCS, V0, P0
   Python, 2023, TOK, V0, P0
   Rao S, 2018, P 2018 C N AM CHAPTE, V1, P129, DOI 10.18653/v1/n18-1012
   Ren S, 2020, ARXIV, V0, P0
   rouge, 2021, PYTH ROUGE SCOR IMPL, V0, P0
   Roy D, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 21), V0, PP1105, DOI 10.1145/3468264.3468588
   Salminen Joni, 2020, ARTIFICIAL INTELLIGENCE IN HCI. FIRST INTERNATIONAL CONFERENCE, V0, P0
   Salminen J, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS), VOL 1, P608, DOI 10.5220/0007744706080615
   Scalabrino S, 2021, IEEE T SOFTWARE ENG, V47, P595, DOI 10.1109/TSE.2019.2901468
   Shimorina A, 2018, ARXIV, V0, P0
   Shterionov D, 2018, MACH TRANSL, V32, P217, DOI 10.1007/s10590-018-9220-z
   spaCy, 2023, IND STRENGTH NAT LAN, V0, P0
   Stent A, 2005, LECT NOTES COMPUT SC, V3406, P341
   Stupp C, 2019, FRAUDSTERS USED AI M, V0, P0
   Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 20), V0, PP1433, DOI 10.1145/3368089.3417058
   Takaichi R, 2022, LECT NOTES COMPUTER, V13709, P0
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang Chaozheng, 2022, ESEC/FSE 2022: PROCEEDINGS OF THE 30TH ACM JOINT EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP382, DOI 10.1145/3540250.3549113
   Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P8696
   Yang G, 2023, J SYST SOFTWARE, V197, P0, DOI 10.1016/j.jss.2022.111577
   Yang G, 2022, EUR CON SFTWR MTNCE, V0, PP361, DOI 10.1109/SANER53432.2022.00052
   Yin PC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4553
   Yin PC, 2018, IEEE WORK CONF MIN S, V0, PP476, DOI 10.1145/3196398.3196408
   Yu C, 2022, PROC IEEE INT CONF S, V0, PP82, DOI 10.1109/ICSME55016.2022.00016
   Zeng Zhengran, 2022, ISSTA 2022: PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, V0, PP39, DOI 10.1145/3533767.3534390
   Zhou X, 2021, PROC IEEE INT CONF S, V0, PP425, DOI 10.1109/ICSME52107.2021.00044
NR 78
TC 0
Z9 0
U1 0
U2 0
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 1
PY 2023
VL 225
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120073
EA APR 2023
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA G3EZ0
UT WOS:000988042200001
DA 2023-11-10
ER

PT J
AU Zhao, H
   Li, XQ
   Wang, FL
   Zeng, QT
   Diao, XL
AF Zhao, Hua
   Li, Xiaoqian
   Wang, Fengling
   Zeng, Qingtian
   Diao, Xiuli
TI Incorporating keyword extraction and attention for multi-label text classification
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Multi-label text classification; keyword extraction; attention mechanism; label indicates; natural language processing
AB As one of the fundamental tasks in natural language processing, Multi-Label Text Classification (MLTC) is used to mark one or more relevant labels for a given text from a large set of labels. Existing MLTC methods have increasingly focused on improving classification effectiveness by fusing the correlations of labels. Still, the research suffers from difficulties in comprehensively extracting text features and distinguishing similar labels. This paper proposed a multi-label text classification model based on keyword extraction and attention mechanism. The model proposed using keywords to represent labels, adopting both self-attention and interactive attention mechanisms (between labels and text) to extract text features and create text vectors. Finally, fusing text vectors as the classifier's input. Experiments were conducted on two public datasets and a self-built dataset of illegal advertisements. The experimental results showed that the keyword-based label representation approach proposed in this paper can better obtain label semantics, avoid noise and improve the performance of the multi-label text classification.
C1 [Zhao, Hua; Li, Xiaoqian; Zeng, Qingtian; Diao, Xiuli] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Shandong, Peoples R China.
   [Wang, Fengling] Heze Coll, Coll Comp Sci, Heze, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Heze University
RP Zhao, H (通讯作者)，Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
EM huazhao@sdust.edu.cn
FU Shandong Natural Science Foundation Project [ZR2021MG038]; Special Study on Cultural Tourism of Shandong Social Science Planning [21CLYJ32]; Shandong Postgraduate Education Quality Improvement Plan [SDYJG19075]; Education Quality Improvement Plan [SDYJG19075]; Shandong Education Teaching Research Key Project [2021JXZ010]; National Statistical Science Research Project [2021LY053]; Shandong University of Science and Technology Education and Teaching Research "Stars Plan" Project [QX2021M29]
CR Babbar R, 2017, WSDM17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP721, DOI 10.1145/3018661.3018741
   Bhatia K, 2015, ADV NEURAL INFORM PR, V0, P730
   Hao C, 2022, COMPUTER SYSTEMS APP, V6, P167
   Jain H, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP935, DOI 10.1145/2939672.2939756
   Khandagale S, 2020, MACH LEARN, V109, P2099, DOI 10.1007/s10994-020-05888-2
   Kurata Gakuto, 2016, P C N AM CHAPT ASS C, V0, PP521, DOI 10.18653/v1/N16-1063
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Li L, 2021, KNN BERT FINE TUNING, V0, P0
   Liu H, 2022, SMALL MICROCOMPUTER, V0, P1
   Liu JZ, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP115, DOI 10.1145/3077136.3080834
   Mencía EL, 2008, LECT NOTES ARTIF INT, V5212, P50, DOI 10.1007/978-3-540-87481-2_4
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Pennesi ME, 2018, HUM GENE THER, V29, P1428, DOI 10.1089/hum.2018.014
   Prabhu Y, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP993, DOI 10.1145/3178876.3185998
   [宋泽宇 Song Zeyu], 2022, 模式识别与人工智能 PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V35, P185
   Tagami Y, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP455, DOI 10.1145/3097983.3097987
   Xiao L, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P466
   Xun GX, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1074, DOI 10.1145/3394486.3403151
   Yang C, 2022, COMPUTER ENG APPL, V0, P1
   Yen IEH, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP545, DOI 10.1145/3097983.3098083
   You Ronghui, 2019, NEURIPS, V0, P5812
NR 21
TC 0
Z9 0
U1 5
U2 5
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2023
VL 45
IS 2
BP 2083
EP 2093
DI 10.3233/JIFS-230506
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA O7HK6
UT WOS:001045474700014
DA 2023-11-10
ER

PT J
AU Pellegrini, C
   Navab, N
   Kazi, A
AF Pellegrini, Chantal
   Navab, Nassir
   Kazi, Anees
TI Unsupervised pre-training of graph transformers on patient population graphs
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Pre-training; Transformer; Population graphs; Outcome; disease prediction; Multi-modal data analysis
ID network
AB Pre-training has shown success in different areas of machine learning, such as Computer Vision, Natural Language Processing (NLP), and medical imaging. However, it has not been fully explored for clinical data analysis. An immense amount of clinical records are recorded, but still, data and labels can be scarce for data collected in small hospitals or dealing with rare diseases. In such scenarios, pre-training on a larger set of unlabeled clinical data could improve performance. In this paper, we propose novel unsupervised pre-training techniques designed for heterogeneous, multi-modal clinical data for patient outcome prediction inspired by masked language modeling (MLM), by leveraging graph deep learning over population graphs. To this end, we further propose a graph-transformer-based network, designed to handle heterogeneous clinical data. By combining masking-based pre-training with a transformer-based network, we translate the success of masking -based pre-training in other domains to heterogeneous clinical data. We show the benefit of our pre-training method in a self-supervised and a transfer learning setting, utilizing three medical datasets TADPOLE, MIMIC -III, and a Sepsis Prediction Dataset. We find that our proposed pre-training methods help in modeling the data at a patient and population level and improve performance in different fine-tuning tasks on all datasets.
C1 [Pellegrini, Chantal; Navab, Nassir; Kazi, Anees] Tech Univ Munich, Comp Aided Med Procedures, Munich, Germany.
   [Navab, Nassir] Johns Hopkins Univ, Comp Aided Med Procedures, Baltimore, MD USA.
   [Kazi, Anees] Harvard Med Sch, Massachusetts Gen Hosp, Cambridge, MA USA.
   [Kazi, Anees] Tech Univ Munich, Munich, Germany.
C3 Technical University of Munich; Johns Hopkins University; Harvard University; Massachusetts General Hospital; Technical University of Munich
RP Pellegrini, C (通讯作者)，Tech Univ Munich, Comp Aided Med Procedures, Munich, Germany.
EM chantal.pellegrini@tum.de
FU BigPicture; Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes of Health ); DOD ADNI; National Institute on Aging; National Institute of Biomedical Imaging and Bioengineering; AbbVie; Alzheimer's Association; Alzheimer's Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharma-ceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd; Genentech, Inc.; Fujirebio [U01 AG024904]; GE Healthcare [W81XWH-12-2-0012]; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research amp; Development, LLC; Johnson amp; Johnson Pharmaceutical Research amp; Development LLC; Lumosity; Lundbeck; Merck amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; Transition Therapeutics; ADNI clinical sites in Canada; Northern California Institute for Research and Education
CR Agrawal MN, 2022, INT C ARTIFICIAL INT, V0, P2330
   Ahmedt-Aristizabal D, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21144758
   Alsentzer E, 2019, ARXIV, V0, P0
   [Anonymous], 2022, MSE L2, V0, P0
   [Anonymous], 2022, CROSS ENTR, V0, P0
   Bai WJ, 2019, LECT NOTES COMPUT SC, V11765, P541, DOI 10.1007/978-3-030-32245-8_60
   Bao Hangbo, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2106.08254
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen L, 2019, MED IMAGE ANAL, V58, P0, DOI 10.1016/j.media.2019.101539
   Cheng Ouyang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12374), V0, PP762, DOI 10.1007/978-3-030-58526-6_45
   Cohen JP, 2022, P MACHINE LEARNING R, V172, P231
   Cosmo Luca, 2020, MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI 2020. 23RD INTERNATIONAL CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12262), V0, PP643, DOI 10.1007/978-3-030-59713-9_62
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ghorbani M, 2022, MED IMAGE ANAL, V75, P0, DOI 10.1016/j.media.2021.102272
   Goldberger AL, 2000, CIRCULATION, V101, PE215, DOI 10.1161/01.CIR.101.23.e215
   Gupta P, 2020, J HEALTHC INFORM RES, V4, P112, DOI 10.1007/s41666-019-00062-3
   Han X, 2021, OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002
   He Y, 2020, ARXIV, V0, P0
   Hu W, 2020, INT C LEARN REPR ICL, V0, P0
   Hu ZN, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1857, DOI 10.1145/3394486.3403237
   Johnson A, 2020, MIMIC 4 PHYSIONET, V0, P0
   Johnson AEW, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0322-0
   Johnson AEW, 2016, SCI DATA, V3, P0, DOI 10.1038/sdata.2016.35
   Joulin A, 2017, ICML, V0, P0
   Kazi A, 2021, ARXIV, V0, P0
   Kazi A, 2023, IEEE T PATTERN ANAL, V45, P1606, DOI 10.1109/TPAMI.2022.3170249
   Kazi A, 2019, I S BIOMED IMAGING, V0, PP1896, DOI 10.1109/ISBI.2019.8759274
   Kazi A, 2019, LECT NOTES COMPUT SC, V11492, P73, DOI 10.1007/978-3-030-20351-1_6
   Kingma DP, 2014, C TRACK P, V0, P0
   Komodakis Nikos, 2018, INT C LEARNING REPRE, V0, P0
   Landi I, 2020, NPJ DIGIT MED, V3, P0, DOI 10.1038/s41746-020-0301-z
   Li YK, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-62922-y
   Liu X, 2023, IEEE T KNOWL DATA EN, V35, P857, DOI 10.1109/TKDE.2021.3090866
   Liu YH, 2019, ARXIV, V0, P0
   Lu Y, 2021, LEARNING PRETRAIN GR, V0, P0
   Ma QP, 2021, MOL IMAGING BIOL, V23, P572, DOI 10.1007/s11307-021-01578-0
   Malhotra P, 2017, ARXIV, V0, P0
   Marinescu RV, 2018, ARXIV, V0, P0
   McDermott Matthew, 2021, CHIL 21: PROCEEDINGS OF THE CONFERENCE ON HEALTH, V0, P0
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mitani AA, 2020, JAMA NETW OPEN, V3, P0, DOI 10.1001/jamanetworkopen.2020.1965
   Kipf TN, 2017, ARXIV, V0, P0
   Noortman WA, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0239438
   Pang C, 2021, MACHINE LEARNING HLT, V0, P239
   Parisot S, 2018, MED IMAGE ANAL, V48, P117, DOI 10.1016/j.media.2018.06.001
   Park S, 2022, P C HLTH INFERENCE L, V174, P261
   Pathak D, 2016, PROC CVPR IEEE, V0, PP2536, DOI 10.1109/CVPR.2016.278
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pötsch N, 2021, EUR RADIOL, V31, P5866, DOI 10.1007/s00330-021-07787-z
   Pollard TJ, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2018.178
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Rasmy L, 2021, NPJ DIGIT MED, V4, P0, DOI 10.1038/s41746-021-00455-y
   Reyna MA, 2020, CRIT CARE MED, V48, P210, DOI 10.1097/CCM.0000000000004145
   Rong Y, 2020, ADV NEURAL INF PROCE, V0, P0
   Shang JY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5953
   Soenksen LR, 2022, NPJ DIGIT MED, V5, P0, DOI 10.1038/s41746-022-00689-4
   Valenchon J, 2019, INT CONF ACOUST SPEE, V0, PP3157, DOI 10.1109/ICASSP.2019.8683433
   van Timmeren JE, 2017, ACTA ONCOL, V56, P1537, DOI 10.1080/0284186X.2017.1350285
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Velickovic P, 2018, P 6 INT C LEARN REPR, V0, P0
   Verma S, 2019, ARXIV, V0, P0
   Vivar Gerome, 2018, GRAPHS IN BIOMEDICAL IMAGE ANALYSIS AND INTEGRATING MEDICAL IMAGING AND NON-IMAGING MODALITIES. SECOND INTERNATIONAL WORKSHOP, V0, P0
   Wang Shirly, 2020, CHIL 20: PROCEEDINGS OF THE CONFERENCE ON HEALTH, V0, P0
   Wang XY, 2021, LECT NOTES COMPUT SC, V12908, P186, DOI 10.1007/978-3-030-87237-3_18
   Wells Brian J, 2013, EGEMS (WASH DC), V1, P1035, DOI 10.13063/2327-9214.1035
   Xiao C, 2018, J AM MED INFORM ASSN, V25, P1419, DOI 10.1093/jamia/ocy068
   Xie YC, 2023, IEEE T PATTERN ANAL, V45, P2412, DOI 10.1109/TPAMI.2022.3170559
   Xu K, 2018, ARXIV PREPRINT ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1810.00826
   Yang ZL, 2019, ADV NEUR IN, V32, P0
   Ying C, 2021, ADV NEUR IN, V34, P0
   Yongxiang Huang, 2020, MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI 2020. 23RD INTERNATIONAL CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12267), V0, PP562, DOI 10.1007/978-3-030-59728-3_55
   Yu X, 2021, ARXIV, V0, P0
   Zebin T, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY - CIBCB 2019, V0, PP59, DOI 10.1109/cibcb.2019.8791477
   Zhang JW, 2020, ARXIV, V0, P0
   Zheng RC, 2021, BIOMOLECULES, V11, P0, DOI 10.3390/biom11020307
NR 77
TC 0
Z9 0
U1 6
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD OCT 15
PY 2023
VL 89
IS 
BP 
EP 
DI 10.1016/j.media.2023.102895
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA O9GR6
UT WOS:001046836000001
PM 37473609
DA 2023-11-10
ER

PT J
AU Saleh, H
   Alhothali, A
   Moria, K
AF Saleh, Hind
   Alhothali, Areej
   Moria, Kawthar
TI Detection of Hate Speech using BERT and Hate Speech Word Embedding with Deep Model
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
AB There is an increased demand for detecting online hate speech, especially with the recent changing policies of hate content and free-of-speech right of online social media platforms. Detecting hate speech will reduce its negative impact on social media users. A lot of effort in the Natural Language Processing (NLP) field aimed to detect hate speech in general or detect specific hate speech such as religion, race, gender, or sexual orientation. Hate communities tend to use abbreviations, intentional spelling mistakes, and coded words in their communication to evade detection, which adds more challenges to hate speech detection tasks. Word representation from its domain will play an increasingly pivotal role in detecting hate speech. This paper investigates the feasibility of leveraging domain-specific word embedding as features and a bidirectional LSTM-based deep model as a classifier to automatically detect hate speech. This approach guarantees that the word is assigned its negative meaning, which is a very helpful technique to detect coded words. Furthermore, we investigate the use of the transfer learning language model (BERT) on the hate speech problem as a binary classification task as it provides high-performance results for many NLP tasks. The experiments showed that domain-specific word embedding with the bidirectional LSTM-based deep model achieved a 93% f1-score, while BERT achieved 96% f1-score on a combined balanced dataset from available hate speech datasets. The results proved that the performance of pre-trained models is influenced by the size of the trained data. Although there is a huge variation in the corpus size, the first approach achieved a very close result compared to BERT, which is trained on a huge data corpus, this is because it is trained on data related to the same domain. The first approach was very helpful to detect coded words while the second approach achieved better performance because it is trained on much larger data. To conclude, it is very helpful to build large pre-trained models from rich domains specific content in current social media platforms.
C1 [Saleh, Hind] Univ Tabuk, Comp Sci Dept, Tabuk, Saudi Arabia.
   [Saleh, Hind; Alhothali, Areej; Moria, Kawthar] King Abdulaziz Univ, Comp Sci Dept, Mecca, Saudi Arabia.
   [Saleh, Hind] King Abdulaziz Univ, Comp Sci Dept, Tabuk, Saudi Arabia.
C3 University of Tabuk; King Abdulaziz University; King Abdulaziz University
RP Saleh, H (通讯作者)，King Abdulaziz Univ, Comp Sci Dept, Tabuk, Saudi Arabia.
EM h.alatwi@ut.edu.sa
CR Abadi M, 2016, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1603.04467
   Agarwal S, 2015, LECT NOTES COMPUT SC, V8956, P431, DOI 10.1007/978-3-319-14977-6_47
   Ailem M, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1081, DOI 10.1145/3077136.3080727
   Al-Azani S, 2017, PROCEDIA COMPUT SCI, V109, P359, DOI 10.1016/j.procs.2017.05.365
   Albadi N, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), V0, PP69, DOI 10.1109/ASONAM.2018.8508247
   Badjatiya P, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP759, DOI 10.1145/3041021.3054223
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Clement J, 2019, US TEENS HATE SPEECH, V0, P0
   CUDA&REG; NVIDIA, 2020, NVIDIA CUDNN NVIDIA, V0, P0
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   De Smedt T, 2018, ARXIV, V0, P0
   Demilie WB, 2022, J BIG DATA-GER, V9, P1
   Devlin J, 2019, ARXIV, V0, P0
   Djuric N, 2015, WWW15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP29, DOI 10.1145/2740908.2742760
   Duggan M, 2017, ONLINE HARASSMENT 20, V0, P0
   Peters ME, 2018, ARXIV, V0, P0
   Ferrara E, 2016, LECT NOTES COMPUT SC, V10047, P22, DOI 10.1007/978-3-319-47874-6_3
   Fortuna P, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3232676
   Founta A-M, 2018, P 12 INT AAAI C WEB, V12, P491
   Gamback B, 2017, P 1 WORKSHOP ABUSIVE, V0, PP85, DOI 10.18653/v1/W17-3013
   Gialampoukidis I, 2017, P 2 INT WORKSH MULT, V0, PP21, DOI 10.1145/3078897.3080534
   Gibert OD, 2018, ARXIV, V0, P0
   Golbeck J, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI 17), V0, PP229, DOI 10.1145/3091478.3091509
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gupta S, 2017, COMP STUDY EMBEDDING, V0, P0
   Hartung M, 2017, LECT NOTES COMPUT SC, V10260, P320, DOI 10.1007/978-3-319-59569-6_40
   Inc HateBase, 2020, HATEBASE, V0, P0
   Jaki S, 2019, ARXIV, V0, P0
   League AD, 2019, ONLINE HATE HARASSME, V0, P0
   Li CY, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), V0, PP121, DOI 10.1109/ICCSNT.2015.7490719
   Lilleberg J, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), V0, PP136, DOI 10.1109/ICCI-CC.2015.7259377
   Liu A, 2018, NEURAL NETWORK MODEL, V0, P0
   Ltd We Are Social, 2020, DIG 2020, V0, P0
   Magu R, 2017, P INT AAAI C WEB SOC, V0, PP608, DOI 10.1609/ICWSM.V11I1.14921
   Mikolov T, 2013, ARXIV, V0, P0
   Mozafari M, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0237861
   Nobata C, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16), V0, PP145, DOI 10.1145/2872427.2883062
   Pelicon A, 2019, P 13 INT WORKSHOP SE, V0, PP604, DOI 10.18653/v1/S19-2108
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pitsilis GK, 2018, APPL INTELL, V48, P4730, DOI 10.1007/s10489-018-1242-y
   Rajpurkar P, 2016, ARXIV, V0, P0
   Ribeiro MH, 2017, ARXIV, V0, P0
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Siencnik SK, 2015, P 20 NORD C COMP LIN, V0, P239
   Socher Richard, 2012, TUTORIAL ABSTRACTS A, V0, P5
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Wang AL, 2019, ARXIV, V0, P0
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wang PL, 2015, ARXIV, V0, P0
   Waseem Z, 2016, WORKSH NLP COMP SOC, V0, P138
   Waseem Zeerak, 2016, P NAACL STUD RES WOR, V0, PP88, DOI 10.18653/V1/N16-2013
   Weber A, 2009, MANUAL HATE SPEECH, V0, P0
   Wei YF, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, V0, PP1251, DOI 10.1109/ASONAM.2016.7752398
   Williams A, 2018, ARXIV, V0, P0
   Wu Y, 2015, P BIONLP, V15, P171
   Zhang ZQ, 2018, LECT NOTES COMPUT SC, V10843, P745, DOI 10.1007/978-3-319-93417-4_48
   Zhu J, 1900, P788, V0, P0
NR 57
TC 4
Z9 4
U1 20
U2 41
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD DEC 31
PY 2023
VL 37
IS 1
BP 
EP 
DI 10.1080/08839514.2023.2166719
PG 22
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 8M3IX
UT WOS:000924364300001
DA 2023-11-10
ER

PT J
AU Almasri, M
   Al-Malki, N
   Alotaibi, R
AF Almasri, Miada
   Al-Malki, Norah
   Alotaibi, Reem
TI A semi supervised approach to Arabic aspect category detection using Bert and teacher-student model
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE BERT; Transformer; AraBERT; Sentiment Analysis; Teacher model; Noisy Student model; Aspect Category Detection
ID sentiment analysis
AB Aspect-based sentiment analysis tasks are well researched in English. However, we find such research lacking in the context of the Arabic language, especially with reference to aspect category detection. Most of this research is focusing on supervised machine learning methods that require the use of large, labeled datasets. Therefore, the aim of this research is to implement a semi-supervised self-training approach which utilizes a noisy student framework to enhance the capability of a deep learning model, AraBERT v02. The objective is to perform aspect category detection on both the SemEval 2016 hotel review dataset and the Hotel Arabic-Reviews Dataset (HARD) 2016. The fourstep framework firstly entails developing a teacher model that is trained on the aspect categories of the SemEval 2016 labeled dataset. Secondly, it generates pseudo labels for the unlabeled HARD dataset based on the teacher model. Thirdly, it creates a noisy student model that is trained on the combined datasets (similar to 1 million sentences). The aim is to minimize the combined cross entropy loss. Fourthly, an ensembling of both teacher and student models is carried out to enhance the performance of AraBERT. Findings indicate that the ensembled teacher-student model demonstrates a 0.3% improvement in its micro F1 over the initial noisy student implementation, both in predicting the Aspect Categories in the combined datasets. However, it has achieved a 1% increase over the micro F1 of the teacher model. These results outperform both baselines and other deep learning models discussed in the related literature.
C1 [Almasri, Miada; Alotaibi, Reem] King Abdulaziz Univ, Fac Comp & Informat Technol, Informat Technol Dept, Jeddah, Saudi Arabia.
   [Al-Malki, Norah] King Abdulaziz Univ, Fac Arts & Humanities, European Languages Dept, Jeddah, Saudi Arabia.
C3 King Abdulaziz University; King Abdulaziz University
RP Al-Malki, N (通讯作者)，King Abdulaziz Univ, Fac Arts & Humanities, European Languages Dept, Jeddah, Saudi Arabia.
EM malmasre@kau.edu.sa
FU Deanship of Scientific Research (DSR), King Abdulaziz University, Saudi Arabia, Jeddah [J-003-612-1443]
CR Abdelgwad MM, 2022, J BIG DATA-GER, V9, P0, DOI 10.1186/s40537-022-00656-6
   Abdulwahhab Baha al, 2019, AL QADISIYAH J COMPU, V11, P22, DOI 10.29304/jqcm.2019.11.2.559
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Al-Smadi M, 2016, INT CONF INTERNET, V0, PP98, DOI 10.1109/ICITST.2016.7856675
   [Anonymous], 2016, 10 INT WORKSHOP SEMA, V0, P0
   Antoun W, 2021, ARXIV, V0, P0
   Winatmoko YA, 2020, ARXIV, V0, P0
   Bensoltane Rajae, 2021, E3S WEB OF CONFERENCES, V297, P0, DOI 10.1051/e3sconf/202129701072
   Bhat MM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P10702
   Chauhan GS, 2020, EXPERT SYST APPL, V161, P0, DOI 10.1016/j.eswa.2020.113673
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Dragoni M, 2019, INFORM PROCESS MANAG, V56, P1103, DOI 10.1016/j.ipm.2018.04.010
   Du JF, 2020, ARXIV, V0, P0
   Du JY, 2021, COGN COMPUT, V13, P1114, DOI 10.1007/s12559-021-09855-4
   Elnagar A, 2018, INTELLIGENT NATURAL, V0, P35
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Herrera F, 2016, MULTILABEL CLASSIFIC, V0, PP17, DOI 10.1007/978-3-319-41111-8
   Kumar JA, 2021, COGN COMPUT, V13, P1423, DOI 10.1007/s12559-021-09948-0
   Licai Sun, 2020, MUSE20: PROCEEDINGS OF THE 1ST INTERNATIONAL MULTIMODAL SENTIMENT ANALYSIS IN REAL-LIFE MEDIA CHALLENGE AND WORKSHOP, V0, PP27, DOI 10.1145/3423327.3423672
   Majumder N, 2022, NEURAL COMPUT APPL, V34, P8333, DOI 10.1007/s00521-020-05287-7
   Mowlaei ME, 2020, EXPERT SYST APPL, V148, P0, DOI 10.1016/j.eswa.2020.113234
   Mukherjee Subhabrata, 2020, NEURIPS, V0, P0
   Ozyurt B, 2021, EXPERT SYST APPL, V168, P0, DOI 10.1016/j.eswa.2020.114231
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Pathak A, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10212641
   Pavlinek M, 2017, EXPERT SYST APPL, V80, P83, DOI 10.1016/j.eswa.2017.03.020
   Pontiki Maria, 2016, SEMEVAL 2016, V0, P0
   Qizhe Xie, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10684, DOI 10.1109/CVPR42600.2020.01070
   Ramezani S, 2020, P ACM SIGIR WORKSHOP, V0, P0
   Smith LN, 2017, IEEE WINT CONF APPL, V0, PP464, DOI 10.1109/WACV.2017.58
   Sun Q, 2019, ENG APPL ARTIF INTEL, V81, P68, DOI 10.1016/j.engappai.2019.02.004
   Tao J, 2020, J BIG DATA-GER, V7, P0, DOI 10.1186/s40537-019-0278-0
   Triguero I, 2015, KNOWL INF SYST, V42, P245, DOI 10.1007/s10115-013-0706-y
   Valdivia A, 2020, J AMB INTEL HUM COMP, V11, P39, DOI 10.1007/s12652-018-1150-3
   van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6
   Van Thin D, 2021, ARXIV, V0, P0
   Xing Fang, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, V0, P478, DOI 10.1109/SNAMS.2019.8931817
   Xu H, 2019, ARXIV, V0, P0
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang XY, 2020, ARXIV, V0, P0
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
   Zhu XJ, 2005, SEMISUPERVISED LEARN, V0, P0
   Zhuang HL, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP1241, DOI 10.1145/3397271.3401179
NR 44
TC 0
Z9 0
U1 1
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUN 8
PY 2023
VL 9
IS 
BP 
EP 
DI 10.7717/peerj-cs.1425
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA J4NA9
UT WOS:001009384900002
PM 37346563
DA 2023-11-10
ER

PT J
AU Kamimura, R
AF Kamimura, Ryotaro
TI Contradiction neutralization for interpreting multi-layered neural networks
SO APPLIED INTELLIGENCE
LA English
DT Article; Early Access
DE Neutralization; Contradiction; Comprehensive; Nullified; Compressive; Collective; Human-centered bias
ID mutual information; binocular interaction; selectivity; interpretability; representations; regularization; ensemble; model
AB The present paper aims to propose a new method for neutralizing contradictions in neural networks. Neural networks exhibit numerous contradictions in the form of contrasts, differences, and errors, making it extremely challenging to find a compromise between them. In this context, neutralization is introduced not to resolve these contradictions, but to weaken them by transforming them into more manageable and concrete forms. In this paper, contradictions are neutralized or weakened through four neutralization methods: comprehensive, nullified, compressive, and collective. Comprehensive neutralization involves increasing the neutrality of all components in a neural network. Nullified neutralization is employed to weaken contradictions among different computational and optimization procedures. Compressive neutralization aims to simplify multi-layered neural networks while preserving the original internal information as much as possible. Collective neutralization is achieved by considering as many final networks as possible under different conditions, inputs, learning steps, and so on. The proposed method was applied to two data sets, one of which consisted of irregular forms resulting from natural language processing. The experimental results demonstrate that comprehensive neutralization could enhance the neutrality of all components and represent features across a broader range of components, thereby improving generalization. Nullified neutralization enabled a compromise between neutrality maximization and error minimization. Through compressive and collective neutralization of a large number of compressed weights, it became possible to interpret compressed and collective weights. In particular, inputs that were considered relatively unimportant by conventional methods emerged as highly significant. Finally, these results were compared with those obtained in the field of the human-centered approach to provide a clearer understanding of the significance of contradiction resolution, applied to neural networks.
C1 [Kamimura, Ryotaro] Tokai Univ, 1117 Kitakaname, Hiratsuka, Kanagawa 2591292, Japan.
   [Kamimura, Ryotaro] Kumamoto Drone Technol & Dev, Nishi Ku, Kamimatsuo, Kumamoto 8615289, Japan.
C3 Tokai University
RP Kamimura, R (通讯作者)，Tokai Univ, 1117 Kitakaname, Hiratsuka, Kanagawa 2591292, Japan.; Kamimura, R (通讯作者)，Kumamoto Drone Technol & Dev, Nishi Ku, Kamimatsuo, Kumamoto 8615289, Japan.
EM ryo@keyaki.cc.u-tokai.ac.jp
FU The author would like to thank Mitali Das for correcting and revising the paper.
CR Amjad RA, 2020, IEEE T PATTERN ANAL, V42, P2225, DOI 10.1109/TPAMI.2019.2909031
   Arbabzadah F, 2016, LECT NOTES COMPUT SC, V9796, P344, DOI 10.1007/978-3-319-45886-1_28
   Bach S, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0130140
   Barak O, 2013, J NEUROSCI, V33, P3844, DOI 10.1523/JNEUROSCI.2753-12.2013
   BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32, DOI 10.1523/jneurosci.02-01-00032.1982
   Binder A, 2016, LECT NOTES COMPUT SC, V9887, P63, DOI 10.1007/978-3-319-44781-0_8
   Bucilua C, 2006, P 12 ACM SIGKDD INT, V0, PP535, DOI 10.1145/1150402.1150464
   Cadieu C, 2007, J NEUROPHYSIOL, V98, P1733, DOI 10.1152/jn.01265.2006
   Capone L, 2020, XAI IT AI IA, V0, P80
   Chalk M, 2016, ADV NEURAL INF PROCE, V29, P1957
   Chen X, 2016, ADV NEURAL INF PROCE, V29, P0
   Cover T, 2006, ELEMENTS INFORM THEO, V2nd ed., P0
   DECO G, 1995, NEURAL COMPUT, V7, P86, DOI 10.1162/neco.1995.7.1.86
   Deco G, 1997, NEURAL NETWORKS, V10, P683, DOI 10.1016/S0893-6080(96)00110-4
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Erhan Dumitru, 2009, TECHNICAL REPORT, V0, P0
   Fritschek R, 2019, IEEE INT WORK SIGN P, V0, P0, DOI DOI 10.1109/spawc.2019.8815464
   Gabrié M, 2018, ADV NEUR IN, V31, P0
   Garibay OO, 2023, INT J HUM-COMPUT INT, V0, P0, DOI DOI 10.1080/10447318.2022.2153320
   Dos Santos CFG, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3510413
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P221
   Gunasekar S, 2018, 2018 INFORMATION THEORY AND APPLICATIONS WORKSHOP (ITA), V0, P0
   Hall ET, 1976, CULTURE, V0, P0
   Hinton G, 2015, ARXIV, V0, P0
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Ilyas A, 2019, ADV NEUR IN, V32, P0
   Jehee JFM, 2012, J NEUROSCI, V32, P16747, DOI 10.1523/JNEUROSCI.6112-11.2012
   Kenji U, 2021, TEXT MINING, V0, P0
   Koch-Janusz M, 2018, NAT PHYS, V14, P578, DOI 10.1038/s41567-018-0081-4
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kohonen T, 1995, SELF ORG MAPS, V0, P0, DOI DOI 10.1007/978-3-642-56927-2
   Kolchinsky A, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21121181
   KROGH A, 1992, ADV NEUR IN, V4, P950
   Krueger David, 2021, INT C MACH LEARN, V0, P5815
   Kuang K, 2020, AAAI CONF ARTIF INTE, V34, P4485
   Kukacka J, 2017, ARXIV, V0, P0
   Lake BM, 2017, BEHAV BRAIN SCI, V40, P0, DOI 10.1017/S0140525X16001837
   Langley P, 2022, AAAI CONF ARTIF INTE, V0, P12268
   Lapuschkin S, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-08987-4
   Lapuschkin S, 2016, PROC CVPR IEEE, V0, PP2912, DOI 10.1109/CVPR.2016.318
   Lin G-Y, 2022, P 2022 C EMP METH NA, V0, P6303
   Liu L, 2019, 2019 IEEE 16TH INTERNATIONAL CONFERENCE ON MOBILE AD HOC AND SMART SYSTEMS (MASS 2019), V0, PP274, DOI 10.1109/MASS.2019.00040
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Luo P, 2016, AAAI CONF ARTIF INTE, V0, P3560
   Mahendran A, 2015, PROC CVPR IEEE, V0, PP5188, DOI 10.1109/CVPR.2015.7299155
   McClelland JL, 1986, PARALLEL DISTRIBUTED, V2, P216, DOI 10.7551/MITPRESS/5237.001.0001
   Meng QJ, 2021, IEEE T MED IMAGING, V40, P722, DOI 10.1109/TMI.2020.3035424
   Miller John P, 2021, INT C MACH LEARN, V0, P7721
   Molavipour S, 2020, INT CONF ACOUST SPEE, V0, PP5025, DOI 10.1109/ICASSP40776.2020.9053422
   Montavon G, 2019, EXPLAINABLE INTERPRE, V0, PP193, DOI 10.1007/978-3-030-28954-6_10
   Nguyen A, 2019, EXPLAINABLE AI INTER, V11700, P55, DOI 10.1007/978-3-030-28954-6
   Ohno S, 2013, CONFERENCE PROCEEDINGS OF 2013 ASIA-PACIFIC CONFERENCE ON SYNTHETIC APERTURE RADAR (APSAR), V0, P601
   Oliva A, 2019, EXPLAINABLE AI INTER, V0, PP243, DOI 10.1007/978-3-030-28954-6_12
   Razin N, 2020, ADV NEURAL INF PROCE, V33, P21174
   RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5
   Schoups A, 2001, NATURE, V412, P549, DOI 10.1038/35087601
   Sengupta E, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART), V0, PP226, DOI 10.1109/SYSMART.2018.8746946
   Shen ZY, 2020, AAAI CONF ARTIF INTE, V34, P5692
   Shimizu K, 2009, MULTIVARIATE ANAL, V0, P0
   Steinke T, 2020, C LEARN THEOR, V0, P3437
   Sturm I, 2016, J NEUROSCI METH, V274, P141, DOI 10.1016/j.jneumeth.2016.10.008
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW), V0, P0
   Tuli S, 2021, ARXIV, V0, P0
   Vessonen E, 2021, SYNTHESE, V199, P10615, DOI 10.1007/s11229-021-03261-x
   Vessonen E, 2021, THEOR PSYCHOL, V31, P84, DOI 10.1177/0959354320945036
   Wall R, 2000, 11 IR C ART INT COGN, V0, P52
   Wang LW, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P3740
   Wang TL, 2019, IEEE I CONF COMP VIS, V0, PP5309, DOI 10.1109/ICCV.2019.00541
   Wang ZQ, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-15158-3
   Wei WQ, 2021, IEEE T DEPEND SECURE, V18, P1513, DOI 10.1109/TDSC.2020.3024660
   White LE, 2001, NATURE, V411, P1049, DOI 10.1038/35082568
   Wu CY, 2018, IEEE-ACM T AUDIO SPE, V26, P256, DOI 10.1109/TASLP.2017.2774919
   Wu M, 2020, AAAI CONF ARTIF INTE, V34, P6413
   Xia Y, 2020, AAAI CONF ARTIF INTE, V34, P1062
   Yang CL, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), V0, PP1563, DOI 10.1109/HPCC/SmartCity/DSS.2018.00256
   Yifan Z, 2019, FRONT ENV SCI-SWITZ, V7, P0, DOI 10.3389/fenvs.2019.00046
   Zhang XX, 2021, PROC CVPR IEEE, V0, PP5368, DOI 10.1109/CVPR46437.2021.00533
   Zhou BL, 2019, IEEE T PATTERN ANAL, V41, P2131, DOI 10.1109/TPAMI.2018.2858759
NR 79
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10489-023-04883
EA OCT 2023
PG 28
WC Computer Science, Artificial Intelligence
SC Computer Science
GA T6YA4
UT WOS:001079407800001
DA 2023-11-10
ER

PT J
AU Zhang, ZS
   Chen, KH
   Wang, R
   Utiyama, M
   Sumita, E
   Li, ZC
   Zhao, H
AF Zhang, Zhuosheng
   Chen, Kehai
   Wang, Rui
   Utiyama, Masao
   Sumita, Eiichiro
   Li, Zuchao
   Zhao, Hai
TI Universal Multimodal Representation for Language Understanding
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Task analysis; Visualization; Machine translation; Feature extraction; Annotations; Transformers; Standards; Artificial intelligence; natural language understanding; vision-language modeling; multimodal machine translation
AB Representation learning is the foundation of natural language processing (NLP). This work presents new methods to employ visual information as assistant signals to general NLP tasks. For each sentence, we first retrieve a flexible number of images either from a light topic-image lookup table extracted over the existing sentence-image pairs or a shared cross-modal embedding space that is pre-trained on out-of-shelf text-image pairs. Then, the text and images are encoded by a Transformer encoder and convolutional neural network, respectively. The two sequences of representations are further fused by an attention layer for the interaction of the two modalities. In this study, the retrieval process is controllable and flexible. The universal visual representation overcomes the lack of large-scale bilingual sentence-image pairs. Our method can be easily applied to text-only tasks without manually annotated multimodal parallel corpora. We apply the proposed method to a wide range of natural language generation and understanding tasks, including neural machine translation, natural language inference, and semantic similarity. Experimental results show that our method is generally effective for different tasks and languages. Analysis indicates that the visual signals enrich textual representations of content words, provide fine-grained grounding information about the relationship between concepts and events, and potentially conduce to disambiguation.
C1 [Zhang, Zhuosheng; Wang, Rui; Li, Zuchao; Zhao, Hai] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Zhang, Zhuosheng; Wang, Rui; Li, Zuchao; Zhao, Hai] Shanghai Jiao Tong Univ, Key Lab, Shanghai Educ Commiss Intelligent Interact & Cogn, Shanghai 200240, Peoples R China.
   [Chen, Kehai] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen 518055, Peoples R China.
   [Utiyama, Masao; Sumita, Eiichiro] NICT, Koganei, Tokyo 1848795, Japan.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Harbin Institute of Technology; National Institute of Information & Communications Technology (NICT) - Japan
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM zhangzs@sjtu.edu.cn; chenkehai@hit.edu.cn; wangrui.nlp@gmail.com; mutiyama@nict.go.jp; eiichiro.sumita@nict.go.jp; charlee@sjtu.edu.cn; zhaohai@cs.sjtu.edu.cn
FU Key Projects of National Natural Science Foundation of China [U1836222, 61733011]; National Natural Science Foundation of China [62276077, 6217020129]; Shanghai Pujiang Program [21PJ1406800]; Shanghai Municipal Science and Technology Major Project [2021SHZDZX0102]; Beijing Academy of Artificial Intelligence (BAAI) [4]; CCF-Baidu Open Fund [CCFBAIDU OF2022018]; Shenzhen College Stability Support Plan [GXWD20220811170358002, GXWD20220817123150002]
CR Abnar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4190
   [Anonymous], 2017, PROC 2 WORKSHOP EVAL, V0, P0
   [Anonymous], 2017, P 4 WORKSHOP ASIAN T, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bentivogli L, 2009, P TAC, V0, P1
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Brown WM, 2003, NAT RESOUR RES, V12, P141, DOI 10.1023/A:1024218913435
   Brownlee J, 2019, MACHINE LEARNING MAS, V0, P0
   Caglayan O, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4159
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Chen KH, 2019, IEEE-ACM T AUDIO SPE, V27, P1970, DOI 10.1109/TASLP.2019.2937190
   Clark K, 2020, PROC 8 INT C LEARN R, V0, P1
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dolan B, 2005, 3 INT WORKSH PAR IWP, V0, P1
   Durand T, 2016, PROC CVPR IEEE, V0, PP4743, DOI 10.1109/CVPR.2016.513
   Elliott D, 2016, P ACL 2016, V0, P70
   Engilberge M, 2018, PROC CVPR IEEE, V0, PP3984, DOI 10.1109/CVPR.2018.00419
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Gao Chenyu, 2022, IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, V44, P9603, DOI 10.1109/TPAMI.2021.3132034
   Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Gronroos S, 2018, P 3 C MACHINE TRANSL, V0, P603
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hewitt J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2566
   Hill F, 2019, PROC 7 INT C LEARN R, V0, P0
   Hong RC, 2022, IEEE T PATTERN ANAL, V44, P684, DOI 10.1109/TPAMI.2019.2911066
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu RH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP1419, DOI 10.1109/ICCV48922.2021.00147
   Ive J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6525
   Iyer Shankar, 2017, 1 QUORA DATASET RELE, V0, P0
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kingma DP, 2017, PROC 3 INT C LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1412.6980
   Kocmi T, 2017, P 14 INT C NATURAL L, V0, P56
   Koehn Philipp, 2004, P 2004 C EMPIRICAL M, V0, P388
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5039
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li XR, 2019, IEEE T MULTIMEDIA, V21, P2347, DOI 10.1109/TMM.2019.2896494
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Lin H, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1320, DOI 10.1145/3394171.3413715
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   Liu YH, 2019, ARXIV, V0, P0
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Ma XZ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4282
   MCDANIEL MA, 1986, J EXP PSYCHOL LEARN, V12, P54, DOI 10.1037/0278-7393.12.1.54
   Meier D, 2000, ACCELERATED LEARNING, V0, P0
   Meng YX, 2019, ADV NEURAL INFORM PR, V0, P2742
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Miyazaki T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1780
   Mukherjee T, 2016, P 2016 C EMPIRICAL M, V0, P912
   Noh H, 2017, ADV NEUR IN, V30, P0
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Parida S, 2019, ARXIV, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Plummer BA, 2022, IEEE T PATTERN ANAL, V44, P2155, DOI 10.1109/TPAMI.2020.3029008
   Portaz M, 2019, ARXIV, V0, P0
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Ren Z, 2016, P 2016 ACM MULTIMEDI, V0, P0, DOI DOI 10.1145/2964284.2967212
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Shi HY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1842
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Su W, 2020, PROC 8 INT C LEARN R, V0, P0
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Tan H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2066
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang J, 2014, PROC CVPR IEEE, V0, PP1386, DOI 10.1109/CVPR.2014.180
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang X, 2021, IEEE T PATTERN ANAL, V43, P4205, DOI 10.1109/TPAMI.2020.2972281
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   Wu Zhiyong, 2021, P 59 ANN M ASS COMP, V1, P6153, DOI 10.18653/V1/2021.ACL-LONG
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yin YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3025
   Yoshikawa Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P417, DOI 10.18653/v1/P17-2066
   Zablocki É, 2018, AAAI CONF ARTIF INTE, V0, P5626
   Zhang J, 2017, P 2 C MACH TRANSL, V0, P477
   Zhang K, 2018, IEEE DATA MINING, V0, PP747, DOI 10.1109/ICDM.2018.00090
   Zhang Z, 2020, PROC 8 INT C LEARN R, V0, P0
   Zhang Zhuosheng, 2020, AAAI CONF ARTIF INTE, V0, P9628
   Zhou CT, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1388
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
NR 91
TC 2
Z9 2
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUL 1
PY 2023
VL 45
IS 7
BP 9169
EP 9185
DI 10.1109/TPAMI.2023.3234170
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA I7PI8
UT WOS:001004665900080
PM 37018264
DA 2023-11-10
ER

PT J
AU Church, KW
   Yue, R
AF Church, Kenneth Ward
   Yue, Richard
TI Emerging trends: Smooth-talking machines
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Large language models; Hallucinations; ChatGPT; Responsible AI
ID computer
AB Large language models (LLMs) have achieved amazing successes. They have done well on standardized tests in medicine and the law. That said, the bar has been raised so high that it could take decades to make good on expectations. To buy time for this long-term research program, the field needs to identify some good short-term applications for smooth-talking machines that are more fluent than trustworthy.
C1 [Church, Kenneth Ward; Yue, Richard] Northeastern Univ, Inst Experiential AI, San Jose, CA 95113 USA.
RP Church, KW (通讯作者)，Northeastern Univ, Inst Experiential AI, San Jose, CA 95113 USA.
EM k.church@northeastern.edu
CR Bender Emily M, 2021, FACCT 21: PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, V0, P0
   Church K, 2022, NAT LANG ENG, V29, P483
   Church K, 2011, LINGUISTIC ISSUES LA, V6, P1
   Church KW, 1993, MACHINE TRANSLATION, V8, P239, DOI 10.1007/BF00981759
   Church KW, 2023, NAT LANG ENG, V29, P824, DOI 10.1017/S1351324923000141
   Dorr B, 2011, MACH TRANSL, V0, P745
   Firth JR, 1957, STUDIES LINGUISTIC A, V0, P10
   Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3
   Kung Tiffany H, 2023, PLOS DIGIT HEALTH, V2, Pe0000198, DOI 10.1371/journal.pdig.0000198
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   STEWART KK, 1985, J AUTOM CHEM, V7, P169, DOI 10.1155/S1463924685000360
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
NR 12
TC 0
Z9 0
U1 1
U2 1
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD SEP 15
PY 2023
VL 29
IS 5
BP 1402
EP 1410
DI 10.1017/S1351324923000463
PG 9
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA R2BC5
UT WOS:001062434100008
DA 2023-11-10
ER

PT J
AU Dale, R
AF Dale, Robert
TI Navigating the text generation revolution: Traditional data-to-text NLG companies and the rise of ChatGPT
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Natural language generation; Automated writing assistance
AB Since the release of ChatGPT at the end of November 2022, generative AI has been talked about endlessly in both the technical press and the mainstream media. Large language model technology has been heralded as many things: the disruption of the search engine, the end of the student essay, the bringer of disinformation horizontal ellipsis but what does it mean for commercial providers of earlier iterations of natural language generation technology? We look at how the major players in the space are responding, and where things might go in the future.
C1 [Dale, Robert] Language Technol Grp, Church Point, NSW, Australia.
RP Dale, R (通讯作者)，Language Technol Grp, Church Point, NSW, Australia.
EM rdale@language-technology.com
NR 0
TC 0
Z9 0
U1 18
U2 18
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUL 15
PY 2023
VL 29
IS 4
BP 1188
EP 1197
DI 10.1017/S1351324923000347
PG 10
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA M8CH8
UT WOS:001032435400011
DA 2023-11-10
ER

PT J
AU Wan, Q
   Du, SH
   Liu, YQ
   Fang, J
   Wei, LA
   Liu, S
AF Wan, Qian
   Du, Shangheng
   Liu, Yaqi
   Fang, Jing
   Wei, Luona
   Liu, Sannyuya
TI Document-level relation extraction with hierarchical dependency tree and bridge path
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Information extraction; Relation extraction; Natural language processing; Graph neural network; Deep learning
ID entity
AB The inter-sentence relation in a document is characterized by complex contextual information, large span of correlation and many kinds of relations, leading to the poor effect of sentence-level relation extraction models when addressing inter-sentence relations. Graph networks have been widely used in the research of document-level relation extraction due to their advantages in modeling local structural features and long-distance context dependencies. However, most previous studies modeled document in a coarse-grained manner, which ignores the richness and otherness of hierarchical features in a document. Consequently, contextual information modeling is not sufficient and fails to participate in deep reasoning efficiently. In this paper, we propose a document-level relation extraction model based on the Hierarchical Dependency Tree and Bridge Path (HDT-BP). The model uses sentence as a unit to independently extract the fine-grained features of each hierarchy and reconstructs the chain-structured document based on multiple dependent relationships into a hierarchical dependency tree. Moreover, the relational bridge entity is introduced during relation extraction to improve the model performance by modeling the bridge path feature. Experimental results demonstrate that our model exhibits superior performance on the DocRED dataset and achieves a significant improvement in extracting relational facts that never appeared in the training set. Extensive additional experiments further verify the effectiveness of our model.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Wan, Qian; Du, Shangheng; Fang, Jing; Liu, Sannyuya] Cent China Normal Univ, Natl Engn Res Ctr Educ Big Data, Wuhan 430079, Hubei, Peoples R China.
   [Wan, Qian; Du, Shangheng; Fang, Jing; Liu, Sannyuya] Cent China Normal Univ, Fac Artificial Intelligence Educ, Wuhan 430079, Hubei, Peoples R China.
   [Wei, Luona] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China.
   [Liu, Yaqi] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
   [Liu, Sannyuya] Natl Engn Res Ctr Educ Big Data, 11th Floor,South Lake Bldg,382 Xiongchu Rd, Wuhan 430079, Hubei, Peoples R China.
C3 Central China Normal University; Central China Normal University; National University of Defense Technology - China; Zhongnan University of Economics & Law
RP Wei, LA (通讯作者)，Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China.; Liu, S (通讯作者)，Natl Engn Res Ctr Educ Big Data, 11th Floor,South Lake Bldg,382 Xiongchu Rd, Wuhan 430079, Hubei, Peoples R China.
EM wanq8228@163.com; dsh@mails.ccnu.edu.cn; liuyaqi@zuel.edu.cn; fangjing@ccnu.edu.cn; wlnelysion@163.com; liusy5918@outlook.com
FU National Key Research and Development Program of China [2020AAA01088 04]; National Natural Science Foundation of China [62293553]; Hubei Provincial Natural Science Foundation of China [2023AFB295]; Knowledge Innovation Program of Wuhan-Shugung Project [2023010201020 390]; Fundamental Research Funds for the Central Universities [CCNU22LJ005, CCNU23XJ003]
CR Alonso O, 2007, SIGIR FORUM, V0, PP35, DOI 10.1145/1328964.1328968
   Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Bai F, 2019, ARXIV, V0, P0
   Chen WH, 2017, PROC CVPR IEEE, V0, PP1320, DOI 10.1109/CVPR.2017.145
   Christopoulou F, 2019, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Doddington GR, 2004, P 4 INT C LANG RES E, V0, P837
   Giorgi J, 2022, ARXIV, V0, P0
   Gu JH, 2017, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/bax024
   Gu JH, 2016, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/baw042
   Guo ZJ, 2020, ARXIV, V0, P0
   Gupta P, 2019, AAAI CONF ARTIF INTE, V0, P6513
   Gurevych I, 2017, P 2017 C EMP METH NA, V0, P1784
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hendrickx I, 2019, ARXIV, V0, P0
   Hosseini S, 2020, DATA MIN KNOWL DISC, V34, P1136, DOI 10.1007/s10618-020-00688-7
   Huang Kevin, 2020, ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Sahu SK, 2019, ARXIV, V0, P0
   Li B, 2020, P 28 INT C COMP LING, V0, P1551
   Li LF, 2020, ARTIF INTELL MED, V103, P0, DOI 10.1016/j.artmed.2020.101817
   Li ZH, 2016, IEEE INT C BIOINFORM, V0, PP994, DOI 10.1109/BIBM.2016.7822658
   Miwa M, 2016, ARXIV, V0, P0
   Najafipour S, 2022, IEEE T KNOWL DATA EN, V34, P448, DOI 10.1109/TKDE.2020.2982148
   Nan GS, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1546
   Nasar Z, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3445965
   dos Santos CN, 2015, ARXIV, V0, P0
   Peng N, 2017, T ASSOC COMPUT LING, V5, P101, DOI 10.1162/TACL_A_00049
   Quirk C, 2017, ARXIV, V0, P0
   Nguyen DQ, 2018, ARXIV, V0, P0
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Son J, 2017, PROC CVPR IEEE, V0, PP3786, DOI 10.1109/CVPR.2017.403
   Sun K, 2021, AAAI CONF ARTIF INTE, V35, P13851
   Takanobu R, 2019, AAAI CONF ARTIF INTE, V0, P7072
   Tan FA, 2022, ARXIV, V0, P0
   Tang HZ, 2020, LECT NOTES ARTIF INT, V12084, P197, DOI 10.1007/978-3-030-47426-3_16
   Tran HM, 2020, FINDINGS ASS COMPUTA, V0, PP4561, DOI 10.18653/V1/2020.FINDINGS-EMNLP
   Van Gysel JEL, 2019, FIRST INTERNATIONAL WORKSHOP ON DESIGNING MEANING REPRESENTATIONS, V0, P1
   Veličkovic P, 2018, ARXIV, V0, P0
   Verga P, 2018, ARXIV, V0, P0
   Wan H, 2021, AAAI CONF ARTIF INTE, V35, P13916
   Wan Q, 2023, KNOWL-BASED SYST, V262, P0, DOI 10.1016/j.knosys.2022.110228
   Wang HL, 2021, KNOWL-BASED SYST, V228, P0, DOI 10.1016/j.knosys.2021.107274
   Wang H, 2019, ARXIV, V0, P0
   Wang Y, 2020, ARXIV, V0, P0
   Wolf T, 2020, ARXIV, V0, P0
   Wu TT, 2021, ARXIV, V0, P0
   Xu B, 2021, ARXIV, V0, P0
   Xu BF, 2021, AAAI CONF ARTIF INTE, V35, P14149
   Xu W, 2021, AAAI CONF ARTIF INTE, V35, P14167
   Xue FZ, 2021, AAAI CONF ARTIF INTE, V35, P14194
   Yao Y, 2019, ARXIV, V0, P0
   Ye W, 2019, ARXIV, V0, P0
   Yuan CS, 2021, INFORM SCIENCES, V568, P163, DOI 10.1016/j.ins.2021.04.007
   Zhang NY, 2021, ARXIV, V0, P0
   Zhang YH, 2018, ARXIV, V0, P0
   Zhou HW, 2016, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/baw048
   Zhou WX, 2021, AAAI CONF ARTIF INTE, V35, P14612
   Zhou Y, 2020, ARXIV, V0, P0
NR 59
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD OCT 25
PY 2023
VL 278
IS 
BP 
EP 
DI 10.1016/j.knosys.2023.110873
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA S5YQ1
UT WOS:001071922300001
DA 2023-11-10
ER

PT J
AU Gedik, E
   Güngör, T
AF Gedik, Esin
   Güngör, Tunga
TI Solving Turkish math word problems by sequence-to-sequence encoder-decoder models
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
LA English
DT Article
DE Math word problems; sequence-to-sequence model; attention mechanism; natural language processing
AB Solving math word problems (MWP) is a challenging task due to the semantic gap between natural language texts , mathematical equations. The main purpose of the task is to take a written math problem as input and produce a proper equation as output for solving that problem. This paper describes a sequence-to-sequence (seq2seq) neural model for automatically solving Turkish MWPs based on their semantic meanings in the text. It comprises a bidirectional encoder to comprehend the semantics of the problem by encoding the input sequence and a decoder with attention to extract the equation by tracking the semantic meanings of the output symbols. We investigate the success of several embedding types, pretrained language models , neural models. Our research is novel in the sense that there exist no studies in Turkish on this natural language processing task that utilizes pretrained language models and neural models. There is also no Turkish dataset that can be used to train the neural models for the MWP task. As the first large-scale Turkish MWP dataset, we translated the well-known English MWP datasets into Turkish using a machine translation system. Although Turkish is an agglutinative and grammatically challenging language, the proposed models achieve around 72% accuracy on the dataset compiled from three English datasets.
C1 [Gedik, Esin; Güngör, Tunga] Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye.
C3 Bogazici University
RP Gedik, E (通讯作者)，Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye.
EM esin.gedik@boun.edu.tr
FU Bo?azi?i University Research Fund [16903]
CR Amini A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2357
   Bahdanau D, 2016, ARXIV, V0, P0
   Bakman Y, 2007, ARXIV, V0, P0
   Bobrow DG, 1964, NATURAL LANGUAGE INP, V0, P0
   Budur E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8253
   Cakiroglu U, 2008, CURR CONTENTS, V5, P311
   Eken S, 2014, DUZCE U BILIM TEKNOL, V2, P48
   Hosseini MJ, 2014, 2014EMNLP, V0, P523
   Huang D, 2018, P 27 INT C COMP LING, V0, PP213, DOI 10.1016/B978-0-12-809641-3.00011-9
   Huang DQ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P419
   Huang DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P887
   Koncel-Kedziorski R, 2016, P 2016 C N AM CHAPTE, V0, PP1152, DOI 10.18653/VLIN16-1136
   Kushman N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P271
   Lan Y, 2021, ARXIV, V0, P0
   Liguda Christian, 2012, NATURAL LANGUAGE PROCESSING AND INFORMATION SYSTEMS. PROCEEDINGS 17TH INTERNATIONAL CONFERENCE ON APPLICATIONS OF NATURAL LANGUAGE TO INFORMATION SYSTEMS, V0, P247, DOI 10.1007/978-3-642-31178-9_29
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Ma Yuhui, 2010, 2010 2ND INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE (ETCS), V0, PP476, DOI 10.1109/ETCS.2010.316
   Miao SY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P975
   Mitra A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2144
   Mukherjee A, 2008, ARTIF INTELL REV, V29, P93, DOI 10.1007/s10462-009-9110-0
   Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3434237
   Patel A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2080
   Robaidek B, 2018, ARXIV, V0, P0
   Sachan M, 2017, P 6 JOINT C LEXICAL, V0, P251
   Say ACC, 2001, INT J PATTERN RECOGN, V15, P359, DOI 10.1142/S0218001401000897
   Say C, 1994, P 9 INT S COMP INF S, V0, P550
   Seo M, 2015, P 2015 C EMPIRICAL M, V0, P1466
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Upadhyay S, 2016, P 2016 C EMPIRICAL M, V0, P297
   Wang H, 2016, P 2016 C EMP METH NA, V0, P541
   Wang Y, 2017, P 2017 C EMPIRICAL M, V0, P0
NR 31
TC 0
Z9 0
U1 7
U2 8
PU Tubitak Scientific & Technological Research Council Turkey
PI ANKARA
PA ATATURK BULVARI NO 221, KAVAKLIDERE, TR-06100 ANKARA, TURKIYE
SN 1300-0632
EI 1303-6203
J9 TURK J ELECTR ENG CO
JI Turk. J. Electr. Eng. Comput. Sci.
PD JUN 15
PY 2023
VL 31
IS 2
BP 431
EP 447
DI 10.55730/1300-0632.3993
PG 18
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA A8YV0
UT WOS:000957927500012
DA 2023-11-10
ER

PT J
AU Zhu, BB
   Bao, T
   Wang, KR
   Liu, L
   Han, JY
   Peng, T
AF Zhu, Beibei
   Bao, Tie
   Wang, Kerun
   Liu, Lu
   Han, Jiayu
   Peng, Tao
TI A semi-supervised neighborhood matching model for global entity alignment
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Knowledge graph; Natural language processing; Neighborhood structure; Global entity alignment
ID dbpedia
AB As an important way to integrate knowledge graphs, entity alignment is widely used in the field of natural language processing. Entity alignment is to find entities that exist in different knowledge graphs but have the same real-world meaning. Recently, most entity alignment models consider only the one-hop neighborhood node information of candidate entity alignment pairs, without considering the relations connected to neighboring nodes. Relations are critical to determining whether two entities can be aligned when they have the same neighborhood structure. Therefore, besides using the structural information of entities, we also use relation semantics to enhance entity alignment. The larger the number of training seed set, the better the model performance. Based on the premise, we use the semi-supervised bidirectional nearest neighbor iteration strategy to expand the size of the training seed set without manual labeling. Furthermore, to ensure the stability of the entity alignment results, we consider the dependencies between alignment decisions and perform global entity alignment from a comprehensive perspective. We evaluate the performance of our model on three publicly available cross-lingual datasets, and the experimental results demonstrate the effectiveness of our model.
C1 [Zhu, Beibei; Bao, Tie; Wang, Kerun; Peng, Tao] Jilin Univ, Coll Comp Sci & Technol, Qianjin St, Changchun 130012, Jilin, Peoples R China.
   [Bao, Tie; Liu, Lu; Peng, Tao] Jilin Univ, Coll Software, Qianjin St, Changchun 130012, Jilin, Peoples R China.
   [Zhu, Beibei; Bao, Tie; Wang, Kerun; Liu, Lu; Peng, Tao] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Qianjin St, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Peng, T (通讯作者)，Jilin Univ, Coll Comp Sci & Technol, Qianjin St, Changchun 130012, Jilin, Peoples R China.; Peng, T (通讯作者)，Jilin Univ, Coll Software, Qianjin St, Changchun 130012, Jilin, Peoples R China.; Peng, T (通讯作者)，Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Qianjin St, Changchun 130012, Jilin, Peoples R China.
EM zhubb20@mails.jlu.edu.cn; baotie@jlu.edu.cn; wangkr19@mails.jlu.edu.cn; liulu@jlu.edu.cn; jyhan126@uw.edu; tpeng@jlu.edu.cn
FU National Natural Science Foundation of China [61872163, 61806084]; Jilin Province Key Scientific and Technological Research and Development Project [20210201131GX]; Jilin Provincial Education Department project [JJKH20190160KJ]
CR Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bordes A, 2013, P NEUR INF PROC SYST, V0, P1
   Cao YX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1452
   Chen B, 2020, LECT NOTES ARTIF INT, V12084, P845, DOI 10.1007/978-3-030-47426-3_65
   Chen L, 2021, APPL INTELL, V51, P8896, DOI 10.1007/s10489-021-02400-8
   Chen W, 2021, 20 CHINA NATL C, V0, P0
   Chen X, 2020, 5 IEEE INT C DATA SC, V0, P0
   Ghorbani M, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), V0, PP208, DOI 10.1145/3341161.3342942
   Guo H, 2021, NEUROCOMPUTING, V461, P598, DOI 10.1016/j.neucom.2021.03.132
   Haihong E, 2020, INT J MACH LEARN COM, V10, P0
   Hu KR, 2021, NEURAL COMPUT APPL, V33, P11157, DOI 10.1007/s00521-020-05654-4
   Jiang S, 2021, WEB INF SYST APPL 18, V0, P0
   Jiang TT, 2019, LECT NOTES ARTIF INT, V11670, P162, DOI 10.1007/978-3-030-29908-8_13
   Kuhn Harold W, 1955, NAV RES LOG, V2, P83, DOI 10.1002/NAV.20053
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Li CJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2723
   Li J, 2022, ACM WEB C 2022 VIRTU, V0, P0
   Lin JJ, 2021, NEURAL COMPUT APPL, V33, P681, DOI 10.1007/s00521-020-05057-5
   Lin XX, 2019, IEEE DATA MINING, V0, PP429, DOI 10.1109/ICDM.2019.00053
   Lin YK, 2015, AAAI CONF ARTIF INTE, V0, P2181
   Lu GY, 2022, J TRAVEL MED, V29, P0, DOI 10.1093/jtm/taab156
   Luo S, 2022, ASS COMPUTATIONAL LI, V0, P0
   Ma MH, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11060815
   Mao X, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P2843
   Mao X, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM 20), V0, PP420, DOI 10.1145/3336191.3371804
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Roth AE, 2008, INT J GAME THEORY, V36, P537, DOI 10.1007/s00182-008-0117-6
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Shi XF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P813
   Song X, 2021, KNOWLEDGE SCI ENG MA, V0, P0
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Sun ZQ, 2020, AAAI CONF ARTIF INTE, V34, P222
   Sun ZQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4396
   Sun ZQ, 2017, LECT NOTES COMPUT SC, V10587, P628, DOI 10.1007/978-3-319-68288-4_37
   Tam NT, 2021, 37 IEEE INT C DATA E, V0, P0
   Tang XB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3174
   Wang CG, 2016, AAAI CONF ARTIF INTE, V0, P2130
   Wang T, 2020, NEURAL COMPUT APPL, V32, P235, DOI 10.1007/s00521-018-3806-5
   Wang Z, 2014, AAAI CONF ARTIF INTE, V0, P1112
   Wang ZC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P349
   Wu Y, 2020, 58 ANN M ASS COMPUTA, V0, P0
   Wu YT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5278
   Wu YT, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P240
   Xu K, 2020, AAAI CONF ARTIF INTE, V34, P9354
   Xu K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3156
   Yang B, 2022, NEURAL COMPUT APPL, V34, P2569, DOI 10.1007/s00521-021-05985-w
   Yang SW, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4431
   Zeng W, 2019, INT WORKSHOPS ECML P, V0, P0
   Zeng W, 2021, LECT NOTES COMPUT SC, V12681, P272, DOI 10.1007/978-3-030-73194-6_19
   Zeng WX, 2020, PROC INT CONF DATA, V0, PP1870, DOI 10.1109/ICDE48307.2020.00191
   Zhang FZ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP353, DOI 10.1145/2939672.2939673
   Zhang YY, 2018, AAAI CONF ARTIF INTE, V0, P6069
   Zhao X, 2019, 16 EXTENDED SEMANTIC, V0, P0
   Zhu H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4258
   Zhu QN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1943
   Zhu RB, 2021, LECT NOTES ARTIF INT, V12712, P501, DOI 10.1007/978-3-030-75762-5_40
   Zhu Y, 2020, ARXIV, V0, P0
NR 58
TC 0
Z9 0
U1 19
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD MAY 15
PY 2023
VL 35
IS 15
BP 10779
EP 10799
DI 10.1007/s00521-023-08264-y
EA JAN 2023
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA P9VF6
UT WOS:000919030000004
DA 2023-11-10
ER

PT J
AU Shamsabadi, AS
   Ramezani, R
   Farsani, HK
   Nematbakhsh, M
AF Shamsabadi, Abbas Shahini
   Ramezani, Reza
   Farsani, Hadi Khosravi
   Nematbakhsh, Mohammadali
TI Direct relation detection for knowledge-based question answering
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Question answering; Relation detection; Knowledge base; Natural language processing
AB This study addresses the problem of relation detection for answering single-relation factoid questions over knowledge bases (KBs). In this kind of questions, the answer is obtained from a single KB fact in the form of subject-predicate-object. Conventional fact extraction methods have two steps: entity linking and relation detection, in which the output of the entity linking is used by the relation detection step to first find candidate relations, and then choose the best relation from candidate relations. Such methods have difficulties with the relation detection if there is an error or ambiguity in the entity linking step. This paper explores the relation detection task without the entity-linking step utilizing the hierarchical structure of relations and an out-of-box POS tagger. As relations are of different levels of abstraction, the proposed solution uses multiple classifiers in pipeline, each of which uses separate BiGRU neural networks fed with questions embedded with one-hot encoding at the character level. Besides, to increase the accuracy of the proposed model and to avoid the need for large amounts of training data, after each word of the question, its POS tag is inserted before feeding the network. The experimental results show that the accuracy of the proposed solution for the direct relation detection is 89.5%. In addition, the proposed solution can be used for the indirect relation detection whose accuracy is 96.3%, which is higher than state-of-the-art relation detection techniques. Finally, the positive effects of using POS tags have been examined.
C1 [Shamsabadi, Abbas Shahini; Ramezani, Reza; Nematbakhsh, Mohammadali] Univ Isfahan, Fac Comp Engn, Dept Software Engn, Esfahan, Iran.
   [Farsani, Hadi Khosravi] Shahrekord Univ, Dept Comp Engn, Shahrekord, Iran.
C3 University of Isfahan; Shahrekord University
RP Ramezani, R (通讯作者)，Univ Isfahan, Fac Comp Engn, Dept Software Engn, Esfahan, Iran.
EM ashahini@eng.ui.ac.ir; r.ramezani@eng.ui.ac.ir; khosravi@eng.sku.ac.ir; nematbakhsh@eng.ui.ac.ir
CR [Anonymous], 2016, EMNLP, V0, P0
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Bordes Antoine, 2014, MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES. EUROPEAN CONFERENCE, V0, P165, DOI 10.1007/978-3-662-44848-9_11
   Bordes A, 2014, QUESTION ANSWERING S, V0, P0, DOI DOI 10.3115/V1/D14-1067
   Bordes A, 2015, ARXIV, V0, P0
   Chen YR, 2020, KNOWL-BASED SYST, V201, P0, DOI 10.1016/j.knosys.2020.106077
   Cui H, 2021, KNOWL INF SYST, V63, P2741, DOI 10.1007/s10115-021-01609-w
   Deng Y, 2019, AAAI CONF ARTIF INTE, V0, P6318
   Fader A, 2013, ACL, V1, P1608
   Green Jr Bert F, 1961, W JOINT IRE AIEE ACM, V0, PP219, DOI 10.1017/CBO9781107415324.004
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Jabalameli M, 2021, EXPERT SYST APPL, V177, P0, DOI 10.1016/j.eswa.2021.114922
   Jabalameli M, 2020, ETRI J, V42, P239, DOI 10.4218/etrij.2018-0312
   Jiao J, 2021, KNOWL-BASED SYST, V228, P0, DOI 10.1016/j.knosys.2021.107270
   Lukovnikov D, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1211, DOI 10.1145/3038912.3052675
   Ma E, 2018, WORD EMBEDDING WHY Y, V0, P0
   Maheshwari G, 2019, LECT NOTES COMPUT SC, V11778, P487, DOI 10.1007/978-3-030-30793-6_28
   Melis G, 2018, INT C LEARN REPR, V0, P0
   Mohammed S, 2018, P C N AM CHAPT ASS C, V0, PP291, DOI 10.18653/v1/n18-2047
   Qi Peng, 2018, CONLL 2018 SHARED TA, V0, PP160, DOI 10.18653/V1/K18-2016
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang RZ, 2019, IEEE ACCESS, V7, P46773, DOI 10.1109/ACCESS.2019.2909826
   Weston J, 2016, 4 INT C LEARNING REP, V0, P0
   Xiong HB, 2021, KNOWL-BASED SYST, V221, P0, DOI 10.1016/j.knosys.2021.106954
   Yih WT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1321
   Yih WT, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P643
   Yin W, 2016, P COLING 2016 26 INT, V0, P1746
   Yu M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P571, DOI 10.18653/v1/P17-1053
   Zhang HZ, 2018, IEEE ACCESS, V6, P75429, DOI 10.1109/ACCESS.2018.2883304
NR 30
TC 0
Z9 0
U1 2
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JAN 15
PY 2023
VL 211
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118678
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 7V4XR
UT WOS:000912819000005
DA 2023-11-10
ER

PT J
AU Gao, P
   Geng, SJ
   Zhang, RR
   Ma, TL
   Fang, RY
   Zhang, YF
   Li, HS
   Qiao, Y
AF Gao, Peng
   Geng, Shijie
   Zhang, Renrui
   Ma, Teli
   Fang, Rongyao
   Zhang, Yongfeng
   Li, Hongsheng
   Qiao, Yu
TI CLIP-Adapter: Better Vision-Language Models with Feature Adapters
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article; Early Access
DE Feature adapter; Vision-language model; Few-shot learning; Open-vocabulary
AB Large-scale contrastive vision-language pretraining has shown significant progress in visual representation learning. Unlike traditional visual systems trained by a fixed set of discrete labels, a new paradigm was introduced in Radford et al. (International conference on machine learning, PMLR, 2021) to directly learn to align images with raw texts in an open-vocabulary setting. On downstream tasks, a carefully chosen text prompt is employed to make zero-shot predictions. To avoid non-trivial prompt engineering, context optimization (Zhou et al. in Int J Comput Vis 130(9):2337-2348, 2022) has been proposed to learn continuous vectors as task-specific prompts with few-shot training examples. In this paper, we show that there is an alternative path to achieve better vision-language models other than prompt tuning. While prompt tuning is for the textual inputs, we propose CLIP-Adapter to conduct fine-tuning with feature adapters on either visual or language branch. Specifically, CLIP-Adapter adopts an additional bottleneck layer to learn new features and performs residual-style feature blending with the original pretrained features. As a consequence, CLIP-Adapter is able to outperform context optimization while maintaining a simple design. Experiments and extensive ablation studies on various visual classification tasks demonstrate the effectiveness of our approach.
C1 [Gao, Peng; Zhang, Renrui; Ma, Teli; Qiao, Yu] Shanghai AI Lab, Shanghai, Peoples R China.
   [Geng, Shijie; Zhang, Yongfeng] Rutgers State Univ, New Brunswick, NJ USA.
   [Fang, Rongyao; Li, Hongsheng] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
C3 Shanghai Artificial Intelligence Laboratory; Rutgers State University System; Rutgers New Brunswick; Chinese University of Hong Kong
RP Gao, P (通讯作者)，Shanghai AI Lab, Shanghai, Peoples R China.
EM gaopeng@pjlab.org.cn; sg1309@rutgers.edu; zhangrenrui@pjlab.org.cn; hsli@ee.cuhk.edu.hk; qiaoyu@pjlab.org.cn
CR Alayrac Jean-Baptiste, 2022, ADV NEURAL INFORM PR, V0, P0
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Carion Nicolas, 2020, ECCV, V0, P0, DOI DOI 10.1007/978-3-030-58452-813
   Chen Yen-Chun, 2020, ECCV, V0, P0
   Cimpoi M, 2014, PROC CVPR IEEE, V0, PP3606, DOI 10.1109/CVPR.2014.461
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong L, 2019, ADV NEUR IN, V32, P0
   Dosovitskiy Alexey, 2021, ICLR, V0, P0
   Howard AG, 2017, ARXIV, V0, P0
   Gao P, 2021, P IEEE CVF INT C COM, V0, P3621
   Gao P, 2021, NEURIPS, V0, P0
   Gao P, 2019, PROC CVPR IEEE, V0, PP6632, DOI 10.1109/CVPR.2019.00680
   Gao T, 2021, ACL IJCNLP, V0, P0
   Gu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8410
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Hendrycks Dan, 2021, ARXIV200616241, V0, P8340
   Hendrycks Dan, 2021, CVPR, V0, P3
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Hu SD, 2022, ARXIV, V0, P0
   Jia C, 2021, PR MACH LEARN RES, V139, P0
   Jia ML, 2022, LECT NOTES COMPUT SC, V13693, P709, DOI 10.1007/978-3-031-19827-4_41
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Kim Jin-Hwa, 2018, ADV NEURAL INFORM PR, V0, P0
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), V0, PP554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3045
   Li C, 2022, 36 C NEUR INF PROC S, V0, P0
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li Junnan, 2021, ADV NEURAL INF PROCE, V0, PP9694, DOI 10.48550/ARXIV.2107.07651
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Lian D, 2022, ADV NEURAL INFORM PR, V35, P109
   Liu PF, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3560815
   Liu X, 2021, ARXIV, V0, P0
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Maji S, 2013, ARXIV, V0, P0
   Mao Mingyuan, 2021, ADV NEURAL INF PROCE, V34, P25346
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Parkhi OM, 2012, PROC CVPR IEEE, V0, PP3498, DOI 10.1109/CVPR.2012.6248092
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Recht B, 2019, PR MACH LEARN RES, V97, P0
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Simonyan K, 2015, ARXIV, V0, P0
   Soomro K, 2012, ARXIV, V0, P0
   Sun T, 2022, INT C MACH LEARN PML, V0, P20,841
   Sung YL, 2022, PROC CVPR IEEE, V0, PP5217, DOI 10.1109/CVPR52688.2022.00516
   Sung YL, 2022, ADV NEURAL INFORM PR, V35, P0
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsimpoukelli Maria, 2021, ADV NEURAL INFORM PR, V34, P200
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang Haohan, 2019, NEURIPS, V32, P6
   Wang WH, 2022, ARXIV, V0, P0
   Wang Zirui, 2022, INT C LEARN REPR, V0, P0
   Wortsman M, 2022, PROC CVPR IEEE, V0, PP7949, DOI 10.1109/CVPR52688.2022.00780
   Xiao JX, 2010, PROC CVPR IEEE, V0, PP3485, DOI 10.1109/CVPR.2010.5539970
   Xiujun I, 2020, ECCV, V0, P0
   Yao Y, 2022, P 2022 C EMP METH NA, V0, P117
   Yao Y, 2022, ARXIV, V0, P0
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Zhou C, 2022, INT C LEARN REPR, V0, P0
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
NR 70
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s11263-023-01891
EA SEP 2023
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA R8IP5
UT WOS:001066741400001
DA 2023-11-10
ER

PT J
AU Cao, HQ
   He, P
   Wang, CJ
AF Cao, Huiqin
   He, Peng
   Wang, Chengjin
TI Processing of Chinese language and text information system under the background of speech recognition
SO SOFT COMPUTING
LA English
DT Article; Early Access
DE Speech recognition; Chinese; Language and text; Information system
AB With the popularization of computers, artificial intelligence technology has become more and more mature, among which speech recognition technology in artificial intelligence is favored by people. In the past few years, the acoustic model combined with the Gaussian mixture model and the hidden Markov model has always been in the leading position. In the field of speech recognition technology, because the development of speech data has gradually expanded, and the complexity of the data has also increased. The larger the data, the traditional data network model is slowly showing inadequacy. However, the deep neural network model is easy to deal with large and complex data modeling. This article combines the advantages of basic learning theory and speech recognition technology, and launches in-depth research on embedding learning theoretical knowledge into the field of speech recognition. Nowadays, large-scale text information databases relying on computers are becoming more and more important in linguistic research, and a large-scale corpus that fully reflects language facts and contains rich language information has been constructed. The establishment of the text information database system is long, from word segmentation, part-of-speech tagging to syntactic tagging to semantic tagging. Therefore, the characteristic of information system processing is that the systematic description depends on the application environment of understanding vocabulary and reasoning. According to different scenarios, the realization methods of semantic description roles are also different, and the description of semantic roles in correct scenarios is clearer, more detailed and systematic. Therefore, this article is of great significance for solving the semantic problem of using Chinese frame network for Chinese information processing in the context of speech recognition.
C1 [Cao, Huiqin] Keimyung Univ, Dept Educ, Daegu 42601, South Korea.
   [Cao, Huiqin] Hunan Vocat Coll Nationalities, Sch Primary Educ, Yueyang 414000, Hunan, Peoples R China.
   [He, Peng] Yueyang Vocat Tech Coll, Sch Informat, Yueyang 414000, Peoples R China.
   [Wang, Chengjin] Jiaxing Nanhu Univ, Sch Humanities & Arts, Jiaxing 314001, Peoples R China.
C3 Keimyung University
RP Wang, CJ (通讯作者)，Jiaxing Nanhu Univ, Sch Humanities & Arts, Jiaxing 314001, Peoples R China.
EM wang_chengjin@126.com
FU Study on The Construction of Chinese Language Curriculum Based on The Integration of Certificate and Curriculum for Tibetan Normal Students (Education special project in 2020 of Hunan Province Social Science Fund) [20YBJ16]
CR Affolter K, 2019, VLDB J, V28, P793, DOI 10.1007/s00778-019-00567-8
   Bertsimas D, 2021, MACH LEARN, V110, P249, DOI 10.1007/s10994-020-05893-5
   Chen HR, 2016, TECHNOL PEDAGOG EDUC, V25, P171, DOI 10.1080/1475939X.2015.1007077
   Cho Byung Chul, 2018, JOURNAL OF DIGITAL CONVERGENCE 디지털융복합연구, V16, P9, DOI 10.14400/JDC.2018.16.2.009
   de Lima TA, 2020, COMPUT SPEECH LANG, V62, P0, DOI 10.1016/j.csl.2019.101055
   Hamza M, 2020, INT J ELECT COMPUT E, V10, P3643
   Lai XX, 2021, INT J SPEECH TECHNOL, V0, P0, DOI DOI 10.1007/s10772-021-09872-6
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Moon Hyung Jin, 2020, JOURNAL OF THE KOREA CONVERGENCE SOCIETY 한국융합학회논문지, V11, P19, DOI 10.15207/JKCS.2020.11.7.019
   Shi L, 2021, INT J LESSON LEARN S, V10, P75, DOI 10.1108/IJLLS-09-2020-0065
   Tao F, 2021, IEEE T MULTIMEDIA, V23, P1, DOI 10.1109/TMM.2020.2975922
   Wang DP, 2019, INT J BILING EDUC BI, V22, P138, DOI 10.1080/13670050.2016.1231773
   Xie Y, 2019, TECHTRENDS, V63, P251, DOI 10.1007/s11528-019-00389-z
   Yuan C, 2019, J AM MED INFORM ASSN, V26, P294, DOI 10.1093/jamia/ocy178
   Zaatri A, 2015, J NEW TECHNOL MATER, V277, P1
NR 15
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s00500-023-08710-y
EA JUN 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA J0MF4
UT WOS:001006626400009
DA 2023-11-10
ER

PT J
AU Ding, HJ
   Xu, XL
AF Ding, Haijie
   Xu, Xiaolong
TI SAN-T2T: An automated table-to-text generator based on selective attention network
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE neural language; selective attention network; semantic vector; table-to-text
ID model
AB Table-to-text generation aims to generate descriptions for structured data (i.e., tables) and has been applied in many fields like question-answering systems and search engines. Current approaches mostly use neural language models to learn alignment between output and input based on the attention mechanisms, which are still flawed by the gradual weakening of attention when processing long texts and the inability to utilize the records' structural information. To solve these problems, we propose a novel generative model SAN-T2T, which consists of a field-content selective encoder and a descriptive decoder, connected with a selective attention network. In the encoding phase, the table's structure is integrated into its field representation, and a content selector with self-aligned gates is applied to take advantage of the fact that different records can determine each other's importance. In the decoding phase, the content selector's semantic information enhances the alignment between description and records, and a featured copy mechanism is applied to solve the rare word problem. Experiments on WikiBio and WeatherGov datasets show that SAN-T2T outperforms the baselines by a large margin, and the content selector indeed improves the model's performance.
C1 [Ding, Haijie] Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Big Data Secur & Intelligent Proc, Nanjing, Peoples R China.
   [Xu, Xiaolong] Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of Posts & Telecommunications
RP Xu, XL (通讯作者)，Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing, Peoples R China.
EM xuxl@njupt.edu.cn
CR [Anonymous], 2007, P 11 EUROPEAN WORKSH, V0, P0, DOI DOI 10.1017/CB09781107415324.004
   Bahdanau D, 2016, ARXIV, V0, P0
   Bao JW, 2019, IEEE-ACM T AUDIO SPE, V27, P311, DOI 10.1109/TASLP.2018.2878381
   Barzilay R, 2005, P C HUM LANG TECHN E, V0, PP331, DOI 10.3115/1220575.1220617
   Cao J, 2019, 2019 INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING SYSTEMS (SPSS 2019), V0, PP121, DOI 10.1145/3364908.3365287
   Chen K, 2021, KNOWL-BASED SYST, V215, P0, DOI 10.1016/j.knosys.2020.106610
   Chen W, 2020, P 58 ANN M ASS COMP, V0, PP7929, DOI 10.18653/V1/2020.ACL-MAIN.708
   Chen WH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8635
   Chen Z, 2020, FINDINGS ASS COMPUTA, V0, P2096
   Deng W, 2020, PROCEEDINGS OF 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS), V0, PP244, DOI 10.1109/icaiis49377.2020.9194949
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gong H, 2020, P 2020 C EMP METH NA, V0, P2905
   Gong H, 2020, P 28 INT C COMP LING, V0, PP1978, DOI 10.18653/V1/2020.COLING-MAIN.179
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Heafield K, 2013, P 51 ANN M ASS COMP, V2, P690
   Jean S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1
   Jiang N, 2020, INFORM SCIENCES, V530, P167, DOI 10.1016/j.ins.2020.03.080
   Kondadadi R, 2013, LONG PAPERS, V1, P1406
   Konstas I, 2013, P 2013 C EMPIRICAL M, V0, P1503
   Konstas I, 2013, J ARTIF INTELL RES, V48, P305, DOI 10.1613/jair.4025
   Lebret Remi, 2016, P 2016 C EMP METH NA, V0, PP1203, DOI 10.18653/v1/D16-1128
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li G, 2019, P 3 WORKSH NEUR GEN, V0, P148
   Liang P, 2009, P JOINT C 47 ANN M A, V0, PP91, DOI 10.1007/978-3-642-02374-3_6
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu TY, 2018, AAAI CONF ARTIF INTE, V0, P4881
   Ma SM, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2047
   Mei Hongyuan, 2016, P 2016 C N AM CHAPTE, V0, P720
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Oya Tatsuro, 2014, PROC 8 INT NATURAL L, V0, P45
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Parikh AP, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1173
   Puduppully R, 2021, T ASSOC COMPUT LING, V9, P510, DOI 10.1162/tacl_a_00381
   Puduppully R, 2019, AAAI CONF ARTIF INTE, V0, P6908
   Qin GH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3761
   Rebuffel C, 2019, ARXIV, V0, P0
   Rebuffel C, 2022, DATA MIN KNOWL DISC, V36, P318, DOI 10.1007/s10618-021-00801-4
   Reiter E, 2000, BUILDING NATURAL LAN, V0, P41
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sha L, 2018, AAAI CONF ARTIF INTE, V0, P5414
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Vaswani A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1706.03762
   Wiseman S, 2017, P 2017 C EMPIRICAL M, V0, P0
   Wiseman S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3174
   Zhang B, 2020, IEEE T PATTERN ANAL, V42, P154, DOI 10.1109/TPAMI.2018.2876404
   Zhang YK, 2019, IEEE-ACM T AUDIO SPE, V27, P1164, DOI 10.1109/TASLP.2019.2913087
NR 48
TC 0
Z9 0
U1 7
U2 7
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1017/S135132492300013X
EA MAY 2023
PG 25
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA F2VU8
UT WOS:000980984200001
DA 2023-11-10
ER

PT J
AU Tang, YC
   Wu, XP
   Zhou, CL
   Zhu, GX
   Song, JW
   Liu, GY
   Li, ZH
AF Tang, Yachen
   Wu, Xingping
   Zhou, Chunlei
   Zhu, Guangxin
   Song, Jinwei
   Liu, Guangyi
   Li, Zhihong
TI Automatic schema construction of electrical graph data platform based on multi-source relational data models
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article
DE Automated extraction; Electrical graph data platform; Ontology model; Schema construction; Relational data models
ID system; ontology
AB Data storage and management in power systems usually adopt relational databases. However, the relational database requires ample storage space and has low data retrieval and query efficiency. An electrical graph data platform can describe the complicated relationships between concepts and entities involved in power systems with the form of an association graph, which provides a better ability to organize, manage, and apply massive amounts of information. Since the construction of the top-level ontology model or schema for a specific field graph data platform is cumbersome, complex, and generally requires lots of association analysis and expert system intervention, it is insufficiently automated, time-consuming, and unable to cope with large-scale electric power knowledge. This paper proposes a method for automatically constructing the schema of an electrical graph data platform, which uses the diverse table structure information from the relational database and SQL language descriptions to extract ontologies to form the ontology candidate set automatically. Then the method utilizes ontology clustering and disambiguation to initial an ontology graph model and automatically update ontology and relationship expressions. Meanwhile, the model layering is used to construct a hierarchical model based on different business needs, and the schema optimization is applied according to expert comments.
C1 [Tang, Yachen; Liu, Guangyi; Li, Zhihong] Envis Digital, Redwood City, CA 94065 USA.
   [Wu, Xingping; Zhou, Chunlei; Zhu, Guangxin; Song, Jinwei] State Grid Corp China, Big Data Ctr, Beijing 100107, Peoples R China.
C3 State Grid Corporation of China
RP Tang, YC (通讯作者)，Envis Digital, Redwood City, CA 94065 USA.
EM yachent@mtu.edu
FU "Research Project on Spatial-temporal Data Modeling and Electric Carbon Correlation Analysis Based on Graph Technology under New Power System" of State Grid Big Data Center [52999021N006]
CR An J, 2018, MOB INF SYST, V2018, P0, DOI 10.1155/2018/1359174
   Bogodorova T, 2020, IEEE T POWER SYST, V35, P4968, DOI 10.1109/TPWRS.2020.3020726
   Chen He-ping, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND SOFTWARE ENGINEERING (CSSE 2008), V0, PP1078, DOI 10.1109/CSSE.2008.1427
   Chen XL, 2020, IEEE T POWER SYST, V35, P85, DOI 10.1109/TPWRS.2019.2925369
   Chen YR, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2344
   Dahab MY, 2008, EXPERT SYST APPL, V34, P1474, DOI 10.1016/j.eswa.2007.01.043
   FLINN DG, 1992, IEEE T POWER SYST, V7, P784, DOI 10.1109/59.141786
   Ge J, 2012, J COMPUT, V7, P1445, DOI 10.4304/jcp.7.6.1445-1452
   Guo Chaomin, 2012, COMPUTER ENGINEERING AND APPLICATIONS, V48, P115, DOI 10.3778/j.issn.1002-8331.2012.07.030
   He L, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, V0, P345, DOI 10.1109/IITA.Workshops.2008.10
   Huang YH, 2015, CSEE J POWER ENERGY, V1, P19, DOI 10.17775/CSEEJPES.2015.00003
   Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Liu G, 2020, POWER SYST TECHNOL, V45, P2051
   Liu Y, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, V0, P0
   Lu Y, 2019, DISTRIBUTION UTILIZA, V36, P12
   Lu Yao, 2019, 2019 IEEE/ACIS 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS). PROCEEDINGS, V0, P452
   Mahdisoltani Farzaneh, 2015, CIDR, V0, P0
   Mogotlane KD, 2016, INT J WEB SEMANT TEC, V7, P21, DOI 10.5121/IJWEST.2016.7403
   Noy Natalya F, 2001, ONTOLOGY DEV, V0, P0
   Park HM, 2018, IEEE T IMAGE PROCESS, V27, P2314, DOI 10.1109/TIP.2017.2779264
   Samuelsson O, 2006, IEEE T POWER SYST, V21, P1007, DOI 10.1109/TPWRS.2006.873014
   Shanshan Qi, 2019, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1237, P0, DOI 10.1088/1742-6596/1237/2/022159
   Simpson RH, 2001, IEEE T IND APPL, V37, P153, DOI 10.1109/28.903140
   Singh A, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), V0, PP304, DOI 10.1109/RAICS.2013.6745492
   STAINHAOUER GN, 1990, IEEE T ACOUST SPEECH, V38, P705, DOI 10.1109/29.52710
   Su Z, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), V0, PP761, DOI 10.1109/ICCCS49078.2020.9118512
   Subhashini R, 2011, INT J ENTERPRISE COM, V1, P60
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Wang K, 2017, IEEE T IND INFORM, V13, P1969, DOI 10.1109/TII.2017.2692775
   Wang PW, 2019, IEEE ACCESS, V7, P159888, DOI 10.1109/ACCESS.2019.2950900
   Wei Deng, 2019, CHINESE JOURNAL OF ELECTRICAL ENGINEERING, V5, P33, DOI 10.23919/CJEE.2019.000025
   Xie J, 2013, TSINGHUA SCI TECHNOL, V18, P515
   Zhou JH, 2019, IEEE ACCESS, V7, P38856, DOI 10.1109/ACCESS.2019.2905048
   Zhu ZB, 2018, IEEE ACCESS, V6, P41760, DOI 10.1109/ACCESS.2018.2851604
NR 35
TC 0
Z9 0
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-023X
EI 1872-6933
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD MAY 15
PY 2023
VL 145
IS 
BP 
EP 
DI 10.1016/j.datak.2022.102129
EA FEB 2023
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 9C2SP
UT WOS:000935273700001
DA 2023-11-10
ER

PT J
AU Majewska, O
   Razumovskaia, E
   Ponti, EM
   Vulic, I
   Korhonen, A
AF Majewska, Olga
   Razumovskaia, Evgeniia
   Ponti, Edoardo M.
   Vulic, Ivan
   Korhonen, Anna
TI Cross-Lingual Dialogue Dataset Creation via Outline-Based Generation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Multilingual task-oriented dialogue (ToD) facilitates access to services and information for many (communities of) speakers. Nevertheless, its potential is not fully realized, as current multilingual ToD datasets-both for modular and end-to-end modeling-suffer from severe limitations. 1) When created from scratch, they are usually small in scale and fail to cover many possible dialogue flows. 2) Translation-based ToD datasets might lack naturalness and cultural specificity in the target language. In this work, to tackle these limitations we propose a novel outline-based annotation process for multilingual ToD datasets, where domain-specific abstract schemata of dialogue are mapped into natural language outlines. These in turn guide the target language annotators in writing dialogues by providing instructions about each turn's intents and slots. Through this process we annotate a new large-scale dataset for evaluation of multilingual and cross-lingual ToD systems. Our Cross-lingual Outline-based Dialogue dataset (cod) enables natural language understanding, dialogue state tracking, and end-to-end dialogue evaluation in 4 diverse languages: Arabic, Indonesian, Russian, and Kiswahili. Qualitative and quantitative analyses of cod versus an equivalent translation-based dataset demonstrate improvements in data quality, unlocked by the outline-based approach. Finally, we benchmark a series of state-of-the-art systems for cross-lingual ToD, setting reference scores for future work and demonstrating that cod prevents over-inflated performance, typically met with prior translation-based ToD datasets.
C1 [Majewska, Olga; Razumovskaia, Evgeniia; Ponti, Edoardo M.; Vulic, Ivan; Korhonen, Anna] Univ Cambridge, Language Technol Lab, Cambridge, England.
   [Ponti, Edoardo M.] Univ Edinburgh, Inst Language Cognit & Computat, Edinburgh, Scotland.
C3 University of Cambridge; University of Edinburgh
RP Majewska, O (通讯作者)，Univ Cambridge, Language Technol Lab, Cambridge, England.
EM om304@cam.ac.uk; er563@cam.ac.uk; ep490@cam.ac.uk; iv250@cam.ac.uk; alk23@cam.ac.uk
FU ERC PoC Grant MultiConvAI: Enabling Multilingual Conversational AI [957356]
CR Altinok Duygu, 2018, P 1 FINANCIAL NARRAT, V0, P1
   [Anonymous], 2011, P 49 ANN M ASS COMP, V0, P0
   Artetxe M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7674
   BABBY LH, 1975, LANGUAGE, V51, P342, DOI 10.2307/412860
   Bellomaria Valentina, 2019, P 6 ITALIAN C COMPUT, V0, P0
   Bohus D, 2009, COMPUT SPEECH LANG, V23, P332, DOI 10.1016/j.csl.2008.10.001
   BONNEAUMAYNARD H, 2005, INTERSPEECH, V0, P3457
   Budzianowski P, 2019, P 3 WORKSHOP NEURAL, V0, PP15, DOI 10.18653/V1/D19-5602
   Cao J, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P782
   Castellucci G, 2019, ARXIV, V0, P0
   Chao GL, 2019, INTERSPEECH, V0, PP1468, DOI 10.21437/Interspeech.2019-1355
   Chaves AP, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI19), V0, PP102, DOI 10.1145/3349537.3351901
   Clark JH, 2020, T ASSOC COMPUT LING, V8, P454, DOI 10.1162/tacl_a_00317
   Conneau Alexis, 2020, ASS COMPUT LINGUIST, V0, PP8440, DOI 10.18653/v1/2020.acl-main.747
   Denecke Kerstin, 2019, STUD HEALTH TECHNOL INFORM, V259, P77
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding BS, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1639
   Dyer Chris, 2013, P 2013 C N AM CHAPTE, V0, P644
   Farajian MA, 2020, PROC 5 C MACH TRANSL, V0, P65
   Feng FXY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P878
   FitzGerald J, 2022, ARXIV, V0, P0
   Gong Y, 2019, AAAI CONF ARTIF INTE, V0, P6465
   Graham Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P72
   Gupta N, 2006, IEEE T AUDIO SPEECH, V14, P213, DOI 10.1109/TSA.2005.854085
   Hakkani-Tür D, 2016, INTERSPEECH, V0, PP715, DOI 10.21437/Interspeech.2016-402
   He XD, 2013, INT CONF ACOUST SPEE, V0, PP8342, DOI 10.1109/ICASSP.2013.6639292
   Hemphill CT, 1990, SPEECH NATURAL LANGU, V0, P0
   Holtzman Ari, 2020, ICLR, V0, P0
   Hu JJ, 2020, PR MACH LEARN RES, V119, P0
   Hung CC, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P3687
   Junczys-Dowmunt M, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P116
   KELLEY JF, 1984, ACM T OFF INF SYST, V2, P26, DOI 10.1145/357417.357420
   Krishnan Jitin, 2021, P 1 WORKSHOP MULTILI, V0, PP211, DOI 10.18653/v1/2021.mrl-1.18
   Larson S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1311
   Lembersky G, 2012, COMPUT LINGUIST, V38, P799, DOI 10.1162/COLI_a_00111
   Li HR, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2950
   Lin Zhaojiang, 2021, P NEURAL INFORM PROC, V1, P0
   Liu FY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P10467
   Liu X, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI19), V0, PP165, DOI 10.1145/3292522.3326020
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Liu ZH, 2020, AAAI CONF ARTIF INTE, V34, P8433
   Dao MH, 2021, INTERSPEECH, V0, PP4698, DOI 10.21437/Interspeech.2021-618
   Muise C, 2019, ARXIV, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Chaves AP, 2021, ARXIV, V0, P0
   Ponti EM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2362
   Ponti EM, 2021, ARXIV, V0, P0
   Quan J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P930
   Rastogi A, 2020, AAAI CONF ARTIF INTE, V34, P8689
   Razumovskaia E, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), V0, P2017
   Razumovskaia Evgeniia, 2022, J ARTIF INTELL RES, V74, P1351, DOI 10.1613/jair.1.13083
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Schuster S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3795
   Shah P, 2018, P 2018 C N AM CHAPTE, V0, PP41, DOI 10.18653/v1/N18-3006
   Siddhant A, 2020, AAAI CONF ARTIF INTE, V34, P8854
   Susanto RH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P38, DOI 10.18653/v1/P17-2007
   Upadhyay S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6034, DOI 10.1109/ICASSP.2018.8461905
   van der Goot R, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2479
   van der Maaten L, 2012, MACH LEARN, V87, P33, DOI 10.1007/s10994-011-5273-4
   Volansky V, 2015, DIGIT SCHOLARSH HUM, V30, P98, DOI 10.1093/llc/fqt031
   Xu W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5052
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Yang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P87
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
   Zang XX, 2020, NLP FOR CONVERSATIONAL AI, V0, P109
   Zhang WN, 2019, ARXIV, V0, P0
   Zhang ZC, 2019, IEEE ACCESS, V7, P168849, DOI 10.1109/ACCESS.2019.2954766
   Zhu Q, 2020, T ASSOC COMPUT LING, V8, P281, DOI 10.1162/tacl_a_00314
   Zuo Lei, 2021, ARXIV PREPRINT ARXIV, V0, P0
NR 69
TC 0
Z9 0
U1 1
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JAN 12
PY 2023
VL 11
IS 
BP 139
EP 156
DI 10.1162/tacl_a_00539
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8J8EU
UT WOS:000922645500009
DA 2023-11-10
ER

PT J
AU Chen, ZH
   Wu, M
   Chan, AL
   Li, XL
   Ong, YS
AF Chen, Zhenghua
   Wu, Min
   Chan, Alvin
   Li, Xiaoli
   Ong, Yew-Soon
TI Survey on AI Sustainability: Emerging Trends on Learning Algorithms and Research Challenges
SO IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE
LA English
DT Article
DE Artificial intelligence; Sustainable development; Costs; Green products; Market research; Research and development; Learning systems; Algorithm design and analysis
ID neural-networks; machine; efficient; fairness; privacy; game; go
AB Artificial Intelligence (AI) is a fast-growing research and development (R&D) discipline which is attracting increasing attention because it promises to bring vast benefits for consumers and businesses, with considerable benefits promised in productivity growth and innovation. To date, significant accomplishments have been reported in many areas that have been deemed challenging for machines, ranging from computer vision, natural language processing, audio analysis to smart sensing and many others. The technology trend in realizing success has developed towards increasingly complex and large-size AI models to solve more complex problems at superior performance and robustness. This rapid progress, however, has taken place at the expense of substantial environmental costs and resources. In addition, debates on the societal impacts of AI, such as fairness, safety, and privacy, have continued to grow in intensity. These issues have reflected major concerns pertaining to the sustainable development of AI. In this work, major trends in machine learning approaches that can address the sustainability problem of AI have been reviewed. Specifically, the emerging AI methodologies and algorithms are examined for addressing the sustainability issue of AI in two major aspects, i.e., environmental sustainability and social sustainability of AI. Then, the major limitations of the existing studies are highlighted, and potential research challenges and directions are proposed for the development of the next generation of sustainable AI techniques. It is believed that this technical review can help promote a sustainable development of AI R&D activities for the research community.
C1 [Chen, Zhenghua; Wu, Min; Chan, Alvin; Li, Xiaoli; Ong, Yew-Soon] ASTAR, Singapore, Singapore.
   [Chan, Alvin; Li, Xiaoli; Ong, Yew-Soon] Nanyang Technol Univ, Singapore, Singapore.
C3 Agency for Science Technology & Research (A*STAR); Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Chen, ZH (通讯作者)，ASTAR, Singapore, Singapore.
EM chen0832@e.ntu.edu.sg
FU A*STAR Center for Frontier AI Research; School of Computer Science and Engineering at Nanyang Technological University
CR Adi Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, V0, P1615
   Alemdar H, 2017, IEEE IJCNN, V0, PP2547, DOI 10.1109/IJCNN.2017.7966166
   Amberkar A, 2018, 2018 INT C CURRENT T, V0, PP1, DOI 10.1109/ICCTCT.2018.8551185
   Andriushchenko M, 2020, ANN C NEURAL INFORM, V33, P0
   Anneroth, 2019, SUSTAINABLE INVENTOR, V0, P0
   [Anonymous], 1990, ADV NEURAL INFORM PR, V0, P0
   Balunovic M, 2019, P INT C LEARN REPR, V0, P0
   Bellamy Rachel KE, 2018, ARXIV, V0, P0
   Beyer Lucas, 2021, ARXIV, V0, P0
   Blum A, 2020, J MACH LEARN RES, V21, P0
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), V0, PP1, DOI 10.1109/SPW.2018.00009
   Carr AN, 2020, OPENREVIEW, V0, P0
   Caton S, 2020, ARXIV, V0, P0
   Chan A, 2020, ARXIV, V0, P0
   Chan A, 2019, ARXIV, V0, P0
   Chan A, 2020, PROC CVPR IEEE, V0, PP329, DOI 10.1109/CVPR42600.2020.00041
   Chau M, 2008, DECIS SUPPORT SYST, V44, P482, DOI 10.1016/j.dss.2007.06.002
   Chen C, 2020, AAAI CONF ARTIF INTE, V34, P3422
   Chen HP, 2017, IEEE J SEL AREA COMM, V35, P557, DOI 10.1109/JSAC.2017.2659498
   Chen J, 2020, ARXIV, V0, P0
   Chen T, 2020, PROC INT C LEARN REP, V0, P0
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   Chen XL, 2021, PROC CVPR IEEE, V0, PP15745, DOI 10.1109/CVPR46437.2021.01549
   Chen Z, 2021, GEN DEEP LEARNING IM, V0, P0
   Chenet B, 2018, ARXIV, V0, P0
   Choong HX, 2022, ARXIV, V0, P0
   Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7
   Cohen J, 2019, PR MACH LEARN RES, V97, P0
   Croce F, 2020, PR MACH LEARN RES, V119, P0
   Cubuk ED, 2019, PROC CVPR IEEE, V0, PP113, DOI 10.1109/CVPR.2019.00020
   de Penning HLH, 2011, IJCAI 2011 P 22 INT, V0, P0, DOI DOI 10.5591/978-1-57735
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Denil Misha, 2013, ADV NEURAL INFORM PR, V0, PP2148, DOI 10.5555/2999792.2999852
   Devlin J, 2018, ARXIV, V1, P4171
   Dodge S, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017), V0, P0
   Doersch C, 2015, IEEE I CONF COMP VIS, V0, PP1422, DOI 10.1109/ICCV.2015.167
   Drucker H, 1991, INT JOINT C NEUR NET, VII, P145
   Dwork C, 2012, P 3 INN THEOR COMP S, V0, PP214, DOI 10.1145/2090236.2090255
   Etmann C, 2019, PR MACH LEARN RES, V97, P0
   Feldman M, 2015, KDD15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP259, DOI 10.1145/2783258.2783311
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fukuda T, 2017, INTERSPEECH, V0, PP3697, DOI 10.21437/Interspeech.2017-614
   Furlanello T, 2018, INT C MACHINE LEARNI, V0, P1607
   Ganin Yaroslav, 2016, JMLR, V0, PP2, DOI 10.1007/978-3-319-58347-1_10
   Geifman Y, 2017, ADV NEUR IN, V30, P0
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Green B, 2019, P 2019 C FAIRNESS AC, V0, PP90, DOI https://doi.org/10.1145/3287560.3287563
   Grill J, 2020, ADV NEURAL INF PROCE, V33, P21271
   Gu T, 2017, ARXIV, V0, P0
   Guo YH, 2019, PROC CVPR IEEE, V0, PP4800, DOI 10.1109/CVPR.2019.00494
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hagendorff T, 2020, MIND MACH, V30, P99, DOI 10.1007/s11023-020-09517-8
   Han S, 2016, DEEP COMPRESSION COM, V0, P0
   Han S, 2015, ADV NEUR IN, V28, P0
   Hanson S, 1988, ADV NEURAL INFORM PR, V1, P177
   Hao K, 2019, MIT TECHNOL REV, V75, P0
   Hardt M, 2016, ADV NEUR IN, V29, P0
   Hardy S, 2017, ARXIV, V0, P0
   Hassibi B, 1993, 2 ORDER DENVATIVES N, V0, P0
   He Kaiming, 2020, P IEEE CVF C COMP VI, V0, PP9729, DOI 10.1109/CVPR42600.2020.00975
   He T, 2019, IEEE INT CON MULTI, V0, PP1360, DOI 10.1109/ICME.2019.00236
   Hein Matthias, 2017, ADV NEURAL INFORM PR, V0, P0
   Hemmer Patrick, 2022, DEEP LEARNING APPLICATIONS, Volume 3. Advances in Intelligent Systems and Computing (1395), P171, DOI 10.1007/978-981-16-3357-7_7
   Hendrycks D, 2020, ARXIV, V0, P0
   Hendrycks D, 2019, ARXIV, V0, P0
   Hinton G, 2014, PROC NIPS DEEP LEARN, V1050, P0
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hou ZJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P2725, DOI 10.1109/ICASSP39728.2021.9414936
   Hu H, 2016, ARXIV, V0, P0
   Huang QG, 2018, IEEE WINT CONF APPL, V0, PP709, DOI 10.1109/WACV.2018.00083
   Hubara I, 2016, ADV NEUR IN, V29, P0
   Jacob B, 2018, PROC CVPR IEEE, V0, PP2704, DOI 10.1109/CVPR.2018.00286
   Jakubovitz D, 2018, LECT NOTES COMPUT SC, V11216, P525, DOI 10.1007/978-3-030-01258-8_32
   Jamal MA, 2019, PROC CVPR IEEE, V0, PP11711, DOI 10.1109/CVPR.2019.01199
   Jia Robin, 2017, ADVERSARIAL EXAMPLES, V0, P0
   Jiang H, 2020, PR MACH LEARN RES, V108, P702
   Kairouz P, 2019, ARXIV, V0, P0
   Kamiran F, 2012, KNOWL INF SYST, V33, P1, DOI 10.1007/s10115-011-0463-8
   Kannan H, 2018, ARXIV, V0, P0
   Kewei Cheng, 2021, IEEE INTELLIGENT SYSTEMS, V36, P87, DOI 10.1109/MIS.2021.3082561
   Khalili MM, 2021, AAAI CONF ARTIF INTE, V35, P8092
   Khanal SS, 2020, EDUC INF TECHNOL, V25, P2635, DOI 10.1007/s10639-019-10063-9
   Kim B, 2016, ADV NEUR IN, V29, P0
   Kindylidi I, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su132112064
   Kireev K, 2021, ARXIV, V0, P0
   Koch Gregory, 2015, P INT C MACH LEARN W, V2, P0, DOI 10.1136/BMJ.2.5108.1355-C
   Koh PW, 2017, PR MACH LEARN RES, V70, P0
   Komiyama J, 2018, PR MACH LEARN RES, V80, P0
   Komodakis N, 2017, PROC INT C LEARN REP, V0, P0
   Komodakis Nikos, 2018, INT C LEARN REPR ICL, V0, P3
   Konecn J, 2016, ARXIV, V0, P0
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee N, 2018, ARXIV, V0, P0
   LEE S, 2019, ARXIV, V0, P0
   Lee SH, 2018, LECT NOTES COMPUT SC, V11210, P339, DOI 10.1007/978-3-030-01231-1_21
   Leonetti M, 2016, ARTIF INTELL, V241, P103, DOI 10.1016/j.artint.2016.07.004
   Li B, 2021, ARXIV, V0, P0
   Li Hao, 2017, INT C LEARN REPR ICL, V0, P0
   Li QB, 2023, IEEE T KNOWL DATA EN, V35, P3347, DOI 10.1109/TKDE.2021.3124599
   Li X, 2013, P DAT CLASS ALG APPL, V0, P0
   Li X, 2019, PROC INT C LEARN REP, V0, P1
   Liang TL, 2021, NEUROCOMPUTING, V461, P370, DOI 10.1016/j.neucom.2021.07.045
   Liu K, 2018, LECT NOTES COMPUT SC, V11050, P273, DOI 10.1007/978-3-030-00470-5_13
   Liu QD, 2021, PROC CVPR IEEE, V0, PP1013, DOI 10.1109/CVPR46437.2021.00107
   Liu Y, 2020, IEEE INTELL SYST, V35, P70, DOI 10.1109/MIS.2020.2988525
   Liu Z, 2017, IEEE I CONF COMP VIS, V0, PP2755, DOI 10.1109/ICCV.2017.298
   Liuet al, 2018, PROC 25ND ANN NETW D, V0, P0
   Lyu L, 2020, ARXIV, V0, P0
   Ma YZ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4732
   Madry A, 2018, 6 INT C LEARNING REP, V0, P1
   Maltoni D, 2019, NEURAL NETWORKS, V116, P56, DOI 10.1016/j.neunet.2019.03.010
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Mehrabi N, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3457607
   Mensah J, 2019, COGENT SOC SCI, V5, P0, DOI 10.1080/23311886.2019.1653531
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mocanu DC, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-04316-3
   Molnar C, 2020, COMM COM INF SC, V0, P0, DOI DOI 10.1007/978-3-030-65965-3_28
   Narayanan Arvind, 2018, P C FAIRN ACC TRANSP, V1170, P3
   Narayanan D, 2021, INT CONF HIGH PERFOR, V0, P0, DOI DOI 10.1145/3458817.3476209
   Nelson B, 2008, P 1 USENIX WORKSHOP, V8, P1
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Ong YS, 2019, IEEE TETCI, V3, P411, DOI 10.1109/TETCI.2019.2928344
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Papernot N, 2018, ARXIV, V0, P0
   Park W, 2019, PROC CVPR IEEE, V0, PP3962, DOI 10.1109/CVPR.2019.00409
   Patterson David, 2021, ARXIV, V0, P0
   Peng X, 2020, PROC INT C LEARN REP, V0, P0
   Qiao X, 2019, ADV NEURAL INFORM PR, V0, P14004
   Raghunathan A, 2018, ADV NEUR IN, V31, P0
   Rahman MM, 2020, DOMAIN ADAPTATION VI, V0, PP81, DOI 10.1007/978-3-030-30671-7_6
   Raji ID, 2019, AIES 19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, V0, P0
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Renda A, 2020, ARXIV, V0, P0
   Renetal P, 2020, ARXIV, V0, P0
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, V0, P1527
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Romero A, 2014, ARXIV, V0, P0
   Ros AS, 2018, AAAI CONF ARTIF INTE, V0, P1660
   Rosenfeld Elan, 2020, INT C MACHINE LEARNI, V119, P8230
   Schnabel T, 2016, PR MACH LEARN RES, V48, P0
   Schumann R, 2019, P 23 C COMPUTATIONAL, V0, PP472, DOI 10.18653/V1/K19-1044
   Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831
   Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7
   Settles Burr, 2009, ACTIVE LEARNING LIT, V0, P0
   Shafahi A, 2019, ARXIV, V0, P0
   Siddiqui Yawar, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9430, DOI 10.1109/CVPR42600.2020.00945
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Smailovic J, 2014, INFORM SCIENCES, V285, P181, DOI 10.1016/j.ins.2014.04.034
   Smith V, 2017, ADV NEUR IN, V30, P0
   Snell J, 2017, ADV NEUR IN, V30, P0
   Steinhardt J, 2017, ADV NEUR IN, V30, P0
   Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693
   Sun BC, 2017, ADV COMPUT VIS PATT, V0, PP153, DOI 10.1007/978-3-319-58347-1_8
   Sung F, 2018, PROC CVPR IEEE, V0, PP1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2014, ARXIV, V0, P0
   Tan S, 2020, ARXIV, V0, P0
   Tep KS, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P1073, DOI 10.1109/Trustcom.2015.485
   Tian Y, 2019, ARXIV, V0, P0
   Tran B, 2018, ADV NEUR IN, V31, P0
   Tran NH, 2019, IEEE INFOCOM SER, V0, PP1387, DOI 10.1109/INFOCOM.2019.8737464
   Tzeng E, 2017, PROC CVPR IEEE, V0, PP2962, DOI 10.1109/CVPR.2017.316
   Tzeng Eric, 2014, ARXIV14123474, V0, P0, DOI DOI 10.48550/ARXIV.1412.3474
   Valera I, 2018, ADV NEUR IN, V31, P0
   Van Wynsberghe A, 2021, AI ETHICS, V1, P213, DOI 10.1007/S43681-021-00043-6
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT, V0, P0
   Vanschoren J, 2018, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Verma S, 2020, ARXIV201010596, V32, P0
   Vinuesa R, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-019-14108-y
   Vinyals Oriol, 2016, ADV NEURAL INFORM PR, V29, P0, DOI 10.48550/ARXIV.1606.04080
   Wang BL, 2019, P IEEE S SECUR PRIV, V0, PP707, DOI 10.1109/SP.2019.00031
   Wang C-Y, 2020, ARXIV, V0, P0
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P3048, DOI 10.1109/TPAMI.2021.3055564
   Wang LP, 2019, INT CON DISTR COMP S, V0, PP954, DOI 10.1109/ICDCS.2019.00099
   Wang S, 2020, ARXIV200104536, V0, P0
   Wang Y, 2019, IEEE I CONF COMP VIS, V0, PP3522, DOI 10.1109/ICCV.2019.00362
   Wang YY, 2021, KDD 21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1748, DOI 10.1145/3447548.3467326
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Weber M, 2020, ARXIV, V0, P0
   Wen W, 2016, ADV NEURAL INFORM PR, V0, P2074
   Wenger, 2021, ARXIV, V0, P0
   Wertheimer D, 2021, PROC CVPR IEEE, V0, PP8008, DOI 10.1109/CVPR46437.2021.00792
   Wu JX, 2016, PROC CVPR IEEE, V0, PP4820, DOI 10.1109/CVPR.2016.521
   Wu K, 2021, P 30 INT JOINT C ART, V0, P3192
   Wu YC, 2020, PROC VLDB ENDOW, V13, P2090, DOI 10.14778/3407790.3407811
   Xiao H, 2015, NEUROCOMPUTING, V160, P53, DOI 10.1016/j.neucom.2014.08.081
   Xie CH, 2019, PROC CVPR IEEE, V0, PP501, DOI 10.1109/CVPR.2019.00059
   Xu DP, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1452
   Xu H, 2020, INT J AUTOM COMPUT, V17, P151, DOI 10.1007/s11633-019-1211-x
   Xu Q, 2022, IEEE T IND ELECTRON, V69, P2022, DOI 10.1109/TIE.2021.3057030
   Yang P, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3339474
   Yang Q, 2019, FEDERATED LEARNING, V0, P0
   Yang S, 2019, ARXIV, V0, P0
   Yim J, 2017, PROC CVPR IEEE, V0, PP7130, DOI 10.1109/CVPR.2017.754
   Yu JH, 2018, PROC CVPR IEEE, V0, PP5505, DOI 10.1109/CVPR.2018.00577
   Yuan F, 2021, AAAI CONF ARTIF INTE, V35, P14284
   Yuan TN, 2021, PROC CVPR IEEE, V0, PP5326, DOI 10.1109/CVPR46437.2021.00529
   Zafar MB, 2017, PR MACH LEARN RES, V54, P962
   Zelasko P, 2021, ARXIV, V0, P0
   Zemel Rich, 2013, ICML, V0, P0, DOI DOI 10.5555/3042817.3042973
   Zhang H, 2019, PR MACH LEARN RES, V97, P0
   Zhang Jingfeng, 2020, INT C MACHINE LEARNI, V0, P11278
   Zhang Y, 2018, PROC CVPR IEEE, V0, PP4320, DOI 10.1109/CVPR.2018.00454
   Zhao R, 2019, MECH SYST SIGNAL PR, V115, P213, DOI 10.1016/j.ymssp.2018.05.050
   Zhou A, 2017, ARXIV, V0, P0
   Zhou S, 2016, ARXIV, V0, P0
NR 213
TC 0
Z9 0
U1 12
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1556-603X
EI 1556-6048
J9 IEEE COMPUT INTELL M
JI IEEE Comput. Intell. Mag.
PD MAY 15
PY 2023
VL 18
IS 2
BP 60
EP 77
DI 10.1109/MCI.2023.3245733
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA E2CL0
UT WOS:000973677500011
DA 2023-11-10
ER

PT J
AU AlArfaj, AA
   Hakami, NA
   Mahmoud, HAH
AF AlArfaj, Abeer Abdulaziz
   Hakami, Nada Ali
   Mahmoud, Hanan Ahmed Hosni
TI Predicting Violence-Induced Stress in an Arabic Social Media Forum
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Arabic language analysis; violence-induced stress detection; hybrid model; deep learning
AB Social Media such as Facebook plays a substantial role in virtual com-munities by sharing ideas and ideologies among different populations over time. Social interaction analysis aids in defining people's emotions and aids in assessing public attitudes, towards different issues such as violence against women and chil-dren. In this paper, we proposed an Arabic language prediction model to identify the issue of Violence-Induced Stress in social media. We searched for Arabic posts of many countries through Facebook application programming interface (API). We discovered that the stress state of a battered woman is usually related to her friend's stress states on Facebook. We applied a large real database from Facebook platforms to analytically investigate the correlation of violence-induced stress states and the victim interactions on social media. We extracted a set of tex-tual, spatial, and interaction attributes from various features. Therefore, we are proposing a hybrid model-an interaction graph model incorporated in a deep learning neural model to leverage post content and interaction data for vio-lence-induced stress detection. Experiments depict that our proposed hybrid mod-el can enhance the prediction performance by 10% in F1-measure. Also, considering the user interaction information can learn an interesting phenomenon, where, the sparse social interactions of violence-induced stress stressed victims is higher by around 15% percent non-battered users, signifying that the structure of the friends of such victims is less connected than non-stressed users.
C1 [AlArfaj, Abeer Abdulaziz; Mahmoud, Hanan Ahmed Hosni] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11671, Saudi Arabia.
   [Hakami, Nada Ali] Jazan Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, Jazan, Saudi Arabia.
C3 Princess Nourah bint Abdulrahman University; Jazan University
RP Hakami, NA (通讯作者)，Jazan Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, Jazan, Saudi Arabia.
EM nmhakami@jazanu.edu.sa
FU Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia [PNURSP2022R113]
CR Abdul-Mageed M, 2014, COMPUT SPEECH LANG, V28, P20, DOI 10.1016/j.csl.2013.03.001
   Abdulla NA, 2014, INT J INF TECHNOL WE, V9, P55, DOI 10.4018/ijitwe.2014070104
   Abdullah M, 2021, INT J COMPUTERS APPL, V7, P1
   Ali MNY, 2019, INT J AMBIENT COMPUT, V10, P92, DOI 10.4018/IJACI.2019070106
   [Anonymous], 2014, P 17 ACM C COMP SUPP, V0, P0, DOI DOI 10.1145/2531602.2531675
   Baer L, 2000, PSYCHOTHER PSYCHOSOM, V69, P35, DOI 10.1159/000012364
   Bagroy S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI17), V0, PP1634, DOI 10.1145/3025453.3025909
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cavazos-Rehg PA, 2016, COMPUT HUM BEHAV, V54, P351, DOI 10.1016/j.chb.2015.08.023
   Coppersmith G, 2015, P 2 WORKSHOP CLPSYCH, V0, PP31, DOI 10.3115/V1/W15-1204
   De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P2098, DOI 10.1145/2858036.2858207
   DeChoudhury M, 2019, PROC 7 INT AAAI C WE, V0, P44
   Elgohary F, 2019, INT J ENG RES APPL, V3, P100
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Kern ML, 2016, PSYCHOL METHODS, V21, P507, DOI 10.1037/met0000091
   Lakshmi B, 2019, INT J AMBIENT COMPUT, V10, P34, DOI 10.4018/IJACI.2019040103
   Lin CT, 2017, IEEE ACCESS, V5, P10612, DOI 10.1109/ACCESS.2017.2675884
   Mowery D, 2015, P 2 WORKSHOP COMPUTA, V0, P89
   Pedersen T, 2015, P 2 WORKSHOP COMPUTA, V0, PP46, DOI 10.3115/V1/W15-1206
   Peng H, 2019, IEEE ACCESS, V7, P92630, DOI 10.1109/ACCESS.2019.2927121
   Saad M, 2020, TEXT PREPROCESSING, V29, P351
   Schwartz H, 2019, PROC WORKSHOP COMPUT, V0, P121
   Shah AM, 2021, INT J MED INFORM, V149, P0, DOI 10.1016/j.ijmedinf.2021.104434
   Shah AM, 2020, J AMB INTEL HUM COMP, V11, P2925, DOI 10.1007/s12652-019-01434-8
   Smith K, 2019, NATURE NEWS, V15, P210
   Subhani AR, 2017, IEEE ACCESS, V5, P13545, DOI 10.1109/ACCESS.2017.2723622
   Sun Y, 2018, PROC SIAM INT C DATA, V0, P195
   Tadesse MM, 2019, IEEE ACCESS, V7, P44883, DOI 10.1109/ACCESS.2019.2909180
   Tsugawa S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, PP3187, DOI 10.1145/2702123.2702280
   van Kasteren TLM, 2010, PERS UBIQUIT COMPUT, V14, P489, DOI 10.1007/s00779-009-0277-9
   Wang RJ, 2019, INT J AMBIENT COMPUT, V10, P17, DOI 10.4018/IJACI.2019070102
   Yazdavar Amir Hossein, 2017, PROC IEEE ACM INT CONF ADV SOC NETW ANAL MIN, V2017, P1191, DOI 10.1145/3110025.3123028
   Zhang XR, 2022, CMC-COMPUT MATER CON, V71, P3035, DOI 10.32604/cmc.2022.022304
   Zhang XR, 2022, COMPUT SYST SCI ENG, V41, P1043, DOI 10.32604/csse.2022.022305
NR 34
TC 0
Z9 0
U1 0
U2 8
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD JUN 15
PY 2023
VL 35
IS 2
BP 1423
EP 1439
DI 10.32604/iasc.2023.028067
PG 17
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA 5K3QZ
UT WOS:000869645300009
DA 2023-11-10
ER

PT J
AU Godslove, JF
   Nayak, AK
AF Godslove, Julius Femi
   Nayak, Ajit Kumar
TI Trilingual conversational intent decoding for response retrieval
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article; Early Access
DE Trilingual conversational question answering; Natural language processing; Information retrieval; Natural language inferencing; Natural language understanding
AB The rich diversity of human language allows speakers to seamlessly transition between multiple languages during conversations. While humans have the remarkable ability to become proficient in multiple languages in a short period, developing machines that can converse in multiple natural languages with an understanding of diverse dialects requires sophisticated Natural Language Processing (NLP) techniques such as dialect recognition and intent extraction. This facilitates mutual understanding between parties who use phrases, sentences, words, or expressions from multiple languages within a single context. The work in this paper, propose a trilingual approach to multi-dialect conversation modeling within the same conversational session and context for a mix of English, Hindi-English text, Hindi-Devanagari text and Yoruba text. The model identifies the language used and determines the intent behind a query to respond in the same dialect. Our model is capable of detecting the end of a conversation, and it also detects the predominant dialect and responds accordingly in scenarios where a user's input query contains a mix of languages. This approach is particularly useful in situations where there is limited data available for multilingual or trilingual conversation tasks based on Intent Detection (ID). We evaluate our proposed pipeline and model on three benchmark ID datasets and a trilingual dialogue dataset for response retrieval by intent decoding. Our model outperforms existing approaches in terms of performance metrics and has faster training time. Moreover, our trilingual approach to multi-dialect conversation modeling provides a versatile tool for efficient and effective inter-dialect conversational automation, even when dealing with large datasets, with minimal parameters and low resource overhead. The lightweight architectural pipeline and efficient algorithms used in our model contribute to its high performance and versatility.
C1 [Godslove, Julius Femi] Siksha O Anusandhan Univ, Dept Comp Sci & Engn, J-15,Khandagiri Marg, Bhubaneswar 751030, Odisha, India.
   [Nayak, Ajit Kumar] Siksha O Anusandhan Univ, Dept Comp Sci & Informat Technol, J-15,Khandagiri Marg, Bhubaneswar 751030, Odisha, India.
C3 Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University
RP Godslove, JF (通讯作者)，Siksha O Anusandhan Univ, Dept Comp Sci & Engn, J-15,Khandagiri Marg, Bhubaneswar 751030, Odisha, India.
EM Juliusgodslove88@gmail.com; Ajitnayak@soa.ac.in
FU We aim to promote transparency and reproducibility in our research, and we encourage readers to use these resources to further their own studies.
CR Adiwardana D, 2020, ARXIV, V0, P0
   Albadr MAA, 2019, INT J SPEECH TECHNOL, V22, P711, DOI 10.1007/s10772-019-09621-w
   Albadr MAA, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0194770
   Anand A, 2020, ARXIV, V0, P0
   Avishek A, 2021, ACM SIGIR FORUM, V54, P1, DOI 10.1145/3451964.3451967
   Aymen BEM, 2021, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2103.09185
   Babatunde AN, 2021, INT J SPEECH TECHNOL, V24, P979, DOI 10.1007/s10772-021-09852-w
   Babatunde AN, 2022, J DIG INNOVATIONS CO, V10, P69
   Bahdanau D, 2016, ARXIV, V0, P0
   Bassett C, 2019, AI SOC, V34, P803, DOI 10.1007/s00146-018-0825-9
   Cai RC, 2017, INT CONF DAT MIN WOR, V0, PP430, DOI 10.1109/ICDMW.2017.62
   Cheng SH, 2021, INFORM SCIENCES, V579, P15, DOI 10.1016/j.ins.2021.07.091
   Dalton J, 2020, ARXIV, V0, P0
   Dwivedi VP, 2021, ARXIV, V0, P0
   ELAffendi MA, 2018, 2018 SIXTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION, V0, P0
   Firdaus M, 2023, INFORM FUSION, V91, P299, DOI 10.1016/j.inffus.2022.09.029
   Glaese A, 2022, ARXIV, V0, P0
   Goo C-W, 2018, P C N AM CH ASS COMP, V2, P753
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Immidisetti S, 2021, THESIS, V325, P0
   Karpukhin V, 2020, ARXIV, V0, P0
   Kato T, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), V0, P60
   Kaya H, 2018, NEUROCOMPUTING, V275, P1028, DOI 10.1016/j.neucom.2017.09.049
   Kim HK, 2017, NEUROCOMPUTING, V266, P336, DOI 10.1016/j.neucom.2017.05.046
   Kunchukuttan A, 2018, ARXIV, V0, P0
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Lin ZH, 2017, ARXIV, V0, P0
   Liu B, 2016, INTERSPEECH, V0, PP685, DOI 10.21437/Interspeech.2016-1352
   Mabrouk A, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21020636
   Maia A, 2022, P 2022 C EMPIRICAL M, V0, P138
   Ouyang L, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2203.02155
   Oyelere SS, 2018, EDUC INF TECHNOL, V23, P467, DOI 10.1007/s10639-017-9613-2
   Peerat L, 2022, CL RELKT CROSS LINGU, V0, P2141
   Perkins H, 2020, ARXIV, V0, P0
   Ravuri S, 2015, INTERSPEECH, V0, P2832
   Sangodiah Anbuselvan, 2015, JOURNAL OF THEORETICAL AND APPLIED INFORMATION TECHNOLOGY, V71, P386
   Siblini W, 2019, ARXIV, V0, P0
   Siddhi P, 2020, INT J ADV TRENDS COM, V9, P9155
   Thoppilan R, 2022, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2201.08239
   Tri N, 2016, COCO NIPS, V0, P0, DOI DOI 10.48550/arXiv.1611.09268
   Tu JX, 2019, MATH PROBL ENG, V2019, P0, DOI 10.1155/2019/2039872
   Tur G, 2011, SPOKEN LANGUAGE UNDE, V0, P0
   Usman H, 2021, 2 INT C PERS TECHN, V3, P206, DOI 10.1007/978-3-030-69143-117
   Vedula N, 2019, ARXIV, V0, P0
   Vulic Ivan, 2021, ARXIV, V0, P0
   Wang JP, 2015, AAAI CONF ARTIF INTE, V0, P339
   Wang X, 2018, IEEE ACM T AUDIO SPE, V26, P890
   Pham XL, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON EDUCATION AND E-LEARNING (ICEEL 2018), V0, PP16, DOI 10.1145/3291078.3291115
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yaseen ZM, 2019, J HYDROL, V569, P387, DOI 10.1016/j.jhydrol.2018.11.069
   Ye W, 2017, IOP C SERIES MAT SCI, V261, P0
   Yilin S, 2021, P 59 ANN M ASS COMP, V1, P2443
   Zhang Y, 2016, COLING, V0, P3198
NR 53
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s10115-023-01972
EA SEP 2023
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA Q6XJ7
UT WOS:001058931700001
DA 2023-11-10
ER

PT J
AU Liu, Q
   Geng, XB
   Huang, HY
   Qin, T
   Lu, J
   Jiang, DX
AF Liu, Qian
   Geng, Xiubo
   Huang, Heyan
   Qin, Tao
   Lu, Jie
   Jiang, Daxin
TI MGRC: An End-to-End Multigranularity Reading Comprehension Model for Question Answering
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Bit error rate; Task analysis; Knowledge discovery; Training; Pipelines; Semantics; Learning systems; Machine reading comprehension (MRC); natural language processing; question answering
AB Deep neural network-based models have achieved great success in extractive question answering. Recently, many works have been proposed to model multistage matching for this task, which usually first retrieve relevant paragraphs or sentences and then extract an answer span from the retrieved results. However, such a pipeline-based approach suffers from the error propagation problem, especially for sentence-level retrieval that is usually difficult to achieve high accuracy due to the severe data imbalance problem. Furthermore, since the paragraph/sentence selector and the answer extractor are closely related, modeling them independently does not fully exploit the power of multistage matching. To solve these problems, we propose a novel end-to-end multigranularity reading comprehension model, which is a unified framework to explicitly model three matching granularities, including paragraph identification, sentence selection, and answer extraction. Our approach has two main advantages. First, the end-to-end approach alleviates the error propagation problem in both the training and inference phases. Second, the shared features in a unified model improve the learning of representations of different matching granularities. We conduct a comprehensive comparison on four large-scale datasets (SQuAD-open, NewsQA, SQuAD 2.0, and SQuAD Adversarial) and verify that the proposed approach outperforms both the vanilla BERT model and existing multistage matching approaches. We also conduct an ablation study and verify the effectiveness of the proposed components in our model structure.
C1 [Liu, Qian; Lu, Jie] Univ Technol Sydney, Australian Artificial Intelligence Inst, Sydney, NSW 2007, Australia.
   [Liu, Qian; Huang, Heyan] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
   [Geng, Xiubo; Qin, Tao; Jiang, Daxin] Microsoft Co, STCA NLP Grp, Beijing 100190, Peoples R China.
C3 University of Technology Sydney; Beijing Institute of Technology
RP Geng, XB; Jiang, DX (通讯作者)，Microsoft Co, STCA NLP Grp, Beijing 100190, Peoples R China.
EM xigeng@microsoft.com; djiang@microsoft.com
FU National Natural Science Foundation of China [U19B2020]
CR Alberti C, 2019, ABS190108634 CORR, V0, P1
   [Anonymous], 2018, PROC INT C LEARN REP, V0, P0
   Chen D, 2018, THESIS STANFORD U ST, V0, P0
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Choi Eunsol, 2017, P 55 ANN M ASS COMP, V0, P209
   Das R, 2019, P ICLR, V0, P1
   Devlin J, 2018, ARXIV, V1, P4171
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Hu MH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2285
   Hu MH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2077
   Jia Robin, 2017, P 2017 C EMP METH NA, V0, PP2021, DOI 10.18653/V1/D17-1215
   Kingma DP, 2014, C TRACK P, V0, P0
   Kundu S, 2018, AAAI CONF ARTIF INTE, V0, P5828
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   Lin YK, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1736
   Liu DH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6241
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Min S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1725
   Nguyen T, 2016, P INT MICR VEH COMP, V0, PP1, DOI 10.13031/AIM.20162444593
   Nie YX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2553
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Seo Min Joon, 2017, ICLR, V0, P0
   Shen T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2442
   Swayamdipta S, 2018, P ICLR, V0, P1
   Tay Y, 2018, ADV NEUR IN, V31, P0
   Trischler Adam, 2017, P 2 WORKSH REPR LEAR, V0, PP191, DOI 10.18653/V1/W17-2623
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang SH, 2018, AAAI CONF ARTIF INTE, V0, P5981
   Wang Shuohang, 2017, P 5 INT C LEARN REPR, V0, P0
   Wang W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1705
   Weissenborn D, 2017, ABS170304816 CORR, V0, P1
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zheng B, 2020, P 58 ANN M ASS COMPU, V0, P6708
   Zhong V, 2019, P 7 INT C LEARN REPR, V0, P1
NR 39
TC 5
Z9 5
U1 1
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD MAY 15
PY 2023
VL 34
IS 5
BP 2594
EP 2605
DI 10.1109/TNNLS.2021.3107029
EA SEP 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA F4FE0
UT WOS:000732918100001
PM 34478387
DA 2023-11-10
ER

PT J
AU Lu, Y
   Guo, C
   Dou, Y
   Dai, XY
   Wang, FY
AF Lu, Yue
   Guo, Chao
   Dou, Yong
   Dai, Xingyuan
   Wang, Fei-Yue
TI Could ChatGPT Imagine: Content Control for Artistic Painting Generation Via Large Language Models
SO JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS
LA English
DT Article
DE Intelligent systems; Human-machine interactions; Artistic painting generation; Large language model; ChatGPT; Linguistic intelligence
ID parallel; metaverses
AB Intelligent systems and human-machine interactions have consistently provided convenience in both work and daily life. Artificial Intelligence Generated Content (AIGC) can assist humans in artistic creation by generating painting images based on textual descriptions. However, the quality of generated painting images depends heavily on well-designed prompts, which are labor-intensive and time-consuming in painting creation. Large Language Models (LLMs) like ChatGPT have shown impressive performance in linguistic tasks such as question answering and logical inference, demonstrating strong linguistic intelligence. This paper proposes an assistant painting creation approach to provide precise content control for painting generation by combining LLMs with text-to-image generative models and evaluates the performance of the proposed approach on painting content generation and painting element arrangement. The experimental results show that our approach can provide clear guidance on rich painting content and reasonable arrangements of painting elements, demonstrating its ability of text-based painting scene imagination. In painting generation tasks, LLMs like ChatGPT can help the text-to-image models with precise control over the painting content and improve the overall painting results.
C1 [Lu, Yue] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Guo, Chao; Dai, Xingyuan; Wang, Fei-Yue] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.
   [Dou, Yong] Macao Univ Sci & Technol, Macao Inst Syst Engn, Macau 999078, Peoples R China.
C3 Shandong University; Chinese Academy of Sciences; Institute of Automation, CAS; Macau University of Science & Technology
RP Wang, FY (通讯作者)，Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.
EM feiyue.wang@ia.ac.cn
FU This work is supported in part by Skywork Intelligence Culture amp; Technology LTD.; Skywork Intelligence Culture amp; Technology LTD.
CR Antaki F, 2023, MEDRXIV, V0, P2023
   Bang Y, 2023, ARXIV, V0, P0
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Bubeck S, 2023, ARXIV, V0, P0
   Chen JQ, 2022, J INTELL ROBOT SYST, V105, P0, DOI 10.1007/s10846-022-01648-7
   Dai XY, 2022, FRONT INFORM TECH EL, V23, P1795, DOI 10.1631/FITEE.2200323
   Ding BS, 2023, ARXIV, V0, P0
   do Nascimento LM, 2021, J INTELL ROBOT SYST, V102, P0, DOI 10.1007/s10846-021-01364-8
   Fan LL, 2023, IEEE T SYST MAN CY-S, V53, P3485, DOI 10.1109/TSMC.2022.3227209
   Frieder S, 2023, ARXIV, V0, P0
   Guo BY, 2023, ARXIV, V0, P0
   Guo C, 2019, CHIN J INTELL SCI TE, V1, P335
   Guo C, 2023, IEEE-CAA J AUTOMATIC, V10, P835, DOI 10.1109/JAS.2023.123555
   Guo C, 2023, IEEE T SYST MAN CY-S, V53, P2200, DOI 10.1109/TSMC.2022.3230406
   Guo C, 2022, J INTELL ROBOT SYST, V105, P0, DOI 10.1007/s10846-022-01616-1
   Guo C, 2020, IEEE INT CON AUTO SC, V0, PP673, DOI 10.1109/case48305.2020.9216814
   Hao Y, 2022, ARXIV, V0, P0
   Hu W, 2023, PREPRINT, V0, P0
   Ishihara Y, 2021, J INTELL ROBOT SYST, V103, P0, DOI 10.1007/s10846-021-01465-4
   Jeblick K, 2022, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2212.14882
   Jiao WX, 2023, ARXIV, V0, P0
   Kang MZ, 2023, IEEE T SYST MAN CY-S, V53, P3718, DOI 10.1109/TSMC.2022.3230830
   Karimov A, 2023, J INTELL ROBOT SYST, V107, P0, DOI 10.1007/s10846-023-01831-4
   Kosinski M, 2023, ARXIV, V0, P0
   Li JJ, 2023, IEEE T SYST MAN CY-S, V53, P3389, DOI 10.1109/TSMC.2022.3226748
   Li XX, 2023, ARXIV, V0, P0
   Liu HL, 2022, J INTELL ROBOT SYST, V104, P0, DOI 10.1007/s10846-021-01564-2
   Liu KH, 2023, IEEE T SYST MAN CY-S, V53, P3858, DOI 10.1109/TSMC.2022.3233588
   Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 22), V0, P0, DOI DOI 10.1145/3491102.3501825
   Lu JW, 2022, IEEE-CAA J AUTOMATIC, V9, P2079, DOI 10.1109/JAS.2022.106094
   LU J, 2022, FRONT INFORM TECH EL, V23, P991, DOI 10.1631/FITEE.2240000
   Lu Y, 2023, IEEE INTELL SYST, V38, P31, DOI 10.1109/MIS.2023.3260992
   Lu Y, 2022, IEEE T COMPUT SOC SY, V0, P0, DOI DOI 10.1109/TCSS.2022.3223539
   Lu Y, 2022, NEUROCOMPUTING, V490, P163, DOI 10.1016/j.neucom.2022.01.068
   [鲁越 Lu Yue], 2020, 自动化学报 ACTA AUTOMATICA SINICA, V46, P2239
   Mitrovic S, 2023, ARXIV, V0, P0
   Murray N, 2012, PROC CVPR IEEE, V0, PP2408, DOI 10.1109/CVPR.2012.6247954
   Nichol AQ, 2022, ICML, V0, P16784
   Oppenlaender J, 2022, ARXIV, V0, P0
   Ouyang L, 2022, ADV NEURAL INFORM PR, V0, P0
   Qiao SF, 2023, ARXIV, V0, P0
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Ramesh A, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2204.06125
   Rombach R, 2022, PROC CVPR IEEE, V0, PP10674, DOI 10.1109/CVPR52688.2022.01042
   Saharia Chitwan, 2022, ADV NEURAL INFORM PR, V2, P0
   Shen Y, 2022, IEEE-CAA J AUTOMATIC, V9, P2047, DOI 10.1109/JAS.2022.106115
   Song HF, 2022, J INTELL ROBOT SYST, V106, P0, DOI 10.1007/s10846-022-01652-x
   Strathearn C, 2021, J INTELL ROBOT SYST, V101, P0, DOI 10.1007/s10846-021-01332-2
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Wang F-Y, 2017, PARALLEL ART INTELLI, V0, P0
   Wang Fei-yue, 2004, CONTROL AND DECISION, V19, P485
   Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486
   Wang FY, 2022, FRONT INFORM TECH EL, V23, P1142, DOI 10.1631/FITEE.2100418
   Wang J, 2022, IEEE T SYST MAN CY-S, V0, P1
   Wang KF, 2017, ARTIF INTELL REV, V48, P299, DOI 10.1007/s10462-017-9569-z
   Wang X, 2022, IEEE T SYST MAN CY-S, V0, P1
   Wang XJ, 2022, IEEE-CAA J AUTOMATIC, V9, P2055, DOI 10.1109/JAS.2022.106103
   Wang Y, 2023, PREPRINT, V0, P0
   Wang Y, 2022, IEEE T SYST MAN CY-S, V0, P1
   Wang YT, 2022, IEEE-CAA J AUTOMATIC, V9, P2071, DOI 10.1109/JAS.2022.106091
   Wei J, 2022, ADV NEURAL INFORM PR, V35, P24824
   Yang J, 2022, IEEE-CAA J AUTOMATIC, V9, P2063, DOI 10.1109/JAS.2022.106097
   Ye PJ, 2022, FRONT INFORM TECH EL, V23, P1765, DOI 10.1631/FITEE.2100335
   Yue Lu, 2021, 2021 IEEE 1ST INTERNATIONAL CONFERENCE ON DIGITAL TWINS AND PARALLEL INTELLIGENCE (DTPI), V0, PP156, DOI 10.1109/DTPI52967.2021.9540081
   Zhang B, 2021, ARXIV, V0, P0
   Zhang H, 2022, IEEE T SYST MAN CY-S, V0, P1
   Zhou J, 2023, FRONT INFORM TECH EL, V0, P0, DOI DOI 10.1631/FITEE.2300089
   Zhu BH, 2023, ARXIV, V0, P0
NR 68
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-0296
EI 1573-0409
J9 J INTELL ROBOT SYST
JI J. Intell. Robot. Syst.
PD OCT 15
PY 2023
VL 109
IS 2
BP 
EP 
DI 10.1007/s10846-023-01956-6
PG 15
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA U3DA1
UT WOS:001083626300001
DA 2023-11-10
ER

PT J
AU Punetha, N
   Jain, G
AF Punetha, Neha
   Jain, Goonjan
TI Game theory and MCDM-based unsupervised sentiment analysis of restaurant reviews
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Sentiment classification; MCDM; Game theory; Reviews; Emotion analysis
ID model; network; lexicon; system
AB Sentiment Analysis is a method to identify, extract, and quantify people's feelings, opinions, or attitudes. The wealth of online data motivates organizations to keep tabs on customers' opinions and feelings by turning to sentiment analysis tasks. Along with the sentiment analysis, the emotion analysis of written reviews is also essential to improve customer satisfaction with restaurant service. Due to the availability of massive online data, various computerized methods are proposed in the literature to decipher text sentiments. The majority of current methods rely on machine learning, which necessitates the pre-training of large datasets and incurs substantial space and time complexity. To address this issue, we propose a novel unsupervised sentiment classification model. This study presents an unsupervised mathematical optimization framework to perform sentiment and emotion analysis of reviews. The proposed model performs two tasks. First, it identifies a review's positive and negative sentiment polarities, and second, it determines customer satisfaction as either satisfactory or unsatisfactory based on a review. The framework consists of two stages. In the first stage, each review's context, rating, and emotion scores are combined to generate performance scores. In the second stage, we apply a non-cooperative game on performance scores and achieve Nash Equilibrium. The output from this step is the deduced sentiment of the review and the customer's satisfaction feedback. The experiments were performed on two restaurant review datasets and achieved state-of-the-art results. We validated and established the significance of the results through statistical analysis. The proposed model is domain and language-independent. The proposed model ensures rational and consistent results.
C1 [Punetha, Neha; Jain, Goonjan] Delhi Technol Univ, Dept Appl Math, New Delhi, India.
C3 Delhi Technological University
RP Jain, G (通讯作者)，Delhi Technol Univ, Dept Appl Math, New Delhi, India.
EM nehapunetha80@gmail.com; goonjanjain@dtu.ac.in
CR Afzaal M, 2016, ADV FUZZY SYST, V2016, P0, DOI 10.1155/2016/6965725
   Al-Mashhadany AK, 2021, INDONESIAN J ELECT E, V21, P1759, DOI 10.11591/IJEECS.V21.I3.PP1759-1770
   Almutairi K, 2022, INT J ENERG RES, V46, P6766, DOI 10.1002/er.7620
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Biaou BOS, 2022, J KING SAUD UNIV-COM, V34, P2451, DOI 10.1016/j.jksuci.2020.09.015
   Billyan Baiq, 2019, 2019 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATIONS TECHNOLOGY (ICOIACT), V0, P543
   Birjali M, 2021, KNOWL-BASED SYST, V226, P0, DOI 10.1016/j.knosys.2021.107134
   Carosia AED, 2021, EXPERT SYST APPL, V184, P0, DOI 10.1016/j.eswa.2021.115470
   Chiha R, 2022, APPL INTELL, V52, P17845, DOI 10.1007/s10489-022-03279-9
   Collins BC, 2022, EXTRACT IND SOC, V10, P0, DOI 10.1016/j.exis.2022.101094
   Colomo-Palacios R, 2017, PERVASIVE MOB COMPUT, V38, P505, DOI 10.1016/j.pmcj.2016.03.001
   Dahooie JH, 2021, TECHNOL FORECAST SOC, V173, P0, DOI 10.1016/j.techfore.2021.121158
   Debnath A, 2018, J BUS ECON MANAG, V19, P154, DOI 10.3846/16111699.2017.1401553
   Donadi M, 2018, SYSTEM SENTIMENT ANA, V0, P1
   Du CD, 2021, INFORM FUSION, V68, P118, DOI 10.1016/j.inffus.2020.11.003
   Nguyen DN, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-03011-6
   Fikri M, 2019, INDONES J ELECT ENG, V13, P902, DOI 10.11591/ijeecs.v13.i3.pp902-909
   Fiok K, 2021, EXPERT SYST APPL, V186, P0, DOI 10.1016/j.eswa.2021.115771
   García-Pablos A, 2018, EXPERT SYST APPL, V91, P127, DOI 10.1016/j.eswa.2017.08.049
   Govindarajan M, 2014, SENTIMENT ANAL RESTA, V0, P0
   Gu T, 2022, APPL INTELL, V0, PP1, DOI 10.1007/S10489-022-03630-0/TABLES/6
   Han HY, 2018, MULTIMED TOOLS APPL, V77, P21265, DOI 10.1007/s11042-017-5529-5
   Hashemkhani Zolfani S, 2014, BUS MANAG, V0, PP191, DOI 10.3846/bm.2014.024
   Hemalatha S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), V0, PP700, DOI 10.1109/iccs45141.2019.9065812
   Hossain N, 2020, 2020 11 INT C COMP C, V0, P0, DOI DOI 10.1109/ICCCNT49239.2020.9225328
   Hu JH, 2020, INT T OPER RES, V27, P1236, DOI 10.1111/itor.12569
   Ileri M, 2021, HORA 2021 3 INT C HU, V0, P0, DOI DOI 10.1109/HORA52670.2021.9461354
   Jain G, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3502739
   Jain L, 2020, KNOWL-BASED SYST, V203, P0, DOI 10.1016/j.knosys.2020.106158
   Jain PK, 2021, COMPUT SCI REV, V41, P0, DOI 10.1016/j.cosrev.2021.100413
   Jindal K, 2021, MATER TODAY-PROC, V0, P0, DOI DOI 10.1016/j.matpr.2021.01.048
   Jo Y, 2011, P 4 ACM INT C WEB SE, V0, PP815, DOI 10.1145/1935826.1935932
   Kaden M, 2014, P EUR S ART NEUR NET, V0, P47
   Kardakis S, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11093883
   Khotimah DAK, 2018, SENTIMENT DETECTION, V0, P0
   Kim S, 2013, P 27 AAAI C ARTIFICI, V0, PP526, DOI 10.1609/AAAI.V27I1.8700
   Kolios A, 2016, ENERGIES, V9, P0, DOI 10.3390/en9070566
   Larsono RA, 2019, PROCEEDINGS OF 2019 12TH INTERNATIONAL CONFERENCE ON INFORMATION & COMMUNICATION TECHNOLOGY AND SYSTEM (ICTS), V0, PP49, DOI 10.1109/ICTS.2019.8850982
   Li LY, 2022, COMPUT EDUC, V176, P0, DOI 10.1016/j.compedu.2021.104354
   Li MZ, 2021, APPL INTELL, V51, P5016, DOI 10.1007/s10489-020-02101-8
   Liang RX, 2019, INT J FUZZY SYST, V21, P963, DOI 10.1007/s40815-019-00606-0
   Lin CH, 2012, IEEE T KNOWL DATA EN, V24, P1134, DOI 10.1109/TKDE.2011.48
   Liu N, 2020, NEUROCOMPUTING, V395, P66, DOI 10.1016/j.neucom.2020.02.018
   Liu TY, 2018, INT J FUZZY SYST, V20, P1321, DOI 10.1007/s40815-017-0400-4
   Luo Y, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11195254
   Ma YF, 2018, INT J HOSP MANAG, V71, P120, DOI 10.1016/j.ijhm.2017.12.008
   Madani K, 2012, J WATER RES PLAN MAN, V138, P90, DOI 10.1061/(ASCE)WR.1943-5452.0000164
   Madani K, 2011, ADV WATER RESOUR, V34, P607, DOI 10.1016/j.advwatres.2011.02.009
   Mee A, 2021, KNOWL-BASED SYST, V228, P0, DOI 10.1016/j.knosys.2021.107238
   Mei Q, 2007, P 16 INT C WORLD WID, V0, PP171, DOI 10.1145/1242572.1242596
   Muthumanickam K, 2015, J KING SAUD UNIV-COM, V27, P386, DOI 10.1016/j.jksuci.2014.10.004
   Nasim Z, 2017, INT J ARTIF INTELL T, V26, P0, DOI 10.1142/S0218213017500233
   Ozyurt B, 2021, EXPERT SYST APPL, V168, P0, DOI 10.1016/j.eswa.2020.114231
   Pandesenda Adam Imansyah, 2020, 2020 INTERNATIONAL CONFERENCE ON INFORMATICS, V0, P0
   Peng YQ, 2022, APPL INTELL, V52, P5867, DOI 10.1007/s10489-021-02724-5
   Perikos I, 2021, KNOWL-BASED SYST, V229, P0, DOI 10.1016/j.knosys.2021.107332
   Punetha N, 2023, EXPERT SYST APPL, V214, P0, DOI 10.1016/j.eswa.2022.119128
   Rani R, 2020, UNDEFINED PERFORMANC, V0, P0
   Rani R, 2022, J KING SAUD UNIV-COM, V34, P2771, DOI 10.1016/j.jksuci.2020.03.003
   Ray PP, 2018, J KING SAUD UNIV-COM, V30, P291, DOI 10.1016/j.jksuci.2016.10.003
   Rintyarna Bagus Setya, 2020, INTERNATIONAL JOURNAL OF INFORMATION AND DECISION SCIENCES, V12, P75
   Roubens M, 1997, FUZZY SET SYST, V90, P199, DOI 10.1016/S0165-0114(97)00087-0
   Song M, 2019, INFORM PROCESS MANAG, V56, P637, DOI 10.1016/j.ipm.2018.12.005
   Swathi T, 2022, APPL INTELL, V52, P13675, DOI 10.1007/s10489-022-03175-2
   Trevisiol M, 1900, DOI 10.1145/2631775.2631784, V0, P0
   Vashishtha S, 2021, EXPERT SYST APPL, V169, P0, DOI 10.1016/j.eswa.2020.114323
   Vashishtha S, 2019, EXPERT SYST APPL, V138, P0, DOI 10.1016/j.eswa.2019.112834
   Vincent Thomas L, 2005, P1, V0, P0, DOI DOI 10.1017/CBO9780511542633.002
   von Neumann J, 2007, THEORY GAMES EC BEHA, V0, P1
   Wu HL, 2022, APPL INTELL, V52, P16353, DOI 10.1007/s10489-022-03384-9
   Wu J, 2022, APPL INTELL, V52, P10716, DOI 10.1007/s10489-021-02991-2
   Yang YF, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20195455
   Zhang DY, 2021, APPL INTELL, V51, P6136, DOI 10.1007/s10489-021-02189-6
   Zhang QG, 2023, APPL INTELL, V53, P16332, DOI 10.1007/s10489-022-03343-4
   Zhang SY, 2022, INT J INF SYST SERV, V14, P0, DOI 10.4018/IJISSS.295872
   Zhang Z, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P542
   Zhao AP, 2021, KNOWL-BASED SYST, V227, P0, DOI 10.1016/j.knosys.2021.107220
   Zuheros C, 2021, INFORM FUSION, V68, P22, DOI 10.1016/j.inffus.2020.10.019
NR 78
TC 3
Z9 3
U1 19
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD SEP 15
PY 2023
VL 53
IS 17
BP 20152
EP 20173
DI 10.1007/s10489-023-04471-1
EA MAR 2023
PG 22
WC Computer Science, Artificial Intelligence
SC Computer Science
GA R9UV1
UT WOS:000960219200001
PM 37363390
DA 2023-11-10
ER

PT J
AU Huh, T
   Ko, Y
AF Huh, Taehun
   Ko, Youngjoong
TI Efficient framework for low-resource abstractive summarization by meta-transfer learning and pointer-generator networks
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Low-resource abstractive summarization; Meta-transfer learning; Pointer-generator network; Copy mechanism; Prompt-tuning
AB Recently, large language models have shown great success on various abstractive summarization datasets. These datasets consist of numerous data that are enough to train a large number of parameters. However, for a new domain, there is a lack of labeled data to train those parameters and the model is easily overfitted to a small amount of data. In addition, because annotating document-summary pairs is too expensive and transfer learning using high-resource datasets causes a domain shifting problem, a low-resource abstractive summarization task is becoming necessary. Herein, we propose an efficient framework for low-resource abstractive summarization using a pointer-generator network and a meta-learning technique to address the above problems. Meta-learning using existing high-resource datasets enables our model to rapidly adapt to a new domain using limited data to solve the domain shifting problem. In addition, we explore the copy mechanism using a pointer-generator network that can copy words from a source document when generating a summary. The experimental results on 11 different datasets show that the proposed model outperforms the previous state-of-the-art models in low-resource abstractive summarization on most of the datasets.
C1 [Huh, Taehun] Sungkyunkwan Univ, Dept Artificial Intelligence, Suwon, Gyeonggi Do, South Korea.
   [Ko, Youngjoong] Sungkyunkwan Univ, Dept Comp Sci & Engn, Suwon, Gyeonggi Do, South Korea.
C3 Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU)
RP Ko, Y (通讯作者)，Sungkyunkwan Univ, Dept Comp Sci & Engn, Suwon, Gyeonggi Do, South Korea.
EM yjko@skku.edu
FU National Research Foundation of Korea (NRF) - Korea government (MSIT) [2022-0-00369]; Institute for Information amp; communications Technology Planning amp; Evaluation (IITP) - Korea government (MSIT); Development of AI Technology; Institute of Information amp; communications Technology Planning amp; Evaluation (IITP) - Korea government (MSIT); AI Graduate School Support Program (Sungkyunkwan University);  [NRF-2020R1A2C2100362]
CR Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen YS, 2021, AAAI CONF ARTIF INTE, V35, P12692
   Cohan A, 2018, ARXIV180405685, V0, P0, DOI DOI 10.18653/v1/n18-2097
   Fabbri AR, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P704
   Fabbri AR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1074
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Gu JT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3622
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Huh T, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 22), V0, PP2629, DOI 10.1145/3477495.3531908
   Kim B, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2519
   Kornilova A, 2019, P 2 WORKSH NEW FRONT, V0, PP48, DOI 10.18653/V1/D19-5406
   Koupaee M, 2018, ARXIV, V0, P0
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61
   Magooda A, 2021, FINDINGS ASS COMPUTA, V0, P1652
   Mi F, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3151
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sharma E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2204
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Vinyals O, 2015, P ADV NEURAL INFORM, V0, PP2692, DOI 10.48550/arxiv.1506.03134
   Yu T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5892
   Zhang Jingqing, 2020, P INT C MACH LEARN, V0, PP11328, DOI 10.1038/S41746-021-00437-0
   Zhang R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P446
   Zhao YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P583
NR 30
TC 0
Z9 0
U1 4
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 30
PY 2023
VL 234
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.121029
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA Q7OP8
UT WOS:001059384300001
DA 2023-11-10
ER

PT J
AU Kanerva, J
   Ginter, F
   Chang, LH
   Rastas, I
   Skantsi, V
   Kilpeläinen, J
   Kupari, HM
   Piirto, A
   Saarni, J
   Sevón, M
   Tarkka, O
AF Kanerva, Jenna
   Ginter, Filip
   Chang, Li-Hsin
   Rastas, Iiro
   Skantsi, Valtteri
   Kilpelainen, Jemina
   Kupari, Hanna-Mari
   Piirto, Aurora
   Saarni, Jenna
   Sevon, Maija
   Tarkka, Otto
TI Towards diverse and contextually anchored paraphrase modeling: A dataset and baselines for Finnish
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Paraphrasing; Corpus annotation; Finnish; Paraphrase modeling
AB In this paper, we study natural language paraphrasing from both corpus creation and modeling points of view. We focus in particular on the methodology that allows the extraction of challenging examples of paraphrase pairs in their natural textual context, leading to a dataset potentially more suitable for evaluating the models' ability to represent meaning, especially in document context, when compared with those gathered using various sentence-level heuristics. To this end, we introduce the Turku Paraphrase Corpus, the first large-scale, fully manually annotated corpus of paraphrases in Finnish. The corpus contains 104,645 manually labeled paraphrase pairs, of which 98% are verified to be true paraphrases, either universally or within their present context. In order to control the diversity of the paraphrase pairs and avoid certain biases easily introduced in automatic candidate extraction, the paraphrases are manually collected from different paraphrase-rich text sources. This allows us to create a challenging dataset including longer and more lexically diverse paraphrases than can be expected from those collected through heuristics. In addition to quality, this also allows us to keep the original document context for each pair, making it possible to study paraphrasing in context. To our knowledge, this is the first paraphrase corpus which provides the original document context for the annotated pairs.We also study several paraphrase models trained and evaluated on the new data. Our initial paraphrase classification experiments indicate a challenging nature of the dataset when classifying using the detailed labeling scheme used in the corpus annotation, the accuracy substantially lacking behind human performance. However, when evaluating the models on a large scale paraphrase retrieval task on almost 400M candidate sentences, the results are highly encouraging, 29-53% of the pairs being ranked in the top 10 depending on the paraphrase type. The Turku Paraphrase Corpus is available at github.com/TurkuNLP/Turku-paraphrase-corpus as well as through the popular HuggingFace datasets under the CC-BY-SA license.
C1 [Kanerva, Jenna; Ginter, Filip; Chang, Li-Hsin; Rastas, Iiro; Skantsi, Valtteri; Kilpelainen, Jemina; Kupari, Hanna-Mari; Piirto, Aurora; Saarni, Jenna; Sevon, Maija; Tarkka, Otto] Univ Turku, Dept Comp, TurkuNLP, Turku, Finland.
C3 University of Turku
RP Kanerva, J (通讯作者)，Univ Turku, Dept Comp, TurkuNLP, Turku, Finland.
EM jmnybl@utu.fi
FU European Language Grid; Academy of Finland; Digicampus project
CR Altheneyan A, 2020, INT J PATTERN RECOGN, V34, P0, DOI 10.1142/S0218001420530043
   [Anonymous], 2018, P 3 C MACHINE TRANSL, V0, P0, DOI DOI 10.18653/V1/W18-6317
   Arwinder Singh GSJ, 2020, INT J ADV SCI TECHNO, V29, P9433
   Bhagat R, 2013, COMPUT LINGUIST, V39, P463, DOI 10.1162/COLI_a_00166
   Chang L-H, 2021, P 1 WORKSH MOD TRANS, V0, P100
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Creutz M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1364
   Davani AM, 2022, T ASSOC COMPUT LING, V10, P92, DOI 10.1162/tacl_a_00449
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dolan WB, 2005, P 3 INT WORKSH PAR I, V0, P0
   Dong Q, 2021, ARXIV, V0, P0
   Eyecioglu A, 2018, LECT NOTES COMPUT SC, V9623, P588, DOI 10.1007/978-3-319-75477-2_42
   Federmann Christian, 2019, P 5 WORKSH NOIS US G, V0, PP17, DOI 10.18653/V1/D19-5503
   Ganitkevitch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P4276
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Gudkov V, 2020, NEURAL GENERATION AND TRANSLATION, V0, P54
   He Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7572
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kanerva J, 2021, ANNOTATION GUIDELINE, V0, P0
   Kanerva J, 2021, P 23 NORD C COMP LIN, V0, P288
   Kanerva J, 2018, P CONLL 2018 SHAR TA, V0, P0
   Lan Wuwei, 2017, P 2017 C EMP METH NA, V0, PP1224, DOI 10.18653/V1/D17-1126
   Luotolahti J, 2015, P 3 INT C DEP LING D, V0, P211
   Mehdizadeh Seraj R, 2015, P 2015 C EMPIRICAL M, V0, P1379
   Pavlick E, 2019, T ASSOC COMPUT LING, V7, P677, DOI 10.1162/tacl_a_00293
   Pivovarova L, 2018, COMM COM INF SC, V789, P211, DOI 10.1007/978-3-319-71746-3_18
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Scherrer Y, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6868
   Schwenk Holger, 2017, P 2 WORKSH REPR LEAR, V0, PP157, DOI 10.18653/V1/W17-2619
   Shimohata M, 2004, P 4 INT C LANG RES E, V0, P1407
   Soni S, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), V0, P20
   Tiedemann J, 2020, P 5 C MACH TRANSL, V0, P1174
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Virtanen Antti, 2019, ARXIV, V0, P0
   Wang A, 2019, ADV NEURAL INFORM PR, V0, P0
   Wieting J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P451
NR 36
TC 0
Z9 0
U1 1
U2 1
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324923000086
EA MAR 2023
PG 35
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 9Y3IG
UT WOS:000950352200001
DA 2023-11-10
ER

PT J
AU Vu, MH
   Akbar, R
   Robert, PA
   Swiatczak, B
   Sandve, GK
   Greiff, V
   Haug, DTT
AF Vu, Mai Ha
   Akbar, Rahmad
   Robert, Philippe A.
   Swiatczak, Bartlomiej
   Sandve, Geir Kjetil
   Greiff, Victor
   Haug, Dag Trygve Truslew
TI Linguistically inspired roadmap for building biologically reliable protein language models
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID evolution; identification; prediction; entropy; cell
AB Language models trained on proteins can help to predict functions from sequences but provide little insight into the underlying mechanisms. Vu and colleagues explain how extracting the underlying rules from a protein language model can make them interpretable and help explain biological mechanisms. Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence-function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared with natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding and model interpretation. Incorporating linguistic ideas into protein LMs enables the development of next-generation interpretable machine learning models with the potential of uncovering the biological mechanisms underlying sequence-function relationships.
C1 [Vu, Mai Ha; Haug, Dag Trygve Truslew] Univ Oslo, Dept Linguist, Scandinavian Studies, Oslo, Norway.
   [Akbar, Rahmad; Robert, Philippe A.; Greiff, Victor] Univ Oslo, Oslo Univ Hosp, Dept Immunol, Oslo, Norway.
   [Swiatczak, Bartlomiej] Univ Sci & Technol China, Dept Hist Sci & Sci Archeol, Hefei, Anhui, Peoples R China.
   [Sandve, Geir Kjetil] Univ Oslo, Dept Informat, Oslo, Norway.
C3 University of Oslo; University of Oslo; Chinese Academy of Sciences; University of Science & Technology of China, CAS; University of Oslo
RP Vu, MH; Haug, DTT (通讯作者)，Univ Oslo, Dept Linguist, Scandinavian Studies, Oslo, Norway.
EM m.h.vu@iln.uio.no; daghaug@uio.no
FU Leona M. and Harry B. Helmsley Charitable Trust [2019PG-T1D011]; UiO World-Leading Research Community; UiO:LifeScience Convergence Environment Immunolingo; EU Horizon 2020 iReceptorplus [825821]; Research Council of Norway FRIPRO project [300740]; Research Council of Norway IKTPLUSS project [311341]; Norwegian Cancer Society Grant [215817]; Stiftelsen Kristian Gerhard Jebsen (KG Jebsen Coeliac Disease Research Centre)
CR Adebayo J, 2022, INT C LEARNING REPRE, V0, P0
   Agerri R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P4781
   Akbar R, 2022, MABS-AUSTIN, V14, P0, DOI 10.1080/19420862.2021.2008790
   Akbar R, 2021, CELL REP, V34, P0, DOI 10.1016/j.celrep.2021.108856
   Alley EC, 2019, NAT METHODS, V16, P1315, DOI 10.1038/s41592-019-0598-1
   Alva V, 2015, ELIFE, V4, P0, DOI 10.7554/eLife.09410
   Angluin D, 1992, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL ACM SYMPOSIUM ON THE THEORY OF COMPUTING, V0, PP351, DOI 10.1145/129712.129746
   ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6
   Asgari E, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-38746-w
   Asgari E, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0141287
   Bender Emily M, 2021, FACCT 21: PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, V0, P0
   Bepler T, 2021, CELL SYST, V12, P654, DOI 10.1016/j.cels.2021.05.017
   Bhattamishra S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7096
   Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020
   Brown PF, 1992, COMPUTATIONAL LINGUISTICS, V18, P31
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Burley SK, 2017, METHODS MOL BIOL, V1606, P627, DOI 10.1007/978-1-4939-7000-1_26
   Chen C, 2022, PREPRINT, V0, PPARXIV.2204.04213, DOI 10.48550/arXiv.2204.04213
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, PP276, DOI 10.18653/v1/w19-4828
   Clark P, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3882
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Corrie BD, 2018, IMMUNOL REV, V284, P24, DOI 10.1111/imr.12666
   de Vries W, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7676
   Detlefsen NS, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-29443-w
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doddapaneni S, 2021, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2107.00676
   Elhanati Y, 2015, PHILOS T R SOC B, V370, P0, DOI 10.1098/rstb.2014.0243
   Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   Eyraud R, 2021, MACH LEARN, V0, P0, DOI DOI 10.1007/s10994-021-05948-1
   Fernandez-Fuentes N, 2010, PLOS COMPUT BIOL, V6, P0, DOI 10.1371/journal.pcbi.1000750
   Ferruz N, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-32007-7
   Ferruz N, 2022, NAT MACH INTELL, V4, P521, DOI 10.1038/s42256-022-00499-z
   Ferruz N, 2020, J MOL BIOL, V432, P3898, DOI 10.1016/j.jmb.2020.04.013
   Firth F, 1968, SELECTED PAPERS JR F, V0, P168
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI 10.5555/177910.177914
   Ganesan D, 2017, BIONLP 2017, V2017, P238
   Gimona M, 2006, NAT REV MOL CELL BIO, V7, P68, DOI 10.1038/nrm1785
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Goldberg Y, 2019, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.1901.05287
   Greiff V, 2017, CELL REP, V19, P1467, DOI 10.1016/j.celrep.2017.04.054
   Gutierrez-Vasques X, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P3454
   Heinzinger M, 2019, BMC BIOINFORMATICS, V20, P0, DOI 10.1186/s12859-019-3220-8
   Hie B, 2021, SCIENCE, V371, P284, DOI 10.1126/science.abd7331
   Hie BL, 2022, CELL SYST, V13, P274, DOI 10.1016/j.cels.2022.01.003
   Hiraoka T, 2020, FINDINGS ASS COMPUTA, V0, PP1341, DOI 10.18653/V1/2020.FINDINGS-EMNLP.120
   Hofmann V, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P385
   Hofmann V, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3594
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1725
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kao W-T, 2021, FINDINGS ASS COMPUTA, V0, P2195
   Kaplan J, 2020, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2001.08361
   Kaufman S, 2012, ACM T KNOWL DISCOV D, V6, P0, DOI 10.1145/2382577.2382579
   Kolodny R, 2021, MOL BIOL EVOL, V38, P2191, DOI 10.1093/molbev/msab017
   Krishna K, 2021, FINDINGS ASS COMPUTA, V0, P3178
   Kutuzov Andrey, 2019, PROC 1 NLPL WORKSHOP, V0, P22
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4483
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Leem J, 2022, PATTERNS, V3, P0, DOI 10.1016/j.patter.2022.100513
   LIn T, 2022, OPEN, V3, P111, DOI 10.1016/J.AIOPEN.2022.10.001
   Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574
   Linzen, 2021, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2111.09509
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI 10.1353/LAN.2019.0015
   Linzen T, 2019, LANGUAGE, V95, PE99, DOI 10.1353/lan.2019.0015
   Littmann M, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-020-80786-0
   Liu C-L, 2020, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2004.09205
   Liu YH, 2019, INFORM SYST RES, V0, P0, DOI DOI 10.48550/arXiv.1907.11692
   Madani A, 2021, DEEP NEURAL LANGUAGE, V0, P0, DOI DOI 10.1101/2021.07.18.452833
   Marcou Q, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-02832-w
   Matthews A, 2018, P C N AM CHAPT ACL H, V1, P1435
   McCoy RT, 2020, T ASSOC COMPUT LING, V8, P125, DOI 10.1162/tacl_a_00304
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   Meier J, 2021, ADV NEURAL INF PROCE, V34, P29287, DOI 10.1101/2021.07.09.450648
   Mielke SJ, 2021, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2112.10508
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   MONTAGUE R, 1970, THEORIA, V36, P373
   Morris TP, 2019, STAT MED, V38, P2074, DOI 10.1002/sim.8086
   Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3434237
   Nijkamp E, 2022, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2206.13517
   Niven T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4658
   Ofer D, 2021, COMPUT STRUCT BIOTEC, V19, P1750, DOI 10.1016/j.csbj.2021.03.022
   Olsen Tobias H, 2022, BIOINFORM ADV, V2, Pvbac046, DOI 10.1093/bioadv/vbac046
   Olsen TH, 2022, PROTEIN SCI, V31, P141, DOI 10.1002/pro.4205
   Ostrovsky-Berman M, 2021, FRONT IMMUNOL, V12, P0, DOI 10.3389/fimmu.2021.680687
   Pan Y, 2020, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2001.01589
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pinter Y, 2021, ARXIV, V0, P0
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Rae JW, 2022, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2112.11446
   Rao RS, 2019, ADV NEUR IN, V32, P0
   Rives A, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2016239118
   Robert PA, 2022, NAT COMPUT SCI, V2, P845, DOI 10.1038/s43588-022-00372-4
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Ruffolo JA, 2021, MACHINE LEARNING STR, V0, P0
   Ruffolo JA, 2022, PATTERNS, V3, P0, DOI 10.1016/j.patter.2021.100406
   Sandve GK, 2022, BIOINFORMATICS, V38, P4994, DOI 10.1093/bioinformatics/btac612
   Schluter N, 2018, P 2018 C N AM ASS CO, V2, P242, DOI 10.18653/V1/N18-2039
   Schwartz L, 2020, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.2005.05477
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Shin S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, V0, P5168
   Shuai RW, 2021, MACHINE LEARNING STR, V0, P0
   Stern M, 2019, PR MACH LEARN RES, V97, P0
   Strait BJ, 1996, BIOPHYS J, V71, P148, DOI 10.1016/S0006-3495(96)79210-X
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Szklarczyk D, 2019, NUCLEIC ACIDS RES, V47, PD607, DOI 10.1093/nar/gky1131
   Szymborski J, 2022, BIOINFORMATICS, V38, P3958, DOI 10.1093/bioinformatics/btac429
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Unsal S, 2022, NAT MACH INTELL, V4, P227, DOI 10.1038/s42256-022-00457-9
   Vig J, 2020, INT C LEARNING REPRE, V0, P0
   Villegas-Morcillo A, 2021, BIOINFORMATICS, V37, P162, DOI 10.1093/bioinformatics/btaa701
   Wang QL, 2018, NEURAL COMPUT, V30, P2568, DOI 10.1162/neco_a_01111
   Wang YB, 2019, CELLS-BASEL, V8, P0, DOI 10.3390/cells8020122
   Warstadt A, 2020, P SOC COMPUT LINGUIS, V3, P437
   Weber CR, 2020, BIOINFORMATICS, V36, P3594, DOI 10.1093/bioinformatics/btaa158
   Weiss G, 2018, PR MACH LEARN RES, V80, P0
   Welleck S, 2019, P 36 INT C MACH LEAR, V0, P6716
   Xu Jingjing, 2021, P 59 ANN M ASS COMP, V1, P7361
   Xu M, 2022, INT C LEARNING REPRE, V0, P0
   Yang KK, 2018, BIOINFORMATICS, V34, P2642, DOI 10.1093/bioinformatics/bty178
NR 122
TC 4
Z9 4
U1 20
U2 23
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD MAY 15
PY 2023
VL 5
IS 5
BP 485
EP 496
DI 10.1038/s42256-023-00637-1
EA APR 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA G6XR8
UT WOS:000963904900001
DA 2023-11-10
ER

PT J
AU Zhou, HY
   Guo, JS
   Zhang, YH
   Han, XG
   Yu, LQ
   Wang, LS
   Yu, YZ
AF Zhou, Hong-Yu
   Guo, Jiansen
   Zhang, Yinghao
   Han, Xiaoguang
   Yu, Lequan
   Wang, Liansheng
   Yu, Yizhou
TI nnFormer: Volumetric Medical Image Segmentation via a 3D Transformer
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE & nbsp;Transformer; attention mechanism; volumetric image segmentation
AB Transformer, the model of choice for natural language processing, has drawn scant attention from the medical imaging community. Given the ability to exploit long-term dependencies, transformers are promising to help atypical convolutional neural networks to learn more contextualized visual representations. However, most of recently proposed transformer-based segmentation approaches simply treated transformers as assisted modules to help encode global context into convolutional representations. To address this issue, we introduce nnFormer (i.e., not-another transFormer), a 3D transformer for volumetric medical image segmentation. nnFormer not only exploits the combination of interleaved convolution and self-attention operations, but also introduces local and global volume-based self-attention mechanism to learn volume representations. Moreover, nnFormer proposes to use skip attention to replace the traditional concatenation/summation operations in skip connections in U-Net like architecture. Experiments show that nnFormer significantly outperforms previous transformer-based counterparts by large margins on three public datasets. Compared to nnUNet, the most widely recognized convnet-based 3D medical segmentation model, nnFormer produces significantly lower HD95 and is much more computationally efficient. Furthermore, we show that nnFormer and nnUNet are highly complementary to each other in model ensembling. Codes and models of nnFormer are available at https://git.io/JSf3i.
C1 [Zhou, Hong-Yu; Guo, Jiansen; Zhang, Yinghao; Wang, Liansheng] Xiamen Univ, Dept Comp Sci, Xiamen 361005, Fujian, Peoples R China.
   [Han, Xiaoguang] Chinese Univ Hong Kong Shenzhen, Shenzhen Res Inst Big Data, Shenzhen 518172, Guangdong, Peoples R China.
   [Yu, Lequan] Univ Hong Kong, Dept Stat & Actuarial Sci, Hong Kong, Peoples R China.
   [Yu, Yizhou] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Xiamen University; Chinese University of Hong Kong, Shenzhen; Shenzhen Research Institute of Big Data; University of Hong Kong; University of Hong Kong
RP Wang, LS (通讯作者)，Xiamen Univ, Dept Comp Sci, Xiamen 361005, Fujian, Peoples R China.; Yu, YZ (通讯作者)，Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM whuzhouhongyu@gmail.com; jsguo@stu.xmu.edu.cn; zhangyinghao@stu.xmu.edu.cn; hanxiaoguang@cuhk.edu.cn; lqyu@hku.hk; lswang@xmu.edu.cn; yizhouy@acm.org
FU Ministry of Science and Technology of the People's Republic of China [STI2030-Major Projects2021ZD0201900]
CR Antonelli M, 2021, ARXIV, V0, P0
   Ba Jimmy Lei, 2016, ARXIV, V0, P0
   Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502
   Cao H, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2105.05537
   Carion Nicolas, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12346), V0, PP213, DOI 10.1007/978-3-030-58452-8_13
   Chen BZ, 2022, ARXIV, V0, P0
   Chen J, 2021, ARXIV, V0, P0
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Xinlei, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2111.06377
   Dosovitskiy A, 2021, ARXIV, V0, P0
   Hatamizadeh A, 2022, LECT NOTES COMPUT SC, V12962, P272, DOI 10.1007/978-3-031-08999-2_22
   Hatamizadeh A, 2022, IEEE WINT CONF APPL, V0, PP1748, DOI 10.1109/WACV51458.2022.00181
   Hendrycks D, 2020, ARXIV, V0, P0
   Huang X, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2109.07162
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Karimi D, 2022, ARXIV, V0, P0
   Landman Bennett, 2015, PROC MICCAI MULTIATL, V5, P12, DOI 10.7303/SYN3193805
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li S, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2105.09511
   Li YJ, 2022, ARXIV, V0, P0
   Lin A, 2021, ARXIV, V0, P0
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu Z, 2021, ARXIV, V0, P0
   Luo WJ, 2016, ADV NEUR IN, V29, P0
   Maria Jose Valanarasu J, 2021, MEDICAL TRANSFORMER, V0, P0, DOI DOI 10.48550/arXiv.2102.10662
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Qu TP, 2022, MED IMAGE ANAL, V75, P0, DOI 10.1016/j.media.2021.102232
   Ronneberger O, 2015, P INT C MED IM COMP, V0, P234
   Szegedy C, 2015, P C COMP VIS PATT RE, V0, P1
   Tang YC, 2022, PROC CVPR IEEE, V0, PP20698, DOI 10.1109/CVPR52688.2022.02007
   Tuli S, 2021, ARXIV, V0, P0
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Xie YT, 2021, LECT NOTES COMPUT SC, V12903, P171, DOI 10.1007/978-3-030-87199-4_16
   Xu G, 2021, ARXIV, V0, P0, DOI DOI 10.2139/SSRN.4116174
   Yao C, 2021, ARXIV, V0, P0
   Yun BX, 2021, ARXIV, V0, P0
   Zhang DW, 2021, PATTERN RECOGN, V110, P0, DOI 10.1016/j.patcog.2020.107562
   Zhang YD, 2021, ARXIV, V0, P0
   Zheng SX, 2021, PROC CVPR IEEE, V0, PP6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou HY, 2023, IEEE T PATTERN ANAL, V45, P8020, DOI 10.1109/TPAMI.2023.3234002
   Zhou HY, 2021, IEEE INT CONF COMP V, V0, PP2230, DOI 10.1109/ICCVW54120.2021.00252
   Zhou HY, 2022, NAT MACH INTELL, V4, P32, DOI 10.1038/s42256-021-00425-9
NR 44
TC 2
Z9 2
U1 27
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PD JUN 15
PY 2023
VL 32
IS 
BP 4036
EP 4045
DI 10.1109/TIP.2023.3293771
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA M9RO6
UT WOS:001033515600010
PM 37440404
DA 2023-11-10
ER

PT J
AU Wen, GH
   Ye, S
   Li, HH
   Wen, PC
   Zhang, YH
AF Wen, Guihua
   Ye, Sheng
   Li, Huihui
   Wen, Pengcheng
   Zhang, Yuhan
TI Multimodal and Multitask Learning with Additive Angular Penalty Focus Loss for Speech Emotion Recognition
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
ID network; gender
AB Speech emotion recognition has lots of applications such as human-computer interaction and health management. The current methods are challenged with the problems of fuzzy decision boundary and imbalance between difficult and easy samples in the training data. This paper first proposes an additive angle penalty focus loss function (APFL), which strictly refines the fuzzy decision boundary by introducing angle penalty factors to improve the compactness within the class and enlarge the distance between classes. It also assigns the larger loss to difficult samples to make the model pay more attention to them, as they are easily misclassified. Simultaneously, due to the lack of training samples, the framework of multimodal and multitask learning with APFL is further proposed, which extracts spectrogram features by deep neural network, text features by the pretrained language model, and audio features by the pretrained sound model. It uses the gender recognition as an auxiliary task. The experimental results verify the effectiveness of the proposed loss function and framework.
C1 [Wen, Guihua; Ye, Sheng; Wen, Pengcheng] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Li, Huihui] Guangdong Polytech Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
   [Zhang, Yuhan] Dongguan Songshanhu Cent Hosp, Dept Neurol, Dongguan, Peoples R China.
C3 South China University of Technology; Guangdong Polytechnic Normal University
RP Wen, PC (通讯作者)，South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.; Li, HH (通讯作者)，Guangdong Polytech Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
EM crghwen@scut.edu.cn; asjiangh@qq.com; lihh@gpnu.edu.cn; 583283648@qq.com; zyhan2002@126.com
FU This study was supported by National Natural Science Foundation of China (Grant nos. 62176095 and 62006049), Guangzhou Science and Technology Planning Project (Grant nos. 2023B03J1336 and 2023A03J0316), Guangdong Province Key Area Ramp;D Plan Project (Gra [62176095, 62006049]; National Natural Science Foundation of China [2023B03J1336, 2023A03J0316]; Guangzhou Science and Technology Planning Project [2020B1111120001]; Guangdong Province Key Area Ramp;D Plan Project [2023A1515010939]; Guangdong Basic and Applied Basic Research Foundation [2022KTSCX068, 2021ZDZX1079]; Project of Education Department of Guangdong Province
CR Abadi M, 2016, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1603.04467
   Alaparthi VS, 2022, C HUM SYST INTERACT, V0, P0
   Atmaja BT, 2022, SENSORS-BASEL, V22, P0, DOI 10.3390/s22165941
   Bakhshi A, 2022, SPEECH COMMUN, V139, P62, DOI 10.1016/j.specom.2022.02.007
   Barkur R, 2022, P IEEE INT C EL COMP, V0, P0
   Bhosale S, 2020, INT CONF ACOUST SPEE, V0, PP7189, DOI 10.1109/icassp40776.2020.9054621
   Burkhardt F, 2005, INTERSPEECH, V0, P1517
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Dai DY, 2019, INT CONF ACOUST SPEE, V0, PP7405, DOI 10.1109/ICASSP.2019.8683765
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2022, IEEE T PATTERN ANAL, V44, P5962, DOI 10.1109/TPAMI.2021.3087709
   Dong GN, 2022, IEEE T CIRC SYST VID, V32, P6472, DOI 10.1109/TCSVT.2022.3163445
   Fan WQ, 2022, IEEE-ACM T AUDIO SPE, V30, P1803, DOI 10.1109/TASLP.2022.3171965
   Feng H, 2020, INTERSPEECH, V0, PP501, DOI 10.21437/Interspeech.2020-1180
   Gorrostieta C, 2019, INTERSPEECH, V0, PP2823, DOI 10.21437/Interspeech.2019-1708
   Guo LL, 2018, INTERSPEECH, V0, PP1611, DOI 10.21437/Interspeech.2018-2156
   Haq S, 2009, P INT C AUD VIS SPEE, V0, P53
   Haq S, 2008, P INT C AUD VIS SPEE, V0, P185
   Houari H, 2020, TRAIT SIGNAL, V37, P413, DOI 10.18280/ts.370308
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang J, 2018, INTERSPEECH, V0, PP3673, DOI 10.21437/Interspeech.2018-1432
   Ibrahim H, 2022, NEURAL COMPUT APPL, V34, P17581, DOI 10.1007/s00521-022-07410-2
   Kalhor E, 2021, MULTIMED TOOLS APPL, V80, P8127, DOI 10.1007/s11042-020-10119-w
   Kang Z, 2022, ARXIV, V0, P0
   Kerkeni L, 2019, SPEECH COMMUN, V114, P22, DOI 10.1016/j.specom.2019.09.002
   Kexin Z, 2022, SPEECH EMOTION RECOG, V0, P0
   Khare A, 2020, INTERSPEECH, V0, PP384, DOI 10.21437/Interspeech.2020-1827
   Kumar P, 2021, P ANN C INT SPEECH C, V4, P2927
   Latif S, 2022, ARXIV, V0, P0
   Li BY, 2019, AAAI CONF ARTIF INTE, V0, P8577
   Li RC, 2021, INTERSPEECH, V0, PP4488, DOI 10.21437/Interspeech.2021-785
   Li ZX, 2019, INTERSPEECH, V0, PP1696, DOI 10.21437/Interspeech.2019-1683
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu JX, 2020, INT CONF ACOUST SPEE, V0, PP7174, DOI 10.1109/icassp40776.2020.9053192
   Ma X, 2018, INTERSPEECH, V0, PP3683, DOI 10.21437/Interspeech.2018-2228
   Manohar K, 2022, KNOWL-BASED SYST, V246, P0, DOI 10.1016/j.knosys.2022.108659
   Mao SY, 2022, IEEE-ACM T AUDIO SPE, V30, P123, DOI 10.1109/TASLP.2021.3133195
   Mao SY, 2019, INT CONF ACOUST SPEE, V0, PP6715, DOI 10.1109/ICASSP.2019.8683172
   Ocquaye ENN, 2021, INT J INTELL SYST, V36, P53, DOI 10.1002/int.22291
   Runnan L, 2019, INT CONF ACOUST SPEE, V0, PP6675, DOI 10.1109/icassp.2019.8682154
   Satt A, 2017, INTERSPEECH, V0, PP1089, DOI 10.21437/Interspeech.2017-200
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Shilandari A, 2022, SIGNAL IMAGE VIDEO P, V16, P1955, DOI 10.1007/s11760-022-02156-9
   Song P, 2021, IEEE T COGN DEV SYST, V13, P343, DOI 10.1109/TCDS.2020.2990928
   Su BH, 2023, IEEE T AFFECT COMPUT, V14, P1991, DOI 10.1109/TAFFC.2022.3146325
   Tang YW, 2022, SPEECH COMMUN, V143, P21, DOI 10.1016/j.specom.2022.07.004
   Tuncer T, 2021, KNOWL-BASED SYST, V211, P0, DOI 10.1016/j.knosys.2020.106547
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vasuki P, 2019, INT J INTELL INF TEC, V15, P22, DOI 10.4018/IJIIT.2019100102
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1041, DOI 10.1145/3123266.3123359
   Wang S, 2022, ARXIV, V0, P0
   Wen GH, 2022, KNOWL-BASED SYST, V254, P0, DOI 10.1016/j.knosys.2022.109589
   Wen X-C, 2022, P IJCAI INT JOINT C, V0, P2305
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu XX, 2021, IEEE-ACM T AUDIO SPE, V29, P3280, DOI 10.1109/TASLP.2021.3120586
   Ye JX, 2022, SPEECH COMMUN, V145, P21, DOI 10.1016/j.specom.2022.07.005
   Ye JX, 2023, ARXIV, V0, P0
   Yenigalla P, 2018, INTERSPEECH, V0, PP3688, DOI 10.21437/Interspeech.2018-1811
   Zhang JF, 2022, COMPUT IND ENG, V168, P0, DOI 10.1016/j.cie.2022.108078
   Zhang SQ, 2022, IEEE T AFFECT COMPUT, V13, P680, DOI 10.1109/TAFFC.2019.2947464
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhao HJ, 2021, J SIGNAL PROCESS SYS, V93, P299, DOI 10.1007/s11265-020-01538-x
   Zhou Y, 2022, IEEE-ACM T AUDIO SPE, V30, P695, DOI 10.1109/TASLP.2022.3145287
NR 64
TC 0
Z9 0
U1 0
U2 0
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD OCT 17
PY 2023
VL 2023
IS 
BP 
EP 
DI 10.1155/2023/3662839
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA W0RX7
UT WOS:001088800600001
DA 2023-11-10
ER

PT J
AU Ding, JJ
   Zhang, C
   Li, DY
   Sangaiah, AK
AF Ding, Juanjuan
   Zhang, Chao
   Li, Deyu
   Sangaiah, Arun Kumar
TI Hyperautomation for Air Quality Evaluations: A Perspective of Evidential Three-way Decision-making
SO COGNITIVE COMPUTATION
LA English
DT Article; Early Access
DE Three-way decision; Multi-granularity; Rough set; Hyperautomation; Air quality evaluation
ID fuzzy time-series; reasoning approach; rough sets; clustering method; model; pollution
AB Hyperautomation acts as a real digital transformation with the support of several cutting-edge cognitive computation methods that include robotic process automation, natural language processing, artificial intelligence, and other emerging ones, which is conducive to processing complex industrial processes via extending the range of various data-driven cognitive decision-making algorithms. The study of air quality evaluations (AQE) plays a significant role in ensuring healthy atmospheric environments. In view of the objective existence of uncertainties, AQE can be modeled and addressed by a typical data-driven automated decision-making problem, and hyperautomation can provide a reasonable solution via associating with a variety of techniques. This article explores hyperautomation for AQE via evidential three-way large-scale group decision-making (LSGDM) in an intuitionistic fuzzy (IF) setting. First, the notion of intuitionistic fuzzy sets (IFSs) is incorporated into the paradigm of multi-granularity (MG) three-way decisions (TWD), and the model of adjustable MG IF probabilistic rough sets (PRSs) is developed. Second, an IF clustering analysis with the improved technique for order preference by similarity to ideal solution (TOPSIS) method is conducted to affirm representative members within a decision group. Third, a novel IF LSGDM method is built via adjustable MG IF PRSs and the evidence reasoning (ER) method. Finally, a case study in the setting of AQE is studied by using the presented evidential three-way LSGDM method. Corresponding experimental analyses are carried out for illustrating the efficiency of hyperautomation for AQE. In general, the proposed method improves the performance of information fusion by virtue of adjustable MG IF PRSs, and the TOPSIS method avoids the influence of subjective factors on decision results. Meanwhile, the evaluation information of decision-makers (DMs) is fully analyzed by means of the ER method, which can provide more explainable decision results.
C1 [Ding, Juanjuan; Zhang, Chao; Li, Deyu] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Shanxi, Peoples R China.
   [Zhang, Chao; Li, Deyu] Shanxi Univ, Key Lab Computat Intelligence, Chinese Informat Proc Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.
   [Sangaiah, Arun Kumar] Natl Yunlin Univ Sci & Technol, Int Grad Inst Artificial Intelligence, Touliu 64002, Taiwan.
   [Sangaiah, Arun Kumar] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
C3 Shanxi University; Shanxi University; National Yunlin University Science & Technology; Lebanese American University
RP Zhang, C; Li, DY (通讯作者)，Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Shanxi, Peoples R China.; Zhang, C; Li, DY (通讯作者)，Shanxi Univ, Key Lab Computat Intelligence, Chinese Informat Proc Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.; Sangaiah, AK (通讯作者)，Natl Yunlin Univ Sci & Technol, Int Grad Inst Artificial Intelligence, Touliu 64002, Taiwan.; Sangaiah, AK (通讯作者)，Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
EM 2816904900@qq.com; czhang@sxu.edu.cn; lidy@sxu.edu.cn; aksangaiah@ieee.org
CR Abu Dabous S, 2021, INT J PAVEMENT ENG, V22, P455, DOI 10.1080/10298436.2019.1622012
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Atef M, 2021, COMPUT APPL MATH, V40, P0, DOI 10.1007/s40314-021-01501-x
   Chen MY, 2015, INFORM SCIENCES, V294, P227, DOI 10.1016/j.ins.2014.09.038
   Chen MY, 2014, FUTURE GENER COMP SY, V37, P461, DOI 10.1016/j.future.2013.09.025
   CHEN SM, 1994, FUZZY SET SYST, V67, P163, DOI 10.1016/0165-0114(94)90084-1
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Ding HN, 2020, NEURAL COMPUT APPL, V32, P5213, DOI 10.1007/s00521-019-04016-z
   Du SD, 2021, IEEE T KNOWL DATA EN, V33, P2412, DOI 10.1109/TKDE.2019.2954510
   Du ZJ, 2020, INFORM FUSION, V63, P13, DOI 10.1016/j.inffus.2020.05.004
   Fan CL, 2018, IEEE ACCESS, V6, P27214, DOI 10.1109/ACCESS.2018.2832206
   Fisher B, 2003, ATMOS ENVIRON, V37, P1865, DOI 10.1016/S1352-2310(03)00028-1
   Fuller R, 2022, LANCET PLANET HEALTH, V6, PE535, DOI 10.1016/S2542-5196(22)00090-0
   Garg H, 2019, APPL INTELL, V49, P496, DOI 10.1007/s10489-018-1290-3
   Goshua A, 2022, ALLERGY, V77, P1955, DOI 10.1111/all.15224
   Haleem A, 2021, SENSORS INT, V2, P100124, DOI 10.1016/j.sintl.2021.100124
   Hong DH, 2000, FUZZY SET SYST, V114, P103, DOI 10.1016/S0165-0114(98)00271-1
   Hu BQ, 2017, INT J APPROX REASON, V82, P285, DOI 10.1016/j.ijar.2016.12.007
   Huang B, 2019, APPL MATH COMPUT, V348, P487, DOI 10.1016/j.amc.2018.12.018
   Jia F, 2019, INFORM SCIENCES, V471, P29, DOI 10.1016/j.ins.2018.08.051
   Koo JW, 2020, AIR QUAL ATMOS HLTH, V13, P77, DOI 10.1007/s11869-019-00772-y
   Lang GM, 2020, IEEE T FUZZY SYST, V28, P447, DOI 10.1109/TFUZZ.2019.2908123
   Leong WC, 2020, J ENVIRON CHEM ENG, V8, P0, DOI 10.1016/j.jece.2019.103208
   Li WT, 2023, IEEE T FUZZY SYST, V31, P2112, DOI 10.1109/TFUZZ.2022.3217377
   Li WT, 2022, IEEE T NEUR NET LEAR, V0, P0, DOI DOI 10.1109/TNNLS.2022.3184120
   Li WT, 2022, FUZZY SET SYST, V440, P149, DOI 10.1016/j.fss.2022.01.007
   Li WT, 2022, ARTIF INTELL REV, V55, P1821, DOI 10.1007/s10462-021-10053-9
   Liang DC, 2017, INFORM SCIENCES, V375, P183, DOI 10.1016/j.ins.2016.09.039
   Liu D, 2012, INT J UNCERTAIN FUZZ, V20, P119, DOI 10.1142/S0218488512400090
   Liu PD, 2019, IEEE ACCESS, V7, P147825, DOI 10.1109/ACCESS.2019.2942854
   Ma ZZ, 2020, IEEE T SYST MAN CY-S, V50, P2421, DOI 10.1109/TSMC.2018.2815716
   Mirabelli MC, 2020, ENVIRON RES, V183, P0, DOI 10.1016/j.envres.2020.109185
   Piasecki M, 2020, ENERGIES, V13, P0, DOI 10.3390/en13123120
   Qian YH, 2010, INFORM SCIENCES, V180, P949, DOI 10.1016/j.ins.2009.11.023
   Ribeiro JPA, 2021, P I MECH ENG L-J MAT, V235, P1271, DOI 10.1177/1464420721992445
   Sangaiah AK, 2020, SOFT COMPUT, V24, P7885, DOI 10.1007/s00500-019-04010-6
   Sangaiah AK, 2017, NEURAL COMPUT APPL, V28, P111, DOI 10.1007/s00521-015-2040-7
   Shafer G, 1976, MATH THEORY EVIDENCE, V0, P0
   Singh PK, 2019, COGN COMPUT, V11, P513, DOI 10.1007/s12559-019-09635-1
   Suman, 2021, MATER TODAY-PROC, V34, P863, DOI 10.1016/j.matpr.2020.07.141
   Sun BZ, 2022, APPL SOFT COMPUT, V123, P0, DOI 10.1016/j.asoc.2022.108933
   Sun BZ, 2020, INFORM FUSION, V55, P91, DOI 10.1016/j.inffus.2019.07.013
   Sun BZ, 2018, INT J APPROX REASON, V93, P424, DOI 10.1016/j.ijar.2017.11.015
   Szmidt E, 2001, FUZZY SET SYST, V118, P467, DOI 10.1016/S0165-0114(98)00402-3
   Tang M, 2021, OMEGA-INT J MANAGE S, V100, P0, DOI 10.1016/j.omega.2019.102141
   Wan QF, 2020, GROUP DECIS NEGOT, V29, P901, DOI 10.1007/s10726-020-09684-0
   Wang PX, 2019, INT J MACH LEARN CYB, V10, P2767, DOI 10.1007/s13042-018-0901-y
   Wang QF, 2019, J INTELL FUZZY SYST, V37, P1639, DOI 10.3233/JIFS-179228
   Wang YN, 2015, INT J COMPUT INT SYS, V8, P75, DOI 10.1080/18756891.2014.964009
   Xing ZJ, 2018, IEEE T FUZZY SYST, V26, P353, DOI 10.1109/TFUZZ.2017.2666219
   Xu XH, 2019, INFORM SCIENCES, V477, P410, DOI 10.1016/j.ins.2018.10.058
   Xu ZS, 2007, IEEE T FUZZY SYST, V15, P1179, DOI 10.1109/TFUZZ.2006.890678
   Yan Zhang, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTING, V0, P552, DOI 10.1109/ICCNC.2019.8685642
   YANG JB, 1994, IEEE T SYST MAN CYB, V24, P1, DOI 10.1109/21.259681
   Yang JB, 2001, EUR J OPER RES, V131, P31, DOI 10.1016/S0377-2217(99)00441-5
   Yao JT, 2015, IEEE T FUZZY SYST, V23, P3, DOI 10.1109/TFUZZ.2014.2360548
   Yao YY, 2019, KNOWL-BASED SYST, V180, P26, DOI 10.1016/j.knosys.2019.05.016
   Yao YY, 2018, INT J APPROX REASON, V103, P107, DOI 10.1016/j.ijar.2018.09.005
   Yao YY, 2010, INFORM SCIENCES, V180, P341, DOI 10.1016/j.ins.2009.09.021
   YAO YY, 1990, METHODOLOGIES FOR INTELLIGENT SYSTEMS, V0, P17
   Yin P, 2020, LANCET PLANET HEALTH, V4, PE386, DOI 10.1016/S2542-5196(20)30161-3
   Yu H, 2016, KNOWL-BASED SYST, V91, P189, DOI 10.1016/j.knosys.2015.05.028
   Zhan JM, 2023, IEEE-CAA J AUTOMATIC, V10, P330, DOI 10.1109/JAS.2022.106061
   Zhan JM, 2020, ARTIF INTELL REV, V53, P671, DOI 10.1007/s10462-018-9674-7
   Zhan JM, 2019, INFORM SCIENCES, V476, P290, DOI 10.1016/j.ins.2018.10.016
   Zhang C, 2022, INT J APPROX REASON, V147, P40, DOI 10.1016/j.ijar.2022.05.004
   Zhang C, 2021, INT J APPROX REASON, V138, P161, DOI 10.1016/j.ijar.2021.08.004
   Zhang C, 2020, INFORM SCIENCES, V511, P192, DOI 10.1016/j.ins.2019.09.037
   Zhang C, 2020, INFORM SCIENCES, V507, P665, DOI 10.1016/j.ins.2019.01.033
   Zhang L, 2019, INFORM SCIENCES, V478, P275, DOI 10.1016/j.ins.2018.11.033
   Zhang Ning, 2019, INTERNATIONAL JOURNAL OF CROWD SCIENCE, V3, P0, DOI 10.1108/IJCS-09-2018-0018
   Zhang Y, 2017, INT J APPROX REASON, V81, P103, DOI 10.1016/j.ijar.2016.11.005
   Zheng YH, 2021, EXPERT SYST APPL, V168, P0, DOI 10.1016/j.eswa.2020.114355
   Zhong XY, 2020, APPL SOFT COMPUT, V87, P0, DOI 10.1016/j.asoc.2019.105973
NR 74
TC 3
Z9 3
U1 17
U2 22
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s12559-022-10101-8
EA JAN 2023
PG 17
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA 8U1HW
UT WOS:000929703300001
DA 2023-11-10
ER

PT J
AU Hsueh, YL
   Chou, TL
AF Hsueh, Yu-Ling
   Chou, Tai-Liang
TI A Task-oriented Chatbot Based on LSTM and Reinforcement Learning
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Dialogue generation; reinforcement learning; chatbots; natural language processing; deep learning
AB Thanks to the advancements in deep learning, chatbots are widely used in messaging applications. Undoubtedly, a chatbot is a new way of interaction between humans and machines. However, most of the chatbots act as a simple question answering system that responds with formulated answers. Traditional conversational chatbots usually adopt a retrieval-based model that requires a large amount of conversational data for retrieving various intents. Hence, training a chatbot model that uses low-resource conversational data to generate more diverse dialogues is desirable. We propose a method to build a task-oriented chatbot using a sentence generation model that generates sequences based on the generative adversarial network. The architecture of our model contains a generator that generates a diverse sentence and a discriminator that judges the sentences by comparing the generated and the ground-truth sentences. In the generator, we combine the attention model with the sequence-to-sequence model using hierarchical long short-term memory to extract sentence information. For the discriminator, our reward mechanism assigns low rewards for repeated sentences and high rewards for diverse sentences. Extensive experiments are presented to demonstrate the utility of our model that generates more diverse and information-rich sentences than those of the existing approaches.
C1 [Hsueh, Yu-Ling] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Adv Inst Mfg High Tech Innovat AIM HI, 168 Univ Rd, Chiayi 621301, Taiwan.
   [Hsueh, Yu-Ling] Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, 168 Univ Rd, Chiayi 621301, Taiwan.
   [Chou, Tai-Liang] Natl Chung Cheng Univ, Dept Comp Sci & Amp Informat Engn, 168 Univ Rd, Chiayi 621301, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University; National Chung Cheng University
RP Hsueh, YL (通讯作者)，Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Adv Inst Mfg High Tech Innovat AIM HI, 168 Univ Rd, Chiayi 621301, Taiwan.; Hsueh, YL (通讯作者)，Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, 168 Univ Rd, Chiayi 621301, Taiwan.
EM hsueh@cs.ccu.edu.tw; ztliang106m@cs.ccu.edu.tw
CR [Anonymous], 2004, ROUGE PACKAGE AUTOMA, V0, P0
   [Anonymous], 2015, US, V0, P0
   [Anonymous], 2021, SIRI, V0, P0
   [Anonymous], 2021, BUILD NATURAL RICH C, V0, P0
   [Anonymous], 2017, US, V0, P0
   [Anonymous], 2021, US, V0, P0
   [Anonymous], 2021, ICTCLAS, V0, P0
   [Anonymous], 2021, JIEBA, V0, P0
   Arjovsky M, 2017, ARXIV, V0, P0
   Bartl A, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP1120, DOI 10.1109/ICMLA.2017.00011
   Clancey William J, 1979, IJCAI 99 P 16 INT JO, V0, P155
   Williams JD, 2017, ARXIV, V0, P0
   Devlin J, 1900, P4171, V0, P0, DOI DOI 10.18653/v1/N19-1423
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Peters ME, 2018, ARXIV, V0, P0
   Emerson Thomas, 2005, P 4 SIGHAN WORKSH CH, V133, P0
   Eric Mihail, 2017, SHORT PAPERS, V2, P468
   Huang C, 2017, IEEE I CONF COMP VIS, V0, PP105, DOI 10.1109/ICCV.2017.21
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Lavie A, 2007, P 2 WORKSHOP STAT MA, V0, P228
   Li J, 2016, P 2016 C N AM CHAPT, V0, PP110, DOI 10.18653/v1/n16-1014
   Li Jiwei, 2016, EMNLP, V0, P0
   Li Jiwei, 2017, P EMNLP, V0, P2157
   Li XJ, 2018, ARXIV, V0, P0
   Liu B, 2017, ARXIV, V0, P0
   Liu Bing, 2018, P 2018 C N AM CHAPT, V0, PP67, DOI 10.18653/V1/N18-4010
   Liu W, 2011, KDD, V0, P1010
   Luong M-T, 2015, P 2015 C EMP METH NA, V0, PP1412, DOI 10.18653/V1/D15-1166
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, V0, P1
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Rubinstein Reuven Y, 2004, CROSS ENTROPY METHOD, V133, P0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shah P, 2018, P 2018 C N AM CHAPTE, V0, PP41, DOI 10.18653/v1/N18-3006
   Shu Lei, 2019, ARXIV, V0, P0
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Serban IV, 2016, ARXIV, V0, P0
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu YH, 2016, ARXIV, V0, P0
   Xu J, 2018, DP GAN DIVERSITY PRO, V0, P0
   Yu K, 2018, PROC CVPR IEEE, V0, PP2443, DOI 10.1109/CVPR.2018.00259
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
   Zhou KY, 2018, AAAI CONF ARTIF INTE, V0, P7582
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 46
TC 3
Z9 3
U1 5
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JAN 15
PY 2023
VL 22
IS 1
BP 
EP 
DI 10.1145/3529649
PG 27
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9D8QE
UT WOS:000936360700003
DA 2023-11-10
ER

PT J
AU Tao, ZH
   Ouyang, CP
   Liu, YB
   Chung, TLE
   Cao, YX
AF Tao, Zhihua
   Ouyang, Chunping
   Liu, Yongbin
   Chung, Tonglee
   Cao, Yixin
TI Multi-head attention graph convolutional network model: End-to-end entity and relation joint extraction based on multi-head attention graph convolutional network
SO CAAI TRANSACTIONS ON INTELLIGENCE TECHNOLOGY
LA English
DT Article
DE information retrieval; Natural Language Processing
ID recognition
AB At present, the entity and relation joint extraction task has attracted more and more scholars' attention in the field of natural language processing (NLP). However, most of their methods rely on NLP tools to construct dependency trees to obtain sentence structure information. The adjacency matrix constructed by the dependency tree can convey syntactic information. Dependency trees obtained through NLP tools are too dependent on the tools and may not be very accurate in contextual semantic description. At the same time, a large amount of irrelevant information will cause redundancy. This paper presents a novel end-to-end entity and relation joint extraction based on the multi-head attention graph convolutional network model (MAGCN), which does not rely on external tools. MAGCN generates an adjacency matrix through a multi-head attention mechanism to form an attention graph convolutional network model, uses head selection to identify multiple relations, and effectively improve the prediction result of overlapping relations. The authors extensively experiment and prove the method's effectiveness on three public datasets: NYT, WebNLG, and CoNLL04. The results show that the authors' method outperforms the state-of-the-art research results for the task of entities and relation extraction.
C1 [Tao, Zhihua; Ouyang, Chunping; Liu, Yongbin] Univ South China, Sch Comp Sci, Hengyang, Peoples R China.
   [Chung, Tonglee] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Cao, Yixin] Singapore Management Univ, Sch Comp & Informat Syst, Singapore, Singapore.
C3 University of South China; Tsinghua University; Singapore Management University
RP Ouyang, CP (通讯作者)，Univ South China, 28 Changsheng West Rd, Hengyang 421001, Hunan, Peoples R China.
EM ouyangcp@126.com
FU State Key Program of National Natural Science of China [61533018]; National Natural Science Foundation of China [61402220]; Philosophy and Social Science Foundation of Hunan Province [16YBA323]; Natural Science Foundation of Hunan Province [2020JJ4525]; Scientific Research Fund of Hunan Provincial Education Department [18B279, 19A439]
CR Bach N, 2007, LITER REV LANG STATI, V0, P0
   Bai C, 2020, NEUROCOMPUTING, V0, P0
   Bekoulis G, 2018, EXPERT SYST APPL, V114, P34, DOI 10.1016/j.eswa.2018.07.032
   Bekoulis G, 2018, EXPERT SYST APPL, V102, P100, DOI 10.1016/j.eswa.2018.02.031
   Fei H, 2020, INF PROCESS MANAG, V0, P0
   Fu TJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1409
   Fundel K, 2007, BIOINFORMATICS, V23, P365, DOI 10.1093/bioinformatics/btl616
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Guo ZJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P241
   Gupta P, 2016, P COLING 2016 26 INT, V0, P2537
   Honnibal Matthew, 2015, P 2015 C EMPIRICAL M, V0, PP1373, DOI 10.18653/v1/d15-1162
   Kambhatla N, 2004, P ACL 2004 INT POST, V0, PP22, DOI 10.3115/1219044.1219066
   Katiyar A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P917, DOI 10.18653/v1/P17-1085
   Kingma DP, 2014, C TRACK P, V0, P0
   Kipf T N, 2016, ICLR, V0, P0
   Li Q, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P402, DOI 10.3115/v1/p14-1038
   Li X, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P17
   Liu J, 2021, KNOWL-BASED SYST, V221, P0, DOI 10.1016/j.knosys.2021.106958
   Marcheggiani D, 2017, ARXIV170304826, V0, P0, DOI DOI 10.18653/V1/D17-1159
   Miwa M, 2014, PROC C EMPIRICAL MET, V0, PP1858, DOI 10.3115/V1/D14-1200
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Wei B, 2021, IEEE T COGN DEV SYST, V13, P503, DOI 10.1109/TCDS.2020.2977974
   Zeng X, 2018, P 56 ANN M ASS COMP, V0, P0
   Zhang X, 2017, P 15 C EUR CHAPT ASS, V0, P0
   Zhang YX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6279, DOI 10.1109/ICASSP.2018.8462291
   Zheng SC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1227, DOI 10.18653/v1/P17-1113
NR 28
TC 1
Z9 1
U1 10
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2468-6557
EI 2468-2322
J9 CAAI T INTELL TECHNO
JI CAAI T. Intell. Technol.
PD JUN 15
PY 2023
VL 8
IS 2
BP 468
EP 477
DI 10.1049/cit2.12086
EA MAR 2022
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA K0YA4
UT WOS:000773627200001
DA 2023-11-10
ER

PT J
AU Bacco, L
   Dell'Orletta, F
   Lai, HY
   Merone, M
   Nissim, M
AF Bacco, Luca
   Dell'Orletta, Felice
   Lai, Huiyuan
   Merone, Mario
   Nissim, Malvina
TI A text style transfer system for reducing the physician-patient expertise gap: An analysis with automatic and human evaluations
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Healthcare; Natural language processing; Text style transfer; Text simplification; Semantic textual similarity
ID health literacy; weighted kappa; agreement; risk; information; care
AB Physicians and patients often come from different backgrounds and have varying levels of education, which can result in communication difficulties in the healthcare process. To address this expertise gap, we present a "Text Style Transfer'' system. Our system uses Semantic Textual Similarity techniques based on Sentence Transformers models to create pseudo-parallel datasets from a large, non-parallel corpus of lay and expert texts. This approach allowed us to train a denoising autoencoder model (BART), overcoming the limitations of previous systems. Our extensive analysis, which includes both automatic metrics and human evaluations from both lay (patients) and expert (physicians) individuals, shows that our system outperforms state-of-the-art models and is comparable to human-provided gold references in some cases.
C1 [Bacco, Luca; Merone, Mario] Univ Campus Biomed Roma, Dept Engn, Unit Comp Syst & Bioinformat, Via Alvaro Portillo 21, I-00128 Rome, Italy.
   [Bacco, Luca; Dell'Orletta, Felice] CNR, Ist Linguist Computaz Antonio Zampolli, ItaliaNLP Lab, Via Giuseppe Moruzzi, 1, I-56124 Pisa, Italy.
   [Bacco, Luca] Webmonks Srl, R&D Lab, Via Triopio 5, I-00178 Rome, Italy.
   [Lai, Huiyuan; Nissim, Malvina] Univ Groningen, CLCG, Oude Kijk Int Jatstr 26, NL-9712 EK Groningen, Netherlands.
C3 University Campus Bio-Medico - Rome Italy; Consiglio Nazionale delle Ricerche (CNR); Istituto di Linguistica Computazionale "A. Zampolli" (ILC-CNR); University of Groningen
RP Merone, M (通讯作者)，Univ Campus Biomed Roma, Dept Engn, Unit Comp Syst & Bioinformat, Via Alvaro Portillo 21, I-00128 Rome, Italy.
EM l.bacco@unicampus.it; felice.dellorletta@ilc.cnr.it; h.lai@rug.nl; m.merone@unicampus.it; m.nissim@rug.nl
CR Gatys LA, 2015, ARXIV, V0, P0
   Alsentzer Emily, 2019, P 2 CLIN NATURAL LAN, V0, P0, DOI DOI 10.18653/V1/W19-1909
   Ananiadou S, 2021, FINDINGS ASS COMPUTA, V0, P876
   Apfel F, 2013, HLTH LIT SOL FACTS, V0, P3
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bacco L, 2020, COMPUT LINGUIST, V630, P16
   Bacco L, 2022, FRONT SURG, V9, P0, DOI 10.3389/fsurg.2022.957085
   Baker DW, 1998, J GEN INTERN MED, V13, P791, DOI 10.1046/j.1525-1497.1998.00242.x
   Baker DW, 2002, AM J PUBLIC HEALTH, V92, P1278, DOI 10.2105/AJPH.92.8.1278
   Basu C, 2021, AUTOMATIC MED TEXT S, V0, P0
   Batterham RW, 2016, PUBLIC HEALTH, V132, P3, DOI 10.1016/j.puhe.2016.01.001
   Benigeri M, 2003, HEALTH PROMOT INT, V18, P381, DOI 10.1093/heapro/dag409
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, PD267, DOI 10.1093/nar/gkh061
   Briakou E, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1321
   Briakou E, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, V0, P0
   CAMERER C, 1989, J POLIT ECON, V97, P1232, DOI 10.1086/261651
   Cao YX, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1061
   Cífka O, 2020, IEEE-ACM T AUDIO SPE, V28, P2638, DOI 10.1109/TASLP.2020.3019642
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dai N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5997
   de Mattei L, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6709
   Devaraj A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, PP4972, DOI 10.18653/v1/2021.naacl-main.395
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   EHinton Geoffrey, 2012, ARXIV, V0, P0
   Elazar Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P11
   Fu ZX, 2018, AAAI CONF ARTIF INTE, V0, P663
   Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6894
   Gao YJ, 2022, J AM MED INFORM ASSN, V29, P1797, DOI 10.1093/jamia/ocac127
   Grabar N, 2018, P 1 WORKSHOP AUTOMAT, V0, P3
   Guo Y, 2021, AAAI CONF ARTIF INTE, V35, P160
   Hadsell R, 2006, P 2006 IEEE COMP SOC, V2, P1735, DOI 10.1109/CVPR.2006.100
   Henderson M, 2017, EFFICIENT NATURAL LA, V0, P0
   Hu Z, 2017, P MACHINE LEARNING R, V70, P1587
   Huang HZ, 2017, PROC CVPR IEEE, V0, PP7044, DOI 10.1109/CVPR.2017.745
   Imankulova A, 2017, P 4 WORKSHOP ASIAN T, V0, P70
   Imankulova A, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3341726
   Jin D, 2021, COMPUT LINGUIST, V0, P1
   Jin ZJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3097
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Johnson AEW, 2016, SCI DATA, V3, P0, DOI 10.1038/sdata.2016.35
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Kim YH, 2022, EXPERT SYST APPL, V198, P0, DOI 10.1016/j.eswa.2022.116792
   King A, 2010, NAT REV CARDIOL, V7, P473, DOI 10.1038/nrcardio.2010.122
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Lai H, 2021, P 2021 C EMPIRICAL M, V0, PP4241, DOI 10.18653/v1/2021.emnlp-main.349
   Lai HY, 2022, PROCEEDINGS OF THE 2ND WORKSHOP ON HUMAN EVALUATION OF NLP SYSTEMS (HUMEVAL 2022), V0, P102
   Lai HY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P262
   Lai HY, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P484
   Lample G, 2019, 7 INT C LEARN REPR I, V0, P0
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lewis M, 2019, ARXIV, V0, P0
   Li J, 2018, P 2018 C N AM CHAPT, V1, P1865, DOI 10.18653/V1/N18-1169
   Long R, 2022, IAENG INT J COMPUTER, V49, P0
   Luo FL, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5116
   Luo JY, 2020, ARXIV, V0, P0
   Madaan A, 2020, ARXIV, V0, P0
   Mäenpää T, 2009, INT J MED INFORM, V78, P757, DOI 10.1016/j.ijmedinf.2009.07.001
   Manzini E, 2022, EXPERT SYST APPL, V204, P0, DOI 10.1016/j.eswa.2022.117446
   Marie B, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P392, DOI 10.18653/v1/P17-2062
   McCreery CH, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP3458, DOI 10.1145/3394486.3412861
   Mukherjee S, 2022, EXPERT SYST APPL, V191, P0, DOI 10.1016/j.eswa.2021.116195
   Niu, 2018, T ASS COMPUTATIONAL, V0, P0, DOI DOI 10.1162/TACL_A_00027
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Prabhumoye S, 2018, ARXIV, V0, P0
   Rabinovich E, 2017, ARXIV, V0, P0
   Rao SD, 2018, ARXIV, V0, P0
   Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2685
   Reimers N, 2019, ARXIV, V0, P0
   Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2699
   Sancheti Abhilasha, 2020, ADVANCES IN INFORMATION RETRIEVAL, V0, P0
   Sellam Thibault, 2020, P 58 ANN M ASS COMPU, V0, PP7881, DOI 10.18653/V1/2020.ACL-MAIN.704
   Sennrich R, 2016, ARXIV, V0, P0
   Shardlow M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P380
   Shen TX, 2017, ADV NEUR IN, V30, P0
   Shrout P E, 1998, STAT METHODS MED RES, V7, P301, DOI 10.1191/096228098672090967
   Soldaini Luca, 2016, MEDIR WORKSHOP, V0, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Surya S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2058
   Tan SSL, 2017, J MED INTERNET RES, V19, P0, DOI 10.2196/jmir.5729
   Tian CY, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17217768
   Tong A, 2020, CLIN J AM SOC NEPHRO, V15, P937, DOI 10.2215/CJN.00900120
   Toshevska Martina, 2022, IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, V3, P669, DOI 10.1109/TAI.2021.3115992
   van den Bercken L, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP3286, DOI 10.1145/3308558.3313630
   Vanbelle S, 2016, PSYCHOMETRIKA, V81, P399, DOI 10.1007/s11336-014-9439-4
   Hoang VCD, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, V0, P18
   Vydiswaran V G Vinod, 2014, AMIA ANNU SYMP PROC, V2014, P1150
   Wang X, 2017, P IEEE C COMPUTER VI, V0, P0
   Wang Y, 2018, P BIOCREATIVEOHNLP C, V0, P0
   Wang YS, 2020, JMIR MED INF, V8, P0, DOI 10.2196/23375
   Wang YS, 2020, LANG RESOUR EVAL, V54, P57, DOI 10.1007/s10579-018-9431-1
   Weng WH, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP3121, DOI 10.1145/3292500.3330710
   White Ryen W, 2009, AMIA ANNU SYMP PROC, V2009, P696
   Xu W, 2021, ARXIV, V0, P0
   Zeng-Treitler Qing, 2007, AMIA ANNU SYMP PROC, V0, P846
   Zhang N, 2022, ARXIV, V0, P0
   Zhang Tianyi, 2020, ICLR, V0, P0
   Zhou C, 2020, ARXIV, V0, P0
   Zhu SL, 2020, COMPUT INTEL NEUROSC, V2020, P0, DOI 10.1155/2020/8823906
   Zielstorff RD, 2003, J BIOMED INFORM, V36, P326, DOI 10.1016/j.jbi.2003.09.015
NR 101
TC 0
Z9 0
U1 1
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2023
VL 233
IS 
BP 
EP 
DI 10.1016/j.eswa.2023.120874
EA JUL 2023
PG 18
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA N9AQ1
UT WOS:001039858600001
DA 2023-11-10
ER

PT J
AU Man, TX
   Vodyaho, A
   Ignatov, DI
   Kulikov, I
   Zhukova, N
AF Man, Tianxing
   Vodyaho, Alexander
   Ignatov, Dmitry I.
   Kulikov, Igor
   Zhukova, Nataly
TI Synthesis of multilevel knowledge graphs: Methods and technologies for dynamic networks
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Knowledge graphs; Multilevel object model; Inductive synthesis; Deductive synthesis; Ontology; Telecommunication benchmark
AB Knowledge Graphs is one of the most popular techniques for knowledge-based modelling in various subdomains of modern AI technologies ranging from natural language processing to e-commerce recommendations and cyberphysical systems. Even complex technical systems like telecommunication networks could be modelled by means of Knowledge Graphs. However, there are serious challenges when we deal with such systems having a huge number of interconnected elements (e.g. technical objects and their groups) that change over time. Thus, up-to-date there is no adequate solution for not only telecommunication networks but for any complex dynamic systems where inductive and deductive synthesis of large Knowledge Graph based models that are easily reconfigurable and scalable is required.We state and solve the problem of building such models for one of the most common types of objects where models can be represented as hierarchical re-configurable structures. This representation enables recent advances in multilevel inductive-deductive synthesis for model building.From a methodological viewpoint, we propose a novel complex approach to multilevel synthesis for objects with dynamic hierarchical structure based on modified methods for inductive and deductive synthesis of Knowledge Graphs. From a practical perspective we present a real case-study on an interactive service for digital cable TV networks - which is especially interesting for data engineers and scientists - where various problems ranging from network health monitoring to channel advertising can be solved with the same hierarchical model. We release an openly available domain benchmark, which features two realistic datasets (namely, for SPARQL querying performance analysis, and for our case study on dynamic network monitoring). Last but not least, our experiments with recent state-of-the-art approaches to knowledge graph querying Abdelaziz et al. (2017) show that the developed models of multilevel synthesis reduce the time complexity up to 73% on practice compared to the baselines, and are lossless and able to beat their competitors based on parallel knowledge graph processing from 4% to 91% in terms of computational time (depending on the query type). Further parallelisation of our multilevel models is even more efficient (the reduction of query processing time is about 40%-45%) and opens promising prospects for the creation and exploitation of dynamic Knowledge Graphs in practice.
C1 [Man, Tianxing] Jilin Univ, Sch Life Sci, Sch Artificial Intelligence, 2699 Qianjin St, Changchun 130012, Jilin, Peoples R China.
   [Vodyaho, Alexander; Kulikov, Igor] St Petersburg Electrotech Univ LETI, St Petersburg, Russia.
   [Ignatov, Dmitry I.] Natl Res Univ Higher Sch Econ, Pokrovsky Bulvar 11, Moscow 109028, Russia.
   [Zhukova, Nataly] Russian Acad Sci SPCRAS, St Petersburg Fed Res Ctr, St Petersburg, Russia.
C3 Jilin University; Saint Petersburg State Electrotechnical University; HSE University (National Research University Higher School of Economics); Russian Academy of Sciences; St. Petersburg Federal Research Center of the Russian Academy of Sciences
RP Man, TX (通讯作者)，Jilin Univ, Sch Life Sci, Sch Artificial Intelligence, 2699 Qianjin St, Changchun 130012, Jilin, Peoples R China.
EM mantx@jlu.edu.cn; aivodyaho@mail.ru; dignatov@hse.ru; i.a.kulikov@gmail.com; nazhukova@mail.ru
CR Abdelaziz I, 2017, PROC VLDB ENDOW, V10, P2049, DOI 10.14778/3151106.3151109
   Abualigah L, 2022, EXPERT SYST APPL, V191, P0, DOI 10.1016/j.eswa.2021.116158
   Abualigah L, 2021, COMPUT IND ENG, V157, P0, DOI 10.1016/j.cie.2021.107250
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, P0, DOI 10.1016/j.cma.2020.113609
   Al-Tamimi AK, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY TRENDS (ITT 2020), V0, PP1, DOI 10.1109/itt51279.2020.9320778
   Altan A, 2020, PERFORMANCE METAHEUR, V0, P0, DOI DOI 10.1109/ismsit50672.2020.9255181
   Andrews Simon, 2018, GRAPH STRUCTURES FOR KNOWLEDGE REPRESENTATION AND REASONING. 5TH INTERNATIONAL WORKSHOP, V0, P3, DOI 10.1007/978-3-319-78102-0_1
   Bellini P, 2018, J VISUAL LANG COMPUT, V45, P24, DOI 10.1016/j.jvlc.2018.03.002
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009040101
   Bonatti Piero Andrea, 2019, DAGSTUHL REPORTS, V9, P29, DOI 10.4230/DagRep.8.9.29
   Bykau S, 2012, J DATA SEMANT, V1, P31, DOI 10.1007/s13740-012-0001-1
   Cafarella MJ, 2008, PROC VLDB ENDOW, V1, P538, DOI 10.14778/1453856.1453916
   Cardoso SD, 2020, KNOWL-BASED SYST, V194, P0, DOI 10.1016/j.knosys.2020.105508
   Chekol MW, 2017, AAAI CONF ARTIF INTE, V0, P88
   Chubb J, 2021, ARCH MATH LOGIC, V60, P721, DOI 10.1007/s00153-020-00753-4
   Crestan E, 2011, WSDM 11, V0, PP545, DOI 10.1145/1935826.1935904
   Demianiuk V, 2021, IEEE ACM T NETWORK, V29, P275, DOI 10.1109/TNET.2020.3034890
   Dessì D, 2021, FUTURE GENER COMP SY, V116, P253, DOI 10.1016/j.future.2020.10.026
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TPAMI.2007.1115
   Diana Maynard IA, 2016, WEB, V0, P0, DOI DOI 10.2200/S00741ED1V01Y201611WBE015
   Ell Basil, 2014, THE SEMANTIC WEB: TRENDS AND CHALLENGES. 11TH INTERNATIONAL CONFERENCE (ESWC 2014). PROCEEDINGS: LNCS 8465, V0, PP426, DOI 10.1007/978-3-319-07443-6_29
   Faralli S, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P590
   Ferrara E, 2014, ARXIV, V0, P0
   Flesca S, 2004, AI COMMUN, V17, P57
   Gentile CF, 2014, TEXT SPEECH DIALOGUE, V8655, P0
   Goel R, 2019, ARXIV, V0, P0, DOI DOI 10.1609/AAAI.V34I04.5815
   Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI 10.1145/3447772
   Hajipour V, 2015, INT J ADV MANUF TECH, V80, P31, DOI 10.1007/s00170-015-6993-6
   Han S, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP227, DOI 10.1145/3132847.3132957
   Hasan Rakebul, 2014, THE SEMANTIC WEB: TRENDS AND CHALLENGES. 11TH INTERNATIONAL CONFERENCE (ESWC 2014). PROCEEDINGS: LNCS 8465, V0, PP795, DOI 10.1007/978-3-319-07443-6_53
   Hertling S, 2020, KNOWL INF SYST, V62, P2169, DOI 10.1007/s10115-019-01415-5
   Nguyen HL, 2020, INFORM FUSION, V61, P56, DOI 10.1016/j.inffus.2020.03.014
   Hogan A, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3447772
   Huang WT, 2020, KNOWL-BASED SYST, V206, P0, DOI 10.1016/j.knosys.2020.106321
   Iana Andreea, 2019, SEMANTIC SYSTEMS. THE POWER OF AI AND KNOWLEDGE GRAPHS. 15TH INTERNATIONAL CONFERENCE, V0, P117, DOI 10.1007/978-3-030-33220-4_9
   Ji SX, 2021, ARXIV, V0, P0
   Jiang T, 2016, P 2016 C EMP METH NA, V0, P2350
   Jiang Tingsong, 2016, P COLING 2016 26 INT, V0, P1715
   Jin W, 2019, RECURRENT EVENT NETW, V0, P0
   Krinkin Kirill, 2022, INTERNATIONAL JOURNAL OF EMBEDDED AND REAL-TIME COMMUNICATION SYSTEMS, V0, P0, DOI DOI 10.4018/IJERTCS.311464
   Krinkin K, 2020, 9 MEDITERRANEAN C EM, V0, PP1, DOI 10.1109/MECO49872.2020.9134148
   Krinkin K, 2021, ARCHITECTURE CLOUD T, V0, P0, DOI DOI 10.23919/fruct53335.2021.9599995
   Krinkin KV, 2021, PROCEDIA COMPUT SCI, V186, P571, DOI 10.1016/j.procs.2021.04.178
   Krinkin K, 2021, INT J EMBED REAL-TIM, V12, P32, DOI 10.4018/IJERTCS.2021070103
   Krinkin K, 2020, PROC CONF OPEN INNOV, V0, PP231, DOI 10.23919/FRUCT48808.2020.9087429
   Leblay J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP1771, DOI 10.1145/3184558.3191639
   Lee I, 2009, HDB RES TELECOMMUNIC, V0, P0
   Lei Sang, 2021, EXPERT SYSTEMS WITH APPLICATIONS, V164, P0, DOI 10.1016/j.eswa.2020.113992
   Lei ZF, 2020, FUTURE GENER COMP SY, V102, P534, DOI 10.1016/j.future.2019.08.030
   Long JW, 2020, APPL SOFT COMPUT, V91, P0, DOI 10.1016/j.asoc.2020.106205
   Madhavan J, 2008, PROC VLDB ENDOW, V1, P1241
   Malik KM, 2020, EXPERT SYST APPL, V145, P0, DOI 10.1016/j.eswa.2019.113120
   Man TX, 2020, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.288
   Martinez-Rodriguez JL, 2018, EXPERT SYST APPL, V113, P339, DOI 10.1016/j.eswa.2018.07.017
   Masmoudi M, 2021, KNOWLEDGE HYPERGRAPH, V0, P0, DOI DOI 10.1016/j.future.2020.09.029
   Kazemi SM, 2020, ARXIV, V0, P0
   Morrow RK, 2016, TELECOMMUNICATIONS N, V0, P0
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Omran PG, 2021, IEEE T KNOWL DATA EN, V33, P1348, DOI 10.1109/TKDE.2019.2941685
   Osipov V, 2017, INT J COMPUT COMMUN, V11, P17
   Osipov V, 2019, LECT NOTES COMPUT SC, V11620, P441, DOI 10.1007/978-3-030-24296-1_35
   Osipov VY, 2017, 2017 INTERNATIONAL CONFERENCE ON CONTROL, V0, P0
   Ost A, 2001, MODERN TELECOMMUNICA, V0, PP9, DOI 10.1007/978-3-662-04421-6_2
   Palumbo E, 2020, EXPERT SYST APPL, V151, P0, DOI 10.1016/j.eswa.2020.113235
   Qiao X, 2012, TELECOMMUNICATIONS N, V0, P0, DOI DOI 10.5772/36794
   Ren H, 2022, IEEE T ARTIF INTELL, V0, P0
   Sezer Ali, 2021, 2021 3RD INTERNATIONAL CONGRESS ON HUMAN-COMPUTER INTERACTION, V0, P0, DOI 10.1109/HORA52670.2021.9461342
   Sezer A, 2021, 2021 3 INT C HUM COM, V0, P1
   Shao BL, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.113764
   Stoica R, 2019, 13 ALBERTO MENDELZON, V0, P0
   Tabacof P, 2020, 8 INT C LEARNING REP, V0, P26
   Trivedi R, 2017, ARXIV, V0, P0
   Velten K, 2009, MATH MODELING SIMULA, V0, P0
   Vodyaho Alexander, 2021, ZENODO, V0, P0, DOI DOI 10.5281/ZENODO.7605504
   Vodyaho A, 2022, LECT NOTES COMPUT SC, V13380, P693, DOI 10.1007/978-3-031-10542-5_48
   Vodyaho A, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9111846
   Walshaw C, 2003, JOURNAL OF GRAPH ALGORITHMS AND APPLICATIONS, V7, P0, DOI 10.7155/jgaa.00070
   Wu GQ, 2018, IEEE ACCESS, V6, P6220, DOI 10.1109/ACCESS.2017.2787787
   Wu H, 2017, EXPLOITING LINKED DA, V0, PP147, DOI 10.1007/978-3-319-45654-6_6
   Yang ZX, 2020, KNOWL-BASED SYST, V204, P0, DOI 10.1016/j.knosys.2020.106194
   Yoshinov R, 2020, METHODS COMPOSING HI, V72, P69, DOI 10.7546/PECR.72.20.07
   Yuan Liang, 2018, COMPUTATIONAL VISUAL MEDIA, V4, P123, DOI 10.1007/s41095-018-0110-3
   Zhang J, 2021, OPEN, V2, P14, DOI 10.1016/j.aiopen.2021.03.001
   Zhou G, 2005, P 43 ANN M ASS COMPU, V0, P0, DOI DOI 10.3115/1219840.1219893
   Zhou Q, 2019, TOCO ONTOLOGY REPRES, V0, P0, DOI DOI 10.1007/978-3-030-21348-0_33
   Zhu XR, 2022, ARXIV, V0, P0
NR 86
TC 0
Z9 0
U1 5
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD AUG 15
PY 2023
VL 123
IS 
BP 
EP 
DI 10.1016/j.engappai.2023.106244
PG 32
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA P9QL6
UT WOS:001053951500001
DA 2023-11-10
ER

PT J
AU Hadni, M
   Hjiaj, H
AF Hadni, Meryeme
   Hjiaj, Hassane
TI New Model of Feature Selection based Chaotic Firefly Algorithm for Arabic Text Categorization
SO INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY
LA English
DT Article
DE Chaotic method; firefly algorithm; arabic text categorization; feature selection
AB The dimensionality reduction is a type of problem that appear in the most classification processes. It contains a large number of features; these features may contain unreliable data which may lead the categorization process to unwanted results. Feature selection can be used for reducing dimensionality of datasets and find interesting relevant information. In Arabic language, the number of works applies a meta-heuristic algorithm for feature selection is still limited due to the complex nature of Arabic inflectional and derivational rules as well as its intricate grammatical rules and its rich morphology. This paper proposes a new model for Arabic Feature Selection that combines the chaotic method in the Firefly Algorithm (CFA). The Chaotic Algorithm replaces the attractiveness coefficient in firefly algorithm by the outputs of chaotic application. The enhancement of the new approach involves introducing a novel search strategy which is able to obtain a good ratio between exploitation and exploration abilities of the algorithm. In terms In terms of performance, the experiments of the proposed method are tested using classifiers, namely Naive Bayes (NB), Support Vector Machine (SVM) and K-Nearest Neighbors (KNN) and three evaluation measures, including precision, recall, and F-measure. The experimental findings show that the combining of CFA and SVM classifiers outperforms other combinations in terms of precision.
C1 [Hadni, Meryeme] EMSI, LAMIGEP, Comp Sci, Rabat, Morocco.
   [Hjiaj, Hassane] Fac Sci, Dept Math, Agadir, Morocco.
RP Hadni, M (通讯作者)，EMSI, LAMIGEP, Comp Sci, Rabat, Morocco.
EM meryemehadni@gmail.com; hjiajhassane@yahoo.fr
CR Ahmad SR, 2017, AIP CONF PROC, V1891, P0, DOI 10.1063/1.5005351
   Al-Harbi S, 2008, P 9 INT C STAT AN TE, V0, P77
   Al-Zahrani AM, 2015, J UNIVERS COMPUT SCI, V21, P1454
   Alghamdi H, 2012, P IEEE WORLD C COMP, V0, PP10, DOI 10.1109/CEC.2012.6252960
   Bessou S, 2007, 1 SEM NAT LANG NAT I, V0, P20
   El-Halees A, 2007, ISLAMIC U J, V15, P157
   El-Kourdi M, 2004, P WORKSHOP COMPUTATI, V0, P0, DOI DOI 10.3115/1621804.1621819
   Greene D, 2017, POLIT ANAL, V25, P77, DOI 10.1017/pan.2016.7
   Hadni M, 2013, INT J NATURAL LANGUA, V2, P1
   Hadni M, 2022, INT AR C INF TECHN A, V0, PP1, DOI 10.1109/ACIT57182.2022.9994102
   Hadni M, 2013, INT J DATA MINING KN, V3, P0, DOI 10.5121/ijdkp.2013.3401
   Jaafaru B, 2020, J ENG RES APPL, V10, P0, DOI 10.9790/9622-1004032637
   Lin J, 2012, INT CONF COMP SCI ED, V0, PP1842, DOI 10.1109/ICCSE.2012.6295429
   Marie-Sainte SL, 2020, J KING SAUD UNIV-COM, V32, P320, DOI 10.1016/j.jksuci.2018.06.004
   Mohd Abdelwadood, 2007, JOURNAL OF COMPUTER SCIENCES, V3, P430, DOI 10.3844/jcssp.2007.430.435
   Mohammad S, 2021, EMOTION MEASUREMENT, V0, PP323, DOI 10.1016/B978-0-12-821124-3.00011-9
   Nahar K, 2020, INT ARAB J INF TECHN, V17, P394, DOI 10.34028/iajit/17/3/13
   Saraç E, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (IEEE INISTA), V0, P0
   Selamat A, 2014, J TEKNOL, V70, P73, DOI 10.11113/jt.v70.3518
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Tandra V, 2021, P INT C ICT SMART SO, V0, PP1, DOI 10.1109/ICISS53185.2021.9532503
   Thirumagal D, 2021, INT J ENG RES TECHNO, V10, P38
   Thribhuvan N, 2022, INT ARAB J INF TECHN, V19, P721, DOI 10.34028/iajit/19/5/3
   Touati-Hamad Z, 2022, INT ARAB J INF TECHN, V19, P681, DOI 10.34028/iajit/19/4/13
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yang YM, 1999, SIGIR99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP42, DOI 10.1145/312624.312647
   Yoshida M, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P10
   Yousif S, 2019, IAENG INT J COMPUTER, V64, P750
   Zhang L, 2018, DECIS SUPPORT SYST, V106, P64, DOI 10.1016/j.dss.2017.12.001
NR 29
TC 0
Z9 0
U1 1
U2 1
PU ZARKA PRIVATE UNIV
PI ZARQA
PA COLL COMPUTING & INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN
SN 1683-3198
EI 
J9 INT ARAB J INF TECHN
JI Int. Arab J. Inf. Technol.
PD JUN 15
PY 2023
VL 20
IS 3A
BP 461
EP 468
DI 10.34028/iajit/20/3A/3
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA S0YV7
UT WOS:001068521100004
DA 2023-11-10
ER

PT J
AU Di, DL
   Song, XY
   Zhang, WN
   Zhang, Y
   Wang, FL
AF Di, Donglin
   Song, Xianyang
   Zhang, Weinan
   Zhang, Yue
   Wang, Fanglin
TI Building Dialogue Understanding Models for Low-resource Language Indonesian from Scratch
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Dialogue datasets; intent classification; slot-filling; indonesian
AB Using off-the-shelf resources from resource-rich languages to transfer knowledge to low-resource languages has received a lot of attention. The requirements of enabling the model to achieve the reliable performance, including the scale of required annotated data and the effective framework, are not well guided. To address the first question, we empirically investigate the cost-effectiveness of several methods for training intent classification and slot-filling models from scratch in Indonesia (ID) using English data. Confronting the second challenge, we propose a Bi-Confidence-Frequency Cross-Lingual transfer framework (BiCF), which consists of "BiCF Mixing", "Latent Space Refinement" and "Joint Decoder", respectively, to overcome the lack of low-resource language dialogue data. BiCF Mixing based on the word-level alignment strategy generates code-mixed data by utilizing the importance-frequency and translating-confidence. Moreover, Latent Space Refinement trains a new dialogue understanding model using code-mixed data and word embedding models. Joint Decoder based on Bidirectional LSTM (BiLSTM) and Conditional Random Field (CRF) is used to obtain experimental results of intent classification and slot-filling. We also release a large-scale fine-labeled Indonesia dialogue dataset (ID-WOZ(1)) and ID-BERT for experiments. BiCF achieves 93.56% and 85.17% (F1 score) on intent classification and slot filling, respectively. Extensive experiments demonstrate that our framework performs reliably and cost-efficiently on different scales of manually annotated Indonesian data.
C1 [Di, Donglin; Wang, Fanglin] Adv AI, Res & Dev, 80 Robinson Rd, Singapore 068898, Singapore.
   [Song, Xianyang] Northeast Forestry Univ, Harbin 150040, Peoples R China.
   [Zhang, Weinan] Harbin Inst Technol, 92 West Dazhi St, Harbin, Heilongjiang, Peoples R China.
   [Zhang, Yue] Westlake Univ, Hangzhou 310024, Zhejiang, Peoples R China.
C3 Northeast Forestry University - China; Harbin Institute of Technology; Westlake University
RP Di, DL (通讯作者)，Adv AI, Res & Dev, 80 Robinson Rd, Singapore 068898, Singapore.
EM donglin.ddl@gmail.com; sxy56713@nefu.edu.cn; wnzhang@ir.hit.edu.cn; yue.zhang@wias.org.cn; fanglin.wang@advancegroup.com
FU Science and Technology Innovation 2030 Major Project of China [2021ZD0113302]; National Natural Science Foundation of China [62076081, 61772153, 61936010]
CR Ammar Waleed, 2016, T ASS COMPUTATIONAL, V4, P431, DOI 10.1162/TACL_A_00109
   [Anonymous], 2015, P 2015 C EMPIRICAL M, V0, P0
   [Anonymous], 2013, SIMPLE FAST EFFECTIV, V0, P0
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Budzianowski Pawel, 2018, C EMPIRICAL METHODS, V0, P0
   Chen Hongshen, 2016, P 2016 C EMPIRICAL M, V0, P731
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Cheng Y, 2019, JOINT TRAINING NEURA, V0, PP25, DOI 10.1007/978-981-32-9748-7_3
   Chowanda Andry, 2017, INT C COMPUTER SCI C, V0, P0
   Collins Michael, 2011, STAT MACHINE TRANSLA, V0, P0
   de Melo Gerard, 2017, P IJCNLP 2017, V0, P3
   Devlin J, 2019, ARXIV, V0, P0
   Dozat T, 2017, ARXIV, V0, P0
   Feng Yue, 2020, ANN M ASS COMPUTATIO, V0, P0
   FLEISS JL, 1969, PSYCHOL BULL, V72, P323, DOI 10.1037/h0028106
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3483
   Gunasekara C, 2020, ARXIV, V0, P0
   Guo J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1234
   Guo JY, 2022, ARXIV, V0, P0
   Guo Jinyu, 2021, ARXIV, V0, P0
   HongminWang Yue Zhang, 2017, ARXIV, V0, P0
   Joulin A, 2016, ARXIV, V0, P0
   KELLEY JF, 1984, ACM T OFF INF SYST, V2, P26, DOI 10.1145/357417.357420
   Kim S, 2021, FINDINGS 2022 C EMPI, V0, P352
   Koto F, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P801
   Lin Yen-Ting, 2021, ARXIV, V0, P0
   Liu Hui, 2018, ANN M ASS COMPUTATIO, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Liu ZH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1297
   Liu ZH, 2020, AAAI CONF ARTIF INTE, V34, P8433
   McCann Bryan, 2017, ADV NEURAL INFORM PR, V0, P6297
   Moghe N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1137
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ramos J, 2003, P 1 INSTR C MACH LEA, VVolume 242, P29
   Salton Gerard, 1982, EXTENDED BOOLEAN INF, V0, P0
   Schuster Sebastian, 2018, N AM CHAPTER ASS COM, V0, P0
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   Sun WW, 2021, SIGIR 21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1442, DOI 10.1145/3404835.3462883
   Tho Cuk, 2018, PROCEDIA COMPUTER SCIENCE, V135, P315, DOI 10.1016/j.procs.2018.08.179
   Tiedemann J, 2016, J ARTIF INTELL RES, V55, P209, DOI 10.1613/jair.4785
   Tiedemann Jorg, 2015, P 20 NORDIC C COMPUT, V0, P191
   Vaswani A, 2018, C ASS MACHINE TRANSL, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wu Chien-Sheng, 2019, ANN M ASS COMPUTATIO, V0, P0
   Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046
   Xiang Lu, 2021, P CCF INT C NATURAL, V0, P193
   Yang Z, 2019, NEURAL INFORM PROCES, V0, P0
   Zhang MS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P997
NR 52
TC 0
Z9 0
U1 3
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR 15
PY 2023
VL 22
IS 4
BP 
EP 
DI 10.1145/3575803
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FI3
UT WOS:000998929700013
DA 2023-11-10
ER

PT J
AU Rahman, H
   Rahin, RS
   Mahbub, AM
   Islam, A
   Mukta, SH
   Rahman, M
AF Rahman, Habibur
   Rahin, Rezwan Shahrior
   Mahbub, Araf Mohammad
   Islam, Adnanul
   Mukta, Saddam Hossain
   Rahman, Mahbubur
TI Punctuation Prediction in Bangla Text
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Neural networks; punctuation prediction; natural language processing; BRNN
ID network
AB Punctuation prediction is critical as it can enhance the readability of machine-transcribed speeches or texts significantly by adding appropriate punctuation. Furthermore, systems like Automatic Speech Recognizer (ASR) produce texts that are unpunctuated, making the readability difficult for humans and also hampers the performance of various natural language processing (NLP) tasks. Such NLP related tasks have been investigated thoroughly for English; however, very limited work is done for punctuation prediction in the Bangla language. In this study, we train a bidirectional recurrent neural network (BRNN) along with Attention model with a plausibly large Bangla dataset. Afterwards, we apply extensive postprocessing techniques for predicting punctuation more accurately with the employed model. Initially, we perform experimentationwith a relatively imbalanced dataset, and our model shows promising results (F1 = 56.9 for Period) in punctuation prediction. Later, we also investigate the model's performance using a balanced Bangla dataset to achieve higher performance scores (F1 = 62.2 for Question). Thus, the goal of this study is to propose an efficient approach that can predict punctuation in Bangla texts effectively. Our study also includes investigation on how our postprocessing techniques affect the prediction performance. Being an early attempt for the punctuation prediction in Bangla text, our work is expected to significantly contribute in the NLP field for the Bangla language, and will pave the way for future work with the Bangla language in this direction.
C1 [Rahman, Habibur; Rahin, Rezwan Shahrior; Mahbub, Araf Mohammad; Mukta, Saddam Hossain] United Int Univ, Dhaka 1200, Bangladesh.
   [Islam, Adnanul] Monash Univ, Clayton, Vic 3800, Australia.
   [Rahman, Mahbubur] Mil Inst Sci & Technol, Mirpur Cantonment, Dhaka 1216, Bangladesh.
C3 United International University (UIU); Monash University
RP Rahman, H (通讯作者)，United Int Univ, Dhaka 1200, Bangladesh.
EM habiburrahmanshamimm@gmail.com; rezwanshahriorrahin@gmail.com; araf@gtaf.org; Adnan.Islam@monash.edu; saddam@cse.uiu.ac.bd; mahbub@cse.mist.ac.bd
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Adiba FI, 2020, INT J AUTOMATION ART, V1, P80
   Al Nazi Zabir, 2020, BANGLA NEWSPAPER DAT, V0, P0, DOI DOI 10.34740/KAGGLE/DSV/1576225
   Alam Tanvirul, 2020, P 6 WORKSHOP NOISY U, V0, PP132, DOI 10.18653/V1/2020.WNUT-1.18
   Bahdanau D, 2016, ARXIV, V0, P0
   Ballesteros Miguel, 2016, P 2016 C EMPIRICAL M, V0, P1048
   Beeferman D, 1998, INT CONF ACOUST SPEE, V0, PP689, DOI 10.1109/ICASSP.1998.675358
   Cho KYHY, 2014, ARXIV, V0, P0
   Cho KYHY, 2014, ARXIV, V0, P0
   Chung JY, 2014, ARXIV, V0, P0
   Fang M, 2019, P INT C LEARN REPR I, V0, PP1, DOI 10.1109/ICSIDP47821.2019.9172986
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hasan HMMahmudul, 2020, 2020 THIRD INTERNATIONAL CONFERENCE ON SMART SYSTEMS AND INVENTIVE TECHNOLOGY (ICSSIT), V0, PP1131, DOI 10.1109/ICSSIT48917.2020.9214196
   Islam Adnanul, 2016, P 7 ANN S COMPUTING, V0, P0
   Islam MA, 2021, NEURAL COMPUT APPL, V33, P12141, DOI 10.1007/s00521-021-05895-x
   Islam MA, 2017, PROCEEDINGS OF 2017 4TH INTERNATIONAL CONFERENCE ON NETWORKING, V0, P95
   Islam MdAdnanul, 2022, P 22 ACMINTERNATIONA, V0, P0, DOI DOI 10.1145/3514197.3549640
   Juin CC, 2017, TENCON IEEE REGION, V0, PP1806, DOI 10.1109/TENCON.2017.8228151
   Kim S, 2019, INT CONF ACOUST SPEE, V0, PP7280, DOI 10.1109/ICASSP.2019.8682418
   Li XX, 2020, INTERSPEECH, V0, PP1067, DOI 10.21437/Interspeech.2020-2052
   Liu X, 2018, INT CONF ASIAN LANG, V0, PP74, DOI 10.1109/IALP.2018.8629143
   Makhija K, 2019, ASIAPAC SIGN INFO PR, V0, PP268, DOI 10.1109/APSIPAASC47483.2019.9023200
   Makhoul J, 1999, P DARPA BROADCAST NE, V249, P252
   Milkowski M, 2010, SOFTWARE PRACT EXPER, V40, P543, DOI 10.1002/spe.971
   Moró A, 2017, INTERSPEECH, V0, PP558, DOI 10.21437/Interspeech.2017-204
   Mukta MSH, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3474363
   Nanchen A, 2019, INT CONF ACOUST SPEE, V0, PP7275, DOI 10.1109/ICASSP.2019.8683796
   Oktem Alp, 2017, STATISTICAL LANGUAGE AND SPEECH PROCESSING. 5TH INTERNATIONAL CONFERENCE, V0, P131, DOI 10.1007/978-3-319-68456-7_11
   Parlar T, 2019, COMPUT SCI-AGH, V20, P123, DOI 10.7494/csci.2019.20.1.3097
   Peitz Stephan, 2011, P 8 INT WORKSHOP SPO, V0, P0
   Pham QH, 2019, SOICT 2019: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY, V0, PP322, DOI 10.1145/3368926.3369716
   Rodr¡guez P, 2018, ARXIV, V0, P0
   Salloum W, 2017, BIONLP 2017, V2017, P159
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Su YH, 2019, NEUROCOMPUTING, V356, P151, DOI 10.1016/j.neucom.2019.04.044
   Szaszák G, 2019, INTERSPEECH, V0, PP2988, DOI 10.21437/Interspeech.2019-2132
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Tilk O, 2016, INTERSPEECH, V0, PP3047, DOI 10.21437/Interspeech.2016-1517
   Tündik MA, 2018, INT CONF COGN INFO, V0, PP135, DOI 10.1109/CogInfoCom.2018.8639876
   Varavs A, 2018, LECT NOTES ARTIF INT, V11171, P91, DOI 10.1007/978-3-030-00810-9_9
   Wang F, 2018, INT C PATT RECOG, V0, PP2803, DOI 10.1109/ICPR.2018.8545470
   Wang T, 2015, ARXIV, V0, P0
   Xu K, 2016, 2016 10 INT S CHINES, V0, PP1, DOI 10.1109/ISCSLP.2016.7918492
   Yi JY, 2019, INT CONF ACOUST SPEE, V0, PP7270, DOI 10.1109/ICASSP.2019.8682260
   Zelasko P, 2018, ARXIV, V0, P0
NR 45
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2023
VL 22
IS 3
BP 
EP 
DI 10.1145/3575804
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA H9FA8
UT WOS:000998922200019
DA 2023-11-10
ER

