PT J
AU Qamar, S
   Mujtaba, H
   Majeed, H
   Beg, MO
AF Qamar, Saira
   Mujtaba, Hasan
   Majeed, Hammad
   Beg, Mirza Omer
TI Relationship Identification Between Conversational Agents Using Emotion Analysis
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Behavioral analysis; Dialogue systems; Social network analysis; Multi-agent interaction; Conversational interactions
AB Human relationships are influenced by the underlying emotions in their interactions. With the increasing use of social networks, relationships from textual data can also be inferred from online interactions. Such interactions result in massive amount of textual data which is available in the form of text messages, emails, and social media posts. Identification and analysis of human relationships are useful for numerous applications ranging from cybersecurity to public health. In this paper, we present a method called RIEA (Relationship Identification using Emotion Analysis), for identifying relationships between multiple intelligent agents by analyzing the conversation between them. The objective of our work is to combine concepts of cognitive psychology and natural language processing (NLP) to extract emotions and map them onto a set of relationships and analyze how relationships transform over time. We employ psychological models to label a large corpus of conversations and apply machine learning techniques to determine emotion-to-relationship mapping. We use four distinct association classes and four attachment styles using best-worst scaling method for classification. Combining the attachment and association styles given in research literature gives us the relationship combinations for our analysis. Additionally, this work studies the most common changes of behaviors and emotions and the corresponding transformations in human relationships. Our results show that RIEA can correctly detect interpersonal relationships with an accuracy of 85%. The evaluation shows that RIEA can accurately identify interpersonal relationships from conversations and can be extended for identifying more complex relationships. This study also highlights the effect of changes in emotional behavior in the development of relationships over time.
C1 [Qamar, Saira; Mujtaba, Hasan; Majeed, Hammad; Beg, Mirza Omer] Natl Univ Comp & Emerging Sci, AK Brohi Rd,H-11-4, Islamabad, Pakistan.
RP Beg, MO (通讯作者)，Natl Univ Comp & Emerging Sci, AK Brohi Rd,H-11-4, Islamabad, Pakistan.
EM sairaqamar591@yahoo.com; hasan.mujtaba@nu.edu.pk; hammad.majeed@nu.edu.pk; omer.beg@nu.edu.pk
CR Al-Ghadir AI, 2019, COGN COMPUT, V11, P71, DOI 10.1007/s12559-018-9592-7
   Awan MN, 2020, COMPUTER SPEECH LANG, V65, P101
   Bourgais M, 2018, LECT NOTES ARTIF INT, V10798, P89, DOI 10.1007/978-3-319-91587-6_7
   Bravo-Marquez F, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), V0, PP536, DOI 10.1109/WI.2016.0091
   Cabrera-Diego LA, 2020, KNOWL-BASED SYST, V195, P0, DOI 10.1016/j.knosys.2020.105633
   Calefato F, 2017, INT CONF AFFECT, V0, PP79, DOI 10.1109/ACIIW.2017.8272591
   Collenette J, 2019, SPR PROC ADV ROBOT, V6, P559, DOI 10.1007/978-3-319-73008-0_39
   Danescu-Niculescu-Mizil C, 2011, P WORKSH COGN MOD CO, V0, P0
   Danisman T, 2008, FEELER EMOTION CLASS, V0, P53
   DERIVERA J, 1986, MOTIV EMOTION, V10, P351, DOI 10.1007/BF00992109
   Flynn TN, 2014, HDB CHOICE MODELLING, V0, P178
   Fox J, 2015, CYBERPSYCH BEH SOC N, V18, P491, DOI 10.1089/cyber.2015.0123
   Gilovich T, 2012, SOCIAL PSYCHOL, V0, P0
   Ho Dung T, 2012, KNOWLEDGE MANAGEMENT AND ACQUISITION FOR INTELLIGENT SYSTEMS. PROCEEDINGS OF THE 12TH PACIFIC RIM KNOWLEDGE ACQUISITION WORKSHOP, V0, P94, DOI 10.1007/978-3-642-32541-0_8
   Hortensius R, 2018, IEEE T COGN DEV SYST, V10, P852, DOI 10.1109/TCDS.2018.2826921
   Islam MR, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, V0, PP1536, DOI 10.1145/3167132.3167296
   Kao ECC, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, V0, P70, DOI 10.1109/ICIME.2009.113
   Khawaja HS, 2018, INT CONF EMERG TECHN, V0, P0
   Kolak J, 2013, ARXIV13036094, V0, P0
   Li YM, 2019, COGN COMPUT, V11, P459, DOI 10.1007/s12559-019-9624-y
   Lin J, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS15), V0, P1947
   Liu ZH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1297
   Ma YK, 2020, INFORM FUSION, V64, P50, DOI 10.1016/j.inffus.2020.06.011
   Majumder N, 2019, AAAI CONF ARTIF INTE, V0, P6818
   Mohammad SM, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P198
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Naeem B, 2020, J COMPUT SOC SCI, V3, P231, DOI 10.1007/s42001-020-00063-y
   Neviarouskaya A, 2007, LECT NOTES COMPUT SC, V4738, P218
   Plutchik R, 2003, EMOTIONS LIFE PERSPE, V0, P10: 1557989494
   Saunier J, 2014, AAMAS14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, V0, P645
   Shiota MN, 2004, REGULATION OF EMOTION, V0, P127
   Singh D, 2017, AAMAS17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, V0, P249
   Singh D, 2016, AUTON AGENT MULTI-AG, V30, P1050, DOI 10.1007/s10458-016-9332-x
   Smith Eliot R, 2014, SOCIAL PSYCHOL, V0, P0, DOI DOI 10.4324/9780203833698
   Strapparava C, 2004, P 4 INT C LANGUAGE R, V0, P0
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Wang JJ, 2006, INT CONF SIGN PROCES, V0, P1815
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Wang ZX, 2020, MULTIMED TOOLS APPL, V79, P35553, DOI 10.1007/s11042-019-08328-z
   Wu S, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.515
   Yang HC, 2018, COGN COMPUT, V10, P1152, DOI 10.1007/s12559-018-9576-7
   Young T, 2020, NEUROCOMPUTING, V388, P102, DOI 10.1016/j.neucom.2019.12.126
NR 42
TC 9
Z9 9
U1 0
U2 23
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD MAY 15
PY 2021
VL 13
IS 3
BP 673
EP 687
DI 10.1007/s12559-020-09806-5
EA JAN 2021
PG 15
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA SB1BA
UT WOS:000604851700007
DA 2023-11-10
ER

PT J
AU Sidig, AAI
   Luqman, H
   Mahmoud, S
   Mohandes, M
AF Sidig, Ala Addin, I
   Luqman, Hamzah
   Mahmoud, Sabri
   Mohandes, Mohamed
TI KArSL: Arabic Sign Language Database
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Arabic sign language database; sign language recognition; sign language translation; gesture recognition; human computer interaction; HMM
ID gesture recognition
AB Sign language is the major means of communication for the deaf community. It uses body language and gestures such as hand shapes, lib patterns, and facial expressions to convey a message. Sign language is geography-specific, as it differs from one country to another. Arabic Sign language is used in all Arab countries. The availability of a comprehensive benchmarking database for ArSL is one of the challenges of the automatic recognition of Arabic Sign language. This article introduces KArSL database for ArSL, consisting of 502 signs that cover 11 chapters of ArSL dictionary. Signs in KArSL database are performed by three professional signers, and each sign is repeated 50 times by each signer. The database is recorded using state-of-art multi-modal Microsoft Kinect V2. We also propose three approaches for sign language recognition using this database. The proposed systems are Hidden Markov Models, deep learning images' classification model applied on an image composed of shots of the video of the sign, and attention-based deep learning captioning system. Recognition accuracies of these systems indicate their suitability for such a large number of Arabic signs. The techniques are also tested on a publicly available database. KArSL database will be made freely available for interested researchers.
C1 [Sidig, Ala Addin, I; Luqman, Hamzah; Mahmoud, Sabri; Mohandes, Mohamed] King Fahd Univ Petr & Minerals, Dhahran 31261, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP Sidig, AAI (通讯作者)，King Fahd Univ Petr & Minerals, Dhahran 31261, Saudi Arabia.
EM alasidig@kfupm.edu.sa; hluqman@kfupm.edu.sa; smasaad@kfupm.edu.sa; mohandes@kfupm.edu.sa
FU King Fahd University of Petroleum and Minerals (KFUPM) [IN151008]
CR Abadi M, 2016, TECH REP, V0, P0
   Ahmed AAW, 2014, EUROPEAN WIRELESS C, V0, P1
   Al-Fityani Kinda, 2010, SIGN LANGUAGES CAMBR, V0, PP433, DOI 10.1017/CBO9780511712203.020
   Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   AL-Rousan M, 2009, APPL SOFT COMPUT, V9, P990, DOI 10.1016/j.asoc.2009.01.002
   Ali A, 2016, P 5 INT C INF COMM T, V0, PP1, DOI 10.1109/ICTA.2015.7426902.
   Almasre MA, 2016, COMPUT SCI ELECTR, V0, PP146, DOI 10.1109/CEEC.2016.7835904
   Aly S, 2014, COMM COM INF SC, V488, P36
   Alyl S, 2016, ICENCO 2016 - 2016 12TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO) - BOUNDLESS SMART SOCIETIES, V0, PP99, DOI 10.1109/ICENCO.2016.7856452
   Amin O, 2015, 2015 TENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), V0, PP389, DOI 10.1109/ICCES.2015.7393081
   [Anonymous], 2008, THESIS DUBLIN CITY U, V0, P0
   [Anonymous], 2012, INT C COMMUNICATIONS, V0, P0
   [Anonymous], 2011, INT J ADV COMPUT SCI, V0, P0
   [Anonymous], 2011, P 2 WORKSHOP SPEECH, V0, P0
   Arab League Educational Cultural and Scientific Organization, 2006, 2 PART UN AR SIGN LA, V0, P0
   Arab League Educational Cultural and Scientific Organization, 2000, LAS 1 PART UN AR SIG, V0, P0
   Assaleh K, 2005, EURASIP J APPL SIG P, V2005, P2136, DOI 10.1155/ASP.2005.2136
   Assaleh K, 2008, P 5 INT S MECH APPL, V0, P1
   Aujeszky T, 2016, MULTIMED TOOLS APPL, V75, P8493, DOI 10.1007/s11042-015-2767-2
   Barczak ALC, 2011, RES LETT INF MATH SC, V15, P12
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, V0, P0, DOI DOI 10.5244/C.25.76
   Crasborn Onno, 2007, INT J CORPUS LINGUIS, V12, P535
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   DREUW P, 2007, HAND, V60, P80
   ElBadawy M, 2015, ADV INTELL SYST, V323, P721, DOI 10.1007/978-3-319-11310-4_63
   Escalera S, 2013, ICMI13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP445, DOI 10.1145/2522848.2532595
   Filhol M, 2016, UNIVERSAL ACCESS INF, V15, P487, DOI 10.1007/s10209-015-0413-4
   Gkigkelos Nikolaos, 2017, P 21 PAN HELL C INF, V0, P1
   Guesmi F, 2016, IEEE SYS MAN CYBERN, V0, PP3561, DOI 10.1109/SMC.2016.7844785
   Hamed A, 2016, INT CONF ADV COMPU, V0, PP451, DOI 10.1109/IACC.2016.90
   Hassan M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), V0, PP852, DOI 10.1109/CSCI.2016.164
   Hirafuji Neiva Davi, 2018, EXPERT SYSTEMS WITH APPLICATIONS, V103, P159, DOI 10.1016/j.eswa.2018.01.051
   Kadous MohammedWaleed, 2002, THESIS U NEW S WAL, V0, P0
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Luqman H, 2019, UNIVERSAL ACCESS INF, V18, P939, DOI 10.1007/s10209-018-0622-8
   Mohammadzaheri Morteza, 2007, 2007 INFORMATION, V0, P272, DOI 10.1109/IDC.2007.374562
   Mohandes M, 2005, ISSPA 2005: THE 8TH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, Vols 1 and 2, Proceedings
   Mohandes M, 2014, PROC IEEE INT SYMP, V0, PP960, DOI 10.1109/ISIE.2014.6864742
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Mohandes M, 2012, COMPUT ELECTR ENG, V38, P422, DOI 10.1016/j.compeleceng.2011.10.013
   Mohandes M, 2004, PROCEEDINGS. 2004 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES: FROM THEORY TO APPLICATIONS (IEEE CAT. NO.04EX852), V0, PP479, DOI 10.1109/ICTTA.2004.1307840
   Mohandes M, 2001, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, V0, P0
   Mohandes M, 2013, 2013 COMPUTING, V0, P90, DOI 10.1109/ComComAp.2013.6533615
   Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), V0, P0, DOI DOI 10.1109/ICCVW.2011.6130290
   SamirElons A, 2013, IET IMAGE PROCESS, V7, P829, DOI 10.1049/iet-ipr.2012.0222
   Shanableh T, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS
   Shanableh T, 2007, IEEE T SYST MAN CY B, V37, P641, DOI 10.1109/TSMCB.2006.889630
   Shohieb SM, 2015, J KING SAUD UNIV-COM, V27, P68, DOI 10.1016/j.jksuci.2014.03.011
   Sidig AAI, 2018, INT J ADV COMPUT SC, V9, P283
   Sidig Ala addin I, 2018, ARABIC SIGN LANGUAGE, V0, P297
   Soodtoetong N, 2018, 2018 15TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, V0, P0
   Sun C, 2013, IEEE T CYBERNETICS, V43, P1418, DOI 10.1109/TCYB.2013.2265337
   Tolba MF, 2013, NEURAL COMPUT APPL, V23, P999, DOI 10.1007/s00521-012-1024-0
   Tolba MF, 2012, P 8 INT C INF SYST I, V0, P0
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Von Agris U, 2007, P GEST HUM COMP INT, V0, P0
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zahedi M, 2006, LREC WORKSH REPR PRO, V0, P21
   Zahedi Morteza, 2005, INT GESTURE WORKSHOP, V0, P68
   Zaki MM, 2011, PATTERN RECOGN LETT, V32, P572, DOI 10.1016/j.patrec.2010.11.013
NR 63
TC 15
Z9 15
U1 0
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR 15
PY 2021
VL 20
IS 1
BP 
EP 
DI 10.1145/3423420
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RO2RN
UT WOS:000640893600018
DA 2023-11-10
ER

PT J
AU Niu, YL
   Zhang, HW
   Lu, ZW
   Chang, SF
AF Niu, Yulei
   Zhang, Hanwang
   Lu, Zhiwu
   Chang, Shih-Fu
TI Variational Context: Exploiting Visual and Textual Context for Grounding Referring Expressions
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Grounding referring expression; variational Bayesian model; referring expression generation
AB We focus on grounding (i.e., localizing or linking) referring expressions in images, e.g., "largest elephant standing behind baby elephant". This is a general yet challenging vision-language task since it does not only require the localization of objects, but also the multimodal comprehension of context - visual attributes (e.g., "largest", "baby") and relationships (e.g., "behind") that help to distinguish the referent from other objects, especially those of the same category. Due to the exponential complexity involved in modeling the context associated with multiple image regions, existing work oversimplifies this task to pairwise region modeling by multiple instance learning. In this paper, we propose a variational Bayesian method, called Variational Context, to solve the problem of complex context modeling in referring expression grounding. Specifically, our framework exploits the reciprocal relation between the referent and context, i.e., either of them influences estimation of the posterior distribution of the other, and thereby the search space of context can be greatly reduced. In addition to reciprocity, our framework considers the semantic information of context, i.e., the referring expression can be reproduced based on the estimated context. We also extend the model to unsupervised setting where no annotation for the referent is available. Extensive experiments on various benchmarks show consistent improvement over state-of-the-art methods in both supervised and unsupervised settings.
C1 [Niu, Yulei; Lu, Zhiwu] Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
   [Niu, Yulei; Lu, Zhiwu] Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing 100872, Peoples R China.
   [Zhang, Hanwang] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Chang, Shih-Fu] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
C3 Renmin University of China; Renmin University of China; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Columbia University
RP Niu, YL (通讯作者)，Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.; Niu, YL (通讯作者)，Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing 100872, Peoples R China.
EM niu@ruc.edu.cn; hanwangzhang@gmail.com; zhiwu.lu@gmail.com; sfchang@ee.columbia.edu
FU National Natural Science Foundation of China [61573363, 61832017]
CR [Anonymous], 2017, PROC 1 WORKSHOP LANG, V0, P0
   [Anonymous], 2001, UNCERTAINTY ARTIFICI, V0, P0, DOI DOI 10.48550/ARXIV.1301.2315
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, ARXIV, V0, P0
   Chen Xinpeng, 2018, ARXIV181203426, V0, P0
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Dai B, 2017, PROC CVPR IEEE, V0, PP3298, DOI 10.1109/CVPR.2017.352
   Das A, 2017, IEEE I CONF COMP VIS, V0, PP2970, DOI 10.1109/ICCV.2017.321
   Deng CR, 2018, PROC CVPR IEEE, V0, PP7746, DOI 10.1109/CVPR.2018.00808
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Fox CW, 2012, ARTIF INTELL REV, V38, P85, DOI 10.1007/s10462-011-9236-8
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   Golland D, 2010, P 2010 C EMP METH NA, V0, P410
   He K, 2016, LECT NOTES COMPUT SC, V0, PP70, DOI 10.1007/978-3-319-46493-0_38
   Hu RH, 2017, IEEE I CONF COMP VIS, V0, PP804, DOI 10.1109/ICCV.2017.93
   Hu RH, 2017, PROC CVPR IEEE, V0, PP4418, DOI 10.1109/CVPR.2017.470
   Hu RH, 2016, PROC CVPR IEEE, V0, PP4555, DOI 10.1109/CVPR.2016.493
   Joseph RK, 2016, CRIT POL ECON S ASIA, V0, P1
   Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, V0, PP787, DOI 10.3115/V1/D14-1086
   Kingma DP, 2013, AUTOENCODING VARIATI, V0, P0
   Krahmer E, 2012, COMPUT LINGUIST, V38, P173, DOI 10.1162/COLI_a_00088
   Li YK, 2018, PROC CVPR IEEE, V0, PP6116, DOI 10.1109/CVPR.2018.00640
   Li YK, 2017, PROC CVPR IEEE, V0, PP7244, DOI 10.1109/CVPR.2017.766
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JY, 2017, IEEE I CONF COMP VIS, V0, PP4866, DOI 10.1109/ICCV.2017.520
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JH, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING TECHNOLOGY (CSET2015), V0, P289
   Luo RT, 2017, PROC CVPR IEEE, V0, PP3125, DOI 10.1109/CVPR.2017.333
   Makhzani Alireza, 2015, ARXIV151105644, V0, P0
   Mao JH, 2016, PROC CVPR IEEE, V0, PP11, DOI 10.1109/CVPR.2016.9
   Mitchell M, 2010, P 6 INT NAT LANG GEN, V0, P95
   Mitchell M, 2013, P NAAC HLT 2013, V0, P1174
   Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Plummer BA, 2017, IEEE I CONF COMP VIS, V0, PP1946, DOI 10.1109/ICCV.2017.213
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Schuster Sebastian, 2015, P 4 WORKSH VIS LANG, V0, P0
   Sohn K, 2015, ADV NEURAL INFORM PR, V0, PP3483, DOI 10.5555/2969442.2969628
   Sun QR, 2017, PROC CVPR IEEE, V0, PP435, DOI 10.1109/CVPR.2017.54
   Thomas JA, 2014, MEANING INTERACTION, V0, P0
   van Deemter K, 2006, INLG, V0, P130
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   WINOGRAD T, 1972, COGNITIVE PSYCHOL, V3, P1, DOI 10.1016/0010-0285(72)90002-3
   Xiao FY, 2017, PROC CVPR IEEE, V0, PP5253, DOI 10.1109/CVPR.2017.558
   Xu X, 2015, IEEE ICC, V0, PP2048, DOI 10.1109/ICC.2015.7248627
   Xue J, 2016, SYM REL DIST SYST, V0, PP91, DOI 10.1109/SRDS.2016.19
   Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47
   Yu LC, 2018, PROC CVPR IEEE, V0, PP1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2017, PROC CVPR IEEE, V0, PP3521, DOI 10.1109/CVPR.2017.375
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Yunchao Wei, 2017, 2017 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP6488, DOI 10.1109/CVPR.2017.687
   Zhang HW, 2018, PROC CVPR IEEE, V0, PP4158, DOI 10.1109/CVPR.2018.00437
   Zhang HW, 2017, IEEE I CONF COMP VIS, V0, PP4243, DOI 10.1109/ICCV.2017.454
   Zhang Hanwang, 2017, CVPR, V0, P0, DOI DOI 10.48550/ARXIV.1702.08319
   Zhao Z, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3518
   Zhuang BH, 2018, PROC CVPR IEEE, V0, PP4252, DOI 10.1109/CVPR.2018.00447
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 62
TC 6
Z9 6
U1 0
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JAN 1
PY 2021
VL 43
IS 1
BP 347
EP 359
DI 10.1109/TPAMI.2019.2926266
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA PC7WN
UT WOS:000597206900023
PM 31283493
DA 2023-11-10
ER

PT J
AU Adelani, DI
   Abbott, J
   Neubig, G
   D'souza, D
   Kreutzer, J
   Lignos, C
   Palen-Michel, C
   Buzaaba, H
   Rijhwani, S
   Ruder, S
   Mayhew, S
   Azime, IA
   Muhammad, SH
   Emezue, CC
   Nakatumba-Nabende, J
   Ogayo, P
   Anuoluwapo, A
   Gitau, C
   Mbaye, D
   Alabi, J
   Yimam, SM
   Gwadabe, TR
   Ezeani, I
   Niyongabo, RA
   Mukiibi, J
   Otiende, V
   Orife, I
   David, D
   Ngom, S
   Adewumi, T
   Rayson, P
   Adeyemi, M
   Muriuki, G
   Anebi, E
   Chukwuneke, C
   Odu, N
   Wairagala, EP
   Oyerinde, S
   Siro, C
   Bateesa, TS
   Oloyede, T
   Wambui, Y
   Akinode, V
   Nabagereka, D
   Katusiime, M
   Awokoya, A
   Mboup, M
   Gebreyohannes, D
   Tilaye, H
   Nwaike, K
   Wolde, D
   Faye, A
   Sibanda, B
   Ahia, O
   Dossou, BFP
   Ogueji, K
   Diop, TI
   Diallo, A
   Akinfaderin, A
   Marengereke, T
   Osei, S
AF Adelani, David Ifeoluwa
   Abbott, Jade
   Neubig, Graham
   D'souza, Daniel
   Kreutzer, Julia
   Lignos, Constantine
   Palen-Michel, Chester
   Buzaaba, Happy
   Rijhwani, Shruti
   Ruder, Sebastian
   Mayhew, Stephen
   Azime, Israel Abebe
   Muhammad, Shamsuddeen H.
   Emezue, Chris Chinenye
   Nakatumba-Nabende, Joyce
   Ogayo, Perez
   Anuoluwapo, Aremu
   Gitau, Catherine
   Mbaye, Derguene
   Alabi, Jesujoba
   Yimam, Seid Muhie
   Gwadabe, Tajuddeen Rabiu
   Ezeani, Ignatius
   Niyongabo, Rubungo Andre
   Mukiibi, Jonathan
   Otiende, Verrah
   Orife, Iroro
   David, Davis
   Ngom, Samba
   Adewumi, Tosin
   Rayson, Paul
   Adeyemi, Mofetoluwa
   Muriuki, Gerald
   Anebi, Emmanuel
   Chukwuneke, Chiamaka
   Odu, Nkiruka
   Wairagala, Eric Peter
   Oyerinde, Samuel
   Siro, Clemencia
   Bateesa, Tobius Saul
   Oloyede, Temilola
   Wambui, Yvonne
   Akinode, Victor
   Nabagereka, Deborah
   Katusiime, Maurice
   Awokoya, Ayodele
   Mboup, Mouhamadane
   Gebreyohannes, Dibora
   Tilaye, Henok
   Nwaike, Kelechi
   Wolde, Degaga
   Faye, Abdoulaye
   Sibanda, Blessing
   Ahia, Orevaoghene
   Dossou, Bonaventure F. P.
   Ogueji, Kelechi
   Diop, Thierno Ibrahima
   Diallo, Abdoulaye
   Akinfaderin, Adewale
   Marengereke, Tendai
   Osei, Salomey
TI MasakhaNER: Named Entity Recognition for African Languages
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We take a step towards addressing the under-representation of the African continent in NLP research by bringing together different stakeholders to create the first large, publicly available, high-quality dataset for named entity recognition (NER) in ten African languages. Wedetail the characteristics of these languages to help researchers and practitioners better understand the challenges they pose for NER tasks. We analyze our datasets and conduct an extensive empirical evaluation of stateof-the-art methods across both supervised and transfer learning settings. Finally, we release the data, code, and models to inspire future research on African NLP.(1)
C1 [Adelani, David Ifeoluwa; Abbott, Jade; D'souza, Daniel; Kreutzer, Julia; Lignos, Constantine; Palen-Michel, Chester; Buzaaba, Happy; Azime, Israel Abebe; Muhammad, Shamsuddeen H.; Emezue, Chris Chinenye; Nakatumba-Nabende, Joyce; Ogayo, Perez; Anuoluwapo, Aremu; Gitau, Catherine; Mbaye, Derguene; Alabi, Jesujoba; Gwadabe, Tajuddeen Rabiu; Ezeani, Ignatius; Niyongabo, Rubungo Andre; Otiende, Verrah; Orife, Iroro; David, Davis; Ngom, Samba; Adewumi, Tosin; Adeyemi, Mofetoluwa; Anebi, Emmanuel; Oyerinde, Samuel; Siro, Clemencia; Oloyede, Temilola; Wambui, Yvonne; Akinode, Victor; Awokoya, Ayodele; Mboup, Mouhamadane; Gebreyohannes, Dibora; Tilaye, Henok; Nwaike, Kelechi; Wolde, Degaga; Faye, Abdoulaye; Sibanda, Blessing; Ahia, Orevaoghene; Dossou, Bonaventure F. P.; Ogueji, Kelechi; Diop, Thierno Ibrahima; Diallo, Abdoulaye; Akinfaderin, Adewale; Marengereke, Tendai; Osei, Salomey] Masakhane NLP, Newark, NJ 07102 USA.
   [Adelani, David Ifeoluwa] Saarland Univ, Spoken Language Syst Grp LSV, Saarbrucken, Germany.
   [Abbott, Jade] Retro Rabbit, Pretoria, South Africa.
   [Neubig, Graham; Rijhwani, Shruti] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
   [D'souza, Daniel] ProQuest, Morrisville, NC USA.
   [Kreutzer, Julia] Google Res, Toronto, ON, Canada.
   [Lignos, Constantine; Palen-Michel, Chester] Brandeis Univ, Waltham, MA 02254 USA.
   [Ruder, Sebastian] DeepMind, London, England.
   [Mayhew, Stephen] Duolingo, Pittsburgh, PA USA.
   [Buzaaba, Happy] Univ Tsukuba, Grad Sch Syst & Informat Engn, Tsukuba, Ibaraki, Japan.
   [Azime, Israel Abebe; Osei, Salomey] African Inst Math Sci Aims AMMI, Addis Ababa, Ethiopia.
   [Muhammad, Shamsuddeen H.] Univ Porto, Port Harcourt, Nigeria.
   [Muhammad, Shamsuddeen H.] Bayero Univ, Kano, Nigeria.
   [Emezue, Chris Chinenye] Tech Univ Munich, Munich, Germany.
   [Nakatumba-Nabende, Joyce; Mukiibi, Jonathan; Muriuki, Gerald; Wairagala, Eric Peter; Bateesa, Tobius Saul; Nabagereka, Deborah; Katusiime, Maurice] Makerere Univ, Kampala, Uganda.
   [Ogayo, Perez] African Leadership Univ, Kigali, Rwanda.
   [Anuoluwapo, Aremu] Univ Lagos, Lagos, Nigeria.
   [Alabi, Jesujoba] Max Planck Inst Informat, Saarbrucken, Germany.
   [Yimam, Seid Muhie] Univ Hamburg, LT Grp, Hamburg, Germany.
   [Gwadabe, Tajuddeen Rabiu] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Ezeani, Ignatius; Rayson, Paul; Chukwuneke, Chiamaka] Univ Lancaster, Lancaster, England.
   [Niyongabo, Rubungo Andre] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Otiende, Verrah] US Int Univ Africa USIU A, Nairobi, Kenya.
   [Orife, Iroro] Niger Volta LTI, Naija, Germany.
   [Adewumi, Tosin] Luleo Univ Technol, Lulea, Sweden.
   [Odu, Nkiruka] African Univ Sci & Technol, Abuja, Nigeria.
   [Awokoya, Ayodele] Univ Ibadan, Ibadan, Nigeria.
   [Sibanda, Blessing] Namibia Univ Sci & Technol, Windhoek, Namibia.
   [Ahia, Orevaoghene] Instadeep, Lagos, Nigeria.
   [Dossou, Bonaventure F. P.] Jacobs Univ Bremen, Bremen, Germany.
   [Ogueji, Kelechi] Univ Waterloo, Waterloo, ON, Canada.
C3 Saarland University; Carnegie Mellon University; Brandeis University; University of Tsukuba; Bayero University; Technical University of Munich; Makerere University; University of Lagos; Max Planck Society; University of Hamburg; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Lancaster University; University of Electronic Science & Technology of China; African University of Science & Technology; University of Ibadan; Namibia University of Science & Technology; Jacobs University; University of Waterloo
RP Adelani, DI (通讯作者)，Masakhane NLP, Newark, NJ 07102 USA.; Adelani, DI (通讯作者)，Saarland Univ, Spoken Language Syst Grp LSV, Saarbrucken, Germany.
FU EU [3081705]
CR Adelani D, 2021, ABS210308647 ARXIV, V0, P0
   Agic E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3204
   Alabi JO, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P2754
   Benikova D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2524
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Caines Andrew, 2019, GEOGRAPHIC DIVERSITY, V0, P0
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/tacl_a_00104
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   De Pauw Guy, 2007, P 1 INT COMP SCI ICT, V0, P8
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Eberhard David M, 2020, ETHNOLOGUE LANGUAGES, V0, P0
   Eiselen R, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3344
   El-Kishky A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5960
   Emenanjo Nolue, 1978, ELEMENTS MODERN IGBO, V0, P0
   Ezeani Ignatius, 2020, ABS200400648 ARXIV, V0, P0, DOI DOI 10.1037/H0031619
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Fu J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6058
   Gururangan Suchin, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Hedderich MA, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2580
   Howard Jeremy, 2018, P ACL 2018, V0, P0
   Hu Junjie, 2020, P ICML, V0, P0
   Huang Z, 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Ijite Blessing Onovbiona, 2012, SER VERB CONSTR NIG, V0, P0
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lample Guillaume, 2016, P NAACL HLT 2016, V0, P0
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4483
   Lin Y, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P1
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Martinus Laura, 2019, ARXIV190605685, V0, P0
   MBS, 2020, TEER INJ BIBL WOL AN, V0, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Nekoto Wilhelmina, 2020, FINDINGS ASS COMPUTA, V0, P0
   Neubig Graham, 2017, ABS170103980 ARXIV, V0, P0
   Niyongabo Rubungo Andre, 2020, P 28 INT C COMP LING, V0, P5507
   Offiong Mensah Eyo, 2012, ÍKALA, V17, P167
   Ojarikre Anthony, 2013, PERSPECTIVES, V3, P0
   Onyenwe IE, 2016, LECT NOTES ARTIF INT, V9924, P206, DOI 10.1007/978-3-319-45510-5_24
   Pan XM, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1946, DOI 10.18653/v1/P17-1178
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pfeiffer Jonas, 2020, ARXIV201215562, V0, P0
   Pfeiffer Jonas, 2020, P EMNLP 2020, V0, P0
   Ratinov L, 2009, P 13 C COMPUTATIONAL, V0, P0, DOI DOI 10.3115/1596374.1596399
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Rijhwani S, 2020, PROC 58 ANN M ASS CO, V0, P8118
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Sangal Rajeev, 2008, P IJCNLP 08 WORKSH N, V0, P0
   Shaalan K, 2014, COMPUT LINGUIST, V40, P469, DOI 10.1162/coli_a_00178
   Strassel S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3273
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Tjong Kim Sang EF, 2002, COLING 02, V0, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yadav V, 2018, P 27 INT C COMP LING, V0, P2145
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
NR 54
TC 20
Z9 20
U1 4
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 1116
EP 1131
DI 10.1162/tacl_a_00416
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200066
DA 2023-11-10
ER

PT J
AU Qiang, JP
   Wu, XD
AF Qiang, Jipeng
   Wu, Xindong
TI Unsupervised Statistical Text Simplification
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Encyclopedias; Electronic publishing; Internet; Benchmark testing; Standards; Mathematical model; Text simplification; machine translation; unsupervised
AB Most recent approaches for Text Simplification (TS) have drawn on insights from machine translation to learn simplification rewrites from the monolingual parallel corpus of complex and simple sentences, yet their effectiveness strongly relies on large amounts of parallel sentences. However, there has been a serious problem haunting TS for decades, that is, the availability of parallel TS corpora is scarce or not fit for the learning task. In this paper, we will focus on one especially useful and challenging problem of unsupervised TS without a single parallel sentence. To the best of our knowledge, we present the first unsupervised text simplification system based on phrase-based machine translation system, which leverages a careful initialization of phrase tables and language models. On the widely used WikiLarge and WikiSmall benchmarks, our system respectively obtains 39.08 and 25.12 SARI points, even outperforms some supervised baselines.
C1 [Qiang, Jipeng] Yangzhou Univ, Dept Comp Sci, Yangzhou 225127, Jiangsu, Peoples R China.
   [Wu, Xindong] Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 10084, Anhui, Peoples R China.
   [Wu, Xindong] Mininglamp Acad Sci, Minininglamp, Beijing 100084, Peoples R China.
C3 Yangzhou University; Hefei University of Technology
RP Qiang, JP (通讯作者)，Yangzhou Univ, Dept Comp Sci, Yangzhou 225127, Jiangsu, Peoples R China.
EM jpqiang@yzu.edu.cn; xwu@hfut.edu.cn
FU National Key Research and Development Program of China [2016YFB1000900]; National Natural Science Foundation of China [61703362, 91746209]; Program for Changjiang Scholars and Innovative Research Team in University (PCSIRT) of the Ministry of Education, China [IRT17R32]; Natural Science Foundation of Jiangsu Province of China [BK20170513]
CR Artetxe M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3632
   Bahdanau D, 2016, ARXIV, V0, P0
   Cho, 2018, P INT C LEARN REPR, V0, P73
   Coster W, 2011, P 49 ANN M ASS COMP, V2, P665
   Heafield K, 2011, P 6 WORKSH STAT MACH, V0, P187
   Hwang W, 2015, P 2015 C N AM CHAPTE, V0, PP211, DOI 10.3115/v1/n15-1022
   Kincaid JP, 1975, 875 NAV AIR STAT MEM, V0, P0
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5039
   Narayan S, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P435
   Nisioi S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P85, DOI 10.18653/v1/P17-2014
   Paetzold GH, 2016, AAAI CONF ARTIF INTE, V0, P3761
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Saggion H, 2017, SYNTH LECT HUM LANG, V10, P1, DOI 10.1007/978-3-031-02166-4
   Stajner S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P823
   Sulem E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P162
   Wang T, 2016, AAAI CONF ARTIF INTE, V0, P4270
   Woodsend K, 2011, P 2011 C EMPIRICAL M, V0, P409
   Wubben S, 2012, P 50 ANN M ASS COMPU, V0, P1015
   Xu W, 2016, T ASSOC COMPUT LING, V4, P401, DOI 10.1162/TACL_A_00107
   Xu W, 2015, T ASSOC COMPUT LING, V3, P283, DOI 10.1162/tacl_a_00139
   Yatskar M, 2010, HUMAN LANGUAGE TECHN, V0, P365
   Zhang X, 2017, P 2017 C EMP METH NA, V0, P584
   Zhu Z, 2010, P 23 INT C COMP LING, V0, P1353
NR 24
TC 5
Z9 6
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD APR 1
PY 2021
VL 33
IS 4
BP 1802
EP 1806
DI 10.1109/TKDE.2019.2947679
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA QT5HG
UT WOS:000626617900030
DA 2023-11-10
ER

PT J
AU Kumar, Y
   Singh, N
   Kumar, M
   Singh, A
AF Kumar, Yogesh
   Singh, Navdeep
   Kumar, Munish
   Singh, Amitoj
TI AutoSSR: an efficient approach for automatic spontaneous speech recognition model for the Punjabi Language
SO SOFT COMPUTING
LA English
DT Article
DE Gaussian mixtures; MFCC; Recognition accuracy; Spontaneous speech; Acoustic model
ID system
AB In this article, the authors have presented the design and development of automatic spontaneous speech recognition of the Punjabi language. To dimensions up to the natural speech recognizer, the very large vocabulary Punjabi text corpus has been taken from a Punjabi interview's speech corpus, presentations, etc. Afterward, the Punjabi text corpus has been cleaned by using the proposed corpus optimization algorithm. The proposed automatic spontaneous speech model has been trained with 13,218 of Punjabi words and more than 200 min of recorded speech. The research work also confirmed that the 2,073,456 unique in-word Punjabi tri-phoneme combinations present in the dictionary comprise of 131 phonemes. The performance of the proposed model has grown increasingly to 87.10% sentence-level accuracy for 2381 Punjabi trained sentences and word-level accuracy of 94.19% for 13,218 Punjabi words. Simultaneously, the word error rate has been reduced to 5.8% for 13,218 Punjabi words. The performance of the proposed system has also been tested by using other parameters such as overall likelihood per frame and convergence ratio on various iterations for different Gaussian mixtures.
C1 [Kumar, Yogesh] Chandigarh Grp Coll, Dept Comp Sci & Engn, Mohali, Punjab, India.
   [Singh, Navdeep] Mata Gujri Coll, Dept Comp Sci, Fatehgarh Sahib, Punjab, India.
   [Kumar, Munish; Singh, Amitoj] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
RP Kumar, M (通讯作者)，Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM yogesh.arora10744@gmail.com; navdeep_jaggi@yahoo.com; munishcse@gmail.com; amitoj.ptu@gmail.com
CR Abushariah A, 2010, COMPUT COMMUN ENG, V0, P1423
   Akita Y, 2010, IEEE T AUDIO SPEECH, V18, P1539, DOI 10.1109/TASL.2009.2037400
   Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Ali H, 2015, INT J COMPUTER APPL, V118, P1
   Ali H, 2015, INT J COMPUT APPL, V5, P118
   Beke A, 2012, 3RD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM 2012), V0, P65
   Braathen B, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, V0, P360, DOI 10.1109/AFGR.2002.1004180
   Choudhary A, 2013, ASS COMPUTER ELECT E, V0, P847
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Digalakis V, 2003, LARGE VOCABULARY CON, V0, P1
   Fohr D, 2017, IEEE INT C INFORM SY, V7, P870
   Furui S, 2003, P EUR, V0, P1993
   Ganesh A, 2013, INT C SIGNAL PROCESS, V29, P56
   GHAI W, 2013, INT J COMPUTER APPL, V72, P23, DOI 10.5120/12563-9002
   Ghai W, 2012, INT J SOFT COMPUT EN, V2, P379
   HENDY NA, 2013, WORLD ACAD SCI ENG T, V7, P1149
   Hernández-Mena Carlos Daniel, 2017, J. APPL. RES. TECHNOL, V15, P259, DOI 10.1016/j.jart.2017.02.001
   Hoesen D, 2016, PROCEDIA COMPUT SCI, V81, P167, DOI 10.1016/j.procs.2016.04.045
   Hofmann H, 2010, 2010 PROCEEDINGS OF 4TH INTERNATIONAL UNIVERSAL COMMUNICATION SYMPOSIUM (IUCS 2010), V0, PP58, DOI 10.1109/IUCS.2010.5666767
   Izzad M, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, V0, P219, DOI 10.1109/ComManTel.2013.6482394
   Kalaivani EC, 2013, STUDY SPEAKER RECOGN, V2, P963
   Karpov A, 2014, SPEECH COMMUN, V56, P213, DOI 10.1016/j.specom.2013.07.004
   Kaur A, 2014, INT J SOFT COMPUT EN, V1, P150
   Kumar A, 2014, INT J COMPUT APPL, V2014, P163
   Kumar Y, 2016, IJ ED MANAG ENG, V6, P64, DOI 10.5815/ijeme.2016.06.07
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Maekawa K, 2000, LREC, V6, P1
   Menacer MA, 2017, PROCEDIA COMPUT SCI, V117, P81, DOI 10.1016/j.procs.2017.10.096
   Moneykumar M, 2015, P 12 INT C NAT LANG, V0, P0
   Nakamura M, 2007, INT CONF ACOUST SPEE, V0, P473
   Nimbargi S, 2015, INT J COMBINED RES D, V4, P0
   Patil UG, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, V0, P433, DOI 10.1109/CAST.2016.7915008
   Rahul L, 2013, P 4 NAT C COMP VIS P, V0, P1
   Saini P, 2013, INT J ENG TRENDS TEC, V4, P132
   Sajjan SC, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, V0, P451, DOI 10.1109/WiSPNET.2016.7566174
   Sarfraz H, 2010, P 8 INT C FRONT INF, V0, P0
   Sarma H, 2014, ADV INTELLIGENT SYST, V264, P0
   Sarma H, 2017, ACM T ASIAN LOW-RESO, V17, P0, DOI 10.1145/3137055
   Singh LG, 2016, INT J ADV RES COMPUT, V8, P349
   Stouten F, 2006, SPEECH COMMUN, V48, P1590, DOI 10.1016/j.specom.2006.04.004
   Tailor JH, 2016, INT J COMPUTER APPL, V138, P28, DOI 10.5120/IJCA2016909049
   Takaaki H, 2003, EUROSPEECH, V0, P2817
   Vijayendra AD, 2016, PROCEDIA COMPUT SCI, V93, P668, DOI 10.1016/j.procs.2016.07.259
   Vimala C, 2012, PROCEDIA ENGINEER, V30, P1097, DOI 10.1016/j.proeng.2012.01.968
   Weninger F, 2011, INT CONF ACOUST SPEE, V0, P5840
   Yu C, 2019, SYMMETRY, V11, P1
   Zarrouk E, 2015, PROCEDIA COMPUT SCI, V60, P508, DOI 10.1016/j.procs.2015.08.259
NR 47
TC 8
Z9 8
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD JAN 15
PY 2021
VL 25
IS 2
BP 1617
EP 1630
DI 10.1007/s00500-020-05248-1
EA AUG 2020
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA QC6GS
UT WOS:000558898900005
DA 2023-11-10
ER

PT J
AU Goyal, S
   Chattopadhyay, C
   Bhatnagar, G
AF Goyal, Shreya
   Chattopadhyay, Chiranjoy
   Bhatnagar, Gaurav
TI Knowledge-driven description synthesis for floor plan interpretation
SO INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION
LA English
DT Article
DE Floor plan; Captioning; Evaluation; Language modeling
AB Image captioning is a widely known problem in the area of AI. Caption generation from floor plan images has applications in indoor path planning, real estate, and providing architectural solutions. Several methods have been explored in the literature for generating captions or semi-structured descriptions from floor plan images. Since only the caption is insufficient to capture fine-grained details, researchers also proposed descriptive paragraphs from images. However, these descriptions have a rigid structure and lack flexibility, making it difficult to use them in real-time scenarios. This paper offers two models, description synthesis from image cue (DSIC) and transformer-based description generation (TBDG), for text generation from floor plan images. These two models take advantage of modern deep neural networks for visual feature extraction and text generation. The difference between both models is in the way they take input from the floor plan image. The DSIC model takes only visual features automatically extracted by a deep neural network, while the TBDG model learns textual captions extracted from input floor plan images with paragraphs. The specific keywords generated in TBDG and understanding them with paragraphs make it more robust in a general floor plan image. Experiments were carried out on a large-scale publicly available dataset and compared with state-of-the-art techniques to show the proposed model's superiority.
C1 [Goyal, Shreya; Chattopadhyay, Chiranjoy; Bhatnagar, Gaurav] Indian Inst Technol, Jodhpur 342037, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Jodhpur
RP Chattopadhyay, C (通讯作者)，Indian Inst Technol, Jodhpur 342037, Rajasthan, India.
EM chiranjoy@iitj.ac.in
FU Science and Engineering Research Board [ECR/2016/000953]
CR Adam S, 2000, INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION, V3, P89, DOI 10.1007/s100320000033
   Bahdanau D, 2016, ARXIV, V0, P0
   Barducci A, 2012, INT C PATT RECOG, V0, P298
   Bhatnagar, 2018, MAHCI, V0, P0
   Bhatnagar, 2019, ICDAR, V0, P0
   Chatterjee M, 2018, LECT NOTES COMPUT SC, V11206, P747, DOI 10.1007/978-3-030-01216-8_45
   Chen Xinlei, 2015, ARXIV150400325, V0, P0
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   de las Heras LP, 2015, INT J DOC ANAL RECOG, V18, P15, DOI 10.1007/s10032-014-0236-5
   Delalandre M, 2010, INT J DOC ANAL RECOG, V13, P187, DOI 10.1007/s10032-010-0120-x
   Dutta A, 2013, PATTERN RECOGN, V46, P752, DOI 10.1016/j.patcog.2012.10.003
   Dutta A, 2011, PROC INT CONF DOC, V0, PP982, DOI 10.1109/ICDAR.2011.199
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Goyal S, 2019, IET IMAGE PROCESS, V13, P2623, DOI 10.1049/iet-ipr.2018.5627
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/ICCV.2017.322
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI arXiv:1406.4729
   Hihn J, 2016, AEROSP CONF PROC, V0, P0
   Jiang, 2017, ICDAR, V0, P0
   Joseph RK, 2016, CRIT POL ECON S ASIA, V0, P1
   Khan I, 2020, MULTIMED TOOLS APPL, V79, P8695, DOI 10.1007/s11042-018-6289-6
   Krause J, 2017, PROC CVPR IEEE, V0, PP3337, DOI 10.1109/CVPR.2017.356
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li S, 2011, P C COMP NAT LANG LE, V0, P220
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2017, AAAI CONF ARTIF INTE, V0, P1445
   Luong Minh-Thang, 2015, ARXIV151106114, V0, P0
   Madugalla A, 2020, ACM T ACCESS COMPUT, V13, P0, DOI 10.1145/3410446
   Mao YZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4258
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   Marinai, 2018, IAPR WORKSH ART NEUR, V0, P0
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Park CC, 2015, ADV NEUR IN, V28, P0
   Qureshi RJ, 2008, LECT NOTES COMPUT SC, V5046, P91, DOI 10.1007/978-3-540-88188-9_10
   Redmon J, 2016, YOU ONLY LOOK ONCE U, V0, P0, DOI DOI 10.1109/CVPR.2016.91
   Redmon Joseph, 2018, ARXIV180402767CSCV, V0, P0
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rezvanifar A, 2020, IEEE COMPUT SOC CONF, V0, PP2419, DOI 10.1109/CVPRW50498.2020.00292
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Sabour S, 2017, ADV NEUR IN, V30, P0
   Saha Ranajit, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP51, DOI 10.1109/ICDAR.2019.00018
   Schreiber S, 2017, PROC INT CONF DOC, V0, PP1162, DOI 10.1109/ICDAR.2017.192
   Sharma D, 2017, PROC INT CONF DOC, V0, PP420, DOI 10.1109/ICDAR.2017.76
   Sharma N, 2018, INT CONF FRONT HAND, V0, PP416, DOI 10.1109/ICFHR-2018.2018.00079
   Su H, 2020, PATTERN RECOGN, V97, P0, DOI 10.1016/j.patcog.2019.107003
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Viola P, 2001, PROC CVPR IEEE, V0, PP511, DOI 10.1109/cvpr.2001.990517
   Wang Q, 2018, ARXIV180509019, V0, P0
   Wang ZW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP672, DOI 10.1145/3240508.3240583
   Yao T, 2017, IEEE I CONF COMP VIS, V0, PP4904, DOI 10.1109/ICCV.2017.524
NR 53
TC 3
Z9 3
U1 2
U2 9
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1433-2833
EI 1433-2825
J9 INT J DOC ANAL RECOG
JI Int. J. Doc. Anal. Recognit.
PD JUN 15
PY 2021
VL 24
IS 1-2
BP 19
EP 32
DI 10.1007/s10032-021-00367-3
EA APR 2021
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SO2BR
UT WOS:000644294300001
DA 2023-11-10
ER

PT J
AU Liu, WG
   Tang, JH
   Liang, XD
   Cai, QL
AF Liu, Wenge
   Tang, Jianheng
   Liang, Xiaodan
   Cai, Qingling
TI Heterogeneous graph reasoning for knowledge-grounded medical dialogue system
SO NEUROCOMPUTING
LA English
DT Article
DE Deep learning; Dialogue system; Graph reasoning
AB Beyond the common difficulties faced in task-oriented dialogue system, medical dialogue has recently attracted increasing attention due to its huge application potential while posing more challenges in reasoning over medical domain knowledge and logic. Existing works resort to neural language models for dialogue embedding and neglect the explicit logical reasoning, leading to poor explainable and generalization ability. In this work, we propose an explainable Heterogeneous Graph Reasoning (HGR) model to unify the relational dialogue context understanding and entity-correlation reasoning into a heterogeneous graph structure. HGR encodes entity context according to the corresponding utterance and deduces next response after fusing the underlying medical knowledge with entity context by attentional graph propagation. To push forward the future research on expert-sensitive task-oriented dialogue system, we first release a large-scale Medical Dialogue Consultant benchmark (MDG-C) with 16 Gastrointestinal diseases for evaluating consultant capability and a Medical Dialogue Diagnosis benchmark (MDG-D) with 6 diseases for measuring diagnosis capability of models, respectively. Extensive experiments on both MDG-C and MDG-D benchmarks demonstrate the superiority of our HGR over state-of-the-art knowledge grounded approaches in general fields of medical dialogue system. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Wenge; Tang, Jianheng; Liang, Xiaodan; Cai, Qingling] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University
RP Cai, QL (通讯作者)，Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510006, Peoples R China.
EM caiqingl@mail.sysu.edu.cn
FU National Natural Science Foundation of China [U1811461]; State Key Development Program of China [2018YFC0116904]; Major Science and Technology Planning Project of Guangdong Province of China [810229511112]
CR [Anonymous], 2018, P 2018 C EMP METH NA, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2014, 9 WORKSH STAT MACH T, V0, P0, DOI DOI 10.3115/V1/W14-3346
   Bahdanau D, 2016, ARXIV, V0, P0
   Bordes A, 2017, P 5 INT C LEARN REPR, V0, P0
   [奥德玛 Byambasuren Odmaa], 2019, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V33, P1
   Chen Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5033
   Dhingra B, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P484, DOI 10.18653/v1/P17-1045
   Dinan E, 2021, NEUROCOMPUTING, V442, P260
   Du N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4979
   Du N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P915
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), V0, P1
   Ghazvininejad M, 2018, AAAI CONF ARTIF INTE, V0, P5110
   Hu LM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4821
   Huang M, 2020, P 58 ANN M ASS COMP, V0, P0
   Kao H-C, 2016, P NIPS WORKSH DEEP R, V0, P0
   Kim G, 2020, 8 INT C LEARN REPR I, V0, P0
   Li X, 2017, P 8 INT JOINT C NAT, V1, P733
   Lian RZ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5081
   Liu QL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P201
   Liu SM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1489
   Peng BL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2182
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Shi XM, 2020, AAAI CONF ARTIF INTE, V34, P8838
   Tuan Yi-Lin, 2019, P 2019 EMNLP IJCNLP, V0, P1855
   Velickovic P, 2018, P ICLR, V0, P0
   Wu WQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3794
   Xu L, 2019, AAAI CONF ARTIF INTE, V0, P7346
   Yan Z, 2017, AAAI CONF ARTIF INTE, V0, P4618
   Yu W, 2019, P ADV NEUR INF PROC, V0, P2765
   Zhang H, 2016, IEEE INT SYMP SIGNAL, V0, PP1, DOI 10.1109/ISSPIT.2016.7885999
   Zhang HY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2031
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhou H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4623
NR 36
TC 8
Z9 8
U1 1
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUN 28
PY 2021
VL 442
IS 
BP 260
EP 268
DI 10.1016/j.neucom.2021.02.021
EA MAR 2021
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RW0QF
UT WOS:000646228600003
DA 2023-11-10
ER

PT J
AU Li, ZN
   Li, Q
   Zou, XT
   Ren, JT
AF Li, Zhaoning
   Li, Qi
   Zou, Xiaotian
   Ren, Jiangtao
TI Causality extraction based on self-attentive BiLSTM-CRF with transferred embeddings
SO NEUROCOMPUTING
LA English
DT Article
DE Causality extraction; Sequence labeling; BiLSTM-CRF; Flair embeddings; Self-attention
AB Causality extraction from natural language texts is a challenging open problem in artificial intelligence. Existing methods utilize patterns, constraints, and machine learning techniques to extract causality, heavily depending on domain knowledge and requiring considerable human effort and time for feature engineering. In this paper, we formulate causality extraction as a sequence labeling problem based on a novel causality tagging scheme. On this basis, we propose a neural causality extractor with the BiLSTM-CRF model as the backbone, named SCITE (Self-attentive BiLSTM-CRF wIth Transferred Embeddings), which can directly extract cause and effect without extracting candidate causal pairs and identifying their relations separately. To address the problem of data insufficiency, we transfer contextual string embeddings, also known as Flair embeddings, which are trained on a large corpus in our task. In addition, to improve the performance of causality extraction, we introduce a multihead selfattention mechanism into SCITE to learn the dependencies between causal words. We evaluate our method on a public dataset, and experimental results demonstrate that our method achieves significant and consistent improvement compared to baselines. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Li, Zhaoning; Li, Qi; Zou, Xiaotian; Ren, Jiangtao] Sun Yat Sen Univ, Guangdong Prov Key Lab Computat Sci, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Ren, JT (通讯作者)，Sun Yat Sen Univ, Guangdong Prov Key Lab Computat Sci, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM lizhn7@mail2.sysu.edu.cn; liqi38@mail2.sysu.edu.cn; zouxt5@mail2.sysu.edu.cn; issrjt@mail.sysu.edu.cn
FU National Natural Science Foundation of China [U1711263, U1811462]; Guangdong Province Key Laboratory of Computational Science at the Sun Yat-sen University [2020B1212060032]
CR Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Borchmann L, 2018, P POLEVAL 2018 WORKS, V0, P63
   Carreón ECA, 2019, INFORM PROCESS MANAG, V56, P1339, DOI 10.1016/j.ipm.2019.03.007
   Chang DS, 2006, INFORM PROCESS MANAG, V42, P662, DOI 10.1016/j.ipm.2005.04.004
   Chelba Ciprian, 2014, ONE BILLION WORD BEN, V0, P0
   Cheng Jianpeng, 2016, P 2016 C EMPIRICAL M, V0, PP551, DOI 10.18653/V1/D16-1053
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dasgupta T, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), V0, P306
   De Silva TN, 2017, INT J COMPUT SYST EN, V0, P696
   Ding YJ, 2019, NEUROCOMPUTING, V325, P211, DOI 10.1016/j.neucom.2018.10.028
   Dozat T, 2016, P 4 INT C LEARN REP, V0, P0
   Dunietz J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1691
   Gal Y, 2016, ADV NEURAL INFORM PR, V29, P1019, DOI 10.48550/ARXIV.1512.05287
   Girju R, 2003, P ACL 2003 WORKSH MU, V12, P76, DOI 10.3115/1119312.1119322
   Girju R, 2002, P 15 INT FLOR ART IN, V0, P360
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hashimoto C, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P987
   Hendrickx Iris, 2010, P 5 INT WORKSH SEM E, V0, PP33, DOI 10.3115/1621969.1621986
   Ittoo A, 2011, LECT NOTES COMPUT SC, V6716, P52, DOI 10.1007/978-3-642-22327-3_6
   Khoo CSG, 1998, LITERARY & LINGUISTIC COMPUTING, V13, P177, DOI 10.1093/llc/13.4.177
   Khoo CSG, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P336
   Khoo CSG, 2001, INFORM PROCESS MANAG, V37, P119, DOI 10.1016/S0306-4573(00)00022-4
   Komninos A, 2016, P 2016 C N AM CHAPT, V0, PP1490, DOI 10.18653/V1/N16-1175
   Kruengkrai C, 2017, AAAI CONF ARTIF INTE, V0, P3466
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li PF, 2019, EXPERT SYST APPL, V115, P512, DOI 10.1016/j.eswa.2018.08.009
   Li XG, 2018, J MACH LEARN RES, V18, P0
   Luo ZY, 2016, FIFTEENTH INTERNATIONAL CONFERENCE ON THE PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, V0, P421
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Martinez-Camara E, 2017, IWCS 2017 12 C COMP, V0, P0
   Mintz M, 2009, P JOINT C 47 ANN M A, V2, P1003, DOI 10.3115/1690219.1690287
   Miranda A, 2012, MOVE MEANINGFUL INTE, V0, P33
   Mostafazadeh N, 2016, P 4 WORKSH EV, V0, PP51, DOI 10.18653/V1/W16-1007
   OGorman Tim, 2016, P 2 WORKSH COMP NEWS, V0, PP47, DOI 10.18653/V1/W16-5706
   Pascanu R, 2013, P 30 INT C MACHINE L, V0, P0
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Radinsky Kira, 2012, P 21 INT C WORLD WID, V0, PP909, DOI 10.1145/2187836.2187958
   Reimers N, 2017, P C EMPIRICAL METHOD, V0, PP338, DOI 10.18653/V1/D17-1035
   Riaz M, 2010, IEEE INT C SEMANT CO, V0, PP361, DOI 10.1109/ICSC.2010.19
   Silverstein C, 2000, DATA MIN KNOWL DISC, V4, P163, DOI 10.1023/A:1009891813863
   Sobrino A, 2014, NEUROCOMPUTING, V135, P53, DOI 10.1016/j.neucom.2013.05.056
   Sorgente A, 2013, P 7 INT WORKSH INF F, V2013, P37
   Strubell E, 2017, P 2017 C EMPIRICAL M, V0, PP2670, DOI 10.18653/V1/D17-1283
   Sutton RS, 1998, INTRO REINFORCEMENT, V1st, P0
   Tan ZX, 2018, AAAI CONF ARTIF INTE, V0, P4929
   Vaswani A, 2017, ARXIV, V30, P5998
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Zhao SD, 2016, NEUROCOMPUTING, V173, P1943, DOI 10.1016/j.neucom.2015.09.066
   Zheng SC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1227, DOI 10.18653/v1/P17-1113
NR 56
TC 39
Z9 45
U1 9
U2 48
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 29
PY 2021
VL 423
IS 
BP 207
EP 219
DI 10.1016/j.neucom.2020.08.078
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA PG6IT
UT WOS:000599837600019
DA 2023-11-10
ER

PT J
AU Graziani, L
   Gori, M
   Melacci, S
AF Graziani, Lisa
   Gori, Marco
   Melacci, Stefano
TI A language modeling-like approach to sketching
SO NEURAL NETWORKS
LA English
DT Article
DE Sketch generation; Recurrent Neural Networks; Language Modeling
AB Sketching is a universal communication tool that, despite its simplicity, is able to efficiently express a large variety of concepts and, in some limited contexts, it can be even more immediate and effective than natural language. In this paper we explore the feasibility of using neural networks to approach sketching in the same way they are commonly used in Language Modeling. We propose a novel approach to what we refer to as "Sketch Modeling", in which a neural network is exploited to learn a probabilistic model that estimates the probability of sketches. We focus on simple sketches and, in particular, on the case in which sketches are represented as sequences of segments. Segments and sequences can be either given - when the sketches are originally drawn in this format - or automatically generated from the input drawing by means of a procedure that we designed to create short sequences, loosely inspired by the human behavior. A Recurrent Neural Network is used to learn the sketch model and, afterward, the network is seeded with an incomplete sketch that it is asked to complete, generating one segment at each time step. We propose a set of measures to evaluate the outcome of a Beam Search-based generation procedure, showing how they can be used to identify the most promising generations. Our experimental analysis assesses the feasibility of this way of modeling sketches, also in the case in which several different categories of sketches are considered. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Graziani, Lisa] Univ Siena, Dept Social Polit & Cognit Sci, Siena, Italy.
   [Graziani, Lisa; Gori, Marco; Melacci, Stefano] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Gori, Marco] Univ Cote dAzur, MAASAI, Nice, France.
   [Graziani, Lisa] Univ Florence, Dept Informat Engn, Florence, Italy.
C3 University of Siena; University of Siena; UDICE-French Research Universities; Universite Cote d'Azur; University of Florence
RP Melacci, S (通讯作者)，Univ Siena, Dept Informat Engn & Math, Siena, Italy.
EM lisa.graziani@unifi.it; marco.gori@unisi.it; mela@diism.unisi.it
CR Aksan E, 2020, ADV NEUR IN, V0, P0
   [Anonymous], 2015, P WORKSHOP SKETCH BA, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Ballester P, 2016, AAAI CONF ARTIF INTE, V0, P1124
   Baran I, 2010, COMPUT GRAPH FORUM, V29, P655, DOI 10.1111/j.1467-8659.2009.01635.x
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao N, 2019, AAAI CONF ARTIF INTE, V0, P2564
   Chen Y, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Creswell Antonia, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE: WORKSHOPS. PROCEEDINGS: LNCS 9913, V0, PP798, DOI 10.1007/978-3-319-46604-0_55
   Dantanarayana L, 2016, CAAI T INTELL TECHNO, V1, P272, DOI 10.1016/j.trit.2016.10.003
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Douglas David H, 1973, CARTOGRAPHICA INT J, V0, P0, DOI DOI 10.1002/9780470669488.CH2
   Eitz M, 2012, ACM T GRAPHIC, V31, P0, DOI 10.1145/2185520.2185540
   Forbus KD, 2018, AAAI CONF ARTIF INTE, V0, P7665
   Graves A, 2013, ARXIV PREPRINT ARXIV, V0, P0
   Graziani L, 2018, LECT NOTES ARTIF INT, V11298, P320, DOI 10.1007/978-3-030-03840-3_24
   Ha David, 2017, ARXIV170403477, V0, P0
   Liu F, 2019, PROC CVPR IEEE, V0, PP5823, DOI 10.1109/CVPR.2019.00598
   Maggini M, 2020, IEEE T NEUR NET LEAR, V31, P4475, DOI 10.1109/TNNLS.2019.2955597
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2011, INT CONF ACOUST SPEE, V0, P5528
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ribeiro Leo Sampaio Ferraz, 2020, P IEEECVF C COMPUTER, V0, P14153
   Sangkloy P, 2016, ACM T GRAPHIC, V35, P0, DOI 10.1145/2897824.2925954
   Sarvadevabhatla RK, 2020, IEEE T PATTERN ANAL, V42, P221, DOI 10.1109/TPAMI.2018.2877996
   Sasaki K, 2019, IEEE T COGN DEV SYST, V11, P119, DOI 10.1109/TCDS.2018.2868160
   Song JF, 2018, PROC CVPR IEEE, V0, PP801, DOI 10.1109/CVPR.2018.00090
   Sun ZB, 2012, LECT NOTES COMPUT SC, V7572, P626, DOI 10.1007/978-3-642-33718-5_45
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tang H, 2019, IEEE INT CONF AUTOMA, V0, P192
   Todorovic D, 2008, SCHOLARPEDIA, V3, P5345
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wiseman Sam, 2016, P 2016 C EMPIRICAL M, V0, PP1296, DOI 10.18653/V1/D16-1137
   Xu P, 2019, TNNLS, V0, P0
   Xu P, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Zhang, 2019, VEGETAT HIST ARCHAEO, V0, P1
NR 38
TC 0
Z9 0
U1 0
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD DEC 15
PY 2021
VL 144
IS 
BP 627
EP 638
DI 10.1016/j.neunet.2021.09.020
EA OCT 2021
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA WH9IW
UT WOS:000707983400013
PM 34653720
DA 2023-11-10
ER

PT J
AU Hossain, MR
   Hoque, MM
   Siddique, N
   Sarker, IH
AF Hossain, Md. Rajib
   Hoque, Mohammed Moshiul
   Siddique, Nazmul
   Sarker, Iqbal H.
TI Bengali text document categorization based on very deep convolution neural network
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Intelligent systems; Natural language processing; Low resource language; Semantic feature extraction; Document categorization; Deep convolution network
ID feature-selection; classification
AB In recent years, the amount of digital text contents or documents in the Bengali language has increased enormously on online platforms due to the effortless access of the Internet via electronic gadgets. As a result, an enormous amount of unstructured data is created that demands much time and effort to organize, search or manipulate. To manage such a massive number of documents effectively, an intelligent text document classification system is proposed in this paper. Intelligent classification of text document in a resource-constrained language (like Bengali) is challenging due to unavailability of linguistic resources, intelligent NLP tools, and larger text corpora. Moreover, Bengali texts are available in two morphological variants (i.e., Sadhu-bhasha and Cholito-bhasha) making the classification task more complicated. The proposed intelligent text classification model comprises GloVe embedding and Very Deep Convolution Neural Network (VDCNN) classifier. Due to the unavailability of standard corpus, this work develops a large Embedding Corpus (EC) containing 969, 000 unlabelled texts and Bengali Text Classification Corpus (BDTC) containing 156, 207 labelled documents arranged into 13 categories. Moreover, this work proposes the Embedding Parameters Identification (EPI) Algorithm, which selects the best embedding parameters for low-resource languages (including Bengali). Evaluation of 165 embedding models with intrinsic evaluators (semantic & syntactic similarity measures) shows that the GloVe model is more suitable (regarding Spearman & Pearson correlation) than other embeddings (Word2Vec, FastText, m-BERT) in Bengali text. Experimental results on the test dataset confirm that the proposed GloVe + VDCNN model outperformed (achieving the highest 96.96% accuracy) the other classification models and existing methods to perform the Bengali text classification task.
C1 [Hossain, Md. Rajib; Hoque, Mohammed Moshiul; Sarker, Iqbal H.] Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong 4349, Bangladesh.
   [Siddique, Nazmul] Univ Ulster, Sch Comp Engn & Intelligent Syst, Coleraine, Londonderry, North Ireland.
C3 Chittagong University of Engineering & Technology (CUET); Ulster University
RP Hoque, MM (通讯作者)，Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong 4349, Bangladesh.
EM moshiul_240@cuet.ac.bd; nh.siddique@ulster.ac.uk; iqbal@cuet.ac.bd
FU Establishment of CUET IT Business Incubator Project; BHTPA; ICT Division, Bangladesh
CR Abuaiadah D, 2014, INT J COMPUT APPL, V101, P31, DOI 10.5120/17701-8680
   Agarap AF, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Ahmad A, 2016, INT CONF COMPUT INFO, V0, PP425, DOI 10.1109/ICCITECHN.2016.7860236
   Akhter MP, 2020, IEEE ACCESS, V8, P42689, DOI 10.1109/ACCESS.2020.2976744
   Alhaj YA, 2019, IEEE ACCESS, V7, P32664, DOI 10.1109/ACCESS.2019.2903331
   Alhawarat M, 2020, IEEE ACCESS, V8, P24653, DOI 10.1109/ACCESS.2020.2970504
   Ambalavanan AK, 2020, J BIOMED INFORM, V112, P0, DOI 10.1016/j.jbi.2020.103578
   [Anonymous], 2008, P 25 INT C MACHINE L, V0, P0
   [Anonymous], 2016, P 2016 C N AM CHAPTE, V0, P0
   Bahassine S, 2017, J ENG SCI TECHNOL, V12, P1475
   Behera RK, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102435
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1961189.1961199
   Chiu Billy, 2016, P 1 WORKSH EV VECT S, V0, PP1, DOI 10.18653/V1/W16-2501
   Chung J, 2014, NIPS 2014 WORKSH DEE, V0, PP1, DOI 10.48550/ARXIV.1412.3555
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Dang HT, 2002, P ACL 02 WORKSH WORD, V0, PP88, DOI 10.3115/1118675.1118688
   Dash NS, 2019, UTILITY APPL LANGUAG, V0, PP17, DOI 10.1007/978-981-13-1801-6_2
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhar A, 2020, ADV INTELL SYST COMP, V1034, P281, DOI 10.1007/978-981-15-1084-7_27
   Elbagir S, 2019, IEEE ACCESS, V7, P163677, DOI 10.1109/ACCESS.2019.2952127
   Enríquez F, 2016, EXPERT SYST APPL, V66, P1, DOI 10.1016/j.eswa.2016.09.005
   Gambino G, 2019, P 3 WORKSH NAT LANG, V0, P0
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3483
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Griesshaber D, 2020, COMPUT SPEECH LANG, V62, P0, DOI 10.1016/j.csl.2019.101056
   Hashemi S, 2009, IEEE T KNOWL DATA EN, V21, P624, DOI 10.1109/TKDE.2008.181
   Hashmi SU, 2019, IEEE INT C SEMANT CO, V0, PP142, DOI 10.1109/ICSC.2019.00032
   He J, 2019, IEEE ACCESS, V7, P40707, DOI 10.1109/ACCESS.2019.2907992
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Hoque MM, 2018, 2018 INT C ADV, V0, PP1, DOI 10.1109/IC4ME2.2018.8465632
   Hossain Md Rajib, 2021, HYBRID INTELLIGENT SYSTEMS. 20TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS 2020). ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1375), V0, PP103, DOI 10.1007/978-3-030-73050-5_11
   Hossain MR, 2021, P ICIOTCT IND, V0, PP494, DOI 10.1007/978-3-030-76736-5_45
   Hossain MR, 2020, P 17 INT C NATURAL L, V0, P453
   Hossain MR, 2019, P ERCICA BANG IND, V0, PP513, DOI 10.1007/978-981-13-5953-8_43
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kabir F, 2015, 2015 INT C COGN COMP, V0, PP1, DOI 10.1109/CCIP.2015.7100687
   Kaiming H, 2015, ABS151203385, V0, P0
   Keskar NS, 2016, ABS160904836, V0, P0
   Khan M, 2019, DEEP LEARNING METHOD, V0, PP31, DOI 10.1007/978-981-13-3459-7
   Khan NH, 2018, IEEE ACCESS, V6, P46019, DOI 10.1109/ACCESS.2018.2865532
   Khatouni AS, 2019, IEEE SYMP COMP COMMU, V0, PP424, DOI 10.1109/iscc47284.2019.8969578
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kowsari K, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP364, DOI 10.1109/ICMLA.2017.0-134
   Kumari M, 2016, PROCEDIA COMPUT SCI, V89, P555, DOI 10.1016/j.procs.2016.06.093
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS
   Liebeskind C, 2015, LANG RESOUR EVAL, V49, P227, DOI 10.1007/s10579-015-9298-3
   Mei JP, 2017, IEEE T FUZZY SYST, V25, P1239, DOI 10.1109/TFUZZ.2016.2604009
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, PP1, DOI 10.1162/153244303322533223
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Moirangthem DS, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.113898
   Mucherino A, 2009, SPRINGER SER OPTIM A, V34, P83, DOI 10.1007/978-0-387-88615-2_4
   Nikolentzos Giannis, 2017, P 15 C EUROPEAN CHAP, V0, P450
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Phani S, 2017, ACM T ASIAN LOW-RESO, V16, P0, DOI 10.1145/3099473
   Rahman MA, 2018, DATA, V3, P0, DOI 10.3390/data3020015
   Rebecca P, 2006, P 5 INT C LANGUAGE R, V0, P831
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Ruder Sebastian, 2017, OVERVIEW MULTITASK L, V0, P0
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sakalle A, 2021, EXPERT SYST APPL, V173, P0, DOI 10.1016/j.eswa.2020.114516
   Sarker IH, 2021, SN COMPUTER SCI, V2, P1, DOI 10.1007/S42979-021-00557-0
   Shriberg E, 2004, P 5 SIGDIAL WORKSH D, V0, P97
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Su J, 2015, EMNLP, V0, P536
   Tang D, 2015, EMNLP, V0, P0, DOI DOI 10.18653/v1/D15-1167
   TETKO IV, 1995, J CHEM INF COMP SCI, V35, P826, DOI 10.1021/ci00027a006
   Wen ZY, 2018, J MACH LEARN RES, V19, P0
   Wu D, 2020, IEEE ACCESS, V8, P32215, DOI 10.1109/ACCESS.2020.2973430
   Xiao YS, 2017, KNOWL-BASED SYST, V120, P198, DOI 10.1016/j.knosys.2017.01.001
   Zhang X, 2015, ADV NEUR IN, V28, P0
   Zhou DX, 2020, NEURAL NETWORKS, V124, P319, DOI 10.1016/j.neunet.2020.01.018
   Zia T, 2015, MALAYS J COMPUT SCI, V28, P93
NR 77
TC 8
Z9 8
U1 0
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 1
PY 2021
VL 184
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115394
EA JUL 2021
PG 23
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA WI0YM
UT WOS:000708093400018
DA 2023-11-10
ER

PT J
AU Gaur, B
   Saluja, GS
   Sivakumar, HB
   Singh, S
AF Gaur, Bodhvi
   Saluja, Gurpreet Singh
   Sivakumar, Hamsa Bharathi
   Singh, Sanjay
TI Semi-supervised deep learning based named entity recognition model to parse education section of resumes
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Named entity recognition (NER); Semi-supervised learning; Deep learning models; Natural language processing; Resume information extraction
AB A job seeker's resume contains several sections, including educational qualifications. Educational qualifications capture the knowledge and skills relevant to the job. Machine processing of the education sections of resumes has been a difficult task. In this paper, we attempt to identify educational institutions' names and degrees from a resume's education section. Usually, a significant amount of annotated data is required for neural network-based named entity recognition techniques. A semi-supervised approach is used to overcome the lack of large annotated data. We trained a deep neural network model on an initial (seed) set of resume education sections. This model is used to predict entities of unlabeled education sections and is rectified using a correction module. The education sections containing the rectified entities are augmented to the seed set. The updated seed set is used for retraining, leading to better accuracy than the previously trained model. This way, it can provide a high overall accuracy without the need of large annotated data. Our model has achieved an accuracy of 92.06% on the named entity recognition task.
C1 [Gaur, Bodhvi; Saluja, Gurpreet Singh; Sivakumar, Hamsa Bharathi; Singh, Sanjay] Manipal Inst Technol, Dept Informat & Commun Technol, MAHE, Manipal 576104, India.
   [Gaur, Bodhvi] Johns Hopkins Univ, Dept Comp Sci, 3400 North Charles St, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Singh, S (通讯作者)，Manipal Inst Technol, Dept Informat & Commun Technol, MAHE, Manipal 576104, India.
EM bgaur1@jhu.edu; gurpreet.singh11@learner.manipal.edu; hamsa.bharathi@learner.manipal.edu; sanjay.singh@manipal.edu
CR [Anonymous], 2018, NATURAL LANGUAGE TOO, V0, P0
   Ayishathahira CH, 2018, 2018 INTERNATIONAL CET CONFERENCE ON CONTROL, V0, P0
   Babar N, 2017, LEVENSHTEIN ALGORITH, V0, P0
   Bird Steven, 2009, NATURAL LANGUAGE PRO, V0, P0
   Burr T, 2015, ALGORITHMS, V8, P466, DOI 10.3390/a8030466
   Chifu ES, 2017, INT C INTELL COMP CO, V0, PP189, DOI 10.1109/ICCP.2017.8117003
   Chollet F, 2018, KERAS DEEP LEARNING, V0, P0
   Farkas Richard, 2014, MINING INTELLIGENCE AND KNOWLEDGE EXPLORATION. SECOND INTERNATIONAL CONFERENCE, V0, P333, DOI 10.1007/978-3-319-13817-6_32
   Ghufran M, 2017, INT CONF RES CHAL, V0, PP135, DOI 10.1109/RCIS.2017.7956530
   Gonzalez J, 2018, FUZZYWUZZY FUZZY STR, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Jacob Ferosh, 2014, 2014 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), V0, PP86, DOI 10.1109/CTS.2014.6867547
   Jiang ZX, 2009, 2009 WRI INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND MOBILE COMPUTING: CMC 2009, VOL 3, P588, DOI 10.1109/CMC.2009.253
   Keskar NS, 2016, ARXIV160904836, V0, P0
   Khanam MH, 2016, INT CONF SOFTW ENG, V0, PP940, DOI 10.1109/ICSESS.2016.7883220
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lee JB, 2017, ARXIV170906075, V0, P1
   Maheshwary S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP87, DOI 10.1145/3184558.3186942
   Mhapasekar Darshan P, 2017, 2017 INTERNATIONAL CONFERENCE ON TRENDS IN ELECTRONICS AND INFORMATICS (ICEI). PROCEEDINGS, V0, PP43, DOI 10.1109/ICOEI.2017.8300962
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   PAWAR S, 2012, P 5 ACM COMP C INT S, V0, P0
   Ratinov L, 2009, P 13 C COMPUTATIONAL, V0, P0, DOI DOI 10.3115/1596374.1596399
   Ravindranath VK, 2019, PROC INT CONF DOC, V0, PP169, DOI 10.1109/ICDARW.2019.40100
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Sayfullina L, 2017, INT C AN IM SOC NETW, V0, P82
   Tarar S, 2010, INT CONF COMP SCI, V0, PP653, DOI 10.1109/ICCSIT.2010.5564686
   Pham TH, 2018, COMM COM INF SC, V781, P219, DOI 10.1007/978-981-10-8438-6_18
   Tikhonova M, 2019, 2019 INT C ENG TEL E, V0, PP1, DOI 10.1109/EnT47717.2019.9030535
   Tran Q, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Pham T, 2019, ANN OPER RES, V277, P83, DOI 10.1007/s10479-017-2486-3
   Xu Z, 2020, IEEE T CLOUD COMPUT, V8, P387, DOI 10.1109/TCC.2016.2517638
   Yu K, 2005, P 43 ANN M ASS COMP, V0, PP499, DOI 10.3115/1219840.1219902
   Zafarian A, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), V0, PP129, DOI 10.1109/AISP.2015.7123504
   Zhang Chuang, 2009, 2009 WRI WORLD CONGRESS ON COMPUTER SCIENCE AND INFORMATION ENGINEERING, V0, P12, DOI 10.1109/CSIE.2009.562
   Zhang C, 2018, IEEE T SMART GRID, V9, P4236, DOI 10.1109/TSG.2017.2653198
   Zhang M, 2017, PDF2JSON, V0, P0
NR 39
TC 9
Z9 10
U1 4
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUN 15
PY 2021
VL 33
IS 11
BP 5705
EP 5718
DI 10.1007/s00521-020-05351-2
EA SEP 2020
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SE8CE
UT WOS:000570842500002
DA 2023-11-10
ER

PT J
AU Body, T
   Tao, XH
   Li, YF
   Li, L
   Zhong, N
AF Body, Thomas
   Tao, Xiaohui
   Li, Yuefeng
   Li, Lin
   Zhong, Ning
TI Using back-and-forth translation to create artificial augmented textual data for sentiment analysis models
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Natural language processing; Translation; Sentiment analysis; Data augmentation
AB Sentiment analysis classification models trained using neural networks require large amounts of data, but collecting these datasets requires significant time and resources. Although artificial data has been used successfully in computer vision, there are few effective and generalizable methods for creating artificial augmented text data. In this paper, a text based data augmentation method is proposed called back-and-forth translation that can be used to artificially increase the size of any natural language dataset. By creating augmented text data and adding it to the original dataset, it is demonstrated by empirical experiments that back-and-forth translation data augmentation can reduce the error rate in binary sentiment classification models by up to 3.4%. These results are shown to be statistically significant.
C1 [Body, Thomas; Tao, Xiaohui] Univ Southern Queensland, Sch Sci, Darling Hts, Qld, Australia.
   [Li, Yuefeng] Queensland Univ Technol, Sci & Engn Fac, Brisbane, Qld, Australia.
   [Li, Lin] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Zhong, Ning] Maebashi Inst Technol, Dept Life Sci & Informat, Maebashi, Gumma, Japan.
C3 University of Southern Queensland; Queensland University of Technology (QUT); Wuhan University of Technology
RP Body, T; Tao, XH (通讯作者)，Univ Southern Queensland, Sch Sci, Darling Hts, Qld, Australia.
EM u1101544@umail.usq.edu.au; xiaohui.tao@usq.edu.au; y2.li@qut.edu.au; cathylilin@whut.edu.cn; zhong@maebashi-it.ac.jp
CR [Anonymous], 2014, ARXIV14021128CSSTAT, V0, P0
   [Anonymous], 2015, NIPSX 15 P 28 INT C, V0, P0
   Bar D, 2015, TUDCS20150017, V0, P0
   Campos DF, 2016, ARXIV161109268V3, V0, P0
   Cubuk ED, 2019, PROC CVPR IEEE, V0, PP113, DOI 10.1109/CVPR.2019.00020
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Fei Hongliang, 2020, P 58 ANN M ASS COMP, V0, PP5759, DOI 10.18653/V1/2020.ACL-MAIN.510
   Galinsky R, 2016, PROCEEDINGS OF THE 2016 IEEE ARTIFICIAL INTELLIGENCE AND NATURAL LANGUAGE CONFERENCE (AINL FRUCT 2016), V0, P45
   Gao F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5539
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Honnibal Matthew, 2015, P 2015 C EMPIRICAL M, V0, PP1373, DOI 10.18653/v1/d15-1162
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kim Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1246
   Kobayashi S, 2018, P 2018 C N AM CHAPTE, V2, P452, DOI 10.18653/v1/N18-2072
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, P 2019 C N AM ASS CO, V1, P3609
   Li Jiwei, 2015, ARXIV150601066, V0, P0, DOI DOI 10.18653/V1/N16-1082
   Li Y, 2020, INFORMATION, V11, P0, DOI 10.3390/info11050255
   Longadge R, 2013, ARXIV13051707, V2, P83, DOI 10.48550/ARXIV.1305.1707
   Lun JQ, 2020, AAAI CONF ARTIF INTE, V34, P13446
   Luo GX, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/6140153
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Maynard D, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1142
   McCann Bryan, 2017, ADV NEURAL INFORM PR, V0, P6297
   Mesbah S, 2020, THESIS DELFT U TECHN, V0, P0, DOI DOI 10.4233/uuid:dbbfe1fc-bf63-45f0-8cf2-28ed7dab90eb
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Qiu SY, 2020, WWW20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, V0, PP249, DOI 10.1145/3366424.3383552
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Shakeel MH, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102204
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Sun X, 2017, INT CONF AFFECT, V0, PP12, DOI 10.1109/ACIIW.2017.8272616
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   Tran Toan, 2017, ADV NEURAL INFORM PR, V0, PP2794, DOI 10.5555/3294996.3295039
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang XK, 2019, INT J INNOV COMPUT I, V15, P227, DOI 10.24507/ijicic.15.01.227
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Wieting John, 2017, P 2017 C EMP METH NA, V0, PP274, DOI 10.18653/V1/D17-1026
   Wu X, 2019, LECT NOTES COMPUT SC, V11539, P84, DOI 10.1007/978-3-030-22747-0_7
   Yaeger L, 1996, P NIPS, V0, P807
   Yi K, 2019, PROC CVPR IEEE, V0, PP7010, DOI 10.1109/CVPR.2019.00718
   Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897
NR 45
TC 6
Z9 6
U1 3
U2 20
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 15
PY 2021
VL 178
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115033
EA APR 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA UR4HD
UT WOS:000696711100011
DA 2023-11-10
ER

PT J
AU Liu, SQ
   Zhao, DW
AF Liu, Shuqiang
   Zhao, Dawei
TI Diffusion and economic growth fuzzy intelligent system based on DSGE model
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE DSGE model; fuzzy intelligence system; system performance; diffusion; and economic growth
ID investment; time; help
AB In general, there are a lot of uncertainties in uncertain information, natural language, and human knowledge. The conclusion can be better deduced by using an approximate reasoning method, while a fuzzy intelligent system can deal with uncertain data and rule evaluation information systems. In order to better explore diffusion and economic growth, this paper constructs a fuzzy intelligent system based on the DSGE model and uses this system to analyze diffusion and economic growth. In order to verify the feasibility of this system, we test the response time and accuracy of the system. In addition, we also use the system to simulate diffusion and economic growth. The results show that with the increase of the task amount, the gap between the actual response time and the expected response time of the fuzzy intelligent system based on the DSGE model increases. When the task quantity is 20, the expected response time is 2.31 and the actual response time is 2.24. When the task quantity is 40, the expected response time is 2.5 and the actual response time is 2.36. The larger the task quantity is, the faster the response time of a fuzzy intelligent system based on the DSEG model is. Therefore, the fuzzy intelligent system based on the DSEG model has good performance and can analyze diffusion and economic growth well.
C1 [Liu, Shuqiang] Heilongjiang Inst Technol, Sch Econ & Management, Harbin, Heilongjiang, Peoples R China.
   [Zhao, Dawei] Harbin Univ Sci & Technol, Sch Econ & Management, Harbin, Heilongjiang, Peoples R China.
C3 Heilongjiang Institute of Technology; Harbin University of Science & Technology
RP Liu, SQ (通讯作者)，Heilongjiang Inst Technol, Sch Econ & Management, Harbin, Heilongjiang, Peoples R China.
EM shuqiangliu@yeah.net
FU Heilongjiang Province Philosophy and Social Science Research Planning Project [18JYD395]
CR Amidu AR, 2016, INT J HOUS MARK ANAL, V9, P272, DOI 10.1108/IJHMA-05-2015-0022
   [Anonymous], 2016, MATH PROBLEMS ENG, V0, P0
   Velásquez RMA, 2017, FUZZY INF ENG, V9, P493, DOI 10.1016/j.fiae.2017.12.005
   Cassio Nobrega B, 2018, INT J SOC ECON, V45, P0
   Castaldo A, 2018, APPL ECON, V50, P838, DOI 10.1080/00036846.2017.1343448
   Dong J, 2018, INTELLIGENTAUTOMATIO, V24, P1
   Gammoudi A, 2017, INT J INTELL COMPUT, V10, P200, DOI 10.1108/IJICC-09-2016-0036
   Gu J, 2017, REV FACULTAD INGENIE, V14, P382
   Gunter U, 2019, EMPIR ECON, V56, P1283, DOI 10.1007/s00181-017-1383-6
   He H, 2018, J INTELL FUZZY SYST, V35, P325, DOI 10.3233/JIFS-169591
   Hongjun G, 2018, J INTELL FUZZY SYST, V35, P1
   Hongli J, 2016, J COMPUTATIONAL THEO, V13, P2102, DOI 10.1166/JCTN.2016.6181
   Jia Y, 2016, LECT NOTES ELECT ENG, V0, PP285, DOI 10.1007/978-3-662-48365-7
   Jiang JJ, 2019, J CLEAN PROD, V212, P1242, DOI 10.1016/j.jclepro.2018.12.116
   Jin X, 2017, B TECNICO, V55, P276
   Kollias C, 2019, EMPIR ECON, V56, P935, DOI 10.1007/s00181-017-1379-2
   Mayevsky VI, 2019, VOPR EKON, V0, PP45, DOI 10.32609/0042-8736-2019-8-45-66
   Muchdie M, 2017, INT J ENCE RES, V6, P1899
   Su JF, 2018, J INTELL FUZZY SYST, V35, P2749, DOI 10.3233/JIFS-169627
   Torner G, 2019, DTSCH Z WIRTSCHAFTS, V2019, P93
   Tylecote A, 2019, RES POLICY, V48, P858, DOI 10.1016/j.respol.2018.10.001
   Wang D, 2018, J INTELL FUZZY SYST, V35, P1
   Wang M, 2019, RENEW ENERG, V132, P255, DOI 10.1016/j.renene.2018.08.009
   Wu Y, 2018, J CLEAN PROD, V190, P94, DOI 10.1016/j.jclepro.2018.04.139
   Xu J, 2017, B TECNICO, V55, P434
NR 25
TC 0
Z9 0
U1 0
U2 5
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2021
VL 40
IS 4
BP 5975
EP 5983
DI 10.3233/JIFS-189437
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RN7FL
UT WOS:000640518000023
DA 2023-11-10
ER

PT J
AU Ma, H
   Wang, J
   Qian, LF
   Lin, HF
AF Ma, Hui
   Wang, Jian
   Qian, Lingfei
   Lin, Hongfei
TI HAN-ReGRU: hierarchical attention network with residual gated recurrent unit for emotion recognition in conversation
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Emotion recognition in conversation; Pre-trained word embedding; Hierarchical attention network; Bidirectional gated recurrent unit; Residual connection; Position embedding
AB Emotion recognition in conversation aims to identify the emotion of each consistent utterance in a conversation from several pre-defined emotions. The task has recently become a new popular research frontier in natural language processing because of the increase in open conversational data and its application in opinion mining. However, most existing methods for the task cannot capture the long-range contextual information in an utterance and a conversation effectively. To alleviate this problem, we propose a novel hierarchical attention network with residual gated recurrent unit framework. Firstly, we adopt the pre-trained BERT-Large model to obtain context-dependent representation for each token of each utterance in a conversation. Then, a hierarchical attention network is proposed to capture long-range contextual information about the conversation structure. Besides, in order to better model position information of the utterances in a conversation, we add position embedding to the input of the multi-head attention. Experiments on two textual dialogue emotion datasets demonstrate that our model significantly outperforms the state-of-the-art baseline methods.
C1 [Ma, Hui; Wang, Jian; Qian, Lingfei; Lin, Hongfei] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
C3 Dalian University of Technology
RP Wang, J (通讯作者)，Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
EM huima@mail.dlut.edu.cn; wangjian@dlut.edu.cn; qlf201211057@mail.dlut.edu.cn; hflin@dlut.edu.cn
FU National Key Research and Development Program of China [2018YFC0830603]; Natural Science Foundation of China [61632011]
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Alm CO, 2005, P HUM LANG TECHN C C, V0, P0
   Ambartsoumian A, 2018, P 9 WORKSHOP COMPUTA, V0, PP130, DOI 10.18653/V1/W18-6219
   Bahdanau D, 2016, ARXIV, V0, P0
   Baziotis C, 2017, P 11 INT WORKSHOP SE, V0, PP747, DOI 10.18653/V1/S17-2126
   Chen SY, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1597
   Chung Junyoung, 2014, NIPS 2014 WORKSH DEE, V0, P0
   Colneric N, 2020, IEEE T AFFECT COMPUT, V11, P433, DOI 10.1109/TAFFC.2018.2807817
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du JC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3988
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Gui Lin, 2017, P 2017 C EMP METH NA, V0, PP1593, DOI 10.18653/V1/D17-1167
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2594
   Hazarika Devamanyu, 2018, PROC CONF, V2018, P2122, DOI 10.18653/v1/n18-1193
   He K, 2016, LECT NOTES COMPUT SC, V0, PP70, DOI 10.1007/978-3-319-46493-0_38
   Ho Dung T, 2012, KNOWLEDGE MANAGEMENT AND ACQUISITION FOR INTELLIGENT SYSTEMS. PROCEEDINGS OF THE 12TH PACIFIC RIM KNOWLEDGE ACQUISITION WORKSHOP, V0, P94, DOI 10.1007/978-3-642-32541-0_8
   Hsu CC, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), V0, P27
   Jiao WX, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P397
   Khosla S, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), V0, P37
   Kim Y, 2014, IEEE ASME INT C ADV, V0, PP1747, DOI 10.1109/AIM.2014.6878336
   Kingma DP, 2015, P ICLR, V0, P1
   Kratzwald B, 2018, DECIS SUPPORT SYST, V115, P24, DOI 10.1016/j.dss.2018.09.002
   Kumar A, 2016, PR MACH LEARN RES, V48, P0
   Li HR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4152
   Lu JS, 2016, ADV NEUR IN, V29, P0
   Luo LK, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), V0, P32
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Neviarouskaya A, 2007, LECT NOTES COMPUT SC, V4738, P218
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Perikos I, 2016, ENG APPL ARTIF INTEL, V51, P191, DOI 10.1016/j.engappai.2016.01.012
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Quan CQ, 2010, COMPUT SPEECH LANG, V24, P726, DOI 10.1016/j.csl.2010.02.002
   Rozgic V, 2012, ASIAPAC SIGN INFO PR, V0, P0
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shang LF, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1577
   Shen T, 2018, AAAI CONF ARTIF INTE, V0, P5446
   Socher R, 2011, P C EMPIRICAL METHOD, V0, P151
   Strapparava C, 2010, ANNOTATING IDENTIFYI, V0, P21
   Sukhbaatar S, 2015, ADV NEUR IN, V28, P0
   Tan ZX, 2018, AAAI CONF ARTIF INTE, V0, P4929
   Tang HJ, 2016, PROCEEDINGS OF 2016 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), V0, PP214, DOI 10.1109/ICCSNT.2016.8070151
   Tao CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4418
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vinyals O, 2015, COMPUTER SCI, V0, P0, DOI DOI 10.48550/ARXIV.1506.03134
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Wu Y, 2018, KNOWL-BASED SYST, V161, P90, DOI 10.1016/j.knosys.2018.07.033
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
NR 51
TC 14
Z9 15
U1 5
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD APR 15
PY 2021
VL 33
IS 7
BP 2685
EP 2703
DI 10.1007/s00521-020-05063-7
EA JUL 2020
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA QZ2BL
UT WOS:000555050000006
DA 2023-11-10
ER

PT J
AU Li, MZ
   Chen, L
   Zhao, J
   Li, Q
AF Li, Mingzheng
   Chen, Lei
   Zhao, Jing
   Li, Qiang
TI Sentiment analysis of Chinese stock reviews based on BERT model
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Chinese stock reviews; Sentiment analysis; BERT; Fine-tuning
AB A large number of stock reviews are available on the Internet. Sentiment analysis of stock reviews has strong significance in research on the financial market. Due to the lack of a large amount of labeled data, it is difficult to improve the accuracy of Chinese stock sentiment classification using traditional methods. To address this challenge, in this paper, a novel sentiment analysis model for Chinese stock reviews based on BERT is proposed. This model relies on a pre-trained model to improve the accuracy of classification. The model use a BERT pre-training language model to perform representation of stock reviews on the sentence level, and subsequently feed the obtained feature vector into the classifier layer for classification. In the experiments, we demonstrate that our method has higher precision, recall, and F1 than TextCNN, TextRNN, Att-BLSTM and TextCRNN. Our model can obtain the best results which are indicated to be effective in Chinese stock review sentiment analysis. Meanwhile, Our model has powerful generalization capacity and can perform sentiment analysis in many fields.
C1 [Li, Mingzheng; Chen, Lei; Zhao, Jing; Li, Qiang] Huainan Normal Univ, Coll Comp Sci, Huainan 232038, Peoples R China.
C3 Huainan Normal University
RP Li, MZ (通讯作者)，Huainan Normal Univ, Coll Comp Sci, Huainan 232038, Peoples R China.
EM mzli.hhu@gmail.com
FU Industry-University Cooperation Cooperative Education Program of the Department of Higher Education, Ministry of Education of China [201901148034]
CR Abid F, 2019, FUTURE GENER COMP SY, V95, P292, DOI 10.1016/j.future.2018.12.018
   Abualigah L, 2020, STUDIES COMPUTATIONA, V0, P0, DOI DOI 10.1007/978-3-030-34614-0_7
   Abualigah LMQ, 2019, FEATURE SELECTION EN, V0, P0
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Asghar MZ, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0171649
   Catelli R, 2020, APPL SOFT COMPUT, V97, P0, DOI 10.1016/j.asoc.2020.106779
   Devlin J, 2018, ARXIV, V1, P4171
   Duan D, 2019, BERT BASED RES CLASS, V0, P0, DOI DOI 10.19678/j.issn.1000-3428.0056222
   Endo P, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), V0, PP696, DOI 10.1109/WAINA.2014.113
   Esposito M, 2020, INFORM SCIENCES, V514, P88, DOI 10.1016/j.ins.2019.12.002
   [冯时 Feng Shi], 2012, 计算机研究与发展 JOURNAL OF COMPUTER RESEARCH AND DEVELOPMENT, V49, P2395
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hanandeh ES, 2017, J COMPUT SCI, V0, P0
   Jiang F, 2019, IEEE INT CONF COMMUN, V0, P0, DOI DOI 10.1109/iccchina.2019.8855843
   Jotheeswaran J, 2015, ARPN J ENG APPL SCI, V10, P5883
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Li YX, 2004, PATTERN RECOGN, V37, P1901, DOI 10.1016/j.patcog.2004.03.002
   Liu Y, 2017, INFORM SCIENCES, V394, P38, DOI 10.1016/j.ins.2017.02.016
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Pranckevicius T, 2017, BALT J MOD COMPUT, V5, P221, DOI 10.22364/bjmc.2017.5.2.05
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Sheu H-J, 2010, INT J BUS FIN RES, V4, P159
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang AQ, 2016, INT CONF GEOINFORM, V0, P0
   Wang RS, 2019, IEEE IJCNN, V0, P0
   Wang X, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1343
   Wang YL, 2020, KNOWL-BASED SYST, V190, P0, DOI 10.1016/j.knosys.2019.105030
   Wawre SV, 2016, INT J SCI RES, V5, P819, DOI 10.21275/v5i4.NOV162724
   Wu X, 2020, INFORM SCIENCES, V538, P142, DOI 10.1016/j.ins.2020.05.066
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   [俞敬松 Yu Jingsong], 2019, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V33, P57
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 35
TC 27
Z9 30
U1 10
U2 135
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JUL 15
PY 2021
VL 51
IS 7
BP 5016
EP 5024
DI 10.1007/s10489-020-02101-8
EA JAN 2021
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SU8MT
UT WOS:000605561600009
DA 2023-11-10
ER

PT J
AU Priyadarshi, A
   Saha, SK
AF Priyadarshi, Ankur
   Saha, Sujan Kumar
TI The first named entity recognizer in Maithili: Resource creation and system development
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Named entity recognition; Maithili language; corpus annotation; LSTM model; gazetteer lists
AB In this paper, we present our effort on the development of a Maithili Named Entity Recognition (NER) system. Maithili is one of the official languages of India, with around 50 million native speakers. Although various NER systems have been developed in several Indian languages, we did not find any openly available NER resource or system in Maithili. For the development, we manually annotated a Maithili NER corpus containing around 200K words. We prepared a baseline classifier using Conditional Random Fields (CRF). Then we ran many experiments using various recurrent neural networks (RNN). We collected larger raw corpus to obtain better word embedding and character embedding. In our experiments, we found, neural models are better than CRF; a CRF layer is effective for the prediction of the final output in the RNN models; character embedding is effective in Maithili language. We also investigated the effectiveness of gazetteer lists in neural models. We prepared a few gazetteer lists from various web resources and used those in the neural models. The incorporation of the gazetteer layer caused performance improvement. The final system achieved an f-measure of 91.6% with 94.9% precision and 88.53% recall.
C1 [Priyadarshi, Ankur; Saha, Sujan Kumar] Birla Inst Technol, Comp Sci & Engn Dept, Ranchi 835215, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Priyadarshi, A (通讯作者)，Birla Inst Technol, Comp Sci & Engn Dept, Ranchi 835215, Bihar, India.
EM Priyadarshiankur81@gmail.com
FU Science and Engineering Research Board (SERB), India [EEQ/2016/000241]
CR [Anonymous], 2008, P ACL 08, V0, P0, DOI DOI 10.1039/B003067H
   [Anonymous], 2008, P IJCNLP 2008, V0, P0
   Baldwin T, 2015, P WORKSH NOIS US GEN, V0, P126
   Bhattu SN, 2018, FIRE, V0, P158
   Biswas Sitanath, 2009, 2009 2ND INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ENGINEERING AND TECHNOLOGY (ICETET 2009), V0, PP639, DOI 10.1109/ICETET.2009.10
   Bordes A, 2011, 25 AAAI C ART INT, V0, P0
   Borthwick A, 1999, THESIS NEW YORK U GR, V0, P0
   Chopra D, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), V0, PP581, DOI 10.1109/CICT.2016.121
   Cucerzan S, 1999, P 1999 JOINT SIGDAT, V0, P90
   Das A, 2017, ACM T ASIAN LOW-RESO, V16, P0, DOI 10.1145/3015467
   Ekbal A, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, V0, P349
   Ekbal A, 2007, LINGUIST INVESTIG, V30, P95
   Ganesh HBBarathi, 2018, FIRE, V0, P119
   Gorla S, 2020, INFORMATION, V11, P0, DOI 10.3390/info11020082
   Goyal A, 2018, COMPUT SCI REV, V29, P21, DOI 10.1016/j.cosrev.2018.06.001
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Grishman R, 1996, COLING 1996, V0, P0, DOI DOI 10.3115/992628.992709
   Grishman Ralph, 1995, 6 MESS UND C MUC 6 P, V0, P0
   Gupta D, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1762
   Gupta V, 1900, V33, V0, P28
   Heinzerling B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P2989
   Isozaki H, 2002, P 19 INT C COMP LING, V0, PP1, DOI 10.3115/1071884.1071911
   Kumar N, 2006, P TECHN REP, V0, P0
   Lawrie D, 2020, FLOR ART INT RES S, V0, P0
   Leaman Robert, 2008, PAC SYMP BIOCOMPUT, V0, P652
   Li W, 2004, ACM T ASIAN LANG INF, V2, P290, DOI 10.1145/979872.979879
   Mccallum A, 2003, P 7 C NATURAL LANGUA, V0, PP188, DOI 10.3115/1119176.1119206
   Mikolov T, 2011, INT CONF ACOUST SPEE, V0, P5528
   Misawa S, 2017, P 1 WORKSH SUBW CHAR, V0, PP97, DOI 10.18653/V1/W17-4114
   Mundotiya RK, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Pandian SL, 2008, INFOS, V0, PNLP45
   Prasad G, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, V0, P0
   Priyadarshi A, 2020, COMPUT SPEECH LANG, V62, P0, DOI 10.1016/j.csl.2019.101054
   Reimers N, 2017, P C EMPIRICAL METHOD, V0, PP338, DOI 10.18653/V1/D17-1035
   Rocktäschel T, 2012, BIOINFORMATICS, V28, P1633, DOI 10.1093/bioinformatics/bts183
   Saha SK, 2012, KNOWL-BASED SYST, V27, P322, DOI 10.1016/j.knosys.2011.09.015
   Saha SK, 2009, J BIOMED INFORM, V42, P905, DOI 10.1016/j.jbi.2008.12.012
   Sharma R, 2022, NAT PROD RES, V36, P2166, DOI 10.1080/14786419.2020.1844696
   Singh AK, 2008, P IJCNLP 08 WORKSH N, V0, P5
   Singh OM, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2019), V0, PP184, DOI 10.1109/CIC48465.2019.00031
   Srikanth P, 2008, P IJCNLP 08 WORKSH N, V0, P0
   Thenmalar S, 2015, INT J NAT LANG COMPU, V4, P01, DOI 10.5121/ijnlc.2015.4501
   Vijayakrishna R, 2008, P IJCNLP 08 WOKSHOP, V0, P93
   Vinayak A, 2016, ARXIV PREPRINT ARXIV, V0, P154
   Wakao T, 1996, COLING 1996 VOLUME 1, V0, P0
   Yadav V, 2018, P 27 INT C COMP LING, V0, P2145
NR 47
TC 2
Z9 2
U1 1
U2 6
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2021
VL 41
IS 1
BP 1083
EP 1095
DI 10.3233/JIFS-210051
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UB5PA
UT WOS:000685896700064
DA 2023-11-10
ER

PT J
AU Alwajih, F
   Badr, E
   Abdou, S
   Fahmy, A
AF Alwajih, Fakhraddin
   Badr, Eman
   Abdou, Sherif
   Fahmy, Aly
TI DeepOnKHATT: An End-to-End Arabic Online Handwriting Recognition System
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Arabic online handwriting recognition; long short-term memory; connectionist temporal classification; deep learning
AB The importance of online handwriting recognition technology has steadily increased in recent years. This importance stems from the rapid increase in the number of handheld devices with digital pens and styluses. In addition, a large number of currently available communication software have been designed to support handwriting boards. During the past decade, most innovation in online handwriting recognition technology was geared towards supporting languages using the Latin alphabet. There has been a lack of sufficient development of Arabic online handwriting recognition (AOHR) systems, especially ones that perform recognition at the sentence level. In this paper, we present DeepOnKHATT, an end-to-end AOHR based on bidirectional long short-term memory and the connectionist temporal classification (BLSTM-CTC). DeepOnKHATT is capable of performing recognition at the sentence level in real-time. We evaluated our system utilizing two open access databases: CHAW and Online-KHATT. Our model achieved a 4.08% character error rate (CER) and a 14.65% word error rate (WER) against the CHAW dataset and a 12.24% CER and a 28.35% WER against the Online-KHATT dataset. A Comparison of the functionality of our proposed model to that of other existing systems showed that DeepOnKHATT had outperformed these systems.
C1 [Alwajih, Fakhraddin; Badr, Eman; Abdou, Sherif; Fahmy, Aly] Cairo Univ, Fac Comp & Artificial Intelligence, Giza, Egypt.
   [Alwajih, Fakhraddin] Ibb Univ, Dept Comp Sci, Ibb, Yemen.
   [Badr, Eman] Univ Sci & Technol, Zewail City Sci Technol & Innovat, Giza, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank (EKB); Misr University for Science & Technology
RP Alwajih, F (通讯作者)，Cairo Univ, Fac Comp & Artificial Intelligence, Giza, Egypt.; Alwajih, F (通讯作者)，Ibb Univ, Dept Comp Sci, Ibb, Yemen.
EM f.alwajih@grad.fci-cu.edu.eg; emostafa@zewailcity.edu.eg; s.abdou@fci-cu.edu.eg; aly.fahmy@cu.edu.eg
CR Akouaydi H, 2019, PROC INT CONF DOC, V0, PP41, DOI 10.1109/ICDARW.2019.50114
   Al-Helali BM, 2017, ACM COMPUT SURV, V50, P0, DOI 10.1145/3060620
   Al-Helali BM, 2016, CYBERNET SYST, V47, P478, DOI 10.1080/01969722.2016.1206768
   [Anonymous], 2006, IWFHR 06, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2014, ARXIV14125567V2CSCL, V0, P0
   Carbune V, 2020, INT J DOC ANAL RECOG, V23, P89, DOI 10.1007/s10032-020-00350-4
   El MKAEH, 2008, 11 INT C FRONT HANDW, V0, P0
   Graves Alex, 2006, P 23 INT C MACH LEAR, V0, P369
   Hosny I, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), V0, PP565, DOI 10.1109/ACPR.2011.6166664
   Jaeger S, 2001, INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION, V3, P169, DOI 10.1007/PL00013559
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Kherallah M, 2011, PROC INT CONF DOC, V0, PP1454, DOI 10.1109/ICDAR.2011.289
   Liwicki M, 2007, PROC INT CONF DOC, V0, P367
   Maalej R, 2020, MULTIMED TOOLS APPL, V79, P17969, DOI 10.1007/s11042-020-08740-w
   Maalej R, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, V0, P417, DOI 10.1109/DAS.2016.49
   Mahmoud Sabri A, 2018, OPEN CYBERN SYST J, V12, P42
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Njah S, 2012, INT CONF FRONT HAND, V0, PP308, DOI 10.1109/ICFHR.2012.230
   Park DS, 2019, INTERSPEECH, V0, PP2613, DOI 10.21437/Interspeech.2019-2680
   Prabhavalkar R, 2017, INTERSPEECH, V0, PP939, DOI 10.21437/Interspeech.2017-233
   Ragab OKA, 2018, P 4 AS C PATT REC AC, V0, P882
   Singh H, 2021, ARTIF INTELL REV, V54, P1525, DOI 10.1007/s10462-020-09886-7
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tagougui N, 2014, ARXIV14010486, V0, P0
   Tagougui N, 2017, PROC SPIE, V10341, P0, DOI 10.1117/12.2268419
   Tagougui N, 2013, INT J DOC ANAL RECOG, V16, P209, DOI 10.1007/s10032-012-0186-8
   Wilson-Nunn D, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP135, DOI 10.1109/ASAR.2018.8480300
   Yahia H, 2017, PROC SPIE, V10341, P0, DOI 10.1117/12.2268650
   Zitouni R, 2021, INT J COMPUT INT SYS, V14, P187, DOI 10.2991/ijcis.d.201024.001
NR 31
TC 4
Z9 4
U1 0
U2 6
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD SEP 15
PY 2021
VL 35
IS 11
BP 
EP 
DI 10.1142/S0218001421530062
PG 22
WC Computer Science, Artificial Intelligence
SC Computer Science
GA US1GT
UT WOS:000697185300014
DA 2023-11-10
ER

PT J
AU Chaudhary, A
   Anastasopoulos, A
   Sheikh, Z
   Neubig, G
AF Chaudhary, Aditi
   Anastasopoulos, Antonios
   Sheikh, Zaid
   Neubig, Graham
TI Reducing Confusion in Active Learning for Part-Of-Speech Tagging
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Active learning (AL) uses a data selection algorithm to select useful training samples to minimize annotation cost. This is now an essential tool for building low-resource syntactic analyzers such as part-of-speech (POS) taggers. Existing AL heuristics are generally designed on the principle of selecting uncertain yet representative training instances, where annotating these instances may reduce a large number of errors. However, in an empirical study across six typologically diverse languages (German, Swedish, Galician, North Sami, Persian, and Ukrainian), we found the surprising result that even in an oracle scenario where we know the true uncertainty of predictions, these current heuristics are far from optimal. Based on this analysis, we pose the problem of ALas selecting instances that maximally reduce the confusion between particular pairs of output tags. Extensive experimentation on the aforementioned languages shows that our proposed AL strategy outperforms other AL strategies by a significant margin. We also present auxiliary results demonstrating the importance of proper calibration of models, which we ensure through cross-view training, and analysis demonstrating how our proposed strategy selects examples that more closely follow the oracle data distribution. The code is publicly released here.(1)
C1 [Chaudhary, Aditi; Sheikh, Zaid; Neubig, Graham] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
   [Anastasopoulos, Antonios] Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University; Carnegie Mellon University
RP Chaudhary, A (通讯作者)，Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
EM aschaudh@cs.cmu.edu; antonis@gmu.edu; zsheikh@cs.cmu.edu; gneubig@cs.cmu.edu
FU Dr. Robert Sansom Fellowship; Waibel Presidential Fellowship; National Science Foundation [1761548]; Division Of Behavioral and Cognitive Sci; Direct For Social, Behav & Economic Scie [1761548] Funding Source: National Science Foundation
CR Anastasopoulos A, 2018, P 27 INT C COMPUTATI, V0, P2529
   Ankita, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, V0, P1072, DOI 10.1109/GUCON.2018.8674901
   [Anonymous], 2007, P LING ANN WORKSH LA, V0, P0
   Bellare K, 2007, 6 INT WORKSH INF INT, V0, P0
   Bohnet B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2642
   Chaudhary A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5164
   Clark K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1914
   Cotterell R, 2017, P 2017 C EMP METH NA, V0, PP748, DOI 10.18653/V1/D17-1078
   Das Dipanjan, 2011, P 49 ANN M ASS COMP, V0, P600
   Devlin J, 2018, ARXIV, V1, P4171
   Fang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P587, DOI 10.18653/v1/P17-2093
   Garrette Dan, 2013, P 2013 C N AM CHAPT, V0, P138
   Hammarstrom H, 2018, GLOTTOLOG 3 3, V0, P0
   Huang SJ, 2014, IEEE T PATTERN ANAL, V36, P1936, DOI 10.1109/TPAMI.2014.2307881
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Kirov C, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1868
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lekakou M, 2013, DOCUMENTATION ANAL E, V0, P0
   Lewis DD, 1995, SIGIR FORUM, V0, P246
   Lin YH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3125
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Malaviya C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2653
   Marcheggiani Diego, 2014, P 2014 C EMP METH NA, V0, PP898, DOI 10.3115/V1/D14-1097
   McCarthy Arya D, 2018, P 2 WORKSH UN DEP UD, V0, PP91, DOI 10.18653/V1/W18-6011
   Nicolai G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1765
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1659
   Nivre Joakim, 2018, UNIVERSAL DEPENDENCI, V0, P523
   Nixon J, 2019, IEEE CVPR, V0, P38
   Sener Ozan, 2018, INT C LEARN REPR, V0, P1
   Settles B, 2008, P 2008 C EMPIRICAL M, V0, P1070
   Settles Burr, 2009, ACTIVE LEARNING LIT, V0, P0
   Siddhant Aditya, 2020, EVALUATING CROSS LIN, V0, P0, DOI DOI 10.1609/aaai.v34i05.6414
   Tckstrm Oscar, 2013, T ASS COMPUTATIONAL, V1, P1, DOI 10.1162/tacl_a_00205
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Z, 2018, IEEE WINT CONF APPL, V0, PP1888, DOI 10.1109/WACV.2018.00209
   Wicentowski R, 2001, P 1 INT C HUM LANG T, V0, P0
   Yang Zhilin, 2017, ICLR, V0, P0
   Zitouni I, 2008, P C EMPIRICAL METHOD, V0, P600
NR 39
TC 4
Z9 4
U1 2
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 1
EP 16
DI 10.1162/tacl_a_00350
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200001
DA 2023-11-10
ER

PT J
AU Schick, T
   Udupa, S
   Schütze, H
AF Schick, Timo
   Udupa, Sahana
   Schuetze, Hinrich
TI Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper contains prompts and model outputs that are offensive in nature. When trained on large, unfiltered crawls from the Internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: They often generate racist, sexist, violent, or otherwise toxic language. As largemodels require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: Pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated-word lists, nor does it require any training data or changes to the model's parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.(1)
C1 [Schick, Timo; Schuetze, Hinrich] Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc CIS, Munich, Germany.
   [Udupa, Sahana] Ludwig Maximilians Univ Munchen, Inst Social & Cultural Anthropol, Munich, Germany.
C3 University of Munich; University of Munich
RP Schick, T (通讯作者)，Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc CIS, Munich, Germany.
EM schickt@cis.lmu.de; sahana.udupa@lmu.de; inquiries@cislmu.org
FU European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme [740516, 957442]; European Research Council (ERC) [957442] Funding Source: European Research Council (ERC)
CR Abid Abubakar, 2021, ARXIV210105783V2, V0, P0, DOI DOI 10.1145/3461702.3462624
   AlecRadford Karthik Narasimhan, 2018, IMPROVING LANGUAGE U, V0, P0
   Basta C, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), V0, P33
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bolukbasi T, 2016, ADV NEUR IN, V29, P0
   Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P7
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Caliskan A, 2017, SCIENCE, V356, P0, DOI 10.1126/science.aal4230
   Dathathri S, 2020, ICLR, V0, P0
   Dev S, 2020, AAAI CONF ARTIF INTE, V34, P7659
   Devlin J, 2018, ARXIV, V1, P4171
   Fedus William, 2021, ARXIV210103961V1, V0, P0
   Gehman Samuel, 2020, FINDINGS ASS COMPUTA, V0, P3356
   Gokaslan Aaron, 2019, OPENWEBTEXT CORPUS, V0, P0
   Gonen Hila, 2019, P NAACL HLT, V0, P609
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, V0, PP8342, DOI 10.18653/V1/2020.ACL-MAIN.740
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Junxian He, 2020, ARXIV201204281V1, V0, P0
   Kaneko M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P212
   Kaneko M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1256
   Kassner N, 2020, PROC 58 ANN M ASS CO, V0, PP7811, DOI 10.18653/v1/2020.acl-main.698
   Keskar Nitish Shirish, 2019, ARXIV190905858V2, V0, P0
   Knowles Rebecca, 2016, C ASS MACHINE TRANSL, V1, P107
   Krause Ben, 2021, FINDINGS ASS COMPUTA, V0, P4929
   Liang Sheng, 2020, P 28 INT C COMP LING, V0, PP5082, DOI 10.18653/V1/2020.COLING-MAIN.446
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Mikolov T, 2013, ARXIV13013781 CS, V0, P0, DOI DOI 10.48550/ARXIV.1301.3781
   Nadeem M, 2021, P 59 ANN M ASS COMPU, V0, PP5356, DOI 10.18653/v1/2021.acl-long.416
   Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1953
   Pavlopoulos J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4296
   Puri Raul, 2019, ARXIV191210165V1, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ravfogel Shauli, 2020, P 58 ANN M ASS COMP, V0, PP7237, DOI 10.18653/V1/2020.ACL-MAIN.647
   Rudinger Rachel, 2018, P 2018 C N AM CHAPT, V2, P0, DOI 10.18653/v1/n18- 2002
   Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2699
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2339
   Schick Timo, 2021, P 16 C EUR CHAPT ASS, V0, P0
   Schick Timo, 2020, ARXIV201211926V1, V0, P0
   Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3407
   StephenMerity Caiming Xiong, 2017, 5 INT C LEARN REPR I, V0, P0
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3645
   Timnit Gebru, 2021, P 2020 C FAIRN ACC T, V0, P0
   Udupa S, 2020, ARTIF INTELL, V0, P0
   Udupa S, 2021, EXTREME SPEECH CHALL, V0, P0
   Wang Alex, 2019, ARXIV190204094, V0, P0, DOI DOI 10.18653/v1/W19-2304
   Wolf T, 1900, P38, V0, P0
   Wuebker J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P66
   Zhao JY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4847
   Zhao Jieyu, 2017, P 2017 C EMP METH NA, V0, PP2979, DOI 10.18653/V1/D17-1323
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 52
TC 8
Z9 8
U1 3
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 1408
EP 1424
DI 10.1162/tacl_a_00434
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200084
DA 2023-11-10
ER

PT J
AU Kraljevic, Z
   Searle, T
   Shek, A
   Roguski, L
   Noor, K
   Bean, D
   Mascio, A
   Zhu, LL
   Folarin, AA
   Roberts, A
   Bendayan, R
   Richardson, MP
   Stewart, R
   Shah, AD
   Wong, WK
   Ibrahim, Z
   Teo, JT
   Dobson, RJB
AF Kraljevic, Zeljko
   Searle, Thomas
   Shek, Anthony
   Roguski, Lukasz
   Noor, Kawsar
   Bean, Daniel
   Mascio, Aurelie
   Zhu, Leilei
   Folarin, Amos A.
   Roberts, Angus
   Bendayan, Rebecca
   Richardson, Mark P.
   Stewart, Robert
   Shah, Anoop D.
   Wong, Wai Keong
   Ibrahim, Zina
   Teo, James T.
   Dobson, Richard J. B.
TI Multi-domain clinical natural language processing with MedCAT: The Medical Concept Annotation Toolkit
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Electronic health record information extraction; Clinical natural language processing; Clinical concept embeddings; Clinical ontology embeddings
ID umls
AB Electronic health records (EHR) contain large volumes of unstructured text, requiring the application of information extraction (IE) technologies to enable clinical analysis. We present the open source Medical Concept Annotation Toolkit (MedCAT) that provides: (a) a novel self-supervised machine learning algorithm for extracting concepts using any concept vocabulary including UMLS/SNOMED-CT; (b) a feature-rich annotation interface for customizing and training IE models; and (c) integrations to the broader CogStack ecosystem for vendor-agnostic health system deployment. We show improved performance in extracting UMLS concepts from open datasets (F1:0.448-0.738 vs 0.429-0.650). Further real-world validation demonstrates SNOMED-CT extraction at 3 large London hospitals with self-supervised training over -8.8B words from -17M clinical records and further fine-tuning with -6K clinician annotated examples. We show strong transferability (F1 > 0.94) between hospitals, datasets and concept types indicating cross-domain EHR-agnostic utility for accelerated clinical and research use cases.
C1 [Kraljevic, Zeljko; Searle, Thomas; Bean, Daniel; Mascio, Aurelie; Folarin, Amos A.; Roberts, Angus; Bendayan, Rebecca; Ibrahim, Zina; Dobson, Richard J. B.] Kings Coll London, Inst Psychiat Psychol & Neurosci, Dept Biostat & Hlth Informat, London, England.
   [Roguski, Lukasz; Noor, Kawsar; Bean, Daniel; Roberts, Angus; Shah, Anoop D.; Dobson, Richard J. B.] UCL, Hlth Data Res UK London, London, England.
   [Shek, Anthony; Richardson, Mark P.; Teo, James T.] Kings Coll London, Inst Psychiat Psychol & Neurosci, Dept Clin Neurosci, London, England.
   [Roguski, Lukasz; Noor, Kawsar; Zhu, Leilei; Folarin, Amos A.; Shah, Anoop D.; Wong, Wai Keong; Dobson, Richard J. B.] UCL, Inst Hlth Informat, London, England.
   [Stewart, Robert] Kings Coll London, Inst Psychiat Psychol & Neurosci, Dept Psychol Med, London, England.
   [Searle, Thomas; Mascio, Aurelie; Folarin, Amos A.; Roberts, Angus; Bendayan, Rebecca; Stewart, Robert; Dobson, Richard J. B.] South London & Maudsley NHS Fdn Trust, NIHR Biomed Res Ctr, London, England.
   [Searle, Thomas; Mascio, Aurelie; Folarin, Amos A.; Roberts, Angus; Bendayan, Rebecca; Stewart, Robert; Dobson, Richard J. B.] Kings Coll London, London, England.
   [Teo, James T.] Kings Coll Hosp NHS Fdn Trust, Dept Neurol, London, England.
   [Roguski, Lukasz; Noor, Kawsar; Zhu, Leilei; Shah, Anoop D.; Wong, Wai Keong] Univ Coll London Hosp, NHS Fdn Trust, NIHR BRC Clin Res Informat Unit, London, England.
C3 University of London; King's College London; University of London; University College London; University of London; King's College London; University of London; University College London; University of London; King's College London; South London & Maudsley NHS Trust; University of London; King's College London; King's College Hospital NHS Foundation Trust; Oxford University Hospitals NHS Foundation Trust; University of London; University College London; University College London Hospitals NHS Foundation Trust
RP Dobson, RJB (通讯作者)，Kings Coll London, Inst Psychiat Psychol & Neurosci, Dept Biostat & Hlth Informat, London, England.
EM richard.j.dobson@kcl.ac.uk
CR Alsentzer E, 2019, PROC 2 CLIN NATURAL, V0, P0
   Ammar W, 2019, **NON-TRADITIONAL**, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733
   Beam AL, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Bean DM, 2020, EUR J HEART FAIL, V22, P967, DOI 10.1002/ejhf.1924
   Bodenreider O, 2003, J BIOMED INFORM, V36, P414, DOI 10.1016/j.jbi.2003.11.002
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, PD267, DOI 10.1093/nar/gkh061
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Carr E, 2020, EVALUATION IMPROVEME, V0, P0, DOI DOI 10.1101/2020.04.24.20078006
   Devlin J, 2018, ARXIV, V1, P4171
   Ferrucci D, 2004, NAT LANG ENG, V0, P1
   Fraser KC, 2019, ARXIV191001274, V0, P0
   Gorinski PJ, 2019, ARXIV190303985, V0, P0
   Gorrell G, 2018, ARXIV181104860, V0, P0
   Hellrich Johannes, 2014, AMIA ANNU SYMP PROC, V2014, P655
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Jackson R, 2018, BMC MED INFORM DECIS, V18, P0, DOI 10.1186/s12911-018-0623-9
   Johnson AEW, 2016, SCI DATA, V3, P0, DOI 10.1038/sdata.2016.35
   Jonquet Clement, 2009, SUMMIT TRANSL BIOINFORM, V2009, P56
   Keselman A, 2008, J AM MED INFORM ASSN, V15, P496, DOI 10.1197/jamia.M2599
   Krauthammer M, 2004, J BIOMED INFORM, V37, P512, DOI 10.1016/j.jbi.2004.08.004
   Landi I, 2020, NPJ DIGIT MED, V3, P0, DOI 10.1038/s41746-020-0301-z
   Luo L, 2018, BIOINFORMATICS, V34, P1381, DOI 10.1093/bioinformatics/btx761
   Mascio A, 2020, 19TH SIGBIOMED WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2020), V0, P86
   Mikolov T, 2013, ADV NEURAL INFORM PR, V0, PP3111, DOI 10.5555/2999792.2999959
   Miotto R, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep26094
   Mohan S, 2019, AKBC, V0, P0, DOI DOI 10.24432/C5G59C
   Mowery DL, 2014, TASK 2 SHARECLEF EHE, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Savova GK, 2010, J AM MED INFORM ASSN, V17, P507, DOI 10.1136/jamia.2009.001560
   Searle T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P139
   Soysal E, 2017, J AM MED INFORM ASSN, V0, P0, DOI DOI 10.1093/jamia/ocx132.ocx132
   Stearns MQ, 2001, J AM MED INFORM ASSN, V0, P662
   Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang KC, 2018, J DIGIT IMAGING, V31, P353, DOI 10.1007/s10278-018-0069-8
   Wang X, 2019, BIOINFORMATICS, V35, P1745, DOI 10.1093/bioinformatics/bty869
   Whetzel PL, 2011, NUCLEIC ACIDS RES, V39, PW541, DOI 10.1093/nar/gkr469
   Wu HH, 2018, J AM MED INFORM ASSN, V25, P530, DOI 10.1093/jamia/ocx160
   Xu B, 2018, IEEE ACCESS, V6, P33432, DOI 10.1109/ACCESS.2018.2845840
   Zakeri R, 2020, CASE CONTROL COHORT, V0, P0, DOI DOI 10.1101/2020.07.08.20148965
NR 43
TC 37
Z9 37
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JUL 15
PY 2021
VL 117
IS 
BP 
EP 
DI 10.1016/j.artmed.2021.102083
EA MAY 2021
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA SR7MW
UT WOS:000661230700008
PM 34127232
DA 2023-11-10
ER

PT J
AU Lin, L
   Liu, J
   Zhang, XB
   Liang, XF
AF Lin, Lin
   Liu, Jie
   Zhang, Xuebing
   Liang, Xiufang
TI Automatic translation of spoken English based on improved machine learning algorithm
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Machine learning; improved algorithm; spoken English; automatic translation
ID feature-extraction; text; recognition
AB Due to the complexity of English machine translation technology and its broad application prospects, many experts and scholars have invested more energy to analyze it. In view of the complex and changeable English forms, the large difference between Chinese and English word order, and insufficient Chinese-English parallel corpus resources, this paper uses deep learning to complete the conversion between Chinese and English. The research focus of this paper is how to use language pairs with rich parallel corpus resources to improve the performance of Chinese-English neural machine translation, that is, to use multi-task learning to train neural machine translation models. Moreover, this research proposes a low-resource neural machine translation method based on weight sharing, which uses the weight-sharing method to improve the performance of Chinese-English low-resource neural machine translation. In addition, this study designs a control experiment to analyze the effectiveness of this study model. The research results show that the model proposed in this paper has a certain effect.
C1 [Lin, Lin; Liu, Jie; Zhang, Xuebing; Liang, Xiufang] Cangzhou Normal Univ, Cangzhou 061000, Hebei, Peoples R China.
C3 Cangzhou Normal University
RP Lin, L (通讯作者)，Cangzhou Normal Univ, Cangzhou 061000, Hebei, Peoples R China.
EM czlinlin2020@163.com
FU Key Project of Humanities and Social Sciences Research in Colleges and Universities [SD192023]; Hebei Province Quality Open Online Course 2019 - "Oral English" of Hebei Education Department
CR Aghdam MH, 2015, J ARTIFIC INT SOFT C, V5, P38
   Al-Tahrawi Mayy M, 2016, JOURNAL OF SOFTWARE, V11, P418, DOI 10.17706/jsw.11.4.418-430
   Gissel ST, 2015, J INF TECHNOL EDUC-R, V14, P439
   Hu YM, 2016, COMPUT INTELL-US, V32, P480, DOI 10.1111/coin.12064
   Kamble RR, 2018, INT J COMPUT SCI ENG, V6, P223
   Kumar G, 2017, J COMPUT THEORETICAL, V14, P2021, DOI 10.1166/jctn.2017.6537
   Maruthu PJ, 2016, ADV NAT APPL SCI, V10, P64
   Maruthupandi J, 2017, INT J DATA MIN MODEL, V9, P237, DOI 10.1504/IJDMMM.2017.086583
   Mojaveriyan Mohammad, 2016, INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS AND APPLICATIONS, V8, P42, DOI 10.5815/ijisa.2016.03.05
   Nayak M, 2015, ADV INTELL SYST, V309, P497, DOI 10.1007/978-81-322-2009-1_56
   Oki T, 2015, GROWTH CHANGE, V21, P61
   Ramalakshmi E, 2015, INT J COMPUT APPL, V127, P30
   Robati Z, 2015, INT J COMPUT APPL, V109, P1
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Soleymanpour M, 2016, INT J SPEECH TECHNOL, V20, P1
   Tommasel A, 2018, INFORM FUSION, V40, P1, DOI 10.1016/j.inffus.2017.05.003
   Wang HL, 2019, J INTELL FUZZY SYST, V37, P481, DOI 10.3233/JIFS-179102
   Wu GH, 2016, INT J SECUR APPL, V10, P67, DOI 10.14257/ijsia.2016.10.11.06
   Zatarain-Cabada R, 2015, RES COMPUTING SCI, V106, P49
   Zhao ZC, 2019, J INTELL FUZZY SYST, V37, P1659, DOI 10.3233/JIFS-179230
   Zia Tehseen, 2015, INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS AND APPLICATIONS, V7, P33, DOI 10.5815/ijisa.2015.06.03
   Zia T, 2015, MALAYS J COMPUT SCI, V28, P93
NR 22
TC 21
Z9 21
U1 8
U2 39
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2021
VL 40
IS 2
BP 2385
EP 2395
DI 10.3233/JIFS-189234
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA QH1ZP
UT WOS:000618076700056
DA 2023-11-10
ER

PT J
AU Jain, A
   Singh, SK
   Singh, KP
AF Jain, Anamika
   Singh, Satish Kumar
   Singh, Krishna Pratap
TI Multi-task learning using GNet features and SVM classifier for signature identification
SO IET BIOMETRICS
LA English
DT Article
ID vector
AB Signature biometrics is a widely accepted and used modality to verify the identity of an individual in many legal and financial organisations. A writer and language-independent signature identification method that can distinguish between the genuine and forged sample irrespective of the language of the signature has been proposed. To extract the distinguishing features, a pre-trained model GoogLeNet, which is fine-tuned with the largest signature dataset present till date (GPDS Synthetic), has been used. The proposed method is tested over the BHSig260 (contains images from two regional languages, Bengali and Hindi) dataset. With the help of the above fine-tuned model, knowledge is transferred to the publicly available datasets - BHSig260 and MCYT-75. The features extracted using the fine-tuned model has been fed to the support vector machine (SVM) classifiers. With the proposed method, 96.5% and 95.7% accuracy on Bengali and Hindi datasets, and 93% on MCYT-75 with skilled forged samples have been achieved respectively.
C1 [Jain, Anamika; Singh, Satish Kumar; Singh, Krishna Pratap] Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Jain, A (通讯作者)，Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
EM anamika06jain@gmail.com
CR Bhunia AK, 2019, NEURAL COMPUT APPL, V31, P8737, DOI 10.1007/s00521-019-04220-x
   Bouamra W, 2018, EXPERT SYST APPL, V107, P182, DOI 10.1016/j.eswa.2018.04.035
   Dey S, 2017, PATTERN RECOGN LETT, V0, P0
   Diaz M, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3274658
   Diaz M, 2016, INT C PATT RECOG, V0, PP1147, DOI 10.1109/ICPR.2016.7899791
   Diaz M, 2017, IEEE T PATTERN ANAL, V39, P951, DOI 10.1109/TPAMI.2016.2560810
   Dutta A, 2016, INT C PATT RECOG, V0, PP3422, DOI 10.1109/ICPR.2016.7900163
   Eskander GS, 2013, IET BIOMETRICS, V2, P169, DOI 10.1049/iet-bmt.2013.0024
   Ferrer MA, 2013, 6 IAPR INT C BIOM IC, V0, PP1, DOI 10.1109/ICB.2013.6612969
   Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981
   Ferrer MA, 2012, IEEE T INF FOREN SEC, V7, P966, DOI 10.1109/TIFS.2012.2190281
   Fierrez-Aguilar J, 2005, LECT NOTES COMPUT SC, V3546, P523
   Hafemann LG, 2018, INT J DOC ANAL RECOG, V21, P219, DOI 10.1007/s10032-018-0301-6
   Hafemann LG, 2016, INT C PATT RECOG, V0, PP2989, DOI 10.1109/ICPR.2016.7900092
   Hafemann LG, 2016, IEEE IJCNN, V0, PP2576, DOI 10.1109/IJCNN.2016.7727521
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI arXiv:1406.4729
   Jagtap AB, 2020, MULTIMED TOOLS APPL, V79, P35109, DOI 10.1007/s11042-020-08857-y
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Khan SS, 2010, LECT NOTES ARTIF INT, V6206, P188
   Loka H, 2017, IET BIOMETRICS, V6, P70, DOI 10.1049/iet-bmt.2016.0046
   Okawa M, 2018, PATTERN RECOGN, V79, P480, DOI 10.1016/j.patcog.2018.02.027
   Oliveira LS, 2017, INT CONF IMAG PROC, V0, P1
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Pal S, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, V0, P72, DOI 10.1109/DAS.2016.48
   Pal S, 2013, IET BIOMETRICS, V2, P182, DOI 10.1049/iet-bmt.2013.0016
   Ren JC, 2012, KNOWL-BASED SYST, V26, P144, DOI 10.1016/j.knosys.2011.07.016
   Ruder Sebastian, 2017, OVERVIEW MULTITASK L, V0, P0
   Serdouk Y, 2017, IMAGE VISION COMPUT, V66, P26, DOI 10.1016/j.imavis.2017.08.004
   Shariatmadari S, 2020, INT J PATTERN RECOGN, V34, P0, DOI 10.1142/S0218001420530018
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Soleimani A, 2016, PATTERN RECOGN LETT, V80, P84, DOI 10.1016/j.patrec.2016.05.023
   Szegedy C, 2014, ARXIV, V0, P0
   Wan V, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS
   Wei P, 2019, PROC CVPR IEEE, V0, PP5757, DOI 10.1109/CVPR.2019.00591
   Weston J, 1999, 7TH EUROPEAN SYMPOSIUM ON ARTIFICIAL NEURAL NETWORKS. ESANN99. PROCEEDINGS, V0, P219
   Yilmaz MB, 2018, IEEE COMPUT SOC CONF, V0, PP639, DOI 10.1109/CVPRW.2018.00094
NR 36
TC 4
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2047-4938
EI 2047-4946
J9 IET BIOMETRICS
JI IET Biom.
PD MAR 15
PY 2021
VL 10
IS 2
BP 117
EP 126
DI 10.1049/bme2.12007
EA FEB 2021
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA QM6RT
UT WOS:000616971300001
DA 2023-11-10
ER

PT J
AU Nihal, RA
   Rahman, S
   Broti, NM
   Deowan, SA
AF Nihal, Ragib Amin
   Rahman, Sejuti
   Broti, Nawara Mahmood
   Deowan, Shamim Ahmed
TI Bangla Sign alphabet recognition with zero-shot and transfer learning
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Bangla sign language; Deep learning; Recognition; Large dataset; Convolutional neural network
ID classification; scale
AB Bangla, being the fifth most spoken language in the world has its own distinct sign language with two methods (one-handed and two-handed) of representation. However, a standard automatic recognition system of Bangla sign language (BdSL) is still to be achieved. Though widely studied and explored by researchers in the past years, certain unaddressed issues like identifying unseen signs and both types of BdSL or lack of evaluation of the models in versatile environmental conditions demarcate the real-world implementation of the automatic recognition of BdSL. To find a probable solution to the shortcomings in the existing works, this paper proposes two approaches based on conventional transfer learning and contemporary Zero-shot learning (ZSL) for automatic BdSL alphabet recognition of both seen and unseen data. The performance of the proposed system is evaluated for both types of Bangla sign representations as well as on a large dataset with 35,149 images from over 350 subjects, varying in terms of backgrounds, camera angle, light contrast, skin tone, hand size, and orientation. For the ZSL approach, a new semantic descriptor dedicated to BdSL is created and a split of the dataset into seen and unseen classes is proposed. Our model achieved 68.21%, 91.57%, and 54.34% of harmonic mean accuracy, seen accuracy, and zero-shot accuracy with six unseen classes respectively. For the transfer learning-based approach, we found pre-trained DenseNet201 architecture to be the best performing feature extractor and Linear Discriminant Analysis as the best classifier with an overall accuracy of 93.68% on the large dataset after conducting quantitative experimentation on 18 CNN architectures and 21 classifiers. The satisfactory result from our models supports its very probative potential to serve extensively for the hearing and speaking impaired community. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Nihal, Ragib Amin; Rahman, Sejuti; Broti, Nawara Mahmood; Deowan, Shamim Ahmed] Univ Dhaka, Dept Robot & Mechatron Engn, Dhaka 1000, Bangladesh.
C3 University of Dhaka
RP Rahman, S (通讯作者)，Univ Dhaka, Dept Robot & Mechatron Engn, Dhaka 1000, Bangladesh.
EM sejuti.rahman@du.ac.bd
CR Ahmed Sohail, 2016, 2016 13TH INTERNATIONAL CONFERENCE ON SERVICE SYSTEMS AND SERVICE MANAGEMENT (ICSSSM), V0, PP1, DOI 10.1109/ICSSSM.2016.7538459
   Aziz KE, 2017, 2017 6TH INTERNATIONAL CONFERENCE ON INFORMATICS, V0, P0
   Bilge YC, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Bossard B, 2003, LECT NOTES ARTIF INT, V2915, P90
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Cheraghian A, 2019, P MVA 2019 16 INT C, V0, P0
   Dalal N, 2005, PROC CVPR IEEE, V0, PP886, DOI 10.1109/cvpr.2005.177
   Farhadi A, 2009, PROC CVPR IEEE, V0, PP1778, DOI 10.1109/CVPRW.2009.5206772
   Goldberg Y, 2014, CORR, V0, P0
   Hill J, 2020, NAT ELECTRON, V3, P512, DOI 10.1038/s41928-020-0451-7
   Hoque OB, 2018, 2018 INTERNATIONAL CONFERENCE ON INNOVATION IN ENGINEERING AND TECHNOLOGY (ICIET), V0, P0
   Islam MS, 2018, P 2018 INT C BANGLA, V0, P0, DOI DOI 10.1109/ICBSLP.2018.8554466
   Islam M, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON MECHATRONICS ENGINEERING (ICOM), V0, PP1, DOI 10.1109/icom47790.2019.8952046
   Jarman AM, 2015, INT J ELECT INFORMAT, V4, P1
   Jiaxi Wu, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12361), V0, PP456, DOI 10.1007/978-3-030-58517-4_27
   KNUTH DE, 1992, AM MATH MON, V99, P403, DOI 10.2307/2325085
   Kornblith S, 2019, PROC CVPR IEEE, V0, PP2656, DOI 10.1109/CVPR.2019.00277
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Madapana Naveen, 2020, ICMI 20: PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP754, DOI 10.1145/3382507.3421161
   Madapana N, 2017, P 19 ACM INT C MULT, V0, P331
   Medar R, 2017, ICCUBEA IEEE, V0, P1
   Nicodemus B, 2017, SIGN LANG STUD, V17, P143, DOI 10.1353/sls.2017.0000
   Nihal RA, 2021, SN COMPUT SCI, V2, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rafi AM, 2019, GHTC, V0, P1
   Rahaman MA, 2020, FRONT COMPUT SCI-CHI, V14, P0, DOI 10.1007/s11704-018-7253-3
   Rahaman MA, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), V0, PP192, DOI 10.1109/ICCITechn.2014.7073150
   Rony AJ, 2018, INT CONF ELECTR ENG, V0, PP74, DOI 10.1109/CEEICT.2018.8628158
   Sadik F, 2019, 2019 5 IEEE INT WIE, V0, P1
   Uddin J, 2017, EICT IEEE, V0, P1
   Urmee PP, 2019, 2019 5TH IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (WIECON-ECE 2019), V0, P0, DOI DOI 10.1109/wiecon-ece48653.2019.9019934
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wu JT, 2018, LECT NOTES COMPUT SC, V11305, P244, DOI 10.1007/978-3-030-04221-9_22
NR 35
TC 5
Z9 5
U1 4
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD OCT 15
PY 2021
VL 150
IS 
BP 84
EP 93
DI 10.1016/j.patrec.2021.06.020
EA JUL 2021
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UO5CG
UT WOS:000694711500010
DA 2023-11-10
ER

PT J
AU Romaro, C
   Najman, FA
   Lytton, WW
   Roque, AC
   Dura-Bernal, S
AF Romaro, Cecilia
   Najman, Fernando Araujo
   Lytton, William W.
   Roque, Antonio C.
   Dura-Bernal, Salvador
TI LNetPyNE Implementation and Scaling of the Potjans-Diesmann Cortical Microcircuit Model
SO NEURAL COMPUTATION
LA English
DT Article
ID reaction-diffusion; spiking; neurons; networks; cortex; state
AB The Potjans-Diesmann cortical microcircuit model is a widely used model originally implemented in NEST. Here, we reimplemented the model using NetPyNE, a high-level Python interface to the NEURON simulator, and reproduced the findings of the original publication. We also implemented a method for scaling the network size that preserves first- and second-order statistics, building on existing work on network theory. Our new implementation enabled the use of more detailed neuron models with multicompartmental morphologies and multiple biophysically realistic ion channels. This opens the model to new research, including the study of dendritic processing, the influence of individual channel parameters, the relation to local field potentials, and other multiscale interactions. The scaling method we used provides flexibility to increase or decrease the network size as needed when running these CPU-intensive detailed simulations. Finally, NetPyNE facilitates modifying or extending the model using its declarative language; optimizing model parameters; running efficient, large-scale parallelized simulations; and analyzing the model through built-in methods, including local field potential calculation and information flow measures.
C1 [Romaro, Cecilia; Roque, Antonio C.] Univ Sao Paulo, Dept Phys, Sch Philosophy Sci & Letters Ribeirao Preto, BR-14049 Ribeirao Preto, SP, Brazil.
   [Najman, Fernando Araujo] Univ Sao Paulo, Inst Math & Stat, BR-05508 Sao Paulo, SP, Brazil.
   [Lytton, William W.; Dura-Bernal, Salvador] State Univ New York Downstate Hlth Sci Univ, Dept Physiol & Pharmacol, Brooklyn, NY 11203 USA.
   [Dura-Bernal, Salvador] Nathan S Kline Inst Psychiat Res, New York, NY 10962 USA.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo; Nathan Kline Institute for Psychiatric Research
RP Romaro, C (通讯作者)，Univ Sao Paulo, Dept Phys, Sch Philosophy Sci & Letters Ribeirao Preto, BR-14049 Ribeirao Preto, SP, Brazil.
EM ceciliaromaro@gmail.com; fernando.najman@usp.br; billl@neurosim.downstate.edu; antonior@usp.br; salvadordura@gmail.com
FU NIH [U24EB028998, R01EB022903, U01EB017695]; NYS SCIRB [DOH01-C32250GG-3450000]; FAPESP (Sao Paulo Research Foundation) Research, Disseminations and Innovation Center for Neuromathematics [2013/07699-0, 2015/50122-0, 2018/20277-0]; Brazilian Coordenao de Aperfeioamento de Pessoal de Nvel Superior [88882.378774/2019-01, 88882.377124/2019-01]; CNPq [306251/2014-0];  [NSF1904444]
CR Büssow R, 2007, MECH SYST SIGNAL PR, V21, P2970, DOI 10.1016/j.ymssp.2007.06.001
   Beul SF, 2015, FRONT NEUROANAT, V8, P0, DOI 10.3389/fnana.2014.00165
   Bezaire MJ, 2016, ELIFE, V5, P0, DOI 10.7554/eLife.18566
   Binzegger T, 2004, J NEUROSCI, V24, P8441, DOI 10.1523/JNEUROSCI.1400-04.2004
   Bos H, 2016, PLOS COMPUT BIOL, V12, P0, DOI 10.1371/journal.pcbi.1005132
   Brunel N, 2000, J COMPUT NEUROSCI, V8, P183, DOI 10.1023/A:1008925309027
   Buzsáki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Cain N, 2016, PLOS COMPUT BIOL, V12, P0, DOI 10.1371/journal.pcbi.1005045
   Carnevale T, 2006, NEURON BOOK, V0, P0, DOI DOI 10.1017/CBO9780511541612
   Chicharro D, 2011, BIOL CYBERN, V105, P331, DOI 10.1007/s00422-011-0469-z
   Clopath C, 2010, NAT NEUROSCI, V13, P344, DOI 10.1038/nn.2479
   de Kock CPJ, 2009, P NATL ACAD SCI USA, V106, P16446, DOI 10.1073/pnas.0904143106
   Dean DC, 2018, BRAIN STRUCT FUNCT, V223, P1953, DOI 10.1007/s00429-017-1600-2
   Douglas RJ, 1989, NEURAL COMPUT, V1, P480, DOI 10.1162/neco.1989.1.4.480
   Dura-Bernal S, 2018, 201707 BIORXIV, V0, P0
   Dura-Bernal S, 2019, P SOC NEUR SFN 19, V0, P0
   Dura-Bernal S, 2019, ELIFE, V8, P0, DOI 10.7554/eLife.44494
   Gewaltig M-O, 2007, SCHOLARPEDIA, V2, P0, DOI 10.4249/SCHOLARPEDIA.1430
   Hagen E, 2016, CEREB CORTEX, V26, P4461, DOI 10.1093/cercor/bhw237
   Harris KD, 2011, NAT REV NEUROSCI, V12, P509, DOI 10.1038/nrn3084
   Hines ML, 2004, J COMPUT NEUROSCI, V17, P7, DOI 10.1023/B:JCNS.0000023869.22017.2e
   Labarrera C, 2018, CELL REP, V23, P1034, DOI 10.1016/j.celrep.2018.03.103
   Lapique L, 1907, J PHYSL PATHOL GEN, V9, P620, DOI 10.1007/S00422-007-0189-6
   Lee JH, 2017, FRONT COMPUT NEUROSC, V11, P0, DOI 10.3389/fncom.2017.00028
   Lytton WW, 2016, NEURAL COMPUT, V28, P2063, DOI 10.1162/NECO_a_00876
   McDougal RA, 2013, FRONT NEUROINFORM, V7, P0, DOI 10.3389/fninf.2013.00028
   Newton AJH, 2018, FRONT NEUROINFORM, V12, P0, DOI 10.3389/fninf.2018.00041
   Neymotin SA, 2016, FRONT PHARMACOL, V7, P0, DOI 10.3389/fphar.2016.00157
   PINSKY PF, 1995, BIOL CYBERN, V73, P129, DOI 10.1007/BF00204051
   Potjans TC, 2014, SPIKING CORTICAL NET, V0, P0
   Potjans TC, 2014, CEREB CORTEX, V24, P785, DOI 10.1093/cercor/bhs358
   Ranjan Rajnish, 2011, FRONT NEUROINFORM, V5, P36, DOI 10.3389/fninf.2011.00036
   Romaro C, 2020, ARXIV200202381, V0, P0
   Sakata S, 2009, NEURON, V64, P404, DOI 10.1016/j.neuron.2009.09.020
   Schmidt M, 2018, BRAIN STRUCT FUNCT, V223, P1409, DOI 10.1007/s00429-017-1554-4
   Schuecker J, 2017, PLOS COMPUT BIOL, V13, P0, DOI 10.1371/journal.pcbi.1005179
   Schwalger T, 2017, PLOS COMPUT BIOL, V13, P0, DOI 10.1371/journal.pcbi.1005507
   Shimoura RO, 2018, RESCIENCE, V4, P0
   Sivagnanam S, 2013, P 5 INT WORKSHOP SCI, V0, P0
   SWADLOW HA, 1989, J NEUROPHYSIOL, V62, P288, DOI 10.1152/jn.1989.62.1.288
   Tetzlaff T, 2012, PLOS COMPUT BIOL, V8, P0, DOI 10.1371/journal.pcbi.1002596
   Thomson AM, 2002, CEREB CORTEX, V12, P936, DOI 10.1093/cercor/12.9.936
   Towns J, 2014, COMPUT SCI ENG, V16, P62, DOI 10.1109/MCSE.2014.80
   van Albada SJ, 2015, PLOS COMPUT BIOL, V11, P0, DOI 10.1371/journal.pcbi.1004490
   van Vreeswijk C, 1998, NEURAL COMPUT, V10, P1321, DOI 10.1162/089976698300017214
   Wagatsuma N, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0080788
   West DC, 2006, CEREB CORTEX, V16, P200, DOI 10.1093/cercor/bhi098
NR 47
TC 3
Z9 3
U1 1
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0899-7667
EI 1530-888X
J9 NEURAL COMPUT
JI Neural Comput.
PD JUL 15
PY 2021
VL 33
IS 7
BP 1993
EP 2032
DI 10.1162/neco_a_01400
PG 40
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA SU9FC
UT WOS:000663434700009
PM 34411272
DA 2023-11-10
ER

PT J
AU Jiao, XQ
   Chang, HT
   Yin, YC
   Shang, LF
   Jiang, X
   Chen, X
   Li, LL
   Wang, F
   Liu, Q
AF Jiao, Xiaoqi
   Chang, Huating
   Yin, Yichun
   Shang, Lifeng
   Jiang, Xin
   Chen, Xiao
   Li, Linlin
   Wang, Fang
   Liu, Qun
TI Improving task-agnostic BERT distillation with layer mapping search q
SO NEUROCOMPUTING
LA English
DT Article
DE Pre-trained language models; Bert; Knowledge distillation; Task-agnostic; Layer mapping
ID genetic algorithm
AB Knowledge distillation (KD) which transfers the knowledge from a large teacher model to a small student model, has been widely used to compress the BERT model recently. Besides the supervision in the output in the original KD, recent works show that layer-level supervision is crucial to the performance of the stu-dent BERT model. However, previous works designed the layer mapping strategy heuristically (e.g., uni-form or last-layer), which can lead to inferior performance. In this paper, we propose to use the genetic algorithm (GA) to search for the optimal layer mapping automatically. To accelerate the search process, we further propose a proxy setting where a small portion of the training corpus are sampled for distilla-tion, and three representative tasks are chosen for evaluation. After obtaining the optimal layer mapping, we perform the task-agnostic BERT distillation with it on the whole corpus to build a compact student model, which can be directly fine-tuned on downstream tasks. Comprehensive experiments on the eval-uation benchmarks demonstrate that 1) layer mapping strategy has a significant effect on task-agnostic BERT distillation and different layer mappings can result in quite different performances; 2) the optimal layer mapping strategy from the proposed search process consistently outperforms the other heuristic ones; 3) with the optimal layer mapping, our student model achieves state-of-the-art performance on the GLUE tasks. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Jiao, Xiaoqi; Wang, Fang] Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
   [Chang, Huating] Zhejiang Univ, Hangzhou 310058, Peoples R China.
   [Yin, Yichun; Shang, Lifeng; Jiang, Xin; Chen, Xiao; Liu, Qun] Huawei Noahs Ark Lab, Beijing, Peoples R China.
   [Li, Linlin] Huawei Technol Co Ltd, Shenzhen, Peoples R China.
C3 Huazhong University of Science & Technology; Zhejiang University; Huawei Technologies; Huawei Technologies
RP Wang, F (通讯作者)，Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
EM wangfang@hust.edu.cn
FU NSFC [61832020, 61821003, 61772216]; National Science and Technology Major Project [2017ZX01032-101]; Fundamental Research Funds for the Central Universities
CR [Anonymous], 2020, ICLR, V0, P0
   [Anonymous], 2014, ARXIV LEARNING, V0, P0
   Bebis G, 1997, NEUROCOMPUTING, V17, P167, DOI 10.1016/S0925-2312(97)00050-7
   Clark Kevin, 2020, ICLR, V0, P0
   Cui BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3548
   Cui YM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5883
   Dehghani M, 2019, 7 INT C LEARN REPR I, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Elbayad Maha, 2020, ICLR, V0, P0
   Gordon MA, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P143
   Hinton Geoffrey, 2015, ARXIV150302531, V0, P0
   Hou Lu, 2020, NEURIPS, V33, P9782
   Jiao Xiaoqi, 2020, TINYBERT DISTILLING, V0, P0
   Kabir MM, 2011, NEUROCOMPUTING, V74, P2914, DOI 10.1016/j.neucom.2011.03.034
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Le QV, 2020, ARXIV200402967, V0, P0
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu W, 2020, P 58 ANN M ASS COMPU, V0, PP6035, DOI 10.18653/V1/2020.ACL-MAIN.537
   Liu Y, 2019, ROBUSTLY OPTIMIZED B, V0, P0
   Ma X, 2019, ARXIV190609777, V0, P0
   McCarley J, 2019, ABS191006360 CORR, V0, P0
   Meng D, 2012, NEUROCOMPUTING, V78, P48, DOI 10.1016/j.neucom.2011.05.029
   Mitchell Melanie, 1998, INTRO GENETIC ALGORI, V0, P0
   Raffel C, 2019, ARXIV191010683, V0, P0
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Sadeghi J, 2014, INFORM SCIENCES, V272, P126, DOI 10.1016/j.ins.2014.02.075
   Sajjad Hassan, 2020, ARXIV200403844, V0, P0
   Sanh V, 2019, ARXIV, V0, P0
   Shen S, 2019, ARXIV190905840, V0, P0
   So DR, 2019, PR MACH LEARN RES, V97, P0
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4323
   Sun Z, 2020, ARXIV200402984, V0, P0
   Sun Z, 2019, MOBILEBERT TASKAGNOS, V0, P0
   Tang Raphael, 2019, DISTILLING TASK SPEC, V0, P0
   Tsai H, 2019, P 2019 C EMPIRICAL M, V0, P3623
   Turc Iulia, 2019, ARXIV190808962, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang Wenhui, 2020, ARXIV200210957, V0, P0, DOI DOI 10.1145/3308558.3313562
   Wang ZY, 2020, NEUROCOMPUTING, V404, P247, DOI 10.1016/j.neucom.2020.03.082
   Xie LX, 2017, IEEE I CONF COMP VIS, V0, PP1388, DOI 10.1109/ICCV.2017.154
   Xu CW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7859
   Yang Z, 2019, PREPRINT, V0, P0
   Yao X, 1999, P IEEE, V87, P1423, DOI 10.1109/5.784219
   Zafrir Ofir, 2019, 2019 FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS), V0, PP36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zeng XP, 2009, NEUROCOMPUTING, V72, P1214, DOI 10.1016/j.neucom.2008.02.010
   Zhang Z, 2020, ARXIV200505179, V0, P0, DOI DOI 10.1007/S11263
NR 47
TC 2
Z9 2
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 21
PY 2021
VL 461
IS 
BP 194
EP 203
DI 10.1016/j.neucom.2021.07.050
EA JUL 2021
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UR8ZM
UT WOS:000697030100017
DA 2023-11-10
ER

PT J
AU Wang, KL
   Yi, YH
   Tang, ZW
   Peng, JB
AF Wang, Kaili
   Yi, Yaohua
   Tang, Ziwei
   Peng, Jibing
TI Multi-scene ancient Chinese text recognition with deep coupled alignments
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Multi-scene ancient Chinese text; recognition; Transfer learning; Deep coupled alignments; Cross-domain fusion
ID character-recognition; representation; network
AB The task of multi-scene ancient Chinese text recognition (MACR) is challenging due to large-scale categories, high intra-class variance and inter-class similarity and complicated backgrounds. Little effort has been devoted to MACR research due to insufficient datasets and language barrier. Because the sub-dataset generation process of sub-dataset is mutually blind, there are discrepancies in the class category number, deep feature representation and class center distribution after the dataset statistics and character analysis are performed. The general deep learning method that assumes that data are independent and identically distributed is inappropriate. The deep coupled alignments (CA) module based on domain adaptation is presented to alleviate domain and class center shifts. In addition, a cross-domain fusion (CF) module is proposed to mitigate negative transfer in partial domain adaptation by updating the target domain with the full-class and augmenting the source domain with pseudo labeled samples. Extensive experiments of the proposed method are conducted, and the results illustrate the superiority of CA-CF to previous methods in terms of the model size and recognition accuracy. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, Kaili; Yi, Yaohua; Tang, Ziwei; Peng, Jibing] Wuhan Univ, Sch Printing & Packaging, Wuhan 430072, Peoples R China.
   [Wang, Kaili] Wuhan Inst Technol, Sch Comp Sci & Engn, Wuhan 430205, Peoples R China.
C3 Wuhan University; Wuhan Institute of Technology
RP Yi, YH (通讯作者)，Wuhan Univ, Sch Printing & Packaging, Wuhan 430072, Peoples R China.
EM klw@whu.edu.cn; whudcil@whu.edu.cn; tangziwei@whu.edu.cn; 2019102170004@whu.edu.cn
FU National Science and Technology Major Project, China [2017ZX01030102]
CR [Anonymous], 2011, P 2011 WORKSHOP HIST, V0, P0
   Bai X, 2016, IEEE T IMAGE PROCESS, V25, P2789, DOI 10.1109/TIP.2016.2555080
   Chen C, 2020, AAAI CONF ARTIF INTE, V34, P3422
   Chen C, 2019, AAAI CONF ARTIF INTE, V0, P3296
   Gao PC, 2017, INT J DOC ANAL RECOG, V20, P59, DOI 10.1007/s10032-016-0277-z
   Gao PC, 2015, MULTIMED TOOLS APPL, V74, P7221, DOI 10.1007/s11042-014-1969-3
   He WH, 2018, IEEE T IMAGE PROCESS, V27, P5406, DOI 10.1109/TIP.2018.2855399
   Hu J, 2017, IEEE GLOB CONF SIG, V0, PP1407, DOI 10.1109/GlobalSIP.2017.8309193
   Jaderberg Max, 2014, ARXIV14053866, V0, P0, DOI DOI 10.5244/C.28.88
   Li X, 2019, PROC CVPR IEEE, V0, PP510, DOI 10.1109/CVPR.2019.00060
   Lin DZ, 2018, NEUROCOMPUTING, V288, P11, DOI 10.1016/j.neucom.2017.02.105
   Lin Y, 2013, ACM-IEEE J CONF DIG, V0, P323
   Liu XY, 2019, INT J DOC ANAL RECOG, V22, P143, DOI 10.1007/s10032-019-00320-5
   Liu ZC, 2018, AAAI CONF ARTIF INTE, V0, P7194
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lu WM, 2011, J ZHEJIANG U-SCI C, V12, P873, DOI 10.1631/jzus.C1100005
   Messina R, 2015, PROC INT CONF DOC, V0, P171
   Ptucha R, 2019, PATTERN RECOGN, V88, P604, DOI 10.1016/j.patcog.2018.12.017
   Ren XH, 2017, IEEE ACCESS, V5, P3193, DOI 10.1109/ACCESS.2017.2676158
   Rui Zhang, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1577, DOI 10.1109/ICDAR.2019.00253
   Saini Rajkumar, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1499, DOI 10.1109/ICDAR.2019.00241
   Shi BG, 2017, PROC INT CONF DOC, V0, PP1429, DOI 10.1109/ICDAR.2017.233
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Sun BC, 2016, AAAI CONF ARTIF INTE, V0, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Tzeng E, 2017, PROC CVPR IEEE, V0, PP2962, DOI 10.1109/CVPR.2017.316
   Tzeng Eric, 2014, ARXIV14123474, V0, P0, DOI DOI 10.48550/ARXIV.1412.3474
   Wang JL, 2018, NEUROCOMPUTING, V317, P149, DOI 10.1016/j.neucom.2018.08.023
   Wang K, 2011, IEEE I CONF COMP VIS, V0, PP1457, DOI 10.1109/ICCV.2011.6126402
   Wang KL, 2020, NEUROCOMPUTING, V377, P64, DOI 10.1016/j.neucom.2019.10.029
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xie HT, 2019, ACM T MULTIM COMPUT, V15, P0, DOI 10.1145/3231737
   Xie ZC, 2018, IEEE T PATTERN ANAL, V40, P1903, DOI 10.1109/TPAMI.2017.2732978
   Yang LJ, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), V0, PP358, DOI 10.1109/ICASI.2018.8394608
   Yu K, 2008, LECT NOTES COMPUT SC, V5353, P228
   Yuan TL, 2019, J COMPUT SCI TECH-CH, V34, P509, DOI 10.1007/s11390-019-1923-y
   Zhan FN, 2018, LECT NOTES COMPUT SC, V11212, P257, DOI 10.1007/978-3-030-01237-3_16
   Zhang XF, 2012, PATTERN RECOGN LETT, V33, P2262, DOI 10.1016/j.patrec.2012.08.018
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhu Han, 2017, P 34 INT C MACH LEAR, V0, P2208
NR 42
TC 2
Z9 2
U1 5
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD SEP 15
PY 2021
VL 108
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107475
EA MAY 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SV1DF
UT WOS:000663565200005
DA 2023-11-10
ER

PT J
AU Ruiz-Dolz, R
   Alemany, J
   Barberá, SMH
   Garcia-Fornes, A
AF Ruiz-Dolz, Ramon
   Alemany, Jose
   Heras Barbera, Stella M.
   Garcia-Fornes, Ana
TI Transformer-Based Models for Automatic Identification of Argument Relations: A Cross-Domain Evaluation
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Article
DE Task analysis; Ethics; Natural language processing; Data mining; Standards; Intelligent systems; Computational modeling
AB Argument mining is defined as the task of automatically identifying and extracting argumentative components (e.g., premises, claims, etc.) and detecting the existing relations among them (i.e., support, attack, rephrase, no relation). One of the main issues when approaching this problem is the lack of data, and the size of the publicly available corpora. In this work, we use the recently annotated US2016 debate corpus. US2016 is the largest existing argument annotated corpus, which allows exploring the benefits of the most recent advances in natural language processing in a complex domain like argument (relation) mining. We present an exhaustive analysis of the behavior of transformer-based models (i.e., BERT, XLNET, RoBERTa, DistilBERT, and ALBERT) when predicting argument relations. Finally, we evaluate the models in five different domains, with the objective of finding the less domain-dependent model. We obtain a macro F1-score of 0.70 with the US2016 evaluation corpus, and a macro F1-score of 0.61 with the Moral Maze cross-domain corpus.
C1 [Ruiz-Dolz, Ramon; Alemany, Jose; Heras Barbera, Stella M.; Garcia-Fornes, Ana] Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia
RP Ruiz-Dolz, R (通讯作者)，Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Valencia 46022, Spain.
EM raruidol@dsic.upv.es; jalemany1@dsic.upv.es; stehebar@upv.es; agarcia@dsic.upv.es
FU Spanish Government [TIN2017-89,156-R]; FPI [BES-2015-074, 498]; Valencian Government [PROMETEO/2018/002]; NVIDIA Corporation
CR Cocarascu O, 2017, P 2017 C EMPIRICAL M, V0, P1374
   Devlin J, 2018, ARXIV, V1, P4171
   Jha R, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC20), V0, PP940, DOI 10.1145/3341105.3373907
   Kotonya N, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P156
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lawrence J, 2019, COMPUT LINGUIST, V45, P765, DOI 10.1162/COLI_a_00364
   Lawrence J, 2014, FRONT ARTIF INTEL AP, V266, P465, DOI 10.3233/978-1-61499-436-7-465
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Menini S, 2018, AAAI CONF ARTIF INTE, V0, P4889
   Naderi Nona, 2015, PRINCIPLES PRACTICE, V0, P16
   Niculae V, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P985, DOI 10.18653/v1/P17-1091
   Palau RM, 2009, P 12 INT C ART INT L, V0, P98
   Rago A, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1949
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Stab C, 2017, COMPUT LINGUIST, V43, P619, DOI 10.1162/COLI_a_00295
   Toni, 2020, DATASET INDEPENDENT, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Visser J, 2020, LANG RESOUR EVAL, V54, P123, DOI 10.1007/s10579-019-09446-8
   Walton D, 2008, ARGUMENTATION SCHEMES, V0, PP1, DOI 10.1017/CBO9780511802034
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
NR 20
TC 3
Z9 3
U1 5
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
EI 1941-1294
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD NOV 1
PY 2021
VL 36
IS 6
BP 62
EP 70
DI 10.1109/MIS.2021.3073993
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA XT1FC
UT WOS:000733340300014
DA 2023-11-10
ER

PT J
AU Akkaya, EK
   Can, B
AF Kagan Akkaya, Emre
   Can, Burcu
TI Transfer learning for Turkish named entity recognition on noisy text
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Named entity recognition; Transfer learning; Recurrent neural networks; Low-resource language; Noisy text
ID resources
AB In this article, we investigate using deep neural networks with different word representation techniques for named entity recognition (NER) on Turkish noisy text. We argue that valuable latent features for NER can, in fact, be learned without using any hand-crafted features and/or domain-specific resources such as gazetteers and lexicons. In this regard, we utilize character-level, character n-gram-level, morpheme-level, and orthographic character-level word representations. Since noisy data with NER annotation are scarce for Turkish, we introduce a transfer learning model in order to learn infrequent entity types as an extension to the Bi-LSTM-CRF architecture by incorporating an additional conditional random field (CRF) layer that is trained on a larger (but formal) text and a noisy text simultaneously. This allows us to learn from both formal and informal/noisy text, thus improving the performance of our model further for rarely seen entity types. We experimented on Turkish as a morphologically rich language and English as a relatively morphologically poor language. We obtained an entity-level F1 score of 67.39% on Turkish noisy data and 45.30% on English noisy data, which outperforms the current state-of-art models on noisy text. The English scores are lower compared to Turkish scores because of the intense sparsity in the data introduced by the user writing styles. The results prove that using subword information significantly contributes to learning latent features for morphologically rich languages.
C1 [Kagan Akkaya, Emre; Can, Burcu] Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
C3 Hacettepe University
RP Can, B (通讯作者)，Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
EM burcucan@cs.hacettepe.edu.tr
CR [Anonymous], 2008, P ACL 08, V0, P0
   [Anonymous], 1997, P 5 APPL NAT LANG PR, V0, P0, DOI DOI 10.3115/974557.974586
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Buswell J, 2017, CABI TOUR TEXT, V0, PP172, DOI 10.1079/9781780645445.0172
   Çelikkaya G, 2013, I C APPL INF COMM TE, V0, P154
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/tacl_a_00104
   Cieliebak M, 2017, W NUT, V0, P166
   Cotterell R, 2017, P 8 INT JOINT C NATU, V2, P91
   Derczynski L, 2017, P 3 WORKSHOP NOISY U, V0, PP140, DOI 10.18653/V1/W17-4418
   Eken B, 2015, P 4 INT C SOFTW ENG, V0, P0
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   glu Dilara Toruno, 2014, P 5 WORKSHOP LANGUAG, V0, P62
   Godin Frederic, 2015, ACL IJCNLP, V0, PP146, DOI 10.18653/V1/W15-4322
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Huang Z, 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Kucuk D, 2014, ARXIV14108668, V0, P0
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Li WQ, 2016, COMPOS COMMUN, V1, P1, DOI 10.1016/j.coco.2016.07.002
   Limsopatham N, 2016, P 2 WORKSH NOIS US G, V0, PP145, DOI 10.17863/CAM.7201
   Lin B, 2017, SAF COAL MINES, V3, P160
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Okur E, 2016, LREC, V0, P0
   Pagliardini Matteo, 2017, ARXIV170302507, V0, P0, DOI DOI 10.18653/V1/N18-1049
   Patrick J, 2017, P 3 WORKSH NOIS US G, V0, PP154, DOI 10.18653/V1/W17-4420
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Petasis G, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P418
   Reimers N, 2014, P KONVENS GERMEVAL S, V0, P0
   Riedl M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P120
   Sak H, 2008, LECT NOTES ARTIF INT, V5221, P417
   Sak H, 2011, LANG RESOUR EVAL, V45, P249, DOI 10.1007/s10579-010-9128-6
   Seker GA, 2017, SEMANT WEB, V8, P625, DOI 10.3233/SW-170253
   Sezer B, 2013, P 27 NAT LING C MAY, V0, P3
   Sikdar Utpal Kumar, 2017, WORKSHOP NOISY USER, V0, PP177, DOI 10.18653/v1/W17-4424
   Solorio, 2017, P 3 WORKSHOP NOISY U, V0, PP148, DOI 10.18653/v1/W17-4419
   Tur G, 2003, NATURAL LANGUAGE ENGINEERING, V9, P181, DOI 10.1017/S135132490200284X
   Üstün A, 2018, REPRESENTATION LEARNING FOR NLP, V0, P144
   Üstün A, 2016, LECT NOTES ARTIF INT, V9918, P43, DOI 10.1007/978-3-319-45925-7_4
   Wu Y, 2003, P ACL 2003 WORKSH MU, V0, P65
   Yang Zhilin, 2017, ICLR, V0, P0
   Yin Z, 2018, ADV NEUR IN, V31, P0
NR 45
TC 10
Z9 10
U1 3
U2 20
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JAN 15
PY 2021
VL 27
IS 1
BP 35
EP 64
DI 10.1017/S1351324919000627
PG 30
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA PE7DH
UT WOS:000598522400002
DA 2023-11-10
ER

PT J
AU Wu, ZF
   Peng, H
   Smith, NA
AF Wu, Zhaofeng
   Peng, Hao
   Smith, Noah A.
TI Infusing Finetuning with Semantic Dependencies
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB For natural language processing systems, two kinds of evidence support the use of text representations from neural language models "pretrained'' on large unannotated corpora: performance on application-inspired benchmarks (Peters et al., 2018, inter alia), and the emergence of syntactic abstractions in those representations (Tenney et al., 2019, inter alia). On the other hand, the lack of grounded supervision calls into question how well these representations can ever capture meaning (Bender and Koller, 2020). We apply novel probes to recent language models-specifically focusing on predicate-argument structure as operationalized by semantic dependencies (Ivanova et al., 2012)-and find that, unlike syntax, semantics is not brought to the surface by today's pretrained models. We then use convolutional graph encoders to explicitly incorporate semantic parses into task-specific finetuning, yielding benefits to natural language understanding (NLU) tasks in the GLUE benchmark. This approach demonstrates the potential for general-purpose (rather than task-specific) linguistic supervision, above and beyond conventional pretraining and finetuning. Several diagnostics help to localize the benefits of our approach.(1)
C1 [Wu, Zhaofeng; Peng, Hao; Smith, Noah A.] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
   [Smith, Noah A.] Allen Inst Artificial Intelligence, Seattle, WA USA.
C3 University of Washington; University of Washington Seattle
RP Wu, ZF (通讯作者)，Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
EM zfw7@cs.washington.edu; hapeng@cs.washington.edu; nasmith@cs.washington.edu
FU Google Fellowship; NSF [1562364]; Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr [1562364] Funding Source: National Science Foundation
CR Abend Omri, 2013, P ACL, V0, P0
   Adi Yossi, 2017, P ICLR, V0, P0
   [Anonymous], 1996, P 16 C COMPUTATIONAL, V0, P0
   [Anonymous], 2016, P LREC, V0, P0
   [Anonymous], 2016, P 1 C MACHINE TRANSL, V0, P0
   Baker CF, 1998, 36 ANN M ASS COMPUTA, V0, PP86, DOI 10.3115/980845.980860
   Bastings J, 2017, P EMNLP 2017, V0, PP1957, DOI 10.18653/V1/D17-1209
   Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254
   Belinkov Y, 2020, COMPUT LINGUIST, V46, P1, DOI 10.1162/COLI_a_00367
   Bender EM, 2020, C SESSION P 58 ANN M, V0, P0
   Bentivogli L, 2009, P TAC, V0, P1
   Cer Daniel M, 2017, P SEMEVAL, V0, P0
   Che Wanxiang, 2019, P MRP, V0, P0
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   CHU YJ, 1965, SCI SINICA, V14, P1396
   Clark KP, 2018, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE, V0, P0
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, PP276, DOI 10.18653/v1/w19-4828
   Clark Kevin, 2020, ICLR, V0, P0
   Copestake Ann, 2005, RES LANGUAGE COMPUTA, V4, P281
   Csernai Kornel, 2017, 1 QUORA DATASET RELE, V0, P0
   Cucurull Guillem, 2018, INT C LEARN REPR, V0, P1
   Dagan Ido, 2005, MACHINE LEARNING CHA, V0, P177
   De Marneffe MC, 2006, LREC, V6, P449
   Devlin J, 2018, ARXIV, V1, P4171
   Dodge Jesse, 2020, ARXIV200206305, V0, P0
   Dolan B, 2005, 3 INT WORKSHOP PARAP, V0, P0
   Dozat T, 2017, ICLR, V0, P0
   Dozat T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P484
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Eriguchi A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P72, DOI 10.18653/v1/P17-2012
   Giampiccolo Danilo, 2007, P ACL PASCAL WORKSH, V0, P0
   Goldberg Yoav, 2019, ABS190105287 ARXIV, V0, P0
   Gorodkin J, 2004, COMPUT BIOL CHEM, V28, P367, DOI 10.1016/j.compbiolchem.2004.09.006
   Hajic Jan, 2012, P LREC, V0, P0
   Harikrishnan R, 2006, PLANT HEALTH PROGRESS, V0, P1
   Hewitt John, 2019, P NAACL, V0, P0
   Hupkes Dieuwke, 2018, P IJCAI, V0, P0
   Ivanova Angelina, 2012, P LAW, V0, P0
   Jiang Haoming, 2019, ARXIV191103437, V0, P0
   Kipf TN, 2016, P INT C LEARNING REP, V0, P0
   Kovaleva Olga, 2019, ARXIV190808593, V0, P4356
   Kuncoro A, 2020, T ASSOC COMPUT LING, V8, P776, DOI 10.1162/tacl_a_00345
   Li Zuchao, 2019, P MRP, V0, P0
   Liu Nelson F, 2019, P NAACL, V0, P0
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Marcheggiani D, 2017, ARXIV170304826, V0, P0, DOI DOI 10.18653/V1/D17-1159
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   McDonald R, 2005, P C HUM LANG TECHN E, V0, PP523, DOI 10.3115/1220575.1220641
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Oepen Stephan, 2019, P MRP, V0, P0
   Oepen Stephan, 2006, P LREC, V0, P0
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Pang Deric, 2019, ARXIV190908217, V0, P0
   Parikh A, 2016, PROC C EMPIR METHODS, V0, PP2249, DOI 10.18653/v1/D16-1244
   Peng H, 2018, P 2018 C N AM CHAPTE, V1, P1492, DOI 10.18653/V1/N18-1135
   Peng H, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2037, DOI 10.18653/v1/P17-1186
   Peng Hao, 2018, P ACL, V0, P0, DOI DOI 10.18653/V1/P18-1173
   Pollard C, 1994, HEAD DRIVEN PHRASE S, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi X, 2016, P 2016 C EMP METH NA, V0, PP1526, DOI 10.18653/V1/D16-1159
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   StephanOepen Marco Kuhlmann, 2014, P SEMEVAL, V0, P0
   StephanOepen Marco Kuhlmann, 2015, P SEMEVAL, V0, P0
   Straka Milan, 2018, P CONLL 2018 SHAR TA, V0, P0, DOI DOI 10.18653/V1/K19-2012
   Straka Milan, 2019, P MRP, V0, P0
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5027
   Surdeanu M, 2008, P 12 C COMP NAT LANG, V0, PP159, DOI 10.3115/1596324.1596352
   Swayamdipta S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3772
   Swayamdipta Swabha, 2019, ARXIV190811047, V0, P0
   Tenney Ian, 2019, INT C LEARN REPR, V0, P0
   Vu Tu, 2020, P EMNLP, V0, P0, DOI DOI 10.18653/V1/2020.EMNLP-MAIN.635
   Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5307
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Xu K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2326
   Zhang Bo, 2020, P ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.297
   Zhang Z, 2019, 34 AAAI C ARTIFICIAL, V0, PP9636, DOI 10.1609/aaai.v34i05.6511
   Zhang Zhuosheng, 2020, AAAI CONF ARTIF INTE, V0, P9628
NR 85
TC 11
Z9 11
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 226
EP 242
DI 10.1162/tacl_a_00363
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200014
DA 2023-11-10
ER

PT J
AU Panneerselvam, R
   Singaravel, G
AF Panneerselvam, R.
   Singaravel, G.
TI Efficient multi-dimensional web information discovery in wireless sensor network
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Multidimensional data; Unified Cube; Octree based Hausdorff Distance (OHD); OHD aided Unified Cube (OAUC)
ID hausdorff distance
AB The increasing availability of small-size sensor devices during the last few years and the large amount of data that they generate has led to the necessity for more efficient methods regarding data management. Here a model has been introduced that can be used for data gathering and information management in sensor networks which provides some advantages through the utilization of semantic web technologies. This work provides a multidimensional approach named an Octree-based Hausdorff Distance aided Unified Cube or OHD Aided Unified Cube (OAUC) which offers a generic representation for both warehoused data and Linked Object Data (LOD) at the conceptual level. A two-stage process is built using Unified Cube according to decision-makers' needs. Initially, the schemas published with specific modeling languages are transformed into a common conceptual representation called exportation cube. Then the associated data are combined using Hausdorff Distance (HD) to form a Unified Cube. The information discovery problem is formulated as a load balancing technique for multiple attributes, with the combined aim being to increase network lifetime, reduce hotspots and also to reduce query processing latency by introducing multi-resolution. The efficiency of the proposed OAUC is analyzed by the comparison of OAUC with existing VF-CAN indexing and storage schemes. OAUC provides better performance in Hausdorff Distance (HD) calculation that is proved by comparing it with ZHD and NAIVE algorithms.
C1 [Panneerselvam, R.] KSR Coll Engn, Dept Elect & Commun Engn, Tiruchengode 637215, India.
   [Singaravel, G.] KSR Coll Engn, Dept Informat Technol, Tiruchengode 637215, India.
RP Panneerselvam, R (通讯作者)，KSR Coll Engn, Dept Elect & Commun Engn, Tiruchengode 637215, India.
EM Panneerselvamksr43@gmail.com; singaravelg@gmai.com
CR Ahmed K, 2015, SENSORS-BASEL, V15, P5474, DOI 10.3390/s150305474
   Al Rasyid MUH, 2016, INT SEM INT TECHN IT, V0, P0
   Arora VK, 2019, J AMB INTEL HUM COMP, V10, P4963, DOI 10.1007/s12652-019-01186-5
   Atapattu S, 2011, IEEE ICC, V0, P0
   Cheng CL, 2014, INT J AUTOM COMPUT, V11, P109, DOI 10.1007/s11633-014-0772-y
   Guotao W, 2016, ICACT, V0, P0
   Hassan M, 2018, IEEE INT C INF REUS, V0, P0
   Horbaczewska G, 2012, B AUST MATH SOC, V86, P282, DOI 10.1017/S0004972711003297
   Huang SW, 2008, 2008 JOINT INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY (POWERCON) AND IEEE POWER INDIA CONFERENCE, VOLS 1 AND 2, P18
   Jiang HB, 2012, IEEE T PARALL DISTR, V23, P1668, DOI 10.1109/TPDS.2012.69
   Liao WH, 2010, IEEE IFIP NETW OP MA, V0, P0
   Mahfooz S, 2013, LIFE SCI J, V10, P1766
   Mao KJ, 2013, INT J DISTRIB SENS N, V0, P0, DOI DOI 10.1155/2013/591809
   Marcus A, 2011, THESIS, V0, P0
   Marosevic T, 2018, MATH COMMUN, V23, P247
   Ramar K, 2012, IEEE INT C ADV ENG S, V0, P0
   Ravat F, 2016, IEEE 10INT C RES CHA, V0, P0
   Song DZ, 2017, IEEE T KNOWL DATA EN, V29, P143, DOI 10.1109/TKDE.2016.2606399
   Taha AA, 2015, IEEE T PATTERN ANAL, V37, P2153, DOI 10.1109/TPAMI.2015.2408351
   Tissera M, 2014, IEEE C WIR SENS ICWI, V0, P0
   Varlan SE, 2010, ADVANTAGES SEMANTIC, V0, P417
   Zafeiropoulos A, 2009, DATA MANAGEMENT SEMA, V11, P253
   Zhang DJ, 2018, IEEE ACCESS, V6, P1350, DOI 10.1109/ACCESS.2017.2778745
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
NR 25
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD MAY 15
PY 2021
VL 12
IS 5
BP 4677
EP 4687
DI 10.1007/s12652-020-01868-5
EA MAR 2020
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA SH1JN
UT WOS:000519860400001
DA 2023-11-10
ER

PT J
AU Popa, DN
   Perez, J
   Henderson, J
   Gaussier, E
AF Popa, Diana Nicoleta
   Perez, Julien
   Henderson, James
   Gaussier, Eric
TI Towards syntax-aware token embeddings
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Token embeddings; Syntax-aware word representations; Tensor factorisation
ID models
AB Distributional semantic word representations are at the basis of most modern NLP systems. Their usefulness has been proven across various tasks, particularly as inputs to deep learning models. Beyond that, much work investigated fine-tuning the generic word embeddings to leverage linguistic knowledge from large lexical resources. Some work investigated context-dependent word token embeddings motivated by word sense disambiguation, using sequential context and large lexical resources. More recently, acknowledging the need for an in-context representation of words, some work leveraged information derived from language modelling and large amounts of data to induce contextualised representations. In this paper, we investigate Syntax-Aware word Token Embeddings (SATokE) as a way to explicitly encode specific information derived from the linguistic analysis of a sentence in vectors which are input to a deep learning model. We propose an efficient unsupervised learning algorithm based on tensor factorisation for computing these token embeddings given an arbitrary graph of linguistic structure. Applying this method to syntactic dependency structures, we investigate the usefulness of such token representations as part of deep learning models of text understanding. We encode a sentence either by learning embeddings for its tokens and the relations between them from scratch or by leveraging pre-trained relation embeddings to infer token representations. Given sufficient data, the former is slightly more accurate than the latter, yet both provide more informative token embeddings than standard word representations, even when the word representations have been learned on the same type of context from larger corpora (namely pre-trained dependency-based word embeddings). We use a large set of supervised tasks and two major deep learning families of models for sentence understanding to evaluate our proposal. We empirically demonstrate the superiority of the token representations compared to popular distributional representations of words for various sentence and sentence pair classification tasks.
C1 [Popa, Diana Nicoleta; Gaussier, Eric] Univ Grenoble Alpes, Lab Informat Grenoble, 700 Ave Cent, F-38401 St Martin Dheres, France.
   [Popa, Diana Nicoleta; Perez, Julien] Naver Labs Europe, 6 Chemin Maupertuis, F-38240 Meylan, France.
   [Henderson, James] Idiap Res Inst, 19 Rue Marconi, CH-1920 Martigny, Switzerland.
C3 UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Naver
RP Popa, DN (通讯作者)，Univ Grenoble Alpes, Lab Informat Grenoble, 700 Ave Cent, F-38401 St Martin Dheres, France.; Popa, DN (通讯作者)，Naver Labs Europe, 6 Chemin Maupertuis, F-38240 Meylan, France.
EM diana.popa@imag.fr
CR [Anonymous], 2012, P 2012 JOINT C EMPIR, V0, P0
   [Anonymous], 2014, C EMPIRICAL METHODS, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2013, P 2013 C EMPIRICAL M, V0, P0
   [Anonymous], 2017, EMNLP, V0, P0
   [Anonymous], 2016, CORR, V0, P0
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Bansal M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P809
   Baroni M, 2010, COMPUT LINGUIST, V36, P673, DOI 10.1162/coli_a_00016
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bentivogli L, 2016, LANG RESOUR EVAL, V50, P95, DOI 10.1007/s10579-015-9332-5
   Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Chen X, 2014, EMNLP, V0, PP1025, DOI 10.3115/V1/D14-1110
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1699
   Dasigi P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2089, DOI 10.18653/v1/P17-1191
   Devlin Jacob, 2018, ACL, V0, P0
   Dolan WB, 2005, P 3 INT WORKSH PAR I, V0, P0
   Faruqui Manaal, 2015, P 2015 C N AM CHAPT, V0, PP1606, DOI 10.3115/v1/N15-1184
   Gehring J, 2017, PR MACH LEARN RES, V70, P0
   Ghannay S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P300
   Grefenstette Edward, 2011, P C EMPIRICAL METHOD, V0, P1394
   Grefenstette G, 1994, EXPLORATIONS AUTOMAT, V0, P0
   Henderson J, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P103
   Honnibal Matthew, 2015, P 2015 C EMPIRICAL M, V0, PP1373, DOI 10.18653/v1/d15-1162
   Hu M, 2004, PROC 10 ACM SIGKDD I, V0, PP168, DOI 10.1145/1014052.1014073
   Irsoy O, 2014, ADV NEURAL INFORM PR, V0, PP2096, DOI 10.5555/2969033.2969061
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V28, P3, DOI 10.48550/ARXIV.1506.06726
   Lee L, 2004, ASS COMPUTATIONAL LI, V0, PP271, DOI 10.3115/1218955.1218990
   Levy O, 2014, ADV NEUR IN, V27, P0
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS
   Lin D, 1998, P 17 INT C COMPUTATI, V2, P768, DOI 10.3115/980432.980696
   Liu PF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1284
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   McCann Bryan, 2017, ADV NEURAL INFORM PR, V0, P6297
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, V0, PP51, DOI 10.18653/V1/K16-1006
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, ARXIV13013781 CS, V0, P0, DOI DOI 10.48550/ARXIV.1301.3781
   Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x
   Mrksic Nikola, 2016, NAACL HLT, V0, PP142, DOI 10.18653/V1/N16-1018
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, V0, PP1059, DOI 10.3115/V1/D14-1113
   Nickel M, 2011, ICML, V0, PP809, DOI 10.5555/3104482.3104584
   Padó S, 2007, COMPUT LINGUIST, V33, P161, DOI 10.1162/coli.2007.33.2.161
   Pang B, 2005, P ACL, V0, PP115, DOI 10.3115/1219840.1219855
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Salant Shimi, 2018, P 2018 C N AM CHAPTE, V0, P554
   Socher R, 2013, LONG PAPERS, V1, P455
   Socher R, 2012, P 2012 JOINT C EMPIR, V0, PP1201, DOI 10.1162/153244303322533223
   Socher R, 2011, P 24 INT C NEUR INF, V0, P0
   Socher R, 2010, P NIPS 2010 DEEP LEA, V0, P1
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Tang J, 2015, KDD15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1165, DOI 10.1145/2783258.2783307
   Trouillon T, 2016, PR MACH LEARN RES, V48, P0
   Tu L, 2017, ABS170602807 CORR, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Vulic I, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P56, DOI 10.18653/v1/P17-1006
   Weir D, 2016, COMPUT LINGUIST, V42, P727, DOI 10.1162/COLI_a_00265
   Westera Matthijs, 2019, P 13 INT C COMP SEM, V0, P0
   Zhao H, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P4069
NR 65
TC 0
Z9 0
U1 1
U2 1
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD NOV 15
PY 2021
VL 27
IS 6
BP 691
EP 720
DI 10.1017/S1351324920000297
PG 30
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YA3KS
UT WOS:000738237000004
DA 2023-11-10
ER

PT J
AU Zunic, A
   Corcoran, P
   Spasic, I
AF Zunic, Anastazia
   Corcoran, Padraig
   Spasic, Irena
TI Aspect-based sentiment analysis with graph convolution over syntactic dependencies
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Sentiment analysis; Natural language processing; Dependency parsing; Neural network; Graph convolutional network
ID umls
AB Aspect-based sentiment analysis is a natural language processing task whose aim is to automatically classify the sentiment associated with a specific aspect of a written text. In this study, we propose a novel model for aspectbased sentiment analysis, which exploits the dependency parse tree of a sentence using graph convolution to classify the sentiment of a given aspect. To evaluate this model in the domain of health and well-being, where this task is biased toward negative sentiment, we used a corpus of drug reviews. Specific aspects were grounded in the Unified Medical Language System, a large repository of inter-related biomedical concepts and the corresponding terminology. Our experiments demonstrated that graph convolution approach outperforms standard deep learning architectures on the task of aspect-based sentiment analysis. Moreover, graph convolution over dependency parse trees (F-score of 0.8179) outperforms the same approach over a flat sequence representation of sentences (F-score of 0.7332). These results bring the performance of sentiment analysis in health and well-being in line with the state of the art in other domains.
C1 [Zunic, Anastazia; Corcoran, Padraig; Spasic, Irena] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
C3 Cardiff University
RP Spasic, I (通讯作者)，Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
EM spasici@cardiff.ac.uk
CR [Anonymous], 2006, 100 STAT TESTS, V0, P0, DOI DOI 10.4135/9781849208499
   [Anonymous], 2008, COLING WORKSH CROSS, V0, P0
   Bao LX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P253
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, PD267, DOI 10.1093/nar/gkh061
   Chen D, 2014, P 2014 C EMPIRICAL M, V0, PP740, DOI 10.3115/V1/D14-1082
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   de Marneffe MC, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P4585
   Devlin J, 2018, ARXIV, V1, P4171
   Errica Federico, 2020, ICLR, V0, P0
   Grasser F, 2018, DH 18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, V0, PP121, DOI 10.1145/3194658.3194677
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hamilton William L, 2017, ADV NEURAL INFORM PR, V0, P1025
   Han Y, 2020, IEEE ACCESS, V8, P21314, DOI 10.1109/ACCESS.2020.2969473
   Hoang M, 2019, P 22 NORDIC C COMPUT, V0, P187
   Hu M, 2004, PROC 10 ACM SIGKDD I, V0, PP168, DOI 10.1145/1014052.1014073
   Jurafsky D, 2019, SPEECH LANGUAGE PROC, V3rd, P232
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kipf T N, 2016, ICLR, V0, P0
   Korkontzelos I, 2016, J BIOMED INFORM, V62, P148, DOI 10.1016/j.jbi.2016.06.007
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Ruder S, 2016, PROC C EMPIRICAL MET, V0, P999
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Schlichtkrull Michael, 2018, EUROPEAN SEMANTIC WE, V0, PP593, DOI 10.1007/978-3-319-93417-438
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Spasic I, 2020, JMIR MED INF, V8, P0, DOI 10.2196/17984
   Stone PJ, 1966, GEN INQUIRER COMPUTE, V0, P0
   Strapparava C, 2004, P 4 INT C LANGUAGE R, V0, P0
   Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380
   Sun K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5679
   Tran LTT, 2015, J BIOMED INFORM, V58, P19, DOI 10.1016/j.jbi.2015.08.024
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Wilson TS, 2005, PHIL EDUC, V0, PP347, DOI 10.3115/1220575.1220619
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   Yadav S, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P2790
   Yin D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3695
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2205
   Zunic A, 2020, JMIR MED INF, V8, P34, DOI 10.2196/16023
NR 44
TC 7
Z9 7
U1 1
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD SEP 15
PY 2021
VL 119
IS 
BP 
EP 
DI 10.1016/j.artmed.2021.102138
EA AUG 2021
PG 7
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA UR8WM
UT WOS:000697022300006
PM 34531007
DA 2023-11-10
ER

PT J
AU Ghosal, T
   Edithal, V
   Ekbal, A
   Bhattacharyya, P
   Chivukula, SSSK
   Tsatsaronis, G
AF Ghosal, Tirthankar
   Edithal, Vignesh
   Ekbal, Asif
   Bhattacharyya, Pushpak
   Chivukula, Srinivasa Satya Sameer Kumar
   Tsatsaronis, George
TI Is your document novel? Let attention guide you. An attention-based model for document-level novelty detection
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Document-Level Novelty Detection; Decomposable Attention; Natural Language Inference; Document Classification
ID metrics
AB Detecting, whether a document contains sufficient new information to be deemed as novel, is of immense significance in this age of data duplication. Existing techniques for document-level novelty detection mostly perform at the lexical level and are unable to address the semantic-level redundancy. These techniques usually rely on handcrafted features extracted from the documents in a rule-based or traditional feature-based machine learning setup. Here, we present an effective approach based on neural attention mechanism to detect document-level novelty without any manual feature engineering. We contend that the simple alignment of texts between the source and target document(s) could identify the state of novelty of a target document. Our deep neural architecture elicits inference knowledge from a large-scale natural language inference dataset, which proves crucial to the novelty detection task. Our approach is effective and outperforms the standard baselines and recent work on document-level novelty detection by a margin of similar to 3% in terms of accuracy.
C1 [Ghosal, Tirthankar; Edithal, Vignesh; Ekbal, Asif; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Patna 801103, Bihar, India.
   [Chivukula, Srinivasa Satya Sameer Kumar; Tsatsaronis, George] Elsevier, Amsterdam, Netherlands.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of Technology System (IIT System)
RP Ghosal, T (通讯作者)，Indian Inst Technol Patna, Patna 801103, Bihar, India.
EM tirthankar.slg@gmail.com
FU Ministry of Electronics and Information Technology (MeitY), Government of India; Visvesvaraya PhD scheme for Electronics and IT, Ministry of Electronics and Information Technology (MeitY), Government of India
CR Allan J, 2000, PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT. CIKM 2000, V0, PP374, DOI 10.1145/354756.354843
   Allan J, 1998, PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP37, DOI 10.1145/290941.290954
   Allan J, 2001, ARDA WORKSH LANG MOD ARDA WORKSH LANG MOD, V0, P0
   Allan J, 2003, P 26 ANN INT ACM SIG, V0, PP314, DOI 10.1145/860435.860493
   [Anonymous], 2003, NIST SPECIAL PUBLICA, V0, P0
   [Anonymous], 2006, ACL WORKSHOP GRAPH B, V0, P0
   [Anonymous], 2004, P 13 TEXT RETRIEVAL, V0, P0
   [Anonymous], 2001, P 1 INT C HUM LANG T, V0, P0
   [Anonymous], 2002, P 8 ACM SIGKDD INT C, V0, P0, DOI DOI 10.1145/775047.775150
   [Anonymous], 2003, C RES DEV INFORM RET, V0, P0
   [Anonymous], 2017, P 2017 C EMP METH NA, V0, P0
   [Anonymous], 2005, P 14 ACM INT C INFOR, V0, P0, DOI DOI 10.1145/1099554.1099734
   [Anonymous], 1998, C RES DEV INFORM RET, V0, P0
   [Anonymous], 1999, P WORKSH COR ITS APP, V0, P0
   [Anonymous], 2003, TREC, V0, P0
   Arora S, 2016, 5 INT C LEARN REPR 2 5 INT C LEARN REPR 2, V0, P0
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Bentivogli Luisa, 2011, TAC, V0, P0
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Bysani P, 2010, P NAACL HLT 2010 STU, V0, P13
   Carbonell J, 1998, PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP335, DOI 10.1145/290941.291025
   Carpenter GA, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, P1459, DOI 10.1109/ICNN.1997.614010
   Cer D, 2018, P EMNLP, V0, P169
   Chandar P, 2013, SIGIR13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P413
   Clarke CLA, 2011, WSDM, V0, P0
   Clarke CLA, 2008, SIGIR, V0, P0
   Collins-Thompson K, 2002, TREC, V0, P0
   Dagan Ido, 2013, SYNTHESIS LECT HUMAN, V0, P0, DOI DOI 10.2200/S00509ED1V01Y201305HLT023
   Dasgupta D, 1996, P 5 INT C INTELLIGEN, V0, P82
   Dasgupta Tirthankar, 2016, KNOWLEDGE EXTRACTION, V0, P6
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Franz Martin, 2001, TOPIC DETECTION TRAC, V0, P193
   Gabrilovich Evgeniy, 2004, P 13 INT C WORLD WID, V0, PP482, DOI 10.1145/988672.988738
   Ghosal T, 2018, P 27 INT C COMP LING, V0, P2802
   Ghosal Tirthankar, 2018, P 11 INT C LANG RES, V0, P0
   Guh RS, 1999, ARTIF INTELL ENG, V13, P413, DOI 10.1016/S0954-1810(99)00022-9
   Harman D, 2002, P 11 TEXT RETRIEVAL P 11 TEXT RETRIEVAL, V0, P0
   Karkali M, 2013, LECT NOTES COMPUT SC, V8180, P57, DOI 10.1007/978-3-642-41230-1_5
   King SP, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON CONTROL APPLICATIONS, VOLS 1 & 2, P221, DOI 10.1109/CCA.2002.1040189
   Kwee AT, 2009, LECT NOTES ARTIF INT, V5476, P40, DOI 10.1007/978-3-642-01307-2_7
   Lai Alice, 2017, P 8 INT JOINT C NATU, V1, P100
   Le Q, 2014, INT C MACHINE LEARNI, V32, P0, DOI 10.1145/2740908.2742760
   Lee Sungjin, 2015, P 2015 C EMP METH NA, V0, P0
   Lin Z, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Manikopoulos C, 2002, IEEE COMMUN MAG, V40, P76, DOI 10.1109/MCOM.2002.1039860
   Mishra S, 2016, D LIB MAGAZINE, V22, P0
   Mou L, 2015, ABS151208422 CORR ABS151208422 CORR, V0, P0
   Parikh A, 2016, PROC C EMPIR METHODS, V0, PP2249, DOI 10.18653/v1/D16-1244
   Ru Liyun, 2004, TREC, V0, P0
   Schiffman Barry, 2005, P C HUMAN LANGUAGE T, V0, P716
   Soboroff I, 2005, P C HUM LANG TECHN E, V0, P105
   Tang WY, 2010, EXPERT SYST APPL, V37, P5172, DOI 10.1016/j.eswa.2009.12.075
   Tarassenko L, 1995, FOURTH INTERNATIONAL CONFERENCE ON `ARTIFICIAL NEURAL NETWORKS (CONF. PUBL. NO.409), V0, PP442, DOI 10.1049/cp:19950597
   Tax DMJ, 1998, ADVANCES IN PATTERN RECOGNITION. JOINT IAPR INTERNATIONAL WORKSHOPS SSPR98 AND SPR98. PROCEEDINGS, V0, PP593, DOI 10.1007/BFb0033283
   Tsai FS, 2011, KNOWL INF SYST, V29, P419, DOI 10.1007/s10115-010-0372-2
   Tsai FS, 2010, INFORM SCIENCES, V180, P2359, DOI 10.1016/j.ins.2010.02.020
   Verheij A, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P431, DOI 10.1109/WI-IAT.2012.128
   Wang X, 2016, ABS160509090 CORR, V0, P0
   Wayne CL, 2022, WORKSH HELD U MAR, V27, P28
   Yi Zhang, 2002, PROCEEDINGS OF SIGIR 2002. TWENTY-FIFTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P81
   Zhang Y, 2009, ESAIR 2009, V0, PP30, DOI 10.1145/1506250.1506256
   Zhao P, 2016, 39 INT ACM SIGIR C R, V0, P100
NR 62
TC 5
Z9 5
U1 0
U2 6
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUL 15
PY 2021
VL 27
IS 4
BP 427
EP 454
DI 10.1017/S1351324920000194
PG 28
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA TH4CY
UT WOS:000672040700002
DA 2023-11-10
ER

PT J
AU Zeng, W
   Fan, G
   Sun, S
   Geng, B
   Wang, WY
   Li, JC
   Liu, WB
AF Zeng, Wei
   Fan, Ge
   Sun, Shan
   Geng, Biao
   Wang, Weiyi
   Li, Jiacheng
   Liu, Weibo
TI Collaborative filtering via heterogeneous neural networks
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Collaborative filtering; Deep learning; Neural networks; Matrix factorization
AB Over the last few years, the deep neural network is utilized to solve the collaborative filtering problem, a method of which has achieved immense success on computer vision, speech recognition as well as natural language processing. On one hand, the deep neural network can be used to capture the side information of users and items. On the other hand, it is also capable of modeling interactions between users and items. Most of existing approaches exploit the neural network with solo structure to model user-item interactions such that the learning representation may be insufficient over the extremely sparse rating data. Recently, a large number of neural networks with mixed structures are devised for learning better representations. A carefully designed hybrid network is able to achieve considerable accuracy but only requires a small amount of extra computation. In order to model user-item interactions, we elaborate a hybrid neural network consisting of the global neural network and several local neural blocks. The multi-layer perceptron is adopted to build the global neural network and the residual network is used to form the local neural block which is inserted into two adjacent global layers. The hybrid network is further combined with the generalized matrix factorization to capture both the linear and nonlinear relationships between users and items. It is verified by experimental results on benchmark datasets that our method is superior to certain state-of-the-art approaches in terms of top-n item recommendation. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Zeng, Wei; Fan, Ge; Sun, Shan; Wang, Weiyi; Li, Jiacheng; Liu, Weibo] Univ Elect Sci & Technol China, Ctr Artificial Intelligence & Smart Hlth, Chengdu, Peoples R China.
   [Geng, Biao] Carnegie Mellon Univ, Coll Engn, Pittsburgh, PA 15213 USA.
   [Fan, Ge] Tencent Inc, Lightspeed & Quantum Studios, Shenzhen, Peoples R China.
C3 University of Electronic Science & Technology of China; Carnegie Mellon University; Tencent
RP Zeng, W (通讯作者)，Univ Elect Sci & Technol China, Ctr Artificial Intelligence & Smart Hlth, Chengdu, Peoples R China.
EM zwei504@uestc.edu.cn; fange@std.uestc.edu.cn; sunshan0813@hotmail.com; bgeng@andrew.cmu.edu; wwy@std.uestc.edu.cn; jiachengli@std.uestc.edu.cn; Weiboliu@std.uestc.edu.cn
FU National Natural Science Foun-dation of China [61806045, 61806043, 61872062]; Funda-mental Research Funds for the Central Universities, China [2672018ZYGX2018J050]
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2015, DEEP COLLABORATIVE F, V0, P0, DOI DOI 10.1145/2806416.2806527
   [Anonymous], 2015, ADV NEURAL INFORM PR, V0, P0
   [Anonymous], 2007, P 24 INT C MACHINE L, V0, P0
   Bayer I, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1341, DOI 10.1145/3038912.3052694
   Chen WY, 2019, ACM T INFORM SYST, V37, P0, DOI 10.1145/3343117
   Cheng H-T, 2016, P 1 WORKSHOP DEEP LE, V0, PP7, DOI 10.1145/2988450.2988454
   Davidson James, 2010, P 4 ACM C REC SYST, V0, PP293, DOI 10.1145/1864708.1864770
   Dong X, 2017, AAAI CONF ARTIF INTE, V0, P1309
   Elkahky A, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), V0, PP278, DOI 10.1145/2736277.2741667
   Glorot Xavier, 2011, P 14 INT C ART INT S, V0, PP315, DOI 10.1002/ECS2.1832
   Gomez-Uribe CA, 2016, ACM TRANS MANAG INF, V6, P0, DOI 10.1145/2843948
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16), V0, PP507, DOI 10.1145/2872427.2883037
   He XN, 2018, IEEE T KNOWL DATA EN, V30, P2354, DOI 10.1109/TKDE.2018.2831682
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP549, DOI 10.1145/2911451.2911489
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/TPAMI.2019.2913372
   Hu YF, 2008, IEEE DATA MINING, V0, PP263, DOI 10.1109/ICDM.2008.22
   Jaderberg M, 2015, ADV NEUR IN, V28, P0
   Kang Z, 2017, NEUROCOMPUTING, V267, P210, DOI 10.1016/j.neucom.2017.06.005
   King DB, 2015, ACS SYM SER, V1214, P1
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lian JX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3805
   Lin MPH, 2014, DES AUT CON, V0, P0, DOI DOI 10.1145/2593069.2593179
   Liu DH, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP344, DOI 10.1145/3292500.3330906
   Mnih Andriy, 2008, NEURIPS, V0, P0
   Qu YR, 2019, ACM T INFORM SYST, V37, P0, DOI 10.1145/3233770
   Rendle S, 2009, P 25 C UNC ART INT U, V0, P452
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, V0, PP1, DOI 10.1007/978-0-387-85820-3_1
   Sarwar B, 2001, P 10 INT C WORLD WID, V0, PP285, DOI 10.1145/371920.372071
   Sedhain S, 2015, WWW15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP111, DOI 10.1145/2740908.2742726
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tay Y, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP729, DOI 10.1145/3178876.3186154
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang DX, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1225, DOI 10.1145/2939672.2939753
   Weston J, 2015, P INT C LEARN REPR, V0, P1
   Wu CH, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2576, DOI 10.1145/3292500.3330665
   Xue F, 2019, ACM T INFORM SYST, V37, P0, DOI 10.1145/3314578
   Xue HJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3203
   Ye JM, 2018, PROC CVPR IEEE, V0, PP9378, DOI 10.1109/CVPR.2018.00977
   Zeng W, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep34292
   Zhou GR, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1059, DOI 10.1145/3219819.3219823
NR 45
TC 6
Z9 6
U1 1
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD SEP 15
PY 2021
VL 109
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107516
EA JUN 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA UB2AQ
UT WOS:000685652800009
DA 2023-11-10
ER

PT J
AU Wu, D
   Jing, XY
   Chen, HW
   Kong, XH
   Xuan, JF
AF Wu, Di
   Jing, Xiao-Yuan
   Chen, Haowen
   Kong, Xiaohui
   Xuan, Jifeng
TI Recommending Relevant Tutorial Fragments for API-Related Natural Language Questions
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE API tutorial; semi-supervised metric learning; natural language questions
AB Application Programming Interface (API) tutorial is an important API learning resource. To help developers learn APIs, an API tutorial is often split into a number of consecutive units that describe the same topic (i.e. tutorial fragment). We regard a tutorial fragment explaining an API as a relevant fragment of the API. Automatically recommending relevant tutorial fragments can help developers learn how to use an API. However, existing approaches often employ supervised or unsupervised manner to recommend relevant fragments, which suffers from much manual annotation effort or inaccurate recommended results. Furthermore, these approaches only support developers to input exact API names. In practice, developers often do not know which APIs to use so that they are more likely to use natural language to describe API-related questions. In this paper, we propose a novel approach, called Tutorial Fragment Recommendation (TuFraRec), to effectively recommend relevant tutorial fragments for API-related natural language questions, without much manual annotation effort. For an API tutorial, we split it into fragments and extract APIs from each fragment to build API-fragment pairs. Given a question, TuFraRec first generates several clarification APIs that are related to the question. We use clarification APIs and API-fragment pairs to construct candidate API-fragment pairs. Then, we design a semi-supervised metric learning (SML)-based model to find relevant API-fragment pairs from the candidate list, which can work well with a few labeled API-fragment pairs and a large number of unlabeled API-fragment pairs. In this way, the manual effort for labeling the relevance of API-fragment pairs can be reduced. Finally, we sort and recommend relevant API-fragment pairs based on the recommended strategy. We evaluate TuFraRec on 200 API-related natural language questions and two public tutorial datasets (Java and Android). The results demonstrate that on average TuFraRec improves NDCG@5 by 0.06 and 0.09, and improves Mean Reciprocal Rank (MRR) by 0.07 and 0.09 on two tutorial datasets as compared with the state-of-the-art approach.
C1 [Wu, Di; Jing, Xiao-Yuan; Chen, Haowen; Kong, Xiaohui; Xuan, Jifeng] Wuhan Univ, Sch Comp, Wuhan, Peoples R China.
   [Jing, Xiao-Yuan] Guangdong Univ Petrochem Technol, Sch Comp, Maoming, Peoples R China.
C3 Wuhan University; Guangdong University of Petrochemical Technology
RP Jing, XY (通讯作者)，Wuhan Univ, Sch Comp, Wuhan, Peoples R China.; Jing, XY (通讯作者)，Guangdong Univ Petrochem Technol, Sch Comp, Maoming, Peoples R China.
EM wudidi@whu.edu.cn; jingxy_2000@126.com; hwc_zzu@126.com; kongxh@whu.edu.cn; jxuan@whu.edu.cn
FU NSFC-Key Project of General Technology Fundamental Research United Fund [U1736211, 61933013]; Natural Science Foundation of Guangdong Province [2019A1515011076]; Innovation Group of Guangdong Education Department [2020KCXTD014, 2018KCXTD019]; Key Project of Natural Science Foundation of Hubei Province [2018CFA024]
CR [Anonymous], 2014, ORDINAL METHODS BEHA, V0, P0
   Baghshah MS, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), V0, P1217
   Bao LF, 2020, ACM T SOFTW ENG METH, V29, P0, DOI 10.1145/3392093
   Cai D, 2007, IEEE C COMP VIS ICCV, V0, PP1, DOI 10.1109/CVPR.2007.383054
   Chapelle Olivier, 2009, CIKM 09, V09, P0
   Chen HW, 2021, IEEE T SOFTWARE ENG, V47, P2803, DOI 10.1109/TSE.2020.2968520
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Grechanik M, 2010, PROC 32 ACMIEEE INT, V1, P475
   Gu XD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), V0, PP933, DOI 10.1145/3180155.3180167
   Huang Q, 2018, IEEE INT CONF AUTOM, V0, PP293, DOI 10.1145/3238147.3238191
   Jia XD, 2021, IEEE T PATTERN ANAL, V43, P2496, DOI 10.1109/TPAMI.2020.2973634
   Jiang H, 2017, PROC INT CONF SOFTW, V0, PP38, DOI 10.1109/ICSE.2017.12
   Jiang H, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Jing XY, 2021, IEEE T PATTERN ANAL, V43, P139, DOI 10.1109/TPAMI.2019.2929166
   Joachims T, 1999, MACHINE LEARNING, V0, P200
   Li J, 2021, IEEE T SERV COMPUT, V14, P472, DOI 10.1109/TSC.2018.2812729
   Li XC, 2020, IEEE T SOFTWARE ENG, V46, P1081, DOI 10.1109/TSE.2018.2876006
   Li ZQ, 2019, AUTOMAT SOFTW ENG, V26, P599, DOI 10.1007/s10515-019-00259-1
   Li ZQ, 2019, IEEE T SOFTWARE ENG, V45, P391, DOI 10.1109/TSE.2017.2780222
   Li ZQ, 2018, IET SOFTW, V12, P161, DOI 10.1049/iet-sen.2017.0148
   Lin B, 2019, PROC INT CONF SOFTW, V0, PP548, DOI 10.1109/ICSE.2019.00066
   Lin ZQ, 2017, IEEE INT CONF AUTOM, V0, PP123, DOI 10.1109/ASE.2017.8115625
   Lv F, 2015, IEEE INT CONF AUTOM, V0, PP260, DOI 10.1109/ASE.2015.42
   McCallum A, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P662
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Petrosyan G, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P869, DOI 10.1109/ICSE.2015.97
   Ponzanelli Luca, 2019, IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, V45, P464, DOI 10.1109/TSE.2017.2779479
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Robillard MP, 2015, EMPIR SOFTW ENG, V20, P1558, DOI 10.1007/s10664-014-9323-y
   Robillard MP, 2011, EMPIR SOFTW ENG, V16, P703, DOI 10.1007/s10664-010-9150-8
   Robillard MP, 2009, IEEE SOFTWARE, V26, P27, DOI 10.1109/MS.2009.193
   Schutze H, 2008, INTRO INFORM RETRIEV, V39, P0
   Subramanian S, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), V0, PP643, DOI 10.1145/2568225.2568313
   Nguyen T, 2018, ESEC/FSE18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP551, DOI 10.1145/3236024.3236036
   Treude C, 2015, IEEE T SOFTWARE ENG, V41, P565, DOI 10.1109/TSE.2014.2387172
   Nguyen TD, 2017, PROC INT CONF SOFTW, V0, PP438, DOI 10.1109/ICSE.2017.47
   Voorhees Ellen M, 1999, P TREC, V0, P0
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wu D, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P119, DOI 10.1109/SANER50967.2021.00020
   Wu D, 2021, EMPIR SOFTW ENG, V26, P0, DOI 10.1007/s10664-021-09962-8
   Wu D, 2020, WIRES DATA MIN KNOWL, V10, P0, DOI 10.1002/widm.1369
   Wu D, 2018, PROC IEEE ACM INT C, V0, PP270, DOI 10.1145/3183440.3194965
   Xu BW, 2017, IEEE INT CONF AUTOM, V0, PP706, DOI 10.1109/ASE.2017.8115681
   Xu BW, 2016, IEEE INT CONF AUTOM, V0, PP51, DOI 10.1145/2970276.2970357
   Ye X, 2016, PROC INT CONF SOFTW, V0, PP404, DOI 10.1145/2884781.2884862
   Zhang F, 2018, IEEE T SOFTWARE ENG, V44, P1070, DOI 10.1109/TSE.2017.2750682
   Zhang N, 2022, IEEE T SOFTWARE ENG, V48, P1185, DOI 10.1109/TSE.2020.3016006
   Zhao DH, 2019, PROC INT CONF SOFTW, V0, PP350, DOI 10.1109/ICSE.2019.00049
   Zhong H, 2009, IEEE INT CONF AUTOM, V0, PP307, DOI 10.1109/ASE.2009.94
NR 50
TC 0
Z9 0
U1 2
U2 15
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD SEP 15
PY 2021
VL 31
IS 09
BP 1251
EP 1275
DI 10.1142/S0218194021500406
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WA4SV
UT WOS:000702877600002
DA 2023-11-10
ER

PT J
AU Alami, N
   Meknassi, M
   En-nahnahi, N
   El Adlouni, Y
   Ammor, O
AF Alami, Nabil
   Meknassi, Mohammed
   En-nahnahi, Noureddine
   El Adlouni, Yassine
   Ammor, Ouafae
TI Unsupervised neural networks for automatic Arabic text summarization using document clustering and topic modeling
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Arabic text summarization; Natural language processing; Deep learning; Neural networks; Clustering; Topic modeling
ID nonnegative matrix factorization; relevance
AB Humans must easily handle the vast amounts of data being generated by the revolution of information technology. Thus, Automatic Text summarization has been applied to various domains in order to find the most relevant information and make critical decisions quickly. In the context of Arabic, text summarization techniques suffer from several problems. First, most existing methods do not consider the context or domain to which the document belongs. Second, the majority of the existing approaches are based on the traditional bag-of-words representation, which involves high dimensional and sparse data, and makes it difficult to capture relevant information. Third, research in Arabic Text summarization is fairly small and only recently compared to that on Anglo-Saxon and other languages due to the shortage of Arabic corpora, resources, and automatic processing tools. In this paper, we try to overcome these limitations by proposing a new approach using documents clustering, topic modeling, and unsupervised neural networks in order to build an efficient document representation model. First, a new document clustering technique using Extreme learning machine is performed on large text collection. Second, topic modeling is applied to documents collection in order to identify topics present in each cluster. Third, each document is represented in a topic space by a matrix where rows represent the document sentences and columns represent the cluster topics. The generated matrix is then trained using several unsupervised neural networks and ensemble learning algorithms in order to build an abstract representation of the document in the concept space. Important sentences are ranked and extracted according to a graph model with a redundancy elimination component. The proposed approach is evaluated on Essex Arabic Summaries Corpus and compared against other Arabic text summarization approaches using ROUGE measure. Experimental results showed that the models trained on topic representation learn better representations and improve significantly the summarization performance. In particular, ensemble learning models demonstrated an important improvement on Rouge recall and promising results on F-measure.
C1 [Alami, Nabil; Meknassi, Mohammed; En-nahnahi, Noureddine; El Adlouni, Yassine] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, LISAC Lab, POB 1796, Fes 30003, Morocco.
   [Ammor, Ouafae] Sidi Mohamed Ben Abdellah Univ, Fac Sci & Technol, Lab Modeling & Math Struct LMSM, BP 2202, Fes 30000, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah University of Fez
RP Alami, N (通讯作者)，Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, LISAC Lab, POB 1796, Fes 30003, Morocco.
EM nab.alami@gmail.com; mohammed.meknassi@usmba.ac.ma; noureddine.en-nahnahi@usmba.ac.ma; yeladlouni@gmail.com; w_ammor@yahoo.fr
CR Affeldt S, 2020, PATTERN RECOGN, V108, P0, DOI 10.1016/j.patcog.2020.107522
   Ailem M, 2017, PATTERN RECOGN, V72, P108, DOI 10.1016/j.patcog.2017.06.005
   Ailem M, 2017, IEEE T KNOWL DATA EN, V29, P1563, DOI 10.1109/TKDE.2017.2681669
   AL-Khawaldeh FT, 2015, WORLD COMPUT SCI INF, V5, P1
   Al-Omour M, 2012, THESIS YAMOUK U JORD, V0, P0
   Al-Radaideh QA, 2018, COGN COMPUT, V10, P651, DOI 10.1007/s12559-018-9547-z
   Alami N, 2019, EXPERT SYST APPL, V123, P195, DOI 10.1016/j.eswa.2019.01.037
   Alami N, 2018, ARAB J SCI ENG, V43, P7803, DOI 10.1007/s13369-018-3198-y
   Alami N, 2015, I C COMP SYST APPLIC, V0, P0
   [Anonymous], 2010, P LANGUAGE RESOURCES, V0, P0
   [Anonymous], 2006, INFORM SCIENCES, V0, P0
   [Anonymous], 2004, P WORKSH TEXT SUMM B, V0, P0
   Antiqueira L, 2009, INFORM SCIENCES, V179, P584, DOI 10.1016/j.ins.2008.10.032
   Azmi AM, 2012, COMPUT SPEECH LANG, V26, P260, DOI 10.1016/j.csl.2012.01.002
   Baralis E, 2013, INFORM SCIENCES, V249, P96, DOI 10.1016/j.ins.2013.06.046
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boudchiche M, 2017, J KING SAUD UNIV-COM, V29, P141, DOI 10.1016/j.jksuci.2016.05.002
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Carbonell J, 1998, PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP335, DOI 10.1145/290941.291025
   Chien JT, 2008, IEEE T AUDIO SPEECH, V16, P198, DOI 10.1109/TASL.2007.909452
   Chien JT, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, V0, P201
   Corizzo R, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0207-2
   Das A, 2017, ACM T ASIAN LOW-RESO, V16, P0, DOI 10.1145/3015467
   Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Douzidia FS, 2004, P DUC2004, V0, P0
   EDMUNDSON HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519
   El-Haj M, 2011, LECT NOTES COMPUT SC, V7097, P550, DOI 10.1007/978-3-642-25631-8_50
   Ester M, 1996, DENSITY BASED ALGORI, V0, P226
   Fang HY, 2015, NEUROCOMPUTING, V149, P1613, DOI 10.1016/j.neucom.2014.08.031
   Firat O, 2017, COMPUT SPEECH LANG, V45, P236, DOI 10.1016/j.csl.2016.10.006
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   He RF, 2016, INFORM SCIENCES, V349, P12, DOI 10.1016/j.ins.2016.02.032
   Heu JU, 2015, INFORM PROCESS MANAG, V51, P212, DOI 10.1016/j.ipm.2014.06.003
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hofmann T, 1999, SIGIR99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP50, DOI 10.1145/312624.312649
   Huang SD, 2020, NEUROCOMPUTING, V382, P196, DOI 10.1016/j.neucom.2019.11.070
   Huang SD, 2019, KNOWL-BASED SYST, V164, P29, DOI 10.1016/j.knosys.2018.10.003
   Ibrahim Ahmed, 2013, NATURAL LANGUAGE PROCESSING AND INFORMATION SYSTEMS. 18TH INTERNATIONAL CONFERENCE ON APPLICATIONS OF NATURAL LANGUAGE TO INFORMATION SYSTEMS, V0, P421, DOI 10.1007/978-3-642-38824-8_53
   Janani R, 2019, EXPERT SYST APPL, V134, P192, DOI 10.1016/j.eswa.2019.05.030
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Khoja S, 1999, STEMMING ARABIC TEXT, V0, P0
   Kim H, 2020, EXPERT SYST APPL, V150, P0, DOI 10.1016/j.eswa.2020.113288
   Kingma DP, 2014, ICLR 2014 C TRACK P, V0, P0
   Larkey LS, 2007, TEXT SPEECH LANG TEC, V38, P221
   Lloret E, 2012, ARTIF INTELL REV, V37, P1, DOI 10.1007/s10462-011-9216-z
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   MacQueen J, 1967, P 5 BERKELEY S MATH, V0, P281
   Mashechkin IV, 2011, PROGRAM COMPUT SOFT+, V37, P299, DOI 10.1134/S0361768811060041
   Mihalcea R, 1900, P404, V0, P0, DOI DOI 10.5555/1613715
   Oufaida H, 2014, J KING SAUD UNIV-COM, V26, P450, DOI 10.1016/j.jksuci.2014.06.008
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Saad MK, 2010, P 6 INT C ELECT COMP, V0, P118
   Nguyen-Hoang TA, 2012, J AMB INTEL HUM COMP, V3, P305, DOI 10.1007/s12652-012-0143-x
   Xiong SF, 2018, NEUROCOMPUTING, V275, P2459, DOI 10.1016/j.neucom.2017.11.023
   Yao KC, 2018, NEUROCOMPUTING, V284, P52, DOI 10.1016/j.neucom.2018.01.020
   Yousefi-Azar M, 2017, EXPERT SYST APPL, V68, P93, DOI 10.1016/j.eswa.2016.10.017
   Yu J, 2018, SIGNAL PROCESS, V143, P346, DOI 10.1016/j.sigpro.2017.07.009
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zhong S, 2005, IEEE IJCNN, V0, P3180
   Zhong SH, 2015, EXPERT SYST APPL, V42, P8146, DOI 10.1016/j.eswa.2015.05.034
NR 61
TC 12
Z9 12
U1 1
U2 40
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JUN 15
PY 2021
VL 172
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.114652
EA FEB 2021
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA RC8LM
UT WOS:000633045400001
DA 2023-11-10
ER

PT J
AU Lin, Y
   Guo, DY
   Zhang, JW
   Chen, ZM
   Yang, B
AF Lin, Yi
   Guo, Dongyue
   Zhang, Jianwei
   Chen, Zhengmao
   Yang, Bo
TI A Unified Framework for Multilingual Speech Recognition in Air Traffic Control Systems
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Hidden Markov models; Task analysis; Atmospheric modeling; Speech recognition; Vocabulary; Decoding; Real-time systems; Acoustic model (AM); air traffic control (ATC); machine translation pronunciation model (PM); multiscale CNN (MCNN); multilingual; robust speech recognition
ID deep neural-networks
AB This work focuses on robust speech recognition in air traffic control (ATC) by designing a novel processing paradigm to integrate multilingual speech recognition into a single framework using three cascaded modules: an acoustic model (AM), a pronunciation model (PM), and a language model (LM). The AM converts ATC speech into phoneme-based text sequences that the PM then translates into a word-based sequence, which is the ultimate goal of this research. The LM corrects both phoneme- and word-based errors in the decoding results. The AM, including the convolutional neural network (CNN) and recurrent neural network (RNN), considers the spatial and temporal dependences of the speech features and is trained by the connectionist temporal classification loss. To cope with radio transmission noise and diversity among speakers, a multiscale CNN architecture is proposed to fit the diverse data distributions and improve the performance. Phoneme-to-word translation is addressed via a proposed machine translation PM with an encoder-decoder architecture. RNN-based LMs are trained to consider the code-switching specificity of the ATC speech by building dependences with common words. We validate the proposed approach using large amounts of real Chinese and English ATC recordings and achieve a 3.95% label error rate on Chinese characters and English words, outperforming other popular approaches. The decoding efficiency is also comparable to that of the end-to-end model, and its generalizability is validated on several open corpora, making it suitable for real-time approaches to further support ATC applications, such as ATC prediction and safety checking.
C1 [Lin, Yi; Guo, Dongyue; Zhang, Jianwei; Chen, Zhengmao; Yang, Bo] Sichuan Univ, Coll Comp Sci, Chengdu 610000, Peoples R China.
C3 Sichuan University
RP Yang, B (通讯作者)，Sichuan Univ, Coll Comp Sci, Chengdu 610000, Peoples R China.
EM yilin@scu.edu.cn; 2017226049015@stu.scu.edu.cn; zhangjianwei@scu.edu.cn; chengzhengmao@scu.edu.cn; boyang@scu.edu.cn
FU National Science Foundation of China (NSFC); Civil Aviation Administration of China (CAAC) [U1833115]
CR Abe A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2849
   Amodei D, 2016, PR MACH LEARN RES, V48, P0
   [Anonymous], 2010, MAN IMPL ICAO LANG P, V2nd, P0
   [Anonymous], 2015, THCHS 30 FREE CHINES, V0, P0
   ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679
   Aymen M, 2011, 2011 INT C COMMUNICA, V0, PP1, DOI 10.1109/CCCA.2011.6031408
   Bahl LR, 1986, ICASSP 86 PROCEEDINGS. IEEE-IECEJ-ASJ INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P49
   Beerends JG, 2002, J AUDIO ENG SOC, V50, P765
   Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Chan W, 2016, INT CONF ACOUST SPEE, V0, PP4960, DOI 10.1109/ICASSP.2016.7472621
   Chen S, 2014, PROC HUM FACTORS ERG, V58, P82, DOI 10.1177/1541931214581018
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4774, DOI 10.1109/ICASSP.2018.8462105
   DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946
   Denes P, 1959, J BRIT I RADIO ENG, V19, P219
   Deng L, 2013, INT CONF ACOUST SPEE, V0, PP6669, DOI 10.1109/ICASSP.2013.6638952
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Ferreiros J, 2012, AEROSP SCI TECHNOL, V21, P7, DOI 10.1016/j.ast.2011.05.002
   Geacar CM, 2010, PROC ICAS, V0, P1
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP273, DOI 10.1109/ASRU.2013.6707742
   Gürlük H, 2015, IEEEAAIA DIGIT AVION, V0, P0
   Helmke H, 2016, 2016 IEEE AIAA 35 DI, V0, P1
   Hershey JR, 2016, INT CONF ACOUST SPEE, V0, PP31, DOI 10.1109/ICASSP.2016.7471631
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hofbauer K, 2008, P 6 INT C LANG RES E, V0, P1
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641
   JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384
   JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159
   JUANG BH, 1991, TECHNOMETRICS, V33, P251, DOI 10.2307/1268779
   Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257, DOI 10.1109/89.568732
   Kim J, 2017, INTERSPEECH, V0, PP1591, DOI 10.21437/Interspeech.2017-477
   Kopald HD, 2013, IEEEAAIA DIGIT AVION, V0, P0
   LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x
   Li J, 2019, INTERSPEECH, V0, PP71, DOI 10.21437/Interspeech.2019-1819
   Lin Y, 2020, IEEE T INTELL TRANSP, V21, P4572, DOI 10.1109/TITS.2019.2940992
   Lin Y, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19030679
   Lippmann RP, 1989, NEURAL COMPUT, V1, P1, DOI 10.1162/neco.1989.1.1.1
   Luong M-T, 2015, P 2015 C EMP METH NA, V0, PP1412, DOI 10.18653/V1/D15-1166
   Mariño JB, 2006, COMPUT LINGUIST, V32, P527, DOI 10.1162/coli.2006.32.4.527
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP167, DOI 10.1109/ASRU.2015.7404790
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Nguyen VN, 2015, INT J COMPUT, V9, P1916
   Oualil Y, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP404, DOI 10.1109/ASRU.2017.8268964
   Panayotov V, 2015, INT CONF ACOUST SPEE, V0, PP5206, DOI 10.1109/ICASSP.2015.7178964
   Pellegrini T, 2018, ARXIV181012614, V0, P0
   Prabhavalkar R, 2017, INTERSPEECH, V0, PP939, DOI 10.21437/Interspeech.2017-233
   Sainath TN, 2015, INT CONF ACOUST SPEE, V0, PP4580, DOI 10.1109/ICASSP.2015.7178838
   Sainath TN, 2013, INT CONF ACOUST SPEE, V0, PP8614, DOI 10.1109/ICASSP.2013.6639347
   Smídl L, 2018, LECT NOTES ARTIF INT, V11096, P646, DOI 10.1007/978-3-319-99579-3_66
   Soltau H, 2017, INTERSPEECH, V0, PP3707, DOI 10.21437/Interspeech.2017-1566
   Srinivasamurthy A, 2017, INTERSPEECH, V0, PP2406, DOI 10.21437/Interspeech.2017-1446
   Steve Y, 2002, HTK BOOK, V0, P0
   Stuart M, 2017, IEEE IND ELEC, V0, PP7259, DOI 10.1109/IECON.2017.8217271
   Sun DX, 1999, J AM STAT ASSOC, V94, P650, DOI 10.2307/2670189
   Vintsyuk TK, 1968, CYBERNETICS, V4, P52, DOI 10.1007/BF01074755
   Watanabe S, 2017, IEEE J-STSP, V11, P1240, DOI 10.1109/JSTSP.2017.2763455
   WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088
   Yang B, 2019, ARXIV191111365, V0, P0
   Yu L, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION, V0, P1, DOI 10.1109/ICCSS.2017.8091372
   Yul D, 2017, INT CONF ACOUST SPEE, V0, PP241, DOI 10.1109/ICASSP.2017.7952154
   Zenkel T, 2017, INTERSPEECH, V0, PP513, DOI 10.21437/Interspeech.2017-1683
   Zhang Y, 2016, INTERSPEECH, V0, PP410, DOI 10.21437/Interspeech.2016-1446
NR 64
TC 55
Z9 56
U1 5
U2 31
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD AUG 15
PY 2021
VL 32
IS 8
BP 3608
EP 3620
DI 10.1109/TNNLS.2020.3015830
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA TU6UN
UT WOS:000681169500031
PM 32833649
DA 2023-11-10
ER

PT J
AU Gupta, S
   Tiwari, S
   Ortiz-Rodriguez, F
   Panchal, R
AF Gupta, Shivansh
   Tiwari, Sanju
   Ortiz-Rodriguez, Fernando
   Panchal, Ronak
TI KG4ASTRA: question answering over Indian Missiles Knowledge Graph
SO SOFT COMPUTING
LA English
DT Article
DE Query answering; Knowledge graph; Knowledge extraction; Neo4j; Cypher
AB Natural language, being unstructured, makes the tedious task for building a model to parse it into a query language successfully. An incorrect query for a particular question would lead to an absurd answer. As seen in many semantic parsing approaches, the inaccurate answering of complex questions increases significantly. This leads to many novel effective strategies that can apply to semantic parsing approaches to accurately parse complex natural language questions and generate an appropriate answer over a large knowledge graph. The defense system in a particular country is one of the most crucial components, and the lack of a proper defensive domain interface makes it a significant motivation. Hence, a knowledge graph has been constructed to collect and enquire about all information in one place. In this paper, KG4ASTRA has been designed with a Missile Knowledge Graph consisting of 177 entities linked using 400 relationships. A query-answering model then utilizes this manually created Missile Knowledge Graph, which generates tabular or graph representation for the natural language question. Neo4j platform has been used to prepare the knowledge graph, and Cypher queries are used to execute queries. The modeled knowledge has been evaluated by executing natural language queries on KG4ASTRA query-answering model and compared the search results with other existing knowledge graphs. As of our best knowledge, neither the knowledge graph nor the question-answering model has been designed for Indian Missiles. As a future scope, the proposed knowledge graph will be connected with the existing knowledge graph and extended to automatically extract domain-specific entities.
C1 [Gupta, Shivansh] Jaypee Inst Informat Technol, Noida, India.
   [Tiwari, Sanju; Ortiz-Rodriguez, Fernando] Univ Autonoma Tamaulipas, Ciudad Victoria, Tamaulipas, Mexico.
   [Panchal, Ronak] Vidyabharti Trust Coll BCA, Bardoli, Gujarat, India.
C3 Jaypee Institute of Information Technology (JIIT); Universidad Autonoma de Tamaulipas
RP Tiwari, S (通讯作者)，Univ Autonoma Tamaulipas, Ciudad Victoria, Tamaulipas, Mexico.
EM shivanshgupta171999@gmail.com; sanju.tiwari@uat.edu.mx; ferortiz@uat.edu.mx; ronak.panchal@vtcbb.edu.in
CR Abdelkawi A, 2019, LECT NOTES COMPUT SC, V11877, P571, DOI 10.1007/978-3-030-33246-4_36
   Abujabal A, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1191, DOI 10.1145/3038912.3052583
   Blomqvist E, 2020, KNOWLEDGE GRAPHS, V0, P0
   Bordes Antoine, 2014, MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES. EUROPEAN CONFERENCE, V0, P165, DOI 10.1007/978-3-662-44848-9_11
   Chen YZ, 2019, LECT NOTES COMPUT SC, V11448, P533, DOI 10.1007/978-3-030-18590-9_81
   Dubey M, 2016, LECT NOTES COMPUT SC, V9678, P300, DOI 10.1007/978-3-319-34129-3_19
   Gaurav D, 2021, EMERG TECHNOL DATA M, V3, P11
   Gaurav D, 2020, SOFT COMPUT, V24, P9625, DOI 10.1007/s00500-019-04473-7
   Gharibi M, 2020, FRONT BIG DATA, V3, P0, DOI 10.3389/fdata.2020.00012
   Goyal A, 2020, KNOWL GRAPH SEM WEB, V0, P0
   Graefe G, 1993, PROCEEDINGS. NINTH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (CAT. NO.92CH3258-1), V0, PP209, DOI 10.1109/ICDE.1993.344061
   Gubichev A, 2015, THESIS TU MUNCHEN, V0, P0
   Lin ZQ, 2017, J COMPUT SCI TECH-CH, V32, P242, DOI 10.1007/s11390-017-1718-y
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Mishra Sanju, 2019, INTERNATIONAL JOURNAL OF WEB-BASED LEARNING AND TEACHING TECHNOLOGIES, V14, P55, DOI 10.4018/IJWLTT.2019070105
   Moerkotte Guido, 2008, SIGMOD, V0, P539
   Neumann T, 2011, PROC VLDB ENDOW, V4, P539, DOI 10.14778/2002938.2002940
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Powers DM, 2011, EVALUATION PRECISION, V2, P37, DOI 10.48550/arXiv.2010.16061
   Ruan T, 2019, BMC MED INFORM DECIS, V19, P0, DOI 10.1186/s12911-019-0798-8
   Selinger Patricia, 1979, P 1979 ACM SIGMOD IN, V0, PP23, DOI 10.1145/582095.582099
   Sheng Ming, 2020, WEB INFORMATION SYSTEMS AND APPLICATIONS. 17TH INTERNATIONAL CONFERENCE, V0, P215, DOI 10.1007/978-3-030-60029-7_20
   Tiwari S, 2021, SOFT COMPUT, V25, P8337, DOI 10.1007/s00500-021-05756-8
   Unger C, 2012, P 21 INT C WORLD WID, V0, PP639, DOI 10.1145/2187836.2187923
   Villazon-Terrazas B, 2020, KNOWLEDGE GRAPHS SEM, V0, P0
   Walter Sebastian, 2012, THE SEMANTIC WEB. 11TH INTERNATIONAL SEMANTIC WEB CONFERENCE (ISWC 2012). PROCEEDINGS, V0, PP362, DOI 10.1007/978-3-642-35173-0_25
   Wang HW, 2018, CIKM18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP417, DOI 10.1145/3269206.3271739
   Xu K, 2015, LECT NOTES COMPUT SC, V9283, P414, DOI 10.1007/978-3-319-24027-5_43
   Yahya M, 2012, P 2012 JOINT C EMPIR, V0, P379
   Yao XC, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P956
   Zou L, 2014, SIGMOD14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP313, DOI 10.1145/2588555.2610525
NR 31
TC 2
Z9 2
U1 5
U2 33
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD NOV 15
PY 2021
VL 25
IS 22
BP 13841
EP 13855
DI 10.1007/s00500-021-06233-y
EA SEP 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA WL6HB
UT WOS:000702246200002
DA 2023-11-10
ER

PT J
AU Victoria, AH
   Maragatham, G
AF Victoria, A. Helen
   Maragatham, G.
TI Automatic tuning of hyperparameters using Bayesian optimization
SO EVOLVING SYSTEMS
LA English
DT Article
DE Hyperparameters; Optimization; CIFAR-10; Black box function
AB Deep learning is a field in artificial intelligence that works well in computer vision, natural language processing and audio recognition. Deep neural network architectures has number of layers to conceive the features well, by itself. The hyperparameter tuning plays a major role in every dataset which has major effect in the performance of the training model. Due to the large dimensionality of data it is impossible to tune the parameters by human expertise. In this paper, we have used the CIFAR-10 Dataset and applied the Bayesian hyperparameter optimization algorithm to enhance the performance of the model. Bayesian optimization can be used for any noisy black box function for hyperparameter tuning. In this work Bayesian optimization clearly obtains optimized values for all hyperparameters which saves time and improves performance. The results also show that the error has been reduced in graphical processing unit than in CPU by 6.2% in the validation. Achieving global optimization in the trained model helps transfer learning across domains as well.
C1 [Victoria, A. Helen; Maragatham, G.] SRM Inst Sci & Technol, Dept Informat Technol, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Victoria, AH (通讯作者)，SRM Inst Sci & Technol, Dept Informat Technol, Chennai, Tamil Nadu, India.
EM helenvia@srmist.edu.in; maragatg@srmist.edu.in
CR ANGELOV P, 1994, INT J INTELL SYST, V9, P261, DOI 10.1002/int.4550090302
   Angelov P, 2011, INT J INTELL SYST, V26, P189, DOI 10.1002/int.20462
   [Anonymous], 2018, LETS KEEP IT SIMPLE, V0, P0
   [Anonymous], 2014, CORRELATION BUDGET C, V0, P0
   [Anonymous], 2017, 31 C NEUR INF PROC S, V0, P0
   Baruah RD, 2014, IEEE T CYBERNETICS, V44, P1619, DOI 10.1109/TCYB.2013.2291234
   Bergstra J, 2013, PROC INT C MACH LEAR, V0, PP115, DOI 10.5555/3042817.3042832
   Bergstra J, 2011, ADV NEURAL INFORM PR, V24, P1, DOI 10.5555/2986459.2986743
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Brochu E, 2010, TUTORIAL BAYESIAN OP, V0, P0
   Calandra R, 2016, ANN MATH ARTIF INTEL, V76, P5, DOI 10.1007/s10472-015-9463-9
   Dewancker I, 2015, BAYESIAN OPTIMIZATIO, V0, P0
   Du GM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), V0, PP708, DOI 10.1109/SIPROCESS.2016.7888355
   Erhan D, 2014, PROC CVPR IEEE, V0, PP2155, DOI 10.1109/CVPR.2014.276
   Feurer M, 2019, SPRING SER CHALLENGE, V0, PP113, DOI 10.1007/978-3-030-05318-5_6
   Le HT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P2961, DOI 10.1109/ICASSP.2018.8461847
   Joy TT, 2016, INT C PATT RECOG, V0, PP2574, DOI 10.1109/ICPR.2016.7900023
   Knudde N, 2018, 2018 IEEE MTT-S INTERNATIONAL CONFERENCE ON NUMERICAL ELECTROMAGNETIC AND MULTIPHYSICS MODELING AND OPTIMIZATION (NEMO), V0, P0
   Kramer O, 2011, STUD COMPUT INTELL, V356, P61
   Lorenzo PR, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCO17 COMPANION), V0, PP1864, DOI 10.1145/3067695.3084211
   Lyu WL, 2018, IEEE T CIRCUITS-I, V65, P1954, DOI 10.1109/TCSI.2017.2768826
   Mantovani RG, 2015, IEEE P INT JOINT C N, V0, P1
   Marchant R, 2012, IEEE INT C INT ROBOT, V0, PP2242, DOI 10.1109/IROS.2012.6385653
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Snoek J, 2012, ADV NEURAL INFORM PR, V25, P2951
NR 27
TC 102
Z9 104
U1 15
U2 57
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-6478
EI 1868-6486
J9 EVOL SYST-GER
JI Evol. Syst.
PD MAR 15
PY 2021
VL 12
IS 1
BP 217
EP 223
DI 10.1007/s12530-020-09345-2
EA MAY 2020
PG 7
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RF2XW
UT WOS:000535386600001
DA 2023-11-10
ER

PT J
AU Shi, YK
   Zhang, S
   Zhou, CX
   Liang, XD
   Yang, XJ
   Lin, L
AF Shi, Yukai
   Zhang, Sen
   Zhou, Chenxing
   Liang, Xiaodan
   Yang, Xiaojun
   Lin, Liang
TI GTAE: Graph Transformer-Based Auto-Encoders for Linguistic-Constrained Text Style Transfer
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE Text style transfer; graph neural network; natural language processing
AB Non-parallel text style transfer has attracted increasing research interests in recent years. Despite successes in transferring the style based on the encoder-decoder framework, current approaches still lack the ability to preserve the content and even logic of original sentences, mainly due to the large unconstrained model space or too simplified assumptions on latent embedding space. Since language itself is an intelligent product of humans with certain grammars and has a limited rule-based model space by its nature, relieving this problem requires reconciling the model capacity of deep neural networks with the intrinsic model constraints from human linguistic rules. To this end, we propose a method called Graph Transformer-based Auto-Encoder, which models a sentence as a linguistic graph and performs feature extraction and style transfer at the graph level, to maximally retain the content and the linguistic structure of original sentences. Quantitative experiment results on three non-parallel text style transfer tasks show that our model outperforms state-of-the-art methods in content preservation, while achieving comparable performance on transfer accuracy and sentence naturalness.
C1 [Shi, Yukai; Yang, Xiaojun] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
   [Zhang, Sen] Univ Sydney, UBTECH Sydney AI Ctr, Sch Comp Sci, Sydney, NSW 2000, Australia.
   [Zhou, Chenxing; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.
   [Liang, Xiaodan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou, Peoples R China.
C3 Guangdong University of Technology; University of Sydney; Sun Yat Sen University; Sun Yat Sen University
RP Yang, XJ (通讯作者)，Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
EM ykshi@gdut.edu.cn; szha2609@uni.sydney.edu.au; zhouchx9@mail2.sysu.edu.cn; xdliang328@gmail.com; yangxj18@gdut.edu.cn; linliang@ieee.org
FU Technology Project of Guangdong Province [2019A050513011, 2017B090901056]; Guangzhou Science and Technology Plan Project [202002030386]; Guangdong Graduate Education Innovation Project [2020XSLT16]; National Nature Science Foundation of China [U1701266, 62002069]; Guangdong Provincial Key Laboratory of Intellectual Property and Big Data [2018B030322016]
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   [Anonymous], 2011, ACM T INTEL SYST TEC, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Chen TS, 2019, PROC CVPR IEEE, V0, PP6156, DOI 10.1109/CVPR.2019.00632
   Chen TS, 2019, IEEE T MULTIMEDIA, V21, P1022, DOI 10.1109/TMM.2018.2870062
   Cucurull Guillem, 2018, INT C LEARN REPR, V0, P1
   Cui WQ, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3326166
   Dai N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5997
   Fu ZX, 2018, AAAI CONF ARTIF INTE, V0, P663
   Gatys LA, 2016, PROC CVPR IEEE, V0, PP2414, DOI 10.1109/CVPR.2016.265
   Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572
   Gori M, 2005, IEEE IJCNN, V0, P729
   Hu Z, 2017, PR MACH LEARN RES, V0, P0
   Hu ZT, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), V0, P13
   Jin Zhijing, 2019, IMAT UNSUPERVISED TE, V0, P0
   Johnson Justin, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9906, V0, PP694, DOI 10.1007/978-3-319-46475-6_43
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kingma DP, 2014, C TRACK P, V0, P0
   Kingma DP, 2014, ADV NEURAL INFORM PR, V0, P0
   Koncel-Kedziorski R, 2019, P NAACL HLT, V0, P0
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Lample G, 2019, 7 INT C LEARN REPR I, V0, P0
   Li CY, 2019, AAAI CONF ARTIF INTE, V0, P6666
   Li J, 2018, P 2018 C N AM CHAPT, V1, P1865, DOI 10.18653/V1/N18-1169
   Li Z, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3313874
   Lin Liang, 2018, DEEP REASONING KNOWL, V0, P0
   Logeswaran Lajanugen, 2018, ADV NEUR IN, V0, P5103
   Luo FL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2013
   Luo Fuli, 2019, DUAL REINFORCEMENT L, V0, P0
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Mir Remi, 2019, EVALUATING STYLE TRA, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pele O, 2009, IEEE I CONF COMP VIS, V0, PP460, DOI 10.1109/ICCV.2009.5459199
   Prabhumoye S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P866
   Rossi RA, 2018, ACM T INTEL SYST TEC, V9, P0, DOI 10.1145/3200764
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, V0, PP59, DOI 10.1109/ICCV.1998.710701
   Shen T, 2017, ADV NEURAL INFORM PR, V30, P6830
   Shi YK, 2020, IEEE SIGNAL PROC LET, V27, P481, DOI 10.1109/LSP.2020.2978410
   Shi YK, 2020, IEEE T PATTERN ANAL, V42, P2809, DOI 10.1109/TPAMI.2019.2915301
   Shi YK, 2019, IEEE ACCESS, V7, P39660, DOI 10.1109/ACCESS.2019.2906936
   Shi Y, 2017, IEEE T MULTIMEDIA, V19, P2804, DOI 10.1109/TMM.2017.2711263
   Thukral D, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3337799
   TIAN Y, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Tuzel O, 2016, P NIPS, V0, P469
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang PW, 2018, ACM T INTEL SYST TEC, V9, P0, DOI 10.1145/3151957
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   Xu Jingjing, 2018, UNPAIRED SENTIMENT T, V0, P0
   Yang XJ, 2020, PATTERN RECOGN LETT, V130, P345, DOI 10.1016/j.patrec.2018.06.024
   Yang Z, 2018, NEURIPS, V0, P0
   Yi ZL, 2017, IEEE I CONF COMP VIS, V0, PP2868, DOI 10.1109/ICCV.2017.310
   Yin ZJ, 2012, ACM T INTEL SYST TEC, V3, P0, DOI 10.1145/2337542.2337548
   Zhang C, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3230707
   Zhang Tianyi, 2019, ICLR, V0, P0
   Zhang Z, 2018, CORR, V0, P0
   Zhao J, 2018, 35 INT C MACHINE LEA, V0, P9405
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 57
TC 3
Z9 3
U1 1
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2157-6904
EI 2157-6912
J9 ACM T INTEL SYST TEC
JI ACM Trans. Intell. Syst. Technol.
PD JUL 15
PY 2021
VL 12
IS 3
BP 
EP 
DI 10.1145/3448733
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA WY9DN
UT WOS:000719577700006
DA 2023-11-10
ER

PT J
AU Ong, DC
   Soh, H
   Zaki, J
   Goodman, ND
AF Ong, Desmond C.
   Soh, Harold
   Zaki, Jamil
   Goodman, Noah D.
TI Applying Probabilistic Programming to Affective Computing
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Computational modeling; Probabilistic logic; Programming; Object oriented modeling; Cognition; Psychology; Affective computing; Affective computing; artificial intelligence; emotion theory; modeling human emotion
ID emotion; appraisal; cognition; model; principles; perception; framework; tracking
AB Affective Computing is a rapidly growing field spurred by advancements in artificial intelligence, but often, held back by the inability to translate psychological theories of emotion into tractable computational models. To address this, we propose a probabilistic programming approach to affective computing, which models psychological-grounded theories as generative models of emotion, and implements them as stochastic, executable computer programs. We first review probabilistic approaches that integrate reasoning about emotions with reasoning about other latent mental states (e.g., beliefs, desires) in context. Recently-developed probabilistic programming languages offer several key desidarata over previous approaches, such as: (i) flexibility in representing emotions and emotional processes; (ii) modularity and compositionality; (iii) integration with deep learning libraries that facilitate efficient inference and learning from large, naturalistic data; and (iv) ease of adoption. Furthermore, using a probabilistic programming framework allows a standardized platform for theory-building and experimentation: Competing theories (e.g., of appraisal or other emotional processes) can be easily compared via modular substitution of code followed by model comparison. To jumpstart adoption, we illustrate our points with executable code that researchers can easily modify for their own models. We end with a discussion of applications and future directions of the probabilistic programming approach
C1 [Ong, Desmond C.] ASTAR, Inst High Performance Comp, ASTAR Artificial Intelligence Initiat, Singapore 138632, Singapore.
   [Soh, Harold] Natl Univ Singapore, Dept Comp Sci, Singapore 117417, Singapore.
   [Zaki, Jamil] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA.
   [Goodman, Noah D.] Stanford Univ, Dept Psychol, Dept Comp Sci, Stanford, CA 94305 USA.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); National University of Singapore; Stanford University; Stanford University
RP Ong, DC (通讯作者)，ASTAR, Inst High Performance Comp, ASTAR Artificial Intelligence Initiat, Singapore 138632, Singapore.
EM desmond.c.ong@gmail.com; hsoh@comp.nus.edu.sg; jzaki@stanford.edu; ngoodman@stanford.edu
FU A*STAR Human-Centric Artificial Intelligence Programme (SERC SSF Project) [A1718g0048]; Singapore MOE AcRF Tier 1 [251RES1709]; NIH [1R01MH112560-01]; DARPA [FA8750-14-2-0009]
CR [Anonymous], 1987, INTENTIONAL STANCE, V0, P0
   [Anonymous], 2016, ARXIV161005735, V0, P0
   [Anonymous], 1997, WORDS THOUGHTS THEOR, V0, P0
   [Anonymous], 2016, YOUNG CHILDREN ADULT, V0, P0
   [Anonymous], 2014, OXFORD HDB AFFECTIVE, V0, P0
   [Anonymous], 2014, AUTOENCODING VARIATI, V0, P0
   Baker CL, 2017, NAT HUM BEHAV, V1, P0, DOI 10.1038/s41562-017-0064
   Baker CL, 2009, COGNITION, V113, P329, DOI 10.1016/j.cognition.2009.07.005
   Becker-Asano C, 2008, LECT NOTES COMPUT SC, V5208, P15
   Bingham E, 2019, J MACH LEARN RES, V20, P0
   Brave S, 2003, HUM FAC ER, V0, PP81, DOI 10.1201/b10368-6
   Broekens J, 2008, COGN SYST RES, V9, P173, DOI 10.1016/j.cogsys.2007.06.007
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241
   DMello S, 2007, IEEE INTELL SYST, V22, P53, DOI 10.1109/MIS.2007.79
   de Melo CM, 2014, J PERS SOC PSYCHOL, V106, P73, DOI 10.1037/a0034251
   Dehghani M, 2014, JUDGM DECIS MAK, V9, P104
   Devlin HC, 2016, COGNITIVE THER RES, V40, P72, DOI 10.1007/s10608-015-9720-6
   Devlin HC, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0110470
   Dias Joao, 2014, EMOTION MODELING. TOWARDS PRAGMATIC COMPUTATIONAL MODELS OF AFFECTIVE PROCESSES. LNCS 8750, V0, PP44, DOI 10.1007/978-3-319-12973-0_3
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P, 1978, MANUAL FACIAL ACTION, V0, P0
   Ellsworth PC, 2003, SER AFFECTIVE SCI, V0, P572
   Frijda NH, 1986, EMOTIONS STUDIES EMO, V0, P0
   Gerstenberg T, 2017, OXFORD HDB CAUSAL RE, V0, PP515, DOI 10.1093/OXFORDHB/9780199399550.013.28
   Gerstenberg T, 2017, PSYCHOL SCI, V28, P1731, DOI 10.1177/0956797617713053
   Gilbert D, 1998, HDB SOCIAL PSYCHOL, V0, P0, DOI DOI 10.1002/9780470561119
   Goodman N, 2018, P ADV NEURAL INFORM, V0, P0
   Goodman ND, 2016, ARXIV160802926, V0, P0
   Goodman ND, 2008, UAI, V0, PP220, DOI 10.5555/3023476.3023503
   Goodman ND, 2014, DESIGN IMPLEMENTATIO, V0, P0
   Goodman ND, 2016, TRENDS COGN SCI, V20, P818, DOI 10.1016/j.tics.2016.08.005
   Goodman ND, 2015, CONCEPTUAL MIND: NEW DIRECTIONS IN THE STUDY OF CONCEPTS, V0, P623
   Goodman ND, 2013, ACM SIGPLAN NOTICES, V48, P399, DOI 10.1145/2480359.2429117
   Goodman ND, 2013, TOP COGN SCI, V5, P173, DOI 10.1111/tops.12007
   Grice P, 1975, SYNTAX SEMANTICS, V3, P0, DOI 10.1163/9789004368811_003
   Gunes Hatice, 2010, INTERNATIONAL JOURNAL OF STRATEGIC SYNTHETIC EMOTIONS, V1, P68, DOI 10.4018/jse.2010101605
   Hoffman MD, 2013, J MACH LEARN RES, V14, P1303
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Jara-Ettinger J, 2016, TRENDS COGN SCI, V20, P589, DOI 10.1016/j.tics.2016.05.011
   Jern A, 2015, COGNITION, V142, P12, DOI 10.1016/j.cognition.2015.05.006
   Kao JT, 2016, COGNITIVE SCI, V40, P1270, DOI 10.1111/cogs.12269
   Kao JT, 2014, P NATL ACAD SCI USA, V111, P12002, DOI 10.1073/pnas.1407479111
   Kim Y, 2013, INT CONF ACOUST SPEE, V0, PP3687, DOI 10.1109/ICASSP.2013.6638346
   Koller Daphne, 2009, PROBABILISTIC GRAPHI, V0, P0
   Lake BM, 2017, BEHAV BRAIN SCI, V40, P0, DOI 10.1017/S0140525X16001837
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Levine EE, 2018, J EXP PSYCHOL GEN, V147, P702, DOI 10.1037/xge0000399
   Lin J, 1900, V2, V0, P59
   Lindquist KA, 2012, BEHAV BRAIN SCI, V35, P121, DOI 10.1017/S0140525X11000446
   Malle BF, 2006, MIND EXPLAINS BEHAV, V0, P0
   Marinier RP, 2009, COGN SYST RES, V10, P48, DOI 10.1016/j.cogsys.2008.03.004
   Marr D, 1982, VISION, V0, P0
   Marsella S, 2010, COMPUTATIONAL MODELS, V11, P21
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   MCCLOSKEY M, 1983, SCI AM, V248, P122, DOI 10.1038/scientificamerican0483-122
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   NEWCOMB T, 1958, AM SOCIOL REV, V23, P742, DOI 10.2307/2089062
   NEWELL A, 1992, BEHAV BRAIN SCI, V15, P464, DOI 10.1017/S0140525X00069740
   Ong DC, 2019, TOP COGN SCI, V11, P338, DOI 10.1111/tops.12371
   Ong DC, 2018, EMOTION, V18, P116, DOI 10.1037/emo0000309
   Ong DC, 2015, COGNITION, V143, P141, DOI 10.1016/j.cognition.2015.06.010
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Potts C, 2016, J SEMANT, V33, P755, DOI 10.1093/jos/ffv012
   Reisenzein R, 2013, IEEE T AFFECT COMPUT, V4, P246, DOI 10.1109/T-AFFC.2013.14
   Roberts J, 2013, PROBABILISTIC PROGRA, V0, P0
   ROSS LD, 1977, J PERS SOC PSYCHOL, V35, P485, DOI 10.1037/0022-3514.35.7.485
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saxe R, 2017, CURR OPIN PSYCHOL, V17, P15, DOI 10.1016/j.copsyc.2017.04.019
   Scherer KR, 2008, COGNITION EMOTION, V22, P789, DOI 10.1080/02699930701516791
   Skerry AE, 2015, CURR BIOL, V25, P1945, DOI 10.1016/j.cub.2015.06.009
   Skerry AE, 2014, COGNITION, V130, P204, DOI 10.1016/j.cognition.2013.11.002
   SMITH CA, 1993, COGNITION EMOTION, V7, P233, DOI 10.1080/02699939308409189
   Swartout W, 2006, AI MAG, V27, P96
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788
   Tran Dustin, 2017, ARXIV170103757, V0, P0
   Vallverdu Jordi, 2009, HDB RES SYNTHETIC EM, V0, P0
   Van Kleef GA, 2010, ADV EXP SOC PSYCHOL, V42, P45, DOI 10.1016/S0065-2601(10)42002-X
   Wellman HM, 2000, CHILD DEV, V71, P895, DOI 10.1111/1467-8624.00198
   WELLMAN HM, 1992, ANNU REV PSYCHOL, V43, P337, DOI 10.1146/annurev.ps.43.020192.002005
   Wierzbicka A, 1999, EMOTIONS LANGUAGES C, V0, P0, DOI DOI 10.1017/CBO9780511521256
   Wondra JD, 2015, PSYCHOL REV, V122, P411, DOI 10.1037/a0039252
   Wong Y, 2007, HDB SELF CONSCIOUS E, V0, P209
   Wu Y, 2018, CHILD DEV, V89, P649, DOI 10.1111/cdev.12759
   Wu Y, 2018, COGNITIVE SCI, V42, P850, DOI 10.1111/cogs.12548
   Yannakakis GN, 2017, INT CONF AFFECT, V0, PP248, DOI 10.1109/ACII.2017.8273608
   Yoon EJ, 2017, P 39 ANN C COGN SCI, V0, P3602
   Zaki J, 2013, PERSPECT PSYCHOL SCI, V8, P296, DOI 10.1177/1745691613475454
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 90
TC 6
Z9 6
U1 1
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
EI 
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD APR-JUN 15
PY 2021
VL 12
IS 2
BP 306
EP 317
DI 10.1109/TAFFC.2019.2905211
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA SJ8QC
UT WOS:000655791600004
PM 34055236
DA 2023-11-10
ER

PT J
AU O'Riordan, LJ
   Doyle, M
   Baruffa, F
   Kannan, V
AF O'Riordan, Lee J.
   Doyle, Myles
   Baruffa, Fabio
   Kannan, Venkatesh
TI A hybrid classical-quantum workflow for natural language processing
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE quantum computing; NLP; AI; HPC
AB Natural language processing (NLP) problems are ubiquitous in classical computing, where they often require significant computational resources to infer sentence meanings. With the appearance of quantum computing hardware and simulators, it is worth developing methods to examine such problems on these platforms. In this manuscript we demonstrate the use of quantum computing models to perform NLP tasks, where we represent corpus meanings, and perform comparisons between sentences of a given structure. We develop a hybrid workflow for representing small and large scale corpus data sets to be encoded, processed, and decoded using a quantum circuit model. In addition, we provide our results showing the efficacy of the method, and release our developed toolkit as an open software suite.
C1 [O'Riordan, Lee J.; Doyle, Myles; Kannan, Venkatesh] Irish Ctr High End Comp, Dublin, Ireland.
   [O'Riordan, Lee J.; Doyle, Myles; Kannan, Venkatesh] Natl Univ Ireland, Galway, Ireland.
   [Baruffa, Fabio] Intel Deutschland GmbH, Feldkirchen, Germany.
C3 Ollscoil na Gaillimhe-University of Galway; Intel Corporation
RP O'Riordan, LJ (通讯作者)，Irish Ctr High End Comp, Dublin, Ireland.; O'Riordan, LJ (通讯作者)，Natl Univ Ireland, Galway, Ireland.
EM lee.oriordan@ichec.ie
FU Enterprise Ireland; European Union [IP 2018 0751]; Intel
CR Aerts D, 2014, LECT NOTES COMPUT SC, V8369, P71, DOI 10.1007/978-3-642-54943-4_7
   [Anonymous], 2016, ARXIV160107195, V0, P0
   Arunachalam S, 2015, NEW J PHYS, V17, P0, DOI 10.1088/1367-2630/17/12/123010
   BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457
   Bausch J, 2019, ARXIV19090523, V0, P0
   Bird S, 2009, NATURAL LANGUAGE PRO, Vfirst, P0
   Blacoe W, 2015, LECT NOTES COMPUT SC, V8951, P41, DOI 10.1007/978-3-319-15931-7_4
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Coecke B, 2010, ARXIV10034394, V0, P0
   Coecke B, 2020, QUANTUM NATURAL LANG, V0, P0
   Coecke B, 2019, ARXIV190403478, V0, P0
   Coecke B, 2011, NEW J PHYS, V13, P0, DOI 10.1088/1367-2630/13/4/043016
   Cowtan Alexander, 2019, LEIBNIZ INT P INFORM, V135, P1, DOI 10.4230/LIPICS.TQC.2019.5
   de Felice G, 2020, P 3 ANN INT APPL CAT, V0, P0
   Di Matteo O, 2020, IEEE T QUANTUM ENG, V1, P1, DOI 10.1109/TQE.2019.2960170
   Giovannetti V, 2008, PHYS REV LETT, V100, P0, DOI 10.1103/PhysRevLett.100.160501
   Guerreschi GG, 2020, QUANTUM SCI TECHNOL, V5, P0, DOI 10.1088/2058-9565/ab8505
   Hagberg AA, 2008, P PYTH SCI C, V0, P0
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Harrow AW, 2020, ARXIV200400026, V0, P0
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jaiswal AK, 2018, P C LERN WISS DAT AN, V0, P159
   Jakob Wenzel, 2017, PYBIND11 SEAMLESS OP, V0, P0
   Lambek J, 2008, JOURNAL OF LOGIC, V0, P0
   Levy Omer, 2014, P COMPUTATIONAL NATU, V0, P0, DOI DOI 10.3115/V1/W14-1618
   McKinney W, 2010, P 9 PYTH SCI C AUST, V0, PP56, DOI 10.25080/majora-92bf1922-00a
   Mikolov T, 2013, ADV NEURAL INFORM PR, V0, PP3111, DOI 10.5555/2999792.2999959
   Mikolov T, 2013, P WORKSHOP ICLR, V0, P0
   Mitarai K, 2019, PHYS REV A, V99, P0, DOI 10.1103/PhysRevA.99.012301
   Nisbet R, 2009, HDB STAT ANAL DATA M, V0, P0, DOI DOI 10.1016/B978-0-12-374765-5.X0001-0
   ORiordan LJ, 2020, QNLP ICHEC QUANTUM N, V0, P0, DOI DOI 10.5281/zenodo.3743034
   Socher R, 2013, LONG PAPERS, V1, P455
   Tiwari P, 2018, ARXIV181004491, V0, P0
   Trugenberger CA, 2001, PHYS REV LETT, V87, P0, DOI 10.1103/PhysRevLett.87.067901
   Trugenberger CA, 2002, QUANTUM INF PROCESS, V1, P471, DOI 10.1023/A:1024022632303
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wang B, 2019, QUANTUM LIKE MODELS, V0, PP83, DOI 10.1007/978-3-030-25913-6_5
   Wang BY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1444, DOI 10.1145/3331184.3331412
   Wiebe N, 2019, ARXIV190205162, V0, P0
   Wiebe N, 2015, QUANTUM INF COMPUT, V15, P316
   Zeng W, 2016, ELECTRON P THEOR COM, V0, PP67, DOI 10.4204/EPTCS.221.8
NR 42
TC 7
Z9 7
U1 2
U2 11
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR 15
PY 2021
VL 2
IS 1
BP 
EP 
DI 10.1088/2632-2153/abbd2e
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences
SC Computer Science; Science & Technology - Other Topics
GA SQ6YW
UT WOS:000660500300016
DA 2023-11-10
ER

PT J
AU Buyuk, O
   Arslan, LM
AF Buyuk, Osman
   Arslan, Levent M.
TI Learning from mistakes: Improving spelling correction performance with automatic generation of realistic misspellings
SO EXPERT SYSTEMS
LA English
DT Article
DE deep learning; machine learning; natural language processing; neural network
AB Sequence to sequence models (seq2seq) require a large amount of labelled training data to learn the mapping between the input and output. A large set of misspelled words together with their corrections is needed to train a seq2seq spelling correction system. Low-resource languages such as Turkish usually lack such large annotated datasets. Although misspelling-reference pairs can be synthesized with a random procedure, the generated dataset may not well match to genuine human-made misspellings. This might degrade the performance in realistic test scenarios. In this paper, we propose a novel procedure to automatically introduce human-like misspellings to legitimate words in Turkish language. Generated human-like misspellings are used to improve the performance of a seq2seq spelling correction system. The proposed system consists of two separate models; a misspelling generator and a spelling corrector. The generator is trained using a relatively small number of human-made misspellings and their manual corrections. Reference words and their misspellings are used as inputs and outputs of the generator, respectively. As a result, it is trained to add realistic spelling errors to the valid words. Training data of the spelling corrector is augmented by the generator's human-like misspellings. In the experiments, we observe that the data augmentation significantly improves the spelling correction performance. Our proposed method yields 5% absolute improvement over the state-of-the-art Turkish spelling correction systems in a test set which contains human-made misspellings from Twitter messages.
C1 [Buyuk, Osman] Izmir Demokrasi Univ, Dept Elect & Elect Engn, Izmir, Turkey.
   [Arslan, Levent M.] Bogazici Univ, Dept Elect & Elect Engn, Istanbul, Turkey.
   [Arslan, Levent M.] Sestek Speech Enabled Software Technol Inc, Sestek Res & Dev Ctr, Istanbul, Turkey.
C3 Izmir Democracy University; Bogazici University
RP Buyuk, O (通讯作者)，Izmir Demokrasi Univ, Dept Elect & Elect Engn, Izmir, Turkey.
EM osman.buyuk@idu.edu.tr
FU Turkiye Bilimsel ve Teknolojik Arastirma Kurumu; America Online
CR AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855
   [Anonymous], 2007, STRUCTURE, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bi XJ, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), V0, PP2297, DOI 10.1145/2556288.2557414
   Bolucu N, 2019, IEEE SCI M EL EL BIO, V0, PP1, DOI 10.1109/EBBT.2019.8742067
   Buyuk, 2005, THESIS SABANCI U TUR, V0, P0
   Buyuk O, 2021, EXPERT SYST, V38, P0, DOI 10.1111/exsy.12692
   Büyük O, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3383200
   Büyük O, 2019, SIG PROCESS COMMUN, V0, P0, DOI DOI 10.1109/siu.2019.8806476
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4774, DOI 10.1109/ICASSP.2018.8462105
   Church KW, 1991, STAT COMP, V1, P93, DOI 10.1007/BF01889984
   CNTK, 2020, MICROSOFT COGNITIVE, V0, P0
   Çöltekin Ç, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1079
   Erdogan H, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP98, DOI 10.1109/ASRU.2005.1566516
   Etoori Pravallika, 2018, P ACL 2018 STUDENT R, V0, P146
   Fivez P, 2017, BIOM NAT LANG PROC W, V0, PP143, DOI 10.18653/V1/W17-2317
   Flor M, 2019, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, V0, P76
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hagen M, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1261, DOI 10.1145/3077136.3080749
   Hassan H, 2008, INT JOINT C NAT LANG, VII, P0
   Hassan Hany, 2013, P 51 INT C, V0, P1577
   Ince EYilmaz, 2017, INTERNATIONAL JOURNAL OF INFORMATION AND ELECTRONICS ENGINEERING, V7, P68, DOI 10.18178/ijiee.2017.7.2.663
   Kasewa S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4977
   Koskenniemi, 1983, 2 LEVEL MORPHOLOGY G, V11, P12
   Kristensson, 2017, NEURAL NETWORKS TEXT, V1, P1
   Kristensson Per Ola, 2005, P 10 INT C INT US IN, V0, PP151, DOI 10.1145/1040830.1040867
   Manning, 2015, EFFECTIVE APPROACHES, V1, P1
   MAYS E, 1991, INFORM PROCESS MANAG, V27, P517, DOI 10.1016/0306-4573(91)90066-U
   Mikolov, 2016, ENRICHING WORD VECTO, V1, P1
   Oflazer K, 1996, COMPUT LINGUIST, V22, P73
   Oflazer K, 1994, LITERARY & LINGUISTIC COMPUTING, V9, P137, DOI 10.1093/llc/9.2.137
   Rios A, 2011, LANGUAGE TECHNOLOGY, V0, P51
   Saraclar, 2008, ADV NAT LANG PROC 6, V0, P0
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Torunoglu SD, 2016, P 1 INT C TURK COMP, V1, P7
   Venugopalan S, 2015, IEEE I CONF COMP VIS, V0, PP4534, DOI 10.1109/ICCV.2015.515
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Xiang, 2016, ABSTRACTIVE TEXT SUM, V1, P1
NR 38
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD AUG 15
PY 2021
VL 38
IS 5
BP 
EP 
DI 10.1111/exsy.12692
EA MAR 2021
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA TI7FY
UT WOS:000629739600001
DA 2023-11-10
ER

PT J
AU Wang, XZ
   Gao, TY
   Zhu, ZC
   Zhang, ZY
   Liu, ZY
   Li, JZ
   Tang, J
AF Wang, Xiaozhi
   Gao, Tianyu
   Zhu, Zhaocheng
   Zhang, Zhengyan
   Liu, Zhiyuan
   Li, Juanzi
   Tang, Jian
TI KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagE Representation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M(1), a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.
C1 [Wang, Xiaozhi; Zhang, Zhengyan; Liu, Zhiyuan; Li, Juanzi] Tsinghua Univ, Dept CST, BNRist, Beijing, Peoples R China.
   [Liu, Zhiyuan; Li, Juanzi] Tsinghua Univ, Inst AI, KIRC, Beijing, Peoples R China.
   [Gao, Tianyu] Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA.
   [Zhu, Zhaocheng; Tang, Jian] Mila Quebec AI Inst, Quebec City, PQ, Canada.
   [Zhu, Zhaocheng] Univ Montreal, Montreal, PQ, Canada.
   [Tang, Jian] HEC, Montreal, PQ, Canada.
   [Tang, Jian] CIFAR AI Res Chair, Montreal, PQ, Canada.
C3 Tsinghua University; Tsinghua University; Princeton University; Universite de Montreal; Universite de Montreal; HEC Montreal
RP Liu, ZY (通讯作者)，Tsinghua Univ, Dept CST, BNRist, Beijing, Peoples R China.; Liu, ZY (通讯作者)，Tsinghua Univ, Inst AI, KIRC, Beijing, Peoples R China.; Tang, J (通讯作者)，Mila Quebec AI Inst, Quebec City, PQ, Canada.; Tang, J (通讯作者)，HEC, Montreal, PQ, Canada.; Tang, J (通讯作者)，CIFAR AI Res Chair, Montreal, PQ, Canada.
EM wangxz20@mails.tsinghua.edu.cn; tianyug@princeton.edu; zy-z19@mails.tsinghua.edu.cn; zhaocheng.zhu@umontreal.ca; liuzy@tsinghua.edu.cn; lijuanzi@tsinghua.edu.cn; jian.tang@hec.ca
FU National Key Research and Development Program of China [2018YFB1004503]; National Natural Science Foundation of China (NSFC) [U1736204, 61533018, 61772302, 61732008]; Institute for Guo Qiang, Tsinghua University [2019GQB0003]; Beijing Academy of Artificial Intelligence [BAAI2019ZD0502]; Natural Sciences and Engineering Research Council (NSERC); CanadaCIFAR AI Chair Program; Tsinghua University Initiative Scientific Research Program
CR Balazevic I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5185
   Bojchevski Aleksandar, 2018, P ICLR, V0, P0
   Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   Cao YX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P227
   Cao YX, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1623, DOI 10.18653/v1/P17-1149
   Choi E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P87
   Collobert R, 2008, P 25 INT C MACH LEAR, V0, PP160, DOI 10.1145/1390156.1390177
   Dai Andrew M, 2015, NIPS, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Gao TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6250
   Hamaguchi T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1802
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Han X, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Han X, 2018, AAAI CONF ARTIF INTE, V0, P4832
   Hayashi H, 2020, AAAI CONF ARTIF INTE, V34, P7911
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Kassner N, 2020, PROC 58 ANN M ASS CO, V0, PP7811, DOI 10.18653/v1/2020.acl-main.698
   Kazemi SM, 2018, ADV NEUR IN, V31, P0
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lin YK, 2015, AAAI CONF ARTIF INTE, V0, P2181
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   Liu Yinhan, 2019, CSCL190711692V1 CORR, V0, P0
   Logan RL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5962
   Logeswaran L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3449
   McCloskey M, 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI 10.1016/S0079-7421(08)60536-8
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P43
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Poerner Nina, 2020, FINDINGS ASS COMPUTA, V0, PP803, DOI 10.18653/V1/2020.FINDINGS-EMNLP.71
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ruize Wang, 2020, FINDINGS ASS COMPUTA, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi BX, 2018, AAAI CONF ARTIF INTE, V0, P1957
   Snell Jake, 2017, NEURIPS, V0, P0
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2895
   Sun Z, 2019, P ICLR, V0, P0
   Trouillon T, 2016, PR MACH LEARN RES, V48, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4465
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang PF, 2019, AAAI CONF ARTIF INTE, V0, P7152
   Wang Z, 2014, P 2014 C EMP METH NA, V0, PP1591, DOI 10.3115/V1/D14-1167
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Wu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6397
   Xie RB, 2016, AAAI CONF ARTIF INTE, V0, P2659
   Xiong Wenhan, 2019, P ICLR, V0, P0
   Yamada I, 2016, P 20 SIGNLL C COMP N, V0, PP250, DOI 10.18653/V1/K16-1025
   Yang BS, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1436, DOI 10.18653/v1/P17-1132
   Yang Bishan, 2015, P INT C LEARN REPR, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zaremoodi P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P656
   Zhang Y, 2017, P 2017 C EMPIRICAL M, V0, P35
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
   Zhu ZC, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2494, DOI 10.1145/3308558.3313508
NR 61
TC 103
Z9 107
U1 10
U2 35
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 176
EP 194
DI 10.1162/tacl_a_00360
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200011
DA 2023-11-10
ER

PT J
AU Capuano, N
   Greco, L
   Ritrovato, P
   Vento, M
AF Capuano, Nicola
   Greco, Luca
   Ritrovato, Pierluigi
   Vento, Mario
TI Sentiment analysis for customer relationship management: an incremental learning approach
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Customer relationship management; Hierarchical attention networks; Machine learning; Natural language processing; Sentiment analysis
AB In recent years there has been a significant rethinking of corporate management, which is increasingly based on customer orientation principles. As a matter of fact, customer relationship management processes and systems are ever more popular and crucial to facing today's business challenges. However, the large number of available customer communication stimuli coming from different (direct and indirect) channels, require automatic language processing techniques to help filter and qualify such stimuli, determine priorities, facilitate the routing of requests and reduce the response times. In this scenario, sentiment analysis plays an important role in measuring customer satisfaction, tracking consumer opinion, interacting with consumers and building customer loyalty. The research described in this paper proposes an approach based on Hierarchical Attention Networks for detecting the sentiment polarity of customer communications. Unlike other existing approaches, after initial training, the defined model can improve over time during system operation using the feedback provided by CRM operators thanks to an integrated incremental learning mechanism. The paper also describes the developed prototype as well as the dataset used for training the model which includes over 30.000 annotated items. The results of two experiments aimed at measuring classifier performance and validating the retraining mechanism are also presented and discussed. In particular, the classifier accuracy turned out to be better than that of other algorithms for the supported languages (macro-averaged f1-score of 0.89 and 0.79 for Italian and English respectively) and the retraining mechanism was able to improve the classification accuracy on new samples without degrading the overall system performance.
C1 [Capuano, Nicola] Univ Basilicata, Sch Engn, Viale Ateneo Lucano 10, I-85100 Potenza, Italy.
   [Greco, Luca; Ritrovato, Pierluigi; Vento, Mario] Univ Salerno, Dept Comp & Elect Engn & Appl Math, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
C3 University of Basilicata; University of Salerno
RP Capuano, N (通讯作者)，Univ Basilicata, Sch Engn, Viale Ateneo Lucano 10, I-85100 Potenza, Italy.
EM nicola.capuano@unibas.it; lgreco@unisa.it; pritrovato@unisa.it; mvento@unisa.it
FU Universita degli Studi della Basilicata within the CRUI-CARE Agreement; Italian Ministry for Economic Development (Ministero dello Sviluppo Economico) [F/050104/00/X32]
CR Aiken M, 2019, STUD LING LIT, V3, P0, DOI 10.22158/SLL.V3N3P253
   [Anonymous], 2008, WSDM, V0, P0
   [Anonymous], 2014, P IEEE C COMP VIS PA, V0, P0
   [Anonymous], 2012, SENTIMENT ANAL OPINI, V0, P0
   Ayyagari MR, 2019, INT J ADV COMPUT SC, V10, P51
   Baccianella S, 2010, P 7 C LANG RES EV LR, V0, P0
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Baldwin T, 2012, P ACL 2012 SYST DEM, V0, P0
   Capuano N, 2019, P 14 INT C P2P PAR G, V0, P0
   Cervantes A, 2018, 180606610V ARXIV, V0, P0
   Cichosz P, 2019, APPL MATH COMPUT SCI, V28, P787
   Coussement K, 2009, EXPERT SYST APPL, V36, P6127, DOI 10.1016/j.eswa.2008.07.021
   Doan T, 2016, 15 IEEE INT C MACH L, V0, P0
   Farris PW, 2010, MARKETING METRICS DE, V0, P0
   GANESAN S, 1994, J MARKETING, V58, P1, DOI 10.2307/1252265
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Goodfellow Ian J, 2013, P INT C LEARN REPR I, V0, P0
   Hangal S, 2011, P 24 ANN ACM S US IN, V0, P0
   Jurek A, 2015, SECURITY INFORM, V4, P0
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kotzias D, 2015, P 21 ACM SIGKDD INT, V0, P0
   Le Q, 2014, P INT C MACH LEARN, V0, P1188
   Lee PBL, 2002, P ACL 02 C EMP METH, V0, P0
   Li Z, 2016, P EUR C COMP VIS AMS, V0, P0
   Liu S, 2015, P INT C INT SYST KNO, V0, P0
   Liu SS, 2018, EXPERT SYST APPL, V99, P1, DOI 10.1016/j.eswa.2018.01.026
   Mermillod M, 2013, FRONT PSYCHOL, V4, P0, DOI 10.3389/fpsyg.2013.00504
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mishra S, 2015, P 26 ACM C HYP SOC M, V0, P0
   Moghaddam S, 2015, P EUR C INF RETR ECI, V0, P0
   Nivre J, 2016, P 10 INT C LANG RES, V0, P0
   Ofek N, 2015, P PAC AS C KNOWL DIS, V0, P0
   Park Y, 2009, P 18 ACM C INF KNOWL, V0, P0
   Peng F, 2003, P INT HLT NAACL C ED, V0, P0
   Pradhan Sameer, 2017, HDB LINGUISTIC ANNOT, V0, PP521, DOI 10.1007/978-94-024-0881-2_20
   Raschka S, 2018, 181112808 ARXIV, V0, P0
   Robins A, 1995, CONNECTION SCIENCE, V7, P123, DOI 10.1080/09540099550039318
   Rusu AA, 2016, 160604671 ARXIV, V0, P0
   Saif M, 2011, P 2 WORKSH COMP APPR, V0, P0
   Schutze H, 2008, INTRO INFORM RETRIEV, V39, P0
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Severyn A, 2015, P 38 INT ACM SIGIR C, V0, P0
   Shan GX, 2020, EXPERT SYST APPL, V147, P0, DOI 10.1016/j.eswa.2020.113198
   Sharma P, 2014, INT J ELECT CUSTOMER, V8, P0
   Smith SL, 2017, 171100489 ARXIV, V0, P0
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Tang DY, 2015, WIRES DATA MIN KNOWL, V5, P292, DOI 10.1002/widm.1171
   Van Looy A, 2016, SOCIAL MEDIA MANAGEM, V0, P133
   Yang Z, 2016, P INT NAACL HLT 2016, V0, P0
NR 49
TC 17
Z9 17
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JUN 15
PY 2021
VL 51
IS 6
BP 3339
EP 3352
DI 10.1007/s10489-020-01984-x
EA NOV 2020
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SE7YN
UT WOS:000588577700001
DA 2023-11-10
ER

PT J
AU Antonini, A
   Suárez-Figueroa, MC
   Adamou, A
   Benatti, F
   Vignale, F
   Gravier, G
   Lupi, L
AF Antonini, Alessio
   Carmen Suarez-Figueroa, Mari
   Adamou, Alessandro
   Benatti, Francesca
   Vignale, Francois
   Gravier, Guillaume
   Lupi, Lucia
TI Understanding the phenomenology of reading through modelling
SO SEMANTIC WEB
LA English
DT Article
DE Reading experience; conceptual modelling; experience ontology; digital humanities; modelling methods
ID framework
AB Large scale cultural heritage datasets and computational methods for the Humanities research framework are the two pillars of Digital Humanities (DH), a research field aiming to expand Humanities studies beyond specific sources and periods to address macro-scale research questions on broad human phenomena. In this regard, the development of machine-readable semantically enriched data models based on a cross-disciplinary "language" of phenomena is critical for achieving the interoperability of research data. This paper reports on, documents, and discusses the development of a model for the study of reading experiences as part of the EU JPI-CH project Reading Europe Advanced Data Investigation Tool (READ-IT). Through the discussion of the READ-IT ontology of reading experience, this contribution will highlight and address three challenges emerging from the development of a conceptual model for the support of research on cultural heritage. Firstly, this contribution addresses modelling for multi-disciplinary research. Secondly, this work describes the development of an ontology of reading experience, under the light of the experience of previous projects, and of ongoing and future research developments. Lastly, this contribution addresses the validation of a conceptual model in the context of ongoing research, the lack of a consolidated set of theories and of a consensus of domain experts.
C1 [Antonini, Alessio] Open Univ OU, Knowledge Media Inst KMi, Milton Keynes MK7 6AA, Bucks, England.
   [Carmen Suarez-Figueroa, Mari] Univ Politecn Madrid UPM, Ontol Engn Grp OEG, Campus Montegancedo S-N, Madrid 28660, Spain.
   [Adamou, Alessandro] NUI Galway NUIG, Insight Ctr Data Analyt, IDA Business Pk, Galway, Ireland.
   [Benatti, Francesca] Open Univ OU, Dept English & Creat Writing, Milton Keynes MK7 6AA, Bucks, England.
   [Vignale, Francois] Le Mans Univ, 3LAM, Ave Olivier Messiaen, F-72085 Le Mans, France.
   [Gravier, Guillaume] Inst Rech Informat & Syst Aleatoires IRISA, 263 Ave Gen Leclerc, F-35000 Rennes, France.
   [Lupi, Lucia] Politecn Torino, Dipartimento Interateneo Sci Progetto & Polit Ter, Viale Mattioli 39, I-10125 Turin, Italy.
   [Lupi, Lucia] Univ Turin, Viale Mattioli 39, I-10125 Turin, Italy.
C3 Universidad Politecnica de Madrid; Le Mans Universite; Universite de Rennes; Polytechnic University of Turin; University of Turin
RP Antonini, A (通讯作者)，Open Univ OU, Knowledge Media Inst KMi, Milton Keynes MK7 6AA, Bucks, England.
EM alessio.antonini@open.ac.uk
FU Reading Europe - Advanced Data Investigation Tool (READ-IT) - JPI Cultural Heritage under the European Union Horizon 2020 Research and Innovation programme [699523]; Agence Nationale de la Recherche [ANR-17-JPCH-0001-01]; Research, Development and Innovation Program from the Universidad Politectinca de Madrid (UPM) (Programa Propio de I+D+i de la UPM); project entitled "System for Evaluating and Adapting Learning Materials to the Easy-to-Read Methodology"; Agence Nationale de la Recherche (ANR) [ANR-17-JPCH-0001] Funding Source: Agence Nationale de la Recherche (ANR); AHRC [AH/S000410/1] Funding Source: UKRI
CR Adamou A, 2019, INT J DIGIT LIBRARIE, V20, P61, DOI 10.1007/s00799-018-0235-0
   [Anonymous], 1979, THEORY ACTION, V0, P0
   [Anonymous], 2012, ONTOLOGY ENG NETWORK, V0, P0
   [Anonymous], 1993, EXPERIENCING NARRATI, V0, P0, DOI DOI 10.12987/9780300159240
   [Anonymous], 2017, P 13 INT C SEMANTIC, V0, P0
   [Anonymous], 1995, FORMS MEANINGS TEXTS, V0, P0
   [Anonymous], 1995, IJCAI95 WORKSH BAS O, V0, P0
   Antonini A, 2019, MODEL READING MODELL, V0, P0
   Antonini A, 2019, P 1 INT WORKSH OP DA, V0, P0
   Antonini A, 2019, STANDING SHOULDERS G, V0, P0
   Antonini A, 2019, PROCEEDINGS OF THE 30TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT 19), V0, PP111, DOI 10.1145/3342220.3343646
   Boroditsky L, 2001, COGNITIVE PSYCHOL, V43, P1, DOI 10.1006/cogp.2001.0748
   Bortolussi M, 2007, PSYCHONARRATOLOGY, V0, P0
   Brewster C, 2004, 4 INT C LANG RES EV, V0, P641
   Calvino I, 1979, SE NOTTE DINVERNO VI, V0, P0
   Suárez-Figueroa MC, 2015, APPL ONTOL, V10, P107, DOI 10.3233/AO-150145
   DARNTON R, 1982, DAEDALUS-US, V111, P65
   Davies D, 2007, AESTHETICS LIT, V0, P0
   Eco U, 2011, LECTOR FABULA COOPER, V0, P0
   Flanders J, 2016, NEW COMPANION DIGITA, V0, P228
   Flint Kate, 1995, WOMAN READER 1837 19, V0, P0
   Gangemi A, 2005, CEUR WORKSHOP P, V166, P0
   Gibson James J, 1979, ECOLOGICAL APPROACH, V0, P0
   Guarino N, 2003, IN HAND I S, V0, P151
   Guizzardi G, 2005, THESIS, V015, P0
   Hastings J, 2011, P 2 INT C BIOM ONT I, V0, P26
   Hitchcock T, 2014, HIST BLOG, V0, P0
   Hlomani H, 2014, INT JOINT C KNOWL DI, V0, PP329, DOI 10.1007/978-3- 319- 25840-9.
   Iser W, 1979, ACT READING THEORY A, V0, P0
   Jack B, 2012, WOMAN READER, V0, P0
   Kehagias DD, 2008, P ASK IT FIN C JUN, V0, P1
   Knoell D, 2017, P GWEM 2019 COL 9 C, V0, P97
   Kuzmicová A, 2014, STYLE, V48, P275, DOI 10.5325/style.48.3.275
   Laite J, 2020, J SOC HIST, V53, P963, DOI 10.1093/jsh/shy118
   Mangen A, 2016, LITERACY, V50, P116, DOI 10.1111/lit.12086
   Mangen A, 2017, CONVERGENCE-US, V23, P166, DOI 10.1177/1354856515586042
   Marrone Gianfranco, 2001, CORPI SOCIALI PROCES, V0, P0
   MITCHELL M, 2001, RES DESIGN EXPLAINED, V0, P0
   Mussell J, 2013, HIST DIGITAL AGE, V0, P79
   Norman D, 2013, DESIGN EVERYDAY THIN, V0, P0
   Oatley K, 2002, NARRATIVE IMPACT: SOCIAL AND COGNITIVE FOUNDATIONS, V0, P39
   Putnam L, 2016, AM HIST REV, V121, P377, DOI 10.1093/ahr/121.2.377
   Rose Jonathan, 2001, INTELLECTUAL LIFE BR, V0, P0
   Stanislavski C, 1936, ACTOR PREPARES, V0, P0
   Steunebrink B, 2009, P 4 WORKSH EM COMP A, V0, P0
   Vignale F, 2019, DH 2019 ABSTRACTS, V0, P0
   Vincent David, 1993, LITERACY POPULAR CUL, V0, P0
   Willis I, 2017, RECEPTION, V0, P0
NR 50
TC 3
Z9 3
U1 1
U2 15
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1570-0844
EI 2210-4968
J9 SEMANT WEB
JI Semant. Web
PD JUN 15
PY 2021
VL 12
IS 2
BP 191
EP 217
DI 10.3233/SW-200396
PG 27
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA QB1MB
UT WOS:000613905500004
DA 2023-11-10
ER

PT J
AU Huang, HY
   Lei, M
   Feng, C
AF Huang, Heyan
   Lei, Ming
   Feng, Chong
TI Graph-based reasoning model for multiple relation extraction
SO NEUROCOMPUTING
LA English
DT Article
DE Relation extraction; Information extraction; Neural networks; Natural language processing
AB Linguistic knowledge is useful for various NLP tasks, but the difficulty lies in the representation and application. We consider that linguistic knowledge is implied in a large-scale corpus, while classification knowledge, the knowledge related to the definitions of entity and relation types, is implied in the labeled training data. Therefore, a corpus subgraph is proposed to mine more linguistic knowledge from the easily accessible unlabeled data, and sentence subgraphs are used to acquire classification knowledge. They jointly constitute a relation knowledge graph (RKG) to extract relations from sentences in this paper. On RKG, entity recognition can be regarded as a property value filling problem and relation classification can be regarded as a link prediction problem. Thus, the multiple relation extraction can be treated as a reasoning process for knowledge completion. We combine statistical reasoning and neural network reasoning to segment sentences into entity chunks and non-entity chunks, then propose a novel Chunk Graph LSTM network to learn the representations of entity chunks and infer the relations among them. The experiments on two standard datasets demonstrate our model outperforms the previous models for multiple relation extraction. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Huang, Heyan; Lei, Ming; Feng, Chong] 5 South Zhongguancun St, Beijing, Peoples R China.
RP Lei, M (通讯作者)，5 South Zhongguancun St, Beijing, Peoples R China.
EM 66529158@qq.com
FU National Key Research and Development Program of China [2016QY03D0602]; National Natural Science Foundation of China [61751201]
CR [Anonymous], 2015, P ICLR, V0, P0
   Bollegala Danushka Tarupathi, 2010, P 19 INT C WORLD WID, V0, PP151, DOI 10.1145/1772690.1772707
   Bordes A, 2011, LEARNING STRUCTURED, V0, P0
   Bunescu RC, 2005, PROC ADV NEURAL INF, V0, P171
   Daojian Zeng, 2014, P COLING 25 INT C CO, V0, P2335
   Devlin J, 2018, ARXIV, V1, P4171
   Fu TJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1409
   Gardner M, 2015, P 2015 C EMPIRICAL M, V0, PP1488, DOI 10.18653/V1/D15-1173
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Lei M, 2019, NEURAL COMPUT APPL, V31, P9113, DOI 10.1007/s00521-019-04430-3
   Li Q, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P402, DOI 10.3115/v1/p14-1038
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Luan Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3036
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Peng N, 2017, T ASSOC COMPUT LING, V5, P101, DOI 10.1162/TACL_A_00049
   Pennington CDMJeffrey, 2014, EMPIRICAL METHODS NA, V0, P1532
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Ren X, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1015, DOI 10.1145/3038912.3052708
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sanh V, 2019, P AAAI 2019 HON HAW, V0, P0
   Socher R, 2012, P 2012 JOINT C EMPIR, V0, PP1201, DOI 10.1162/153244303322533223
   Su J, 2015, EMNLP, V0, P536
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tylenda T, 2013, P 51 ANN M ASS COMPU, V0, P1488
   Vu NT, 2016, P 2016 C N AM CHAPT, V0, P0
   Wang LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1298
   Wang SL, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4461
   Wu J, 2015, IEEE T CYBERNETICS, V45, P430, DOI 10.1109/TCYB.2014.2327111
   Wu J, 2014, IEEE T KNOWL DATA EN, V26, P2382, DOI 10.1109/TKDE.2013.2297923
   Xu Y, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Yang SZ, 2008, IEEE INTL CONF CONTR, V0, P697
   Zeng Daojian, 2015, P 2015 C EMP METH NA, V0, PP1753, DOI 10.18653/V1/D15-1203
   Zheng SC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1227, DOI 10.18653/v1/P17-1113
NR 35
TC 9
Z9 9
U1 1
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 8
PY 2021
VL 420
IS 
BP 162
EP 170
DI 10.1016/j.neucom.2020.09.025
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA PI6QI
UT WOS:000601212800013
DA 2023-11-10
ER

PT J
AU Shcherban, S
   Liang, P
   Li, ZY
   Yang, C
AF Shcherban, Sergei
   Liang, Peng
   Li, Zengyang
   Yang, Chen
TI Multiclass Classification of UML Diagrams from Images Using Deep Learning
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE UML diagrams; neural network; deep learning; multiclass classification; image classification
AB Unified Modeling Language (UML) diagrams are a recognized standard modeling language for representing design of software systems. For academic research, large cases containing UML diagrams are needed. One of the challenges in collecting such datasets is automatically determining whether an image is a UML diagram or not and what type of UML diagram an image contains. In this work, we collected UML diagrams from open datasets and manually labeled them into 10 types of UML diagrams (i.e. class diagrams, activity diagrams, use case diagrams, sequence diagrams, communication diagrams, component diagrams, deployment diagrams, object diagrams, package diagrams, and state machine diagrams) and non-UML images. We evaluated the performance of seven popular neural network architectures using transfer learning on the dataset of 4706 images, including 700 class diagrams, 454 activity diagrams, 651 use case diagrams, 706 sequence diagrams, 204 communication diagrams, 208 component diagrams, 287 deployment diagrams, 207 object diagrams, 246 package diagrams, 323 state machine diagrams, and 720 non-UML images, respectively. We also proposed our neural network architecture for multiclass classification of UML diagrams. The experiment results show that Xception achieved the best performance amongst the algorithms we evaluated with a precision of 93.03%, a recall of 92.44%, and an F1-score of 92.73%. Moreover, it is possible to develop small and almost the same efficient neural network architectures, that our proposed architecture has the least parameters (around 2.4 millions) and spends the least time per image (0.0135s per image using graphics processing unit) for classifying UML diagrams with a precision of 91.25%, a recall of 90.34%, and an F1-score of 90.79%.
C1 [Shcherban, Sergei; Liang, Peng] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Li, Zengyang] Cent China Normal Univ, Sch Comp Sci, Wuhan 430079, Peoples R China.
   [Yang, Chen] Shenzhen Polytech, Sch Artificial Intelligence, Shenzhen 518000, Peoples R China.
C3 Wuhan University; Central China Normal University; Shenzhen Polytechnic University
RP Liang, P (通讯作者)，Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
EM k1myriel@yandex.ru; liangp@whu.edu.cn; zengyangli@ccnu.edu.cn; yangchen@szpt.edu.cn
FU National Key R&D Program of China [2018YFB1402800]; Natural Science Foundation of China (NSFC) [62172311]; Natural Science Foundation of Hubei Province of China [2021CFB577]
CR Ahmed J, 2020, THESIS U GOETHENBURG, V0, P0
   Aranda J, 2007, INT REQUIR ENG CONF, V0, PP39, DOI 10.1109/RE.2007.54
   Avenash R, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, V0, P0
   Bengio Y, 1998, HDB BRAIN THEORY NEU, V0, P255
   Bian W, 2019, 2019 ACM/IEEE 22ND INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS COMPANION (MODELS-C 2019), V0, PP700, DOI 10.1109/MODELS-C.2019.00106
   Bonifro FD, 2021, PEERJ COMPUT SCI, V7, P0
   Chatterjee P, 2021, PROC INT CONF SOFTW, V0, PP1260, DOI 10.1109/ICSE43902.2021.00115
   Chaudron MRV, 2012, SOFTW SYST MODEL, V11, P571, DOI 10.1007/s10270-012-0278-4
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Contributors T, 2019, TORCHVISIONMODELS, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Fu LT, 2011, COMPUT AIDED DESIGN, V43, P278, DOI 10.1016/j.cad.2010.12.011
   Geirhos Robert, 2017, ARXIV170606969, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hebig R, 2016, 19TH ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS16), V0, PP173, DOI 10.1145/2976767.2976778
   Hollemans M, 2020, NEW MOBILE NEURAL NE, V0, P0
   Howard AG, 2017, MOBILENETS EFFICIENT, V0, P0
   Howard A, 2019, IEEE I CONF COMP VIS, V0, PP1314, DOI 10.1109/ICCV.2019.00140
   Huang GL, 2017, IEEE ICC, V0, P0
   Jacobson I, 1993, OBJECT ORIENTED SOFT, V0, P0
   Jordan J, 2018, COMMON ARCHITECTURES, V0, P0
   Karasneh Bilal, 2013, 2013 39TH EUROMICRO CONFERENCE ON SOFTWARE ENGINEERING AND ADVANCED APPLICATIONS (SEAA), V0, PP134, DOI 10.1109/SEAA.2013.45
   Loussaief S, 2017, 2018 INTERNATIONAL CONFERENCE ON ADVANCED SYSTEMS AND ELECTRICAL TECHNOLOGIES (IC_ASET), V0, P6
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lynch W, 2019, COMPREHENSIVE GUIDE, V0, P0
   More P, 2012, INT J APPL INF SYST, V1, P19
   OMG, 2015, UNIFIED MODELING LAN, V0, P0
   Osman MH, 2018, EUROMICRO CONF PROC, V0, PP396, DOI 10.1109/SEAA.2018.00070
   Rashid S, 2019, AUTOMATIC CLASSIFICA, V0, P0
   Rumbaugh J, 1991, OBJECT ORIENTED MODE, V0, P0
   Shcherban S, 2021, 33 INT C SOFTW ENG K, V0, PP57, DOI 10.18293/seke2021-185
   Shcherban S, 2021, DATASET PAPER MULTIC, V0, P0, DOI DOI 10.5281/zenodo.5141007
   SunEdition, 2010, GRAPHS DAT, V0, P0
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   TensorFlow, 2019, MODULE TFKERASAPPLIC, V0, P0
   Truong Ho-Quang, 2014, 2014 21ST ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE (APSEC), V0, PP399, DOI 10.1109/APSEC.2014.65
   Usman M, 2009, INT J SOFT ENG ITS A, V3, P21
   Zoph B, 2018, PROC CVPR IEEE, V0, PP8697, DOI 10.1109/CVPR.2018.00907
NR 40
TC 1
Z9 1
U1 2
U2 9
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD DEC 15
PY 2021
VL 31
IS 11N12
BP 1683
EP 1698
DI 10.1142/S0218194021400179
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA YM3XJ
UT WOS:000746510600008
DA 2023-11-10
ER

PT J
AU Zeng, ZH
   Bhat, S
AF Zeng, Ziheng
   Bhat, Suma
TI Idiomatic Expression Identification using Semantic Compatibility
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Idiomatic expressions are an integral part of natural language and constantly being added to a language. Owing to their non-compositionality and their ability to take on a figurative or literal meaning depending on the sentential context, they have been a classical challenge for NLP systems. To address this challenge, we study the task of detecting whether a sentence has an idiomatic expression and localizing it when it occurs in a figurative sense. Prior research for this task has studied specific classes of idiomatic expressions offering limited views of their generalizability to new idioms. We propose a multi-stage neural architecture with attention flow as a solution. The network effectively fuses contextual and lexical information at different levels using word and sub-word representations. Empirical evaluations on three of the largest benchmark datasets with idiomatic expressions of varied syntactic patterns and degrees of non-compositionality show that our proposed model achieves new state-of-the-art results. A salient feature of the model is its ability to identify idioms unseen during training with gains from 1.4% to 30.8% over competitive baselines on the largest dataset.
C1 [Zeng, Ziheng; Bhat, Suma] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign
RP Zeng, ZH (通讯作者)，Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
EM zzeng13@illinois.edu; spbhat2@illinois.edu
FU IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR)-a research collaboration as part of the IBM AI Horizons Network
CR [Anonymous], 2010, P 23 INT C COMPUTATI, V0, P0
   [Anonymous], 1999, NATURE IDIOMS SYSTEM, V0, P0
   [Anonymous], 2006, P WORKSH MULT EXPR I, V0, P0
   Baldwin T, 2005, COMPUT SPEECH LANG, V19, P398, DOI 10.1016/j.csl.2005.02.004
   Baldwin T, 2010, CH CRC MACH LEARN PA, V0, P267
   Baroni M, 2009, LANG RESOUR EVAL, V43, P209, DOI 10.1007/s10579-009-9081-4
   Biddle R, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP1217, DOI 10.1145/3366423.3380198
   Bird S, 2004, P ACL INTERACTIVE PO, V0, P214
   Blunsom P, 2007, THESIS U MELBOURNE M, V0, P0
   BNC Consortium, 2007, BRIT NATL CORPUS, V0, P0
   BOBROW SA, 1973, MEM COGNITION, V1, P343, DOI 10.3758/BF03198118
   Constant M, 2017, COMPUT LINGUIST, V43, P837, DOI 10.1162/COLI_a_00302
   Cook P, 2008, P LREC WORKSH SHAR T, V0, P19
   Cordeiro S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1986
   Devlin J, 2018, ARXIV, V1, P4171
   Dong Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3393
   Evert S, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P188
   Fadaee M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P925
   Fazly A, 2009, COMPUT LINGUIST, V35, P61, DOI 10.1162/coli.08-010-R1-07-048
   Fazly Afsaneh, 2006, 11 C EUR CHAPT ASS C, V0, P0
   Feldman Anna, 2013, COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING. 14TH INTERNATIONAL CONFERENCE, V0, P435, DOI 10.1007/978-3-642-37247-6_35
   Filippova K, 2015, P 2015 C EMPIRICAL M, V0, P360
   Flor M, 2018, P 2018 C N AM CHAPT, V0, P86
   Fothergill Richard, 2012, P 1 JOINT C LEX COMP, V0, P100
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Gong HY, 2020, FIGURATIVE LANGUAGE PROCESSING, V0, P146
   Gong Hongyu, 2017, P AAAI C ART INT, V31, P0
   Green S, 2013, COMPUT LINGUIST, V39, P195, DOI 10.1162/COLI_a_00139
   Haagsma H, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P279
   Hashimoto Chikara, 2006, COLINGACL 2006 21 IN, V0, P353
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jang H, 2015, P 16 ANN M SPEC INT, V0, P384
   KATZ JJ, 1963, LANGUAGE, V39, P170, DOI 10.2307/411200
   Korkontzelos I, 2013, 2 JOINT C LEX COMP S, V0, P39
   Korkontzelos loannis, 2010, HLT NAACL, V0, P636
   Kumar T, 2020, FIGURATIVE LANGUAGE PROCESSING, V0, P116
   Kurfali Murathan, 2020, P JOINT WORKSH MULT, V0, P85
   Liu CS, 2019, AAAI CONF ARTIF INTE, V0, P6738
   Liu CS, 2017, AAAI CONF ARTIF INTE, V0, P3230
   Liu Changsheng, 2019, THESIS U PITTSBURGH, V0, P0
   Liu Pengfei, 2017, P 2017 C EMPIRICAL M, V0, P1204
   Malmi E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5054
   Mao R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3888
   McCarthy Diana, 2007, P 2007 JOINT C EMP M, V0, P369
   Moon R, 1998, FIXED EXPRESSIONS ID, V0, P0
   Nasr A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1116
   Nivre Joakim, 2004, P METH EV MULT UN RE, V0, P0
   PEARCE DARREN, 2001, P WORKSHOP WORDNET O, V0, P41
   Peng J, 2014, P 2014 C EMPIRICAL M, V0, P2019
   Peng Jing, 2016, COMMUN COMPUT PHYS, V656, P17, DOI 10.1007/978-3-319-55209
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Reddy Siva, 2011, P 5 INT JOINT C NATU, V0, P210
   Sag IA, 2002, COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING. THIRD INTERNATIONAL CONFERENCE, V0, P1
   Salton Giancarlo, 2014, P 3 WORKSHOP HYBRID, V0, PP36, DOI 10.3115/v1/W14-1007
   Salton GD, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P194
   Savary A, 2017, P 13 WORKSH MULT EXP, V0, P31
   Schneider Nathan, 2015, P 2015 C N AM CHAPT, V0, PP1537, DOI 10.3115/V1/N15-1177
   Schone P, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, P100
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Scott D, 2020, P 28 INT C COMPUTATI, V0, P627
   Seo Min Joon, 2017, 5 INT C LEARN REPR I, V0, P0
   Shutova E, 2013, COMPUT LINGUIST, V39, P301, DOI 10.1162/COLI_a_00124
   Sporleder Caroline, 2009, P 12 C EUR ACL, V0, P754
   Srivastava RK, 2015, SEV SAV STAT CAST, V0, P0
   Steen GJ, 2010, METHOD LINGUISTIC ME, V0, P0, DOI DOI 10.1075/celcr.14
   Stevenson M, 2001, COMPUT LINGUIST, V27, P321, DOI 10.1162/089120101317066104
   Su CD, 2020, FIGURATIVE LANGUAGE PROCESSING, V0, P30
   Tabossi P, 2008, J EXP PSYCHOL LEARN, V34, P313, DOI 10.1037/0278-7393.34.2.313
   Tabossi P, 2009, MEM COGNITION, V37, P529, DOI 10.3758/MC.37.4.529
   Taslimipoor Shiva, 2018, MULTIWORD EXPRESSION, V0, P299
   Westerstahl Dag, 2002, P LLC8 CSLI PUBL, V0, P0
   WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8
   Wolf T, 1900, P38, V0, P0
NR 73
TC 2
Z9 2
U1 1
U2 4
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 1546
EP 1562
DI 10.1162/tacl_a_00442
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200092
DA 2023-11-10
ER

PT J
AU Li, SB
   Wang, Q
AF Li, Shoubin
   Wang, Qing
TI A hybrid approach to recognize generic sections in scholarly documents
SO INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION
LA English
DT Article
DE Machine learning; Document structure; Natural language processing; Deep learning
AB Discourse parsing of scholarly documents is the premise and basis for standardizing the writing of scholarly documents, understanding their content, and quickly locating and extracting specific information from them. With the continuous emergence of a large number of scholarly documents, how to automatically analyze scholarly documents quickly and effectively has become a research hotspot. In this paper, we propose a hybrid model, which considers both section headers and body texts, to recognize generic sections in scholarly documents automatically. We conduct a comprehensive analysis of the semantic difference between short phrases and long narrative text chunks on the SectLabel dataset. The experimental results show that our model achieves 91.67% F-1-value in the generic section recognization, which is better than the baseline.
C1 [Li, Shoubin; Wang, Qing] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Li, Shoubin] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Software, CAS
RP Li, SB (通讯作者)，Univ Chinese Acad Sci, Beijing, Peoples R China.
EM shoubin@iscas.ac.cn; wq@iscas.ac.cn
CR Afshar, 2018, COMP STUDY GENERIC S, V0, P0
   Binmakhashen GM, 2020, ACM COMPUT SURV, V52, P0, DOI 10.1145/3355610
   Bosc T, 2016, FRONT ARTIF INTEL AP, V287, P21, DOI 10.3233/978-1-61499-686-6-21
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Cocarascu O, 2018, COMPUT LINGUIST, V44, P833, DOI 10.1162/coli_a_00338
   Constantin, 2013, P 2013 ACM S DOC ENG, V0, P0
   Dasigi, 2017, ABS170205398 ARXIV, V0, P0
   de Waard A, 2012, J ENGL ACAD PURP, V11, P357, DOI 10.1016/j.jeap.2012.06.002
   Dumais ST, 2002, SIGIR 02, V0, P0
   EIBAND M, 2018, LONG SHORT PAPERS, V0, P211
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Guo YF, 2011, BMC BIOINFORMATICS, V12, P0, DOI 10.1186/1471-2105-12-69
   Hailin, 2010, CROSS CULT COMMUN, V6, P36
   He DF, 2017, PROC INT CONF DOC, V0, PP254, DOI 10.1109/ICDAR.2017.50
   Hirohata K, 2008, P IJCNLP, V0, P0
   Hirohata K, 2008, P 3 INT JOINT C NATU, VI, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang Yong, 2016, JOURNAL OF THE CHINA SOCIETY FOR SCIENTIFIC AND TECHNICAL INFORMATION, V35, P425, DOI 10.3772/j.issn.1000-0135.2016.004.009
   Kafes, 2016, GENERIC STRUCTURE ME, V0, P0
   Kosaraju, 2019, DOCUMENT LAYOUT ANAL, V0, P0
   Li WK, 2019, FUTURE INTERNET, V11, P0, DOI 10.3390/fi11040096
   Lin, 2006, BIONLP NAACL HLT, V0, P0
   Lu Wei, 2014, JOURNAL OF THE CHINA SOCIETY FOR SCIENTIFIC AND TECHNICAL INFORMATION, V33, P979, DOI 10.3772/j.issn.1000-0135.2014.09.010
   LUONG MT, 2012, LOGICAL STRUCTURE RE, V0, P270
   Mullen T, 2005, NAT LANG PROCESS TEX, V7, P52, DOI 10.1145/1089815.1089823
   Nasar Z, 2018, SCIENTOMETRICS, V117, P1931, DOI 10.1007/s11192-018-2921-5
   Olshausen BA, 2003, J COGNITIVE NEUROSCI, V15, P154, DOI 10.1162/089892903321107891
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rahman, 2017, RHETORICAL STRUCTURE, V0, P0
   Sulistyo, 2013, ENGLISH TEACH J, V4, P0
   Teufel, 2009, DISCIPLINE INDEPENDE, V0, P0
   Teufel S, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P110
   Teufel S, 2002, COMPUT LINGUIST, V28, P409, DOI 10.1162/089120102762671936
   Tkaczyk D, 2015, INT J DOC ANAL RECOG, V18, P317, DOI 10.1007/s10032-015-0249-8
   Waard, 2008, MODELING SCI RES ART, V0, P0
   [王东波 Wang Dongbo], 2018, 情报学报 JOURNAL OF THE CHINA SOCIETY FOR SCIENTIFIC AND TECHNICAL INFORMATION, V37, P997
   WANG Li-fei, 2017, CONSTRUCTING MODEL A, V0, P45
   Xu Zhong, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1015, DOI 10.1109/ICDAR.2019.00166
NR 38
TC 0
Z9 1
U1 1
U2 4
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1433-2833
EI 1433-2825
J9 INT J DOC ANAL RECOG
JI Int. J. Doc. Anal. Recognit.
PD DEC 15
PY 2021
VL 24
IS 4
BP 339
EP 348
DI 10.1007/s10032-021-00381-5
EA JUN 2021
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WL2BA
UT WOS:000664022700001
DA 2023-11-10
ER

PT J
AU Feng, D
   Chen, HN
AF Feng, Dan
   Chen, Hainan
TI A small samples training framework for deep Learning-based automatic information extraction: Case study of construction accident news reports analysis
SO ADVANCED ENGINEERING INFORMATICS
LA English
DT Article
DE Automatic information extraction; Small sample training; Cross combination-based text augmentation; Construction accident news reports
ID safety performance; management; knowledge; system; nlp
AB Knowledge management is crucial for construction safety management. Widely collected and well-organized safety-related documents are recognized to be significant in raising the workers' security awareness and then to prevent hazards and accidents. To improve document processing efficiency, automatic information extraction plays an important role. However, currently, automatic information extraction modeling requires large scale training datasets. It is a big challenge for the engineering industry, especially for the fields which heavily rely on the experts' knowledge. Limited data sources, and high time and labor costs make it not practical to establish a large-scale dataset. This work proposed a natural language data augmentation-based small samples training framework for automatic information extraction modeling. With the designed cross combination-based text data augmentation algorithm, the deep neural network can be employed to build up automatic information extraction models without large-scale raw data and manual annotations. Characters semantic coding is employed to avoid word segmentation and make sure that the framework can be utilized in different writing language systems. The BiLSTM-CRF model is adopted as the detection core to conduct character classification. Through a case study of two independent accident news report datasets analysis, the proposed framework has been validated. A reliable and robust automatic information extraction model can be established, even though with small samples training.
C1 [Feng, Dan] Wuhan Univ, Sch Econ & Management, Wuhan 420106, Peoples R China.
   [Feng, Dan] China Construct Seventh Engn Div Corp LTD, Zhengzhou 450004, Peoples R China.
   [Chen, Hainan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518000, Peoples R China.
C3 Wuhan University; Sun Yat Sen University
RP Chen, HN (通讯作者)，Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518000, Peoples R China.
EM hn.chen@live.com
FU China Postdoctoral Science Foundation [2019M663239]; Fundamental Research Funds for the Central Universities [19lgpy289]
CR Auch F, 2010, INT J MANAG PROJ BUS, V3, P443, DOI 10.1108/17538371011056075
   Bamel UK, 2020, ACCIDENT ANAL PREV, V135, P0, DOI 10.1016/j.aap.2019.105387
   Chen HN, 2019, ADV ENG INFORM, V42, P0, DOI 10.1016/j.aei.2019.100959
   Chi NW, 2017, GAZETTEERS INFORM EX, V0, P401
   Dawood H, 2019, J INF TECHNOL CONSTR, V24, P540, DOI 10.36680/j.itcon.2019.030
   Duryan M, 2020, ACCIDENT ANAL PREV, V139, P0, DOI 10.1016/j.aap.2020.105496
   Ghazal MM, 2022, INT J CONSTR MANAG, V22, P1632, DOI 10.1080/15623599.2020.1738205
   Gunduz M, 2020, COMPUT INTEL NEUROSC, V2020, P0, DOI 10.1155/2020/2610306
   Hardison D, 2019, SAFETY SCI, V120, P517, DOI 10.1016/j.ssci.2019.08.001
   Hassan FU, 2020, J LEG AFF DISPUTE RE, V12, P0, DOI 10.1061/(ASCE)LA.1943-4170.0000379
   Hassani K, 2016, ACM COMPUT SURV, V49, P0, DOI 10.1145/2932710
   Huang YH, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11226426
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Kim T, 2019, J CONSTR ENG M, V145, P0, DOI 10.1061/(ASCE)CO.1943-7862.0001625
   Lample G, 2016, P HLTNAACL, V0, P0
   Levy O, 2014, ARXIV PREPRINT ARXIV, V0, P0
   Li J, 2015, SAFETY SCI, V74, P70, DOI 10.1016/j.ssci.2014.12.003
   Li SQ, 2020, J CLEAN PROD, V257, P0, DOI 10.1016/j.jclepro.2020.120581
   Liu QJ, 2020, ENG CONSTR ARCHIT MA, V27, P765, DOI 10.1108/ECAM-03-2019-0136
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Mansouri S, 2020, J CONSTR ENG M, V146, P0, DOI 10.1061/(ASCE)CO.1943-7862.0001759
   Mohammadi A, 2018, SAFETY SCI, V109, P382, DOI 10.1016/j.ssci.2018.06.017
   Nazeer, 1900, P1072, V0, P0
   Nnaji C, 2020, J TRAFFIC TRANSP ENG, V7, P61, DOI 10.1016/j.jtte.2019.11.001
   Stenetorp P, 2012, P DEM 13 C EUR CHAPT, V0, P102
   Tang LYN, 2017, J MANAGE ENG, V33, P0, DOI 10.1061/(ASCE)ME.1943-5479.0000554
   Tixier AJP, 2016, AUTOMAT CONSTR, V62, P45, DOI 10.1016/j.autcon.2015.11.001
   Wang WM, 2008, INFORM PROCESS MANAG, V44, P1707, DOI 10.1016/j.ipm.2008.05.002
   Winge S, 2019, J SAFETY RES, V71, P139, DOI 10.1016/j.jsr.2019.09.015
   Xie QP, 2019, IEEE ACCESS, V7, P32672, DOI 10.1109/ACCESS.2019.2903106
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Ye Zhixiu, 2018, P 56 ANN M ASS COMP, V2, P235
   Yu ES, 2019, ENERGIES, V12, P0, DOI 10.3390/en12234425
   Zhang JS, 2017, AUTOMAT CONSTR, V73, P45, DOI 10.1016/j.autcon.2016.08.027
   Zhang JS, 2016, J COMPUT CIVIL ENG, V30, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000346
   Zhang JS, 2015, J COMPUT CIVIL ENG, V29, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000427
   Zou Y, 2017, AUTOMAT CONSTR, V80, P66, DOI 10.1016/j.autcon.2017.04.003
NR 38
TC 33
Z9 33
U1 12
U2 60
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1474-0346
EI 1873-5320
J9 ADV ENG INFORM
JI Adv. Eng. Inform.
PD JAN 15
PY 2021
VL 47
IS 
BP 
EP 
DI 10.1016/j.aei.2021.101256
EA FEB 2021
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Multidisciplinary
SC Computer Science; Engineering
GA QY9OF
UT WOS:000630364600035
DA 2023-11-10
ER

PT J
AU Ni, P
   Li, GM
   Hung, PCK
   Chang, V
AF Ni, Pin
   Li, Gangmin
   Hung, Patrick C. K.
   Chang, Victor
TI StaResGRU-CNN with CMedLMs: A stacked residual GRU-CNN with pre-trained biomedical language models for predictive intelligence
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Natural language processing; Predictive intelligence; Biomedical text mining; Named Entity Recognition; Text classification; Transfer learning; Pre-trained language model
ID sentiment analysis; neural-network; text
AB As a task requiring strong professional experience as supports, predictive biomedical intelligence cannot be separated from the support of a large amount of external domain knowledge. By using transfer learning to obtain sufficient prior experience from massive biomedical text data, it is essential to promote the performance of specific downstream predictive and decision-making task models. This is an efficient and convenient method, but it has not been fully developed for Chinese Natural Language Processing (NLP) in the biomedical field. This study proposes a Stacked Residual Gated Recurrent Unit-Convolutional Neural Networks (StaResGRU-CNN) combined with the pre-trained language models (PLMs) for biomedical text-based predictive tasks. Exploring related paradigms in biomedical NLP based on transfer learning of external expert knowledge and comparing some Chinese and English language models. We have identified some key issues that have not been developed or those present difficulties of application in the field of Chinese biomedicine. Therefore, we also propose a series of Chinese bioMedical Language Models (CMedLMs) with detailed evaluations of downstream tasks. By using transfer learning, language models are introduced with prior knowledge to improve the performance of downstream tasks and solve specific predictive NLP tasks related to the Chinese biomedical field to serve the predictive medical system better. Additionally, a free-form text Electronic Medical Record (EMR)-based Disease Diagnosis Prediction task is proposed, which is used in the evaluation of the analyzed language models together with Clinical Named Entity Recognition, Biomedical Text Classification tasks. Our experiments prove that the introduction of biomedical knowledge in the analyzed models significantly improves their performance in the predictive biomedical NLP tasks with different granularity. And our proposed model also achieved competitive performance in these predictive intelligence tasks. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Ni, Pin] UCL, Sch Engn, London, England.
   [Li, Gangmin] Univ Bedfordshire, Sch Comp Sci & Technol, Luton, Beds, England.
   [Hung, Patrick C. K.] Ontario Tech Univ, Fac Business & Informat Technol, Oshawa, ON, Canada.
   [Chang, Victor] Teesside Univ, Sch Comp Engn & Digital Technol, Artificial Intelligence & Informat Syst Res Grp, Middlesbrough, Cleveland, England.
C3 University of London; University College London; University of Bedfordshire; University of Teesside
RP Chang, V (通讯作者)，Teesside Univ, Sch Comp Engn & Digital Technol, Artificial Intelligence & Informat Syst Res Grp, Middlesbrough, Cleveland, England.
EM V.Chang@tees.ac.uk
FU VC Research [VCR 0000130]; AI University Research Center (AI-URC) through the XJTLU Key Program Special Fund, China [KSF-P-02, KSF-A-17]; Suzhou Bureau of Science and Technology through the Key Industrial Technology Innovation Program, China [SYG201840]
CR Alsentzer Emily, 2019, P 2 CLIN NATURAL LAN, V0, P0, DOI DOI 10.18653/V1/W19-1909
   Anagnostopoulos C, 2018, APPL INTELL, V48, P966, DOI 10.1007/s10489-017-1032-y
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Bharadwaj A, 2016, P 2016 C EMPIRICAL M, V0, PP1462, DOI 10.18653/V1/D16-1153
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chalkidis I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6314
   Chapiro J, 2019, RADIOL-ARTIF INTELL, V1, P0, DOI 10.1148/ryai.2019190139
   Chatterjee Rajen, 2017, P 2 C MACHINE TRANSL, V0, P157
   Chen Q, 2017, ARXIV171104289, V0, P0
   Chen Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2406
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/TACL_A_00104
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai AM, 2015, ADV NEUR IN, V28, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dligach D, 2019, J AM MED INFORM ASSN, V26, P1272, DOI 10.1093/jamia/ocz072
   Du J, 2021, IEEE T CYBERNETICS, V51, P1586, DOI 10.1109/TCYB.2020.2969705
   Gargiulo F, 2019, APPL SOFT COMPUT, V79, P125, DOI 10.1016/j.asoc.2019.03.041
   Gridach M, 2020, APPL SOFT COMPUT, V93, P0, DOI 10.1016/j.asoc.2020.106232
   Gridach M, 2017, J BIOMED INFORM, V70, P85, DOI 10.1016/j.jbi.2017.05.002
   Groth, 2019, SEMANTICS POSTERS DE, V0, P0
   Hakala K, 2019, P 5 WORKSH BIONLP OP, V0, PP56, DOI 10.18653/V1/D19-5709
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Holzinger Andreas, 2014, INTERACTIVE KNOWLEDGE DISCOVERY AND DATA MINING IN BIOMEDICAL INFORMATICS. STATE-OF-THE-ART AND FUTURE CHALLENGES: LNCS 8401, V0, PP271, DOI 10.1007/978-3-662-43968-5_16
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang CC, 2016, BRIEF BIOINFORM, V17, P132, DOI 10.1093/bib/bbv024
   Huang K, 2019, CLINICALBERT MODELIN, V0, P0
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jin Q, 2019, PROC 3 WORK EVAL VEC, V0, PP82, DOI 10.18653/v1/W19-2011
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kamkarhaghighi M, 2017, EXPERT SYST APPL, V90, P241, DOI 10.1016/j.eswa.2017.08.021
   Kathidjiotis Y, 2020, APPL INTELL, V50, P3219, DOI 10.1007/s10489-020-01712-5
   Kim J, 2020, NEUROCOMPUTING, V376, P214, DOI 10.1016/j.neucom.2019.10.033
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li JQ, 2016, KNOWL-BASED SYST, V106, P220, DOI 10.1016/j.knosys.2016.05.045
   Li YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3442
   Li YM, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON COMPLEXITY, V0, P53, DOI 10.5220/0009582700530060
   Li YM, 2019, IEEE INT CONF BIG DA, V0, PP6133, DOI 10.1109/BigData47090.2019.9005449
   Li YM, 2020, COMPUTING, V102, P1305, DOI 10.1007/s00607-019-00773-w
   Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Ni P, 2021, ACM T INTERNET TECHN, V21, P0, DOI 10.1145/3418208
   Ni P, 2020, INT J ENTERP INF SYS, V16, P1, DOI 10.4018/IJEIS.2020100101
   Ni P, 2020, NEURAL COMPUT APPL, V32, P16149, DOI 10.1007/s00521-020-04805-x
   Ni P, 2019, IEEE INT CONF BIG DA, V0, PP6166, DOI 10.1109/BigData47090.2019.9006331
   Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), V0, P58
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rios Anthony, 2015, ACM BCB, V2015, P258, DOI 10.1145/2808719.2808746
   Ruder S, 2019, THESIS NATL U IRELAN, V0, P0
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Toderici G, 2017, PROC CVPR IEEE, V0, PP5435, DOI 10.1109/CVPR.2017.577
   Tomori S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P236
   Venkataraman GR, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0234647
   Wang DS, 2020, APPL SOFT COMPUT, V86, P0, DOI 10.1016/j.asoc.2019.105913
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wikipedia, 2020, OFFL WIK CHIN DOWNL, V0, P0
   Yadav V, 2018, P 27 INT C COMP LING, V0, P2145
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang H, 2018, P 2018 C N AM CHAPT, V2, P175, DOI 10.18653/v1/N18-2028
NR 69
TC 8
Z9 8
U1 4
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD DEC 15
PY 2021
VL 113
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107975
EA OCT 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA XG4UW
UT WOS:000724750600006
DA 2023-11-10
ER

PT J
AU Toniato, A
   Schwaller, P
   Cardinale, A
   Geluykens, J
   Laino, T
AF Toniato, Alessandra
   Schwaller, Philippe
   Cardinale, Antonio
   Geluykens, Joppe
   Laino, Teodoro
TI Unassisted noise reduction of chemical reaction datasets
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID transformer; language; system; smiles
AB The recent advances in computational chemistry rely on large data collections of chemical compounds and reactions. However, not all entries in these datasets are correct. Toniato and colleagues present here an automated approach to identify incorrect reactions, using the effect of catastrophic forgetting in neural networks. Existing deep learning models applied to reaction prediction in organic chemistry can reach high levels of accuracy (>90% for natural language processing-based ones). With no chemical knowledge embedded other than the information learnt from reaction data, the quality of the datasets plays a crucial role in the performance of the prediction models. Human curation is prohibitively expensive, so unaided approaches to remove chemically incorrect entries from existing datasets are essential to improve the performance of artificial intelligence models in synthetic chemistry tasks. Here, we propose a machine learning-based, unassisted approach to remove chemically wrong entries from chemical reaction collections. We apply this method to the Pistachio collection of chemical reactions and to an open dataset, both extracted from United States Patent and Trademark Office patents. Our results show an improved prediction quality for models trained on the cleaned and balanced datasets. For retrosynthetic models, the roundtrip accuracy metric grows by 13 percentage points and the value of the cumulative Jensen-Shannon divergence decreases by 30% compared to its original record. The coverage remains high at 97%, and the value of the class diversity is not affected by the cleaning. The proposed strategy is the first unassisted rule-free technique to address automatic noise reduction in chemical datasets.
C1 [Toniato, Alessandra; Schwaller, Philippe; Cardinale, Antonio; Geluykens, Joppe; Laino, Teodoro] IBM Res Europe, Zurich, Switzerland.
   [Schwaller, Philippe] Univ Bern, Dept Chem, Bern, Switzerland.
   [Cardinale, Antonio] Univ Pisa, Dept Chem, Pisa, Italy.
C3 University of Bern; University of Pisa
RP Toniato, A (通讯作者)，IBM Res Europe, Zurich, Switzerland.
EM ato@zurich.ibm.com
CR Coley CW, 2019, SCIENCE, V365, P557, DOI 10.1126/science.aax1566
   Coley CW, 2017, ACS CENTRAL SCI, V3, P1237, DOI 10.1021/acscentsci.7b00355
   Dai H, 2019, P 33 C NEUR INF PROC, V32, P8872
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Lowe DM, 2012, EXTRACTION CHEM STRU, V0, P0
   McCloskey M, 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI 10.1016/S0079-7421(08)60536-8
   Öztürk H, 2020, DRUG DISCOV TODAY, V25, P689, DOI 10.1016/j.drudis.2020.01.020
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Rao M, 2004, IEEE T INFORM THEORY, V50, P1220, DOI 10.1109/TIT.2004.828057
   SATOH H, 1995, J CHEM INF COMP SCI, V35, P34, DOI 10.1021/ci00023a005
   Schneider N, 2016, J CHEM INF MODEL, V56, P2336, DOI 10.1021/acs.jcim.6b00564
   Schwaller P, 2019, ACS SYM SER, V1326, P61, DOI 10.1021/bk-2019-1326.ch004
   Schwaller P, 2020, CHEM SCI, V11, P3316, DOI 10.1039/c9sc05704h
   Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576
   Segler MHS, 2018, NATURE, V555, P604, DOI 10.1038/nature25978
   Segler MHS, 2017, CHEM-EUR J, V23, P5966, DOI 10.1002/chem.201605499
   Shannon CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/J.1538-7305.1948.TB01338.X
   Somnath VR, 2020, LEARNING GRAPH MODEL, V0, P0
   Tetko IV, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-19266-y
   Thakkar A, 2020, CHEM SCI, V11, P154, DOI 10.1039/c9sc04944d
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wallis S, 2013, J QUANT LINGUIST, V20, P178, DOI 10.1080/09296174.2013.799918
   WEININGER D, 1989, J CHEM INF COMP SCI, V29, P97, DOI 10.1021/ci00062a008
   WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005
   Zheng SJ, 2020, J CHEM INF MODEL, V60, P47, DOI 10.1021/acs.jcim.9b00949
   Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8
NR 27
TC 15
Z9 15
U1 5
U2 30
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD JUN 15
PY 2021
VL 3
IS 6
BP 485
EP +
DI 10.1038/s42256-021-00319-w
EA MAR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SV9GP
UT WOS:000636319000002
DA 2023-11-10
ER

PT J
AU Zeng, QT
   Zhao, XS
   Hu, XH
   Duan, H
   Zhao, ZY
   Li, C
AF Zeng, Qingtian
   Zhao, Xishi
   Hu, Xiaohui
   Duan, Hua
   Zhao, Zhongying
   Li, Chao
TI Learning emotional word embeddings for sentiment analysis
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Sentiment analysis; word embedding; classification; representation learning
ID algorithms
AB Word embeddings have been successfully applied in many natural language processing tasks due to its their effectiveness. However, the state-of-the-art algorithms for learning word representations from large amounts of text documents ignore emotional information, which is a significant research problem that must be addressed. To solve the above problem, we propose an emotional word embedding (EWE) model for sentiment analysis in this paper. This method first applies pre-trained word vectors to represent document features using two different linear weighting methods. Then, the resulting document vectors are input to a classification model and used to train a text sentiment classifier, which is based on a neural network. In this way, the emotional polarity of the text is propagated into the word vectors. The experimental results on three kinds of real-world data sets demonstrate that the proposed EWE model achieves superior performances on text sentiment prediction, text similarity calculation, and word emotional expression tasks compared to other state-of-the-art models.
C1 [Zeng, Qingtian; Zhao, Xishi; Li, Chao] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao, Peoples R China.
   [Hu, Xiaohui; Duan, Hua; Zhao, Zhongying] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Shandong Prov Key Lab Wisdom Mine Informat Techno, Qingdao, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of Science & Technology
RP Li, C (通讯作者)，Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao, Peoples R China.; Zhao, ZY (通讯作者)，Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM zzysuin@163.com; 1008lichao@163.com
FU National Natural Science Foundation of China [62072288, 61303167, 61702306, U1931207]; Shandong Provincial Natural Science Foundation, China [ZR2017BF015]; SDUST Research Fund [2015TDJH102]; Humanities and Social Science Research Project of the Ministry of Education [18YJAZH017]; Taishan Scholar Program of Shandong Province [ts20190936]
CR Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen XX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1236
   Collobert R, 2008, P 25 INT C MACH LEAR, V0, PP160, DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai H, 2019, INTERDISCIP SCI, V11, P559, DOI 10.1007/s12539-019-00343-w
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Fu YP, 2020, ARAB J SCI ENG, V45, P2571, DOI 10.1007/s13369-019-04241-7
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Günther F, 2016, FRONT PSYCHOL, V7, P0, DOI 10.3389/fpsyg.2016.01646
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kaibi I, 2019, 2019 INT C WIR TECHN, V0, P0
   Le HS, 2013, IEEE T AUDIO SPEECH, V21, P195, DOI 10.1109/TASL.2012.2215599
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Liu B, 2015, SENTIMENT ANALYSIS: MINING OPINIONS, V0, P0
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mohamed EH, 2020, INT J COMPUT INTELL, V19, P0
   Morin F, 2005, AISTATS, V5, P246
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Severyn A, 2015, P 9 INT WORKSH SEM E, V0, P464
   Socher R, 2013, LONG PAPERS, V1, P455
   Socher R, 2011, P C EMPIRICAL METHOD, V0, P151
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   STONE PJ, 1962, BEHAV SCI, V7, P484
   Sun X, 2018, TEXT SENTIMENT POLAR, V0, P99
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Yang L, 2015, LECT NOTES ARTIF INT, V9427, P15, DOI 10.1007/978-3-319-25816-4_2
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
   Zhao ZY, 2021, IEEE T NETW SCI ENG, V8, P695, DOI 10.1109/TNSE.2020.3048902
   Zhao ZY, 2021, INFORM SCIENCES, V543, P382, DOI 10.1016/j.ins.2020.07.001
   Zhao ZY, 2019, KNOWL-BASED SYST, V163, P404, DOI 10.1016/j.knosys.2018.09.002
NR 44
TC 7
Z9 7
U1 1
U2 24
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2021
VL 40
IS 5
BP 9515
EP 9527
DI 10.3233/JIFS-201993
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RT4UM
UT WOS:000644456300058
DA 2023-11-10
ER

PT J
AU Bai, X
   Abasi, R
   Edizel, B
   Mantrach, A
AF Bai, Xiao
   Abasi, Reza
   Edizel, Bora
   Mantrach, Amin
TI Position-Aware Deep Character-Level CTR Prediction for Sponsored Search
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Predictive models; Search engines; Deep learning; Context modeling; Advertising; Engines; Data models; Deep learning; NLP; online advertising; sponsored search; CTR prediction
AB Predicting the click-through rate of an advertisement is a critical component of online advertising platforms. In sponsored search, the click-through rate estimates the probability that a displayed advertisement is clicked by a user after she submits a query to the search engine. Commercial search engines typically rely on machine learning models trained with a large number of features to make such predictions. This inevitably requires a lot of engineering efforts to define, compute, and select the appropriate features. In this paper, we propose two novel approaches (one working at character level and the other working at word level) that use deep convolutional neural networks to predict the click-through rate of a query-advertisement pair. Specifically, the proposed architectures consider as input only the textual content appearing in a query-advertisement pair and the page position at which the advertisement appears on the search result page of the query, and produce as output a click-through rate prediction. By comparing the character-level model with the word-level model, we show that language representation can be learnt from scratch at character level when trained on enough data. Through extensive experiments using billions of query-advertisement pairs of a popular commercial search engine, we demonstrate that both approaches significantly outperform a baseline model built on well-selected text features and a state-of-the-art word2vec-based approach. We also show the importance of the position feature in the proposed approaches in improving the prediction accuracy. When combining the predictions of the deep models introduced in this study with the prediction of the model in production of the same commercial search engine, we significantly improve the accuracy and the calibration of the click-through rate prediction of the production system. We also show the potential of leveraging the CTR prediction of the proposed deep learning models for query-ad relevance modeling and query-ad matching tasks in sponsored search.
C1 [Bai, Xiao] Yahoo Research, Sunnyvale, CA 94089 USA.
   [Abasi, Reza] Oath Inc, Sunnyvale, CA 94089 USA.
   [Edizel, Bora] Pompeu Fabra Univ, Barcelona 08002, Spain.
   [Edizel, Bora] Eurecat, Barcelona 08002, Spain.
   [Mantrach, Amin] Criteo Labs, Palo Alto, CA 94301 USA.
C3 Yahoo! Inc; Yahoo! Inc United States; Pompeu Fabra University
RP Bai, X (通讯作者)，Yahoo Research, Sunnyvale, CA 94089 USA.
EM xbai@oath.com; mabasi@oath.com; bora.edizel@upf.edu; a.mantrach@criteo.com
FU Yahoo Research
CR Aiello L, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP185, DOI 10.1145/2983323.2983840
   [Anonymous], 2015, BOOSTING NAMED ENTIT, V0, P0
   [Anonymous], 2009, P 3 INT WORKSH DAT M, V0, P0
   Baeza-Yates R, 1999, MODERN INFORM RETRIE, V0, P0
   Bai X, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP52, DOI 10.1145/3219819.3219897
   Ballesteros M, 2015, P 2015 C EMP METH NA, V0, PP349, DOI 10.18653/V1/D15-1041
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chen Ye, 2012, P 18 ACM SIGKDD INT, V0, P795
   Chen-Guang He, 2010, PROCEEDINGS 2010 IEEE YOUTH CONFERENCE ON INFORMATION, V0, P351, DOI 10.1109/YCICT.2010.5713117
   Conneau I, 2016, VERY DEEP CONVOLUTIO, V0, P0
   dos Santos CN, 2014, PR MACH LEARN RES, V32, P1818
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Edelman B, 2005, 11765 NAT BUR EC RES, V0, P0
   Edizel B, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP305, DOI 10.1145/3077136.3080811
   Glorot Xavier, 2011, P 14 INT C ART INT S, V0, PP315, DOI 10.1002/ECS2.1832
   Graepel Thore, 2010, P 27 INT C MACH LEAR, V0, PP13, DOI 10.1109/TNSE.2021.3102582
   Grbovic M, 2016, SIGIR16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP375, DOI 10.1145/2911451.2911538
   He K, 2015, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2015.123
   He X, 2014, P 8 INT WORKSH DAT M, V0, PP1, DOI 10.1145/2648584.2648589
   Hillard D, 2011, INFORM RETRIEVAL, V14, P315, DOI 10.1007/s10791-010-9152-6
   Hu BT, 2014, ADV NEUR IN, V27, P0
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, P2333
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Jiang ZL, 2016, CONTROL ENG APPL INF, V18, P11
   Juan YC, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS16), V0, PP43, DOI 10.1145/2959100.2959134
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Kingma DP, 2014, C TRACK P, V0, P0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   McMahan HB, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD13), V0, P1222
   Mehta A, 2005, ANN IEEE SYMP FOUND, V0, PP264, DOI 10.1109/SFCS.2005.12
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Qin Tao, 2013, ARXIV13062597, V0, P0
   Richardson M, 2007, P 16 INT C WORLD WID, V0, P521
   Saveski M, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS14), V0, PP89, DOI 10.1145/2645710.2645751
   Shen Yelong, 2014, P 23 ACM INT C C INF, V0, P0, DOI DOI 10.1145/2661829.2661935
   Wang TF, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD13), V0, P563
   Zhai SF, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1295, DOI 10.1145/2939672.2939759
   Zhang Xiang, 2015, NEURIPS, V0, P0, DOI DOI 10.5555/2969239.2969312
   Zhang Y, 2016, PROC 11 AAAI C, V0, P1369
NR 39
TC 5
Z9 5
U1 0
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD APR 1
PY 2021
VL 33
IS 4
BP 1722
EP 1736
DI 10.1109/TKDE.2019.2941881
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA QT5HG
UT WOS:000626617900023
DA 2023-11-10
ER

PT J
AU Chew, AWZ
   Pan, Y
   Wang, Y
   Zhang, LM
AF Chew, Alvin Wei Ze
   Pan, Yue
   Wang, Ying
   Zhang, Limao
TI Hybrid deep learning of social media big data for predicting the evolution of COVID-19 transmission
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE COVID-19; Natural language processing; Time-series prediction; Deep learning; Big-data
AB In this study, a hybrid deep-learning model termed as ODANN, built upon neural networks (NN) coupled with data assimilation and natural language processing (NLP) features extraction methods, has been constructed to concurrently process daily COVID-19 time-series records and large volumes of COVID-19 related Twitter data, as representative of the global community's aggregated emotional responses towards the current pandemic, to model the growth rate in the number of confirmed COVID-19 cases globally via a proposed G parameter. Overall, there were 3 key components to ODANN's development phase, namely: (i) data hydration and pre-processing were performed on COVID-19 related Twitter data ranging between 23 January 2020 and 10 May 2020, which amounted to over 100 million Tweets written in English language; (ii) multiple NLP features extraction methods were subsequently leveraged to encode the hydrated Twitter data into useful semantic word vectors for training ODANN under an optimal set of hyperparameters; and (iii) historical time-series data of defined characteristics were also assimilated into ODANN's selected hidden layer(s) to model the G parameter daily with a lead-time of 1 day. By far, our experimental results demonstrated that by adopting a rolling time-window size of 5 days, with respect to the number of historical time-series records for assimilating different data features, enabled ODANN to outperform other traditional time -series models and recent studies, in terms of the computed RMSE and MAE scores attained from the model's testing step. Overall, the summarized results from ODANN demonstrated its competitive edge in modelling and forecasting the growth rate in the number of COVID-19 cases globally. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Chew, Alvin Wei Ze] Bentley Syst Res Off, 1 Harbourfront Pl,HarbourFront Tower One, Singapore 098633, Singapore.
   [Pan, Yue] Shanghai Jiao Tong Univ, Dept Civil Engn, Shanghai Key Lab Digital Maintenance Bldg & Infra, 800 Dongchuan Rd, Shanghai, Peoples R China.
   [Wang, Ying; Zhang, Limao] Nanyang Technol Univ, Sch Civil & Environm Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 Shanghai Jiao Tong University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Zhang, LM (通讯作者)，Nanyang Technol Univ, Sch Civil & Environm Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM Alvin.Chew@bentley.com; panyue001@sjtu.edu.cn; YING006@e.ntu.edu.sg; limao.zhang@ntu.edu.sg
CR Agerri R, 2015, KNOWL-BASED SYST, V79, P36, DOI 10.1016/j.knosys.2014.11.007
   Aldaco R, 2020, SCI TOTAL ENVIRON, V742, P0, DOI 10.1016/j.scitotenv.2020.140524
   Ali I, 2020, SCI TOTAL ENVIRON, V728, P0, DOI 10.1016/j.scitotenv.2020.138861
   Alp ZZ, 2018, KNOWL-BASED SYST, V141, P211, DOI 10.1016/j.knosys.2017.11.021
   Arora P, 2020, CHAOS SOLITON FRACT, V139, P0, DOI 10.1016/j.chaos.2020.110017
   Ayo FE, 2020, COMPUT SCI REV, V38, P0, DOI 10.1016/j.cosrev.2020.100311
   Beck BR, 2020, COMPUT STRUCT BIOTEC, V18, P784, DOI 10.1016/j.csbj.2020.03.025
   Browning L, 2021, J CLIN PATHOL, V74, P443, DOI 10.1136/jclinpath-2020-206854
   Chen Emily, 2020, JMIR PUBLIC HEALTH SURVEILL, V6, Pe19273, DOI 10.2196/19273
   Chen JD, 2021, SOC INDIC RES, V153, P65, DOI 10.1007/s11205-020-02481-x
   Chew AWZ, 2021, SUSTAIN CITIES SOC, V75, P0, DOI 10.1016/j.scs.2021.103231
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, P0, DOI 10.1016/j.chaos.2020.109864
   Davenport Thomas, 2019, FUTURE HEALTHC J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   Haman M, 2020, HELIYON, V6, P0, DOI 10.1016/j.heliyon.2020.e05540
   Hazarika BB, 2020, APPL SOFT COMPUT, V96, P0, DOI 10.1016/j.asoc.2020.106626
   Hirose H, 2012, INT SYMP PARAL ARCH, V0, PP100, DOI 10.1109/PAAP.2012.23
   Hong HG, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0236464
   Hou KK, 2021, PERS INDIV DIFFER, V175, P0, DOI 10.1016/j.paid.2021.110701
   Huang CL, 2020, LANCET, V395, P497, DOI 10.1016/S0140-6736(20)30183-5
   Kumar N, 2020, PROC 11 INT C COMPUT, V0, P0, DOI DOI 10.1109/ICCCNT49239.2020
   Li C, 2021, KNOWL-BASED SYST, V218, P0, DOI 10.1016/j.knosys.2021.106849
   Liu T, 2020, NEW ENGL J MED, V0, P0, DOI DOI 10.1101/2020.01.25. 919787
   Lwin May Oo, 2020, JMIR PUBLIC HEALTH SURVEILL, V6, Pe19447, DOI 10.2196/19447
   Mikolov T, 2013, ADV NEURAL INFORM PR, V0, PP3111, DOI 10.5555/2999792.2999959
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nunez M, 2021, FORECASTING VIRUS OU, V0, P0
   OLeary DE, 2015, INTELL SYST ACCOUNT, V22, P227, DOI 10.1002/isaf.1376
   Pan Y, 2021, SUSTAIN CITIES SOC, V75, P0, DOI 10.1016/j.scs.2021.103254
   Pan Y, 2021, AUTOMAT CONSTR, V124, P0, DOI 10.1016/j.autcon.2021.103564
   Papastefanopoulos V, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10113880
   Park HW, 2020, J MED INTERNET RES, V22, P0, DOI 10.2196/18897
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petropoulos F, 2022, INT J FORECASTING, V38, P439, DOI 10.1016/j.ijforecast.2020.11.010
   Postnikov EB, 2020, CHAOS SOLITON FRACT, V135, P0, DOI 10.1016/j.chaos.2020.109841
   Rustam F, 2020, IEEE ACCESS, V8, P101489, DOI 10.1109/ACCESS.2020.2997311
   Santos JC, 2014, THEOR BIOL MED MODEL, V11, P0, DOI 10.1186/1742-4682-11-S1-S6
   Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975
   Signorini A, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0019467
   Sinnenberg L, 2017, AM J PUBLIC HEALTH, V107, PE1, DOI 10.2105/AJPH.2016.303512
   Tian T, 2020, COVID NET DEEP LEARN, V0, P0
   Tsao SF, 2021, LANCET DIGIT HEALTH, V3, PE175, DOI 10.1016/S2589-7500(20)30315-0
   Unkel S, 2012, J R STAT SOC A STAT, V175, P49, DOI 10.1111/j.1467-985X.2011.00714.x
   Venigalla Akhila Sri Manasa, 2020, CSCW 20: 23RD CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, V0, PP65, DOI 10.1145/3406865.3418567
   Yesilkanat CM, 2020, CHAOS SOLITON FRACT, V140, P0, DOI 10.1016/j.chaos.2020.110210
   Yousefinaghani S, 2021, FRONT PUBLIC HEALTH, V9, P0, DOI 10.3389/fpubh.2021.656635
   Zhang L, 2021, ARTIFICIAL INTELLIGE, V0, P1
   Zheng NN, 2020, IEEE T CYBERNETICS, V50, P2891, DOI 10.1109/TCYB.2020.2990162
NR 47
TC 15
Z9 15
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD DEC 5
PY 2021
VL 233
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107417
EA OCT 2021
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WK7QW
UT WOS:000709919000018
PM 34690447
DA 2023-11-10
ER

PT J
AU Bird, JJ
   Ekárt, A
   Faria, DR
AF Bird, Jordan J.
   Ekart, Aniko
   Faria, Diego R.
TI Chatbot Interaction with Artificial Intelligence: human data augmentation with T5 and language transformer ensemble for text classification
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article; Early Access
DE Chatbot; Human-machine interaction; Data augmentation; Transformers; Language transformation; Natural Language Processing
AB In this work we present the Chatbot Interaction with Artificial Intelligence (CI-AI) framework as an approach to the training of a transformer based chatbot-like architecture for task classification with a focus on natural human interaction with a machine as opposed to interfaces, code, or formal commands. The intelligent system augments human-sourced data via artificial paraphrasing in order to generate a large set of training data for further classical, attention, and language transformation-based learning approaches for Natural Language Processing (NLP). Human beings are asked to paraphrase commands and questions for task identification for further execution of algorithms as skills. The commands and questions are split into training and validation sets. A total of 483 responses were recorded. Secondly, the training set is paraphrased by the T5 model in order to augment it with further data. Seven state-of-the-art transformer-based text classification algorithms (BERT, DistilBERT, RoBERTa, DistilRoBERTa, XLM, XLM-RoBERTa, and XLNet) are benchmarked for both sets after fine-tuning on the training data for two epochs. We find that all models are improved when training data is augmented by the T5 model, with an average increase of classification accuracy by 4.01%. The best result was the RoBERTa model trained on T5 augmented data which achieved 98.96% classification accuracy. Finally, we found that an ensemble of the five best-performing transformer models via Logistic Regression of output label predictions led to an accuracy of 99.59% on the dataset of human responses. A highly-performing model allows the intelligent system to interpret human commands at the social-interaction level through a chatbot-like interface (e.g. "Robot, can we have a conversation?") and allows for better accessibility to AI by non-technical users.
C1 [Bird, Jordan J.; Faria, Diego R.] Aston Univ, Aston Robot Vis & Intelligent Syst Lab ARVIS Lab, Birmingham, W Midlands, England.
   [Ekart, Aniko] Aston Univ, Sch Engn & Appl Sci, Birmingham, W Midlands, England.
C3 Aston University; Aston University
RP Bird, JJ (通讯作者)，Aston Univ, Aston Robot Vis & Intelligent Syst Lab ARVIS Lab, Birmingham, W Midlands, England.
EM birdj1@aston.ac.uk; a.ekart@aston.ac.uk; d.faria@aston.ac.uk
CR Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC, V0, P0
   [Anonymous], 2005, M ASS COMP LING, V0, P0
   [Anonymous], 2013, P UBICOMP 13 ADJ, V0, P0
   Biedert Ralf, 2012, P S EYE TRACK RES AP, V0, PP123, DOI 10.1145/2168556.2168575
   Bird, 1900, P593, V0, P0
   Bird J, 2019, MENTAL EMOTIONAL SEN, V0, P0, DOI DOI 10.1109/IS.2018.8710576
   Bird JJ, 2020, IEEE INT C INT ROBOT, V0, PP10380, DOI 10.1109/IROS45743.2020.9341557
   Bird JJ, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20185151
   Bird JJ, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), V0, PP795, DOI 10.1109/IS.2018.8710576
   Bird JJ, 2019, ADV INTELL SYST COMP, V840, P179, DOI 10.1007/978-3-319-97982-3_15
   Bollweg L, 2018, EDMEDIA INNOVATE LEA, V0, P1455
   Candello, 2018, 2018 CHI C HUM FACT, V0, P1
   Chada, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Chang, 2020, ELLACHANG T5 PARAPHR, V0, P0
   Chang W-C, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Chollet F, 2015, KERAS, V0, P0
   Ciechanowski L, 2019, FUTURE GENER COMP SY, V92, P539, DOI 10.1016/j.future.2018.01.055
   Conneau Alexis, 2019, ARXIV191102116, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Devlin J, 2018, OPEN SOURCING BERT S, V0, P0
   Di Gangi MA, 2019, INTERSPEECH, V0, PP1133, DOI 10.21437/Interspeech.2019-3045
   DIMOVSKI M, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Eckstein G, 2019, TESL EJ, V23, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Haller E, 2013, I C CONTR SYS COMP S, V0, PP582, DOI 10.1109/CSCS.2013.85
   Hou, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   JIN L, 2018, P 13 WORKSH INN US N, V0, P13
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kruger JL, 2014, READ RES QUART, V49, P105, DOI 10.1002/rrq.59
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Leonhardt MD, 2007, 7TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, V0, P845, DOI 10.1109/ICALT.2007.275
   Lewis Martha, 2020, IFCOLOG J LOGICS THE, V7, P0
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Lukovnikov D, 2019, LECT NOTES COMPUT SC, V11778, P470, DOI 10.1007/978-3-030-30793-6_27
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, V0, PP1, DOI 10.1007/978-1-4419-9326-7
   Maiya, 2020, ARXIV200410703CSLG, V0, P0
   Manurung R, 2008, APPL ARTIF INTELL, V22, P841, DOI 10.1080/08839510802295962
   Marquis A, 2020, FRONT PSYCHOL, V11, P0, DOI 10.3389/fpsyg.2020.00452
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Paszke Adam, 2019, NEURIPS, V0, P0
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petrovic S, 2013, ACL 2, V0, P228
   Qi Di, 2020, ARXIV200107966, V0, P0
   Quora, 2017, QUOR QUEST PAIRS KAG, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2019, ABS191010683 ARXIV, V0, P0
   Resnik P, 2009, 2009 C EMPIRICAL MET, V0, P381
   Roller S, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234
   SHAGASS C, 1976, ARCH GEN PSYCHIAT, V33, P121
   SHANGIPOURATAEI T, 2020, P 2 WORKSH FIG LANG, V0, PP67, DOI 10.18653/V1/2020.FIGLANG-1.9
   Shao TH, 2019, IEEE ACCESS, V7, P26146, DOI 10.1109/ACCESS.2019.2900753
   Shleifer, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Stephens, 2002, WHAT HAS LOEBNER CON, V0, P0
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Sun L, 2020, ARXIV200715789, V0, P0
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Virkar M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), V0, PP891, DOI 10.1109/ICCS45141.2019.9065723
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang CC, 2019, MULTIMED TOOLS APPL, V78, P4813, DOI 10.1007/s11042-018-5754-6
   Wang Quan, 2019, ARXIV191102168, V0, P0
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6382
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang, 2018, ARXIV PREPRINT ARXIV, V0, P0
NR 70
TC 3
Z9 3
U1 5
U2 30
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1007/s12652-021-03439-8
EA AUG 2021
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA UD9TX
UT WOS:000687544000004
DA 2023-11-10
ER

PT J
AU Ilievski, F
   Oltramari, A
   Ma, KX
   Zhang, B
   McGuinness, DL
   Szekely, P
AF Ilievski, Filip
   Oltramari, Alessandro
   Ma, Kaixin
   Zhang, Bin
   McGuinness, Deborah L.
   Szekely, Pedro
TI Dimensions of commonsense knowledge
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Commonsense knowledge; Semantics; Knowledge graphs; Reasoning
AB Commonsense knowledge is essential for many AI applications, including those in natural language processing, visual processing, and planning. Consequently, many sources that include commonsense knowledge have been designed and constructed over the past decades. Recently, the focus has been on large text-based sources, which facilitate easier integration with neural (language) models and application to textual tasks, typically at the expense of the semantics of the sources and their harmonization. Efforts to consolidate commonsense knowledge have yielded partial success, with no clear path towards a comprehensive solution. We aim to organize these sources around a common set of dimensions of commonsense knowledge. We survey a wide range of popular commonsense sources with a special focus on their relations. We consolidate these relations into 13 knowledge dimensions. This consolidation allows us to unify the separate sources and to compute indications of their coverage, overlap, and gaps with respect to the knowledge dimensions. Moreover, we analyze the impact of each dimension on downstream reasoning tasks that require commonsense knowledge, observing that the temporal and desire/goal dimensions are very beneficial for reasoning on current downstream tasks, while distinctness and lexical knowledge have little impact. These results reveal preferences for some dimensions in current evaluation, and potential neglect of others. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Ilievski, Filip; Zhang, Bin; Szekely, Pedro] Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA 90292 USA.
   [Oltramari, Alessandro] Bosch Res & Technol Ctr, Intelligent Internet Things, Pittsburgh, PA USA.
   [Ma, Kaixin] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
   [McGuinness, Deborah L.] Rensselaer Polytech Inst, Tetherless World Constellat, Troy, NY USA.
C3 University of Southern California; Bosch; Carnegie Mellon University; Rensselaer Polytechnic Institute
RP Ilievski, F (通讯作者)，Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA 90292 USA.
EM ilievski@isi.edu; Alessandro.Oltramari@us.bosch.com; kaixinm@andrew.cmu.edu; binzhang@isi.edu; dlm@cs.rpi.edu; pszekely@isi.edu
FU DARPA MCS program [N660011924033]; United States Office Of Naval Research
CR [Anonymous], 1990, PHILOS ARTIFICIAL IN, V0, P0
   Aristotle R, 2012, METAPHYSICS, V0, P0
   Asher N, 1990, EUR WORKSH LOG ART I, V0, P1
   Baker CF, 1998, 36 ANN M ASS COMPUTA, V0, PP86, DOI 10.3115/980845.980860
   Banerjee P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P151
   Bhagavatula Chandra, 2020, INT C LEARN REPR, V0, P0
   Bhakthavatsalam S, 2020, ARXIV200500660, V0, P0
   Bhakthavatsalam Sumithra, 2020, ARXIV200607510, V0, P0
   Bisk Y, 2020, AAAI CONF ARTIF INTE, V34, P7432
   Boratko M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1122
   Bosselut A, 2019, ARXIV190605317, V0, P0
   Brentano F, 2014, PSYCHOL EMPIRICAL ST, V0, P0
   Cambria E, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP105, DOI 10.1145/3340531.3412003
   Cambria E, 2014, IEEE INTELL SYST, V29, P44, DOI 10.1109/MIS.2012.118
   Casati R, 1999, PARTS PLACES STRUCTU, V0, P0
   Chen Junpeng, 2011, IJCNLP, V0, P686
   Davison J, 2019, P 2019 C EMPIRICAL M, V0, P1173
   de Lacalle ML, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2662
   Devlin J, 2018, ARXIV, V1, P4171
   Dodge EK, 2015, P 3 WORKSH MET NLP A, V0, P40
   Elazar Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P10486
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   Forbus KD, 1997, QUALITATIVE REASONIN, V0, P0
   Gangemi A, 2002, LECT NOTES ARTIF INT, V2473, P166
   Gangemi A, 2016, LECT NOTES COMPUT SC, V10024, P239, DOI 10.1007/978-3-319-49004-5_16
   Gibson EJ, 2000, ECOLOGICAL APPROACH, V0, P0
   Gordon AS, 2017, FORMAL THEORY COMMON, V0, P0
   Grice P, 1975, SYNTAX SEMANTICS, V3, P0, DOI 10.1163/9789004368811_003
   Guha RV, 2016, COMMUN ACM, V59, P44, DOI 10.1145/2844544
   Hartigan JA, 1979, APPLIED STATISTICS, V28, P100, DOI 10.2307/2346830
   Hicks GD, 1904, P ARISTOTELIAN SOC, V5, P136
   Ilievski F, 2020, INT SEM WEB C ISWC T, V0, P0
   Ilievski F, 2021, AAAI TUTORIALS COMMONSENSE KNOWLEDG, V0, P0
   Ilievski F, 2020, WIK WORKSH, V0, P0
   Ilievski F, 2021, LECT NOTES COMPUT SC, V12731, P680, DOI 10.1007/978-3-030-77385-4_41
   Ilievski F, 2017, LECT NOTES ARTIF INT, V10318, P143, DOI 10.1007/978-3-319-59888-8_12
   Jeretic Paloma, 2020, P 58 ANN M ASS COMP, V0, PP8690, DOI 10.18653/V1/2020.ACL-MAIN.768
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Kipper-Schuler K, 2005, THESIS, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   LASCARIDES A, 1993, LINGUIST PHILOS, V16, P437, DOI 10.1007/BF00986208
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   LEVINE J, 1983, PAC PHILOS QUART, V64, P354
   Lewis Patrick, 2020, ADV NEURAL INFORM PR, V33, P9459, DOI 10.48550/ARXIV.2005.11401
   Li Xiang Lisa, 2021, ARXIV210100190, V0, P0
   Lin BY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6862
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2829
   Lin Z, 2020, FINDINGS ASS COMPUTA, V0, P441
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Liu Y, 2019, ROBUSTLY OPTIMIZED B, V0, P0
   Ma K, 2021, AAAI, V0, P0
   Ma Kaixin, 2019, P 1 WORKSH COMM INF, V0, PP22, DOI 10.18653/V1/D19-6003
   MacLachlen Gale, 1994, FRAMING INTERPRETATI, V0, P0
   McCarthy John, 1960, PROGRAMS COMMON SENS, V0, P0
   Miller GA, 1998, WORDNET ELECT LEXICA, V0, P0
   Miller GA, 2003, TRENDS COGN SCI, V7, P141, DOI 10.1016/S1364-6613(03)00029-9
   Moore RC, 1982, ROLE LOGIC KNOWLEDGE, V0, P0
   Mostafazadeh N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4569
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Niles I, 2001, FORMAL ONTOLOGY IN INFORMATION SYSTEMS. COLLECTED PAPERS FROM THE SECOND INTERNATIONAL CONFERENCE, V0, PP2, DOI 10.1145/505168.505170
   Onyeka E, 2020, PROC INT C TOOLS ART, V0, PP935, DOI 10.1109/ICTAI50040.2020.00146
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Plummer BA, 2016, INT J COMPUT VISION, V0, P1
   Puri M, 2018, IEEE INT CONF BIG DA, V0, PP5433, DOI 10.1109/BigData.2018.8622162
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Razniewski Simon, 2021, WSDM 21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP1143, DOI 10.1145/3437963.3441664
   Roget PM, 2020, ROGETS THESAURUS, V0, P0
   Rohde D, 2006, COMMUN ACM, V8, P116
   Romero J, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP1411, DOI 10.1145/3357384.3357955
   Sap M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4463
   Sap M, 2019, AAAI CONF ARTIF INTE, V0, P3027
   Sap Maarten, 2020, ACL, V0, P0
   Segers R, 2015, P MAPLEX, V0, P0
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Shwartz V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4615
   Singh P, 2002, LECT NOTES COMPUT SC, V2519, P1223
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Storks S, 2019, CORR, V0, P0
   Szabo M, 1934, COLLECTED PAPERS G G, V0, P0
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Tandon N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP115, DOI 10.18653/v1/P17-4020
   Tandon N, 2017, SIGMOD REC, V46, P49, DOI 10.1145/3186549.3186562
   Tanon TP, 2020, LECT NOTES COMPUT SC, V12123, P583, DOI 10.1007/978-3-030-49461-2_34
   van Miltenburg E, 2016, P WORKSH MULT CORP C, V0, P0
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Williams BM, 2017, P 13 INT S COMM REAS, V0, P0
   WINSTON ME, 1987, COGNITIVE SCI, V11, P417, DOI 10.1207/s15516709cog1104_2
   Wu W, 2012, P 2012 ACM SIGMOD IN, V0, PP481, DOI 10.1145/2213836.2213891
   Yang Wei, 2018, ARXIV181006543, V0, P0
   Zellers R, 2019, PROC CVPR IEEE, V0, PP6713, DOI 10.1109/CVPR.2019.00688
   Zhang H, 2020, P 58 ANN M ASS COMPU, V0, PP5736, DOI 10.18653/v1/2020.acl-main.508
   Zhou Pei, 2020, ARXIV200500782, V0, P0
NR 93
TC 12
Z9 13
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD OCT 11
PY 2021
VL 229
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107347
EA AUG 2021
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UO5NV
UT WOS:000694743300008
DA 2023-11-10
ER

PT J
AU Zhang, Y
   Fu, ZL
   Huang, FY
   Liu, YZ
AF Zhang, Yu
   Fu, Zilong
   Huang, Fuyu
   Liu, Yizhi
TI PMMN: Pre-trained multi-Modal network for scene text recognition
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Multi-modal information; Pre-trained model; Scene text recognition
ID attention; system
AB Scene Text Recognition (STR) task needs to consume large-amount data to develop a powerful recognizer, including visual data like images and linguistic data like texts. However, existing methods mainly leverage a one-stage training manner to train the entire framework end-to-end, which deeply relies on the well-annotated images and does not effectively use the data of the two modalities mentioned above. To solve this, in this paper, we propose a pre-trained multi-modal network (PMMN) that utilizes visual and linguistic data to pre-train the vision model and language model respectively to learn modality-specific knowledge for accurate scene text recognition. In detail, we first pre-train the proposed off-the-shelf vision model and language model to convergence. And then, we combine the pre-trained models in a unified framework for end-to-end fine-tuning and utilize the learned multi-modal information to interact with each other to generate robust features for character prediction. Extensive experiments are conducted to demonstrate the effectiveness of PMMN. The evaluation results on six benchmarks show that our proposed method exceeds most existing methods, achieving state-of-the-art performance. (c) 2021 Published by Elsevier B.V.
C1 [Zhang, Yu] Zhengzhou Normal Univ, Coll Informat Sci & Technol, Zhengzhou 450044, Peoples R China.
   [Fu, Zilong] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Peoples R China.
   [Huang, Fuyu] Univ Sci & Technol China, Beijing Res Inst, Beijing 100193, Peoples R China.
   [Liu, Yizhi] Hunan Univ Sci & Technol, Xiangtan, Peoples R China.
   [Zhang, Yu] Beijing Univ Technol, Beijing 100124, Peoples R China.
C3 Zhengzhou Normal University; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Hunan University of Science & Technology; Beijing University of Technology
RP Fu, ZL (通讯作者)，Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Peoples R China.
EM JeromeF@mail.ustc.edu.cn
FU National Nature Science Foundation of China [U19B2023]; Key Project of Hunan Provincial Education Department [19A172]
CR Bahdanau D, 2016, ARXIV, V0, P0
   Cheng ZZ, 2018, PROC CVPR IEEE, V0, PP5571, DOI 10.1109/CVPR.2018.00584
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, V0, PP5086, DOI 10.1109/ICCV.2017.543
   Coquenet D, 2020, INT CONF FRONT HAND, V0, PP19, DOI 10.1109/ICFHR2020.2020.00015
   Deli Yu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP12110, DOI 10.1109/CVPR42600.2020.01213
   Devlin J, 2018, ARXIV, V1, P4171
   Fang SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP248, DOI 10.1145/3240508.3240571
   Fenfen Sheng, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP781, DOI 10.1109/ICDAR.2019.00130
   Graves Alex, 2006, P 23 INT C MACH LEAR, V0, P369
   Gupta A, 2016, PROC CVPR IEEE, V0, PP2315, DOI 10.1109/CVPR.2016.254
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He RN, 2016, AAAI CONF ARTIF INTE, V0, P144
   Hu WY, 2020, AAAI CONF ARTIF INTE, V34, P11005
   Jaderberg M, 2014, ARXIV, V0, P0
   Jaderberg M, 2015, ADV NEUR IN, V28, P0
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Karatzas D, 2015, PROC INT CONF DOC, V0, PP1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, V0, PP1484, DOI 10.1109/ICDAR.2013.221
   Li H, 2019, AAAI CONF ARTIF INTE, V0, P8610
   Liao MH, 2019, AAAI CONF ARTIF INTE, V0, P8714
   Liao MH, 2021, IEEE T PATTERN ANAL, V43, P532, DOI 10.1109/TPAMI.2019.2937086
   Litman R, 2020, P IEEE CVF C COMP VI, V0, P11962
   Liu Wei, 2016, BMVC, V0, P0
   Lung KY, 2021, PATTERN RECOGN LETT, V144, P82, DOI 10.1016/j.patrec.2021.01.011
   Lyu PY, 2019, ARXIV190605708, V0, P0
   Ma YJ, 2021, IEEE T MULTIMEDIA, V0, P0
   Merity Stephen, 2016, POINTER SENTINEL MIX, V0, P0
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, V0, P0, DOI DOI 10.5244/C.26.127
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Sanchez-Riera J, 2016, PATTERN RECOGN LETT, V73, P1, DOI 10.1016/j.patrec.2015.12.006
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, V0, PP4168, DOI 10.1109/CVPR.2016.452
   Simonyan K, 2015, ARXIV, V0, P0
   Singh A, 2019, PROC CVPR IEEE, V0, PP8309, DOI 10.1109/CVPR.2019.00851
   Phan TQ, 2013, IEEE I CONF COMP VIS, V0, PP569, DOI 10.1109/ICCV.2013.76
   Vaswani A, 2017, ARXIV, V30, P5998
   Wan Z, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Wan ZY, 2020, AAAI CONF ARTIF INTE, V34, P12120
   Wang K, 2011, IEEE I CONF COMP VIS, V0, PP1457, DOI 10.1109/ICCV.2011.6126402
   Wang TW, 2020, AAAI CONF ARTIF INTE, V34, P12216
   Wu L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1500, DOI 10.1145/3343031.3350929
   Xia ZX, 2021, IEEE IND ELECTRON M, V15, P6, DOI 10.1109/MIE.2020.2970790
   Xiao HH, 2020, PATTERN RECOGN LETT, V133, P305, DOI 10.1016/j.patrec.2020.03.001
   Xie HT, 2019, ACM T MULTIM COMPUT, V15, P0, DOI 10.1145/3231737
   Yan MK, 2019, IEEE I CONF COMP VIS, V0, PP9146, DOI 10.1109/ICCV.2019.00924
   Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3280
   Yang Z, 2019, PREPRINT, V0, P0
   Yue X, 2020, P EUR C COMP VIS GLA, V0, P135
   Zhang JX, 2020, PATTERN RECOGN LETT, V136, P205, DOI 10.1016/j.patrec.2020.06.009
   Zhang R, 2020, IEEE T PATTERN ANAL, V42, P909, DOI 10.1109/TPAMI.2018.2890637
   Zhao JY, 2020, PATTERN RECOGN LETT, V138, P217, DOI 10.1016/j.patrec.2020.07.027
   Zheng Yucheng, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Zhi Qiao, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP13525, DOI 10.1109/CVPR42600.2020.01354
NR 55
TC 6
Z9 6
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD NOV 15
PY 2021
VL 151
IS 
BP 103
EP 111
DI 10.1016/j.patrec.2021.07.016
EA AUG 2021
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UW6SN
UT WOS:000700283100016
DA 2023-11-10
ER

PT J
AU Hudson, GT
   Al Moubayed, N
AF Hudson, G. Thomas
   Al Moubayed, Noura
TI Ask me in your own words: paraphrasing for multitask question answering
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Question answering; Paraphrasing; Multitask learning; Dataset
AB Multitask learning has led to significant advances in Natural Language Processing, including the decaNLP benchmark where question answering is used to frame 10 natural language understanding tasks in a single model. In this work we show how models trained to solve decaNLP fail with simple paraphrasing of the question. We contribute a crowd-sourced corpus of paraphrased questions (PQ-decaNLP), annotated with paraphrase phenomena. This enables analysis of how transformations such as swapping the class labels and changing the sentence modality lead to a large performance degradation. Training both MQAN and the newer T5 model using PQ-decaNLP improves their robustness and for some tasks improves the performance on the original questions, demonstrating the benefits of a model which is more robust to paraphrasing. Additionally, we explore how paraphrasing knowledge is transferred between tasks, with the aim of exploiting the multitask property to improve the robustness of the models. We explore the addition of paraphrase detection and paraphrase generation tasks, and find that while both models are able to learn these new tasks, knowledge about paraphrasing does not transfer to other decaNLP tasks.
C1 [Hudson, G. Thomas; Al Moubayed, Noura] Univ Durham, Dept Comp Sci, Durham, England.
C3 Durham University
RP Hudson, GT (通讯作者)，Univ Durham, Dept Comp Sci, Durham, England.
EM g.t.hudson@durham.ac.uk
FU EPSRC [EP/T022167/1]; N8 research partnership
CR Altheneyan A, 2020, INT J PATTERN RECOGN, V34, P0, DOI 10.1142/S0218001420530043
   [Anonymous], 2018, P 22 C COMP NAT LANG, V0, P0
   [Anonymous], 2013, ACL, V0, P0
   Barrón-Cedeño A, 2013, COMPUT LINGUIST, V39, P917, DOI 10.1162/COLI_a_00153
   Bordes A, 2014, QUESTION ANSWERING S, V0, P0, DOI DOI 10.3115/V1/D14-1067
   Buck C, 2018, ICLR, V0, P1
   Caruana R A, 1993, P 10 INT C MACHINE L, V48, P41, DOI 10.1016/B978-1-55860-307-3.50012-5
   Devlin Jacob, 2019, BERT PRE TRAINING DE, V0, P4171
   Dolan WB, 2005, P 3 INT WORKSH PAR I, V0, P0
   Dong L, 2017, P 2017 C EMP METH NA, V0, PP875, DOI 10.18653/ v1/D17-1091
   Duong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P845
   El Desouki Mohamed I, 2019, INT J COMPUT APPL, V975, P8887
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hunt E, 2019, 2019 10TH IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (ICBK 2019), V0, PP97, DOI 10.1109/ICBK.2019.00021
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Iyyer M, 2018, P 2018 C N AM CHAPT, V1, P1875, DOI 10.18653/V1/N18-1170
   Li ZC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3403
   McCann Bryan, 2018, ABS180608730 CORR, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Ribeiro MT, 2018, P 56 ANN M ASS COMPU, V1, P0
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Socher Richard, 2017, P 2017 C EMP METH NA, V0, PP1923, DOI 10.18653/V1/D17-1206
   Tomar GS, 2017, P EMPIRICAL METHODS, V0, P142
   Vila M, 2014, OPEN J MODERN LINGUI, V4, P205, DOI 10.4236/OJML.2014.41016
   Vila M, 2011, PROCES LENG NAT, V0, P83
   Vila M, 2015, LANG RESOUR EVAL, V49, P77, DOI 10.1007/s10579-014-9272-5
   Yang YP, 2017, AER ADV ENG RES, V141, P1, DOI 10.1109/ULTSYM.2017.8091994
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
NR 29
TC 1
Z9 1
U1 0
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD OCT 27
PY 2021
VL 7
IS 
BP 
EP 
DI 10.7717/peerj-cs.759
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA WN8PN
UT WOS:000712029200001
PM 34805510
DA 2023-11-10
ER

PT J
AU Cong, Y
   Wu, YM
   Liang, XB
   Pei, JY
   Qin, ZS
AF Cong, Yao
   Wu, Yimin
   Liang, Xinbo
   Pei, Jiayan
   Qin, Zishan
TI PH-model: enhancing multi-passage machine reading comprehension with passage reranking and hierarchical information
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Multi-passage reading comprehension; Passage reranking; Hierarchical neural network; Gumbel-Softmax; Natural language processing
ID neural-networks
AB Machine reading comprehension(MRC), which employs computers to answer questions from given passages, is a popular research field. In natural language, a natural hierarchical representation can be seen: characters, words, phrases, sentences, paragraphs, and documents. Current studies have demonstrated that hierarchical information can help machines understand natural language. However, prior works focused on the overall performance of MRC tasks without considering hierarchical information. In addition, the noise problem still has not been adequately addressed, even though many researchers have adopted the technique of passage reranking. Thus, in this paper, focusing on noise information processing and the extraction of hierarchical information, we propose a model (PH-Model) with a passage reranking framework (P) and hierarchical neural network (H) for a Chinese multi-passage MRC task. PH-Model produces more precise answers by reducing noise information and extracting hierarchical information. Experimental results on the DuReader 2.0 dataset (a large scale real-world Chinese MRC dataset) show that PH-Model outperforms the ROUGE-L and BLEU-4 baseline by 18.24% and 24.17%, respectively.
C1 [Cong, Yao; Wu, Yimin; Liang, Xinbo; Qin, Zishan] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Pei, Jiayan] South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
C3 South China University of Technology; South China University of Technology
RP Wu, YM (通讯作者)，South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM congyao95@hotmail.com; csymwu@scut.edu.cn; xbliang321@hotmail.com; scutasensio@gmail.com; qzs_233@foxmail.com
FU National Key R & D Program of China [2016YFB1200402-020]
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Catelli R, 2020, APPL SOFT COMPUT, V97, P0, DOI 10.1016/j.asoc.2020.106779
   Cui F, 2019, CHIN J URBAN ENV STU, V7, P0, DOI 10.1142/S2345748119400062
   Duta IC, 2016, INT WORK CONTENT MUL, V0, P0
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Esposito M, 2020, INFORM SCIENCES, V514, P88, DOI 10.1016/j.ins.2019.12.002
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   He W, 2018, MACHINE READING FOR QUESTION ANSWERING, V0, P37
   Imran SA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), V0, PP1193, DOI 10.1109/ROBIO.2013.6739626
   Jang Eric, 2017, INT C LEARN REPR, V0, P0
   Jiahua L, 2018, J CHINESE INFORM PRO, V0, P0
   Jiang YC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2714
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Li Z, 2018, CHIN INT CONF ELECTR, V0, PP93, DOI 10.1109/CICED.2018.8592530
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Lin DW, 2019, LECT NOTES COMPUT SC, V11772, P121, DOI 10.1007/978-3-030-31624-2_10
   Liu J, 2018, P 2018 C EMP METH NA, V0, P2109
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mucheng Ren, 2019, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 8TH CCF INTERNATIONAL CONFERENCE, V0, P0
   Nishida K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2335
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pota M, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10144710
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seo Min Joon, 2017, 5 INT C LEARN REPR I, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vinyals O, 2015, P ADV NEURAL INFORM, V0, PP2692, DOI 10.48550/arxiv.1506.03134
   Wang Shuohang, 2017, P 5 INT C LEARN REPR, V0, P0
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Wang YZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1918
   Yan M, 2019, AAAI CONF ARTIF INTE, V0, P7354
   Yang A, 2018, MACHINE READING FOR QUESTION ANSWERING, V0, P98
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
NR 38
TC 5
Z9 5
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD AUG 15
PY 2021
VL 51
IS 8
BP 5440
EP 5452
DI 10.1007/s10489-020-02168-3
EA JAN 2021
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA TG7OE
UT WOS:000606299200003
DA 2023-11-10
ER

PT J
AU Giorgi, I
   Golosio, B
   Esposito, M
   Cangelosi, A
   Masala, GL
AF Giorgi, Ioanna
   Golosio, Bruno
   Esposito, Massimo
   Cangelosi, Angelo
   Masala, Giovanni L.
TI Modeling Multiple Language Learning in a Developmental Cognitive Architecture
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Computer architecture; Computational modeling; Brain modeling; Deep learning; Natural language processing; Task analysis; Cognitive system; multilingual system; natural language understanding; neural network
ID working-memory; information; selection; examples
AB In this work, we model multiple natural language learning in a developmental neuroscience-inspired architecture. The artificial neural network with adaptive behavior exploited for language learning (ANNABELL) model, is a large-scale neural network, however, unlike most deep learning methods that solve natural language processing (NLP) tasks, it does not represent an empirical engineering solution for specific NLP problems; rather, its organization complies with findings from cognitive neuroscience, particularly the multicompartment working memory models. The system is appropriately trained to understand the level of cognitive development required for language acquisition and the robustness achieved in learning simultaneously four languages, using a corpus of text-based exchanges of developmental complexity. The selected languages, Greek, Italian and Albanian, besides English, differ significantly in structure and complexity. Initially, the system was validated in each language alone and was then compared with the open-ended cumulative training, in which languages are learned jointly, prior to querying with random language at random order. We aimed to assess if the model could learn the languages together to the same degree of skill as learning each apart. Moreover, we explored the generalization skill in multilingual context questions and the ability to elaborate a short text of preschool literature. We verified if the system could follow a dialogue coherently and cohesively, keeping track of its previous answers and recalling them in subsequent queries. The results show that the architecture developed broad language processing functionalities, with satisfactory performances in each language trained singularly, maintaining high accuracies when they are acquired cumulatively.
C1 [Giorgi, Ioanna; Cangelosi, Angelo] Univ Manchester, Dept Comp Sci, Manchester M13 9PL, Lancs, England.
   [Golosio, Bruno] Univ Cagliari, Dipartimento Fis, I-09042 Cagliari, Italy.
   [Golosio, Bruno] Ist Nazl Fis Nucl, Sez Cagliari, I-09042 Cagliari, Italy.
   [Esposito, Massimo] CNR, Inst High Performance Comp & Networking, I-80131 Naples, Italy.
   [Masala, Giovanni L.] Manchester Metropolitan Univ, Dept Comp & Math, Manchester M15 6BH, Lancs, England.
C3 University of Manchester; University of Cagliari; Istituto Nazionale di Fisica Nucleare (INFN); Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR); Manchester Metropolitan University
RP Giorgi, I (通讯作者)，Univ Manchester, Dept Comp Sci, Manchester M13 9PL, Lancs, England.
EM ioanna.giorgi@manchester.ac.uk; massimo.esposito@icar.cnr.it; angelo.cangelosi@manchester.ac.uk
CR Abutalebi Jubin, 2001, BILING-LANG COGN, V4, P179, DOI 10.1017/S136672890100027X
   Amodei D, 2016, PR MACH LEARN RES, V48, P0
   Anderson LW, 2001, TAXONOMY LEARNING TE, V0, P0
   [Anonymous], 2004, STUDIES ALBANIAN OTH, V0, P0
   [Anonymous], 2016, IBM COGNITIVE INSIGH, V0, P0
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Bryck RL, 2005, MEM COGNITION, V33, P611, DOI 10.3758/BF03195328
   De Houwer A, 1999, ERIC DIG CLEARINGHOU, V0, P0
   Dominey PE, 2013, FRONT PSYCHOL, V4, P0, DOI 10.3389/fpsyg.2013.00500
   Dupoux E, 2018, COGNITION, V173, P43, DOI 10.1016/j.cognition.2017.11.008
   Fang H, 2015, PROC CVPR IEEE, V0, PP1473, DOI 10.1109/CVPR.2015.7298754
   Fidelman P, 2015, P COGN SCI SOC, V7, P660
   Fu XH, 2019, KNOWL-BASED SYST, V171, P81, DOI 10.1016/j.knosys.2019.02.008
   Gan Z, 2017, PROC CVPR IEEE, V0, PP1141, DOI 10.1109/CVPR.2017.127
   Gaspers J, 2017, IEEE T COGN DEV SYST, V9, P183, DOI 10.1109/TCDS.2016.2614958
   Gella S, 2017, EMPIRICAL METHODS NA, V0, P2839
   Golosio B, 2015, PROCEDIA COMPUT SCI, V71, P196, DOI 10.1016/j.procs.2015.12.200
   Golosio B, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0140866
   Google AI Blog, 2018, TEACH GOOGL ASS BE M, V0, P0
   Hinaut X, 2015, P COGN COMP INT NEUR, V0, P56
   Hinaut X, 2020, IEEE T COGN DEV SYST, V12, P179, DOI 10.1109/TCDS.2019.2957006
   Hinaut X, 2015, BRAIN LANG, V150, P54, DOI 10.1016/j.bandl.2015.08.002
   Hinaut X, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0052946
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Jorgji J, 2018, FRONT ARTIF INTEL AP, V303, P992, DOI 10.3233/978-1-61499-900-3-992
   Kadar A, 2018, P 22 C COMP NAT LANG, V0, PP402, DOI 10.18653/V1/K18-1039
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kelly MA, 2018, PROCEDIA COMPUT SCI, V145, P724, DOI 10.1016/j.procs.2018.11.047
   Krashen SD, 1983, NATURAL APPROACH LAN, V0, P0
   Lake BM, 2017, BEHAV BRAIN SCI, V40, P0, DOI 10.1017/S0140525X16001837
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Matusevych Y, 2017, BILING-LANG COGN, V20, P128, DOI 10.1017/S1366728915000607
   MIIKKULAINEN R, 1995, APPL INTELL, V5, P137, DOI 10.1007/BF00877229
   Miikkulainen R, 1993, SUBSYMBOLIC NATURAL, V0, P0
   Mitra B, 2017, P 26 INT C WORLD, V0, PP1291, DOI 10.1145/3038912.3052579
   Monner D, 2012, BIOL INSPIR COGN ARC, V2, P37, DOI 10.1016/j.bica.2012.06.002
   Moulin-Frier C, 2018, IEEE T COGN DEV SYST, V10, P1005, DOI 10.1109/TCDS.2017.2754143
   Navigli R, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5697
   Oberauer K, 2002, J EXP PSYCHOL LEARN, V28, P411, DOI 10.1037//0278-7393.28.3.411
   Peyronel S, 2005, BASIC ITALIAN GRAMMA, V0, P0
   Poulopoulou M, 2015, MODERN GREEK GRAMMAR, V0, P0
   Ramirez NF, 2016, WHY BABY BRAIN CAN L, V0, P0
   Rescorla L, 2002, J SPEECH LANG HEAR R, V45, P0, DOI 10.1044/1092-4388(2002/059)
   Rescorla L, 2001, J SPEECH LANG HEAR R, V44, P434, DOI 10.1044/1092-4388(2001/035)
   Robert RS, 1995, KNOWLEDGE MEMORY REA, V0, P1
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Szmrecsanyi B, 2012, LINGUAE LITT, V13, P6
   Vandierendonck A, 2012, PSYCHOL BELG, V52, P229, DOI 10.5334/pb-52-2-3-229
   Verhagen J, 2016, J EXP CHILD PSYCHOL, V141, P65, DOI 10.1016/j.jecp.2015.06.015
   Wang G, 2018, KNOWL-BASED SYST, V148, P85, DOI 10.1016/j.knosys.2018.02.024
   Watson B, 2019, MY 1 JUNGLE STORY, V0, P0
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu HJ, 2019, KNOWL-BASED SYST, V163, P252, DOI 10.1016/j.knosys.2018.08.032
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   Zhang FZ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP353, DOI 10.1145/2939672.2939673
   Zhao XW, 2010, INT J BILING EDUC BI, V13, P505, DOI 10.1080/13670050.2010.488284
NR 57
TC 4
Z9 4
U1 3
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC 15
PY 2021
VL 13
IS 4
BP 922
EP 933
DI 10.1109/TCDS.2020.3033963
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA XM6HH
UT WOS:000728925200020
DA 2023-11-10
ER

PT J
AU Ahkouk, K
   Machkour, M
   Majhadi, K
   Mama, R
AF Ahkouk, Karam
   Machkour, Mustapha
   Majhadi, Khadija
   Mama, Rachid
TI SQLSketch: Generating SQL Queries using a sketch-based approach
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Natural language processing; text to SQL translation; database interfaces; natural language translation; machine translation
AB In the last decade, many intelligent interfaces and layers have been suggested to allow the use of relational databases and extraction of the content using only the natural language. However most of them struggle when exposed to new databases. In this article, we present SQLSketch, a sketch-based network for generating SQL queries to address the problem of automatically translate Natural Languages questions to SQL using the related databases schemas. We argue that the previous models that use full or partial sequence-to-sequence structure in the decoding phase can, in fact, have counter-effect on the generation operation and came up with more loss of the context or the meaning of the user question. In this regard, we use a full sketch-based structure that decouples the generation process into many small prediction modules. The SQLSketch is evaluated against GreatSQL, a new cross-domain, large-scale and balanced dataset for the Natural Language to SQL translation task. For a long-term aim of making better models and contributing in adding more improvements to the semantic parsing tasks, we propose the GreatSQL dataset as the first balanced cross-domain corpus that includes 45,969 pairs of natural language questions and their corresponding SQL queries in addition to simplified and well structured ground-truth annotations. We establish results for SQLSketch using GreatSQL dataset and compare the performance against two popular types of models that represent the sequential and partial-sketch based approaches. Experimental result shows that SQLSketch outperforms the baseline models by 13% in exact matching accuracy and achieve a score of 23.9% to be the new state-of-the-art model on GreatSQL.
C1 [Ahkouk, Karam; Machkour, Mustapha; Majhadi, Khadija; Mama, Rachid] Ibn Zohr Univ, Fac Sci, Souss Massa Daraa, Morocco.
C3 Ibn Zohr University of Agadir
RP Ahkouk, K (通讯作者)，Ibn Zohr Univ, Fac Sci, Souss Massa Daraa, Morocco.
EM k.ahkouk@uiz.ac.ma
CR Ahkouk Karam, 2020, INTERNATIONAL JOURNAL OF REASONING-BASED INTELLIGENT SYSTEMS, V12, P264, DOI 10.1504/IJRIS.2020.111786
   [Anonymous], 2017, ABS170900103 CORR, V0, P0
   [Anonymous], 2003, P 8 INT C INT US INT, V0, P0
   [Anonymous], 2019, ARXIV190111504, V0, P0
   Artzi Yoav, 2013, T ASS FORCOMPUTATION, V0, P0
   Banarescu L, 2013, P 7 LING ANN WORKSH, V0, P0
   Berant J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1415, DOI 10.3115/v1/p14-1133
   Bogin B, 2019, ARXIV190506241, V0, P0
   Das Dipanjan, 2010, NAACL, V0, P0
   Devlin Jacob, 2018, ARXIV181004805, V0, P0
   Dong L, 2016, P 54 ANN M ASS COMP, V1, P0
   Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731
   Finegan-Dollak C, 2018, ACL ASS COMPUTATIONA, V0, P0
   He P, 2019, ARXIV190808113, V0, P0
   Hwang Wonseok, 2019, ARXIV190201069, V0, P0
   Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089
   Lee D, 2019, P 2019 C EMP METH NA, V0, P6047
   Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468
   Liang P, 2011, P 49 ANN M ASS COMPU, V1, P590
   Lin Kevin, 2019, ARXIV190513326, V0, P0
   Lin Xi Victoria, 2018, LREC, V0, P0
   Ling Wang, 2016, ACL 1, V0, P0
   Oda Y, 2015, IEEE INT CONF AUTOM, V0, PP574, DOI 10.1109/ASE.2015.36
   Price P, 1990, SPEECH NATURAL LANGU, V0, PP91, DOI 10.3115/116580.116612
   Reddy S, 2014, TACL, V2, P377, DOI 10.1162/TACL_A_00190
   Shi T, 2018, ARXIV180905054, V0, P0
   Tang Lappoon R, 2001, MACHINE LEARNING ECM, V0, P466
   Wang C, 2017, POINTING OUT SQL QUE, V0, P0
   Wong Yuk Wah, 2007, P 45 ANN M ASS COMP, V0, P0
   Xu X, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Yaghmazadeh N, 2017, P ACM PROGRAM LANG, V63, P0
   Yu T, 2018, ARXIV180908887, V0, P0
   Yu T, 2018, ARXIV180409769, V0, P0
   Yu Tao, 2018, P EMNLP, V0, P0, DOI DOI 10.18653/v1/D18-1193
   Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050
   Zettlemoyer Luke S, 2005, UAI, V0, P0
   Zhao L, 2019, ARXIV190506241, V0, P0
NR 37
TC 0
Z9 0
U1 2
U2 2
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2021
VL 40
IS 6
BP 12253
EP 12263
DI 10.3233/JIFS-210359
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA TA8PR
UT WOS:000667508800130
DA 2023-11-10
ER

PT J
AU Ma, CX
   Zhang, C
AF Ma, Changxia
   Zhang, Chen
TI Joint Pre-Trained Chinese Named Entity Recognition Based on Bi-Directional Language Model
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Bi-directional encoder representations-from-transformers; context-sensitive language; multi-head attention; named entity recognition; natural language processing
AB The current named entity recognition (NER) is mainly based on joint convolution or recurrent neural network. In order to achieve high performance, these networks need to provide a large amount of training data in the form of feature engineering corpus and lexicons. Chinese NER is very challenging because of the high contextual relevance of Chinese characters, that is, Chinese characters and phrases may have many possible meanings in different contexts. To this end, we propose a model that leverages a pre-trained and bi-directional encoder representations-from-transformers language model and a joint bi-directional long short-term memory (Bi-LSTM) and conditional random fields (CRF) model for Chinese NER. The underlying network layer embeds Chinese characters and outputs character-level representations. The output is then fed into a bidirectional long short-term memory to capture contextual sequence information. The top layer of the proposed model is CRF, which is used to take into account the dependencies of adjacent tags and jointly decode the optimal chain of tags. A series of extensive experiments were conducted to research the useful improvements of the proposed neural network architecture on different datasets without relying heavily on handcrafted features and domain-specific knowledge. Experimental results show that the proposed model is effective, and character-level representation is of great significance for Chinese NER tasks. In addition, through this work, we have composed a new informal conversation message corpus called the autonomous bus information inquiry dataset, and compared to the advanced baseline, our method has been significantly improved.
C1 [Ma, Changxia] Jiangsu Ocean Univ, Sch Comp Engn, Lianyungang 222005, Peoples R China.
   [Zhang, Chen] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
C3 Jiangsu Ocean University; National University of Singapore
RP Ma, CX (通讯作者)，Jiangsu Ocean Univ, Sch Comp Engn, Lianyungang 222005, Peoples R China.
EM 1997000062@jou.edu.cn; e0397123@u.nus.edu
FU Jiangsu Ocean University Research Foundation [KH18245]; National Research Foundation, Prime Minister's Office, Singapore under its LTA Urban Mobility Grand Challenge Program [UM01/002]; ST Kinetics Autonomous Bus Trial
CR [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2002, P 6 C NATURAL LANGUA, V0, P0
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/TACL_A_00104
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Devlin J, 2018, ARXIV, V1, P4171
   Dong C, 2016, LECT NOTES COMPUT SC, V10102, P239, DOI 10.1007/978-3-319-50496-4_20
   Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260
   Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Goller C, 1996, IEEE IJCNN, V0, PP347, DOI 10.1109/ICNN.1996.548916
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Han XP, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR11), V0, P765
   He H, 2017, EACL, V15, P713, DOI 10.18653/V1/E17-2113
   Hu ZT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2410, DOI 10.18653/v1/p16-1228
   Huang Z, 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Levow G, 2006, P 5 SIGHAN WORKSH CH, V0, P108
   Li HB, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2532
   Li JZ, 2020, SSPS 2020: 2020 2ND SYMPOSIUM ON SIGNAL PROCESSING SYSTEMS, V0, PP96, DOI 10.1145/3421515.3421534
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Liu JX, 2019, NEUROCOMPUTING, V338, P46, DOI 10.1016/j.neucom.2019.01.085
   Liu LY, 2018, AAAI CONF ARTIF INTE, V0, P5253
   Liu ZX, 2010, LECT NOTES ARTIF INT, V6216, P634
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Mccallum A, 2003, P 7 C NATURAL LANGUA, V0, PP188, DOI 10.3115/1119176.1119206
   McCallum A, 2000, ICML, V0, P0
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Peng N, 2015, P 2015 C EMP METH NA, V0, PP548, DOI 10.18653/V1/D15-1064
   Peng N, 2017, ARXIV160300786V2CSCL, V0, P0
   Peng NY, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P149
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Peters ME, 2018, ARXIV180205365, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ratinov L, 2009, P 13 C COMPUTATIONAL, V0, P0, DOI DOI 10.3115/1596374.1596399
   Sang EFTK, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P173
   Shi XL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P594
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wu F, 2019, WEB C 2019 P WORLD, V0, PP3342, DOI 10.1145/3308558.3313743
   Yang J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2720
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zhou JS, 2013, CHINESE J ELECTRON, V22, P225
NR 45
TC 1
Z9 1
U1 1
U2 22
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD JUL 15
PY 2021
VL 35
IS 09
BP 
EP 
DI 10.1142/S0218001421530037
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UF4SF
UT WOS:000688564900018
DA 2023-11-10
ER

PT J
AU Trabelsi, I
   Perotto, FS
   Malik, U
AF Trabelsi, Imen
   Perotto, Filipo Studzinski
   Malik, Usman
TI Training universal background models with restricted data for speech emotion recognition
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article; Early Access
DE Speech emotion recognition; Restricted universal background models; Support vector machines
ID speaker; information; corpus; voice
AB Speech emotion recognition (SER) is an important research topic which relies heavily on emotional data. Admitting that SER has seen some recent advancements, Universal Background Model (UBM), a standard reference concept from a neighbouring field which is speaker recognition, has always been the base module for the newly developed methods such as Joint Factor Analysis. Theoretically, UBM is a Gaussian model trained with an extensive and representative set of speech samples recorded from different target classes in order to extract general feature characteristics. Obtaining large amount of emotional data to train UBM is a challenging task, further complicated by the cost of annotations and the ambiguity of resulting labels. In addition, it's dependent upon the training data. In this paper, we make preliminary exploration on a new approach: Training UBM models, named as restricted UBM, with a small amount of speech, which can be even different from the training data. Experiments show that this approach results in a domain-independent UBM capable of designing an acoustic model transferable to different datasets. Four standard benchmark speech databases from different languages have been used for the experimental evaluation. The results show that our proposed model outperforms the existing state of the art baselines. Moreover, we applied this approach on emotional speaker recognition.
C1 [Trabelsi, Imen; Malik, Usman] Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen,LITIS, Rouen, France.
   [Perotto, Filipo Studzinski] Univ Paul Sabatier, Toulouse Univ, IRIT, Toulouse, France.
C3 Universite de Rouen Normandie; Universite Le Havre Normandie; Universite de Toulouse; Universite Toulouse III - Paul Sabatier; Universite Federale Toulouse Midi-Pyrenees (ComUE)
RP Trabelsi, I (通讯作者)，Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen,LITIS, Rouen, France.
EM imen.beji@insa-rouen.fr
CR Alhasan K, 2019, IEEE 17TH INT CONF ON DEPENDABLE, V0, P271, DOI 10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00057
   Aljanaki A, 2016, INFORM PROCESS MANAG, V52, P115, DOI 10.1016/j.ipm.2015.03.004
   [Anonymous], 1992, LINGUIST DATA CONSOR, V0, P0, DOI DOI 10.35111/17gk-bn40
   [Anonymous], 1977, SPECTRAL ANAL IDENTI, V0, P0
   Bänziger T, 2014, J NONVERBAL BEHAV, V38, P31, DOI 10.1007/s10919-013-0165-x
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Davis MH, 2018, EMPATHY SOCIAL PSYCH, V0, P0, DOI DOI 10.4324/9780429493898
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Desplanques B, 2018, INTERSPEECH, V0, PP3648, DOI 10.21437/Interspeech.2018-1778
   Dissanayake V, 1900, P526, V0, P0, DOI DOI 10.21437/Interspeech.2020-1356
   Ekman P, 2016, PERSPECT PSYCHOL SCI, V11, P31, DOI 10.1177/1745691615596992
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Gangamohan P, 2016, INTEL SYST REF LIBR, V105, P205, DOI 10.1007/978-3-319-31056-5_11
   Haq S, 2009, P INT C AUD VIS SPEE, V0, P53
   Haque A, 2017, INT J SPEECH TECHNOL, V20, P15, DOI 10.1007/s10772-016-9386-9
   Hasan T, 2011, IEEE T AUDIO SPEECH, V19, P1890, DOI 10.1109/TASL.2010.2102753
   Hofmann M, 2006, NOTES, V26, P3
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang XL, 2017, APPL COMPUT HARMON A, V43, P162, DOI 10.1016/j.acha.2016.09.001
   Huang YM, 2019, J AMB INTEL HUM COMP, V10, P1787, DOI 10.1007/s12652-017-0644-8
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, P0, DOI 10.1016/j.bspc.2020.101894
   Keltner D, 2017, SCI FACIAL EXPRESSIO, V0, PP57, DOI 10.1093/ACPROF:OSO/9780190613501.003.0004
   Kerkeni L, 2020, SOCIAL MEDIA MACHINE, V0, P0
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P99, DOI 10.1007/s10772-011-9125-1
   Kragel PA, 2016, TRENDS COGN SCI, V20, P444, DOI 10.1016/j.tics.2016.03.011
   Latif S, 2018, INTERSPEECH, V0, PP257, DOI 10.21437/Interspeech.2018-1625
   Lee L, 1996, INT CONF ACOUST SPEE, V0, PP353, DOI 10.1109/ICASSP.1996.541105
   Lin HCK, 2012, J AMB INTEL HUM COMP, V3, P19, DOI 10.1007/s12652-011-0086-7
   Lopatovska I, 2011, INFORM PROCESS MANAG, V47, P575, DOI 10.1016/j.ipm.2010.09.001
   Lozano-Monasor E, 2017, J AMB INTEL HUM COMP, V8, P567, DOI 10.1007/s12652-017-0464-x
   McLaughlin J, 1999, 6 EUR C SPEECH COMM, V0, P0
   Meyer D, 2015, SUPPORT VECTOR MACHI, V0, P0
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH, V0, P0
   RALAMBONDRAINY H, 1995, PATTERN RECOGN LETT, V16, P1147, DOI 10.1016/0167-8655(95)00075-R
   Rong J, 2009, INFORM PROCESS MANAG, V45, P315, DOI 10.1016/j.ipm.2008.09.003
   Schmitt M, 2016, SPEECH COMM 12 ITG S, V0, PP1, DOI 10.1109/SYSCON.2016.7490579
   Schuller B, 2019, COMPUT SPEECH LANG, V53, P156, DOI 10.1016/j.csl.2018.02.004
   Schuller B, 2013, INTERSPEECH, V0, P148
   Schuller B, 2015, COMPUT SPEECH LANG, V29, P100, DOI 10.1016/j.csl.2014.08.003
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   Schuller BW, 2018, INTERSPEECH, V0, P122
   Sobin C, 1999, J PSYCHOLINGUIST RES, V28, P347, DOI 10.1023/A:1023237014909
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Tzinis E, 2018, INTERSPEECH, V0, PP927, DOI 10.21437/Interspeech.2018-1377
   Vafeiadis A, 2017, ACOUSTIC SCENE CLASS, V0, P0
   Vafeiadis A, 2020, ENG APPL ARTIF INTEL, V89, P0, DOI 10.1016/j.engappai.2019.08.020
   Vapnik Vladimir, 1999, NATURE STAT LEARNING, V2, P0
   Verma GK, 2017, MULTIMED TOOLS APPL, V76, P2159, DOI 10.1007/s11042-015-3119-y
   Weiss B, 2005, P INTERSPEECH, V0, P0
   You CH, 2015, COMPUT SPEECH LANG, V30, P116, DOI 10.1016/j.csl.2014.09.003
   Zhang J, 2020, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-020-02049-0
NR 52
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1007/s12652-021-03200-1
EA APR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA RI5OK
UT WOS:000636956400007
DA 2023-11-10
ER

PT J
AU Figueroa, A
   Timilsina, M
AF Figueroa, Alejandro
   Timilsina, Mohan
TI What identifies different age cohorts in Yahoo! Answers?
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Intelligent information retrieval; Community question answering; User demographic analysis; Natural language processing
ID social question; selection; network; answerability; community; features; ranking; traits; users; cqa
AB For different kinds of online platforms, understanding demographics has shown to be instrumental in improving user experience, especially for personalizing and contextualizing content. Needless to say, there has been a number of studies delving into demographics in online social media platforms including Facebook and Twitter. However, only a mere handful of works have explored demographic factors behind community question-answering platforms despite their massive amount of members. For this reason, we decided to undertake a study of Yahoo! Answers members, namely as it relates to age demographics. To this end, we automatically built and annotated a large-scale corpus comprising metadata and textual inputs produced by ca. 650,000 community fellows. We profit from this collection by conducting both an exploratory/statistical analysis and predictive modelling. In the former, we explored the correlation between distinct age groups and some variables that, intuitively, can seem to be highly correlated with some cohorts. Interestingly enough, this analysis revealed that Millennials are answering questions prompted by their succeeding age group (GEN Z). In the latter, we assessed the prediction rate of various traditional statistical methods and neural networks classifiers coupled with numerous combinations of assorted textual and metadata features. Overall, best classifiers finished with an MRR of up to 0.862, and were modelled by means of FastText and Maximum Entropy (MaxEnt). In terms of informative attributes, user asking/answering activity patterns and sentimentally charged words provide telltale clues about which age group a community peer belongs to. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Figueroa, Alejandro] Univ Andres Bello, Fac Ingn, Dept Ciencias Ingn, Antonio Varas 880, Santiago, Chile.
   [Timilsina, Mohan] Natl Univ Ireland Galway, Insight Ctr Data Analyt, Data Sci Inst, Galway, Ireland.
C3 Universidad Andres Bello; Ollscoil na Gaillimhe-University of Galway
RP Figueroa, A (通讯作者)，Univ Andres Bello, Fac Ingn, Dept Ciencias Ingn, Antonio Varas 880, Santiago, Chile.
EM alejandro.figueroa@unab.cl; mohan.timilsina@insight-centre.org
CR Abric Durham, 2019, 2019 IEEE/ACM 16TH INTERNATIONAL CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR), V0, PP230, DOI 10.1109/MSR.2019.00046
   Ahmad A, 2018, DATA TECHNOL APPL, V52, P190, DOI 10.1108/DTA-07-2017-0054
   Andrew G, 2007, P 24 INT C MACH LEAR, V0, PP33, DOI 10.1145/1273496.1273501
   [Anonymous], 2018, GLOBAL J FLEXIBLE SY, V0, P0
   [Anonymous], 2015, CLEF 2015 EV LABS WO, V0, P0, DOI DOI 10.1007/S13398-014-0173-7.2
   [Anonymous], 2013, CLEF 2013 EVALUATION, V0, P0
   [Anonymous], 2012, P ACM 2012 C COMPUTE, V0, P0
   Atkinson J, 2017, COMPUTER, V50, P58, DOI 10.1109/MC.2017.18
   Attiaoui D, 2017, PROCEDIA COMPUT SCI, V112, P622, DOI 10.1016/j.procs.2017.08.099
   Barash Vladimir D, 2009, 3 INT AAAI C WEBLOGS, V0, P0
   Bayot Roy Khristopher, 2016, I C SOFTWARE KNOWL I, V0, P0
   Beel Joeran, 2013, RESEARCH AND ADVANCED TECHNOLOGY FOR DIGITAL LIBRARIES. INTERNATIONAL CONFERENCE ON THEORY AND PRACTICE OF DIGITAL LIBRARIES, V0, P396, DOI 10.1007/978-3-642-40501-3_45
   Bouguessa M, 2015, ACM T INTEL SYST TEC, V6, P0, DOI 10.1145/2700481
   Bouziane A, 2015, PROCEDIA COMPUT SCI, V73, P366, DOI 10.1016/j.procs.2015.12.005
   Braslavski P, 2017, CHIIR17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, V0, PP345, DOI 10.1145/3020165.3022149
   Burel G, 2015, P ACM C HYPERTEXT SO, V0, PP201, DOI 10.1145/2700171.2791041
   Chen J, 2020, SOCIAL MEDIA DEMOGRA, V0, P0
   Chiang WL, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1485, DOI 10.1145/2939672.2939826
   Choi E, 2016, J ASSOC INF SCI TECH, V67, P1182, DOI 10.1002/asi.23490
   Chua AYK, 2015, J INF SCI, V41, P720, DOI 10.1177/0165551515590096
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Culotta A, 2015, AAAI CONF ARTIF INTE, V0, P72
   Culotta A, 2016, J ARTIF INTELL RES, V55, P389, DOI 10.1613/jair.4935
   Danescu-Niculescu-Mizil C, 2013, P 22 C WORLD WIDE WE, V0, P307
   Dredze M, 2008, ICML, V307, P264, DOI 10.1145/1390156.1390190
   Elalfy D, 2018, EGYPT INFORM J, V19, P21, DOI 10.1016/j.eij.2017.06.002
   Espina A, 2017, EXPERT SYST APPL, V80, P126, DOI 10.1016/j.eswa.2017.03.014
   Falavarjani SAM, 2019, INFORM PROCESS MANAG, V56, P0, DOI 10.1016/j.ipm.2019.102070
   Figueroa A, 2013, PROC AAAI C ARTIF IN, V0, P1099
   Figueroa A, 2021, INFORMATION, V12, P0, DOI 10.3390/info12020048
   Figueroa A, 2019, INFORM FUSION, V50, P112, DOI 10.1016/j.inffus.2018.10.006
   Figueroa A, 2017, EXPERT SYST APPL, V90, P405, DOI 10.1016/j.eswa.2017.08.037
   Figueroa A, 2016, IEEE INTERNET COMPUT, V20, P8, DOI 10.1109/MIC.2015.22
   Figueroa A, 2016, EXPERT SYST APPL, V50, P89, DOI 10.1016/j.eswa.2015.12.016
   Figueroa A, 2015, COMPUT IND, V68, P162, DOI 10.1016/j.compind.2015.01.005
   Figueroa A, 2014, EXPERT SYST APPL, V41, P4730, DOI 10.1016/j.eswa.2014.02.004
   Ford D, 2017, S VIS LANG HUM CEN C, V0, PP239, DOI 10.1109/VLHCC.2017.8103473
   Ford D, 2016, S VIS LANG HUM CEN C, V0, PP264, DOI 10.1109/VLHCC.2016.7739708
   Fu CG, 2020, KNOWL-BASED SYST, V188, P0, DOI 10.1016/j.knosys.2019.07.015
   Fu HY, 2019, INFORM PROCESS MANAG, V56, P14, DOI 10.1016/j.ipm.2018.08.007
   Gabrilovich E, 2009, J ARTIF INTELL RES, V34, P443, DOI 10.1613/jair.2669
   Ghasemi N, 2021, ACM T KNOWL DISCOV D, V15, P0, DOI 10.1145/3441302
   Guan T, 2018, COMPUT HUM BEHAV, V81, P137, DOI 10.1016/j.chb.2017.12.023
   Gumus F, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), V0, PP670, DOI 10.1109/ASONAM.2014.6921657
   Guy I, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP216, DOI 10.1145/3159652.3159733
   Guy I, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP835, DOI 10.1145/3209978.3210058
   Hamilton William L, 2017, PROC INT AAAI CONF WEBLOGS SOC MEDIA, V2017, P540
   Harel S, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2799, DOI 10.1145/3308558.3313457
   Harper FM, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P759
   Hoogeveen D, 2018, INT AAAI C WEB SOC M, V0, P0
   Hou SL, 2020, EXPERT SYST APPL, V157, P0, DOI 10.1016/j.eswa.2020.113421
   Josang A, 2001, INT J UNCERTAIN FUZZ, V9, P279, DOI 10.1142/S0218488501000831
   Jose JM, 2018, P 2018 IEEE SENS NEW, V0, PP1, DOI 10.1109/ICCSDET.2018.8821219
   Kayes I, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), V0, PP570, DOI 10.1145/2736277.2741674
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kucuktunc Onur, 2012, P 5 ACM INT C WEB SE, V0, PP633, DOI 10.1145/2124295.2124371
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Lee MC, 2015, IEEE DATA MINING, V0, PP835, DOI 10.1109/ICDM.2015.75
   Lewis DD, 1998, MACHINE LEARNING: ECML-98. 10TH EUROPEAN CONFERENCE ON MACHINE LEARNING. PROCEEDINGS, V0, PP4, DOI 10.1007/BFb0026666
   Li M, 2020, EXPERT SYST APPL, V141, P0, DOI 10.1016/j.eswa.2019.112923
   Li M, 2019, DATA TECHNOL APPL, V53, P456, DOI 10.1108/DTA-02-2019-0025
   Li ZY, 2019, AAAI CONF ARTIF INTE, V0, P192
   Liang D, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP95, DOI 10.1145/3331184.3331228
   Lin B, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), V0, PP425, DOI 10.1109/MSR.2016.050
   Liu Y, 2019, KNOWL-BASED SYST, V182, P0, DOI 10.1016/j.knosys.2019.06.002
   Liu Z, 2017, INFORM PROCESS MANAG, V53, P490, DOI 10.1016/j.ipm.2016.05.001
   Lyu SS, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP1198, DOI 10.1145/3308558.3313510
   Maity SK, 2018, IEEE T COMPUT SOC SY, V5, P816, DOI 10.1109/TCSS.2018.2859964
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Miyao Y, 2005, LECT NOTES COMPUT SC, V3248, P684
   Mohasseb A, 2018, INFORM PROCESS MANAG, V54, P1228, DOI 10.1016/j.ipm.2018.05.001
   Molino P, 2016, ACM T INFORM SYST, V35, P0, DOI 10.1145/2948063
   Momtazi S, 2018, INFORM PROCESS MANAG, V54, P380, DOI 10.1016/j.ipm.2018.01.001
   Morrison P, 2013, IEEE WORK CONF MIN S, V0, PP69, DOI 10.1109/MSR.2013.6624008
   Neshati M, 2017, INFORM PROCESS MANAG, V53, P1026, DOI 10.1016/j.ipm.2017.04.002
   Nguyen D, 2014, P COLING 2014 25 INT, V0, P1950
   Othman N, 2019, PROCEDIA COMPUT SCI, V159, P485, DOI 10.1016/j.procs.2019.09.203
   Palomera D, 2017, INFORM SCIENCES, V381, P20, DOI 10.1016/j.ins.2016.11.006
   Patra B, 2017, ABS170504009 CORR, V0, P0
   Pelechrinis K, 2015, WORLD WIDE WEB, V18, P33, DOI 10.1007/s11280-013-0249-x
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Rangel F, 2016, WORKING NOTES PAPERS, V0, P750
   Rangel F, 2014, NOTEBOOK PAPERS CEUR, V0, P1
   Rao S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2737
   Rechavi A, 2012, 2012 45TH HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), V0, PP781, DOI 10.1109/HICSS.2012.398
   Rong Wenge, 2019, IEEE IJCNN, V0, P1
   Roy PK, 2018, INT J INFORM MANAGE, V42, P25, DOI 10.1016/j.ijinfomgt.2018.05.003
   Schwartz HA, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0073791
   Srba I, 2016, ACM T WEB, V10, P0, DOI 10.1145/2934687
   STRAUSS B, 1991, GENERATIONS HIST AM, V0, P0
   Sun JK, 2018, DATA MIN KNOWL DISC, V32, P1339, DOI 10.1007/s10618-018-0577-7
   Sun ZJ, 2020, KNOWL-BASED SYST, V205, P0, DOI 10.1016/j.knosys.2020.106256
   Surdeanu M, 2011, COMPUT LINGUIST, V37, P351, DOI 10.1162/COLI_a_00051
   Surdeanu Mihai, 2015, P 2015 C N AM CHAPTE, V0, P1
   Timilsina M, 2021, APPL SOFT COMPUT, V104, P0, DOI 10.1016/j.asoc.2021.107188
   Timilsina M, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), V0, PP237, DOI 10.1145/3106426.3106450
   Tsuruoka Y, 2009, P 47 ANN M ASS COMPU, V0, PP477, DOI 10.3115/1687878.1687946
   Voorhees Ellen M, 1999, P TREC, V0, P0
   Wang JL, 2016, ACM T INTEL SYST TEC, V8, P0, DOI 10.1145/2932193
   Wang Y, 2018, ASIA PAC SOFWR ENG, V0, PP436, DOI 10.1109/APSEC.2018.00058
   Weise E, 2020, YAHOO SAYS 2013 HACK, V0, P0
   Wen JH, 2018, AAAI CONF ARTIF INTE, V0, P2556
   Wen JH, 2019, EXPERT SYST APPL, V118, P563, DOI 10.1016/j.eswa.2018.10.038
   Yadav V, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1217, DOI 10.1145/3209978.3210142
   Zhang W, 2021, AAAI CONF ARTIF INTE, V35, P14463
   Zhao Y, 2019, P ASS INFORM SCI TEC, V56, P517, DOI 10.1002/PRA2.56
   Zhao Z, 2017, AAAI CONF ARTIF INTE, V0, P3532
   Zhe L, 2018, INFORM PROCESS MANAG, V54, P159, DOI 10.1016/j.ipm.2017.10.004
   Zhou GY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P250
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zhou XQ, 2018, NEUROCOMPUTING, V274, P8, DOI 10.1016/j.neucom.2016.07.082
NR 112
TC 6
Z9 6
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD SEP 27
PY 2021
VL 228
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107278
EA JUL 2021
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UB6YZ
UT WOS:000685990600002
DA 2023-11-10
ER

PT J
AU Zhu, ZY
   Li, Y
   Wang, Y
   Wang, YJ
   Tong, HH
AF Zhu, Ziye
   Li, Yun
   Wang, Yu
   Wang, Yaojing
   Tong, Hanghang
TI A deep multimodal model for bug localization
SO DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Article
DE Bug localization; Bug report; Multimodal learning; Attention mechanism; Multi-grained features
AB Bug localization utilizes the collected bug reports to locate the buggy source files. The state of the art falls short in handling the following three aspects, including (L1) the subtle difference between natural language and programming language, (L2) the noise in the bug reports and (L3) the multi-grained nature of programming language. To overcome these limitations, we propose a novel deep multimodal model named DeMoB for bug localization. It embraces three key features, each of which is tailored to address each of the three limitations. To be specific, the proposed DeMoB generates the multimodal coordinated representations for both bug reports and source files for addressing L1. It further incorporates the AttL encoder to process bug reports for addressing L2, and the MDCL encoder to process source files for addressing L3. Extensive experiments on four large-scale real-world data sets demonstrate that the proposed DeMoB significantly outperforms existing techniques.
C1 [Zhu, Ziye; Li, Yun; Wang, Yu] Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Big Data Secur & Intelligent Proc, Nanjing, Peoples R China.
   [Li, Yun; Wang, Yaojing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Tong, Hanghang] Univ Illinois, Dept Comp Sci, Urbana, IL USA.
C3 Nanjing University of Posts & Telecommunications; Nanjing University; University of Illinois System; University of Illinois Urbana-Champaign
RP Li, Y (通讯作者)，Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Big Data Secur & Intelligent Proc, Nanjing, Peoples R China.; Li, Y (通讯作者)，Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM 2016070251@njupt.edu.cn; liyun@njupt.edu.cn; 2017070114@njupt.edu.cn; wyj@smail.nju.edu.cn; htong@illinois.edu
FU Natural Science Foundation of China [61772284]; State Key Lab [KFKT2020B21]; Postgraduate Research and Practice Innovation Program of Jiangsu Province [SJKY19_0763]; NSF [1947135, 2003924]
CR Lam AN, 2017, INT C PROGRAM COMPRE, V0, PP218, DOI 10.1109/ICPC.2017.24
   [Anonymous], 2012, P INT C NEUR INF PRO, V0, P0
   [Anonymous], 2005, P 6 INT S AUTOMATED, V0, P0
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bennin KE, 2018, P 22 INT C EV ASS SO, V0, P101
   Cao Y, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1445, DOI 10.1145/2939672.2939812
   COSI P, 1994, INT CONF ACOUST SPEE, V0, P553
   Debroy V, 2009, UTDCS459, V0, P0
   DeMillo RA, 1997, P INT COMP SOFTW APP, V0, PP515, DOI 10.1109/CMPSAC.1997.625061
   Fidler S, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Huo X, 2016, IJCAI, V0, P1606
   Huo X, 2018, IEEE DATA MINING, V0, PP1049, DOI 10.1109/ICDM.2018.00133
   Huo X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1909
   Jiang Y, 2015, 2015 INTERNATIONAL SYMPOSIUM ON BIOELECTRONICS AND BIOINFORMATICS (ISBB), V0, PP1, DOI 10.1109/ISBB.2015.7344908
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim D, 2013, IEEE T SOFTWARE ENG, V39, P1597, DOI 10.1109/TSE.2013.24
   King DB, 2015, ACS SYM SER, V1214, P1
   Li W, 2012, SCI CHINA INFORM SCI, V55, P133, DOI 10.1007/s11432-011-4530-2
   Liu ZN, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2137, DOI 10.1145/3357384.3358155
   Lukins SK, 2008, WORK CONF REVERSE EN, V0, PP155, DOI 10.1109/WCRE.2008.33
   Marcus A, 2004, 11TH WORKING CONFERENCE ON REVERSE ENGINEERING, V0, P214, DOI 10.1109/WCRE.2004.10
   Mihalcea R, 2006, LECT NOTES COMPUT SC, V3878, P319
   Mroueh Y, 2015, INT CONF ACOUST SPEE, V0, PP2130, DOI 10.1109/ICASSP.2015.7178347
   Peters ME, 2018, P 2018 C N AM CHAPTE, V0, P0, DOI DOI 10.18653/V1/N18-1202
   Poria S, 2016, IEEE DATA MINING, V0, PP439, DOI 10.1109/ICDM.2016.0055
   Rahman MM, 2018, PROC IEEE ACM INT C, V0, PP348, DOI 10.1145/3183440.3195003
   Rajagopalan SS, 2016, LECT NOTES COMPUT SC, V9911, P338, DOI 10.1007/978-3-319-46478-7_21
   Saha RK, 2013, IEEE INT CONF AUTOM, V0, PP345, DOI 10.1109/ASE.2013.6693093
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi ZD, 2018, APPL SOFT COMPUT, V62, P636, DOI 10.1016/j.asoc.2017.10.048
   Silberer C, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P721
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sterling CD, 2007, SOFTWARE PRACT EXPER, V37, P1061, DOI 10.1002/spe.798
   Hoang T, 2019, IEEE T SOFTWARE ENG, V45, P1002, DOI 10.1109/TSE.2018.2810892
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Wang YJ, 2018, IEEE DATA MINING, V0, PP607, DOI 10.1109/ICDM.2018.00076
   Wong WE, 2006, J SYST SOFTWARE, V79, P891, DOI 10.1016/j.jss.2005.06.045
   Xiao Y, 2017, ASIA PAC SOFWR ENG, V0, PP338, DOI 10.1109/APSEC.2017.40
   Xu YB, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2565, DOI 10.1145/3219819.3220051
   Ye X, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), V0, PP689, DOI 10.1145/2635868.2635874
   Zhang J, 2015, SCI CHINA INFORM SCI, V58, P0, DOI 10.1007/s11432-014-5241-2
   Zhang YD, 2019, AAAI CONF ARTIF INTE, V0, P5845
   Zhou J, 2012, PROC INT CONF SOFTW, V0, PP14, DOI 10.1109/ICSE.2012.6227210
NR 47
TC 10
Z9 11
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1384-5810
EI 1573-756X
J9 DATA MIN KNOWL DISC
JI Data Min. Knowl. Discov.
PD JUL 15
PY 2021
VL 35
IS 4
BP 1369
EP 1392
DI 10.1007/s10618-021-00755-7
EA APR 2021
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA SX2CO
UT WOS:000645169900001
DA 2023-11-10
ER

PT J
AU Engesser, T
   Mattmüller, R
   Nebel, B
   Thielscher, M
AF Engesser, Thorsten
   Mattmueller, Robert
   Nebel, Bernhard
   Thielscher, Michael
TI Game description language and dynamic epistemic logic compared
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Game description language; Dynamic epistemic logic
AB Several different frameworks have been proposed to model and reason about knowledge in dynamic multi-agent settings, among them the logic-programming-based game description language GDL-III and dynamic epistemic logic (DEL). GDL-III and DEL have complementary strengths and weaknesses in terms of ease of modeling and simplicity of semantics. In this paper, we formally study the expressiveness of GDL-III vs. DEL. We clarify the commonalities and differences between those languages, demonstrate how to bridge the differences where possible, and identify large fragments of GDL-III and DEL that are equivalent in the sense that they can be used to encode games or planning tasks that admit the same legal action sequences. We prove the latter by providing translations between those fragments of GDL-III and DEL. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Engesser, Thorsten; Mattmueller, Robert; Nebel, Bernhard] Univ Freiburg, Fac Engn, Freiburg, Germany.
   [Thielscher, Michael] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
C3 University of Freiburg; University of New South Wales Sydney
RP Engesser, T (通讯作者)，Univ Freiburg, Fac Engn, Freiburg, Germany.; Thielscher, M (通讯作者)，Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
EM engesser@cs.uni-freiburg.de; mattmuel@cs.uni-freiburg.de; nebel@cs.uni-freiburg.de; mit@unsw.edu.au
CR Apt K, 1987, FDN DEDUCTIVE DATABA, V0, P89
   Baral C, 2017, DAGSTUHL REPORTS, V7, P1
   Bolander Thomas, 2011, JOURNAL OF APPLIED NON-CLASSICAL LOGIC, V21, P9, DOI 10.3166/jancl.21.9-34
   Bolander T, 2014, CEUR WORKSHOP P, V0, P87
   Bolander T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P2791
   Charrier T, 2016, P 25 INT JOINT C ART, V0, P1030
   Clark KL, 1978, LOGIC AND DATA BASES, V0, P293
   Cooper MC, 2016, FRONT ARTIF INTEL AP, V285, P193, DOI 10.3233/978-1-61499-672-9-193
   Engesser T, 2017, ELECTRON P THEOR COM, V0, PP75, DOI 10.4204/EPTCS.243.6
   Gelfond M, 2008, FOUND ARTIF INTELL, V0, PP285, DOI 10.1016/S1574-6526(07)03007-6
   Genesereth M, 2005, AI MAG, V26, P62
   Genesereth M, 2014, SYNTHESIS LECT AI MA, V0, P0
   Kominis F, 2015, P I C AUTOMAT PLAN S, V0, P147
   Kooi B, 2011, P 13 C THEOR ASP RAT, V0, PP205, DOI 10.1145/2000378.2000403
   Le Tiep, 2018, P ICAPS, V0, P0
   Liu Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1912
   Lloyd J, 1987, SERIES SYMBOLIC COMP, V0, P0
   Löwe B, 2011, LECT NOTES ARTIF INT, V6953, P179, DOI 10.1007/978-3-642-24130-7_13
   Moses Y, 2016, ELECTRON P THEOR COM, V0, PP231, DOI 10.4204/EPTCS.215.17
   Muise C, 2015, AAAI CONF ARTIF INTE, V0, P3327
   Rasmusen E, 2007, GAMES INFORM INTRO G, V0, P0
   Ruan J, 2011, P AAAI, V0, P840
   Schiffel S, 2014, J ARTIF INTELL RES, V49, P171, DOI 10.1613/jair.4115
   Schiffel S, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), V0, P911
   Thielscher M, 2017, IJCAI 17, V0, P1276
   van Benthem J, 2006, INFORM COMPUT, V204, P1620, DOI 10.1016/j.ic.2006.04.006
   VanDitmarsch H, 2007, SYNTH LIBR, V337, P1, DOI 10.1007/978-1-4020-5839-4
   Wan H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1093
NR 28
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD MAR 15
PY 2021
VL 292
IS 
BP 
EP 
DI 10.1016/j.artint.2020.103433
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA TI1SQ
UT WOS:000672565500003
DA 2023-11-10
ER

PT J
AU Yazi, FS
   Vong, WT
   Raman, V
   Then, PHH
   Lunia, MJ
AF Yazi, Fatin Syafiqah
   Vong, Wan-Tze
   Raman, Valliappan
   Then, Patrick Hang Hui
   Lunia, Mukulraj J.
TI AN EXPERIMENTAL EVALUATION OF DEEP NEURAL NETWORK MODEL PERFORMANCE FOR THE RECOGNITION OF CONTRADICTORY MEDICAL RESEARCH CLAIMS USING SMALL AND MEDIUM-SIZED CORPORA
SO MALAYSIAN JOURNAL OF COMPUTER SCIENCE
LA English
DT Article
DE Evidence-based medicine; contradiction detection; medical literature; deep neural network; deep learning
AB Corpora come in various shapes and sizes and play an essential role in facilitating Natural Language Processing (NLP) tasks. However, the availability of corpora specialized for Evidence-Based Medicine (EBM) related tasks is limited. The study is aimed to discover how the size of a corpus influence the performance of our Deep Neural Network (DNN) model developed for contradiction detection in medical literature. We explored the potential of the EBM Summarizer corpus by Molla and Santiago-Martinez, a medium-sized corpus to be used with our contradiction detection model. The dataset preparation involves the filtering of open-ended questions, duplicates of claims, and vague claims. As a result, two datasets were created with the claim input represented by sniptext in one dataset and longtext in the other. Experiments were conducted with varying numbers of hidden layers and units of the model using different datasets. The performance of the DNN model was recorded and compared with the result of using a small-sized corpus. It was found that the DNN model performance did not improve even after it was trained with a larger dataset derived from the medium-sized corpus. The factors may include the limitation of the DNN model itself and the quality of the datasets.
C1 [Yazi, Fatin Syafiqah; Vong, Wan-Tze; Raman, Valliappan; Then, Patrick Hang Hui] Swinburne Univ Technol, Fac Engn Comp & Sci, Kuching 93350, Malaysia.
   [Lunia, Mukulraj J.] Sri Krishna Coll Informat Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
C3 Swinburne University of Technology; Swinburne University of Technology Sarawak
RP Yazi, FS (通讯作者)，Swinburne Univ Technol, Fac Engn Comp & Sci, Kuching 93350, Malaysia.
EM fyazi@swinburne.edu.my; wvong@swinburne.edu.my; vraman@swinburne.edu.my; pthen@swinburne.edu.my; mukul_lunia99@outlook.com
CR ALAMRI A, 2016, DETECTION CONTRADICT, V0, P0
   Alamri A, 2016, J BIOMED SEMANT, V7, P0, DOI 10.1186/s13326-016-0083-z
   Bavani ES, 2016, P COLING 2016 26 INT, V0, P0
   Cohn C, 2020, COLL COMPUT DIGIT ME, V0, P0
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Devlin J, 2018, ARXIV, V1, P4171
   Ezen-Can A, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Gauch R, 2008, ITS GREAT OOPS NO IT, V0, P0
   GUYAT GH, 1993, JAMA-J AM MED ASSOC, V270, P2096, DOI 10.1001/jama.270.17.2096
   Kim JD, 2003, BIOINFORMATICS, V19, Pi180, DOI 10.1093/bioinformatics/btg1023
   Kim T, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2528
   Mollá D, 2016, LANG RESOUR EVAL, V50, P705, DOI 10.1007/s10579-015-9327-2
   Molla Diego, 2011, P AUSTRALASIAN LANGU, V0, P86
   Nye B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P197
   Ohta T, 2002, GENIA CORPUS ANNOTAT, V0, P82
   Prasad V, 2013, MAYO CLIN PROC, V88, P790, DOI 10.1016/j.mayocp.2013.05.012
   Richardson W S, 1995, ACP J CLUB, V123, P0
   Rosemblat G, 2019, J BIOMED INFORM, V98, P0, DOI 10.1016/j.jbi.2019.103275
   Sackett DL, 1996, BRIT MED J, V312, P71, DOI 10.1136/bmj.312.7023.71
   Sarafraz F, 2012, FINDING CONFLICTING, V0, P0
   Sarker A, 2020, LIGHT WEIGHT TEXT SU, V0, P0, DOI DOI 10.1101/2020.05.22.20110742v1
   Song X, 2020, LINEAR TIME WORDPIEC, V0, P0
   Tawfik NS, 2019, LECT NOTES COMPUT SC, V11608, P368, DOI 10.1007/978-3-030-23281-8_32
   Tawfik NS, 2018, INT C MACH LEARN DAT, V1, P138, DOI 10.1007/978-3-319-96136-112
   Usha S, 2020, J CRIT REV, V7, P1047
   Vincze V, 2008, BMC BIOINFORMATICS, V9, P0, DOI 10.1186/1471-2105-9-S11-S9
   Yazi Fatin Syafiqah, 2021, 2021 FIFTH INTERNATIONAL CONFERENCE ON INFORMATION RETRIEVAL AND KNOWLEDGE MANAGEMENT (CAMP), V0, PP116, DOI 10.1109/CAMP51653.2021.9498061
NR 27
TC 1
Z9 1
U1 1
U2 3
PU UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH
PI KUALA LUMPUR
PA UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH, KUALA LUMPUR, 50603, MALAYSIA
SN 0127-9084
EI 
J9 MALAYS J COMPUT SCI
JI Malayas. J. Comput. Sci.
PD JUN 15
PY 2021
VL 0
IS 
BP 68
EP 77
DI 10.22452/mjcs.sp2021no2.5
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA YQ8SY
UT WOS:000749575900005
DA 2023-11-10
ER

PT J
AU Mohan, P
   Sundaram, M
   Satpathy, S
   Das, S
AF Mohan, Prakash
   Sundaram, Manikandan
   Satpathy, Sambit
   Das, Sanchali
TI An efficient technique for cloud storage using secured de-duplication algorithm
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Vector space Model; Wordnet; deduplication; cosine similarity; NLTK
AB Techniques of data compression involve de-duplication of data that plays an important role in eliminating duplicate copies of information and has been widely employed in cloud storage to scale back the storage capacity and save information measure. A secure AES encryption de-duplication system for finding duplication with the meaning and store up it in the cloud. To protect the privacy of sensitive information whereas supporting de-duplication, The AES encryption technique and SHA-256 hashing algorithm have been utilized to encrypt the information before outsourcing. Pre-processing is completed and documents are compared and verified with the use of wordnet. Cosine similarity is employed to see the similarity between both the documents and to perform this, a far economical VSM data structure is used. Wordnet hierarchical corpus is used to see syntax and semantics so that the identification of duplicates is done. NLTK provides a large vary of libraries and programs for symbolic and statistical natural language process (NLP) for the Python programming language that is used here for the unidentified words by cosine similarity. Within the previous strategies, cloud storage was used abundantly since similar files were allowed to store. By implementing our system, space for storing is reduced up to 85%. Since AES and SHA-256 are employed, it provides high security and efficiency.
C1 [Mohan, Prakash; Sundaram, Manikandan] Karpagam Coll Engn, Data Sci & Analyt Ctr, Coimbatore, Tamil Nadu, India.
   [Satpathy, Sambit; Das, Sanchali] Noida Inst Engn & Technol, Greater Noida, Uttar Pradesh, India.
C3 Noida Institute of Engineering & Technology
RP Mohan, P (通讯作者)，Karpagam Coll Engn, Data Sci & Analyt Ctr, Coimbatore, Tamil Nadu, India.
EM salemprakash@gmail.com
CR Akhila K, 2016, PROCEDIA COMPUT SCI, V87, P38, DOI 10.1016/j.procs.2016.05.123
   [Anonymous], 2016, INT J COMPUT SCI MOB, V0, P0
   [Anonymous], 2012, J CHINA U POSTS TELE, V0, P0
   Bellare M, 2009, J CRYPTOL, V22, P1, DOI 10.1007/s00145-008-9028-8
   Bugiel S, 2011, WORKSH CRYPT SEC CLO, V0, P0
   Cui H, 2017, IEEE T BIG DATA, V0, P1
   Farah Sayeed R, 2015, INT J APPL ENG RES, V10, P8121
   Farkiya Alabhya, 2015, INT J COMPUTER SCI I, V6, P5465
   Gupta B, 2017, INT J COMPUT APPL, V165, P29, DOI 10.5120/IJCA2017914022
   Jiang T, 2017, IEEE T INF FOREN SEC, V12, P532, DOI 10.1109/TIFS.2016.2622013
   Jurafsky D, 2009, SPEECH LANGUAGE PROC, V0, P0
   KALE MA, 2018, INT J ADV SCI RES, V3, P14
   Liu HB, 2012, J BIOMED SEMANT, V3, P0, DOI 10.1186/2041-1480-3-3
   Mohan P, 2017, INT J INF SECUR PRIV, V11, P1, DOI 10.4018/IJISP.2017040101
   Prajapati P, 2020, J KING SAUD UNIV-COM, V0, P0, DOI DOI 10.1016/j.jksuci.2020.10.021
   Puzio P, 2016, INT J COMPUTER APPL, V3, P206
   Raghatate R, 2014, INT J COMPUTER SCI M, V3, P0
   Ramalingam C, 2021, SYMMETRY-BASEL, V13, P0, DOI 10.3390/sym13020317
   Rashid F, 2012, 2012 TENTH ANNUAL INTERNATIONAL CONFERENCE ON PRIVACY, V0, P81, DOI 10.1109/PST.2012.6297923
   Shynu PG, 2020, J CLOUD COMPUT-ADV S, V9, P0, DOI 10.1186/s13677-020-00214-6
   Sivashakthi P, 2013, INT J ENG TECHNOLOGY, V3, P2250
   Sridharan J, 2019, ADV INTELLIGENT SYST, V758, P0, DOI 10.1007/ 978- 981- 13- 0514-6 67
   Tang X, 2021, SECUR COMMUN NETW, V2021, P0, DOI 10.1155/2021/6686281
   Verma S, 2015, INT J COMPUTER SECUR, V1, P2454
   Vurukonda N, 2016, PROCEDIA COMPUT SCI, V92, P128, DOI 10.1016/j.procs.2016.07.335
   Walunj RS, 2014, INTERNATIONAL J ENG, V11, P34
   Yan Z, 2016, IEEE CLOUD COMPUT, V3, P28, DOI 10.1109/MCC.2016.29
   Zaware ASN, 2015, INT J ADV ENG RES DE, V2, P2348
   Zheng Yan, 2016, IEEE TRANSACTIONS ON BIG DATA, V2, P138, DOI 10.1109/TBDATA.2016.2587659
NR 29
TC 23
Z9 23
U1 2
U2 4
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2021
VL 41
IS 2
BP 2969
EP 2980
DI 10.3233/JIFS-210038
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA US3NM
UT WOS:000697340200032
DA 2023-11-10
ER

PT J
AU Abul Bashar, M
   Nayak, R
AF Abul Bashar, Md
   Nayak, Richi
TI Active Learning for Effectively Fine-Tuning Transfer Learning to Downstream Task
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE Misogynistic tweet; hate speech; active learning; transfer learning; imbalanced dataset; topic model
ID framework
AB Language model (LM) has become a common method of transfer learning in Natural Language Processing (NLP) tasks when working with small labeled datasets. An LM is pretrained using an easily available large unlabelled text corpus and is fine-tuned with the labelled data to apply to the target (i.e., downstream) task. As an LM is designed to capture the linguistic aspects of semantics, it can be biased to linguistic features. We argue that exposing an LM model during fine-tuning to instances that capture diverse semantic aspects (e.g., topical, linguistic, semantic relations) present in the dataset will improve its performance on the underlying task. We propose a Mixed Aspect Sampling (MAS) framework to sample instances that capture different semantic aspects of the dataset and use the ensemble classifier to improve the classification performance. Experimental results show that MAS performs better than random sampling as well as the state-of-the-art active learning models to abuse detection tasks where it is hard to collect the labelled data for building an accurate classifier.
C1 [Abul Bashar, Md; Nayak, Richi] Queensland Univ Technol, Sch Comp Sci, 2 George St, Brisbane, Qld 4000, Australia.
C3 Queensland University of Technology (QUT)
RP Abul Bashar, M (通讯作者)，Queensland Univ Technol, Sch Comp Sci, 2 George St, Brisbane, Qld 4000, Australia.
EM m1.bashar@qut.edu.au; r.nayak@qut.edu.au
FU QUT IFE Catapult fund
CR Abul Bashar M, 2020, KNOWL INF SYST, V62, P4029, DOI 10.1007/s10115-020-01481-0
   Abul Bashar M, 2018, DATA MIN KNOWL DISC, V32, P849, DOI 10.1007/s10618-018-0556-z
   Abul Bashar M, 2017, COMPUT INTELL-US, V33, P948, DOI 10.1111/coin.12133
   AHLUWALIA R, 2018, EVALITA EVAL NLP SPE, V12, P194, DOI 10.4000/BOOKS.AACCADEMIA.4698
   Alharbi AS, 2018, LECT NOTES ARTIF INT, V11320, P656, DOI 10.1007/978-3-030-03991-2_59
   Andrzejewski D, 2011, P 17 ACM SIGKDD INT, V0, PP600, DOI 10.1145/2020408.2020503
   [Anonymous], 2010, P 16 ACM SIGKDD INT, V0, P0, DOI DOI 10.1145/1835804.1835859
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2004, KERNEL QUERY COMMITT, V0, P0
   [Anonymous], 2018, ARXIV180104433, V0, P0
   [Anonymous], 2009, TECHNICAL REPORT, V0, P0
   [Anonymous], 2004, 16 IASC INT S COMPUT, V0, P0
   [Anonymous], 2014, CSCW, V0, P0
   Attenberg J, 2011, ACM SIGKDD EXPLORATI, V12, P36, DOI 10.1145/1964897.1964906
   Badjatiya P, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP759, DOI 10.1145/3041021.3054223
   Bashar Md Abul, 2017, AI 2017: ADVANCES IN ARTIFICIAL INTELLIGENCE. 30TH AUSTRALASIAN JOINT CONFERENCE. PROCEEDINGS: LNAI 10400, V0, PP237, DOI 10.1007/978-3-319-63004-5_19
   Bashar MA, 2018, 16 AUSTRALASIAN DATA, V0, P3
   Bashar MA, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), V0, PP105, DOI 10.1109/WI.2016.25
   Bashar Md Abul, 2018, P 16 AUSTR DAT MIN C, V0, P0
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cai D, 2012, IEEE T KNOWL DATA EN, V24, P707, DOI 10.1109/TKDE.2011.104
   Cai WB, 2015, INFORM RETRIEVAL J, V18, P123, DOI 10.1007/s10791-015-9250-6
   CARTER CK, 1994, BIOMETRIKA, V81, P541
   Chattopadhyay R, 2013, ACM T KNOWL DISCOV D, V7, P0, DOI 10.1145/2513092.2513094
   Chelba C, 2014, ARXIV PREPRINT ARXIV, V0, P0
   Chemudugunta C, 2008, LECT NOTES COMPUT SC, V5318, P229, DOI 10.1007/978-3-540-88564-1_15
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Craven M, 1999, PROC INT CONF INTELL SYST MOL BIOL, V0, P77
   Dai Andrew M, 2015, NIPS, V0, P0
   Dasgupta S, 2008, P 25 INT C MACHINE L, V0, PP208, DOI 10.1145/1390156.1390183
   Davidson T, 2017, 11 INT AAAI C WEB SO, V11, P0
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   Devlin J, 2018, ARXIV, V1, P4171
   Downey A, 2012, THINK BAYES BAYESIAN, V0, P0
   Ertekin S, 2007, P 16 ACM C C INF KNO, V0, PP127, DOI 10.1145/1321440.1321461
   Fersini Elisabetta, 2018, P 6 EV CAMP NAT LANG, V0, P0
   Gal Y, 2016, ADV NEUR IN, V29, P0
   Gao Y, 2017, ACM T INTEL SYST TEC, V9, P0, DOI 10.1145/3094786
   Gitari ND, 2015, INT J MULTIMEDIA UBI, V10, P215, DOI 10.14257/IJMUE.2015.10.4.21
   Goutsias J, 2012, RANDOM SETS THEORY A, V97, P0
   Gulordava K, 2018, ARXIV180311138, V0, P0
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang SJ, 2014, IEEE T PATTERN ANAL, V36, P1936, DOI 10.1109/TPAMI.2014.2307881
   Hulpus I, 2013, P 6 ACM INT C WEB SE, V0, PP465, DOI 10.1145/2433396.2433454
   Kruse R, 2012, UNCERTAINTY VAGUENES, V0, P0
   Lewis DD, 1994, SIGIR 94. PROCEEDINGS OF THE SEVENTEENTH ANNUAL INTERNATIONAL ACM-SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P3
   Lin CH, 2018, P 6 AAAI C HUMAN COM, V0, P0
   Liu P, 2019, P 13 INT WORKSH SEM, V0, PP87, DOI 10.18653/v1/S19-2011
   Liu WH, 2020, ACM T INTEL SYST TEC, V11, P0, DOI 10.1145/3372121
   Liu WH, 2018, ACM T INTEL SYST TEC, V9, P0, DOI 10.1145/3230709
   Logeswaran L, 2018, INT C LEARN REPR, V0, P0
   Melis G, 2017, ARXIV170705589, V0, P0
   Merity Stephen, 2017, ICLR, V0, P0
   Mikolov T, 2012, IEEE W SP LANG TECH, V0, PP234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   MOLCHANOV I, 2005, THEORY RANDOM SETS, V19, P0
   Molchanov Ilya, 2006, THEORY RANDOM SETS, V0, P0
   Patterson G, 2015, P AAAI C HUM COMP CR, V3, P150
   Powers DM, 2011, EVALUATION PRECISION, V2, P37, DOI 10.48550/arXiv.2010.16061
   Radford A, 2017, LEARNING GENERATE RE, V0, P0
   Re C, 2016, HILDA 16 SIGMOD, V0, P0, DOI DOI 10.1145/2939502.2939515
   Reyes O, 2018, ACM T INTEL SYST TEC, V9, P0, DOI 10.1145/3161606
   Settles B, 2008, P 2008 C EMPIRICAL M, V0, P1070
   Seung HS, 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP287, DOI 10.1145/130385.130417
   Sharma M, 2017, DATA MIN KNOWL DISC, V31, P164, DOI 10.1007/s10618-016-0460-3
   Shi LX, 2012, ACM T INTEL SYST TEC, V3, P0, DOI 10.1145/2089094.2089109
   Silva L, 2016, P INT AAAI C WEB SOC, V10, P687, DOI 10.1609/icwsm.v10i1.14811
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun C, 2017, IEEE I CONF COMP VIS, V0, PP843, DOI 10.1109/ICCV.2017.97
   Tal Linzen, 2016, ARXIV161101368, V0, P0
   Thompson CA, 1999, MACHINE LEARNING, V0, P406
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P384
   Vidgen, 2020, ARXIV200503909, V0, P0
   Wang M, 2017, EXPERT SYST APPL, V85, P305, DOI 10.1016/j.eswa.2017.05.046
   West Jeremy, 2007, B YOUNG U COLL PHYS, V1, P32
   Williams W, 2015, INT CONF ACOUST SPEE, V0, PP5391, DOI 10.1109/ICASSP.2015.7179001
   Wu, 2016, ARXIV160202410, V0, P0
   Xiang G, 2012, P 21 ACM INT C INFOR, V0, PP1980, DOI 10.1145/2396761.2398556
   Yoo D, 2019, PROC CVPR IEEE, V0, PP93, DOI 10.1109/CVPR.2019.00018
   You XG, 2014, IEEE T IMAGE PROCESS, V23, P3203, DOI 10.1109/TIP.2014.2327805
   Yu D, 2010, COMPUT SPEECH LANG, V24, P433, DOI 10.1016/j.csl.2009.03.004
   Zaremba W, 2014, PREPRINT, V0, P0
   Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260, DOI 10.1109/TMM.2002.1017738
   Zhang Kelly W, 2018, ARXIV180910040, V0, P0
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
   Zhu J, 2008, P 22 INT C COMPUTATI, V1, P1137
NR 90
TC 7
Z9 7
U1 1
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2157-6904
EI 2157-6912
J9 ACM T INTEL SYST TEC
JI ACM Trans. Intell. Syst. Technol.
PD MAR 15
PY 2021
VL 12
IS 2
BP 
EP 
DI 10.1145/3446343
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA QY6ZE
UT WOS:000630185800011
DA 2023-11-10
ER

PT J
AU Chinnalagu, A
   Durairaj, AK
AF Chinnalagu, Anandan
   Durairaj, Ashok Kumar
TI Context-based sentiment analysis on customer reviews using machine learning linear models
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Natural language processing; Text analytics; Machine learning; Linear models
AB Customer satisfaction and their positive sentiments are some of the various goals for successful companies. However, analyzing customer reviews to predict accurate sentiments have been proven to be challenging and time-consuming due to high volumes of collected data from various sources. Several researchers approach this with algorithms, methods, and models. These include machine learning and deep learning (DL) methods, unigram and skip-gram based algorithms, as well as the Artificial Neural Network (ANN) and bag-of-word (BOW) regression model. Studies and research have revealed incoherence in polarity, model overfitting and performance issues, as well as high cost in data processing. This experiment was conducted to solve these revealing issues, by building a high performance yet cost-effective model for predicting accurate sentiments from large datasets containing customer reviews. This model uses the fastText library from Facebook's AI research (FAIR) Lab, as well as the traditional Linear Support Vector Machine (LSVM) to classify text and word embedding. Comparisons of this model were also done with the author's a custom multi-layer Sentiment Analysis (SA) Bi-directional Long Short-Term Memory (SA-BLSTM) model. The proposed fastText model, based on results, obtains a higher accuracy of 90.71% as well as 20% in performance compared to LSVM and SA-BLSTM models.
C1 [Chinnalagu, Anandan; Durairaj, Ashok Kumar] Bharathidasan Univ, Govt Arts Coll, Comp Sci, Karur, Tamil Nadu, India.
C3 Bharathidasan University
RP Chinnalagu, A (通讯作者)，Bharathidasan Univ, Govt Arts Coll, Comp Sci, Karur, Tamil Nadu, India.
EM anandanc@hotmail.com
CR Alharbi NM, 2021, MATH PROBL ENG, V2021, P0, DOI 10.1155/2021/5536560
   [Anonymous], 2007, QA ATTITUDE EXPLOITI, V0, P0
   [Anonymous], 2017, HDLTEX HIERARCHICAL, V0, P0
   Ashok Kumar D, 2020, P 9 INT C SYST MOD A, V0, P0, DOI DOI 10.1109/SMART50582.2020.9337098
   Bo Pang, 2008, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V2, P1, DOI 10.1561/1500000001
   Bojanowski Piotr, 2017, ARXIV170705776, V0, P0
   Chinatalapudi N, 2021, SENTIMENTAL ANAL COV, V0, P0
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Crone SF, 2015, ARTIFICIAL NEURAL NE, V0, P0
   Gaye B, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.712
   Gopalakrishnan Karthik, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Ikonomakis M, 2005, WSEAS TRANSACTIONS ON COMPUTERS, V4, P966
   Joachims T, 1998, P 10 EUR C MACH LEAR, V0, PP137, DOI 10.1007/BFB0026683
   Joulin Armand, 2016, ARXIV160701759, V0, P0
   Kowalczyk A, 2017, SUPPORT VECTOR MACHI, V0, P0
   Kowsari K, 2019, INFORMATION, V10, P0, DOI 10.3390/info10040150
   Kruspe A, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Kumar SA, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.713
   Labhsetwar SR, 2020, ICTACT J SOFT COMPUT, V10, P2054
   Mestre M, 2018, FASTTEXT STEPPING CO, V0, P0
   Mikolov T, 2012, EXPLOITING SIMILARIT, V0, P0
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mittal A, 2019, SENTIMENT ANAL TWITT, V0, P0
   Nitsche M, 2019, COMP NEURAL DOCUMENT, V0, P0
   Qu L, 2010, P 23 INT C COMPUTATI, V0, P913
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, P129
   Zhang X, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Zolotov V, 2017, ARXIV170205531, V0, P0
NR 29
TC 4
Z9 4
U1 3
U2 15
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD DEC 17
PY 2021
VL 7
IS 
BP 
EP 
DI 10.7717/peerj-cs.813
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA XU1BU
UT WOS:000734010400003
PM 35036535
DA 2023-11-10
ER

PT J
AU Criollo-C, S
   Lema, M
   Gonzalez, MS
   Jaramillo-Alcázar, A
   Guerrero-Arias, A
   Luján-Mora, S
AF Criollo-C, Santiago
   Lema, Mayron
   Gonzalez, Mario Salvador
   Jaramillo-Alcazar, Angel
   Guerrero-Arias, Andrea
   Lujan-Mora, Sergio
TI Exploring the technological acceptance of a mobile learning tool used in the teaching of an indigenous language
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Mobile learning; m-learning; Mobile applications; Mobile devices; Kichwa; Learning; Education; Mobile app; DSR; UTAUT Model
ID higher-education; students; university; intention; system
AB Language is the primordial element for cultural transfer in indigenous communities; if it is not practiced, there is a risk of losing it and with it, a large part of the history of a community. Ecuador is a multicultural and multiethnic country with 18 indigenous peoples. Currently, in this country, some native languages are at risk of disappearing due to factors such as racial discrimination, underestimation of the language, and, above all, the lack of interest and motivation of the new generations to learn this language. Information technologies have made it possible to create mobile applications such as games, dictionaries, and translators that promote the learning of the Kichwa language. However, the acceptance of technology has not been evaluated, nor the intention to involve mobile devices in the process of teaching this language. Subsequently the objective of this work is to explore the acceptance of technology and the use of mobile devices to motivate the learning of the Kichwa language. For this purpose, the mobile application "Otavalo Rimay" was used with several students of a Kichwa language learning center. The methodology used to verify the hypothesis of this work was Design Sciences Research (DSR) together with the theory of acceptance and use of technology (UTAUT). The instrument used for this evaluation was a survey carried out after the use of the mobile application. The statistical analysis of the results obtained indicates characteristics such as the utility and perceived ease of use, positively influence students to motivate the use of mobile devices in learning a language. The results also show the great technological acceptance by students for learning and confirm that currently, mobile learning is accepted for use in education.
C1 [Criollo-C, Santiago; Lema, Mayron; Gonzalez, Mario Salvador; Jaramillo-Alcazar, Angel] Univ Las Amer, Fac Ingn & Ciencias Aplicadas, Quito, Pichincha, Ecuador.
   [Guerrero-Arias, Andrea] Jezreel Int Christian Acad, Dept EGB BGU, Quito, Pichincha, Ecuador.
   [Lujan-Mora, Sergio] Univ Alicante, Dept Software & Comp Syst, Alicante, Spain.
C3 Universidad de Las Americas - Ecuador; Universitat d'Alacant
RP Criollo-C, S (通讯作者)，Univ Las Amer, Fac Ingn & Ciencias Aplicadas, Quito, Pichincha, Ecuador.
EM luis.criollo@udla.edu.ec
CR Ahmad A, 2018, IEEE ACCESS, V6, P17711, DOI 10.1109/ACCESS.2018.2818724
   Almaiah Mohammed Amin, 2019, EDUCATION AND INFORMATION TECHNOLOGIES, V24, P885, DOI 10.1007/s10639-018-9810-7
   Almaiah Mohammed Amin, 2014, INTERNATIONAL JOURNAL OF INTERACTIVE MOBILE TECHNOLOGIES, V8, P31, DOI 10.3991/ijim.v8i4.3965
   Almaiah MA, 2019, EDUC INF TECHNOL, V24, P1433, DOI 10.1007/s10639-018-9840-1
   Almaiah MA, 2016, ENG SCI TECHNOL, V19, P1314, DOI 10.1016/j.jestch.2016.03.004
   [Anonymous], 2016, P INT C INT US INT, V0, P0
   [Anonymous], 1985, TECHNOLOGY ACCEPTANC, V0, P0
   Beckstead JW, 2002, WESTERN J NURS RES, V24, P307, DOI 10.1177/01939450222045923
   Bleustein-Blanchet M, 2016, TRAINING IND MAGAZIN, V1, P6
   Briz-Ponce L, 2017, COMPUT HUM BEHAV, V72, P612, DOI 10.1016/j.chb.2016.05.027
   Briz-Ponce L, 2015, J MED SYST, V39, P0, DOI 10.1007/s10916-015-0352-x
   Cisco, 2020, ANN REP 2018 2023, V0, P0
   CoboMdel P, 2015, DIARIO TELEGRAFO ENT, V0, P0
   Cook J, 2011, E LEARNING DIGITAL M, V0, PP181, DOI 10.2304/ELEA.2011.8.3.181
   Criollo-C S, 1900, P148, V0, P0
   Criollo S, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER SCIENCE (INCISCOS), V0, PP268, DOI 10.1109/INCISCOS.2017.43
   Dekhane S, 2014, P 15 ANN C INF TECHN, V0, PP133, DOI 10.1145/2656450.2656484
   Dingly A, 2015, NEW DIGITAL NATIVES, V0, P0
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   Grasso A, 2005, IEEE INTERNATIONAL WORKSHOP ON WIRELESS AND MOBILE TECHNOLOGIES IN EDUCATION, V0, P123, DOI 10.1109/WMTE.2005.27
   Hamada M, 1900, P369, V0, P0, DOI DOI 10.1145/2536853.2536917
   Hamidi H, 2018, TELEMAT INFORM, V35, P1053, DOI 10.1016/j.tele.2017.09.016
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   International Data Corporation, 2015, SMARTPHONE MARKET SH, V0, P0
   Kali Y, 2015, IEEE T LEARN TECHNOL, V8, P5, DOI 10.1109/TLT.2014.2365810
   Karjo CH, 2018, P INT C DIST ED LEAR, V0, PP109, DOI 10.11453231848.3231871
   Keengwe J, 2014, EDUC INF TECHNOL, V19, P441, DOI 10.1007/s10639-012-9235-7
   Law N, 2005, EDUC INF TECHNOL, V10, P5, DOI 10.1007/s10639-005-6743-8
   Liu Y, 2010, COMPUT EDUC, V55, P1211, DOI 10.1016/j.compedu.2010.05.018
   Madani HH, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY AND ACCESSIBILITY (ICTA), V0, P0
   MURTAGH F, 1983, COMPUT J, V26, P354, DOI 10.1093/comjnl/26.4.354
   Nitsche K, 2013, IEEE INT CONF ADV LE, V0, PP508, DOI 10.1109/ICALT.2013.166
   Nunkesser R, 2018, 2018 IEEE/ACM 5TH INTERNATIONAL CONFERENCE ON MOBILE SOFTWARE ENGINEERING AND SYSTEMS (MOBILESOFT), V0, PP214, DOI 10.1145/3197231.3197260
   Papadakis S, 2018, INT J MOB LEARN ORG, V12, P336, DOI 10.1504/IJMLO.2018.095130
   Park SY, 2012, BRIT J EDUC TECHNOL, V43, P592, DOI 10.1111/j.1467-8535.2011.01229.x
   Pimmer C, 2016, COMPUT HUM BEHAV, V63, P490, DOI 10.1016/j.chb.2016.05.057
   Robles-Bykbaev Y, 2018, 2018 IEEE BIENNIAL CONGRESS OF ARGENTINA (ARGENCON), V0, P0
   SanchezPrieto JC, 2017, REV EDUCACION DISTAN, V0, P0
   Taharim NF, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPLICATIONS, V0, P72, DOI 10.1109/NGMAST.2016.23
   Unesco, 2018, INDIGENOUS PEOPLES, V0, P0
   Unesco, 1990, WORLD C HIGH ED, V0, P0
   van Aken JE, 2004, J MANAGE STUD, V41, P219, DOI 10.1111/j.1467-6486.2004.00430.x
   Zappatore M, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTERACTIVE MOBILE COMMUNICATION TECHNOLOGIES AND LEARNING (IMCL), V0, PP96, DOI 10.1109/IMCTL.2015.7359563
   Zhang SH, 2016, INT J EMERG TECHNOL, V11, P4, DOI 10.3991/ijet.v11i12.6314
NR 44
TC 7
Z9 7
U1 1
U2 19
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 2376-5992
EI 
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUN 3
PY 2021
VL 0
IS 
BP 
EP 
DI 10.7717/peerj-cs.550
PG 27
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA SO3MN
UT WOS:000658880000001
PM 34150997
DA 2023-11-10
ER

PT J
AU Cui, BY
   Li, YM
   Zhang, ZF
AF Cui, Baiyun
   Li, Yingming
   Zhang, Zhongfei
TI Joint structured pruning and dense knowledge distillation for efficient transformer model compression
SO NEUROCOMPUTING
LA English
DT Article
DE Transformer Model Compression; Structured Pruning; Knowledge Distillation
AB In this paper, we develop a novel Joint Model Compression (referred to as JMC) method by combining structured pruning and dense knowledge distillation techniques to significantly compress original large language model into a deep compressed shallow network. In particular, a new Direct Importance-aware Structured Pruning (referred as DISP) approach is proposed to structurally prune the redundant structures in the Transformer networks directly based on the corresponding parameter matrices in the model. Besides, a Dense Knowledge Distillation (referred to as DKD) method is developed with a many-to-one layer mapping strategy to leverage more comprehensive layer-wise linguistic knowledge for the distillation. Further, the proposed structured pruning and dense knowledge distillation are integrated together to perform the joint compression, which enables us to achieve a significant compression without sacrificing model accuracy. The extensive experimental results across four NLP tasks on seven datasets demonstrate its effectiveness and superiority to the baselines, while maintaining similar performance to original large model with further remarkable benefits for inference-time speedup and memory efficiency. (c) CO 2021 Elsevier B.V. All rights reserved.
C1 [Cui, Baiyun; Li, Yingming] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China.
   [Zhang, Zhongfei] Binghamton Univ, Dept Comp Sci, Binghamton, NY USA.
C3 Zhejiang University; State University of New York (SUNY) System; State University of New York (SUNY) Binghamton
RP Li, YM (通讯作者)，Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China.
EM baiyunc@yahoo.com; yingming@zju.edu.cn; zzhang@binghamton.edu
FU Science and Technology Innovation [2018AAA0100904]; NSFC [U19B2043, 61702448]; HIKVision and Horizon Robotics; ZJU Converging Media Computing Lab; Artificial Intelligence Research Foundation of Baidu Inc.
CR Aguilar G, 2020, AAAI CONF ARTIF INTE, V34, P7350
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Bucilua C, 2006, P 12 ACM SIGKDD INT, V0, PP535, DOI 10.1145/1150402.1150464
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Chen XC, 2020, IEEE IJCNN, V0, P0, DOI DOI 10.1109/ijcnn48605.2020.9207010
   Devlin J, 2018, ARXIV, V1, P4171
   Ding R, 2019, P DAC, V0, P200
   Fan A, 2019, ICLR, V0, P0
   Fang Y, 2020, P 2020 C EMP METH NA, V0, P498
   Gale T, 2019, ARXIV190209574, V0, P0
   Han S, 2015, ADV NEUR IN, V28, P0
   Hinton Geoffrey, 2015, ARXIV150302531, V0, P0
   Hou Lu, 2020, NEURIPS, V33, P9782
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Jiao X, 2020, FINDINGS ASS COMPUTA, V0, P0
   Khetan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2807
   Khot T, 2018, AAAI CONF ARTIF INTE, V0, P5189
   Kim Young Jin, 2020, PROC SUSTAINLP WORK, V0, P149
   Lan Wuwei, 2017, P 2017 C EMP METH NA, V0, PP1224, DOI 10.18653/V1/D17-1126
   Lan Zhenzhong, 2019, ABS190911942, V0, P0
   Li B, 2020, FINDINGS ASS COMPUTA, V0, P3187
   Li JQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3009
   Lin Z, 2020, P FIND ASS COMP LING, V0, P719
   Liu Y, 2019, ROBUSTLY OPTIMIZED B, V0, P0
   Louizos Christos, 2018, ICLR, V0, P0
   Marelli M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   McCarley JS, 2019, ARXIV191006360, V0, P0
   Michel Paul, 2019, ADV NEURAL INFORM PR, V0, P14014
   Nakov P, 2013, 2 JOINT C LEXICAL CO, V0, P312
   Passban P, 2021, AAAI CONF ARTIF INTE, V35, P13657
   Peters ME, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), V0, P7
   Prasanna S, 2020, EMNLP, V0, P3208
   Romero A, 2015, FITNETS HINTS THIN D, V0, P0
   Sanh V, 2020, ADV NEURAL INFORM PR, V33, P20378
   Sanh V, 2019, ARXIV, V0, P0
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Stamoulis Dimitrios, 2019, ECML PKDD, V0, P0
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4323
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2158
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5797
   Wang Z, 2020, EMNLP, V0, P6151
   Xu CW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7859
   Yang Zhilin, 2019, P NEURIPS, V0, P0
   Yin Y, 2020, ARXIV PREPRINT ARXIV, V0, P0
NR 50
TC 8
Z9 11
U1 7
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 11
PY 2021
VL 458
IS 
BP 56
EP 69
DI 10.1016/j.neucom.2021.05.084
EA JUN 2021
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UJ8WL
UT WOS:000691559800006
DA 2023-11-10
ER

PT J
AU Sen, S
   Hasanuzzaman, M
   Ekbal, A
   Bhattacharyya, P
   Way, A
AF Sen, Sukanta
   Hasanuzzaman, Mohammed
   Ekbal, Asif
   Bhattacharyya, Pushpak
   Way, Andy
TI Neural machine translation of low-resource languages using SMT phrase pair injection
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Machine translation; Translation technology
AB Neural machine translation (NMT) has recently shown promising results on publicly available benchmark datasets and is being rapidly adopted in various production systems. However, it requires high-quality large-scale parallel corpus, and it is not always possible to have sufficiently large corpus as it requires time, money, and professionals. Hence, many existing large-scale parallel corpus are limited to the specific languages and domains. In this paper, we propose an effective approach to improve an NMT system in low-resource scenario without using any additional data. Our approach aims at augmenting the original training data by means of parallel phrases extracted from the original training data itself using a statistical machine translation (SMT) system. Our proposed approach is based on the gated recurrent unit (GRU) and transformer networks. We choose the Hindi-English, Hindi-Bengali datasets for Health, Tourism, and Judicial (only for Hindi-English) domains. We train our NMT models for 10 translation directions, each using only 5-23k parallel sentences. Experiments show the improvements in the range of 1.38-15.36 BiLingual Evaluation Understudy points over the baseline systems. Experiments show that transformer models perform better than GRU models in low-resource scenarios. In addition to that, we also find that our proposed method outperforms SMT-which is known to work better than the neural models in low-resource scenarios-for some translation directions. In order to further show the effectiveness of our proposed model, we also employ our approach to another interesting NMT task, for example, old-to-modern English translation, using a tiny parallel corpus of only 2.7K sentences. For this task, we use publicly available old-modern English text which is approximately 1000 years old. Evaluation for this task shows significant improvement over the baseline NMT.
C1 [Sen, Sukanta; Ekbal, Asif; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Patna, Bihar, India.
   [Hasanuzzaman, Mohammed; Way, Andy] Dublin City Univ, ADAPT Ctr, Dublin, Ireland.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of Technology System (IIT System); Dublin City University
RP Sen, S (通讯作者)，Indian Inst Technol Patna, Patna, Bihar, India.
EM sukanta.pcs15@iitp.ac.in
FU Visvesvaraya PhD scheme for Electronics and IT, Ministry of Electronics and Information Technology (MeitY), Government of India
CR [Anonymous], 2004, P 2004 C EMP METH NA, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Artetxe M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3632
   Arthur P, 2016, P 2016 C EMP METH NA, V0, PP1557, DOI 10.18653/V1/D16-1162
   Bahdanau D, 2016, ARXIV, V0, P0
   Bojar O, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3550
   Chatterjee Rajen, 2016, P WMT, V2, P131, DOI 10.18653/V1/W16-2301
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Crego JM, 2016, ARXIV161005540 CORR, V0, P0
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Feng Y, 2017, P 2017 C EMP METH NA, V0, PP1390, DOI 10.18653/V1/D17-1146
   Forcada ML, 1997, LECT NOTES COMPUT SC, V1240, P453, DOI 10.1007/BFb0032504
   Gulcehre C, 2017, COMPUT SPEECH LANG, V45, P137, DOI 10.1016/j.csl.2017.01.014
   Guzman Francisco, 2019, ARXIV190201382, V0, P0
   He W, 2016, AAAI CONF ARTIF INTE, V0, P151
   Heafield K, 2011, P 6 WORKSH STAT MACH, V0, P187
   Hieber Felix, 2017, ABS171205690 CORR, V0, P0
   Jha GN, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   JunczysDowmunt M, 2016, P 9 INT WORKSH SPOK, V0, P0
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kingma DP, 2014, C TRACK P, V0, P0
   KNESER R, 1995, INT CONF ACOUST SPEE, V0, PP181, DOI 10.1109/ICASSP.1995.479394
   Knight Kevin, 2016, ABS160402201 CORR, V0, P0
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P127
   Koehn P, 2017, WMT, V0, P28
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Kunchukuttan A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3473
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5039
   Niehues Jan, 2016, P COLING 2016 26 INT, V0, P1828
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paszke Adam, 2017, PROC 31 C NEURAL INF, V0, P6
   Ramachandran P, 2017, P 2017 C EMP METH NA, V0, PP383, DOI 10.18653/V1/D17-1039
   Ren S, 2019, AAAI CONF ARTIF INTE, V0, P241
   Sennrich R, 2017, P SOFTW DEM 15 C EUR, V0, PP65, DOI 10.18653/V1/E17-3017
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Song K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P449
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tang Yaohua, 2016, NEURAL MACHINE TRANS, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang X, 2017, AAAI CONF ARTIF INTE, V0, P3330
   Wang X, 2018, IEEE-ACM T AUDIO SPE, V26, P2255, DOI 10.1109/TASLP.2018.2860287
   Wang XY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P856
   Wu Y, 2016, ARXIV, V0, P0
   Zhang ZR, 2018, AAAI CONF ARTIF INTE, V0, P555
   Zhao Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4609
   Zong, 2016, P 2016 C EMP METH NA, V0, PP1535, DOI 10.18653/V1/D16-1160
NR 49
TC 10
Z9 10
U1 1
U2 21
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD MAY 15
PY 2021
VL 27
IS 3
BP 271
EP 292
DI 10.1017/S1351324920000303
PG 22
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA SK5CD
UT WOS:000656232400001
DA 2023-11-10
ER

PT J
AU Yogatama, D
   d'Autume, CD
   Kong, LP
AF Yogatama, Dani
   d'Autume, Cyprien de Masson
   Kong, Lingpeng
TI Adaptive Semiparametric Language Models
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We present a language model that combines a large parametric neural network (i.e., a transformer) with a non-parametric episodic memory component in an integrated architecture. Our model uses extended short-term context by caching local hidden states-similar to transformer-XL-and global long-term memory by retrieving a set of nearest neighbor tokens at each timestep. We design a gating function to adaptively combine multiple information sources to make a prediction. This mechanism allows the model to use either local context, short-term memory, or long-term memory (or any combination of them) on an ad hoc basis depending on the context. Experiments on word-based and character-based language modeling datasets demonstrate the efficacy of our proposed method compared to strong baselines.
C1 [Yogatama, Dani; d'Autume, Cyprien de Masson; Kong, Lingpeng] DeepMind, London, England.
RP Yogatama, D (通讯作者)，DeepMind, London, England.
EM dyogatama@google.com; cyprien@google.com; lingpenk@google.com
CR Baevski Alexei, 2019, ARXIV191005453, V0, P0
   Bapna Ankur, 2019, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N19-1191
   Beltagy I, 2020, ARXIV200405150V2, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Choromanski Krzysztof Marcin, 2021, P ICLR, V0, P0
   dAutume Cyprien de Masson, 2019, P NEURIPS, V0, P0
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Devlin J, 2018, ARXIV, V1, P4171
   EdouardGrave Armand, 2017, P ICML, V0, P0
   Eichenbaum H, 2012, HDB PSYCHOL, V2, P3
   Grave E, 2017, ICLR, V0, P0
   Grave Edouard, 2017, P NEURIPS, V0, P0
   Guo Ruiqi, 2020, P ICML, V0, P0
   Guu K, 2020, PR MACH LEARN RES, V119, P0
   Hutter M, 2012, HUMAN KNOWLEDGE COMP, V0, P0
   Inan Hakan, 2017, ICLR, V3771, P0
   Kaiser Lukasz, 2017, P ICLR, V0, P0
   Kassner N, 2020, FINDINGS ASS COMPUTA, V0, PP3424, DOI 10.18653/V1/2020.FINDINGS-EMNLP.307
   Khandelwal U, 2020, P ICLR, V0, P0
   Khandelwal Urvashi, 2021, P ICLR, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Kitaev Nikita, 2020, ARXIV200104451, V0, P0
   Krause Ben, 2018, P ICML, V0, P0
   Krause Ben, 2019, ARXIV, V0, P0
   Liang Percy, 2018, T ASSOC COMPUT LING, V6, P437
   Merity Stephen, 2017, 5 INT C LEARNING REP, V0, P0
   Nematzadeh Aida, 2020, P ICLR WORKSH BRIDG, V0, P0
   Neubig Graham, 2016, P 2016 C EMP METH NA, V0, PP1163, DOI 10.18653/V1/D16-1124
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rae Jack W, 2020, P ICLR, V0, P0
   Rolls ET, 2000, ANNU REV PSYCHOL, V51, P599, DOI 10.1146/annurev.psych.51.1.599
   Shoeybi Mohammad, 2019, ARXIV190908053V4, V0, P0
   TULVING E, 1985, AM PSYCHOL, V40, P385, DOI 10.1037/0003-066x.40.4.385
   Vaswani A, 2017, ARXIV, V30, P5998
   Xiong W, 2021, P ICLR, V0, P0
   Xu P, 2020, P EMNLP, V0, P0
NR 38
TC 11
Z9 11
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 362
EP 373
DI 10.1162/tacl_a_00371
PG 12
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200022
DA 2023-11-10
ER

PT J
AU Zhao, WZ
   Fang, DD
   Zhang, JY
   Zhao, Y
   Xu, XW
   Jiang, XP
   Hu, XH
   He, TT
AF Zhao, Weizhong
   Fang, Dandan
   Zhang, Jinyong
   Zhao, Yao
   Xu, Xiaowei
   Jiang, Xingpeng
   Hu, Xiaohua
   He, Tingting
TI An effective framework for semistructured document classification via hierarchical attention model
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE adaptive class cost learning; attention model; document classification; graph neural network; semistructured data; semantic hierarchy
AB Recent years have witnessed the rapidly growing of the amount of semistructured documents in real-world applications. Due to the huge size of the real-world data, how to manage semistructured documents effectively is a big challenge for researchers. As a fundamental task in natural language processing field, document classification is a feasible way to handle the large-scale semistructured documents. However, existing methods fail to explicitly take advantage of the hierarchical semantics in semistructured documents. It's known that the contained semantics is beneficial for understanding the semistructured documents. Considering the hierarchical structure of a given semistructured document, we propose a semistructured document classification framework which explicitly utilizes the semantic hierarchical attention mechanism. More specifically, the hierarchical attention mechanism and graph neural network are employed to model semistructured documents, by which the multilevel semantic relationships and grammatical information are considered. Moreover, we propose an adaptive class cost learning method to treat the issue of data imbalance. Comprehensive experiments are conducted on two real-world data sets, and the results demonstrate that our framework performs better than selected baselines for semistructured document classification.
C1 [Zhao, Weizhong; Fang, Dandan; Zhang, Jinyong; Zhao, Yao; Jiang, Xingpeng; He, Tingting] Cent China Normal Univ, Hubei Prov Key Lab Artificial Intelligence & Smar, Wuhan, Hubei, Peoples R China.
   [Zhao, Weizhong; Fang, Dandan; Zhang, Jinyong; Zhao, Yao; Jiang, Xingpeng; He, Tingting] Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
   [Zhao, Weizhong; Fang, Dandan; Zhang, Jinyong; Zhao, Yao; Jiang, Xingpeng; He, Tingting] Cent China Normal Univ, Natl Language Resources Monitoring & Res Ctr Netw, Wuhan, Hubei, Peoples R China.
   [Zhao, Weizhong] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin, Peoples R China.
   [Zhao, Weizhong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin, Peoples R China.
   [Xu, Xiaowei] Univ Arkansas Little Rock, Dept Informat Sci, Little Rock, AR USA.
   [Hu, Xiaohua] Drexel Univ, Coll Comp & Informat, Philadelphia, PA 19104 USA.
C3 Central China Normal University; Central China Normal University; Central China Normal University; Guilin University of Electronic Technology; Guangxi Normal University; University of Arkansas System; University of Arkansas Little Rock; Drexel University
RP Zhao, WZ (通讯作者)，Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
EM wzzhao@mail.ccnu.edu.cn
FU National Natural Science Foundation of China [61532008, 61872157, 61932008]; Wuhan Science and Technology Program [2019010701011392]; Key Research and Development Program of Hubei Province [2020BAB017]; Fundamental Research Funds for the Central Universities [CCNU19TD004]; Research Fund of Guangxi Key Lab of Multi-source Information Mining Security [MIMS19-02]; Guangxi Key Laboratory of Trusted Software [kx201905]
CR [Anonymous], 2015, ADV NEURAL INFORM PR, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Bahdanau D, 2016, ARXIV, V0, P0
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cai L, 2003, P 26 ANN INT ACM SIG, V0, PP182, DOI 10.1145/860435.860470
   Chaudhari S, 2021, ACM T INTEL SYST TEC, V12, P0, DOI 10.1145/3465055
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Devlin J, 2018, ARXIV, V1, P4171
   Dozat T, 2017, ICLR, V0, P0
   Fang DD, 2019, IEEE INT CONF BIG DA, V0, PP1096, DOI 10.1109/BigData47090.2019.9006110
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Harrell FE, 2015, SPRINGER SER STAT, V0, PP1, DOI 10.1007/978-3-319-19425-7_1
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He Luheng, 2017, P 55 ANN M ASS COMP, V1, P473, DOI 10.18653/v1/P17-1044
   Hingmire S, 2013, SIGIR13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P877
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kipf TN, 2017, P INT C LEARN REPR, V0, PP1, DOI 10.1109/ICDM.2019.00070
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Lo LJ, 2009, KIDNEY INT, V76, P893, DOI 10.1038/ki.2009.289
   López V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P746
   Mikolov T, 2013, ICLR WORKSH, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ramos J, 2003, P 1 INSTR C MACH LEA, VVolume 242, P29
   Rios Anthony, 2015, ACM BCB, V2015, P258, DOI 10.1145/2808719.2808746
   Sánchez VD, 2003, NEUROCOMPUTING, V55, P5, DOI 10.1016/S0925-2312(03)00373-4
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang WY, 2017, AAAI CONF ARTIF INTE, V0, P3316
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yao L, 2019, AAAI CONF ARTIF INTE, V0, P7370
   Yepes Antonio Jose Jimeno, 2013, AMIA ANNU SYMP PROC, V2013, P709
   Zhang X, 2015, ADV NEUR IN, V28, P0
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2205
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
   Zhou ZH, 2010, COMPUT INTELL-US, V26, P232, DOI 10.1111/J.1467-8640.2010.00358.X
NR 48
TC 9
Z9 9
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD SEP 15
PY 2021
VL 36
IS 9
BP 5161
EP 5183
DI 10.1002/int.22508
EA MAY 2021
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA TY4DZ
UT WOS:000656113400001
DA 2023-11-10
ER

PT J
AU Roh, Y
   Heo, G
   Whang, SE
AF Roh, Yuji
   Heo, Geon
   Whang, Steven Euijong
TI A Survey on Data Collection for Machine Learning: A Big Data-AI Integration Perspective
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Machine learning; Data collection; Labeling; Data models; Data acquisition; Training data; Smart manufacturing; Data collection; data acquisition; data labeling; machine learning
ID challenges
AB Data collection is a major bottleneck in machine learning and an active research topic in multiple communities. There are largely two reasons data collection has recently become a critical issue. First, as machine learning is becoming more widely-used, we are seeing new applications that do not necessarily have enough labeled data. Second, unlike traditional machine learning, deep learning techniques automatically generate features, which saves feature engineering costs, but in return may require larger amounts of labeled data. Interestingly, recent research in data collection comes not only from the machine learning, natural language, and computer vision communities, but also from the data management community due to the importance of handling large amounts of data. In this survey, we perform a comprehensive study of data collection from a data management point of view. Data collection largely consists of data acquisition, data labeling, and improvement of existing data or models. We provide a research landscape of these operations, provide guidelines on which technique to use when, and identify interesting research challenges. The integration of machine learning and data management for data collection is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research.
C1 [Roh, Yuji; Heo, Geon; Whang, Steven Euijong] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Whang, SE (通讯作者)，Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
EM yuji.roh@kaist.ac.kr; geon.heo@kaist.ac.kr; swhang@kaist.ac.kr
FU Engineering Research Center Program through the National Research Foundation of Korea (NRF) - Korean Government MSIT [NRF-2018R1A5A1059921]; SK Telecom; Google AI Focused Research Award
CR Abe N, 1998, MACHINE LEARNING. PROCEEDINGS OF THE FIFTEENTH INTERNATIONAL CONFERENCE (ICML98), V0, P1
   Ahmad S, 2011, P 24 ANN ACM S USER, V0, PP53, DOI 10.1145/2047196.2047203
   Alcalá-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   Allahbakhsh M, 2013, IEEE INTERNET COMPUT, V17, P76, DOI 10.1109/MIC.2013.20
   Amsterdamer Y, 2014, SIGMOD REC, V43, P5, DOI 10.1145/2737817.2737819
   [Anonymous], 2015, FOUND TRENDS DATABAS, V0, P0
   [Anonymous], 2005, P ICML WORKSH LEARN, V0, P0
   [Anonymous], 2012, SIGMOD C, V0, P0, DOI DOI 10.1145/2213836.2213878
   [Anonymous], 2015, CIDR, V0, P0
   [Anonymous], 2016, IEEE DATA ENG B, V0, P0
   Bach SH, 2019, INT CONF MANAGE DATA, V0, PP362, DOI 10.1145/3299869.3314036
   Bach SH, 2017, PR MACH LEARN RES, V70, P0
   Bai YL, 2015, MM15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, V0, PP441, DOI 10.1145/2733373.2806243
   Barowy DW, 2012, ACM SIGPLAN NOTICES, V47, P639, DOI 10.1145/2398857.2384663
   Baumgartner R, 2018, ENCY DATABASE SYSTEM, V2nd, P0
   Baylor D, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1387, DOI 10.1145/3097983.3098021
   Bhardwaj A, 2015, PROC VLDB ENDOW, V8, P1917
   Bhattacherjee S, 2015, PROC VLDB ENDOW, V8, P1346, DOI 10.14778/2824032.2824035
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blum A, 1998, PROCEEDINGS OF THE ELEVENTH ANNUAL CONFERENCE ON COMPUTATIONAL LEARNING THEORY, V0, PP92, DOI 10.1145/279943.279962
   Bohannon P, 2012, P ACM SIGMOD INT C M, V0, P609
   Boim R, 2012, PROC INT CONF DATA, V0, PP1261, DOI 10.1109/ICDE.2012.122
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Bringer E, 2019, P 3 INT WORKSH DAT M, V0, PP1, DOI 10.1145/3329486.3329492
   Bujrbidge R, 2007, LECT NOTES COMPUT SC, V4881, P209
   Cafarella M, 2018, PROC VLDB ENDOW, V11, P2140, DOI 10.14778/3229863.3240492
   Cafarella MJ, 2009, PROC VLDB ENDOW, V2, P0
   Cafarella MJ, 2008, PROC VLDB ENDOW, V1, P538, DOI 10.14778/1453856.1453916
   Carlson A, 2010, AAAI CONF ARTIF INTE, V0, P1306
   Chang JC, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI17), V0, PP2334, DOI 10.1145/3025453.3026044
   Chaudhuri S, 2009, PROC VLDB ENDOW, V2, P1658, DOI 10.14778/1687553.1687622
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen LJ, 2017, PROC VLDB ENDOW, V10, P1214, DOI 10.14778/3137628.3137633
   Chen XL, 2015, IEEE I CONF COMP VIS, V0, PP1431, DOI 10.1109/ICCV.2015.168
   Choi E, 2017, MACH LEARN HEALTHC C, V0, P286
   Chu X, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1713, DOI 10.1145/2723372.2723725
   Crescenzi V, 2001, PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, V0, P109
   Crescenzi V, 2015, DISTRIB PARALLEL DAT, V33, P95, DOI 10.1007/s10619-014-7163-9
   Cubuk ED, 2019, PROC CVPR IEEE, V0, PP113, DOI 10.1109/CVPR.2019.00020
   Dalvi N, 2011, PROC VLDB ENDOW, V4, P219, DOI 10.14778/1938545.1938547
   Daniel F, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3148148
   Day Oscar, 2017, JOURNAL OF BIG DATA, V4, P0, DOI 10.1186/s40537-017-0089-0
   Dekel O, 2009, P 22 ANN C LEARN THE, V0, P0
   Deng D, 2017, P BIENN C INN DAT SY, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Doan A, 2012, PRINCIPLEDATA INTE, V0, P0
   Dolatshah M, 2018, PROC VLDB ENDOW, V12, P376, DOI 10.14778/3297753.3297758
   Dong XL, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP601, DOI 10.1145/2623330.2623623
   Dua D, 2017, UCI MACHINE LEARNING, V0, P0
   Elmeleegy H, 2011, VLDB J, V20, P209, DOI 10.1007/s00778-011-0223-0
   Etzioni O, 2004, P 13 INT C WORLD WID, V0, PP100, DOI 10.1145/988672.988687
   Fernandez RC, 2018, PROC INT CONF DATA, V0, PP1001, DOI 10.1109/ICDE.2018.00094
   Fernandez RC, 2018, PROC INT CONF DATA, V0, PP989, DOI 10.1109/ICDE.2018.00093
   FERNANDEZ RC, 2017, P ACM INT C MAN DAT, V0, P1639
   Ferrara E, 2014, KNOWL-BASED SYST, V70, P301, DOI 10.1016/j.knosys.2014.07.007
   Franklin MJ, 2011, PROC ACM SIGMOD INT, V0, PP61, DOI 10.1145/1989323.1989331
   Frénay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Gao YH, 2018, INT CONF MANAGE DATA, V0, PP943, DOI 10.1145/3183713.3183746
   Garcia-Molina H, 2016, IEEE T KNOWL DATA EN, V28, P901, DOI 10.1109/TKDE.2016.2518669
   Gokhale C, 2014, SIGMOD14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, P601
   Gonzalez H, 2010, P 2010 ACM SIGMOD IN, V0, PP1061, DOI 10.1145/1807167.1807286
   Gonzalez Hector, 2010, P 1 ACM S CLOUD COMP, V0, PP175, DOI 10.1145/1807128.1807158
   Goodfellow IJ, 2014, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2016.90
   Goodfellow IJ, 2017, ARXIV170100160, V0, P0
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gu YJ, 2014, LECT NOTES COMPUT SC, V8834, P215, DOI 10.1007/978-3-319-12637-1_27
   Gupta A, 2016, PROC CVPR IEEE, V0, PP2315, DOI 10.1109/CVPR.2016.254
   Gupta R, 2014, PROC VLDB ENDOW, V7, P505, DOI 10.14778/2732286.2732288
   Halevy AY, 2013, P BIENN C INN DAT SY, V0, P0
   Halevy Alon Y, 2016, IEEE DATA ENG B, V39, P5, DOI 10.1145/2882903.2903730
   Harris WR, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, V0, P317
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Iyyer M, 2018, P 2018 C N AM CHAPT, V1, P1875, DOI 10.18653/V1/N18-1170
   Jaderberg M, 2014, NIPS DEEP LEARN WORK, V0, P0
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P3363
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, V0, PP547, DOI 10.1145/2254556.2254659
   Karger David R, 2011, ADV NEURAL INFORM PR, V0, P1953
   Kim J, 2017, CSCW17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, V0, PP233, DOI 10.1145/2998181.2998196
   Krasanakis E, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP853, DOI 10.1145/3178876.3186133
   Krishnan S, 2016, PROC VLDB ENDOW, V9, P948
   Krishnan Sanjay, 2017, ARXIV171101299, V0, P0
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kulesza T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), V0, PP3075, DOI 10.1145/2556288.2557238
   Kumar A, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP19, DOI 10.1145/2882903.2882952
   Kurach Karol, 2018, ARXIV180704720, V0, P0
   Le Q, 2014, INT C MACHINE LEARNI, V32, P0, DOI 10.1145/2740908.2742760
   Lewis DD, 1994, SIGIR 94. PROCEEDINGS OF THE SEVENTEENTH ANNUAL INTERNATIONAL ACM-SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P3
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li GL, 2016, IEEE T KNOWL DATA EN, V28, P2296, DOI 10.1109/TKDE.2016.2535242
   Li SD, 2019, INT CONF MANAGE DATA, V0, PP1571, DOI 10.1145/3299869.3319878
   Little G, 2010, 23 ANN ACM S USER IN, V0, PP57, DOI 10.1145/1866029.1866040
   Mallinson J, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P881
   Marcus A, 2011, CIDR, V0, P211
   Marcus A, 2012, PROC VLDB ENDOW, V6, P109, DOI 10.14778/2535568.2448944
   McCallumzy AK, 1998, PROC INT C MACHINE L, V0, PP359, DOI 10.1023/A:1007692713085
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mintz M, 2009, P JOINT C 47 ANN M A, V2, P1003, DOI 10.3115/1690219.1690287
   Mitchell T, 2015, AAAI CONF ARTIF INTE, V0, P2302
   Mozafari B, 2014, PROC VLDB ENDOW, V8, P125, DOI 10.14778/2735471.2735474
   Oh TH, 2018, LECT NOTES COMPUT SC, V11208, P663, DOI 10.1007/978-3-030-01225-0_39
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park H, 2014, SIGMOD14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP577, DOI 10.1145/2588555.2610503
   Park H, 2012, PROC VLDB ENDOW, V5, P1990, DOI 10.14778/2367502.2367555
   Park N, 2018, PROC VLDB ENDOW, V11, P1071, DOI 10.14778/3231751.3231757
   Patki N, 2016, PROCEEDINGS OF 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS, V0, P399, DOI 10.1109/DSAA.2016.49
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peng XC, 2015, IEEE I CONF COMP VIS, V0, PP1278, DOI 10.1109/ICCV.2015.151
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Polyzotis N, 2018, SIGMOD REC, V47, P17, DOI 10.1145/3299887.3299891
   Polyzotis N, 2017, SIGMOD17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1723, DOI 10.1145/3035918.3054782
   Raman V, 2001, PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, V0, P381
   Ratner AJ, 2019, P BIENN C INN DAT SY, V0, P0
   Ratner A, 2018, PROCEEDINGS OF THE SECOND WORKSHOP ON DATA MANAGEMENT FOR END-TO-END MACHINE LEARNING, V0, P0, DOI DOI 10.1145/3209889.3209898
   Ratner A, 2020, VLDB J, V29, P709, DOI 10.1007/s00778-019-00552-1
   Ratner A, 2016, ADV NEUR IN, V29, P0
   Ratner AJ, 2017, SIGMOD17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1683, DOI 10.1145/3035918.3056442
   Ratner Alexander J, 2017, ADV NEURAL INF PROCESS SYST, V30, P3239
   Ravi S, 2016, JMLR WORKSH CONF PRO, V51, P519
   Re C, 2016, HILDA 16 SIGMOD, V0, P0, DOI DOI 10.1145/2939502.2939515
   Rekatsinas T, 2017, PROC VLDB ENDOW, V10, P1190
   Ribeiro MT, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P856
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, V0, P1527
   Ribeiro MT, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1135, DOI 10.1145/2939672.2939778
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, V0, PP1, DOI 10.1007/978-0-387-85820-3_1
   Roy N, 2001, P 18 INT C MACH LEAR, V2, P441
   Ruder Sebastian, 2019, P 2019 C N AM CHAPT, V0, PP15, DOI 10.18653/V1/N19-5004
   SALEHI N, 2017, P ACM C COMP SUPP CO, V0, P1890
   Sawadsky N, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), V0, PP812, DOI 10.1109/ICSE.2013.6606627
   Schaekermann Mike, 2018, PROCEEDINGS OF THE ACM ON HUMAN-COMPUTER INTERACTION, V2, P0, DOI 10.1145/3274423
   Schmitz M, 2012, P 2012 JOINT C EMPIR, V0, P523
   Seong-Heum Kim, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP2003, DOI 10.1109/ICRA.2017.7989232
   Settles B, 2012, ACTIVE LEARNING, V6, P1, DOI 10.2200/s00429ed1v01y201207aim018
   Settles B, 2008, P 2008 C EMPIRICAL M, V0, P1070
   Settles Burr, 2007, ADV NEURAL INFORM PR, V20, P0
   Seung HS, 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP287, DOI 10.1145/130385.130417
   Shah V, 2017, PROC VLDB ENDOW, V11, P366, DOI 10.14778/3157794.3157804
   Sheng VS, 2008, P 14 ACM SIGKDD INT, V0, P614
   Simonyan K, 2015, ARXIV, V0, P0
   Stonebraker M, 2013, CIDR, V2013, P0
   Stonebraker M, 2018, IEEE DATA ENG B, V41, P3
   Suchanek F, 2007, P 16 INT C WORLD WID, V0, P0, DOI DOI 10.1145/1242572.1242667
   Suchanek FM, 2015, P BIENN C INN DAT SY, V0, P0
   Tae KH, 2019, P 3 INT WORKSH DAT M, V0, P0, DOI DOI 10.1145/3329486.3329493
   Talukdar PP, 2014, JMLR WORKSH CONF PRO, V33, P940
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Terrizzano IG, 2015, P BIENN C INN DAT SY, V0, P0
   Tomanek K, 2009, P JOINT C 47 ANN M A, V0, P1039
   Triguero I, 2015, KNOWL INF SYST, V42, P245, DOI 10.1007/s10115-013-0706-y
   Trushkowsky B, 2013, PROC INT CONF DATA, V0, PP673, DOI 10.1109/ICDE.2013.6544865
   Wang J, 2012, PROC VLDB ENDOW, V5, P1483, DOI 10.14778/2350229.2350263
   Weiss Karl, 2016, JOURNAL OF BIG DATA, V3, P0, DOI 10.1186/s40537-016-0043-6
   Wrobel S, 2006, P 23 INT C MACH LEAR, V0, PP137, DOI 10.1145/1143844.1143862
   XIA Y, 2014, LNCS, V8692, P387, DOI 10.1007/978-3-319-10593-226
   Xiao T, 2015, PROC CVPR IEEE, V0, PP2691, DOI 10.1109/CVPR.2015.7298885
   Xu L, 2018, SYNTHESIZING TABULAR, V0, P0
   Yahya M, 2014, P C EMP METH NAT LAN, V0, P0, DOI DOI 10.3115/v1/d14-1038
   Yakout Mohamed, 2012, SIGMOD C, V0, PP97, DOI 10.1145/2213836.2213848
   Yarowsky D, 1995, P ACL, V0, PP189, DOI 10.3115/981658.981684
   Yosinski J, 2014, NIPS, V0, P0
   Yu JX, 2010, IEEE DATA ENG B, V33, P67
   Zhang Ce, 2015, THESIS U WISCONSIN M, V0, P0
   Zhou Y, 2004, PROC INT C TOOLS ART, V0, P594
   Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186
   Zhou ZH, 2004, LECT NOTES COMPUT SC, V3201, P525
   Zhou ZH, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), V0, P908
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhu X, 2003, ICML, V0, P0, DOI DOI 10.1109/18.850663
   Zhu Xiaojin, 2008, SEMISUPERVISED LEARN, V0, P0
NR 174
TC 265
Z9 271
U1 46
U2 314
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD APR 1
PY 2021
VL 33
IS 4
BP 1328
EP 1347
DI 10.1109/TKDE.2019.2946162
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA QT5HG
UT WOS:000626617900002
DA 2023-11-10
ER

PT J
AU Ayetiran, EF
   Sojka, P
   Novotny, V
AF Ayetiran, Eniafe Festus
   Sojka, Petr
   Novotny, Vit
TI EDS-MEMBED: Multi-sense embeddings based on enhanced distributional semantic structures via a graph walk over word senses
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Multi-sense embeddings; Graph walk; Language generation; Distributional semantics; Distributional structures; Word sense disambiguation; Knowledge-based systems; Word similarity; Semantic applications
AB Several language applications often require word semantics as a core part of their processing pipeline either as precise meaning inference or semantic similarity. Multi-sense embeddings (m-se) can be exploited for this important requirement. m-se seeks to represent each word by their distinct senses in order to resolve the conflation of meanings of words as used in different contexts. Previous works usually approach this task by training a model on a large corpus and often ignore the effect and usefulness of the semantic relations offered by lexical resources. However, even with large training data, coverage of all possible word senses is still an issue. In addition, a considerable percentage of contextual semantic knowledge are never learned because a huge amount of possible distributional semantic structures are never explored. In this paper, we leverage the rich semantic structures in WordNet using a graph-theoretic walk technique over word senses to enhance the quality of multisense embeddings. This algorithm composes enriched texts from the original texts. Furthermore, we derive new distributional semantic similarity measures for m-se from prior ones. We adapt these measures to word sense disambiguation (wsd) aspect of our experiment. We report evaluation results on 11 benchmark datasets involving wsd and Word Similarity tasks and show that our method for enhancing distributional semantic structures improves embeddings quality on the baselines. Despite the small training data, it achieves state-of-the-art performance on some of the datasets. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ayetiran, Eniafe Festus; Sojka, Petr; Novotny, Vit] Masaryk Univ, Fac Informat, Dept Visual Comp, Bot 68a, Brno 60200, Czech Republic.
C3 Masaryk University Brno
RP Ayetiran, EF (通讯作者)，Masaryk Univ, Fac Informat, Dept Visual Comp, Bot 68a, Brno 60200, Czech Republic.
EM ayetiran@mail.muni.cz; sojka@mail.muni.cz; witiko@mail.muni.cz
FU Faculty of Informatics, Masaryk University, Czech Republic; South Moravian Centre for International Mobility
CR Agirre E, 2009, P 12 C EUROPEAN CHAP, V0, PP33, DOI 10.3115/1609067.1609070
   Agirre E, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), V0, P29
   [Anonymous], 1998, ENCY APPL LING, V0, P0, DOI DOI 10.7551/MITPRESS/7287.001.0001
   [Anonymous], 2010, P C EMP METH NAT LAN, V0, P0
   Athiwaratkun B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1
   Ayetiran EF, 2020, TURK J ELECTR ENG CO, V28, P224, DOI 10.3906/elk-1901-140
   Ayetiran EF, 2018, OPEN COMPUT SCI, V8, P165, DOI 10.1515/comp-2018-0015
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Bruni E, 2012, P 50 ANN M ASS COMP, V1, P136, DOI 10.1109/ICRA.2016.7487801
   Camacho-Collados J, 2016, ARTIF INTELL, V240, P36, DOI 10.1016/j.artint.2016.07.005
   Chaplot DS, 2018, AAAI CONF ARTIF INTE, V0, P2819
   Chen T, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P15
   Chen X, 2014, EMNLP, V0, PP1025, DOI 10.3115/V1/D14-1110
   Devlin J, 2018, BERT PRETRAINING DEE, V0, P0, DOI DOI 10.18653/V1/N19-PROCEEDINGSOFNAACLHLT1423
   Dubossarsky H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1732
   Edmonds P, 2001, P SENSEVAL 2 2 INT W, V0, P1
   Faruqui Manaal, 2015, P 2015 C N AM CHAPT, V0, PP1606, DOI 10.3115/v1/N15-1184
   Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110
   Hadiwinoto C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5297
   Hamp B, 1997, P ACL WORKSHOP AUTOM, V0, P0
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Huang EH, 2012, P 50 ANN M ASS COMPU, V0, P873
   Huang LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3509
   Iacobacci I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1685
   Iacobacci I, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P897
   Iacobacci I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P95
   Langone H, 2004, PROC WORKSHOP FRONT, V0, P63
   Lesk M, 1986, P 5 ANN INT C SYSTEM, V0, PP24, DOI 10.1145/318723.318728
   Li J, 2015, P 2015 C EMP METH NA, V0, PP1722, DOI 10.18653/v1/D15-1200
   Loper E, 2002, ETMTNLP 02 P ACL 02, V0, PP63, DOI 10.3115/1118108.1118117
   Loureiro D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5682
   Luo FL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1402
   Luo FL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2473
   Mancini M, 2017, P 21 C COMPUTATIONAL, V0, PP100, DOI 10.18653/V1/K17-1012
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Miller George A, 1993, P WORKSH HUM LANG TE, V0, P303
   Moro A, 2014, T ASSOC COMPUT LING, V2, P231, DOI 10.1162/TACL_A_00179
   Moro Andrea, 2015, P 9 INT WORKSH SEM E, V0, PP288, DOI 10.18653/V1/S15-2049
   Navigli R, 2007, P SEMEVAL 2007, V0, P30
   Navigli R, 2013, P SEMEVAL, V0, PP222, DOI 10.1016/S0044-328X(82)80082-2
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, V0, PP1059, DOI 10.3115/V1/D14-1113
   Nguyen DQ, 2017, PROC 6 JOINT C LEXIC, V2, P121
   Oele D, 2018, P 9 GLOB WORDNET C G, V0, P262
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pilehvar M T, 2016, P 2016 C EMPIRICAL M, V0, PP1680, DOI 10.18653/V1/D16-1174
   Pradhan Sameer, 2007, P 4 INT WORKSH SEM E, V0, P87
   Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Reisinger J, 2010, HUMAN LANGUAGE TECHN, V0, P109
   Resnik P, 1995, INT JOINT CONF ARTIF, V0, P448
   Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793
   Rothe S, 2017, COMPUT LINGUIST, V43, P593, DOI 10.1162/COLI_a_00294
   Ruas T, 2019, EXPERT SYST APPL, V136, P288, DOI 10.1016/j.eswa.2019.06.026
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Scarlini B, 2020, AAAI CONF ARTIF INTE, V34, P8758
   Snyder Benjamin, 2004, SENSEVAL 3, V0, P41
   Vial L, 2019, P 10 GLOB WORDNET C, V0, P108
   Vial L, 2018, P 11 INT C LANG RES, V0, P1027
   Vial L, 2017, IWCS 2017, V0, P0
   Wang YL, 2020, KNOWL-BASED SYST, V190, P0, DOI 10.1016/j.knosys.2019.105030
   Yuan D, 2016, PROC COLING, V0, P1374
   Zhong Z, 2010, P ACL 2010 SYST DEM, V0, P78
NR 67
TC 2
Z9 2
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD MAY 11
PY 2021
VL 219
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.106902
EA MAR 2021
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RF5HE
UT WOS:000634868500007
DA 2023-11-10
ER

PT J
AU Otter, DW
   Medina, JR
   Kalita, JK
AF Otter, Daniel W.
   Medina, Julian R.
   Kalita, Jugal K.
TI A Survey of the Usages of Deep Learning for Natural Language Processing
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Machine learning; Natural language processing; Decoding; Neural networks; Computer architecture; Computational linguistics; Training; Computational linguistics; deep learning; machine learning; natural language processing (NLP); neural networks
ID neural-network model; representations; neocognitron; generation; algorithm
AB Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This article provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to many applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field.
C1 [Otter, Daniel W.; Medina, Julian R.; Kalita, Jugal K.] Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA.
C3 University of Colorado System; University of Colorado at Colorado Springs
RP Kalita, JK (通讯作者)，Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA.
EM jkalita@uccs.edu
FU National Science Foundation [IIS-1359275, IIS-1659788]
CR Adhikari A, 2019, DOCBERT BERT DOCUMEN, V0, P0
   Agirre E, 2012, P 6 INT WORKSHOP SEM, V0, P385
   Ahmed K, 2017, ARXIV171102132, V0, P0
   Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   [Anonymous], 2015, ARXIV150505008, V0, P0
   [Anonymous], 2014, P 8 WORKSH SYNT SEM, V0, P0
   [Anonymous], 2015, ARXIV150606158, V0, P0
   [Anonymous], 2013, PROC 30 INT C MACH L, V0, P0
   [Anonymous], 2002, COLING 02 6 C NATURA, V0, P0
   [Anonymous], 2017, ARXIV171203556, V0, P0
   [Anonymous], 2016, P 2016 C EMPIRICAL M, V0, P0
   [Anonymous], 2015, ARXIV150807909, V0, P0
   [Anonymous], 2016, ARXIV160306042, V0, P0
   [Anonymous], 2009, P 4 WORKSHOP STAT MA, V0, P0
   [Anonymous], 2016, P 1 C MACHINE TRANSL, V0, P0
   [Anonymous], 2008, COLING 2008 P WORKSH, V0, P0
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Belinkov Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P861, DOI 10.18653/v1/P17-1080
   Benes K, 2017, INTERSPEECH, V0, PP284, DOI 10.21437/Interspeech.2017-1442
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bobrow Daniel G, 1964, NATURAL LANGUAGE INP, V0, P0
   Bordes A, 2014, MACH LEARN, V94, P233, DOI 10.1007/s10994-013-5363-6
   BOTHA J, 2014, P ICML, V0, P1899
   Bowman SR, 2018, BUS SOC, V0, P0
   Britz D, 2017, P 2017 C EMP METH NA, V0, PP1442, DOI 10.18653/v1/D17-1151
   Brunner G, 2018, ARXIV180106024, V0, P0
   Cettolo M, 2016, ARXIV161000572, V0, P0
   Cettolo M, 2012, PROC EUR ASS MACH TR, V0, P261
   Cettolo Mauro, 2014, P INT WORKSH SPOK LA, V0, P0
   Che, 2016, P 10 INT WORKSH SEM, V0, P378
   Chelba C, 2013, ARXIV PREPRINT ARXIV, V0, P0
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, P0, DOI 10.1155/2014/575246
   Chen LQ, 2018, ADV NEUR IN, V31, P0
   Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76
   Chen YB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P167
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/tacl_a_00104
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Choe DK, 2016, P 2016 C EMP METH NA, V0, PP2331, DOI 10.18653/V1/D16-1257
   Chung J, 2014, NIPS 2014 WORKSH DEE, V0, PP1, DOI 10.48550/ARXIV.1412.3555
   Cire\csan DC, 2011, P 22 INT JOINT C ART, VTwo, P1237
   Clark E, 2018, P 2018 C N AM CHAPT, V1, P2250, DOI 10.18653/V1/N18-1204
   Clark E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2748
   Clarkson P, 2001, COMPUT SPEECH LANG, V15, P39, DOI 10.1006/csla.2000.0156
   Cliche M, 2017, P SEMEVAL, V0, PP573, DOI 10.18653/V1/S17-2094
   Collobert R, 2008, P 25 ICML, V25, P160, DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Cowie J, 1996, COMMUN ACM, V39, P80, DOI 10.1145/234173.234209
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V4, P3:1, DOI 10.1145/1217098.1217101
   Cross J, 2016, ARXIV160606406, V0, P0
   Daniluk, 2017, ARXIV170204521, V0, P0
   Daojian Zeng, 2014, P COLING 25 INT C CO, V0, P2335
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Dehouck M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2864
   Denkowski M, 2017, P 1 WORKSH NEUR MACH, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Doersch C, 2016, ARXIV, V0, P0
   Dolan B, 2004, P 20 INT C COMP LING, V0, PP350, DOI 10.3115/1220355.1220406
   Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260
   Dos Santos M, 1900, P69, V0, P0
   Dozat Timothy, 2018, ARXIV180701396, V0, P0
   Duong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P43
   Dyer C, 2016, P 2016 C N AM CHAPT, V0, PP199, DOI 10.18653/v1/N16-1024
   Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334
   ElHihi S, 1996, ADV NEUR IN, V8, P493
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Etter M, 2018, BUS SOC, V57, P60, DOI 10.1177/0007650316683926
   Fan Angela, 2018, ABS180504833 CORR, V0, P0
   Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110
   Fletcher Roger, 2013, PRACTICAL METHODS OP, V0, P0
   Fried Daniel, 2017, ARXIV170703058, V0, P0
   Fujisaki, 1991, CURRENT ISSUES PARSI, V0, P139
   FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gehring J, 2017, ARXIV170503122, V3, P2029, DOI 10.18653/V1/P16-1220
   Ghazvininejad M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6112
   Go Alec, 2009, TWITTER SENTIMENT CL, V0, P0, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Goldberg Y, 2017, SYNTH LECT HUM LANG, V10, P1, DOI 10.2200/S00762ED1V01Y201703HLT037
   Goller C, 1996, P INT C NEURAL NETWO, V347, P352, DOI 10.1109/ICNN.1996.548916
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo JF, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP55, DOI 10.1145/2983323.2983769
   Guo JX, 2018, AAAI CONF ARTIF INTE, V0, P5141
   Hammerton J, 2003, P 7 C NAT LANG LEARN, V4, P172, DOI 10.3115/1119176.1119202
   Hangyo Masatsugu, 2012, P 26 PAC AS C LANG I, V0, P535
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689
   He H, 2016, P 2016 C N AM CHAPT, V0, PP937, DOI 10.18653/V1/N16-1108
   He H, 2015, P 2015 C EMP METH NA, V0, PP1576, DOI 10.18653/V1/D15-1181
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hennessy John L, 2017, COMPUTER ARCHITECTUR, V6th, P0
   Herzig J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P623, DOI 10.18653/v1/P17-2098
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hochreiter Sepp, 2001, FIELD GUIDE DYNAMICA, V0, PP2, DOI 10.1109/9780470544037.ch14
   Holtzman A, 2019, CEUR WORKSHOP PROC, V2540, P0
   Hopkins J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P168, DOI 10.18653/v1/P17-1016
   Hossain MZ, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3295748
   Hovy Eduard, 2006, P HUM LANG TECHN C N, V0, PP57, DOI 10.3115/1614049.1614064
   Hu BT, 2014, ADV NEUR IN, V27, P0
   Hu Z, 2017, P MACHINE LEARNING R, V70, P1587
   Huang EH, 2012, P 50 ANN M ASS COMPU, V0, P873
   Huang Gao, 2017, PROC CVPR IEEE, V0, PP4700, DOI 10.1109/CVPR.2017.243
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, P2333
   Huang Qiuyuan, 2018, ARXIV180508191, V0, P0
   Iyer R, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, V0, P254, DOI 10.1109/ASRU.1997.659013
   Jain P, 2017, ARXIV170705501, V0, P0
   Jelinek F, 1992, SPEECH RECOGNITION AND UNDERSTANDING. RECENT ADVANCES, V0, P345
   Ji Y, 2015, ARXIV151103962, V0, P0
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Jones Karen Sparck, 1994, CURRENT ISSUES COMPU, V0, PP3, DOI 10.1007/978-0-585-35958-8_1
   Judge J, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Jurafsky D, 2017, SPEECH LANGUAGE PROC, V3rd, P0
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC, V0, P0
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kalita, 2019, P INT C NLP, V0, P0
   Kalita J, 2018, ARXIV181012427, V0, P0
   Kalita J, 2018, P 15 INT C NAT LANG, V0, P180
   Kann, 2018, ARXIV180700286, V0, P0
   Kawahara D, 2002, P 3 INT C LANG RES E, V0, P2008
   Kawahara Daisuke, 2006, P 5 INT C LANG RES E, V0, P1344
   KAWATO M, 1987, BIOL CYBERN, V57, P169, DOI 10.1007/BF00364149
   Kenter T, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP1403, DOI 10.1145/3077136.3082062
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Kingma DP, 2013, AUTOENCODING VARIATI, V0, P0
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Koehn P, 2017, WMT, V0, P28
   Koehn P, 2005, P MACHINE TRANSLATIO, V0, P79
   Krantz, 2018, P INT C NLP, V0, P1
   Krishnamurthy J, 2017, EMPIRICAL METHODS NA, V0, P0
   Krizhevsky A, 2014, ONE WEIRD TRICK PARA, V0, P0
   Kuang S, 2018, P 27 INT C COMP LING, V0, P596
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Le Phong, 2014, P 2014 C EMP METH NA, V0, PP729, DOI 10.3115/V1/D14-1081
   Le Q, 2014, INT C MACHINE LEARNI, V32, P0, DOI 10.1145/2740908.2742760
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 1995, CONVOLUTIONAL NETWOR, V3361, P1995, DOI 10.5555/303568.303704
   Li J, 2015, CORR, V0, P0
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS
   Li ZH, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P457
   Liddy ED, 2001, ENCY LIB INFORM SCI, V0, P0
   Lin C, 2019, P 2 CLIN NATURAL LAN, V0, PP65, DOI 10.18653/V1/W19-1908
   Lin K, 2017, ADV NEUR IN, V30, P0
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI 10.1017/S1368980013002176
   Liu X, 2019, ARXIV190606947, V0, P0
   Liu X, 2018, ARXIV180407888, V0, P0
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Liu Y, 2018, COMPUT LINGUIST, V44, P193, DOI 10.1162/COLI_r_00312
   Liu Yijia, 2018, ARXIV180408228, V0, P0
   Lu Zhengdong, 2013, ADV NEURAL INFORM PR, V0, PP1367, DOI 10.7551/MITPRESS/11474.003.0014
   Luong MT, 2014, ARXIV14108206, V27, P82
   Luong T, 2013, P 17 C COMP NAT LANG, V0, PP104, DOI 10.1007/BF02579642
   MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1101, DOI 10.1145/3331184.3331317
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   Marelli M, 2014, P 8 INT WORKSH SEM E, V0, PP1, DOI 10.3115/v1/S14-2001
   Martin LJ, 2018, AAAI CONF ARTIF INTE, V0, P868
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   MengqiuWang Noah A, 2007, P 2007 JOINT C EMP M, V0, P22
   Mikolov T, 2011, 2011 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU), V0, PP196, DOI 10.1109/ASRU.2011.6163930
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mikolov T, 2011, INT CONF ACOUST SPEE, V0, P5528
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Monroe D, 2014, COMMUN ACM, V57, P13, DOI 10.1145/2601069
   More A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3847
   Morita H, 2015, P 2015 C EMP METH NA, V0, PP2292, DOI 10.18653/V1/D15-1276
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Naiwen Xue, 2005, NATURAL LANGUAGE ENGINEERING, V11, P207, DOI 10.1017/S135132490400364X
   Nangia Nikita, 2017, ARXIV170708172, V0, P0
   Nguyen TH, 2016, P 2016 C N AM CHAPTE, V0, PP300, DOI 10.18653/V1/N16-1034
   Nivre J, 2003, P 8 INT C PARS TECHN, V0, P149
   Nivre J, 2009, P 11 INT C PARS TECH, V0, P73
   Nivre J, 2004, P WORKSH INCR PARS B, V0, PP50, DOI 10.3115/1613148.1613156
   Nivre J, 2015, LECT NOTES COMPUT SC, V9041, P3, DOI 10.1007/978-3-319-18111-0_1
   Oepen S, 2015, P 9 INT WORKSHOP SEM, V0, P915
   Ott M, 2018, PR MACH LEARN RES, V80, P0
   Pang L, 2016, AAAI CONF ARTIF INTE, V0, P2793
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paulus R, 2017, ARXIV170504304, V0, P1
   Pavlick E, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P408
   Peng N, 2018, P 1 WORKSH STOR, V0, PP43, DOI 10.18653/v1/W18-1505
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Petrov S, 2012, P NOT 1 WORKSH SYNT, V59, P1
   Poliak Adam, 2018, P 7 JOINT C LEXICAL, V0, PP180, DOI 10.18653/V1/S18-2023
   Poliak Adam, 2018, ARXIV180409779, V0, P0
   Pradhan Sameer, 2013, P 17 C COMPUTATIONAL, V0, P143
   Qi, 2019, ARXIV190110457, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rahman A, 2012, P 2012 JOINT C EMPIR, V0, P777
   Raina Rajat, 2009, INT C MACHINE LEARNI, V0, PP873, DOI 10.1145/1553374.1553486
   Raposo D, 2017, ARXIV170205068, V0, P0
   Rappoport A, 2018, ARXIV180809354, V0, P0
   Reisinger Drew, 2015, T ASSOC COMPUT LING, V3, P475, DOI 10.1162/TACL_A_00152
   Rosenfeld, 2008, EVALUATION METRICS L, V0, P0
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saha S, 2018, ARXIV180604387, V0, P0
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Santos Diana, 2006, P LREC 2006, V0, P0
   Santra A, 2017, ADV GEOSPAT TECH, V0, PP1, DOI 10.4018/978-1-5225-1814-3
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schumann CL, 2019, AIDS BEHAV, V23, P5, DOI 10.1007/s10461-017-1727-4
   Schwenk H, 2012, P 24 INT C COMP LING, V0, P1071
   Sennrich R, 2017, P SOFTW DEM 15 C EUR, V0, PP65, DOI 10.18653/V1/E17-3017
   Serban IV, 2017, AAAI CONF ARTIF INTE, V0, P3295
   Shazeer N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1428
   Shen YL, 2014, WWW14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP373, DOI 10.1145/2567948.2577348
   Smolensky P, 1986, PARALLEL DISTRIBUTED, V1, P194
   Socher R, 2013, LONG PAPERS, V1, P455
   Socher R, 2011, P 24 INT C NEUR INF, V0, P0
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Srivastava Rupesh Kumar, 2015, ARXIV150500387, V0, P2
   Stenetorp, 2013, P DEEP LEARN WORKSH, V0, P0
   Sun MM, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP556, DOI 10.1145/3159652.3159712
   Surdeanu M, 2008, P 12 C COMP NAT LANG, V0, PP159, DOI 10.3115/1596324.1596352
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tambwekar Pradyumna, 2018, ARXIV180910736, V0, P0
   Tan ZX, 2018, AAAI CONF ARTIF INTE, V0, P4929
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Tucker S, 2019, GENERATING BELIEVABL, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Vinyals O, 2015, ADV NEURAL INFORM PR, V28, P0
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang W, 2018, ARXIV180900068, V0, P0
   Wang W, 2019, NAACL, V0, P0
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Wang YS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1332
   Wang YX, 2018, AAAI CONF ARTIF INTE, V0, P5561
   Wei J, 2018, INT CONF COMPUT NETW, V0, PP156, DOI 10.1109/ICCNC.2018.8390270
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   White Aaron Steven, 2017, P 8 INT JOINT C NAT, V8291, P996
   Wiebe J, 2014, P 8 INT WORKSH SEM E, V0, PP81, DOI 10.3115/v1/S14-2010
   Williams Adina, 2017, ARXIV170405426, V0, P0
   Williams W, 2015, INT CONF ACOUST SPEE, V0, PP5391, DOI 10.1109/ICASSP.2015.7179001
   Winograd T, 1971, MACTR84 MIT, V0, P0
   Worsham J, 2018, P 27 INT C COMPUTATI, V0, P1963
   Wu, 2016, ARXIV160202410, V0, P0
   Wu, 2018, P CONLL SHAR TASK MU, V0, P248
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Xu Jingjing, 2018, ARXIV180806945, V0, P0
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P72
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, PP2013, DOI 10.18653/V1/D15-1237
   Yih WT, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P643
   Yin Wenpeng, 2015, P 2015 C N AM CHAPT, V0, PP901, DOI 10.3115/V1/N15-1091
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu ZW, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1650
   Zamani H, 2018, CIKM18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP497, DOI 10.1145/3269206.3271800
   Zaremba Wojciech, 2015, ABS151106732 CORR, V0, P0
   Zaremba Wojciech, 2014, ARXIV14092329, V0, P0
   Zeman D, 2018, P CONLL 2018 SHARED, V0, P1
   Zhang H, 2019, P 23 C COMP NAT LANG, V0, PP789, DOI 10.18653/v1/K19-1074
   Zhang YZ, 2017, PR MACH LEARN RES, V70, P0
   Zheng LJ, 2018, INT J MACH LEARN CYB, V9, P75, DOI 10.1007/s13042-015-0347-4
   Zheng SC, 2017, NEUROCOMPUTING, V257, P59, DOI 10.1016/j.neucom.2016.12.075
   Zhou H, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1213
NR 277
TC 512
Z9 539
U1 172
U2 1019
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD FEB 15
PY 2021
VL 32
IS 2
BP 604
EP 624
DI 10.1109/TNNLS.2020.2979670
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA QE6IX
UT WOS:000616310400012
PM 32324570
DA 2023-11-10
ER

PT J
AU Kasnesis, P
   Heartfield, R
   Liang, X
   Toumanidis, L
   Sakellari, G
   Patrikakis, C
   Loukas, G
AF Kasnesis, Panagiotis
   Heartfield, Ryan
   Liang, Xing
   Toumanidis, Lazaros
   Sakellari, Georgia
   Patrikakis, Charalampos
   Loukas, George
TI Transformer-based identification of stochastic information cascades in social networks using text and image similarity
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Information cascade; Semantic textual similarity; Image similarity; Deep learning
ID diffusion
AB Identifying the origin of information posted on social media and how this may have changed over time can be very helpful to users in determining whether they trust it or not. This currently requires disproportionate effort for the average social media user, who instead has to rely on fact-checkers or other intermediaries to identify information provenance for them. We show that it is possible to disintermediate this process by providing an automated mechanism for determining the information cascade where a post belongs. We employ a transformer-based language model as well as pretrained ResNet50 model for image similarity, to decide whether two posts are sufficiently similar to belong to the same cascade. By using semantic similarity, as well as image in addition to text, we increase accuracy where there is no explicit diffusion of reshares. In a new dataset of 1,200 news items on Twitter, our approach is able to increase clustering performance above 7% and 4.5% for the validation and test sets respectively over the previous state of the art. Moreover, we employ a probabilistic subsampling mechanism, reducing significantly cascade creation time without affecting the performance of large-scale semantic text analysis and the quality of information cascade generation. We have implemented a prototype that offers this new functionality to the user and have deployed it in our own instance of social media platform Mastodon. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Kasnesis, Panagiotis; Toumanidis, Lazaros; Patrikakis, Charalampos] Univ West Attica, Psachna, Greece.
   [Heartfield, Ryan; Liang, Xing; Sakellari, Georgia; Loukas, George] Univ Greenwich, London, England.
C3 University of Greenwich
RP Kasnesis, P (通讯作者)，Univ West Attica, Psachna, Greece.
EM pkasnesis@uniwa.gr
FU European Commission's H2020 Innovation Action programme under project EUNOMIA [825171]
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2013, INT C LEARNING REPRE, V0, P0
   [Anonymous], 2016, ABS160908144 ARXIV, V0, P0
   [Anonymous], 2016, PROC CVPR IEEE, V0, P0, DOI DOI 10.1109/CVPR.2016.90
   Appalaraju S, 2017, ABS170908761 ARXIV, V0, P0
   Ashley C, 2015, PSYCHOL MARKET, V32, P15, DOI 10.1002/mar.20761
   Barbosa S, 2015, P IEEE INT C E-SCI, V0, PP36, DOI 10.1109/eScience.2015.31
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Camacho D, 2020, INFORM FUSION, V63, P88, DOI 10.1016/j.inffus.2020.05.009
   Canziani A, 2017, ABS160507678 ARXIV, V0, P0
   Cavallari S, 2019, IEEE COMPUT INTELL M, V14, P39, DOI 10.1109/MCI.2019.2919396
   Cer DM, 2018, ABS180311175 ARXIV, V0, P0
   Cer DM, 2017, ABS170800055 ARXIV, V0, P0
   Cheng J, 2014, WWW14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP925, DOI 10.1145/2566486.2567997
   Choras M, 2021, APPL SOFT COMPUT, V101, P0, DOI 10.1016/j.asoc.2020.107050
   Dai AM, 2015, ADV NEUR IN, V28, P0
   Dalal N, 2005, PROC CVPR IEEE, V0, PP886, DOI 10.1109/cvpr.2005.177
   Devlin J, 2019, P ANN C N AM CHAPT A, V0, P0
   Dolan B, 2005, 3 INT WORKSH PAR IWP, V0, P1
   Ekinci E, 2020, TURK J ELECTR ENG CO, V28, P2244, DOI 10.3906/elk-1912-62
   FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117
   Gelli F, 2015, MM15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, V0, PP907, DOI 10.1145/2733373.2806361
   Gurevych I, 2019, P C EMP METH NAT LAN, V0, P0
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Karami E, 2015, P NEWF EL COMP ENG C, V0, P0
   Kasnesis P, 2020, IEEE INT CONF MULTI, V0, P0
   Kim J, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP324, DOI 10.1145/3159652.3159734
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Li M, 2017, INFORMATION, V8, P0, DOI 10.3390/info8040118
   Liu Y, 2019, LEARNING PROPAGATE L, V0, P0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv JN, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1883, DOI 10.1145/3123266.3127897
   McParlane PJ, 2014, P INT C MULT RETR, V0, P0
   Meghawat M, 2018, P IEEE C MULT INF PR, V0, P0
   Nguyen HT, 2019, KNOWL-BASED SYST, V182, P0, DOI 10.1016/j.knosys.2019.07.013
   Palubinskas G, 2014, IEEE IMAGE PROC, V0, PP575, DOI 10.1109/ICIP.2014.7025115
   Panizo-LLedot A, 2019, INT C COMPL NETW THE, V0, P427
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Porat T, 2019, EUR J PUBLIC HEALTH, V29, P117, DOI 10.1093/eurpub/cky144
   Poria S, 2016, IEEE IJCNN, V0, PP4465, DOI 10.1109/IJCNN.2016.7727784
   Qi P, 2019, IEEE DATA MINING, V0, PP518, DOI 10.1109/ICDM.2019.00062
   Sakaki S, 2014, P VL COLING, V0, P0
   Sejal D, 2017, INT J MULTIMED INF R, V6, P143, DOI 10.1007/s13735-017-0124-0
   Simonyan K, 2015, ARXIV, V0, P0
   Singh SS, 2019, APPL SOFT COMPUT, V82, P0, DOI 10.1016/j.asoc.2019.105554
   Subbian K, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP597, DOI 10.1145/3038912.3052718
   Taxidou I, 2018, DISTRIB PARALLEL DAT, V36, P47, DOI 10.1007/s10619-017-7211-3
   Taxidou I, 2015, WWW15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP819, DOI 10.1145/2740908.2742475
   Taxidou I, 2014, WWW14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP1313, DOI 10.1145/2567948.2580050
   Vaswani A, 2017, ARXIV, V30, P5998
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334, DOI 10.1109/TPAMI.2005.165
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Xie W, 2018, ACM T KNOWL DISCOV D, V12, P0, DOI 10.1145/3178048
NR 57
TC 5
Z9 5
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD SEP 15
PY 2021
VL 108
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107413
EA MAY 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SV1DB
UT WOS:000663564800004
DA 2023-11-10
ER

PT J
AU Byambadorj, Z
   Nishimura, R
   Ayush, A
   Kitaoka, N
AF Byambadorj, Zolzaya
   Nishimura, Ryota
   Ayush, Altangerel
   Kitaoka, Norihide
TI Normalization of Transliterated MongolianWords Using Seq2Seq Model with Limited Data
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Text normalization; noisy text; transliterated text; neural network; language model; seq2seq model; character conversion
AB The huge increase in social media use in recent years has resulted in new forms of social interaction, changing our daily lives. Due to increasing contact between people from different cultures as a result of globalization, there has also been an increase in the use of the Latin alphabet, and as a result a large amount of transliterated text is being used on social media. In this study, we propose a variety of character level sequence-to-sequence (seq2seq) models for normalizing noisy, transliterated text written in Latin script into Mongolian Cyrillic script, for scenarios in which there is a limited amount of training data available. We applied performance enhancement methods, which included various beam search strategies, N-gram-based context adoption, edit distance-based correction and dictionary-based checking, in novel ways to two basic seq2seq models. We experimentally evaluated these two basic models as well as fourteen enhanced seq2seq models, and compared their noisy text normalization performance with that of a transliteration model and a conventional statistical machine translation (SMT) model. The proposed seq2seq models improved the robustness of the basic seq2seq models for normalizing out-of-vocabulary (OOV) words, and most of our models achieved higher normalization performance than the conventional method. When using test data during our text normalization experiment, our proposed method which included checking each hypothesis during the inference period achieved the lowest word error rate (WER = 13.41%), which was 4.51% fewer errors than when using the conventional SMT method.
C1 [Byambadorj, Zolzaya; Nishimura, Ryota] Tokushima Univ, Dept Adv Technol & Sci, 2-1 Minami Jousanjima Cho, Tokushima 7708506, Japan.
   [Ayush, Altangerel] Mongolian Univ Sci & Technol, Dept Informat Technol, Peace Ave, Ulaanbaatar 18031, Mongolia.
   [Kitaoka, Norihide] Toyohashi Univ Technol, Dept Comp Sci & Engn, 1-1 Hibarigaoka,Tempaku Cho, Toyohashi, Aichi 4418580, Japan.
C3 Tokushima University; Mongolian University of Science & Technology; Toyohashi University of Technology
RP Byambadorj, Z (通讯作者)，Tokushima Univ, Dept Adv Technol & Sci, 2-1 Minami Jousanjima Cho, Tokushima 7708506, Japan.
EM C501947001@tokushima-u.ac.jp; nishimura@is.tokushima-u.ac.jp; a.altangerel@must.edu.mn; kitaoka@tut.jp
CR Abadi Martin, 2016, ARXIV, V0, P0
   AiTi Aw, 2006, P COLINGACL 2006 MAI, V0, P33
   [Anonymous], 1966, SOV PHYS DOKL, V0, P0
   [Anonymous], 2015, DEEP LEARNING PYTHON, V0, P0
   [Anonymous], 2014, EACL, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Gulcehre C, 2015, ARXIV150303535, V0, P0
   Guruuchin Gerelmaa, 2018, J NO CULTURES STUDIE, V9, P205
   Ikeda T, 2016, P 2 WORKSHOP NOISY U, V0, P129
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Liang Huang, 2017, P OF THE 2017 C ON E, V0, P2134
   Lourentzou I, 2019, P INT AAAI C WEB SOC, V13, P335
   Luong Minh-Thang, 2015, EMNLP, V0, P3
   Lusetti M, 2018, P 5 WORKSHOP NLP SIM, V0, P18
   Mager M, 2019, J INTELL FUZZY SYST, V36, P4921, DOI 10.3233/JIFS-179039
   Mandolessi Silvana, 2018, PASADO INASEQUIBLE, V0, P49
   Mann ErJasdeep Singh, 2016, INT RES J ENG TECHNO, V0, P2230
   Norvig P, 2016, WRITE SPELLING CORRE, V0, P0
   Ruzsics T, 2017, P 21 C COMP NAT LANG, V0, P184
   Saloot MA, 2014, P INT C ART INT PATT, V0, P111
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tursun O, 2017, P 3 WORKSHOP NOISY U, V0, P85
   Vilarino Darnes, 2012, PATTERN RECOGNITION. PROCEEDINGS 4TH MEXICAN CONFERENCE (MCPR 2012), V0, PP293, DOI 10.1007/978-3-642-31149-9_30
NR 25
TC 0
Z9 0
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD NOV 15
PY 2021
VL 20
IS 6
BP 
EP 
DI 10.1145/3464361
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA XB8QE
UT WOS:000721586800012
DA 2023-11-10
ER

PT J
AU Tan, LB
   Zhang, HJ
AF Tan, Libin
   Zhang, Haijuan
TI An approach to user knowledge acquisition in product design
SO ADVANCED ENGINEERING INFORMATICS
LA English
DT Article
DE User knowledge; Knowledge acquisition; Recommendation; Rough set
ID open innovation; matrix factorization; management; system; model; information; service; performance; simulation; framework
AB As the world increasingly moves towards a knowledge-based economy, user requirements become an important factor for enterprises to drive product collaborative design evolution. To map user requirements to the product model, user requirements are generally extracted into knowledge that can be used for design decisions. However, because users are interest-driven participants and not professional design engineers, the effect of user knowledge acquisition is not ideal. There are significant challenges for rapid knowledge acquisition with dynamic user requirements. This paper presents an approach to user knowledge acquisition in the product design process, which obtains the tangible requirements of users under the premise that users are adequate for participation. In this approach, the typical information flow is divided into four stages: submission, interaction, knowledge discovery, and model evolution. In the submission stage, natural language processing technology is used to transform text form solutions into data, so that computer technology can be applied to manage large-scale user requirements. In the interaction stage, users are helped to improve their solutions by the iterative recommendation process. In the knowledge discovery stage, after less concerned partial solutions are removed and vacant items are predicted to be supplemented, the final collection of user design information is obtained. Finally, based on rough set theory, design knowledge can be extracted to support the decision of the product model. The washing machine design project is used as a case study to explain the implementation of the proposed approach.
C1 [Tan, Libin; Zhang, Haijuan] Anhui Univ Technol, AnHui Prov Key Lab Special Heavy Load Robot, Maanshan 243002, Peoples R China.
   [Tan, Libin] Beijing Inst Technol, Beijing Adv Innovat Ctr Intelligent Robots & Syst, Beijing, Peoples R China.
C3 Anhui University of Technology; Beijing Institute of Technology
RP Tan, LB (通讯作者)，Anhui Univ Technol, AnHui Prov Key Lab Special Heavy Load Robot, Maanshan 243002, Peoples R China.
EM alextlb@ahut.edu.cn
FU National Key Research and Development Project of China [2017YFE0113200]; National Natural Science Foundation of China [51575264, 51805253]; Beijing Advanced Innovation Center for Intelligent Robots and Systems [2019IRS15]
CR Albatayneh NA, 2018, EDUC TECHNOL SOC, V21, P112
   AlMousa M, 2017, MOB INF SYST, V2017, P0, DOI 10.1155/2017/7507940
   Baldassarre B, 2017, J CLEAN PROD, V147, P175, DOI 10.1016/j.jclepro.2017.01.081
   Batmaz Z, 2019, ARTIF INTELL REV, V52, P1, DOI 10.1007/s10462-018-9654-y
   Dermeval D, 2016, REQUIR ENG, V21, P405, DOI 10.1007/s00766-015-0222-6
   Dou RL, 2017, INT J PROD RES, V55, P3886, DOI 10.1080/00207543.2017.1316020
   Etesami SR, 2015, IEEE T AUTOMAT CONTR, V60, P1886, DOI 10.1109/TAC.2015.2394954
   Fu KL, 2021, MULTIMED TOOLS APPL, V80, P11133, DOI 10.1007/s11042-020-10216-w
   Gao HH, 2020, IEEE INTERNET THINGS, V7, P4532, DOI 10.1109/JIOT.2019.2956827
   Guajardo JA, 2016, MANAGE SCI, V62, P1860, DOI 10.1287/mnsc.2015.2195
   Guo Q, 2019, J COMPUT INF SCI ENG, V19, P0, DOI 10.1115/1.4041418
   Halskov K, 2015, INT J HUM-COMPUT ST, V74, P81, DOI 10.1016/j.ijhcs.2014.09.003
   Ham J, 2017, IND MANAGE DATA SYST, V117, P1166, DOI 10.1108/IMDS-08-2016-0338
   Hartmann T, 2020, DEV BUILT ENVIRON, V4, P0, DOI 10.1016/j.dibe.2020.100020
   Haslwanter JDH, 2020, UNIVERSAL ACCESS INF, V19, P57, DOI 10.1007/s10209-018-0626-4
   Hernando A, 2016, KNOWL-BASED SYST, V97, P188, DOI 10.1016/j.knosys.2015.12.018
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Hong HB, 2016, ENTERP INF SYST-UK, V10, P970, DOI 10.1080/17517575.2015.1071433
   Hu K, 2018, SCIENTOMETRICS, V114, P1031, DOI 10.1007/s11192-017-2574-9
   Imtiaz MN, 2020, APPL ARTIF INTELL, V34, P832, DOI 10.1080/08839514.2020.1787676
   JERZY P, 2019, J COMPUT DES ENG, V6, P479, DOI 10.1016/J.JCDE.2019.02.004
   Jiang SH, 2015, IEEE T MULTIMEDIA, V17, P907, DOI 10.1109/TMM.2015.2417506
   Jiao YR, 2019, COMPUT IND, V108, P1, DOI 10.1016/j.compind.2019.02.011
   Kar AK, 2015, J COMPUT SCI-NETH, V6, P23, DOI 10.1016/j.jocs.2014.11.002
   Kasauli R, 2021, J SYST SOFTWARE, V172, P0, DOI 10.1016/j.jss.2020.110851
   Khan FH, 2017, KNOWL INF SYST, V51, P851, DOI 10.1007/s10115-016-0993-1
   Anh KQ, 2019, J INTELL FUZZY SYST, V37, P7441, DOI 10.3233/JIFS-179352
   Koohi H, 2016, MEASUREMENT, V91, P134, DOI 10.1016/j.measurement.2016.05.058
   Kubler S, 2015, COMPUT AIDED DESIGN, V59, P192, DOI 10.1016/j.cad.2013.08.009
   Li CY, 2018, J SYST SOFTWARE, V138, P108, DOI 10.1016/j.jss.2017.12.028
   Li DS, 2016, FUTURE GENER COMP SY, V55, P311, DOI 10.1016/j.future.2014.11.003
   Li M, 2020, EXPERT SYST APPL, V144, P0, DOI 10.1016/j.eswa.2019.113088
   Li XY, 2021, COMPUT IND, V129, P0, DOI 10.1016/j.compind.2021.103449
   Li XY, 2021, KNOWL-BASED SYST, V215, P0, DOI 10.1016/j.knosys.2021.106739
   Li XY, 2021, J CLEAN PROD, V279, P0, DOI 10.1016/j.jclepro.2020.123618
   Li XY, 2020, J MECH DESIGN, V142, P0, DOI 10.1115/1.4046807
   Li XY, 2017, ADV ENG INFORM, V34, P17, DOI 10.1016/j.aei.2017.08.001
   Liebel G, 2018, REQUIR ENG, V23, P145, DOI 10.1007/s00766-016-0261-7
   Lima E, 2019, ACM T INTERNET TECHN, V19, P0, DOI 10.1145/3319528
   Lin FH, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0183888
   Lin KY, 2016, COMPUT IND ENG, V99, P487, DOI 10.1016/j.cie.2016.05.023
   Liu W, 2020, ENG COMPUT-GERMANY, V36, P527, DOI 10.1007/s00366-019-00712-5
   Martín-de Castro G, 2015, IND MARKET MANAG, V47, P143, DOI 10.1016/j.indmarman.2015.02.032
   McAndrew S, 2015, CULT SOCIOL-LONDON, V9, P56, DOI 10.1177/1749975514542486
   Melegati J, 2019, INFORM SOFTWARE TECH, V109, P92, DOI 10.1016/j.infsof.2019.02.001
   Ortega F, 2016, INFORM SCIENCES, V345, P313, DOI 10.1016/j.ins.2016.01.083
   Panchal JH, 2009, J COMPUT INF SCI ENG, V9, P0, DOI 10.1115/1.3184605
   Park K, 2020, APPL ARTIF INTELL, V34, P396, DOI 10.1080/08839514.2020.1723868
   Peng GZ, 2017, ADV ENG INFORM, V33, P314, DOI 10.1016/j.aei.2016.12.007
   Pineda M, 2013, EUR PHYS J B, V86, P0, DOI 10.1140/epjb/e2013-40777-7
   Pirasteh P, 2015, MOBILE NETW APPL, V20, P497, DOI 10.1007/s11036-014-0544-5
   Pollok P, 2019, J PROD INNOVAT MANAG, V36, P412, DOI 10.1111/jpim.12485
   Randhawa K, 2016, J PROD INNOVAT MANAG, V33, P750, DOI 10.1111/jpim.12312
   Ratwani RM, 2015, J AM MED INFORM ASSN, V22, P1179, DOI 10.1093/jamia/ocv050
   Ren HY, 2021, TECHNOVATION, V101, P0, DOI 10.1016/j.technovation.2020.102196
   Roh T, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0223404
   Sakhnini V, 2017, EMPIR SOFTW ENG, V22, P2001, DOI 10.1007/s10664-016-9475-z
   Sato Y, 2019, EXPERT SYST APPL, V119, P247, DOI 10.1016/j.eswa.2018.10.047
   Shao YL, 2018, ADV ENG SOFTW, V124, P22, DOI 10.1016/j.advengsoft.2018.07.002
   Shieh MD, 2016, J AMB INTEL HUM COMP, V7, P107, DOI 10.1007/s12652-015-0307-6
   Shin DH, 2016, INT J HUM-COMPUT INT, V32, P503, DOI 10.1080/10447318.2016.1177277
   Stantchev V, 2015, COMPUT HUM BEHAV, V51, P762, DOI 10.1016/j.chb.2014.11.092
   Tan LB, 2019, INT J COMPUT INTEG M, V32, P253, DOI 10.1080/0951192X.2019.1571233
   Tiwana A, 2001, DECIS SUPPORT SYST, V31, P241, DOI 10.1016/S0167-9236(00)00134-2
   Ullah R, 2016, DECIS SUPPORT SYST, V81, P41, DOI 10.1016/j.dss.2015.10.007
   Valcarce D, 2016, KNOWL-BASED SYST, V103, P41, DOI 10.1016/j.knosys.2016.03.021
   Violante MG, 2017, COMPUT IND, V86, P15, DOI 10.1016/j.compind.2016.12.007
   Wang D, 2017, IEEE ACCESS, V5, P4887, DOI 10.1109/ACCESS.2017.2677950
   Wang YH, 2017, ADV ENG INFORM, V33, P16, DOI 10.1016/j.aei.2017.04.002
   Wang YB, 2018, J MECH DESIGN, V140, P0, DOI 10.1115/1.4039201
   Wang ZX, 2021, INT J PROD RES, V59, P635, DOI 10.1080/00207543.2019.1702227
   Wang ZX, 2019, ADV ENG INFORM, V42, P0, DOI 10.1016/j.aei.2019.100983
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   Wei W, 2015, PROC CIRP, V36, P1, DOI 10.1016/j.procir.2015.01.020
   Wiesner S, 2015, PROC CIRP, V30, P36, DOI 10.1016/j.procir.2015.02.018
   Wu JH, 2009, INFORM MANAGE-AMSTER, V46, P365, DOI 10.1016/j.im.2009.06.004
   Wu XL, 2018, INFORM FUSION, V43, P13, DOI 10.1016/j.inffus.2017.11.008
   Wu ZY, 2020, J INTELL MANUF, V31, P1559, DOI 10.1007/s10845-020-01534-9
   Yao XL, 2017, RAPID PROTOTYPING J, V23, P983, DOI 10.1108/RPJ-03-2016-0041
   Yi C, 2015, J MANAGE INFORM SYST, V31, P213, DOI 10.1080/0742222.2014.1001270
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zhai LY, 2009, ADV ENG INFORM, V23, P222, DOI 10.1016/j.aei.2008.10.010
   Zhang SA, 2019, ACM COMPUT SURV, V52, P0, DOI 10.1145/3285029
   Zhang Y, 2016, J INFORMETR, V10, P1108, DOI 10.1016/j.joi.2016.09.006
   Zhang YW, 2021, IEEE T SYST MAN CY-S, V51, P3796, DOI 10.1109/TSMC.2019.2931723
   Zhao L, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3444689
   Zhou F, 2020, J MECH DESIGN, V142, P0, DOI 10.1115/1.4044435
NR 87
TC 8
Z9 8
U1 10
U2 89
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1474-0346
EI 1873-5320
J9 ADV ENG INFORM
JI Adv. Eng. Inform.
PD OCT 15
PY 2021
VL 50
IS 
BP 
EP 
DI 10.1016/j.aei.2021.101408
EA SEP 2021
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Multidisciplinary
SC Computer Science; Engineering
GA UY8XY
UT WOS:000701801400004
DA 2023-11-10
ER

PT J
AU Martínez-Huertas, JA
   Olmos, R
   León, JA
AF Martinez-Huertas, Jose A.
   Olmos, Ricardo
   Leon, Jose A.
TI Enhancing topic-detection in computerized assessments of constructed responses with distributional models of language
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Inbuilt rubric; Constructed responses; Summaries; Topic detection; Latent semantic analysis; Automated summary evaluation
ID latent semantic analysis; formative assessment; lsa assessment; summary; text; dimensions
AB Usually, computerized assessments of constructed responses use a predictive-centered approach instead of a validity-centered one. Here, we compared the convergent and discriminant validity of two computerized assessment methods designed to detect semantic topics in constructed responses: Inbuilt Rubric (IR) and Partial Contents Similarity (PCS). While both methods are distributional models of language and use the same Latent Semantic Analysis (LSA) prior knowledge, they produce different semantic representations. PCS evaluates constructed responses using non-meaningful semantic dimensions (this method is the standard LSA assessment of constructed responses), but IR endows original LSA semantic space coordinates with meaning. In the present study, 255 undergraduate and high school students were allocated one of three texts and were tasked to make a summary. A topic-detection task was conducted comparing IR and PCS methods. Evidence from convergent and discriminant validity was found in favor of the IR method for topic-detection in computerized constructed response assessments. In this line, the multicollinearity of PCS method was larger than the one of IR method, which means that the former is less capable of discriminating between related concepts or meanings. Moreover, the semantic representations of both methods were qualitatively different, that is, they evaluated different concepts or meanings. The implications of these automated assessment methods are also discussed. First, the meaningful coordinates of the Inbuilt Rubric method can accommodate expert rubrics for computerized assessments of constructed responses improving computer-assisted language learning. Second, they can provide high-quality computerized feedback accurately detecting topics in other educational constructed response assessments. Thus, it is concluded that: (1) IR method can represent different concepts and contents of a text, simultaneously mapping a considerable variability of contents in constructed responses; (2) IR method semantic representations have a qualitatively different meaning than the LSA ones and present a desirable multicollinearity that promotes the discriminant validity of the scores of distributional models of language; and (3) IR method can extend the performance and the applications of current LSA semantic representations by endowing the dimensions of the semantic space with semantic meanings.
C1 [Martinez-Huertas, Jose A.; Olmos, Ricardo; Leon, Jose A.] Univ Autonoma Madrid, Dept Psychol, Calle Ivan Pavlov 6, Madrid 28049, Spain.
   [Martinez-Huertas, Jose A.] Univ Pontif Comillas, UNINPSI Clin Psychol Ctr, Calle Mateo Inurria 37, Madrid 28036, Spain.
C3 Autonomous University of Madrid; Comillas Pontifical University
RP Martínez-Huertas, JA (通讯作者)，Univ Autonoma Madrid, Dept Psychol, Calle Ivan Pavlov 6, Madrid 28049, Spain.
EM josea.martinez@uam.es; ricardo.olmos@uam.es; joseantonio.leon@uam.es
CR Martínez-Huertas JA, 2018, PSICOL EDUC, V24, P85, DOI 10.5093/psed2048a9
   [Anonymous], 2001, EUROCONFERENCE REC A, V0, P0
   Asimov I, 1969, GREAT IDEAS SCI, V0, P0
   Azmi AM, 2019, INFORM PROCESS MANAG, V56, P1736, DOI 10.1016/j.ipm.2019.05.008
   Bellino A, 2020, IEEE ACCESS, V8, P70216, DOI 10.1109/ACCESS.2020.2982639
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   Corcoran CM, 2020, BIOL PSYCHIAT-COGN N, V5, P770, DOI 10.1016/j.bpsc.2020.06.004
   De Deyne S, 2016, J EXP PSYCHOL GEN, V145, P1228, DOI 10.1037/xge0000192
   de Vega M, 2012, SYMBOLS EMBODIMENT D, V0, PP456, DOI 10.1093/acprof:oso/9780199217274.001.0001
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dessus P, 1999, SCI TECHNIQUES ED, V6, P409, DOI 10.3406/stice.1999.1637
   Dronen N, 2015, P 2 2015 ACM C LEARN, V0, PP3, DOI 10.1145/2724660.2724661
   Foltz PW, 1999, P WORLD C ED MULTIME, V0, P939
   Franzke M, 2005, JOURNAL OF EDUCATIONAL COMPUTING RESEARCH, V33, P53, DOI 10.2190/DH8F-QJWM-J457-FQVB
   Graesser AC, 2018, INT J STEM EDUC, V5, P0, DOI 10.1186/s40594-018-0110-y
   He H, 2016, P 2016 C N AM CHAPT, V0, PP937, DOI 10.18653/V1/N16-1108
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Hu X, 2007, HDB LATENT SEMANTIC, V0, PP401, DOI 10.4324/9780203936399.CH20
   Jain S, 2020, PROCEDIA COMPUT SCI, V167, P1102, DOI 10.1016/j.procs.2020.03.412
   Jones MN, 2015, OXFORD HDB MATH COMP, V0, PP232, DOI 10.1093/OXFORDHB/9780199957996.013.11
   Jonsson A, 2007, ED RES REV, V2, P130, DOI 10.1016/j.edurev.2007.05.002
   Jorge-Botana G, 2013, P 23 ANN M SOC TEXT, V0, P0
   Jorge-Botana G, 2019, EXPERT SYST APPL, V131, P71, DOI 10.1016/j.eswa.2019.04.055
   Jorge-Botana G, 2018, WIRES COGN SCI, V9, P0, DOI 10.1002/wcs.1457
   Jorge-Botana G, 2015, J EDUC COMPUT RES, V52, P341, DOI 10.1177/0735633115571930
   Kaur A, 2019, INNOVATIONS COMPUTER, V79, P57, DOI 10.1007/978-981-13-7082-3_8
   Kintsch E, 2000, INTERACTIVE LEARNING ENVIRONMENTS, V8, P87, DOI 10.1076/1049-4820(200008)8:2;1-B;FT087
   Kintsch E, 2007, HDB LATENT SEMANTIC, V0, PP263, DOI 10.4324/9780203936399.ch14
   Kjell ONE, 2019, PSYCHOL METHODS, V24, P92, DOI 10.1037/met0000191
   Klein R, 2011, P 16 ANN JOINT C INN, V0, PP158, DOI 10.1145/1999747.1999793
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Kundu A, 2015, EXPERT SYST APPL, V42, P796, DOI 10.1016/j.eswa.2014.08.035
   Lalata JAP, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2019), V0, PP140, DOI 10.1145/3357254.3357287
   Landauer TK, 2007, HDB LATENT SEMANTIC, V0, P0, DOI DOI 10.4324/9780203936399
   Landauer T, 2009, THEOR PRACT, V48, P44, DOI 10.1080/00405840802577593
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Landauer TK, 1999, BEHAV BRAIN SCI, V22, P624, DOI 10.1017/S0140525X99382145
   LaVoie N, 2020, EDUC PSYCHOL MEAS, V80, P399, DOI 10.1177/0013164419860575
   León JA, 2006, BEHAV RES METHODS, V38, P616, DOI 10.3758/BF03193894
   Madnani N, 2013, P 8 WORKSH INN US NL, V0, P163
   Magliano JP, 2012, BEHAV RES METHODS, V44, P608, DOI 10.3758/s13428-012-0211-3
   Martin-Loeches M, 2016, ORIGEN EVOLUCION LEN, V0, P0
   Martínez-Huertas JA, 2019, ASSESS EVAL HIGH EDU, V44, P1029, DOI 10.1080/02602938.2019.1570079
   McNamara DS, 2011, TOP COGN SCI, V3, P3, DOI 10.1111/j.1756-8765.2010.01117.x
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Mohamadi Z, 2018, STUD EDUC EVAL, V59, P29, DOI 10.1016/j.stueduc.2018.02.003
   Olmos R, 2016, INFORM PROCESS MANAG, V52, P359, DOI 10.1016/j.ipm.2015.12.002
   Olmos R, 2014, DISCOURSE PROCESS, V51, P494, DOI 10.1080/0163853X.2014.913416
   Peiro A, 1972, CIENCIAS NATURALEZA, V0, P0
   Reddy YM, 2010, ASSESS EVAL HIGH EDU, V35, P435, DOI 10.1080/02602930902862859
   Rehder B, 1998, DISCOURSE PROCESS, V25, P337, DOI 10.1080/01638539809545031
   Rojas-Simón J, 2021, EXPERT SYST APPL, V167, P0, DOI 10.1016/j.eswa.2020.113827
   Roll I, 2011, LEARN INSTR, V21, P267, DOI 10.1016/j.learninstruc.2010.07.004
   Saha SK, 2022, INTERACT LEARN ENVIR, V30, P215, DOI 10.1080/10494820.2019.1651743
   Shen YL, 2014, WWW14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP373, DOI 10.1145/2567948.2577348
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Suleman RM, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.114130
   Susnea I, 2017, IEEE GLOB ENG EDUC C, V0, PP347, DOI 10.1109/EDUCON.2017.7942871
   Tulu CN, 2021, IEEE ACCESS, V9, P19270, DOI 10.1109/ACCESS.2021.3054346
   Turney PD, 2006, COMPUT LINGUIST, V32, P379, DOI 10.1162/coli.2006.32.3.379
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369
   Wade-Stein D, 2004, COGNITION INSTRUCT, V22, P333, DOI 10.1207/s1532690xci2203_3
   Wang P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P352
   Wolfe MBW, 2005, J EXP PSYCHOL LEARN, V31, P359, DOI 10.1037/0278-7393.31.2.359
NR 66
TC 2
Z9 2
U1 0
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2021
VL 185
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115621
EA JUL 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA WH0YJ
UT WOS:000707414500010
DA 2023-11-10
ER

PT J
AU Phan, T
   Do, P
AF Phan, Trung
   Do, Phuc
TI Building a Vietnamese question answering system based on knowledge graph and distributed CNN
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE QAS; Deep learning; DM-Tree; Knowledge graph; Graph embedding
AB Question answering system (QAS) can be applied everywhere such as in schools, hospitals, banks, e-commerce websites. A smart QAS that can replace people is what people expect. Therefore, there are a lot of studies to build, develop, and improve QAS. However, QAS used for low-resource languages like Vietnamese is still very limited. So, in this paper, we present a method for building Vietnamese QAS. Except for specific Vietnamese language processes, most of our solutions can also be applied to other languages. We build QAS based on knowledge graph (KG) and convolutional neural network (CNN). KG provides knowledge and deducing ability for QAS. CNN is used to classify questions in the natural language to identify the correct answer to a given question. Moreover, we also use distributed architecture to train the CNN model. On the other hands, we also propose a solution to speed up searching for answers in a large KG by partitioning and indexing KG by using the DM-Tree structure. Besides, we also present experimental results and evaluation results of our model using common metrics to prove the effectiveness of our solution.
C1 [Phan, Trung; Do, Phuc] Vietnam Natl Univ, Univ Informat Technol, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Do, P (通讯作者)，Vietnam Natl Univ, Univ Informat Technol, Ho Chi Minh City, Vietnam.
EM trungphansg@gmail.com; phucdo@uit.edu.vn
FU Vietnam National University Ho Chi Minh City (VNU-HCMC) [DS2020-26-01]
CR Albawi S, 2017, P INT C ENG TECHN IC, V0, PP1, DOI 10.1109/ICENGTECHNOL.2017.8308186
   Allam AMN, 2016, INT J RES REV INFORM, V2, P0
   Bghiel A, 2020, 3RD INTERNATIONAL CONFERENCE ON NETWORKING, V0, P0, DOI 10.1145/3386723.3387894
   Bhagat P, 2020, ICTD2020, VICTD2020, P0, DOI 10.1145/3392561.3397581
   Bhandare A, 2016, INT J COMPUTER SCI I, V7, P2206
   Brandtzaeg PB, 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Chang DT, 2018, ARXIV180601756V1CSAI, V5, P0
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, V0, P426
   Cloudera I, 2017, SPARK GUIDE, V0, P0
   Databricks, 2017, GENTL INTR AP SPARK, V0, P0
   Deriu JM, 2018, SWISSALPS SEMEVAL 20, V0, P0, DOI DOI 10.18653/v1/s17-2054
   Do P, 2022, NEURAL COMPUT APPL, V34, P8393, DOI 10.1007/s00521-020-05495-1
   Drabas T, 2017, LEARNING PYSPARK, V0, P0
   Fadhil A, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, V0, P408, DOI 10.1145/3099023.3099112
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferri C, 2009, PATTERN RECOGN LETT, V30, P27, DOI 10.1016/j.patrec.2008.08.010
   Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM19), V0, PP105, DOI 10.1145/3289600.3290956
   Iftene A, 2016, ROCHI INT C HUM COMP, V0, P91
   Joeri CI-D, 2016, DISTRIBUTED KERAS DI, V0, P0
   Johnson DQ, 2017, P AUSTR LANG TECHN A, V0, P108
   Kumar M, 2017, APPL WATER SCI, V7, P2103, DOI 10.1007/s13201-016-0406-3
   Lafferty J, 2001, CONDITIONAL RANDOM F, V0, P282
   Langer M, 2020, IEEE T PARALL DISTR, V31, P2802, DOI 10.1109/TPDS.2020.3003307
   Lei Dian, 2018, ARXIV180508355V1CSLG, V0, P0
   Liu L, 2018, LECT NOTES ARTIF INT, V10956, P173, DOI 10.1007/978-3-319-95957-3_19
   Bach NX, 2020, CYBERN INF TECHNOL, V20, P112, DOI 10.2478/cait-2020-0008
   Nguyen DQ, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P2582
   Page LC, 2017, AERA OPEN, V3, P0, DOI 10.1177/2332858417749220
   Pham ST, 2016, P AMS 2015 ASIA MOD, V0, P0, DOI DOI 10.1109/AMS.2015.26
   Do P, 2020, INT J ADV COMPUT SC, V11, P639
   Le-Hong P, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP1049, DOI 10.1145/3184558.3191535
   Reddy, 2020, INT J ELECT COMPUT E, V10, P2710, DOI 10.11591/IJECE.V10I3.PP2710-2718
   Salunkhe A, 2020, INT J COMPUTER APPL, V177, P9, DOI 10.5120/ijca2020919817
   Sandhini S, 2018, EMERGING TRENDS IN ENGINEERING, V0, P0
   Shaikh E, 2019, 2019 2ND IEEE MIDDLE EAST AND NORTH AFRICA COMMUNICATIONS CONFERENCE (IEEEMENACOMM19), V0, PP220, DOI 10.1109/menacomm46666.2019.8988541
   Truong Diem, 2017, P SOICT, V0, P0
   Valueva MV, 2020, MATH COMPUT SIMULAT, V177, P232, DOI 10.1016/j.matcom.2020.04.031
   Veith AdS, 2019, APACHE SPARK, V0, P0, DOI DOI 10.1007/978-3-319-77525-8_37
   Vijoy M, 2016, INT J ADV RES, V0, P0, DOI DOI 10.21474/ijar01/1303
   Vu T, 2018, P 2018 C N AM CHAPT, V0, PP56, DOI 10.18653/V1/N18-5012
   Tung VX, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), V0, PP332, DOI 10.1109/KSE.2015.42
   Wahyudi, 2018, INT C INF TECH SYST, V0, PP536, DOI 10.1109/ICITSI.2018.8696046
   Yue Wang, 2020, ICIAI 2020: PROCEEDINGS OF THE 2020 THE 4TH INTERNATIONAL CONFERENCE ON INNOVATION IN ARTIFICIAL INTELLIGENCE, V0, PP170, DOI 10.1145/3390557.3394296
   Zhou XQ, 2018, NEUROCOMPUTING, V274, P8, DOI 10.1016/j.neucom.2016.07.082
NR 45
TC 9
Z9 9
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD NOV 15
PY 2021
VL 33
IS 21
BP 14887
EP 14907
DI 10.1007/s00521-021-06126-z
EA JUN 2021
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WL7FY
UT WOS:000662912100003
DA 2023-11-10
ER

PT J
AU Shi, SM
   Luo, D
   Wu, X
   Long, CJ
   Huang, HY
AF Shi, Shumin
   Luo, Dan
   Wu, Xing
   Long, Congjun
   Huang, Heyan
TI Multi-level Chunk-based Constituent-to-Dependency Treebank Transformation for Tibetan Dependency Parsing
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Tibetan dependency trees; Low-resource dependency parsing; Multi-level chunk mechanism; Knowledge-driven
AB Dependency parsing is an important task for Natural Language Processing (NLP). However, a mature parser requires a large treebank for training, which is still extremely costly to create. Tibetan is a kind of extremely low-resource language for NLP, there is no available Tibetan dependency treebank, which is currently obtained by manual annotation. Furthermore, there are few related kinds of research on the construction of treebank. We propose a novel method of multi-level chunk-based syntactic parsing to complete constituentto-dependency treebank conversion for Tibetan under scarce conditions. Our method mines more dependencies of Tibetan sentences, builds a high-quality Tibetan dependency tree corpus, and makes fuller use of the inherent laws of the language itself. We train the dependency parsing models on the dependency treebank obtained by the preliminary transformation. The model achieves 86.5% accuracy, 96% LAS, and 97.85% UAS, which exceeds the optimal results of existing conversion methods. The experimental results show that our method has the potential to use a low-resource setting, which means we not only solve the problem of scarce Tibetan dependency treebank but also avoid needless manual annotation. The method embodies the regularity of strong knowledge-guided linguistic analysis methods, which is of great significance to promote the research of Tibetan information processing.
C1 [Shi, Shumin; Luo, Dan; Huang, Heyan] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Wu, Xing] Beijing Inst Technol, Sch Comp Technol, Beijing, Peoples R China.
   [Long, Congjun] Chinese Acad Social Sci, Inst Ethnol & Anthropol, Beijing, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology; Chinese Academy of Social Sciences
RP Shi, SM (通讯作者)，Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
EM bjssm@bit.edu.cn; 3120181013@bit.edu.cn; wuxing@bit.edu.cn; longcj@cass.org.cn; hhy63@bit.edu.cn
FU National Natural Science Foundation of China [61671064, 61732005]; National Key RD Program of China [2018YFC0831704]
CR [Anonymous], 2015, ARXIV150606158, V0, P0
   [Anonymous], 2015, P 2015 C EMPIRICAL M, V0, P0
   [Anonymous], 2016, ARXIV160306042, V0, P0
   Bunescu RC, 2005, P C HUM LANG TECHN E, V0, PP724, DOI 10.3115/1220575.1220666
   Cairang Huaque, 2013, J CHINESE INFORM PRO, V27, P166
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, P0, DOI 10.1155/2014/575246
   Collins M, 2003, COMPUT LINGUIST, V29, P589, DOI 10.1162/089120103322753356
   Di Jiang, 2003, LANGUAGE COMPUTING C, V0, P160
   Dozat T, 2016, ARXIV161101734, V0, P0
   Dozat Timothy, 2018, ARXIV180701396, V0, P0
   Gomez-Rodriguez Carlos, 2018, ARXIV180701745, V0, P0
   Gyal Tashi, 2015, TIBET U, V30, P76
   Hua quecairang, 2013, COMPUTER ENG, V39, P300
   Ji T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2475
   Klein D, 2002, ADV NEUR IN, V14, P35
   [龙从军 Long Congjun], 2019, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V33, P59
   Magerman David M, 1994, ARXIVCMPLG9405009, V0, P0
   Maoji Xiang, 2018, INFORM COMMUNICATION, V8, P92
   McDonald R, 2005, P C HUM LANG TECHN E, V0, PP523, DOI 10.3115/1220575.1220641
   Nivre J, 2006, PROC LREC, V0, P2216
   Nivre J, 2015, LECT NOTES COMPUT SC, V9041, P3, DOI 10.1007/978-3-319-18111-0_1
   Pei WZ, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P313
   Schlichtkrull Michael Sejr, 2017, ARXIV170101623, V0, P0
   Shi Tianze, 2017, ARXIV170809403, V0, P0
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Wang Tianhang, 2014, J CHIN INF PROCESS, V28, P05
   Wang Wenhui, 2016, P ANN M ASS COMP LIN, V0, P0
   Wang Xinyu, 2019, ARXIV190607880, V0, P0
   Xu Peng, 2009, P HUMAN LANGUAGE TEC, V0, P245
   Yamada H, 2003, P 8 INT WORKSH PARS, V0, P195
   Yang H, 2005, PDCAT 2005: SIXTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, V0, PROCEEDINGS
NR 31
TC 0
Z9 0
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR 15
PY 2021
VL 20
IS 2
BP 
EP 
DI 10.1145/3424247
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RZ6OF
UT WOS:000648719600008
DA 2023-11-10
ER

PT J
AU Khattab, O
   Potts, C
   Zaharia, M
AF Khattab, Omar
   Potts, Christopher
   Zaharia, Matei
TI Relevance-guided Supervision for OpenQA with ColBERT
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Systems for Open-Domain Question Answering (OpenQA) generally depend on a retriever for finding candidate passages in a large corpus and a reader for extracting answers from those passages. In much recent work, the retriever is a learned component that uses coarse-grained vector representations of questions and passages. We argue that this modeling choice is insufficiently expressive for dealing with the complexity of natural language questions. To address this, we define ColBERT-QA, which adapts the scalable neural retrieval model ColBERT to OpenQA. ColBERT creates fine-grained interactions between questions and passages. We propose an efficient weak supervision strategy that iteratively uses ColBERT to create its own training data. This greatly improves OpenQA retrieval on Natural Questions, SQuAD, and TriviaQA, and the resulting system attains state-of-the-art extractive OpenQA performance on all three datasets.
C1 [Khattab, Omar; Potts, Christopher; Zaharia, Matei] Stanford Univ, Stanford, CA 94305 USA.
C3 Stanford University
RP Khattab, O (通讯作者)，Stanford Univ, Stanford, CA 94305 USA.
EM okhattab@stanford.edu; cgpotts@stanford.edu; matei@cs.stanford.edu
FU Stanford DAWN projectAnt Financial; Facebook; Google; Infosys; NEC; VMware; Cisco; SAP; Stanford HAI Cloud Credit grant from AWS; NSF under CAREER grant [CNS-1651570]
CR [Anonymous], 2019, ARXIV PREPRINT ARXIV, V0, P0
   Berant J, 2013, P 2013 C EMPIRICAL M, V0, P0
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chen Vincent S, 2019, ADV NEURAL INF PROCESS SYST, V32, P9392
   Clark P, 2016, AI MAG, V37, P5, DOI 10.1609/aimag.v37i1.2636
   Dehghani M, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP65, DOI 10.1145/3077136.3080832
   Devlin J, 2018, ARXIV, V1, P4171
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Guu K, 2020, PR MACH LEARN RES, V119, P0
   Hirschman L, 1999, P 37 ANN M ASS COMPU, V0, P325
   Iyyer M, 2014, EMNLP, V0, PP633, DOI 10.3115/V1/D14-1070
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Joshi Mandar, 2017, P 55 ANN M ASS COMP, V0, P0, DOI DOI 10.18653/v1/P17-1147
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP39, DOI 10.1145/3397271.3401075
   Kratzwald B, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P576
   Kushman N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P271
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6086
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Lewis Patrick, 2020, ADV NEURAL INFORM PR, V33, P9459, DOI 10.48550/ARXIV.2005.11401
   MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP993, DOI 10.1145/3331184.3331316
   Min Sewon, 2019, ARXIV PREPRINT ARXIV, V0, P0, DOI DOI 10.18653/v1/D19-1284
   Nguyen DHN, 2016, IEEE ICC, V0, P0, DOI DOI 10.1109/ICC.2016.7510844
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Richardson M, 2013, P 2013 C EMPIRICAL M, V0, P193
   Robertson Stephen, 2009, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V3, P333, DOI 10.1561/1500000019
   Robertson SE, 1995, TEXT RETRIEVAL CONFERENCE (TREC-3) (NIST SP 500-225), V0, P109
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Voorhees EM, 2000, SIGIR FORUM, V34, P200
   Wang ZG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5878
   Wolf T, 1900, P38, V0, P0
   Xiong Caiming, 2020, ICLR 2020, V0, P0
   Yang PL, 2018, ACM J DATA INF QUAL, V10, P0, DOI 10.1145/3239571
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P72
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, PP2013, DOI 10.18653/V1/D15-1237
   Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3490
   Zhang KT, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP474, DOI 10.1145/3366423.3380131
NR 38
TC 14
Z9 14
U1 1
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 929
EP 944
DI 10.1162/tacl_a_00405
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200055
DA 2023-11-10
ER

PT J
AU Nie, LY
   Gao, CY
   Zhong, ZC
   Lam, W
   Liu, Y
   Xu, ZL
AF Nie, Lun Yiu
   Gao, Cuiyun
   Zhong, Zhicong
   Lam, Wai
   Liu, Yang
   Xu, Zenglin
TI CoreGen: Contextualized Code Representation Learning for Commit Message Generation
SO NEUROCOMPUTING
LA English
DT Article
DE Commit message generation; Code representation learning; Code-to-text generation; Self-supervised learning; Contextualized code representation
AB Automatic generation of high-quality commit messages for code commits can substantially facilitate software developers' works and coordination. However, the semantic gap between source code and natural language poses a major challenge for the task. Several studies have been proposed to alleviate the challenge but none explicitly involves code contextual information during commit message generation. Specifically, existing research adopts static embedding for code tokens, which maps a token to the same vector regardless of its context. In this paper, we propose a novel Contextualized code representation learning strategy for commit message Generation (CoreGen). CoreGen first learns contextualized code representations which exploit the contextual information behind code commit sequences. The learned representations of code commits built upon Transformer are then fine-tuned for downstream commit message generation. Experiments on the benchmark dataset demonstrate the superior effectiveness of our model over the baseline models with at least 28.18% improvement in terms of BLEU-4 score. Furthermore, we also highlight the future opportunities in training contextualized code representations on larger code corpus as a solution to low-resource tasks and adapting the contextualized code representation framework to other code-to-text generation tasks. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Gao, Cuiyun; Xu, Zenglin] Harbin Inst Technol, Shenzhen, Peoples R China.
   [Nie, Lun Yiu; Lam, Wai] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Zhong, Zhicong] Sun Yat Sen Univ, Guangzhou, Peoples R China.
   [Liu, Yang] Nanyang Technol Univ, Singapore, Singapore.
C3 Harbin Institute of Technology; Chinese University of Hong Kong; Sun Yat Sen University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Gao, CY (通讯作者)，Harbin Inst Technol, Shenzhen, Peoples R China.
EM lynie@link.cuhk.edu.hk; gaocuiyun@hit.edu.cn; zhongzhc3@mail2.sysu.edu.cn; wlam@se.cuhk.edu.hk; yangliu@ntu.edu.sg; xuzenglin@hit.edu.cn
FU National Natural Science Foundation of China [62002084]; key program of fundamental research from Shenzhen Science and Technology Innovation Commission [ZX20210035]; Singapore Ministry of Education Academic Research Fund Tier 1 [2018-T1-002-069]; National Research Foundation, Prime Ministers Office, Singapore under its National Cybersecurity RD Program [NRF2018NCR-NCR005-0001]; Singapore National Research Foundation under NCR [NRF2018NCR-NSOE003-0001]; NRF Investigatorship [NRFI06-2020-0022]
CR Ahmad Wasi Uddin, 2020, P 58 ANN M ASS COMP, V0, P4998
   Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, V0, P0
   Allamanis M, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), V0, PP281, DOI 10.1145/2635868.2635883
   Allamanis M, 2013, IEEE WORK CONF MIN S, V0, PP207, DOI 10.1109/MSR.2013.6624029
   Allamanis Miltiadis, 2018, CORR, V0, P0
   [Anonymous], 2010, P IEEE ACM INT C AUT, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Devlin J, 2018, ARXIV, V1, P4171
   Dyer R, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), V0, PP422, DOI 10.1109/ICSE.2013.6606588
   Feng Z, 2020, EMNLP, V0, P0
   Cortés-Coy LF, 2014, IEEE INT WORK C SO, V0, PP275, DOI 10.1109/SCAM.2014.14
   Frantzeskou G, 2008, J SYST SOFTWARE, V81, P447, DOI 10.1016/j.jss.2007.03.004
   Huang Y, 2017, INT SYMP EMP SOFTWAR, V0, PP414, DOI 10.1109/ESEM.2017.56
   Jiang SY, 2017, IEEE INT CONF AUTOM, V0, PP135, DOI 10.1109/ASE.2017.8115626
   Junho Choi, 2011, PROCEEDINGS OF THE 2011 14TH INTERNATIONAL CONFERENCE ON NETWORK-BASED INFORMATION SYSTEMS (NBIS 2011), V0, PP618, DOI 10.1109/NBiS.2011.104
   Karampatsis RM, 2020, ARXIV PREPRINT ARXIV, V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Lavie A, 2007, P 2 WORKSHOP STAT MA, V0, P228
   Lin C-Y, 2002, P ACL 02 WORKSHOP AU, V0, P74
   Linares-Vásquez M, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P709, DOI 10.1109/ICSE.2015.229
   Linares-Vasquez M, 2014, EMPIR SOFTW ENG, V19, P582, DOI 10.1007/s10664-012-9230-z
   Liu Chia-Wei, 2016, P C EMP METH NAT LAN, V0, PP2122, DOI 10.18653/v1/D16-1230
   Liu ZX, 2018, IEEE INT CONF AUTOM, V0, PP373, DOI 10.1145/3238147.3238190
   Loyola P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P287, DOI 10.18653/v1/P17-2045
   Loyola Pablo, 2018, P 11 INT C NAT LANG, V0, PP119, DOI 10.18653/v1/
   Maddison CJ, 2014, PR MACH LEARN RES, V32, P649
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mou LL, 2016, AAAI CONF ARTIF INTE, V0, P1287
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qin Liu, 2019, 2019 IEEE/ACM 16TH INTERNATIONAL CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR), V0, PP299, DOI 10.1109/MSR.2019.00056
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raychev Veselin, 2016, ACM SIGPLAN NOTICES, V51, P731, DOI 10.1145/3022671.2984041
   Raychev V, 2014, ACM SIGPLAN NOTICES, V49, P419, DOI 10.1145/2666356.2594321
   Sennrich R, 2017, P SOFTW DEM 15 C EUR, V0, PP65, DOI 10.18653/V1/E17-3017
   Shen JF, 2016, P INT COMP SOFTW APP, V0, PP103, DOI 10.1109/COMPSAC.2016.162
   Song K, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang S, 2016, PROC INT CONF SOFTW, V0, PP297, DOI 10.1145/2884781.2884804
   White M, 2016, IEEE INT CONF AUTOM, V0, PP87, DOI 10.1145/2970276.2970326
   Xu SB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3975
   Zhang J, 2019, PROC INT CONF SOFTW, V0, PP783, DOI 10.1109/ICSE.2019.00086
   Zhu J, 2020, ICLR, V0, P0
NR 45
TC 6
Z9 6
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 12
PY 2021
VL 459
IS 
BP 97
EP 107
DI 10.1016/j.neucom.2021.05.039
EA JUL 2021
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WM4OM
UT WOS:000711066300009
DA 2023-11-10
ER

PT J
AU Li, ZY
   Ding, X
   Liu, T
AF Li, Zhongyang
   Ding, Xiao
   Liu, Ting
TI TransBERT: A Three-Stage Pre-training Technology for Story-Ending Prediction
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Natural language processing; story-ending prediction; transfer learning; pre-trained models
AB Recent advances, such as GPT, BERT, and RoBERTa, have shown success in incorporating a pre-trained transformer language model and fine-tuning operations to improve downstream NLP systems. However, this framework still has some fundamental problems in effectively incorporating supervised knowledge from other related tasks. In this study, we investigate a transferable BERT (TransBERT) training framework, which can transfer not only general language knowledge from large-scale unlabeled data but also specific kinds of knowledge from various semantically related supervised tasks, for a target task. Particularly, we propose utilizing three kinds of transfer tasks, including natural language inference, sentiment classification, and next action prediction, to further train BERT based on a pre-trained model. This enables the model to get a better initialization for the target task. We take story-ending prediction as the target task to conduct experiments. The final results of 96.0% and 95.0% accuracy on two versions of Story Cloze Test datasets dramatically outperform previous state-of-the-art baseline methods. Several comparative experiments give some helpful suggestions on how to select transfer tasks to improve BERT. Furthermore, experiments on six English and three Chinese datasets show that TransBERT generalizes well to other tasks, languages, and pre-trained models.
C1 [Li, Zhongyang; Ding, Xiao; Liu, Ting] Harbin Inst Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Liu, T (通讯作者)，Harbin Inst Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
EM zyli@ir.hit.edu.cn; xding@ir.hit.edu.cn; tliu@ir.hit.edu.cn
FU National Key Research and Development Program of China [2018AAA0101901]; National Natural Science Foundation of China (NSFC) [61976073, 61702137]; China Scholarship Council
CR [Anonymous], 2017, P 2 WORKSHOP LINKING, V0, P0, DOI DOI 10.18653/V1/W17-0907
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Cai Z, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P616, DOI 10.18653/v1/P17-2097
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Chaturvedi Snigdha, 2017, P EMNLP 2017, V0, P1603
   Chen JA, 2019, AAAI CONF ARTIF INTE, V0, P6244
   Chen J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4946
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2475
   Conneau Alexis, 2019, ARXIV191102116, V0, P0
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177
   Devlin Jacob, 2019, BERT PRE TRAINING DE, V0, P4171
   Dolan B, 2005, 3 INT WORKSHOP PARAP, V0, P0
   Fu ZX, 2018, AAAI CONF ARTIF INTE, V0, P663
   Gao Jianfeng, 2015, P 2015 C N AM CHAPT, V0, PP912, DOI 10.3115/V1/N15-1092
   Giampiccolo Danilo, 2007, P ACL PASCAL WORKSHO, V0, P1
   Guan J, 2019, AAAI CONF ARTIF INTE, V0, P6473
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, P2333
   Li Q, 2018, P 27 INT C COMPUTATI, V0, P1754
   Li Z, 2018, PROC 27 INT C COMPUT, V0, P1033
   Li ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4201
   Li ZY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1800
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   Liu Xin, 2018, P 27 INT C COMP LING, V0, P1952
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Luo FL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6020
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mo KX, 2018, AAAI CONF ARTIF INTE, V0, P5317
   Mostafazadeh N, 2016, P 2016 C N AM CHAPTE, V0, PP839, DOI 10.18653/V1/N16
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Phang J, 2018, ARXIV181101088, V0, P0
   Qin LB, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2078
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Roemmele Melissa, 2011, 2011 AAAI SPRING S S, V0, P90
   Shang Mingyue, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Sharma R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P752
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang BN, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4123
   Wang TM, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5233
   Wang YL, 2019, IEEE INT WORKSH MULT, V0, P0, DOI DOI 10.1109/mmsp.2019.8901772
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yang Zhilin, 2017, ICLR, V0, P0
   Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P93
   Zhou MT, 2019, IEEE-ACM T AUDIO SPE, V27, P719, DOI 10.1109/TASLP.2019.2893499
NR 49
TC 2
Z9 3
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR 15
PY 2021
VL 20
IS 1
BP 
EP 
DI 10.1145/3427669
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RO2RN
UT WOS:000640893600014
DA 2023-11-10
ER

PT J
AU Farazi, M
   Khan, S
   Barnes, N
AF Farazi, Moshiur
   Khan, Salman
   Barnes, Nick
TI Accuracy vs. complexity: A trade-off in visual question answering models
SO PATTERN RECOGNITION
LA English
DT Article
DE Visual question answering; Visual feature extraction; Language features; Multi-modal fusion; Speed-accuracy trade-off
ID language
AB Visual Question Answering (VQA) has emerged as a Visual Turing Test to validate the reasoning ability of AI agents. The pivot to existing VQA models is the joint embedding that is learned by combining the visual features from an image and the semantic features from a given question. Consequently, a large body of literature has focused on developing complex joint embedding strategies coupled with visual attention mechanisms to effectively capture the interplay between these two modalities. However, modelling the visual and semantic features in a high dimensional (joint embedding) space is computationally expensive, and more complex models often result in trivial improvements in the VQA accuracy. In this work, we systematically study the trade-off between the model complexity and the performance on the VQA task. VQA models have a diverse architecture comprising of pre-processing, feature extraction, multi modal fusion, attention and final classification stages. We specifically focus on the effect of "multi-modal fusion" in VQA models that is typically the most expensive step in a VQA pipeline. Our thorough experimental evaluation leads us to three proposals, one optimized for minimal complexity, one for balanced complexity-accuracy and the last one for state-of-the-art VQA performance. (c) 2021 Elsevier Ltd. All rights reserved.
C1 [Farazi, Moshiur] Commonwealth Sci & Ind Res Org CSIRO, Data61, Canberra, ACT 2601, Australia.
   [Farazi, Moshiur; Barnes, Nick] Australian Natl Univ ANU, Coll Engn & Comp Sci, Canberra, ACT 0200, Australia.
   [Khan, Salman] Mohamed bin Zayed Univ Artificial Intelligence MB, Abu Dhabi 0000, U Arab Emirates.
C3 Commonwealth Scientific & Industrial Research Organisation (CSIRO); Australian National University; Mohamed Bin Zayed University of Artificial Intelligence
RP Farazi, M (通讯作者)，Commonwealth Sci & Ind Res Org CSIRO, Data61, Canberra, ACT 2601, Australia.; Farazi, M (通讯作者)，Australian Natl Univ ANU, Coll Engn & Comp Sci, Canberra, ACT 0200, Australia.
EM moshiur.farazi@anu.edu.au
CR Aditya S, 2018, P AAAI C ART INT, V0, P32
   Aditya S, 2018, COMPUT VIS IMAGE UND, V173, P33, DOI 10.1016/j.cviu.2017.12.004
   Agrawal A, 2018, PROC CVPR IEEE, V0, PP4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Andreas J, 2016, PROC CVPR IEEE, V0, PP39, DOI 10.1109/CVPR.2016.12
   [Anonymous], 2018, P EUR C COMP VIS ECC, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2016, ARXIV160603647, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, V0, P8102
   Ben-younes H, 2017, IEEE I CONF COMP VIS, V0, PP2631, DOI 10.1109/ICCV.2017.285
   Cadene R, 2019, PROC CVPR IEEE, V0, PP1989, DOI 10.1109/CVPR.2019.00209
   Cadene Remi, 2019, ADV NEUR IN, V0, P841
   Charikar M, 2004, THEOR COMPUT SCI, V312, P3, DOI 10.1016/S0304-3975(03)00400-6
   dAlche Buc F, 2019, NEURAL INFORM PROCES, V32, P8024
   Devlin J, 2018, ARXIV, V1, P4171
   Fang ZW, 2019, PATTERN RECOGN, V90, P404, DOI 10.1016/j.patcog.2019.01.038
   Farajollahi M, 2018, 2018 C LASERS ELECTR, V0, PP1, DOI 10.1109/PESGM.2018.8586273
   Farazi MR, 2020, IMAGE VISION COMPUT, V103, P0, DOI 10.1016/j.imavis.2020.103985
   Fukui Akira, 2016, ARXIV160601847, V0, PP457, DOI 10.18653/V1/D16-1044
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Gu JX, 2019, IEEE I CONF COMP VIS, V0, PP10322, DOI 10.1109/ICCV.2019.01042
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/TPAMI.2019.2913372
   Hudson DA, 2019, P IEEE CVF C COMP VI, V0, P6700
   Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Jun SH, 2017, ICEC17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, V0, P0, DOI DOI 10.1145/3154943.3154947
   Kafle K, 2017, IEEE I CONF COMP VIS, V0, PP1983, DOI 10.1109/ICCV.2017.217
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V0, PP3294, DOI 10.5555/2969442.2969607
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2021, PATTERN RECOGN, V117, P0, DOI 10.1016/j.patcog.2021.107956
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Lu JS, 2016, ADV NEUR IN, V29, P0
   Patro BN, 2021, PATTERN RECOGN, V110, P0, DOI 10.1016/j.patcog.2020.107586
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Ramakrishnan Sainandan, 2018, ADV NEURAL INFORM PR, V0, P1548
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Shah S, 2019, AAAI CONF ARTIF INTE, V0, P8876
   Shih KJ, 2016, PROC CVPR IEEE, V0, PP4613, DOI 10.1109/CVPR.2016.499
   Simonyan K, 2015, ARXIV, V0, P0
   Su Weijie, 2020, P 8 INT C LEARN REPR, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tan H, 2019, PROC EMNLP, V0, P5100
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang P, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1290
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang R, 2020, P IEEE C COMP VIS PA, V0, PP12746, DOI 10.1109/CVPR42600.2020.01276
   Wu Q, 2016, PROC CVPR IEEE, V0, PP4622, DOI 10.1109/CVPR.2016.500
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Xiujun I, 2020, ECCV, V0, P0
   Xu DF, 2017, PROC CVPR IEEE, V0, PP3097, DOI 10.1109/CVPR.2017.330
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2017, PROC CVPR IEEE, V0, PP4187, DOI 10.1109/CVPR.2017.446
   Yu J, 2020, PATTERN RECOGN, V108, P0, DOI 10.1016/j.patcog.2020.107563
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Zellers R, 2019, PROC CVPR IEEE, V0, PP6713, DOI 10.1109/CVPR.2019.00688
   Zhang Cui cui, 2019, BRIT MACH VIS C BMVC, V0, P0
   Zhang XC, 2017, PROC CVPR IEEE, V0, PP3900, DOI 10.1109/CVPR.2017.415
   Zhang Y, 2018, ARXIV180205766, V0, P0
   Zhu YK, 2016, PROC CVPR IEEE, V0, PP4995, DOI 10.1109/CVPR.2016.540
NR 69
TC 14
Z9 16
U1 1
U2 11
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD DEC 15
PY 2021
VL 120
IS 
BP 
EP 
DI 10.1016/j.patcog.2021.108106
EA JUL 2021
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA UJ8LY
UT WOS:000691531800010
DA 2023-11-10
ER

PT J
AU Varjokallio, M
   Virpioja, S
   Kurimo, M
AF Varjokallio, Matti
   Virpioja, Sami
   Kurimo, Mikko
TI Morphologically motivated word classes for very large vocabulary speech recognition of Finnish and Estonian
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Language modelling; Class-based language models; Morphologically rich languages
ID language models; search
AB We study class-based n-gram and neural network language models for very large vocabulary speech recognition of two morphologically rich languages: Finnish and Estonian. Due to morphological processes such as derivation, inflection and compounding, the models need to be trained with vocabulary sizes of several millions of word types. Class-based language modelling is in this case a powerful approach to alleviate the data sparsity and reduce the computational load. For a very large vocabulary, bigram statistics may not be an optimal way to derive the classes. We thus study utilizing the output of a morphological analyzer to achieve efficient word classes. We show that efficient classes can be learned by refining the morphological classes to smaller equivalence classes using merging, splitting and exchange procedures with suitable constraints. This type of classification can improve the results, particularly when language model training data is not very large. We also extend the previous analyses by rescoring the hypotheses obtained from a very large vocabulary recognizer using class-based neural network language models. We show that despite the fixed vocabulary, carefully constructed classes for word-based language models can in some cases result in lower error rates than subword-based unlimited vocabulary language models. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Varjokallio, Matti; Kurimo, Mikko] Aalto Univ, Sch Elect Engn, Dept Signal Proc & Acoust, Espoo, Finland.
   [Virpioja, Sami] Univ Helsinki, Fac Arts, Dept Digital Humanities, Helsinki, Finland.
C3 Aalto University; University of Helsinki
RP Varjokallio, M (通讯作者)，Aalto Univ, Sch Elect Engn, Dept Signal Proc & Acoust, Espoo, Finland.
EM matti.varjokallio@aalto.fi; sami.virpioja@helsinki.fi; mikko.kurimo@aalto.fi
FU Academy of Finland [251170]
CR Aalto University, 2014, AALTOASR AALT AUT SP, V0, P0
   Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Arisoy E, 2009, IEEE T AUDIO SPEECH, V17, P874, DOI 10.1109/TASL.2008.2012313
   Aubert XL, 2002, COMPUT SPEECH LANG, V16, P89, DOI 10.1006/csla.2001.0185
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Botros R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1443
   Brown PF, 1992, COMPUTATIONAL LINGUISTICS, V18, P467
   Brychcin T, 2011, PROCEEDINGS OF THE 2011 IEEE 6TH INTERNATIONAL CONFERENCE ON INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS (IDAACS 2011), V0, PP560, DOI 10.1109/IDAACS.2011.6072829
   CHEN B, 2009, P HUM LANG TECHN 200, V0, P450
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chen SF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1037
   CORTES C, 2008, HDB SPEECH PROCESSIN, V0, P2
   Creutz M, 2002, P ACL 2002 WORKSH MO, V0, PP21, DOI 10.3115/1118647.1118650
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V5, P1, DOI 10.1145/1322391.1322394
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Enarvi S, 2016, INTERSPEECH, V0, PP3052, DOI 10.21437/Interspeech.2016-618
   Enarvi S, 2017, IEEE-ACM T AUDIO SPE, V25, P2085, DOI 10.1109/TASLP.2017.2743344
   Gatherers: The Department of General Linguistics University of Helsinki; The University of Eastern Finland; CSC-IT Center for Science Ltd, 2000, KIEL CORP EL DOC COL, V0, P0
   Goodman J, 2001, INT CONF ACOUST SPEE, V0, PP561, DOI 10.1109/ICASSP.2001.940893
   Gutmann M, 2010, J MACH LEARN RES, V13, P307
   Hirsimäki T, 2004, HELS UNIV TECHNOL S, V46, P320
   Hirsimäki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   Hirsimäki T, 2009, IEEE T AUDIO SPEECH, V17, P724, DOI 10.1109/TASL.2008.2012323
   Iskra D, 2002, P LREC, V0, P329
   Karlsson, 1999, FINNISH ESSENTIAL GR, V0, P0
   KARLSSON F, 1985, FOLIA LINGUIST, V19, P207, DOI 10.1515/flin.1985.19.1-2.207
   KNESER R, 1995, INT CONF ACOUST SPEE, V0, PP181, DOI 10.1109/ICASSP.1995.479394
   Kneser R, 1991, P 1 INT C QUANT LING, V0, P221
   KUHN T, 1994, INT CONF ACOUST SPEE, V0, P357
   KURIMO M, 2006, P MAIN C HUM LANG TE, V0, P487
   Kurimo M, 2017, LANG RESOUR EVAL, V51, P961, DOI 10.1007/s10579-016-9336-9
   Linden K, 2009, NO EUROPEAN J LANGUA, V1, P1
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P923
   Mansikkaniemi A, 2017, INTERSPEECH, V0, PP3762, DOI 10.21437/Interspeech.2017-1115
   Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9
   Meister E, 2012, PHONETICS S 2012 TAL, V0, P30
   Nasrabadi Nasser M, 2007, J ELECT IMAG, V16, P0
   Ney H, 2000, P IEEE, V88, P1224, DOI 10.1109/5.880081
   Niesler TR, 1998, INT CONF ACOUST SPEE, V0, PP177, DOI 10.1109/ICASSP.1998.674396
   Niesler TR, 1999, COMPUT SPEECH LANG, V13, P99, DOI 10.1006/csla.1998.0115
   Orasmaa S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2460
   Ortmanns S, 2000, COMPUT SPEECH LANG, V14, P15, DOI 10.1006/csla.1999.0131
   Pirinen TA, 2015, P 20 NORD C COMP LIN, V0, P313
   Pylkk_onen J, 2005, P 2 BALT C HUM LANG, V0, P167
   Saagpakk Paul F, 1982, ESTONIAN ENGLISH DIC, V0, P0
   Shi Y, 2013, IEEE ANTENNAS PROP, V0, PP13, DOI 10.1109/APS.2013.6710667
   Siivola V, 2007, IEEE T AUDIO SPEECH, V15, P1617, DOI 10.1109/TASL.2007.896666
   Sixtus A, 2002, COMPUT SPEECH LANG, V16, P245, DOI 10.1006/csla.2002.192
   Smit P, 2017, INTERSPEECH, V0, PP2551, DOI 10.21437/Interspeech.2017-103
   Soltau H, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), V0, PP276, DOI 10.1109/ASRU.2009.5372904
   Srivastava Rupesh Kumar, 2015, NIPS, V0, P2377
   Stolcke A, 2011, P IEEE WORKSHOP AUTO, V0, P0
   TAM YC, 2008, NIPS, V0, P1633
   Tarjan B, 2014, P 4 INT WORKSH SPOK, V0, P131
   The Parliament of Finland, 2017, PLEN SESS PARL FINL, V0, P0
   UiT The Arctic University of Norway; The Divvun group at UiT The Arctic University of Norway, 2020, DIVV GROUP UIT ARCT, V0, P0
   Vaiciunas A, 2004, INFORMATICA-LITHUAN, V15, P565
   Vaiciunas A, 2006, STAT LANGUAGE MODELS, V0, P0
   Varjokallio M, 2018, IEEE W SP LANG TECH, V0, PP227, DOI 10.1109/SLT.2018.8639691
   Varjokallio M, 2016, LECT NOTES ARTIF INT, V9918, P133, DOI 10.1007/978-3-319-45925-7_11
   Varjokallio M, 2014, IEEE W SP LANG TECH, V0, PP495, DOI 10.1109/SLT.2014.7078624
   Varjokallio M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP7, DOI 10.1109/ASRU.2013.6707697
   Viitso T-R, 1997, URALIC LANGUAGES, V0, P115
   Whittaker EWD, 2000, P 6 INT C SPOK LANG, V0, P170
   Whittaker EWD, 2003, COMPUT SPEECH LANG, V17, P87, DOI 10.1016/S0885-2308(02)00047-5
   Whittaker EWD, 2001, INT CONF ACOUST SPEE, V0, PP545, DOI 10.1109/ICASSP.2001.940889
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
   Yu D, 2015, SIGNALS COMMUN TECHN, V0, PP1, DOI 10.1007/978-1-4471-5779-3
NR 70
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR 15
PY 2021
VL 66
IS 
BP 
EP 
DI 10.1016/j.csl.2020.101141
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA PB5PE
UT WOS:000596372000001
DA 2023-11-10
ER

PT J
AU Zhan, ZQ
   Zhao, JY
   Zhang, Y
   Gong, JT
   Wang, QY
   Shen, Q
   Zhang, LX
AF Zhan, Zhiqiang
   Zhao, Jianyu
   Zhang, Yang
   Gong, Jiangtao
   Wang, Qianying
   Shen, Qi
   Zhang, Liuxin
TI Grabbing the Long Tail: A data normalization method for diverse and informative dialogue generation
SO NEUROCOMPUTING
LA English
DT Article
DE Dialogue generation; Long Tail; Data normalization; Diversity; Informativeness
AB Recent neural models have shown significant progress in dialogue generation. Among those models, most of them are based on language models, yielding the generation word by word according to the previous context. Due to the inherent mechanism in language models, as well as the most frequently used cross-entropy function (making the distribution of generations approximate that of training data continuously), trained generation models inevitably tend to generate frequent words in training datasets, leading to low diversity and poor informativeness issues. By investigating a few mainstream dialogue generation models, we find that the probable cause is the intrinsic Long Tail Phenomenon in linguistics. To address these issues of low diversity and poor informativeness, we explore and analyze a large corpus from Wikipedia, and then propose an efficient frequency-based data normalization method, i.e., Log Normalization. Furthermore, we explore another two methods, Mutual Normalization and Log-Mutual Normalization, to eliminate the mutual information effect. In order to validate the effectiveness of the proposed methods, we conduct extensive experiments on three datasets with different subjects, includ-ing social media, film subtitles, and online customer service. Compared with the vanilla transformers, generation models augmented with our proposed methods achieve significant improvements in gener-ated responses, in terms of both diversity and informativeness. Specifically, the unigram and bigram diversity in the responses are improved by 8.5%-14.1% and 19.7%-25.8% on the three datasets, respec-tively. The informativeness (defined as amounts of nouns and verbs) is increased by 13.1%-31.0% and 30.4%-59.0%, respectively. Moreover, our methods can be adapted to new generation models efficiently and effectively, with their model-agnostic characteristics. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhan, Zhiqiang; Zhang, Yang; Gong, Jiangtao; Wang, Qianying; Zhang, Liuxin] Lenovo Res, Smart Educ Lab, Beijing, Peoples R China.
   [Zhao, Jianyu] Lenovo Res, Al Lab, Beijing, Peoples R China.
   [Shen, Qi] Beijing Union Univ, Beijing, Peoples R China.
C3 Legend Holdings; Lenovo; Legend Holdings; Lenovo; Beijing Union University
RP Zhang, LX (通讯作者)，Lenovo Res, Smart Educ Lab, Beijing, Peoples R China.
EM zhanglx2@lenovo.com
FU Research Project of Humanity and Social Science of the Ministry of Education [20YJC880088]
CR Bahdanau D, 2016, ARXIV, V0, P0
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P85
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Devlin J, 2018, ARXIV, V1, P4171
   Gao X, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1229
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Ham D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P583
   Hamedani EM, 2019, KNOWL-BASED SYST, V164, P348, DOI 10.1016/j.knosys.2018.11.004
   Kingma DP, 2014, C TRACK P, V0, P0
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Li Jiwei, 2016, NAACL, V0, PP110, DOI 10.18653/V1/N16-1014
   Lin Q, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1417
   Lin XX, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P41
   Nie LQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1098, DOI 10.1145/3343031.3350923
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Patra BK, 1900, V140, V0, P0
   Ritter A, 2011, P C EMPIRICAL METHOD, V0, P583
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Shannon CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shao TH, 2019, IEEE ACCESS, V7, P26146, DOI 10.1109/ACCESS.2019.2900753
   Shao Yuanlong, 2017, P 2017 C EMP METH NA, V0, PP2210, DOI 10.18653/v1/D17-1235
   Shi Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4361
   Sordoni A, 2015, P 2015 C N AM CHAPT, V0, P196
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wu BW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P53
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P917
   Wu S, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.515
   Xu JJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3940
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang SQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1878
   Zhan Z, 2019, INT JOINT C NEUR NET, V0, P1
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
   Zhou H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4623
NR 37
TC 4
Z9 4
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 14
PY 2021
VL 460
IS 
BP 374
EP 384
DI 10.1016/j.neucom.2021.07.039
EA JUL 2021
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UR5IM
UT WOS:000696783000012
DA 2023-11-10
ER

PT J
AU Ponnusamy, P
   Ghias, AR
   Yi, Y
   Yao, B
   Guo, CL
   Sarikaya, R
AF Ponnusamy, Pragaash
   Ghias, Alireza Roshan
   Yi, Yi
   Yao, Benjamin
   Guo, Chenlei
   Sarikaya, Ruhi
TI Feedback-based self-learning in large-scale conversational AI agents
SO AI MAGAZINE
LA English
DT Article
ID likelihood
AB Today, most of the large-scale conversational AI agents such as Alexa, Siri, or Google Assistant are built using manually annotated data to train the different components of the system including automatic speech recognition (ASR), natural language understanding (NLU), and entity resolution (ER). Typically, the accuracy of the machine learning models in these components are improved by manually transcribing and annotating data. As the scope of these systems increase to cover more scenarios and domains, manual annotation to improve the accuracy of these components becomes prohibitively costly and time consuming. In this paper, we propose a system that leverages customer/system interaction feedback signals to automate learning without any manual annotation. Users of these systems tend to modify a previous query in hopes of fixing an error in the previous turn to get the right results. These reformulations, which are often preceded by defective experiences caused by either errors in ASR, NLU, ER, or the application. In some cases, users may not properly formulate their requests (e.g., providing partial title of a song), but gleaning across a wider pool of users and sessions reveals the underlying recurrent patterns. Our proposed self-learning system automatically detects the errors, generates reformulations, and deploys fixes to the runtime system to correct different types of errors occurring in different components of the system. In particular, we propose leveraging an absorbing Markov Chain model as a collaborative filtering mechanism in a novel attempt to mine these patterns, and coupling it with a guardrail rewrite selection mechanism that reactively evaluates these fixes using feedback friction data. We show that our approach is highly scalable, and able to learn reformulations that reduce Alexa-user errors by pooling anonymized data across millions of customers. The proposed self-learning system achieves a win-loss ratio of 11.8 and effectively reduces the defect rate by more than 30 percent on utterance level reformulations in our production A/B tests. To the best of our knowledge, this is the first self-learning large-scale conversational AI system in production.
C1 [Ponnusamy, Pragaash; Ghias, Alireza Roshan; Yi, Yi; Yao, Benjamin; Guo, Chenlei; Sarikaya, Ruhi] Amazon Alexa, Redmond, WA 98008 USA.
RP Guo, CL (通讯作者)，Amazon Alexa, Redmond, WA 98008 USA.
EM chenlei.guo@gmail.com
CR Chapelle O, 2011, NIPS, V0, P2249
   Devlin J, 2018, ARXIV, V1, P4171
   Doob JL, 1935, ANN MATH STAT, V6, P160, DOI 10.1214/aoms/1177732594
   FAHRMEIR L, 1985, ANN STAT, V13, P342, DOI 10.1214/aos/1176346597
   Fouss F, 2005, P 7 INT C ENT INF SY, V0, P56
   Gao J, 2018, ABS180908267 CORR, V0, P0
   Graepel Thore, 2010, P 27 INT C MACH LEAR, V0, PP13, DOI 10.1109/TNSE.2021.3102582
   Grinstead CM, 1997, INTRO PROBABILITY, V0, P0
   Hill DN, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1813, DOI 10.1145/3097983.3098184
   Jansen BJ, 2009, J AM SOC INF SCI TEC, V60, P1358, DOI 10.1002/asi.21071
   Khorasani ES, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), V0, PP3484, DOI 10.1109/BigData.2016.7841011
   Li Lihong, 2010, P 19 INT C WORLD WID, V0, PP661, DOI 10.1145/1772690.1772758
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   Sahoo N, 2012, MIS QUART, V36, P1329
   Sarikaya R, 2017, IEEE SIGNAL PROC MAG, V34, P67, DOI 10.1109/MSP.2016.2617341
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Terveen L, 2001, NEW MILLENNIUM, V0, P0
   Thompson WR, 1933, BIOMETRIKA, V25, P285, DOI 10.2307/2332286
   Wang JW, 2015, MATH PROBL ENG, V2015, P0, DOI 10.1155/2015/714149
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
   Zhu X, 2012, CIKM 12, V0, P0
NR 22
TC 1
Z9 1
U1 0
U2 0
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
EI 2371-9621
J9 AI MAG
JI AI Mag.
PD JUN 15
PY 2021
VL 42
IS 4
BP 43
EP 56
DI 10.1609/aaai.12025
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YW1QK
UT WOS:000753194600004
DA 2023-11-10
ER

PT J
AU Chen, ZS
   Zhang, SW
   Zhang, JX
   Hu, ZJ
   Han, X
   Xu, MY
AF Chen, Zhongshan
   Zhang, Shengwei
   Zhang, Juxiao
   Hu, Zuojin
   Han, Xue
   Xu, Mengyang
TI A novel artificial intelligence model for color image quality assessment for security enhanement weighted by visual saliency
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Image quality assessment (IQA); brightness distortion; chrome distortion; gradient distortion; visual saliency (VS); structural similarity; artificial intelligence (AI); fuzzy set
ID information
AB Artificial Intelligence (AI) is the enhancement and method of computer system that handles tasks which requires human like intelligence such as recognition, language translation and visual interpretation. Subjective image quality assessment (IQA) is difficult to be implemented in real-time systems, methodology for enhancing the involvement in producing IQA model is to improve the quality of image by significant evaluation. Intuitively, human eyes are not sensitive to the distortion and damage from the area with lesser visual saliency (VS), VS is closely related to IQA. With this consideration, an effective IQA was proposed, which involved two processes. The local quality map of a distorted image was computed using the structural similarity function of its feature attributes, such as brightness, chrominance and gradient. Second, the local quality map was weighted with visual saliency (VS) to get the objective evaluation of image quality. The VS was modeled by extracting the saliency of low-level features of the image, wiping off the molestation information from these saliency based on an apriori threshold, and combining the effective information to construct the saliency map. Image processing using fuzzy is gathering features and segments as fuzzy set while processing images. The experiments on the two largest database for six classical IQA metrics demonstrate that performance of weighted-VS IQA metrics is superior to the performance of no weighted-VS IQA metrics, and the proposed IQA method has higher computational accuracy than the other IQA metrics under a moderate computational complexity, especially for two types of distortion images, such as local block-wise (Block) and fast-fading (FTF).
C1 [Chen, Zhongshan; Zhang, Shengwei; Zhang, Juxiao; Hu, Zuojin; Han, Xue] Nanjing Normal Univ Special Educ, Sch Math & Informat Sci, Shennong Rd 1, Nanjing, Peoples R China.
   [Xu, Mengyang] Nanjing Normal Univ Special Educ, Coll Art & Design, Nanjing, Peoples R China.
C3 Nanjing Normal University of Special Education; Nanjing Normal University of Special Education
RP Chen, ZS (通讯作者)，Nanjing Normal Univ Special Educ, Sch Math & Informat Sci, Shennong Rd 1, Nanjing, Peoples R China.
EM ycddzjb@163.com
CR Achanta R, 2009, PROC CVPR IEEE, V0, PP1597, DOI 10.1109/CVPRW.2009.5206596
   Ahilan A, 2019, IEEE ACCESS, V7, P89570, DOI 10.1109/ACCESS.2019.2891632
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2007, P IEEE C COMP VIS PA, V0, P0
   Bruce NDB, 2009, J VISION, V9, P0, DOI 10.1167/9.3.5
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Ezhilmaran D, 2017, ADV COMPU INTELL ROB, V0, PP1, DOI 10.4018/978-1-5225-2053-5.ch001
   Galezan FH, 2020, AQUACULT ENG, V89, P0, DOI 10.1016/j.aquaeng.2020.102051
   Goferman S, 2010, PROC CVPR IEEE, V0, PP2376, DOI 10.1109/CVPR.2010.5539929
   Harel Jonathan, 2006, ADV NEURAL INFORM PR, V19, P2, DOI 10.7551/MITPRESS/7503.003.0073
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Manickam A, 2019, J ELECTRON IMAGING, V28, P0, DOI 10.1117/1.JEI.28.3.033027
   Ponomarenko N, 2009, ADV MOD RADIOELECTRO, V10, P30
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Uma, 2019, INT J INNOV TECHNOL, V8, P3544, DOI 10.35940/IJITEE.J9762.0881019
   Wang Z, 2003, CONF REC ASILOMAR C, V0, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 27
TC 0
Z9 0
U1 1
U2 10
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2021
VL 40
IS 4
BP 8091
EP 8100
DI 10.3233/JIFS-189632
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RN7PP
UT WOS:000640545600031
DA 2023-11-10
ER

PT J
AU Wang, J
   Zhang, XF
   Chen, L
AF Wang, Jun
   Zhang, Xiaofang
   Chen, Lin
TI How well do pre-trained contextual language representations recommend labels for GitHub issues?
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Deep learning; Issue labeling; Data analysis; Language model
ID tag recommendation; system
AB Motivation: Open-source organizations use issues to collect user feedback, software bugs, and feature requests in GitHub. Many issues do not have labels, which makes labeling time-consuming work for the maintainers. Recently, some researchers used deep learning to improve the performance of automated tagging for software objects. However, these researches use static pre-trained word vectors that cannot represent the semantics of the same word in different contexts. Pre-trained contextual language representations have been shown to achieve outstanding performance on lots of NLP tasks. Description: In this paper, we study whether the pre-trained contextual language models are really better than other previous language models in the label recommendation for the GitHub labels scenario. We try to give some suggestions in fine-tuning pre-trained contextual language representation models. First, we compared four deep learning models, in which three of them use traditional pretrained word embedding. Furthermore, we compare the performances when using different corpora for pre-training. Results: The experimental results show that: (1) When using large training data, the performance of BERT model is better than other deep learning language models such as Bi-LSTM, CNN and RCNN. While with a small size training data, CNN performs better than BERT. (2) Further pre-training on domain-specific data can indeed improve the performance of models. Conclusions: When recommending labels for issues in GitHub, using pre-trained contextual language representations is better if the training dataset is large enough. Moreover, we discuss the experimental results and provide some implications to improve label recommendation performance for GitHub issues. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, Jun; Zhang, Xiaofang] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
   [Chen, Lin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Soochow University - China; Nanjing University
RP Zhang, XF (通讯作者)，Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
EM 20194227028@stu.suda.edu.cn; xfzhang@suda.edu.cn; lchen@nju.edu.cn
FU National Natural Science Foundation of China [61772263, 61872177]; Collaborative Innovation Center of Novel Software Technology and Industrialization; Priority Academic Program Development of Jiangsu Higher Education Institutions
CR Alec R, 2018, TECH REP TECHNICAL R, V0, P0
   [Anonymous], 2014, WORKING C MINING SOF, V0, P0, DOI DOI 10.1145/2597073.2597113
   Antoniol G, 2008, P 2008 C CTR ADV STU, V0, PP23:304, DOI 10.1145/1463788.1463819
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Cabot J, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Charte F, 2015, KNOWL-BASED SYST, V89, P385, DOI 10.1016/j.knosys.2015.07.019
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen Y, 1900, P1, V0, P0
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Guzman E, 2014, P 11 WORKING C MININ, V0, PP352, DOI 10.1145/2597073.2597118
   Herzig K, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), V0, PP392, DOI 10.1109/ICSE.2013.6606585
   Kallis R, 2019, PROC IEEE INT CONF S, V0, PP406, DOI 10.1109/ICSME.2019.00070
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Li C, 2019, LECT NOTES ARTIF INT, V11776, P11, DOI 10.1007/978-3-030-29563-9_2
   Liu J, 2018, AUTOMAT SOFTW ENG, V25, P675, DOI 10.1007/s10515-018-0239-4
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Nemenyi P, 1900, V25, V0, P1233
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, V0, PP257, DOI 10.1007/978-0-387-85820-3_8
   Treude C, 2009, PROC INT CONF SOFTW, V0, PP12, DOI 10.1109/ICSE.2009.5070504
   Tsoumakas G, 2007, INT J DATA WAREHOUS, V3, P1, DOI 10.4018/JDWM.2007070101
   Wang SW, 2018, EMPIR SOFTW ENG, V23, P800, DOI 10.1007/s10664-017-9533-1
   Wilcoxon F, 1992, BREAKTHROUGHS STAT, VII, P196
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Xia X, 2013, IEEE WORK CONF MIN S, V0, PP287, DOI 10.1109/MSR.2013.6624040
   Yang D, 2014, WWW14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP407, DOI 10.1145/2567948.2577285
   Zhang J, 2018, KNOWL-BASED SYST, V159, P148, DOI 10.1016/j.knosys.2018.07.003
   Zhou PY, 2019, INFORM SOFTWARE TECH, V109, P1, DOI 10.1016/j.infsof.2019.01.002
   Zhou PY, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 39
TC 9
Z9 10
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 28
PY 2021
VL 232
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107476
EA SEP 2021
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WB4VP
UT WOS:000703571500011
DA 2023-11-10
ER

PT J
AU Schulder, M
   Wiegand, M
   Ruppenhofer, J
AF Schulder, Marc
   Wiegand, Michael
   Ruppenhofer, Josef
TI Automatic generation of lexica for sentiment polarity shifters
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Sentiment analysis; Sentiment polarity; Lexical semantics; Lexicon generation; Negation content words
AB Alleviating pain is good and abandoning hope is bad. We instinctively understand how words like alleviate and abandon affect the polarity of a phrase, inverting or weakening it. When these words are content words, such as verbs, nouns, and adjectives, we refer to them as polarity shifters. Shifters are a frequent occurrence in human language and an important part of successfully modeling negation in sentiment analysis; yet research on negation modeling has focused almost exclusively on a small handful of closed-class negation words, such as not, no, and without. A major reason for this is that shifters are far more lexically diverse than negation words, but no resources exist to help identify them. We seek to remedy this lack of shifter resources by introducing a large lexicon of polarity shifters that covers English verbs, nouns, and adjectives. Creating the lexicon entirely by hand would be prohibitively expensive. Instead, we develop a bootstrapping approach that combines automatic classification with human verification to ensure the high quality of our lexicon while reducing annotation costs by over 70%. Our approach leverages a number of linguistic insights; while some features are based on textual patterns, others use semantic resources or syntactic relatedness. The created lexicon is evaluated both on a polarity shifter gold standard and on a polarity classification task.
C1 [Schulder, Marc; Wiegand, Michael] Univ Saarland, Sprach & Signalverarbeitung, C7 1, D-66123 Saarbrucken, Germany.
   [Schulder, Marc] Inst Deutsch Gebardensprache, Gorch Fock Wall 7, D-20354 Hamburg, Germany.
   [Wiegand, Michael; Ruppenhofer, Josef] Inst Deutsch Sprache, R 5,6-13, D-68161 Mannheim, Germany.
C3 Saarland University; Institut fur Deutsche Sprache (IDS)
RP Schulder, M (通讯作者)，Univ Saarland, Sprach & Signalverarbeitung, C7 1, D-66123 Saarbrucken, Germany.
EM marc.schulder@uni-hamburg.de
FU German Research Foundation (DFG) [RU 1873/2-1, WI 4204/2-1]
CR Agirre E, 2009, P 12 C EUROPEAN CHAP, V0, PP33, DOI 10.3115/1609067.1609070
   [Anonymous], 2009, PROC HUMAN LANGUAGE, V0, P0
   [Anonymous], 2010, WORKSHOP NEGATION SP, V0, P0
   [Anonymous], 2013, CONLL, V0, P0
   [Anonymous], 1980, GRAMMAR NEGATIVE POL, V0, P0
   [Anonymous], 2008, EMNLP, V0, P0
   [Anonymous], 2011, SEMANT INT HDB NAT L, V0, P0
   [Anonymous], 2006, INFERENCE COMPUTATIO, V0, P0
   Baker CF, 1998, 36 ANN M ASS COMPUTA, V0, PP86, DOI 10.3115/980845.980860
   BAKER CL, 1970, LINGUIST INQ, V1, P169
   Baluja S, 2008, P 17 INT C WORLD WID, V0, PP895, DOI 10.1145/1367497.1367618
   Brandes, 2016, P KONVENS, V0, P226
   BRINTON LJ, 1985, STUD LINGUISTICA, V39, P157, DOI 10.1111/j.1467-9582.1985.tb00750.x
   Cardie C, 2011, P RANLP, V0, P0
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, P0, DOI 10.1155/2014/575246
   Choi Y, 2014, P 2014 C EMP METH NA, V0, PP1181, DOI 10.3115/V1/D14-1125.HTTPS://ACLANTHOLOGY.ORG/D14-1125
   Choi Y, 2014, P 5 WORKSH COMP APPR, V0, P107
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dang HT, 2008, P TAC, V0, P0
   De Marneffe Marie-Catherine, 2008, TECHNICAL REPORT, V0, P0
   Deng L, 2014, P 14 C EUR CHAPT ASS, V0, PP377, DOI 10.3115/V1/E14-1040
   Deng L, 2013, P 51 ANN M ASS COMP, V0, P120
   Esuli A, 2005, P 14 ACM INT C INFOR, V0, PP617, DOI 10.1145/1099554.1099713
   Fillmore CJ, 1967, UNIVERSALS LINGUIST, V0, P1
   Firth JR, 1957, SYNOPSIS LINGUISTIC, V0, P0
   Flekova L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2029
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), V0, P1
   Jiang TY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1297
   JOACHIMS T, 1999, ADV KERNEL METHODS S, V0, P169
   Kang JS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1544
   Kim S, 2015, P 24 ACM INT C INF K, V0, P1131
   Kim SM, 2006, P WORKSH SENT SUBJ T, V0, PP1, DOI 10.3115/1654641.1654642
   Kiritchenko S, 2016, P 7 WORKSH COMP APPR, V0, P43
   Ladusaw, 1980, OUTSTANDING DISSERTA, V0, P0
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Liu B, 2008, P 3 INT C WEB SEARCH, V0, PP219, DOI 10.1145/1341531.1341560
   Liu B, 2011, DATA CENTRIC SYST AP, V0, PP459, DOI 10.1007/978-3-642-19460-3_11
   Liu Y, 2014, LECT NOTES COMPUT SC, V8404, P1, DOI 10.1007/978-3-642-54903-8_1
   Macleod Catherine, 1998, P 8 EURALEX INT C, V0, P187
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Marc S, 2017, IJCNLP 2017, V0, P624
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Miller G, 1990, INT J LEXICOGR, V3, P235, DOI 10.1093/IJL/3.4.235
   Mitchell M, 2013, P TAC, V0, P0
   Moilanen Karo, 2007, P RANLP, V0, P0
   Morante R, 2009, P 13 C COMP NAT LANG, V0, PP21, DOI 10.3115/1596374.1596381
   Morante R, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1429
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Polanyi L, 2006, INFORM RETRIEVAL SER, V20, P1
   Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI 10.1108/00330330610681286
   Reschke K, 2010, P VERB, V0, P98
   Schneider N, 2016, P INT WORKSH SEM EV, V0, P558
   Schulder M, 2018, P 27 INT C COMPUTATI, V0, P2516
   Schulder M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1393
   Shwartz V, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2389
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Szarvas G, 2008, P WORKSHOP CURRENT T, V0, P38
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Talukdar PP, 2008, P C EMP METH NAT LAN, V0, P582
   van der Wouden Ton, 1997, NEGATIVE CONTEXTS CO, V0, P0
   Wiegand M, 2015, P C COMP NAT LANG LE, V0, P215
   Wiegand M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P608
   Wilson TS, 2005, PHIL EDUC, V0, PP347, DOI 10.3115/1220575.1220619
   Zipf, 1935, PSYCHOBIOLOGY LANGUA, V0, P0
NR 64
TC 2
Z9 2
U1 0
U2 18
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD MAR 15
PY 2021
VL 27
IS 2
BP 153
EP 179
DI 10.1017/S135132492000039X
PG 27
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA QX5IM
UT WOS:000629379900004
DA 2023-11-10
ER

PT J
AU Ma, TH
   Yang, MM
   Rong, H
   Qian, YR
   Tian, Y
   Al-Nabhan, N
AF Ma, Tinghuai
   Yang, Mingming
   Rong, Huan
   Qian, Yurong
   Tian, Yuan
   Al-Nabhan, Najla
TI Dual-path CNN with Max Gated block for text-based person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross-modal matching; Person re-identification; Dual-path CNN; Word embedding
ID classification; model
AB Text-based person re-identification (Re-id) is an important task in video surveillance, which consists of retrieving the corresponding person's image given a textual description from a large gallery of images. It is difficult to directly match visual contents with the textual descriptions due to the modality heterogeneity. On the one hand, the textual embedding are not discriminative enough, which originates from the high abstraction of the textual descriptions. One the other hand, Global average pooling (GAP) is commonly utilized to extract more general or smoothed features implicitly but ignores salient local features, which are more important for the cross-modal matching problem. With that in mind, a novel Dual-path CNN with Max Gated block (DCMG) is proposed to extract discriminative word embedding and make visual-textual association concern more on remarkable features of both modalities. The proposed framework is based on two deep residual CNNs jointly optimized with cross modal projection matching (CMPM) loss and cross-modal projection classification (CMPC) loss to embed the two modalities into a joint feature space. First, the pre-trained language model, BERT, is combined with the convolutional neural network (CNN) to learn better word embedding in the text-to-image matching domain. Second, the global Max pooling (GMP) layer is applied to make the visual textual features focus more on the salient part. To further alleviate the noise of the maxed-pooled features, the gated block (GB) is proposed to produce an attention map that focuses on meaningful features of both modalities. Finally, extensive experiments are conducted on the benchmark dataset, CUHK-PEDES, in which our approach achieves the rank-1 score of 55.81% and outperforms the state-of-the-art method by 1.3%. We also evaluate our method on two generic retrieval datasets (Flickr30K, Oxford-102 Flowers) and obtain the competitive performance. Code is available at https://github.com/voriarty/Dual-path-CNN-with-Max-Gated-block-for-Text-Based-Person-Re-identification (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ma, Tinghuai; Yang, Mingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Rong, Huan] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing 210044, Jiangsu, Peoples R China.
   [Qian, Yurong] Xinjiang Univ, Urumqi 830008, Peoples R China.
   [Tian, Yuan] Nanjing Inst Technol, Nanjing 211167, Jiangsu, Peoples R China.
   [Al-Nabhan, Najla] KingSaud Univ, Dept Comp Sci, Riyadh 11362, Saudi Arabia.
C3 Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; Xinjiang University; Nanjing Institute of Technology
RP Ma, TH (通讯作者)，Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM thma@nuist.edu.cn
FU National Science Foundation of China; Deanship of Scientific Research at King Saud University [RG-1441-331]
CR Bonev B, 2013, COMPUT VIS IMAGE UND, V117, P214, DOI 10.1016/j.cviu.2012.11.007
   Chen TL, 2018, IEEE WINT CONF APPL, V0, PP1879, DOI 10.1109/WACV.2018.00208
   Deng WJ, 2018, PROC CVPR IEEE, V0, PP994, DOI 10.1109/CVPR.2018.00110
   Devlin J, 2018, ARXIV, V1, P4171
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Glorot X, 2010, INT C ARTIFICIAL INT, V0, PP249, DOI 10.1.1/207.2059
   Goodfellow IJ, 1900, P2672, V0, P0
   Hao Y, 2020, PATTERN RECOGN, V107, P0, DOI 10.1016/j.patcog.2020.107533
   Hao Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP57, DOI 10.1145/3343031.3351006
   Hao Y, 2019, AAAI CONF ARTIF INTE, V0, P8385
   Kalayeh MM, 2018, PROC CVPR IEEE, V0, PP1062, DOI 10.1109/CVPR.2018.00117
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Komodakis N, 2017, PAYING MORE ATTENTIO, V0, P0
   Kordopatis-Zilos G, 2019, IEEE T MULTIMEDIA, V21, P2638, DOI 10.1109/TMM.2019.2905741
   Li JN, 2020, IEEE T IMAGE PROCESS, V29, P4461, DOI 10.1109/TIP.2020.2972108
   Li K, 2019, IEEE T NEUR NET LEAR, V30, P1896, DOI 10.1109/TNNLS.2018.2875429
   Li LL, 2020, PATTERN RECOGN, V100, P0, DOI 10.1016/j.patcog.2019.107110
   Li S, 2020, PATTERN RECOGN, V97, P0
   Li S, 2018, IEEE T PATTERN ANAL, V40, P2963, DOI 10.1109/TPAMI.2017.2764893
   Li S, 2017, IEEE I CONF COMP VIS, V0, PP1908, DOI 10.1109/ICCV.2017.209
   Li S, 2017, PROC CVPR IEEE, V0, PP5187, DOI 10.1109/CVPR.2017.551
   Liao WZ, 2020, NEUROCOMPUTING, V382, P188, DOI 10.1016/j.neucom.2019.11.074
   Lin X, 2016, LECT NOTES COMPUT SC, V9906, P261, DOI 10.1007/978-3-319-46475-6_17
   Lin YT, 2020, IEEE T IMAGE PROCESS, V29, P5481, DOI 10.1109/TIP.2020.2982826
   Liu Y, 2017, IEEE I CONF COMP VIS, V0, PP4127, DOI 10.1109/ICCV.2017.442
   Lokoc J, 2018, IEEE T MULTIMEDIA, V20, P3361, DOI 10.1109/TMM.2018.2830110
   Ma TH, 2022, IEEE T AFFECT COMPUT, V13, P60, DOI 10.1109/TAFFC.2019.2932061
   Ma TH, 2020, FUTURE GENER COMP SY, V105, P533, DOI 10.1016/j.future.2019.12.022
   Ma TH, 2019, EXPERT SYST APPL, V115, P346, DOI 10.1016/j.eswa.2018.08.010
   Ma TH, 2018, NEUROCOMPUTING, V296, P33, DOI 10.1016/j.neucom.2018.03.029
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, 1 INT C LEARN REPR I, V0, P0
   Nam H, 2017, PROC CVPR IEEE, V0, PP2156, DOI 10.1109/CVPR.2017.232
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Pennington Je ff rey, 2014, P 2014 C EMPIRICAL M, V0, PP1532, DOI 10.3115/V1/D14-1162
   Peters ME, 1900, P2227, V0, P0
   Plummer BA, 2017, INT J COMPUT VISION, V123, P74, DOI 10.1007/s11263-016-0965-7
   Qiao SS, 2020, IEEE T IMAGE PROCESS, V29, P1299, DOI 10.1109/TIP.2019.2940683
   Reed S, 2016, PROC CVPR IEEE, V0, PP49, DOI 10.1109/CVPR.2016.13
   Ren C, 2019, PATTERN RECOGN, V96, P0
   Rong H, 2019, INFORM SCIENCES, V488, P158, DOI 10.1016/j.ins.2019.03.023
   Sarafianos N, 2019, IEEE I CONF COMP VIS, V0, PP5813, DOI 10.1109/ICCV.2019.00591
   Sarfraz MS, 2018, PROC CVPR IEEE, V0, PP420, DOI 10.1109/CVPR.2018.00051
   Sun Yi, 2014, NEURIPS, V0, P0
   Tang YZ, 2020, IEEE T IMAGE PROCESS, V29, P5641, DOI 10.1109/TIP.2020.2985545
   Tang YZ, 2020, NEURAL NETWORKS, V124, P223, DOI 10.1016/j.neunet.2020.01.012
   Tay CP, 2019, PROC CVPR IEEE, V0, PP7127, DOI 10.1109/CVPR.2019.00730
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang GC, 2019, AAAI CONF ARTIF INTE, V0, P8933
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP274, DOI 10.1145/3240508.3240552
   Wang L, 2016, PROC CVPR IEEE, V0, PP5005, DOI 10.1109/CVPR.2016.541
   Wang R, 2019, INFORM PROCESS MANAG, V56, P0, DOI 10.1016/j.ipm.2019.102098
   Wang Y, 1900, P2057, V0, P0
   Wong WJ, 2020, PATTERN RECOGN, V101, P0, DOI 10.1016/j.patcog.2020.107203
   Zhang Y, 1900, P707, V0, P0
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, P0, DOI 10.1145/3383184
NR 58
TC 6
Z9 6
U1 2
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 15
PY 2021
VL 111
IS 
BP 
EP 
DI 10.1016/j.imavis.2021.104168
EA APR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700002
DA 2023-11-10
ER

PT J
AU Li, HQ
   Baucom, B
   Narayanan, S
   Georgiou, P
AF Li, Haoqi
   Baucom, Brian
   Narayanan, Shrikanth
   Georgiou, Panayiotis
TI Unsupervised speech representation learning for behavior modeling using triplet enhanced contextualized networks
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Behavior modeling; Unsupervised representation learning; Context information; Metric learning
ID neural-networks; couple therapy; emotion; classification; prediction; language; features
AB Speech encodes a wealth of information related to human behavior and has been used in a variety of automated behavior recognition tasks. However, extracting behavioral information from speech remains challenging including due to inadequate training data resources stemming from the often low occurrence frequencies of specific behavioral patterns. Moreover, supervised behavioral modeling typically relies on domain-specific construct definitions and corresponding manually-annotated data, rendering generalizing across domains challenging. In this paper, we exploit the stationary properties of human behavior within an interaction and present a representation learning method to capture behavioral information from speech in an unsupervised way. We hypothesize that nearby segments of speech share the same behavioral context and hence map onto similar underlying behavioral representations. We present an encoder-decoder based Deep Contextualized Network (DCN) as well as a Triplet-Enhanced DCN (TE-DCN) framework to capture the behavioral context and derive a manifold representation, where speech frames with similar behaviors are closer while frames of different behaviors maintain larger distances. The models are trained on movie audio data and validated on diverse domains including on a couples therapy corpus and other publicly collected data (e.g., stand-up comedy). With encouraging results, our proposed framework shows the feasibility of unsupervised learning within cross-domain behavioral modeling. (c) 2021 Elsevier Ltd. All rights reserved.
C1 [Li, Haoqi; Narayanan, Shrikanth; Georgiou, Panayiotis] Univ Southern Calif, Signal Anal & Interpretat Lab, Los Angeles, CA 90007 USA.
   [Baucom, Brian] Univ Utah, Dept Psychol, Salt Lake City, UT 84112 USA.
C3 University of Southern California; Utah System of Higher Education; University of Utah
RP Li, HQ (通讯作者)，Univ Southern Calif, Signal Anal & Interpretat Lab, Los Angeles, CA 90007 USA.
EM haoqili@usc.edu; brian.baucom@psych.utah.edu; shri@ee.usc.edu; georgiou@ee.usc.edu
FU U.S. Army Medical Research Acquisition Activity, Fort Detrick MD; Office of the Assistant Secretary of Defense for Health Affairs through the Psychological Health and Traumatic Brain Injury Research Program [W81XWH1510632]; U.S. Department of Defense (DOD) [W81XWH1510632] Funding Source: U.S. Department of Defense (DOD)
CR Amrhein PC, 2003, J CONSULT CLIN PSYCH, V71, P862, DOI 10.1037/0022-006X.71.5.862
   Baer JS, 2009, J SUBST ABUSE TREAT, V37, P191, DOI 10.1016/j.jsat.2009.01.003
   Baucom BR, 2009, J CONSULT CLIN PSYCH, V77, P160, DOI 10.1037/a0014405
   Black MP, 2013, SPEECH COMMUN, V55, P1, DOI 10.1016/j.specom.2011.12.003
   Bone Daniel, 2017, IEEE SIGNAL PROCESSING MAGAZINE, V34, P196
   Bromley J, 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Bryan CJ, 2014, J AFFECT DISORDERS, V159, P15, DOI 10.1016/j.jad.2014.02.021
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Christensen A, 2004, J CONSULT CLIN PSYCH, V72, P176, DOI 10.1037/0022-006X.72.2.176
   Chung YA, 2019, INTERSPEECH, V0, PP146, DOI 10.21437/Interspeech.2019-1473
   Chung YA, 2020, INT CONF ACOUST SPEE, V0, PP3497, DOI 10.1109/ICASSP40776.2020.9054438
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   Devlin J, 2018, ARXIV, V1, P4171
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Eyben Florian, 2010, P 18 ACM INT C MULTI, V0, P1459
   Han K, 2014, INTERSPEECH, V0, P223
   He K, 2015, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2015.123
   Heavey C, 2002, COUPLES INTERACTION, V0, P0
   Heyman RE, 2004, COUPLE OBSERVATIONAL, V0, P81
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu H, 2007, INT CONF ACOUST SPEE, V0, P413
   Imel ZE, 2014, J COUNS PSYCHOL, V61, P146, DOI 10.1037/a0034943
   Jati A, 2019, IEEE-ACM T AUDIO SPE, V27, P1577, DOI 10.1109/TASLP.2019.2921890
   Jones J, 1998, COUPLES INTERACTION, V7, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Li HQ, 2020, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.246
   Li HQ, 2016, INTERSPEECH, V0, PP1407, DOI 10.21437/Interspeech.2016-1217
   Li HQ, 2017, INT CONF ACOUST SPEE, V0, PP5620, DOI 10.1109/ICASSP.2017.7953232
   Li LF, 2013, INT CONF AFFECT, V0, PP312, DOI 10.1109/ACII.2013.58
   Margolin G, 1998, CLIN CHILD FAM PSYCHOL REV, V1, P195, DOI 10.1023/A:1022608117322
   Mikolov T, 2013, ADV NEURAL INFORM PR, V0, PP3111, DOI 10.5555/2999792.2999959
   Milde B, 2018, INTERSPEECH, V0, PP2693, DOI 10.21437/Interspeech.2018-2194
   MILLER WR, 1993, J CONSULT CLIN PSYCH, V61, P455, DOI 10.1037/0022-006X.61.3.455
   Narayanan S, 2013, P IEEE, V101, P1203, DOI 10.1109/JPROC.2012.2236291
   Nasir M, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0185123
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Schuller B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P577
   Schuller B, 2012, ICMI 12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, P449
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Tseng SY, 2016, INTERSPEECH, V0, PP898, DOI 10.21437/Interspeech.2016-1186
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Xia Wei, 2015, 16 ANN C INT SPEECH, V0, P0
   Xiao B, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0143055
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 60
TC 1
Z9 1
U1 2
U2 8
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD NOV 15
PY 2021
VL 70
IS 
BP 
EP 
DI 10.1016/j.csl.2021.101226
EA MAY 2021
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SS4LS
UT WOS:000661725200003
DA 2023-11-10
ER

PT J
AU Naseem, U
   Razzak, I
   Khan, SK
   Prasad, M
AF Naseem, Usman
   Razzak, Imran
   Khan, Shah Khalid
   Prasad, Mukesh
TI A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Text mining; natural language processing; word representation; language models
ID logistic-regression; sentiment; embeddings; classification; framework; context
AB Word representation has always been an important research area in the history of natural language processing (NLP). Understanding such complex text data is imperative, given that it is rich in information and can be used widely across various applications. In this survey, we explore different word representation models and its power of expression, from the classical to modern-day state-of-the-art word representation language models (LMS). We describe a variety of text representation methods, and model designs have blossomed in the context of NLP, including SOTA LMs. These models can transform large volumes of text into effective vector representations capturing the same semantic information. Further, such representations can be utilized by various machine learning (ML) algorithms for a variety of NLP-related tasks. In the end, this survey briefly discusses the commonly used ML- and DL-based classifiers, evaluation metrics, and the applications of these word embeddings in different NLP tasks.
C1 [Naseem, Usman] Univ Sydney, Sch Comp Sci, Sydney, NSW, Australia.
   [Razzak, Imran] Deakin Univ, Sch Informat Technol, Burwood, Australia.
   [Khan, Shah Khalid] RMIT Univ, Sch Engn, Melbourne, Vic, Australia.
   [Prasad, Mukesh] Univ Technol Sydney, Sch Comp Sci, Sydney, NSW, Australia.
C3 University of Sydney; Deakin University; Royal Melbourne Institute of Technology (RMIT); University of Technology Sydney
RP Naseem, U (通讯作者)，Univ Sydney, Sch Comp Sci, Sydney, NSW, Australia.
EM usman.naseem@sydney.edu.au; imran.razzak@deakin.edu.au; s3680269@student.rmit.edu.au; Mukesh.Prasad@uts.edu.au
CR Agarwal Apoorv, 2011, SENTIMENT ANAL TWITT, V0, P0
   Aggarwal CC, 2012, MINING TEXT DATA, V0, PP163, DOI 10.1007/978-1-4614-3223-4_6
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, V0, P1
   Ali F, 2019, INDIAN J SCI TECHNOL, V12, P1, DOI 10.17485/ijst/2019/v12i45/146538
   Altszyler E, 2016, ABS161001520 CORR, V0, P0, DOI DOI 10.1016/J.CONCOG.2017.09.004ABS/1610.0
   [Anonymous], 2014, RETROFITTING WORD VE, V0, P0
   [Anonymous], 2010, TWITTER CORPUS SENTI, V0, P0
   [Anonymous], 2014, C EMPIRICAL METHODS, V0, P0
   [Anonymous], 1988, DOCUMENT RETRIEVAL S, V0, P0
   [Anonymous], 2015, P WORKSHOP NOISY USE, V0, P0
   Balahur A, 2013, 4 WORKSH COMP APPR S, V0, P120
   Balazs JA, 2016, INFORM FUSION, V27, P95, DOI 10.1016/j.inffus.2015.06.002
   Bansal Himani, 2018, SOCIAL NETWORK ANALY, V0, P0, DOI DOI 10.4018/978-1-5225-5097-6
   Bao YW, 2014, LECT NOTES ARTIF INT, V8589, P615, DOI 10.1007/978-3-319-09339-0_62
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3615
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bermingham A, 2011, USING TWITTER MONITO, V0, PP2, DOI 11-3700
   Boia M, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), V0, PP345, DOI 10.1109/SocialCom.2013.54
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bolukbasi T, 2016, ADV NEUR IN, V29, P0
   Camacho-Collados J, 2016, ARTIF INTELL, V240, P36, DOI 10.1016/j.artint.2016.07.005
   Cambria E, 2018, AAAI CONF ARTIF INTE, V0, P1795
   Carreras L, 2001, PROC 4 INT C RECENT, V0, P58
   Castelluccil G, 2015, LECT NOTES COMPUT SC, V9103, P73, DOI 10.1007/978-3-319-19581-0_6
   Celebi Arda, 2016, SEGMENTING HASHTAGS, V0, P0
   Chen Wei James, 2017, COMP STUDY LOGISTIC, V0, P0
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Chung J, 2014, NIPS 2014 WORKSH DEE, V0, PP1, DOI 10.48550/ARXIV.1412.3555
   Clark Kevin, 2020, ICLR, V0, P0
   Collobert R, 2008, P 25 INT C MACH LEAR, V0, PP160, DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P9
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Devlin J, 2018, ARXIV, V1, P4171
   Dhingra Bhuwan, 2017, ABS170300993 CORR, V0, P0
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Edel Greevy, 2004, AUTOMATIC TEXT CATEG, V0, P0
   Elekes A, 2020, INT J DIGIT LIBRARIE, V21, P109, DOI 10.1007/s00799-018-0237-y
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Foster J, 2011, 5 INT JOINT C NATURA, V0, P893
   Fu XH, 2017, NEUROCOMPUTING, V241, P18, DOI 10.1016/j.neucom.2017.01.079
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Giachanou Anastasia, 2017, SENTIMENT PROPAGATIO, V0, P0, DOI DOI 10.1007/978-3-319-56608-5_18
   Giovanelli C, 2017, IEEE IND ELEC, V0, PP7514, DOI 10.1109/IECON.2017.8217316
   Gupta Vishal, 2009, JOURNAL OF EMERGING TECHNOLOGIES IN WEB INTELLIGENCE, V1, P60, DOI 10.4304/jetwi.1.1.60-76
   Haddi E, 2013, PROCEDIA COMPUT SCI, V17, P26, DOI 10.1016/j.procs.2013.05.005
   Hammouda KM, 2004, IEEE T KNOWL DATA EN, V16, P1279, DOI 10.1109/TKDE.2004.58
   He Y, 2011, P 49 ANN M ASS COMPU, V0, PP123, DOI 10.1007/978-3-319-18458-6_3
   Herbelot Aurelie, 2017, P 2017 C EMP METH NA, V0, P304
   HILL BM, 1968, J AM STAT ASSOC, V63, P677, DOI 10.2307/2284038
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu Xia, 2012, MINING TEXT DATA, V0, PP385, DOI 10.1007/978-1-4614-3223-4_12
   Iacobacci I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P95
   Ilic S, 2018, P 9 WORKSHOP COMPUTA, V0, PP2, DOI 10.18653/V1/W18-6202
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaggi M, 2021, APPL SYST INNOV, V4, P0, DOI 10.3390/asi4010013
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Joulin Armand, 2016, ARXIV160701759, V0, P0
   Keskar Nitish Shirish, 2019, CTRL CONDITIONAL TRA, V0, P0
   Khan FH, 2014, DECIS SUPPORT SYST, V57, P245, DOI 10.1016/j.dss.2013.09.004
   Korde Vandana, 2012, TEXT CLASSIFICATION, V0, P0
   Kouloumpis E, 2011, ICWSM, V0, P0
   Kowsari K, 2019, INFORMATION, V10, P0, DOI 10.3390/info10040150
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, V0, PP1621, DOI 10.5555/2891460.2891697
   Lample Guillaume, 2019, NEURIPS, V0, P0
   Lan Z, 2020, CORR, V0, P1
   Larson RR, 2010, J AM SOC INF SCI TEC, V61, P852, DOI 10.1002/asi.21234
   Lauren P, 2018, NEUROCOMPUTING, V277, P129, DOI 10.1016/j.neucom.2017.01.117
   Le Q, 2014, INT C MACHINE LEARNI, V32, P0, DOI 10.1145/2740908.2742760
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ledell Adam Fisch, 2017, ARXIVCSCL170903856, V0, P0
   Lee J, 2019, AM J SPEECH-LANG PAT, V0, P0, DOI DOI 10.1044/2019_AJSLP-CAC48-18-0220
   Lewis M, 2019, ARXIV, V0, P0
   Lin C, 2009, P 18 ACM C INF KNOWL, V0, PP375, DOI 10.1145/1645953.1646003
   Liu PF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1284
   Liu Shuhua, 2014, 6TH INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND INFORMATION RETRIEVAL (KDIR 2014). PROCEEDINGS, V0, P530
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Liu YC, 2018, NEUROCOMPUTING, V275, P2287, DOI 10.1016/j.neucom.2017.11.005
   Magerman DM, 1995, P 33 ANN M ASS COMP, V0, P0
   MANDIC D, 2001, RECURRENT NEURAL NET, V0, P0, DOI DOI 10.1002/047084535X
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   McCann Bryan, 2017, ADV NEURAL INFORM PR, V0, P6297
   Mejova Y, 2011, EXPLORING FEATURE DE, V0, P0
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, V0, PP51, DOI 10.18653/V1/K16-1006
   Melville P, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P1275
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mohammad S, 2013, 2 JOINT C LEX COMP S, V0, PP321, DOI 10.3115/V1/S14-2077
   MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276
   Mrksic Nikola, 2017, T ASS COMPUTATIONAL, V5, P309
   Mullen T, 2006, PROC AAAI SPRING S C, V0, P159
   Muller Martin, 2020, ARXIV200507503, V0, P0
   Naili M, 2017, PROCEDIA COMPUT SCI, V112, P340, DOI 10.1016/j.procs.2017.08.009
   Narayanan V, 2013, LECT NOTES COMPUT SC, V8206, P194, DOI 10.1007/978-3-642-41278-3_24
   Naseem Usman, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP953, DOI 10.1109/ICDAR.2019.00157
   Naseem U, 2020, ARXIV200909223, V0, P0
   Naseem U, 2020, IEEE IJCNN, V0, P0, DOI DOI 10.1109/ijcnn48605.2020.9207237
   Naseem U, 2021, IEEE T COMPUT SOC SY, V8, P1003, DOI 10.1109/TCSS.2021.3051189
   Naseem U, 2021, APPL SYST INNOV, V4, P0, DOI 10.3390/asi4010023
   Naseem U, 2021, MULTIMED TOOLS APPL, V80, P35239, DOI 10.1007/s11042-020-10082-6
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Naseem U, 2019, LECT NOTES ARTIF INT, V11919, P381, DOI 10.1007/978-3-030-35288-2_31
   Naseem Usman, 2020, THESIS U TECHNOLOGY, V0, P0
   Naseem Usman, 2019, AUSTR J INTELLIGENT, V15, P69
   Neelakantan Arvind, 2015, EFFICIENT NONPARAMET, V0, P0
   Niebler Thomas, 2017, ABS170507425 CORR, V0, P0
   Nogueira CSD, 2014, P COLING 2014 25 INT, V0, PP69, DOI 10.1109/ICCAR.2017.7942788
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Pascanu R, 2013, P 30 INT C MACHINE L, V0, P0
   Patriche CV, 2016, PEDOSPHERE, V26, P335, DOI 10.1016/S1002-0160(15)60047-9
   Pinter Y, 2017, P 2017 C EMPIRICAL M, V0, P102
   Qin PD, 2016, NEUROCOMPUTING, V190, P1, DOI 10.1016/j.neucom.2015.12.091
   Qu ZW, 2018, INT CONF BIG DATA, V0, PP677, DOI 10.1109/BigComp.2018.00124
   Quinlan JR, 1986, MACHINE LEARNING, V1, P81, DOI 10.1023/A:1022643204877
   QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rehman Arshia, 2019, AUST J INTELL INF PR, V15, P53
   Ren YF, 2016, AAAI CONF ARTIF INTE, V0, P215
   Reuter J, 2016, INT J NAT LANG COMPU, V5, P23, DOI 10.5121/ijnlc.2016.5402
   Rezaeinia SMahdi, 2017, ARXIV171108609, V0, P0
   Saif H, 2013, P 1 INT WORKSH EM SE, V0, P0
   Saloot Mohammad Arshi, 2015, WORKSH NOIS US GEN T, V0, P0
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Seungil David Ding, 2017, ARXIVSTATML170906680, V0, P0
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP959, DOI 10.1145/2766462.2767830
   Shoeybi M, 2019, ARXIV, V0, P0
   Singh T, 2016, PROCEDIA COMPUT SCI, V89, P549, DOI 10.1016/j.procs.2016.06.095
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Soheily-Khah Saeid, 2017, INTRUSION DETECTION, V0, P0
   Song K, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Sun Yu, 2019, ARXIV190409223, V0, P0
   Sutskever I, 2011, ICML, V0, P0
   Suttles Jared, 2013, COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING. 14TH INTERNATIONAL CONFERENCE, V0, P121, DOI 10.1007/978-3-642-37256-8_11
   Symeonidis S, 2018, EXPERT SYST APPL, V110, P298, DOI 10.1016/j.eswa.2018.06.022
   Tan AH, 1999, P PAKDD WORKSH KNOWL, V0, P65
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   Tang DY, 2015, IEEE-ACM T AUDIO SPE, V23, P1750, DOI 10.1109/TASLP.2015.2449071
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Wei, 2019, ARXIV190804577, V0, P0
   Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, V0, P0
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Wang YY, 2012, ASTROPHYS J, V756, P0, DOI 10.1088/0004-637X/756/1/67
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zhang T, 2014, ARXIV14121058, V0, P0
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhao JQ, 2017, IEEE ACCESS, V5, P2870, DOI 10.1109/ACCESS.2017.2672677
   Zhao JQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), V0, PP748, DOI 10.1109/SmartCity.2015.158
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 160
TC 33
Z9 33
U1 4
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2021
VL 20
IS 5
BP 
EP 
DI 10.1145/3434237
PG 35
WC Computer Science, Artificial Intelligence
SC Computer Science
GA XB8PL
UT WOS:000721584900004
DA 2023-11-10
ER

PT J
AU Roh, J
   Park, S
   Kim, BK
   Oh, SH
   Lee, SY
AF Roh, Jihyeon
   Park, Sungjin
   Kim, Bo-Kyeong
   Oh, Sang-Hoon
   Lee, Soo-Young
TI Unsupervised multi-sense language models for natural language processing tasks
SO NEURAL NETWORKS
LA English
DT Article
DE Language model; Neural language processing (NLP); Multi-sense word modeling
AB Existing language models (LMs) represent each word with only a single representation, which is unsuitable for processing words with multiple meanings. This issue has often been compounded by the lack of availability of large-scale data annotated with word meanings. In this paper, we propose a sense-aware framework that can process multi-sense word information without relying on annotated data. In contrast to the existing multi-sense representation models, which handle information in a restricted context, our framework provides context representations encoded without ignoring word order information or long-term dependency. The proposed framework consists of a context representation stage to encode the variable-size context, a sense-labeling stage that involves unsupervised clustering to infer a probable sense for a word in each context, and a multi-sense LM (MSLM) learning stage to learn the multi-sense representations. Particularly for the evaluation of MSLMs with different vocabulary sizes, we propose a new metric, i.e., unigram-normalized perplexity (PPLu), which is also understood as the negated mutual information between a word and its context information. Additionally, there is a theoretical verification of PPLu on the change of vocabulary size. Also, we adopt a method of estimating the number of senses, which does not require further hyperparameter search for an LM performance. For the LMs in our framework, both unidirectional and bidirectional architectures based on long short-term memory (LSTM) and Transformers are adopted. We conduct comprehensive experiments on three language modeling datasets to perform quantitative and qualitative comparisons of various LMs. Our MSLM outperforms single-sense LMs (SSLMs) with the same network architecture and parameters. It also shows better performance on several downstream natural language processing tasks in the General Language Understanding Evaluation (GLUE) and SuperGLUE benchmarks. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Roh, Jihyeon; Park, Sungjin; Lee, Soo-Young] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
   [Roh, Jihyeon; Park, Sungjin; Lee, Soo-Young] Korea Adv Inst Sci & Technol, Inst Artificial Intelligence, Daejeon, South Korea.
   [Kim, Bo-Kyeong] Korea Adv Inst Sci & Technol, Informat & Elect Res Inst, Daejeon, South Korea.
   [Oh, Sang-Hoon] Mokwon Univ, Div Informat & Commun Convergence Engn, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced Institute of Science & Technology (KAIST); Mokwon University
RP Lee, SY (通讯作者)，Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.; Lee, SY (通讯作者)，Korea Adv Inst Sci & Technol, Inst Artificial Intelligence, Daejeon, South Korea.
EM rohleejh@kaist.ac.kr; zxznm@kaist.ac.kr; bokyeong1015@gmail.com; shoh@kaist.ac.kr; sylee@kaist.ac.kr
FU Industrial Strategic Technology Development Program - Ministry of Trade, Industry and Energy (MOTIE, Korea) [10072064]; Institute of Information & Communications Technology Planning & Evaluation - Ministry of Science and ICT (MSIT, Korea) [2016-0-00562]
CR Aharoni Roee, 2020, P 58 ANN M ASS COMP, V0, PP7747, DOI 10.18653/v1/2020.acl-main.692
   AlexWang Julian Michael, 2019, P NEURIPS, V0, P0
   Amodei D, 2016, PR MACH LEARN RES, V48, P0
   [Anonymous], 2016, P 2016 C EMPIRICAL M, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2015, P 53 ANN M ASS COMP, V0, P0
   Ansell A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P563
   Bartunov S, 2016, JMLR WORKSH CONF PRO, V51, P130
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bird S, 2004, P ACL INTERACTIVE PO, V0, P214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Botha JA, 2014, PR MACH LEARN RES, V32, P1899
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Cheng W-C, 2014, 15 ANN C ISCA, V0, P0
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924
   Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Devlin J, 2018, ARXIV, V1, P4171
   Dolan B, 2005, 3 INT WORKSHOP PARAP, V0, P0
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Grave E, 2016, ARXIV161204426, V0, P0
   Guo J, 2014, P COLING, V2014, P497
   Huang L, 2019, P C EMP METH NAT LAN, V0, P3509
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Inan H, 2016, ARXIV161101462 CORR, V0, P0
   Jain S, 2019, ARXIV190907746, V0, P0
   Jozefowicz Rafal, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Khashabi D, 2018, P 2018 C N AM CHAPTE, V1, P252, DOI 10.18653/V1/N18-1023
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   KNESER R, 1995, INT CONF ACOUST SPEE, V0, PP181, DOI 10.1109/ICASSP.1995.479394
   KVALSETH TO, 1987, IEEE T SYST MAN CYB, V17, P517, DOI 10.1109/TSMC.1987.4309069
   Li J, 2015, P 2015 C EMP METH NA, V0, PP1722, DOI 10.18653/v1/D15-1200
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ma R, 2020, INT CONF ACOUST SPEE, V0, PP8129, DOI 10.1109/icassp40776.2020.9053503
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, V0, PP51, DOI 10.18653/V1/K16-1006
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2014, 3 INT C LEARN REPR I, V0, P0
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Mikolov T, 2011, INT CONF ACOUST SPEE, V0, P5528
   Miller G, 1990, INT J LEXICOGR, V3, P235, DOI 10.1093/IJL/3.4.235
   Miller George A, 1993, P WORKSH HUM LANG TE, V0, P303
   Mou Lili, 2015, NATURAL LANGUAGE INF, V0, P0
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, V0, PP1059, DOI 10.3115/V1/D14-1113
   Panigrahi A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5692
   Peters ME, 2018, ARXIV180205365, V0, P0
   Pilehvar MT, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1267
   Qiu L, 2016, P 2016 C EMP METH NA, V0, PP183, DOI 10.18653/V1/D16-1018
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Reisinger J, 2010, HUMAN LANGUAGE TECHN, V0, P109
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Song Linfeng, 2016, P 5 JOINT C LEXICAL, V0, PP85, DOI 10.18653/V1/S16-2009
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vial L, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang MX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1567
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   White Aaron Steven, 2017, P 8 INT JOINT C NAT, V8291, P996
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yuan D, 2016, PROC COLING, V0, P1374
   Zhao R, 2017, IEEE-ACM T AUDIO SPE, V25, P248, DOI 10.1109/TASLP.2016.2632521
NR 68
TC 3
Z9 3
U1 2
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD OCT 15
PY 2021
VL 142
IS 
BP 397
EP 409
DI 10.1016/j.neunet.2021.05.023
EA JUN 2021
PG 13
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA UJ9WU
UT WOS:000691628800001
PM 34139656
DA 2023-11-10
ER

PT J
AU Stengel-Eskin, E
   Murray, K
   Zhang, S
   White, AS
   Van Durme, B
AF Stengel-Eskin, Elias
   Murray, Kenton
   Zhang, Sheng
   White, Aaron Steven
   Van Durme, Benjamin
TI Joint Universal Syntactic and Semantic Parsing
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID children
AB While numerous attempts have been made to jointly parse syntax and semantics, high performance in one domain typically comes at the price of performance in the other. This trade-off contradicts the large body of research focusing on the rich interactions at the syntax-semantics interface. We explore multiple model architectures that allow us to exploit the rich syntactic and semantic annotations contained in the Universal Decompositional Semantics (UDS) dataset, jointly parsing Universal Dependencies and UDS to obtain state-of-the-art results in both formalisms. We analyze the behavior of a joint model of syntax and semantics, finding patterns supported by linguistic theory at the syntax-semantics interface. We then investigate to what degree joint modeling generalizes to a multilingual setting, where we find similar trends across 8 languages.
C1 [Stengel-Eskin, Elias; Murray, Kenton; Van Durme, Benjamin] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Zhang, Sheng] Microsoft Res, Redmond, WA USA.
   [White, Aaron Steven] Univ Rochester, Rochester, NY 14627 USA.
C3 Johns Hopkins University; Microsoft; University of Rochester
RP Stengel-Eskin, E (通讯作者)，Johns Hopkins Univ, Baltimore, MD 21218 USA.
FU NSF Graduate Research Fellowship; NSF [1749025, 1763705]; DARPA AIDA [FA8750-18-2-0015]; IARPA BETTER [2019-19051600005]; Division Of Behavioral and Cognitive Sci; Direct For Social, Behav & Economic Scie [1749025] Funding Source: National Science Foundation; Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr [1763705] Funding Source: National Science Foundation
CR Abend O, 2013, P 51 ANN M ASS COMP, V1, P228
   Abend O, 2017, COGNITION, V164, P116, DOI 10.1016/j.cognition.2017.02.009
   [Anonymous], 2016, PROC CONLL, V0, P0
   [Anonymous], 2015, PROC EMNLP, V0, P0
   [Anonymous], 2009, LANGUAGE LEARNABILIT, V0, P0
   Artzi Y, 2015, EMNLP, V0, PP1699, DOI 10.18653/v1/D15-1198
   Banarescu Laura, 2013, P 7 LING ANN WORKSH, V0, P0
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Beschke Sebastian, 2019, P INT C REC ADV NAT, V0, PP112, DOI 10.26615/978-954-452-056-4014
   Bies A, 2012, ENGLISH WEB TREEBANK, V0, P0
   Cai S, 2013, P 51 ANN M ASS COMPU, VVolume 2, P748
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, P0, DOI 10.1155/2014/575246
   Chomsky Carol, 1969, ACQUISITION SYNTAX C, V0, P0
   CHU YJ, 1965, SCI SINICA, V14, P1396
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   CROMER RF, 1970, BRIT J PSYCHOL, V61, P397, DOI 10.1111/j.2044-8295.1970.tb01259.x
   Devlin J, 2018, MULTILINGUAL BERT RE, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   DOWTY D, 1991, LANGUAGE, V67, P547, DOI 10.2307/415037
   Dozat Timothy, 2017, 5 INT C LEARN REPR I, V0, P0, DOI DOI 10.1353/lan.1991.0021
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), V0, P1
   Gardner Matt, 2020, FINDINGS ASS COMPUTA, V0, P1307
   Glavas Goran, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Gleitman L, 1990, LANG ACQUIS, V1, P3, DOI 10.1207/S15327817LA0101_2
   Hajic J, 2009, P 13 C COMP NAT LANG, V0, PP1, DOI 10.3115/1596409.1596411
   Hewitt J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2733
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Johansson R, 2008, P 12 C COMPUTATIONAL, V0, P183
   Kondratyuk D, 2019, EMNLP, V0, P2779
   Krishnamurthy J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1188
   Landau B, 1985, LANGUAGE EXPERIENCE, V8, P0
   Misra Dipendra Kumar, 2016, P 2016 C EMP METH NA, V0, PP1775, DOI 10.18653/V1/D16-1183
   MONTAGUE R, 1970, THEORIA, V36, P373
   NAIGLES L, 1990, J CHILD LANG, V17, P357, DOI 10.1017/S0305000900013817
   Nguyen TT, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Oepen S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3991
   Oepen Stephan, 2014, P 8 INT WORKSH SEM E, V0, PP63, DOI 10.3115/V1/S14-2008
   PINKER S, 1979, COGNITION, V7, P217, DOI 10.1016/0010-0277(79)90001-5
   Pollard C, 1994, HEAD DRIVEN PHRASE S, V0, P0
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Steedman M, 2000, SYNTACTIC PROCESS, V0, P0, DOI DOI 10.7551/mitpress/6591.001.0001
   Stengel-Eskin Elias, 2020, P 58 ANN M ASS COMP, V0, PP8427, DOI 10.18653/V1/2020.ACL-MAIN.746
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5027
   Surdeanu M, 2008, P 12 C COMP NAT LANG, V0, PP159, DOI 10.3115/1596324.1596352
   Swayamdipta S, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Swayamdipta S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3772
   Swayamdipta Swabha, 2017, ARXIV170609528, V0, P0
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   White AS, 2016, PROC C EMPIRICAL MET, V0, P1713
   White AS, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5698
   White AS, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4717
   White Aaron Steven, 2020, HDB PRAGMATICS 22 AN, V22, P115, DOI 10.1075/hop.22.lex4
   Zeman D, 2017, P CONLL 2017 SHARED, V0, PP1, DOI 10.18653/V1/K17-3001
   Zeman D, 2018, P CONLL 2018 SHARED, V0, P1
   Zhang S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P80
   Zhang Sheng, 2017, IWCS 2017, V0, P0
   Zhang Sheng, 1900, P3786, V0, P0, DOI DOI 10.18653/v1/D19-1392
   Zhou QJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4306
NR 62
TC 2
Z9 2
U1 1
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 756
EP 773
DI 10.1162/tacl_a_00396
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200046
DA 2023-11-10
ER

PT J
AU Culkin, R
   Hu, JE
   Stengel-Eskin, E
   Qin, GH
   Van Durme, B
AF Culkin, Ryan
   Hu, J. Edward
   Stengel-Eskin, Elias
   Qin, Guanghui
   Van Durme, Benjamin
TI Iterative Paraphrastic Augmentation with Discriminative Span Alignment
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We introduce a novel paraphrastic augmentation strategy based on sentence-level lexically constrained paraphrasing and discriminative span alignment. Our approach allows for the large-scale expansion of existing datasets or the rapid creation of new datasets using a small, manually produced seed corpus. We demonstrate our approach with experiments on the Berkeley FrameNet Project, a large-scale language understanding effort spanningmore than two decades of human labor. With four days of training data collection for a span alignment model and one day of parallel compute, we automatically generate and release to the community 495,300 unique (Frame, Trigger) pairs in diverse sentential contexts, a roughly 50-fold expansion atop FrameNet v1.7. The resulting dataset is intrinsically and extrinsically evaluated in detail, showing positive results on a downstream task.
C1 [Culkin, Ryan; Hu, J. Edward; Stengel-Eskin, Elias; Qin, Guanghui; Van Durme, Benjamin] Johns Hopkins Univ, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Culkin, R (通讯作者)，Johns Hopkins Univ, Baltimore, MD 21218 USA.
EM rculkin@jhu.edu; edward.hu@jhu.edu; elias@jhu.edu; gqin@jhu.edu; vandurme@jhu.edu
FU DARPA AIDA; DARPA KAIROS; NSF [1749025]; Direct For Social, Behav & Economic Scie; Division Of Behavioral and Cognitive Sci [1749025] Funding Source: National Science Foundation
CR Alberti C, 2019, ABS190108634 CORR, V0, P1
   Andreas J, 2020, T ASSOC COMPUT LING, V8, P556, DOI 10.1162/tacl_a_00333
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Baker C, 2007, SEMEVAL, V0, P0
   Berant J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1415, DOI 10.3115/v1/p14-1133
   Brown PF, 1993, COMPUTATIONAL LINGUISTICS, V19, P263
   Burchardt Aljoscha, 2006, APPROACHING TEXTUAL, V0, P0, DOI DOI 10.3115/1654536.1654540
   Choe DK, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1223
   Cohn T, 2008, COMPUT LINGUIST, V34, P597, DOI 10.1162/coli.08-003-R1-07-044
   Das D, 2014, COMPUT LINGUIST, V40, P9, DOI 10.1162/COLI_a_00163
   Das Dipanjan, 2011, ASS COMPUTATIONAL LI, V0, P0
   Das Dipanjan, 2010, P 2010 C N AM CHAPT, V0, P948
   De Smedt T, 2012, J MACH LEARN RES, V13, P2063
   Devlin J, 2018, ARXIV, V1, P4171
   Dolan B, 2005, 3 INT WORKSHOP PARAP, V0, P0
   Dyer Chris, 2013, P 2013 C N AM CHAPTE, V0, P644
   Edward Hu J, 2019, P 23 C COMPUTATIONAL, V0, P44
   Fillmore CJ, 1982, LINGUISTICS MORNING, V0, P111
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Hermann KM, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1448
   Hu J Edward, 2019, NAACL, V0, P0
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kshirsagar M, 2015, ASS COMPUTATIONAL LI, V0, P0, DOI DOI 10.3115/v1/P15-2036
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Kumar A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3609
   Lee K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2840
   Mallinson J, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P881
   Ouyang J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4724
   Pavlick Ellie, 2015, ACL 2015, V0, P0, DOI DOI 10.3115/v1/P15-2067
   Peng H, 2018, P 2018 C N AM CHAPTE, V1, P1492, DOI 10.18653/V1/N18-1135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Post M, 2018, P 2018 C N AM CHAPTE, V1, P1314
   Ragni Anton, 2014, 15 ANN C ISCA, V0, P0
   Ribeiro MT, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P856
   Roth M, 2015, T ASS COMPUTATIONAL, V0, P0, DOI DOI 10.1162/tacla00150
   Roy A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6033
   Ruppenhofer J, 2012, P 3 WORKSHOP COMPUTA, V0, P104
   Schneider Nathan, 2017, P 2017 C EMPIRICAL M, V0, P0, DOI DOI 10.18653/v1/D17-2001
   Shen D, 2007, JOINT C EMPIRICAL ME, V0, P12
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Snow Rion, 2006, ICCL ACL, V0, P0, DOI DOI 10.3115/1220175.1220276
   Stengel-Eskin Elias, 2019, EMNLP IJCNLP, V0, PP909, DOI 10.18653/v1/D19-1084
   Swayamdipta S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3772
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Wang Su, 2018, TASK SUIT TIE PARAPH, V0, P0, DOI DOI 10.1609/aaai.v33i01.33017176
   Wang YS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1332
   Wieting J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P451
   Yao Xuchen, 1900, P590, V0, P0
   Yao Xuchen, 2013, ACL, V2, P702
NR 52
TC 0
Z9 0
U1 1
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 494
EP 509
DI 10.1162/tacl_a_00380
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200030
DA 2023-11-10
ER

PT J
AU Lee, S
   Kim, I
AF Lee, Sujin
   Kim, Incheol
TI DVC-Net: A deep neural network model for dense video captioning
SO IET COMPUTER VISION
LA English
DT Article
ID representation
AB Dense video captioning (DVC) detects multiple events in an input video and generates natural language sentences to describe each event. Previous studies predominantly used convolutional neural networks to extract visual features from videos but failed to employ high-level semantics to effectively explain video content such as people, objects, actions, and places, and utilized only limited context information in generating natural language. To overcome these deficiencies, DVC-Net is proposed, a new deep neural network model that uses high-level semantics to efficiently represent important events as well as visual features. Additionally, DVC-Net uses a bidirectional long short-term memory network, a type of recurrent neural network, to detect events over time. Furthermore, DVC-Net applies an attention mechanism and context gating to effectively exploit context information in a caption generation step. In experiments conducted versus state-of-the-art models, DVC-Net presented relative gains of over 1.72% (BLEU@1 score increases from 12.22 to 13.94) and 3.19% (CIDEr score increases from 12.61 to 15.80) on the large-scale benchmark datasets, namely ActivityNet Captions and MSR-VTT, respectively.
C1 [Lee, Sujin; Kim, Incheol] Kyonggi Univ, Dept Comp Sci, 154-42 Gwanggyosan Ro, Suwon, Gyeonggi Do, South Korea.
C3 Kyonggi University
RP Kim, I (通讯作者)，Kyonggi Univ, Dept Comp Sci, 154-42 Gwanggyosan Ro, Suwon, Gyeonggi Do, South Korea.
EM kic@kgu.ac.kr
FU Ministry of Science and ICT [10.13039/501100014188]
CR Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Buch S, 2017, PROC CVPR IEEE, V0, PP6373, DOI 10.1109/CVPR.2017.675
   Chadha A, 2019, IEEE T CIRC SYST VID, V29, P475, DOI 10.1109/TCSVT.2017.2786999
   Cherian A, 2020, IEEE WINT CONF APPL, V0, PP1606, DOI 10.1109/WACV45572.2020.9093291
   Tran D, 2015, IEEE I CONF COMP VIS, V0, PP4489, DOI 10.1109/ICCV.2015.510
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Gan C, 2017, PROC CVPR IEEE, V0, PP955, DOI 10.1109/CVPR.2017.108
   Gan C, 2015, PROC CVPR IEEE, V0, PP2568, DOI 10.1109/CVPR.2015.7298872
   Gan Z, 2017, PROC CVPR IEEE, V0, PP1141, DOI 10.1109/CVPR.2017.127
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   He K, 2016, PROC CVPR IEEE, V0, P0
   Heilbron FC, 2016, PROC CVPR IEEE, V0, PP1914, DOI 10.1109/CVPR.2016.211
   Hou JY, 2018, IEEE T MULTIMEDIA, V20, P1537, DOI 10.1109/TMM.2017.2771462
   Jonghwan Mun, 2019, 2019 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP6581, DOI 10.1109/CVPR.2019.00675
   Krishna R, 2017, IEEE I CONF COMP VIS, V0, PP706, DOI 10.1109/ICCV.2017.83
   Li Y, 2018, PROC CVPR IEEE, V0, PP7492, DOI 10.1109/CVPR.2018.00782
   Liu AA, 2018, IEEE ACCESS, V6, P68463, DOI 10.1109/ACCESS.2018.2879642
   Liu AA, 2017, COMPUT VIS IMAGE UND, V163, P113, DOI 10.1016/j.cviu.2017.04.013
   Long X, 2018, AAAI CONF ARTIF INTE, V0, P7202
   Long X, 2018, PROC CVPR IEEE, V0, PP7834, DOI 10.1109/CVPR.2018.00817
   Melo G, 2018, T ASS COMPUTATIONAL, V0, P173
   Murtaza F, 2019, IEEE SIGNAL PROC LET, V26, P272, DOI 10.1109/LSP.2018.2888758
   Nian FD, 2017, COMPUT VIS IMAGE UND, V163, P126, DOI 10.1016/j.cviu.2017.06.012
   Ogawa T, 2018, IEEE ACCESS, V6, P61401, DOI 10.1109/ACCESS.2018.2876710
   Pan YW, 2017, PROC CVPR IEEE, V0, PP984, DOI 10.1109/CVPR.2017.111
   Pan YW, 2016, PROC CVPR IEEE, V0, PP4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Park JS, 2019, PROC CVPR IEEE, V0, PP6591, DOI 10.1109/CVPR.2019.00676
   Pei WJ, 2019, PROC CVPR IEEE, V0, PP8339, DOI 10.1109/CVPR.2019.00854
   Shen ZQ, 2017, PROC CVPR IEEE, V0, PP5159, DOI 10.1109/CVPR.2017.548
   Simonyan K, 2015, ARXIV, V0, P0
   Song JK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2737
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, V0, PP4534, DOI 10.1109/ICCV.2015.515
   Wang JW, 2018, PROC CVPR IEEE, V0, PP7190, DOI 10.1109/CVPR.2018.00751
   Wu YC, 2018, IEEE ACCESS, V6, P31677, DOI 10.1109/ACCESS.2018.2842428
   Xu H, 2018, ARXIV180210250, V0, P0
   Xu J, 2016, PROC CVPR IEEE, V0, PP5288, DOI 10.1109/CVPR.2016.571
   Xuanhan Wang, 2017, IEEE SIGNAL PROCESSING LETTERS, V24, P510, DOI 10.1109/LSP.2016.2611485
   Xue HY, 2018, IEEE T IMAGE PROCESS, V27, P5563, DOI 10.1109/TIP.2018.2859820
   Xue HY, 2017, IEEE T IMAGE PROCESS, V26, P5656, DOI 10.1109/TIP.2017.2746267
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yao L, 2015, IEEE I CONF COMP VIS, V0, PP4507, DOI 10.1109/ICCV.2015.512
   Yu Y, 2017, PROC CVPR IEEE, V0, PP3261, DOI 10.1109/CVPR.2017.347
   Zhou LW, 2018, PROC CVPR IEEE, V0, PP8739, DOI 10.1109/CVPR.2018.00911
NR 45
TC 1
Z9 2
U1 2
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9632
EI 1751-9640
J9 IET COMPUT VIS
JI IET Comput. Vis.
PD FEB 15
PY 2021
VL 15
IS 1
BP 12
EP 23
DI 10.1049/cvi2.12013
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA QG3SR
UT WOS:000617509600002
DA 2023-11-10
ER

PT J
AU Han, JB
   Wang, HZ
AF Han, Jiabao
   Wang, Hongzhi
TI Transformer based network for Open Information Extraction
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Open Information Extraction; Neural network; Transformer; Distant supervision
AB Research on Open Information Extraction (Open IE) has made great progress in recent years; it is the task that detects a group of structured, machine-readable statements usually represented in triple form or n-ary relation statements. Open IE is among the core areas of the territory of Natural Language Processing (NLP), and these extractions decompose grammatically complex sentences in a corpus into the relationships they represent, which can be leveraged for various downstream tasks. Even though a lot of work has been done in this direction, there are still many issues with the existing strategies. Most of the previous Open IE systems employ a group of artificially constructed patterns to detect and extract relational tuples from a sentence in a corpus, and these patterns are either automatically learned from annotated training examples or hand-crafted. Such an approach faces some issues, the first is that it requires a lot of manpower. Secondly, they used many NLP tools, therefore, error accumulation in the procedure can negatively impact the results. In this paper, we propose an Open IE approach based on the Transformer architecture. To verify our approach, we make a study using a large and public benchmark dataset, and the experimental results showed that our model achieves a better performance than many existing baselines.
C1 [Han, Jiabao; Wang, Hongzhi] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, HZ (通讯作者)，Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM jiabaohan@hit.edu.cn; wangzh@hit.edu.cn
FU NSFC [U1866602, 61772157]
CR Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   [Anonymous], 2017, ADV NEURAL INFORM PR, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2017, ADV NEUR IN, V0, P0
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Cetto M, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Cho K, 2014, COMPUT SCI, V0, P0
   Chopra S, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Christensen J, 2010, P NAACL HLT 2010 1 I, V0, P52
   del Corro L, 2013, P 22 INT C WORLD WID, V0, PP355, DOI 10.1145/2488388.2488420
   Etzioni O, 2011, P 22 INT JOINT C ART, V0, PP3, DOI 10.5591/978-1-57735-516-8/IJCAI11-012
   Etzioni O, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1409360.1409378
   Fader A, 2011, P C EMPIRICAL METHOD, V0, PP1535, DOI 10.1234/12345678
   Gashteovski K, 2017, P 2017 C EMP METH NA, V0, P2620
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Hill F, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Li C, 2018, PROC CVPR IEEE, V0, PP5226, DOI 10.1109/CVPR.2018.00548
   Mausam, 2016, P 25 INT JOINT C ART, V0, P4074
   Nallapati R, 2016, CONLL 2016, V0, P0
   Pal Harinder, 2016, P 5 WORKSH AUT KNOWL, V0, PP35, DOI 10.18653/V1/W16-1307
   Rush Alexander M, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Saha S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P317, DOI 10.18653/v1/P17-2050
   Salthouse TA, 2000, HDB AGING COGNITION, V0, P359
   Schmitz M, 2012, P 2012 JOINT C EMP M, V0, P523
   Schneider Rudolf, 2017, ARXIV PREPRINT ARXIV, V0, P0
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Stanovsky G, 2016, P 2016 C EMPIRICAL M, V0, P2300
   Stanovsky G, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wu F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P118
   Wu Y, 2016, ARXIV, V0, P0
   Xiong CM, 2016, PR MACH LEARN RES, V48, P0
   Yates A, 2007, P HUM LANG TECHN ANN, V0, PP25, DOI 10.3115/1614164.1614177
   Yong Z, 2017, INT CONF SYST INFORM, V0, PP1477, DOI 10.1109/ICSAI.2017.8248519
NR 36
TC 5
Z9 5
U1 0
U2 15
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD JUN 15
PY 2021
VL 102
IS 
BP 
EP 
DI 10.1016/j.engappai.2021.104262
EA MAY 2021
PG 7
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA SV0BQ
UT WOS:000663493500016
DA 2023-11-10
ER

PT J
AU Sharma, S
   Singh, S
AF Sharma, Sakshi
   Singh, Sukhwinder
TI Vision-based hand gesture recognition using deep learning for the interpretation of sign language
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Human-computer interaction; Feature extraction; Classification; Deep learning; Sign language recognition
ID independent system; classification; alphabets; posture
AB Hand gestures have been the key component of communication since the beginning of an era. The hand gestures are the foundation of sign language, which is a visual form of communication. In this paper, a deep learning based convolutional neural network (CNN) model is specifically designed for the recognition of gesture-based sign language. This model has a compact representation that achieves better classification accuracy with a fewer number of model parameters over the other existing architectures of CNN. In order to evaluate the efficacy of this model, VGG-11 and VGG-16 have also been trained and tested in this work. To evaluate the performance, 2 datasets have been considered. First, in this work, a large collection of Indian sign language (ISL) gestures consisting of 2150 images is collected using RGB camera, and second, a publicly available American sign language (ASL) dataset is used. The highest accuracy of 99.96% and 100% is obtained by the proposed model for ISL and ASL datasets respectively. The performance of the proposed system, VGG-11, and VGG-16 are experimentally evaluated and compared with the existing state-of-art approaches. In addition to accuracy, other efficiency indices have been also used to ascertain the robustness of the proposed work. The findings indicate that the proposed model outperforms the existing techniques as it has the potential to classify maximum gestures with a minimal rate of error. The model is also tested with the augmented data and is found as invariant to rotation and scaling transformation.
C1 [Sharma, Sakshi; Singh, Sukhwinder] Punjab Engn Coll Deemed Univ, ECE Dept, Chandigarh, India.
C3 Punjab Engineering College (Deemed University)
RP Sharma, S (通讯作者)，Punjab Engn Coll Deemed Univ, ECE Dept, Chandigarh, India.
EM sak.sharma92@gmail.com; sukhwindersingh@pec.ac.in
CR Abraham E, 2019, REAL TIME TRANSLATIO, V0, P1
   Akhter S, 2018, ORIENTATION HASHCODE, V0, P1
   Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   Ameen S, 2017, EXPERT SYST, V34, P0, DOI 10.1111/exsy.12197
   [Anonymous], 2019, 2019 2 INT C COMP, V0, P0
   Ansari ZA, 2016, SADHANA-ACAD P ENG S, V41, P161, DOI 10.1007/s12046-015-0405-3
   Arefnezhad S, 2020, EXPERT SYST APPL, V162, P0, DOI 10.1016/j.eswa.2020.113778
   Athira PK, 2022, J KING SAUD UNIV-COM, V34, P771, DOI 10.1016/j.jksuci.2019.05.002
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chong Teak-Wei, 2020, THE JOURNAL OF THE KOREA INSTITUTE OF ELECTRONIC COMMUNICATION SCIENCES 한국전자통신학회 논문지, V15, P291, DOI 10.13067/JKIECS.2020.15.2.291
   Dahmani D, 2014, J VIS COMMUN IMAGE R, V25, P1240, DOI 10.1016/j.jvcir.2013.12.019
   Gangrade J, 2023, IETE J RES, V69, P723, DOI 10.1080/03772063.2020.1838342
   Gupta R, 2020, COMPUT ELECTR ENG, V0, P0, DOI DOI 10.1016/J.COMPELECENG.2020.106898
   He YH, 2019, PROC CVPR IEEE, V0, PP2883, DOI 10.1109/CVPR.2019.00300
   Joshi G, 2018, INT C ADV COMP DAT S, V0, P65
   Joshi G, 2018, IET COMPUT VIS, V12, P570, DOI 10.1049/iet-cvi.2017.0394
   Joshi G, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, V0, PP541, DOI 10.5220/0006200905410548
   Just A, 2006, 2 HANDED GESTURES HU, V0, P0
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, V0, P351
   Kakoty NM, 2018, PROCEDIA COMPUT SCI, V133, P55, DOI 10.1016/j.procs.2018.07.008
   Kang B, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, V0, PP136, DOI 10.1109/ACPR.2015.7486481
   Kaur B, 2017, WIRELESS PERS COMMUN, V95, P4823, DOI 10.1007/s11277-017-4126-2
   Kaur B, 2016, ADV HUM-COMPUT INTER, V2016, P0, DOI 10.1155/2016/6727806
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Kulshreshth A, 2017, IEEE COMPUT GRAPH, V37, P16, DOI 10.1109/MCG.2017.42
   Kumar Anand, 2021, INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY, V13, P349, DOI 10.1007/s41870-020-00525-6
   Kumar P, 2012, PROCEEDINGS OF THE 2012 1ST INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN INFORMATION TECHNOLOGY (RAIT 2012), V0, PP750, DOI 10.1109/RAIT.2012.6194548
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Liu Y, 2021, EXPERT SYST APPL, V172, P0, DOI 10.1016/j.eswa.2021.114602
   Mittal A, 2018, WIRELESS PERS COMMUN, V101, P511, DOI 10.1007/s11277-018-5702-9
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Pathak Bhumika, 2019, COMPUTATIONAL INTELLIGENCE: THEORIES, V0, P487, DOI 10.1007/978-981-13-1132-1_38
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), V0, P0, DOI DOI 10.1109/ICCVW.2011.6130290
   Raheja JL, 2016, PATTERN RECOGNITION AND IMAGE ANALYSIS, V26, P434, DOI 10.1134/S1054661816020164
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Rekha J, 2011, 2011 3RD INTERNATIONAL CONFERENCE ON TRENDZ IN INFORMATION SCIENCES & COMPUTING (TISC), V0, PP30, DOI 10.1109/TISC.2011.6169079
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Sahoo JP, 2018, IET IMAGE PROCESS, V12, P1780, DOI 10.1049/iet-ipr.2017.1312
   Sharma S, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), V0, PP140, DOI 10.1109/icict48043.2020.9112409
   Shrestha S, 2020, SCAND J GASTROENTERO, V55, P430, DOI 10.1080/00365521.2020.1740778
   Siming He, 2019, 2019 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND ADVANCED MANUFACTURING (AIAM). PROCEEDINGS, V0, PP392, DOI 10.1109/AIAM48774.2019.00083
   Simonyan K, 2015, VERY DEEP CONVOLUTIO, V0, P1
   Tao LL, 2013, LECT NOTES COMPUT SC, V8151, P339, DOI 10.1007/978-3-642-40760-4_43
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Ng WL, 2011, LECT NOTES COMPUT SC, V6762, P285
   World health organization (WHO), 2015, DEAFN HEAR LOSS KEY, V0, P0
   Wu CH, 2016, MULTIMED TOOLS APPL, V75, P7065, DOI 10.1007/s11042-015-2632-3
   Xiao QK, 2020, NEURAL NETWORKS, V125, P41, DOI 10.1016/j.neunet.2020.01.030
   Xie B, 2018, J ENG-JOE, V0, PP1515, DOI 10.1049/joe.2018.8327
   Ying Wu, 1999, PROCEEDINGS 1999 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (CAT. 99CH36348), V0, PP6, DOI 10.1109/ICIP.1999.817058
NR 53
TC 36
Z9 36
U1 3
U2 40
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 15
PY 2021
VL 182
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115657
EA AUG 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA UF2TZ
UT WOS:000688432600006
DA 2023-11-10
ER

PT J
AU Inan, E
AF Inan, Emrah
TI Somun: entity-centric summarization incorporating pre-trained language models
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Automatic text summarization; Language models; Harmonic centrality
ID feature-extraction; centrality
AB Text summarization resolves the issue of capturing essential information from a large volume of text data. Existing methods either depend on the end-to-end models or hand-crafted preprocessing steps. In this study, we propose an entity-centric summarization method which extracts named entities and produces a small graph with a dependency parser. To extract entities, we employ well-known pre-trained language models. After generating the graph, we perform the summarization by ranking entities using the harmonic centrality algorithm. Experiments illustrate that we outperform the state-of-the-art unsupervised learning baselines by improving the performance more than 10% for ROUGE-1 and more than 50% for ROUGE-2 scores. Moreover, we achieve comparable results to recent end-to-end models.
C1 [Inan, Emrah] Univ Manchester, Sch Comp Sci, Natl Ctr Text Min, Manchester, Lancs, England.
C3 University of Manchester
RP Inan, E (通讯作者)，Univ Manchester, Sch Comp Sci, Natl Ctr Text Min, Manchester, Lancs, England.
EM emrah.inan@manchester.ac.uk
CR [Anonymous], 2004, ENCYCL LANG LINGUIST, V0, P0
   Arora S, 2017, ICLR, V0, P0
   Bae Sanghwan, 2019, P 2 WORKSH NEW FRONT, V0, PP10, DOI 10.18653/V1/D19-5402
   Boldi P, 2014, INTERNET MATH, V10, P222, DOI 10.1080/15427951.2013.865686
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Carbonell J, 1998, PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP335, DOI 10.1145/290941.291025
   Deng WL, 2019, INT C ELECTR MACH SY, V0, P3728
   Devlin J, 2018, ARXIV, V1, P4171
   Diao YF, 2020, NEURAL COMPUT APPL, V32, P11491, DOI 10.1007/s00521-019-04638-3
   Dong Y, 2018, IEEE ANTENNAS PROP, V0, PP1739, DOI 10.1109/APUSNCURSINRSM.2018.8608240
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Gao JQ, 2020, NEURAL PROCESS LETT, V51, P473, DOI 10.1007/s11063-019-10100-1
   Gao JQ, 2019, OPTIK, V199, P0, DOI 10.1016/j.ijleo.2019.163368
   Gao XZ, 2019, KNOWL-BASED SYST, V164, P253, DOI 10.1016/j.knosys.2018.10.043
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI 10.18653/V1/N18-1065
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Imani M, 2016, INFORM SCIENCES, V342, P191, DOI 10.1016/j.ins.2016.01.032
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kanapala A, 2019, NEURAL COMPUT APPL, V31, P8631, DOI 10.1007/s00521-019-04177-x
   Kupiec J, 1995, P 18 ANN INT ACM SIG, V0, PP68, DOI 10.1145/215206.215333
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Li L, 2019, NEURAL PROCESS LETT, V49, P357, DOI 10.1007/s11063-018-9825-5
   Li Qi, 2012, P 21 ACM INT C INF K, V0, PP1727, DOI 10.1145/2396761.2398506
   Lin Chin-Yew, 2004, P 42 ANN M ASS COMP, V0, PP5, DOI 10.3115/1218955.1219032
   Lin H, 2011, PROC 49 ANN M ASS CO, V0, PP510, DOI 10.1287/MOOR.1100.0463
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Moore Edward F, 1959, P INT S THEORY SWITC, V0, P285
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Narayan S, 2018, P 2018 C N AM CHAPT, V1, P1747, DOI 10.18653/V1/N18-1158
   Nielsen F, 2017, ARXIV171004099, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Ren P, 2016, COLING 2016 26 INT C, V0, P33
   Sanh V, 2019, AAAI CONF ARTIF INTE, V0, P6949
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sidorov G, 2014, COMPUT SIST, V18, P491, DOI 10.13053/CyS-18-3-2043
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Vinyals O, 2015, P ADV NEURAL INFORM, V0, PP2692, DOI 10.48550/arxiv.1506.03134
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang XX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5059
   Zhang XX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P779
   Zhong M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1049
   Zhou QY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P654
NR 49
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD MAY 15
PY 2021
VL 33
IS 10
BP 5301
EP 5311
DI 10.1007/s00521-020-05319-2
EA SEP 2020
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RU2CU
UT WOS:000568479900002
DA 2023-11-10
ER

PT J
AU Nguyen, MT
   Le, DT
   Le, L
AF Nguyen, Minh-Tien
   Le, Dung Tien
   Le, Linh
TI Transformers-based information extraction with limited data for domain-specific business documents
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Information extraction; Transfer learning; Transformers
ID networks
AB Information extraction plays an important role for data transformation in business cases. However, building extraction systems in actual cases face two challenges: (i) the availability of labeled data is usually limited and (ii) highly detailed classification is required. This paper introduces a model for addressing the two challenges. Different from prior studies that usually require a large number of training samples, our extraction model is trained with a small number of data for extracting a large number of information types. To do that, the model takes into account the contextual aspect of pre-trained language models trained on a huge amount of data on general domains for word representation. To adapt to our downstream task, the model employs transfer learning by stacking Convolutional Neural Networks to learn hidden representation for classification. To confirm the efficiency of our method, we apply the model to two actual cases of document processing for bidding and sale documents of two Japanese companies. Experimental results on real testing sets show that, with a small number of training data, our model achieves high accuracy accepted by our clients.
C1 [Nguyen, Minh-Tien; Le, Dung Tien] CINNAMON LAB, 10th Floor,Geleximco Bldg,36 Hoang Cau, Hanoi, Vietnam.
   [Nguyen, Minh-Tien] Hung Yen Univ Technol & Educ, Hung Yen, Vietnam.
   [Le, Linh] Univ Queensland, Brisbane, Qld, Australia.
C3 University of Queensland
RP Nguyen, MT (通讯作者)，Hung Yen Univ Technol & Educ, Hung Yen, Vietnam.
EM tiennm@utehy.edu.vn; nathan@cinnamon.is; linh.le@uq.edu.au
FU Hung Yen University of Technology and Education [UTEHY.L.2020.04]
CR Andrzej J, 2018, 2018 APPLICATIONS OF ELECTROMAGNETICS IN MODERN TECHNIQUES AND MEDICINE (PTZE), V0, PP73, DOI 10.1109/PTZE.2018.8503145
   Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   [Anonymous], 2007, TAPPING UNSTRUCTURED, V0, P0
   CLARK R, 2019, P 16 INT C PAC ASS C, V0, P469
   del Corro L, 2013, P 22 INT C WORLD WID, V0, PP355, DOI 10.1145/2488388.2488420
   Del Corro L, 2015, P 2015 C EMP METH NA, V0, P868
   Deng L, 2018, DEEP LEARNING NATURA, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Finkel JR, 2009, P EMNLP, V0, P141
   Fleischman M, 2002, P 19 INT C COMP LING, V0, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Herbert L, 2017, DIGITAL TRANSFORMATI, V0, P0
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   LeCun Y, 1995, CONVOLUTIONAL NETWOR, V3361, P1995, DOI 10.5555/303568.303704
   Lee C, 2006, LECT NOTES COMPUT SC, V4182, P581
   Lin JCW, 2019, ENG APPL ARTIF INTEL, V85, P175, DOI 10.1016/j.engappai.2019.06.005
   Manyika J, 2017, FUTURE WORKS AI AUTO, V0, P60
   Meizhi Ju, 2018, P 2018 C N AM CHAPT, V0, PP1446, DOI 10.18653/V1/N18-1131
   Nguyen MT, 2018, P 19 INT C COMP LING, V0, P0
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Shimaoka Sonse, 2016, P 5 WORKSH AUT KNOWL, V0, P69
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Tur G, 2011, SPOKEN LANGUAGE UNDE, V0, P0
   Wang LG, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1385, DOI 10.18653/v1/P17-1127
   Watanabe Y, 2007, P 2007 JOINT C EMP M, V0, P649
   Weiss Karl, 2016, JOURNAL OF BIG DATA, V3, P0, DOI 10.1186/s40537-016-0043-6
   Yao L, 2019, AAAI CONF ARTIF INTE, V0, P7370
   Zhao HP, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20071861
   Zhao Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P170
NR 34
TC 11
Z9 12
U1 1
U2 12
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD JUN 15
PY 2021
VL 97
IS 
BP 
EP 
DI 10.1016/j.engappai.2020.104100
PG 12
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA PB5OV
UT WOS:000596371100007
DA 2023-11-10
ER

PT J
AU Prabhakar, DK
   Pal, S
   Kumar, C
AF Prabhakar, Dinesh Kumar
   Pal, Sukomal
   Kumar, Chiranjeev
TI Query Expansion for Transliterated Text Retrieval
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Mixed script information retrieval; transliteration; query expansion; phonetics
ID information-retrieval
AB With Web 2.0, there has been exponential growth in the number of Web users and the volume of Web content. Most of these users are not only consumers of the information but also generators of it. People express themselves here in colloquial languages, but using Roman script (transliteration). These texts are mostly informal and casual, and therefore seldom follow grammar rules. Also, there does not exist any prescribed set of spelling rules in transliterated text. This freedom leads to large-scale spelling variations, which is a major challenge in mixed script information processing. This article studies different existing phonetic algorithms to handle the issue of spelling variation, points out the limitations of them, and proposes a novel phonetic encoding approach with two different flavors in the light of Hindi transliteration. Experiments performed over Hindi song lyrics retrieval in mixed script domain with three different retrieval models show that proposed approaches outperform the existing techniques in a majority of the cases (sometimes statistically significantly) for a number of metrics like nDCG@1, nDCG@5, nDCG@10, MAP, MRR, and Recall.
C1 [Prabhakar, Dinesh Kumar; Kumar, Chiranjeev] IIT ISM, Dhanbad, Bihar, India.
   [Pal, Sukomal] IIT BHU, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (Indian School of Mines) Dhanbad; Indian Institute of Technology System (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU Varanasi)
RP Prabhakar, DK (通讯作者)，IIT ISM, Dhanbad, Bihar, India.
EM dinesh.nitr@gmail.com; sukomalpal@gmail.com; k_chiranjeev@yahoo.co.uk
CR Allan J, 2012, ACM SIGIR FORUM, V46, P2, DOI 10.1145/2215676.2215678
   Amati G, 2002, ACM T INFORM SYST, V20, P357, DOI 10.1145/582415.582416
   Bhat IA, 2014, PRE P 6 WORKSH FIRE, V0, P0
   Choudhury M, 2014, PRE P 6 WORKSH FIRE, V0, P0
   Collier Nigel, 1998, P 17 INT ERN C COMP, V1, P263
   French JC, 1997, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT. CIKM97, V0, PP9, DOI 10.1145/266714.266721
   GADD TN, 1990, PROGRAM-AUTOM LIBR, V24, P363, DOI 10.1108/eb047069
   GADD TN, 1988, PROGRAM-AUTOM LIBR, V22, P222, DOI 10.1108/eb046999
   Gamback Bjorn, 2016, P 10 INT C LANG RES, V0, P0
   Ganguly D, 2014, PRE P 6 WORKSH FIRE, V0, P0
   Gupta K, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2459
   Gupta P, 2013, PRE P 5 WORKSH FIRE, V0, P0
   Gupta P, 2014, SIGIR14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP677, DOI 10.1145/2600428.2609622
   Hsu Chung-Chian, 2010, ACM T ASIAN LANGUAGE, V9, P1
   Joshi H, 2013, PRE P 5 WORKSH FIRE, V0, P0
   Karimi S, 2011, ACM COMPUT SURV, V43, P0, DOI 10.1145/1922649.1922654
   King B, 2013, PROC N AM CHAPTER AS, V0, P1110
   Mitra M, 1998, PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP206, DOI 10.1145/290941.290995
   Mukherjee A, 2014, PRE P 6 WORKSH FIRE, V0, P0
   Odell M, 1918, US PATENT, V0, Patent No. 1261167
   Pakray P, 2013, PRE P 5 WORKSH FIRE, V0, P0
   Prakash A, 2014, PRE P 6 WORKSH FIRE, V0, P0
   Qazvinian V, 2011, P C EMP METH NAT LAN, V0, PP1589, DOI 10.5555/2145432.2145602
   Ratnaparkhi A, 1996, C EMPIRICAL METHODS, V0, P0
   Roy RS, 2013, POSTPR 4 5 WORKSH FO, V0, P1
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Schutze H, 2008, INTRO INFORM RETRIEV, V39, P0
   Sequiera Royal, 2015, P FIRE WORKSHOPS 201, V1587, P19
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P809, DOI 10.1016/S0306-4573(00)00016-9
   Wang Xuerui, 2009, P 2 ACM INT C ONWEB, V0, P74
   Zobel J, 1996, SIGIR FORUM, V0, P166
NR 31
TC 0
Z9 0
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL 15
PY 2021
VL 20
IS 4
BP 
EP 
DI 10.1145/3447649
PG 34
WC Computer Science, Artificial Intelligence
SC Computer Science
GA XB8OR
UT WOS:000721582900011
DA 2023-11-10
ER

PT J
AU Malhotra, S
   Kumar, V
   Agarwal, A
AF Malhotra, Shivani
   Kumar, Vinay
   Agarwal, Alpana
TI Bidirectional transfer learning model for sentiment analysis of natural language
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Universal language model fine-tuning (ULMFit); Bidirectional encoder representations from transformers (BERT); Average stochastic gradient weight-dropped LSTM (AWD-LSTM); Transfer learning; Sentiment classification
AB The contemporary unsupervised word representation methods have been successful in capturing semantic statistics on various Natural Language Processing tasks. However, these methods proved to be futile in addressing tasks like polysemy or homonymy, which prevail in such tasks. There has been a rise in the number of state-of-the-art transfer learning techniques bringing into play the language models pre-trained on large inclusive corpus. Motivated by these techniques, the present paper proposes an efficacious transfer learning based ensemble model. This model is inspired by ULMFit and presents results on challenging sentiment analysis tasks such as contextualization and regularization. We have empirically validated the efficiency of our proposed model by applying it to three conventional datasets for sentiment classification task. Our model accomplished the state-of-the-art outcomes remarkably when compared to acknowledged baselines in terms of classification accuracy.
C1 [Malhotra, Shivani; Kumar, Vinay; Agarwal, Alpana] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Malhotra, S (通讯作者)，Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM smalhotra_phd18@thapar.edu
FU Google Cloud Platform
CR Abid F, 2020, COMPUT COMMUN, V157, P102, DOI 10.1016/j.comcom.2020.04.002
   [Anonymous], 2013, ROLE SYNTAX VECTOR S, V0, P0
   Bahdanau Dzmitry, 2015, 3 INT C LEARN REPR I, V0, P0
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bird S, 2009, NATURAL LANGUAGE PRO, Vfirst, P0
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bouazizi M, 2017, IEEE ACCESS, V5, P20617, DOI 10.1109/ACCESS.2017.2740982
   Cambria E, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.4531228
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Crowdflower, 2016, AIRL TWITT SENT, V0, P0
   de Araujo PHL, 2020, INFERRING SOURCE OFF, V0, P76
   Devlin J, 2018, ARXIV, V1, P4171
   Glorot Xavier, 2011, ICML, V0, P0, DOI DOI 10.1177/1753193411430810
   Gupta C, 2019, NOVEL APPROACH FEATU, V0, P661
   Haddoud M, 2016, KNOWL INF SYST, V49, P909, DOI 10.1007/s10115-016-0924-1
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Jean-Francois P, 2017, FEATURE ENG DEEP LEA, V0, P0
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Joulin A, 2017, P 15 C EUR CHAPT ASS, V0, P427
   Krishnamurthy Gangeshwar, 2018, ARXIV180300344, V0, P0
   Le Q, 2014, INT C MACHINE LEARNI, V32, P0, DOI 10.1145/2740908.2742760
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Manning Christopher, 1999, FDN STAT NATURAL LAN, V0, P3
   McCann B, 2017, LEARNED TRANSLATION, V0, P6294
   Mikolov T, 2013, ARXIV13013781 CS, V0, P0, DOI DOI 10.48550/ARXIV.1301.3781
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Neelakantan A, 2015, EFFICIENT NONPARAMET, V0, P1059
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pathak AR, 2020, ALGO INTELL SY, V0, PP1, DOI 10.1007/978-981-15-1216-2_1
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Pérez-Rosas V, 2015, ICMI15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP59, DOI 10.1145/2818346.2820758
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rane A, 2018, SENTIMENT CLASSIFICA, V0, P769
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Shaukat Z, 2020, SN APPL SCI, V2, P0, DOI 10.1007/s42452-019-1926-x
   Socher, 2018, REGULARIZING OPTIMIZ, V0, P0
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang YX, 2020, INT J MACH LEARN CYB, V11, P1611, DOI 10.1007/s13042-020-01069-8
   Wu YJ, 2020, NEUROCOMPUTING, V390, P88, DOI 10.1016/j.neucom.2020.01.064
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yosinski J, 2014, TRANSFERABLE ARE FEA, V0, P3320
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhao JQ, 2017, IEEE ACCESS, V5, P2870, DOI 10.1109/ACCESS.2017.2672677
   Zheng JM, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102215
NR 51
TC 3
Z9 3
U1 0
U2 19
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD NOV 15
PY 2021
VL 12
IS 11
BP 10267
EP 10287
DI 10.1007/s12652-020-02800-7
EA JAN 2021
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA UT9GM
UT WOS:000604217200009
DA 2023-11-10
ER

PT J
AU Sivasankar, E
   Krishnakumari, K
   Balasubramanian, P
AF Sivasankar, E.
   Krishnakumari, K.
   Balasubramanian, P.
TI An enhanced sentiment dictionary for domain adaptation with multi-domain dataset in Tamil language (ESD-DA)
SO SOFT COMPUTING
LA English
DT Article
DE Dictionary; Mutual information; Tamil language; Sentiment classification; Domain adaptation
ID classification; model
AB Mostly sentiment analysis employs dictionary approaches for recognizing the polarity of terms in a review. However, in sentiment analysis between different domains called domain adaptation (DA), the sentiment lexicon disappoints that leads to the feature mismatch problem. Now, many e-commerce sites try to process reviews in their native languages. In this paper, we propose an enhanced dictionary in our native language (Tamil) that aims at building contextual relationships among the terms of multi-domain datasets that tries to minimize the feature mismatch problem. The proposed dictionary employs both labeled and unlabeled data from the source domain and unlabeled data from the target domain. More precisely, the initial dictionary explores pointwise mutual information for calculating contextual weight then the final dictionary estimates the rank score based on the importance of terms among all the reviews. This work intends to classify reviews of multiple target domains in Tamil by using the unified dictionary with a large number of vocabularies. This extendible dictionary significantly improves the accuracy of DA with the other baseline methods and handles many words in multiple domains with ease.
C1 [Sivasankar, E.; Balasubramanian, P.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 600015, Tamil Nadu, India.
   [Krishnakumari, K.] AVC Coll Engn Mannampandal, Dept Comp Sci & Engn, Mayiladuthurai 609305, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Tiruchirappalli
RP Krishnakumari, K (通讯作者)，AVC Coll Engn Mannampandal, Dept Comp Sci & Engn, Mayiladuthurai 609305, India.
EM sivasanIcar@nitt.edu; krishna.41999@gmail.com; 406117002@nitt.edu
CR Ahmed M, 2020, NEURAL COMPUT APPL, V32, P14719, DOI 10.1007/s00521-020-04824-8
   Al-Moslmi T, 2017, IEEE ACCESS, V5, P16173, DOI 10.1109/ACCESS.2017.2690342
   Aral S, 2013, PROBLEM ONLINE RATIN, V0, P0
   Blitzer J, 2006, P 2006 C EMPIRICAL M, V0, P120
   Bollegala D, 2016, IEEE T KNOWL DATA EN, V28, P398, DOI 10.1109/TKDE.2015.2475761
   Bollegala D, 2013, IEEE T KNOWL DATA EN, V25, P1719, DOI 10.1109/TKDE.2012.103
   Cai Y, 2019, INT J MACH LEARN CYB, V10, P2131, DOI 10.1007/s13042-017-0757-6
   Chen YQ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383
   Dai W, 2007, P 24 INT C MACH LEAR, V0, PP193, DOI 10.1145/1273496.1273521
   Das A, 2012, PROCEEDINGS OF THE FIFTH WORKSHOP ON EXPLOITING SEMANTIC ANNOTATIONS IN INFORMATION RETRIEVAL, V0, P3
   Das A, 2010, WOODHEAD PUBL INDIA, V0, P54
   Denecke K, 2009, 2009 FOURTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, V0, P247
   Dhanalakshmi V, 2009, INTERNATIONAL JOURNAL OF RECENT TRENDS IN ENGINEERING, V1, P166
   Dredze Mark, 2007, P 45 ANN M ASS COMPU, V0, P440
   Ganin Yaroslav, 2015, INT C MACH LEARN, V0, PP1180, DOI 10.48550/ARXIV.1409.7495
   Gindl S, 2010, FRONT ARTIF INTEL AP, V215, P771, DOI 10.3233/978-1-60750-606-5-771
   Glorot Xavier, 2011, ICML, V0, P0, DOI DOI 10.1177/1753193411430810
   Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P174, DOI 10.3115/976909.979640
   Jha V, 2018, COMPUT ELECTR ENG, V69, P585, DOI 10.1016/j.compeleceng.2017.10.015
   Jiang L, 2011, PROC 49 ANN M ASS CO, V0, P151
   Kannan A, 2016, P 13 INT C NAT LANG, V0, P30
   Krishnakumari K, 2020, SOFT COMPUT, V24, P3511, DOI 10.1007/s00500-019-04117-w
   Krishnakumari K, 2018, BIG DATA ANAL, V0, P439
   Li T, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP716, DOI 10.1145/1571941.1572093
   Liu B, 2011, DATA CENTRIC SYST AP, V0, PP459, DOI 10.1007/978-3-642-19460-3_11
   Liu Bing, 2005, P 14 INT C WORLD WID, V0, PP342, DOI 10.1145/1060745.1060797
   Mritunjay K, 2017, STUDY KPMG INDIA GOO, V0, P0
   Neviarouskaya A, 2011, IEEE T AFFECT COMPUT, V2, P22, DOI 10.1109/T-AFFC.2011.1
   Padmamala R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, V0, P0
   Pan S, 2010, I C WIREL COMM NETW, V0, P0
   Pan W, 2012, MINING TEXT DATA, V0, PP223, DOI 10.1007/978-1-4614-3223-4_7
   Patra Braja Gopal, 2015, MINING INTELLIGENCE AND KNOWLEDGE EXPLORATION. THIRD INTERNATIONAL CONFERENCE, V0, P650, DOI 10.1007/978-3-319-26832-3_61
   Rajendran S, 2002, P 1 INT GLOB WORDNET, V152, P271
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Ravishankar N, 2018, ADV INTELL SYST, V668, P687, DOI 10.1007/978-981-10-7868-2_65
   Ravishankar N, 2017, IIOAB J, V8, P172
   Salehan M, 2016, DECIS SUPPORT SYST, V81, P30, DOI 10.1016/j.dss.2015.10.006
   Sarkar Kamal, 2015, MINING INTELLIGENCE AND KNOWLEDGE EXPLORATION. THIRD INTERNATIONAL CONFERENCE, V0, P694, DOI 10.1007/978-3-319-26832-3_66
   Se Shriya, 2015, MINING INTELLIGENCE AND KNOWLEDGE EXPLORATION. THIRD INTERNATIONAL CONFERENCE, V0, P703, DOI 10.1007/978-3-319-26832-3_67
   Se S, 2016, INDIAN J SCI TECHNOL, V9, P1, DOI 10.17485/ijst/2016/v9i45/106482
   Thangarasu M, 2012, INT J COMPUT SCI ENG, V4, P902
   Thilagavathi R, 2016, INT J ENG RES TECHNO, V4, P114
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P417
   Weeds J, 2005, COMPUT LINGUIST, V31, P439, DOI 10.1162/089120105775299122
   Xing FZ, 2019, INFORM PROCESS MANAG, V56, P554, DOI 10.1016/j.ipm.2018.11.002
   Zhendong D, 2006, HOWNET COMPUTATION M, V0, P0
NR 46
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD MAR 15
PY 2021
VL 25
IS 5
BP 3697
EP 3711
DI 10.1007/s00500-020-05400-x
EA OCT 2020
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA QN4IB
UT WOS:000584873000004
DA 2023-11-10
ER

PT J
AU Yechuri, PK
   Ramadass, S
AF Yechuri, Praveen Kumar
   Ramadass, Suguna
TI Classification of Image and Text Data Using Deep Learning-Based LSTM Model
SO TRAITEMENT DU SIGNAL
LA English
DT Article
DE Natural Language Processing (NLP); LSTM; &nbsp; IMDB; Sentiment Analysis (SA)
ID sentiment analysis; online reviews; destinations; analytics
AB The advent of social networking and the internet has resulted in a huge shift in how consumers express their loyalty and where firms acquire a reputation. Customers and businesses frequently leave comments, and entrepreneurs do the same. These write-ups may be useful to those with the ability to analyse them. However, analysing textual content without the use of computers and the associated tools is time-consuming and difficult. The goal of Sentiment Analysis (SA) is to discover client feedback, points of view, or complaints that describe the product in a more negative or optimistic light. You can expect this to be a result based on this data if you merely read and assess feedback or examine ratings. There was a time when only the use of standard techniques, such as linear regression and Support Vector Machines (SVM), was effective for the task of automatically discovering knowledge from written explanations, but the older approaches have now been mostly replaced by deep neural networks, and deep learning has gotten the job done. Convolution and compressing RNNs are useful for tasks like machine translation, caption creation, and language modelling, however they suffer from gradient disappearance or explosion issues with large words. This research uses a deep learning RNN for movie review sentiment prediction that is quite comparable to Long Short-Term Memory networks. A LSTM model was well suited for modelling long sequential data. Generally, sentence vectorization approaches are used to overcome the inconsistency of sentence form. We made an attempt to look into the effect of hyper parameters like dropout of layers, activation functions and we also tested the model with different neural network settings and showed results that have been presented in the various ways to take the data into account. IMDB is the official movie database which serves as the basis for all of the experimental studies in the proposed model.
C1 [Yechuri, Praveen Kumar; Ramadass, Suguna] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci, Chennai 600062, Tamil Nadu, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Yechuri, PK (通讯作者)，Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci, Chennai 600062, Tamil Nadu, India.
EM praveenkumaryechuri@gmail.com
CR Alkalbani AM, 2016, IEEE IJCNN, V0, PP1547, DOI 10.1109/IJCNN.2016.7727382
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Bag S, 2019, J BUS RES, V94, P408, DOI 10.1016/j.jbusres.2017.11.031
   Birjali M, 2017, PROCEDIA COMPUT SCI, V113, P65, DOI 10.1016/j.procs.2017.08.290
   Devlin J, 2018, ARXIV, V1, P4171
   Dong YR, 2020, IEEE ACCESS, V8, P30548, DOI 10.1109/ACCESS.2019.2954985
   Duan WJ, 2013, P ANN HICSS, V0, PP3119, DOI 10.1109/HICSS.2013.400
   Eimurrigi E, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), V0, PP107, DOI 10.1109/INTECH.2017.8102442
   Fan ZP, 2017, J BUS RES, V74, P90, DOI 10.1016/j.jbusres.2017.01.010
   Fang B, 2016, TOURISM MANAGE, V52, P498, DOI 10.1016/j.tourman.2015.07.018
   Fuchs M, 2014, J DESTIN MARK MANAGE, V3, P198, DOI 10.1016/j.jdmm.2014.08.002
   Geetha M, 2017, TOURISM MANAGE, V61, P43, DOI 10.1016/j.tourman.2016.12.022
   Guzman de Nunez XM, 2018, NEW TRENDS INTELLIGE, V0, PP713, DOI 10.3233/978-1-61499-900-3
   Hemalatha I, 2013, IET CHENNAI FOURTH INTERNATIONAL CONFERENCE ON SUSTAINABLE ENERGY AND INTELLIGENT SYSTEMS (SEISCON 2013), V0, P357
   Jeyapriya A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), V0, PP548, DOI 10.1109/ECS.2015.7124967
   Kaur G, 2016, INT J ADV RES COMPUT, V5, P148
   Kim K, 2017, TECHNOL FORECAST SOC, V123, P362, DOI 10.1016/j.techfore.2017.01.001
   Kumari U, 2017, INT J COMPUTER SCI T, V8, P58
   Mali D, 2016, INT J MANAGE APPL SC, V1, P127
   Marrese-Taylor E, 2014, EXPERT SYST APPL, V41, P7764, DOI 10.1016/j.eswa.2014.05.045
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   Salur MU, 2020, IEEE ACCESS, V8, P58080, DOI 10.1109/ACCESS.2020.2982538
   She XY, 2018, INT SYM COMPUT INTEL, V0, PP185, DOI 10.1109/ISCID.2018.10144
   Soumya P, 2017, INT J COMPUTATIONAL, V0, P0
   Tripathy A, 2015, PROCEDIA COMPUT SCI, V57, P821, DOI 10.1016/j.procs.2015.07.523
   Upadhyay Neha, 2016, INT J RES APPL SCI E, V4, P488
   Wang J, 2020, IEEE-ACM T AUDIO SPE, V28, P581, DOI 10.1109/TASLP.2019.2959251
   Wankhede R, 2018, INT J SCI RES SCI TE, V0, P0
   Xiang Z, 2017, TOURISM MANAGE, V58, P51, DOI 10.1016/j.tourman.2016.10.001
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   Yuandong Luan, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTER APPLICATIONS (ICAICA), V0, PP352, DOI 10.1109/ICAICA.2019.8873454
   Zhang JR, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, V0, P1675, DOI 10.1109/IAEAC.2018.8577620
NR 32
TC 5
Z9 5
U1 0
U2 10
PU INT INFORMATION & ENGINEERING TECHNOLOGY ASSOC
PI EDMONTON
PA #2020, SCOTIA PLACE TOWER ONE, 10060 JASPER AVE, EDMONTON, AB T5J 3R8, CANADA
SN 0765-0019
EI 1958-5608
J9 TRAIT SIGNAL
JI Trait. Signal
PD DEC 15
PY 2021
VL 38
IS 6
BP 1809
EP 1817
DI 10.18280/ts.380625
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA YI0CR
UT WOS:000743525900003
DA 2023-11-10
ER

PT J
AU Pelicon, A
   Shekhar, R
   Skrlj, B
   Purver, M
   Pollak, S
AF Pelicon, Andraz
   Shekhar, Ravi
   Skrlj, Blaz
   Purver, Matthew
   Pollak, Senja
TI Investigating cross-lingual training for offensive language detection
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Cross-lingual models; Transfer learning; Intermediate training; Offensive language detection; Deep learning
ID hate speech
AB datasets (e.g., Davidson et al., 2017; Zampieri et al., 2019a; Ljubesic, Fiser & Erjavec, 2019), shared tasks (e.g., Wiegand, Siegel & Ruppenhofer, 2018; Zampieri et al., 2020a) and models (e.g., Salminen et al., 2018; Farha & Magdy, 2020; Gao & Huang, 2017; Zampieri et al., 2020a) have been proposed for several languages. However, so far, good accuracy in automatic detection depends upon the availability of substantial, well-labelled datasets: in many domains and in many languages, this is not the case. A common theme across recent work in NLP which promises to reduce the requirement for such task-specific labeled data is the use of transfer learning (see e.g., Ruder, 2019). Typically, in this approach, a large pre-trained language model (LM) is learned using a general source task (e.g., masked language modeling or next sentence prediction) over a very large amount of easily obtained unlabeled data. This pre-trained LM-which contains a lot of information about word meaning and dependencies-can then be finetuned on the target NLP task (e.g., hate speech detection, question answering etc.), requiring only a smaller labeled dataset to achieve state-of-the-art performance (see e.g., Devlin et al., 2019). While most of this research is focused on the English language only, the principle extends to transfer between languages, and recent work in cross-lingual transfer leverages datasets in multiple languages to provide pre-trained models with multilingual embeddings (Artetxe & Schwenk, 2019; Devlin et al., 2019). For example, Devlin et al. Platforms that feature user-generated content (social media, online forums, newspaper comment sections etc.) have to detect and filter offensive speech within large, fast-changing datasets. While many automatic methods have been proposed and achieve good accuracies, most of these focus on the English language, and are hard to apply directly to languages in which few labeled datasets exist. Recent work has therefore investigated the use of cross-lingual transfer learning to solve this problem, training a model in a well-resourced language and transferring to a less-resourced target language; but performance has so far been significantly less impressive. In this paper, we investigate the reasons for this performance drop, via a systematic comparison of pre-trained models and intermediate training regimes on five different languages. We show that using a better pre-trained language model results in a large gain in overall performance and in zero-shot transfer, and that intermediate training on other languages is effective when little target-language data is available. We then use multiple analyses of classifier confidence and language model vocabulary to shed light on exactly where these gains come from and gain insight into the sources of the most typical mistakes.
C1 [Pelicon, Andraz; Skrlj, Blaz; Purver, Matthew; Pollak, Senja] Jozef Stefan Inst, Ljubljana, Slovenia.
   [Pelicon, Andraz; Skrlj, Blaz] Jozef Stefan Int Postgrad Sch, Ljubljana, Slovenia.
   [Shekhar, Ravi; Purver, Matthew] Queen Mary Univ London, London, England.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute; Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute; University of London; Queen Mary University London
RP Pelicon, A (通讯作者)，Jozef Stefan Inst, Ljubljana, Slovenia.; Pelicon, A (通讯作者)，Jozef Stefan Int Postgrad Sch, Ljubljana, Slovenia.
EM Andraz.Pelicon@ijs.si
FU European Union's Horizon 2020 research and innovation program [825153]; European Union's Rights, Equality and Citizenship Program [875263]; project EMBEDDIA (CrossLingual Embeddings for LessRepresented Languages in European News Media); European Union [875263]; EPSRC [EP/S033564/1]; Slovenian Research Agency (ARRS) core research program Knowledge Technologies [P20103]; research project CANDAS Computer assisted multilingual news discourse analysis [J6-2581]; EPSRC [EP/S033564/1] Funding Source: UKRI
CR Abu Farha I, 2020, P 4 WORKSHOP OPEN SO, V0, P86
   [Anonymous], 2018, 14 C NATURAL LANGUAG, V0, P0
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bai Xiaoyu, 2018, P 6 EV CAMP NAT LANG, V0, P0
   Basile V, 2019, P 13 INT WORKSH SEM, V0, P54
   Beyrer C, 2017, LANCET, V390, P1570, DOI 10.1016/S0140-6736(17)32519-9
   Blair T, 2019, DESIGNATING HATE NEW, V0, P0
   Chopra S, 2020, AAAI CONF ARTIF INTE, V34, P386
   Conneau A, 2020, PROC 58 ANN M ASS CO, V0, P8440
   Conneau A, 2019, ADV NEUR IN, V32, P0
   Davidson Thomas, 2017, ICWSM, V0, P512
   Devlin J, 2018, ARXIV, V1, P4171
   Gagliardone I, 2015, SERIES INTERNET FREE, V0, P0
   Gao L, 2017, INT C REC ADV NAT LA, V0, PP260, DOI 10.26615/978-954-452-049-6-036
   Golbeck J, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI 17), V0, PP229, DOI 10.1145/3091478.3091509
   Hu Junjie, 2020, P 37 INT C MACH LEAR, V0, P0
   Ibrohim Muhammad Okky, 2018, PROCEDIA COMPUTER SCIENCE, V135, P222, DOI 10.1016/j.procs.2018.08.169
   Lample G, 2018, UNSUPERVISED MACHINE, V0, P0
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Leite JA, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P914
   Lin YH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3125
   Liu P, 2019, P 13 INT WORKSH SEM, V0, PP87, DOI 10.18653/v1/S19-2011
   Liu YH, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Ljubesic N, 2018, P 2 WORKSH AB LANG O, V0, PP124, DOI 10.18653/V1/W18-5116
   Ljubesic N, 2019, LECT NOTES ARTIF INT, V11697, P103, DOI 10.1007/978-3-030-27947-9_9
   Lomas N, 2015, FACEBOOK GOOGLE TWIT, V0, P0
   Lomas Natasha, 2017, TECHCRUNCH, V0, P0
   Mandl T, 2019, ACM INT CONF PR SER, V0, PP14, DOI 10.1145/3368567.3368584
   Martin L, 2020, ASS COMPUTATIONAL LI, V0, PP7203, DOI 10.18653/V1/2020.ACL-MAIN.645
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), V0, P18
   Morgan NA, 2020, UPDATE ONLINE HARMS, V0, P0
   Mozetic I, 2020, P C LANG TECHN DIG H, V0, P87
   Mubarak H, 2017, P 1 WORKSHOP ABUSIVE, V0, P0, DOI DOI 10.18653/v1/W17-3008
   Obadimu A, 2019, LECT NOTES COMPUT SC, V11549, P214, DOI 10.1007/978-3-030-21741-9_22
   Pamungkas EW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P363
   Pedersen T, 2020, P 14 WORKSH SEM EV, V0, P1938
   Pelicon A, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10175993
   Pelicon Andraz, 2021, P EACL WORKSH NEWS M, V0, P30
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Plaza-Del-Arco FM, 2020, ACM T INTERNET TECHN, V20, P0, DOI 10.1145/3369869
   Poletto F, 2020, LANG RESOUR EVAL, V55, P1
   Pollak S, 2021, P EACL HACK NEWS MED, V0, P99
   Pruksachatkun Y, 2020, P 58 ANN M ASS COMP, V0, PP5231, DOI 10.18653/V1/2020.ACL-MAIN.467
   Qian J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4755
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Ruder S, 2019, THESIS NATL U IRELAN, V0, P0
   Salminen J, 2018, 12 INT AAAI C WEB SO, V0, P0
   Salminen J, 2020, HUM-CENTRIC COMPUT I, V10, P0, DOI 10.1186/s13673-019-0205-6
   Schmidt Anna, 2017, P 5 INT WORKSH NAT L, V0, PP1, DOI 10.18653/V1/W17-1101
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Shekhar R, 2020, J LANGUAGE TECHNOLOG, V34, P49
   Siegel JM, 2019, P 15 KONVENS, V0, P354
   Simonite T, 2020, WIRED, V0, P0
   Skrlj B, 2021, P EACL HACKASHOP NEW, V0, P76
   Skrlj B, 2021, COGN COMPUT, V0, P0, DOI DOI 10.1007/s12559-021-09826-9
   Stappen L, 2020, CROSS LINGUAL ZERO A, V0, P0
   Stevenson A, 2018, NEW YORK TIMES, V0, P0
   Subedar A, 2018, COUNTRY FACEBOOK POS, V0, P0
   Swayamdipta S, 2020, P 2020 C EMP METH NA, V0, P0
   Ulcar M, 2020, INT C TEXT SPEECH DI, V0, P104
   van der Goot R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Vidgen B, 2020, P 4 WORKSHOP ONLINE, V0, PP162, DOI 10.18653/V1/2020.ALW-1.19
   Vidgen B, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0243300
   Vu T, 2020, P EMNLP2020, V0, P7882
   Wang A, 2019, P NEURIPS, V0, P3266
   Wang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4465
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wiegand M, 2018, P GERMEVAL 2018 WORK, V0, P0
   Wolf T, 1900, P38, V0, P0
   Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1391, DOI 10.1145/3038912.3052591
   Yogatama D, 2019, LEARNING EVALUATING, V0, P0
   Zampieri M, 2019, P 13 INT WORKSHOP SE, V0, PP75, DOI 10.18653/V1/S19-2010
   Zampieri M, 2020, P 14 WORKSHOP SEMANT, V0, P1425
   Zampieri M, 2020, P SEMEVAL, V0, P0
   Zampieri M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1415
NR 77
TC 4
Z9 4
U1 2
U2 10
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUN 25
PY 2021
VL 0
IS 
BP 
EP 
DI 10.7717/peerj-cs.559
PG 39
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA TD1YY
UT WOS:000669132200001
PM 34239970
DA 2023-11-10
ER

PT J
AU Dhar, A
   Mukherjee, H
   Dash, NS
   Roy, K
AF Dhar, Ankita
   Mukherjee, Himadri
   Dash, Niladri Sekhar
   Roy, Kaushik
TI Text categorization: past and present
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Article
DE Text categorization; Conventional methods; Fuzzy logic; Deep learning; Nature-inspired algorithms; Graph-based methods
ID term weighting schemes; feature-selection; fuzzy similarity; classification; representation; documents; model; framework; system
AB Automatic text categorization is the operation of sorting out the text documents into pre-defined text categories using some machine learning algorithms. Normally, it defines the most important approaches to organizing and making the use of a large volume of information exists in unstructured form. Nowadays, text categorization is becoming an extensively researched field of text mining and processing of languages. Word sense, semantic relationships among terms, text documents and categories are quite essential in order of enhancing the performances of categorization. Various surveys on text categorization have already been available which involve techniques of various text representation schemes to such extent but do not include several approaches that have been explored in text categorization over the standard techniques. Here, an exhaustive analysis of different text categorization approaches over the conventional approaches has been undertaken. This survey paper explores a wide variety of algorithms used for categorizing text documents and tries to assemble the existing works into three basic fields: conventional methods, fuzzy logic-based methods, deep learning-based methods. Further, conventional methods have been categorized into three fields: text categorization using handcrafted features, text categorization using nature-inspired algorithms and text categorization using graph-based methods. Furthermore, this survey provides a clear idea about the available libraries used for different algorithms, availability of datasets, categorization technologies explored in various non-Indian and Indian languages as well.
C1 [Dhar, Ankita; Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Dash, Niladri Sekhar] Indian Stat Inst, Linguist Res Unit, Kolkata, India.
C3 West Bengal State University; Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Roy, K (通讯作者)，West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM ankita.ankie@gmail.com; himadrim027@gmail.com; ns_dash@yahoo.com; kaushik.mrg@gmail.com
FU DST
CR Abutiheen ZA, 2018, P SCI C REN EN ITS A, V0, P1
   Al-Harbi S, 2008, P 9 INT C STAT AN TE, V0, P77
   Al-Radaideh Qasem A, 2015, INTERNATIONAL JOURNAL OF KNOWLEDGE ENGINEERING AND DATA MINING, V3, P255
   Al-Taani AT, 2009, INT J COMPUT INF ENG, V03, P671
   Al-Tahrawi Mayy M, 2015, INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS AND APPLICATIONS, V7, P71, DOI 10.5815/ijisa.2015.06.08
   Alam MT, 2018, 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING (ICBSLP), V0, P0
   Ali A, 2009, PROCEEDINGS OF THE ASME SUMMER BIOENGINEERING CONFERENCE 2008, V0, P19
   Aly WM, 2014, INT J COMPUTER APPL, V86, P4, DOI 10.5120/14947-3041
   [Anonymous], 2018, STUDIES COMPUTATIONA, V0, P0, DOI DOI 10.1007/978-3-319-67056-0_20
   [Anonymous], 2016, 2016 9 INT C CONT CO, V0, P0
   [Anonymous], 2012, P INT MULT ENG COMP, V0, P0
   [Anonymous], 2003, AUTOMATIC CATEGORIZA, V0, P0
   [Anonymous], 1994, FUZZY THINKING NEW S, V0, P0
   [Anonymous], 1900, DOI 10.3844/JCSSP.2023.20.56, V0, P0
   [Anonymous], 2010, 12 INT WORKSHOP COMP, V0, P0
   Asim M, 2017, NAT COMMUN, V8, P0, DOI 10.1038/s41467-017-00393-y
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Basu A, 2003, 36 ANN HAW INT C SYS, V0, P0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bidi N, 2016, PROCEEDINGS OF 2016 8TH INTERNATIONAL CONFERENCE ON MODELLING, V0, P806, DOI 10.1109/ICMIC.2016.7804223
   Boukil S, 2018, INT J GRID DISTRIB, V11, P103, DOI 10.14257/ijgdc.2018.11.9.09
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Chen WL, 2005, LECT NOTES COMPUT SC, V3411, P1
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cordobés H, 2014, INT J INTERACT MULTI, V2, P31, DOI 10.9781/ijimai.2014.254
   Cortez P, 2018, EXPERT SYST, V35, P0, DOI 10.1111/exsy.12280
   Cozman F, 2003, P INT C MACH LEARN, V0, P0
   Dasondi V, 2016, 2016 SYMPOSIUM ON COLOSSAL DATA ANALYSIS AND NETWORKING (CDAN), V0, P0
   DeySarkar S, 2014, INT SCH RES NOT, V2014, P10
   Dhar A, 2017, 2017 3 INT C ADV COM, V0, PP1, DOI 10.1109/ICACCAF.2017.8344721
   Dhar A, 2017, P INT C FRONT INT CO, V0, P51
   Dhar A, 2018, J ADV LINGUISTIC STU, V7, P159
   Dhar Ankita, 2018, P ANN CONV COMP SOC, V0, P477
   Dogan T, 2019, ARAB J SCI ENG, V44, P9545, DOI 10.1007/s13369-019-03920-9
   Dumais S, 1998, PROCEEDINGS OF THE 1998 ACM CIKM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP148, DOI 10.1145/288627.288651
   el Ameen A, 2014, P INT AR C INF TECHN, V0, P1
   El-Halees A, 2007, ISLAMIC U J, V15, P157
   El-Kourdi M, 2004, P WORKSHOP COMPUTATI, V0, P0, DOI DOI 10.3115/1621804.1621819
   Elberrichi Z, 2012, INT ARAB J INF TECHN, V9, P465
   Farhoodi Mojgan, 2010, 2010 6TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION MANAGEMENT AND SERVICE (IMS 2010), V0, P318
   Feng GZ, 2018, PATTERN RECOGN LETT, V110, P23, DOI 10.1016/j.patrec.2018.03.003
   Fu G, 2010, COLING 2010 POSTERS, V0, P312
   Gu CW, 2017, IOP CONF SER-MAT SCI, V261, P0, DOI 10.1088/1757-899X/261/1/012008
   Guelpeli MVC, 2010, ADV INFORM KNOWL PRO, V0, PP277, DOI 10.1007/978-1-84996-077-9_11
   Gupta R, 2012, FOOD SCI TECH-INT SE, V0, PP109, DOI 10.1016/B978-0-12-381470-8.00005-0
   Guru DS, 2018, PATTERN RECOGN LETT, V103, P23, DOI 10.1016/j.patrec.2017.12.025
   Guru DS, 2015, PROCEDIA COMPUT SCI, V45, P13, DOI 10.1016/j.procs.2015.03.074
   Hao Lin, 2014, PROCEEDINGS OF 2014 2ND INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRONIC COMMERCE (ICITEC), V0, PP257, DOI 10.1109/ICITEC.2014.7105614
   Haralambous Y, 2014, P INT C AUT LANG PRO, V0, P10
   He J, 2000, PRICAI 2000 WORKSH T, V35, P24
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Huang EH, 2012, ACL, V1, P873
   Islam MS, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, V0, P191, DOI 10.1109/ECACE.2017.7912904
   Jayashree R, 2011, 2011 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, V0, PP147, DOI 10.1109/SoCPaR.2011.6089130
   Jiang C, 2010, INT J ENG RES APPL, V23, P3028
   Jiang JY, 2011, IEEE T KNOWL DATA EN, V23, P335, DOI 10.1109/TKDE.2010.122
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Jin P, 2016, IJCAI, V16, P2824
   Joachims T, 1998, P 10 EUR C MACH LEAR, V0, PP137, DOI 10.1007/BFB0026683
   Kabir KM, 2015, INT CONF ADV ELECTR, V0, PP1, DOI 10.1109/ICAEE.2015.7506782
   Kadhim AI, 2019, ARTIF INTELL REV, V52, P273, DOI 10.1007/s10462-018-09677-1
   Kanapala A, 2019, ARTIF INTELL REV, V51, P371, DOI 10.1007/s10462-017-9566-2
   Kavuri D, 2012, INT J ENG SCI ADV TE, V02, P1572
   Khamar K, 2013, INT J ADV RES COMPUT, V2, P1916
   Khoury R, 2005, P INT C ART COMP INT, V0, P6
   Khreisat L, 2006, P 2006 INT C DAT MIN, V0, P78
   Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457, DOI 10.1109/TKDE.2006.180
   Klir GJ, 1995, FUZZY SETS FUZZY LOG, V0, P0
   Kowsari K, 2018, 2ND INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2018), V0, PP19, DOI 10.1145/3206098.3206111
   Kumar V, 2014, INT J DATABASE THEOR, V7, P61, DOI 10.14257/IJDTA.2014.7.1.06
   Kumari L, 2013, INT J ENG RES APPL, V03, P928
   Labani M, 2018, ENG APPL ARTIF INTEL, V70, P25, DOI 10.1016/j.engappai.2017.12.014
   Lan M, 2009, IEEE T PATTERN ANAL, V31, P721, DOI 10.1109/TPAMI.2008.110
   Lebanon G, 2006, IEEE T PATTERN ANAL, V28, P497, DOI 10.1109/TPAMI.2006.77
   LEWIS DD, 1992, SPEECH AND NATURAL LANGUAGE, V0, P212
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Liu R, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P856
   Liu T, 2010, LECT NOTES COMPUT SC, V6443, P314, DOI 10.1007/978-3-642-17537-4_39
   Liu WY, 2003, J COMPUT SCI TECH-CH, V18, P640, DOI 10.1007/BF02947124
   Malliaros FD, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), V0, PP1473, DOI 10.1145/2808797.2808872
   Mandal AK, 2014, INT J ARTIF INTELL A, V5, P93
   Manikandan R, 2018, ADV MATER INTERFACES, V5, P0, DOI 10.1002/admi.201800041
   Mansur M, 2006, THESIS BRAC U, V0, P0
   Marie-Sainte SL, 2020, J KING SAUD UNIV-COM, V32, P320, DOI 10.1016/j.jksuci.2018.06.004
   Mikawa K, 2011, IEEE SYS MAN CYBERN, V0, PP1741, DOI 10.1109/ICSMC.2011.6083923
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mnih A, 2007, P 24 INT C MACHINE L, V0, PP641, DOI 10.1145/1273496.1273577
   Mohammad AH, 2016, INT J CURRENT ENG TE, V6, P477
   Mohanty S, 2006, P INT C EL COMP COMM, V0, P321
   Mukherjee H, 2018, 2018 FOURTH IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), V0, PP135, DOI 10.1109/ICRCICN.2018.8718729
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Linh NV, 2017, KNOWL INF SYST, V50, P763, DOI 10.1007/s10115-016-0956-6
   Parvin H, 2012, ADV INTEL SOFT COMPU, V151, P493
   Patil JJ, 2015, 2015 INTERNATIONAL CONFERENCE ON ENERGY SYSTEMS AND APPLICATIONS, V0, PP689, DOI 10.1109/ICESA.2015.7503438
   Patil M, 2014, ACEEE INT J INFORM T, V4, P11
   Pawar Gawande S, 2012, INT J MACHINE LEARNI, V2, P423, DOI 10.7763/IJMLC.2012.V2.158
   PENG F, 2003, P 6 INT WORKSH INF R, V11, P41
   Pereira RB, 2018, ARTIF INTELL REV, V49, P57, DOI 10.1007/s10462-016-9516-4
   Prusa JD, 2016, PROCEEDINGS OF 2016 IEEE 17TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI), V0, PP411, DOI 10.1109/IRI.2016.61
   Puri S, 2011, INT J ADV COMPUT SC, V2, P115
   Rajan K, 2009, EXPERT SYST APPL, V36, P10914, DOI 10.1016/j.eswa.2009.02.010
   Rakholia RM, 2017, INDIAN J SCI TECHNOL, V5, P1, DOI 10.17485/ijst/2017/v10i5/103233
   Redmond M, 2017, PROCEEDINGS OF 2017 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE ENGINEERING AND APPLICATIONS (ICKEA), V0, PP13, DOI 10.1109/ICKEA.2017.8169894
   Sarmah J, 2012, P ICGW, V0, P324
   Sathe JB, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), V0, PP93, DOI 10.1109/ISCO.2017.7855960
   Sato M, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P175, DOI 10.5220/0006193401750184
   Sebastiani F, 2005, ENCY DATABASE TECHNO, V0, P0
   Shahi Tej Bahadur, 2018, 2018 INTERNATIONAL CONFERENCE ON COMMUNICATION INFORMATION AND COMPUTING TECHNOLOGY (ICCICT). PROCEEDINGS, V0, P0, DOI DOI 10.1109/ICCICT.2018.8325883
   Shahshahani A, 2018, IEEE INT SYMP CIRC S, V0, P0, DOI DOI 10.1109/ISCAS.2018.8351359
   Singh AP, 2018, ENERGY ENV SUSTAIN, V0, PP7, DOI 10.1007/978-981-10-7518-6_2
   Socher R, 2011, P 24 INT C NEUR INF, V0, P0
   Socher R, 2011, P C EMPIRICAL METHOD, V0, P151
   Suanmali L, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS
   Sujana TS, 2017, 2017 INTERNATIONAL CONFERENCE ON NETWORKS & ADVANCES IN COMPUTATIONAL TECHNOLOGIES (NETACT), V0, PP167, DOI 10.1109/NETACT.2017.8076761
   Swamy MN, 2013, INT J DATA MIN TECH, V02, P251
   Tandel SS, 2019, INT CONF ADVAN COMPU, V0, PP1022, DOI 10.1109/icaccs.2019.8728547
   Tellez ES, 2018, KNOWL-BASED SYST, V149, P110, DOI 10.1016/j.knosys.2018.03.003
   Tetali A, 2012, INT J ADV RES COMPUT, V01, P313
   Thien Hai Nguyen, 2013, NATURAL LANGUAGE PROCESSING AND INFORMATION SYSTEMS. 18TH INTERNATIONAL CONFERENCE ON APPLICATIONS OF NATURAL LANGUAGE TO INFORMATION SYSTEMS, V0, P278, DOI 10.1007/978-3-642-38824-8_25
   Tsekouras GE, 2007, INT FED INFO PROC, V0, P93
   Usman M, 2016, INT J ADV COMPUT SC, V7, P265
   Vinoth R, 2014, INT J ADV FOUND RES, V01, P20
   Wang DQ, 2013, J INF SCI ENG, V29, P209
   Wei ZH, 2009, INT J COMPUT INT SYS, V2, P365
   Wilges B, 2016, J COMPUTER SCI, V12, P341, DOI 10.3844/jcssp.2016.341.349
   Wong KC, 2010, SOC ISS JUSTICE STAT, V0, P1
   Wu HB, 2017, INFORM PROCESS MANAG, V53, P547, DOI 10.1016/j.ipm.2016.10.003
   Wu KY, 2017, IEEE SYS MAN CYBERN, V0, PP1942, DOI 10.1109/SMC.2017.8122902
   Wu TP, 1999, IEEE T SYST MAN CY B, V29, P25, DOI 10.1109/3477.740163
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang KS, 2010, VIROL J, V7, P0, DOI 10.1186/1743-422X-7-121
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhao W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3110
   Zhijie Liu, 2010, 2010 2ND INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE (ETCS), V0, PP219, DOI 10.1109/ETCS.2010.248
   Zonghu Wang, 2010, PROCEEDINGS OF THE 2010 SEVENTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD 2010), V0, PP2363, DOI 10.1109/FSKD.2010.5569866
NR 135
TC 27
Z9 27
U1 6
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
EI 1573-7462
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD APR 15
PY 2021
VL 54
IS 4
BP 3007
EP 3054
DI 10.1007/s10462-020-09919-1
EA SEP 2020
PG 48
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RG6YT
UT WOS:000574081800001
DA 2023-11-10
ER

PT J
AU Bourbakis, NG
   Rematska, G
   Mertoguno, S
AF Bourbakis, N. G.
   Rematska, G.
   Mertoguno, S.
TI Deep Understanding of Technical Documents: Part I. Diagrams Structural-functional Modeling
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Technical document deep understanding; document multiple modalities; formal modelling; Stochastic Petri-nets (SPN)
AB The automatic deep understanding of technical documents is a privilege only to humans so far, since it requires knowledge coming from many different modalities, like text, diagrams, formulas, tables, graphics, pictures, etc. Thus, in response to this very large and complex challenge, this paper investigates the synergistic association of only two modalities, the diagrams as main modality and natural language text as an assistive one in an effort to combine them together for deeper understanding of technical documents. In particular, it presents the formal modelling of a hybrid methodology capable to automatically extract the structural and functional behavior of a system described in a technical document without the use of original code. By system here we mean the block diagram(s) of a system. The methodology presented here is based on a formal language, called Synergy, to efficiently represent and synthesize the structural features of the system, and convert them into a Stochastic Petri-nets (SPN) model as for expressing the functional behavior of the understudy system. The overall methodology will contribute to an automatic deep understanding of technical documents (TD) without the main involvement of human users.
C1 [Bourbakis, N. G.; Rematska, G.; Mertoguno, S.] WSU, CART Ctr, Dayton, OH 45435 USA.
C3 University System of Ohio; Wright State University Dayton
RP Bourbakis, NG (通讯作者)，WSU, CART Ctr, Dayton, OH 45435 USA.
EM nikolaos.bourbakis@wright.edu; rematska@gmail.com; karno@gatech.edu
FU ONR Grant
CR Alexiou M, 2020, IEEE C TOOLS AI NOV, V0, P0
   Bourbakis N, 2017, INT IEEE C ICTAI BOS, V0, P0
   Bourbakis NG, 2016, INT IEEE C ICTAI SAN, V0, P0
   Bourbakis NG, 2020, INT J AI TOOLS, V29, P0
   Bourbakis NG, 1998, PROC INT C TOOLS ART, V0, PP10, DOI 10.1109/TAI.1998.744741
   GATTIKER J, 1995, AUTOTESTCON 95 - SYSTEMS READINESS: TEST TECHNOLOGY FOR THE 21ST CENTURY, V0, P236, DOI 10.1109/AUTEST.1995.522678
   Haas PJ, 2006, STOCHASTIC PETRI NET, V0, P0
   Harrison Michael A, 1978, INTRO FORMAL LANGUAG, V0, P0
   Jiang T, 2010, ALGORITHMS THEORY CO, V0, P0
   Kitsos P, 2003, PROCEEDINGS OF THE 46TH IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS & SYSTEMS, VOLS 1-3, P1363
   Mills M, 2013, PROC INT C TOOLS ART, V0, PP889, DOI 10.1109/ICTAI.2013.135
   Psarologou A, 2017, INT J ARTIF INTELL T, V26, P0, DOI 10.1142/S0218213017500129
   Remane G, 2016, P 37 INT C INF SYST, V0, P0
   Srihari SN, 1986, 1986 PROCEEDINGS OF THE FALL JOINT COMPUTER CONFERENCE (CAT. NO.86CH2345-7), V0, P87
NR 14
TC 3
Z9 3
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD MAY 15
PY 2021
VL 30
IS 03
BP 
EP 
DI 10.1142/S0218213021500159
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SJ3TC
UT WOS:000655454100008
DA 2023-11-10
ER

PT J
AU Hadifar, A
   Deleu, J
   Develder, C
   Demeester, T
AF Hadifar, Amir
   Deleu, Johannes
   Develder, Chris
   Demeester, Thomas
TI Exploration of block-wise dynamic sparseness
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Neural network; Dynamic sparseness; Block-wise matrix multiplication
AB Neural networks have achieved state of the art performance across a wide variety of machine learning tasks, often with large and computation-heavy models. Inducing sparseness as a way to reduce the memory and computation footprint of these models has seen significant research attention in recent years. In this paper, we present a new method for dynamic sparseness , whereby part of the computations are omitted dynamically, based on the input. For efficiency, we combined the idea of dynamic sparseness with block-wise matrix-vector multiplications. In contrast to static sparseness, which permanently zeroes out selected positions in weight matrices, our method preserves the full network capabilities by potentially accessing any trained weights. Yet, matrix vector multiplications are accelerated by omitting a pre-defined fraction of weight blocks from the matrix, based on the input. Experimental results on the task of language modeling, using recurrent and quasi-recurrent models, show that the proposed method can outperform static sparseness baselines. In addition, our method can reach similar language modeling perplexities as the dense baseline, at half the computational cost at inference time. (c) 2021 Published by Elsevier B.V.
C1 [Hadifar, Amir; Deleu, Johannes; Develder, Chris; Demeester, Thomas] Univ Ghent, IMEC, Dept Informat Technol, Technol Pk 126, B-9052 Zwijnaarde, Belgium.
C3 IMEC; Ghent University
RP Hadifar, A (通讯作者)，Univ Ghent, IMEC, Dept Informat Technol, Technol Pk 126, B-9052 Zwijnaarde, Belgium.
EM amir.hadifar@ugent.be
CR [Anonymous], 2016, ARXIV161101576, V0, P0
   [Anonymous], 1990, ADV NEURAL INFORM PR, V0, P0
   [Anonymous], 2017, ICLR, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bolukbasi T, 2017, ICML, V0, P0
   Demeester T, 2018, CONLL, V0, P0
   Gao Xitong, 2018, ARXIV181005331, V0, P0
   Guo L, 2013, PATTERN RECOGN LETT, V34, P603, DOI 10.1016/j.patrec.2013.01.003
   Guo Y, 2016, ADV NEURAL INFORM PR, V0, P0
   Han S, 2015, ADV NEUR IN, V0, P0
   Han S, 2016, CONF PROC INT SYMP C, V0, PP243, DOI 10.1109/ISCA.2016.30
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2234
   Li GY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2383
   Lin J, 2017, ADV NEURAL INFORM PR, V0, P0
   Liu Z, 2017, IEEE I CONF COMP VIS, V0, PP2755, DOI 10.1109/ICCV.2017.298
   Louizos C, 2017, 6 INT C LEARN REPR I, V0, P0
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   Merity Stephen, 2016, POINTER SENTINEL MIX, V0, P0
   Narang S, 2017, INT C LEARNING REPRE, V0, P0
   OJapa V, 2014, RECURRENT NEURAL NET, V0, P0
   Peng HY, 2019, PATTERN RECOGN LETT, V125, P91, DOI 10.1016/j.patrec.2019.03.026
   Sietsma Dow, 1988, ICNN, V0, P0
   Srinivas S, 2015, ICLR, V0, P0
   Van Keirsbilck M, 2019, ARXIV190512340, V0, P0
   Varma G, 2019, ICCV WORKSH, V0, P0
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5797
   Wang WQ, 2019, PATTERN RECOGN LETT, V122, P86, DOI 10.1016/j.patrec.2019.02.024
   Wen W, 2016, ADV NEURAL INFORM PR, V0, P2074
   Wen W, 2017, ARXIV170905027, V0, P0
   Zaras A, 2021, PATTERN RECOGN LETT, V146, P215, DOI 10.1016/j.patrec.2021.03.014
NR 30
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD NOV 15
PY 2021
VL 151
IS 
BP 187
EP 192
DI 10.1016/j.patrec.2021.08.013
EA SEP 2021
PG 6
WC Computer Science, Artificial Intelligence
SC Computer Science
GA US5QV
UT WOS:000697484500006
DA 2023-11-10
ER

PT J
AU Shen, C
   Li, ZH
   Chu, YH
   Zhao, ZY
AF Shen, Chen
   Li, Zhiheng
   Chu, Yonghe
   Zhao, Zhongying
TI GAR: Graph adversarial representation for adverse drug event detection on Twitter
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Adverse drug events; Natural language processing; Graph embeddings; Adversarial training
ID text classification; pharmacovigilance
AB Adverse drug reaction events have become one of the main causes of patient death. Since traditional post-marketing surveillance systems based on spontaneous reports have a serious underreporting issue, in recent years research on the detection of adverse reaction events using social media such as Twitter as a data source has attracted increasing attention in recent year. Deep learning models usually rely on a large number of training samples. However, due to the characteristics of user-generated content and the time-consuming data annotation process, related research is faced with the problems caused by small-scale annotated datasets, which restricts deep learning models in achieving satisfactory results. Accordingly, we introduce two regularization methods are introduced at the representation level, i.e., graph embedding-based data augmentation and adversarial training, to improve the performance of detecting adverse events under such conditions. Besides, the applicable scope of these two methods is analyzed and discussed through experiments. Combined with the convolutional neural network, this paper proposes an adverse drug event detection framework that can make full use of the methods. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Shen, Chen; Li, Zhiheng; Zhao, Zhongying] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
   [Shen, Chen; Chu, Yonghe] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
C3 Shandong University of Science & Technology; Dalian University of Technology
RP Li, ZH (通讯作者)，Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
EM zhihengli@sdust.edu.cn
FU National Natural Science Foundation of China [62072288]
CR Al Dweik R, 2020, EUR J CLIN PHARMACOL, V76, P1723, DOI 10.1007/s00228-020-02958-1
   Alnemer KA, 2015, J MED INTERNET RES, V17, P0, DOI 10.2196/jmir.4898
   Alvaro Nestor, 2017, JMIR PUBLIC HEALTH SURVEILL, V3, Pe24, DOI 10.2196/publichealth.6396
   [Anonymous], 2014, P 20 ACM SIGKDD INT, V0, P0, DOI DOI 10.1145/2623330.2623732
   Chen M, 2019, J INVEST MED, V67, PA3, DOI 10.1136/jim-2019-000994.9
   Chen M, 2022, ENTERP INF SYST-UK, V16, P0, DOI 10.1080/17517575.2020.1856422
   Chowdhury S, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP117, DOI 10.1145/3178876.3186053
   Cocos A, 2017, J AM MED INFORM ASSN, V24, P813, DOI 10.1093/jamia/ocw180
   Du C, 2018, INT J COMPUT COMMUN, V13, P50, DOI 10.15837/ijccc.2018.1.3142
   Gao J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), V0, PP50, DOI 10.1109/SPW.2018.00016
   Goodfellow I, 2017, INT C LEARN REPR, V0, P0
   Grover A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP855, DOI 10.1145/2939672.2939754
   Gupta S, 2018, LECT NOTES COMPUT SC, V10772, P59, DOI 10.1007/978-3-319-76941-7_5
   Hazell L, 2006, DRUG SAFETY, V29, P385, DOI 10.2165/00002018-200629050-00003
   Huynh T, 2016, P COLING 2016 TECHN, V0, P877
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kuhn M, 2016, NUCLEIC ACIDS RES, V44, PD1075, DOI 10.1093/nar/gkv1075
   Lee K, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP705, DOI 10.1145/3038912.3052671
   Li F, 2016, ARXIV160807720, V0, P0
   Li ZH, 2020, J BIOMED INFORM, V106, P0, DOI 10.1016/j.jbi.2020.103431
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Nikfarjam A, 2015, J AM MED INFORM ASSN, V22, P671, DOI 10.1093/jamia/ocu041
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Plumpton CO, 2016, PHARMACOECONOMICS, V34, P771, DOI 10.1007/s40273-016-0397-9
   Samanta S, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Sarker A, 2015, J BIOMED INFORM, V53, P196, DOI 10.1016/j.jbi.2014.11.002
   Shen CW, 2019, COMPUT HUM BEHAV, V101, P474, DOI 10.1016/j.chb.2018.09.031
   Stanovsky G, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P142
   Szegedy Y, 2013, ARXIV13126199, V0, P0
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), V0, PP1067, DOI 10.1145/2736277.2741093
   Wang DX, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1225, DOI 10.1145/2939672.2939753
NR 31
TC 2
Z9 2
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUL 15
PY 2021
VL 106
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107324
EA MAR 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SU8MC
UT WOS:000663384100007
DA 2023-11-10
ER

PT J
AU Li, ZC
   Zhao, H
   He, SX
   Cai, JX
AF Li, Zuchao
   Zhao, Hai
   He, Shexia
   Cai, Jiaxun
TI Syntax Role for Neural Semantic Role Labeling
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Semantic role labeling (SRL) is dedicated to recognizing the semantic predicate-argument structure of a sentence. Previous studies in terms of traditional models have shown syntactic information can make remarkable contributions to SRL performance; however, the necessity of syntactic information was challenged by a few recent neural SRL studies that demonstrate impressive performance without syntactic backbones and suggest that syntax information becomes much less important for neural semantic role labeling, especially when paired with recent deep neural network and large-scale pre-trained language models. Despite this notion, the neural SRL field still lacks a systematic and full investigation on the relevance of syntactic information in SRL, for both dependency and both monolingual and multilingual settings. This paper intends to quantify the importance of syntactic information for neural SRL in the deep learning framework. We introduce three typical SRL frameworks (baselines), sequence-based, tree-based, and graph-based, which are accompanied by two categories of exploiting syntactic information: syntax pruning-based and syntax feature-based. Experiments are conducted on the CoNLL-2005, -2009, and -2012 benchmarks for all languages available, and results show that neural SRL models can still benefit from syntactic information under certain conditions. Furthermore, we show the quantitative significance of syntax to neural SRL models together with a thorough empirical survey using existing models.
C1 [Li, Zuchao; Zhao, Hai; He, Shexia; Cai, Jiaxun] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM charlee@sjtu.edu.cn; zhaohai@cs.sjtu.edu.cn; heshexia@sjtu.edu.cn; caijiaxun@sjtu.edu.cn
FU National Key Research and Development Program of China [2017YFB0304100]; Key Projects of National Natural Science Foundation of China [U1836222, 61733011]
CR [Anonymous], 2016, PROC CONLL, V0, P0
   [Anonymous], 2010, P 23 INT C COMPUTATI, V0, P0
   [Anonymous], 2008, P 2008 C EMPIRICAL M, V0, P0
   [Anonymous], 2009, P 13 C COMPUTATIONAL, V0, P0
   [Anonymous], 2015, P 2015 C EMPIRICAL M, V0, P0
   [Anonymous], 2005, P 43 ANN M ASS COMPU, V0, P0, DOI DOI 10.3115/1219840.1219912
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2016, P 20 C COMPUTATIONAL, V0, P0, DOI DOI 10.18653/V1/K16-2014
   [Anonymous], 2017, P 21 C COMP NAT LANG, V0, P0, DOI DOI 10.18653/V1/K17-1041
   [Anonymous], 2015, ASS COMPUTATIONAL LI, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Baker CF, 1998, 36 ANN M ASS COMPUTA, V0, PP86, DOI 10.3115/980845.980860
   Berant J, 2013, P 2013 C EMPIRICAL M, V0, P0
   Bjorkelund A, 2009, P 13 C COMP NAT LANG, V0, P43
   Cai Jiaxun, 2018, P 27 INT C COMP LING, V0, P2753
   Cai R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1018
   Cai R, 2019, T ASSOC COMPUT LING, V7, P343, DOI 10.1162/tacl_a_00272/1923381
   Carreras Xavier, 2005, P 9 C COMPUTATIONAL, V0, P152
   Chen XC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5415
   Choe DK, 2016, P 2016 C EMP METH NA, V0, PP2331, DOI 10.18653/V1/D16-1257
   Choi JD, 2011, PEDESTRIAN EVACUATIO, V0, PP37, DOI 10.1007/978-1-4419-9725-8_4
   Chomsky N, 1965, ASPECTS THEORY SYNTA, V0, P0
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, PP276, DOI 10.18653/v1/w19-4828
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Devlin J, 2018, ARXIV, V1, P4171
   DOWTY D, 1991, LANGUAGE, V67, P547, DOI 10.2307/415037
   Dozat T, 2017, ICLR, V0, P0
   Fei H, 2021, AAAI CONF ARTIF INTE, V35, P12803
   Fillmore CJ, 1968, UNIVERSALS LINGUISTI, V0, PP1, DOI 10.4236/ENG
   Gildea D, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P239
   Gildea D, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P512
   Gómez-Rodríguez C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1314
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3483
   Hajic J, 2009, P 13 C COMP NAT LANG, V0, PP1, DOI 10.3115/1596409.1596411
   He LH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P364
   He Luheng, 2017, P 55 ANN M ASS COMP, V1, P473, DOI 10.18653/v1/P17-1044
   He SX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2061
   He Shexia, 2019, P 2019 C EMPIRICAL M, V0, PP5349, DOI 10.18653/V1/D19-1538
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   ipf TN, 2017, 5 INT C LEARN REPR I, V0, P0
   Johansson R, 2008, P 12 C COMPUTATIONAL, V0, P183
   Johansson Richard, 2008, P 22 INT C COMPUTATI, V0, P393
   Kasai J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P701
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiperwasser E, 2016, T ASS COMPUTATIONAL, V4, P313, DOI 10.1162/TACL_A_00101
   Kitaev N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2676
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lang Joel, 2010, HUMAN LANGUAGE TECHN, V0, P939
   Lee Kenton, 2017, P 2017 C EMP METH NA, V0, PP188, DOI 10.18653/V1/D17-1018
   Lei Tao, 2015, P 2015 C N AM CHAPTE, V0, P1150
   Levin Beth, 1993, ENGLISH VERB CLASSES, V0, P0
   Li Z, 2020, FINDINGS ASS COMPUTA, V0, PP1134, DOI 10.18653/v1/2020.findings-emnlp.102
   Li ZH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5708
   Li ZC, 2019, AAAI CONF ARTIF INTE, V0, P6730
   Lin YK, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P34, DOI 10.18653/v1/P17-1004
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Luong M-T, 2015, P 2015 C EMP METH NA, V0, P0, DOI DOI 10.18653/V1/D15-1166
   Lyu CC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1071
   Marcheggiani D, 2017, ARXIV170304826, V0, P0, DOI DOI 10.18653/V1/D17-1159
   Marcheggiani D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3915
   Mikolov T, 2013, T ASS COMPUTATIONAL, V26, P[3111, 29], DOI 10.1162/TACLA00120
   Mitchell Tom, 2017, P 2017 C EMPIRICAL M, V0, P1247
   Moschitti A, 2008, COMPUT LINGUIST, V34, P193, DOI 10.1162/coli.2008.34.2.193
   Mulcaire P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P667
   Munir K, 2021, IEEE-ACM T AUDIO SPE, V29, P782, DOI 10.1109/TASLP.2020.3048665
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Naradowsky Jason, 2012, P 2012 JOINT C EMP M, V0, P810
   Ouchi Hiroki, 2018, P EMNLP, V0, P1630
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Palmer M, 2004, P EMNLP 2004, V0, P88
   Peng H, 2018, P 2018 C N AM CHAPTE, V1, P1492, DOI 10.18653/V1/N18-1135
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Pradhan S, 2012, JOINT C EMNLP CONLL, V0, P1
   Pradhan Sameer, 2013, P 17 C COMPUTATIONAL, V0, P143
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   Punyakanok V, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), V0, P1117
   Qian Feng, 2017, P 2 WORKSHOP STRUCTU, V0, P27
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Roth M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1192
   Shi C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2245
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5027
   Surdeanu M, 2008, P 12 C COMP NAT LANG, V0, PP159, DOI 10.3115/1596324.1596352
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tan ZX, 2018, AAAI CONF ARTIF INTE, V0, P4929
   Toutanova K, 2008, COMPUT LINGUIST, V34, P161, DOI 10.1162/coli.2008.34.2.161
   Vinyals O, 2015, ADV NEURAL INFORM PR, V28, P0
   Wang YF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5338
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yih WT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P201
   Zhang Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P616
   Zhao H, 2013, J ARTIF INTELL RES, V46, P203, DOI 10.1613/jair.3717
   Zhao Hai, 2008, P 12 C COMP NAT LANG, V0, P203
   Zhao Hai, 2009, P 2009 C EMPIRICAL M, V0, P30
   Zhao Hongzhong, 2009, PROCEEDINGS OF THE 2009 2ND ASIAN-PACIFIC CONFERENCE ON SYNTHETIC APERTURE RADAR (APSAR 2009), V0, PP55, DOI 10.1109/APSAR.2009.5374342
   Zhou J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1127
   Zhou JR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2396
   Zhou Junru, 2020, FINDINGS ASS COMPUTA, V0, P4438
   Zuchao L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2401
NR 100
TC 4
Z9 4
U1 4
U2 12
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP 15
PY 2021
VL 47
IS 3
BP 529
EP 574
DI 10.1162/COLI_a_00408
PG 46
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YW2AF
UT WOS:000753220200002
DA 2023-11-10
ER

PT J
AU Goyal, A
   Gupta, V
   Kumar, M
AF Goyal, Archana
   Gupta, Vishal
   Kumar, Manish
TI A deep learning-based bilingual Hindi and Punjabi named entity recognition system using enhanced word embeddings
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Named entity recognition (NER); Word embeddings; FastText; Bidirectional Gated Recurrent Unit (Bi-GRU); Natural Language Processing (NLP); Convolutional Neural Networks (CNN)
AB The increasing availability of information on the web makes the task of named entity recognition (NER) more challenging. Named entity recognition is an important pre-processor tool that is concerned with the extraction of entities of our interest such as person, location, organization, gene, protein, number, measurement, etc. The success of earlier named entity recognition systems is highly dependent on rule-based techniques or traditional machine learning algorithms exploiting several linguistic and non-linguistic features. In this article, we propose a novel named entity recognition (NER) system that involves the use of deep learning strategies as well as an enhanced version of word embeddings. We develop a Bidirectional Gated Recurrent Unit (Bi-GRU) and Convolutional Neural Networks (CNN) based bilingual named entity recognition system which is built upon enhanced word embeddings (EWE). Enhanced word embeddings (EWE) are generated by concatenation of FastText word embeddings along with minimal feature embeddings, namely part of speech embeddings, word prefix embeddings, word suffix embeddings, and word length embeddings which improve the computational power of deep learning methods. We perform several experiments using corpora in two different languages. One is IJCNLP-08 NERSSEAL shared task corpora containing annotated dataset in Hindi language and the other is manually annotated dataset in Punjabi language. We also make several experiments on bilingual Hindi and Punjabi dataset. The results of the experiments performed in this work reveal that the Bidirectional GRU and CNN based model along with enhanced word embeddings (EWE) has excelled with Precision, Recall, and F-score value of 92.60%, 90.70%, 91.64% respectively for Hindi, 93.87%, 93.33%, 93.60% respectively for Punjabi and 93.78%, 92.66%, 93.22% respectively for bilingual Hindi and Punjabi named entity recognition. Enhanced word embeddings accelerate the performance of a Bi-GRU and CNN based named entity recognition system without using a large set of features and any sort of gazetteers. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Goyal, Archana] Goswami Ganesh Dutta Sanatan Dharma Coll, Chandigarh, India.
   [Gupta, Vishal] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
   [Kumar, Manish] Panjab Univ Reg Ctr, Muktsar, Punjab, India.
C3 Goswami Ganesh Dutta S. D. College; Panjab University; Panjab University
RP Gupta, V (通讯作者)，Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM vishal@pu.ac.in
CR Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   Alfred Rayner, 2014, INTERNATIONAL JOURNAL OF MACHINE LEARNING AND COMPUTING, V4, P103, DOI 10.7763/IJMLC.2014.V4.428
   Ali MNA, 2018, FUTURE INTERNET, V10, P0, DOI 10.3390/fi10120123
   [Anonymous], 2014, INTELL INF MANAG, V0, P0
   Bharati A, 2007, SSF SHAKTI STANDARD, V0, P1
   Boden M, 2002, GUIDE RECURRENT NEUR, V0, P0
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Dandapat S, 2016, COMPUT SIST, V20, P495, DOI 10.13053/CyS-20-3-2468
   Devlin J, 2018, ARXIV, V1, P4171
   Ekbal A, 2012, PROC INT CONF EMERG, V0, PP331, DOI 10.1109/EAIT.2012.6407942
   Epelbaum T, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Freire Nuno, 2012, THE SEMANTIC WEB: RESEARCH AND APPLICATIONS. PROCEEDINGS 9TH EXTENDED SEMANTIC WEB CONFERENCE (ESWC 2012), V0, PP718, DOI 10.1007/978-3-642-30284-8_55
   Gao Y, 2016, J MACH LEARN RES, V63, P350, DOI 10.48550/arXiv.1604.02910
   Godény B, 2012, INT CONF DAT MIN WOR, V0, PP858, DOI 10.1109/ICDMW.2012.52
   Goyal A, 2019, COMM COM INF SC, V1075, P184, DOI 10.1007/978-981-15-0108-1_18
   Gupta V, 1900, V33, V0, P28
   Hassel M, 2003, NODALIDA 03 14 NORDI, V0, P9
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jain A, 2020, LECT NOTE DATA ENG, V32, P223, DOI 10.1007/978-3-030-25797-2_10
   Kaur A, 2015, PROCEDIA COMPUT SCI, V46, P159, DOI 10.1016/j.procs.2015.02.007
   Korkontzelos I, 2015, ARTIF INTELL MED, V65, P145, DOI 10.1016/j.artmed.2015.05.007
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Mikolov T, 2011, INT CONF ACOUST SPEE, V0, P5528
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nikfarjam A, 2015, J AM MED INFORM ASSN, V22, P671, DOI 10.1093/jamia/ocu041
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Przybyla P, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Saha SK, 2012, KNOWL-BASED SYST, V27, P322, DOI 10.1016/j.knosys.2011.09.015
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Santos Diana, 2006, P LREC 2006, V0, P0
   Sarkar K, 2018, INT J APPL PATTERN R, V5, P11, DOI 10.1504/IJAPR.2018.10011654
   Shah B, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Sharma R, 2011, COMM COM INF SC, V139, P31
   Sharma R, 2020, NEURAL COMPUT APPL, V32, P16191, DOI 10.1007/s00521-020-04881-z
   Sikdar UK, 2012, P COLING 2012, V2012, P2475
   Singh SP, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, V0, P162, DOI 10.1109/COMPTELIX.2017.8003957
   Singh U, 2017, INT J ADV RES COMPUT, V7, P193
   Srivastava S, 2011, INT J COMPUTATIONAL, V2, P10
   Staudemeyer RC, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Tikhomirov M, 2020, LECT NOTES COMPUT SC, V12089, P16, DOI 10.1007/978-3-030-51310-8_2
   Ugawa Arata, 2018, P 27 INT C COMP LING, V0, P3240
   Vinayak A, 2016, ARXIV PREPRINT ARXIV, V0, P154
   Wu Yonghui, 2015, AMIA ANNU SYMP PROC, V2015, P1326
   Yadav V, 2018, P 27 INT C COMP LING, V0, P2145
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
NR 48
TC 8
Z9 8
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD DEC 25
PY 2021
VL 234
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107601
EA OCT 2021
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WW7VC
UT WOS:000718118200003
DA 2023-11-10
ER

PT J
AU Chakravarthula, SN
   Baucom, BRW
   Narayanan, S
   Georgiou, P
AF Chakravarthula, Sandeep Nallan
   Baucom, Brian R. W.
   Narayanan, Shrikanth
   Georgiou, Panayiotis
TI An analysis of observation length requirements for machine understanding of human behaviors from spoken language
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Human behavior; Spoken language; Observation window length; Machine learning
ID observed communication; couple therapy; thin slices; accuracy
AB The task of quantifying human behavior by observing interaction cues is an important and useful one across a range of domains in psychological research and practice. Machine learning-based approaches typically perform this task by first estimating behavior based on cues within an observation window, such as a fixed number of words, and then aggregating the behavior over all the windows in that interaction. The length of this window directly impacts the accuracy of estimation by controlling the amount of information being used. The exact link between window length and accuracy, however, has not been well studied, especially in spoken language. In this paper, we investigate this link and present an analysis framework that determines appropriate window lengths for the task of behavior estimation. Our proposed framework utilizes a two-pronged evaluation approach: (a) extrinsic similarity between machine predictions and human expert annotations, and (b) intrinsic consistency between intra-machine and intra-human behavior relations. We apply our analysis to real-life conversations that are annotated for a large and diverse set of behavior codes and examine the relation between the nature of a behavior and how long it should be observed. We find that behaviors describing negative and positive affect can be accurately estimated from short to medium-length expressions whereas behaviors related to problem-solving and dysphoria require much longer observations and are difficult to quantify from language alone. These findings are found to be generally consistent across different behavior modeling approaches. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Chakravarthula, Sandeep Nallan; Narayanan, Shrikanth; Georgiou, Panayiotis] Univ Southern Calif, Dept Elect & Comp Engn, Viterbi Sch Engn, Los Angeles, CA 90007 USA.
   [Baucom, Brian R. W.] Univ Utah, Dept Psychol, Coll Social & Behav Sci, Salt Lake City, UT 84112 USA.
C3 University of Southern California; Utah System of Higher Education; University of Utah
RP Chakravarthula, SN (通讯作者)，Univ Southern Calif, Dept Elect & Comp Engn, Viterbi Sch Engn, Los Angeles, CA 90007 USA.
EM nallanch@usc.edu
CR AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   [Anonymous], 2010, CONVOLUTIONAL DEEP B, V0, P0, DOI DOI 10.1145/3065386
   [Anonymous], 2002, P INT C SPOKEN LANGU, V0, P0
   Baer JS, 2009, J SUBST ABUSE TREAT, V37, P191, DOI 10.1016/j.jsat.2009.01.003
   Baucom KJW, 2011, J CONSULT CLIN PSYCH, V79, P565, DOI 10.1037/a0025121
   Baumeister RF, 2007, PERS SOC PSYCHOL REV, V11, P167, DOI 10.1177/1088868307301033
   Baumeister Roy F, 2001, REV GEN PSYCHOL, V5, P323, DOI 10.1037/1089-2680.5.4.323
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Black MP, 2013, SPEECH COMMUN, V55, P1, DOI 10.1016/j.specom.2011.12.003
   Blackman MC, 1998, J EXP SOC PSYCHOL, V34, P164, DOI 10.1006/jesp.1997.1347
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Carney DR, 2007, J RES PERS, V41, P1054, DOI 10.1016/j.jrp.2007.01.004
   Chakravarthula SN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P668
   Chakravarthula SN, 2015, INT CONF ACOUST SPEE, V0, PP2090, DOI 10.1109/ICASSP.2015.7178339
   Chakravarthulai SN, 2018, INTERSPEECH, V0, PP2339, DOI 10.21437/Interspeech.2018-1562
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Christensen A, 2004, J CONSULT CLIN PSYCH, V72, P176, DOI 10.1037/0022-006X.72.2.176
   Cullen A, 2017, P 14 INT C AUD VIS S, V0, P0
   Diedenhofen B, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0121945
   Frank Eibe, 2001, MACHINE LEARNING ECM, V0, PP145, DOI 10.1007/3-540-44795-4_13
   Georgiou PC, 2011, LECT NOTES COMPUT SC, V6974, P87, DOI 10.1007/978-3-642-24600-5_12
   Gibson J, 2016, COMMITMENT, V111, P21
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, ARXIV PREPRINT ARXIV, V0, P0
   Zou GY, 2007, PSYCHOL METHODS, V12, P399, DOI 10.1037/1082-989X.12.4.399
   Gupta R, 2014, NAT PROD J, V4, P33, DOI 10.2174/2210315504666140515004826
   Heavey C, 2002, COUPLES INTERACTION, V7, P0
   Heyman RE, 2004, COUPLE OBSERVATIONAL, V0, PP67, DOI 10.4324/9781410610843
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Jones J, 1998, COUPLES INTERACTION, V7, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Krull DS, 1998, PERS SOC PSYCHOL B, V24, P289, DOI 10.1177/0146167298243006
   Krzyzaniak SL, 2019, EUR J PERS, V0, P0
   Lee C-C, 2012, 13 ANN C INT SPEECH, V0, P0
   Lee CC, 2010, 11 ANN C INT SPEECH, V0, P0
   Lee CC, 2014, COMPUT SPEECH LANG, V28, P518, DOI 10.1016/j.csl.2012.06.006
   Li HQ, 2020, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.246
   Liu F, 2017, IEEE GLOB COMM CONF, V0, P0, DOI DOI 10.1109/EMC-B.2017.8260468
   MCCRAE RR, 1986, J PERS, V54, P430, DOI 10.1111/j.1467-6494.1986.tb00403.x
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Miller, 2003, MOTIVATIONAL INTERVI, V0, P0
   Morales M, 2018, P 5 WORKSHOP COMPUTA, V0, PP13, DOI 10.18653/V1/W18-0602
   Murphy NA, 2018, PERS SOC PSYCHOL B, V0, P0
   Narayanan S, 2013, P IEEE, V101, P1203, DOI 10.1109/JPROC.2012.2236291
   Nolan J, 2003, STABLE DISTRIBUTIONS, V0, P0
   Öhman A, 2001, J PERS SOC PSYCHOL, V80, P381, DOI 10.1037//0022-3514.80.3.381
   Olah Chris, 2017, DISTILL, V0, P0, DOI DOI 10.23915/distill.00007
   Perez-Rosas V, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1426, DOI 10.18653/v1/P17-1131
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Reblin M, 2019, PSYCHOONCOLOGY, V0, P0
   Rozgic V, 2011, INT CONF ACOUST SPEE, V0, P2368
   Satterstrom P, 2019, ORGAN BEHAV HUM DEC, V151, P104, DOI 10.1016/j.obhdp.2018.12.007
   Schuller B, 2012, ICMI 12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, P449
   Sevier M, 2008, BEHAV THER, V39, P137, DOI 10.1016/j.beth.2007.06.001
   Smith LN, 2017, IEEE WINT CONF APPL, V0, PP464, DOI 10.1109/WACV.2017.58
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STEINER DD, 1989, J APPL PSYCHOL, V74, P136, DOI 10.1037/0021-9010.74.1.136
   Thornton MA, 2017, P NATL ACAD SCI USA, V114, P5982, DOI 10.1073/pnas.1616056114
   Tseng S-Y, 2017, P INT AUG 2017, V0, P0
   Tseng SY, 2018, ICMI18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP239, DOI 10.1145/3242969.3242996
   Tseng SY, 2016, INTERSPEECH, V0, PP898, DOI 10.21437/Interspeech.2016-1186
   Xia Wei, 2015, 16 ANN C INT SPEECH, V0, P0
   Xiao B, 2012, ASIAPAC SIGN INFO PR, V0, P0
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
NR 64
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR 15
PY 2021
VL 66
IS 
BP 
EP 
DI 10.1016/j.csl.2020.101162
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA PB5PE
UT WOS:000596372000011
DA 2023-11-10
ER

PT J
AU Tian, D
   Li, MC
   Shi, J
   Shen, Y
   Han, S
AF Tian, Dan
   Li, Mingchao
   Shi, Jonathan
   Shen, Yang
   Han, Shuai
TI On-site text classification and knowledge mining for large-scale projects construction by integrated intelligent approach
SO ADVANCED ENGINEERING INFORMATICS
LA English
DT Article
DE Large-scale projects construction; Text classification; Knowledge mining; CNN; Mutual information; TF-IDF
ID 3 gorges project; entity recognition; tf-idf; services
AB A large-scale project produces a lot of text data during construction commonly achieved as various management reports. Having the right information at the right time can help the project team understand the project status and manage the construction process more efficiently. However, text information is presented in unstructured or semi-structured formats. Extracting useful information from such a large text warehouse is a challenge. A manual process is costly and often times cannot deliver the right information to the right person at the right time. This research proposes an integrated intelligent approach based on natural language processing technology (NLP), which mainly involves three stages. First, a text classification model based on Convolution Neural Network (CNN) is developed to classify the construction on-site reports by analyzing and extracting report text features. At the second stage, the classified construction report texts are analyzed with improved frequency-inverse document frequency (TF-IDF) by mutual information to identify and mine construction knowledge. At the third stage, a relation network based on the co-occurrence matrix of the knowledge is presented for visualization and better understanding of the construction on-site information. Actual construction reports are used to verify the feasibility of this approach. The study provides a new approach for handling construction on-site text data which can lead to enhancing management efficiency and practical knowledge discovery for project management.
C1 [Tian, Dan; Li, Mingchao; Han, Shuai] Tianjin Univ, State Key Lab Hydraul Engn Simulat & Safety, Tianjin 300350, Peoples R China.
   [Shi, Jonathan] Louisiana State Univ, Coll Engn, Baton Rouge, LA 70803 USA.
   [Shen, Yang] China Three Gorges Corp, Beijing 100038, Peoples R China.
C3 Tianjin University; Louisiana State University System; Louisiana State University; China Three Gorges Corporation
RP Li, MC (通讯作者)，Tianjin Univ, State Key Lab Hydraul Engn Simulat & Safety, Tianjin 300350, Peoples R China.
EM lmc@tju.edu.cn
FU National Natural Science Foundation of China [51622904]; Open Fund of Hubei Key Laboratory of Construction and Management in Hydropower Engineering [2020KSD05]
CR Chernyshova YS, 2020, IEEE ACCESS, V8, P32587, DOI 10.1109/ACCESS.2020.2974051
   Curiskis SA, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.04.002
   Di Sarno C, 2016, INT J CRIT INFR PROT, V13, P39, DOI 10.1016/j.ijcip.2016.03.002
   Diamantopoulos T, 2018, ENTERP INF SYST-UK, V12, P960, DOI 10.1080/17517575.2017.1416177
   Fang WL, 2020, ADV ENG INFORM, V44, P0, DOI 10.1016/j.aei.2020.101060
   Ferrari A, 2018, EMPIR SOFTW ENG, V23, P3684, DOI 10.1007/s10664-018-9596-7
   Fu HP, 2016, FRONT COMPUT NEUROSC, V10, P0, DOI 10.3389/fncom.2016.00064
   Goh YM, 2017, ACCIDENT ANAL PREV, V108, P122, DOI 10.1016/j.aap.2017.08.026
   Govindarajan UH, 2019, ADV ENG INFORM, V42, P0, DOI 10.1016/j.aei.2019.100955
   Guo Q, 2016, NEUROCOMPUTING, V184, P78, DOI 10.1016/j.neucom.2015.07.135
   Hussain SF, 2019, EXPERT SYST APPL, V131, P116, DOI 10.1016/j.eswa.2019.04.037
   Jiang HC, 2018, TECHNOL FORECAST SOC, V134, P61, DOI 10.1016/j.techfore.2018.05.012
   Jiang HC, 2016, ECOL INDIC, V60, P693, DOI 10.1016/j.ecolind.2015.08.007
   [李明超 Li Mingchao], 2020, 水利学报 JOURNAL OF HYDRAULIC ENGINEERING, V51, P816
   Jung N, 2019, ADV ENG INFORM, V41, P0, DOI 10.1016/j.aei.2019.04.007
   Khatua A, 2019, INFORM PROCESS MANAG, V56, P247, DOI 10.1016/j.ipm.2018.10.010
   Kim J, 2019, KSII T INTERNET INF, V13, P5321, DOI 10.3837/tiis.2019.11.003
   Le TY, 2017, J COMPUT CIVIL ENG, V31, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000701
   Lee J, 2015, EXPERT SYST APPL, V42, P2013, DOI 10.1016/j.eswa.2014.09.063
   Lee N, 2018, MULTIMED TOOLS APPL, V77, P5043, DOI 10.1007/s11042-017-5113-z
   Li Q, 2020, PERS UBIQUIT COMPUT, V24, P259, DOI 10.1007/s00779-019-01289-y
   Li SB, 2018, SCIENTOMETRICS, V117, P721, DOI 10.1007/s11192-018-2905-5
   Liang R, 2017, J INFRASTRUCT SYST, V23, P0, DOI 10.1061/(ASCE)IS.1943-555X.0000364
   Luo LX, 2019, PERS UBIQUIT COMPUT, V23, P405, DOI 10.1007/s00779-018-1183-9
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, PP1, DOI 10.1162/153244303322533223
   Onan A, 2019, IEEE ACCESS, V7, P145614, DOI 10.1109/ACCESS.2019.2945911
   Onan A, 2021, CONCURR COMP-PRACT E, V33, P0, DOI 10.1002/cpe.5909
   Pang SC, 2020, CHINESE J ELECTRON, V29, P233, DOI 10.1049/cje.2019.12.011
   Pence J, 2020, SAFETY SCI, V124, P0, DOI 10.1016/j.ssci.2019.104574
   Qin Y, 2019, FRONT INFORM TECH EL, V20, P872, DOI 10.1631/FITEE.1800520
   Qiu QJ, 2020, EARTH SCI INFORM, V13, P1393, DOI 10.1007/s12145-020-00527-9
   Qiu QJ, 2019, EARTH SCI INFORM, V12, P565, DOI 10.1007/s12145-019-00390-3
   Raza M, 2019, FUTURE GENER COMP SY, V101, P341, DOI 10.1016/j.future.2019.06.022
   [任秋兵 Ren Qiubing], 2019, 水利学报 JOURNAL OF HYDRAULIC ENGINEERING, V50, P1200
   Salama DM, 2016, J COMPUT CIVIL ENG, V30, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000301
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Sun J, 2020, AUTOMAT CONSTR, V111, P0, DOI 10.1016/j.autcon.2019.103048
   Tixier AJP, 2016, AUTOMAT CONSTR, V62, P45, DOI 10.1016/j.autcon.2015.11.001
   Wang DP, 2018, COMPLEXITY, V0, P0, DOI DOI 10.1155/2018/9691868
   Wang YH, 2016, MOD PHYS LETT B, V30, P0, DOI 10.1142/S0217984916501840
   Wei W, 2019, NEUROCOMPUTING, V368, P11, DOI 10.1016/j.neucom.2019.08.047
   Zahedi AG, 2020, SOFT COMPUT, V24, P8233, DOI 10.1007/s00500-019-04486-2
   Zhang F, 2019, AUTOMAT CONSTR, V99, P238, DOI 10.1016/j.autcon.2018.12.016
   Zhang SR, 2017, J CONSTR ENG M, V143, P0, DOI 10.1061/(ASCE)CO.1943-7862.0001403
   Zhang Y, 2020, J INTELL FUZZY SYST, V38, P3117, DOI 10.3233/JIFS-191066
   Zhong BT, 2020, AUTOMAT CONSTR, V113, P0, DOI 10.1016/j.autcon.2020.103089
   Zhong BT, 2020, ADV ENG INFORM, V43, P0, DOI 10.1016/j.aei.2019.101003
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
NR 48
TC 28
Z9 30
U1 19
U2 89
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1474-0346
EI 1873-5320
J9 ADV ENG INFORM
JI Adv. Eng. Inform.
PD AUG 15
PY 2021
VL 49
IS 
BP 
EP 
DI 10.1016/j.aei.2021.101355
EA JUL 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Multidisciplinary
SC Computer Science; Engineering
GA TZ6AB
UT WOS:000684551900005
DA 2023-11-10
ER

PT J
AU Plaza-del-Arco, FM
   Molina-González, MD
   Ureña-López, LA
   Martín-Valdivia, MT
AF Miriam Plaza-del-Arco, Flor
   Dolores Molina-Gonzalez, M.
   Alfonso Urena-Lopez, L.
   Teresa Martin-Valdivia, M.
TI Comparing pre-trained language models for Spanish hate speech detection
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Hate speech; Transfer learning; BERT; BETO; Natural language processing; Text classification
AB Nowadays, due to the great uncontrolled content posted daily on the Web, there has also been a huge increase in the dissemination of hate speech worldwide. Social media, blogs and community forums are examples where people are freely allowed to communicate. However, freedom of expression is not always respectful since offensive or insulting language is sometimes used. Social media companies often rely on users and content moderators to report on this type of content. Nevertheless, due to the large amount of content generated every day on the Web, automatic systems based on Natural Language Processing techniques are required for identifying abusive language online. To date, most of the systems developed to combat this problem are mainly focused on English content, but this issue is a worldwide concern and therefore other languages such as Spanish are involved. In this paper, we address the task of Spanish hate speech identification on social media and provide a deeper understanding of the capabilities of new techniques based on machine learning. In particular, we compare the performance of Deep Learning methods with recently pre-trained language models based on Transfer Learning as well as with traditional machine learning models. Our main contribution is the achievement of promising results in Spanish by applying multilingual and monolingual pre-trained language models such as BERT, XLM and BETO.
C1 [Miriam Plaza-del-Arco, Flor; Dolores Molina-Gonzalez, M.; Alfonso Urena-Lopez, L.; Teresa Martin-Valdivia, M.] Univ Jaen, Adv Studies Ctr Informat & Commun Technol CEATIC, Dept Comp Sci, Campus Lagunillas, E-23071 Jaen, Spain.
C3 Universidad de Jaen
RP Plaza-del-Arco, FM (通讯作者)，Univ Jaen, Adv Studies Ctr Informat & Commun Technol CEATIC, Dept Comp Sci, Campus Lagunillas, E-23071 Jaen, Spain.
EM fmplaza@ujaen.es; mdmolina@ujaen.es; laurena@ujaen.es; maite@ujaen.es
FU European Regional Development Fund (ERDF), LIVING-LANG project [RTI2018-094653-B-C21]; Ministry of Science, Innovation and Universities from the Spanish Government [FPI-PRE2019-089310]
CR [Anonymous], 2013, INT C LEARNING REPRE, V0, P0
   Aragon ME, 2019, SEPLN WORKSH IB LANG, V0, P0
   Badjatiya P, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP759, DOI 10.1145/3041021.3054223
   Basile V, 2019, P 13 INT WORKSH SEM, V0, P54
   Benballa M, 2019, PROC 13 INT WORKSHOP, V0, P469
   Bengio Yoshua, 2012, NEURAL NETWORKS: TRICKS OF THE TRADE. SECOND EDITION: LNCS 7700, V0, PP437, DOI 10.1007/978-3-642-35289-8_26
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Pereira-Kohatsu JC, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19214654
   Comandini G, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, V0, P163
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Devlin J, 2018, ARXIV, V1, P4171
   Djuric N, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), V0, PP248, DOI 10.1145/2736277.2741643
   Fan Yuchen, 2014, 15 ANN C INT SPEECH, V0, P1964
   Fersini E, 2018, P 6 EV CAMP NAT LANG, V0, P0, DOI DOI 10.4000/books.aaccademia.4497
   Fersini Elisabetta, 2018, OVERVIEW TASK AUTOMA, V0, P0
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Florio K, 2019, 2019 8 INT C AFFECTI, V0, P1
   Fortuna P, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3232676
   Frenda S, 2019, J INTELL FUZZY SYST, V36, P4743, DOI 10.3233/JIFS-179023
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI 10.5555/177910.177914
   Gamback B, 2017, P 1 WORKSHOP ABUSIVE, V0, PP85, DOI 10.18653/v1/W17-3013
   Garreta R, 2013, LEARNING SCIKIT LEAR, V0, P0
   Gertner A, 2019, P 13 INT WORKSHOP SE, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hajung Sohn, 2019, 2019 INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS (ICDMW). PROCEEDINGS, V0, PP551, DOI 10.1109/ICDMW.2019.00084
   Hinduja S, 2010, ARCH SUICIDE RES, V14, P206, DOI 10.1080/13811118.2010.494133
   Huang Z, 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Hutto CJ, 2014, ICWSM, V0, P0, DOI DOI 10.1609/ICWSM.V8I1.14550
   Kalampokis E, 2013, INTERNET RES, V23, P544, DOI 10.1108/IntR-06-2012-0114
   Kingma DP, 2014, C TRACK P, V0, P0
   Korde V, 2012, INT J ARTIF INTELL A, V3, P85, DOI 10.5121/IJAIA.2012.3208
   Kowsari K, 2019, INFORMATION, V10, P0, DOI 10.3390/info10040150
   Kumar R, 2018, P 1 WORKSH TROLL AGG, V0, P1
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, V0, PP1621, DOI 10.5555/2891460.2891697
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lingiardi V, 2020, BEHAV INFORM TECHNOL, V39, P711, DOI 10.1080/0144929X.2019.1607903
   Mandl T, 2019, ACM INT CONF PR SER, V0, PP14, DOI 10.1145/3368567.3368584
   Paetzold GH, 2019, P 13 INT WORKSHOP SE, V0, PP519, DOI 10.18653/V1/S19-2093
   Pamungkas EW, 2018, CEUR WORKSHOP P, V2263, P1
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Perez JM, 2019, P 13 INT WORKSH SEM, V0, PP64, DOI 10.18653/V1/S19-2008
   Plaza-Del-Arco FM, 2020, ACM T INTERNET TECHN, V20, P0, DOI 10.1145/3369869
   Ptaszynski M, 2019, P POL EVAL 2019 WORK, V0, P89
   Ribeiro Alison, 1900, P420, V0, P0, DOI DOI 10.18653/V1/S19-2074
   Roberts ST, 2019, P 3 WORKSH AB LANG O, V0, P0
   Ruiz AM, 2005, SENSOR ACTUAT B-CHEM, V108, P34, DOI 10.1016/j.snb.2004.09.045
   Sanguinetti M, 2018, P 11 INT C LANG RES, V0, P1
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shalev-Shwartz S, 2014, UNDERSTANDING MACHIN, V0, P0, DOI DOI 10.1017/CBO9781107298019
   Siegel JM, 2019, P 15 KONVENS, V0, P354
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Torrey L, 2010, HDB RES MACHINE LEAR, V0, PP242, DOI 10.4018/978-1-60566-766-9.CH011
   Tulkens S, 2016, DICT BASED APPROACH, V0, P0
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Vasa K, 2016, INT J ENG DEV RES, V4, P655
   Vaswani A, 2017, ARXIV, V30, P5998
   Vega LEA, 2019, P 13 INT WORKSH SEM, V0, PP447, DOI 10.18653/V1/S19-2079
   Waseem Z, 2016, WORKSH NLP COMP SOC, V0, P138
   Waseem Z, 2017, ABS170509899, V0, P0
   Winter Kevin, 2019, P 13 INT WORKSHOP SE, V0, P431
   Zampieri M, 2019, P 13 INT WORKSHOP SE, V0, PP75, DOI 10.18653/V1/S19-2010
   Zhang H, 2019, P 13 INT WORKSHOP SE, V0, PP441, DOI 10.18653/v1/S19-2078
   Zhang Jingzhao, 2019, ABS191203194 ARXIV, V0, P0
   Zhang Xiang, 2015, NEURIPS, V0, P0, DOI DOI 10.5555/2969239.2969312
NR 66
TC 43
Z9 43
U1 2
U2 43
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 15
PY 2021
VL 166
IS 
BP 
EP 
DI 10.1016/j.eswa.2020.114120
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA PE7DI
UT WOS:000598522500001
DA 2023-11-10
ER

PT J
AU Huang, YX
   Yu, ZT
   Guo, JJ
   Xiang, Y
   Xian, YT
AF Huang, Yuxin
   Yu, Zhengtao
   Guo, Junjun
   Xiang, Yan
   Xian, Yantuan
TI Element graph-augmented abstractive summarization for legal public opinion news with graph transformer
SO NEUROCOMPUTING
LA English
DT Article
DE Abstractive summarization; Legal public opinion news; Element graph; Graph transformer
AB Automatic summarization for legal public opinion news has been an attractive research problem in recent years. Compared with the open-domain, summarization for legal public opinion news has two essential constraints: (1) the key information (e.g., the case elements) of the news should be summarized; (2) the factual errors should be avoided in the generated summary. To address these challenges, the sum-marizer should learn a structured representation of the news (event plan), making it better to understand the event information implied in the news. This paper proposes a novel element graph-augmented abstractive summarization model, which first constructs the structural graph by extracting elements from the source document and then produces graph representation via graph transformer network. Finally, the structural representation is taken as an essential complementary component of the conven-tional sequence-to-sequence model to guide the decoding process simultaneously. Furthermore, the pre-trained language model is introduced to enhance the sequential and structural encoder, which further promotes the summarization model's performance. For evaluation, we build a large-scale legal public opinion news (LPO-news) corpus. Experimental results on LPO-news and another news-oriented CNN/ Daily mail dataset show that our model significantly outperforms other baselines in terms of both ROUGE scores and Bert scores. We also perform a human evaluation to demonstrate our model's effec-tiveness by evaluating the generated summary using several subjective metrics. CO 2021 Published by Elsevier B.V.
C1 [Yu, Zhengtao] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
   Kunming Univ Sci & Technol, Yunnan Key Lab Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of Science & Technology
RP Yu, ZT (通讯作者)，Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
EM ztyu@hotmail.com
FU National Key Research and Development Program of China [2018YFC0830105, 2018YFC0830101, 2018YFC0830100]; National Natural Science Foundation of China [61972186, 61762056, 61472168]; Yunnan provincial major science and technology special plan projects [202002AD080001]; General projects of basic research in Yunnan Province [202001AT070047]
CR Bahdanau D, 2016, ARXIV, V0, P0
   Bastings J, 2017, P EMNLP 2017, V0, PP1957, DOI 10.18653/V1/D17-1209
   Beck D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P273
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cheng Ma, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP7766, DOI 10.1109/CVPR42600.2020.00779
   Damonte M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3649
   Dieng AB, 2020, T ASSOC COMPUT LING, V8, P439, DOI 10.1162/tacl_a_00325
   Dong YR, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3378
   Fernandes P, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Gehring J, 2017, PR MACH LEARN RES, V70, P0
   Gehrmann S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4098
   Gupta S, 2019, EXPERT SYST APPL, V121, P49, DOI 10.1016/j.eswa.2018.12.011
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Huang Luyang, 2020, P 58 ANN M ASS COMP, V0, PP5094, DOI 10.18653/V1/2020.ACL-MAIN.457
   Kingma DP, 2014, C TRACK P, V0, P0
   Kingma DP, 2013, AUTOENCODING VARIATI, V0, P0
   Kipf T N, 2016, ICLR, V0, P0
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Lebret Remi, 2016, P 2016 C EMP METH NA, V0, PP1203, DOI 10.18653/v1/D16-1128
   Li ChunYu, 2018, PROCEEDINGS, V0, P55
   Li HR, 2020, AAAI CONF ARTIF INTE, V34, P8196
   Li W, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4843
   Li Wei, 2020, P 58 ANN M ASS COMP, V0, PP6232, DOI 10.18653/V1/2020.ACLMAIN.555
   Li Y, 2015, 4 INT C LEARNING REP, V0, P0
   Lin JY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P163
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Marcheggiani D, 2018, P 2018 M N AM CHAPTE, V2, P486, DOI 1804.08313
   Miao Y, 2017, P 34 INT C MACH LEAR, V0, P2410
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Song LF, 2019, T ASSOC COMPUT LING, V7, P19, DOI 10.1162/tacl_a_00252
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Trisedya BD, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1627
   Velickovic P, 2018, P ICLR, V0, P0
   Wan Xiaojun, 2008, P C EMP METH NAT LAN, V0, P755
   Wang D, 2020, P 58 ANN M ASS COMP, V0, PP6209, DOI 10.18653/V1/2020.ACL-MAIN.553
   Wang L, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4453
   Xu HY, 2020, INT CONF ACOUST SPEE, V0, PP8219, DOI 10.1109/icassp40776.2020.9054187
   Xu WR, 2020, EURASIP J ADV SIG PR, V2020, P0, DOI 10.1186/s13634-020-00674-7
   Yasunaga M, 2017, ARXIV170606681, V0, P0
   Yun S, 2019, ADV NEUR IN, V32, P0
   Zhang T, 2019, PR MACH LEARN RES, V97, P0
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P317
   Zhou QY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1095, DOI 10.18653/v1/P17-1101
   Zhu J, 2019, INT C LEARN REPR, V0, P0
NR 49
TC 1
Z9 1
U1 3
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 14
PY 2021
VL 460
IS 
BP 166
EP 180
DI 10.1016/j.neucom.2021.07.013
EA JUL 2021
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UR7IV
UT WOS:000696919200016
DA 2023-11-10
ER

PT J
AU Skrlj, B
   Martinc, M
   Lavrac, N
   Pollak, S
AF Skrlj, Blaz
   Martinc, Matej
   Lavrac, Nada
   Pollak, Senja
TI autoBOT: evolving neuro-symbolic representations for explainable low resource text classification
SO MACHINE LEARNING
LA English
DT Article
DE Representation learning; Natural language processing; AutoML; Neuro-symbolic computing
AB Learning from texts has been widely adopted throughout industry and science. While state-of-the-art neural language models have shown very promising results for text classification, they are expensive to (pre-)train, require large amounts of data and tuning of hundreds of millions or more parameters. This paper explores how automatically evolved text representations can serve as a basis for explainable, low-resource branch of models with competitive performance that are subject to automated hyperparameter tuning. We present autoBOT (automatic Bags-Of-Tokens), an autoML approach suitable for low resource learning scenarios, where both the hardware and the amount of data required for training are limited. The proposed approach consists of an evolutionary algorithm that jointly optimizes various sparse representations of a given text (including word, subword, POS tag, keyword-based, knowledge graph-based and relational features) and two types of document embeddings (non-sparse representations). The key idea of autoBOT is that, instead of evolving at the learner level, evolution is conducted at the representation level. The proposed method offers competitive classification performance on fourteen real-world classification tasks when compared against a competitive autoML approach that evolves ensemble models, as well as state-of-the-art neural language models such as BERT and RoBERTa. Moreover, the approach is explainable, as the importance of the parts of the input space is part of the final solution yielded by the proposed optimization procedure, offering potential for meta-transfer learning.
C1 [Skrlj, Blaz; Martinc, Matej; Lavrac, Nada; Pollak, Senja] Jozef Stefan Inst, Jamova 39, Ljubljana 1000, Slovenia.
   [Skrlj, Blaz; Martinc, Matej] Jozef Stefan Int Postgrad Sch, Jamova 39, Ljubljana 1000, Slovenia.
   [Lavrac, Nada] Univ Nova Gorica, Glavni Trg 8, Vipava 5271, Slovenia.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute; University of Nova Gorica
RP Skrlj, B (通讯作者)，Jozef Stefan Inst, Jamova 39, Ljubljana 1000, Slovenia.; Skrlj, B (通讯作者)，Jozef Stefan Int Postgrad Sch, Jamova 39, Ljubljana 1000, Slovenia.
EM blaz.skrlj@ijs.si
FU Slovenian Research Agency (ARRS) [P2-0103, N2-0078]; European Union [825153]; TAILOR (EU Horizon 2020 research and innovation programme) [952215]; AI4EU [825619]; Slovenian Research Agency
CR Agarwal B, 2014, ADV INTELL SYST, V236, P701, DOI 10.1007/978-81-322-1602-5_75
   Arora, 2019, SARCASM DETECTION US, V0, P0
   Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254
   Beyer HG, 2002, THEOR COMPUT SCI, V287, P101, DOI 10.1016/S0304-3975(02)00137-8
   Bird Steven, 2009, NATURAL LANGUAGE PRO, V0, P0
   Bougouin A, 2013, INT JOINT C NATURAL, V0, P543
   Campos R, 2018, LECT NOTES COMPUT SC, V10772, P684, DOI 10.1007/978-3-319-76941-7_63
   Chambers LD, 2000, PRACTICAL HDB GENETI, V0, P0, DOI DOI 10.1201/9781420035568
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1961189.1961199
   Davis L, 1991, HDB GENETIC ALGORITH, V0, P0
   Rainville FM, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION COMPANION (GECCO12), V0, P85
   Deb K, 2014, IEEE T EVOLUT COMPUT, V18, P577, DOI 10.1109/TEVC.2013.2281535
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Denysiuk R, 2019, EXPERT SYST APPL, V116, P65, DOI 10.1016/j.eswa.2018.09.004
   Dorronsoro B, 2017, IEEE INT C CYBERNET, V0, P93
   Dua D, 2017, UCI MACHINE LEARNING, V0, P0
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   El-Beltagy SR, 2009, INFORM SYST, V34, P132, DOI 10.1016/j.is.2008.05.002
   English TM, 1996, EVOLUTIONARY PROGRAMMING V. PROCEEDINGS OF THE FIFTH ANNUAL CONFERENCE ON EVOLUTIONARY PROGRAMMING, V0, P163
   Fellbaum, 2012, WORDNET ENCY APPL LI, V0, P0
   Feurer M, 2019, SPRING SER CHALLENGE, V0, PP113, DOI 10.1007/978-3-030-05318-5_6
   Gijsbers P, 2019, J OPEN SOUR SOFTW, V4, P1132, DOI 10.21105/JOSS.01132
   Greene D, 2006, P 23 INT C MACH LEAR, V0, P377
   Hajj N, 2019, NEURAL COMPUT APPL, V31, P8069, DOI 10.1007/s00521-018-3549-3
   Hastie T, 2009, ELEMENTS STAT LEARNI, V2, P1
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hee, 1990, INT C PAR PROBL SOLV, V0, PP3, DOI 10.1007/BFB0029725
   Ishibuchi H, 2008, IEEE C EVOL COMPUTAT, V0, PP2419, DOI 10.1109/CEC.2008.4631121
   Jennings PC, 2019, NPJ COMPUT MATER, V5, P0, DOI 10.1038/s41524-019-0181-4
   Jing K, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), V0, PP1, DOI 10.1145/3079856.3080246
   Khosrovian K, 2008, LECT NOTES COMPUT SC, V5007, P294, DOI 10.1007/978-3-540-79588-9_26
   Kipf T N, 2016, ICLR, V0, P0
   Komer B, 2014, ICML WORKSH AUTOML, V0, PP50, DOI 10.25080/MAJORA-14BD3278-006
   Kotthoff L, 2017, J MACH LEARN RES, V18, P0
   Kowsari K, 2019, INFORMATION, V10, P0, DOI 10.3390/info10040150
   Kumar R, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON VISION, V0, P0, DOI 10.1145/3271553.3271617
   Lavrac N, 2020, MACH LEARN, V109, P1465, DOI 10.1007/s10994-020-05890-8
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Madrid J, 2019, AUTOTEXT AUTOML TEXT, V0, P0
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Mitchell M, 1998, INTRO GENETIC ALGORI, V0, P0
   Mohr F, 2018, MACH LEARN, V107, P1495, DOI 10.1007/s10994-018-5735-z
   Moradi M, 2020, COMPUT METH PROG BIO, V184, P0, DOI 10.1016/j.cmpb.2019.105117
   Myers IB, 1962, MYERS BRIGGS TYPE IN, V0, P0, DOI DOI 10.1037/14404-000
   Nakov P, 2013, 2 JOINT C LEXICAL CO, V0, P312
   Olson RS, 2019, SPRING SER CHALLENGE, V0, PP151, DOI 10.1007/978-3-030-05318-5_8
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pilát M, 2016, PROC INT C TOOLS ART, V0, PP577, DOI 10.1109/ICTAI.2016.0094
   Pollak, 2017, WORKING NOTES PAPERS, V0, P0
   Pollak S, 2011, PRAGMATICS, V21, P647, DOI 10.1075/prag.21.4.07pol
   Qian MJ, 2014, P ACM INT C INF KNOW, V0, PP1963, DOI 10.1145/2661829.2661993
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   RAPPL G, 1989, Z ANGEW MATH MECH, V69, P37, DOI 10.1002/zamm.19890690119
   Reif M, 2012, MACH LEARN, V87, P357, DOI 10.1007/s10994-012-5286-7
   Rose S, 2010, TEXT MINING APPL THE, V0, P0, DOI DOI 10.1002/9780470689646.CH1
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Skrlj Blaz, 2019, STATISTICAL LANGUAGE AND SPEECH PROCESSING. 7TH INTERNATIONAL CONFERENCE, V0, P311, DOI 10.1007/978-3-030-31372-2_26
   Snoek J, 2012, ADV NEURAL INFORM PR, V25, P2951
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Stanley KO, 2019, NAT MACH INTELL, V1, P24, DOI 10.1038/s42256-018-0006-z
   Sterckx L, 2015, WWW15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP121, DOI 10.1145/2740908.2742730
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD13), V0, PP847, DOI 10.1145/2487575.2487629
   Udell, 2019, P 25 ACM SIGKDD INT, V0, P0
   Vafaie H, 1998, IEEE INTELL SYST APP, V13, P57, DOI 10.1109/5254.671093
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wan XJ, 2010, ACM T INFORM SYST, V28, P0, DOI 10.1145/1740592.1740596
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wolpert DH, 1997, IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, V1, P67, DOI 10.1109/4235.585893
   Zimmer M, 2018, IEEE T COGN DEV SYST, V10, P102, DOI 10.1109/TCDS.2016.2628817
   Zoph B, 2018, PROC CVPR IEEE, V0, PP8697, DOI 10.1109/CVPR.2018.00907
NR 76
TC 5
Z9 5
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD MAY 15
PY 2021
VL 110
IS 5
BP 989
EP 1028
DI 10.1007/s10994-021-05968-x
EA APR 2021
PG 40
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SG9VK
UT WOS:000640146200005
PM 34720391
DA 2023-11-10
ER

PT J
AU Makrynioti, N
   Vassalos, V
AF Makrynioti, Nantia
   Vassalos, Vasilis
TI Declarative Data Analytics: A Survey
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Task analysis; Data analysis; Programming; Optimization; Mathematical model; Analytical models; Prediction algorithms; Declarative programming; data science; machine learning; large-scale analytics
ID linear algebra
AB The area of declarative data analytics explores the application of the declarative paradigm on data science and machine learning. It proposes declarative languages for expressing data analysis tasks and develops systems which optimize programs written in those languages. The execution engine can be either centralized or distributed, as the declarative paradigm advocates independence from particular physical implementations. The survey explores a wide range of declarative data analysis frameworks by examining both the programming model and the optimization techniques used, in order to provide conclusions on the current state of the art in the area and identify open challenges.
C1 [Makrynioti, Nantia; Vassalos, Vasilis] Athens Univ Econ & Business, Dept Informat, Athens 10434, Greece.
C3 Athens University of Economics & Business
RP Makrynioti, N (通讯作者)，Athens Univ Econ & Business, Dept Informat, Athens 10434, Greece.
EM makriniotik@aueb.gr; vassalos@aueb.gr
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Alexandrov A, 2016, SIGMOD REC, V45, P51, DOI 10.1145/2949741.2949754
   Alexandrov A, 2014, VLDB J, V23, P939, DOI 10.1007/s00778-014-0357-y
   [Anonymous], 2009, SIGKDD EXPLOR NEWSL, V11, P10, DOI 10.1145/1656274.1656278
   [Anonymous], 2008, OSDI 08, V0, P0
   [Anonymous], 2015, P WORKSHOP MACHINE L, V0, P0
   [Anonymous], 2010, P 1 ACM S CLOUD COMP, V0, P0
   Aref M, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1371, DOI 10.1145/2723372.2742796
   Armbrust M, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1383, DOI 10.1145/2723372.2742797
   Baydin AG, 2018, J MACH LEARN RES, V18, P0
   Beyer KS, 2011, PROC VLDB ENDOW, V4, P1272
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS), V0, P0
   Bu YY, 2010, PROC VLDB ENDOW, V3, P285
   Cai Zhuhua, 2013, SIGMOD, V0, P0, DOI DOI 10.1145/2463676.2465283
   Chaiken R, 2008, PROC VLDB ENDOW, V1, P1265, DOI 10.14778/1454159.1454166
   Chaudhuri S, 1999, ACM T DATABASE SYST, V24, P177, DOI 10.1145/320248.320249
   Chen LJ, 2017, PROC VLDB ENDOW, V10, P1214, DOI 10.14778/3137628.3137633
   Chollet F, 2015, KERAS, V0, P0
   Davenport James H, 1988, COMPUTER ALGEBRA SYS, V0, P0
   De Sa C, 2016, SIGMOD REC, V45, P60, DOI 10.1145/2949741.2949756
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE 04), V0, P137
   Doulkeridis C, 2014, VLDB J, V23, P355, DOI 10.1007/s00778-013-0319-9
   Ekanayake J, 2010, P 19 ACM INT S HIGH, V0, PP810, DOI 10.1145/1851476.1851593
   GAO ZJ, 2017, P ACM INT C MAN DAT, V0, P961
   Ghoting A, 2011, PROC INT CONF DATA, V0, PP231, DOI 10.1109/ICDE.2011.5767930
   GRAEFE G, 1993, COMPUT SURV, V25, P73, DOI 10.1145/152610.152611
   GRAEFE G, 1994, IEEE T KNOWL DATA EN, V6, P120, DOI 10.1109/69.273032
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Hueske F, 2012, PROC VLDB ENDOW, V5, P1256
   Hueske F, 2013, PROC INT CONF DATA, V0, PP1292, DOI 10.1109/ICDE.2013.6544927
   Isard M, 2007, OPERATING SYSTEMS REVIEW, V41, P59, DOI 10.1145/1272998.1273005
   Khamis MA, 2018, PODS18: PROCEEDINGS OF THE 37TH ACM SIGMOD-SIGACT-SIGAI SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, V0, PP325, DOI 10.1145/3196959.3196960
   Kifer M, 2018, DECLARATIVE LOGIC PR, V0, P0
   Kraska T, 2013, 6 BIENNIAL C INNOVAT, V0, P0
   Kumar A, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1969, DOI 10.1145/2723372.2723713
   Kumar A, 2015, SIGMOD REC, V44, P17, DOI 10.1145/2935694.2935698
   Kunft A, 2019, PROC VLDB ENDOW, V12, P1553, DOI 10.14778/3342263.3342633
   Li XP, 2017, PROC VLDB ENDOW, V10, P1933, DOI 10.14778/3137765.3137812
   Luo SY, 2017, PROC INT CONF DATA, V0, PP523, DOI 10.1109/ICDE.2017.108
   Makrynioti N, 2018, PROCEEDINGS OF THE SECOND WORKSHOP ON DATA MANAGEMENT FOR END-TO-END MACHINE LEARNING, V0, P0, DOI DOI 10.1145/3209889.3209893
   Meng X, 2016, J MACH LEARN RES, V17, P1, DOI 10.1145/2882903.2912565
   Olston C, 2008, P 2008 ACM SIGMOD IN, V0, PP1099, DOI 10.1145/1376616.1376726
   Papadopoulos S, 2016, PROC VLDB ENDOW, V10, P349
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Reinwald, 2016, ABS160505826 CORR, V0, P0
   Rheinländer A, 2017, ACM COMPUT SURV, V50, P0, DOI 10.1145/3078752
   Schleich M, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP3, DOI 10.1145/2882903.2882939
   Seib J, 1991, PROCEEDINGS OF THE TENTH ACM SIGACT-SIGMOD-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, V0, PP241, DOI 10.1145/113413.113435
   Seide F, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2135, DOI 10.1145/2939672.2945397
   Soroush E, 2015, PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, V0, P0, DOI DOI 10.1145/2791347.2791362
   Sparks ER, 2017, PROC INT CONF DATA, V0, PP535, DOI 10.1109/ICDE.2017.109
   Sparks ER, 2013, IEEE DATA MINING, V0, PP1187, DOI 10.1109/ICDM.2013.158
   Stonebraker Michael, 2011, SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT. PROCEEDINGS 23RD INTERNATIONAL CONFERENCE, V0, P1, DOI 10.1007/978-3-642-22351-8_1
   Thomas A, 2018, PROC VLDB ENDOW, V11, P2168, DOI 10.14778/3275366.3275367
   Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD13), V0, PP847, DOI 10.1145/2487575.2487629
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Valduriez, 2011, PRINCIPLES DISTRIBUT, V0, P0
   Zaharia M, 2010, P 2 USENIX C HOT TOP, V0, P10
   Zdonik, 2015, P BIENN C INN DAT SY, V0, P0
   Zhou JR, 2010, PROC INT CONF DATA, V0, PP1060, DOI 10.1109/ICDE.2010.5447802
NR 66
TC 4
Z9 4
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD JUN 1
PY 2021
VL 33
IS 6
BP 2392
EP 2411
DI 10.1109/TKDE.2019.2958084
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA SA8XU
UT WOS:000649587600006
DA 2023-11-10
ER

PT J
AU Aydogan, S
   Kremer, GEO
   Akay, D
AF Aydogan, Sena
   Okudan Kremer, Gul E.
   Akay, Diyar
TI Linguistic summarization to support supply network decisions
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article
DE Supply network design; Linguistic summarization; Fuzzy set theory; Decision support
ID big data analytics; chain network; fuzzy; representation; perspective; management; discovery; design; level
AB A supply chain network architecture is a key element of designing and modeling a supply chain to better understand the cost and time associated with the distribution of products with available resources and market locations. Due to the large size of combinations for product design and supplier choices; descriptive, predictive and prescriptive analytics are needed to design, control and then improve a supply chain network. Current study is the first instance in the supply network management field using linguistic summarization (LS), a descriptive analytics tool generating natural language-based summaries of raw data with the help of fuzzy sets. This study has developed a LS method for revealing information from a realistic complex network of a bike supply chain, and it produces network description phrases by using fuzzy set theory to model linguistic/textual terms. The truth degree of generated summaries is calculated by fuzzy cardinality-based methods instead of scalar cardinality-based methods to overcome inherent disadvantages. The results of the study are interpreted in two ways: word clouds are used for single objective cases, and list of sentences that exceed a threshold value are used for bi-objective cases. LS-based findings, explanations and strategic decisions are directed at decision support to increase supply network performance, efficiency and sustainability.
C1 [Aydogan, Sena; Akay, Diyar] Gazi Univ, Dept Ind Engn, TR-06570 Ankara, Turkey.
   [Okudan Kremer, Gul E.] Iowa State Univ, Dept Ind & Mfg Syst Engn, Ames, IA 50011 USA.
C3 Gazi University; Iowa State University
RP Aydogan, S (通讯作者)，Gazi Univ, Dept Ind Engn, TR-06570 Ankara, Turkey.
EM senaaydogan@gazi.edu.tr; gkremer@iastate.edu; diyar@gazi.edu.tr
FU Council of Higher Education of Turkey (YoK) through Doctoral Studies Abroad for Research Assistants (YUDAB) Scholarship
CR Altintop T, 2017, INT J UNCERTAIN FUZZ, V25, P599, DOI 10.1142/S021848851750026X
   [Anonymous], 2009, ANGELES TIMES SEPTEM, V0, P0
   Baghalian A, 2013, EUR J OPER RES, V227, P199, DOI 10.1016/j.ejor.2012.12.017
   Bai XJ, 2016, J INTELL MANUF, V27, P1131, DOI 10.1007/s10845-014-0939-y
   Barro S, 2003, IEEE T FUZZY SYST, V11, P89, DOI 10.1109/TFUZZ.2002.806319
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Boran FE, 2016, EXPERT SYST APPL, V61, P356, DOI 10.1016/j.eswa.2016.05.044
   Carrasco RA, 2012, SOFT COMPUT, V16, P135, DOI 10.1007/s00500-011-0740-1
   Casasus-Estelles T, 2014, COMMUN COMPUT PHYS, V0, P0, DOI DOI 10.1007/978-3-319-08855-6_5
   Chen SM, 2016, INFORM SCIENCES, V327, P110, DOI 10.1016/j.ins.2015.07.054
   Chiu MC, 2014, J INTELL MANUF, V25, P129, DOI 10.1007/s10845-012-0680-3
   Chiu MC, 2011, J MECH DESIGN, V133, P0, DOI 10.1115/1.4003289
   Choi TY, 2001, J OPER MANAG, V19, P351, DOI 10.1016/S0272-6963(00)00068-1
   Delgado M, 2000, INT J APPROX REASON, V23, P23, DOI 10.1016/S0888-613X(99)00031-6
   Delgado M, 2014, FUZZY SET SYST, V242, P1, DOI 10.1016/j.fss.2013.10.012
   Dubois D, 2005, IEEE T FUZZY SYST, V13, P250, DOI 10.1109/TFUZZ.2004.840130
   Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8
   Dubois D, 2006, DATA MIN KNOWL DISC, V13, P167, DOI 10.1007/s10618-005-0032-4
   Dunn JC, 1973, JOURNAL OF CYBERNETICS, V3, P32, DOI 10.1080/01969727308546046
   Eciolaza L, 2013, APPL SOFT COMPUT, V13, P3956, DOI 10.1016/j.asoc.2012.09.007
   Genc S, 2020, SOFT COMPUT, V24, P1511, DOI 10.1007/s00500-019-03982-9
   Hamta N, 2018, J INTELL MANUF, V29, P259, DOI 10.1007/s10845-015-1106-9
   Han J, 2012, MOR KAUF D, V0, P1
   Hasani A, 2015, INT J PROD RES, V53, P1596, DOI 10.1080/00207543.2014.965349
   Hatipoglu H, 2014, INT J INTELL SYST, V29, P946, DOI 10.1002/int.21671
   Ji GJ, 2017, J SYST SCI SYST ENG, V26, P183, DOI 10.1007/s11518-016-5320-6
   Kacprzyk J, 2000, KYBERNETIKA, V36, P657
   Kacprzyk J, 2010, IEEE T FUZZY SYST, V18, P461, DOI 10.1109/TFUZZ.2010.2040480
   Klibi W, 2010, EUR J OPER RES, V203, P283, DOI 10.1016/j.ejor.2009.06.011
   Leng KJ, 2019, NEURAL COMPUT APPL, V31, P113, DOI 10.1007/s00521-018-3666-z
   Maghsoodi AI, 2018, COMPUT IND ENG, V118, P409, DOI 10.1016/j.cie.2018.03.011
   Martin T, 2010, INT J INTELL SYST, V25, P1217, DOI 10.1002/int.20450
   Park K, 2018, J CLEAN PROD, V187, P590, DOI 10.1016/j.jclepro.2018.03.035
   Perera S, 2017, 3 INT MOR ENG RES C, V0, P0, DOI DOI 10.1109/MERCon.2017.7980470
   Philip N, 2013, COMPUTER AIDED GENER, V0, P0, DOI DOI 10.1115/detc2012-71180
   Rasmussen D, 1999, FUZZY SET SYST, V106, P131, DOI 10.1016/S0165-0114(97)00268-6
   Rickard JT, 2013, P 2013 JOINT IFSA WO, V0, P0, DOI DOI 10.1109/IFSA-NAFIPS.2013.6608484
   Sanchez D, 2012, APPL FERR HELD JOINT, V0, PP1, DOI 10.1109/NAFIPS.2012.6291004
   Seok H, 2018, J INTELL MANUF, V29, P1097, DOI 10.1007/s10845-015-1159-9
   Smits G, 2018, FUZZY SET SYST, V348, P4, DOI 10.1016/j.fss.2018.02.017
   Tiwari S, 2018, COMPUT IND ENG, V115, P319, DOI 10.1016/j.cie.2017.11.017
   van der Spoel S, 2017, INT J PROD RES, V55, P5062, DOI 10.1080/00207543.2015.1064183
   Wang G, 2016, INT J PROD ECON, V176, P98, DOI 10.1016/j.ijpe.2016.03.014
   Wilbik A, 2011, C P IEEE INT C SYST, V0, P0, DOI DOI 10.1109/ICSMC.2011.6084067
   Yager RR, 2008, INT J INTELL SYST, V23, P1196, DOI 10.1002/int.20314
   Yager RR, 2013, P ANN HICSS, V0, PP1435, DOI 10.1109/HICSS.2013.491
   Yager RR, 2010, IEEE T SYST MAN CY A, V40, P413, DOI 10.1109/TSMCA.2009.2036591
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   YAGER RR, 1982, INFORM SCIENCES, V28, P69, DOI 10.1016/0020-0255(82)90033-0
   ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 51
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD AUG 15
PY 2021
VL 32
IS 6
BP 1573
EP 1586
DI 10.1007/s10845-020-01677-9
EA OCT 2020
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
SC Computer Science; Engineering
GA TC3IN
UT WOS:000574811500002
DA 2023-11-10
ER

PT J
AU Elanwar, R
   Qin, WD
   Betke, M
   Wijaya, D
AF Elanwar, Randa
   Qin, Wenda
   Betke, Margrit
   Wijaya, Derry
TI Extracting text from scanned Arabic books: a large-scale benchmark dataset and a fine-tuned Faster-R-CNN model
SO INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION
LA English
DT Article
ID layout analysis; segmentation; documents; images
AB Datasets of documents in Arabic are urgently needed to promote computer vision and natural language processing research that addresses the specifics of the language. Unfortunately, publicly available Arabic datasets are limited in size and restricted to certain document domains. This paper presents the release of BE-Arabic-9K, a dataset of more than 9000 high-quality scanned images from over 700 Arabic books. Among these, 1500 images have been manually segmented into regions and labeled by their functionality. BE-Arabic-9K includes book pages with a wide variety of complex layouts and page contents, making it suitable for various document layout analysis and text recognition research tasks. The paper also presents a page layout segmentation and text extraction baseline model based on fine-tuned Faster R-CNN structure (FFRA). This baseline model yields cross-validation results with an average accuracy of 99.4% and F1 score of 99.1% for text versus non-text block classification on 1500 annotated images of BE-Arabic-9K. These results are remarkably better than those of the state-of-the-art Arabic book page segmentation system ECDP. FFRA also outperforms three other prior systems when tested on a competition benchmark dataset, making it an outstanding baseline model to challenge.
C1 [Elanwar, Randa] Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
   [Qin, Wenda; Betke, Margrit] Boston Univ, Boston, MA 02215 USA.
   [Wijaya, Derry] Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI); Boston University; Boston University
RP Elanwar, R (通讯作者)，Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
EM randa.elanwar@eri.sci.eg; wdqin@bu.edu; betke@bu.edu; wijaya@bu.edu
FU National Science Foundation [1838193]; Hariri Institute for Computing at Boston University; Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr [1838193] Funding Source: National Science Foundation
CR Abdelaziz I, 2014, ARXIV14127626, V0, P0
   Al-Dobais MA, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP171, DOI 10.1109/ASAR.2018.8480378
   Albadi N, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), V0, PP69, DOI 10.1109/ASONAM.2018.8508247
   Alexey B, 2020, COMPUTER VISION PATT, V0, P0
   Almutairi Abdullah, 2019, 2019 18TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP1371, DOI 10.1109/ICMLA.2019.00223
   Alshameri A, 2012, INT J COMPUTER APPL, V49, P30
   [Anonymous], 2018, 2018 IEEE 2 INT WORK, V0, P0
   [Anonymous], 2018, IEEE 2 INT WORKSH AR, V0, P0
   [Anonymous], 2009, P 2 INT C AR LANG RE, V0, P0
   [Anonymous], 2015, P 2 WORKSHOP ARABIC, V0, P0, DOI DOI 10.18653/V1/W15-3210
   Asi A, 2014, INT CONF FRONT HAND, V0, PP140, DOI 10.1109/ICFHR.2014.31
   Barakat B, 2018, INT CONF FRONT HAND, V0, PP374, DOI 10.1109/ICFHR-2018.2018.00072
   Barakat BK, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP151, DOI 10.1109/ASAR.2018.8480333
   Belaid A, 2012, GUIDE OCR ARABIC SCR, V0, PP103, DOI 10.1007/978-1-4471-4072-6_5
   Boussellaa W, 2007, PROC INT CONF DOC, V0, P1058
   Bukhari S, 2010, P 9 IAPR INT WORKSHO, V0, PP183, DOI 10.1145/1815330.1815354
   Bukhari SS, 2012, INT CONF FRONT HAND, V0, PP639, DOI 10.1109/ICFHR.2012.227
   Buslaev A, 2020, INFORMATION, V11, P0, DOI 10.3390/info11020125
   Chen K, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, V0, P299, DOI 10.1109/DAS.2016.13
   Cotterell R, 2014, P 9 INT C LANG RES E, V0, P241
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   El Abed Haikal, 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP1388, DOI 10.1109/ICDAR.2009.284
   El-Mawass N, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION PROCESSING AND COMMUNICATIONS (ICDIPC), V0, PP53, DOI 10.1109/ICDIPC.2016.7470791
   Elanwar R, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP177, DOI 10.1109/ASAR.2018.8480194
   Elanwar R, 2018, INT J DOC ANAL RECOG, V21, P59, DOI 10.1007/s10032-018-0298-x
   Girshick R, 2014, P 2014 IEEE C COMP V, V0, PP580, DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Hadjar K, 2003, PROC INT CONF DOC, V0, P895
   He K, 2017, P IEEE INT C COMPUTE, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hesham AM, 2017, PATTERN ANAL APPL, V20, P1275, DOI 10.1007/s10044-017-0595-x
   Hodosh M, 2010, P NAACL HLT 2010 WOR, V0, P0
   Ibn Khedher M, 2020, PATTERN RECOGN, V100, P0, DOI 10.1016/j.patcog.2019.107144
   Kai Chen, 2015, 2015 13TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP1011, DOI 10.1109/ICDAR.2015.7333914
   Kassis M, 2016, INT CONF FRONT HAND, V0, PP13, DOI 10.1109/ICFHR.2016.0016
   Lawson N, 2010, P NAACL HLT 2010 WOR, V0, P71
   Long J, 2015, P IEEE C COMP VIS PA, V0, P3431
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Mahmoud Sabri A, 2018, OPEN CYBERN SYST J, V12, P42
   Minghao L, 2020, ARXIV200601038, V0, P0
   Neche C, 2019, PROC INT CONF DOC, V0, PP19, DOI 10.1109/ICDARW.2019.50110
   Nikolaou N, 2010, IMAGE VISION COMPUT, V28, P590, DOI 10.1016/j.imavis.2009.09.013
   Pastor-Pellicer J, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, V0, P30, DOI 10.1109/DAS.2016.58
   Pechwitz M, 2002, P CIFED HAMM TUN 21, V0, P127
   Pletschacher S, 2010, PROCEEDINGS OF THE 2010 20TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR 2010), V0, PP257, DOI 10.1109/ICPR.2010.72
   RanaS MS, 2016, P 9 ACM INT C PERV T, V0, P1
   Ren S, 2015, P ADV NEUR INF PROC, V39, P91
   Saade Rami, 2018, 2018 IEEE INTERNATIONAL MULTIDISCIPLINARY CONFERENCE ON ENGINEERING TECHNOLOGY (IMCET), V0, P0, DOI DOI 10.1109/IMCET.2018.8603052
   Shafait F, 2008, IEEE T PATTERN ANAL, V30, P941, DOI 10.1109/TPAMI.2007.70837
   Simonyan K, 2015, ARXIV, V0, P0
   Slimane Fouad, 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP946, DOI 10.1109/ICDAR.2009.155
   Studer Linda, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP720, DOI 10.1109/ICDAR.2019.00120
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wei H, 2015, P 3 INT WORKSH HIST, V0, P55
   Wick C, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), V0, PP287, DOI 10.1109/DAS.2018.39
   Wray S, 2015, P 2 WORKSH AR NAT LA, V0, P99
   Zaidan O, 2011, P 49 ANN M ASS COMP, V0, P37
   Zaidan OF, 2014, COMPUT LINGUIST, V40, P171, DOI 10.1162/COLI_a_00169
   Zhong X, 2019, 15 INT C DOC AN REC, V0, P0
NR 59
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1433-2833
EI 1433-2825
J9 INT J DOC ANAL RECOG
JI Int. J. Doc. Anal. Recognit.
PD DEC 15
PY 2021
VL 24
IS 4
BP 349
EP 362
DI 10.1007/s10032-021-00382-4
EA JUN 2021
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WL2BA
UT WOS:000668434900001
DA 2023-11-10
ER

PT J
AU Liu, GY
   Liao, YH
   Wang, FY
   Zhang, B
   Zhang, L
   Liang, XD
   Wan, X
   Li, SL
   Li, Z
   Zhang, SX
   Cui, SG
AF Liu, Guangyi
   Liao, Yinghong
   Wang, Fuyu
   Zhang, Bin
   Zhang, Lu
   Liang, Xiaodan
   Wan, Xiang
   Li, Shaolin
   Li, Zhen
   Zhang, Shuixing
   Cui, Shuguang
TI Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report Generation With Alternate Learning
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Medical diagnostic imaging; COVID-19; Computed tomography; Visualization; Terminology; Training; Bit error rate; Alternate learning; automatic report generation; COVID-19 lesion diagnosis; imaging-based AI diagnosis systems; transfer learning; visual language BERT (VLBERT)
AB Medical imaging technologies, including computed tomography (CT) or chest X-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19. Since manual report writing is usually too time-consuming, a more intelligent auxiliary medical system that could generate medical reports automatically and immediately is urgently needed. In this article, we propose to use the medical visual language BERT (Medical-VLBERT) model to identify the abnormality on the COVID-19 scans and generate the medical report automatically based on the detected lesion regions. To produce more accurate medical reports and minimize the visual-and-linguistic differences, this model adopts an alternate learning strategy with two procedures that are knowledge pretraining and transferring. To be more precise, the knowledge pretraining procedure is to memorize the knowledge from medical texts, while the transferring procedure is to utilize the acquired knowledge for professional medical sentences generations through observations of medical images. In practice, for automatic medical report generation on the COVID-19 cases, we constructed a dataset of 368 medical findings in Chinese and 1104 chest CT scans from The First Affiliated Hospital of Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun Yat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of the COVID-19 training samples, our model was first trained on the large-scale Chinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for further fine-tuning. The experimental results showed that Medical-VLBERT achieved state-of-the-art performances on terminology prediction and report generation with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The Chinese COVID-19 CT dataset is available at https://covid19ct.github.io/.
C1 [Liu, Guangyi; Liao, Yinghong; Wan, Xiang; Li, Zhen; Cui, Shuguang] Chinese Univ Hong Kong, Shenzhen Res Inst Big Data, Shenzhen 518172, Peoples R China.
   [Liu, Guangyi; Liao, Yinghong; Li, Zhen; Cui, Shuguang] Chinese Univ Hong Kong, Future Network Intelligence Inst FNii, Shenzhen 518172, Peoples R China.
   [Wang, Fuyu] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510630, Peoples R China.
   [Zhang, Bin; Zhang, Shuixing] Jinan Univ, Dept Radiol, Affiliated Hosp 1, Guangzhou 510630, Peoples R China.
   [Zhang, Lu] Jinan Univ, Fac Med Sci, Guangzhou 510630, Peoples R China.
   [Liang, Xiaodan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510006, Peoples R China.
   [Wan, Xiang] Chinese Univ Hong Kong, Guangdong Prov Key Lab Big Data Comp, Shenzhen 518172, Peoples R China.
   [Li, Shaolin] Sun Yat Sen Univ, Affiliated Hosp 5, Zhuhai 519000, Peoples R China.
C3 Chinese University of Hong Kong, Shenzhen; Shenzhen Research Institute of Big Data; Chinese University of Hong Kong, Shenzhen; Sun Yat Sen University; Jinan University; Jinan University; Sun Yat Sen University; Chinese University of Hong Kong, Shenzhen; Sun Yat Sen University
RP Li, Z (通讯作者)，Chinese Univ Hong Kong, Shenzhen Res Inst Big Data, Shenzhen 518172, Peoples R China.; Zhang, SX (通讯作者)，Jinan Univ, Dept Radiol, Affiliated Hosp 1, Guangzhou 510630, Peoples R China.; Liang, XD (通讯作者)，Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510006, Peoples R China.; Li, SL (通讯作者)，Sun Yat Sen Univ, Affiliated Hosp 5, Zhuhai 519000, Peoples R China.
EM guangyiliu@link.cuhk.edu.cn; yinghongliao@link.cuhk.edu.cn; wangfy8@mail2.sysu.edu.cn; 1297225541@qq.com; z12019@stu2019.jnu.edu.cn; xdliang328@gmail.com; wanxiang@sribd.cn; lishlin5@mail.sysu.edu.cn; lizhen@cuhk.edu.cn; shui7515@126.com; shuguangcui@cuhk.edu.cn
FU Key Area Research and Development Program of Guangdong Province [2018B030338001, 2020B0101350001]; National Key Research and Development Program of China [2018YFB1800800]; Shenzhen Outstanding Talents Training Fund; Guangdong Research Project [2017ZT07X152]; NSFC [61902335]; Guangdong Regional Joint Fund-Key Projects [2019B1515120039]; National Natural Science Foundation Fund of China [61931024]; Helixon Biotechnology Company Fund; CCF-Tencent Open Fund
CR Alom MZ, 2020, ARXIV200403747, V0, P0
   Anderson P, 2018, PROC CVPR IEEE, V0, PP3674, DOI 10.1109/CVPR.2018.00387
   Butt C, 2023, APPL INTELL, V53, P4874, DOI 10.1007/s10489-020-01714-3
   Devlin J, 2018, ARXIV, V1, P4171
   Dou Q, 2020, BIOMEDICAL ENG BIOME, V0, PP265, DOI 10.1016/B978-0-12-816034-3.00009-2
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang Gao, 2017, PROC CVPR IEEE, V0, PP4700, DOI 10.1109/CVPR.2017.243
   Jiang ZX, 2018, COMPUT MED IMAG GRAP, V68, P1, DOI 10.1016/j.compmedimag.2018.04.005
   Jing BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2577
   Jing L, 2019, NEURAL COMPUT, V31, P765, DOI 10.1162/neco_a_01174
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Krause J, 2017, PROC CVPR IEEE, V0, PP3337, DOI 10.1109/CVPR.2017.356
   Li C, 2018, DES AUT CON, V0, P0, DOI DOI 10.1145/3195970.3196091
   Li CY, 2019, AAAI CONF ARTIF INTE, V0, P6666
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Liu SQ, 2017, IEEE I CONF COMP VIS, V0, PP873, DOI 10.1109/ICCV.2017.100
   Mahapatra D, 2019, I S BIOMED IMAGING, V0, PP709, DOI 10.1109/ISBI.2019.8759247
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Peng YF, 2021, IEEE T BIG DATA, V7, P3, DOI 10.1109/TBDATA.2020.3035935
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raghu M, 2019, ADV NEUR IN, V32, P0
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Romero A, 2017, 2017 6TH INTERNATIONAL YOUTH CONFERENCE ON ENERGY (IYCE), V0, P0
   Samala RK, 2019, IEEE T MED IMAGING, V38, P686, DOI 10.1109/TMI.2018.2870343
   Shen D, 2018, COMPUTERIZED MED IMA, V68, P1
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, ARXIV, V0, P0
   Su Weijie, 2020, ICLR, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wang L, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4453
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI 10.1080/1064119X.2021.1966557
   Wang XS, 2018, PROC CVPR IEEE, V0, PP9049, DOI 10.1109/CVPR.2018.00943
   Wang X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P899
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
NR 40
TC 16
Z9 16
U1 12
U2 44
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD SEP 15
PY 2021
VL 32
IS 9
BP 3786
EP 3797
DI 10.1109/TNNLS.2021.3099165
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA UK8IQ
UT WOS:000692208800005
PM 34370672
DA 2023-11-10
ER

PT J
AU Tilly, S
   Ebner, M
   Livan, G
AF Tilly, Sonja
   Ebner, Markus
   Livan, Giacomo
TI Macroeconomic forecasting through news, emotions and narrative
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE News sentiment; Time series forecasting; Big data; Natural language processing
ID sentiment; prediction
AB This study proposes a new method of incorporating emotions from newspaper articles into macroeconomic forecasts, attempting to forecast industrial production and consumer prices leveraging narrative and sentiment from global newspapers. For the most part, existing research includes positive and negative tone only to improve macroeconomic forecasts, focusing predominantly on large economies such as the US. These works use mainly anglophone sources of narrative, thus not capturing the entire complexity of the multitude of emotions contained in global news articles. This study expands the existing body of research by incorporating a wide array of emotions from newspapers around the world - extracted from the Global Database of Events, Language and Tone (GDELT) - into macroeconomic forecasts. We present a thematic data filtering methodology based on a bidirectional long short term memory neural network (Bi-LSTM) for extracting emotion scores from GDELT and demonstrate its effectiveness by comparing results for filtered and unfiltered data. We model industrial production and consumer prices across a diverse range of economies using an autoregressive framework, and find that including emotions from global newspapers significantly improves forecasts compared to three autoregressive benchmark models. We complement our forecasts with an interpretability analysis on distinct groups of emotions and find that emotions associated with happiness and anger have the strongest predictive power for the variables we predict.
C1 [Tilly, Sonja] UCL, Comp Sci Dept, 66-72 Gower St, London WC1E 6EA, England.
   [Ebner, Markus] Quoniam Asset Management, Westhafen Tower,Westhafenpl 1, D-60327 Frankfurt, Germany.
   [Livan, Giacomo] London Sch Econ & Polit Sci, Syst Risk Ctr, London WC2A 2AE, England.
C3 University of London; University College London; University of London; London School Economics & Political Science
RP Tilly, S (通讯作者)，UCL, Comp Sci Dept, 66-72 Gower St, London WC1E 6EA, England.
EM sonja.tilly.19@ucl.ac.uk; markus.ebner@quoniam.com; g.livan@ucl.ac.uk
FU EPSRC Early Career Fellowship [EP/N006062/1]
CR Allen DE, 2019, APPL ECON, V51, P3212, DOI 10.1080/00036846.2018.1564115
   [Anonymous], 2015, GDELT 20 GLOBAL KNOW, V0, P0
   [Anonymous], 2016, 202016 NORG BANK, V0, P0
   [Anonymous], 2021, NTR, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Ardia D, 2019, INT J FORECASTING, V35, P1370, DOI 10.1016/j.ijforecast.2018.10.010
   Baker S, 2020, COVID INDUCED EC UNC, V0, P13
   Baker SR, 2016, Q J ECON, V131, P1593, DOI 10.1093/qje/qjw024
   Benjamini Y, 2005, J AM STAT ASSOC, V100, P71, DOI 10.1198/016214504000001907
   Bildirici ME, 2015, PROCD SOC BEHV, V210, P416, DOI 10.1016/j.sbspro.2015.11.389
   Brooks C, 2010, REAL ESTATE MODELLIN, V0, P0, DOI DOI 10.1017/CBO9780511814235
   Brosch T, 2013, SWISS MED WKLY, V143, P0, DOI 10.4414/smw.2013.13786
   Bruner J, 1990, ACTS MEANING, V0, P0
   Buono D, 2017, EUROSTAT REV NATL AC, V1, P93
   Buono D, 2018, EVALUATION NOWCASTIN, V0, P0
   Casanova C, 2017, TRACK CHIN VULN REAL, V0, P0
   Chen HY, 2019, ASIA PAC MANAG REV, V24, P21, DOI 10.1016/j.apmrv.2018.11.001
   Clore GL, 2009, COGN SYST RES, V10, P21, DOI 10.1016/j.cogsys.2008.03.002
   Colladon AF, 2019, DECIS SUPPORT SYST, V123, P0, DOI 10.1016/j.dss.2019.113075
   Cruz FL, 2014, EXPERT SYST APPL, V41, P5984, DOI 10.1016/j.eswa.2014.04.005
   Cubadda G, 2012, ECON MODEL, V29, P1099, DOI 10.1016/j.econmod.2012.03.027
   Datawheel SA, 2012, OBSERVATORY EC COMPL, V0, P0
   DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X
   Dodds PS, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0026752
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   Elshendy M, 2018, J INF SCI, V44, P408, DOI 10.1177/0165551517698298
   Elshendy M, 2017, INT J ENG BUS MANAG, V9, P0, DOI 10.1177/1847979017720040
   Fraiberger SP, 2018, IMF WORKING PAPERS, V0, P0, DOI DOI 10.5089/9781484389218.001
   Fronzetti Colladon A, 2020, FORECASTING FINANC S, V0, P0
   Girardi A, 2016, J FORECASTING, V35, P542, DOI 10.1002/for.2393
   Glaeser EL, 2017, NOWCASTING LOCAL EC, V0, P0
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Graves A, 2005, IEEE IJCNN, V0, P2047
   Harvey D, 1997, INT J FORECASTING, V13, P281, DOI 10.1016/S0169-2070(96)00719-4
   He H, 2013, IMBALANCED LEARNING: FOUNDATIONS, V0, P0
   Hu M, 2004, PROC 10 ACM SIGKDD I, V0, PP168, DOI 10.1145/1014052.1014073
   Kapetanios G, 2018, EC STAT CTR EXCELLEN, V0, P0
   Keynes John Maynard, 2007, GEN THEORY EMPLOYMEN, V0, P0
   Larsen VH, 2019, J ECONOMETRICS, V210, P203, DOI 10.1016/j.jeconom.2018.11.013
   Leamer EE, 1985, ECON PHILOS, V1, P295, DOI 10.1017/S0266267100002546
   Leetaru Kalev Hannes, 2015, INFORMATION SERVICES & USE, V35, P31, DOI 10.3233/ISU-150767
   Leetaru KH, 2016, THESIS U ILLINOIS UR, V0, P0
   Levenberg Abby, 2014, INTERNATIONAL JOURNAL OF COMPUTER AND COMMUNICATION ENGINEERING, V3, P109, DOI 10.7763/IJCCE.2014.V3.302
   Loewenstein G, 2000, AM ECON REV, V90, P426, DOI 10.1257/aer.90.2.426
   Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x
   Magnini B, 2000, P LREC 2000 2 INT C, V0, P1413
   Mihailov A, 2011, OPEN ECON REV, V22, P317, DOI 10.1007/s11079-009-9125-9
   Nyman R, 2018, NEWS NARRATIVES FINA, V0, P0
   Pekar V, 2017, FORECASTING CONSUMER, V0, P0, DOI DOI 10.18653/v1/W17-5212
   Piccardi C, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0208265
   Rousidis D, 2020, MULTIMED TOOLS APPL, V79, P6279, DOI 10.1007/s11042-019-08291-9
   Salisu AA, 2017, ENERGY, V125, P97, DOI 10.1016/j.energy.2017.02.128
   Schaer O, 2019, INT J FORECASTING, V35, P197, DOI 10.1016/j.ijforecast.2018.03.005
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shiller RJ, 2017, AM ECON REV, V107, P967, DOI 10.1257/aer.107.4.967
   Slaper TF, 2018, 2ND INTERNATIONAL CONFERENCE ON ADVANCED RESEARCH METHODS AND ANALYTICS (CARMA 2018), V0, PP107, DOI 10.4995/CARMA2018.2018.8327
   Stern S, 2020, APPL NETW SCI, V5, P0, DOI 10.1007/s41109-020-00272-4
   Strapparava C, 2004, LREC, V0, P40
   Tobias RD, 1995, P 20 ANN SAS US GROU, V20, P0
   Tuckett D, 2014, EC GROWTH EJOURNAL, V0, P0, DOI DOI 10.2139/SSRN.2408155
   van Eyden R, 2019, APPL ENERG, V233, P612, DOI 10.1016/j.apenergy.2018.10.049
NR 61
TC 6
Z9 6
U1 5
U2 35
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD AUG 1
PY 2021
VL 175
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.114760
EA MAR 2021
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA SW2LU
UT WOS:000664351700010
DA 2023-11-10
ER

PT J
AU Gkoumas, D
   Li, QC
   Lioma, C
   Yu, YJ
   Song, DW
AF Gkoumas, Dimitris
   Li, Qiuchi
   Lioma, Christina
   Yu, Yijun
   Song, Dawei
TI What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis
SO INFORMATION FUSION
LA English
DT Article
DE Multimodal human language understanding; Video sentiment analysis; Emotion recognition; Reproducibility in multimodal machine learning
ID network; representations; translation; modality; audio
AB Multimodal video sentiment analysis is a rapidly growing area. It combines verbal (i.e., linguistic) and non-verbal modalities (i.e., visual, acoustic) to predict the sentiment of utterances. A recent trend has been geared towards different modality fusion models utilizing various attention, memory and recurrent components. However, there lacks a systematic investigation on how these different components contribute to solving the problem as well as their limitations. This paper aims to fill the gap, marking the following key innovations. We present the first large-scale and comprehensive empirical comparison of eleven state-of-the-art (SOTA) modality fusion approaches in two video sentiment analysis tasks, with three SOTA benchmark corpora. An in-depth analysis of the results shows that the attention mechanisms are the most effective for modelling crossmodal interactions, yet they are computationally expensive. Second, additional levels of crossmodal interaction decrease performance. Third, positive sentiment utterances are the most challenging cases for all approaches. Finally, integrating context and utilizing the linguistic modality as a pivot for non-verbal modalities improve performance. We expect that the findings would provide helpful insights and guidance to the development of more effective modality fusion models.
C1 [Gkoumas, Dimitris; Yu, Yijun; Song, Dawei] Open Univ, Milton Keynes, Bucks, England.
   [Li, Qiuchi] Univ Padua, Padua, Italy.
   [Lioma, Christina] Univ Copenhagen, Copenhagen, Denmark.
   [Song, Dawei] Beijing Inst Technol, Beijing, Peoples R China.
C3 Open University - UK; University of Padua; University of Copenhagen; Beijing Institute of Technology
RP Gkoumas, D; Song, DW (通讯作者)，Open Univ, Milton Keynes, Bucks, England.; Song, DW (通讯作者)，Beijing Inst Technol, Beijing, Peoples R China.
EM dimitris.gkoumas@open.ac.uk; qiuchili@dei.unipd.it; c.lioma@di.ku.dk; yijun.yu@open.ac.uk; dawei.song@open.ac.uk
FU Quantum Information Access and Retrieval Theory (QUARTZ) - European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant [721321]; Natural Science Foundation of China [U1636203]
CR [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   [Anonymous], 2019, 57 ANN M ASS COMP, V0, P0
   [Anonymous], 2015, ACM COMPUT SURV, V0, P0, DOI DOI 10.1145/2682899
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Barezi EJ, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), V0, P260
   Beard R, 2018, P 22 C COMPUTATIONAL, V0, PP251, DOI 10.18653/v1/K18
   Bokhari M, 2013, INT J COMPUT APPL, V74, P9, DOI 10.5120/12951-9967
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Cambria E, 2013, PROCEEDINGS OF THE 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR HUMAN-LIKE INTELLIGENCE (CIHLI), V0, PP108, DOI 10.1109/CIHLI.2013.6613272
   Chaturvedi I, 2019, PATTERN RECOGN LETT, V125, P264, DOI 10.1016/j.patrec.2019.04.024
   Chen M, 2017, P 19 ACM INT C MULT, V0, PP163, DOI 10.1145/3136755.3136801
   Cornejo C, 2018, ANN CULT PSYCHOL, V0, PP1, DOI 10.1109/TAFFC.2018.2874986
   Degottex Gilles, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P960, DOI 10.1109/ICASSP.2014.6853739
   Devlin J, 2018, ARXIV, V1, P4171
   Donahue J, 2015, PROC CVPR IEEE, V0, PP2625, DOI 10.1109/CVPR.2015.7298878
   Doshi P, 2011, P 13 INT C MULT INT, V0, PP169, DOI 10.1145/2070481.2070509
   Dumpala SH, 2019, 32 C NEURAL INFORM P, V0, P1
   Georgiou E, 2019, INTERSPEECH, V0, PP1646, DOI 10.21437/Interspeech.2019-3243
   Ghosal D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P154
   Ghosal D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3454
   Ghosh S, 2016, INTERSPEECH, V0, PP3603, DOI 10.21437/Interspeech.2016-692
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Gu Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2225
   Hazarika D, 2020, ARXIV200503545, V0, P0
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2594
   Hazarika Devamanyu, 2018, PROC CONF, V2018, P2122, DOI 10.18653/v1/n18-1193
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kiros R, 2014, ABS14112539 CORR, V0, P0
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lazaridou Angeliki, 2015, ARXIV150102598, V0, P0, DOI DOI 10.3115/V1/N15-1016
   Liang PP, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P150
   Liang PP, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2599
   Liang PP, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1569
   Liu ZT, 2019, IEEE T COGN DEV SYST, V11, P517, DOI 10.1109/TCDS.2018.2868121
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Mai SJ, 2020, AAAI CONF ARTIF INTE, V34, P164
   Mai SJ, 2020, IEEE T MULTIMEDIA, V22, P122, DOI 10.1109/TMM.2019.2925966
   Mai SJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P481
   Majumder N, 2019, AAAI CONF ARTIF INTE, V0, P6818
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Morvant E, 2014, LECT NOTES COMPUT SC, V8621, P153, DOI 10.1007/978-3-662-44415-3_16
   Nojavanasghari B, 2016, P 18 ACM INT C MULTI, V0, P2016
   Pham H, 2019, AAAI CONF ARTIF INTE, V0, P6892
   Pham P, 2018, LECT NOTES COMPUT SC, V10858, P150, DOI 10.1007/978-3-319-91464-0_15
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2016, IEEE DATA MINING, V0, PP439, DOI 10.1109/ICDM.2016.0055
   Prange A, 2019, CHI EA 19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290607.3299040
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajagopalan SS, 2016, LECT NOTES COMPUT SC, V9911, P338, DOI 10.1007/978-3-319-46478-7_21
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Shutova Ekaterina, 2016, P 2016 C N AM CH ASS, V0, P160
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Sun ZK, 2020, AAAI CONF ARTIF INTE, V34, P8992
   Tsai Y-HH, 2020, ARXIV200414198, V0, P0
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, PP6558, DOI 10.18653/v1/p19-1656
   Vielzeuf V, 2017, P 19 ACM INT C MULTI, V0, P569
   Wang HH, 2017, IEEE INT CON MULTI, V0, PP949, DOI 10.1109/ICME.2017.8019301
   Wang YS, 2019, AAAI CONF ARTIF INTE, V0, P7216
   Wang ZL, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2514, DOI 10.1145/3366423.3380000
   Wu WQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3794
   Young T, 2020, NEUROCOMPUTING, V388, P102, DOI 10.1016/j.neucom.2019.12.126
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
   Zadeh A, 2019, ARXIV191109826, V0, P0
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2018, AAAI CONF ARTIF INTE, V0, P5642
   Zadeh A, 2018, AAAI CONF ARTIF INTE, V0, P5634
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zadeh Amir, 2017, P 2017 C EMP METH NA, V0, PP1103, DOI 10.18653/V1/D17-1115
   Zhang Y, 2019, COMPLEXITY, V2019, P1, DOI 10.1109/IJCNN.2019.8851942
   Zhang YZ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5436
NR 76
TC 24
Z9 25
U1 2
U2 53
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD FEB 15
PY 2021
VL 66
IS 
BP 184
EP 197
DI 10.1016/j.inffus.2020.09.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA OO8AK
UT WOS:000587596900012
DA 2023-11-10
ER

PT J
AU Sitender
   Bawa, S
   Kumar, M
   Sangeeta
AF Sitender
   Bawa, Seema
   Kumar, Munish
   Sangeeta
TI A comprehensive survey on machine translation for English, Hindi and Sanskrit languages
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article; Early Access
DE Artificial intelligence; BLEU; Knowledge representation; Machine translation; NIST; Natural language processing; Systematic survey; Statistical machine translation
ID system; model; urdu
AB Transforming text from one language to another by using computer systems automatically or with little human interventions is known as Machine Translation System (MTS). Divergence among natural languages in a multilingual environment makes Machine Translation (MT) a difficult and challenging task. The purpose of this paper is to present a comprehensive survey of MTS in general and for English, Hindi and Sanskrit languages in particular. The state-of-the-art MT approach is Neural Machine Translation (NMT) which has been used by Google, Amazon, Facebook and Microsoft but it requires large corpus as well as high computing systems. The availability of MT language modeling tools, parsers data repositories and evaluation metrics has been tabulated in this article. The classification of MTS, evaluation methods and platforms has been done based on a well-defined set of criteria. The new research avenues have been explored in this survey article which will help in developing good quality MTS. Although several surveys have been done on MTS but none of them have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) approach including tools and evaluation methods as done in this survey specifically for English, Hindi and Sanskrit languages.
C1 [Sitender; Bawa, Seema] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Sitender; Sangeeta] Maharaja Surajmal Inst Technol, Dept Informat Technol, New Delhi 110058, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Batinda 151001, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Maharaja Surajmal Institute of Technology
RP Sitender (通讯作者)，Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.; Sitender (通讯作者)，Maharaja Surajmal Inst Technol, Dept Informat Technol, New Delhi 110058, India.
EM sitender@thapar.edu; seema@thapar.edu; munishcse@gmail.com; sangeeta.phogat@gmail.com
CR Aasha VC, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P1565, DOI 10.1109/ICACCI.2015.7275836
   Agrawal R, 2017, THESIS INT I INFORSM, V0, P0
   Allen J, 1995, NATURAL LANGUAGE UND, V0, P0
   Ambati BR, 2018, LANG RESOUR EVAL, V52, P67, DOI 10.1007/s10579-017-9379-6
   [Anonymous], 2016, 10 MOST SPOKEN LANGU, V0, P0
   [Anonymous], 2021, ETHNOLOGUE LANGUAGES, V0, P0
   [Anonymous], 2009, MOSES STAT MACHINE T, V0, P0
   [Anonymous], 2015, P INT WORKSHOP SPOKE, V0, P0
   [Anonymous], 2007, P MACH TRANSL SUMM, V0, P0
   [Anonymous], 2009, RECENT ADV NAT LANG, V0, P0, DOI DOI 10.1075/CILT.309
   Antony PJ, 2013, COMPUT LINGUIST, V18, P47
   Aparna S, 2005, LANG INDIA, V5, P1
   Ata N, 2007, PROC C LANGUAGE TECH, V0, P1
   Badodekar S, 2003, TRANSLATION RESOURCE, V0, P0
   Bahadur P, 2012, INT J ADV COMPUT SC, V4, P52, DOI 10.14569/SpecialIssue.2012.020107
   Bahdanau D, 2016, ARXIV, V0, P0
   Baker Paul, 2002, P LREC 2002, V0, P0
   Balyan R, 2015, COMPUT SPEECH LANG, V32, P91, DOI 10.1016/j.csl.2014.09.007
   Bhadra M, 2009, LECT NOTES ARTIF INT, V5406, P116, DOI 10.1007/978-3-540-93885-9_10
   Bhadwal N, 2020, SCALABLE COMPUT-PRAC, V21, P543, DOI 10.12694/scpe.v21i3.1783
   Bharati A, 2009, ANUSAARAKA ACCESSOR, V0, P1
   Bharati RM, 2003, P INT C NAT LANG PRO, V0, P0
   Budgen D, 2006, 28TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING PROCEEDINGS, V0, PP1051, DOI 10.1145/1134285.1134500
   CARROLL JB, 1966, MECH TRANSL, V9, P55
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Choudhary A, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 4, P293, DOI 10.1109/ICCSIT.2009.5234543
   Christopher M, 2010, 32 ALL IND C LING AI, V0, P69
   Darbari H, 1999, MACH TRANSL SUMM 7 1, V0, P80
   Dave S, 2001, MACHINE TRANSLATION, V16, P251, DOI 10.1023/A:1021902704523
   Desai N, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Desai P, 2014, P 11 INT C NAT LANG, V0, P177
   Devlin J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1370
   Dorr BJ, 2004, P INT C WORLD C ENG, V0, P1
   Dubey Preeti, 2019, INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY, V11, P171, DOI 10.1007/s41870-018-0085-4
   Dubey P, 2013, 2013 INTERNATIONAL CONFERENCE ON MACHINE INTELLIGENCE AND RESEARCH ADVANCEMENT (ICMIRA 2013), V0, PP422, DOI 10.1109/ICMIRA.2013.89
   Dungarwal P, 2014, P 9 WORKSH STAT MACH, V0, P90
   Echizen-Ya H, 2004, SYSTEMS AND COMPUTERS IN JAPAN, V35, P1, DOI 10.1002/scj.10511
   Faes F, 2018, AMAZON LION BRIDGE S, V0, P0
   Federico M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1618
   Forcada ML, 2011, MACH TRANSL, V25, P127, DOI 10.1007/s10590-011-9090-0
   Fromkin V, 2011, INTRO LANGUAGE, V0, P0
   Garje GV, 2013, INT J NATURAL LANGUA, V2, P47, DOI 10.5121/ijnlc.2013.2504
   Gehring J, 2016, ARXIV161102344, V0, P0
   Gehring J, 2017, PR MACH LEARN RES, V70, P0
   Gimenez Jesus, 2010, PRAGUE BULLETIN OF MATHEMATICAL LINGUISTICS, V0, PP77, DOI 10.2478/v10108-010-0022-6
   Gimenez Jesus, 2006, P 5 INT C LANG RES E, V0, P685
   Gopal M, 2011, COMM COM INF SC, V139, P191
   Goyal P, 2009, LECT NOTES ARTIF INT, V5402, P287
   Goyal Vishal, 2010, JOURNAL OF EMERGING TECHNOLOGIES IN WEB INTELLIGENCE, V2, P148, DOI 10.4304/jetwi.2.2.148-151
   Goyal V, 2009, ARXIV PREPRINT ARXIV, V0, P0
   Goyal V, 2011, PROC ASS COMPUTATION, V0, P1
   Hassan H, 2018, ACHIEVING HUMAN PARI, V0, P0
   Hutchins WJ, 1992, INTRO MACHINE TRANSL, V0, P0
   Hutchins WJ, 1995, CONCISE HIST LANGUAG, V0, P431
   Hyderabad I, 2018, MACH TRANSL, V0, P0
   Jain RSinhaRMK, 2001, STRANS 2001, V0, P20
   Jawaid B, 2014, PROC WORKSHOP S SE A, V0, P37
   Jayan V, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), V0, PP282, DOI 10.1109/IC3I.2014.7019748
   Jha Girish Nath, 2010, P 7 INT C LANG RES E, V0, P982
   Jung H, 1999, COMPUT INTELL, V15, P114, DOI 10.1111/0824-7935.00087
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kelly C, 2021, TAB DELIMITED BILING, V0, P0
   Khan N, 2013, PROC WORKSHOP S SE A, V0, P72
   Khan S, 2019, INT ARAB J INF TECHN, V16, P125
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Kulkarni A, 2013, P 2 INT C DEP LING D, V0, P157
   Kulkarni A, 2010, LECT NOTES ARTIF INT, V6465, P70, DOI 10.1007/978-3-642-17528-2_6
   Kumar A, 2010, LECT NOTES ARTIF INT, V6465, P57, DOI 10.1007/978-3-642-17528-2_5
   Kumar Rashi, 2019, P 2019 2 INT C ALGOR, V0, P377
   Le Thuyen PT, 2016, 2016 INT C EL INF CO, V0, P1
   Lin C-Y, 2004, COLING 2004 P 20 INT, V0, PP501, DOI 10.3115/1220355.1220427
   Malik MK, 2013, WORLD APPL SCI J, V24, P1362, DOI 10.5829/idosi.wasj.2013.24.10.760
   Mallikarjun B, 2010, STRENGTH TODAY BRIGH, V10, P1
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), V0, P18
   Microsoft, 2017, MICR TRANSL ACC US N, V0, P0
   Microsoft, 2016, MICR TRANSL LAUNCH N, V0, P0
   Mishra Himani, 2019, INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING NETWORKING AND INFORMATICS (ICANI-2018). ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 870), V0, PP371, DOI 10.1007/978-981-13-2673-8_39
   Mishra Viral, 2012, INTERNATIONAL JOURNAL OF ADVANCED INTELLIGENCE PARADIGMS, V4, P168, DOI 10.1504/IJAIP.2012.048144
   Mishra V, 2008, J RES DEV COMP SCI E, V37, P1
   Mishra V, 2009, INFOCOMP J COMPUTER, V9, P80
   Moher D, 2016, REV ESP NUTR HUM DIE, V20, P148, DOI 10.14306/renhyd.20.2.223
   Mujadia V, 2020, P 5 C MACH TRANSL, V0, P414
   Narayan R, 2014, SCI WORLD J, V0, P0, DOI DOI 10.1155/2014/485737
   Naskar S, 2005, AAMT J, V16, P25
   NCST, 2008, MATR ENGLISH HINDI M, V0, P0
   Nivre J, 2007, NATURAL LANGUAGE ENGINEERING, V13, P95, DOI 10.1017/S1351324906004505
   Och FJ, 2007, JOINT C EMP METH NAT, V0, P858
   Pandey RK, 2016, PROCEDIA COMPUT SCI, V96, P504, DOI 10.1016/j.procs.2016.08.114
   Pathak GR, 2010, AIP CONF PROC, V1324, P122, DOI 10.1063/1.3526172
   Phillips AB, 2011, MACH TRANSL, V25, P161, DOI 10.1007/s10590-011-9109-6
   Post Matt, 2015, PRAGUE BULLETIN OF MATHEMATICAL LINGUISTICS, V0, PP5, DOI 10.1515/pralin-2015-0009
   Pune C, 2018, INDIAN LANGUAGE TECH, V0, P0
   Rajan Remya, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P0
   Raulji Jaideepsinh K, 2019, P 2019 IEEE BOMBAY S, V0, P1
   Reddy MV, 2013, MULTIMEDIA PROCESSIN, V0, P35
   ROSENFELD R, 1997, CMU CAMBRIDGE STAT L, V0, P0
   Sachdeva K, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1807
   Saha GK, 2005, J ZHEJIANG UNIV-SC A, V6, P1047, DOI 10.1631/jzus.2005.A1047
   Sahinur Rahman Laskar, 2020, P 7 WORKSHOP ASIAN T, V0, P109
   Seasly J, 2003, MACH TRANSL, V0, P0
   Shahnawaz, 2015, INTERNATIONAL JOURNAL OF ADVANCED INTELLIGENCE PARADIGMS, V7, P1
   Shahnawaz A, 2011, INFOCOMP J COMPUT SC, V10, P25
   Sharma N, 2011, THESIS THAPAR U PATI, V0, P0
   Sheikh Mahmudul, 2013, INTERNATIONAL JOURNAL OF INTERCULTURAL INFORMATION MANAGEMENT, V3, P123
   Singh Muskaan, 2019, RECENT TRENDS IN COMMUNICATION, V0, P0
   Singh M, 2020, PROCEDIA COMPUT SCI, V167, P2534, DOI 10.1016/j.procs.2020.03.306
   SINHA RMK, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, V0, P0
   Sinha RMK, 2003, MT SUMM 9 NEW ORL US, V0, P494
   Sinha RMK, 2005, 10 EAMT C, V0, P235
   Sinha RMK, 2004, P INT S MACH TRANSL, V0, P10
   Sinha RMK, 2005, 10 MACH TRANSL SUMM, V0, P149
   Sitender, 2021, IETE J RES, V67, P117, DOI 10.1080/03772063.2018.1528187
   Sitender, 2022, MULTIMEDIA SYST, V28, P2105, DOI 10.1007/s00530-020-00692-3
   Sitender, 2021, NEURAL COMPUT APPL, V33, P2819, DOI 10.1007/s00521-020-05156-3
   Slocum J, 1985, COMPUTATIONAL LINGUISTICS, V11, P1
   Sridhar R, 2016, SADHANA-ACAD P ENG S, V41, P607, DOI 10.1007/s12046-016-0504-9
   Stolcke Andreas, 2002, IWSLT, V0, P0
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Udupa R, 2005, LECT NOTES COMPUT SC, V3248, P254
   Upadhyay P, 2014, INT J COMPUT APPL, V4, P2277
   Van Slype G, 1979, CRITICAL STUDY METHO, V0, P0
   Vaswani A, 2013, P 2013 C EMPIRICAL M, V0, P1387
   Venkatapathy S, 2009, ACM T ASIAN LANG INF, V8, P8
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Yandex, 2017, YAND BLOG, V0, P0
   Zhang M, 2017, HIST FRONTIER NEURAL, V0, P0
NR 127
TC 8
Z9 8
U1 2
U2 10
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1007/s12652-021-03479-0
EA SEP 2021
PG 34
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA UP1NL
UT WOS:000695150800001
DA 2023-11-10
ER

PT J
AU Wang, DQ
   Jing, BY
   Lu, CW
   Wu, JJ
   Liu, GN
   Du, CG
   Zhuang, FZ
AF Wang, Deqing
   Jing, Baoyu
   Lu, Chenwei
   Wu, Junjie
   Liu, Guannan
   Du, Chenguang
   Zhuang, Fuzhen
TI Coarse Alignment of Topic and Sentiment: A Unified Model for Cross-Lingual Sentiment Classification
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Data models; Task analysis; Semantics; Learning systems; Bridges; Logistics; Vocabulary; Coarse alignment; cross-lingual sentiment classification (CLSC); topic model
AB Cross-lingual sentiment classification (CLSC) aims to leverage rich-labeled resources in the source language to improve prediction models of a resource-scarce domain in the target language. Existing feature representation learning-based approaches try to minimize the difference of latent features between different domains by exact alignment, which is achieved by either one-to-one topic alignment or matrix projection. Exact alignment, however, restricts the representation flexibility and further degrades the model performances on CLSC tasks if the distribution difference between two language domains is large. On the other hand, most previous studies proposed document-level models or ignored sentiment polarities of topics that might lead to insufficient learning of latent features. To solve the abovementioned problems, we propose a coarse alignment mechanism to enhance the model's representation by a group-to-group topic alignment into an aspect-level fine-grained model. First, we propose an unsupervised aspect, opinion, and sentiment unification model (AOS), which trimodels aspects, opinions, and sentiments of reviews from different domains and helps capture more accurate latent feature representation by a coarse alignment mechanism. To further boost AOS, we propose ps-AOS, a partial supervised AOS model, in which labeled source language data help minimize the difference of feature representations between two language domains with the help of logistics regression. Finally, an expectation-maximization framework with Gibbs sampling is then proposed to optimize our model. Extensive experiments on various multilingual product review data sets show that ps-AOS significantly outperforms various kinds of state-of-the-art baselines.
C1 [Wang, Deqing; Lu, Chenwei; Du, Chenguang] Beihang Univ, Sch Comp Sci, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Jing, Baoyu] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
   [Wu, Junjie; Liu, Guannan] Beihang Univ, Sch Econ & Management, Beijing 100191, Peoples R China.
   [Jing, Baoyu; Liu, Guannan] Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100191, Peoples R China.
   [Zhuang, Fuzhen] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100864, Peoples R China.
   [Zhuang, Fuzhen] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Beihang University; Carnegie Mellon University; Beihang University; Beihang University; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Zhuang, FZ (通讯作者)，Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100864, Peoples R China.
EM zhuangfuzhen@ict.ac.cn
FU National Key Research and Development Program of China [2018YFB1402800]; National Natural Science Foundation of China [71501003, 71531001, 71725002, U1636210, U1836206]; National Key R&D Program of China [2019YFB2101804]; Project of Youth Innovation Promotion Association CAS [2017146]
CR [Anonymous], 2014, ADV NEURAL INFORM PR, V0, P0
   [Anonymous], 2004, PARAMETER ESTIMATION, V0, P0
   [Anonymous], 2013, P 6 ACM INT C ONWEB, V0, P0
   [Anonymous], 2010, P 19 ACM INT C INFOR, V0, P0, DOI DOI 10.1145/1871437.1871486
   [Anonymous], 2011, P 17 ACM SIGKDD INT, V0, P0
   Banea C, 2010, P 23 INT C COMPUTATI, V0, P1
   Bao Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, PP239, DOI 10.1145/2505515.2505556
   Ben-David Shai, 2006, ADV NEURAL INFORM PR, V0, P2
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blitzer J, 2006, P 2006 C EMPIRICAL M, V0, P120
   Dai WY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P210
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Doyle G, 2009, P 26 ANN INT C MACHI, V0, P281
   Fernández AM, 2016, J ARTIF INTELL RES, V55, P131, DOI 10.1613/jair.4762
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Gui L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P860
   Hermann KM, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P58
   Hu XG, 2016, KNOWL-BASED SYST, V97, P60, DOI 10.1016/j.knosys.2016.01.016
   Jain S, 2015, P 2015 C EMP METH NA, V0, P159
   Jo Y, 2011, P 4 ACM INT C WEB SE, V0, PP815, DOI 10.1145/1935826.1935932
   Li S, 2017, IEEE T NEUR NET LEAR, V28, P1682, DOI 10.1109/TNNLS.2016.2538282
   Li T, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP716, DOI 10.1145/1571941.1572093
   Lin C, 2009, P 18 ACM C INF KNOWL, V0, PP375, DOI 10.1145/1645953.1646003
   Lin Z, 2014, P 23 ACM INT C C INF, V0, P1089
   Lin Z, 2016, IEEE-ACM T AUDIO SPE, V24, P0, DOI 10.1109/TASLP.2015.2512041
   Long M, 2012, SDM, V0, P540
   Ma CL, 2015, WWW15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP649, DOI 10.1145/2740908.2741704
   Meng Xinfan, 2012, P ACL, V1, P572
   Mihalcea R, 2007, P 45 ANN M ASS COMPU, V0, P976
   Paul MJ, 2009, P 2009 C EMP METH NA, V0, P1408
   Porteous I, 2008, P 14 ACM SIGKDD INT, V0, PP569, DOI 10.1145/1401890.1401960
   Prettenhofer P, 2012, ACM T INTEL SYST TEC, V3, P0, DOI 10.1145/2036264.2036277
   Wan X, 2008, P C EMPIRICAL METHOD, V0, P553
   Wan X, 2009, P JOINT C 47 ANN M A, V1, P235
   Wang H, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR11), V0, P933
   Xu RC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1415, DOI 10.18653/v1/P17-1130
   Zhao X, 2010, P 2010 C EMP METH NA, V0, P56
   Zhou GY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1426
   Zhou HW, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P430
   Zhou X, 2016, P 2016 C EMPIRICAL M, V0, PP247, DOI 10.18653/V1/D16-1024
   Zhou XJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1403
   Zhuang F, 2010, PROC SIAM INT C DATA, V0, P13
   Zhuang F, 2013, PROC 23TH INT JOINT, V0, P1960
NR 45
TC 20
Z9 20
U1 7
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD FEB 15
PY 2021
VL 32
IS 2
BP 736
EP 747
DI 10.1109/TNNLS.2020.2979225
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA QE6IX
UT WOS:000616310400022
PM 32287008
DA 2023-11-10
ER

PT J
AU Suman, C
   Reddy, SM
   Saha, S
   Bhattacharyya, P
AF Suman, Chanchal
   Reddy, Saichethan Miriyala
   Saha, Sriparna
   Bhattacharyya, Pushpak
TI Why pay more? A simple and efficient named entity recognition system for tweets
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Conditional random field; Hand-crafted feature; Long short term memory; Named entity recognition; Sequence labelling
AB The current paper investigates the problem of multimodal named entity recognition from Twitter data. Named entity recognition (NER) is an important task in natural language processing and has been carefully studied in recent decades. NER from tweets is particularly challenging because of 1) tweets are limited in length, 2) contains noisy text, and 3) contains hashtags. Moreover often tweets are associated with images and hyperlinks. Existing works on tweet-NER mostly concentrate on multimodal deep learning based models neglecting the use of hand-crafted features and usage of hyperlinks. The current paper investigates the incorporation of hand-crafted features extracted from different modalities like images, hyperlinks while extracting named entities from tweet-text. A large set of hand-crafted features are extracted from different modalities (images, hyperlinks) and those are added with the features extracted by a hybrid deep-neural model, bi-directional LSTM and CNN, followed by a conditional random field to perform this task. Several variants of these models in association with different hand-crafted feature sets are designed. Extensive experimentations on a multimodal Twitter data (containing text, images and urls) illustrate that character level hand-crafted features significantly improve the performance of the systems. In a part of the paper, results of the proposed models are also shown on a standard NER dataset, CoNLL 2003 dataset.
C1 [Suman, Chanchal; Saha, Sriparna; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Comp Sci & Engn, Patna, Bihar, India.
   [Reddy, Saichethan Miriyala] IIIT Bhagalpur, Comp Sci & Engn, Bhagalpur, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Patna
RP Suman, C (通讯作者)，Indian Inst Technol Patna, Comp Sci & Engn, Patna, Bihar, India.
EM 1821cs11@iitp.ac.in; miriyala.cse.1725@iiitbh.ac.in; Sriparna@iitp.ac.in; pb@iitp.ac.in
FU SERB WOMEN IN EXCELLENCE AWARD
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], 2016, 10 INT AAAI C WEB SO, V0, P0
   [Anonymous], 2002, CONLL, V0, P0, DOI DOI 10.3115/1072228.1072253
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2003, P 7 C NAT LANG LEARN, V0, P0
   [Anonymous], 2007, P 2007 JOINT C EMPIR, V0, P0
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Azarine IS, 2019, 2019 7 INT C INF COM, V0, P1
   Badjatiya P, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP49, DOI 10.1145/3308558.3313504
   Bae KI, 2020, EXPERT SYST APPL, V159, P0, DOI 10.1016/j.eswa.2020.113455
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, V0, P0, DOI DOI 10.48550/ARXIV.1409.0473
   Baldwin T, 2015, P WORKSH NOIS US GEN, V0, P126
   Belainine Billal, 2016, P 2 WORKSH NOIS US G, V0, P102
   Buyuktopac O, 2019, INT C MAN MACH INT, V0, P125
   Chen HD, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1936, DOI 10.18653/v1/P17-1177
   Chen T, 2013, P 21 ACM INT C MULTI, V0, P781
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/TACL_A_00104
   Derczynski Leon, 2016, P COLING 2016 26 INT, V0, P1169
   Finin T, 2010, P NAACL HLT 2010 WOR, V0, P80
   Florian R, 2003, P 7 C NAT LANG LEARN, V4, P168, DOI 10.3115/1119176.1119201
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Hosseini H, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1448, DOI 10.1145/3331184.3331416
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Kumar V, 2014, ARXIV PREPRINT ARXIV, V0, P0
   Kwiatkowska M, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Lample G, 2016, P HLTNAACL, V0, P0
   Li CL, 2015, IEEE T KNOWL DATA EN, V27, P558, DOI 10.1109/TKDE.2014.2327042
   Li CL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP721, DOI 10.1145/2348283.2348380
   Li J, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Li Q, 2019, ARXIV PREPRINT ARXIV, V0, P0
   LIU X, 2011, P 49 ANN M ASS COMP, V0, P359
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Moon S, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Pang T, 2020, EXPERT SYST APPL, V158, P0, DOI 10.1016/j.eswa.2020.113501
   Pereira Fernando CN, 2001, CONDITIONAL RANDOM F, V0, P0
   Ritter A, 2011, P C EMP METH NAT LAN, V0, PP1524, DOI 10.1075/LI.30.1.03NAD
   Sang EFTK, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P173
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Simonyan K, 2015, INT C LEARN REPRESEN, V0, P0
   Solorio, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Strauss B, 2016, P 2 WORKSH NOIS US G, V0, PP138, DOI 10.19346/V1/W16-2381
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vavliakis KN, 2013, DATA KNOWL ENG, V88, P1, DOI 10.1016/j.datak.2013.08.006
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wu S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P0
   Xu JM, 2012, HLT NAACL, V0, P656
   Yang E-S, 2015, PROC WORKSHOP NOISY, V0, P72
   Zhang Q, 2018, AAAI CONF ARTIF INTE, V0, P5674
   Zhao L, 2020, ARXIV PREPRINT ARXIV, V0, P0
NR 51
TC 9
Z9 9
U1 3
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD APR 1
PY 2021
VL 167
IS 
BP 
EP 
DI 10.1016/j.eswa.2020.114101
EA FEB 2021
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA RN7KC
UT WOS:000640531100002
DA 2023-11-10
ER

PT J
AU Shaikh, A
   Hafeez, A
   Elmagzoub, MA
   Alghamdi, A
   Siddique, A
   Shahzad, B
AF Shaikh, Asadullah
   Hafeez, Abdul
   Elmagzoub, M. A.
   Alghamdi, Abdullah
   Siddique, Ansar
   Shahzad, Basit
TI Ontology-Based Verification of UML Class Model XOR Constraint and Dependency Relationship Constraints
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Ontology-based verification; model verification; class model verification; UML model verification
AB Unified Modeling Language (UML) models are considered important artifacts of model-driven engineering (MDE). This can automatically transform models to other paradigms and programming languages. If a model has bugs, then MDE can transfer these to a new code. The class model is a key component of UML that is used in analysis and design. Without a formal foundation, UML can create only graphical diagrams, making it impossible to verify properties such as satisfiability, consistency and consequences. Different techniques have been used to verify UML class models, but these do not support some important components. This paper transforms and verifies unsupported components such as XOR association constraints and dependency relationships of a UML class model through ontology. We use various UML class models to validate the proposed ontology-based method, easy and efficient transformation and verification of unsupported elements. The results show this approach can verify large and complex models.
C1 [Shaikh, Asadullah; Elmagzoub, M. A.; Alghamdi, Abdullah] Najran Univ, Dept Informat Syst, Najran 61441, Saudi Arabia.
   [Hafeez, Abdul] SMI Univ, Dept Comp Sci, Karachi 76400, Pakistan.
   [Siddique, Ansar] Univ Gujrat, Dept Software Engn, Gujrat 50700, Pakistan.
   [Shahzad, Basit] Natl Univ Modern Languages NUML, Dept Software Engn, Islamabad 44020, Pakistan.
C3 Najran University; University of Gujrat
RP Shaikh, A (通讯作者)，Najran Univ, Dept Informat Syst, Najran 61441, Saudi Arabia.
EM asshaikh@nu.edu.sa
FU ministry of education and the deanship of scientific research of Najran University, Kingdom of Saudi Arabia [NU/ESCI/17/098]
CR Alemán JLF, 2000, 11TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, V0, P344, DOI 10.1109/ISSRE.2000.885885
   Anastasakis K, 2010, SOFTW SYST MODEL, V9, P69, DOI 10.1007/s10270-008-0110-3
   [Anonymous], 2011, ACM SIGSOFT SOFTWARE, V0, P0
   [Anonymous], 2010, P IEEEACM INT C AUTO, V0, P0
   Awaad MH, 1978, ZENTRALBLATT BAKTE A, V240, P0
   Bajwa IS, 2017, MEHRAN UNIV RES J EN, V36, P243, DOI 10.22581/muet1982.1702.04
   Bajwa IS, 2012, J KING SAUD UNIV-COM, V24, P117, DOI 10.1016/j.jksuci.2011.12.003
   Balaban M, 2015, SOFTW SYST MODEL, V14, P1527, DOI 10.1007/s10270-013-0390-0
   Balaban M, 2013, ACM T SOFTW ENG METH, V22, P0, DOI 10.1145/2491509.2491518
   Belghiat A, 2012, P 4 INT C WEB INF TE, V0, P330
   Berardi D, 2005, ARTIF INTELL, V168, P70, DOI 10.1016/j.artint.2005.05.003
   Booch G, 1996, UNIFIED MODELING LAN, V0, P1
   Bordbar B, 2005, IADIS INT C APPL COM, V0, P209
   Cabot J, 2008, CHAMDE 2008 WORKSH P, V0, P31
   Cabot J, 2009, J SYST SOFTWARE, V82, P1459, DOI 10.1016/j.jss.2009.03.009
   Cadoli M, 2004, CSP TECH IMMED APPL, V2, P2
   Clarisó R, 2015, LECT NOTES COMPUT SC, V9276, P108, DOI 10.1007/978-3-319-22969-0_8
   Cook SF, 2017, THESIS, V0, P0
   Defense PM, 1992, US GAO REPORTS, V0, P0
   Erdil Kagan, 2003, COMP180 SOFTWARE ENG, V0, P1
   Files ANMC, 2013, OBJECT MANAGEMENT GR, V0, P1
   Fish A, 2005, 5 VMG U BRIGHT, V0, P0
   France R, 1998, COMPUT STAND INTER, V19, P325, DOI 10.1016/S0920-5489(98)00020-8
   Grimm S, 2007, SEMANTIC WEB SERVICE, V0, P0, DOI DOI 10.1007/3-540-70894-4_3
   Hassan N, 2016, INT J COMPUTER SCI I, V14, P52
   Hussmann H, 2000, LECT NOTES COMPUT SC, V1939, P278
   Kardos M, 2010, J INF ORGAN SCI, V34, P89
   Kent S, 2002, INTEGRATED FORMAL METHODS. THIRD INTERNATIONAL CONFERENCE, V0, P286
   Kim SK, 2000, INT C B Z USERS, V0, P0
   Korytkowski R, 2016, THOUGHTS OCL OBJECT, V0, P0
   Ledang H, 2001, 16TH ANNUAL INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2001), V0, P436, DOI 10.1109/ASE.2001.989849
   Ledang H, 2001, INF 2001 WORKSH INT, V0, P1
   Malgouyres Y, 2006, APPLIED COMPUTING 2006. 21ST ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, V0, PP1804, DOI 10.1145/1141277.1141703
   Maoz S, 2011, LECT NOTES COMPUT SC, V6981, P592, DOI 10.1007/978-3-642-24485-8_44
   Maraee A, 2008, MODEL COEVOLUTION CO, V0, P120
   Maraee A, 2009, MBSE: 2009 INTERNATIONAL CONFERENCE ON MODEL-BASED SYSTEMS ENGINEERING, V0, PP1, DOI 10.1109/MBSE.2009.5031714
   OMGroup, 2007, UML CONSTR VERS 2 5, V0, P0
   Oriol X, 2017, J SYST SOFTWARE, V128, P130, DOI 10.1016/j.jss.2017.03.015
   Parreiras FS, 2010, DATA KNOWL ENG, V69, P1194, DOI 10.1016/j.datak.2010.07.009
   Pérez B, 2019, INFORM SYST, V81, P152, DOI 10.1016/j.is.2018.08.005
   Robert JC, 2020, J OBJECT TECHNOLOGY, V19, P1
   Shaikh Asadullah, 2011, ADVANCES IN SOFTWARE ENGINEERING, V0, P0, DOI DOI 10.1155/2011/370198
   Shaikh A, 2018, IEEE ACCESS, V6, P23864, DOI 10.1109/ACCESS.2018.2797695
   Shaikh A, 2014, SOFTWARE PRACT EXPER, V44, P1379, DOI 10.1002/spe.2211
   Singh M, 2016, PROCEDIA COMPUT SCI, V85, P352, DOI 10.1016/j.procs.2016.05.243
   Song K, 2005, 2005 INTERNATIONAL WORKSHOP ON THE ANALYSIS ON MULTI-TEMPORAL REMOTE SENSING IMAGES, V0, P39
   Technica, 2015, SOFTW BUG GRANT EARL, V0, P0
   Traoré I, 2004, IEEE T SOFTWARE ENG, V30, P736, DOI 10.1109/TSE.2004.86
   Xu W, 2008, INFORM SYSTEMS CRISI, V0, P493
NR 49
TC 2
Z9 2
U1 1
U2 1
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD JUN 15
PY 2021
VL 27
IS 2
BP 565
EP 579
DI 10.32604/iasc.2021.015071
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA QR1CE
UT WOS:000624954000018
DA 2023-11-10
ER

PT J
AU Burks, L
   Ahmed, N
   Loefgren, I
   Barbier, L
   Muesing, J
   McGinley, J
   Vunnam, S
AF Burks, Luke
   Ahmed, Nisar
   Loefgren, Ian
   Barbier, Luke
   Muesing, Jeremy
   McGinley, Jamison
   Vunnam, Sousheel
TI Collaborative human-autonomy semantic sensing through structured POMDP planning
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Human-robot interaction; Data fusion; Partially observable Markov decision processes; Planning; Bayesian methods; Target search; Target localization; Mobile robots; Autonomy
ID value-iteration; decision-making; uncertainty; motion
AB Autonomous unmanned systems and robots must be able to actively leverage all available information sources - including imprecise but readily available semantic observations provided by human collaborators. This work develops and validates a novel active collaborative human-machine sensing solution for robotic information gathering and optimal decision making problems, with an example implementation of a dynamic target search scenario. Our approach uses continuous partially observable Markov decision process (CPOMDP) planning to generate vehicle trajectories that optimally exploit imperfect detection data from onboard sensors, as well as semantic natural language observations that can be specifically requested from human sensors. The key innovations are a method for the inclusion of a human querying/sensing model in a CPOMDP based autonomous decision making process, as well as a scalable hierarchical Gaussian mixture model formulation for efficiently solving CPOMDPs with semantic observations in continuous dynamic state spaces. Unlike previous state-of-the-art approaches this allows planning in large, complex, highly segmented environments. Our solution is demonstrated and validated with a real human-robot team engaged in dynamic indoor target search and capture scenarios on a custom testbed. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Burks, Luke; Ahmed, Nisar; Loefgren, Ian; Barbier, Luke; Muesing, Jeremy; McGinley, Jamison; Vunnam, Sousheel] Univ Colorado, Ann & HJ Smead Aerosp Engn Sci Dept, 429 UCB, Boulder, CO 80309 USA.
C3 University of Colorado System; University of Colorado Boulder
RP Ahmed, N (通讯作者)，Univ Colorado, Ann & HJ Smead Aerosp Engn Sci Dept, 429 UCB, Boulder, CO 80309 USA.
EM luke.burks@colorado.edu; nisar.ahmed@colorado.edu
FU Center for Unmanned Aircraft Systems (CUAS), USA, a National Science Foundation Industry/University Cooperative Research Center (I/UCRC) under NSF, USA [CNS-1650468]
CR Abbeel P, 2004, P 21 INT C MACHINE L, V0, P0
   Ahmed N, 2018, IEEE SIGNAL PROC LET, V25, P1408, DOI 10.1109/LSP.2018.2860238
   Ahmed NR, 2013, IEEE T ROBOT, V29, P189, DOI 10.1109/TRO.2012.2214556
   Armstrong-Crews N, 2008, IEEE INT CONF ROBOT, V0, PP3346, DOI 10.1109/ROBOT.2008.4543721
   Armstrong-Crews N, 2007, IEEE INT CONF ROBOT, V0, PP2477, DOI 10.1109/ROBOT.2007.363691
   Bai HY, 2014, INT J ROBOT RES, V33, P1288, DOI 10.1177/0278364914528255
   Bai HY, 2010, SPRINGER TRAC ADV RO, V68, P175
   Bourgault M, 2008, PROJ MANAG J, V39, PS97, DOI 10.1002/pmj.20063
   BRADSKI G, 2000, DR DOBBS J, V0, P0
   Brechtel S, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), V0, PP392, DOI 10.1109/ITSC.2014.6957722
   Brooks A, 2006, ROBOT AUTON SYST, V54, P887, DOI 10.1016/j.robot.2006.05.007
   Brunskill E, 2010, ANN MATH ARTIF INTEL, V58, P185, DOI 10.1007/s10472-010-9202-1
   Burks L, 2019, IEEE T ROBOT, V0, P0
   Burks L, 2019, 2019 22 INT C INFORM, V0, P1
   Chernova S, 2014, ROBOT LEARNING HUMAN, V8, P1, DOI 10.2200/S00568ED1V01Y201402AIM028
   Dani A, 2014, IEEE SYS MAN CYBERN, V0, PP2114, DOI 10.1109/SMC.2014.6974234
   Doshi F, 2008, CONNECT SCI, V20, P299, DOI 10.1080/09540090802413145
   Dragan AD, 2015, ACMIEEE INT CONF HUM, V0, PP51, DOI 10.1145/2696454.2696473
   Frost J, 2010, P WORKSH COMP MOD SP, V0, P0
   Gopalan N, 2015, P RSS, V32, P590
   Hall D, 2010, ARTECH HSE ELEC WARF, V0, P59
   Hayes B, 2014, IEEE INT C INT ROBOT, V0, PP4442, DOI 10.1109/IROS.2014.6943191
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X
   Kaupp T, 2007, J FIELD ROBOT, V24, P911, DOI 10.1002/rob.20201
   Kaupp T, 2010, ROBOT AUTON SYST, V58, P444, DOI 10.1016/j.robot.2010.02.003
   Khaleghi B, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI 2010), V0, PP50, DOI 10.1109/MFI.2010.5604458
   Koch W, 2004, SEVENTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, V0, P91
   Kurniawati H, 2008, ROBOTICS SCI SYSTEMS, V0, P336
   Littman ML, 1995, MACHINE LEARNING. PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING, V0, P362
   Lore KG, 2016, P 7 INT C CYB PHYS S, V0, P3
   Mehta SS, 2014, IEEE SYS MAN CYBERN, V0, PP3732, DOI 10.1109/SMC.2014.6974511
   Mueller C, 2018, IEEE INT C INT ROBOT, V0, PP6029, DOI 10.1109/IROS.2018.8594133
   Muesing J, 2019, AIAA SCIT 2019 FOR, V0, P2208
   Pineau J, 2003, P INT JOINT C ART IN, V18, P1025
   Porta JM, 2006, J MACH LEARN RES, V7, P2329
   Rosenthal S, 2011, 2011 RO-MAN: THE 20TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, V0, PP53, DOI 10.1109/ROMAN.2011.6005272
   Rosenthal S, 2011, 21 AAAI C ART INT, V0, P0
   Runnalls AR, 2007, IEEE T AERO ELEC SYS, V43, P989, DOI 10.1109/TAES.2007.4383588
   Silver D, 2010, 23 INT C NEUR INF PR, V0, PP2164, DOI 10.5555/2997046.2997137
   Somani A, 2013, ADV NEURAL INFORM PR, V0, P1772
   Sondik EJ, 1971, OPTIMAL CONTROL PART, V0, P0
   Southey T, 2007, IROS 2007 WORKSH SEN, V0, P0
   Spaan MTJ, 2005, J ARTIF INTELL RES, V24, P195, DOI 10.1613/jair.1659
   Sweet N, 2016, P AMER CONTR CONF, V0, PP5479, DOI 10.1109/ACC.2016.7526529
   van den Berg J, 2011, INT J ROBOT RES, V30, P895, DOI 10.1177/0278364911406562
   Walker ME, 2019, ACMIEEE INT CONF HUM, V0, PP202, DOI 10.1109/hri.2019.8673306
   Zhou E, 2010, IEEE T AUTOMAT CONTR, V55, P1101, DOI 10.1109/TAC.2010.2042005
NR 48
TC 7
Z9 8
U1 3
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD JUN 15
PY 2021
VL 140
IS 
BP 
EP 
DI 10.1016/j.robot.2021.103753
EA MAR 2021
PG 19
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA RQ5TD
UT WOS:000642480300012
DA 2023-11-10
ER

PT J
AU Wang, EL
   Kumar, PM
   Samuel, RDJ
AF Wang, Erlu
   Kumar, Priyan Malarvizhi
   Samuel, R. Dinesh Jackson
TI Semantic Graphical Dependence Parsing Model in Improving English Teaching Abilities
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Dependence Parsing; Semantic Graphical; Mono-parsing Text, and BiParsing Text
ID technology
AB It is a very difficult problem to achieve high-order functionality for graphical dependency parsing without growing decoding difficulties. To solve this problem, this article offers a way for Semantic Graphical Dependence Parsing Model (SGDPM) with a language-dependency model and a beam search to represent high-order functions for computer applications. The first approach is to scan a large amount of unnoticed data using a baseline parser. It will build auto-parsed data to create the Language-dependence Model (LDM). The LDM is based on a set of new features during beam search decoding, where it will incorporate the LDM features into the parsing model and utilize the features in parsing models of bilingual text. Our approach has main benefits, which include rich high-order features that are described given the large size and the additional large crude corpus for increasing the difficulty of decoding. Further, SGDPM has been evaluated using the suggested method for parsing tasks of mono-parsing text and bi-parsing text to carry out experiments on the English and Chinese data in the mono-parsing text function using computer applications. Experimental results show that the most accurate Chinese data is obtained with the best known English data systems and their comparable accuracy. Furthermore, the lab-scale experiments on the Chinese/General bilingual information in the bitext parsing process outperform the best recorded existing solutions.
C1 [Wang, Erlu] Jilin Inst Chem Technol, Sch Foreign Language, Jilin 132022, Jilin, Peoples R China.
   [Kumar, Priyan Malarvizhi] Middlesex Univ, London, England.
   [Samuel, R. Dinesh Jackson] Oxford Brookes Univ, Fac Technol Design & Environm, Visual Artificial Intelligence Lab, Oxford, England.
C3 Jilin Institute of Chemical Technology; Middlesex University; Oxford Brookes University
RP Wang, EL (通讯作者)，Jilin Inst Chem Technol, Sch Foreign Language, Jilin 132022, Jilin, Peoples R China.
EM 53182565@qq.com; mkpriyan@khu.ac.kr; rsamuel@brookes.ac.uk
FU Social Science Project of the 13th "Five-Year Plan" of Jilin Provincial Department of Education-Cultivation of English Majors' Innovative and Entrepreneurial Ability in the Information Age [JJKH20190841SK]
CR [Anonymous], 2000, ED POLICY ANAL ARCH, V0, P0, DOI DOI 10.14507/EPAA.V8N51.2000
   Bañados E, 2006, CALICO J, V23, P533, DOI 10.1558/cj.v23i3.533-550
   Bhardwaj BK, 2012, DATA MINING PREDICTI, V0, P0
   Bouhnik D, 2006, J AM SOC INF SCI TEC, V57, P299, DOI 10.1002/asi.20277
   Greenwood CR, 2001, REM SPEC EDUC, V22, P34, DOI 10.1177/074193250102200105
   Hsu HMJ, 2011, INT J INFORM ED TECH, V1, P365, DOI 10.7763/IJIET.2011.V1.59
   Johnson L, 2012, THESIS U LOUISVILLE, V0, P0
   Kern R, 2006, TESOL QUART, V40, P183, DOI 10.2307/40264516
   King J, 2002, COMPUTER ASSISTED LANGUAGE LEARNING, V15, P509, DOI 10.1076/call.15.5.509.13468
   Lau B, 2008, INT J COMPUTING ICT, V2, P19
   Ling Z, 2001, FOREIGN LANG WORLD, V6, P0
   Liu PL, 2010, COMPUT EDUC, V54, P436, DOI 10.1016/j.compedu.2009.08.027
   Liu TY, 2009, J COMPUT ASSIST LEAR, V25, P515, DOI 10.1111/j.1365-2729.2009.00329.x
   Ranalli J, 2008, COMPUT ASSIST LANG L, V21, P441, DOI 10.1080/09588220802447859
   Roschelle JM, 2000, FUTURE CHILD, V10, P76, DOI 10.2307/1602690
   Sadaf A, 2012, COMPUT EDUC, V59, P937, DOI 10.1016/j.compedu.2012.04.001
   Suh S, 2010, J COMPUT ASSIST LEAR, V26, P370, DOI 10.1111/j.1365-2729.2010.00353.x
   Tsai SC, 2011, RECALL, V23, P117, DOI 10.1017/S0958344011000048
   Wiriyachitra, 2002, THAI TESOL FOCUS, V15, P4
   WOZNEY L, 2006, J TECHNOLOGY TEACHER, V14, P173
   Yang SC, 2007, COMPUT HUM BEHAV, V23, P860, DOI 10.1016/j.chb.2006.02.015
   Young CA, 2004, CONTEMPORARY ISSUES IN TECHNOLOGY AND TEACHER EDUCATION, V4, P0
NR 22
TC 0
Z9 0
U1 1
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAY 15
PY 2021
VL 20
IS 3
BP 
EP 
DI 10.1145/3425633
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UY1JZ
UT WOS:000701288900010
DA 2023-11-10
ER

PT J
AU Zhou, ZY
   Yu, HQ
   Fan, GS
AF Zhou, Ziyi
   Yu, Huiqun
   Fan, Guisheng
TI Adversarial training and ensemble learning for automatic code summarization
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Code summarization; Program comprehension; Deep learning
AB Natural language summaries of codes are important during software development and maintenance. Recently, deep learning-based models have achieved good performance on automatic code summarization, which encode token sequence or abstract syntax tree (AST) of code with neural networks. However, almost all of these models are trained using maximum likelihood estimation, which do not guarantee the quality of generated summaries. Moreover, existing models that benefit from multiple encoders lack a fined-grained selection between different encoders, and the encoders may be insufficiently optimized. To address these issues and generate better code summaries, we propose a novel code summarization framework based on adversarial training and ensemble learning. It includes two separately trained encoder-decoder models, one for source code sequence and the other for its AST. Here, an efficient approach to obtain AST node sequence is introduced. We train our models via adversarial training, where each model is guided by a well-designed discriminator that learns to evaluate its outputs. During inference, a module named mixture network is introduced to compute an adaptive combination weight of the models' outputs. We evaluate our framework on a large Java corpus and compare it to several state-of-the-art models. Experimental results show that our approach outperforms the best baseline by 22.6% on BLEU-4, 5.7% on ROUGE-L and 7.6% on METEOR.
C1 [Zhou, Ziyi; Yu, Huiqun; Fan, Guisheng] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Yu, Huiqun] Shanghai Engn Res Ctr Smart Energy, Shanghai, Peoples R China.
C3 East China University of Science & Technology
RP Yu, HQ (通讯作者)，East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.; Yu, HQ (通讯作者)，Shanghai Engn Res Ctr Smart Energy, Shanghai, Peoples R China.
EM zhouziyi@mail.ecust.edu.cn; yhq@ecust.edu.cn; gsfan@ecust.edu.cn
FU NSF of China [61772200, 61702334]; Shanghai Pujiang Talent Program [17PJ1401900]; Shanghai Municipal Natural Science Foundation [17ZR1406900, 17ZR1429700]; Educational Research Fund of ECUST [ZH1726108]
CR Allamanis M, 2016, PR MACH LEARN RES, V48, P0
   Alon Uri, 2019, P 7 INT C LEARN REPR, V0, P0
   [Anonymous], 2006, 11 C EUROPEAN CHAPTE, V0, P0, DOI DOI 10.1145/1083784.1083789
   [Anonymous], 2015, CONF EMP METH NAT LA, V0, P0
   Brockschmidt, 2019, 7 INT C LEARN REPR, V0, P0
   Chen B, 2014, P 9 WORKSH STAT MACH, V0, P362
   Chen C, 2019, AAAI CONF ARTIF INTE, V0, P8142
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   Dognin P, 2019, PROC CVPR IEEE, V0, PP10455, DOI 10.1109/CVPR.2019.01071
   Garmash E, 2016, COLING, V0, P1409
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gui J, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Haiduc S, 2010, 2010 32ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), V0, PP223, DOI 10.1145/1810295.1810335
   Haiduc S, 2010, PROCEEDINGS 17TH WORKING CONFERENCE ON REVERSE ENGINEERING (WCRE 2010), V0, PP35, DOI 10.1109/WCRE.2010.13
   Hellendoorn VJ, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP763, DOI 10.1145/3106237.3106290
   Hu X, 2020, EMPIR SOFTW ENG, V25, P2179, DOI 10.1007/s10664-019-09730-9
   Hu X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2269
   Hu X, 2018, INT C PROGRAM COMPRE, V0, PP200, DOI 10.1145/3196321.3196334
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Kingma DP, 2014, C TRACK P, V0, P0
   Konda VR, 1999, P 12 INT C NEURAL IN, V0, P1008
   LeClair A, 2020, INT C PROGRAM COMPRE, V0, PP184, DOI 10.1145/3387904.3389268
   LeClair A, 2019, PROC INT CONF SOFTW, V0, PP795, DOI 10.1109/ICSE.2019.00087
   Li Jiwei, 2017, EMNLP, V0, P0
   Liang YD, 2018, AAAI CONF ARTIF INTE, V0, P5229
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   McBurney PW, 2016, IEEE T SOFTWARE ENG, V42, P103, DOI 10.1109/TSE.2015.2465386
   Mirza M, 2014, ARXIV14111784, V0, P0, DOI DOI 10.48550/ARXIV.1411.1784
   Moreno L, 2013, CONF PROC INT SYMP C, V0, PP23, DOI 10.1109/ICPC.2013.6613830
   Movshovitz-Attias D, 2013, P 51 ANN M ASS COMP, V2, P35
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Ranzato M, 2016, ICLR, V0, P1
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Sridhara G, 2010, AUTOMATICALLY GENERA, V0, PP43, DOI 10.1145/1858996.1859006
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Wan Y, 2018, IEEE INT CONF AUTOM, V0, PP397, DOI 10.1145/3238147.3238206
   Wei B, 2019, NEURIPS, V0, P6559
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wong E, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Wong E, 2013, IEEE INT CONF AUTOM, V0, PP562, DOI 10.1109/ASE.2013.6693113
   Wu L, 2018, ASIAN C MACHINE LEAR, V0, P534
   Wu Y, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Yang Zhen, 2018, P NAACL HLT, V1, P1346, DOI 10.18653/v1/N18-1122
   Ye W, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2309, DOI 10.1145/3366423.3380295
   Yu L, 2017, PROCEEDINGS OF THE ASME 36TH INTERNATIONAL CONFERENCE ON OCEAN, V0, P0
NR 54
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD OCT 15
PY 2021
VL 33
IS 19
BP 12571
EP 12589
DI 10.1007/s00521-021-05907-w
EA MAY 2021
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WI8EC
UT WOS:000647349100001
DA 2023-11-10
ER

PT J
AU Gao, YZ
   Chen, YY
   Wang, JQ
   Lu, HQ
AF Gao, Yunze
   Chen, Yingying
   Wang, Jinqiao
   Lu, Hanqing
TI Semi-Supervised Scene Text Recognition
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Text recognition; Reinforcement learning; Training; Feature extraction; Annotations; Probability distribution; Predictive models; Semi-supervised scene text recognition; embedding; reinforcement learning
ID neural-network
AB Scene text recognition has been widely researched with supervised approaches. Most existing algorithms require a large amount of labeled data and some methods even require character-level or pixel-wise supervision information. However, labeled data is expensive, unlabeled data is relatively easy to collect, especially for many languages with fewer resources. In this paper, we propose a novel semi-supervised method for scene text recognition. Specifically, we design two global metrics, i.e., edit reward and embedding reward, to evaluate the quality of generated string and adopt reinforcement learning techniques to directly optimize these rewards. The edit reward measures the distance between the ground truth label and the generated string. Besides, the image feature and string feature are embedded into a common space and the embedding reward is defined by the similarity between the input image and generated string. It is natural that the generated string should be the nearest with the image it is generated from. Therefore, the embedding reward can be obtained without any ground truth information. In this way, we can effectively exploit a large number of unlabeled images to improve the recognition performance without any additional laborious annotations. Extensive experimental evaluations on the five challenging benchmarks, the Street View Text, IIIT5K, and ICDAR datasets demonstrate the effectiveness of the proposed approach, and our method significantly reduces annotation effort while maintaining competitive recognition performance.
C1 [Gao, Yunze; Chen, Yingying; Wang, Jinqiao; Lu, Hanqing] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
   [Gao, Yunze; Chen, Yingying; Wang, Jinqiao; Lu, Hanqing] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Chen, YY (通讯作者)，Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
EM yunze.gao@nlpr.ia.ac.cn; yingying.chen@nlpr.ia.ac.cn; jqwang@nlpr.ia.ac.cn; luhq@nlpr.ia.ac.cn
FU Research and Development Projects in the Key Areas of Guangdong Province [2019B010153001]; National Natural Science Foundation of China [61772527, 61806200, 62006230, 61876086]
CR Al-Shamma O, 2014, P 72 ANN INT C MASS, V0, P1
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   [Anonymous], 2017, P WEB WIR GEOGR INF, V0, P0
   Bai F, 2018, PROC CVPR IEEE, V0, PP1508, DOI 10.1109/CVPR.2018.00163
   Bai X, 2016, IEEE T IMAGE PROCESS, V25, P2789, DOI 10.1109/TIP.2016.2555080
   Bissacco A, 2013, IEEE I CONF COMP VIS, V0, PP785, DOI 10.1109/ICCV.2013.102
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI 10.1109/TIP.2015.2400217
   Cheng ZZ, 2018, PROC CVPR IEEE, V0, PP5571, DOI 10.1109/CVPR.2018.00584
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, V0, PP5086, DOI 10.1109/ICCV.2017.543
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Chorowski Jan, 2015, ADV NEURAL INFORM PR, V0, P0, DOI DOI 10.1016/0167-739X(94)90007-8
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Ghosh SK, 2017, PROC INT CONF DOC, V0, PP943, DOI 10.1109/ICDAR.2017.158
   Goel V, 2013, PROC INT CONF DOC, V0, PP398, DOI 10.1109/ICDAR.2013.87
   Gordo A, 2015, PROC CVPR IEEE, V0, PP2956, DOI 10.1109/CVPR.2015.7298914
   Graves Alex, 2006, ICML, V0, PP369, DOI 10.1145/1143844.1143891
   He P, 2016, AAAI CONF ARTIF INTE, V0, P3501
   Huang Thomas, 2011, P 20 INT C WORLD WID, V0, PP297, DOI 10.1145/1963405.1963449
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Jaderberg M, 2014, NIPS DEEP LEARN WORK, V0, P0
   Jaderberg M, 2015, ICLR, V0, PP2017, DOI 10.1038/NBT.3343
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Karatzas D, 2015, PROC INT CONF DOC, V0, PP1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, V0, PP1484, DOI 10.1109/ICDAR.2013.221
   Ketkar, 1900, V2017, V0, P195
   Kingma DP, 2014, C TRACK P, V0, P0
   Lee CY, 2016, PROC CVPR IEEE, V0, PP2231, DOI 10.1109/CVPR.2016.245
   Liu W, 2018, AAAI CONF ARTIF INTE, V0, P7154
   Liu Wei, 2016, BMVC, V0, P0
   Liu ZC, 2018, AAAI CONF ARTIF INTE, V0, P7194
   Lucas SM, 2005, INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION, V7, P105, DOI 10.1007/s10032-004-0134-3
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, V0, P0, DOI DOI 10.5244/C.26.127
   Mishra A, 2012, PROC CVPR IEEE, V0, PP2687, DOI 10.1109/CVPR.2012.6247990
   Novikova T, 2012, LECT NOTES COMPUT SC, V7577, P752, DOI 10.1007/978-3-642-33783-3_54
   Qi G, 2009, P ACM INT C MULT, V0, P243
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, V0, PP4168, DOI 10.1109/CVPR.2016.452
   Shu XB, 2015, MM15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, V0, PP35, DOI 10.1145/2733373.2806216
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Wang J, 2017, NEURIPS, V0, P334
   Wang K, 2011, IEEE I CONF COMP VIS, V0, PP1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, V0, P3304
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Yang Chaofei, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3280
   Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813
   Yi CC, 2014, IEEE T IMAGE PROCESS, V23, P2972, DOI 10.1109/TIP.2014.2317980
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
   Zaremba Wojciech, 2015, ABS151106732 CORR, V0, P0
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 54
TC 5
Z9 5
U1 1
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PD JUN 15
PY 2021
VL 30
IS 
BP 3005
EP 3016
DI 10.1109/TIP.2021.3051485
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA QL9KO
UT WOS:000621399700002
PM 33471761
DA 2023-11-10
ER

PT J
AU van Dinter, R
   Catal, C
   Tekinerdogan, B
AF van Dinter, Raymon
   Catal, Cagatay
   Tekinerdogan, Bedir
TI A Multi-Channel Convolutional Neural Network approach to automate the citation screening process
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Systematic literature review (SLR); Citation screening; Automation; Neural networks; Natural language processing
ID systematic reviews; classification; text; workload
AB The systematic literature review (SLR) process is separated into several steps to increase rigor and reproducibility. The selection of primary studies (i.e., citation screening) is an important step in the SLR process. The citation screening process aims to identify the relevant primary studies fairly and with high rigor using selection criteria. Through the study selection criteria, reviewers determine whether an article should be included or excluded from the SLR. However, the screening process is highly time-consuming and error-prone as the researchers must read each title and possibly hundreds to thousands of abstracts and full-text documents. This study aims to automate the citation screening process using Deep Learning algorithms. With this, it is aimed to reduce the time and costs of the citation screening process and increase the precision and recall of the relevant primary studies. A Multi Channel Convolutional Neural Network (CNN) is proposed, which can automatically classify a given set of citations. As the architecture uses the title and abstract as features, our end-to-end pipeline is domain-independent. We have performed six experiments to assess the performance of Multi-Channel CNNs across 20 publicly available systematic literature review datasets. It was shown that for 18 out of 20 review datasets, the proposed method achieved significant workload savings of at least 10%, while in several cases, our model yielded a statistically significantly better performance over two benchmark review datasets. We conclude that Multi-Channel CNNs are effective for the citation screening process in SLRs. Multi-Channel CNNs perform best on large datasets of over 2500 samples with few abstracts missing. (C) 2021 The Author(s). Published by Elsevier B.V.
C1 [van Dinter, Raymon; Tekinerdogan, Bedir] Wageningen Univ & Res, Informat Technol Grp, Wageningen, Netherlands.
   [Catal, Cagatay] Qatar Univ, Comp Sci & Engn, Doha, Qatar.
C3 Wageningen University & Research; Qatar University
RP Catal, C (通讯作者)，Qatar Univ, Comp Sci & Engn, Doha, Qatar.
EM raymon.vandinter@wur.nl; ccatal@qu.edu.qa; bedir.tekinerdogan@wur.nl
FU Qatar National Library
CR Almeida H, 2016, IEEE T NANOBIOSCI, V15, P354, DOI 10.1109/TNB.2016.2565481
   [Anonymous], 2010, P 23 INT C COMPUTATI, V0, P0
   Bannach-Brown A, 2019, SYST REV-LONDON, V8, P0, DOI 10.1186/s13643-019-0942-7
   Bartholomew M, 2002, POSTGRAD MED J, V78, P695, DOI 10.1136/pmj.78.925.695
   Bekhuis T, 2012, ARTIF INTELL MED, V55, P197, DOI 10.1016/j.artmed.2012.05.002
   Beller EM, 2013, SYST REV-LONDON, V2, P0, DOI 10.1186/2046-4053-2-36
   Brownlee J, 2019, GENTLE INTRO TRANSFE, V0, P0
   Brownlee J, 2016, MACHINE LEARNING MAS, V0, P0
   Brownlee J, 2019, MACHINE LEARNING MAS, V0, P0
   Brownlee J, 2018, GENTLE INTRO K FOLD, V0, P0
   Brownlee J, 2017, DEEP LEARNING NATURA, V0, P0
   Bui DDA, 2016, J BIOMED INFORM, V64, P265, DOI 10.1016/j.jbi.2016.10.014
   Cohen AM, 2011, J AM MED INFORM ASSN, V18, P104, DOI 10.1136/jamia.2010.008177
   Cohen AM, 2009, J AM MED INFORM ASSN, V16, P690, DOI 10.1197/jamia.M3162
   Cohen AM, 2006, J AM MED INFORM ASSN, V13, P206, DOI 10.1197/jamia.M1929
   Cohen KB, 2010, BMC BIOINFORMATICS, V11, P0, DOI 10.1186/1471-2105-11-492
   Colón-Ruiz C, 2020, J BIOMED INFORM, V110, P0, DOI 10.1016/j.jbi.2020.103539
   De Rubira Tomas Tinoco, 2016, 2016 POWER SYSTEMS COMPUTATION CONFERENCE (PSCC), V0, PP1, DOI 10.1109/PSCC.2016.7540930
   Dieste Oscar, 2007, 2007 FIRST INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT, V0, P215
   Felizardo KR, 2014, P 18 INT C EVALUATIO, V0, P4
   Felizardo KR, 2012, INFORM SOFTWARE TECH, V54, P1079, DOI 10.1016/j.infsof.2012.04.003
   Frunza O, 2011, ARTIF INTELL MED, V51, P17, DOI 10.1016/j.artmed.2010.10.005
   Adeva JJG, 2014, EXPERT SYST APPL, V41, P1498, DOI 10.1016/j.eswa.2013.08.047
   González-Toral S, 2019, 2019 XLV LATIN AMERICAN COMPUTING CONFERENCE (CLEI 2019), V0, P0, DOI DOI 10.1109/CLEI47609.2019.235079
   Google Code Archive, 2013, WORD2VEC, V0, P0
   Gurbuz HG, 2018, SOFTWARE QUAL J, V26, P1327, DOI 10.1007/s11219-017-9386-2
   Hashimoto K, 2016, J BIOMED INFORM, V62, P59, DOI 10.1016/j.jbi.2016.06.001
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Howard BE, 2016, SYST REV, V5, P0, DOI 10.1186/s13643-016-0263-z
   Jacovi Alon, 2018, P 2018 EMNLP WORKSHO, V0, P0, DOI DOI 10.18653/V1/W18-5408
   Jha S, 2018, CAPSULE NETWORKS CRI, V0, P0
   Johnson JM, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0192-5
   Kim S, 2014, J BIOMED INFORM, V47, P153, DOI 10.1016/j.jbi.2013.10.005
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Kitchenham B, 2007, TECHNICAL REPORT EBS, V0, P0, DOI DOI 10.1145/1134285.1134500
   Kontonatsios G, 2020, EXPERT SYST APPL, V0, P0
   Kontonatsios G, 2017, J BIOMED INFORM, V72, P67, DOI 10.1016/j.jbi.2017.06.018
   Langlois A, 2018, RES SYNTH METHODS, V9, P587, DOI 10.1002/jrsm.1317
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Matwin S, 2010, J AM MED INFORM ASSN, V17, P446, DOI 10.1136/jamia.2010.004325
   Minaee S, 2020, MED IMAGE ANAL, V65, P0, DOI 10.1016/j.media.2020.101794
   Ng A, 2017, MACHINE LEARNING YEA, V0, P0
   Olorisade BK, 2019, J BIOMED INFORM, V94, P0, DOI 10.1016/j.jbi.2019.103202
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Sawant M, 2019, TEXT SENTIMENTS CLAS, V0, P0
   Sellak H, 2015, P 17 INT C INF INT W, V0, P43
   Timsina P, 2016, INFORM SYST FRONT, V18, P237, DOI 10.1007/s10796-015-9589-7
   Tsafnat G, 2018, SYST REV-LONDON, V7, P0, DOI 10.1186/s13643-018-0724-7
   van Dinter R, 2021, INFORM SOFTWARE TECH, V136, P0, DOI 10.1016/j.infsof.2021.106589
   Wallace BC, 2010, P 16 ACM SIGKDD INT, V0, PP173, DOI 10.1145/1835804.1835829
   Wallace BC, 2010, BMC BIOINFORMATICS, V11, P0, DOI 10.1186/1471-2105-11-55
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yenter A, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, V0, P540, DOI 10.1109/UEMCON.2017.8249013
   Zhang YS, 2019, CHINESE J ELECTRON, V28, P120, DOI 10.1049/cje.2018.11.004
   Zhou Chunting, 2015, ARXIV, V0, P0
NR 58
TC 6
Z9 6
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD NOV 15
PY 2021
VL 112
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107765
EA AUG 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA XG2OH
UT WOS:000724596900017
DA 2023-11-10
ER

PT J
AU Zhao, JY
   Zhan, ZQ
   Li, T
   Li, R
   Hu, CJ
   Wang, SY
   Zhang, Y
AF Zhao, Jianyu
   Zhan, Zhiqiang
   Li, Tong
   Li, Rang
   Hu, Changjian
   Wang, Siyun
   Zhang, Yang
TI Generative adversarial network for Table-to-Text generation
SO NEUROCOMPUTING
LA English
DT Article
DE Table-to-Text generation; Natural language generation; Generative adversarial network
AB Table-to-Text generation aims to generate descriptions which can be viewed as a set of field-value records for factual tables. Despite the significant progress, the state-of-the-art models suffer from two major issues: Nonfluency and Divergence. Nonfluency means descriptions generated by models are not as fluent as those generated by humans, and thus can be distinguished easily. Divergence refers to the fact that the generated sentences contain information which can not be concluded from factual tables. This could be attributed to that most neural models are trained with the Maximum Likelihood Estimation (MLE) loss and use divergence-contained references as the ground truth, which forces the models to learn what cannot be inferred from the source to some extent. Motivated by the limitations of current models, we propose a novel GAN-based model with adversarial learning mechanism, which simultaneously trains a generative model G and a discriminative model D, to address Nonfluency and Divergence issues in Table-to-Text generation. Specifically, we build the generator G as an agent of reinforcement learning with a sequence-to-sequence architecture, which takes the raw data as input and predicts the generated sentences. Meanwhile, we build the discriminator D with a Convolutional Neural Network (CNN) to calculate rewards to measure the fluency of generations. To judge the fidelity of generations with regard to the original table more accurately, we also calculate the rewards from BLEU Table. With the fusion rewards from CNN and BLEU-Table, our methods outperform the baselines by a large margin on the WikiBio and Wiki3C benchmarks evaluated with BLEU, ROURGE, and PARENT. Specifically, our models achieve 49.0 (BLEU-4), 37.8 (ROUGE-4) and 45.4 (PARENT) on WikiBio, as well as 12.9 (BLEU-4) and 6.9 (ROUGE-4) on Wiki3C. More importantly, we construct a new Wiki3C dataset that improves the insufficiency of datasets and promote the progress in Table-to-Text generation. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhao, Jianyu; Li, Rang; Hu, Changjian] Lenovo Res, AI Lab, Beijing, Peoples R China.
   [Zhan, Zhiqiang; Zhang, Yang] Lenovo Res, Smart Educ Lab, Beijing, Peoples R China.
   [Li, Tong] Beijing Univ Technol, Comp Sci, Beijing, Peoples R China.
   [Wang, Siyun] Univ Southern Calif, Los Angeles, CA 90089 USA.
C3 Legend Holdings; Lenovo; Legend Holdings; Lenovo; Beijing University of Technology; University of Southern California
RP Zhang, Y (通讯作者)，Lenovo Res, Smart Educ Lab, Beijing, Peoples R China.
EM zhangyang20@lenovo.com
CR [Anonymous], 2015, CORR, V0, P0
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Chen DL, 2008, P 25 INT C MACH LEAR, V0, PP128, DOI 10.1145/1390156.1390173
   Denton Emily L, 2015, CORR, V28, P1486
   Dhingra B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4884
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo JX, 2018, AAAI CONF ARTIF INTE, V0, P5141
   Heafield K, 2013, P 51 ANN M ASS COMP, V2, P690
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kingma DP, 2014, C TRACK P, V0, P0
   Kukich K, 1983, 21ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P145
   Lebret Remi, 2016, P 2016 C EMP METH NA, V0, PP1203, DOI 10.18653/v1/D16-1128
   Li Jiwei, 2016, EMNLP, V0, P0
   Liang P, 2009, P JOINT C 47 ANN M A, V0, PP91, DOI 10.1007/978-3-642-02374-3_6
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu TY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5985
   Liu TY, 2018, AAAI CONF ARTIF INTE, V0, P4881
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Puduppully R, 2019, AAAI CONF ARTIF INTE, V0, P6908
   Radford A, 2016, 4 INT C LEARN REPR I, V0, P0
   Reiter E, 1997, NATURAL LANGUAGE ENGINEERING, V3, P57, DOI 10.1017/S1351324997001502
   Rohrbach A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4035
   Rush AM, 2015, P EMNLP 15, V0, P0
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Sha L, 2018, AAAI CONF ARTIF INTE, V0, P5414
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Wang K, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4446
   Wiseman S, 2017, P 2017 C EMPIRICAL M, V0, P0
   Wu ML, 2017, INT CONF RES INNOV, V0, P0
   Xu JJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3940
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
NR 34
TC 5
Z9 5
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD SEP 10
PY 2021
VL 452
IS 
BP 28
EP 36
DI 10.1016/j.neucom.2021.04.036
EA MAY 2021
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SU4EC
UT WOS:000663092000003
DA 2023-11-10
ER

PT J
AU Miao, XX
   McLoughlin, I
   Wang, WC
   Zhang, PY
AF Miao, Xiaoxiao
   McLoughlin, Ian
   Wang, Wenchao
   Zhang, Pengyuan
TI D-MONA: A dilated mixed-order non-local attention network for speaker and language recognition
SO NEURAL NETWORKS
LA English
DT Article
DE Speaker/language recognition; Mixed-order attention; Non-local attention; Dilated network
AB Attention-based convolutional neural network (CNN) models are increasingly being adopted for speaker and language recognition (SR/LR) tasks. These include time, frequency, spatial and channel attention, which can focus on useful time frames, frequency bands, regions or channels while extracting features. However, these traditional attention methods lack the exploration of complex information and multi-scale long-range speech feature interactions, which can benefit SR/LR tasks. To address these issues, this paper firstly proposes mixed-order attention (MOA) for low frame-level speech features to gain the finest grain multi-order information at higher resolution. We then combine that with a non local attention (NLA) mechanism and a dilated residual structure to balance fine grained local detail with convolution from multi-scale long-range time/frequency regions in feature space. The proposed dilated mixed-order non-local attention network (D-MONA) exploits the detail available from the first and the second-order feature attention analysis, but achieves this over a much wider context than purely local attention. Experiments are conducted on three datasets, including two SR tasks of Voxceleb and CN-celeb, and one LR task, NIST LRE 07. For SR, D-MONA improves on ResNet-34 results by at least 29% and 15% for Voxceleb1 and CN-celeb respectively. For the LR task, a large improvement is achieved over ResNet-34 of 21% for the challenging 3s utterance condition, 59% for the 10s condition and 67% for the 30s condition. It also outperforms the state-of-the-art deep bottleneck feature-DNN (DBF-DNN) x-vector system at all scales. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Miao, Xiaoxiao; Wang, Wenchao; Zhang, Pengyuan] Chinese Acad Sci, Inst Acoust, Key Lab Speech Acoust & Content Understanding, Beijing, Peoples R China.
   [Miao, Xiaoxiao; Wang, Wenchao; Zhang, Pengyuan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [McLoughlin, Ian] Singapore Inst Technol, ICT Cluster, 10 Dover Dr, Singapore, Singapore.
C3 Chinese Academy of Sciences; Institute of Acoustics, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Singapore Institute of Technology
RP Miao, XX (通讯作者)，Chinese Acad Sci, Inst Acoust, Key Lab Speech Acoust & Content Understanding, Beijing, Peoples R China.
EM miaoxiaoxiao@hccl.ioa.ac.cn; ian.mcloughlin@singaporetech.edu.sg; wangwenchao@hccl.ioa.ac.cn; zhangpengyuan@hccl.ioa.ac.cn
CR Abel A, 2020, ARXIVABS200404095, V0, P0
   Bhattacharya G, 2017, INTERSPEECH, V0, PP1517, DOI 10.21437/Interspeech.2017-1575
   Cai SJ, 2017, IEEE I CONF COMP VIS, V0, PP511, DOI 10.1109/ICCV.2017.63
   Cai W, 2018, P OD 2018 SPEAK LANG, V0, P74
   Cai WC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5189, DOI 10.1109/ICASSP.2018.8462025
   Chen BH, 2019, IEEE I CONF COMP VIS, V0, PP371, DOI 10.1109/ICCV.2019.00046
   Chen L, 2017, PROC CVPR IEEE, V0, PP6298, DOI 10.1109/CVPR.2017.667
   Chowdhury FARR, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5359, DOI 10.1109/ICASSP.2018.8461587
   Dai L, 2020, P INTERSPEECH, V0, P3007
   Dehak N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P864
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Deng J, 2019, P IEEE C COMP VIS PA, V0, PP4690, DOI 10.1109/CVPR.2019.00482
   Heigold G, 2016, INT CONF ACOUST SPEE, V0, PP5115, DOI 10.1109/ICASSP.2016.7472652
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/TPAMI.2019.2913372
   Jiang B, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0100795
   Jiang YH, 2019, INTERSPEECH, V0, PP4040, DOI 10.21437/Interspeech.2019-1606
   Jin M, 2018, IEEE-ACM T AUDIO SPE, V26, P171, DOI 10.1109/TASLP.2017.2766023
   Ko T, 2017, INT CONF ACOUST SPEE, V0, PP5220, DOI 10.1109/ICASSP.2017.7953152
   Kohler MA, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P0
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Li K, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Li X, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Liu J, 2019, CORR, V0, P0
   Miao X, 2019, CIRC SYST SIGNAL PR, V0, P1
   Miao XX, 2019, INTERSPEECH, V0, PP4080, DOI 10.21437/Interspeech.2019-1256
   Miao XX, 2018, IEEE W SP LANG TECH, V0, PP98, DOI 10.1109/SLT.2018.8639522
   Moreno PJ, 2014, INTERSPEECH, V0, P0
   Nagrani A, 2020, COMPUT SPEECH LANG, V60, P0, DOI 10.1016/j.csl.2019.101027
   Nagrani A, 2017, INTERSPEECH, V0, PP2616, DOI 10.21437/Interspeech.2017-950
   Okabel K, 2018, INTERSPEECH, V0, PP2252, DOI 10.21437/Interspeech.2018-993
   Ouellet P, 2014, PROC ODYSSEY, V2014, P293
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Shi Y, 2020, PROC ODYSSEY 2020 SP, V0, P451
   Snyder D, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Snyder D, 2018, P OD JUN, V0, P105
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5329
   Song Y, 2015, 16 ANN C INT SPEECH, V0, P0
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wan L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4879, DOI 10.1109/ICASSP.2018.8462665
   Wang H, 2018, PROC CVPR IEEE, V0, PP1248, DOI 10.1109/CVPR.2018.00136
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Xia B, 2019, IEEE I CONF COMP VIS, V0, PP3759, DOI 10.1109/ICCV.2019.00386
   Xiang X, 2019, ASIAPAC SIGN INFO PR, V0, PP1652, DOI 10.1109/APSIPAASC47483.2019.9023039
   Yu F, 2017, PROC CVPR IEEE, V0, PP636, DOI 10.1109/CVPR.2017.75
   Yun Lei, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P1695, DOI 10.1109/ICASSP.2014.6853887
   Zeinali H, 2019, SYSTEM DESCRIPTION V, V0, P0
   Zhu YK, 2018, INTERSPEECH, V0, PP3573, DOI 10.21437/Interspeech.2018-1158
NR 49
TC 6
Z9 6
U1 0
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD JUL 15
PY 2021
VL 139
IS 
BP 201
EP 211
DI 10.1016/j.neunet.2021.03.014
EA MAR 2021
PG 11
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA SF3TP
UT WOS:000652682000003
PM 33780726
DA 2023-11-10
ER

PT J
AU Liu, S
   Yang, H
   Li, JY
   Kolmanic, S
AF Liu, Shuang
   Yang, Hui
   Li, Jiayi
   Kolmanic, Simon
TI Chinese Named Entity Recognition Method in History and Culture Field Based on BERT
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS
LA English
DT Article
DE History and culture; Named entity recognition; Bert pre-training model; Bidirectional long short-term memory network
AB With rapid development of the Internet, people have undergone tremendous changes in the way they obtain information. In recent years, knowledge graph is becoming a popular tool for the public to acquire knowledge. For knowledge graph of Chinese history and culture, most researchers adopted traditional named entity recognition methods to extract entity information from unstructured historical text data. However, the traditional named entity recognition method has certain defects, and it is easy to ignore the association between entities. To extract entities from a large amount of historical and cultural information more accurately and efficiently, this paper proposes one named entity recognition model combining Bidirectional Encoder Representations from Transformers and Bidirectional Long Short-Term Memory-Conditional Random Field (BERT-BiLSTM-CRF). First, a BERT pre-trained language model is used to encode a single character to obtain a vector representation corresponding to each character. Then one Bidirectional Long Short-Term Memory (BiLSTM) layer is applied to semantically encode the input text. Finally, the label with the highest probability is output through the Conditional Random Field (CRF) layer to obtain each character's category. This model uses the Bidirectional Encoder Representations from Transformers (BERT) pre-trained language model to replace the static word vectors trained in the traditional way. In comparison, the BERT pre-trained language model can dynamically generate semantic vectors according to the context of words, which improves the representation ability of word vectors. The experimental results prove that the model proposed in this paper has achieved excellent results in the task of named entity recognition in the field of historical culture. Compared with the existing named entity identification methods, the precision rate, recall rate, and F-1 value have been significantly improved.
C1 [Liu, Shuang; Li, Jiayi] Dalian Minzu Univ, Sch Comp Sci & Engn, Dalian 116600, Peoples R China.
   [Yang, Hui] Nanjing Inst Tourism & Hospitality, Sch Hotel Management, Nanjing 211100, Peoples R China.
   [Kolmanic, Simon] Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, Maribor 2000, Slovenia.
C3 Dalian Minzu University; University of Maribor
RP Yang, H (通讯作者)，Nanjing Inst Tourism & Hospitality, Sch Hotel Management, Nanjing 211100, Peoples R China.
EM liushuang@dlnu.edu.cn; yanghuimail2020@gmail.com; ygrace788@gmail.com; simon.kolmanic@gmail.com
FU Economic and social development research project of Liaoning province in 2021 [2021lslybkt-022]; Jiangsu Provincial Social Science Applied Research Excellence Project [21SYB138]; Research Innovation Team Grant Project [2021KYTD04]
CR Ajees AP, 2019, INFORMATION, V10, P0, DOI 10.3390/info10060186
   [Anonymous], 2013, INT C LEARNING REPRE, V0, P0
   Chen SY, 2020, ROAD MATER PAVEMENT, V21, PS140, DOI 10.1080/14680629.2020.1746689
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/TACL_A_00104
   Christopher O, 2015, COLAHS BLOG 0827, V0, P0
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai Z, 2019, 2019 12 INT C IM SIG, V0, PP1, DOI 10.1109/CISP-BMEI48845.2019.8965823
   Devlin J, 2018, ARXIV, V1, P4171
   dos Santos CN, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P626
   Gorla S, 2020, INFORMATION, V11, P0, DOI 10.3390/info11020082
   Hammerton J, 2003, P 7 C NAT LANG LEARN, V4, P172, DOI 10.3115/1119176.1119202
   Han XY, 2020, INFORMATION, V11, P0, DOI 10.3390/info11020079
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Li LF, 2020, J INNER MONGOLIA U S, V39, P71
   Liu CL, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, V0, PP1629, DOI 10.1109/BigData.2015.7363931
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Marchioretto Maria Salete, 2015, PESQUISAS BOTANICA, V0, P7
   Mesnil G, 2013, INTERSPEECH, V0, P3738
   Saimaiti A, 2019, INFORMATION, V10, P0, DOI 10.3390/info10040139
   Seti X, 2020, INFORMATION, V11, P0, DOI 10.3390/info11010030
   Sie SH, 2017, PROCEEDINGS OF THE 2017 PACIFIC NEIGHBORHOOD CONSORTIUM ANNUAL CONFERENCE AND JOINT MEETINGS (PNC), V0, PP56, DOI 10.23919/PNC.2017.8203522
   Strubell E, 1900, P2670, V0, P0, DOI DOI 10.18653/v1/D17-1283.2017
   VITERBI AJ, 1989, IEEE COMMUN MAG, V27, P11, DOI 10.1109/35.31452
   Wang Y, 2020, COMPUT APPL, V40, P535
   Yang Piao, 2020, COMPUTER ENGINEERING, V46, P40, DOI 10.19678/j.issn.1000-3428.0054272
   Zhang M, 2020, ENTROPY-SWITZ, V22, P0, DOI 10.3390/e22020252
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Ziniu W, 2019, COMPUT SCI, V46, P138
NR 29
TC 3
Z9 5
U1 7
U2 9
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1875-6891
EI 1875-6883
J9 INT J COMPUT INT SYS
JI Int. J. Comput. Intell. Syst.
PD SEP 22
PY 2021
VL 14
IS 1
BP 
EP 
DI 10.1007/s44196-021-00019-8
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 0G9YN
UT WOS:000778398000001
DA 2023-11-10
ER

PT J
AU Karayigit, H
   Aci, ÇI
   Akdagli, A
AF Karayigit, Habibe
   Aci, Cigdem Inan
   Akdagli, Ali
TI Detecting abusive Instagram comments in Turkish using convolutional Neural network and machine learning methods
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Abusive comment; Hate speech; Classification; Social media; Instagram; Dataset
ID arabic text categorization; hate speech; online harassment; feature-selection; classification; twitter; context; scheme
AB Instagram is a free photo-sharing platform where each user has a profile and can upload photos for followers to view, like, and comment. Abusive comments on images can be humiliating and harmful to those who share photos. Developing a comment filter in languages other than English is difficult and time-consuming. This paper proposes a dataset called Abusive Turkish Comments (ATC) to detect abusive Instagram comments in Turkish. It is composed of a large number of Instagram comments posted to tabloid and sports accounts (i.e., 10,528 abusive and 19,826 not-abusive). It is the first public dataset dedicated to detecting abusive Turkish messages, as far as we know. The sentiment annotation has been done in sentence-level by assigning polarity to each comment. The performance of the abusive message detection models was evaluated using several performance metrics: Convolutional Neural Network (CNN), five well-known classifiers (i.e., Naive Bayes, Support Vector Machine, Decision Tree, Random Forest, and Logistic Regression), and two reweighted classifiers (i.e., Adaptive Boosting (AdaBoost), eXtreme Gradient Boosting (XGBoost)) were compared in terms of F1-score, precision, and recall. The results showed that the best performance (i.e., Micro-averaged F1-score: 0.974, Macro-averaged F1-score: 0.973, Kappa-value: 0.946) was yielded by the CNN model on the oversampled ATC dataset. The abusive message detection model proposed in this study can contribute to the development of Turkish comment filters on Instagram. Different model combinations are considered to select the best model that gives better recognition accuracy.
C1 [Karayigit, Habibe; Akdagli, Ali] Mersin Univ, Dept Elect & Elect Engn, TR-33343 Mersin, Turkey.
   [Aci, Cigdem Inan] Mersin Univ, Dept Comp Engn, TR-33343 Mersin, Turkey.
C3 Mersin University; Mersin University
RP Aci, ÇI (通讯作者)，Mersin Univ, Dept Comp Engn, TR-33343 Mersin, Turkey.
EM d2014242@mersin.edu.tr; caci@mersin.edu; akdagli@mersin.edu.tr
CR Abooraig R, 2018, DIGIT INVEST, V25, P24, DOI 10.1016/j.diin.2018.04.003
   Abroyan N, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), V0, PP42, DOI 10.1109/INTECH.2017.8102422
   Agnihotri D, 2017, EXPERT SYST APPL, V81, P268, DOI 10.1016/j.eswa.2017.03.057
   Al-garadr MA, 2016, COMPUT HUM BEHAV, V63, P433, DOI 10.1016/j.chb.2016.05.051
   Al-Hassan A, 2019, COMPUTER SCI INFORM, V0, P83
   Al-Radaideh QA, 2019, SOFT COMPUT, V23, P5849, DOI 10.1007/s00500-018-3249-z
   Alakrot A, 2018, PROCEDIA COMPUT SCI, V142, P315, DOI 10.1016/j.procs.2018.10.491
   Alayba AM, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP114, DOI 10.1109/ASAR.2017.8067771
   [Anonymous], 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1702.07800
   Aya SA, 2016, DESALIN WATER TREAT, V57, P24132, DOI 10.1080/19443994.2016.1140080
   Ayata D, 2017, PROC 25 SIGNAL PROCE, V0, PP1, DOI 10.1109/SIU.2017.7960629
   Balakrishnan V, 2020, COMPUT SECUR, V90, P0, DOI 10.1016/j.cose.2019.101710
   Bay Y, 2016, LECT NOTES ELECTR EN, V363, P371, DOI 10.1007/978-3-319-22635-4_34
   Bimantara AA, 2019, J DATA SCI ITS APPL, V2, P88, DOI 10.21108/jdsa.2.019.2.20
   BPEmb_TR, 2020, BPEMB T, V0, P0
   Briliani A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), V0, PP98, DOI 10.1109/iotais47347.2019.8980398
   Burnap P, 2015, POLICY INTERNET, V7, P223, DOI 10.1002/poi3.85
   Cakici R, 2018, WIDE COVERAGE PARSIN, V0, PP153, DOI 10.1007/978-3-319-90165-7_8
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Chaki Prakash, 2019, IEEE ICC, V0, P0, DOI DOI 10.1109/icc.2019.8761833
   Chamberlain Benjamin P, 2020, RECSYS 20: FOURTEENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS, V0, PP732, DOI 10.1145/3383313.3418486
   Charitidis P, 2020, ONLINE SOC NETW MEDI, V17, P0, DOI 10.1016/J.OSNEM.2020.100071
   Chatzakou D, 2019, ACM T WEB, V13, P0, DOI 10.1145/3343484
   Chatzakou D, 2017, PROCEEDINGS OF THE 28TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT17), V0, PP65, DOI 10.1145/3078714.3078721
   Chen H, 2017, AICS, V2086, P258
   Chen H, 2017, ADV INTELL SYST, V513, P187, DOI 10.1007/978-3-319-46562-3_12
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   DelVigna F, 2017, ITA SEC 17, V0, P0
   Demirsoz O, 2017, J INF SCI, V43, P509, DOI 10.1177/0165551516653082
   Demirtas E, 2013, P 2 INT WORKSHOP ISS, V0, P1
   Devlin J, 2018, ARXIV, V1, P4171
   Dogan T, 2019, EXPERT SYST APPL, V130, P45, DOI 10.1016/j.eswa.2019.04.015
   Drozd A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND DATA INTENSIVE SYSTEMS, V0, PP61, DOI 10.1109/DSDIS.2015.30
   Dwivedi Raghavendra Kumar, 2019, INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATIONS. PROCEEDINGS OF ICICC-2018. LECTURE NOTES IN NETWORKS AND SYSTEMS (LNNS 56), V0, PP57, DOI 10.1007/978-981-13-2354-6_7
   Eryigit Gulsen, 2008, COMPUTATIONAL LINGUISTICS, V34, P357, DOI 10.1162/coli.2008.07-017-R1-06-83
   Farahbakhsh R, 2020, COMPLEX NETWORKS THE, V0, P928
   Fatima M, 2017, J INTELL LEARN SYST, V09, P1, DOI 10.4236/JILSA.2017.91001
   Fatima S, 2017, INT RES J ENG TECHNO, V4, P141
   Freund Y, 1996, MACHINE LEARNING. PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE (ICML 96), V0, P148
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594
   Gazzah S, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, V0, PP677, DOI 10.1109/DAS.2008.74
   Golbeck J, 2017, LARGE HUMAN LABELED, V0, PP229, DOI 10.1145/ 3091478.3091509
   Google, 2020, COL, V0, P0
   Han J, 2012, MOR KAUF D, V0, P1
   He XD, 2017, IEEE SIGNAL PROC MAG, V34, P109, DOI 10.1109/MSP.2017.2741510
   Heinzerling B, 2018, P 11 INT C LANG RES, V0, P1
   Heirman W, 2008, ASSESSING CONCERNS I, V0, P0
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hmeidi I, 2015, J INF SCI, V41, P114, DOI 10.1177/0165551514558172
   Hosseinmardi Homa, 2015, DETECTION CYBERBULLY, V0, P0
   Hu Y, 2014, P 8 INT AAAI C WEBL, V0, P0
   Huang B, 2018, HUM-COMPUT INT-SPRIN, V0, PP5, DOI 10.1007/978-3-319-78583-7_2
   Huang ZL, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, V0, P0
   Ibrohim Muhammad Okky, 2018, PROCEDIA COMPUTER SCIENCE, V135, P222, DOI 10.1016/j.procs.2018.08.169
   Instagram, 2020, STATISTICS, V0, P0
   Johnson BG, 2018, INTERNET RES, V28, P1275, DOI 10.1108/IntR-03-2017-0100
   Jones LM, 2013, PSYCHOL VIOLENCE, V3, P53, DOI 10.1037/a0030309
   Karayigit H, 2020, ABUSIVE TURKISH COMM, V0, P0
   Keras, 2020, API, V0, P0
   Khan W, 2016, KUWAIT J SCI, V43, P95
   Kiliç S, 2015, J MOOD DISORD, V5, P142, DOI 10.5455/jmood.20150920115439
   Kilinc D, 2016, MARMARA J PURE APPL, V3, P89, DOI 10.7240/mufbed.69674
   Kilinç D, 2017, J INF SCI, V43, P174, DOI 10.1177/0165551515620551
   Kim H, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9112347
   Kowalski RM, 2014, PSYCHOL BULL, V140, P1073, DOI 10.1037/a0035618
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, V0, PP1621, DOI 10.5555/2891460.2891697
   Le T, 2018, SYMMETRY-BASEL, V10, P0, DOI 10.3390/sym10070250
   Lee HS, 2018, DECIS SUPPORT SYST, V113, P22, DOI 10.1016/j.dss.2018.06.009
   Levy Omer, 2014, P COMPUTATIONAL NATU, V0, P0, DOI DOI 10.3115/V1/W14-1618
   Li B, 2018, SOCIAL SCI BEIJING, V0, P38
   Liu P, 2015, P C EMP METH NAT LAN, V0, PP2326, DOI 10.18653/V1/D15-1280
   Mahmood Z, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102233
   Marujo L, 2016, KNOWL-BASED SYST, V94, P33, DOI 10.1016/j.knosys.2015.11.005
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mossie Z, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102087
   Nafan MZ, 2019, J DATA SCI ITS APPL, V2, P88, DOI 10.21108/jdsa.2 019.2.20
   Omar A, 2020, COMP PERFORMANCE MAC, V0, PP247, DOI 10.1007/978-3-030-44289-7_24
   Omar N, 2018, GEMA ONLINE J LANG S, V18, P93, DOI 10.17576/gema-2018-1802-07
   Ornek AH, 2019, INFRARED PHYS TECHN, V103, P0, DOI 10.1016/j.infrared.2019.103044
   Özel SA, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), V0, PP366, DOI 10.1109/UBMK.2017.8093411
   Park JH, 2017, ONE STEP 2 STEP CLAS, V0, P41
   Parlar T, 2019, COMPUT SCI-AGH, V20, P123, DOI 10.7494/csci.2019.20.1.3097
   Patro VM, 2015, T MACH LEARN ARTIF I, V3, P0, DOI 10.14738/TMLAI.32.1108
   Pratiwi NI, 2018, INT C ADV COMP SCI I, V0, PP447, DOI 10.1109/ICACSIS.2018.8618182
   Priyoko Beta, 2019, 2019 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATIONS TECHNOLOGY (ICOIACT), V0, P508
   Renjith S, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102078
   Sarac E, 2017, SULEYMAN DEMIREL UNI, V21, P190, DOI 10.19113/SDUFBED.20964
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Segura-Bedmar I, 2018, J BIOMED INFORM, V87, P50, DOI 10.1016/j.jbi.2018.09.012
   Seiffert C, 2008, PROC INT C TOOLS ART, V0, PP445, DOI 10.1109/ICTAI.2008.59
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP959, DOI 10.1145/2766462.2767830
   Shen YL, 2014, WWW14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP373, DOI 10.1145/2567948.2577348
   Shi HT, 2019, COMPUT METH PROG BIO, V171, P1, DOI 10.1016/j.cmpb.2019.02.005
   Shushkevich E, 2019, COMPUT SIST, V23, P1159, DOI 10.13053/CyS-23-4-3299
   Statista, 2020, TURK NUMB INST US 20, V0, P0
   Talukder A, 2020, NUTRITION, V78, P0, DOI 10.1016/j.nut.2020.110861
   Tang YW, 2019, STAT PUBLIC POLICY, V6, P80, DOI 10.1080/2330443X.2019.1660285
   TDK, 2020, TURK LANG SOC, V0, P0
   Terragni S, 2020, INFORM SCIENCES, V512, P581, DOI 10.1016/j.ins.2019.09.039
   Van Royen K, 2015, TELEMAT INFORM, V32, P89, DOI 10.1016/j.tele.2014.04.002
   VITO, 2020, NEWS, V0, P0
   Wang N, 2010, P INT C COMP COMM TE, V3, P439, DOI 10.1109/CCTAE.2010.5544382
   Waseem Z, 2018, HUM-COMPUT INT-SPRIN, V0, PP29, DOI 10.1007/978-3-319-78583-7_3
   Waseem Zeerak, 2016, P NAACL STUD RES WOR, V0, PP88, DOI 10.18653/V1/N16-2013
   Weber I, 2017, 11 INT AAAI C WEB SO, V0, P0
   Wei FS, 2018, IEEE INT CONF BIG DA, V0, PP3317, DOI 10.1109/BigData.2018.8622157
   WIEGAND M, 2018, P C N AM CHAP ASS CO, V0, P0
   Wiegand M, 2018, GERMEV 2018 SHAR TAS, V0, P0
   Yih WT, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P643
   Yildirim S, 2020, BEST EVALUATE CLASSI, V0, P0
   Yildirim S, 2020, ALGO INTELL SY, V0, PP311, DOI 10.1007/978-981-15-1216-2_12
   Yuan Bo, 2012, 2012 INT JOINT C NEU, V0, PP1, DOI 10.1109/IJCNN.2012.6252738
   Zhang A, 2020, SUBWORD EMBEDDING DI, V0, P664
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
   Zhang ZQ, 2018, LECT NOTES COMPUT SC, V10843, P745, DOI 10.1007/978-3-319-93417-4_48
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zin HM, 2018, ADV SCI LETT, V24, P933, DOI 10.1166/asl.2018.10661
NR 120
TC 17
Z9 17
U1 4
U2 32
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JUL 15
PY 2021
VL 174
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.114802
EA MAR 2021
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA SU4ZF
UT WOS:000663146900001
DA 2023-11-10
ER

PT J
AU Kaing, H
   Ding, CC
   Utiyama, M
   Sumita, E
   Sam, S
   Seng, S
   Sudoh, K
   Nakamura, S
AF Kaing, Hour
   Ding, Chenchen
   Utiyama, Masao
   Sumita, Eiichiro
   Sam, Sethserey
   Seng, Sopheap
   Sudoh, Katsuhito
   Nakamura, Satoshi
TI Towards Tokenization and Part-of-Speech Tagging for Khmer: Data and Discussion
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Khmer; annotated data; tokenization; POS-tagging; machine learning
AB As a highly analytic language, Khmer has considerable ambiguities in tokenization and part-of-speech (POS) tagging processing. This topic is investigated in this study. Specifically, a 20, 000-sentence Khmer corpus with manual tokenization and POS-tagging annotation is released after a series of work over the last 4 years. This is the largest morphologically annotated Khmer dataset as of 2020, when this article was prepared. Based on the annotated data, experiments were conducted to establish a comprehensive benchmark on the automatic processing of tokenization and POS-tagging for Khmer. Specifically, a support vector machine, a conditional random field (CRF), a long short-term memory (LSTM)-based recurrent neural network, and an integrated LSTM-CRF model have been investigated and discussed. As a primary conclusion, processing at morpheme-level is satisfactory for the provided data. However, it is intrinsically difficult to identify further grammatical constituents of compounds or phrases because of the complex analytic features of the language. Syntactic annotation and automatic parsing for Khmer will be scheduled in the near future.
C1 [Kaing, Hour; Ding, Chenchen; Utiyama, Masao; Sumita, Eiichiro] Natl Inst Informat & Commun Technol, ASTREC, Kyoto, Japan.
   [Kaing, Hour; Sudoh, Katsuhito; Nakamura, Satoshi] Nara Inst Sci & Technol, Nara, Japan.
   [Sam, Sethserey; Seng, Sopheap] Natl Inst Posts Telecoms & ICT, Phnom Penh, Cambodia.
C3 National Institute of Information & Communications Technology (NICT) - Japan; Nara Institute of Science & Technology
RP Ding, CC (通讯作者)，Natl Inst Informat & Commun Technol, ASTREC, Kyoto, Japan.
EM hour_kaing@nict.go.jp; chenchen.ding@nict.go.jp; mutiyama@nict.go.jp; eiichiro.sumita@nict.go.jp; sethserey.sam@niptict.edu.kh; sopheap.seng@niptict.edu.kh; sudoh@is.naist.jp; s-nakamura@is.naist.jp
CR [Anonymous], 1972, CONT CAMBODIAN GRAMM, V0, P0
   [Anonymous], 2004, P C EMP METH NAT LAN, V0, P0
   Bi N, 2014, SIGNAL INFORM PROCES, V0, PP1, DOI 10.1109/APSIPA.2014.7041822
   Chea V, 2015, KHMER NATURAL LANGUA, V0, P62
   Chen Xinchi, 2015, P 2015 C EMPIRICAL M, V0, PP1197, DOI 10.18653/V1/D15-1141
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Ding CC, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3373268
   Ding CC, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3325885
   Ding CC, 2019, ACM T ASIAN LOW-RESO, V18, P0, DOI 10.1145/3276773
   Ding CC, 2016, ACM T ASIAN LOW-RESO, V15, P0, DOI 10.1145/2846095
   Ding Chenchen, 2020, TOKENIZED POS TAGGED, V0, P0, DOI DOI 10.5281/zenodo.3937914
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Huang Z, 2015, BIDIRECTIONAL LSTM C, V0, P0
   Huor Chea Sok, 2004, PAN LOCALIZATION WOR, V0, P0
   Jie Yang, 2018, P 27 INT C COMP LING, V0, P3879
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Kruengkrai C, 2009, IEICE T INF SYST, VE92D, P2298, DOI 10.1587/transinf.E92.D.2298
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Mon AM, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P2980
   Neubig G, 2011, PROC 49 ANN M ASS CO, V0, P529
   Neubig Graham, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Neubig Graham, 2010, P LREC, V0, P0
   Nou Chenda, 2007, 2007 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (ICAI07), V0, P581
   Nou C, 2007, IRI 2007: PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, V0, P215
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   Riza Hammam, 2016, 2016 CONFERENCE OF THE ORIENTAL CHAPTER OF INTERNATIONAL COMMITTEE FOR COORDINATION AND STANDARDIZATION OF SPEECH DATABASES AND ASSESSMENT TECHNIQUES (O-COCOSDA), V0, PP1, DOI 10.1109/ICSDA.2016.7918974
   Seng S, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2658
   Sollich P, 1996, ADV NEUR IN, V8, P190
   Sumita Eiichiro, 2017, P PACLING, V0, P179
   Yang J, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P74
   Zhao H, 2010, ACM T ASIAN LANG INF, V9, P1
NR 33
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD NOV 15
PY 2021
VL 20
IS 6
BP 
EP 
DI 10.1145/3464378
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA XB8QE
UT WOS:000721586800013
DA 2023-11-10
ER

PT J
AU Lalrempuii, C
   Soni, B
   Pakray, P
AF Lalrempuii, Candy
   Soni, Badal
   Pakray, Partha
TI An Improved English-to-Mizo Neural Machine Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Neural machine translation; transformer; low-resource language; Mizo; BLEU; METEOR; TER
AB Machine Translation is an effort to bridge language barriers and misinterpretations, making communication more convenient through the automatic translation of languages. The quality of translations produced by corpus-based approaches predominantly depends on the availability of a large parallel corpus. Although machine translation of many Indian languages has progressively gained attention, there is very limited research on machine translation and the challenges of using various machine translation techniques for a low-resource language such as Mizo. In this article, we have implemented and compared statistical-based approaches with modern neural-based approaches for the English-Mizo language pair. We have experimented with different tokenization methods, architectures, and configurations. The performance of translations predicted by the trained models has been evaluated using automatic and human evaluation measures. Furthermore, we have analyzed the prediction errors of the models and the quality of predictions based on variations in sentence length and compared the model performance with the existing baselines.
C1 [Lalrempuii, Candy; Soni, Badal; Pakray, Partha] Natl Inst Technol, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Silchar
RP Lalrempuii, C (通讯作者)，Natl Inst Technol, Silchar, India.
EM candy_rs@cse.nits.ac.in; badal@cse.nits.ac.in; partha@cse.nits.ac.in
CR Ahmadnia B, 2019, OPEN COMPUT SCI, V9, P268, DOI 10.1515/comp-2019-0019
   Ahmadnia B, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP1209, DOI 10.1109/ICMLA.2018.00196
   Ahmadnia Benyamin, 2017, P INT C RECENT ADV N, V0, PP24, DOI 10.26615/978-954-452-049-6_004
   Al-Onaizan Yaser, 2016, P 2016 C EMP METH NA, V0, PP268, DOI 10.18653/V1/D16-1026
   Almansor EH, 2018, PROC INT C MACH LEAR, V0, P347
   [Anonymous], 1992, INTRO MACHINE TRANSL, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bandyopadhyay Sivaji, 2018, ARXIVARXIV181204898, V0, P0
   Bentham J, 2016, MEX INT CONF ARTIF I, V0, PP8, DOI 10.1109/MICAI-2016.2016.00010
   Chen Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1925, DOI 10.18653/v1/P17-1176
   Chhangte L, 1993, THESIS U OREGON EUGE, V0, P0
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   DUTTA I, 2017, P C INT SPEECH COMM, V0, P0, DOI DOI 10.21437/INTERSPEECH.2017-1304
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Gogoi P, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6458
   Gu JT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3622
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI 10.18653/v1/n18
   Gulcehre C, 2015, ARXIV150303535, V0, P0
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6098
   Hautli-Janisz A, 2015, MACH TRANSL, V29, P285, DOI 10.1007/s10590-015-9170-7
   He Di, 2016, ADV NEURAL INFORM PR, V0, PP820, DOI 10.5555/3157096.3157188
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Khiangte Laltluangliana, 2008, MIZOS N E INDIA INTR, V0, P0
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Knight Kevin, 2016, ABS160402201 CORR, V0, P0
   Koehn P, 2010, STAT MACHINE TRANSLA, V0, P0
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Lalrempuii Candy, 2020, MACHINE LEARNING IMA, V0, P193
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5039
   Levin E, 2006, MACH TRANSL, V0, P383
   Luong Minh-Thang, 2015, EMNLP, V0, P3
   Majumder G, 2018, LECT NOTES COMPUT SC, V9623, P623, DOI 10.1007/978-3-319-75477-2_45
   Och FJ, 2003, COMPUT LINGUIST, V29, P0
   Pakray P, 2015, 2015 FOURTEENTH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI), V0, PP3, DOI 10.1109/MICAI.2015.7
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pathak A, 2019, NEURAL COMPUT APPL, V31, P7615, DOI 10.1007/s00521-018-3601-3
   Pathak A, 2019, J INTELL SYST, V28, P465, DOI 10.1515/jisys-2018-0065
   Saini S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, V0, PP676, DOI 10.1109/CICT.2015.123
   Sankaranarayanan, 2018, P 2018 C N AM CHAPT, V0, PP112, DOI 10.18653/V1/N18-4016
   Sarkhel Sneha, 2011, ANN LIBR INF STUD, V57, P388
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, V0, P223
   Somers H, 1999, MACHINE TRANSLATION, V14, P113, DOI 10.1023/A:1008109312730
   Stolcke Andreas, 2004, P 7 INT C SPOK LANG, V0, P0
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Unanue IJ, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P880
   Vaswani A, 2017, ARXIV, V30, P5998
   Zhang B, 2017, IEEE-ACM T AUDIO SPE, V25, P2424, DOI 10.1109/TASLP.2017.2751420
   Zheng H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4251
NR 50
TC 8
Z9 8
U1 3
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL 15
PY 2021
VL 20
IS 4
BP 
EP 
DI 10.1145/3445974
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA XB8OR
UT WOS:000721582900008
DA 2023-11-10
ER

PT J
AU Laddha, A
   Hanoosh, M
   Mukherjee, D
   Patwa, P
   Narang, A
AF Laddha, Abhishek
   Hanoosh, Mohamed
   Mukherjee, Debdoot
   Patwa, Parth
   Narang, Ankur
TI Large scale multilingual sticker recommendation in messaging apps
SO AI MAGAZINE
LA English
DT Article
AB Stickers are popularly used while messaging to visually express nuanced thoughts. We describe a real-time sticker recommendation (SR) system. We decompose SR into two steps: predict the message that is likely to be sent, and substitute that message with an appropriate sticker. To address the challenges caused by transliteration of message from users' native language to the Roman script, we learn message embeddings by employing character-level CNN in an unsupervised manner. We use them to cluster semantically similar messages. Next, we predict the message cluster instead of the message. Except for validation, our system does not require human labeled data, leading to a fully automatic tuning pipeline. We propose a hybrid message prediction model, which can easily run on low-end phones. We discuss message cluster to sticker mapping, addressing the multilingual needs of our users, automated tuning of the system and also propose a novel application of community detection algorithm. As of November 2020, our system contains 100k+ stickers, has been deployed for 15+ months, and is being used by millions of users.
C1 [Laddha, Abhishek; Hanoosh, Mohamed; Mukherjee, Debdoot; Patwa, Parth; Narang, Ankur] Hike Messenger, VP AI, New Delhi, India.
RP Narang, A (通讯作者)，Hike Messenger, VP AI, New Delhi, India.
EM ankur@hike.in
CR Agrawal Shipra, 2012, COLT, V23, P0
   [Anonymous], 2016, EMNLP, V0, P0
   [Anonymous], 2015, NIPSX 15 P 28 INT C, V0, P0
   Barbieri F, 2018, NAACL, V0, P0
   Barbieri F, 2017, EACL, V0, P0
   Chung J, 2014, CORR, V0, P0
   Clauset A, 2004, PHYS REV E, V70, P0, DOI 10.1103/PhysRevE.70.066111
   Devlin J, 2018, ARXIV, V1, P4171
   Donato G, 2017, P 8 WORKSH COMP APPR, V0, P0
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP, V0, P0
   Howard Andrew G, 2017, ARXIV170404861, V0, P0
   Jacob B, 2018, PROC CVPR IEEE, V0, PP2704, DOI 10.1109/CVPR.2018.00286
   Joulin A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2979
   Kannan A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP955, DOI 10.1145/2939672.2939801
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V28, P3, DOI 10.48550/ARXIV.1506.06726
   Laddha A, 2020, AAAI, V0, P0
   Logeswaran L, 2018, EFFICIENT FRAMEWORK, V0, P0
   McInnes L, 2017, INT CONF DAT MIN WOR, V0, PP33, DOI 10.1109/ICDMW.2017.12
   Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607
   Raghavan UN, 2007, PHYS REV E, V76, P0, DOI 10.1103/PhysRevE.76.036106
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Xing C, 2017, AAAI CONF ARTIF INTE, V0, P3351
   Yan R, 2016, SIGIR16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP55, DOI 10.1145/2911451.2911542
   Yang YF, 2018, REPRESENTATION LEARNING FOR NLP, V0, P164
   Zhang Yilin, 2018, NEURIPS, V0, P0, DOI DOI 10.5555/3326943.3327110
NR 28
TC 0
Z9 0
U1 0
U2 0
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
EI 
J9 AI MAG
JI AI Mag.
PD JUN 15
PY 2021
VL 42
IS 4
BP 16
EP 28
DI 10.1609/aaai.12023
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YW1QK
UT WOS:000753194600002
DA 2023-11-10
ER

PT J
AU Shibly, MMA
   Tisha, TA
   Tani, TA
   Ripon, S
AF Shibly, Mir Moynuddin Ahmed
   Tisha, Tahmina Akter
   Tani, Tanzina Akter
   Ripon, Shamim
TI Convolutional neural network-based ensemble methods to recognize Bangla handwritten character
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Convolutional neural network; Ensemble learning; Bangla handwritten character recognition; Deep learning; Stacked generalization; Bootstrap aggregating; Image classification; Feature extraction
ID stacked generalization
AB In this era of advancements in deep learning, an autonomous system that recognizes handwritten characters and texts can be eventually integrated with the software to provide better user experience. Like other languages, Bangla handwritten text extraction also has various applications such as post-office automation, signboard recognition, and many more. A large-scale and efficient isolated Bangla handwritten character classifier can be the first building block to create such a system. This study aims to classify the handwritten Bangla characters. The proposed methods of this study are divided into three phases. In the first phase, seven convolutional neural networks i.e., CNN-based architectures are created. After that, the best performing CNN model is identified, and it is used as a feature extractor. Classifiers are then obtained by using shallow machine learning algorithms. In the last phase, five ensemble methods have been used to achieve better performance in the classification task. To systematically assess the outcomes of this study, a comparative analysis of the performances has also been carried out. Among all the methods, the stacked generalization ensemble method has achieved better performance than the other implemented methods. It has obtained accuracy, precision, and recall of 98.68%, 98.69%, and 98.68%, respectively on the Ekush dataset. Moreover, the use of CNN architectures and ensemble methods in large-scale Bangla handwritten character recognition has also been justified by obtaining consistent results on the BanglaLekha-Isolated dataset. Such efficient systems can move the handwritten recognition to the next level so that the handwriting can easily be automated.
C1 [Shibly, Mir Moynuddin Ahmed; Tisha, Tahmina Akter; Tani, Tanzina Akter; Ripon, Shamim] East West Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
C3 East West University Bangladesh
RP Shibly, MMA; Ripon, S (通讯作者)，East West Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
EM 2016-3-60-057@std.ewubd.edu; dshr@ewubd.edu
CR Aggarwal CC, 2015, DATA MINING, V0, PP663, DOI 10.1007/978-3-319-14142-8.
   Alam S, 2018, NUMTADB ASSEMBLED BE, V0, P0
   Alif MAR, 2018, 20 INT C COMP INF TE, V0, P1
   Alom MZ, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/6747098
   [Anonymous], 2014, 2 INT C LEARN REPR I, V0, P0
   [Anonymous], 2006, IWFHR, V0, P0
   Baldominos A, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9153169
   Bhattacharya S, 2016, P INT C FRONT HANDWR, V0, P0
   Biller O, 2016, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.39
   Biswas M, 2017, DATA BRIEF, V12, P103, DOI 10.1016/j.dib.2017.03.035
   Chatterjee S, 2020, LECT NOTES COMPUTER, V11886, P0, DOI 10.1007/978-3-030-44689-5_13
   Chen T, 2016, P 22 ACM SIGKDD INT, V0, P785
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Chowdhury RR, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, V0, P0
   Ciresan DC, 2011, PROC INT CONF DOC, V0, PP1135, DOI 10.1109/ICDAR.2011.229
   Das A, 2018, INT C PATT RECOG, V0, PP3180, DOI 10.1109/ICPR.2018.8545630
   Das N, 2014, INT J DOC ANAL RECOG, V17, P413, DOI 10.1007/s10032-014-0222-y
   Fidalgo E, 2018, PATTERN RECOGN LETT, V112, P176, DOI 10.1016/j.patrec.2018.06.033
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   Han J, 2012, MOR KAUF D, V0, P1
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   IDEAL, 2017, LECT NOTES COMPUTER, V10585, P0
   Ju C, 2018, J APPL STAT, V45, P2800, DOI 10.1080/02664763.2018.1441383
   Khan HA, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, V0, P0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsson G, 2019, 5 INT C LEARN REPR I, V0, P0
   Manoharan DS, 2019, J INNOV IMAGE PROCES, V1, P31, DOI 10.36548/JIIP.2019.1.004
   Nicolas-Alonso LF, 2015, IEEE T NEUR SYS REH, V23, P702, DOI 10.1109/TNSRE.2015.2398573
   Opitz D, 1999, J ARTIF INTELL RES, V11, P169, DOI 10.1613/JAIR.614
   Pal U, 2007, P 10 INT C INF TECHN, V0, P0
   Peng Y, 2017, INTELLIGENT DATA ENG, V0, P0
   Perez L, 2017, ARXIV171204621, V0, P0
   Pham H, 2020, P INT C FRONT HANDWR, V0, P0
   Rabby AKMSA, 2019, COMMUNICATIONS COMPU, V0, P0
   Rahaman Mamun M, 2018, 2018 INT C BANGL SPE, V0, P21
   Rahman Mahbubar, 2015, INTERNATIONAL JOURNAL OF IMAGE, V0, P0
   Rajaraman S, 2018, P ANN INT C IEEE ENG, V0, P0
   Ranzato M, 2007, NEURIPS, V0, P0
   Reza S, 2019, INT C BANGL SPEECH L, V0, P0
   Sarkar R, 2012, INT J DOC ANAL RECOG, V15, P71, DOI 10.1007/s10032-011-0148-6
   Sarkhel R, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), V0, PP325, DOI 10.1109/ReTIS.2015.7232899
   Sazal MMR, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRICAL INFORMATION AND COMMUNICATION TECHNOLOGY (EICT), V0, P0
   Sharif SMA, 2016, INT C COMP ELEC ENG, V0, PP463, DOI 10.1109/ICECE.2016.7853957
   Shibly MMA, 1900, V176, V0, P0, DOI DOI 10.1007/978-981-33-4355-9_46
   Shopon M, 2017, IWCI 2016, V0, P0
   Simonyan K, 2015, ARXIV, V0, P0
   Sitaula C, 2021, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.412
   Solanki S, 2019, INT J ENG ADV TECHNO, V0, P0
   Sreenivasa E, 2016, INT, V135, P30, DOI 10.5120/ijca2016908349
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tsai CF, 2005, NEUROCOMPUTING, V64, P497, DOI 10.1016/j.neucom.2004.08.005
   Vinet L, 2011, J PHYS A-MATH THEOR, V44, P0, DOI 10.1088/1751-8113/44/8/085201
NR 53
TC 1
Z9 1
U1 0
U2 5
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUN 28
PY 2021
VL 0
IS 
BP 1
EP 30
DI 10.7717/peerj-cs.565
PG 30
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA TD1IZ
UT WOS:000669090700001
PM 34307856
DA 2023-11-10
ER

PT J
AU Tilly, S
   Livan, G
AF Tilly, Sonja
   Livan, Giacomo
TI Macroeconomic forecasting with statistically validated knowledge graphs
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Knowledge graph; Time series forecasting; Natural language processing; Big data
ID business cycles; models
AB This study leverages narrative from global newspapers to construct theme-based knowledge graphs about world events, demonstrating that features extracted from such graphs improve forecasts of industrial production in three large economies compared to a number of benchmarks. Our analysis relies on a filtering methodology that extracts "backbones"of statistically significant edges from large graph data sets. We find that changes in the eigenvector centrality of nodes in such backbones capture shifts in relative importance between different themes significantly better than graph similarity measures. We supplement our results with an interpretability analysis, showing that the theme categories "disease"and "economic"have the strongest predictive power during the time period that we consider. Our work serves as a blueprint for the construction of parsimonious - yet informative - theme-based knowledge graphs to monitor in real time the evolution of relevant phenomena in socio-economic systems.
C1 [Tilly, Sonja; Livan, Giacomo] UCL, Comp Sci Dept, 66-72 Gower St, London WC1E 6EA, England.
   [Livan, Giacomo] London Sch Econ & Polit Sci, System Risk Ctr, London WC2A 2AE, England.
C3 University of London; University College London; University of London; London School Economics & Political Science
RP Tilly, S (通讯作者)，UCL, Comp Sci Dept, 66-72 Gower St, London WC1E 6EA, England.
EM sonja.tilly.19@ucl.ac.uk; g.livan@ucl.ac.uk
CR Adamic L, 2017, ECONOMET J, V20, PS126, DOI 10.1111/ectj.12090
   [Anonymous], 1995, P 20 ANN SAS US GROU, V0, P0
   Bagrow JP, 2019, APPL NETW SCI, V4, P0, DOI 10.1007/s41109-019-0156-x
   Baker SR, 2020, WORKING PAPER SERIES - NATIONAL BUREAU OF ECONOMIC RESEARCH (MASSACHUSETTS), V0, P0
   Baker SR, 2016, Q J ECON, V131, P1593, DOI 10.1093/qje/qjw024
   Bellomarini L, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Benjamini Y, 2005, J AM STAT ASSOC, V100, P71, DOI 10.1198/016214504000001907
   Bildirici ME, 2015, PROCD SOC BEHV, V210, P416, DOI 10.1016/j.sbspro.2015.11.389
   Brooks C, 2010, REAL ESTATE MODELLIN, V0, P0, DOI DOI 10.1017/CBO9780511814235
   Brosch T, 2013, SWISS MED WKLY, V143, P0, DOI 10.4414/smw.2013.13786
   Bruner J, 1990, ACTS MEANING, V0, P0
   Buono D, 2018, EVALUATION NOWCASTIN, V0, P0
   Campi M, 2020, ENVIRON RES LETT, V15, P0, DOI 10.1088/1748-9326/abc2f6
   Carvalho VM, 2016, CEPR DISCUSSION PAPE, V11711, P0
   Christiano LJ, 2005, J POLIT ECON, V113, P1, DOI 10.1086/426038
   Clore GL, 2009, COGN SYST RES, V10, P21, DOI 10.1016/j.cogsys.2008.03.002
   Colladon AF, 2019, DECIS SUPPORT SYST, V123, P0, DOI 10.1016/j.dss.2019.113075
   Constantin A, 2018, J FINANC STABIL, V35, P226, DOI 10.1016/j.jfs.2016.10.011
   Cubadda G, 2012, ECON MODEL, V29, P1099, DOI 10.1016/j.econmod.2012.03.027
   Dehmer M, 2018, FRONT APPL MATH STAT, V4, P37, DOI 10.3389/FAMS.2018.00037
   DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X
   Elshendy M, 2018, J INF SCI, V44, P408, DOI 10.1177/0165551517698298
   Ghalmane Z, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-71876-0
   Giannone D, 2008, J MONETARY ECON, V55, P665, DOI 10.1016/j.jmoneco.2008.05.010
   Girardi A, 2016, J FORECASTING, V35, P542, DOI 10.1002/for.2393
   Gomez DM, 2017, APPL ECON, V49, P972, DOI 10.1080/00036846.2016.1210765
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Graves A, 2005, IEEE IJCNN, V0, P2047
   Guo L, 2020, J BROADCAST ELECTRON, V64, P418, DOI 10.1080/08838151.2020.1796391
   Harvey D, 1997, INT J FORECASTING, V13, P281, DOI 10.1016/S0169-2070(96)00719-4
   KEYNES John Maynard, 1936, GEN THEORY EMPLOYMEN, VVII, P0
   King G, 2017, SCIENCE, V358, P776, DOI 10.1126/science.aao1100
   Latora V, 2017, COMPLEX NETWORKS PRI, V0, P0
   Leamer EE, 1985, ECON PHILOS, V1, P295, DOI 10.1017/S0266267100002546
   Leetaru KH, 2012, D LIB MAGAZINE, V18, P5, DOI 10.1045/SEPTEMBER2012-LEETARU
   Leetaru KH, 2014, D LIB MAGAZINE, V20, P8, DOI 10.1045/SEPTEMBER2014-LEETARU
   Marcaccioli R, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-08667-3
   McCracken MW, 2016, J BUS ECON STAT, V34, P574, DOI 10.1080/07350015.2015.1086655
   Nyman R, 2018, NEWS NARRATIVES FINA, V0, P0
   Piccardi C, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0208265
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Serrano MA, 2009, P NATL ACAD SCI USA, V106, P6483, DOI 10.1073/pnas.0808904106
   Shiller RJ, 2017, AM ECON REV, V107, P967, DOI 10.1257/aer.107.4.967
   Smets F, 2007, AM ECON REV, V97, P586, DOI 10.1257/aer.97.3.586
   Stern S, 2020, NETWORK PERSPECTIVE, V0, P0, DOI DOI 10.1007/s41109-020-00272-4
   Stevanovic D, 2020, ARXIV200812477, V0, P0
   Stock JH, 2001, J ECON PERSPECT, V15, P101, DOI 10.1257/jep.15.4.101
   Tantardini M, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-53708-y
   Temizsoy A, 2017, J FINANC STABIL, V33, P346, DOI 10.1016/j.jfs.2016.11.003
   Thorsrud LA, 2016, BIG DATA VERSUS BIG, V0, P0
   Tilly S, 2021, EXPERT SYST APPL, V175, P0, DOI 10.1016/j.eswa.2021.114760
   Tuckett D, 2014, EC GROWTH E JOURNAL, V0, P0, DOI DOI 10.2139/ssrn
   Tumminello M, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0017994
   van Eyden R, 2019, APPL ENERG, V233, P612, DOI 10.1016/j.apenergy.2018.10.049
   Yang Y, 2020, ARXIV PREPRINT ARXIV, V0, P0
NR 55
TC 1
Z9 1
U1 5
U2 27
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 30
PY 2021
VL 186
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115765
EA SEP 2021
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA UZ0AD
UT WOS:000701874800014
DA 2023-11-10
ER

PT J
AU Gong, N
   Yao, NM
   Lv, ZY
   Wang, SB
AF Gong, Ning
   Yao, Nianmin
   Lv, Ziying
   Wang, Shibin
TI GEPC: Global embeddings with PID control
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Natural language processing; Representation learning; Word embedding; Global vectors
AB Global vectors, or global embeddings, are important word representations for many natural language processing tasks. With the popularity of dynamic embeddings (also known as contextual embeddings, such as ELMo and BERT) in recent years, attentions on global vectors have been diverted to a large extent. While, compared to the dynamic embeddings, the global embeddings are faster to train, straightforward to interpret, and eligible to be evaluated by many standard and credible intrinsic benchmarks (e.g., word similarity correlation and analogy accuracy). Thus, they are still widely-used in numerous downstream applications until now. However, the model design of the global embeddings has some limitations, making the learned word representations suboptimal. In this paper, we propose a novel method to deal with these limitations using PID control. To the best of our knowledge, this is one of the first efforts to leverage PID control in the research of word embed dings. Empirical results on standard intrinsic and extrinsic benchmarks show consistent performance boost of the proposed method, suggesting that the method proposed in this paper can be considered as a promising alternative to learn better word representations for the downstream tasks. ? 2021 Elsevier Ltd. All rights reserved.
C1 [Gong, Ning; Yao, Nianmin; Lv, Ziying] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
   [Wang, Shibin] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang, Henan, Peoples R China.
C3 Dalian University of Technology; Henan Normal University
RP Yao, NM (通讯作者)，Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
EM ginoailab@gmail.com; lucos@dlut.edu.cn
FU National Key R&D Program of China [2018AAA0100300]; Innovation Foundation of Science and Technology of Dalian via the project of Study on the Key Management and Privacy Preservation in VANET [2018J12GX045]
CR Allen C, 2019, PR MACH LEARN RES, V97, P0
   [Anonymous], 2015, T ASSOC COMPUT LING, V0, P0, DOI DOI 10.1162/TACL_A_00134
   Azzopardi L, 2005, SIGIR 2005. PROCEEDINGS OF THE TWENTY-EIGHTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP575, DOI 10.1145/1076034.1076135
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   Chelba Ciprian, 2014, ONE BILLION WORD BEN, V0, P0
   CHURCH KW, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P76
   Clark C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P845
   Derczynski L, 2017, P 3 WORKSHOP NOISY U, V0, PP140, DOI 10.18653/V1/W17-4418
   Derczynski Leon, 2016, P COLING 2016 26 INT, V0, P1169
   Diepold, 2017, RECURRENT NEURAL NET, V0, P0
   Gerz Daniela, 2016, P OF THE 2016 C ON E, V0, P2173
   Goodstein RL, 1970, MATH GAZ, V54, P173, DOI 10.2307/3612125
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Jafari R, 2006, SELF TUNING PID CONT, V0, P332
   Kim Y, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Lang Ken, 1995, MACH LEARN P, V0, P0
   Lebret R, 2014, EACL, V0, PP482, DOI 10.3115/v1/e14-1051
   Levy O, 2014, ADV NEUR IN, V27, P0
   Lim SK, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1557, DOI 10.18653/v1/P17-1143
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Minorsky N, 2010, NAV ENG J, V34, P280
   Mnih Andriy, 2012, ARXIV12066426, V0, P1751
   Opez-Monroy AP, 2018, P C N AM CHAPT ASS C, V0, PP1216, DOI 10.18653/V1/N18-1110
   Peng ML, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2409
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Powers D, 2006, INT WORDN C, V0, P0
   Reddy Siva, 2017, EMNLP, V0, P0
   Ritter A, 2011, P C EMP METH NAT LAN, V0, PP1524, DOI 10.1075/LI.30.1.03NAD
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Suzuki J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P186
   van der Maaten LJP, 2008, J MACH LEARN RES, V9, P2579
   Wendlandt L, 2018, P NAACL HLT, V0, PP2092, DOI 10.18653/v1/N18-1190
NR 36
TC 0
Z9 0
U1 1
U2 28
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL 15
PY 2021
VL 68
IS 
BP 
EP 
DI 10.1016/j.csl.2021.101197
EA FEB 2021
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA RD1BC
UT WOS:000633221700004
DA 2023-11-10
ER

PT J
AU Borg, A
   Boldt, M
   Rosander, O
   Ahlstrand, J
AF Borg, Anton
   Boldt, Martin
   Rosander, Oliver
   Ahlstrand, Jim
TI E-mail classification with machine learning and word embeddings for improved customer support
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE E-mail classification; Machine learning; Long short-term memory; Natural language processing
AB Classifying e-mails into distinct labels can have a great impact on customer support. By using machine learning to label e-mails, the system can set up queues containing e-mails of a specific category. This enables support personnel to handle request quicker and more easily by selecting a queue that match their expertise. This study aims to improve a manually defined rule-based algorithm, currently implemented at a large telecom company, by using machine learning. The proposed model should have higher F-1-score and classification rate. Integrating or migrating from a manually defined rule-based model to a machine learning model should also reduce the administrative and maintenance work. It should also make the model more flexible. By using the frameworks, TensorFlow, Scikit-learn and Gensim, the authors conduct a number of experiments to test the performance of several common machine learning algorithms, text-representations, word embeddings to investigate how they work together. A long short-term memory network showed best classification performance with an F-1-score of 0.91. The authors conclude that long short-term memory networks outperform other non-sequential models such as support vector machines and AdaBoost when predicting labels for e-mails. Further, the study also presents a Web-based interface that were implemented around the LSTM network, which can classify e-mails into 33 different labels.
C1 [Borg, Anton; Boldt, Martin; Rosander, Oliver; Ahlstrand, Jim] Blekinge Inst Technol, Dept Comp Sci & Engn, S-37179 Karlskrona, Sweden.
C3 Blekinge Institute Technology
RP Borg, A (通讯作者)，Blekinge Inst Technol, Dept Comp Sci & Engn, S-37179 Karlskrona, Sweden.
EM anton.borg@bth.se; martin.boldt@bth.se; oliver.rosander@student.bth.se; jim.ahlstrand@student.bth.se
FU Blekinge Institute of Technology
CR Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC, V0, P0
   [Anonymous], 2004, P 21 INT C MACH LEAR, V0, P0
   [Anonymous], 2017, META DATA DUMPS META, V0, P0
   [Anonymous], 2015, T ASSOC COMPUT LING, V0, P0, DOI DOI 10.1162/TACL_A_00134
   Baron NS, 1998, LANG COMMUN, V18, P133, DOI 10.1016/S0271-5309(98)00005-6
   Borg A, 2019, LECT NOTES ARTIF INT, V11606, P308, DOI 10.1007/978-3-030-22999-3_28
   Bottou L, 2012, NEURAL NETWORKS TRIC, V0, P421
   Bougie R, 2003, J ACAD MARKET SCI, V31, P377, DOI 10.1177/0092070303254412
   Buitinck L, 2013, ECML PKDD WORKSH LAN, V0, P108
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Christopher DM, 2008, INTRO INFORM RETRIEV, V151, P5
   Coden AR, 2005, J BIOMED INFORM, V38, P422, DOI 10.1016/j.jbi.2005.02.009
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Coussement K, 2008, DECIS SUPPORT SYST, V44, P870, DOI 10.1016/j.dss.2007.10.010
   De Boom C, 2016, PATTERN RECOGN LETT, V80, P150, DOI 10.1016/j.patrec.2016.06.012
   Domingos P, 1996, P 13 INT C MACHINE L, V0, P105
   Fallgren P, 2016, 6 SWED LANG TECHN C, V0, P0
   Flach P, 2012, MACHINE LEARNING ART, V0, P0
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Halpin N, 2016, CUSTOMER SERVICE REP, V0, P0
   Ingersoll GS, 2013, TAMING TEXT FIND ORG, V0, P0
   Kar P, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1625, DOI 10.1145/2939672.2939832
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Lewis D, 1998, EUR C MACH LEARN, V1398, P4, DOI 10.1007/BFB0026666
   Loshchilov Ilya, 2016, ICLR, V0, P0
   McCormick C, 2017, WORD2VEC TUTORIAL SK, V0, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nowak J, 2017, LECT NOTES ARTIF INT, V10246, P553, DOI 10.1007/978-3-319-59060-8_50
   Olson DL, 2008, ADV DATA MINING TECH, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   RICHINS ML, 1983, J MARKETING, V47, P68, DOI 10.2307/3203428
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Shannon CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/J.1538-7305.1948.TB01338.X
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Szegedy C, 2014, ARXIV, V0, P0
   Tahmasebi N, 2016, SWEDISH CULTUROMICS, V0, P0
   Tsvetkov Y, 2016, ARXIV160606710, V0, P0
   Vorontsov Eugene, 2017, ARXIV170200071, V0, P0
   Witten IH, 2011, MOR KAUF D, V0, P1
   Yan Y, 2018, NEURAL PROCESS LETT, V47, P117, DOI 10.1007/s11063-017-9636-0
   Zhang JQ, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS
   杨云峰, 1999, 西安公路交通大学学报 JOURNAL OF XIAN HIGHWAY UNIVERSITY, V0, P67
NR 50
TC 10
Z9 10
U1 3
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD MAR 15
PY 2021
VL 33
IS 6
BP 1881
EP 1902
DI 10.1007/s00521-020-05058-4
EA JUN 2020
PG 22
WC Computer Science, Artificial Intelligence
SC Computer Science
GA QT9XW
UT WOS:000541326700002
DA 2023-11-10
ER

PT J
AU Zhao, D
   Wang, J
   Chu, YH
   Zhang, YJ
   Yang, ZH
   Lin, HF
AF Zhao, Di
   Wang, Jian
   Chu, Yonghe
   Zhang, Yijia
   Yang, Zhihao
   Lin, Hongfei
TI Improving biomedical word representation with locally linear embedding
SO NEUROCOMPUTING
LA English
DT Article
DE Distributed word representation; Biomedical word embedding; Manifold learning; Electronic health records
AB Distributed word representation, usually obtained through calculation from large corpora, has been widely used in biomedical text because of its effectiveness in representing word semantic information. High-quality and meaningful biomedical words enable doctors to obtain the gist of information and knowledge in a short time to make clinical decisions quickly. Currently, the distributed word representation ignores the influence of the word embedding geometric structure obtained through calculation on the word semantic information and cannot accurately represent the word information, thus affecting the representation effect of biomedical text. To solve the above problems, we propose a biomedical word embedding framework based on manifold learning. Our work provides new perspectives for representing biomedical word embedding, which is the key concept in biomedical natural language processing tasks. First, the distributed word representation model is used to obtain the pretrained word embedding, and then the manifold learning is used to re-embed the pretrained word embedding. To verify the validity of the proposed framework in the biomedical domain, we evaluate the algorithm by using biomedical texts. Experimental results show that the proposed method can effectively improve the results of electronic health record classification and semantic similarity. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhao, Di; Wang, Jian; Chu, Yonghe; Zhang, Yijia; Yang, Zhihao; Lin, Hongfei] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Wang, J; Zhang, YJ (通讯作者)，Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
EM wangjian@dlut.edu.cn; zhyj@dlut.edu.cn
FU National Natural Science Foundation of China [62072070]
CR [Anonymous], 2014, RETROFITTING WORD VE, V0, P0
   [Anonymous], 2014, C EMPIRICAL METHODS, V0, P0
   Bai T, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP72, DOI 10.1145/3308558.3313485
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chen Q, 2016, P ACL, V0, P0
   Chiu B, 2016, P 15 WORKSH BIOM NAT, V0, PP166, DOI 10.18653/V1/W16-2922
   Chiu B, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), V0, P125
   Collobert R, 2008, P 25 ICML, V25, P160, DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Devlin J, 2018, BERT PRETRAINING DEE, V0, P0, DOI DOI 10.18653/V1/N19-PROCEEDINGSOFNAACLHLT1423
   Devlin J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1370
   Fei H, 2020, INFORM SCIENCES, V512, P175, DOI 10.1016/j.ins.2019.09.075
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hasan Souleiman, 2017, P 2017 C EMP METH NA, V0, PP321, DOI 10.18653/V1/D17-1033
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Jha K, 2018, IEEE DATA MINING, V0, PP1061, DOI 10.1109/ICDM.2018.00135
   Jiang ZC, 2016, IEEE ACM T COMPUT BI, V13, P634, DOI 10.1109/TCBB.2015.2478467
   Johnson AEW, 2016, SCI DATA, V3, P0, DOI 10.1038/sdata.2016.35
   Luo L, 2018, BIOINFORMATICS, V34, P1381, DOI 10.1093/bioinformatics/btx761
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mu Jiaqi, 2018, INT C LEARN REPR, V0, P0
   Mullenbach J, 2018, NAACL HLT 2018 2018, V1, P1101, DOI 10.18653/V1/N18-1100
   Pakhomov Serguei, 2010, AMIA ANNU SYMP PROC, V2010, P572
   Pakhomov SVS, 2011, J BIOMED INFORM, V44, P251, DOI 10.1016/j.jbi.2010.10.004
   Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), V0, P58
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Prakash A, 2017, AAAI CONF ARTIF INTE, V0, P3274
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Smalheiser NR, 2019, J BIOMED INFORM, V90, P0, DOI 10.1016/j.jbi.2019.103096
   STERNBERG RJ, 1983, J EXP PSYCHOL GEN, V112, P80, DOI 10.1037/0096-3445.112.1.80
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P384
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang GY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2321
   Wang YS, 2018, J BIOMED INFORM, V87, P12, DOI 10.1016/j.jbi.2018.09.008
   Xie XC, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP649, DOI 10.1145/3357384.3357897
   Yonghe C, 2019, IJCAI, V0, P5394
   Zhang YJ, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0055-0
   Zhao ZH, 2016, BIOINFORMATICS, V32, P3444, DOI 10.1093/bioinformatics/btw486
   Zhou HW, 2019, COMPUT BIOL CHEM, V83, P0, DOI 10.1016/j.compbiolchem.2019.107146
NR 41
TC 0
Z9 0
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD AUG 4
PY 2021
VL 447
IS 
BP 172
EP 182
DI 10.1016/j.neucom.2021.02.071
EA APR 2021
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SL5MG
UT WOS:000656961600001
DA 2023-11-10
ER

PT J
AU Bakhtin, A
   Deng, YT
   Gross, S
   Ott, M
   Ranzato, M
   Szlam, A
AF Bakhtin, Anton
   Deng, Yuntian
   Gross, Sam
   Ott, Myle
   Ranzato, Marc'Aurelio
   Szlam, Arthur
TI Residual Energy-Based Models for Text
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE energy-based models; text generation; negative sampling; importance sampling; generalization; real/fake discrimination
ID networks
AB Current large-scale auto-regressive language models (Radford et al., 2019; Liu et al., 2018; Graves, 2013) display impressive fluency and can generate convincing text. In this work we start by asking the question: Can the generations of these models be reliably distinguished from real text by statistical discriminators? We find experimentally that the answer is affirmative when we have access to the training data for the model, and guardedly affirmative even if we do not. This suggests that the auto-regressive models can be improved by incorporating the (globally normalized) discriminators into the generative process. We give a formalism for this using the Energy-Based Model framework, and show that it indeed improves the results of the generative models, measured both in terms of perplexity and in terms of human evaluation.
C1 [Bakhtin, Anton; Gross, Sam; Ott, Myle; Ranzato, Marc'Aurelio; Szlam, Arthur] Facebook AI Res, 770 Broadway, New York, NY 10003 USA.
   [Deng, Yuntian] Harvard Univ, 33 Oxford St, Cambridge, MA 02138 USA.
C3 Facebook Inc; Harvard University
RP Bakhtin, A (通讯作者)，Facebook AI Res, 770 Broadway, New York, NY 10003 USA.
EM YOLO@FB.COM; DENGYUNTIAN@SEAS.HARVARD.EDU; SGROSS@FB.COM; MYLEOTT@FB.COM; RANZATO@FB.COM; ASZLAM@FB.COM
CR [Anonymous], 2018, INT C LEARN REPR, V0, P0
   Azadi Samaneh, 2019, INT C LEARN REPR, V0, P0
   Baevski A, 2019, INT C LEARN REPR, V0, P0
   Bowman Samuel R, 2015, ARXIV151106349, V0, P0
   Brown TB, 2020, ARXIV200514165V4CSCL, V0, P0
   Caccia M, 2018, ARXIV181102549, V0, P0
   Dauphin YN, 2017, PR MACH LEARN RES, V70, P0
   dAutume Cyprien de Masson, 2019, ADV NEURAL INFORM PR, V0, PP4300, DOI 10.5555/3454287.3454674
   Devlin J, 2018, ARXIV, V1, P4171
   Ding H, 2017, PROC IEEE MICR ELECT, V0, PP1099, DOI 10.1109/MEMSYS.2017.7863605
   Du Yilun, 2019, NEURAL INFORM PROCES, V0, P0
   Edunov Sergey, 2018, N AM ASS COMPUTATION, V0, P0
   Fan Angela, 2018, ASS COMPUTATIONAL LI, V0, P0
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gao RQ, 2018, PROC CVPR IEEE, V0, PP9155, DOI 10.1109/CVPR.2018.00954
   Gehrmann Sebastian, 2019, ASS COMPUTATIONAL LI, V0, P0
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, ARXIV PREPRINT ARXIV, V0, P0
   Grover Aditya, 2019, NEURAL INFORM PROCES, V0, P0
   Gutmann Michael, 2010, P 13 INT C ART INT S, V0, PP297, DOI 10.1145/3292500.3330651
   Hashimoto Tatsunori B, 2019, N AMERICAL ASS COMPU, V0, P0
   He J, 2019, LAGGING INFERENCE NE, V0, P0
   Hinton GE, 2005, AISTATS, V0, P0
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Holtzman Ari, 2020, ICLR, V0, P0
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   HORVITZ DG, 1952, J AM STAT ASSOC, V47, P663, DOI 10.2307/2280784
   Ippolito D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1808
   Keskar Nitish Shirish, 2019, CTRL CONDITIONAL TRA, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V28, P3, DOI 10.48550/ARXIV.1506.06726
   LeCun Yann, 2006, PREDICTING STRUCTURE, V1, P0
   Liu PJ, 2018, ARXIV180110198, V0, P1
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Loshchilov Ilya, 2016, ICLR, V0, P0
   Ma Zhuang, 2018, EMPIRICAL METHODS NA, V0, P0
   Merity Stephen, 2016, POINTER SENTINEL MIX, V0, P0
   Nagel S, 2016, CC NEWS, V0, P0
   Naskar Subhajit, 2020, ARXIV200913267, V0, P0
   Nijkamp Erik, 2019, ADV NEURAL INFORM PR, V0, P5233
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Owen AB, 2013, MONTE CARLO THEORY M, V0, P0
   Parshakova Tetiana, 2019, C COMP NAT LANG LEAR, V0, P0
   Pascanu R, 2013, P 30 INT C MACHINE L, V0, P0
   Paszke A, 2017, 31 C NEUR INF PROC S, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Ranzato M, 2016, ICLR, V0, P1
   Ranzato M, 2013, IEEE T PATTERN ANAL, V35, P2206, DOI 10.1109/TPAMI.2013.29
   Ranzato MarcAurelio, 2007, 11 INT WORKSH ART IN, V0, P0
   Roark B, 2007, COMPUT SPEECH LANG, V21, P373, DOI 10.1016/j.csl.2006.06.006
   Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Scialom Thomas, 2020, ARXIV200604643, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shen LB, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P177
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Teh YW, 2004, J MACH LEARN RES, V4, P1235
   Vaswani A, 2017, ARXIV, V30, P5998
   Viola P, 2001, 2 INT WORKSH STAT CO, V57, P87
   Wang B, 2018, IEEE W SP LANG TECH, V0, PP70, DOI 10.1109/SLT.2018.8639591
   Wang B, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6134, DOI 10.1109/ICASSP.2018.8461813
   Wang B, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P785
   Wang B, 2018, IEEE T PATTERN ANAL, V40, P876, DOI 10.1109/TPAMI.2017.2696536
   Wang B, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP294, DOI 10.1109/ASRU.2017.8268949
   Welleck Sean, 2020, ABS190804319 ARXIV, V0, P0
   Xie JW, 2021, IEEE T PATTERN ANAL, V43, P516, DOI 10.1109/TPAMI.2019.2934852
   Xie JW, 2018, PROC CVPR IEEE, V0, PP8629, DOI 10.1109/CVPR.2018.00900
   Xie JW, 2016, PR MACH LEARN RES, V48, P0
   Yu LQ, 2017, AAAI CONF ARTIF INTE, V0, P66
   Zellers Rowan, 2019, NEURAL INFORM PROCES, V0, P0
   Zhang Hugh, 2020, ARXIV200410450, V0, P0
   Zhao JK, 2018, PR MACH LEARN RES, V80, P0
   Zhu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), V0, PP267, DOI 10.1109/ICCVW.2015.43
NR 75
TC 5
Z9 5
U1 6
U2 6
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
EI 
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD JUN 15
PY 2021
VL 22
IS 
BP 
EP 
DI 
PG 41
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA QW3BP
UT WOS:000628529500040
DA 2023-11-10
ER

PT J
AU Cheng, RZ
   Chen, J
AF Cheng, Ruozhen
   Chen, Jing
TI A location conversion method for roads through deep learning-based semantic matching and simplified qualitative direction knowledge representation
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Natural language descriptions; Road location conversion; Geocoding; Qualitative direction reasoning; Deep learning; Simplified qualitative direction knowledge
ID localization
AB Qualitative direction knowledge that appears in natural language descriptions of road-related locations could point to the interior of individual roads or associate multiple roads. Interpreting such descriptions to perform location conversion for roads will support intelligent road-related location services. Existing geocoding technologies could perform textual or semantic matching to transform road names to spatial locations, and research on qualitative direction reasoning could perform efficient location conversion based on semantic queries of qualitative direction knowledge between roads. However, research on geocoding lacks the consideration of matching the described internal direction knowledge of a road to a part of the road. Moreover, efficient location conversion based on semantic queries cannot scale to large road datasets due to the retrieval efficiency of a large amount of qualitative direction knowledge between roads. To accomplish this goal, this study proposes a location conversion method for roads, wherein a road ontology is designed to model the interior direction knowledge of the roads, a deep learning-based road semantic matching model is trained to match the internal direction knowledge descriptions and road segments, and a simplified qualitative direction knowledge representation between roads is performed to support rapid location conversion between roads based on efficient semantic queries. The proposed method was implemented on a road dataset of New York State. The results demonstrate that the proposed method can be effectively applied in road location conversion based on descriptions that contain qualitative direction knowledge inside individual roads or between multiple roads, which expands the scope of artificial intelligence applications.
C1 [Cheng, Ruozhen; Chen, Jing] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Chen, J (通讯作者)，129 Louyu Rd, Wuhan, Peoples R China.
EM jchen@whu.edu.cn
FU National Key R&D Program of China [2018YFB0505302]
CR Shahri AA, 2021, NEURAL COMPUT APPL, V33, P3841, DOI 10.1007/s00521-020-05223-9
   [Anonymous], 1901, B SOC VAUD SCI N, V0, P0, DOI DOI 10.5169/SEALS-266440
   [Anonymous], 2002, DISCRETE GLOBAL GRID, V0, P0
   Asheghi R, 2020, J HYDROINFORM, V22, P562, DOI 10.2166/hydro.2020.098
   Breuel, 2015, ARXIV150802788, V0, P0
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Chung J, 2014, NIPS 2014 WORKSH DEE, V0, PP1, DOI 10.48550/ARXIV.1412.3555
   Comber S, 2019, T GIS, V23, P334, DOI 10.1111/tgis.12522
   Fogliaroni P, 2012, THESIS U BREMEN, V0, P0
   Fogliaroni P, 2016, SPAT COGN COMPUT, V16, P272, DOI 10.1080/13875868.2016.1203327
   Goyal RK, 2001, LECT NOTES COMPUT SC, V2121, P36
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Hu YJ, 2019, INT J GEOGR INF SCI, V33, P714, DOI 10.1080/13658816.2018.1458986
   Koumarelas I, 2018, ACM J DATA INF QUAL, V10, P0, DOI 10.1145/3232852
   Leutenegger ST, 1997, PROC INT CONF DATA, V0, PP497, DOI 10.1109/ICDE.1997.582015
   Levenshtein VI, 1966, BINARY CODES CAPABLE, V0, P0, DOI DOI 10.1109/TVCG.2012.323
   Lin Y, 2020, INT J GEOGR INF SCI, V34, P559, DOI 10.1080/13658816.2019.1681431
   Long ZG, 2016, INT J GEOGR INF SCI, V30, P1072, DOI 10.1080/13658816.2015.1104535
   Matci DK, 2018, COMPUT ENVIRON URBAN, V70, P1, DOI 10.1016/j.compenvurbsys.2018.01.009
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Mylopoulos J, 1980, OVERVIEW KNOWLEDGE R, V0, P5
   Nesi P, 2016, ENG APPL ARTIF INTEL, V51, P202, DOI 10.1016/j.engappai.2016.01.011
   Perry M, 2012, GEOSPARQL A GEOGRAPH, V0, P0
   Regalia B, 2019, T GIS, V23, P601, DOI 10.1111/tgis.12548
   Santos R, 2018, INT J GEOGR INF SCI, V32, P324, DOI 10.1080/13658816.2017.1390119
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stock K, 2018, INT J GEOGR INF SCI, V32, P1087, DOI 10.1080/13658816.2018.1432861
   TETKO IV, 1995, J CHEM INF COMP SCI, V35, P826, DOI 10.1021/ci00027a006
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Ying X, 2019, J PHYS CONF SER, V1168, P0, DOI 10.1088/1742-6596/1168/2/022022
   Zhang HC, 2019, PROCEEDINGS OF THE 2019 14TH SYMPOSIUM ON PIEZOELECTRCITY, V0, P122, DOI 10.1109/spawda48812.2019.9019295
   Zhang X, 2014, WEB INFORM SYSTEMS E, V0, PP8182, DOI 10.1007/978-3-642-54370-8_4
NR 33
TC 0
Z9 0
U1 1
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD SEP 15
PY 2021
VL 104
IS 
BP 
EP 
DI 10.1016/j.engappai.2021.104400
EA AUG 2021
PG 18
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA UC0UD
UT WOS:000686249600006
DA 2023-11-10
ER

PT J
AU Aras, G
   Makaroglu, D
   Demir, S
   Cakir, A
AF Aras, Gizem
   Makaroglu, Didem
   Demir, Seniz
   Cakir, Altan
TI An evaluation of recent neural sequence tagging models in Turkish named entity recognition
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Named entity recognition; Turkish; Transfer learning; CRF; Digital media industry
AB Named entity recognition (NER) is an extensively studied task that extracts and classifies named entities in a text. NER is crucial not only in downstream language processing applications such as relation extraction and question answering but also in large scale big data operations such as real-time analysis of online digital media content. Recent research efforts on Turkish, a less studied language with morphologically rich nature, have demonstrated the effectiveness of neural architectures on well-formed texts and yielded state-of-the art results by formulating the task as a sequence tagging problem. In this work, we empirically investigate the use of recent neural architectures (Bidirectional long short-term memory (BiLSTM) and Transformer-based networks) proposed for Turkish NER tagging in the same setting. Our results demonstrate that transformer-based networks which can model long-range context overcome the limitations of BiLSTM networks where different input features at the character, subword, and word levels are utilized. We also propose a transformer-based network with a conditional random field (CRF) layer that leads to the state-of-the-art result (95.95% f-measure) on a common dataset. Our study contributes to the literature that quantifies the impact of transfer learning on processing morphologically rich languages.
C1 [Aras, Gizem; Makaroglu, Didem] Demiroren Teknol AS, Dept Big Data & Analyt, Istanbul, Turkey.
   [Makaroglu, Didem] Istanbul Tech Univ, Inst Informat, Istanbul, Turkey.
   [Demir, Seniz] MEF Univ, Dept Comp Engn, Istanbul, Turkey.
   [Cakir, Altan] Istanbul Tech Univ, Fac Sci & Letters, Phys Engn, Istanbul, Turkey.
   [Cakir, Altan] Istanbul Tech Univ Artificial Intelligence, Data Sci Res & Applicat Ctr, Istanbul, Turkey.
C3 Istanbul Technical University; MEF Universitesi; Istanbul Technical University
RP Aras, G (通讯作者)，Demiroren Teknol AS, Dept Big Data & Analyt, Istanbul, Turkey.
EM gizem.aras@demirorenteknoloji.com; makaroglu17@itu.edu.tr; demirse@mef.edu.tr; altan.cakir@itu.edu.tr
CR Acs J, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   Akdemir A, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Akkaya EK, 2020, NAT LANG ENG, V0, P1
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2013, INT C LEARNING REPRE, V0, P0
   [Anonymous], 2009, P HUM LANG TECHN 200, V0, P0
   [Anonymous], 2010, COMPUTER INFORM SCI, V0, P0
   Arkhipov M, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP2019), V0, P89
   BERTurk, 2020, BERT MOD TURKISH, V0, P0
   Çelikkaya G, 2013, I C APPL INF COMM TE, V0, P154
   Chen Lingzhen, 2018, P 27 INT C COMPUTATI, V0, P2181
   Chen YB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P167
   Chieu HL, 2003, P CONLL 2003, V0, P160
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/TACL_A_00104
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Demir H, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP117, DOI 10.1109/ICMLA.2014.24
   Devlin J, 2018, ARXIV, V1, P4171
   Ekbal A, 2008, P IJCNLP 08 WORKSH N, V0, P0
   Eken B, 2015, P 4 INT C SOFTW ENG, V0, P0
   Ertopçu B, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), V0, PP474, DOI 10.1109/UBMK.2017.8093439
   Firth JR, 1957, SYNOPSIS LINGUISTIC, V0, P0
   Grave E, 2018, P 11 INT C LANG RES, V0, P0
   Gunes A, 2018, 2018 26 SIGN PROC CO, V0, PP1, DOI 10.1109/siu.2018.8404500
   Güngör O, 2019, NAT LANG ENG, V25, P147, DOI 10.1017/S1351324918000281
   Hakkani-Tur DZ, 2000, THESIS BILKENT U DEP, V0, P0
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jurafsky D, 2018, SPEECH LANGUAGE PROC, V3rd, P0
   Küçük D, 2017, LECT NOTES COMPUT SC, V10260, P176, DOI 10.1007/978-3-319-59569-6_20
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Kuru O, 2016, P COLING 2016 26 INT, V0, P911
   Lafferty J, 2001, P 18 INT C MACHINE L, V0, P0, DOI DOI 10.5555/645530.655813
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lample Guillaume, 2019, NEURIPS, V0, P0
   Lin XD, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4216
   Liu Y, 2019, ROBUSTLY OPTIMIZED B, V0, P0
   Luong T, 2013, P 17 C COMP NAT LANG, V0, PP104, DOI 10.1007/BF02579642
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Marrero M, 2013, COMPUT STAND INTER, V35, P482, DOI 10.1016/j.csi.2012.09.004
   Martin L, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Melamud O, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Molla D, 2006, NAMED ENTITY RECOGNI, V0, P0
   Oflazer K, 1994, OUTLINE TURKISH MORP, V0, P0
   Okur E, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P549
   Paliouras G, 2000, ECAI WORKSH MACH, V0, P0
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Saju CJ, 2017, P 2 INT C REC TRENDS, V0, P0
   Santos CN, 2015, ABS150505008 CORR, V0, P0
   Seker GA, 2012, P COLING 2012, V0, P2459
   Souza F, 2019, ARXIV190910649, V0, P0
   Tatar S, 2011, J INF SCI, V37, P137, DOI 10.1177/0165551511398573
   Tur G, 2003, NATURAL LANGUAGE ENGINEERING, V9, P181, DOI 10.1017/S135132490200284X
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Virtanen A, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Al-Nabki MW, 2020, NEUROCOMPUTING, V382, P1, DOI 10.1016/j.neucom.2019.11.072
   Wolf T, 2019, ARXIV, V0, P0
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
   Yao L, 2009, 2009 IEEE INT C SYST, V0, P176
   Yeniterzi R, 2011, P ACL 2011 STUD SESS, V0, P105
   Yu J, 2020, P 58 ANN M ASS COMPU, V0, PP6470, DOI 10.18653/v1/2020.acl-main.577
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zhou GD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P473
   Zirikly A, 2015, P NAACL HLT, V0, P176
NR 66
TC 8
Z9 8
U1 2
U2 13
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 15
PY 2021
VL 182
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115049
EA MAY 2021
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA UF3EW
UT WOS:000688460900011
DA 2023-11-10
ER

PT J
AU Fröhling, L
   Zubiaga, A
AF Froehling, Leon
   Zubiaga, Arkaitz
TI Feature-based detection of automated language models: tackling GPT-2, GPT-3 and Grover
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Feature-based detection; Language models; Language generation; Text classification; NLP
AB The recent improvements of language models have drawn much attention to potential cases of use and abuse of automatically generated text. Great effort is put into the development of methods to detect machine generations among human-written text in order to avoid scenarios in which the large-scale generation of text with minimal cost and effort undermines the trust in human interaction and factual information online. While most of the current approaches rely on the availability of expensive language models, we propose a simple feature-based classifier for the detection problem, using carefully crafted features that attempt to model intrinsic differences between human and machine text. Our research contributes to the field in producing a detection method that achieves performance competitive with far more expensive methods, offering an accessible "first line-of-defense" against the abuse of language models. Furthermore, our experiments show that different sampling methods lead to different types of flaws in generated text.
C1 [Froehling, Leon] Leibniz Univ Hannover, Hannover, Germany.
   [Zubiaga, Arkaitz] Queen Mary Univ London, London, England.
C3 Leibniz University Hannover; University of London; Queen Mary University London
RP Fröhling, L (通讯作者)，Leibniz Univ Hannover, Hannover, Germany.
EM froehling@statistik.uni-hannover.de
CR Argamon-Engelson S, 1998, P AAAI WORKSH TEXT C, V0, P1
   Badaskar Sameer, 2008, P 3 INT JOINT C NAT, VII, P0
   Bakhtin A, 2019, ARXIV, V0, P0
   Baly R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3528
   Barzilay R, 2019, ARXIV, V0, P0
   Barzilay R, 2008, COMPUT LINGUIST, V34, P1, DOI 10.1162/coli.2008.34.1.1
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3615
   Belz A, 2019, C TRUTH TRUST ONL, V0, P0
   Bisk Yonatan, 2020, ARXIV, V0, P0
   Biswal S, 2019, P MACHINE LEARNING H, V0, P513
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Budzianowski P, 2019, P 3 WORKSHOP NEURAL, V0, PP15, DOI 10.18653/V1/D19-5602
   Clark J, 2019, GPT 2 SIMPLE BASELIN, V0, P0
   Crossley SA, 2011, READ FOREIGN LANG, V23, P84
   Devlin J, 2018, ARXIV, V1, P4171
   Eneva E, 2001, P 2001 C EMP METH NA, V0, P0
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P4647, DOI 10.1145/2858036.2858535
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Feng L, 2010, P COLING 2010, V23-27, P276, DOI 10.5555/1944566.1944598
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Fung B, 2017, WASH POST, V0, P0
   Gehrmann S, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, P111
   Hagiwara M, 2019, P 2019 C EMP METH NA, V0, P0
   Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689
   Holtzman A, 2019, CEUR WORKSHOP PROC, V2540, P0
   Ippolito D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1808
   Jiang S, 2020, ARXIV, V0, P0
   Joachims T, 1998, P 10 EUR C MACH LEAR, V0, PP137, DOI 10.1007/BFB0026683
   Kao J, 2017, MEDIUM, V0, P0
   Koppel M, 2002, LITERARY & LINGUISTIC COMPUTING, V17, P401, DOI 10.1093/llc/17.4.401
   Lewandowsky S, 2012, PSYCHOL SCI PUBL INT, V13, P106, DOI 10.1177/1529100612451018
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Morstatter F, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, V0, PP533, DOI 10.1109/ASONAM.2016.7752287
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, V0, P3391
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rubin V, 2016, P 2 WORKSHOP COMPUTA, V0, P7
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   See A, 2019, CONLL, V0, PP843, DOI 10.18653/V1/K19-1079
   Selyukh A, 2017, NPR, V0, P0
   Shevlane Toby, 2020, AIES 20: PROCEEDINGS OF THE AAAI/ACM CONFERENCE ON AI, V0, P0
   Solaiman I, 2019, ARXIV, V0, P0
   Sun Z, 2020, ARXIV, V0, P0
   Thorne James, 2018, P 27 INT C COMP LING, V0, P3346
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Zellers R, 2020, ARXIV, V0, P0
   Zellers Rowan, 2019, NEURIPS, V0, P0
   Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217
NR 49
TC 11
Z9 11
U1 7
U2 19
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD APR 6
PY 2021
VL 0
IS 
BP 
EP 
DI 10.7717/peerj-cs.443
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA RI6KM
UT WOS:000637015700001
PM 33954234
DA 2023-11-10
ER

PT J
AU Li, K
   Naacke, H
   Amann, B
AF Li, Ke
   Naacke, Hubert
   Amann, Bernd
TI An Analytic Graph Data Model and Query Language for Exploring the Evolution of Science
SO BIG DATA RESEARCH
LA English
DT Article
DE Topic modeling; Topic evolution networks; LDA; Science evolution; Big data
ID topic evolution; information
AB In this article we propose a data model and query language for the visualisation and exploration of topic evolution networks representing the research progress in scientific document archives. Our model is independent of a particular topic extraction and alignment method and proposes a set of semantic and structural metrics for characterizing and filtering meaningful topic evolution patterns. These metrics are particularly useful for the visualization and the exploration of large topic evolution graphs. We also present a first implementation of our model on top of Apache Spark and experimental results obtained for four real-world document archives. (C) 2021 Elsevier Inc. All rights reserved.
C1 [Li, Ke; Naacke, Hubert; Amann, Bernd] Sorbonne Univ, CNRS, LIP6, 4 Pl Jussieu, F-75005 Paris, France.
C3 UDICE-French Research Universities; Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)
RP Li, K; Naacke, H; Amann, B (通讯作者)，Sorbonne Univ, CNRS, LIP6, 4 Pl Jussieu, F-75005 Paris, France.
EM ke.li@lip6.fr; hubert.naacke@lip6.fr; bernd.amann@lip6.fr
FU [ANR-16-CE38-0002-01]
CR Andrei V, 2016, EURASIP J BIOINFORM, V0, P0, DOI DOI 10.1186/s13637-016-0050-0
   [Anonymous], 2011, P 20 INT C WORLD WID, V0, P0, DOI DOI 10.1145/1963405.1963444
   Armbrust M, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1383, DOI 10.1145/2723372.2742797
   Bancilhon F, 1986, KNOWLEDGE BASE MANAG, V0, P0
   Beykikhoshk A, 2018, KNOWL INF SYST, V55, P599, DOI 10.1007/s10115-017-1095-4
   Bhadury A, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16), V0, PP381, DOI 10.1145/2872427.2883046
   Bhattacharyya A, 1943, BULL CALCUTTA MATH S, V35, P99, DOI 10.1038/157869B0
   Bin Lu, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, V0, PP81, DOI 10.1109/ICDMW.2011.125
   Blei DM, 2006, PROC 23 INT C MACHIN, V148, P113, DOI 10.1145/1143844.1143859
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chavalarias D, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0054847
   Chen BT, 2017, J INFORMETR, V11, P1175, DOI 10.1016/j.joi.2017.10.003
   Franz M, 2001, SIGIR FORUM, V0, P310
   GARFIELD E, 1955, SCIENCE, V122, P108, DOI 10.1126/science.122.3159.108
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hall D, 2008, P C EMP METH NAT LAN, V0, PP363, DOI 10.3115/1613715.1613763
   He Q, 2009, PROCEEDING 18 ACM C, V0, PP957, DOI 10.1145/1645953.1646076
   Hofmann T, 1999, SIGIR99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP50, DOI 10.1145/312624.312649
   Hu BB, 2015, J ASSOC INF SCI TECH, V66, P2643, DOI 10.1002/asi.23347
   Jaccard P, 1912, NEW PHYTOL, V11, P37, DOI 10.1111/j.1469-8137.1912.tb05611.x
   Kontostathis A, 2004, SURVEY OF TEXT MINING, V0, P185
   Kuhn TS, 1994, INT ENCY UNIFIED SCI, V2, P0
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Li K, 2020, INT C EXT DAT TECHN, V0, P619
   Li KH, 2020, INVEST RADIOL, V55, P327, DOI 10.1097/RLI.0000000000000672
   Meng XR, 2016, J MACH LEARN RES, V17, P0
   Miller JW, 2013, ADV NEURAL INFORM PR, V0, P199
   Naacke H, 2019, IEEE INT CONF BIG DA, V0, PP4793, DOI 10.1109/BigData47090.2019.9005483
   Niu ZX, 2018, IEEE T IMAGE PROCESS, V27, P50, DOI 10.1109/TIP.2017.2718667
   Priva UC, 2015, COGNITION, V135, P4, DOI 10.1016/j.cognition.2014.11.006
   Qu HY, 2006, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON TELEHEALTH, V0, P75
   Rubin TN, 2012, MACH LEARN, V88, P157, DOI 10.1007/s10994-011-5272-5
   Salatino AA, 2018, ACM-IEEE J CONF DIG, V0, PP303, DOI 10.1145/3197026.3197052
   Shahaf D, 2015, COMMUN ACM, V58, P62, DOI 10.1145/2735624
   Sun XL, 2013, SCI REP-UK, V3, P0, DOI 10.1038/srep01069
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wang C, 2008, P 24 ANN C UNCERTAIN, V0, P579
   Wang X, 2006, P 12 ACM SIGKDD INT, V0, PP424, DOI 10.1145/1150402.1150450
   Wheeler DL, 2008, NUCLEIC ACIDS RES, V36, PD13, DOI 10.1093/nar/gkm1000
   Xin Reynold S, 2013, 1 INT WORKSH GRAPH D, V0, P1
   Zhou D, 2006, PROC 15 ACM INT C IN, V0, P248
   Zuo ZY, 2018, ACM-IEEE J CONF DIG, V0, PP405, DOI 10.1145/3197026.3203891
NR 42
TC 0
Z9 0
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-5796
EI 
J9 BIG DATA RES
JI Big Data Res.
PD NOV 15
PY 2021
VL 26
IS 
BP 
EP 
DI 10.1016/j.bdr.2021.100247
EA AUG 2021
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA WL5QB
UT WOS:000710458600011
DA 2023-11-10
ER

PT J
AU Peng, P
   You, MY
   Xu, WS
   Li, JX
AF Peng, Peng
   You, Mingyu
   Xu, Weisheng
   Li, Jiaxin
TI Fully integer-based quantization for mobile convolutional neural network inference
SO NEUROCOMPUTING
LA English
DT Article
DE Convolutional neural network; Quantization; Model compression; Deep learning
AB Deploying deep convolutional neural networks on mobile devices is challenging because of the conflict between their heavy computational overhead and the hardware's restricted computing capacity. Network quantization is typically used to alleviate this problem. However, we found that a "datatype mismatch" issue in existing low bitwidth quantization approaches can generate severe instruction redundancy, dramatically reducing their running efficiency on mobile devices. We therefore propose a novel quantization approach which ensures that only integer-based arithmetic is needed during the inference stage of the quantized model. To this end, we improved the quantization function to compel the quantized value to follow a standard integer format. Then we presented to simultaneously quantize the batch normalization parameters by a logarithm-like method. By doing so, the quantized model can keep the advantage of low bitwidth representation, while preventing the occurrence of "datatype mismatch" issue and corresponding instruction redundancy. Comprehensive experiments show that our method can achieve comparable prediction accuracy to other state-of-the-art methods while reducing the run-time latency by a large margin. Our fully integer-based quantized Resnet-18 has 4-bit weights, 4-bit activations and only a 0.7% top-1 and 0.4% top-5 accuracy drop on the ImageNet dataset. The assembly language implementation of a series of building blockscan reach a maximum of 4.33x the speed of the original full-precision version on an ARMv8 CPU. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Peng, Peng; You, Mingyu; Xu, Weisheng; Li, Jiaxin] Tongji Univ, Coll Elect & Informat Engn, Dept Control Sci & Engn, Shanghai 201804, Peoples R China.
   [You, Mingyu] Tongji Univ, Shanghai Inst Intelligent Sci & Technol, Shanghai 201804, Peoples R China.
C3 Tongji University; Tongji University
RP You, MY (通讯作者)，Tongji Univ, Coll Elect & Informat Engn, Dept Control Sci & Engn, Shanghai 201804, Peoples R China.; You, MY (通讯作者)，Tongji Univ, Shanghai Inst Intelligent Sci & Technol, Shanghai 201804, Peoples R China.
EM peng.peng@tongji.edu.cn; myyou@tongji.edu.cn; xuweisheng@tongji.edu.cn; lijx@tongji.edu.cn
FU Shanghai Natural Science Foundation [18ZR1442600]; National Natural Science Foundation of China [62073244]; Innovation Program of Science and Technology Commission of Shanghai Municipality [19DZ1209200]
CR Ashouri AH, 2019, NEUROCOMPUTING, V370, P56, DOI 10.1016/j.neucom.2019.08.063
   Bengio Yoshua, 2013, CORR, V0, P0
   Capotondi A, 2020, IEEE T CIRCUITS-II, V67, P871, DOI 10.1109/TCSII.2020.2983648
   Choukroun Y, 2019, IEEE INT CONF COMP V, V0, PP3009, DOI 10.1109/ICCVW.2019.00363
   Dettmers T, 2016, ICLR, V0, P0
   Gutierrez-Galan D, 2018, NEUROCOMPUTING, V272, P17, DOI 10.1016/j.neucom.2017.03.090
   He K, 2016, PROC CVPR IEEE, V0, P0
   Hinton Geoffrey, 2015, ARXIV150302531, V0, P0
   Howard Andrew G, 2017, ARXIV170404861, V0, P0
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Jacob B, 2018, PROC CVPR IEEE, V0, PP2704, DOI 10.1109/CVPR.2018.00286
   Jain S, 2019, CANCER INVEST, V37, P453, DOI 10.1080/07357907.2019.1662918
   Lin Xiaofan, 2017, ADV NEURAL INFORM PR, V0, PP344, DOI 10.48550/ARXIV.1711.11294
   Liu L, 2019, NEUROCOMPUTING, V360, P246, DOI 10.1016/j.neucom.2019.06.035
   LIU Z, 2018, ARXIVARXIV180800278V, V1219, P747, DOI 10.1007/978-3-030-01267-0_44
   Liu ZG, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3066
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mishra A, 2018, INT C LEARN REPR, V0, P0
   Park E, 2017, PROC CVPR IEEE, V0, PP7197, DOI 10.1109/CVPR.2017.761
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, VERY DEEP CONVOLUTIO, V0, P1
   Xu XF, 2020, NEUROCOMPUTING, V393, P165, DOI 10.1016/j.neucom.2018.10.114
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang QR, 2019, NEUROCOMPUTING, V323, P37, DOI 10.1016/j.neucom.2018.09.038
   Zhang X, 2018, PROC CVPR IEEE, V0, PP6848, DOI 10.1109/CVPR.2018.00716
   Zhu C, 2016, IEEE 83 VEH TECHN C, V0, P1
   Zhu XT, 2018, IEEE INT CON MULTI, V0, P0
   Zhuang BH, 2019, PROC CVPR IEEE, V0, PP413, DOI 10.1109/CVPR.2019.00050
NR 34
TC 15
Z9 15
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD APR 7
PY 2021
VL 432
IS 
BP 194
EP 205
DI 10.1016/j.neucom.2020.12.035
EA JAN 2021
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA QL2IY
UT WOS:000620904600003
DA 2023-11-10
ER

PT J
AU Gündel, S
   Setio, AAA
   Ghesu, FC
   Grbic, S
   Georgescu, B
   Maier, A
   Comaniciu, D
AF Guendel, Sebastian
   Setio, Arnaud A. . A. .
   Ghesu, Florin C.
   Grbic, Sasa
   Georgescu, Bogdan
   Maier, Andreas
   Comaniciu, Dorin
TI Robust classification from noisy labels: Integrating additional knowledge for chest radiography abnormality assessment
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Label noise; Robust loss function; Multi-task learning; Chest radiography abnormality classification
ID lung; segmentation; uncertainty; radiology; error
AB Chest radiography is the most common radiographic examination performed in daily clinical practice for the detection of various heart and lung abnormalities. The large amount of data to be read and reported, with more than 100 studies per day for a single radiologist, poses a challenge in consistently maintaining high interpretation accuracy. The introduction of large-scale public datasets has led to a series of novel systems for automated abnormality classification. However, the labels of these datasets were obtained using natural language processed medical reports, yielding a large degree of label noise that can impact the performance. In this study, we propose novel training strategies that handle label noise from such suboptimal data. Prior label probabilities were measured on a subset of training data re-read by 4 board certified radiologists and were used during training to increase the robustness of the training model to the label noise. Furthermore, we exploit the high comorbidity of abnormalities observed in chest radiography and incorporate this information to further reduce the impact of label noise. Additionally, anatomical knowledge is incorporated by training the system to predict lung and heart segmentation, as well as spatial knowledge labels. To deal with multiple datasets and images derived from various scanners that apply different post-processing techniques, we introduce a novel image normalization strategy. Experiments were performed on an extensive collection of 297,541 chest radiographs from 86,876 patients, leading to a state-of-the-art performance level for 17 abnormalities from 2 datasets. With an average AUC score of 0.880 across all abnormalities, our proposed training strategies can be used to significantly improve performance scores. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Guendel, Sebastian; Setio, Arnaud A. . A. .] Siemens Healthineers, Digital Technol & Inovat, D-91052 Erlangen, Germany.
   [Ghesu, Florin C.; Grbic, Sasa; Georgescu, Bogdan; Comaniciu, Dorin] Siemens Healthineers, Digital Technol & Inovat, Princeton, NJ 08540 USA.
   [Guendel, Sebastian; Maier, Andreas] Friedrich Alexander Univ Erlangen Nurnberg, Pattern Recognit Lab, D-91058 Erlangen, Germany.
C3 Siemens AG; Siemens AG; University of Erlangen Nuremberg
RP Gündel, S (通讯作者)，Friedrich Alexander Univ Erlangen Nurnberg, Pattern Recognit Lab, D-91058 Erlangen, Germany.
EM sebastian.guendel@fau.de
CR Amyar A, 2020, MULTITASK DEEP LEARN, V0, P0, DOI DOI 10.1101/2020.04.16.20064709
   [Anonymous], 2014, COMPUTERENCE, V0, P0
   [Anonymous], 2017, ARXIV170509850, V0, P0
   [Anonymous], 2017, ARXIV171010501CS, V0, P0
   [Anonymous], 2018, WEAKLY SUPERVISED ME, V0, P0
   [Anonymous], 2017, INT C MACHINE LEARNI, V0, P0
   Arazo E, 2019, UNSUPERVISED LABEL N, V0, P0
   Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x
   Balabanova Y, 2005, BMJ-BRIT MED J, V331, P379, DOI 10.1136/bmj.331.7513.379
   Barbosa Jr E, 2021, INVEST RADIOL, V0, P0, DOI DOI 10.1097/RLI.0 0 0 0000000000763
   Bayliss Elizabeth A, 2005, HEALTH QUAL LIFE OUTCOMES, V3, P51
   Brady AP, 2017, INSIGHTS IMAGING, V8, P171, DOI 10.1007/s13244-016-0534-1
   Bruno MA, 2015, RADIOGRAPHICS, V35, P1668, DOI 10.1148/rg.2015150023
   Cai JZ, 2018, LECT NOTES COMPUT SC, V11071, P589, DOI 10.1007/978-3-030-00934-2_66
   Chattopadhay A, 2018, IEEE WINT CONF APPL, V0, PP839, DOI 10.1109/WACV.2018.00097
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Dippel S, 2002, IEEE T MED IMAGING, V21, P343, DOI 10.1109/TMI.2002.1000258
   Fleishon HB, 2006, ACAD RADIOL, V13, P453, DOI 10.1016/j.acra.2005.12.014
   Gaal G, 2020, ATTENTION U NET BASE, V0, P0
   Gal Y, 2016, PR MACH LEARN RES, V48, P0
   Ghamrawi N, 2005, P 14 ACM INT C INF K, V0, PP195, DOI 10.1145/1099554.1099591
   Ghesu FC, 2021, MED IMAGE ANAL, V68, P0, DOI 10.1016/j.media.2020.101855
   Ghesu FC, 2019, LECT NOTES COMPUT SC, V11769, P676, DOI 10.1007/978-3-030-32226-7_75
   Ghesu FC, 2019, IEEE T PATTERN ANAL, V41, P176, DOI 10.1109/TPAMI.2017.2782687
   Gohagan JK, 2000, CONTROL CLIN TRIALS, V21, P251S, DOI 10.1016/S0197-2456(00)00097-0
   Gómez O, 2020, NEURAL COMPUT APPL, V32, P15949, DOI 10.1007/s00521-019-04532-y
   Guan Q, 2018, CORRABS180109927, V0, P0
   Guan QJ, 2020, PATTERN RECOGN LETT, V130, P259, DOI 10.1016/j.patrec.2018.10.027
   Guan WJ, 2020, EUR RESPIR J, V55, P0, DOI 10.1183/13993003.00547-2020
   Gundel Sebastian, 2019, PROGRESS IN PATTERN RECOGNITION, V0, P0
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/TPAMI.2019.2913372
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang ZW, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9010190
   Irvin J, 2019, AAAI CONF ARTIF INTE, V0, P590
   Josang A, 2016, ARTIF INTELL-FOUND, V0, PP1, DOI 10.1007/978-3-319-42337-1
   Jusoh Shaidah, 2018, JOURNAL OF THEORETICAL AND APPLIED INFORMATION TECHNOLOGY, V96, P1486
   Karimi D, 2020, MED IMAGE ANAL, V65, P0, DOI 10.1016/j.media.2020.101759
   Kholiavchenko M, 2020, INT J COMPUT ASS RAD, V15, P425, DOI 10.1007/s11548-019-02115-9
   Kingma DP, 2014, C TRACK P, V0, P0
   Lakshminarayanan B, 2017, ADV NEUR IN, V30, P0
   Larrazabal AJ, 2020, IEEE T MED IMAGING, V39, P3813, DOI 10.1109/TMI.2020.3005297
   Li W, 2016, COMPUT MATH METHOD M, V2016, P0, DOI 10.1155/2016/6215085
   Liu H, 2019, COMPUT MED IMAG GRAP, V75, P66, DOI 10.1016/j.compmedimag.2019.05.005
   Mehta H, 2017, ARXIV171105225, V0, P0
   Oakden-Rayner L, 2019, HALF MILLION XRAYS 1, V0, P0
   Oakden-Rayner L, 2017, EXPLORING CHESTXRAY1, V0, P0
   Philipsen RHHM, 2015, IEEE T MED IMAGING, V34, P1965, DOI 10.1109/TMI.2015.2418031
   Rajkomar A, 2018, NPJ DIGIT MED, V1, P0, DOI 10.1038/s41746-018-0029-1
   Rajpurkar P, 2018, PLOS MED, V15, P0, DOI 10.1371/journal.pmed.1002686
   Rolnick D, 2017, DEEP LEARNING IS ROB, V0, P0
   Rubin J, 2018, CORRABS180407839, V0, P0
   Rusiecki A, 2019, LECT NOTES ARTIF INT, V11508, P215, DOI 10.1007/978-3-030-20912-4_21
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvan R, 2020, ICML WORKSHOP ART LE, V0, P0
   Shen Y, 2018, LECT NOTES COMPUT SC, V11046, P389, DOI 10.1007/978-3-030-00919-9_45
   Tang YX, 2018, LECT NOTES COMPUT SC, V11046, P249, DOI 10.1007/978-3-030-00919-9_29
   Van Eeden S, 2012, AM J RESP CRIT CARE, V186, P11, DOI 10.1164/rccm.201203-0455PP
   Wang HY, 2021, MED IMAGE ANAL, V67, P0, DOI 10.1016/j.media.2020.101846
   Wang HY, 2020, IEEE J BIOMED HEALTH, V24, P475, DOI 10.1109/JBHI.2019.2928369
   Wang X, 2019, IMAE NOISE ROBUST LE, V0, P0
   Wang XS, 2017, PROC CVPR IEEE, V0, PP3462, DOI 10.1109/CVPR.2017.369
   Yan CC, 2018, ACM-BCB18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, V0, P0
   Zhang Z, 2018, GEN CROSS ENTROPY LO, V0, P0
   Zhe L, 2018, PROC CVPR IEEE, V0, PP8290, DOI 10.1109/CVPR.2018.00865
   Zhu S, 2005, SIGIR 2005. PROCEEDINGS OF THE TWENTY-EIGHTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP274, DOI 10.1145/1076034.1076082
   Zhu WT, 2018, IEEE WINT CONF APPL, V0, PP673, DOI 10.1109/WACV.2018.00079
   Zotin A, 2019, PROCEDIA COMPUT SCI, V159, P1439, DOI 10.1016/j.procs.2019.09.314
NR 67
TC 12
Z9 12
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD AUG 15
PY 2021
VL 72
IS 
BP 
EP 
DI 10.1016/j.media.2021.102087
EA MAY 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA TU8XW
UT WOS:000681314900005
PM 34015595
DA 2023-11-10
ER

PT J
AU Ganesh, P
   Chen, Y
   Lou, X
   Khan, MA
   Yang, Y
   Sajjad, H
   Nakov, P
   Chen, DM
   Winslett, M
AF Ganesh, Prakhar
   Chen, Yao
   Lou, Xin
   Khan, Mohammad Ali
   Yang, Yin
   Sajjad, Hassan
   Nakov, Preslav
   Chen, Deming
   Winslett, Marianne
TI Compressing Large-Scale Transformer-Based Models: A Case Study on BERT
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Pre-trained Transformer-based models have achieved state-of-the-art performance for various Natural Language Processing (NLP) tasks. However, these models often have billions of parameters, and thus are too resourcehungry and computation-intensive to suit lowcapability devices or applications with strict latency requirements. One potential remedy for this is model compression, which has attracted considerable research attention. Here, we summarize the research in compressing Transformers, focusing on the especially popular BERT model. In particular, we survey the state of the art in compression for BERT, we clarify the current best practices for compressing large-scale Transformer models, and we provide insights into the workings of various methods. Our categorization and analysis also shed light on promising future research directions for achieving lightweight, accurate, and generic NLP models.
C1 [Ganesh, Prakhar; Chen, Yao; Lou, Xin; Khan, Mohammad Ali] Adv Digital Sci Ctr, Singapore, Singapore.
   [Yang, Yin] Hamad Bin Khalifa Univ, Coll Sci & Engn, Ar Rayyan, Qatar.
   [Sajjad, Hassan; Nakov, Preslav] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Ar Rayyan, Qatar.
   [Chen, Deming; Winslett, Marianne] Univ Illinois, Urbana, IL USA.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Computing Research Institute; University of Illinois System; University of Illinois Urbana-Champaign
RP Ganesh, P (通讯作者)，Adv Digital Sci Ctr, Singapore, Singapore.
EM prakhar.g@adsc-create.edu.sg; yao.chen@adsc-create.edu.sg; lou.xin@adsc-create.edu.sg; mohamraad.k@adsc-create.edu.sg; yyang@hbku.edu.qa; hsajjad@hbku.edu.qa; pnakov@hbku.edu.qa; dchen@illinois.edu; winslett@illinois.edu
FU Qatar National Research Fund (Qatar Foundation) [NPRP10-0208-170408]; National Research Foundation, Prime Minister's Office, Singapore, under its Campus for Research Excellence and Technological Enterprise (CREATE) program
CR Ben Noach M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P884
   Boo Y, 2020, INT CONF ACOUST SPEE, V0, PP1753, DOI 10.1109/icassp40776.2020.9054724
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Cao QQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4487
   Chen DY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2463
   Chen Tianlong, 2020, P 34 C NEUR INF PROC, V0, P1753
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Chia Yew Ken, 2018, P COMP DEEP NEUR NET, V0, P0
   Chumachenko Artem, 2020, WEIGHT SQUEEZING REP, V0, P0
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, PP276, DOI 10.18653/v1/w19-4828
   Deb Kalyanmoy, 2014, SEARCH METHODOLOGIES, V0, PP403, DOI 10.1007/978-1-4614-6940-7_15
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding LF, 2020, 11TH IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG 2020), V0, PP420, DOI 10.1109/ICBK50248.2020.00066
   Fan Angela, 2021, P 10 INT C LEARN REP, V0, P0
   Fan Angela, 2020, P 8 INT C LEARN REPR, V0, P0
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Franco J, 2021, PHYSIOTHER THEOR PR, V37, P1419, DOI 10.1080/09593985.2019.1709234
   Gordon MA, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P143
   Goyal Saurabh, 2020, INT C MACH LEARN PML, V0, P3690
   Guo Fu-Ming, 2019, ARXIV190912486, V0, P0
   HOU L, 2020, ADV NEUR IN, V33, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hubara I, 2018, J MACH LEARN RES, V18, P0
   Jiao X, 2020, FINDINGS ASS COMPUTA, V0, PP4163, DOI 10.18653/v1/2020.findings-emnlp.372
   Kaitao, 2020, ARXIV200412817, V0, P0
   Khetan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2807
   Kitaev Nikita, 2020, ARXIV200104451, V0, P0
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4365
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Li B, 2020, FINDINGS ASS COMPUTA, V0, P3187
   Li JQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3009
   Li Zhuohan, 2020, INT C MACH LEARN, V0, P5958
   Lin Z, 2020, P FIND ASS COMP LING, V0, P719
   Liu L, 2019, ARXIV191103588, V0, P0
   Liu W, 2020, P 58 ANN M ASS COMPU, V0, PP6035, DOI 10.18653/V1/2020.ACL-MAIN.537
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Machacek Matous, 2014, P 9 WORKSH STAT MACH, V0, PP293, DOI 10.3115/v1/W14-3336
   Mao Yihuan, 2020, COLING, V0, PP3225, DOI 10.18653/V1/2020.COLING-MAIN.287
   Michel Paul, 2019, ADV NEURAL INFORM PR, V0, P14014
   Mukherjee S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2221
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Prakash Prafull, 2020, FIND 2020 C EMP METH, V0, PP4711, DOI 10.18653/v1/2020.findings-emnlp.423
   Prasanna S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3208
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Raganato A, 2020, FINDINGS ASS COMPUTA, V0, PP556, DOI 10.18653/V1/2020.FINDINGS-EMNLP.49
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rosset, 2020, MICROSOFT RES BLOG, V2, P13
   Sajjad Hassan, 2020, ARXIV200403844, V0, P0
   Sanh Victor, 2020, ADV NEURAL INFORM PR, V33, P0
   Sanh Victor, 2019, P 5 WORKSH EN EFF MA, V0, P0, DOI DOI 10.1609/aaai.v34i05.6409
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Shoeybi M, 2019, ARXIV, V0, P0
   Sun SQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P498
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4323
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2158
   Tambe T, 2021, MICRO, V0, P0
   Tang R, 2019, P 2 WORKSH DEEP LEAR, V0, PP202, DOI 10.18653/V1/D19-6122
   Tay Yi, 2020, ARXIV200500743, V0, P0
   Tian James Yi, 2019, ARXIV191206638, V0, P0
   Tsai Henry, 2020, ARXIV200806808, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang SR, 2020, COMPUTING, V102, P717, DOI 10.1007/s00607-019-00768-7
   Wang Sinong, 2020, ARXIV200604768, V0, P0, DOI DOI 10.1007/s00607-019-00768-7
   Wang Wenhui, 1900, V33, V0, P0
   Wasserblat Moshe, 2020, P SUSTAINLP WORKSHOP, V0, PP35, DOI 10.18653/V1/2020.SUSTAINLP-1.5
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Xin J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2246
   Xu CW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7859
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), V0, PP811, DOI 10.1109/MICRO50266.2020.00071
   Zafrir O, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), V0, PP36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zhao Guangxiang, 2019, ARXIV191211637, V0, P0
   Zhao Sanqiang, 2019, ARXIV190911687, V0, P0
   Zhou Denny, 1900, P11546, V0, P0
   Zhou W, 2020, ADV NEURAL INFORM PR, V0, P0
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 82
TC 33
Z9 34
U1 9
U2 21
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 1061
EP 1080
DI 10.1162/tacl_a_00413
PG 20
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200063
DA 2023-11-10
ER

PT J
AU Bugliarello, E
   Cotterell, R
   Okazaki, N
   Elliott, D
AF Bugliarello, Emanuele
   Cotterell, Ryan
   Okazaki, Naoaki
   Elliott, Desmond
TI Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework of Vision-and-Language BERTs
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Large-scale pretraining and task-specific fine-tuning is now the standard methodology for many tasks in computer vision and natural language processing. Recently, a multitude of methods have been proposed for pretraining vision and language BERTs to tackle challenges at the intersection of these two key areas of AI. These models can be categorized into either single-stream or dual-stream encoders. We study the differences between these two categories, and show how they can be unified under a single theoretical framework. We then conduct controlled experiments to discern the empirical differences between five vision and language BERTs. Our experiments show that training data and hyperparameters are responsible for most of the differences between the reported results, but they also reveal that the embedding layer plays a crucial role in these massive models.
C1 [Bugliarello, Emanuele] Univ Copenhagen, Copenhagen, Denmark.
   [Cotterell, Ryan] Univ Cambridge, Cambridge, England.
   [Cotterell, Ryan; Okazaki, Naoaki] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Elliott, Desmond] Tokyo Inst Technol, Tokyo, Japan.
C3 University of Copenhagen; University of Cambridge; Swiss Federal Institutes of Technology Domain; ETH Zurich; Tokyo Institute of Technology
RP Bugliarello, E (通讯作者)，Univ Copenhagen, Copenhagen, Denmark.
EM emanuele@di.ku.dk; rcotterell@inf.ethz.ch; okazaki@c.titech.ac.jp; de@di.ku.dk
FU European Union [801199]; "Research and Development of Deep Learning Technology for Advanced Multilingual Speech Translation,'' the Commissioned Research of National Institute of Information and Communications Technology (NICT), Japan
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Ba Jimmy Lei, 2016, ARXIV160706450, V0, P0
   Benjamin DJ, 2018, NAT HUM BEHAV, V2, P6, DOI 10.1038/s41562-017-0189-z
   Cho J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8785
   de Vries H, 2017, PROC CVPR IEEE, V0, PP4466, DOI 10.1109/CVPR.2017.475
   Devlin J, 2018, ARXIV, V1, P4171
   Dodge Jesse, 2020, ARXIV200206305, V0, P0
   Gardner Matt, 2020, FINDINGS ASS COMPUTA, V0, P1307
   Geva M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1161
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Gururangan Suchin, 2018, ARXIV180302324, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hill F, 2021, INT C LEARN REPR, V0, P0
   Huang Zhicheng, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Hudson DA, 2019, PROC CVPR IEEE, V0, PP6693, DOI 10.1109/CVPR.2019.00686
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, V0, PP787, DOI 10.3115/V1/D14-1086
   Kim Wonjae, 2021, P INT C MACH LEARN, V0, P5583
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li LJ, 2019, IEEE I CONF COMP VIS, V0, PP10312, DOI 10.1109/ICCV.2019.01041
   Li X, 2020, COMPUTER VISION ECCV, V0, P121
   Lin JR, 2020, IEEE INT C INT ROBOT, V0, PP4870, DOI 10.1109/IROS45743.2020.9340790
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Mao JH, 2016, PROC CVPR IEEE, V0, PP11, DOI 10.1109/CVPR.2016.9
   Narang Sharan, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Qi Di, 2020, ARXIV200107966, V0, P0
   Radford Alec, 2021, ABS210300020 CORR, V0, P0
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Ren S, 2015, P ADV NEUR INF PROC, V39, P91
   Ribeiro MT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6174
   Rogers A, 2020, FINDINGS ASS COMPUTA, V0, P1256
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3645
   Su Weijie, 2020, P 8 INT C LEARN REPR, V0, P0
   Suhr A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6418
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wu Y, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Xie Ning, 2019, ARXIV190106706, V0, P0
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yu LC, 2018, PROC CVPR IEEE, V0, PP1307, DOI 10.1109/CVPR.2018.00142
   Zellers R, 2019, PROC CVPR IEEE, V0, PP6713, DOI 10.1109/CVPR.2019.00688
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu YK, 2016, PROC CVPR IEEE, V0, PP4995, DOI 10.1109/CVPR.2016.540
NR 53
TC 24
Z9 26
U1 1
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 978
EP 994
DI 10.1162/tacl_a_00408
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200058
DA 2023-11-10
ER

PT J
AU Sezerer, E
   Tenekeci, S
   Acar, A
   Baloglu, B
   Tekir, S
AF Sezerer, Erhan
   Tenekeci, Samet
   Acar, Ali
   Baloglu, Bora
   Tekir, Selma
TI Author Reputation Measurement on Question and Answer Sites by the Classification of Author-Generated Content
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE Author reputation measurement; text classification; question and answer sites; stack overflow; stack exchange
ID grey literature; stack; credibility; reviews
AB In the field of software engineering, practitioners' share in the constructed knowledge cannot be underestimated and is mostly in the form of grey literature (GL). GL is a valuable resource though it is subjective and lacks an objective quality assurance methodology. In this paper, a quality assessment scheme is proposed for question and answer (Q&A) sites. In particular, we target stack overflow (SO) and stack exchange (SE) sites. We model the problem of author reputation measurement as a classification task on the author-provided answers. The authors' mean, median, and total answer scores are used as inputs for class labeling. State-of-the-art language models (BERT and DistilBERT) with a softmax layer on top are utilized as classifiers and compared to SVM and random baselines. Our best model achieves 63.8% accuracy in binary classification in SO design patterns tag and 71.6% accuracy in SE software engineering category. Superior performance in SE software engineering can be explained by its larger dataset size. In addition to quantitative evaluation, we provide qualitative evidence, which supports that the system's predicted reputation labels match the quality of provided answers.
C1 [Sezerer, Erhan; Tenekeci, Samet; Acar, Ali; Baloglu, Bora; Tekir, Selma] Izmir Inst Technol, Dept Comp Engn, Izmir, Turkey.
C3 Izmir Institute of Technology
RP Tekir, S (通讯作者)，Izmir Inst Technol, Dept Comp Engn, Izmir, Turkey.
EM erhansezerer@iyte.edu.tr; samettenekeci@iyte.edu.tr; aliacar@iyte.edu.tr; baloglub@gmail.com; selmatekir@iyte.edu.tr
CR Adams RJ, 2017, INT J MANAG REV, V19, P432, DOI 10.1111/ijmr.12102
   Agichtein Eugene, 2008, P INT C WEB SEARCH W, V0, PP183, DOI 10.1145/1341531.1341557
   [Anonymous], 2009, P 18 INT C WORLD WID, V0, P0, DOI DOI 10.1145/1526709.1526717
   Barua A, 2014, EMPIR SOFTW ENG, V19, P619, DOI 10.1007/s10664-012-9231-y
   Bazelli B, 2013, PROC IEEE INT CONF S, V0, PP460, DOI 10.1109/ICSM.2013.72
   Devlin J, 2018, ARXIV, V1, P4171
   Fritch JW, 2001, J AM SOC INF SCI TEC, V52, P499, DOI 10.1002/asi.1081
   Gao ZP, 2020, ACM T SOFTW ENG METH, V29, P0, DOI 10.1145/3401026
   Garousi V, 2019, INFORM SOFTWARE TECH, V106, P101, DOI 10.1016/j.infsof.2018.09.006
   Garousi V, 2016, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE ON EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING 2016 (EASE 16), V0, P0, DOI DOI 10.1145/2915970.2916008
   Hanrahan Benjamin V, 2012, P ACM 2012 C COMPUTE, V0, P0, DOI DOI 10.1145/2141512.2141550
   Khan HU, 2017, COMPUT HUM BEHAV, V68, P64, DOI 10.1016/j.chb.2016.11.012
   Li T, 2012, CH CRC DATA MIN KNOW, V0, P1
   Liang SS, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1764, DOI 10.1145/3219819.3220043
   Mahood Q, 2014, RES SYNTH METHODS, V5, P221, DOI 10.1002/jrsm.1106
   Metzger MJ, 2007, J AM SOC INF SCI TEC, V58, P2078, DOI 10.1002/asi.20672
   Neshati M, 2017, INFORM PROCESS MANAG, V53, P780, DOI 10.1016/j.ipm.2017.02.005
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Ponzanelli L, 2014, PROC IEEE INT CONF S, V0, PP541, DOI 10.1109/ICSME.2014.90
   Riahi F, 2012, P 21 INT C WORLD WID, V0, P791
   Sanh V, 2019, ARXIV191001108, V0, P0
   Sengupta S, 2020, P 53 HAW INT C SYST, V0, P2898
   Toba H, 2014, INFORM SCIENCES, V261, P101, DOI 10.1016/j.ins.2013.10.030
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wathen CN, 2002, J AM SOC INF SCI TEC, V53, P134, DOI 10.1002/asi.10016
   Yao Y, 2015, INFORM SCIENCES, V302, P70, DOI 10.1016/j.ins.2014.12.038
   Zhang Z, 2020, INT J SOFTW ENG KNOW, V30, P1707, DOI 10.1142/S0218194020400276
NR 29
TC 0
Z9 0
U1 1
U2 9
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD OCT 15
PY 2021
VL 31
IS 10
BP 1421
EP 1445
DI 10.1142/S0218194021500479
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WX0ZH
UT WOS:000718333000003
DA 2023-11-10
ER

PT J
AU Yang, LF
   Fu, KQ
   Zhang, JS
   Shinozaki, T
AF Yang, Longfei
   Fu, Kaiqi
   Zhang, Jinsong
   Shinozaki, Takahiro
TI Non-native acoustic modeling for mispronunciation verification based on language adversarial representation learning
SO NEURAL NETWORKS
LA English
DT Article
DE Mispronunciation verification; Computer aided pronunciation training; Language adversarial training; Unsupervised learning; Non-native acoustic modeling
AB Non-native mispronunciation verification is designed to provide feedback to guide language learners to correct their pronunciation errors in their further learning and it plays an important role in the computer-aided pronunciation training (CAPT) system. Most existing approaches focus on establishing the acoustic model directly using non-native corpus thus they are suffering the data sparsity problem due to time-consuming non-native speech data collection and annotation tasks. In this work, to address this problem, we propose a pre-trained approach to utilize the speech data of two native languages (the learner's native and target languages) for non-native mispronunciation verification. We set up an unsupervised model to extract knowledge from a large scale of unlabeled raw speech of the target language by making predictions about future observations in the speech signal, then the model is trained with language adversarial training using the learner's native language to align the feature distribution of two languages by confusing a language discriminator. In addition, sinc filter is incorporated at the first convolutional layer to capture the formant-like feature. Formant is relevant to the place and manner of articulation. Therefore, it is useful not only for pronunciation error detection but also for providing instructive feedback. Then the pre-trained model serves as the feature extractor in the downstream mispronunciation verification task. Through the experiments on the Japanese part of the BLCU inter-Chinese speech corpus, the experimental results demonstrate that for the non-native phone recognition and mispronunciation verification tasks (1) the knowledge learned from two native languages speech with the proposed unsupervised approach is useful for these two tasks (2) our proposed language adversarial representation learning is effective to improve the performance (3) formant-like feature can be incorporated by introducing sinc filter to further improve the performance of mispronunciation verification. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Yang, Longfei; Shinozaki, Takahiro] Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo, Japan.
   [Fu, Kaiqi; Zhang, Jinsong] Beijing Language & Culture Univ, Res Inst Int Chinese Language Educ, Beijing, Peoples R China.
C3 Tokyo Institute of Technology; Beijing Language & Culture University
RP Shinozaki, T (通讯作者)，Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo, Japan.; Zhang, JS (通讯作者)，Beijing Language & Culture Univ, Res Inst Int Chinese Language Educ, Beijing, Peoples R China.
EM yang.l.ae@m.titech.ac.jp; kaiq.fu@gmail.com; jinsong.zhang@blcu.edu.cn; shinot@ict.e.titech.ac.jp
FU JSPS KAKENHI [JP20H00095]; Discipline TeamSupport Program of Beijing Language and Culture University [GF201906]; Advanced Innovation Center for Language Resource and Intelligence [KYR17005]
CR [Anonymous], 2011, THESIS, V0, P0
   Browne MW, 2000, J MATH PSYCHOL, V44, P108, DOI 10.1006/jmps.1999.1279
   Bu H, 2017, 2017 20TH CONFERENCE OF THE ORIENTAL CHAPTER OF THE INTERNATIONAL COORDINATING COMMITTEE ON SPEECH DATABASES AND SPEECH I/O SYSTEMS AND ASSESSMENT (O-COCOSDA), V0, PP58, DOI 10.1109/ICSDA.2017.8384449
   Cao W, 2009, P NCMMSC, V0, P0
   Cao W, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1922
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Duan R, 2014, 15 ANN C INT SPEECH, V0, P0
   Duan RC, 2020, IEEE-ACM T AUDIO SPE, V28, P391, DOI 10.1109/TASLP.2019.2955858
   Fohr D, 2006, 9 INT C SPOK LANG PR, V0, P0
   Gao YM, 2016, ASIAPAC SIGN INFO PR, V0, P0, DOI DOI 10.1109/APSIPA.2016.7820820
   Gao YM, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P693
   Haibo He, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE. ICAI 2007, V0, P358
   Harrison AM, 2009, P S LANG APPL TECHN, V0, P45
   Hu WP, 2013, INTERSPEECH, V0, P1885
   Hu WP, 2015, SPEECH COMMUN, V67, P154, DOI 10.1016/j.specom.2014.12.008
   Hyvarinen Aapo, 2016, ADV NEURAL INFORM PR, V0, P3765
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Iverson P, 2003, COGNITION, V87, PB47, DOI 10.1016/S0010-0277(02)00198-1
   Jo Chul-Ho, 1998, 5 INT C SPOK LANG PR, V0, P0
   Joshi S, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P697
   King DB, 2015, ACS SYM SER, V1214, P1
   Koreman J, 2013, SPEECH LANGUAGE TECH, V0, P0
   Lee A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P643
   Lin J, 2021, J MED VIROL, V93, P934, DOI 10.1002/jmv.26346
   Maekawa K, 2004, REPRODUCTION, V16, P5
   Ravanelli M, 2018, ARXIV181109725, V0, P0
   Ravanelli M, 2018, IEEE W SP LANG TECH, V0, PP1021, DOI 10.1109/SLT.2018.8639585
   Rivière M, 2020, INT CONF ACOUST SPEE, V0, PP7414, DOI 10.1109/icassp40776.2020.9054548
   Schneider Steffen, 2019, ARXIV190405862, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tieleman T, 2012, COURSERA LECT 65 RMS, V0, P0
   Uebler U, 1999, 6 EUR C SPEECH COMM, V0, P0
   Viikki O, 1998, SPEECH COMMUN, V25, P133, DOI 10.1016/S0167-6393(98)00033-8
   Vinyals O, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Wang YJ, 2004, P CHINESE TEACHING W, V2004, P54, DOI 10.13724/j.cnki.ctiw.2004.03.008
   Wang YB, 2012, INT CONF ACOUST SPEE, V0, PP5049, DOI 10.1109/ICASSP.2012.6289055
   Wang Z, 2003, P 2003 IEEE INT C AC, V0, PI
   Wei S, 2009, SPEECH COMMUN, V51, P896, DOI 10.1016/j.specom.2009.03.004
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Witt SM, 1999, THESIS, V0, P0
   Witt SM, 2000, SPEECH COMMUN, V30, P95, DOI 10.1016/S0167-6393(99)00044-8
   Wu Longji, 1989, SUMMARY EXPT PHONETI, V0, P0
   Xie XL, 2010, J JILIN TEACHERS I E, V0, P0
   Yang LF, 2017, INT CONF ASIAN LANG, V0, PP52, DOI 10.1109/IALP.2017.8300544
   Zheng J, 2007, INT CONF ACOUST SPEE, V0, P201
NR 45
TC 4
Z9 4
U1 1
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD OCT 15
PY 2021
VL 142
IS 
BP 597
EP 607
DI 10.1016/j.neunet.2021.07.017
EA AUG 2021
PG 11
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA UJ9WU
UT WOS:000691628800016
PM 34388438
DA 2023-11-10
ER

PT J
AU Hao, ZF
   Lv, D
   Li, ZJ
   Cai, RC
   Wen, W
   Xu, BY
AF Hao, Zhifeng
   Lv, Di
   Li, Zijian
   Cai, Ruichu
   Wen, Wen
   Xu, Boyan
TI Semi-supervised disentangled framework for transferable named entity recognition
SO NEURAL NETWORKS
LA English
DT Article
DE Named entity recognition; Semi-supervised learning; Transfer learning; Disentanglement
AB Named entity recognition (NER) for identifying proper nouns in unstructured text is one of the most important and fundamental tasks in natural language processing. However, despite the widespread use of NER models, they still require a large-scale labeled data set, which incurs a heavy burden due to manual annotation. Domain adaptation is one of the most promising solutions to this problem, where rich labeled data from the relevant source domain are utilized to strengthen the generalizability of a model based on the target domain. However, the mainstream cross-domain NER models are still affected by the following two challenges (1) Extracting domain-invariant information such as syntactic information for cross-domain transfer. (2) Integrating domain-specific information such as semantic information into the model to improve the performance of NER. In this study, we present a semi supervised framework for transferable NER, which disentangles the domain-invariant latent variables and domain-specific latent variables. In the proposed framework, the domain-specific information is integrated with the domain-specific latent variables by using a domain predictor. The domain-specific and domain-invariant latent variables are disentangled using three mutual information regularization terms, i.e., maximizing the mutual information between the domain-specific latent variables and the original embedding, maximizing the mutual information between the domain-invariant latent variables and the original embedding, and minimizing the mutual information between the domain-specific and domain-invariant latent variables. Extensive experiments demonstrated that our model can obtain state-of-the-art performance with cross-domain and cross-lingual NER benchmark data sets. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Hao, Zhifeng; Lv, Di; Li, Zijian; Cai, Ruichu; Wen, Wen; Xu, Boyan] Guangdong Univ Technol, Sch Comp Sci, Guangzhou, Peoples R China.
   [Hao, Zhifeng] Foshan Univ, Sch Math & Big Data, Guangzhou, Peoples R China.
C3 Guangdong University of Technology; Foshan University
RP Cai, RC (通讯作者)，Guangdong Univ Technol, Sch Comp Sci, Guangzhou, Peoples R China.
EM cairuichu@gmail.com
FU NSFC-Guangdong Joint Fund, China [U1501254]; Natural Science Foundation of China [61876043]; Natural Science Foundation of Guangdong, China [2014A030306004, 2014A030308008]; Guangdong High-level Personnel of Special Support Program, China [2015TQ01X140]; Science and Technology Planning Project of Guangzhou, China [201902010058]
CR [Anonymous], 2016, ARXIV160306270, V0, P0
   [Anonymous], 2018, P IEEE ACM 26 INT S, V0, P0, DOI DOI 10.1109/IWQOS.2018.8624168
   Belghazi MI, 2018, PR MACH LEARN RES, V80, P0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cai RC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2060
   Chen M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2453
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/tacl_a_00104
   Collins H, 2017, GRAVITYS KISS: THE DETECTION OF GRAVITATIONAL WAVES, V0, P195
   Dinh Laurent, 2014, ARXIV14108516, V0, P0
   Donsker DM, 1975, ASYMPTOTIC EVALUATIO, Vii, P279
   Duan N, 2017, P 2017 C EMP METH NA, V0, PP866, DOI 10.18653/V1/D17-1090
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Higgins Irina, 2016, BETA VAE LEARNING BA, V0, P0
   Hu J, 2019, ARXIV190600376, V0, P0
   Kim H, 2018, PR MACH LEARN RES, V80, P0
   Kim Joo-Kyung, 2017, P 2017 C EMP METH NA, V0, PP2832, DOI 10.18653/V1/D17-1302
   King DB, 2015, ACS SYM SER, V1214, P1
   Konkol Michal, 2014, TEXT, V0, P0
   Lafferty J, 2001, CONDITIONAL RANDOM F, V0, P282
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lee JY, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P4470
   Lin BY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2012
   Liu JJ, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP72, DOI 10.1109/ASRU.2013.6707708
   Liu LQ, 2018, AAAI CONF ARTIF INTE, V0, P8109
   Locatello F, 2019, PR MACH LEARN RES, V97, P0
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   McCallum A, 2000, ICML, V0, P0
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   Ritter A, 2011, P C EMP METH NAT LAN, V0, PP1524, DOI 10.1075/LI.30.1.03NAD
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Tjong Kim Sang EF, 2002, COLING 02 6 C NAT LA, V0, P0
   Tran Q, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Tzeng E, 2015, IEEE I CONF COMP VIS, V0, PP4068, DOI 10.1109/ICCV.2015.463
   Weischedel Ralph, 2013, ONTONOTES RELEASE 50, V0, P0
   Xiao M, 2012, 26 AAAI C ART INT, V0, P0
   Yang Zhilin, 2017, ICLR, V0, P0
   Zeldes A, 2017, LANG RESOUR EVAL, V51, P581, DOI 10.1007/s10579-016-9343-x
   Zhang LH, 2015, INT CONF SOFTW ENG, V0, PP931, DOI 10.1109/ICSESS.2015.7339207
   Zhang ZJ, 2018, PROCEEDINGS OF GEOSHANGHAI 2018 INTERNATIONAL CONFERENCE: FUNDAMENTALS OF SOIL BEHAVIOURS, V0, PP185, DOI 10.1007/978-981-13-0125-4_20
NR 41
TC 9
Z9 11
U1 1
U2 34
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD MAR 15
PY 2021
VL 135
IS 
BP 127
EP 138
DI 10.1016/j.neunet.2020.11.017
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA PW9LL
UT WOS:000610987500011
PM 33383527
DA 2023-11-10
ER

PT J
AU Xue, SY
   Ren, FJ
AF Xue, Siyuan
   Ren, Fuji
TI Intent-enhanced attentive Bert capsule network for zero-shot intention detection
SO NEUROCOMPUTING
LA English
DT Article
DE Zero-shot intent detection; Label embedding attention mechanism; Pre-trained language model; Attentive capsule network; Metric learning
ID extraction
AB Spoken language understanding (SLU) plays an indispensable role in the dialogue system. The traditional intention detection task is regarded as a classification problem where utterances are associated with predefined intents. However, the various expressions of user's intents and constantly emerging novel intents make the annotating time-consuming and labor-intensive, building massive obstacles for extending the model to new tasks. Identifying unexpected user intention and achieving the user's desire goal is a challenging task. Therefore, we conduct zero-shot intention detection based on a transformation-based learning manner. In this paper, we propose an intent-enhanced attentive capsule network (IE-BertCapsNet) further guides the aggregation process of the capsule network and generalizable useful features that can be adapted to emerging intentions. Coupling with the large margin cosine loss function, the proposed model can identify discriminative features by forcing the whole network to minimize inter-class distance and minimize intra-class distance. Finally, we leverage the IE-BertCapsNet's feature extraction ability and knowledge transferring capability to conduct zero-shot intent detection and generalized zero-shot intent detection. Extensive experiments on five benchmark task-oriented datasets in four languages demonstrate that the proposed model can achieve competitive performance that can better discriminate known intents and detect unknown intents. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Xue, Siyuan; Ren, Fuji] Tokushima Univ, Fac Engn, Tokushima 7700814, Japan.
C3 Tokushima University
RP Ren, FJ (通讯作者)，Tokushima Univ, Fac Engn, Tokushima 7700814, Japan.
EM 501747003@tokushima-u.ac.jp; ren@is.tokushima-u.ac.jp
FU Research Clusters program of Tokushima University [2003002]
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, P0, DOI 10.1109/TPAMI.2015.2487986
   [Anonymous], 2014, C EMPIRICAL METHODS, V0, P0
   [Anonymous], 2016, P 2016 C N AM CHAPTE, V0, P0
   Bach, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Chen YN, 2016, INT CONF ACOUST SPEE, V0, PP6045, DOI 10.1109/ICASSP.2016.7472838
   Chen Z, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P547
   Coucke A, 2018, SNIPS VOICE PLATFORM, V0, P0
   Deng JW, 2023, IEEE T AFFECT COMPUT, V14, P475, DOI 10.1109/TAFFC.2020.3034215
   Du CX, 2019, AAAI CONF ARTIF INTE, V0, P6359
   Ferreira E, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1403
   Ferreira E, 2015, INT CONF ACOUST SPEE, V0, PP5321, DOI 10.1109/ICASSP.2015.7178987
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Geng RY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3904
   Gong J, 2018, PROC 27 INT C COMPUT, V0, P2742
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hua X, 2018, PROCESSINGS ACL, V0, P5491
   Khanpour H, 2016, P COLING 2016 26 INT, V0, P2012
   Kim J, 2020, NEUROCOMPUTING, V376, P214, DOI 10.1016/j.neucom.2019.10.033
   King DB, 2015, ACS SYM SER, V1214, P1
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V0, PP3294, DOI 10.5555/2969442.2969607
   Kumar A, 2017, INTERSPEECH, V0, PP2914, DOI 10.21437/Interspeech.2017-516
   Liu Han, 2019, C EMP METH NAT LANG, V0, P4798
   Ma Yukun, 2016, P COLING 2016 26 INT, V0, P171
   Palatucci Mark, 2009, NEURIPS, V0, P1410
   Peng C, 2017, PROC CVPR IEEE, V0, PP1743, DOI 10.1109/CVPR.2017.189
   Quan CQ, 2016, INFORM SCIENCES, V329, P581, DOI 10.1016/j.ins.2015.09.050
   Quan CQ, 2014, INFORM SCIENCES, V272, P16, DOI 10.1016/j.ins.2014.02.063
   Ren FJ, 2005, INT J INF TECH DECIS, V4, P141, DOI 10.1142/S0219622005001428
   Ren FJ, 2020, IEEE ACCESS, V8, P82242, DOI 10.1109/ACCESS.2020.2991484
   Ren FJ, 2016, INFORM SCIENCES, V329, P568, DOI 10.1016/j.ins.2015.09.052
   Ren FJ, 2013, INFORM SCIENCES, V236, P109, DOI 10.1016/j.ins.2013.02.029
   Rodriguez-Serrano JA, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.5
   Sabour S, 2017, ADV NEURAL INFORM PR, V1, P3856, DOI 10.5555/3294996.3295142
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Schuster S, 2018, NAACL, V0, P0
   Shen D, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Wang GY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2321
   Wang H, 2018, PROC CVPR IEEE, V0, PP5265, DOI 10.1109/CVPR.2018.00552
   Wang YQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2033, DOI 10.1145/3308558.3313750
   Xia CY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3090
   Xue S, 2018, P ICSESS, V0, P0
   Yan GF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1050
   Yang M, 2019, NEURAL NETWORKS, V118, P247, DOI 10.1016/j.neunet.2019.06.014
   Yazdani Majid, 2015, P 2015 C EMP METH NA, V0, PP244, DOI 10.18653/V1/D15-1027
   Yogatama D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P291
   Zhang BW, 2020, IEEE-ACM T AUDIO SPE, V28, P2538, DOI 10.1109/TASLP.2020.3017093
   Zhang CL, 2017, INTERSPEECH, V0, PP1487, DOI 10.21437/Interspeech.2017-1608
   Zhang HW, 2016, PROC CVPR IEEE, V0, PP2809, DOI 10.1109/CVPR.2016.307
   Zhang NY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P986
   ZHANG W, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Zheng WS, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5464
   Zhou YY, 2020, RESEARCH-CHINA, V2020, P0, DOI 10.34133/2020/2616410
NR 53
TC 3
Z9 3
U1 2
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 11
PY 2021
VL 458
IS 
BP 1
EP 13
DI 10.1016/j.neucom.2021.05.085
EA JUN 2021
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA UJ8WL
UT WOS:000691559800001
DA 2023-11-10
ER

PT J
AU He, KQ
   Yan, YM
   Xu, WR
AF He, Keqing
   Yan, Yuanmeng
   Xu, Weiran
TI From context-aware to knowledge-aware: Boosting OOV tokens recognition in slot tagging with background knowledge
SO NEUROCOMPUTING
LA English
DT Article
DE Slot tagging; Contextual representation; Background knowledge; Knowledge Integration; Multi-level graph attention
AB Neural-based context-aware models for slot tagging tasks in language understanding have achieved state-of-the-art performance, especially deep contextualized models, such as ELMo, BERT. However, the presence of out-of-vocab (OOV) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-aware slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multi-level graph attention to explicitly reason via lexical relations. We aim to leverage both linguistic regularities covered by deep language models (LM) and high-quality background knowledge derived from curated knowledge bases (KB). Consequently, our model could infer rare and unseen words in the test dataset by incorporating contextual semantics learned from the training dataset and lexical relations from ontology. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets. We also show through detailed analysis that incorporating background knowledge effectively alleviates issues of data scarcity. (c) 2021 Elsevier B.V. All rights reserved.
C1 [He, Keqing; Yan, Yuanmeng; Xu, Weiran] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Xu, WR (通讯作者)，Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.
EM kqin@bupt.edu.cn; yanyuanmeng@bupt.edu.cn; xuweiran@bupt.edu.cn
FU National Key R&D Program of China [2019YFF0303300, 2019YFF0303302, MCM20190701]
CR Chen Q, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Chen Q, 2017, ARXIV171104289, V0, P0
   Coucke Alice, 2018, ABS190707526 CORR, V0, P0
   Das R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Devlin Jacob, 2019, PRETRAINING DEEP BID, V0, P0
   E HH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5467
   Goo C-W, 2018, P C N AM CH ASS COMP, V2, P753
   Hakkani-Tur D, 2019, P 57 ANN M ASS COMP, V0, P0, DOI DOI 10.18653/v1/p19-1547
   Hakkani-Tur DZ, 2019, ACL, V0, P0
   Hemphill CT, 1990, P SPEECH NAT LANG P, V0, P0
   Iyyer M, 2018, P 2018 C N AM CHAPT, V1, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Lee S, 2018, AAAI, V0, P0
   Liang P, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Lin BY, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Liu B, 2015, PROCEEDING NIPS WORK, V0, P0
   Liu B, 2016, INTERSPEECH, V0, PP685, DOI 10.21437/Interspeech.2016-1352
   Ma Xuezhe, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Ma YK, 2018, AAAI CONF ARTIF INTE, V0, P5876
   Mesnil G, 2015, IEEE-ACM T AUDIO SPE, V23, P530, DOI 10.1109/TASLP.2014.2383614
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Ray A, 2019, INTERSPEECH, V0, PP1183, DOI 10.21437/Interspeech.2019-2955
   Raymond Christian, 2007, INT P, V0, P0
   Socher R, 2013, ADV NEURAL INFORM PR, V0, PP926, DOI 10.1109/ICICIP.2013.6568119
   uGAs, 2016, P 2 WORKSH NOISY USE, V0, P178
   Wen H, 2019, P 2019 C EMP METH NA, V0, P0
   Williams K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES(NAACL HLT 2019), VOL. 2 (INDUSTRY PAPERS), P83
   Wu Y, 2016, ARXIV, V0, P0
   Yang An, 2019, ACL, V0, P0
   Yang B, 2014, ARXIV PREPRINT ARXIV, V0, P0
   Yang BS, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1436, DOI 10.18653/v1/P17-1132
   Yang Qiang, 2018, ARXIV PREPRINT ARXIV, V0, P0
NR 33
TC 3
Z9 3
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUL 20
PY 2021
VL 445
IS 
BP 267
EP 275
DI 10.1016/j.neucom.2021.01.134
EA APR 2021
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SF5RD
UT WOS:000652811700004
DA 2023-11-10
ER

PT J
AU Han, JB
   Wang, HZ
AF Han, Jiabao
   Wang, Hongzhi
TI Improving Open Information Extraction with Distant Supervision Learning
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Distant supervision learning; Open information extraction; Neural network; Sequence-to-sequence model
AB Open information extraction (Open IE), as one of the essential applications in the area of Natural Language Processing (NLP), has gained great attention in recent years. As a critical technology for building Knowledge Bases (KBs), it converts unstructured natural language sentences into structured representations, usually expressed in the form of triples. Most conventional open information extraction approaches leverage a series of manual pre-defined extraction patterns or learn patterns from labeled training examples, which requires a large number of human resources. Additionally, many Natural Language Processing tools are involved, which leads to error accumulation and propagation. With the rapid development of neural networks, neural-based models can minimize the error propagation problem, but it also faces the problem of data-hungry in supervised learning. Especially, they leverage existing Open IE tools to generate training data, and it causes data quality issues. In this paper, we employ a distant supervision learning approach to improve the Open IE task. We conduct extensive experiments by employing two popular sequence-to-sequence models (RNN and Transformer) and a large benchmark data set to demonstrate the performance of our approach.
C1 [Han, Jiabao; Wang, Hongzhi] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, HZ (通讯作者)，Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM jiabaohan@outlook.com; wangzh@hit.edu.cn
FU NSFC [U1866602, 61772157]
CR Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   Bahdanau Dzmitry, 2015, 3 INT C LEARN REPR I, V0, P0
   Cetto M, 2018, P 27 INT C COMP LING, V0, P2300
   Cho K, 2014, COMPUT SCI, V0, P0
   Christensen J, 2010, P NAACL HLT 2010 1 I, V0, P0
   Cui L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P407
   del Corro L, 2013, P 22 INT C WORLD WID, V0, PP355, DOI 10.1145/2488388.2488420
   Duan L, 2019, RES INDOOR LIGHTING, V0, P0
   Etzioni O, 2011, P 22 INT JOINT C ART, V0, PP3, DOI 10.5591/978-1-57735-516-8/IJCAI11-012
   Etzioni O, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1409360.1409378
   Fader A, 2011, P C EMPIRICAL METHOD, V0, PP1535, DOI 10.1234/12345678
   Gashteovski K, 2017, P 2017 C EMP METH NA, V0, P2620
   Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Hill F, 2016, P 4INT C LEARN REPR, V0, P0
   Hoffmann R, 2011, PROC 49 ANN M ASS CO, V1, P541, DOI 10.5555/2002472
   Kenter T, 2015, P 24 ACM INT C INF K, V0, P1411
   Klatt T, 2017, ARXIV170707499 CORR, V0, P0
   Lei K, 2018, ARXIV181201889 CORR, V0, P0
   Li C, 2018, PROC CVPR IEEE, V0, PP5226, DOI 10.1109/CVPR.2018.00548
   Li G, 2017, BIONLP, V0, PP184, DOI 10.18653/V1/W17-2323
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Mausam, 2016, P 25 INT JOINT C ART, V0, P4074
   Min Bonan, 2013, P 2013 C N AM CHAPT, V0, PP777, DOI 10.1186/S40537-016-0043-6
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Pal Harinder, 2016, P 5 WORKSH AUT KNOWL, V0, PP35, DOI 10.18653/V1/W16-1307
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Roth B, 2013, PROC WORKSHOP AUTOMA, V0, P73
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Saha S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P317, DOI 10.18653/v1/P17-2050
   Salthouse TA, 2000, HDB AGING COGNITION, V0, P359
   Santoro A, 2017, P ADV NEUR INF PROC, V0, P4967
   Sarhan I, 2019, LECT NOTES COMPUT SC, V11608, P359, DOI 10.1007/978-3-030-23281-8_31
   Schmitz M, 2012, P 2012 JOINT C EMPIR, V0, P523
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Stanovsky G, 2016, ARXIV160301648 CORR, V0, P0
   Stanovsky G, 2016, P 2016 C EMPIRICAL M, V0, P2300
   Surdeanu M, 2012, EMNLP CONLL, V0, P455
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Takamatsu S, 2012, P 50 ANN M ASS COMPU, V0, P721
   Vaswani A, 2017, ARXIV, V30, P5998
   Weston J, 2016, 4 INT C LEARN REPR I, V0, P0
   Wu F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P118
   Wu Y, 2017, PERIPHYTON: FUNCTIONS AND APPLICATION IN ENVIRONMENTAL REMEDIATION, V0, P1
   Xiong CM, 2016, PR MACH LEARN RES, V48, P0
   Yates A, 2007, P HUM LANG TECHN ANN, V0, PP25, DOI 10.3115/1614164.1614177
   Yong Z, 2017, INT CONF SYST INFORM, V0, PP1477, DOI 10.1109/ICSAI.2017.8248519
NR 49
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD OCT 15
PY 2021
VL 53
IS 5
BP 3287
EP 3306
DI 10.1007/s11063-021-10548-0
EA JUN 2021
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WH4LR
UT WOS:000658086500001
DA 2023-11-10
ER

PT J
AU Atri, YK
   Pramanick, S
   Goyal, V
   Chakraborty, T
AF Atri, Yash Kumar
   Pramanick, Shraman
   Goyal, Vikram
   Chakraborty, Tanmoy
TI See, hear, read: Leveraging multimodality with guided attention for abstractive text summarization
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Abstractive text summarization; Multimodality; Attention; Factorized multimodal transformer; Language model
AB In recent years, abstractive text summarization with multimodal inputs has started drawing attention due to its ability to accumulate information from different source modalities and generate a fluent textual summary. However, existing methods use short videos as the visual modality and short summary as the ground-truth, therefore, perform poorly on lengthy videos and long ground-truth summary. Additionally, there exists no benchmark dataset to generalize this task on videos of varying lengths. In this paper, we introduce AVIATE, the first large-scale dataset for abstractive text summarization with videos of diverse duration, compiled from presentations in well-known academic conferences like NDSS, ICML, NeurIPS, etc. We use the abstract of corresponding research papers as the reference summaries, which ensure adequate quality and uniformity of the ground-truth. We then propose FLORAL, a factorized multi-modal Transformer based decoder-only language model, which inherently captures the intra-modal and inter-modal dynamics within various input modalities for the text summarization task. FLORAL utilizes an increasing number of self-attentions to capture multimodality and performs significantly better than traditional encoder-decoder based networks. Extensive experiments illustrate that FLORAL achieves significant improvement over the baselines in both qualitative and quantitative evaluations on the existing How2 dataset for short videos and newly introduced AVIATE dataset for videos with diverse duration, beating the best baseline on the two datasets by 1.39 and 2.74 ROUGE-L points respectively. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Atri, Yash Kumar; Pramanick, Shraman; Goyal, Vikram; Chakraborty, Tanmoy] IIIT Delhi, New Delhi, India.
C3 Indraprastha Institute of Information Technology Delhi
RP Atri, YK; Pramanick, S (通讯作者)，IIIT Delhi, New Delhi, India.
EM yashk@iiitd.ac.in; shramanp@iiitd.ac.in; vikram@iiitd.ac.in; tanmoy@iiitd.ac.in
FU Ramanujan Fellowship (SERB); Infosys centre for AI, IIIT Delhi, India
CR Baroni M, 2016, LANG LINGUIST COMPAS, V10, P3, DOI 10.1111/lnc3.12170
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Castro S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4619
   Chen JQ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4046
   Chen M, 2017, P 19 ACM INT C MULT, V0, PP163, DOI 10.1145/3136755.3136801
   Cheng JP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P484
   Chopra S, 2016, P 2016 C N AM ASS CO, V0, P93
   Chowdhury T, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3716
   Chung T, 2020, KNOWL-BASED SYST, V192, P0, DOI 10.1016/j.knosys.2019.105363
   Devlin J, 2018, ARXIV, V1, P4171
   Du Y, 2020, KNOWL-BASED SYST, V0, P0
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fabbri AR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1074
   Fang CJ, 2017, EXPERT SYST APPL, V72, P189, DOI 10.1016/j.eswa.2016.12.021
   Gehrmann S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4098
   Gella S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P968
   Graham Yvette, 2015, P 2015 C EMP METH NA, V0, PP128, DOI 10.18653/V1/D15-1013
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI 10.18653/V1/N18-1065
   Haghighi Aria, 2009, P HUM LANG TECHN 200, V0, P0, DOI DOI 10.3115/1620754.1620807
   Hannun AY, 2014, ABS14125567 CORR, V0, P0
   Hara K, 2018, PROC CVPR IEEE, V0, PP6546, DOI 10.1109/CVPR.2018.00685
   Iashin V, 2020, P IEEE CVF C COMP VI, V0, P0
   Kay W, 2017, ARXIV, V0, P0
   Khandelwal Urvashi, 2019, ARXIV, V0, P0
   Kiela D, 2017, DEEP EMBODIMENT GROU, V0, P11
   Lebanoff L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4131
   Li HR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4152
   Li HR, 2019, IEEE T KNOWL DATA EN, V31, P996, DOI 10.1109/TKDE.2018.2848260
   Li Haoran, 2017, P 2017 C EMP METH NA, V0, PP1092, DOI 10.18653/v1/D17-1114
   Li ZF, 2016, ACM T INTEL SYST TEC, V7, P0, DOI 10.1145/2807705
   Libovicky J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P196, DOI 10.18653/v1/P17-2031
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP1425, DOI 10.1145/3240508.3240667
   McFee B, 2018, CF HAWTHORNE CJ CARR, V0, P0
   Metze F, 2018, P WORKSHOP VISUALLY, V0, P0
   Miao Yishu, 2016, P 2016 C EMPIRICAL M, V0, P319
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Mun J, 2017, AAAI CONF ARTIF INTE, V0, P4233
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Nallapati R, 2017, AAAI CONF ARTIF INTE, V0, P3075
   Narayan S, 2018, P 2018 C N AM CHAPT, V1, P1747, DOI 10.18653/V1/N18-1158
   Palaskar S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6587
   Park S, 2014, PROC EUR S-STATE DEV, V0, PP50, DOI 10.1109/ESSDERC.2014.6948755
   Pramanick Shraman, 2021, P INT AAAI C WEB SOC, V15, P513
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rush AM, 2015, P EMNLP 15, V0, P0
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shah RR, 2016, KNOWL-BASED SYST, V108, P102, DOI 10.1016/j.knosys.2016.05.022
   Shen X, 2020, KNOWL-BASED SYST, V0, P0
   Shi XX, 2020, NEUROCOMPUTING, V417, P347, DOI 10.1016/j.neucom.2020.08.035
   Song Kaiqiang, 2018, P 27 INT C COMPUTATI, V0, P1717
   Tepperman J, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1838
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, PP6558, DOI 10.18653/v1/p19-1656
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Zadeh A, 2020, ELSEVIER INF FUSION, V0, P0
   Zeng KH, 2016, LECT NOTES COMPUT SC, V9906, P609, DOI 10.1007/978-3-319-46475-6_38
   Zhou LW, 2018, AAAI CONF ARTIF INTE, V0, P7590
   Zhou QY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P654
   Zhu JN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4154
NR 61
TC 5
Z9 5
U1 6
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD SEP 5
PY 2021
VL 227
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107152
EA JUN 2021
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA TS0WT
UT WOS:000679379000015
DA 2023-11-10
ER

PT J
AU Liu, MT
   Zhang, YJ
   Xu, JN
   Chen, YF
AF Liu, Mingtong
   Zhang, Yujie
   Xu, Jinan
   Chen, Yufeng
TI Deep bi-directional interaction network for sentence matching
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Sentence matching; Deep interaction network; Deep fusion; Attention mechanism; Multi-layer neural network; Interpretability study
AB The goal of sentence matching is to determine the semantic relation between two sentences, which is the basis of many downstream tasks in natural language processing, such as question answering and information retrieval. Recent studies using attention mechanism to align the elements of two sentences have shown promising results in capturing semantic similarity/relevance. Most existing methods mainly focus on the design of multi-layer attention network, however, some critical issues have not been dealt with well: 1) the higher attention layer is easily affected by error propagation because it relies on the alignment results of preceding attentions; 2) models have the risk of losing low-layer semantic features with the increase of network depth; and 3) the approach of capturing global matching information brings about large computing complexity for model training. To this end, we propose a Deep Bi-Directional Interaction Network (DBDIN) to solve these issues, which captures semantic relatedness from two directions and each direction employs multiple attention-based interaction units. To be specific, the attention of each interaction unit will repeatedly focus on the original sentence representation of another one for semantic alignment, which alleviates the error propagation problem by attending to a fixed semantic representation. Then we design deep fusion to aggregate and propagate attention information from low layers to high layers, which effectively retains low-layer semantic features for subsequential interactions. Moreover, we introduce a self-attention mechanism at last to enhance global matching information with smaller model complexity. We conduct experiments on natural language inference and paraphrase identification tasks with three benchmark datasets SNLI, SciTail and Quora. Experimental results demonstrate that our proposed method can achieve significant improvements over baseline systems without using any external knowledge. Additionally, we conduct interpretable study to disclose how our deep interaction network with attention can benefit sentence matching, which provides a reference for future model design. Ablation studies and visualization analyses further verify that our model can better capture interactive information between two sentences, and the proposed components are indeed able to help modeling semantic relation more precisely.
C1 [Liu, Mingtong; Zhang, Yujie; Xu, Jinan; Chen, Yufeng] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Sch Comp & Informat Technol, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Zhang, YJ (通讯作者)，Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM 16112075@bjtu.edu.cn; yjzhang@bjtu.edu.cn; jaxu@bjtu.edu.cn; chenyf@bjtu.edu.cn
FU National Nature Science Foundation of China [61876198, 61976015, 61370130, 61976016]; BeijingMunicipal Natural Science Foundation [4172047]; International Science and Technology Cooperation Program of China [K11F100010]
CR Androutsopoulos I, 2010, J ARTIF INTELL RES, V38, P135, DOI 10.1613/jair.2985
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bjerva Johannes, 2016, P COLING 2016 26 INT, V0, P3531
   Bowman SR, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1466
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), V0, PP551, DOI 10.1109/CIS.2016.133
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Chen Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2406
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Chomsky N, 1957, SOME CONCEPTS CONSEQ, V0, P0
   Clark P, 2016, AAAI CONF ARTIF INTE, V0, P2580
   Ding YZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1150, DOI 10.18653/v1/P17-1106
   Dowty D, 2007, DIRECT COMPOSITIONAL, V0, P23
   Dozat Timothy, 2016, ARXIV161101734, V0, P0
   Duan CQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4033
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Esposito M, 2020, INFORM SCIENCES, V514, P88, DOI 10.1016/j.ins.2019.12.002
   Fan HQ, 2018, PROC CVPR IEEE, V0, PP1072, DOI 10.1109/CVPR.2018.00118
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Ghaeini R, 2018, P C N AM ASS CHAPT A, VI, P1460, DOI 10.18653/V1/N18-1132
   Glorot Xavier, 2011, P 14 INT C ART INT S, V0, PP315, DOI 10.1002/ECS2.1832
   Gong Yichen, 2017, 6 INT C LEARNING REP, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   He K, 2016, LECT NOTES COMPUT SC, V0, PP70, DOI 10.1007/978-3-319-46493-0_38
   Heilman M, 2010, PROC NAACL HLT, V0, P1011
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Hui SC, 2017, ARXIV1800100102, V0, P0
   Iftene A, 2007, P ACL PASCAL WORKSH, V0, P125
   Im J, 2017, ARXIV171202047, V0, P0
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Karpathy A, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Khot T, 2018, AAAI CONF ARTIF INTE, V0, P5189
   Kim S, 2019, AAAI CONF ARTIF INTE, V0, P6586
   Kingma DP, 2014, C TRACK P, V0, P0
   Li Jiwei, 2015, ARXIV150601066, V0, P0, DOI DOI 10.18653/V1/N16-1082
   Lin Z, 2017, P ICLR, V0, P0
   Liu PF, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1034
   Liu Q, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1821, DOI 10.1145/3219819.3219960
   Madnani N, 2012, P 2012 C N AM CHAPT, V0, P182
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mou LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P130
   OShea K, 2012, APPL INTELL, V37, P558, DOI 10.1007/s10489-012-0349-9
   Pan BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P989
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paria Biswajit, 2016, ARXIV161104741, V0, P0
   Parikh A, 2016, PROC C EMPIR METHODS, V0, PP2249, DOI 10.18653/v1/D16-1244
   Park C, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3365679
   Peng DL, 2019, IEEE ACCESS, V7, P61320, DOI 10.1109/ACCESS.2019.2915937
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pota M, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10144710
   Rocktaschel Tim, 2015, ARXIV150906664, V0, P0
   Sha Lei, 2016, P COLING, V0, P2870
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava RK, 2015, CORR, V1505, P387
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tan M, 2015, ARXIV151104108, V0, P0
   Wang S, 2016, 2016 C N AM ASS COMP, V0, P1442
   Wang S, 2016, ARXIV161101747, V0, P0
   Wang YL, 2020, KNOWL-BASED SYST, V190, P0, DOI 10.1016/j.knosys.2019.105030
   Wang Z, 2017, IEEE IJCNN, V0, PP1411, DOI 10.1109/IJCNN.2017.7966018
   Wang Zhiguo, 2016, ARXIV160207019, V0, P0
   Wang Zhiguo, 2015, ARXIV150702628, V0, P0
   Xiao L, 2004, APPL INTELL, V21, P195, DOI 10.1023/B:APIN.0000033637.51909.04
   Yang RQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4699
   Yin WP, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P540
   Yin Wenpeng, 2016, T ASSOC COMPUT LING, V0, PP259, DOI 10.1162/TACL_A_00097
   Zhang Z, 2019, P 33 PAC AS C LANG I, V0, P0
   Zhou X, 2019, ARXIV190902209, V0, P0
NR 69
TC 6
Z9 6
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JUL 15
PY 2021
VL 51
IS 7
BP 4305
EP 4329
DI 10.1007/s10489-020-02156-7
EA JAN 2021
PG 25
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SU8MT
UT WOS:000604215300006
DA 2023-11-10
ER

PT J
AU Park, HH
   Zhang, KJ
   Haley, C
   Steimel, K
   Liu, H
   Schwartz, L
AF Park, Hyunji Hayley
   Zhang, Katherine J.
   Haley, Coleman
   Steimel, Kenneth
   Liu, Han
   Schwartz, Lane
TI Morphology Matters: A Multilingual Language Modeling Analysis
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID token ratio
AB Prior studies in multilingual language modeling (e.g., Cotterell et al., 2018; Mielke et al., 2019) disagree on whether or not inflectional morphology makes languages harder to model. We attempt to resolve the disagreement and extend those studies. We compile a larger corpus of 145 Bible translations in 92 languages and a larger number of typological features.(1) We fill in missing typological data for several languages and consider corpus-based measures of morphological complexity in addition to expert-produced typological features. We find that several morphological measures are significantly associated with higher surprisal when LSTM models are trained with BPE-segmented data. We also investigate linguistically motivated subword segmentation strategies like Morfessor and Finite-State Transducers (FSTs) and find that these segmentation strategies yield better performance and reduce the impact of a language's morphology on language modeling.
C1 [Park, Hyunji Hayley; Schwartz, Lane] Univ Illinois, Chicago, IL 60680 USA.
   [Zhang, Katherine J.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Haley, Coleman] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Steimel, Kenneth] Indiana Univ, Bloomington, IN 47405 USA.
   [Liu, Han] Univ Chicago, Chicago, IL 60637 USA.
   [Liu, Han] Univ Colorado, Boulder, CO 80309 USA.
C3 University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; Carnegie Mellon University; Johns Hopkins University; Indiana University System; Indiana University Bloomington; University of Chicago; University of Colorado System; University of Colorado Boulder
RP Park, HH (通讯作者)，Univ Illinois, Chicago, IL 60680 USA.
EM hpark129@illinois.edu; kjzhang@cmu.edu; chaley7@jhu.edu; ksteimel@iu.edu; hanliu@uchicago.edu; lanes@illinois.edu
FU National Science Foundation's Major Research Instrumentation program [1725729]; University of Illinois at Urbana-Champaign
CR [Anonymous], 2013, PERFECTIVE IMPERFECT, V0, P0
   Arppe Antti, 2014, FINITE STATE TRANSDU, V0, P0
   Axelson Eric, 2015, HELSINKI FINITE STAT, V0, P0
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bentz C, 2016, P WORKSH COMP LING L, V0, P142
   Bostrom Kaj, 2020, FINDINGS ASS COMPUTA, V0, P0
   Cagri Coltekin, 2014, P 9 INT C LANG RES E, V0, P0
   Cagri Coltekin, 2010, P 7 INT C LANG RES E, V0, P0
   Christodouloupoulos C, 2015, LANG RESOUR EVAL, V49, P375, DOI 10.1007/S10579-014-9287-Y
   Cotterell Ryan, 2018, P 2018 C N AM CHAPT, V2, P536
   Covington MA, 2010, J QUANT LINGUIST, V17, P94, DOI 10.1080/09296171003643098
   Creutz M, 2007, ACM T SPEECH LANGUAG, V4, P1, DOI 10.1145/1322391.1322394
   Dehouck M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2864
   Devlin J, 2018, ARXIV, V1, P4171
   Gerz D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P316
   Kann, 2018, ARXIV180700286, V0, P0
   Kettunen K, 2014, J QUANT LINGUIST, V21, P223, DOI 10.1080/09296174.2014.911506
   Kirov C, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1868
   Klavans JL, 2018, P WORKSHOP COMPUTATI, V0, P1
   Koehn P, 2005, P AAMT 10 MACH TRANS, V0, PP79, DOI 10.3115/1626355.1626380
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Larasati SD, 2011, COMM COM INF SC, V100, P119
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Mayer T, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3158
   Merity Stephen, 2018, CSCL180308240V1 CORR, V0, P0
   Mieke, 2016, ACL STANDS ANN M ASS, V0, P0
   Mielke Sabrina J, 2019, P AAAI C ART INT, V33, P0, DOI 10.1609/aaai.v33i01.33016843
   Mielke SJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4975
   Pirinen TA, 2015, P 20 NORD C COMP LIN, V0, P313
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Sagot Benoit, 2013, COMPUTATIONAL APPROA, V0, P0
   Schmittou HR, 2004, P IEEE INT C PERV CO, V0, P1
   Schwartz Lane, 2020, CSCL200505477V2 CORR, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shibata Y, 1999, BYTE PAIR ENCODING T, V0, P0
   Tomczak M, 2014, TRENDS SPORT SCI, V1, P19, DOI 10.1186/S13054-016-1208-6
   Tyers FM, 2020, P 4 WORKSH UN DEP U, V0, P195
   Vania C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2016, DOI 10.18653/v1/P17-1184
   Vilca Hugo David Calderon, 2012, ANALIZADOR MORF OLOG, V0, P0
   Virpioja S, 2013, MORFESSOR 2 0 PYTHON, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
NR 41
TC 6
Z9 6
U1 3
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 261
EP 276
DI 10.1162/tacl_a_00365
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200016
DA 2023-11-10
ER

PT J
AU Zhao, KF
   Su, J
   Yu, JX
   Zhang, H
AF Zhao, Kangfei
   Su, Jiao
   Yu, Jeffrey Xu
   Zhang, Hao
TI SQL-G: Efficient Graph Analytics by SQL
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Structured Query Language; Sparks; Algebra; Engines; Programming; Distributed databases; Data processing; Graph analytics; distributed graph processing; SQL recursive query; spark
ID computation; socialite
AB Querying graphs and conducting graph analytics become important in data processing since many real applications are dealing with massive graphs, such as online social networks, Semantic Web, knowledge graphs, etc. Over the years, many distributed graph processing systems have been developed to support graph analytics using various programming models, and many graph querying languages have been proposed. A natural question that arises is how to integrate graph data and traditional non-graph data in a distributed system for users to conduct analytics. There are two issues. One issue is related to expressiveness on how to specify graph analytics as well as data analytics by a querying language. The other issue is related to efficiency on how to process analytics in a distributed system. For the first issue, SQL is a best candidate, since SQL is a well-accepted language for data processing. We concentrate on SQL for graph analytics. Our early work shows that graph analytics can be supported by SQL in a way from "semiring + while" to "relational algebra + while" via the enhanced recursive SQL queries. In this article, we focus on the second issue on how to process such enhanced recursive SQL queries based on the GAS (Gather-Apply-Scatter) model under which efficient graph processing systems can be developed. To demonstrate the efficiency, we implemented a system by tightly coupling Spark SQL and GraphX on Spark which is one of the most popular in-memory data-flow processing platforms. First, we enhance Spark SQL by adding the capability of supporting the enhanced recursive SQL queries for graph analytics. In this regard, graph analytics can be processed using a distributed SQL engine alone. Second, we further propose new transformation rules to optimize/translate the operations for recursive SQL queries to the operations by GraphX. In this regard, graph analytics by SQL can be processed in a similar way as done by a distributed graph processing system using the APIs provided by the system. We conduct extensive performance studies to test graph analytics using large real graphs. We show that our approach can achieve similar or even higher efficiency, in comparison to the built-in graph algorithms in the existing graph processing systems.
C1 [Zhao, Kangfei; Su, Jiao; Yu, Jeffrey Xu; Zhang, Hao] Chinese Univ Hong Kong, Sha Tin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Yu, JX (通讯作者)，Chinese Univ Hong Kong, Sha Tin, Hong Kong, Peoples R China.
EM kfzhao@se.cuhk.edu.hk; jiaosu@se.cuhk.edu.hk; yu@se.cuhk.edu.hk; hzhang@se.cuhk.edu.hk
FU Research Grants Council of the Hong Kong SAR, China [14203618, 14202919]
CR Aberger CR, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP431, DOI 10.1145/2882903.2915213
   Aggarwal CC, 2010, ADV DATABASE SYST, V40, P1, DOI 10.1007/978-1-4419-6045-0
   Aggarwal CC, 2011, SOCIAL NETWORK DATA ANALYTICS, V0, P1
   [Anonymous], 2015, FOUND TRENDS DATABAS, V7, P2, DOI 10.1561/1900000056
   [Anonymous], 2011, KDD, V0, P0
   [Anonymous], 2017, SYSTEMS BIG GRAPH AN, V0, P0
   [Anonymous], 2006, DIMACS CHALLENGE 9 S, V0, P0
   Armbrust M, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1383, DOI 10.1145/2723372.2742797
   Arni F, 2003, THEOR PRACT LOG PROG, V3, P61, DOI 10.1017/S1471068402001515
   Baeza PB, 2013, P 32 ACM SIGMOD SIGA, V0, PP175, DOI 10.1145/2463664.2465216
   Boldi Paolo, 2004, P 13 INT C WORLD WID, V0, PP595, DOI 10.1145/988672.988752
   Brandes Ulrik, 2005, NETWORK ANAL METHODO, V0, P0
   Cormen TH, 2009, INTRO ALGORITHMS, V0, P0
   Yan D, 2014, PROC VLDB ENDOW, V7, P1981, DOI 10.14778/2733085.2733103
   Das T, 2012, P 9 USENIX C NETWORK, V0, PP2, DOI 10.1111/J.1095-8649.2005.00662.X
   Dave A, 2016, FOURTH INTERNATIONAL WORKSHOP ON GRAPH DATA MANAGEMENT EXPERIENCES AND SYSTEMS (GRADES2016), V0, P0, DOI DOI 10.1145/2960414.2960416
   DeCarlo LT, 1997, PSYCHOL METHODS, V2, P292, DOI 10.1037/1082-989X.2.3.292
   Fan Jing, 2015, CIDR, V0, P0
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Friedman E, 2009, PROC VLDB ENDOW, V2, P1402, DOI 10.14778/1687553.1687567
   Gao J, 2011, PROC VLDB ENDOW, V5, P358, DOI 10.14778/2095686.2095694
   Gonzalez Joseph E, 2012, 10 USENIX S OP SYST, V0, PP17, DOI 10.1145/74850.74870
   Gonzalez Joseph E, 2014, P 11 USENIX S OPERAT, V0, P599
   He H, 2008, P 2008 ACM SIGMOD IN, V0, PP405, DOI 10.1145/1376616.1376660
   Jindal A, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, V0, PP1191, DOI 10.1109/BigData.2015.7363873
   Jindal A, 2014, IEEE INT CONF BIG DA, V0, PP441, DOI 10.1109/BigData.2014.7004261
   Kang U, 2011, KNOWL INF SYST, V27, P303, DOI 10.1007/s10115-010-0305-0
   Kepner J, 2011, SOFTW ENVIRON TOOLS, V22, P1, DOI 10.1137/1.9780898719918
   Kwak HG, 2010, INT CONF ADV COMMUN, V0, P591
   Leskovec J, 2021, SNAP DATASETS STANFO, V0, P0
   Lin CB, 2016, PROC VLDB ENDOW, V10, P265
   Ma HB, 2016, PROC VLDB ENDOW, V9, P900
   McCune RR, 2015, ACM COMPUT SURV, V48, P0, DOI 10.1145/2818185
   McSherry Frank, 2015, P 15 USENIX C HOT TO, V0, P0
   Moffitt VZ, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16 COMPANION), V0, PP843, DOI 10.1145/2872518.2889290
   Passing L, 2017, EDBT, V0, P84
   Perry M, 2011, SEMAT WEB BEYOND-COM, V12, P61, DOI 10.1007/978-1-4419-9446-2_3
   Raghavan UN, 2007, PHYS REV E, V76, P0, DOI 10.1103/PhysRevE.76.036106
   RAMAKRISHNAN R, 1995, J LOGIC PROGRAM, V23, P125, DOI 10.1016/0743-1066(94)00039-9
   Rastogi V, 2013, PROC INT CONF DATA, V0, PP50, DOI 10.1109/ICDE.2013.6544813
   Salimi S, 2014, P WORKSH GRAPH DAT M, V0, P1
   Schutze H, 2008, INTRO INFORM RETRIEV, V39, P0
   Seo J, 2013, PROC VLDB ENDOW, V6, P1906, DOI 10.14778/2556549.2556572
   Seo J, 2013, PROC INT CONF DATA, V0, PP278, DOI 10.1109/ICDE.2013.6544832
   Shkapsky A, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1135, DOI 10.1145/2882903.2915229
   Shkapsky A, 2013, PROC VLDB ENDOW, V6, P1258, DOI 10.14778/2536274.2536290
   Shkapsky A, 2015, PROC INT CONF DATA, V0, PP867, DOI 10.1109/ICDE.2015.7113340
   Simmen D, 2014, PROC VLDB ENDOW, V7, P1405, DOI 10.14778/2733004.2733013
   Srihari S, 2010, LECT NOTES ARTIF INT, V6119, P160
   Tian Y, 2013, PROC VLDB ENDOW, V7, P193, DOI 10.14778/2732232.2732238
   van Rest O, 2016, FOURTH INTERNATIONAL WORKSHOP ON GRAPH DATA MANAGEMENT EXPERIENCES AND SYSTEMS (GRADES2016), V0, P0, DOI DOI 10.1145/2960414.2960421
   Verma S, 2017, PROC VLDB ENDOW, V10, P493, DOI 10.14778/3055540.3055543
   Wood PT, 2012, SIGMOD REC, V41, P50, DOI 10.1145/2206869.2206879
   Yu PS, 2010, LINK MINING: MODELS, V0, P0
   Zaniolo C, 1993, DEDUCTIVE AND OBJECT-ORIENTED DATABASES. THIRD INTERNATIONAL CONFERENCE, V0, P204
   Zaniolo C, 1997, ADV DATABASE SYSTEMS, V0, P0
   Zhang Y, 2013, P 2013 ACM SIGMOD IN, V0, PP1049, DOI 10.1145/2463676.2463684
   Zhang Y, 2011, PROCEEDINGS OF THE 15TH INTERNATIONAL DATABASE ENGINEERING & APPLICATIONS SYMPOSIUM (IDEAS 11), V0, P124
   Zhao KF, 2017, SIGMOD17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1165, DOI 10.1145/3035918.3035943
   Zhou Y, 2015, PROC VLDB ENDOW, V8, P1262, DOI 10.14778/2809974.2809987
   Zhu Xiaowei, 2015, USENIX ANN TECHN C, V0, P375
NR 61
TC 0
Z9 0
U1 1
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD MAY 1
PY 2021
VL 33
IS 5
BP 2237
EP 2251
DI 10.1109/TKDE.2019.2950620
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA RJ3XT
UT WOS:000637532700032
DA 2023-11-10
ER

PT J
AU Fan, SQ
   Zhang, BB
   Zhou, SL
   Wang, MH
   Li, K
AF Fan, Siqi
   Zhang, Binbin
   Zhou, Silin
   Wang, Menghan
   Li, Ke
TI Few-Shot Relation Extraction Towards Special Interests
SO BIG DATA RESEARCH
LA English
DT Article
DE Relation extraction; Few-shot; Special interests; Dependency parsing
AB With the continuous development of natural language processing, Relation extraction (RE) has been intensively studied and well performed in extracting relations from unstructured texts in both English and modern Chinese. In this paper, we study to extract relations from a special type of text, that is, Chinese textual description of Han Dynasty Stone Reliefs (HanDSR). We aim to develop an efficient relation extractor for special interests with a small number of samples. The problem is challenging due to the large number of rare words in the texts and the mixed-use of modern and ancient Chinese in the same sentence without a domain corpus. To address these problems, we propose a relation extraction method based on dependency parsing and utilize the information of HanDSR on the basic parser. To exploit the representation of dependency trees, we design five dependency semantic path patterns(DSPPs) to extract relation triples of special interests. Besides, we build the HanDSR Treebank that includes 4190 sentences, 28124 dependency trees, following the annotation format of the Penn Chinese Treebank 8.0, which addresses the lack of domain-specific corpus and could be used in extract relations from such texts. Extensive experiments on HanDSR dataset demonstrate the accuracy and efficiency of our solution. The experimental results illustrate that our proposal significantly outperforms the rule-based relation extraction model in both effectiveness and efficiency. (C) 2021 Elsevier Inc. All rights reserved.
C1 [Fan, Siqi; Zhou, Silin; Wang, Menghan; Li, Ke] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Zhang, Binbin] Shanghai Int Studies Univ, Shanghai, Peoples R China.
C3 University of Electronic Science & Technology of China; Shanghai International Studies University
RP Zhang, BB (通讯作者)，Shanghai Int Studies Univ, Shanghai, Peoples R China.
EM sqfann@gmail.com; zhangbinbin@gmail.com; zhousilinXY@gmail.com; shakurasss@foxmail.com; like_like@std.uestc.edu.cn
CR Agichtein E, 2000, ACM 2000. DIGITAL LIBRARIES. PROCEEDINGS OF THE FIFTH ACM CONFERENCE ON DIGITAL LIBRARIES, V0, PP85, DOI 10.1145/336597.336644
   [Anonymous], 2011, P 49 ANN M ASS COMPU, V0, P0
   [Anonymous], 2015, P 29 PAC AS C LANG I, V0, P0
   Batista David S, 2015, P 2015 C EMPIRICAL M, V0, P499
   Brin S, 1999, LECT NOTES COMPUT SC, V1590, P172
   Brown PF, 1992, COMPUTATIONAL LINGUISTICS, V18, P467
   Califf Mary Elaine, 1997, CONLL97 COMPUTATIONA, V0, P0
   Califf ME, 2004, J MACH LEARN RES, V4, P177, DOI 10.1162/153244304322972685
   Can DC, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2902
   Che W, 2020, ARXIV200911616, V2009, P11616
   Che Wanxiang, 2005, COMP VOL P C INCL DE, V0, P0
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, P0, DOI 10.1155/2014/575246
   Daojian Zeng, 2014, P COLING 25 INT C CO, V0, P2335
   Goldberg Y, 2012, P COLING 2012, V0, P959
   Han X, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P745
   Han X, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P169
   He Han, 2020, HANLP HAN LANGUAGE P, V0, P0
   Hearst MA, 1992, AUTOMATIC ACQUISITIO, V0, P0, DOI DOI 10.3115/992133.992154
   Huffman SB, 1995, P CONN STAT SYMB APP, V0, PP246, DOI 10.1007/3-540-60925-351
   Jia SB, 2018, ACM T ASIAN LOW-RESO, V17, P0, DOI 10.1145/3162077
   Naiwen Xue, 2005, NATURAL LANGUAGE ENGINEERING, V11, P207, DOI 10.1017/S135132490400364X
   Nanda Kambhatla, 2004, P 42 ANN M ASS COMP, V0, P0
   Nivre J, 2003, P 8 INT C PARS TECHN, V0, P149
   Nivre J, 2008, COMPUT LINGUIST, V34, P513, DOI 10.1162/coli.07-056-R1-07-027
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P101
   ROBINSON JJ, 1970, LANGUAGE, V46, P259, DOI 10.2307/412278
   Roth D, 2002, COLING 2002, V0, P0
   Schmitz M, 2012, P 2012 JOINT C EMPIR, V0, P523
   Shao JTJNYan, 2017, P 8 INT JOINT C NAT, V1, P173
   Yates A, 2007, P HUM LANG TECHN ANN, V0, PP25, DOI 10.3115/1614164.1614177
NR 30
TC 1
Z9 1
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-5796
EI 
J9 BIG DATA RES
JI Big Data Res.
PD NOV 15
PY 2021
VL 26
IS 
BP 
EP 
DI 10.1016/j.bdr.2021.100273
EA SEP 2021
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA WD4NB
UT WOS:000704918400002
DA 2023-11-10
ER

PT J
AU Cossu, A
   Carta, A
   Lomonaco, V
   Bacciu, D
AF Cossu, Andrea
   Carta, Antonio
   Lomonaco, Vincenzo
   Bacciu, Davide
TI Continual learning for recurrent neural networks: An empirical evaluation
SO NEURAL NETWORKS
LA English
DT Article
DE Continual learning; Recurrent neural networks; Benchmarks; Evaluation
ID framework
AB Learning continuously during all model lifetime is fundamental to deploy machine learning solutions robust to drifts in the data distribution. Advances in Continual Learning (CL) with recurrent neural networks could pave the way to a large number of applications where incoming data is non stationary, like natural language processing and robotics. However, the existing body of work on the topic is still fragmented, with approaches which are application-specific and whose assessment is based on heterogeneous learning protocols and datasets. In this paper, we organize the literature on CL for sequential data processing by providing a categorization of the contributions and a review of the benchmarks. We propose two new benchmarks for CL with sequential data based on existing datasets, whose characteristics resemble real-world applications. We also provide a broad empirical evaluation of CL and Recurrent Neural Networks in classincremental scenario, by testing their ability to mitigate forgetting with a number of different strategies which are not specific to sequential data processing. Our results highlight the key role played by the sequence length and the importance of a clear specification of the CL scenario. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Cossu, Andrea; Carta, Antonio; Lomonaco, Vincenzo; Bacciu, Davide] Univ Pisa, Largo B Pontecorvo 3, I-56127 Pisa, Italy.
   [Cossu, Andrea] Scuola Normale Super Pisa, Piazza Cavalieri 7, I-56126 Pisa, Italy.
C3 University of Pisa; Scuola Normale Superiore di Pisa
RP Cossu, A (通讯作者)，Scuola Normale Super Pisa, Piazza Cavalieri 7, I-56126 Pisa, Italy.
EM andrea.cossu@sns.it; antonio.carta@di.unipi.it; vincenzo.lomonaco@unipi.it; bacciu@di.unipi.it
FU European Community [871385]
CR Ahmad S, 2016, DO NEURONS OPERATE S, V0, P0
   Ahn Hongjoon, 2019, ADV NEUR IN, V0, P4392
   Aljundi R, 2019, ICLR, V0, P0
   Aljundi R, 2019, PROC CVPR IEEE, V0, PP11246, DOI 10.1109/CVPR.2019.01151
   Aljundi R, 2018, LECT NOTES COMPUT SC, V11207, P144, DOI 10.1007/978-3-030-01219-9_9
   Aljundi Rahaf, 2019, ADV NEURAL INFORM PR, V0, PP11849, DOI 10.1109/CVPR.2019.01151
   Amato G, 2016, ADV INTELL SYST, V476, P1, DOI 10.1007/978-3-319-40114-0_1
   [Anonymous], 2015, COMPUT SCI, V0, P0, DOI DOI 10.4140/TCP.N.2015.249
   [Anonymous], 1997, P 19 ANN COGN SCI SO, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2014, EMPIRICAL EVALUATION, V0, P0
   Ans B, 2004, CONNECT SCI, V16, P71, DOI 10.1080/09540090412331271199
   ANS B, 2002, P 24 ANN C COGN SCI, V0, P0
   Asghar Nabiha, 2019, ICLR, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Beaulieu S, 2020, FRONT ARTIF INTEL AP, V325, P992, DOI 10.3233/FAIA200193
   Biesialska M, 2020, P 28 INT C COMPUTATI, V0, PP6523, DOI 10.18653/V1/2020.COLING-MAIN.574
   Bojar O, 2017, P 2 C MACH TRANSL, V2, P169, DOI 10.18653/V1/W17-4717
   Buchner J, 2017, SYNTHETIC SPEECH COM, V0, P0
   Caccia M, 2020, ADV NEURAL INFORM PR, V33, P16532
   Carta Antonio, 2021, P ACM S NEUR GAZ DET, V0, P0
   Ceni A, 2020, COGN COMPUT, V12, P330, DOI 10.1007/s12559-019-09634-2
   Chaudhry A, 2018, LECT NOTES COMPUT SC, V11215, P556, DOI 10.1007/978-3-030-01252-6_33
   Chaudhry Arslan, 2019, 7 INT C LEARNING REP, V0, P0
   Chen DC, 2019, APPL SOFT COMPUT, V85, P0, DOI 10.1016/j.asoc.2019.105880
   Chen Tianqi, 2016, P ICLR, V0, P0
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Coop R, 2013, IEEE IJCNN, V0, P0
   Coop R, 2012, MIDWEST SYMP CIRCUIT, V0, PP726, DOI 10.1109/MWSCAS.2012.6292123
   Cossu A, 2020, IEEE IJCNN, V0, P0, DOI DOI 10.1109/ijcnn48605.2020.9207550
   Cui YW, 2016, NEURAL COMPUT, V28, P2474, DOI 10.1162/NECO_a_00893
   de Jong Edwin D, 2016, ARXIV161103068CS, V0, P0
   De Lange Matthias, 2019, ARXIV PREPRINT ARXIV, V2, P0
   Ditzler G, 2015, IEEE COMPUT INTELL M, V10, P12, DOI 10.1109/MCI.2015.2471196
   Duncker Lea, 2020, NEURIPS, V33, P0
   Ebrahimi Sayna, 2020, P INT C LEARN REPR, V0, P7
   Ehret Benjamin, 2020, ARXIV200612109CSSTAT, V0, P0
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Farquhar S, 2018, NEURIPS BAYES DEEP L, V0, P0
   Farquhar Sebastian, 2019, PRIV MACH LEARN ART, V0, P0
   Finn C, 2019, P MACHINE LEARNING R, V0, P1920
   French RM, 1997, CONNECTION SCIENCE, V9, P353, DOI 10.1080/095400997116595
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   FRENCH RM, 1991, PROGRAM OF THE THIRTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, V0, P173
   Gama J, 2014, ACM COMPUT SURV, V46, P0, DOI 10.1145/2523813
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, V0, PP776, DOI 10.1109/ICASSP.2017.7952261
   Giles C Lee, 2019, CONTINUAL LEARNING R, V0, P0
   Golkar Siavash, 2019, ARXIV190304476, V0, P0
   Graves A, 2014, ARXIV14105401, V0, P0, DOI DOI 10.3389/NEUR0.12.006.2007
   Graves Alex, 2012, ARXIV12113711, V0, P0
   Graves Alex, 2006, P 23 INT C MACH LEAR, V0, P369
   GROSSBERG S, 1980, PSYCHOL REV, V87, P1, DOI 10.1037/0033-295X.87.1.1
   Ha David, 2018, INT C LEARN REPR, V0, P0
   Harries MB, 1998, MACH LEARN, V32, P101, DOI 10.1023/A:1007420529897
   Harrison J, 2019, CONTINUOUS METALEARN, V0, P0
   Hasan M, 2015, IEEE T MULTIMEDIA, V17, P1909, DOI 10.1109/TMM.2015.2477242
   Hayes TL, 2018, ARXIV180905922, V0, P0
   He Xu, 2019, ARXIV190605201, V0, P0
   Hospedales T, 2020, ARXIV, V0, P0
   Hung Ching-Yi, 2019, ADV NEURAL INFORM PR, V0, P13669
   Javed Khurram, 2019, NEURIPS, V0, P0
   Junczys-Dowmunt Marcin, 2016, P WORKSHOP CHALLENGE, V0, P0
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kobayashi T, 2019, LECT NOTES COMPUT SC, V11731, P35, DOI 10.1007/978-3-030-30493-5_4
   Kruszewski German, 2020, EVALUATING ONLINE CO, V0, P0
   Kurle R, 2020, ICLR, V0, P0
   Kusupati Aditya, 2019, ARXIV190102358CSSTAT, V0, P0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lesort T, 2020, REGULARIZATION SHORT, V0, P0
   Lesort T, 2020, INFORM FUSION, V58, P52, DOI 10.1016/j.inffus.2019.12.004
   Li HongLin, 2019, CONTINUAL LEARNING B, V0, P0
   Li Yuanpeng, 2020, ICLR, V0, P0
   Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37
   Lison P, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1742
   Lomonaco V, 2021, IEEE COMPUT SOC CONF, V0, PP3595, DOI 10.1109/CVPRW53098.2021.00399
   Lomonaco Vincenzo, 2017, ARXIV170503550, V0, P17
   Lopez-Paz D, 2017, ADV NEUR IN, V30, P0
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   Madasu Avinash, 2020, ARXIV200701189, V0, P0
   Maltoni D, 2019, NEURAL NETWORKS, V116, P56, DOI 10.1016/j.neunet.2019.03.010
   McClelland JL, 2020, PHILOS T R SOC B, V375, P0, DOI 10.1098/rstb.2019.0637
   McCloskey M, 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI 10.1016/S0079-7421(08)60536-8
   Mehta Nikhil, 2020, ARXIV, V0, P1
   Nguyen Cuong V, 2018, INT C LEARN REPR ICL, V0, P0
   Nguyen Hung, 2019, ECML, V0, P0
   Ororbia Alexander, 2019, ARXIV, V0, P1
   Ororbia Alexander, 2020, SPIKING NEURAL PREDI, V0, P0
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Parisi German I, 2018, FRONT NEUROROBOTICS, V12, P0, DOI 10.3389/FNBOT.2018.00078
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Philps Daniel, 2019, ARXIV191104489, V0, P0
   Ring MB, 1997, MACH LEARN, V28, P77, DOI 10.1023/A:1007331723572
   Robins A, 1995, CONNECTION SCIENCE, V7, P123, DOI 10.1080/09540099550039318
   Rolnick D, 2019, P 33 INT C NEURAL IN, V0, P0
   Rusu AA, 2016, ARXIV, V0, P0
   Schäfer AM, 2006, LECT NOTES COMPUT SC, V4131, P632
   Schak M, 2019, LECT NOTES COMPUT SC, V11728, P714, DOI 10.1007/978-3-030-30484-3_56
   Schlimmer JC, 1986, MACHINE LEARNING, V1, P317, DOI 10.1007/BF00116895
   Schwarz J, 2018, PR MACH LEARN RES, V80, P0
   Sodhani S, 2020, NEURAL COMPUT, V32, P1, DOI 10.1162/neco_a_01246
   Sokar Ghada, 2020, SPACENET MAKE FREE S, V0, P0
   Sun F-Y, 2020, ICLR, V0, P0
   Tang Binh, 2020, ICLR, V0, P0
   Thompson B, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2062
   Toneva Mariya, 2019, INT C LEARN REPR ICL, V0, P0
   van de Ven GM, 2018, GENERATIVE REPLAY FE, V0, P0
   van de Ven GM, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17866-2
   van de Ven Gido M, 2018, CONT LEARN WORKSH NE, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Von Oswald Johannes, 2019, ARXIV190600695, V0, P0
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wang ZP, 2019, IEEE WORK APPL SIG, V0, PP308, DOI 10.1109/WASPAA.2019.8937236
   Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Wolf T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P1
   Xue Jiabin, 2019, MULTITASK LEARNING F, V0, P0
   Yoon Jaehong, 2018, INT C LEARN REPR, V0, P0
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zenke F, 2017, PR MACH LEARN RES, V70, P0
   Zeno C, 2018, ARXIV180310123, V0, P0
NR 122
TC 31
Z9 33
U1 5
U2 28
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD NOV 15
PY 2021
VL 143
IS 
BP 607
EP 627
DI 10.1016/j.neunet.2021.07.021
EA JUL 2021
PG 21
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA WC6WR
UT WOS:000704396800018
PM 34343775
DA 2023-11-10
ER

PT J
AU Li, JD
   Cotterell, R
   Sachan, M
AF Li, Jiaoda
   Cotterell, Ryan
   Sachan, Mrinmaya
TI Differentiable Subset Pruning of Transformer Heads
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Multi-head attention, a collection of several attention mechanisms that independently attend to different parts of the input, is the key ingredient in the Transformer. Recent work has shown, however, that a large proportion of the heads in a Transformer's multi-head attention mechanism can be safely pruned away without significantly harming the performance of the model; such pruning leads to models that are noticeably smaller and faster in practice. Our work introduces a new head pruning technique that we term differentiable subset pruning. Intuitively, our method learns perhead importance variables and then enforces a user-specified hard constraint on the number of unpruned heads. The importance variables are learned via stochastic gradient descent. We conduct experiments on natural language inference and machine translation; we show that differentiable subset pruning performs comparably or better than previous works while offering precise control of the sparsity level.(1)
C1 [Li, Jiaoda; Cotterell, Ryan; Sachan, Mrinmaya] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Cotterell, Ryan] Univ Cambridge, Cambridge, England.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Cambridge
RP Li, JD (通讯作者)，Swiss Fed Inst Technol, Zurich, Switzerland.
EM jiaoda.li@inf.ethz.ch; ryan.cotterell@inf.ethz.ch; mrinmaya.sachan@inf.ethz.ch
FU SNF [201009]
CR Agyeman KA, 2016, 2016 INTERNATIONAL CONFERENCE ON PROBABILISTIC METHODS APPLIED TO POWER SYSTEMS (PMAPS), V0, P0
   [Anonymous], 1990, ADV NEURAL INFORM PR, V0, P0
   Bahdanau Dzmitry, 2015, 3 INT C LEARN REPR I, V0, P0
   Behnke M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2664
   Bengio Yoshua, 2013, ABS13083432V1 CORR, V0, P0
   Brix C, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3909
   Brown T, 2020, ADV NEURAL INFORM PR, V33, P1877
   Budhraja A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3230
   Cettolo Mauro, 2014, P INT WORKSH SPOK LA, V0, P0
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, PP276, DOI 10.18653/v1/w19-4828
   Cotterell R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1182, DOI 10.18653/v1/P17-1109
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   Fan Angela, 2020, INT C LEARN REPR, V0, P0
   Franco J, 2021, PHYSIOTHER THEOR PR, V37, P1419, DOI 10.1080/09593985.2019.1709234
   Gal Y, 2016, PR MACH LEARN RES, V48, P0
   Gillenwater J, 2012, P JOINT C EMP METH N, V0, P710
   Goldberg Yoav, 2019, ABS190105287 ARXIV, V0, P0
   Gomez Aidan N, 2019, ABS190513678V5 CORR, V0, P0
   Gordon MA, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P143
   Gumbel, 1954, STAT THEORY EXTREME, V33, P0
   Guo YW, 2016, ADV NEUR IN, V29, P0
   Han S, 2015, ADV NEUR IN, V28, P0
   Han S, 2016, CONF PROC INT SYMP C, V0, PP243, DOI 10.1109/ISCA.2016.30
   Hassibi Babak, 1994, ADV NEURAL INFORM PR, V6, P0
   He YH, 2017, IEEE I CONF COMP VIS, V0, PP1398, DOI 10.1109/ICCV.2017.155
   Huang Z, 2018, LECT NOTES COMPUT SC, V11220, P351, DOI 10.1007/978-3-030-01270-0_21
   Jang Eric, 2017, INT C LEARN REPR, V0, P0
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Kingma DP, 2015, ADV NEUR IN, V28, P0
   Koehn P, 2007, P 45 ANN M ASS COMP, V0, P0
   Kool W, 2019, PR MACH LEARN RES, V97, P0
   Li H, 2017, PRUNING FILTERS EFFI, V0, P0
   Liu Z, 2017, IEEE I CONF COMP VIS, V0, PP2755, DOI 10.1109/ICCV.2017.298
   Louizos, 2018, 6 INT C LEARN REPR, Vvol 12, P0
   Luo JH, 2017, IEEE I CONF COMP VIS, V0, PP5068, DOI 10.1109/ICCV.2017.541
   Maddison CJ, 2017, INT C LEARNING REPRE, V0, P0
   Maddison CJ, 2014, ADV NEUR IN, V27, P0
   McCarley JS, 2021, ABS191006360V3 CORR, V0, P0
   Michel P, 2019, ADV NEUR IN, V32, P0
   Molchanov D, 2017, PR MACH LEARN RES, V70, P0
   Molchanov P, 2017, 5 INT C LEARN REPR, V0, P0
   Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P314
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Plötz T, 2018, ADV NEUR IN, V31, P0
   Prasanna S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3208
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Sajjad Hassan, 2021, ABS200403844V2 CORR, V0, P0
   Sanh V, 2020, ADV NEURAL INFORM PR, V33, P20378
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Theis Lucas, 2018, ABS180105787V2 CORR, V0, P0
   Tucker G, 2017, ADV NEURAL INFORM PR, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vieira, 2021, DISTRIBUTION SMALLES, V0, P0
   Vieira Tim, 2021, DISTRIBUTION FUNCTIO, V0, P0
   Vieira Tim, 2014, GUMBEL MAX TRICK WEI, V0, P0
   VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5797
   Wen W, 2016, ADV NEUR IN, V29, P0
   Williams A, 2018, P C N AM CHAPT ASS C, V1, P1112, DOI 10.18653/V1/N18-1101
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xie Sang Michael, 2019, INT JOINT C ART INT, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   YELLOTT JI, 1977, J MATH PSYCHOL, V15, P109, DOI 10.1016/0022-2496(77)90026-8
   Zhou JR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2396
   Zhu Michael, 2017, ARXIV171001878, V0, P0
NR 66
TC 2
Z9 2
U1 4
U2 11
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 15
PY 2021
VL 9
IS 
BP 1442
EP 1459
DI 10.1162/tacl_a_00436
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200086
DA 2023-11-10
ER

PT J
AU Smit, P
   Virpioja, S
   Kurimo, M
AF Smit, Peter
   Virpioja, Sami
   Kurimo, Mikko
TI Advances in subword-based HMM-DNN speech recognition across languages
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Large vocabulary speech recognition; Subword units; Character units; Recurrent neural network language models
ID neural-networks; models; dropout
AB We describe a novel way to implement subword language models in speech recognition systems based on weighted finite state transducers, hidden Markov models, and deep neural networks. The acoustic models are built on graphemes in a way that no pronunciation dictionaries are needed, and they can be used together with any type of subword language model, including character models. The advantages of short subword units are good lexical coverage, reduced data sparsity, and avoiding vocabulary mismatches in adaptation. Moreover, constructing neural network language models (NNLMs) is more practical, because the input and output layers are small. We also propose methods for combining the benefits of different types of language model units by reconstructing and combining the recognition lattices. We present an extensive evaluation of various subword units on speech datasets of four languages: Finnish, Swedish, Arabic, and English. The results show that the benefits of short subwords are even more consistent with NNLMs than with traditional n-gram language models. Combination across different acoustic models and language models with various units improve the results further. For all the four datasets we obtain the best results published so far. Our approach performs well even for English, where the phoneme-based acoustic models and word-based language models typically dominate: The phoneme-based baseline performance can be reached and improved by 4% using graphemes only when several grapheme-based models are combined. Furthermore, combining both grapheme and phoneme models yields the state-of-the-art error rate of 15.9% for the MGB 2018 dev17b test. For all four languages we also show that the language models perform reasonably well when only limited training data is available. (C) 2020 The Authors. Published by Elsevier Ltd.
C1 [Smit, Peter; Virpioja, Sami; Kurimo, Mikko] Aalto Univ, Dept Signal Proc & Acoust, Espoo, Finland.
   [Virpioja, Sami] Univ Helsinki, Dept Digital Humanities, Helsinki, Finland.
   [Smit, Peter] Inscripta, Helsinki, Finland.
   [Virpioja, Sami] Utopia Analyt, Helsinki, Finland.
C3 Aalto University; University of Helsinki
RP Smit, P (通讯作者)，Aalto Univ, Dept Signal Proc & Acoust, Espoo, Finland.; Smit, P (通讯作者)，Inscripta, Helsinki, Finland.
EM peter.smit@inscripta.io
FU Svenska folkskolans vanner r.f. via the DigiTala project; Business Finland's Challenge Finland project TELLme; Kone foundation; EU's Horizon 2020 research and innovation programme via the project MeMAD [GA 780069]; project FoTran [GA 771113]
CR Ali A, 2014, IWSLT 2014 INT WORKS, V0, P0
   Ali A, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP316, DOI 10.1109/ASRU.2017.8268952
   Ali A, 2016, IEEE W SP LANG TECH, V0, PP279, DOI 10.1109/SLT.2016.7846277
   [Anonymous], 2015, ARXIV150807909, V0, P0
   [Anonymous], 2011, P 18 NORD C COMP LIN, V0, P0
   Arisoy E, 2009, IEEE T AUDIO SPEECH, V17, P874, DOI 10.1109/TASL.2008.2012313
   Bisani M, 2005, P INTERSPEECH, V0, P725
   Botros R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1443
   Chan W, 2016, INT CONF ACOUST SPEE, V0, PP4960, DOI 10.1109/ICASSP.2016.7472621
   Cheng GF, 2017, INTERSPEECH, V0, PP1586, DOI 10.21437/Interspeech.2017-129
   Choueiter G, 2006, INT CONF ACOUST SPEE, V0, P1053
   Creutz M, 2002, P ACL 2002 WORKSH MO, V0, PP21, DOI 10.3115/1118647.1118650
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V4, P3:1, DOI 10.1145/1217098.1217101
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V5, P1, DOI 10.1145/1322391.1322394
   CSC-IT Center for Science, 1998, HELS KORP VERS FINN, V0, P0
   Enarvi S, 2016, INTERSPEECH, V0, PP3052, DOI 10.21437/Interspeech.2016-618
   Enarvi S, 2017, IEEE-ACM T AUDIO SPE, V25, P2085, DOI 10.1109/TASLP.2017.2743344
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI 10.5555/177910.177914
   Goel V, 2000, COMPUT SPEECH LANG, V14, P115, DOI 10.1006/csla.2000.0138
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Hirsimäki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   Hirsimäki T, 2009, IEEE T AUDIO SPEECH, V17, P724, DOI 10.1109/TASL.2008.2012323
   ISKRA DJ, 2002, LREC, V0, P0
   Kirchhoff K, 2006, COMPUT SPEECH LANG, V20, P589, DOI 10.1016/j.csl.2005.10.001
   Kneser R, 1993, CONTRIBUTIONS QUANTI, V0, PP221, DOI /10.1007/978-94-011-1769-2_15
   KUO HKJ, 2012, INTERSPEECH 2012 13, V0, P1670
   Kurimo M, 2017, LANG RESOUR EVAL, V51, P961, DOI 10.1007/s10579-016-9336-9
   Manohar V, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP346, DOI 10.1109/ASRU.2017.8268956
   Mansikkaniemi A, 2017, INTERSPEECH, V0, PP3762, DOI 10.21437/Interspeech.2017-1115
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mirjam K, 2003, INTERSPEECH 2003 EUR, V0, P0
   Mohri M, 2008, SPRINGER HDB SPEECH, V0, P0, DOI DOI 10.1007/978-3-540-49127-9_28
   Morin F, 2005, AISTATS, V5, P246
   Mousa AE, 2013, INT CONF ACOUST SPEE, V0, PP8435, DOI 10.1109/ICASSP.2013.6639311
   Peddinti V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3214
   Povey D, 2011, ASRU 2011 IEEE WORKS, V0, P0
   Povey D, 2016, INTERSPEECH, V0, PP2751, DOI 10.21437/Interspeech.2016-595
   Prabhavalkar R, 2017, INTERSPEECH, V0, PP939, DOI 10.21437/Interspeech.2017-233
   Rao K, 2017, INT CONF ACOUST SPEE, V0, PP4815, DOI 10.1109/ICASSP.2017.7953071
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Rosti A, 1998, SPEECHDAT FINNISH DA, V0, P0
   Sainath TN, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5859, DOI 10.1109/ICASSP.2018.8462380
   Siivola V, 2007, IEEE T AUDIO SPEECH, V15, P1617, DOI 10.1109/TASL.2007.896666
   Smit P, 2016, 2 INT WORKSH COMP LI, V0, P12
   Smit P, 2017, ASRU, V0, P0
   Smit P, 2017, INTERSPEECH, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava Rupesh Kumar, 2015, NIPS, V0, P2377
   Tarjan B, 2014, P 4 INT WORKSH SPOK, V0, P131
   Varjokallio M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP7, DOI 10.1109/ASRU.2013.6707697
   Virpioja S, 2013, MORFESSOR 2 0 PYTHON, V0, P0
   Wang Y, 2018, ICASSP 2018 IEEE INT, V0, P0
   WONG JHM, 2017, ASRU, V0, PP84, DOI 10.1109/ASRU.2017.8268920
   Xu HH, 2010, INT CONF ACOUST SPEE, V0, PP4938, DOI 10.1109/ICASSP.2010.5495100
NR 55
TC 17
Z9 17
U1 0
U2 11
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR 15
PY 2021
VL 66
IS 
BP 
EP 
DI 10.1016/j.csl.2020.101158
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA PB5PE
UT WOS:000596372000009
DA 2023-11-10
ER

PT J
AU Fan, A
   Bhosale, S
   Schwenk, H
   Ma, ZY
   El-Kishky, A
   Goyal, S
   Baines, M
   Celebi, O
   Wenzek, G
   Chaudhary, V
   Goyal, N
   Birch, T
   Liptchinsky, V
   Edunov, S
   Grave, E
   Auli, M
   Joulin, A
AF Fan, Angela
   Bhosale, Shruti
   Schwenk, Holger
   Ma, Zhiyi
   El-Kishky, Ahmed
   Goyal, Siddharth
   Baines, Mandeep
   Celebi, Onur
   Wenzek, Guillaume
   Chaudhary, Vishrav
   Goyal, Naman
   Birch, Tom
   Liptchinsky, Vitaliy
   Edunov, Sergey
   Grave, Edouard
   Auli, Michael
   Joulin, Armand
TI Beyond English-Centric Multilingual Machine Translation
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE many-to-many; multilingual machine translation; model scaling; bitext mining; neural networks
ID matrices
AB Existing work in translation demonstrated the potential of massively multilingual machine translation by training a single model able to translate between any pair of languages. However, much of this work is English-Centric, training only on data which was translated from or to English. While this is supported by large sources of training data, it does not reflect translation needs worldwide. In this work, we create a true Many-to-Many multilingual translation model that can translate directly between any pair of 100 languages. We build and open-source a training data set that covers thousands of language directions with parallel data, created through large-scale mining. Then, we explore how to effectively increase model capacity through a combination of dense scaling and language-specific sparse parameters to create high quality models. Our focus on non-English-Centric models brings gains of more than 10 BLEU when directly translating between non-English directions while performing competitively to the best single systems from the Workshop on Machine Translation (WMT). We open-source our scripts so that others may reproduce the data, evaluation, and final M2M-100 model: https://github.com/pytorch/fairseq/tree/master/examples/m2m_100.
C1 [Fan, Angela; Bhosale, Shruti; Schwenk, Holger; Ma, Zhiyi; El-Kishky, Ahmed; Goyal, Siddharth; Baines, Mandeep; Celebi, Onur; Wenzek, Guillaume; Chaudhary, Vishrav; Goyal, Naman; Birch, Tom; Liptchinsky, Vitaliy; Edunov, Sergey; Grave, Edouard; Auli, Michael; Joulin, Armand] LORIA, Facebook AI, Paris, France.
C3 Universite de Lorraine
RP Fan, A (通讯作者)，LORIA, Facebook AI, Paris, France.
EM ANGELAFAN@FB.COM
CR Aarne Talman, 2019, P 4 C MACH TRANSL SH, V2, P0
   Agic E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3204
   Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   Ahia Orevaoghene, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Ahmed El-Kishky, 2020, P EMNLP, V0, P0
   Alla Lo, 2020, ARXIV PREPRINT ARXIV, V0, P0
   [Anonymous], 2020, OPENREVIEW, V0, P0
   [Anonymous], 2009, EACL, V0, P0
   [Anonymous], 2010, P C N AM CHAPTER ASS, V0, P0
   [Anonymous], 2016, SHARED TASK PAPERS, V0, P0
   Arivazhagan N, 2019, ARXIV190705019, V0, P0
   Arora S, 2018, PR MACH LEARN RES, V80, P0
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Artetxe M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3197
   Ba Jimmy Lei, 2016, ARXIV160706450, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1538
   Barrault L, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P1
   Bojar, 2018, P 3 C MACH TRANSL SH, V2, P272, DOI 10.18653/V1/W18-6401
   Bojar O, 2011, P 6 WORKSHOP STAT MA, V0, P330
   Bojar rej, 2017, P 2 C MACHINE TRANSL, V0, P169
   Bouamor H, 2018, P 11 WORKSH BUILD US, V0, P43
   Caswell I, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P53
   Celikkanat Hande, 2020, PRAGUE B MATH LINGUI, V0, PP143, DOI 10.14712/00326585.009
   Cettolo Mauro, 2017, P 14 INT C SPOKEN LA, V0, P2
   Chaudhary V, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, P0
   Chen PZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1672
   Chen Tianqi, 2016, ARXIV160406174, V0, P0
   Chormai Pattarawat, 2016, PYTHAINLP THAI NATUR, V0, P0
   Christodouloupoulos C, 2015, LANG RESOUR EVAL, V49, P375, DOI 10.1007/s10579-014-9287-y
   Conneau Alexis, 2019, ARXIV191102116, V0, P0
   Costa-jussa Marta R, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Dabre R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1410
   Ding CC, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3325885
   Ding Chenchen, 2016, P 3 WORKSHOP ASIAN T, V0, P149
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P489
   Emezue Chris Chinenye, 2020, P THE 4 WIDENING NAT, V0, PP83, DOI 10.18653/V1/2020.WINLP-1.21
   Escolano C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P236
   Escolano Carlos, 2020, ARXIV200601594, V0, P0
   Escolano Carlos, 1900, P2020, V0, P0
   Espl`a Miquel, 2019, P MACHINE TRANSLATIO, V0, P118
   Etchegoyhen T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2009
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Fan A, 2019, INT C LEARN REPR, V0, P0
   Firat O, 2016, P 2016 C N AM CHAPT, V0, P866
   Garmash E, 2016, COLING, V0, P1409
   Gehring J, 2017, ARXIV170503122, V3, P2029, DOI 10.18653/V1/P16-1220
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu JT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1258
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI 10.18653/v1/n18
   Guzman F, 2019, 2 NEW EVALUATION DAT, V0, P0
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6098
   Ha Thanh-Le, 2016, P 13 INT WORKSH SPOK, V0, P0
   He K, 2016, PROC CVPR IEEE, V0, P0
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Huang YP, 2019, ADV NEUR IN, V32, P0
   Jiale Chen, 2019, P 2019 C EMP METH NA, V0, P962
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Jorg Tiedemann, 2018, CEUR WORKSHOP PROC, V2084, P188
   Kaplan Jared, 2020, ARXIV200108361, V0, P0
   Kasai Jungo, 2020, DEEP ENCODER SHALLOW, V0, P0
   Khandelwal Urvashi, 2020, ARXIV201000710, V0, P0
   Kim CD, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Kim Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P866
   Kingma DP, 2014, C TRACK P, V0, P0
   Koehn P, 2005, MT SUMMIT, V0, P79
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Koehn P, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, P0
   Koehn Philipp, 2018, P 3 C MACH TRANSL SH, V0, PP726, DOI 10.18653/V1/W18-6453
   Koehn Philipp, 1900, P726, V0, P0
   Koehn Philipp, 2009, STAT MACHINE TRANSLA, V0, P0
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Kunchukuttan A, 2020, INDICNLP LIB, V0, P0
   Kvapilíková I, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, V0, P255
   Lakew Surafel M, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Lepikhin Dmitry, 2020, GSHARD SCALING GIANT, V0, P0
   Lewis Jason Edward, 2020, INDIGENOUS PROTOCOL, V0, P0
   Li B, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P257
   Li Xian, 2020, ADV NEURAL INFORM PR, V33, P0
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P923
   Littell Patrick, 2017, P 2017 C EMP METH NA, V0, PP2529, DOI 10.18653/V1/D17-1268
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Lu Y, 2018, P 3 C MACH TRANSL RE, V0, PP84, DOI 10.18653/V1/W18-6309
   Melese Michael, 2018, P 1 WORKSH LING RES, V0, P83
   Mousavi S, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Nekoto Wilhelmina, 2020, FIND ASS COMP LING E, V0, PP2144, DOI 10.18653/V1/2020.FINDINGS-EMNLP.195
   Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P314
   Nguyen TQ, 2019, ARXIV191005895, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pereira Guilherme C, 2017, ARXIV170106548, V0, P0
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P46
   Pinnis Marcis, 2017, TILDES MACHINE TRANS, V0, P0
   Pinnis Marcis, 2019, TILDES MACHINE TRANS, V0, P0
   Pinnis Marcis, 2018, TILDES MACHINE TRANS, V0, P0
   Post Matt, 2018, P 3 C MACH TRANSL RE, V0, PP186, DOI 10.18653/v1/W18-6319
   Prates MOR, 2020, NEURAL COMPUT APPL, V32, P6363, DOI 10.1007/s00521-019-04144-6
   Qi Ye, 2018, ARXIV180406323, V0, P0, DOI DOI 10.18653/
   Rajbhandari S, 2019, ZERO MEMORY OPTIMIZA, V0, P0
   Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2685
   Riza Hammam, 2016, 2016 CONFERENCE OF THE ORIENTAL CHAPTER OF INTERNATIONAL COMMITTEE FOR COORDINATION AND STANDARDIZATION OF SPEECH DATABASES AND ASSESSMENT TECHNIQUES (O-COCOSDA), V0, PP1, DOI 10.1109/ICSDA.2016.7918974
   Schwenk, 2008, P INT WORKSH SPOK LA, V0, P182
   Schwenk Holger, 2021, P 59 ANN M ASS COMPU, V0, PP6490, DOI 10.18653/V1/2021.ACL-LONG.507
   Sellam Thibault, 2020, P 58 ANN M ASS COMPU, V0, PP7881, DOI 10.18653/V1/2020.ACL-MAIN.704
   Sennrich R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P211
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sennrich Rico, 2016, P 1 C MACHINE TRANSL, V2, P371, DOI 10.18653/V1/W16-2323
   Shazeer N, 2018, ADV NEUR IN, V31, P0
   Shen Jiajun, 2019, P 6 WORKSHOP ASIAN T, V0, P112
   Shoeybi M, 2019, ARXIV, V0, P0
   Siddhant A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2827
   Siminyu K, 2020, AI4D AFRICAN LANGUAG, V0, P0
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   SINKHORN R, 1967, PAC J MATH, V21, P343, DOI 10.2140/pjm.1967.21.343
   Strassel S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3273
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tang Yuqing, 2020, ARXIV200800401, V0, P0
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Tufis Dan, 2013, RANLP, V0, P702
   Uchechukwu Chinedu, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Utiyama M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P72
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vieira LN, 2021, INFORM COMMUN SOC, V24, P1515, DOI 10.1080/1369118X.2020.1776370
   Hoang VCD, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, V0, P18
   Wang Xinyi, 2020, P 58 ANN M ASS COMP, V0, P8526
   Wang YN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2955
   Wenzek G, 2019, ARXIV191100359, V0, P0
   Williams Philip, 2017, U EDINBURGHS NEURAL, V0, P0
   Yonghui Wu, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Zhang B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1628
   Ziemski M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3530
NR 135
TC 58
Z9 59
U1 2
U2 7
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
EI 
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD JUN 15
PY 2021
VL 22
IS 
BP 
EP 
DI 
PG 48
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA SU5FA
UT WOS:000663162000001
DA 2023-11-10
ER

PT J
AU Zhou, ZG
   Ma, YM
   Zhang, Y
   Liu, YA
   Liu, YH
   Zhang, L
   Deng, SC
AF Zhou, Zhiguang
   Ma, Yuming
   Zhang, Yong
   Liu, Yanan
   Liu, Yuhua
   Zhang, Lin
   Deng, Shengchun
TI Context-Aware Visual Abstraction of Crowded Parallel Coordinates
SO NEUROCOMPUTING
LA English
DT Article
DE Crowded parallel coordinates; Large data visualization; Doc2Vec; Sampling
AB As the size of dataset increases, it has become a difficult task to explore structures of interest from crowded parallel coordinates due to visual clutter. Numerous methods have been proposed to simplify the visualization of crowded parallel coordinates, such as filtering, bundling and sampling. However, contextual structures are hardly preserved in the course of simplification, which make significant features easily lost in the simplified parallel coordinates. In this paper, we propose a context-aware visual sampling method for the exploration of crowded parallel coordinates. A Doc2Vec model, widely used in the field of Natural Language Processing (NLP), is utilized to represent the contextual structures across a series of attribute axes with quantifiable vectors. Then, an adaptive blue noise sampling model is employed to reduce the size of original dataset in the vectorized space, guarantying that data items with different contextual structures would be retained in the simplified parallel coordinates. A set of meaningful visual interfaces are designed, enabling users to easily capture the contextual features and evaluate the sampled parallel coordinates. Case studies based on real-world datasets and quantitative comparison have demonstrated the effectiveness of our method in the simplification of crowded parallel coordinates and the exploration of large scale multi-dimensional datasets. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhou, Zhiguang; Ma, Yuming; Zhang, Yong; Liu, Yanan; Zhang, Lin; Deng, Shengchun] Zhejiang Univ Finance & Econ, Informat Sch, Hangzhou, CO, Peoples R China.
   [Zhou, Zhiguang; Liu, Yuhua] Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou, CO, Peoples R China.
   [Zhou, Zhiguang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, CO, Peoples R China.
C3 Zhejiang University of Finance & Economics; Hangzhou Dianzi University; Zhejiang University
RP Liu, YH (通讯作者)，Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou, CO, Peoples R China.
EM liuyh216@163.com
FU National Natural Science Foundation of China [61872314, 61802339]; National Key Research and Development Program of China [2019YFB1406300]; Statistical Research Project of Zhejiang Province [20TJZZ10]; Public Welfare Technology Applied Research Project of Zhejiang Province [GF20G010005, GF20F020065, LGF20F020010]; Open Project Program of the State Key Lab of CADCG of Zhejiang University [A2001]
CR [Anonymous], 2007, BIOL TRANSLATIONAL C, V0, P0
   [Anonymous], 2009, VMV 2009 P VIS MOD V, V0, P0
   Artero AO, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, V0, P81, DOI 10.1109/INFVIS.2004.68
   Barthélemy M, 2004, EUR PHYS J B, V38, P163, DOI 10.1140/epjb/e2004-00111-4
   Bielza Concha, 2004, BAYESIAN INFORM CRIT, V0, P0, DOI DOI 10.1002/9780471650126.dob0814
   Bottou L, 2012, NEURAL NETWORKS TRIC, V0, P421
   Ebeida Mohamed, 2014, ACM T GRAPHIC, V37, P2014, DOI 10.1145/3194657
   Ellis G, 2005, CHI 05 EXTENDED ABST, V0, PP1351, DOI 10.1145/1056808.1056914
   Ellis G, 2006, IEEE T VIS COMPUT GR, V12, P717, DOI 10.1109/TVCG.2006.138
   Emiliano PC, 2014, COMPUT STAT DATA AN, V69, P141, DOI 10.1016/j.csda.2013.07.032
   Fanea E, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, V0, P149, DOI 10.1109/INFVIS.2005.1532141
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Govea Blanca Vargas, 2011, EFFECTS RELEVANT CON, V791, P0
   Gregorio Palmas, 2016, IEEE VGTC C VIS, V16, P0, DOI 10.2312/eurovisshort.20161162
   Grover A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP855, DOI 10.1145/2939672.2939754
   Guo D, 2003, INFORMATION VISUALIZATION, V2, P232, DOI 10.1057/palgrave.ivs.9500053
   Heck D, 2013, ACM T GRAPHIC, V32, P0, DOI 10.1145/2487228.2487233
   Heinrich Julian, 2011, 1 EVALUATION BUNDLIN, V0, P0
   Nguyen H, 2018, IEEE T VIS COMPUT GR, V24, P1301, DOI 10.1109/TVCG.2017.2661309
   Holten D, 2010, COMPUT GRAPH FORUM, V29, P793, DOI 10.1111/j.1467-8659.2009.01666.x
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu Z, 2018, J INFORM HIDING MULT, V9, P1337
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Johansson J, 2006, INFORMATION VISUALIZATION, V5, P125, DOI 10.1057/palgrave.ivs.9500117
   Johansson J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, V0, P125, DOI 10.1109/INFVIS.2005.1532138
   Johansson J, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, V0, P188, DOI 10.1109/IV.2005.1
   Kandogan Eser, 2001, P IEEE INF VIS S, V0, P0
   Le Q, 2014, INT C MACHINE LEARNI, V32, P0, DOI 10.1145/2740908.2742760
   Lee H, 2018, ELECTRON COMMER RES, V18, P433, DOI 10.1007/s10660-017-9268-5
   Lee Sangheon, 2016, SENTIMENT CLASSIFICA, V0, PP1, DOI 10.1145/ 2971603.2971631
   Leskovec Jure Jure, 2006, SAMPLING LARGE GRAPH, V0, P0, DOI DOI 10.1145/1150402.1150479
   Lind M, 2009, INFORMATION VISUALIZATION, V0, PROCEEDINGS
   McDonnell KT, 2008, COMPUT GRAPH FORUM, V27, P1031, DOI 10.1111/j.1467-8659.2008.01239.x
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Palmas G, 2014, IEEE PAC VIS SYMP, V0, PP57, DOI 10.1109/PacificVis.2014.40
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Qin HX, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3119910
   Qu H, 2007, IEEE T VIS COMPUT GR, V13, P1408, DOI 10.1109/TVCG.2007.70523
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ribeiro LFR, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP385, DOI 10.1145/3097983.3098061
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Viau C, 2010, IEEE T VIS COMPUT GR, V16, P1100, DOI 10.1109/TVCG.2010.205
   Walker Rick, 2013, 2013 17TH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, V0, PP36, DOI 10.1109/IV.2013.101
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wang Y, 2009, PATTERN RECOGN, V42, P259, DOI 10.1016/j.patcog.2008.05.010
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Watts Duncan, 2011, COLLECTIVE DYNAMICSS, V0, P0, DOI DOI 10.1515/9781400841356.301
   Xie C, 2017, IEEE T VIS COMPUT GR, V23, P51, DOI 10.1109/TVCG.2016.2598479
   Yan DM, 2013, ACM T GRAPHIC, V32, P0, DOI 10.1145/2516971.2516973
   Ying-Huey Fua, 1999, PROCEEDINGS VISUALIZATION 99 (CAT. NO.99CB37067), V0, PP43, DOI 10.1109/VISUAL.1999.809866
   Zhou H, 2008, COMPUT GRAPH FORUM, V27, P1047, DOI 10.1111/j.1467-8659.2008.01241.x
   Zhou H, 2009, COMPUT GRAPH FORUM, V28, P759, DOI 10.1111/j.1467-8659.2009.01476.x
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
   Zhou ZG, 2019, IEEE ACCESS, V7, P0, DOI 10.1109/ACCESS.2019.2935471
NR 55
TC 3
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 12
PY 2021
VL 459
IS 
BP 23
EP 34
DI 10.1016/j.neucom.2021.05.005
EA JUL 2021
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WM4OM
UT WOS:000711066300003
DA 2023-11-10
ER

