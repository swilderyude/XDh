FN Clarivate Analytics Web of Knowledge
VR 1.0
PT J
AU Varjokallio, M
   Virpioja, S
   Kurimo, M
AF Varjokallio, Matti
   Virpioja, Sami
   Kurimo, Mikko
TI Morphologically motivated word classes for very large vocabulary speech
   recognition of Finnish and Estonian
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Language modelling; Class-based language models; Morphologically rich
   languages
ID LANGUAGE MODELS; SEARCH
AB We study class-based n-gram and neural network language models for very large vocabulary speech recognition of two morphologically rich languages: Finnish and Estonian. Due to morphological processes such as derivation, inflection and compounding, the models need to be trained with vocabulary sizes of several millions of word types. Class-based language modelling is in this case a powerful approach to alleviate the data sparsity and reduce the computational load. For a very large vocabulary, bigram statistics may not be an optimal way to derive the classes. We thus study utilizing the output of a morphological analyzer to achieve efficient word classes. We show that efficient classes can be learned by refining the morphological classes to smaller equivalence classes using merging, splitting and exchange procedures with suitable constraints. This type of classification can improve the results, particularly when language model training data is not very large. We also extend the previous analyses by rescoring the hypotheses obtained from a very large vocabulary recognizer using class-based neural network language models. We show that despite the fixed vocabulary, carefully constructed classes for word-based language models can in some cases result in lower error rates than subword-based unlimited vocabulary language models. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Varjokallio, Matti; Kurimo, Mikko] Aalto Univ, Sch Elect Engn, Dept Signal Proc & Acoust, Espoo, Finland.
   [Virpioja, Sami] Univ Helsinki, Fac Arts, Dept Digital Humanities, Helsinki, Finland.
C3 Aalto University; University of Helsinki
RP Varjokallio, M (通讯作者)，Aalto Univ, Sch Elect Engn, Dept Signal Proc & Acoust, Espoo, Finland.
EM matti.varjokallio@aalto.fi; sami.virpioja@helsinki.fi;
   mikko.kurimo@aalto.fi
RI Kurimo, Mikko/F-6647-2012
OI Virpioja, Sami/0000-0002-3568-150X
FU Academy of Finland [251170]
FX This work was supported by the Academy of Finland with the grant 251170.
   Aalto Science-IT project provided computational resources for the work.
   We would like to thank the anonymous reviewers for valuable comments,
   which helped to improve the article.
CR Aalto University, 2014, AALTOASR AALT AUT SP
   Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   Arisoy E, 2009, IEEE T AUDIO SPEECH, V17, P874, DOI 10.1109/TASL.2008.2012313
   Aubert XL, 2002, COMPUT SPEECH LANG, V16, P89, DOI 10.1006/csla.2001.0185
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Botros R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1443
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Brychcin T., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P560, DOI 10.1109/IDAACS.2011.6072829
   CHEN B, 2009, P HUM LANG TECHN 200, P450
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chen SF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1037
   CORTES C, 2008, HDB SPEECH PROCESSIN, P2
   Creutz M, 2002, P ACL 2002 WORKSH MO, P21, DOI DOI 10.3115/1118647.1118650
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V5, P1, DOI DOI 10.1145/1322391.1322394
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Enarvi S, 2016, INTERSPEECH, P3052, DOI 10.21437/Interspeech.2016-618
   Enarvi S, 2017, IEEE-ACM T AUDIO SPE, V25, P2085, DOI 10.1109/TASLP.2017.2743344
   Gatherers: The Department of General Linguistics University of Helsinki; The University of Eastern Finland; CSC-IT Center for Science Ltd, 2000, KIEL CORP EL DOC COL
   Goodman J, 2001, INT CONF ACOUST SPEE, P561, DOI 10.1109/ICASSP.2001.940893
   Gutmann M., 2010, J MACH LEARN RES, V13, P307
   Hirsimäki T, 2004, HELS UNIV TECHNOL S, V46, P320
   Hirsimäki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   Hirsimäki T, 2009, IEEE T AUDIO SPEECH, V17, P724, DOI 10.1109/TASL.2008.2012323
   Iskra D., 2002, P LREC, P329
   Karlsson, 1999, FINNISH ESSENTIAL GR
   KARLSSON F, 1985, FOLIA LINGUIST, V19, P207, DOI 10.1515/flin.1985.19.1-2.207
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kneser R., 1991, P 1 INT C QUANT LING, P221
   KUHN T, 1994, INT CONF ACOUST SPEE, P357
   KURIMO M, 2006, P MAIN C HUM LANG TE, P487
   Kurimo M, 2017, LANG RESOUR EVAL, V51, P961, DOI 10.1007/s10579-016-9336-9
   Linden K., 2009, NO EUROPEAN J LANGUA, V1, P1
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P923
   Mansikkaniemi A, 2017, INTERSPEECH, P3762, DOI 10.21437/Interspeech.2017-1115
   Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9
   Meister E., 2012, PHONETICS S 2012 TAL, P30
   Nasrabadi Nasser M, 2007, J ELECT IMAG, V16
   Ney H, 2000, P IEEE, V88, P1224, DOI 10.1109/5.880081
   Niesler TR, 1998, INT CONF ACOUST SPEE, P177, DOI 10.1109/ICASSP.1998.674396
   Niesler TR, 1999, COMPUT SPEECH LANG, V13, P99, DOI 10.1006/csla.1998.0115
   Orasmaa S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2460
   Ortmanns S, 2000, COMPUT SPEECH LANG, V14, P15, DOI 10.1006/csla.1999.0131
   Pirinen T.A., 2015, P 20 NORD C COMP LIN, P313
   Pylkk_onen J., 2005, P 2 BALT C HUM LANG, P167
   Saagpakk Paul F., 1982, ESTONIAN ENGLISH DIC
   Shi Y, 2013, IEEE ANTENNAS PROP, P13, DOI 10.1109/APS.2013.6710667
   Siivola V, 2007, IEEE T AUDIO SPEECH, V15, P1617, DOI 10.1109/TASL.2007.896666
   Sixtus A, 2002, COMPUT SPEECH LANG, V16, P245, DOI 10.1006/csla.2002.192
   Smit P, 2017, INTERSPEECH, P2551, DOI 10.21437/Interspeech.2017-103
   Soltau H, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P276, DOI 10.1109/ASRU.2009.5372904
   Srivastava Rupesh Kumar, 2015, NIPS, P2377
   Stolcke A., 2011, P IEEE WORKSHOP AUTO
   TAM YC, 2008, NIPS, P1633
   Tarjan B., 2014, P 4 INT WORKSH SPOK, P131
   The Parliament of Finland, 2017, PLEN SESS PARL FINL
   UiT The Arctic University of Norway; The Divvun group at UiT The Arctic University of Norway, 2020, DIVV GROUP UIT ARCT
   Vaiciunas A, 2004, INFORMATICA-LITHUAN, V15, P565
   Vaiciunas A., 2006, STAT LANGUAGE MODELS
   Varjokallio M, 2018, IEEE W SP LANG TECH, P227, DOI 10.1109/SLT.2018.8639691
   Varjokallio M, 2016, LECT NOTES ARTIF INT, V9918, P133, DOI 10.1007/978-3-319-45925-7_11
   Varjokallio M, 2014, IEEE W SP LANG TECH, P495, DOI 10.1109/SLT.2014.7078624
   Varjokallio M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P7, DOI 10.1109/ASRU.2013.6707697
   Viitso T.-R., 1997, URALIC LANGUAGES, P115
   Whittaker E.W.D., 2000, P 6 INT C SPOK LANG, P170
   Whittaker EWD, 2003, COMPUT SPEECH LANG, V17, P87, DOI 10.1016/S0885-2308(02)00047-5
   Whittaker EWD, 2001, INT CONF ACOUST SPEE, P545, DOI 10.1109/ICASSP.2001.940889
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
NR 70
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR
PY 2021
VL 66
AR 101141
DI 10.1016/j.csl.2020.101141
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PB5PE
UT WOS:000596372000001
OA Green Accepted
DA 2023-11-10
ER

PT S
AU Alumäe, T
AF Alumäe, T
BE Sojka, P
   Kopecek, I
   Pala, K
TI Large vocabulary continuous speech recognition for Estonian using
   morphemes and classes
SO TEXT, SPEECH AND DIALOGUE, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 7th International Conference on Texts, Speech and Dialogue
CY SEP 08-11, 2004
CL Brno, CZECH REPUBLIC
SP Int Speech Commun Assoc
AB This paper describes development of a large vocabulary continuous speaker independent speech recognition system for Estonian. Estonian is an agglutinative language and the number of different word forms is very large, in addition, the word order is relatively unconstrained. To achieve a good language coverage, we use pseudo-morphemes as basic units in a statistical trigram language model. To improve language model robustness, we automatically find morpheme classes and interpolate the morpheme model with the class-based model. The language model is trained on a newspaper corpus of 15 million word forms. Clustered triphones with multiple Gaussian mixture components are used for acoustic modeling. The system with interpolated morpheme language model is found to perform significantly better than the baseline word form trigram system in all areas. The word error rate of the best system is 27.7% which is a 10.0% absolute improvement over the baseline system.
C1 Tallinn Univ Technol, Inst Cybernet, Lab Phonet & Speech Technol, EE-200108 Tallinn, Estonia.
C3 Tallinn University of Technology
RP Tallinn Univ Technol, Inst Cybernet, Lab Phonet & Speech Technol, EE-200108 Tallinn, Estonia.
RI Alumäe, Tanel/C-2602-2014
OI Alumae, Tanel/0000-0001-5083-1556
CR [Anonymous], 1993, P EUROSPEECH
   [Anonymous], 2001, JULIUS AN OPEN SOURC
   Eek A., 1999, P LP 98, V98, P529
   HENNOSTE T, 2000, C NON INT FENN TAR 2, P338
   Kwon OW, 2003, SPEECH COMMUN, V39, P287, DOI 10.1016/S0167-6393(02)00031-6
   SIIVOLA V, 2003, P EUROSPEECH 2003 GE
   SZARVAS M, 2003, P EUROSPEECH 2003 GE
   Waibel A, 2000, P IEEE, V88, P1297, DOI 10.1109/5.880085
   Young S., 2009, HTK BOOK HTK VERSION
NR 9
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-23049-1
J9 LECT NOTES COMPUT SC
PY 2004
VL 3206
BP 245
EP 252
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BAX16
UT WOS:000224026300031
DA 2023-11-10
ER

PT J
AU Tantug, AC
AF Tantug, Ahmet Cuneyd
TI DOCUMENT CATEGORIZATION WITH MODIFIED STATISTICAL LANGUAGE MODELS FOR
   AGGLUTINATIVE LANGUAGES
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS
LA English
DT Article
DE document categorization; statistical language modeling; n-gram; Turkish
ID TEXT CATEGORIZATION; SPEECH RECOGNITION; TURKISH; CLASSIFICATION;
   PROBABILITIES; HUNGARIAN
AB In this paper, we investigate the document categorization task with statistical language models. Our study mainly focuses on categorization of documents in agglutinative languages. Due to the productive morphology of agglutinative languages, the number of word forms encountered in naturally occurring text is very large. From the language modeling perspective, a large vocabulary results in serious data sparseness problems. In order to cope with this drawback, previous studies in various application areas suggest modified language models based on different morphological units. It is reported that performance improvements can be achieved with these modified language models. In our document categorization experiments, we use standard word form based language models as well as other modified language models based on root words, root words and part-of-speech information, truncated word forms and character sequences. Additionally, to find an optimum parameter set, multiple tests are carried out with different language model orders and smoothing methods. Similar to previous studies on other tasks, our experimental results on categorization of Turkish documents reveal that applying linguistic preprocessing steps for language modeling provides improvements over standard language models to some extent. However, it is also observed that similar level of performance improvements can also be acquired by simpler character level or truncated word form models which are language independent.
C1 Istanbul Tech Univ, Dept Comp Engn, Elekt Elekt Fak, TR-34469 Istanbul, Turkey.
C3 Istanbul Technical University
RP Tantug, AC (通讯作者)，Istanbul Tech Univ, Dept Comp Engn, Elekt Elekt Fak, Ayazaga Yerleskesi, TR-34469 Istanbul, Turkey.
EM tantug@itu.edu.tr
RI Tantug, Ahmet Cuneyd ACT/M-4497-2013
OI Tantug, Ahmet Cuneyd ACT/0000-0003-0524-3397
CR Amasyali M., 2004, IEEE 12 SIGN PROC CO
   Amasyali MF, 2006, LECT NOTES COMPUT SC, V3999, P221
   [Anonymous], 1997, READINGS INFORM RETR
   [Anonymous], 2001, BIT PROGR LANGUAGE M
   [Anonymous], 2003, LANGUAGE MODELING IN
   Arisoy E, 2006, SIGNAL PROCESS, V86, P2844, DOI 10.1016/j.sigpro.2005.12.002
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Can F, 2008, J AM SOC INF SCI TEC, V59, P407, DOI 10.1002/asi.20750
   Caropreso MF, 2001, TEXT DATABASES AND DOCUMENT MANAGEMENT: THEORY AND PRACTICE, P78
   Cataltepe Z, 2007, IEEE 15 SIGN PROC CO, P1
   Cavnar W. B., 1994, 3 ANN S DOC ANAL INF
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   CLEARY JG, 1984, IEEE T COMMUN, V32, P396, DOI 10.1109/TCOM.1984.1096090
   EKMEKCIOGLU FC, 1996, INFORM RES, V2
   Eryigit G., 2006, 11 C EUR CHAPT ASS C
   Eryigit G., 2008, COMPUTATIONAL LINGUI, V34
   Feng He, 2007, Advances in Information Retrieval. 29th European Conference on IR Research, ECIR 2007. Proceedings (Lecture Notes in Computer Science Vol.4425), P703
   Frank E., 2000, Proceedings DCC 2000. Data Compression Conference, DOI 10.1109/DCC.2000.838202
   Ganapathiraju M., 2002, HUM LANG TECHN C
   GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344
   Gungor T., 2003, INT 12 TURK S ART IN
   Hakkani-Tür DZ, 2002, COMPUT HUMANITIES, V36, P381, DOI 10.1023/A:1020271707826
   Halácsy P, 2007, LECT NOTES COMPUT SC, V4730, P99
   Hankamer J, 1986, W COAST C FORM LING
   Ilhan U., 2001, DEP COMP ENG
   Jeffreys H., 1948, THEORY PROBABILITY, V2nd
   JELINEK F, 1977, J ACOUST SOC AM, V62, pS63, DOI 10.1121/1.2016299
   Johnson W E., 1932, MIND, V41, P409, DOI [10.1093/mind/XLI.164.409, DOI 10.1093/MIND/XLI.164.409]
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Korenius T., 2004, C INF KNOWL MAN
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   Li YH, 1998, COMPUT J, V41, P537, DOI 10.1093/comjnl/41.8.537
   Lidstone G. J., 1920, T FACULTY ACTUARIES, V8, P182
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   Oflazer K, 1996, COMPUT LINGUIST, V22, P73
   Oflazer K., 1995, LIT LINGUISTIC COMPU, V9, P137
   Özgür L, 2004, PATTERN RECOGN LETT, V25, P1819, DOI 10.1016/j.patrec.2004.07.004
   Peng FC, 2003, LECT NOTES COMPUT SC, V2633, P335
   Peng FC, 2004, INFORM RETRIEVAL, V7, P317, DOI 10.1023/B:INRT.0000011209.19643.e2
   Ponte J.M., 1998, P 21 ANN INT ACM SIG
   Robertson S. E., 1976, J AM SOC INFORM SCI, V27
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Sever H., 2006, C INT TEXT PROC COMP
   Stolcke A., 2002, P 7 INT C SPOK LANG
   Tantug A. C., 2006, 15 TURK S ART INT NE
   Tantug AC, 2006, ADV SOFT COMP, V34, P495, DOI 10.1007/3-540-31662-0_38
   Tantug AC, 2006, LECT NOTES COMPUT SC, V4263, P230
   Tordai A, 2006, LECT NOTES COMPUT SC, V4022, P179
   Wei ZH, 2009, INT J COMPUT INT SYS, V2, P365
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
   Yuret D., 2009, JOINT C 47 ANN M ASS
   Zelaia A., 2005, ARCH CONTROL SCI, V600, P202
   Zhou SB, 2009, INT J COMPUT INT SYS, V2, P398
NR 56
TC 10
Z9 10
U1 1
U2 10
PU ATLANTIS PRESS
PI PARIS
PA 29 AVENUE LAUMIERE, PARIS, 75019, FRANCE
SN 1875-6891
EI 1875-6883
J9 INT J COMPUT INT SYS
JI Int. J. Comput. Intell. Syst.
PD OCT
PY 2010
VL 3
IS 5
BP 632
EP 645
DI 10.1080/18756891.2010.9727729
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 702XX
UT WOS:000285930300007
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Koller, O
   Forster, J
   Ney, H
AF Koller, Oscar
   Forster, Jens
   Ney, Hermann
TI Continuous sign language recognition: Towards large vocabulary
   statistical recognition systems handling multiple signers
SO COMPUTER VISION AND IMAGE UNDERSTANDING
LA English
DT Article
DE Sign language recognition; Statistical modelling; Tracking; Visual
   modelling; Signer dependency; Signer adaptation
ID PATTERNS; MODELS
AB This work presents a statistical recognition approach performing large vocabulary continuous sign language recognition across different signers. Automatic sign language recognition is currently evolving from artificial lab-generated data to 'real-life' data. To the best of our knowledge, this is the first time system design on a large data set with true focus on real-life applicability is thoroughly presented. Our contributions are in five areas, namely tracking, features, signer dependency, visual modelling and language modelling. We experimentally show the importance of tracking for sign language recognition with respect to the hands and facial landmarks. We further contribute by explicitly enumerating the impact of multimodal sign language features describing hand shape, hand position and movement, inter-hand-relation and detailed facial parameters, as well as temporal derivatives. In terms of visual modelling we evaluate non-gesture-models, length modelling and universal transition models. Signer-dependency is tackled with CMLLR adaptation and we further improve the recognition by employing class language models. We evaluate on two publicly available large vocabulary databases representing lab-data (SIGNUM database: 25 signers, 455 sign vocabulary, 19k sentences) and unconstrained 'real-life' sign language (RWTH-PHOENIX-Weather database: 9 signers, 1081 sign vocabulary, 7k sentences) and achieve up to 10.0%/16.4% and respectively up to 34.3%/53.0% word error rate for single signer/multi-signer setups. Finally, this work aims at providing a starting point to newcomers into the field. (c) 2015 Elsevier Inc. All rights reserved.
C1 [Koller, Oscar; Forster, Jens; Ney, Hermann] Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit, Aachen, Germany.
C3 RWTH Aachen University
RP Koller, O (通讯作者)，Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit, Aachen, Germany.
EM koller@cs.rwth-aachen.de; forster@cs.rwth-aachen.de;
   ney@cs.rwth-aachen.de
RI Koller, Oscar/W-8720-2019
CR [Anonymous], 2012, P 2012 IEEE COMPUTER, DOI DOI 10.1109/CVPRW.2012.6239187
   [Anonymous], 2010, 2010 IEEE COMPUTER S
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2013, P 2013 10 IEEE INT C, DOI DOI 10.1109/FG.2013.6553777
   [Anonymous], 2000, SIGN WRITING
   [Anonymous], 2008, IEEE INT C AUTOMATIC, DOI DOI 10.1109/AFGR.2008.4813439
   [Anonymous], 2014, TECHNICAL REPORT
   [Anonymous], 2010, EUROPEAN C COMPUTER
   Aran O, 2009, PATTERN RECOGN, V42, P812, DOI 10.1016/j.patcog.2008.09.010
   Bauer B., 1999, P INT WORKSH PHYS TA
   Bowden R, 2004, LECT NOTES COMPUT SC, V3021, P390
   Braffort A., 2010, LREC, P453
   Chen S. F., 1998, TR1098 HARV U COMP S
   Cooper H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P914, DOI 10.1109/ICCVW.2011.6130349
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   Cooper Helen, 2011, VISUAL ANAL HUMANS
   Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dick T, 2006, LECT NOTES COMPUT SC, V4174, P566
   Dilsizian M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1924
   Dreuw P., 2012, THESIS
   Dreuw P, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P293
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   Efthimiou E., 2012, P 5 WORKSH REPR PROC, P23
   Evangelidis GD, 2015, LECT NOTES COMPUT SC, V8925, P595, DOI 10.1007/978-3-319-16178-5_42
   Forster J., 2013, WORKSH SPEECH LANG P, P41
   Forster J., 2014, INT C LANG RES EV RE, P1
   Forster J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3785
   Forster J, 2013, LECT NOTES COMPUT SC, V7887, P89
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043
   Gass Tobias, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P456, DOI 10.1109/FG.2011.5771442
   Gass Tobias, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3304, DOI 10.1109/ICPR.2010.808
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   Han JW, 2009, PATTERN RECOGN LETT, V30, P623, DOI 10.1016/j.patrec.2008.12.010
   Hanke T., 2004, LREC, V4, P1
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jiangwen Deng, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P126
   Kadous M. W., 1996, PROC WORKSHOP INTEGR, P165
   Kelly D, 2011, IEEE T SYST MAN CY B, V41, P526, DOI 10.1109/TSMCB.2010.2065802
   Kelly D, 2009, 2009 13TH INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, P145, DOI 10.1109/IMVIP.2009.33
   Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153
   Klaser Alexander, 2008, BMVC
   Koller O, 2014, LECT NOTES COMPUT SC, V8689, P281, DOI 10.1007/978-3-319-10590-1_19
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   Liu JJ, 2014, IMAGE VISION COMPUT, V32, P671, DOI 10.1016/j.imavis.2014.02.009
   Lowe D.G., 1999, P INT C COMP VIS, P1150, DOI 10.1109/ICCV.1999.790410
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Nayak S, 2012, J MACH LEARN RES, V13, P2589
   Neidle C., 2012, P 5 WORKSH REPR PROC, P137
   NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320
   Ney H., 2010, LECT NOTES
   Ong EJ, 2014, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2014.248
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Pfister T., 2013, P BRIT MACH VIS C LE, P1
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Pitsikalis V, 2011, CVPRW, P1, DOI DOI 10.1109/CVPRW.2011.5981681
   Rutkowski P., 2013, DEAFNESS STUDIES CON
   Rybach D., 2011, P ASRU WAIK HI US DE
   Schmidt C., 2013, INT S SIGN LANG TRAN, V2
   Schmidt C, 2013, INT WORKSH SPOK LANG, P197
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Stein D., 2007, 11 C THEOR METH ISS, P214
   TAMURA S, 1988, PATTERN RECOGN, V21, P343, DOI 10.1016/0031-3203(88)90048-9
   Theodorakis S, 2009, INT CONF ACOUST SPEE, P1601, DOI 10.1109/ICASSP.2009.4959905
   Thoutenhoofd E, 2008, CONSTRUCTION EXPLOIT, P44
   Tokuda M., 1998, Assistive technology and artificial intelligence. Applications in robotics, user interfaces and natural language processing, P97, DOI 10.1007/BFb0055973
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vogler C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P116, DOI 10.1109/ICCV.1999.791206
   Von Agris U, 2008, P 2008 8 IEEE INT C, P1, DOI DOI 10.1109/AFGR.2008.4813472
   Waldron M. B., 1995, IEEE Transactions on Rehabilitation Engineering, V3, P261, DOI 10.1109/86.413199
   Wang CL, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P323
   Xiao J, 2004, PROC CVPR IEEE, P535
   Yang RD, 2010, IEEE T PATTERN ANAL, V32, P462, DOI 10.1109/TPAMI.2009.26
   Zahedi M., 2006, BRIT MACH VIS C, V3, P1019
NR 76
TC 179
Z9 185
U1 3
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1077-3142
EI 1090-235X
J9 COMPUT VIS IMAGE UND
JI Comput. Vis. Image Underst.
PD DEC
PY 2015
VL 141
BP 108
EP 125
DI 10.1016/j.cviu.2015.09.013
PG 18
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CW4SD
UT WOS:000364981500010
DA 2023-11-10
ER

PT J
AU Schwenk, H
AF Schwenk, Holger
TI Continuous space language models
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
ID MAXIMUM-ENTROPY APPROACH
AB This paper describes the use of a neural network language model for large vocabulary continuous speech recognition. The underlying idea of this approach is to attack the data sparseness problem by performing the language model probability estimation in a continuous space. Highly efficient learning algorithms are described that enable the use of training corpora of several hundred million words. It is also shown that this approach can be incorporated into a large vocabulary continuous speech recognizer using a lattice rescoring framework at a very low additional processing time. The neural network language model was thoroughly evaluated in a state-of-the-art large vocabulary continuous speech recognizer for several international benchmark tasks, in particular the NIST evaluations on broadcast news and conversational speech recognition. The new approach is compared to four-gram back-off language models trained with modified Kneser-Ney smoothing which has often been reported to be the best known smoothing method. Usually the neural network language model is interpolated with the back-off language model. In that way, consistent word error rate reductions for all considered tasks and languages were achieved, ranging from 0.4% to almost 1% absolute. (c) 2006 Elsevier Ltd. All rights reserved.
C1 CNRS, LIMSI, Spoken Language Proc Grp, F-91403 Orsay, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS)
RP Schwenk, H (通讯作者)，CNRS, LIMSI, Spoken Language Proc Grp, BP 133, F-91403 Orsay, France.
EM schwenk@limsi.fr
CR [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], EUR C SPEECH COMM TE
   [Anonymous], 2005, P HUMAN LANGUAGE TEC
   [Anonymous], P INT C AC SPEECH SI
   [Anonymous], 1989, P IEEE ICASSP
   Bellegarda J.-R., 1997, P 5 EUR C SPEECH COM, P1451
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   BENGIO Y, 2000, 1178 U MONTR DEP INF
   BENGIO Y, 2003, P AISTATS C
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Bilmes J, 1997, INT CONF ACOUST SPEE, P4153, DOI 10.1109/ICASSP.1997.604861
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Bridle J.S., 1989, NEUROCOMPUTING, P227, DOI [10.1007/978-3-642-76153-9, DOI 10.1007/978-3-642-76153-9_28]
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Brown P. F., 1990, Computational Linguistics, V16, P79
   BULYKO I, 2003, P HLT NAACL, P7
   Castro MJ, 2003, LECT NOTES COMPUT SC, V2686, P598
   CASTRO MJ, 2001, P WORKSH NAT LANG PR
   Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147
   CHEN L, 2001, P EUROSPEECH 01, P255
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chen Z., 2000, P INT C SPOK LANG PR, P493
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Emami A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P372
   Emami A, 2005, INT CONF ACOUST SPEE, P581
   Federico M, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P240, DOI 10.1109/ICSLP.1996.607087
   FEDERICO M, 1999, P EUR, P1583
   Fiscus JG, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P347, DOI 10.1109/ASRU.1997.659110
   Gauvain JL, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P212
   GAUVAIN JL, 2002, SPEECH COMMUN, V37, P98
   GAUVAIN JL, 2005, P INT LISB PORT, P1665
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   Hinton G.E, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI DOI 10.1109/69.917563
   ITO A, 1999, P EUR, P1591
   Iver R, 1999, COMPUT SPEECH LANG, V13, P267, DOI 10.1006/csla.1999.0124
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Kimball O., 2004, P 2004 RICH TRANSCR
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   KUOI HKJ, 2002, P INT C AC SPEECH SI, P325
   LAMEL L, 2006, P TC STAR WORKSH SPE, P123
   Lamel L., 2005, P EUR, P1657
   MIIKKULAINEN R, 1991, COGNITIVE SCI, V15, P343, DOI 10.1207/s15516709cog1503_2
   Morin F., 2005, P 10 INT WORKSH ART
   NGUYEN L, 2004, P 2004 RICH TRANSCR
   Paccanaro A, 2000, IEEE IJCNN, P259, DOI 10.1109/IJCNN.2000.857906
   PRASAD R, 2004, P 2004 RICH TRANSCR
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Schmidhuber J, 1996, IEEE T NEURAL NETWOR, V7, P142, DOI 10.1109/72.478398
   Schwenk H, 2004, IEEE IJCNN, P3059
   Schwenk H, 2002, INT CONF ACOUST SPEE, P765
   SCHWENK H, 2005, P EUR, P737
   SCHWENK H, 2003, P ISCA IEEE WORKSH S, P49
   SCHWENK H, 2004, P INT C SPOK LANG PR, P1215
   Schwenk H, 2006, P COLING ACL MAIN C, P723
   SCHWENK H, 2004, P 2004 RICH TRANSCR
   SCHWENK H, 2001, 200120 LIMSICNRS
   Vapnik V, 1998, NEW YORK
   Wang W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P261
   XU P, 2005, P EUR, P741
   Xu W., 2000, P INT C SPEECH LANG, P202
   2005, INTEL MATH KERNEL LI
NR 65
TC 250
Z9 267
U1 2
U2 17
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL
PY 2007
VL 21
IS 3
BP 492
EP 518
DI 10.1016/j.csl.2006.09.003
PG 27
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 152IM
UT WOS:000245355600005
DA 2023-11-10
ER

PT S
AU Tufis, D
AF Tufis, D
BE Matousek, V
   Mautner, P
   Ocelikova, J
   Sojka, P
TI Tiered tagging and combined language models classifiers
SO TEXT, SPEECH AND DIALOGUE
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Text, Speech and Diaglogue (TSD 99)
CY SEP 13-17, 1999
CL PLZEN, CZECH REPUBLIC
SP Medav GmbH, SpeechWorks, Univ Bohemia, Fac Appl Sci, Masaryk Univ
AB We address the problem of morpho-syntactic disambiguation of arbitrary texts in a highly inflectional natural language. We use a large tagset (615 tags), EAGLES and MULTEXT compliant [5]. The large tagset is internally mapped onto a reduced one (82 tags), serving statistical disambiguation, and a text disambiguated in terms of this tagset is subsequently subject to a recovery process of all the information left out from the large tagset. This two step process is called ties-ed tagging. To further improve the tagging accuracy we use a combined language models classifier, a procedure that interpolates the results of tagging the game text with several register-specific language models.
C1 Romanian Acad, RACAI, RO-74311 Bucharest, Romania.
C3 Romanian Academy of Sciences; Research Institute Artificial Intelligence
   Mihai Draganescu
RP Tufis, D (通讯作者)，Romanian Acad, RACAI, 13 13 Septembrie, RO-74311 Bucharest, Romania.
RI Tufis, Dan/AAO-4732-2020
CR BRILL E, 1998, P 36 ANN M ASS COMP, V1, P191, DOI DOI 10.1147/5135
   DIETTERICH TG, 1998, APPROXIMATE STAT TES
   ELWORTHY D., 1995, P ACL SIGDAT WORKSH
   Erjavec T., 1997, SPECIFICATIONS NOTAT
   Tufis D., 1997, RECENT ADV ROMANIAN, P35
   TUFIS D, 1998, P 1 INT C LANG RES E, P589
   TUFIS D, 1999, P COMPLEX 99 PECS HU
   VONHALTEREN H, 1998, P JOINT 17 INT C COM, P491
   [No title captured]
NR 9
TC 31
Z9 31
U1 1
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-66494-7
J9 LECT NOTES ARTIF INT
PY 1999
VL 1692
BP 28
EP 33
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BQ71V
UT WOS:000089259200005
DA 2023-11-10
ER

PT J
AU Park, HH
   Zhang, KJ
   Haley, C
   Steimel, K
   Liu, H
   Schwartz, L
AF Park, Hyunji Hayley
   Zhang, Katherine J.
   Haley, Coleman
   Steimel, Kenneth
   Liu, Han
   Schwartz, Lane
TI Morphology Matters: A Multilingual Language Modeling Analysis
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID TOKEN RATIO
AB Prior studies in multilingual language modeling (e.g., Cotterell et al., 2018; Mielke et al., 2019) disagree on whether or not inflectional morphology makes languages harder to model. We attempt to resolve the disagreement and extend those studies. We compile a larger corpus of 145 Bible translations in 92 languages and a larger number of typological features.(1) We fill in missing typological data for several languages and consider corpus-based measures of morphological complexity in addition to expert-produced typological features. We find that several morphological measures are significantly associated with higher surprisal when LSTM models are trained with BPE-segmented data. We also investigate linguistically motivated subword segmentation strategies like Morfessor and Finite-State Transducers (FSTs) and find that these segmentation strategies yield better performance and reduce the impact of a language's morphology on language modeling.
C1 [Park, Hyunji Hayley; Schwartz, Lane] Univ Illinois, Chicago, IL 60680 USA.
   [Zhang, Katherine J.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Haley, Coleman] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Steimel, Kenneth] Indiana Univ, Bloomington, IN 47405 USA.
   [Liu, Han] Univ Chicago, Chicago, IL 60637 USA.
   [Liu, Han] Univ Colorado, Boulder, CO 80309 USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital; Carnegie Mellon University;
   Johns Hopkins University; Indiana University System; Indiana University
   Bloomington; University of Chicago; University of Colorado System;
   University of Colorado Boulder
RP Park, HH (通讯作者)，Univ Illinois, Chicago, IL 60680 USA.
EM hpark129@illinois.edu; kjzhang@cmu.edu; chaley7@jhu.edu;
   ksteimel@iu.edu; hanliu@uchicago.edu; lanes@illinois.edu
OI Schwartz, Lane/0000-0003-2609-8133; Haley, Coleman/0000-0003-3089-9558;
   Liu, Han/0009-0001-0434-9141; Zhang, Katherine/0000-0003-2032-6035
FU National Science Foundation's Major Research Instrumentation program
   [1725729]; University of Illinois at Urbana-Champaign
FX This paper builds on our prior work for the 2019 Sixth Frederick Jelinek
   Memorial Summer Workshop on Speech and Language Technology (JSALT 2019)
   (Schwartz et al., 2020). We thank the organizers of the workshop and the
   members of our workshop team on Neural Polysynthetic Language Modeling
   for inspiring us to pursue this research direction. Our special thanks
   to Rebecca Knowles, Christo Kirov, Lori Levin, Chi-kiu (Jackie) Lo, and
   TACL reviewers and editors for their feedback on our manuscript. We
   thank Ata Tuncer for his assistance with Turkish segmentation. This work
   utilizes resources supported by the National Science Foundation's Major
   Research Instrumentation program, grant #1725729, as well as the
   University of Illinois at Urbana-Champaign.
CR [Anonymous], 2013, PERFECTIVE IMPERFECT
   Arppe Antti, 2014, FINITE STATE TRANSDU
   Axelson Eric, 2015, HELSINKI FINITE STAT
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bentz C., 2016, P WORKSH COMP LING L, P142
   Bostrom Kaj, 2020, FINDINGS ASS COMPUTA
   Cagri Coltekin, 2014, P 9 INT C LANG RES E
   Cagri Coltekin, 2010, P 7 INT C LANG RES E
   Christodouloupoulos C., 2015, LANG RESOUR EVAL, V49, P375, DOI DOI 10.1007/S10579-014-9287-Y
   Cotterell Ryan, 2018, P 2018 C N AM CHAPT, V2, P536
   Covington MA, 2010, J QUANT LINGUIST, V17, P94, DOI 10.1080/09296171003643098
   Creutz M., 2007, ACM T SPEECH LANGUAG, V4, P1, DOI [10.1145/1322391.1322394, DOI 10.1145/1187415.1187418]
   Dehouck M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2864
   Devlin J., 2018, ARXIV, V1, P4171
   Gerz D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P316
   Kann, 2018, ARXIV180700286
   Kettunen K, 2014, J QUANT LINGUIST, V21, P223, DOI 10.1080/09296174.2014.911506
   Kirov C, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1868
   Klavans J. L., 2018, P WORKSHOP COMPUTATI, P1
   Koehn P., 2005, P AAMT 10 MACH TRANS, P79, DOI DOI 10.3115/1626355.1626380
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Larasati SD, 2011, COMM COM INF SC, V100, P119
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Mayer T, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3158
   Merity Stephen, 2018, CSCL180308240V1 CORR
   Mieke, 2016, ACL STANDS ANN M ASS
   Mielke Sabrina J., 2019, P AAAI C ART INT, V33, DOI [10.1609/aaai.v33i01.33016843, DOI 10.1609/AAAI.V33I01.33016843]
   Mielke SJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4975
   Pirinen T.A., 2015, P 20 NORD C COMP LIN, P313
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Sagot Benoit, 2013, COMPUTATIONAL APPROA
   Schmittou H.R., 2004, P IEEE INT C PERV CO, P1
   Schwartz Lane, 2020, CSCL200505477V2 CORR
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shibata Y., 1999, BYTE PAIR ENCODING T
   Tomczak M., 2014, TRENDS SPORT SCI, V1, P19, DOI DOI 10.1186/S13054-016-1208-6
   Tyers F.M., 2020, P 4 WORKSH UN DEP U, P195
   Vania C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2016, DOI 10.18653/v1/P17-1184
   Vilca Hugo David Calderon, 2012, ANALIZADOR MORF OLOG
   Virpioja S, 2013, MORFESSOR 2 0 PYTHON
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
NR 41
TC 6
Z9 6
U1 3
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 261
EP 276
DI 10.1162/tacl_a_00365
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200016
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Kirchhoff, K
   Vergyri, D
   Bilmes, J
   Duh, K
   Stolcke, A
AF Kirchhoff, Katrin
   Vergyri, Dimitra
   Bilmes, Jeff
   Duh, Kevin
   Stolcke, Andreas
TI Morphology-based language modeling for conversational Arabic speech
   recognition
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB Language modeling for large-vocabulary conversational Arabic speech recognition is faced with the problem of the complex morphology of Arabic, which increases the perplexity and out-of-vocabulary rate. This problem is compounded by the enormous dialectal variability and differences between spoken and written language. In this paper, we investigate improvements in Arabic language modeling by developing various morphology-based language models. We present four different approaches to morphology-based language modeling, including a novel technique called factored language models. Experimental results are presented for both rescoring and first-pass recognition experiments. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   SRI Int, Berkeley, CA 94720 USA.
C3 University of Washington; University of Washington Seattle; SRI
   International
RP Kirchhoff, K (通讯作者)，Univ Washington, Dept Elect Engn, Box 352500, Seattle, WA 98195 USA.
EM katrin@ee.washington.edu; dverg@speech.sri.com;
   bilmes@ee.washington.edu; duh@ee.washington.edu; stolcke@speech.sri.com
CR ABDELMASSIH ET, 1975, INTRO EGYPTIAN ARABI
   [Anonymous], P EUR
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2002, PROCEEDINGSOF WORKSH
   [Anonymous], P INT C AC SPEECH SI
   Beyerlein P, 1998, INT CONF ACOUST SPEE, P481, DOI 10.1109/ICASSP.1998.674472
   Billa J, 2002, INT CONF ACOUST SPEE, P5
   BILLA J, 1997, P EUR, P363
   Bilmes J. A., 2003, P C N AM CHAPT ASS C, P4, DOI DOI 10.3115/1073483.1073485
   BORNW P, 1992, COMPUTATIONAL LINGUS, V18, P467
   BYRNE B, 2001, P EUR, P487
   Byrne W, 2000, INT CONF ACOUST SPEE, P1029
   CARKI K, 2000, P INT C AC SPEECH SI, P134
   DIGALAKIS V, 1994, INT CONF ACOUST SPEE, P537
   DUPONT P, 1997, CMUCS97173
   ELBEZE M, 1990, P INT C AC SPEECH SI, P577
   GEUTNER P, 1995, INT CONF ACOUST SPEE, P445, DOI 10.1109/ICASSP.1995.479624
   GILDEA D, 2001, THESIS U CALIFORNIA
   Glotin H, 2001, INT CONF ACOUST SPEE, P173, DOI 10.1109/ICASSP.2001.940795
   Holland JH, 1975, ADAPTATION NATURAL A
   JI G, 2004, P HLT NAACL, P137
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KIECZA D, 1999, P ICSP SEOUL KOR, P323
   Kirchhoff K, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P765
   KIRCHHOFF K, 2002, NOVEL SPEECH RECOGNI
   Kitano H., 1990, Complex Systems, V4, P461
   MURVEIT H, 1993, P IEEE INT C AC SPEE, V2, P319
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   OSTENDORF M, 1991, P DARPA WORKSH SPEEC, P83
   Parandekar S, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P28
   Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI [10.1108/00330330610681286, 10.1108/eb046814]
   SCHULZ E, 2000, STANDARD ARABIC ELEM
   SCHWARTZ R, 2003, P INT C AC SPEECH SI, P753
   Stolcke A., 2000, P NIST SPEECH TRANSC
   VERGYRI D, 2000, P INT C SPOK LANG PR
   Wang W, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P238
   WANG W, 2003, OAIARXIVORGCS0305041
   Whittaker E.W.D., 2000, THESIS CAMBRIDGE U C
NR 38
TC 61
Z9 63
U1 0
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD OCT
PY 2006
VL 20
IS 4
BP 589
EP 608
DI 10.1016/j.csl.2005.10.001
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 087FH
UT WOS:000240727800011
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Wang, XL
   Yeung, DS
   Liu, JNK
   Luk, R
AF Wang, XL
   Yeung, DS
   Liu, JNK
   Luk, R
TI A hybrid language model based on statistics and linguistic rules
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE hybrid language model; n-gram model; computational linguistics; Chinese
   input
ID SPEECH RECOGNITION
AB Language modeling is a current research topic in many domains including speech recognition, optical character recognition, handwriting recognition, machine translation and spelling correction. There are two main types of language models, the mathematical and the linguistic. The most widely used mathematical language model is the n-gram model inferred from statistics. This model has three problems: long distance restriction, recursive nature and partial language understanding. Language models based on linguistics present many difficulties when applied to large scale real texts. We present here a new hybrid language model that combines the advantages of the n-gram statistical language model with those of a linguistic language model which makes use of grammatical or semantic rules. Using suitable rules, this hybrid model can solve problems such as long distance restriction, recursive nature and partial language understanding. The new language model has been effective in experiments and has been incorporated in Chinese sentence input products for Windows and Macintosh OS.
C1 Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
   Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150006, Peoples R China.
C3 Hong Kong Polytechnic University; Harbin Institute of Technology
RP Wang, XL (通讯作者)，Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
EM csdaniel@comp.polyu.edu.hk; csnkliu@comp.polyu.edu.hk;
   csrluk@comp.polyu.edu.hk
RI Luk, Robert W.P./B-9382-2015
OI Luk, Robert W.P./0000-0002-9310-8867
CR BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   CHELBA C, 1998, ACL, V17, P225
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Clarkson P., 1997, P IEEE INT C AC SPEE, P799
   COLLINS MJ, 1997, ACL, V35, P16
   ESSEN U, 1992, P IEEE ICASSP, P1161
   Iyer RM, 1999, IEEE T SPEECH AUDI P, V7, P30, DOI 10.1109/89.736328
   KNESER R, 1997, P IEEE ICASSP, P779
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   KUPIEC J, 1992, P IEEE ICASSP, P1177
   LEE KF, 1990, IEEE T ACOUST SPEECH, V38, P35, DOI 10.1109/29.45616
   Lee LS, 1993, IEEE T SPEECH AUDI P, V1, P158, DOI 10.1109/89.222876
   MASATAKI H, 1997, P ICASSP, P783
   NIESLER T, 1997, P IEEE ICASSP, P795
   Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930
   PLACEWAY P, 1993, P IEEE ICASSP, P1133
   Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RISEMAN EM, 1971, IEEE T COMPUT, VC 20, P397, DOI 10.1109/T-C.1971.223255
   SIMONS M, 1997, P IEEE INT C AC SPEE, P787
   SUEN CY, 1979, IEEE T PATTERN ANAL, V1, P164, DOI 10.1109/TPAMI.1979.4766902
   Wang Xiaolong, 1993, Chinese Journal of Computers, V16, P370
   Wang Xiaolong, 1994, Chinese Journal of Computers, V17, P96
   WANG XL, 1989, CHINESE SCI BULL, V34, P1924
   Wong PK, 1998, IEEE T PATTERN ANAL, V20, P1016, DOI 10.1109/34.713366
   ZHAO J, 1998, COLING ACL, V98, P1
NR 27
TC 2
Z9 2
U1 1
U2 10
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD FEB
PY 2005
VL 19
IS 1
BP 109
EP 128
DI 10.1142/S0218001405003934
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 913EY
UT WOS:000228135600007
DA 2023-11-10
ER

PT J
AU Guo, JF
   Han, Q
   Ma, GZ
   Liu, H
   van Hooland, S
AF Guo, Junfei
   Han, Qi
   Ma, Guangzhi
   Liu, Hong
   van Hooland, Seth
TI Tunable discounting and visual exploration for language models
SO NEUROCOMPUTING
LA English
DT Article
DE Language model; Tunable discounting; Polynomial discounting; Domain
   adaptation; Visualization
AB A language model is fundamental to many applications in natural language processing. Most language models are trained on a large amount of dataset and difficult to be adapted to other domains which may have only a small dataset available. Tuning discounting parameters for smoothing is one way to adapt language models for a new domain. In this work, we present novel language models based on tunable discounting mechanisms. The language models are trained on a large dataset, but their discounting parameters can be tuned to a target dataset afterwards. We explore tunable discounting and polynomial discounting functions based on the modified Kneser-Ney (mKN) models. Specifically, we propose the tunable mKN (TmKN) model, polymomial discounting mKN (PmKN) model, and tunable and polynomial discounting mKN (TPmKN) model. We test our proposed models and compared with the mKN model, improved KN model, and the tunable mKN with the interpolation model (mKN + interp). With the implementation, our language models achieve perplexity improvements in both in-domain and out-of-domain evaluation. Experimental results indicate that our new models significantly outperform the baseline model and our models are especially suitable for adapting to new domains. In addition, we use the visualization technique to depict the relationship between parameter settings and the language model performances for guiding our parameter optimization process. The exploratory visual analysis is then used to examine the performance of the proposed language models which will reveal the strength and characteristic of the models. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Guo, Junfei; Ma, Guangzhi; Liu, Hong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Guo, Junfei; van Hooland, Seth] Univ Libre Bruxelles, Informat & Commun Sci Dept, Brussels, Belgium.
   [Han, Qi] Univ Stuttgart, Inst Visualizat & Interact Syst, Stuttgart, Germany.
C3 Huazhong University of Science & Technology; Universite Libre de
   Bruxelles; University of Stuttgart
RP Ma, GZ (通讯作者)，Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
EM junfei.guo@ulb.ac.be; Qi.Han@vis.uni-stuttgart.de;
   maguangzhi@hust.edu.cn; hongliu@hust.edu.cn; svhoolan@ulb.ac.be
CR Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   [Anonymous], 2015, DEEP LEARNING WORKSH
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2005, P HUMAN LANGUAGE TEC
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   [Anonymous], 2010, INTERSPEECH, DOI DOI 10.1016/J.CSL.2010.08.008
   [Anonymous], 1996, 34 ANN M ASS COMP LI, DOI DOI 10.3115/981863.981904
   Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137
   Brooks M, 2015, IEEE CONF VIS ANAL, P105, DOI 10.1109/VAST.2015.7347637
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Card S.K., 1999, READING INFORM VISUA
   Chelba C., 2014, ARXIV PREPRINT ARXIV
   Eisele A, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2868
   Federico M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1618
   Guo J., 2014, P 11 BIENN C ASS MAC, P356
   Heafield K., 2013, P 51 ANN M ASS COMP, V2, P690
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Heimerl F., 2012, P COLING 2012 POST M, P461
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   JELINEK F, 1977, J ACOUST SOC AM, V62, pS63, DOI 10.1121/1.2016299
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kneser R., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P586, DOI 10.1109/ICASSP.1993.319375
   Koehn P., 2010, STAT MACHINE TRANSLA
   Kruger R., 2013, IEEE C VIS AN SCI TE
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P612
   Mnih A, 2009, NEUROCOMPUTING, V72, P1414, DOI 10.1016/j.neucom.2008.12.025
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH
   Schutze H., 2011, P ACL ACL, P1516
   Schutze H., 2008, INTRO INFORM RETRIEV, V39
   Williams W, 2015, INT CONF ACOUST SPEE, P5391, DOI 10.1109/ICASSP.2015.7179001
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 33
TC 1
Z9 1
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD DEC 20
PY 2017
VL 269
SI SI
BP 73
EP 81
DI 10.1016/j.neucom.2016.08.145
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FI8QA
UT WOS:000412266000009
DA 2023-11-10
ER

PT J
AU Ross, J
   Belgodere, B
   Chenthamarakshan, V
   Padhi, I
   Mroueh, Y
   Das, P
AF Ross, Jerret
   Belgodere, Brian
   Chenthamarakshan, Vijil
   Padhi, Inkit
   Mroueh, Youssef
   Das, Payel
TI Large-scale chemical language representations capture molecular
   structure and properties
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
AB Large language models have recently emerged with extraordinary capabilities, and these methods can be applied to model other kinds of sequence, such as string representations of molecules. Ross and colleagues have created a transformer-based model, trained on a large dataset of molecules, which provides good results on property prediction tasks.
   Models based on machine learning can enable accurate and fast molecular property predictions, which is of interest in drug discovery and material design. Various supervised machine learning models have demonstrated promising performance, but the vast chemical space and the limited availability of property labels make supervised learning challenging. Recently, unsupervised transformer-based language models pretrained on a large unlabelled corpus have produced state-of-the-art results in many downstream natural language processing tasks. Inspired by this development, we present molecular embeddings obtained by training an efficient transformer encoder model, MoLFormer, which uses rotary positional embeddings. This model employs a linear attention mechanism, coupled with highly distributed training, on SMILES sequences of 1.1 billion unlabelled molecules from the PubChem and ZINC datasets. We show that the learned molecular representation outperforms existing baselines, including supervised and self-supervised graph neural networks and language models, on several downstream tasks from ten benchmark datasets. They perform competitively on two others. Further analyses, specifically through the lens of attention, demonstrate that MoLFormer trained on chemical SMILES indeed learns the spatial relationships between atoms within a molecule. These results provide encouraging evidence that large-scale molecular language models can capture sufficient chemical and structural information to predict various distinct molecular properties, including quantum-chemical properties.
C1 [Ross, Jerret; Belgodere, Brian; Chenthamarakshan, Vijil; Padhi, Inkit; Mroueh, Youssef; Das, Payel] IBM Res, Yorktown Hts, NY 10598 USA.
C3 International Business Machines (IBM)
RP Ross, J; Das, P (通讯作者)，IBM Res, Yorktown Hts, NY 10598 USA.
EM rossja@us.ibm.com; daspa@us.ibm.com
OI Chenthamarakshan, Vijil/0000-0001-7830-5777
CR Altae-Tran H, 2017, ACS CENTRAL SCI, V3, P283, DOI 10.1021/acscentsci.6b00367
   [Anonymous], 2007, DAYLIGHT CHEM INFORM
   Beltagy I, 2020, Arxiv, DOI [arXiv:2004.05150, DOI 10.48550/ARXIV.2004.05150]
   Bommasani Rishi, 2021, ARXIV
   Chen PF, 2019, Arxiv, DOI arXiv:1906.05488
   Chen T, 2020, PR MACH LEARN RES, V119
   Chithrananda S, 2020, Arxiv, DOI [arXiv:2010.09885, DOI 10.48550/ARXIV.2010.09885]
   Choromanski K, 2021, PROC 9 INT C LEARNIN
   Defferrard M, 2016, ADV NEUR IN, V29
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Fang XM, 2022, NAT MACH INTELL, V4, P127, DOI 10.1038/s42256-021-00438-4
   Gao W., 2022, 36 C NEURAL INFORM P
   Gasteiger Johannes, 2020, INT C LEARN REPR
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hu W, 2020, 8 INT C LEARNING REP
   ipf T.N., 2017, 5 INT C LEARN REPR I
   Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+
   Jo J, 2020, METHODS, V179, P65, DOI 10.1016/j.ymeth.2020.05.009
   Katharopoulos A, 2020, PR MACH LEARN RES, V119
   Ke G., 2021, 9 INT C LEARNING REP
   Kim Sunghwan, 2019, Nucleic Acids Res, V47, pD1102, DOI 10.1093/nar/gky1033
   Kirkpatrick P, 2004, NATURE, V432, P823, DOI 10.1038/432823a
   Kitaev Nikita, 2020, ARXIV200104451
   Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947
   Li Y., 2016, 4 INT C LEARNING REP
   Liao R., 2019, 7 INT C LEARNING REP
   Liu S., 2022, INT C LEARNING REPRE
   Liu Shichen, 2019, ADV NEURAL INFORM PR, V32
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Lu CQ, 2019, AAAI CONF ARTIF INTE, P1052
   Öztürk H, 2018, BIOINFORMATICS, V34, P821, DOI 10.1093/bioinformatics/bty593
   Park S., 2019, PMLR, P230, DOI DOI 10.48550/ARXIV.1908.06760
   Paul A, 2018, Arxiv, DOI arXiv:1811.08283
   Raffel C, 2020, J MACH LEARN RES, V21
   Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118
   Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t
   Rupp M, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.058301
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Schutt Kristof T, 2017, ADV NEURAL INFORM PR, P1
   Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576
   Shaw Peter, 2018, NAACL, P5, DOI DOI 10.18653/V1/N18-2074
   Shiwei Wang, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P29, DOI 10.1109/ICIVC50857.2020.9177456
   Su JL, 2022, Arxiv, DOI arXiv:2104.09864
   Urbina F, 2022, NAT MACH INTELL, V4, P189, DOI 10.1038/s42256-022-00465-9
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic P, 2018, P 6 INT C LEARN REPR
   Vishnu A., 2018, SMILES2VEC INTERPRET, DOI DOI 10.48550/ARXIV.1712.02034
   Wang YY, 2022, NAT MACH INTELL, V4, P279, DOI 10.1038/s42256-022-00447-x
   WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005
   Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a
   Xiong ZP, 2020, J MED CHEM, V63, P8749, DOI 10.1021/acs.jmedchem.9b00959
   Yang K, 2019, J CHEM INF MODEL, V59, P3370, DOI 10.1021/acs.jcim.9b00237
   You Y., 2020, INT C LEARNING REPRE
NR 56
TC 10
Z9 9
U1 20
U2 36
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD DEC
PY 2022
VL 4
IS 12
DI 10.1038/s42256-022-00580-7
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7Z6CX
UT WOS:000915646400002
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Blat, F
   Castro, MJ
   Tortajada, S
   Sánchez, JA
AF Blat, F
   Castro, MJ
   Tortajada, S
   Sánchez, JA
BE Matousek, V
   Mautner, P
   Pavelka, T
TI A hybrid approach to statistical language modeling with multilayer
   perceptrons and unigrams
SO TEXT, SPEECH AND DIALOGUE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 8th International Conference on Text, Speech and Dialogue
CY SEP 12-15, 2005
CL Karlovy Vary, CZECH REPUBLIC
SP Univ West Bohemia, Fac Appl Sci, Massaryk Univ, Fac Informat, Int Speech Commun Assoc
AB In language engineering, language models are employed in order to improve system performance. These language models are usually N-gram models which are estimated from large text databases using the occurrence frequencies of these N-grams. An alternative to conventional frequency-based estimation of N-gram probabilities consists on using neural networks to this end. In this paper, an approach to language modeling with a hybrid language model is presented as a linear combination of a connectionist N-gram model, which is used to represent the global relations between certain linguistic categories, and a stochastic model of word distribution into such categories. The hybrid language model is tested on the corpus of the Wall Street journal processed in the Penn Treebank project.
C1 Univ Politecn Valencia, Dept Sistemes Informat & Computacio, E-46022 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Blat, F (通讯作者)，Univ Politecn Valencia, Dept Sistemes Informat & Computacio, E-46022 Valencia, Spain.
EM fblat@dsic.upv.es; mcastro@dsic.upv.es; stortajada@dsic.upv.es;
   jandreu@dsic.upv.es
RI Castro-Bleda, M. J./H-2372-2011; Tortajada, Salvador/M-6257-2015;
   Sánchez, Joan Andreu/M-1550-2014; Tortajada, Salvador/AAB-6037-2020
OI Tortajada, Salvador/0000-0001-7426-2407; Sánchez, Joan
   Andreu/0000-0003-0423-2020; Tortajada, Salvador/0000-0001-7426-2407
CR [Anonymous], 1998, STAT METHODS SPEECH
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   BENEDI J, 2005, IN PRESS COMPUTER SP
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   CASTRO M, 1999, P S PATT REC IM AN B, P9
   Castro MJ, 2003, LECT NOTES COMPUT SC, V2686, P598
   Castro MJ, 1999, IEE CONF PUBL, P910, DOI 10.1049/cp:19991228
   CASTRO MJ, 2001, P 2 WORKSH NAT LANG, P16
   CLARKSON P, 1997, P EUR 97 RHOD GREEC, P2707
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   NAKAMUR AM, 1989, P ICASSP, P731
   Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526
   Rodriguez P, 2003, APPL INTELL, V19, P39, DOI 10.1023/A:1023864622883
   ROSENFELD R, 1994, THESIS CARNEGIE MELL
   RUMELHART D, 1986, PDP COMPUTATIONAL MO
   Schwenk H, 2004, IEEE IJCNN, P3059
   Schwenk H, 2002, INT CONF ACOUST SPEE, P765
   SCHWENK H, 2003, WORK SPONT SPEECH PR
   XU W, 2000, P ICSLP
NR 22
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-28789-2
J9 LECT NOTES ARTIF INT
PY 2005
VL 3658
BP 195
EP 202
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BDA46
UT WOS:000232264700025
DA 2023-11-10
ER

PT J
AU Lukauskas, M
   Rasymas, T
   Minelga, M
   Vaitmonas, D
AF Lukauskas, Mantas
   Rasymas, Tomas
   Minelga, Matas
   Vaitmonas, Domas
TI LARGE SCALE FINE-TUNED TRANSFORMERS MODELS APPLICATION FOR BUSINESS
   NAMES GENERATION
SO COMPUTING AND INFORMATICS
LA English
DT Article
DE Natural language processing; NLP; natural language generation; NLG;
   transformers
AB Natural language processing (NLP) involves the computer analysis and processing of human languages using a variety of techniques aimed at adapting various tasks or computer programs to linguistically process natural language. Currently, NLP is increasingly applied to a wide range of real-world problems. These tasks can vary from extracting meaningful information from unstructured data, analyzing sentiment, translating text between languages, to generating human-level text autonomously. The goal of this study is to employ transformer-based natural language models to generate high-quality business names. Specifically, this work investigates whether larger models, which require more training time, yield better results for generating relatively short texts, such as business names. To achieve this, we utilize different transformer architectures, including both freely available and proprietary models, and compare their performance. Our dataset comprises 250 928 observations of business names. Based on the perplexity metric, the top performing model in our study is the GPT2-Medium model. However, our findings reveal a discrepancy between human evaluation and perplexity-based assessment. According to human evaluation, the best results are obtained using the GPT-Neo1.3B model. Interestingly, the larger GPT-Neo-2.7B model yields poorer results, with its performance not being statistically different from that of the GPT-Neo125M model, which is 20 times smaller.
C1 [Lukauskas, Mantas] Kaunas Univ Technol, Dept Appl Math, K Donelaicio St 73, LT-44249 Kaunas, Lithuania.
   [Rasymas, Tomas] UAB, Hostinger, Jonavos St 60C, LT-44192 Kaunas, Lithuania.
   [Minelga, Matas; Vaitmonas, Domas] UAB, Zyro Inc, Jonavos St 60C, LT-44192 Kaunas, Lithuania.
C3 Kaunas University of Technology
RP Lukauskas, M (通讯作者)，Kaunas Univ Technol, Dept Appl Math, K Donelaicio St 73, LT-44249 Kaunas, Lithuania.
EM mantas.lukauskas@ktu.lt; tomas.rasymas@hostinger.com; matas@zyro.com;
   domas@zyro.com
CR Adhikari A, 2019, Arxiv, DOI arXiv:1904.08398
   AMIDEI J., 2019, P 12 INT C NATURAL L, P397, DOI DOI 10.18653/V1/W19-8648
   [Anonymous], 2013, ADV NEURAL INFORM PR
   Bojar O., 2017, P 2 C MACH TRANSL, P169, DOI [10.18653/v1/W17-4717, DOI 10.18653/V1/W17-4717]
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   COCH J., 1996, P 16 C COMPUTATIONAL, P249, DOI 10.3115/992628.992673
   Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030483
   DE COSTER M., 2021, P 1 INT WORKSH AUT T, P88
   Devlin J, 2018, OPEN SOURCING BERT S
   Fan A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3558
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   GAuTAM A., 2021, COMMUNICATIONS COMPU, V1402, P189, DOI [10.1007/978-3-030-73696-5_18, DOI 10.1007/978-3-030-73696-5_18]
   GKATZIA D., 2015, P 15 EUROPEAN WORKSH, P57
   GRAHAM Y., 2013, P 7 LINGUISTIC ANNOT, P33
   Hendrycks D, 2020, Arxiv, DOI [arXiv:1606.08415, DOI 10.48550/ARXIV.1606.08415]
   JONES K. S., 1995, EVALUATING NATURAL L, DOI [10.1007/BFb0027470, DOI 10.1007/BFB0027470]
   Joshi A., 2015, BRIT J APPL SCI TECH, V7, P396, DOI [10.9734/BJAST/2015/14975, DOI 10.9734/BJAST/2015/14975]
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Lester JC, 1997, COMPUT LINGUIST, V23, P65
   Lewis M., 2020, P 58 ANN M ASS COMP
   Li JY, 2021, Arxiv, DOI arXiv:2105.10311
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Lu Y, 2022, IEEE-ACM T AUDIO SPE, V30, P1927, DOI 10.1109/TASLP.2022.3180678
   Mellish C, 1998, COMPUT SPEECH LANG, V12, P349, DOI 10.1006/csla.1998.0106
   Merchant K, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1803, DOI 10.1109/ICACCI.2018.8554831
   Mishev K, 2020, IEEE ACCESS, V8, P131662, DOI 10.1109/ACCESS.2020.3009626
   Pan LM, 2019, Arxiv, DOI arXiv:1905.08949
   Radford A., 2019, BETTER LANGUAGE MODE, V1, P2
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024
   Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Tevet G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P326
   Vaswani A, 2017, ADV NEUR IN, V30
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Xia YC, 2019, AAAI CONF ARTIF INTE, P5466
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Yang ZL, 2020, Arxiv, DOI [arXiv:1906.08237, DOI 10.48550/ARXIV.1906.08237]
NR 39
TC 0
Z9 0
U1 2
U2 2
PU SLOVAK ACAD SCIENCES INST INFORMATICS
PI BRATISLAVA
PA DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA
SN 1335-9150
J9 COMPUT INFORM
JI Comput. Inform.
PY 2023
VL 42
IS 3
BP 525
EP 545
DI 10.31577/cai20233525
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S4MF6
UT WOS:001070918300001
DA 2023-11-10
ER

PT J
AU Faal, F
   Schmitt, K
   Yu, JY
AF Faal, Farshid
   Schmitt, Ketra
   Yu, Jia Yuan
TI Reward modeling for mitigating toxicity in transformer-based language
   models
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Language models; Transformers; Reinforcement learning; Toxic language
   mitigation; Natural language generation
AB Transformer-based language models can generate fluent text and be efficiently adapted across various natural language generation tasks. However, language models that are pretrained on large unlabeled web text corpora have been shown to suffer from degenerating toxic content and social bias behaviors, consequently hindering their safe deployment. Various detoxification methods have been proposed to mitigate language model toxicity; however, these methods struggle to detoxify language models when conditioned on prompts that contain specific social identities related to gender, race, or religion. In this study, we propose Reinforce-Detoxify, a reinforcement learning-based method for mitigating toxicity in language models. We address the challenge of safety in language models and propose a new reward model that can detect toxic content and mitigate unintended bias towards social identities in toxicity prediction. The experiments demonstrate that the Reinforce-Detoxify method for language model detoxification outperforms existing detoxification approaches in automatic evaluation metrics, indicating that our approach in language model detoxification is less prone to unintended bias toward social identities in generated content.
C1 [Faal, Farshid; Schmitt, Ketra; Yu, Jia Yuan] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
   [Schmitt, Ketra] Concordia Univ, Ctr Engn Soc, Montreal, PQ, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Faal, F (通讯作者)，Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM f_faal@encs.concordia.ca; ketra.schmitt@concordia.ca;
   jiayuan.yu@concordia.ca
RI Schmitt, Ketra/GWQ-5329-2022
OI Faal, Farshid/0000-0002-2555-3221
CR Bengio Y., 2009, P 26 ANN INT C MACHI, DOI DOI 10.1145/1553374.1553380
   Böhm F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3110
   Boyd-Graber Jordan L., 2017, P 2017 C EMP METH NA, P1464, DOI DOI 10.18653/V1/D17-1153
   Dathathri S, 2020, ICLR
   Davidson T., 2017, ICWSM
   Dhamala J, 2021, P 2021 ACM C FAIRN A, P862, DOI DOI 10.1145/3442188.3445924
   Dhariwal Prafulla, 2017, OPENAI BASELINES
   Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Gao Y, 2020, INFORM RETRIEVAL J, V23, P555, DOI 10.1007/s10791-019-09367-8
   Gehman Samuel, 2020, FINDINGS ASS COMPUTA, P3356
   Gokaslan Aaron, 2019, OPENWEBTEXT CORPUS
   Gururangan Suchin, 2020, ACL, DOI [DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.acl-main.740]
   Holtzman Ari, 2020, ICLR
   Krause B, 2021, GEDI GENERATIVE DISC
   Li Jiwei, 2016, EMNLP
   Li M, 2021, APPL INTELL, V51, P7109, DOI 10.1007/s10489-021-02188-7
   Liu A, 2021, P 59 ANN M ASS COMPU, P6691
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Niven T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4658
   Paulus Romain, 2018, 6 INT C LEARN REPR I
   Do P, 2022, APPL INTELL, V52, P636, DOI 10.1007/s10489-021-02460-w
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Ranzato M, 2016, ICLR, P1
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Schulman John, 2017, ARXIV170706347
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407
   Stiennon N., 2020, P 34 INT C NEUR INF, P3008
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Vaswani A, 2017, ADV NEUR IN, V30
   Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2153
   Welbl J., 2021, FINDINGS ASS COMPUTA, V2021, P2447, DOI DOI 10.18653/V1/2021.FINDINGS-EMNLP.210
   Wiegand M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P602
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu YX, 2018, AAAI CONF ARTIF INTE, P5602
   Xu A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2390
   Yang S, 2022, APPL INTELL, V52, P1672, DOI 10.1007/s10489-021-02431-1
   Yi Sanghyun, 2019, P 12 INT C NAT LANG, P65
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Ziegler D. M., 2019, FINE TUNING LANGUAGE
NR 45
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD APR
PY 2023
VL 53
IS 7
BP 8421
EP 8435
DI 10.1007/s10489-022-03944-z
EA JUL 2022
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A9OT4
UT WOS:000827937500006
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Divina, F
   Vogt, P
AF Divina, Federico
   Vogt, Paul
BE Vogt, P
   Sugita, Y
   Tuci, E
   Nehaniv, C
TI A hybrid model for learning word-meaning mappings
SO SYMBOL GROUNDING AND BEYOND, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 3rd Annual International Wokshop on Emergence and Evolution of
   Linguistic Communication
CY SEP 30-OCT 01, 2006
CL Rome, ITALY
AB In this paper we introduce a model for the simulation of language evolution, which is incorporated in the New Ties project. The New Ties project aims at evolving a cultural society by integrating evolutionary, individual and social learning in large scale multi-agent simulations. The model presented here introduces a novel implementation of language games, which allows agents to communicate in a more natural way than with most other existing implementations of language games. In particular, we propose a hybrid mechanism that combines cross-situational learning techniques with more informed feedback mechanisms. In our study we focus our attention on dealing with referential indeterminacy after joint attention has been established and on whether the current model can deal with larger populations than previous studies involving cross-situational learning. Simulations show that the proposed model can indeed lead to coherent languages in a quasi realistic world environment with larger populations.
C1 Tilburg Univ, NL-5000 LE Tilburg, Netherlands.
   Univ Edinburgh, Sch Philosophy Psychol & Language Sci, Language Evolut & Computat Res Unit, Edinburgh EH8 9YL, Midlothian, Scotland.
C3 Tilburg University; University of Edinburgh
RP Divina, F (通讯作者)，Tilburg Univ, POB 90153, NL-5000 LE Tilburg, Netherlands.
EM f.divina@uvt.nl; paulv@ling.ed.ac.uk
RI Divina, Federico/K-3880-2014
OI Divina, Federico/0000-0002-0964-9506; Vogt, Paul/0000-0002-9446-4425
CR AKHTAR N, 1999, FIRST LANG, V19, P347, DOI DOI 10.1177/014272379901905703
   BARONCHELLI A, 2006, P EV, V6
   BLOOM P, 2000, CHILDREN LEAR MEANIN
   Clark, 1987, MECH LANGUAGE ACQUIS, DOI DOI 10.4324/9781315798721
   DEBEUEL J, 2006, IN PRESS ALIFE, V10
   DIVINA F, 2005, P 8 EUR C ART LIF EC, P644
   DIVINIA F, 2006, ILK RES GROUP TECHNI
   Epstein J., 1996, GROWING ARTIFICIAL S
   Gilbert N, 2006, JASSS-J ARTIF SOC S, V9
   Houston-Price C, 2005, J CHILD LANG, V32, P175, DOI 10.1017/S0305000904006610
   Macnamara J., 1982, NAMES THINGS STUDY H
   QUINE WVO, 2013, WORD OBJECT
   Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7
   Smith ADM, 2003, ARTIF LIFE, V9, P175, DOI 10.1162/106454603322221513
   SMITH K, 2006, P EM EV LING COMM EE
   Steels L., 1997, EVOLUTION COMMUNICAT, V10, P1, DOI DOI 10.1075/E0C.1.1.02STE
   STEELS L, 1999, P IJCAI 99
   Tomasello M., 2003, CULTURAL ORIGINS HUM
   Vogt P, 2003, JASSS-J ARTIF SOC S, V6
   Vogt P, 2005, ARTIF INTELL, V167, P206, DOI 10.1016/j.artint.2005.04.010
   VOGT P., 2000, THESIS VRIJE U BRUSS
   VOGT P, 2005, P AISB 200K SOC INSP, P80
NR 22
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-45769-0
J9 LECT NOTES ARTIF INT
PY 2006
VL 4211
BP 1
EP 15
PG 15
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFJ24
UT WOS:000242307400001
DA 2023-11-10
ER

PT J
AU Shuang, K
   Li, R
   Gu, MY
   Loo, J
   Su, S
AF Shuang, Kai
   Li, Rui
   Gu, Mengyu
   Loo, Jonathan
   Su, Sen
TI Major-Minor Long Short-Term Memory for Word-Level Language Model
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Feature extraction; Semantics; Correlation; Natural language processing;
   Data models; Task analysis; Training; Language model (LM); long
   short-term memory (LSTM); natural language processing (NLP); shortcut
   connections
AB Language model (LM) plays an important role in natural language processing (NLP) systems, such as machine translation, speech recognition, learning token embeddings, natural language generation, and text classification. Recently, the multilayer long short-term memory (LSTM) models have been demonstrated to achieve promising performance on word-level language modeling. For each LSTM layer, larger hidden size usually means more diverse semantic features, which enables the LM to perform better. However, we have observed that when a certain LSTM layer reaches a sufficiently large scale, the promotion of overall effect will slow down, as its hidden size increases. In this article, we analyze that an important factor leading to this phenomenon is the high correlation between the newly extended hidden states and the original hidden states, which hinders diverse feature expression of the LSTM. As a result, when the scale is large enough, simply lengthening the LSTM hidden states will cost tremendous extra parameters but has little effect. We propose a simple yet effective improvement on each LSTM layer consisting of a large-scale Major LSTM and a small-scale Minor LSTM to break the high correlation between the two parts of hidden states, which we call Major-Minor LSTMs (MMLSTMs). In experiments, we demonstrate the LM with MMLSTMs surpasses the existing state-of-the-art model on Penn Treebank (PTB) and WikiText-2 (WT2) data sets and outperforms the baseline by 3.3 points in perplexity on WikiText-103 data set without increasing model parameter counts.
C1 [Shuang, Kai; Li, Rui; Gu, Mengyu; Su, Sen] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Loo, Jonathan] Univ West London, Sch Comp & Engn, London W5 5RF, England.
C3 Beijing University of Posts & Telecommunications; University of West
   London
RP Li, R (通讯作者)，Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
EM shuangk@bupt.edu.cn; lirui@bupt.edu.cn; jonathan.loo@uwl.ac.uk
RI Loo, Jonathan/E-6075-2019
OI Loo, Jonathan/0000-0002-2197-8126; shuang, kai/0000-0003-0917-3541; Li,
   Rui/0000-0002-4595-0881
FU National Key Research and Development Program of China [2017YFB1400603]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB1400603.
CR Al-Rfou R, 2019, AAAI CONF ARTIF INTE, P3159
   [Anonymous], 2018, ARXIV180106146
   [Anonymous], 2013, PREPRINT ARXIV 1308
   [Anonymous], 2016, ARXIV161204426
   [Anonymous], 2017, ARXIV170109175
   [Anonymous], 2016, P 2016 C EMPIRICAL M, DOI [DOI 10.18653/V1/D16-1123, 10.18653/v1/d16-1123]
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2017, ARXIV171100066
   [Anonymous], 2017, ARXIV170310722
   Assylbekov Z., 2017, ARXIV170706480
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Botha JA, 2014, PR MACH LEARN RES, V32, P1899
   Britz D., 2017, P 2017 C EMP METH NA, P1442, DOI [10.18653/v1/D17-1151, DOI 10.18653/V1/D17-1151]
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Dyer C., 2017, ARXIV170406986
   Fortunato M., 2017, CORR
   Gal Y, 2016, ADV NEUR IN, V29
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Inan H., 2016, ABS161101462 CORR
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   King DB, 2015, ACS SYM SER, V1214, P1
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Koehn P., 2010, STAT MACHINE TRANSLA
   Koehn Philipp, 2009, STAT MACHINE TRANSLA
   Krause Ben, 2017, ARXIV170907432
   Luong M.-T., 2015, P 2015 C EMP METH NA, DOI DOI 10.18653/V1/D15-1166
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Melis G., 2017, ARXIV170705589
   Merity Stephen, 2017, ICLR
   Merity Stephen, 2016, POINTER SENTINEL MIX
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Ororbia AG, 2017, NEURAL COMPUT, V29, P3327, DOI [10.1162/NECO_a_01017, 10.1162/neco_a_01017]
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Press O, 2016, ARXIV160805859
   Radford A., 2017, LEARNING GENERATE RE
   Ripley B.D., 2007, PATTERN RECOGN, DOI DOI 10.1016/J.PATCOG.2017.10.013
   Salakhutdinov R. R., 2012, ARXIV
   Schraudolph NN, 1998, LECT NOTES COMPUT SC, V1524, P207
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wan L, 2013, P 30 INT C MACH LEAR, P1058
   Wu, 2016, ARXIV160202410
   Yang Z., 2017, ARXIV171103953
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Zaremba W., 2014, PREPRINT
   Zilly JG, 2016, RECURRENT HIGHWAY NE
   Zoph B, ARXIV161101578
NR 49
TC 11
Z9 11
U1 0
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD OCT
PY 2020
VL 31
IS 10
BP 3932
EP 3946
DI 10.1109/TNNLS.2019.2947563
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY5NS
UT WOS:000576436600013
PM 31825875
OA Green Accepted
DA 2023-11-10
ER

PT J
AU Ramesh, G
   Doddapaneni, S
   Bheemaraj, A
   Jobanputra, M
   Raghavan, AK
   Sharma, A
   Sahoo, S
   Diddee, H
   Mahalakshmi, J
   Kakwani, D
   Kumar, N
   Pradeep, A
   Nagaraj, S
   Deepak, K
   Raghavan, V
   Kunchukuttan, A
   Kumar, P
   Khapra, MS
AF Ramesh, Gowtham
   Doddapaneni, Sumanth
   Bheemaraj, Aravinth
   Jobanputra, Mayank
   Raghavan, A. K.
   Sharma, Ajitesh
   Sahoo, Sujit
   Diddee, Harshita
   Mahalakshmi, J.
   Kakwani, Divyanshu
   Kumar, Navneet
   Pradeep, Aswin
   Nagaraj, Srihari
   Deepak, Kumar
   Raghavan, Vivek
   Kunchukuttan, Anoop
   Kumar, Pratyush
   Khapra, Mitesh Shantadevi
TI <i>Samanantar</i>: The Largest Publicly Available Parallel Corpora
   Collection for 11 Indic Languages
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We present Samanantar, the largest publicly available parallel corpora collection for Indic languages. The collection contains a total of 49.7 million sentence pairs between English and 11 Indic languages (from two language families). Specifically, we compile 12.4 million sentence pairs from existing, publicly available parallel corpora, and additionally mine 37.4 million sentence pairs from the Web, resulting in a 4x increase. We mine the parallel sentences from the Web by combining many corpora, tools, and methods: (a) Web-crawled monolingual corpora, (b) document OCR for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. Human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages. Further, we extract 83.4 million sentence pairs between all 55 Indic language pairs from the English-centric parallel corpus using English as the pivot language. We trained multilingual NMT models spanning all these languages on Samanantar which outperform existing models and baselines on publicly available benchmarks, such as FLORES, establishing the utility of Samanantar. Our data and models are available publicly at and we hope they will help advance research in NMT and multilingual NLP for Indic languages.
C1 [Ramesh, Gowtham; Doddapaneni, Sumanth; Kumar, Pratyush; Khapra, Mitesh Shantadevi] RBCDSAI, Chennai, India.
   [Bheemaraj, Aravinth; Sharma, Ajitesh; Sahoo, Sujit; Kumar, Navneet; Pradeep, Aswin; Nagaraj, Srihari; Deepak, Kumar] Tarento Technol, Bengaluru, India.
   [Jobanputra, Mayank; Kakwani, Divyanshu; Kumar, Pratyush; Khapra, Mitesh Shantadevi] IIT Madras, Chennai, India.
   [Raghavan, A. K.; Diddee, Harshita; Mahalakshmi, J.; Kakwani, Divyanshu; Kunchukuttan, Anoop; Kumar, Pratyush; Khapra, Mitesh Shantadevi] AI4Bharat, Chennai, India.
   [Bheemaraj, Aravinth; Sharma, Ajitesh; Sahoo, Sujit; Kumar, Navneet; Pradeep, Aswin; Nagaraj, Srihari; Deepak, Kumar; Raghavan, Vivek] EkStep Fdn, Bengaluru, India.
   [Kunchukuttan, Anoop] Microsoft, New Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras
RP Khapra, MS (通讯作者)，RBCDSAI, Chennai, India.; Khapra, MS (通讯作者)，IIT Madras, Chennai, India.; Khapra, MS (通讯作者)，AI4Bharat, Chennai, India.
EM miteshk@cse.iitm.ac.in
RI Martsenyuk, Vasyl P/D-6964-2015; Kumar, Pratyush/HIR-7873-2022
OI Martsenyuk, Vasyl P/0000-0001-5622-1038; 
FU Robert Bosch Center for Data Science and Artificial Intelligence; Google
FX We would like to thank the TACL editors andreviewers, who have helped us
   shape this pa-per. We would like to thank EkStep Foundationfor their
   generous grant which went into hir-ing human resources as well as cloud
   resourcesneeded for this work. We would like to thankthe Robert Bosch
   Center for Data Science and Artificial Intelligence for supporting
   Sumanthand Gowtham through their Post BaccalaureateFellowship Program.
   We would like to thank Google for their generous grant through their
   TPUResearch Cloud Program. We would also liketo thank the following
   members from TarentoTechnlogies for providing logistical and tech-nical
   support: Sivaprakash Ramasamy, AmrithaDevadiga, Karthickeyan
   Chandrasekar, NareshKumar, Dhiraj D, Vishal Mahuli, Dhanvi
   Desai,Jagadeesh Lachannagari, Dhiraj Suthar, PromodhPinto, Sajish
   Sasidharan, Roshan Prakash Shah,and Abhilash Seth.
CR Agic E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3204
   Agirre E, 2016, P 10 INT WORKSH SEM, P497, DOI DOI 10.18653/V1/S16-1081
   Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   [Anonymous], 2016, P C N AM CHAPT ASS C
   Anoop, 2020, INDICNLP LIB
   Anoop, 2018, IIT BOMBAY ENGLISH H
   Antonios, 2020, TICO 19 TRANSLATION
   Anvita Abbi, 2012, LANGUAGES INDIA INDI
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bahdanau D., 2015, P 3 INT C LEARN REPR
   Barrault L, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P1
   Barro L, 2021, PLATELETS, V32, P153, DOI 10.1080/09537104.2020.1849602
   Barry, 2020, PMINDIA COLLECTION P
   Bengio Yoshua., 2009, P INT C MACH LEARN, DOI 10.1145/1553374.1553380
   Bojar Ondrej, 2014, P 9 WORKSH STAT MACH, P12, DOI DOI 10.3115/V1/W14-3302
   Christodouloupoulos C, 2015, LANG RESOUR EVAL, V49, P375, DOI 10.1007/s10579-014-9287-y
   Dabre Raj, 2017, P 31 PAC AS C LANG I, P282
   El-Kishky A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5960
   EMENEAU MB, 1956, LANGUAGE, V32, P3, DOI 10.2307/410649
   Fangxiaoyu Feng, 2020, LANGUAGE AGNOSTIC BE
   Freitag M., 2020, P 5 C MACH TRANSL, P550
   Gonzales A.R., 2020, P 5 C MACHINE TRANSL, P528
   Goyal N, 2021, Arxiv, DOI arXiv:2106.03193
   Goyal Vikrant., 2020, P 5 C MACHINE TRANSL, P202
   Guo RQ, 2020, PR MACH LEARN RES, V119
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6098
   Holger, 2019, WIKIMATRIX MINING 13
   Holger, 2020, CCMATRIX MINING BILL, DOI [10.18653/v1/2021.acl-long.507, DOI 10.18653/V1/2021.ACL-LONG.507]
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Johnson J, 2017, Arxiv, DOI [arXiv:1702.08734, 10.48550/arXiv.1702.08734, 10.48550/ARXIV.1702.08734]
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Junczys-Dowmunt M., 2018, P 3 C MACHINE TRANSL, P888
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, P4948
   Kocmi T, 2018, P 3 C MACH TRANSL RE, P244, DOI DOI 10.18653/V1/W18-6325
   Koehn P., 2017, WMT, P28
   Kreutzer J, 2022, Arxiv, DOI arXiv:2103.12028
   Linting, 2021, MT5 MASSIVELY MULTIL
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P923
   Loganathan, 2012, P WORKSHOP MACHINE T, P113
   Nakaike T, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (IEEE ICBC), DOI 10.1109/icbc48266.2020.9169454
   Nakazawa T, 2021, WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION, P1
   Naveen Arivazhagan, 2019, MASSIVELY MULTILINGU
   Nguyen Toan Q., 2017, INT JOINT C NATURAL
   Ortiz Suarez P.J., 2019, P WORKSHOP CHALLENGE, DOI [DOI 10.14618/IDS-PUB-9021, 10.14618/IDS-PUB-9021]
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48
   Parida Shantipriya, 2020, P WILDRE5 5 WORKSHOP, P14
   Philip J, 2021, CODS-COMAD 2021: PROCEEDINGS OF THE 3RD ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA (8TH ACM IKDD CODS & 26TH COMAD), P178, DOI 10.1145/3430984.3431026
   Post M., 2012, P 7 WORKSHOP STAT MA, P401
   Reimers N, 2020, Arxiv, DOI [arXiv:2004.09813, DOI 10.48550/ARXIV.2004.09813]
   Riza Hammam, 2016, 2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA), P1, DOI 10.1109/ICSDA.2016.7918974
   Schwenk H, 2020, Arxiv, DOI arXiv:1911.04944
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sennrich Rico, 2011, P 18 NORDIC C COMPUT, P175
   Shah P., 2019, 2 INT C ADV COMP COM, P1
   Subbarao Karumuri V., 2012, S ASIAN LANGUAGES SY, P263
   Subramanya SJ, 2019, ADV NEUR IN, V32
   Tahmid, 2020, NOT LOW RESOURCE ANY, DOI [10.18653/v1/2020.emnlp-main.207, DOI 10.18653/V1/2020.EMNLP-MAIN.207]
   Tan X, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P963
   Thompson B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1342
   Tiedemann J., 2020, P 22 ANN CONFERENEC
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Vaswani A., 2017, ARXIV, V30, P5998
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Yuqing, 2020, MULTILINGUAL TRANSLA
NR 65
TC 15
Z9 15
U1 1
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD FEB 9
PY 2022
VL 10
BP 145
EP 162
DI 10.1162/tacl_a_00452
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 8K9NR
UT WOS:000923420100003
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Tan, M
   Zhou, WL
   Zheng, L
   Wang, SJ
AF Tan, Ming
   Zhou, Wenli
   Zheng, Lei
   Wang, Shaojun
TI A Scalable Distributed Syntactic, Semantic, and Lexical Language Model
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID MAXIMUM-ENTROPY APPROACH; INFORMATION
AB This paper presents an attempt at building a large scale distributed composite language model that is formed by seamlessly integrating an n-gram model, a structured language model, and probabilistic latent semantic analysis under a directed Markov random field paradigm to simultaneously account for local word lexical information, mid-range sentence syntactic structure, and long-span document semantic content. The composite language model has been trained by performing a convergent N-best list approximate EM algorithm and a follow-up EM algorithm to improve word prediction power on corpora with up to a billion tokens and stored on a supercomputer. The large scale distributed composite language model gives drastic perplexity reduction over n-grams and achieves significantly better translation quality measured by the Bleu score and "readability" of translations when applied to the task of re-ranking the N-best list from a state-of-the-art parsing-based machine translation system.
C1 [Tan, Ming; Zhou, Wenli; Zheng, Lei; Wang, Shaojun] Wright State Univ, Knoe Sis Ctr, Dayton, OH 45435 USA.
   [Tan, Ming; Zhou, Wenli; Wang, Shaojun] Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.
C3 University System of Ohio; Wright State University Dayton; University
   System of Ohio; Wright State University Dayton
RP Tan, M (通讯作者)，Wright State Univ, Knoe Sis Ctr, Dayton, OH 45435 USA.
EM tan.6@wright.edu; zhou.23@wright.edu; lei.zheng@wright.edu;
   shaojun.wang@wright.edu
FU National Science Foundation [IIS RI-small 0812483]; Google; Air Force
   Office of Scientific Research [FA9550-10-1-0335]; Div Of Information &
   Intelligent Systems; Direct For Computer & Info Scie & Enginr [1218863]
   Funding Source: National Science Foundation
FX We would like to dedicate this work to the memory of Fred Jelinek, who
   passed away while we were finalizing this manuscript. Fred Jelinek laid
   the foundation for modern speech recognition and text translation
   technology. His work has greatly influenced us. This research is
   supported by the National Science Foundation under grant IIS RI-small
   0812483, a Google research award, and Air Force Office of Scientific
   Research under grant FA9550-10-1-0335. We would like to thank the Ohio
   Supercomputer Center for an allocation of computing time to make this
   research possible; Ciprian Chelba for providing the SLM code, answering
   many questions regarding SLM, and consulting on various aspects of the
   work; Ying Zhang and Philip Resnik for providing the 1,000-best list
   from Hiero for re-ranking in machine translation; Peng Xu for suggesting
   to look at the conditional probability of a word given its document
   history to make the perplexity result much more convincing. Finally we
   would also like to thank the reviewers, who made a number of invaluable
   suggestions about the writing of the paper and pointed out many
   weaknesses in our original manuscript.
CR Aho A. V., 1972, THEORY PARSING TRANS, V1
   Amari S-I., 2000, TRANSLATIONS MATH MO, Vvol 191
   [Anonymous], 1998, STAT METHODS SPEECH
   [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], 2006, PROC 23 INT C MACH L
   [Anonymous], [No title captured]
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   [Anonymous], 2010, P NAACL HLT 2010 DEM
   [Anonymous], 1999, P EUR C SPEECH COMM
   [Anonymous], 2003, HLT NAACL 2003 HUMAN
   [Anonymous], 2010, DATA INTENSIVE TEXT
   Bahl L, 1977, 94 M AC SOC AM MI S1, V62, pS63
   BARRON AR, 1991, ANN STAT, V19, P1347, DOI 10.1214/aos/1176348252
   Bellegarda J., 2001, TEXT SPEECH LANGUAGE, V17, P101
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   Bellegarda JR, 2004, SPEECH COMMUN, V42, P93, DOI 10.1016/j.specom.2003.08.002
   Benedí JM, 2005, COMPUT SPEECH LANG, V19, P249, DOI 10.1016/j.csl.2004.09.001
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Bilmes J. A., 2003, P C N AM CHAPT ASS C, P4, DOI DOI 10.3115/1073483.1073485
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Charniak E, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P116
   Charniak E., 2003, P MT SUMM 9 NEW ORL, P40
   Chelba, 1998, P 36 ANN M ASS COMP, V1, P225
   Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147
   Chelba C., 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), P127, DOI 10.1109/SLT.2010.5700834
   Chelba C, 2000, THESIS J HOPKINS U B
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chiang D, 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Della Pietra S., 1994, Grammatical Inference and Applications. Second International Colloquium, ICGI-94 Proceedings, P78
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Emami A, 2007, INT CONF ACOUST SPEE, P37
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36
   Hastie TJ., 2009, ELEMENTS STAT LEARNI, V2nd ed.
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jelinek F, 2004, IMA VOL MATH APPL, V138, P37
   Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P381
   Jelinek F., 1991, EUROSPEECH 91. 2nd European Conference on Speech Communication and Technology Proceedings, P1037
   Jelinek F, 1999, 6 EUR C SPEECH COMM
   Jelinek F, 2009, COMPUT LINGUIST, V35, P483, DOI 10.1162/coli.2009.35.4.35401
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Khudanpur S, 2000, COMPUT SPEECH LANG, V14, P355, DOI 10.1006/csla.2000.0149
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X
   Lau R., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P45, DOI 10.1109/ICASSP.1993.319225
   Lauritzen SL., 1996, GRAPH MODELS
   Lavie A, 2006, MINDS WORKSH MACH TR
   Mark K, 1996, IMAGE MODELS THEIR S, P131
   MCALLESTER D, 2004, P 20 C UNC ART INT U, P382
   Michele Banko, 2001, P 1 INT C HUM LANG T, P1, DOI [10.3115/1072133.1072204, DOI 10.3115/1072133.1072204]
   Norvig, 2010, MODERN APPROACH
   Norvig P, 2008, ACM 17 C INF KNOWL M
   Och F, 2005, STAT MACHINE TRANSLA
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pereira F, 2000, PHILOS T ROY SOC A, V358, P1239, DOI 10.1098/rsta.2000.0583
   Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159
   Rosenfeld R, 2000, PHILOS T R SOC A, V358, P1311, DOI 10.1098/rsta.2000.0588
   Saul L, 1997, P 2 C EMPIRICAL METH, P81
   Teh Y. W., 2010, BAYESIAN NONPARAMETR, P158, DOI DOI 10.1017/CBO9780511802478.006
   Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985
   Van Uytsel DH, 2005, COMPUT SPEECH LANG, V19, P171, DOI 10.1016/j.csl.2004.05.009
   Vapnik V, 1998, NEW YORK
   Wang S, 2009, CONSISTENCY GE UNPUB
   Wang S, 2012, ACM T KNOWL IN PRESS
   Wang S, 2005, 22 INT C MACH LEARN, P953
   Wang SJ, 2006, LECT NOTES ARTIF INT, V4201, P97
   Wang SJ, 2005, MACH LEARN, V60, P229, DOI 10.1007/s10994-005-0928-7
   Wang W, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P238
   WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060
   Yamada K, 2001, P 39 ANN C ASS COMP, P1067
   Zangwill WI., 1969, NONLINEAR PROGRAMMIN
   Zhang Y., 2006, P 2006 C EMP METH NA, P216
   Zhang Y, 2008, THESIS CARNEGIE MELL
   Zhang Y, 2011, HDB NATURAL LANGUAGE, P252
NR 82
TC 2
Z9 2
U1 0
U2 15
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2012
VL 38
IS 3
BP 631
EP 671
DI 10.1162/COLI_a_00107
PG 41
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 996JW
UT WOS:000308083100007
OA Bronze, Green Published
DA 2023-11-10
ER

PT J
AU Ma, PC
   Petridis, S
   Pantic, M
AF Ma, Pingchuan
   Petridis, Stavros
   Pantic, Maja
TI Visual speech recognition for multiple languages in the wild
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID AUTOMATIC RECOGNITION; LIPS
AB Visual speech recognition (VSR) aims to recognize the content of speech based on lip movements, without relying on the audio stream. Advances in deep learning and the availability of large audio-visual datasets have led to the development of much more accurate and robust VSR models than ever before. However, these advances are usually due to the larger training sets rather than the model design. Here we demonstrate that designing better models is equally as important as using larger training sets. We propose the addition of prediction-based auxiliary tasks to a VSR model, and highlight the importance of hyperparameter optimization and appropriate data augmentations. We show that such a model works for different languages and outperforms all previous methods trained on publicly available datasets by a large margin. It even outperforms models that were trained on non-publicly available datasets containing up to to 21 times more data. We show, furthermore, that using additional training data, even in other languages or with automatically generated transcriptions, results in further improvement.
   Recognition of speech from lip movements is still a challenging problem and much effort is concentrated on the English language. Ma et al. have used auxiliary tasks to train a model such that it works for a range of different languages, including Mandarin, Spanish, Italian, French and Portuguese.
C1 [Ma, Pingchuan; Petridis, Stavros; Pantic, Maja] Imperial Coll London, London, England.
   [Petridis, Stavros; Pantic, Maja] Meta AI, London, England.
C3 Imperial College London
RP Ma, PC (通讯作者)，Imperial Coll London, London, England.
EM pingchuan.ma16@imperial.ac.uk
OI Ma, Pingchuan/0000-0003-3752-0803
CR Afouras T., 2018, PREPRINT
   Afouras T, 2020, INT CONF ACOUST SPEE, P2143, DOI [10.1109/ICASSP40776.2020.9054253, 10.1109/icassp40776.2020.9054253]
   Afouras T, 2018, INTERSPEECH, P3244
   Afouras T, 2022, IEEE T PATTERN ANAL, V44, P8717, DOI 10.1109/TPAMI.2018.2889052
   [Anonymous], 2018, NEW YORK TIMES 1022
   [Anonymous], 2021, FACEBOOK
   Assael Y., 2016, PREPRINT
   Bear HL, 2014, IEEE IMAGE PROC, P1371, DOI 10.1109/ICIP.2014.7025274
   Bicevskis Katie, 2016, Can Acoust, V44, P17
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Cheng SY, 2020, INT CONF ACOUST SPEE, P4357, DOI [10.1109/icassp40776.2020.9054384, 10.1109/ICASSP40776.2020.9054384]
   Chung JS, 2020, INTERSPEECH, P299, DOI 10.21437/Interspeech.2020-2337
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   Crawford S., 2019, WIRED 1216
   Denby B, 2010, SPEECH COMMUN, V52, P270, DOI 10.1016/j.specom.2009.08.002
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dungan L, 2018, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2018.8451754
   Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479
   Ephrat A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201357
   Feathers, 2021, TECH CO ARE TRAINING
   Flynn S., 2020, INNOVATION TECH 1118
   Geirhos R, 2019, PROC 7 INT C LEARNIN
   Greene J., 2020, WASHINGTON POST 0611
   Gulati A, 2020, INTERSPEECH, P5036, DOI 10.21437/Interspeech.2020-3015
   Haliassos A, 2021, PROC CVPR IEEE, P5037, DOI 10.1109/CVPR46437.2021.00500
   Heracleous P, 2013, COMPUT SPEECH LANG, V27, P288, DOI 10.1016/j.csl.2012.06.003
   Kim YJ, 2021, INTERSPEECH, P3675, DOI 10.21437/Interspeech.2021-2041
   Kingma D. P., 2014, C TRACK P
   Lee J, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6224, DOI 10.1109/ICASSP39728.2021.9414594
   Liopa, LIOPA
   Liu CX, 2021, IEEE W SP LANG TECH, P172, DOI 10.1109/SLT48900.2021.9383548
   Ma P., 2022, MPC001 VISUAL SPEECH, DOI [10.5281/zenodo.7065080, DOI 10.5281/ZENODO.7065080]
   Ma PC, 2021, INTERSPEECH, P3011, DOI 10.21437/Interspeech.2021-1360
   Ma PC, 2019, INTERSPEECH, P4090, DOI 10.21437/Interspeech.2019-2726
   Ma PC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7608, DOI 10.1109/ICASSP39728.2021.9415063
   Ma PC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7613, DOI 10.1109/ICASSP39728.2021.9414567
   Makino T, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P905, DOI [10.1109/asru46091.2019.9004036, 10.1109/ASRU46091.2019.9004036]
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Metz R., 2021, CNN 0518
   Mira R, 2023, IEEE T CYBERNETICS, V53, P3454, DOI 10.1109/TCYB.2022.3162495
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Pascual S, 2019, INTERSPEECH, P161, DOI 10.21437/Interspeech.2019-2605
   Petridis S., 2017, PROC 28 BRIT MACHINE, DOI [10.5244/C.31.161, DOI 10.5244/C.31.161]
   Petridis S, 2018, IEEE W SP LANG TECH, P513, DOI 10.1109/SLT.2018.8639643
   Petridis S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6219, DOI 10.1109/ICASSP.2018.8461596
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Prajwal K. R., 2020, P IEEE CVF C COMP VI, P13796
   Ren SC, 2021, PROC CVPR IEEE, P13320, DOI 10.1109/CVPR46437.2021.01312
   Salesky E, 2021, INTERSPEECH, P3655, DOI 10.21437/Interspeech.2021-11
   Serdyuk D, 2022, INTERSPEECH, P2833, DOI 10.21437/Interspeech.2022-10920
   Serdyuk D, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P796, DOI 10.1109/ASRU51503.2021.9688191
   Shihui Ma, 2020, 2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC). Proceedings, P78, DOI 10.1109/DSC50466.2020.00020
   Shillingford B, 2019, INTERSPEECH, P4135, DOI 10.21437/Interspeech.2019-1669
   Shukla A., 2020, PROC WORKSHOP SELF S
   Simko J, 2016, J ACOUST SOC AM, V139, P151, DOI 10.1121/1.4939495
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sterpu G, 2020, IEEE-ACM T AUDIO SPE, V28, P1052, DOI 10.1109/TASLP.2020.2980436
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Toshniwal S, 2017, INTERSPEECH, P3532, DOI 10.21437/Interspeech.2017-1118
   Valk J, 2021, IEEE W SP LANG TECH, P652, DOI 10.1109/SLT48900.2021.9383459
   Wand M, 2017, INTERSPEECH, P3662, DOI 10.21437/Interspeech.2017-421
   Watanabe S, 2018, INTERSPEECH, P2207, DOI 10.21437/Interspeech.2018-1456
   Yoshimura T, 2020, INT CONF ACOUST SPEE, P6999, DOI [10.1109/ICASSP40776.2020.9054358, 10.1109/icassp40776.2020.9054358]
   Yu JW, 2020, INT CONF ACOUST SPEE, P6984, DOI [10.1109/ICASSP40776.2020.9054127, 10.1109/icassp40776.2020.9054127]
   Yu WT, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3430, DOI 10.1109/ICASSP39728.2021.9414553
   Zadeh A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1801, DOI 10.18653/v1/2020.emnlp-main.141
   Zhang XB, 2019, AAAI CONF ARTIF INTE, P9211
   Zhao Y, 2020, AAAI CONF ARTIF INTE, V34, P6917
   Zhao Ya, 2019, P ACM MULTIMEDIA ASI
NR 69
TC 6
Z9 7
U1 4
U2 9
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD NOV
PY 2022
VL 4
IS 11
BP 930
EP 939
DI 10.1038/s42256-022-00550-z
EA OCT 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6H3DZ
UT WOS:000871286200001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Li, R
   Liu, C
   Jiang, DZ
AF Li, Rui
   Liu, Cheng
   Jiang, Dazhi
TI Efficient dynamic feature adaptation for cross language sentiment
   analysis with biased adversarial training
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Pre-trained language model; Cross-language understanding; Sentiment
   analysis; Efficient domain adaptation; Adversarial training
AB Fine-tuning a large multi-lingual pretrained language model demonstrates impressive results in crosslanguage understanding. However, it still suffers when the training and test data have different distributions owing to various languages and domains. On one hand, annotating target data for different languages or domains is time-consuming or infeasible. On the other hand, fine-tuning a large language model often incurs high computational costs. In this paper, we aim to develop an efficient and effective adaptation framework for cross-language sentiment analysis based on a fixed pretrained multi-lingual model. Specifically, we propose a Dynamic Feature Adaptation (DFA) module to fully leverage the features from different layers of the pretrained model such that its large backbone is not involved during adaptation training. Furthermore, we observe that traditional adversarial domain adaptation training could compromise the discriminative information of the model by pushing source and target features towards each other. The source features obtained with supervised training preserved the discriminability of the model, which should be less affected. Therefore, we propose a novel Biased Adversarial Training (BAT) method, that encourages only the target features towards source features. Extensive experimental results on various cross-lingual and cross-lingual-and-domain sentiment analysis tasks demonstrate the superiority of the proposed framework. Additionally, several ablation studies are conducted to validate the effectiveness of each proposed module. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Li, Rui; Liu, Cheng; Jiang, Dazhi] Shantou Univ, Dept Comp Sci, Shantou 515063, Guangdong, Peoples R China.
C3 Shantou University
RP Li, R (通讯作者)，Shantou Univ, Dept Comp Sci, Shantou 515063, Guangdong, Peoples R China.
EM ruili@stu.edu.cn; chengliu10@gmail.com; dzjiang@stu.edu.cn
FU National Natural Science Foundation of China [62106136]; Natural Science
   Foundation of Guangdong Province, China [2022A1515010434]; Shantou
   University, China [NTF20007, NTF22012]
FX star This work was supported in part by National Natural Science
   Foundation of China (Project No. 62106136) , in part by the Natural
   Science Foundation of Guangdong Province, China (Project No.
   2022A1515010434) , in part by Shantou University, China under Project
   NTF20007 and Project NTF22012. *
CR Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Benedetto F, 2016, STUD COMPUT INTELL, V639, P341, DOI 10.1007/978-3-319-30319-2_14
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Cambria E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3829
   Chen CQ, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107982
   Chen ST, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2022.109271
   Chen X., 2018, T ASSOC COMPUT LING, V6, P557, DOI DOI 10.1162/TACL_A_00039
   Chen YM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9125
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Dang NC, 2020, Arxiv, DOI arXiv:2006.03541
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du CN, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4019
   Fu YP, 2022, NEUROCOMPUTING, V494, P56, DOI 10.1016/j.neucom.2022.04.092
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He K, 2023, IEEE T AFFECT COMPUT, V14, P1731, DOI 10.1109/TAFFC.2022.3202831
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3467
   Jianfei Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P589, DOI 10.1007/978-3-030-58586-0_35
   Kingma D. P., 2017, PROC 3 INT C LEARN R, DOI DOI 10.48550/ARXIV.1412.6980
   Kundu JN, 2022, PR MACH LEARN RES
   Li B, 2021, PROC CVPR IEEE, P1104, DOI 10.1109/CVPR46437.2021.00116
   Li JC, 2018, AAAI CONF ARTIF INTE, P5213
   Li JT, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3672
   Li R., 2022, P 29 INT C COMP LING, P6934
   Li YS, 2021, PROC CVPR IEEE, P10993, DOI 10.1109/CVPR46437.2021.01085
   Liang X, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.108982
   Liu C, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3377, DOI 10.1145/3394486.3403390
   Liu H., 2019, INT C MACH LEARN, P4013
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685
   Mao R, 2023, IEEE T AFFECT COMPUT, V14, P1743, DOI 10.1109/TAFFC.2022.3204972
   Mikolov Tomas, 2013, INT C LEARN REPR
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Prettenhofer P, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1118
   Radford Alec, 2016, ICLR, DOI DOI 10.48550/ARXIV.1511.06434
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tian Q, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108903
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Yequan, 2016, P 2016 C EMP METH NA, P606, DOI [DOI 10.18653/V1/D16-1058, 10.18653/v1/D16-1058]
   Wilson G, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3400066
   Yang B, 2019, ADV NEUR IN, V32
   Yang ZL, 2019, ADV NEUR IN, V32
   Ye H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7386
   Yi CA, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.108831
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Zaheer M., 2020, ADV NEUR IN, V33
   Zellinger W., 2017, ARXIV170208811, P1
   Zhang H., 2018, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang SS, 2022, Arxiv, DOI [arXiv:2205.01068, DOI 10.48550/ARXIV.2205.01068]
   Zhao CJ, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105254
   Zhou Q, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106606
NR 56
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 4
PY 2023
VL 279
AR 110957
DI 10.1016/j.knosys.2023.110957
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T5XB2
UT WOS:001078705700001
DA 2023-11-10
ER

PT J
AU Oh, BD
   Schuler, W
AF Oh, Byung-Doh
   Schuler, William
TI Why Does Surprisal From Larger Transformer-Based Language Models Provide
   a Poorer Fit to Human Reading Times?
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID NAMES
AB This work presents a linguistic analysis into why larger Transformer-based pre-trained language models with more parameters and lower perplexity nonetheless yield surprisal estimates that are less predictive of human reading times. First, regression analyses show a strictly monotonic, positive log-linear relationship between perplexity and fit to reading times for the more recently released five GPT-Neo variants and eight OPT variants on two separate datasets, replicating earlier results limited to just GPT-2 (Oh et al., 2022). Subsequently, analysis of residual errors reveals a systematic deviation of the larger variants, such as underpredicting reading times of named entities and making compensatory overpredictions for reading times of function words such as modals and conjunctions. These results suggest that the propensity of larger Transformer-based models to 'memorize' sequences during training makes their surprisal estimates diverge from humanlike expectations, which warrants caution in using pre-trained language models to study human language processing.
C1 [Oh, Byung-Doh; Schuler, William] Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Oh, BD (通讯作者)，Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
EM oh.531@osu.edu; schuler.77@osu.edu
FU National Science Foundation [1816891]; Direct For Computer & Info Scie &
   Enginr; Div Of Information & Intelligent Systems [1816891] Funding
   Source: National Science Foundation
FX We thank our TACL action editor and the reviewers for their helpful
   comments. This work was supported by the National Science Foundation
   grant #1816891. All views expressed are those of the authors and do not
   necessarily reflect the views of the National Science Foundation.
CR Aran Wang, 2021, GPTJ6B
   Arehalli Suhas., 2022, P 26 C COMP NAT LANG, P301
   Aurnhammer Christoph., 2019, P 41 ANN M COGNITIVE, P112
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Black S, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P95
   Black Sid, 2021, Zenodo
   Byung-Doh Oh., 2022, P 2022 C EMPIRICAL M, P9324
   Carlini N, 2022, Arxiv, DOI arXiv:2202.07646
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Clark Christian., 2022, 35 ANN C HUM SENT PR
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008
   Devlin J., NAACL HLT, P4171, DOI 10.18653/v1/N19-1423
   Dyer C., 2016, P 2016 C N AM CHAPT, P199, DOI [10.18653/v1/N16-1024, DOI 10.18653/V1/N16-1024]
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844
   Futrell R, 2021, LANG RESOUR EVAL, V55, P63, DOI 10.1007/s10579-020-09503-7
   Gibson E, 2000, IMAGE, LANGUAGE, BRAIN, P95
   Goodkind A., 2018, P 8 WORKSHOP COGNITI, P10, DOI DOI 10.18653/V1/W18-0102
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hahn M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2122602119
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159
   Hale J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2727
   Hao Yiding, 2020, PROC WORKSHOP COGNIT, P75
   Hollenstein N, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P141
   Johnson-Laird P. N., 1983, MENTAL MODELS COGNIT
   Kennedy A., 2003, P 12 EUROPEAN C EYE
   Kuribayashi T., 2021, P 59 ANN M ASS COMPU, DOI [10.18653/v1/2021.acl-long.405, DOI 10.18653/V1/2021.ACL-LONG.405]
   Kuribayashi Tatsuki., 2022, P 2022 C EMPIRICAL M
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Lewis RL, 2006, TRENDS COGN SCI, V10, P447, DOI 10.1016/j.tics.2006.08.007
   Merkx D., 2021, P WORKSH COGN MOD CO, P12, DOI DOI 10.18653/V1/2021.CMCL-1.2
   Nelson Elhage Neel, 2021, MATH FRAMEWORK TRANS
   Nguyen Luan., 2012, P 24 INT C COMPUTATI, P2125
   Oh BD, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.777963
   Oh BD, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3746
   Proverbio AM, 2001, NEUROPSYCHOLOGIA, V39, P815, DOI 10.1016/S0028-3932(01)00003-3
   Radford A., 2019, LANGUAGE MODELS ARE
   Ryu S.H., 2021, P WORKSH COGN MOD CO
   Ryu Soo Hyun., 2022, 35 ANN C HUM SENT PR
   Sanh V, 2019, ARXIV
   Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shain C, 2021, COGNITION, V215, DOI 10.1016/j.cognition.2021.104735
   Shain C, 2020, NEUROPSYCHOLOGIA, V138, DOI 10.1016/j.neuropsychologia.2019.107307
   Shain Cory., 2018, WORKSHOP LINGUISTIC
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013
   Thompson Alan D., 2022, LIFEARCHITECTAI REPO
   van Schijndel M, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12988
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2013, BRAIN LANG, V125, P118, DOI 10.1016/j.bandl.2013.01.006
   Wilcox Ethan Gotlieb., 2020, P 42 ANN M COGNITIVE, P1707
   Zhang SS, 2022, Arxiv, DOI [arXiv:2205.01068, DOI 10.48550/ARXIV.2205.01068]
NR 52
TC 0
Z9 0
U1 5
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 27
PY 2023
VL 11
BP 336
EP 350
DI 10.1162/tacl_a_00548
PG 15
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA C1JR6
UT WOS:000959570700002
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Deng, HL
   Zhang, L
   Wang, LT
AF Deng, Hongli
   Zhang, Lei
   Wang, Lituan
TI Global context-dependent recurrent neural network language model with
   sparse feature learning
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Recurrent neural network; Language model; Global context; Sparse
   feature; Deep learning
AB Recurrent neural network language models (RNNLMs) are an important type of language model. In recent years, context-dependent RNNLMs are the most widely used ones as they apply additional information summarized from other sequences to access the larger context. However, when the sequences are mutually independent or randomly shuffled, these models cannot learn useful additional information, resulting in no larger context taken into account. In order to ensure that the model can obtain more contextual information in any case, a new language model is proposed in this paper. It can capture the global context just by the words within the current sequences, incorporating all the preceding and following words of target, without resorting to additional information summarized from other sequences. This model includes two main modules: a recurrent global context module used for extracting the global contextual information of the target and a sparse feature learning module that learns the sparse features of all the possible output words to distinguish the target word from others at the output layer. The proposed model was tested on three language modeling tasks. Experimental results show that it improves the perplexity of the model, speeds up the convergence of the network and learns better word embeddings compared with other language models.
C1 [Deng, Hongli; Zhang, Lei; Wang, Lituan] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
   [Deng, Hongli] China West Normal Univ, Educ & Informat Technol Ctr, Nanchong 637002, Peoples R China.
C3 Sichuan University; China West Normal University
RP Zhang, L (通讯作者)，Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
EM leizhang@scu.edu.cn
FU Fok Ying Tung Education Foundation [151068]; National Natural Science
   Foundation of China [61332002]; Foundation for Youth Science and
   Technology Innovation Research Team of Sichuan Province [2016TD0018]
FX This work was supported by Fok Ying Tung Education Foundation (Grant
   151068); National Natural Science Foundation of China (Grants 61332002);
   and Foundation for Youth Science and Technology Innovation Research Team
   of Sichuan Province (Grants 2016TD0018).
CR [Anonymous], 2016, IEEE T CYBERN
   [Anonymous], P 49 ANN M ASS COMP
   [Anonymous], ARXIV151103729
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Brown PF., 1997, COMPUT LINGUIST, V18, P467
   Chelba C., 2013, ARXIV PREPRINT ARXIV
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Federico M, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P240, DOI 10.1109/ICSLP.1996.607087
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Graves A., 2013, ARXIV PREPRINT ARXIV
   Kim Y., 2015, ARXIV150806615
   Kneser R, 1995, IMPROVED BACKING OFF
   Lee H., 2008, ADV NEURAL INFORM PR, P873
   Liu X, 2015, INT CONF ACOUST SPEE, P5406, DOI 10.1109/ICASSP.2015.7179004
   Mahoney Matt, 2009, LARGE TEXT COMPRESSI
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mikolov Tomas, 2013, INT C LEARN REPR
   Niesler TR, 1996, INT CONF ACOUST SPEE, P164, DOI 10.1109/ICASSP.1996.540316
   Pascanu R, 2013, CONSTRUCT DEEP RECUR
   Saxe Andrew M, 2013, ARXIV13126120
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   T.D. Team, 2016, THEANO PYTHON FRAMEW
   Toma M, 2012, THESIS
   Wu, 2016, ARXIV160202410
   Yamamoto H., 2003, Systems and Computers in Japan, V34, P108, DOI 10.1002/scj.1210
   Zaremba Wojciech, 2014, ARXIV14092329
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang S., 2015, ARXIV151002693
   Zhang SL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P495
   Zhen L., 2016, IEEE T NEURAL NETWOR, V99, P1
NR 37
TC 8
Z9 8
U1 1
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD FEB
PY 2019
VL 31
SU 2
BP 999
EP 1011
DI 10.1007/s00521-017-3065-x
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HT7TB
UT WOS:000464766200026
DA 2023-11-10
ER

PT J
AU Wu, ZF
   Merrill, W
   Peng, H
   Beltagy, I
   Smith, NA
AF Wu, Zhaofeng
   Merrill, William
   Peng, Hao
   Beltagy, Iz
   Smith, Noah A. A.
TI Transparency Helps Reveal When Language Models Learn Meaning
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Many current NLP systems are built from language models trained to optimize unsupervised objectives on large amounts of raw text. Under what conditions might such a procedure acquire meaning? Our systematic experiments with synthetic data reveal that, with languages where all expressions have context-independent denotations (i.e., languages with strong transparency), both autoregressive and masked language models successfully learn to emulate semantic relations between expressions. However, when denotations are changed to be context-dependent with the language otherwise unmodified, this ability degrades. Turning to natural language, our experiments with a specific phenomenon-referential opacity-add to the growing body of evidence that current language models do not represent natural language semantics well. We show this failure relates to the context-dependent nature of natural language form-meaning mappings.
C1 [Wu, Zhaofeng] MIT, Cambridge, MA 02139 USA.
   [Merrill, William] NYU, New York, NY USA.
   [Peng, Hao; Beltagy, Iz; Smith, Noah A. A.] Allen Inst Artificial Intelligence, Seattle, WA USA.
   [Smith, Noah A. A.] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA USA.
C3 Massachusetts Institute of Technology (MIT); New York University;
   University of Washington; University of Washington Seattle
RP Wu, ZF (通讯作者)，MIT, Cambridge, MA 02139 USA.
EM zfw@csail.mit.edu; willm@nyu.edu; haop@allenai.org; beltagy@allenai.org;
   noah@allenai.org
CR Alain G., 2017, 5 INT C LEARNING REP
   Alec Radford, 2019, LANGUAGE MODELS ARE
   Andreas Jacob., 2019, P INT C LEARNING REP
   [Anonymous], 2010, RECURSION HUMAN LANG, DOI DOI 10.1515/9783110219258.43
   [Anonymous], P C PROP ATT
   [Anonymous], 2011, INT SEMANTICS UNPUB
   Bender E. M., 2020, C SESSION P 58 ANN M
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Cao BX, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1860
   Carnap R., 1947, MEANING NECESSITY ST
   Chomsky N., 1995, LECT GOVT BINDING
   Chomsky Noam., 1983, SOME CONCEPTS CONSEQ
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Daniel S., 2018, THESIS CUNY
   Devlin J., 2018, ARXIV, V1, P4171
   Dufter P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2353
   Efron B., 1993, INTRO BOOTSTRAP, DOI DOI 10.1201/9780429246593
   Elsahar H, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3448
   Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   FISHER R. A., 1937, The design of experiments.
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5
   Frege Gottlob, 1892, Z PHILOS PHILOS KRIT
   Grice P., 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1163/9789004368811_003
   GROENENDIJK J, 1991, LINGUIST PHILOS, V14, P39, DOI 10.1007/BF00628304
   Gulordava K., 2018, P 2018 C N AM CHAPT, V1, P1195, DOI DOI 10.18653/V1/N18-1108
   Haviv A, 2022, Arxiv, DOI [arXiv:2203.16634, DOI 10.48550/ARXIV.2203.16634]
   Heim I., 1982, SEMANTICS DEFINITE I
   Heim Irene., 1998, SEMANTICS GENERATIVE
   Hewitt J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2733
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Kamp Hans., 1981, FORMAL METHODS STUDY, P277
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769
   Kearns Kate, 2011, SEMANTICS
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365
   Kripke Saul A., 1972, SEMANTICS NATURAL LA, P253
   Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813
   Li BH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9119
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI DOI 10.1353/LAN.2019.0015
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2171
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Loshchilov Ilya, 7 INT C LEARN REPR I
   Lyu Qing., 2022, P 2022 C N AM CHAPT, P5286, DOI [10.18653/v1/2022.naacl-main.388, DOI 10.18653/V1/2022.NAACL-MAIN.388]
   Merrill W, 2021, T ASSOC COMPUT LING, V9, P1047, DOI 10.1162/tacl_a_00412
   Pandia L, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1583
   Patel R., 2022, INT C LEARNING REPRE
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Poerner Nina, 2020, FINDINGS ASS COMPUTA, P803, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.71
   QUINE WV, 1956, J PHILOS, V53, P177, DOI 10.2307/2022451
   Ravichander A, 2020, P 9 JOINT C LEX COMP, P88
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Salmon Nathan, 1990, PROPOSITIONAL ATTITU, P215
   SHIEBER SM, 1985, LINGUIST PHILOS, V8, P333, DOI 10.1007/BF00630917
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222
   Soler AG, 2021, T ASSOC COMPUT LING, V9, P825, DOI 10.1162/tacl_a_00400
   Speaks J., 2021, STANFORD ENCY PHILOS
   Tanya Reinhart, 1976, SYNTACTIC DOMAIN ANA
   Tenney Ian., 2019, P INT C LEARNING REP
   Traylor A, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P158
   Voita E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4396
   Vulie I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7222
   Wu ZF, 2021, T ASSOC COMPUT LING, V9, P226, DOI 10.1162/tacl_a_00363
   Yu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4896
   Yu Lang, 2021, FINDINGS ASS COMPUTA, P2279
   Zhong Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5017
NR 68
TC 0
Z9 0
U1 2
U2 2
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 20
PY 2023
VL 11
BP 617
EP 634
DI 10.1162/tacl_a_00565
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA K7VI6
UT WOS:001018475800001
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Beliga, S
   Ipsic, I
   Martincic-Ipsic, S
AF Beliga, Slobodan
   Ipsic, Ivo
   Martincic-Ipsic, Sanda
TI Evaluation of Language Models over Croatian Newspaper Texts
SO INFORMATION TECHNOLOGY AND CONTROL
LA English
DT Article
DE Statistical language model; Natural language regularity; Word-based
   language model; Category-based language model; Brown algorithm; POS
   class; N-gram; Perplexity; Croatian corpora
ID SPEECH RECOGNITION; CORPUS
AB Statistical language modeling involves techniques and procedures that assign probabilities to word sequences or, said in other words, estimate the regularity of the language. This paper presents basic characteristics of statistical language models, reviews their use in the large set of speech and language applications, explains their formal definition and shows different types of language models. A detailed overview of n-gram and class-based models (as well as their combinations) is given chronologically, by type and complexity of models, and in aspect of their use in different NLP applications for different natural languages. The proposed experimental procedure compares three different types of statistical language models: n-gram models based on words, categorical models based on automatically determined categories and categorical models based on POS tags. In the paper, we propose a language model for contemporary Croatian texts, a procedure how to determine the best n-gram and the optimal number of categories, which leads to significant decrease of language model perplexity, estimated from the Croatian News Agency articles (HINA) corpus. Using different language models estimated from the HINA corpus, we show experimentally that models based on categories contribute to a better description of the natural language than those based on words. These findings of the proposed experiment are applicable, except for Croatian, for similar highly inflectional languages with rich morphology and non-mandatory sentence word order.
C1 [Beliga, Slobodan; Ipsic, Ivo; Martincic-Ipsic, Sanda] Univ Rijeka, Dept Informat, Radmile Matejcic 2, Rijeka 51000, Croatia.
C3 University of Rijeka
RP Beliga, S (通讯作者)，Univ Rijeka, Dept Informat, Radmile Matejcic 2, Rijeka 51000, Croatia.
EM sbeliga@inf.uniri.hr; ivoi@inf.uniri.hr; smarti@inf.uniri.hr
RI Martincic, Sanda/N-7971-2018; Beliga, Slobodan/A-1300-2016
OI Martincic, Sanda/0000-0002-1900-5333; Beliga,
   Slobodan/0000-0003-1407-6156; Ipsic, Ivo/0000-0002-2720-9002
FU University of Rijeka under the Language Networks project [13.13.2.2.07];
   University of Rijeka under Natural and Multimodal Man-Machine
   Communication project [13.13.1.3.04]
FX This work has been supported in part by the University of Rijeka under
   the Language Networks (13.13.2.2.07) and Natural and Multimodal
   Man-Machine Communication (13.13.1.3.04) projects.
CR AGic ZELJKo, 2013, P 4 BIENNIAL INT WOR, P48
   Al-Anzi FS, 2004, COMPUT HUMANITIES, V38, P469, DOI 10.1007/s10579-004-2323-6
   Allan J, 2003, ACM SIGIR FORUM, V37, P31
   [Anonymous], 1997, 5 EUR C SPEECH COMM
   [Anonymous], 1998, STAT METHODS SPEECH
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 1997, P EUROSPEECH 97
   [Anonymous], 1993, P EUROSPEECH
   [Anonymous], ADV SPEECH SIGNAL PR
   [Anonymous], 1997, PROC RIAO
   [Anonymous], STAT LANGUAGE MODELS
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   Baldwin Timothy, 2010, HUMAN LANGUAGE TECHN, P229
   Banko M., 2004, P HLT NAACL 2004 HLT, P1
   Beliga S, 2016, INT J SEMANT WEB INF, V12, P1, DOI 10.4018/IJSWIS.2016070101
   Beliga S, 2015, J INF ORGAN SCI, V39, P1
   Bidin S., 2014, P 9 LANG TECHN C INF, P95
   Bisazza A, 2014, P COLING 2014 25 INT, P1918
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Brychcin T., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P560, DOI 10.1109/IDAACS.2011.6072829
   Carter S, 2013, LANG RESOUR EVAL, V47, P195, DOI 10.1007/s10579-012-9195-y
   Cavnar William B, 1994, N GRAM BASED TEXT CA, V161175
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Dzikiene JK, 2014, INF TECHNOL CONTROL, V43, P321, DOI 10.5755/j01.itc.43.3.5871
   Erjavec T., 2003, P EACL 2003 WORKSH M, P25
   Geutner P., 1997, EUROSPEECH
   Giannakopoulos G., 2008, ACM T SPEECH LANGUAG, V5, p5:1, DOI 10.1145/1410358.1410359
   Herdagdelen A, 2013, LANG RESOUR EVAL, V47, P1127, DOI 10.1007/s10579-013-9227-2
   HLADEK D., 2012, J ELECT ELECT ENG, V5, P85
   Hopkins Johns, 2015, IWSLT INT WORKSHOP S, P180
   HOUVARDAS J, 2006, P 12 INT C ART INT, V4183, P77
   Jardino M., 1994, ICSLP 94. 1994 International Conference on Spoken Language Processing, P867
   Jurafsky Daniel, 1999, COMPUTATIONAL LINGUI
   Justo R, 2007, ADV INTEL SOFT COMPU, V45, P421
   Kilgarriff A, 2014, LANG RESOUR EVAL, V48, P121, DOI 10.1007/s10579-013-9251-2
   Kim SN, 2013, LANG RESOUR EVAL, V47, P723, DOI 10.1007/s10579-012-9210-3
   Kirchhoff K, 2006, COMPUT SPEECH LANG, V20, P589, DOI 10.1016/j.csl.2005.10.001
   Koo H, 2015, LANG RESOUR EVAL, V49, P355, DOI 10.1007/s10579-015-9296-5
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   LI H, 2007, P 45 ANN M ASS COMP, P120
   Liu F., 2009, P HUM LANG TECHN 200, P620
   Ljubesic N., MULTEXT E MORPHOSYNT
   Maltese G., 2001, P EUR C SPEECH COMM, P21
   Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152
   Manning C. D., 1999, FDN STAT NATURAL LAN, P164
   Manning CD, 2009, INTRO INFORM RETRIEV
   Markievicz I, 2015, INF TECHNOL CONTROL, V44, P155, DOI 10.5755/j01.itc.44.2.7322
   Martincic-Ipsic S, 2008, INFORMATICA-LITHUAN, V19, P227
   Martins B., 2005, P 2005 ACM S APPL CO, P764, DOI DOI 10.1145/1066677.1066852
   Mijic J., 2010, P 7 INT C FORM APPR, P59
   Momtazi S., 2009, P 18 ACM C INF KNOWL, P1911, DOI DOI 10.1145/1645953.1646263
   MOORE G, 2000, P ICSLP, P512
   Nacinovic L., 2009, INFUTURE2009 DIGITAL, P333
   Niesler T. R, 1996, CUEDFINFENGTR258
   Niesler T. R, 1996, CUEDFINFENGTR265
   Niesler TR, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P220, DOI 10.1109/ICSLP.1996.607081
   Niesler TR, 1997, THESIS
   Petrovic S., 2006, Journal of Computing and Information Technology - CIT, V14, P321, DOI 10.2498/cit.2006.04.08
   PINNIS MARCIS, 2012, P 10 C TERMINOLOGY K, P193
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   Samuelsson C, 1999, INT CONF ACOUST SPEE, P537, DOI 10.1109/ICASSP.1999.758181
   Sharma M., 2016, COMPREHENSIVE STUDY
   Song F, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P279, DOI 10.1145/312624.312698
   STOLCKE A, 1997, P EUROSPEECH, V5, P2779
   Sun J., 2002, P 19 INT C COMP LING, V1, P1
   Turan M, 2014, INF TECHNOL CONTROL, V43, P433, DOI 10.5755/j01.itc.43.4.7010
   Vaiciunas A, 2004, INFORMATICA-LITHUAN, V15, P565
   Wakita Y, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P530, DOI 10.1109/ICSLP.1996.607171
   Ward W., 1990, P DARPA SPEECH NAT L, P127
   Yokoyama T., 2003, IEEE P AC SPEECH SIG, V1
   Zaman S, 2014, INF TECHNOL CONTROL, V43, P371, DOI 10.5755/j01.itc.43.4.5980
NR 72
TC 0
Z9 0
U1 1
U2 11
PU KAUNAS UNIV TECHNOLOGY
PI KAUNAS
PA KAUNAS UNIV TECHNOL, DEPT ELECTRONICS ENGINEERING, STUDENTU STR 50,
   KAUNAS, LT-51368, LITHUANIA
SN 1392-124X
J9 INF TECHNOL CONTROL
JI Inf. Technol. Control
PY 2017
VL 46
IS 4
BP 425
EP 444
DI 10.5755/j01.itc.46.4.18367
PG 20
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA FQ4NI
UT WOS:000418333900001
OA Bronze
DA 2023-11-10
ER

PT S
AU Maucec, MS
   Kacic, Z
AF Maucec, MS
   Kacic, Z
BE Sojka, P
   Kopecek, I
   Pala, K
TI Topic-sensitive language modelling
SO TEXT, SPEECH AND DIALOGUE, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 3rd International Workshop on Text, Speech and Dialogue (TSD 2000)
CY SEP 13-16, 2000
CL BRNO, CZECH REPUBLIC
AB The paper proposes a new framework to construct topic-sensitive language models for large vocabulary speech recognition. Identifying a domain of discourse, a model appropriate for the current domain can be built. In our experiments, the target domain was represented with a piece of text. By using appropriate features, sub-corpus of a large collection of training text was extracted. Our feature selection process was especially suited to languages where words are formed by many different inflectional affixatation. All words with the same meaning (but different grammatical form) were collected in one cluster and represented as one feature. We used the heuristic word weighting classifier TFIDF (term frequency / inverse document frequency) to further shrink the feature vector. Final language model was built by interpolation of topic specific models and a general model. Experiments have been done by using English and Slovenian corpus.
C1 Univ Maribor, SI-2000 Maribor, Slovenia.
C3 University of Maribor
RP Maucec, MS (通讯作者)，Univ Maribor, Smetanova 17, SI-2000 Maribor, Slovenia.
CR DONNELLY PG, 1999, LANGUAGE MODELLING H
   Jelinek F., 1997, STAT METHODS SPEECH
   SEYMORE K, 1997, USING STORY TOPICS L
NR 3
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-41042-2
J9 LECT NOTES ARTIF INT
PY 2000
VL 1902
BP 253
EP 258
PG 6
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BS62J
UT WOS:000170595900043
DA 2023-11-10
ER

PT J
AU Wang, YC
   Wu, CK
   Tsai, RTH
AF Wang, Yu-Chun
   Wu, Chun-Kai
   Tsai, Richard Tzong-Han
TI Cross-language article linking with different knowledge bases using
   bilingual topic model and translation features
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Cross-language article linking; Link discovery; Bilingual topic model
AB Creating links among online encyclopedia articles in different languages is crucial in the construction and integration of large multilingual knowledge bases. Most research to date has focused on linking among different language versions of Wikipedia, yet other large online encyclopedias in a variety of languages exist. In this work, we present a cross-language article-linking method using a bilingual topic model and translation features based on an SVM model to link articles in English Wikipedia and Chinese Baidu Baike, the most widely used Wiki-like encyclopedia in China. To evaluate our approach, we compile data sets from Baidu Baike articles and their corresponding English Wikipedia articles. The evaluation results show that our approach achieves at most 0.8158 in MRR, outperforming the baseline system by 0.1328 (+19.44%) in MRR. Our method does not heavily depend on linguistic characteristics, and it can be easily extended to generate cross-language article links among different online encyclopedias in other languages. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Wang, Yu-Chun] Chunghwa Telecom, Telecommun Labs, Taipei, Taiwan.
   [Wu, Chun-Kai] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30013, Taiwan.
   [Tsai, Richard Tzong-Han] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
   [Tsai, Richard Tzong-Han] NTU IoX Ctr, Taipei, Taiwan.
C3 Chunghwa Telecom; National Tsing Hua University; National Central
   University
RP Tsai, RTH (通讯作者)，Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.; Tsai, RTH (通讯作者)，NTU IoX Ctr, Taipei, Taiwan.
EM ycwang@cht.com.tw; s102065512@m102.nthu.edu.tw; thtsai@csie.ncu.edu.tw
OI Tsai, Richard Tzong-Han/0000-0003-0513-107X
FU Ministry of Science and Technology of Taiwan [MOST
   104-2221-E-008-034-MY3]; National Taiwan University [NTU-105R104045];
   Intel Corporation; Delta Electronics
FX This research was supported in part by the Ministry of Science and
   Technology of Taiwan (MOST 104-2221-E-008-034-MY3), National Taiwan
   University (NTU-105R104045), Intel Corporation, and Delta Electronics.
CR [Anonymous], 2010, P 2010 TEXT AN C
   [Anonymous], 2009, PROBABILISTIC RELEVA
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Clarke J., 2012, P 6 TEXT AN C TAC 20
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fahrni A., 2012, P 6 TEXT AN C TAC 20, V1
   Guo Y, 2011, P 4 TEXT AN C TAC 20
   Hachey B, 2011, LECT NOTES COMPUT SC, V6997, P213, DOI 10.1007/978-3-642-24434-6_16
   Jiang M, 2014, NEW MEDIA SOC, V16, P212, DOI 10.1177/1461444813481196
   Lee T, 2013, P 52 ANN M ASS COMP, P631
   Lehmann J., 2014, SEMANT WEB, V1, P1
   Liao H.-T., 2013, P 9 INT S OP COLL, P27
   McNamee P., 2009, TEXT ANAL C, V17, P111
   McNamee Paul., 2011, P 5 INT JOINT C NATU, P255
   Miao Q., 2013, P TEXT AN C TAC 2013
   Nguyen D, 2009, LECT NOTES COMPUT SC, V5706, P58, DOI 10.1007/978-3-642-04447-2_6
   Oh Jong-Hoon, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P322, DOI 10.1109/WIIAT.2008.317
   Sorg P., 2008, P AAAI 2008 WORKSH W, P49
   Nguyen T, 2011, PROC VLDB ENDOW, V5, P133, DOI 10.14778/2078324.2078329
   Zhang T, 2013, P 23 INT JOINT C ART, P2218
   Zhang W., 2011, P TEXT AN C TAC 2011
NR 21
TC 6
Z9 7
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 1
PY 2016
VL 111
BP 228
EP 236
DI 10.1016/j.knosys.2016.08.015
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DY7TH
UT WOS:000385331700019
DA 2023-11-10
ER

PT J
AU Novotney, S
   Schwartz, R
   Khudanpur, S
AF Novotney, Scott
   Schwartz, Richard
   Khudanpur, Sanjeev
TI Getting more from automatic transcripts for semi-supervised language
   modeling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Language modeling; Automatic speech recognition; LVCSR; Low-resource
AB Many under-resourced languages such as Arabic diglossia or Hindi sub-dialects do not have sufficient in-domain text to build strong language models for use with automatic speech recognition (ASR). Semi-supervised language modeling uses a speech-to-text system to produce automatic transcripts from a large amount of in-domain audio typically to augment a small amount of manual transcripts. In contrast to the success of semi-supervised acoustic modeling, conventional language modeling techniques have provided only modest gains. This paper first explains the limitations of back-off language models due to their dependence on long-span n-grams, which are difficult to accurately estimate from automatic transcripts. From this analysis, we motivate a more robust use of the automatic counts as a prior over the estimated parameters of a log-linear language model. We demonstrate consistent gains for semi-supervised language models across a range of low-resource conditions. (C) 2015 Elsevier Ltd. All rights reserved.
C1 [Novotney, Scott; Schwartz, Richard] Raytheon BBN Technol, Cambridge, MA 02451 USA.
   [Khudanpur, Sanjeev] Johns Hopkins Univ, Baltimore, MD USA.
C3 Raytheon Technologies; Raytheon BBN Technologies; Johns Hopkins
   University
RP Novotney, S (通讯作者)，Raytheon BBN Technol, 10 Moulton St, Cambridge, MA 02451 USA.
EM snovotne@bbn.com; schwartz@bbn.com; khudanpur@jhu.edu
OI Khudanpur, Sanjeev/0000-0001-5976-0897
CR Alumae T., 2010, COMPUT LINGUIST, P301
   [Anonymous], 2004, LREC
   Bacchiani M, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P224
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BULYKO I, 2003, P HLT NAACL, P7
   Chen S. F, 1999, TECHNICAL REPORT
   Della Pietra S., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P633, DOI 10.1109/ICASSP.1992.225829
   Dikici E., 2014, 15 ANN C INT SPEECH, P2857
   Finkel J. R, 2009, P HUM LANG TECHN 200, P602, DOI DOI 10.3115/1620754.1620842
   Gillick L., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P532, DOI 10.1109/ICASSP.1989.266481
   Goodman J, 2001, INT CONF ACOUST SPEE, P561, DOI 10.1109/ICASSP.2001.940893
   Gretter R, 2001, INT CONF ACOUST SPEE, P557, DOI 10.1109/ICASSP.2001.940892
   Khudanpur S, 1999, INT CONF ACOUST SPEE, P553, DOI 10.1109/ICASSP.1999.758185
   Kimball O., 2004, P 2004 RICH TRANSCR
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Lau R., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P45, DOI 10.1109/ICASSP.1993.319225
   Ma J, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2374
   Nakano M., 2003, P 8 EUR C SPEECH COM, P417
   Novotney S., 2010, P ANN C N AM CHAPT A
   Novotney S, 2009, INT CONF ACOUST SPEE, P4297, DOI 10.1109/ICASSP.2009.4960579
   Prasad R., 2005, P INTERSPEECH, P1645
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003
   Sethy A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P25, DOI 10.1109/ASRU.2013.6707700
   Siu M.-H., 1997, P ANN C INT SPEECH C
   Tam Y.-C., 2011, P ANN C INT SPEECH C
   Wu J., 2000, ICSLP, V3, P114
   Xu PY, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P317, DOI 10.1109/ASRU.2009.5373401
NR 29
TC 5
Z9 5
U1 0
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR
PY 2016
VL 36
BP 93
EP 109
DI 10.1016/j.csl.2015.08.007
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CZ5DP
UT WOS:000367123000006
DA 2023-11-10
ER

PT J
AU Bertolami, R
   Bunke, H
AF Bertolami, Roman
   Bunke, Horst
TI INTEGRATION OF <i>n</i>-GRAM LANGUAGE MODELS IN MULTIPLE CLASSIFIER
   SYSTEMS FOR OFFLINE HANDWRITTEN TEXT LINE RECOGNITION
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Offline handwritten text line recognition; multiple classifier systems;
   language modeling
ID COMBINATION; FUSION
AB Current multiple classifier systems for unconstrained handwritten text recognition do not provide a straightforward way to utilize language model information. In this paper, we describe a generic method to integrate a statistical n-gram language model into the combination of multiple offline handwritten text line recognizers. The proposed method first builds a word transition network and then rescores this network with an n-gram language model. Experimental evaluation conducted on a large dataset of offline handwritten text lines shows that the proposed approach improves the recognition accuracy over a reference system as well as over the original combination method that does not include a language model.
C1 [Bertolami, Roman; Bunke, Horst] Univ Bern, Inst Comp Sci & Appl Math, CH-3012 Bern, Switzerland.
C3 University of Bern
RP Bertolami, R (通讯作者)，Univ Bern, Inst Comp Sci & Appl Math, Neubruckstr 10, CH-3012 Bern, Switzerland.
EM bertolam@iam.unibe.ch; bunke@iam.unibe.ch
FU Swiss National Science Foundation [200020-19124/1]
FX This research was supported by the Swiss National Science Foundation
   (Nr. 200020-19124/1). The authors thank Dr. Matthias Zimmermann for
   providing the statistical bigram language model.
CR [Anonymous], INT J DOC ANAL RECOG
   [Anonymous], 1979, DEP LINGUISTICS
   [Anonymous], P CORP LING CIT
   [Anonymous], READINGS SPEECH RECO, DOI 10.1016/B978-0-08-051584-7.50045-0
   Bauer L., 1993, MANUAL INFORM ACCOMP
   Bertolami R, 2005, PROC INT CONF DOC, P521, DOI 10.1109/ICDAR.2005.167
   Bertolami R, 2006, PATTERN RECOGN LETT, V27, P2005, DOI 10.1016/j.patrec.2006.06.002
   Brakensiek A, 2004, LECT NOTES COMPUT SC, V2956, P103
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Brown G., 2005, Information Fusion, V6, P5, DOI 10.1016/j.inffus.2004.04.004
   Burnard L., 2000, REFERENCE GUIDE BRIT
   CHEN SF, 1996, P 34 ANN M ASS COMP, P310, DOI DOI 10.3115/981863.981904
   Dengel A., 1997, HDB CHARACTER RECOGN, P227
   Fiscus JG, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P347, DOI 10.1109/ASRU.1997.659110
   Gader PD, 1996, PATTERN RECOGN LETT, V17, P577, DOI 10.1016/0167-8655(96)00021-9
   Goodman J. T., 2001, MSRTR200172
   Gunter S., 2003, International Journal on Document Analysis and Recognition, V5, P224, DOI 10.1007/s10032-002-0088-2
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Hopcroft J., 2007, ADDISON WESLEY SERIE, V3rd
   HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145
   Impedovo S., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P1, DOI 10.1142/S0218001491000041
   Johansson S., 1986, TAGGED LOB CORPUS US
   Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017
   Kim G, 1999, ADV HANDWRITING RECO, P163
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kuncheva L. I., 2014, COMBINING PATTERN CL, V2d, DOI DOI 10.1002/0471660264
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   MARTI UV, 2001, LNCS, V2096, P388
   Oliveira LS, 2006, INT J DOC ANAL RECOG, V8, P262, DOI 10.1007/s10032-005-0013-6
   PALLETT D, 1999, DARPA BROADC NEWS WO
   Pitrelli JF, 2006, INT J DOC ANAL RECOG, V8, P35, DOI 10.1007/s10032-005-0011-8
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raudys S, 2006, NEURAL NETWORKS, V19, P1506, DOI 10.1016/j.neunet.2006.01.018
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   SANCHIS A, 2000, ICPR, V3, P278
   SCHWENK H, 2000, ISCA ITRW WORKSH AUT, P47
   Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887
   SIRLANTZIS K, 2001, LNCS, V2096, P99
   Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Ye XY, 2002, PATTERN RECOGN LETT, V23, P381, DOI 10.1016/S0167-8655(01)00171-4
   Zeppenfeld T, 1997, INT CONF ACOUST SPEE, P1815, DOI 10.1109/ICASSP.1997.598889
   Zimmermann M, 2006, IEEE T PATTERN ANAL, V28, P818, DOI 10.1109/TPAMI.2006.103
   Zimmermann M, 2004, INT C PATT RECOG, P541, DOI 10.1109/ICPR.2004.1334297
   Zimmermann M, 2004, INT C PATT RECOG, P550, DOI 10.1109/ICPR.2004.1334301
NR 47
TC 3
Z9 3
U1 0
U2 4
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD NOV
PY 2008
VL 22
IS 7
BP 1301
EP 1321
DI 10.1142/S0218001408006855
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 396NM
UT WOS:000262598400002
DA 2023-11-10
ER

PT S
AU Kurimo, M
   Lagus, K
AF Kurimo, M
   Lagus, K
BE Dorronsoro, JR
TI An efficiently focusing large vocabulary language model
SO ARTIFICIAL NEURAL NETWORKS - ICANN 2002
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Artifical Neural Networks (ICANN 2002)
CY AUG 28-30, 2002
CL MADRID, SPAIN
SP Univ Autonoma Madrid, Neural Network Grp Escuela Tecn Superior Ingenier Informat, European Neural Networks Soc, Spain Minist Cienc Tecnol, Inst Ingenier Conocimiento, FET Program, European Commiss, IEEE Neural Network Council, Japanese Neural Network Soc, Asia Pacific Neural Assembly, IEEE NNC, Spanish RIG
AB Accurate statistical language models are needed, for example, for large vocabulary speech recognition. The construction of models that are computationally efficient and able to utilize long-term dependencies in the data is a challenging task. In this article we describe how a topical clustering obtained by ordered maps of document collections can be utilized for the construction of efficiently focusing statistical language models. Experiments on Finnish and English texts demonstrate that considerable improvements are obtained in perplexity compared to a general n-gram model and to manually classified topic categories. In the speech recognition task the recognition history and the current hypothesis can be utilized to focus the model towards the current discourse or topic, and then apply the focused model to re-rank the hypothesis.
C1 Helsinki Univ Technol, Neural Networks Res Ctr, FIN-02015 Helsinki, Finland.
C3 Aalto University
RP Kurimo, M (通讯作者)，Helsinki Univ Technol, Neural Networks Res Ctr, POB 5400, FIN-02015 Helsinki, Finland.
RI Kurimo, Mikko/F-6647-2012
CR Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   Clarkson P, 2001, COMPUT SPEECH LANG, V15, P39, DOI 10.1006/csla.2000.0156
   CLARKSON P, 1997, P EUR 97 RHOD GREEC, P2707
   Clarkson P., 1997, P IEEE INT C AC SPEE, P799
   GILDEA D, 1999, P EUROSPEECH, P2167
   IYER RM, 1999, IEEE T SPEECH AUDIO, V7
   Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729
   Kohonen T., 2001, SELF ORG MAPS
   LAGUS K, 2002, IN PRESS NEURAL PROC
   LAU R, 1993, P INT C AC SPEECH SI, P45
   SIIVOLA V, 2001, P EUR
NR 11
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-44074-7
J9 LECT NOTES COMPUT SC
PY 2002
VL 2415
BP 1068
EP 1073
PG 6
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BW28K
UT WOS:000181441900173
DA 2023-11-10
ER

PT J
AU Swaileh, W
   Soullard, Y
   Paquet, T
AF Swaileh, Wassim
   Soullard, Yann
   Paquet, Thierry
TI A unified multilingual handwriting recognition system using multigrams
   sub-lexical units
SO PATTERN RECOGNITION LETTERS
LA English
DT Article; Proceedings Paper
CT 18th Conference of the International-Graphonomics-Society (IGS)
CY JUN 18-21, 2017
CL Gaeta, ITALY
SP Int Graphon Soc
DE Sub-lexical units; Multilingual; Language model; Handwriting
   recognition; Multigrams
AB We address the design of a unified multilingual system for handwriting recognition. Most of multilingual systems rests on specialized models that are trained on a single language and one of them is selected at test time. While some recognition systems are based on a unified optical model, dealing with a unified language model remains a major issue, as traditional language models are generally trained on corpora composed of large word lexicons per language. Here, we bring a solution by considering language models based on sub-lexical units, called multigrams. Dealing with multigrams strongly reduces the lexicon size and thus decreases the language model complexity. This makes possible the design of an end-to-end unified multilingual recognition system where both a single optical model and a single language model are trained on all the languages. We discuss the impact of the language unification on each model and show that our system reaches state-of-the-art methods performance with a strong reduction of the complexity. (c) 2018 Elsevier B.V. All rights reserved.
C1 [Swaileh, Wassim; Soullard, Yann; Paquet, Thierry] Univ Rouen, LITIS Lab, EA 4108, Normandie Univ, Rouen, France.
C3 Universite de Rouen Normandie
RP Swaileh, W (通讯作者)，Univ Rouen, LITIS Lab, EA 4108, Normandie Univ, Rouen, France.
EM wassim.swaileh2@univ-rouen.fr
RI swaileh, wassim/L-2721-2019
OI swaileh, wassim/0000-0003-4314-6352
CR [Anonymous], 2002, HIDDEN SEMIMAR UNPUB
   [Anonymous], ARTIFICIAL NEURAL NE
   [Anonymous], THESIS
   [Anonymous], 2013, P 4 INT WORKSH MULT
   Barlas P, 2016, J IMAGING SCI TECHN, V60, DOI 10.2352/J.ImagingSci.Technol.2016.60.1.010407
   Bluche  T., 2017, P 13 INT C DOC AN RE, P13
   Bluche T., 2015, THESIS
   Croft B., 2013, LANGUAGE MODELING IN, V13
   del Agua MA, 2012, COMM COM INF SC, V328, P187
   DELIGNE S, 1995, INT CONF ACOUST SPEE, P169, DOI 10.1109/ICASSP.1995.479391
   Diringer  D., 1951, ALPHABET KEY HIST MA
   Ghoshal A, 2013, INT CONF ACOUST SPEE, P7319, DOI 10.1109/ICASSP.2013.6639084
   Gorski N., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P523, DOI 10.1109/ICDAR.1999.791840
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Graves Alex, 2006, ICML, P369, DOI DOI 10.1145/1143844.1143891
   Johansson S., 1980, ALLC Journal, V1, P25
   Kalindra  R., 2004, METHODOLOGY, P1
   Kessentini Y., 2008, MULTISTREAM HMM BASE, P1
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kozielski M, 2014, INT CONF FRONT HAND, P343, DOI 10.1109/ICFHR.2014.64
   Kozielski M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P121, DOI 10.1109/DAS.2014.8
   Kumar C. S., 2005, 9 EUR C SPEECH COMM
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J. J., 1997, UNIFIED NETWORK BASE
   Margner V., 2012, GUIDE OCR ARABIC SCR
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Mathew M, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P186, DOI 10.1109/DAS.2016.68
   Messina R, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P212, DOI 10.1109/DAS.2014.24
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   Mousa A. I. E.-D., 2014, TECHNICAL REPORT
   Moysset B, 2014, INT CONF FRONT HAND, P297, DOI 10.1109/ICFHR.2014.57
   Plötz T, 2009, INT J DOC ANAL RECOG, V12, P269, DOI 10.1007/s10032-009-0098-4
   Ray A, 2015, PROC INT CONF DOC, P1256, DOI 10.1109/ICDAR.2015.7333965
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Singh S., 2013, J EMERGING TRENDS CO, V4, P545
   Swaileh  W., 2017, INT C DOC AN HANDWR
   Swaileh W, 2016, INT CONF FRONT HAND, P536, DOI [10.1109/ICFHR.2016.97, 10.1109/ICFHR.2016.0104]
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.48, 10.1109/ICFHR.2016.0052]
   Yu SZ, 2010, ARTIF INTELL, V174, P215, DOI 10.1016/j.artint.2009.11.011
NR 41
TC 8
Z9 8
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD APR 15
PY 2019
VL 121
SI SI
BP 68
EP 76
DI 10.1016/j.patrec.2018.07.027
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA HN0KM
UT WOS:000459876700010
OA Green Submitted, Green Published, hybrid
DA 2023-11-10
ER

PT J
AU Guo, Q
   Cao, S
   Yi, Z
AF Guo, Quan
   Cao, Shuai
   Yi, Zhang
TI A medical question answering system using large language models and
   knowledge graphs
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE knowledge graph; medical question answering; named entity recognition;
   pretrained language model; Siamese network
ID EXTRACTION; ONTOLOGY
AB Question answering systems have become prominent in all areas, while in the medical domain it has been challenging because of the abundant domain knowledge. Retrieval based approach has become promising as large pretrained language models come forth. This study focuses on building a retrieval-based medical question answering system, tackling the challenge with large language models and knowledge extensions via graphs. We first retrieve an extensive but coarse set of answers via Elasticsearch efficiently. Then, we utilize semantic matching with pretrained language models to achieve a fine-grained ranking enhanced with named entity recognition and knowledge graphs to exploit the relation of the entities in question and answer. A new architecture based on siamese structures for answer selection is proposed. To evaluate the approach, we train and test the model on two Chinese data sets, NLPCC2017 and cMedQA. We also conduct experiments on two English data sets, TREC-QA and WikiQA. Our model achieves consistent improvement as compared to strong baselines on all data sets. Qualification studies with cMedQA and our in-house data set show that our system gains highly competitive performance. The proposed medical question answering system outperforms baseline models and systems in quantification and qualification evaluations.
C1 [Guo, Quan; Cao, Shuai; Yi, Zhang] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Yi, Z (通讯作者)，Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Sichuan, Peoples R China.
EM zhangyi@scu.edu.cn
FU National Key Research and Development Program of China [2018AAA0100201]
FX This study is supported by the National Key Research and Development
   Program of China, Grant Number 2018AAA0100201.
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bekoulis G, 2018, EXPERT SYST APPL, V114, P34, DOI 10.1016/j.eswa.2018.07.032
   Ben Abacha A, 2015, INFORM PROCESS MANAG, V51, P570, DOI 10.1016/j.ipm.2015.04.006
   Bian WJ, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1987, DOI 10.1145/3132847.3133089
   Buscaldi D, 2010, J INTELL INF SYST, V34, P113, DOI 10.1007/s10844-009-0082-y
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dai Z, 2019, 2019 12 INT C IM SIG, P1, DOI [10.1109/CISP-BMEI48845.2019.8965823, DOI 10.1109/CISP-BMEI48845.2019.8965823]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gribova V, 2021, INT J INTELL SYST, V36, P291, DOI 10.1002/int.22300
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo QL, 2010, INT J INTELL SYST, V25, P655, DOI 10.1002/int.20417
   He H., 2015, P 2015 C EMP METH NA, P1576, DOI [DOI 10.18653/V1/D15-1181, 10.18653/v1/D15-1181]
   He T, 2020, INT J INTELL SYST, V35, P1375, DOI 10.1002/int.22257
   Huang Z., 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Khalid MA, 2008, LECT NOTES COMPUT SC, V4956, P705
   Kolomiyets O, 2011, INFORM SCIENCES, V181, P5412, DOI 10.1016/j.ins.2011.07.047
   Laskar MTR, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5505
   Lee Minsuk, 2006, AMIA Annu Symp Proc, P469
   Li D., 2019, ABS190507588 CORR
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Lloret E, 2011, INT J INTELL SYST, V26, P1125, DOI 10.1002/int.20502
   Nogueira Rodrigo, 2019, ABS190104085 CORR
   Padigela H., 2019, ABS190501758 CORR
   Pulman Stephen, 2014, ABS14121632 CORR
   Qiao Yifan, 2019, ARXIV190407531
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567
   Rodrigo A, 2017, KNOWL-BASED SYST, V137, P83, DOI 10.1016/j.knosys.2017.09.015
   Segler MHS, 2018, NATURE, V555, P604, DOI 10.1038/nature25978
   Shen Gehui, 2017, P 2017 C EMP METH NA, P1179, DOI [DOI 10.18653/V1/D17-1122, 10.18653/v1/D17-1122]
   Tay Y, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P583, DOI 10.1145/3159652.3159664
   Wang D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P707
   Wang H, 2020, INT J INTELL SYST, V35, P1987, DOI 10.1002/int.22280
   Wimalasuriya DC, 2010, J INF SCI, V36, P306, DOI 10.1177/0165551509360123
   Xu P., 2019, ABS190505910 CORR
   Yang L, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P287, DOI 10.1145/2983323.2983818
   Yang Wei, 2019, ABS190310972 CORR
   Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P19
   Yun W, 2021, INT J INTELL SYST, V36, P1686, DOI 10.1002/int.22357
   Zaidi SSA, 2022, INT J INTELL SYST, V37, P3654, DOI 10.1002/int.22701
   Zhang S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7080767
   Zou XH, 2020, J PHYS CONF SER, V1487, DOI 10.1088/1742-6596/1487/1/012016
NR 42
TC 3
Z9 3
U1 51
U2 93
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD NOV
PY 2022
VL 37
IS 11
BP 8548
EP 8564
DI 10.1002/int.22955
EA JUL 2022
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4V0ZM
UT WOS:000822761000001
DA 2023-11-10
ER

PT J
AU Guimaraes, N
   Campos, R
   Jorge, A
AF Guimaraes, Nuno
   Campos, Ricardo
   Jorge, Alipio
TI Pre-trained language models: What do they know?
SO WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Article; Early Access
DE large language models; natural language; pretrained language models;
   processing
AB Large language models (LLMs) have substantially pushed artificial intelligence (AI) research and applications in the last few years. They are currently able to achieve high effectiveness in different natural language processing (NLP) tasks, such as machine translation, named entity recognition, text classification, question answering, or text summarization. Recently, significant attention has been drawn to OpenAI's GPT models' capabilities and extremely accessible interface. LLMs are nowadays routinely used and studied for downstream tasks and specific applications with great success, pushing forward the state of the art in almost all of them. However, they also exhibit impressive inference capabilities when used off the shelf without further training. In this paper, we aim to study the behavior of pre-trained language models (PLMs) in some inference tasks they were not initially trained for. Therefore, we focus our attention on very recent research works related to the inference capabilities of PLMs in some selected tasks such as factual probing and common-sense reasoning. We highlight relevant achievements made by these models, as well as some of their current limitations that open opportunities for further research.This article is categorized under:Fundamental Concepts of Data and Knowledge > Key Design Issues in DataMiningTechnologies > Artificial Intelligence
C1 [Guimaraes, Nuno; Campos, Ricardo; Jorge, Alipio] LIAAD INESCTEC, Porto, Portugal.
   [Guimaraes, Nuno; Jorge, Alipio] Univ Porto, Porto, Portugal.
   [Campos, Ricardo] Univ Beira Interior, Covilha, Portugal.
   [Campos, Ricardo] Polytech Inst Tomar, Ci2 Smart Cities Res Ctr, Tomar, Portugal.
C3 Universidade do Porto; INESC TEC; Universidade do Porto; Universidade da
   Beira Interior; Instituto Politecnico de Tomar
RP Guimaraes, N (通讯作者)，LIAAD INESCTEC, Porto, Portugal.
EM nuno.r.guimaraes@inesctec.pt
RI Jorge, Alipio/A-1721-2008
OI Jorge, Alipio/0000-0002-5475-1382; Campos, Ricardo/0000-0002-8767-8126
FU FCT-Fundacao para a Ciencia e a Tecnologia; Component 5-Capitalization
   and Business Innovation [2022.09312]; European Union (EU); Next
   Generation EU;  [41]
FX FCT-Fundacao para a Ciencia e a Tecnologia, Grant/Award Number:
   2022.09312.PTDC; Component 5-Capitalization and Business Innovation,
   Grant/Award Number: 41; European Union (EU); Next Generation EU
CR Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Bian N, 2023, Arxiv, DOI arXiv:2303.16421
   Cheng L., 2023, ARXIV
   Clark P, 2018, Arxiv, DOI arXiv:1803.05457
   Cong Y, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON COMMONSENSE REPRESENTATION AND REASONING (CSRR 2022), P17
   Garcez AD, 2019, Arxiv, DOI arXiv:1905.06088
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Frith C, 2005, CURR BIOL, V15, pR644, DOI 10.1016/j.cub.2005.08.041
   Ganguly D, 2023, LECT NOTES COMPUT SC, V13982, P331, DOI 10.1007/978-3-031-28241-6_34
   Gao Leo, 2021, Zenodo, DOI 10.5281/ZENODO.5371629
   Guo TC, 2023, Arxiv, DOI arXiv:2305.18365
   Hendrycks D., 2021, P INT C LEARN REPR I
   Jiang ZB, 2021, Arxiv, DOI arXiv:2012.00955
   Jiang ZB, 2021, T ASSOC COMPUT LING, V9, P962, DOI 10.1162/tacl_a_00407
   Kaneda Y, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42924
   Kasai J, 2023, Arxiv, DOI arXiv:2303.18027
   Kassner N., 2020, PROC 58 ANN M ASS CO, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]
   Katz DM., 2023, GPT 4 PASSES BAR EXA, DOI [10.2139/ssrn.4389233, DOI 10.2139/SSRN.4389233]
   Kosinski M, 2023, Arxiv, DOI arXiv:2302.02083
   Kung TH, 2023, PLOS DIGIT HLTH, V2, DOI DOI 10.1101/2022.12.19.22283643
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Lamichhane B, 2023, Arxiv, DOI arXiv:2303.15727
   Levine DM, 2023, medRxiv, DOI [10.1101/2023.01.30.23285067, 10.1101/2023.01.30.23285067v1, DOI 10.1101/2023.01.30.23285067]
   Lin BY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6862
   Lin S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3214
   Liu P., 2022, PRETRAIN PROMPT PRED
   Liu ZL, 2023, Arxiv, DOI arXiv:2303.11032
   Loem M., 2023, P 18 WORKSH INN US N, P205
   Lu P., 2023, LONG PAPERS, P14605
   Lu YQ, 2023, ANN BIOMED ENG, V51, P1898, DOI 10.1007/s10439-023-03234-w
   Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5
   Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280
   Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]
   Nunes D, 2023, Arxiv, DOI arXiv:2303.17003
   Pelrine K, 2023, Arxiv, DOI arXiv:2305.14928
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   Raunak V, 2023, Arxiv, DOI arXiv:2305.14878
   Redford A., 2018, IMPROVING LANGUAGE U
   Savelka J., 2023, ARXIV
   Savelka J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P117, DOI 10.1145/3587102.3588792
   Savelka J, 2023, Arxiv, DOI [arXiv:2306.10073, 10.48550/arXiv.2306.10073, DOI 10.48550/ARXIV.2306.10073]
   Savelka J, 2023, Arxiv, DOI arXiv:2303.08033
   Singh R, 2016, COGNITIVE SCI, V40, P607, DOI 10.1111/cogs.12260
   Sobania D, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR, APR, P23, DOI 10.1109/APR59189.2023.00012
   Stolfo A., 2023, P 61 ANN M ASS COMP, P545
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H., 2023, P INT JOINT C ART IN
   Weir N., 2020, 42 ANN VIRT M COGN S
   Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791
   Zhang H., 2022, P 32 INT JOINT C ART
   Zhou A., 2023, ARXIV
   Zhu YK, 2015, Arxiv, DOI arXiv:1506.06724
   2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 56
TC 0
Z9 0
U1 6
U2 6
PU WILEY PERIODICALS, INC
PI SAN FRANCISCO
PA ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA
SN 1942-4787
EI 1942-4795
J9 WIRES DATA MIN KNOWL
JI Wiley Interdiscip. Rev.-Data Mining Knowl. Discov.
PD 2023 SEP 21
PY 2023
DI 10.1002/widm.1518
EA SEP 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S4BK3
UT WOS:001070635500001
DA 2023-11-10
ER

PT S
AU Castro, MJ
   Prat, F
AF Castro, MJ
   Prat, F
BE Mira, J
   Alvarez, JR
TI New directions in connectionist language modeling
SO COMPUTATIONAL METHODS IN NEURAL MODELING, PT 1
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 7th International Work Conference on Artificial and Natural Neural
   Networks
CY JUN 03-06, 2003
CL MENORCA, SPAIN
SP Univ Nacl Educ Distancia, IFIP, WG Neural Comp Syst, Spanish RIB IEEE Neural Networks Council
AB In language engineering, language models are employed in order to improve system performance. These language models are usually N-gram models which are estimated from large text databases using the occurrence frequencies of these N-grams. An alternative to conventional frequency-based estimation of N-gram probabilities consists in using neural networks to this end. These "connectionist N-gram models", although their training is very time-consuming, present a pair of interesting advantages over the conventional approach: networks provide an implicit smoothing in their estimations and the number of free parameters does not grow exponentially with N.
   Some experimental works provide empirical evidence on the capability of multilayer perceptrons and simple recurrent networks to emulate N-gram models, and proposes new directions for extending neural networks-based language models.
C1 Univ Politecn Valencia, Dept Sistemes Informat & Computacio, E-46022 Valencia, Spain.
   Univ Jaume 1 Castello, Dept Llenguatges & Sistemes Informat, E-12071 Castellon de La Plana, Spain.
C3 Universitat Politecnica de Valencia; Universitat Jaume I
RP Castro, MJ (通讯作者)，Univ Politecn Valencia, Dept Sistemes Informat & Computacio, E-46022 Valencia, Spain.
EM mcastro@dsic.upv.es; fprat@lsi.uji.es
RI Castro-Bleda, M. J./H-2372-2011
CR [Anonymous], P 6 INT C SPOK LANG
   [Anonymous], 1989, P IEEE ICASSP
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Castro MJ, 1999, IEE CONF PUBL, P910, DOI 10.1049/cp:19991228
   CASTRO MJ, 2001, P 2 WORKSH NAT LANG, P16
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Jelinek F., 1997, STAT METHODS SPEECH
   RODRIGUEZ P, 2003, IN PRESS J APPL INTE
   Rumelhart DE., 1986, PARALLEL DISTRIBUTED, P319
   Schwenk H, 2002, INT CONF ACOUST SPEE, P765
NR 13
TC 9
Z9 9
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-40210-1
J9 LECT NOTES COMPUT SC
PY 2003
VL 2686
BP 598
EP 605
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods;
   Neurosciences
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA BX35G
UT WOS:000185042000076
DA 2023-11-10
ER

PT J
AU Pelicon, A
   Shekhar, R
   Skrlj, B
   Purver, M
   Pollak, S
AF Pelicon, Andraz
   Shekhar, Ravi
   Skrlj, Blaz
   Purver, Matthew
   Pollak, Senja
TI Investigating cross-lingual training for offensive language detection
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Cross-lingual models; Transfer learning; Intermediate training;
   Offensive language detection; Deep learning
ID HATE SPEECH
AB datasets (e.g., Davidson et al., 2017; Zampieri et al., 2019a; Ljubesic, Fiser & Erjavec, 2019), shared tasks (e.g., Wiegand, Siegel & Ruppenhofer, 2018; Zampieri et al., 2020a) and models (e.g., Salminen et al., 2018; Farha & Magdy, 2020; Gao & Huang, 2017; Zampieri et al., 2020a) have been proposed for several languages. However, so far, good accuracy in automatic detection depends upon the availability of substantial, well-labelled datasets: in many domains and in many languages, this is not the case. A common theme across recent work in NLP which promises to reduce the requirement for such task-specific labeled data is the use of transfer learning (see e.g., Ruder, 2019). Typically, in this approach, a large pre-trained language model (LM) is learned using a general source task (e.g., masked language modeling or next sentence prediction) over a very large amount of easily obtained unlabeled data. This pre-trained LM-which contains a lot of information about word meaning and dependencies-can then be finetuned on the target NLP task (e.g., hate speech detection, question answering etc.), requiring only a smaller labeled dataset to achieve state-of-the-art performance (see e.g., Devlin et al., 2019). While most of this research is focused on the English language only, the principle extends to transfer between languages, and recent work in cross-lingual transfer leverages datasets in multiple languages to provide pre-trained models with multilingual embeddings (Artetxe & Schwenk, 2019; Devlin et al., 2019). For example, Devlin et al.
   Platforms that feature user-generated content (social media, online forums, newspaper comment sections etc.) have to detect and filter offensive speech within large, fast-changing datasets. While many automatic methods have been proposed and achieve good accuracies, most of these focus on the English language, and are hard to apply directly to languages in which few labeled datasets exist. Recent work has therefore investigated the use of cross-lingual transfer learning to solve this problem, training a model in a well-resourced language and transferring to a less-resourced target language; but performance has so far been significantly less impressive. In this paper, we investigate the reasons for this performance drop, via a systematic comparison of pre-trained models and intermediate training regimes on five different languages. We show that using a better pre-trained language model results in a large gain in overall performance and in zero-shot transfer, and that intermediate training on other languages is effective when little target-language data is available. We then use multiple analyses of classifier confidence and language model vocabulary to shed light on exactly where these gains come from and gain insight into the sources of the most typical mistakes.
C1 [Pelicon, Andraz; Skrlj, Blaz; Purver, Matthew; Pollak, Senja] Jozef Stefan Inst, Ljubljana, Slovenia.
   [Pelicon, Andraz; Skrlj, Blaz] Jozef Stefan Int Postgrad Sch, Ljubljana, Slovenia.
   [Shekhar, Ravi; Purver, Matthew] Queen Mary Univ London, London, England.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute;
   Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute;
   University of London; Queen Mary University London
RP Pelicon, A (通讯作者)，Jozef Stefan Inst, Ljubljana, Slovenia.; Pelicon, A (通讯作者)，Jozef Stefan Int Postgrad Sch, Ljubljana, Slovenia.
EM Andraz.Pelicon@ijs.si
OI Purver, Matthew/0000-0003-2297-1273; Shekhar, Ravi/0000-0002-8798-641X;
   Pelicon, Andraz/0000-0002-2060-6670
FU European Union's Horizon 2020 research and innovation program [825153];
   European Union's Rights, Equality and Citizenship Program [875263];
   project EMBEDDIA (CrossLingual Embeddings for LessRepresented Languages
   in European News Media); European Union [875263]; EPSRC [EP/S033564/1];
   Slovenian Research Agency (ARRS) core research program Knowledge
   Technologies [P20103]; research project CANDAS Computer assisted
   multilingual news discourse analysis [J6-2581]; EPSRC [EP/S033564/1]
   Funding Source: UKRI
FX This research is supported by the European Union's Horizon 2020 research
   and innovation program under Grant Agreement No. 825153, project
   EMBEDDIA (CrossLingual Embeddings for LessRepresented Languages in
   European News Media) . The results of this publication reflect only the
   authors' views, and the Commission is not responsible for any use that
   may be made of the information it contains. Andra Pelicon was funded
   also by the European Union's Rights, Equality and Citizenship Program
   (2014-2020) project IMSyPP (Innovative Monitoring Systems and Prevention
   Policies of Online Hate Speech, Grant No. 875263) . Matthew Purver is
   also supported by the EPSRC under grant EP/S033564/1. This work is also
   supported by the Slovenian Research Agency (ARRS) core research program
   Knowledge Technologies (P20103) , the research project CANDAS Computer
   assisted multilingual news discourse analysis with contextual embeddings
   (Grant no. J6-2581) and the young researchers' program for the work of
   Bla Skrlj. There was no additional external funding received for this
   study. The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Abu Farha I, 2020, P 4 WORKSHOP OPEN SO, P86
   [Anonymous], 2018, 14 C NATURAL LANGUAG
   [Anonymous], P 6 EV CAMP NAT LANG
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bai Xiaoyu, 2018, P 6 EV CAMP NAT LANG
   Basile V, 2019, P 13 INT WORKSH SEM, P54
   Beyrer C, 2017, LANCET, V390, P1570, DOI 10.1016/S0140-6736(17)32519-9
   Blair T, 2019, DESIGNATING HATE NEW
   Chopra S, 2020, AAAI CONF ARTIF INTE, V34, P386
   Conneau A., 2020, PROC 58 ANN M ASS CO, P8440
   Conneau A, 2019, ADV NEUR IN, V32
   Davidson Thomas, 2017, ICWSM, P512
   Devlin J., 2018, ARXIV, V1, P4171
   Gagliardone I., 2015, SERIES INTERNET FREE
   Gao L., 2017, INT C REC ADV NAT LA, P260, DOI [10.26615/978-954-452-049-6-036, DOI 10.26615/978-954-452-049-6-036]
   Golbeck J, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P229, DOI 10.1145/3091478.3091509
   Hu Junjie, 2020, P 37 INT C MACH LEAR
   Ibrohim Muhammad Okky, 2018, Procedia Computer Science, V135, P222, DOI 10.1016/j.procs.2018.08.169
   Lample G., 2018, UNSUPERVISED MACHINE
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Leite JA, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P914
   Lin YH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3125
   Liu P., 2019, P 13 INT WORKSH SEM, P87, DOI [10.18653/v1/S19-2011, DOI 10.18653/V1/S19-2011]
   Liu Y.H., 2019, ROBERTA ROBUSTLY OPT
   Ljubesic N, 2018, P 2 WORKSH AB LANG O, P124, DOI DOI 10.18653/V1/W18-5116
   Ljubesic N, 2019, LECT NOTES ARTIF INT, V11697, P103, DOI 10.1007/978-3-030-27947-9_9
   Lomas N., 2015, FACEBOOK GOOGLE TWIT
   Lomas Natasha, 2017, TECHCRUNCH
   Mandl T, 2019, ACM INT CONF PR SER, P14, DOI 10.1145/3368567.3368584
   Martin L., 2020, ASS COMPUTATIONAL LI, P7203, DOI DOI 10.18653/V1/2020.ACL-MAIN.645
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), P18
   Morgan NA., 2020, UPDATE ONLINE HARMS
   Mozetic I., 2020, P C LANG TECHN DIG H, P87
   Mubarak H, 2017, P 1 WORKSHOP ABUSIVE, DOI 10.18653/v1/W17-3008
   Obadimu A, 2019, LECT NOTES COMPUT SC, V11549, P214, DOI 10.1007/978-3-030-21741-9_22
   Pamungkas EW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P363
   Pedersen T., 2020, P 14 WORKSH SEM EV, P1938
   Pelicon A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175993
   Pelicon Andraz, 2021, P EACL WORKSH NEWS M, P30
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Plaza-Del-Arco FM, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3369869
   Poletto F, 2020, LANG RESOUR EVAL, V55, P1
   Pollak S, 2021, P EACL HACK NEWS MED, P99
   Pruksachatkun Y., 2020, P 58 ANN M ASS COMP, P5231, DOI DOI 10.18653/V1/2020.ACL-MAIN.467
   Qian J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4755
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Ruder S., 2019, THESIS NATL U IRELAN
   Salminen J., 2018, 12 INT AAAI C WEB SO
   Salminen J, 2020, HUM-CENTRIC COMPUT I, V10, DOI 10.1186/s13673-019-0205-6
   Schmidt Anna, 2017, P 5 INT WORKSH NAT L, P1, DOI DOI 10.18653/V1/W17-1101
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Shekhar R, 2020, J LANGUAGE TECHNOLOG, V34, P49
   Siegel JM, 2019, P 15 KONVENS, P354
   Simonite T, 2020, WIRED
   Skrlj B, 2021, P EACL HACKASHOP NEW, P76
   Skrlj B, 2021, COGN COMPUT, DOI DOI 10.1007/s12559-021-09826-9
   Stappen L, 2020, CROSS LINGUAL ZERO A
   Stevenson A, 2018, NEW YORK TIMES
   Subedar A, 2018, COUNTRY FACEBOOK POS
   Swayamdipta S, 2020, P 2020 C EMP METH NA
   Ulcar M, 2020, INT C TEXT SPEECH DI, P104
   van der Goot R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Vidgen B., 2020, P 4 WORKSHOP ONLINE, P162, DOI DOI 10.18653/V1/2020.ALW-1.19
   Vidgen B, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243300
   Vu T., 2020, P EMNLP2020, P7882
   Wang A., 2019, P NEURIPS, P3266
   Wang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4465
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wiegand M, 2018, P GERMEVAL 2018 WORK
   Wolf T., P 2020 C EMPIRICAL M, P38
   Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1391, DOI 10.1145/3038912.3052591
   Yogatama D, 2019, LEARNING EVALUATING
   Zampieri M., 2019, P 13 INT WORKSHOP SE, P75, DOI DOI 10.18653/V1/S19-2010
   Zampieri M., 2020, P 14 WORKSHOP SEMANT, P1425
   Zampieri M, 2020, P SEMEVAL
   Zampieri M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1415
NR 77
TC 4
Z9 4
U1 2
U2 10
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUN 25
PY 2021
AR e559
DI 10.7717/peerj-cs.559
PG 39
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TD1YY
UT WOS:000669132200001
PM 34239970
OA Green Published, gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Wang, R
   Utiyama, M
   Goto, I
   Sumita, E
   Zhao, H
   Lu, BL
AF Wang, Rui
   Utiyama, Masao
   Goto, Isao
   Sumita, Eiichiro
   Zhao, Hai
   Lu, Bao-Liang
TI Converting Continuous-Space Language Models into <i>N</i>-gram Language
   Models with Efficient Bilingual Pruning for Statistical Machine
   Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Machine translation; continuous-space language model; neural network
   language model; language model pruning
AB The Language Model (LM) is an essential component of Statistical Machine Translation (SMT). In this article, we focus on developing efficient methods for LM construction. Our main contribution is that we propose a Natural N-grams based Converting (NNGC) method for transforming a Continuous-Space Language Model (CSLM) to a Back-off N-gram Language Model (BNLM). Furthermore, a Bilingual LM Pruning (BLMP) approach is developed for enhancing LMs in SMT decoding and speeding up CSLM converting. The proposed pruning and converting methods can convert a large LM efficiently by working jointly. That is, a LM can be effectively pruned before it is converted from CSLM without sacrificing performance, and further improved if an additional corpus contains out-of-domain information. For different SMT tasks, our experimental results indicate that the proposed NNGC and BLMP methods outperform the existing counterpart approaches significantly in BLEU and computational cost.
C1 [Wang, Rui; Zhao, Hai; Lu, Bao-Liang] Shanghai Jiao Tong Univ, Ctr Brain Like Comp & Machine Intelligence, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Utiyama, Masao; Sumita, Eiichiro] Natl Inst Informat & Commun Technol, Multilingual Translat Lab, 3-5 Hikaridai, Kyoto 6190289, Japan.
   [Goto, Isao] NHK Japan Broadcasting Corp, Sci & Technol Res Labs, Setagaya Ku, 1-10-11 Kinuta, Tokyo 1578510, Japan.
   [Goto, Isao] Natl Inst Informat & Commun Technol, Kyoto 6190289, Japan.
   [Zhao, Hai; Lu, Bao-Liang] Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interac, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; National Institute of Information &
   Communications Technology (NICT) - Japan; NHK Japan Broadcasting Corp;
   National Institute of Information & Communications Technology (NICT) -
   Japan; Shanghai Jiao Tong University
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Ctr Brain Like Comp & Machine Intelligence, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.; Utiyama, M (通讯作者)，Natl Inst Informat & Commun Technol, Multilingual Translat Lab, 3-5 Hikaridai, Kyoto 6190289, Japan.; Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interac, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM wangrui.nlp@gmail.com; mutiyama@nict.go.jp; goto.i-es@nhk.or.jp;
   eiichiro.sumita@nict.go.jp; zhaohai@cs.sjtu.edu.cn; bllu@sjtu.edu.cn
RI Wang, Rui/AAI-1990-2020
OI Wang, Rui/0000-0001-8007-2503; Lu, Bao-Liang/0000-0001-8359-0058
FU National Natural Science Foundation of China [60903119, 61170114,
   61272248]; National Basic Research Program of China [2013CB329401];
   Science and Technology Commission of Shanghai Municipality
   [13511500200]; European Union Seventh Framework Program [247619]; Cai
   Yuanpei Program [201304490199, 201304490171]; art and science
   interdisciplinary funds of Shanghai Jiao Tong University [14X190040031];
   Key Project of National Society Science Foundation of China [15-ZDA041]
FX Rui Wang, Hai Zhao, and Bao-Liang Lu were partially supported by the
   National Natural Science Foundation of China (Grant No. 60903119, Grant
   No. 61170114, and Grant No. 61272248), the National Basic Research
   Program of China (Grant No. 2013CB329401), the Science and Technology
   Commission of Shanghai Municipality (Grant No. 13511500200), the
   European Union Seventh Framework Program (Grant No. 247619), the Cai
   Yuanpei Program (CSC fund 201304490199, 201304490171), and the art and
   science interdisciplinary funds of Shanghai Jiao Tong University, No.
   14X190040031, and the Key Project of National Society Science Foundation
   of China, No. 15-ZDA041.
CR [Anonymous], 2012, P NAACL HLT 2012 WOR
   [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2013, INT J INTEGR MED, DOI DOI 10.1063/1.4791601
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2008, ADV NEURAL INF PROCE
   [Anonymous], 2012, P COLING 2012 POSTER
   [Anonymous], P 52 ANN M ASS COMP
   [Anonymous], 2011, P IEEE AUT SPEECH RE
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   [Anonymous], 2013, P 2013 C EMPIRICAL M
   [Anonymous], 2003, HLT NAACL 2003 HUMAN
   [Anonymous], 1996, 34 ANN M ASS COMP LI, DOI DOI 10.3115/981863.981904
   Arisoy E, 2014, IEEE-ACM T AUDIO SPE, V22, P184, DOI 10.1109/TASLP.2013.2286919
   Arisoy E, 2013, INT CONF ACOUST SPEE, P8242, DOI 10.1109/ICASSP.2013.6639272
   Auli M., 2013, P 2013 C EMPIRICAL M, V13, P1044
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Chelba C., 2010, P INTERSPEECH, P2242
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Deoras A, 2011, INT CONF ACOUST SPEE, P5532
   Devlin J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1370
   Fujii Atsushi, 2010, P 8 NTCIR WORKSH M E, P293
   Goto I., 2011, P 9 NTCIR WORKSH M E, V9, P559
   Gutmann Michael, 2010, P 13 INT C ART INT S, P297, DOI DOI 10.1145/3292500.3330651
   Heafield K., 2013, P 51 ANN M ASS COMP, V2, P690
   Huang Zhongqiang, 2013, P NII TESTB COMM INF
   Jia ZY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1512
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Le HS, 2011, INT CONF ACOUST SPEE, P5524
   Li Peng, 2014, P COLING 2014 25 INT, P1897
   Liu SY, 2014, ADV MECH ENG, DOI 10.1155/2014/868041
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Nair V., 2010, P 27 INT C MACHINE L
   Niehues J., 2012, P INT WORKSH SPOK LA, P311
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Peng Xiaochang, 2014, P 2014 C EMP METH NA, P1735
   Roark Brian, 2013, P 51 ANN M ASS COMP, P43
   Schwenk Holger, 2010, Prague Bulletin of Mathematical Linguistics, P137, DOI 10.2478/v10108-010-0014-6
   Schwenk H, 2006, P COLING ACL MAIN C, P723
   Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003
   Siivola V, 2007, IEEE T AUDIO SPEECH, V15, P1617, DOI 10.1109/TASL.2007.896666
   Son L. H., 2012, P 2012 C N AM CHAPT, P39
   Son L. H., 2010, P EMNLP 10, P778
   Stolcke Andreas, 1998, P DARPA BROADC NEWS, P270
   Sundermeyer M, 2014, P 2014 C EMP METH NA, P14, DOI DOI 10.3115/V1/D14-1003
   Vaswani A., 2013, P 2013 C EMPIRICAL M, P1387
   Wang R., 2014, P 2014 C EMP METH NA, P189
   Wang R, 2015, IEEE-ACM T AUDIO SPE, V23, P1209, DOI 10.1109/TASLP.2015.2425220
   Wang Rui, 2015, P 29 PAC AS C LANG I, P274
   Wang Rui, 2013, P C EMP METH NAT LAN, P845
   Wang XL, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P752
   Xu Q., 2012, P COLING 2012 POSTER, P1341
   Zaidan O.F., 2009, PRAGUE B MATH LINGUI, V91, P79
   Zhang Jingyi, 2014, P 2014 C EMP METH NA, P183
   Zhang Jingyi, 2013, P 23 INT JOINT C ART, P2211
   Zhao H., 2009, P 12 C EUR CHAPT ACL, P879
   Zhao H., 2013, LECT NOTES COMPUTER, V7817, P248
   Zhao Hai, 2009, P 2009 C EMPIRICAL M, P30
   Zhao Hongzhong, 2009, Proceedings of the 2009 2nd Asian-Pacific Conference on Synthetic Aperture Radar (APSAR 2009), P55, DOI 10.1109/APSAR.2009.5374342
NR 63
TC 4
Z9 4
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR
PY 2016
VL 15
IS 3
AR 11
DI 10.1145/2843942
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ0SB
UT WOS:000373913600001
OA Bronze
DA 2023-11-10
ER

PT J
AU Hu, JY
   Turin, W
   Brown, MK
AF Hu, JY
   Turin, W
   Brown, MK
TI Language modeling using stochastic automata with variable length
   contexts
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
ID TEXT COMPRESSION; PROBABILITIES
AB It is well known that language models are effective for increasing the accuracy of speech and handwriting recognizers, but large language models are often required to achieve low model perplexity (or entropy) and still have adequate language coverage. We study three efficient methods for variable order stochastic language modeling in the context of the stochastic pattern recognition problem. Two of these methods are previous techniques from recent literature, and one is a new method based on a successful text compression technique. We give results of a comparative analysis, and demonstrate that the best performance is achieved by extending one of the previous techniques using elements from the newly developed method. (C) 1997 Academic Press Limited.
RP Hu, JY (通讯作者)，AT&T BELL LABS,LUCENT TECHNOL,600 MT AVE,MURRAY HILL,NJ 07974, USA.
CR [Anonymous], 1980, HIDDEN MARKOV MODELS
   Bahl L. R., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing, P418
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P2350
   BAKER JK, 1975, IEEE T ACOUST SPEECH, VAS23, P24, DOI 10.1109/TASSP.1975.1162650
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Bell T.C., 1990, TEXT COMPRESSION
   BENGIO Y, 1994, ADV NEURAL INFORMATI, V6, P937
   BILLINGSLEY P, 1961, ANN MATH STAT, V32, P12, DOI 10.1214/aoms/1177705136
   CLEARY JG, 1984, IEEE T COMMUN, V32, P396, DOI 10.1109/TCOM.1984.1096090
   CORMACK GV, 1987, COMPUT J, V30, P541, DOI 10.1093/comjnl/30.6.541
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FERGUSON J, 1980, P S APPL HIDD MARK M, P8
   Guyon I., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P454, DOI 10.1109/ICDAR.1995.599034
   Hu J., 1994, P INT WORKSH FRONT H, p195}205
   JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Kucera H., 1967, COMPUTATIONAL ANAL P
   LEVINSON SE, 1978, AT&T TECH J, V57, P1627, DOI 10.1002/j.1538-7305.1978.tb02115.x
   LEVINSON SE, 1977, P ICASSP 77, P479
   MAKHOUL J, 1994, P ICASSP 94 AD AUSTR, pV125
   NATHAN KS, 1995, P ICASSP 95 DETR MIC, P2619
   PLACEWAY P, 1993, P INT C AC SPEECH SI, V2, P33
   RICCARDI G, 1995, P ICASSP 95, P237
   RISSANEN J, 1981, IEEE T INFORM THEORY, V27, P12, DOI 10.1109/TIT.1981.1056282
   RON D, 1994, ADV NEURAL INFORMATI, V6, P176
   SCHENKEL M, 1995, MACH VISION APPL, P215
   TEUHOLA J, 1993, COMPUT J, V36, P607, DOI 10.1093/comjnl/36.7.607
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
NR 28
TC 11
Z9 11
U1 1
U2 2
PU ACADEMIC PRESS LTD
PI LONDON
PA 24-28 OVAL RD, LONDON, ENGLAND NW1 7DX
SN 0885-2308
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 1997
VL 11
IS 1
BP 1
EP 16
DI 10.1006/csla.1996.0020
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WU722
UT WOS:A1997WU72200001
DA 2023-11-10
ER

PT J
AU Marreddy, M
   Oota, SR
   Vakada, LS
   Chinni, VC
   Mamidi, R
AF Marreddy, Mounika
   Oota, Subba Reddy
   Vakada, Lakshmi Sireesha
   Chinni, Venkata Charan
   Mamidi, Radhika
TI Am I a Resource-Poor Language? Data Sets, Embeddings, Models and
   Analysis for four different NLP Tasks in Telugu Language
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE BERT-Te; RoBERTa-Te; ELMo-Te; resource creation; text classification;
   low-resource languages
ID CLASSIFICATION; EMOTIONS
AB Due to the lack of a large annotated corpus, many resource-poor Indian languages struggle to reap the benefits of recent deep feature representations in Natural Language Processing (NLP). Moreover, adopting existing language models trained on large English corpora for Indian languages is often limited by data availability, rich morphological variation, syntax, and semantic differences. In this paper, we explore the traditional to recent efficient representations to overcome the challenges of a low resource language, Telugu. In particular, our main objective is to mitigate the low-resource problem for Telugu. Overall, we present several contributions to a resource-poor language viz. Telugu. (i) a large annotated data (35,142 sentences in each task) for multiple NLP tasks such as sentiment analysis, emotion identification, hate-speech detection, and sarcasm detection, (ii) we create different lexicons for sentiment, emotion, and hate-speech for improving the efficiency of the models, (iii) pretrained word and sentence embeddings, and (iv) different pretrained language models for Telugu such as ELMo-Te, BERT-Te, RoBERTa-Te, ALBERT-Te, and DistilBERT-Te on a large Telugu corpus consisting of 8,015,588 sentences (1,637,408 sentences from TeluguWikipedia and 6,378,180 sentences crawled from different Telugu websites). Further, we show that these representations significantly improve the performance of four NLP tasks and present the benchmark results for Telugu. We argue that our pretrained embeddings are competitive or better than the existing multilingual pretrained models: mBERT, XLM-R, and IndicBERT. Lastly, the fine-tuning of pretrained models show higher performance than linear probing results on four NLP tasks with the following F1-scores: Sentiment (68.72), Emotion (58.04), Hate-Speech (64.27), and Sarcasm (77.93). We also experiment on publicly available Telugu datasets (Named Entity Recognition, Article Genre Classification, and Sentiment Analysis) and find that our Telugu pretrained language models (BERT-Te and RoBERTa-Te) outperform the state-of-the-art system except for the sentiment task. We open-source our corpus, four different datasets, lexicons, embeddings, and code https://github.com/Cha14ran/DREAM- T. The pretrained Transformer models for Telugu are available at https://huggingface.co/ltrctelugu.
C1 [Marreddy, Mounika; Oota, Subba Reddy; Vakada, Lakshmi Sireesha; Chinni, Venkata Charan; Mamidi, Radhika] IIITH, Prof CR Rao Rd, Hyderabad, Telengana, India.
C3 International Institute of Information Technology Hyderabad
RP Marreddy, M (通讯作者)，IIITH, Prof CR Rao Rd, Hyderabad, Telengana, India.
EM marreddy@research.iiit.ac.in; oota.subba@students.iiit.ac.in;
   lakshmi.sireesha@research.iiit.ac.in;
   venkata.charan@students.iiit.ac.in; radhika.mamidi@iiit.ac.in
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Amir S, 2016, Arxiv, DOI arXiv:1607.00976
   [Anonymous], 2010, P CONLL
   [Anonymous], 2008, EMNLP
   [Anonymous], 2012, P 2012 JOINT C EMPIR
   [Anonymous], 2007, P 45 ANN M ACL INTER
   [Anonymous], 2017, ADV NEURAL INFORM PR
   Arulmozi S., 2017, WORDNET INDIAN LANGU, P201
   Barbieri F., 2014, P 5 WORKSHOP COMPUTA, p50~58
   Bhowmick PK, 2009, LECT NOTES COMPUT SC, V5909, P261, DOI 10.1007/978-3-642-11164-8_42
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Brill E, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P257
   Burnap P, 2015, POLICY INTERNET, V7, P223, DOI 10.1002/poi3.85
   Burnap P, 2016, EPJ DATA SCI, V5, DOI 10.1140/epjds/s13688-016-0072-6
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen Ying, 2010, P CCF INT C NAT LANG, P179
   Chen ZY, 2018, Arxiv, DOI arXiv:1801.02808
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Choudhary N, 2018, Arxiv, DOI arXiv:1804.00806
   Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, 10.48550/arXiv.1412.3555, DOI 10.48550/ARXIV.1412.3555]
   Cohn Trevor, 2005, SEMANTIC ROLE LABELL
   Das A., 2010, P 8 WORKSHOP ASIAN L, P56
   Devlin J., 2018, ARXIV, V1, P4171
   Devlin Jacob, 2018, MULTILINGUAL BERT R
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, DOI 10.48550/ARXIV.1802.05365]
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Esuli A., 2006, P 5 INT C LANG RES E, V5, P417, DOI DOI 10.1155/2015/715730
   Felbo B, 2017, Arxiv, DOI arXiv:1708.00524
   Gangula Rama Rohit Reddy, 2018, P 11 INT C LANGUAGE
   Gitari ND, 2015, INT J MULTIMEDIA UBI, V10, P215, DOI DOI 10.14257/IJMUE.2015.10.4.21
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hadiwinoto C, 2019, Arxiv, DOI arXiv:1910.00194
   Heinzerling B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2989
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Joshi A., 2016, ARXIV161000883
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Joulin A, 2016, Arxiv, DOI arXiv:1607.01759
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, P4948
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim Hae-Young, 2014, Restor Dent Endod, V39, P74, DOI 10.5395/rde.2014.39.1.74
   Kim S., 2004, P 20 INT C COMP LING, P1367, DOI DOI 10.3115/1220355.1220555
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, P1746, DOI DOI 10.3115/V1/D14-1181
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, P3294, DOI DOI 10.5555/2969442.2969607
   Kshirsagar R, 2018, Arxiv, DOI arXiv:1809.10644
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G, 2019, Arxiv, DOI arXiv:1901.07291
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Mohammad SM, 2013, Arxiv, DOI arXiv:1308.6242
   Marreddy M., 2021, 2021 INT JOINT C NEU, P1
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mohammad S. M., 2010, P NAACL HLT 2010 WOR
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Moilanen Karo, 2007, SENTIMENT COMPOSITIO
   Mukku S. S., 2017, P 1 WORKSHOP BUILDIN, P54
   Mukku SS, 2017, LECT NOTES COMPUT SC, V10440, P355, DOI 10.1007/978-3-319-64283-3_26
   Nandy Ankita, WORDS PICTOGRAMS IND
   Nobata C, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P145, DOI 10.1145/2872427.2883062
   Pang B., 2005, P ACL, P115, DOI DOI 10.3115/1219840.1219855
   Parupalli S, 2018, Arxiv, DOI arXiv:1804.02186
   Parupalli Sreekavitha, 2018, P ACL 2018 STUDENT R, P99
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.28.739
   Qian Q, 2016, ARXIV
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ramos J., 2003, P 1 INSTR C MACH LEA, VVolume 242, P29
   Reagan AJ, 2016, EPJ DATA SCI, V5, DOI 10.1140/epjds/s13688-016-0093-1
   Riloff Ellen, 2013, EMNLP
   Ruxton GD, 2008, BEHAV ECOL, V19, P690, DOI 10.1093/beheco/arn020
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Sharma R., 2017, P 2017 C EMPIRICAL M, P547
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Stieglitz S, 2013, J MANAGE INFORM SYST, V29, P217, DOI 10.2753/MIS0742-1222290408
   Suarez Pedro Javier Ortiz, 2019, 7THWORKSHOP CHALLENG
   SWIER R, 2005, P HUM LANG TECHN C C, P883
   Tang D., 2015, EMNLP, DOI 10.18653/v1/D15-1167
   Tokuhisa R., 2008, P 22 INT C COMP LING, V1, P881, DOI DOI 10.3115/1599081.1599192
   Tummalapalli Madhuri, 2018, P INT C COMPUTATIONA
   Varshit Battu, 2018, P INT C PATTERN RECO, P148
   Wallach H. M., 2006, P 23 INT C MACH LEAR, V23, P977, DOI DOI 10.1145/1143844.1143967
   Waseem Zeerak, 2016, P NAACL STUD RES WOR, P88, DOI [DOI 10.18653/V1/N16-2013, 10.18653/v1/n16-2013]
   Wilson Theresa, 2005, P HUMAN LANGUAGE TEC, P347, DOI DOI 10.3115/1220575.1220619
   Wu SJ, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P120
   Xiong CM, 2018, Arxiv, DOI arXiv:1611.01604
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yen SJ, 2006, LECT NOTES CONTR INF, V344, P731
   Yessenalina A, 2010, P 2010 C EMP METH NA, P1046
   Yin WP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1351
   Yu HF, 2011, MACH LEARN, V85, P41, DOI 10.1007/s10994-010-5221-8
   Yu L-C, 2017, EMNLP, P534, DOI DOI 10.18653/V1/D17-1056
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang Meishan, 2016, COLING
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang ZQ, 2018, LECT NOTES COMPUT SC, V10843, P745, DOI 10.1007/978-3-319-93417-4_48
   Zhao Han, 2015, P 24 INT JOINT C ART
   Zhou D., 2016, C EMP METH NAT LANG, P638
   Zhou P, 2016, Arxiv, DOI arXiv:1611.06639
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 98
TC 1
Z9 1
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JAN
PY 2023
VL 22
IS 1
AR 18
DI 10.1145/3531535
PG 34
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9D8QE
UT WOS:000936360700002
DA 2023-11-10
ER

PT J
AU Shi, LB
   Rong, WE
   Zhou, SJ
   Jiang, N
   Xiong, Z
AF Shi, Libin
   Rong, Wenge
   Zhou, Shijie
   Jiang, Nan
   Xiong, Zhang
TI A dual channel class hierarchy based recurrent language modeling
SO NEUROCOMPUTING
LA English
DT Article
DE Recurrent language modeling; Class hierarchy; Over-large vocabulary
ID ALGORITHM
AB In recurrent language models the usage of the class hierarchy of vocabulary is a major direction to over-come over-large vocabulary issue, yet the hierarchy is not aligned within the models, including the embedding, hidden and softmax layer. Currently most methods employ the hierarchical information in embedding and/or softmax layers. It is interesting to ask if incorporating such information into hidden layer will be beneficial to the overall language modeling performance. Therefore, in this research we propose a dual channel class hierarchy (DCCH) model that utilizes two channels of RNNs to form a class hierarchy within the model, where class-channel is used to capture class sequence's information. Furthermore, we study two auxiliary techniques in class organization: word hierarchy initialization and class exchange, to boost the overall performance. Finally, experiments on the PTB, WikiText-103, Wiki-fr and OBW datasets evaluate the potential of proposed model and our observation. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Shi, Libin; Rong, Wenge; Zhou, Shijie; Jiang, Nan; Xiong, Zhang] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Shi, Libin] Beihang Univ, Sino French Enginnering Sch, Beijing 100191, Peoples R China.
   [Rong, Wenge; Zhou, Shijie; Jiang, Nan; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Rong, WE (通讯作者)，Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM w.rong@buaa.edu.cn
RI JIANG, NAN/AHB-1945-2022
FU State Key Laboratory of Software Development Environment of China
   [SKLSDE2019ZX-16]
FX This work was partially supported by the State Key Laboratory of
   Software Development Environment of China (No. SKLSDE2019ZX-16).
CR BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bengio Y, 2008, IEEE T NEURAL NETWOR, V19, P713, DOI 10.1109/TNN.2007.912312
   Bishop C. M., 2006, MACH LEARN
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Chelba Ciprian, 2014, ONE BILLION WORD BEN
   Chen HD, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1936, DOI 10.18653/v1/P17-1177
   Chen WL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1975
   Chen X, 2014, INTERSPEECH, P641
   Drake DE, 2003, INFORM PROCESS LETT, V85, P211, DOI 10.1016/S0020-0190(02)00393-9
   Fei Tao, 2018, IEEE/ACM Transactions on Audio, Speech and Language Processing, V26, P1286, DOI 10.1109/TASLP.2018.2815268
   Fernandez J., 2018, P ACL 2018 STUD RES, P9
   Fu RJ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1199
   Goodman J, 2001, INT CONF ACOUST SPEE, P561, DOI 10.1109/ICASSP.2001.940893
   Gutmann MU, 2012, J MACH LEARN RES, V13, P307
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Huang GS, 2019, NEURAL PROCESS LETT, V49, P683, DOI 10.1007/s11063-018-9836-2
   Jiang N, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1951
   Jing K., ABS190603591 CORR
   Joulin Armand, 2017, ICML 2017 P 34 INT C, P1302
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   Kuhn Harold W, 1955, NAV RES LOG, V2, P83, DOI [DOI 10.1002/NAV.20053, 10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]
   Li X, 2016, ADV NEUR IN, V29
   Li ZL, 2018, AAAI CONF ARTIF INTE, P5220
   Liang P., 2005, THESIS MIT
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Mnih A., 2008, P 22 ANN C NEURAL IN, P1081, DOI 10.5555/2981780.2981915
   Mnih Andriy, 2012, ARXIV12066426, P1751
   Morin F., 2005, AISTATS, V5, P246
   Pezeshki M., ABS150100299 CORR
   Preis R, 1999, LECT NOTES COMPUT SC, V1563, P259
   Shen Y., ABS170708588 CORR
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Theano Development Team, ABS160502688 CORR
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wilcox E., ABS190604068 CORR
NR 40
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD DEC 22
PY 2020
VL 418
BP 291
EP 299
DI 10.1016/j.neucom.2020.07.112
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT2YS
UT WOS:000590717800011
DA 2023-11-10
ER

PT S
AU Cho, SY
AF Cho, SY
BE Zhang, C
   Guesgen, HW
   Yeap, WK
TI Improvement of language models using dual-source backoff
SO PRICAI 2004: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 8th Pacific Rim International Conference on Artificial Intelligence
   (PRICAI 2004)
CY AUG 09-13, 2004
CL Auckland, NEW ZEALAND
SP Univ Auckland, Inst Informat Technol Res, USAF Off Sci Res, Asian Off Aerosp Res & Dev, Auckland Univ Technol, Franz Inc
ID PROBABILITIES
AB Language models are essential in predicting the next word in a spoken sentence, thereby enhancing the speech recognition accuracy, among other things. However, spoken language domains are too numerous, and therefore developers suffer from the lack of corpora with sufficient sizes. This paper proposes a method of combining two n-gram language models, one constructed from a very small corpus of the right domain of interest, the other constructed from a large but less adequate corpus, resulting in a significantly enhanced language model. This method is based on the observation that a small corpus from the right domain has high quality n-grams but has serious sparseness problem, while a large corpus from a different domain has more n-gram statistics but incorrectly biased. With our approach, two n-grarn statistics are combined by extending the idea of Katz's backoff and therefore is called a dual-source backoff. We ran experiments with 3-gram language models constructed from newspaper corpora of several million to tens of million words together with models from smaller broadcast news corpora. The target domain was broadcast news. We obtained significant improvement (30%) by incorporating a small corpus around one thirtieth size of the newspaper corpus.
C1 MyongJi Univ, Dept Comp Sci, Kyunggido, South Korea.
C3 Myongji University
RP Cho, SY (通讯作者)，MyongJi Univ, Dept Comp Sci, San 38-2 Yong In, Kyunggido, South Korea.
EM shcho@mju.ac.kr
CR AKIBA T, 2002, P INT C SPOK LANG PR, P881
   CHEN SF, 1998, P ICASSP 98, V2, P681
   GOOD IJ, BIOMETRICA 3 4, V40, P237
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   JELINEK F, 1977, J ACOUST SOC AM, V62, pS63, DOI 10.1121/1.2016299
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   ROSENFELD R, 1994, THESIS CARNEGIEMELLO
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
NR 9
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-22817-9
J9 LECT NOTES ARTIF INT
PY 2004
VL 3157
BP 892
EP 900
PG 9
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BAU59
UT WOS:000223633300094
DA 2023-11-10
ER

PT J
AU Kamper, H
   de Wet, F
   Hain, T
   Niesler, T
AF Kamper, Herman
   de Wet, Febe
   Hain, Thomas
   Niesler, Thomas
TI Capitalising on North American speech resources for the development of a
   South African English large vocabulary speech recognition system
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Under-resourced languages; Accented speech; South African English;
   Varieties of English
AB South African English is currently considered an under-resourced variety of English. Extensive speech resources are, however, available for North American (US) English. In this paper we consider the use of these US resources in the development of a South African large vocabulary speech recognition system. Specifically we consider two research questions. Firstly, we determine the performance penalties that are incurred when using US instead of South African language models, pronunciation dictionaries and acoustic models. Secondly, we determine whether US acoustic and language modelling data can be used in addition to the much more limited South African resources to improve speech recognition performance. In the first case we find that using a US pronunciation dictionary or a US language model in a South African system results in fairly small penalties. However, a substantial penalty is incurred when using a US acoustic model. In the second investigation we find that small but consistent improvements over a baseline South African system can be obtained by the additional use of US acoustic data. Larger improvements are obtained when complementing the South African language modelling data with US and/or UK material. We conclude that, when developing resources for an under-resourced variety of English, the compilation of acoustic data should be prioritised, language modelling data has a weaker effect on performance and the pronunciation dictionary the smallest. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Kamper, Herman; de Wet, Febe; Niesler, Thomas] Univ Stellenbosch, Dept Elect & Elect Engn, ZA-7600 Stellenbosch, South Africa.
   [de Wet, Febe] CSIR, Meraka Inst, Human Language Technol Competency Area, ZA-0001 Pretoria, South Africa.
   [Hain, Thomas] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.
C3 Stellenbosch University; Council for Scientific & Industrial Research
   (CSIR) - South Africa; University of Sheffield
RP Niesler, T (通讯作者)，Univ Stellenbosch, Dept Elect & Elect Engn, ZA-7600 Stellenbosch, South Africa.
EM kamperh@sun.ac.za; fdw@sun.ac.za; t.hain@dcs.shef.ac.uk; trn@sun.ac.za
OI Hain, Thomas/0000-0003-0939-3464; Kamper, Herman/0000-0003-2980-3475; de
   Wet, Febe/0000-0003-3495-9802
FU Royal Society; South African National Research Foundation (NRF) under a
   South Africa - UK Science Network grant [UID68470]
FX This research was supported financially by the Royal Society and the
   South African National Research Foundation (NRF) (UID68470) under a
   South Africa - UK Science Network grant. Parts of this work were
   executed using the High Performance Computer (HPC) facility at
   Stellenbosch University. The authors would like to thank Alison Wileman,
   for her hard work on the South African English pronunciation dictionary
   and transcriptions, and Matt Gibson, for his helpful comments and
   suggestions.
CR Abberley D, 1998, INT CONF ACOUST SPEE, P3781, DOI 10.1109/ICASSP.1998.679707
   [Anonymous], 1996 ENGLISH BROADCA
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2009, HTK BOOK HTK VERSION
   [Anonymous], 1997 ENGLISH BROADCA
   [Anonymous], HDB VARIETIES ENGLIS
   [Anonymous], 2005, P INT 2005 EUR 9 EUR
   [Anonymous], P ICSLP SYDN AUSTR
   [Anonymous], 2009, P INTERSPEECH
   [Anonymous], 2012, IEEE POWER ENG SOC G
   [Anonymous], P EUR AALB DENM
   ARISOY E, 2007, P INT EUR ANTW BELG, P2381
   Bisani M, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P409
   Caballero M, 2009, SPEECH COMMUN, V51, P217, DOI 10.1016/j.specom.2008.08.003
   Cettolo M, 2000, CONTENT BASED MULTIM, P372
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Davel M.H., 2011, P INTERSPEECH, P3153
   De Vries N.J., 2011, P INTERSPEECH, P3177
   Despres J, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P88
   Gales MJF, 2006, IEEE T AUDIO SPEECH, V14, P1513, DOI 10.1109/TASL.2006.878264
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   Hain T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P358
   Hecht R., 2002, P INT C SPOK LANG PR, P1753
   Imseng D., 2012, P INTERSPEECH, P1910
   Kamper H., 2012, P SLTU CAP TOWN S AF, P102
   Kamper H, 2012, SPEECH COMMUN, V54, P801, DOI 10.1016/j.specom.2012.01.008
   Kirchhoff K, 2005, SPEECH COMMUN, V46, P37, DOI 10.1016/j.specom.2005.01.004
   Le VB, 2009, IEEE T AUDIO SPEECH, V17, P1471, DOI 10.1109/TASL.2009.2021723
   Loots L, 2011, SPEECH COMMUN, V53, P75, DOI 10.1016/j.specom.2010.07.006
   Maclntyre R., 1998, 1996 CSR HUB4 LANGUA
   NIST, 2009, SPEECH REC SCOR TOOL
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH
   Schultz T, 2001, SPEECH COMMUN, V35, P31, DOI 10.1016/S0167-6393(00)00094-7
   Swietojanski P., 2012, P IEEE SLT MIAM FL, P419
   Vu N., 2011, P INTERSPEECH, P3145
   Vu N. T., 2012, PROC INTERSPEECH 201, P2586
   Wan V, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P217, DOI 10.1109/SLT.2008.4777879
   Woodland PC, 1997, INT CONF ACOUST SPEE, P719, DOI 10.1109/ICASSP.1997.596005
   Yanmin Qian, 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P354, DOI 10.1109/ASRU.2011.6163957
NR 39
TC 10
Z9 10
U1 0
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD NOV
PY 2014
VL 28
IS 6
BP 1255
EP 1268
DI 10.1016/j.csl.2014.04.005
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AN8JI
UT WOS:000340850000001
DA 2023-11-10
ER

PT J
AU Clark, A
   Eyraud, R
   Habrard, A
AF Clark, Alexander
   Eyraud, Remi
   Habrard, Amaury
TI Using Contextual Representations to Efficiently Learn Context-Free
   Languages
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE grammatical inference; context-free language; positive data only;
   membership queries
ID SENSITIVE LANGUAGES; FREE GRAMMARS; IDENTIFICATION; SETS
AB We present a polynomial update time algorithm for the inductive inference of a large class of context-free languages using the paradigm of positive data and a membership oracle. We achieve this result by moving to a novel representation, called Contextual Binary Feature Grammars (CBFGs), which are capable of representing richly structured context-free languages as well as some context sensitive languages. These representations explicitly model the lattice structure of the distribution of a set of substrings and can be inferred using a generalisation of distributional learning. This formalism is an attempt to bridge the gap between simple learnable classes and the sorts of highly expressive representations necessary for linguistic representation: it allows the learnability of a large class of context-free languages, that includes all regular languages and those context-free languages that satisfy two simple constraints. The formalism and the algorithm seem well suited to natural language and in particular to the modeling of first language acquisition. Preliminary experimental results confirm the effectiveness of this approach.
C1 [Clark, Alexander] Univ London, Dept Comp Sci, Egham TW20 0EX, Surrey, England.
   [Eyraud, Remi; Habrard, Amaury] Aix Marseille Univ, CNRS UMR 6166, Lab Informat Fondamentale Marseille, F-13453 Marseille 13, France.
C3 University of London; Royal Holloway University London; UDICE-French
   Research Universities; Aix-Marseille Universite
RP Clark, A (通讯作者)，Univ London, Dept Comp Sci, Egham TW20 0EX, Surrey, England.
EM ALEXC@CS.RHUL.AC.UK; REMI.EYRAUD@LIF.UNIV-MRS.FR;
   AMAURY.HABRARD@LIF.UNIV-MRS.FR
FU European Community under the PASCAL2 Network of Excellence
   [IST-2007-216886]
FX This work was supported in part by the IST Programme of the European
   Community, under the PASCAL2 Network of Excellence, IST-2007-216886.
   This publication only reflects the authors' views.
CR ADRIAANS P, 2002, ALGEBRAS DIAGRAMS DE, P127
   Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1007/BF00116828
   ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6
   [Anonymous], 1997, HDB FORMAL LANGUAGES, DOI DOI 10.1007/978-3-642-59126-6_2
   [Anonymous], 1967, ALGEBRAIC LINGUISTIC
   Asveld PRJ, 2006, THEOR COMPUT SCI, V354, P118, DOI 10.1016/j.tcs.2005.11.010
   BOASSON L, 1985, J COMPUT SYST SCI, V31, P332, DOI 10.1016/0022-0000(85)90056-X
   Boullier P., 2000, Grammars, V3, P111, DOI 10.1023/A:1009907814595
   Boullier P, 2003, THEOR COMPUT SCI, V293, P391, DOI 10.1016/S0304-3975(01)00353-X
   BOULLIER P, 2001, ELECT NOTES THEORETI, V53
   CARRASCO RC, 1994, LECT NOTES ARTIF INT, V862, P139, DOI DOI 10.1007/3-540-58473-0_144
   Chomsky Noam, 1986, LANGUAGE PROBLEMS KN
   Clark A., 2006, Proceedings of the Third IASTED International Conference on Financial Engineering and Applications, P59
   CLARK A, 2009, P C FORM GRAMM BORD
   Clark A, 2007, J MACH LEARN RES, V8, P1725
   Clark A, 2010, LECT NOTES ARTIF INT, V6339, P24, DOI 10.1007/978-3-642-15488-1_4
   de la Higuera C., 2002, Computational Learning Theory. 15th Annual Conference on Computational Learning Theory, COLT 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2375), P185
   DelaHiguera C, 1997, MACH LEARN, V27, P125, DOI 10.1023/A:1007353007695
   Denis F, 2004, THEOR COMPUT SCI, V313, P267, DOI 10.1016/j.tcs.2003.11.008
   Eyraud R, 2007, MACH LEARN, V66, P7, DOI 10.1007/s10994-006-9593-8
   Gazdar Gerald., 1985, GEN PHRASE STRUCTURE
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   HORNING JJ, 1969, THESIS STANFORD U CA
   Klein Dan, 2004, P 42 ANN M ASS COMP, P478
   Lang K. J., 1998, Grammatical Inference. 4th International Colloquium, ICGI-98. Proceedings, P1, DOI 10.1007/BFb0054059
   Langley P, 2000, LECT NOTES ARTIF INT, V1810, P220
   Mitrana V, 2005, FUND INFORM, V64, P307
   Nakamura K, 2005, PATTERN RECOGN, V38, P1384, DOI 10.1016/j.patcog.2005.01.004
   Oates T, 2006, LECT NOTES ARTIF INT, V4201, P137
   Okhotin A., 2001, Journal of Automata, Languages and Combinatorics, V6, P519
   OKHOTIN A, 2003, FORMAL LANGUAGE THEO, V79, P145
   Parekh R., 1996, Grammatical Inference: Learning Syntax from Sentences. Third International Colloquium, ICGI-96 Proceedings, P238, DOI 10.1007/BFb0033358
   PITT L, 1989, P INT WORKSH AN IND, P18
   Starkie B, 2004, LECT NOTES COMPUT SC, V3264, P16
   Starkie B, 2006, LECT NOTES ARTIF INT, V4201, P214
   Yokomori T, 2003, THEOR COMPUT SCI, V298, P179, DOI 10.1016/S0304-3975(02)00423-1
   YOSHINAKA R, 2008, ICGI 2008, P266
   Yoshinaka R, 2009, LECT NOTES ARTIF INT, V5809, P278, DOI 10.1007/978-3-642-04414-4_24
NR 39
TC 12
Z9 12
U1 2
U2 3
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD OCT
PY 2010
VL 11
BP 2707
EP 2744
PG 38
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA 678AQ
UT WOS:000284040000005
DA 2023-11-10
ER

PT J
AU Huang, H
   Wu, SZ
   Chen, KH
   Liang, XN
   Di, H
   Yang, MY
   Zhao, TJ
AF Huang, Hui
   Wu, Shuangzhi
   Chen, Kehai
   Liang, Xinnian
   Di, Hui
   Yang, Muyun
   Zhao, Tiejun
TI Multi-view fusion for universal translation quality estimation
SO INFORMATION FUSION
LA English
DT Article
DE Translation quality estimation; Machine translation; Pre-trained model;
   Large language model
AB Machine translation quality estimation (QE) aims to evaluate the result of translation without reference. Despite the progress it has made, state-of-the-art QE models are proven to be biased. More specifically, they over-rely on spurious statistical features while ignoring the bilingual semantic adequacy, leading to performance degradation. Besides, existing approaches require large amounts of annotation data, restricting their applications in new domains and languages. In this work, we propose a universal framework for quality estimation based on multi-view fusion. We first introduce noise to the target side of the parallel sentence pair, either by pre-trained language model or by large language model. After that, with the clean parallel pairs and the noised pairs as different views, the QE model is trained to distinguish the clean pairs from the noised ones. Our method can improve the accuracy and generalizability in supervised scenario, and can solely perform estimation in zero-shot scenario. We perform experiments on WMT QE evaluation datasets under different scenarios, verifying the effectiveness of our method. We also make an in-depth investigation of the bias of QE model.
C1 [Huang, Hui; Yang, Muyun; Zhao, Tiejun] Harbin Inst Technol, Fac Comp, Harbin, Peoples R China.
   [Wu, Shuangzhi] ByteDance AI Lab, Beijing, Peoples R China.
   [Chen, Kehai] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
   [Liang, Xinnian] Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China.
   [Di, Hui] Toshiba Co Ltd, Res & Dev Ctr, Beijing, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Beihang
   University
RP Yang, MY (通讯作者)，Harbin Inst Technol, Fac Comp, Harbin, Peoples R China.
EM dihui@toshiba.com.cn; wufurui@bytedance.com; chenkehai@hit.edu.cn;
   xnliang@buaa.edu.cn; dihui@toshiba.com.cn; yangmuyun@hit.edu.cn;
   tjzhao@hit.edu.cn
FU National Natural Science Foundation of China [62276077, U1908216];
   National Key R&D Program of China [2020AAA0108000]; Key RD Program of
   Yunnan, PR China [202203AA080004]; Shenzhen College Stability Support
   Plan, PR China [GXWD20220811170358002]; Global Tone Communication
   Technology Co., Ltd, PR China
FX This work is supported by National Natural Science Foundation of China
   (62276077, U1908216) , National Key R & D Program of China
   (2020AAA0108000) , Key RD Program of Yunnan, PR China (202203AA080004)
   and Shenzhen College Stability Support Plan, PR China (No.
   GXWD20220811170358002) . Muyun Yang is also partially supported by a
   joint project with Global Tone Communication Technology Co., Ltd, PR
   China.
CR Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Bang Y, 2023, Arxiv, DOI arXiv:2302.04023
   Behnke H, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1475
   Blatz J., 2004, COLING 2004, P315
   Burchardt A, 2013, P TRANSL COMP ASL LO, V35
   Conneau Alexis, 2020, ASS COMPUT LINGUIST, P8440, DOI [10.18653/v1/2020.acl-main.747, DOI 10.18653/V1/2020.ACL-MAIN, DOI 10.18653/V1/2020.ACL-MAIN.747]
   Cui Q, 2021, AAAI CONF ARTIF INTE, V35, P12719
   Devlin J., 2018, ARXIV, V1, P4171
   Fomicheva M., 2020, ARXIV
   Fomicheva M, 2020, T ASSOC COMPUT LING, V8, P539, DOI 10.1162/tacl_a_00330
   Fonseca E, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, DAY 2, P1
   Geng X., 2023, P AAAI C ART INT, V37, P12827
   Graham Y, 2017, NAT LANG ENG, V23, P3, DOI 10.1017/S1351324915000339
   Kepler F, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, DAY 2, P78
   Kepler F, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P117
   Kim H., 2016, P 2016 C N AM CHAPT, P494, DOI [10.18653/v1/N16-1059, DOI 10.18653/V1/N16-1059]
   Kim H, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, DAY 2, P85
   Kim Yoon, 2016, ARXIV160607947, DOI DOI 10.18653/V1
   Kreutzer J., 2015, P 10 WORKSH STAT MAC, P316, DOI [10.18653/v1/W15-3037, DOI 10.18653/V1/W15-3037]
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Liang Percy, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2211.09110
   Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100
   Martins A.F.T., 2017, T ASSOC COMPUT LING, V5, P205, DOI [DOI 10.1162/TACL_A_00056, 10.1162/tacl_a_00056]
   Qin C., 2023, ARXIV
   Ranasinghe Tharindu, 2020, P 28 INT C COMP LING, P5070
   Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2685
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Schwenk H, 2019, Arxiv, DOI [arXiv:1907.05791, 10.48550/ARXIV.1907.05791, DOI 10.48550/ARXIV.1907.05791]
   Shao YF, 2022, Arxiv, DOI arXiv:2109.05729
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, P223
   Specia L., 2021, P 6 C MACH TRANSL AS, P684
   Sun S., 2020, P 58 ANN M ASS COMP, P6262, DOI [10.18653/v1/2020.acl-main.558, DOI 10.18653/V1/2020.ACL-MAIN.558]
   Sung S, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P366
   Tuan YL, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P619
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Wang TZ, 2022, Arxiv, DOI arXiv:2005.10242
   Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, DOI 10.48550/ARXIV.2201.11903]
   Yang ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6191
   Zerva C., 2022, P 7 C MACH TRANSL WM, P69
   2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 40
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD FEB
PY 2024
VL 102
AR 102022
DI 10.1016/j.inffus.2023.102022
EA SEP 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U3GI9
UT WOS:001083713100001
DA 2023-11-10
ER

PT S
AU Gao, GL
   Biligetu
   Nabuqing
   Zhang, SW
AF Gao, Guanglai
   Biligetu
   Nabuqing
   Zhang, Shuwu
BE Huang, DS
   Li, K
   Irwin, GW
TI A Mongolian speech recognition system based on HMM
SO COMPUTATIONAL INTELLIGENCE, PT 2, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT International Conference on Intelligent Computing (ICIC)
CY AUG 16-19, 2006
CL Kunming, PEOPLES R CHINA
SP IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China
AB Speaker independent large vocabulary continuous speech recognition technique has always been the research focus in the domain of artificial intelligence and pattern recognition. A Mongolian large vocabulary continuous speech recognition system is introduced in this paper. Mongolian is belonged to Altai phylum, and similar with the Western language. According to the characteristics of Mongolian pronunciation, we build the Mongolian acoustic model. We collected a large size corpus to construct the language model. HTK (HMM Toolkit) has been used to construct the system. The experimental results indicated that the design of models related to the Mongolian speech recognition is rational and correct.
C1 Inner Mongolia Univ, Coll Comp Sci, Hohhot 010021, Peoples R China.
   Chinese Acad Sci, Inst Automat, Beijing 100080, Peoples R China.
C3 Inner Mongolia University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Gao, GL (通讯作者)，Inner Mongolia Univ, Coll Comp Sci, Hohhot 010021, Peoples R China.
EM csggl@imu.edu.cn
CR DENG L, 1994, IEEE T SPEECH AUD PR, V2
   du Preez JA, 1998, COMPUT SPEECH LANG, V12, P23, DOI 10.1006/csla.1997.0037
   GAO S, 2000, ACOUSTIC MODELING SE
   JELINEK F, 1980, INTERPOLATED ESTIMAT, P381
   KNOWN O, 1996, IEEE SIGNAL PROCESSI, V3
   LAWRENEC R, 1989, P IEEE, V77
   LI J, 2004, J TSINGHUA U SCI TEC, V24, P61
   MARI JF, 1997, IEEE T SPEECH AUDIO, V5
   QING G, 1995, MONGOLIAN GRAMMER
   WUHUA, 2000, SOFTWARE T, P271
NR 10
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-37274-1
J9 LECT NOTES ARTIF INT
PY 2006
VL 4114
BP 667
EP 676
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BEY13
UT WOS:000240083300084
DA 2023-11-10
ER

PT J
AU Gajecki, L
AF Gajecki, Leszek
TI Architectures of neural networks applied for LVCSR language modeling
SO NEUROCOMPUTING
LA English
DT Article
DE Language modeling; Speech recognition; Neural network architectures;
   Self-organized maps
AB The n-gram model and its derivatives are both widely applied solutions for Large Vocabulary Continuous Speech Recognition (LVCSR) systems. However, Slavonic languages require a language model that considers word order less strictly than English, i.e. the language that is the subject of most linguistic research. Such a language model is a necessary module in LVCSR systems, because it increases the probability of finding the right word sequences. The aim of the presented work is to create a language module for the Polish language with the application of neural networks. Here, the capabilities of Kohonen's Self-Organized Maps will be explored to find the associations between words in spoken utterances. To fulfill such a task, the application of neural networks to evaluate sequences of words will be presented. Then, the next step of language model development, the network architectures, will be discussed. The network proposed for the construction of the considered model is inspired by the Cocke-Young-Kasami parsing algorithm. (C) 2014 Elsevier B.V. All rights reserved.
C1 Univ Informat Technol & Management, PL-35205 Rzeszow, Poland.
C3 University of Information Technology & Management Rzeszow
RP Gajecki, L (通讯作者)，Univ Informat Technol & Management, Ul Sucharskiego 2, PL-35205 Rzeszow, Poland.
EM lgajecki@wsiz.rzeszow.pl
OI Gajecki, Leszek/0000-0001-6665-9690
FU Polish National Center of Science (Ph.D.) [N516 513439]; Podkarpackie
   Voivodship Scholarship Fund; Malopolska Ph.D. Scholarships
FX Word lattices used in research were generated by the Laboratory of
   Integrated Speech and Language Processing Systems, Poznan
   Super-computing and Networking Centre, Poland. Author would thank to the
   Head of Laboratory Professor Grazyna Demenko, and to Marek Lange, who
   prepared these lattices. This research was supported by Polish National
   Center of Science (Ph.D. Grant no. N516 513439), and by Podkarpackie
   Voivodship Scholarship Fund. Part of works was performed on computer,
   which was funded by Malopolska Ph.D. Scholarships. Author would thank
   also to James Graham from University Ohio and Joanna Kurek for language
   correction.
CR [Anonymous], 2008, SPRINGER HDB SPEECH
   Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137
   Brocki Lukasz, 2010, THESIS WARSZAWA
   Brocki Lukasz, 2008, SPEECH LANG TECHNOL, V11, P55
   Castro MJ, 2003, LECT NOTES COMPUT SC, V2686, P598
   Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chou W, 2003, PATTERN RECOGNITION IN SPEECH AND LANGUAGE PROCESSING, P1
   Demenko G., 2008, P LREC C MARR MOR
   Demenko G., 2011, P 17 INT C PHON SCI
   Duchateau J., 1998, THESIS KATHOLIEKE U
   Emami A, 2005, MACH LEARN, V60, P195, DOI 10.1007/s10994-005-0916-y
   Erdogan H, 2005, COMPUT SPEECH LANG, V19, P321, DOI 10.1016/j.csl.2004.10.002
   ESAT-PSI, 2006, DESCR ESAT SPEECH RE
   Gajecki L, 2008, SPEECH LANGUAGE TECN, V11, P55
   Gajecki L., 2011, P 5 LANG TECHN C FUN, P216
   Hnatkowska B., 2008, J MED INFORM TECHNOL, V12
   Hopcroft J. E., 2006, INTRO AUTOMATA THEOR, V3rd
   IPI PAN, 2006, CORP POL
   Jelinek F., 1992, Speech Recognition and Understanding. Recent Advances, Trends and Applications. Proceedings of the NATO Advanced Study Institute, P345
   Jelinek F., 1997, STAT METHODS SPEECH
   Kohonen T., 2001, SELF ORG MAPS
   Korzinek D, 2007, RECENT ADVANCES IN MECHATRONICS, P87, DOI 10.1007/978-3-540-73956-2_18
   Lawrence S, 1996, IEEE IJCNN, P1853, DOI 10.1109/ICNN.1996.549183
   Melin P., 2005, HYBRID INTELLIGENT S, P109
   Mikolov T, 2009, INT CONF ACOUST SPEE, P4725, DOI 10.1109/ICASSP.2009.4960686
   Ney H., 1997, HDB STANDARDS RESOUR, V2, P91
   Pollard C, 1994, HEAD DRIVEN PHRASE S
   Przepiorkowski A., 2002, FORMALNY OPIS JEZYKA
   Przepiorkowski A., 2008, POWIERZCHNIOWE PRZET
   Przepiorkowski A., 2004, IPI PAN CORPUS PRIMA
   RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171
   Stolcke A., 2000, P INT C SPOK LANG PR
   Szymanski M., 2008, SPEECH LANG TECHNOL, V11, P39
   Tadeusiewicz R., 2010, COMPUT METHODS MAT S, V10, P1
   Tadeusiewicz R, 2008, STUD COMPUT INTELL, V122, P135
   Van Uytsel DH, 2005, COMPUT SPEECH LANG, V19, P171, DOI 10.1016/j.csl.2004.05.009
   Xu W, 2000, P ICSLP 2000 BEIJ CH
NR 38
TC 7
Z9 7
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUN 10
PY 2014
VL 133
BP 46
EP 53
DI 10.1016/j.neucom.2013.11.033
PG 8
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AF1NU
UT WOS:000334481400005
DA 2023-11-10
ER

PT S
AU Byrne, W
   Hajic, J
   Ircing, P
   Jelinek, F
   Khudanpur, S
   McDonough, J
   Peterek, N
   Psutka, J
AF Byrne, W
   Hajic, J
   Ircing, P
   Jelinek, F
   Khudanpur, S
   McDonough, J
   Peterek, N
   Psutka, J
BE Matousek, V
   Mautner, P
   Ocelikova, J
   Sojka, P
TI Large vocabulary speech recognition for read and broadcast Czech
SO TEXT, SPEECH AND DIALOGUE
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Text, Speech and Diaglogue (TSD 99)
CY SEP 13-17, 1999
CL PLZEN, CZECH REPUBLIC
SP Medav GmbH, SpeechWorks, Univ Bohemia, Fac Appl Sci, Masaryk Univ
AB We describe read speech and broadcast news corpora collected as part of a multi-year international collaboration for the development of large vocabulary speech recognition systems in the Czech language. Initial investigations into language modeling for Czech automatic speech recognition are described and preliminary recognition results on the read speech corpus are presented.
C1 Johns Hopkins Univ, Baltimore, MD 21218 USA.
   Charles Univ, Prague, Czech Republic.
   Univ W Bohemia, Pilsen, Czech Republic.
C3 Johns Hopkins University; Charles University Prague; University of West
   Bohemia Pilsen
RP Byrne, W (通讯作者)，Johns Hopkins Univ, Baltimore, MD 21218 USA.
RI Khudanpur, Sanjeev P/A-3327-2010; Peterek, Nino/HSF-8425-2023; Ircing,
   Pavel/C-4543-2011; Hajic, Jan/D-3429-2017
OI Ircing, Pavel/0000-0001-6967-1687; Hajic, Jan/0000-0002-3503-7730;
   Khudanpur, Sanjeev/0000-0001-5976-0897; Byrne,
   William/0000-0003-1896-4492
CR GEUTNER P, 1998, ADAPTIVE VOCABULARIE
   HAJIC J, 1998, VALENCY MEANING, P106
   HAJIC J, 1984, THESIS CHARLES U PRA
   MOHRI M, 1998, FULL EXPANSION CONTE
   NOUZA J, 1997, PHONETIC ALPHABET SP, V6, P16
   PSUTKA J, 1995, COMMUNICATION COMPUT
   Young S., 1999, HTK BOOK
NR 7
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-66494-7
J9 LECT NOTES ARTIF INT
PY 1999
VL 1692
BP 235
EP 240
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BQ71V
UT WOS:000089259200043
DA 2023-11-10
ER

PT J
AU Han, SJ
   Ransom, KJ
   Perfors, A
   Kemp, C
AF Han, Simon Jerome
   Ransom, Keith J.
   Perfors, Andrew
   Kemp, Charles
TI Inductive reasoning in humans and large language models
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Reasoning; Property induction; Category-based induction;
   Non-monotonicity; Neural networks; GPT-3.5; GPT-4; AI; Large language
   models; Representation
ID SIMILARITY; JUDGMENTS; UNIVERSAL; LOGIC
AB The impressive recent performance of large language models has led many to wonder to what extent they can serve as models of general intelligence or are similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4 to a classic problem in human inductive reasoning known as property induction. Over two experiments, we elicit human judgments on a range of property induction tasks spanning multiple domains. Although GPT-3.5 struggles to capture many aspects of human behavior, GPT-4 is much more successful: for the most part, its performance qualitatively matches that of humans, and the only notable exception is its failure to capture the phenomenon of premise non-monotonicity. Our work demonstrates that property induction allows for interesting comparisons between human and machine intelligence and provides two large datasets that can serve as benchmarks for future work in this vein.
C1 [Han, Simon Jerome; Ransom, Keith J.; Perfors, Andrew; Kemp, Charles] Univ Melbourne, Parkville, Australia.
C3 University of Melbourne
RP Han, SJ (通讯作者)，Univ Melbourne, Parkville, Australia.
EM simon.jerome.han@gmail.com
FU Complex Human Data Hub at the University of Melbourne; Australian
   Research Council [FT190100200]
FX This work was supported in part by the Complex Human Data Hub at the
   University of Melbourne and by Australian Research Council Grant
   FT190100200.
CR Anderson J. R., 1990, ADAPTIVE CHARACTER T
   Bhatia S, 2022, PSYCHOL REV, DOI 10.1037/rev0000319
   Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120
   Brewka G., 1997, NONMONOTONIC REASONI, V73
   Brunswik E., 1957, CONT APPROACHES COGN, P5
   Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]
   Carey S., 1985, CONCEPTUAL CHANGE CH
   Chang TA, 2023, Arxiv, DOI arXiv:2303.11504
   Chater N, 2011, HBK HIST LOGIC, V10, P553
   COLLINS A, 1989, COGNITIVE SCI, V13, P1, DOI 10.1207/s15516709cog1301_1
   Davis E, 2015, COMMUN ACM, V58, P92, DOI 10.1145/2701413
   De Deyne S, 2008, BEHAV RES METHODS, V40, P1030, DOI 10.3758/BRM.40.4.1030
   Frank M. C., 2023, NATURE REV PSYCHOL, P1
   GELMAN SA, 1986, COGNITION, V23, P183, DOI 10.1016/0010-0277(86)90034-X
   GELMAN SA, 1988, COGNITIVE PSYCHOL, V20, P65, DOI 10.1016/0010-0285(88)90025-4
   Glick J. J. P., 2011, THESIS STANFORD U
   Hagendorff T, 2023, Arxiv, DOI arXiv:2303.13988
   Han S. J., 2022, P ANN M COGN SCI SOC
   Hayes BK, 2019, PSYCHON B REV, V26, P1043, DOI 10.3758/s13423-018-1562-2
   Hayes BK, 2018, WIRES COGN SCI, V9, DOI 10.1002/wcs.1459
   HEIT E, 1994, J EXP PSYCHOL LEARN, V20, P411, DOI 10.1037/0278-7393.20.2.411
   Heit E., 1998, RATIONAL MODELS COGN, P248
   Holland J.H., 1989, INDUCTION PROCESSES
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1725
   Jiang GY, 2023, Arxiv, DOI arXiv:2306.00503
   Keil F. C., 1989, CONCEPTS KINDS COGNI
   Kemp C., 2011, ADV NEURAL INFORM PR, V24, P316
   Kemp C, 2014, PSYCHON B REV, V21, P23, DOI 10.3758/s13423-013-0467-3
   Kemp C, 2012, COGNITIVE PSYCHOL, V64, P35, DOI 10.1016/j.cogpsych.2011.10.001
   Kemp C, 2010, ACTA PSYCHOL, V133, P216, DOI 10.1016/j.actpsy.2009.11.012
   Kemp C, 2009, PSYCHOL REV, V116, P20, DOI 10.1037/a0014282
   Kiciman E, 2023, Arxiv, DOI arXiv:2305.00050
   Lake BM, 2023, PSYCHOL REV, V130, P401, DOI 10.1037/rev0000297
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813
   Lipkin B, 2023, Arxiv, DOI arXiv:2305.01020
   Lopez A, 1997, COGNITIVE PSYCHOL, V32, P251, DOI 10.1006/cogp.1997.0651
   LOPEZ A, 1992, CHILD DEV, V63, P1070, DOI 10.1111/j.1467-8624.1992.tb01681.x
   Magar I., 2022, ARXIV
   Medin DL, 2003, PSYCHON B REV, V10, P517, DOI 10.3758/BF03196515
   Misra K., 2021, P 43 ANN M COGN SCI, P216
   Mitchell M., 2023, SCIENCE, V381
   MURPHY GL, 1985, PSYCHOL REV, V92, P289, DOI 10.1037/0033-295X.92.3.289
   Olsson C., 2022, IN CONTEXT LEARNING
   OpenAI, 2023, GPT 4 TECHN REP
   OpenAI, 2022, NEW IMPR EMB MOD
   OSHERSON DN, 1990, PSYCHOL REV, V97, P185, DOI 10.1037/0033-295X.97.2.185
   Pothos E. M., 2011, FORMAL APPROACHES CA
   Proffitt JB, 2000, J EXP PSYCHOL LEARN, V26, P811, DOI 10.1037/0278-7393.26.4.811
   Ransom KJ, 2016, COGNITIVE SCI, V40, P1775, DOI 10.1111/cogs.12308
   RIPS LJ, 1975, J VERB LEARN VERB BE, V14, P665, DOI 10.1016/S0022-5371(75)80055-7
   RIPS LJ, 1989, SIMILARITY AND ANALOGICAL REASONING, P21, DOI 10.1017/CBO9780511529863.004
   Rogers T. T., 2004, SEMANTIC COGNITION P
   Rogers TT, 2014, COGNITIVE SCI, V38, P1024, DOI 10.1111/cogs.12148
   Sap M., 2019, P 2019 EMNLP IJCNLP
   Shapira N, 2023, Arxiv, DOI arXiv:2305.14763
   SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243
   Simon HA., 1970, SCI ARTIFICIAL
   Sloman S. A., 2005, CAMBRIDGE HDB THINKI, P95
   SLOMAN SA, 1993, COGNITIVE PSYCHOL, V25, P231, DOI 10.1006/cogp.1993.1006
   SMITH EE, 1993, COGNITION, V49, P67, DOI 10.1016/0010-0277(93)90036-U
   Srivastava Aarohi, 2022, ARXIV, DOI 10.48550/arXiv.2206.04615
   Storks S, 2020, Arxiv, DOI arXiv:1904.01172
   Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009
   Todd PM, 2007, CURR DIR PSYCHOL SCI, V16, P167, DOI 10.1111/j.1467-8721.2007.00497.x
   Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]
   Ullman TD, 2023, Arxiv, DOI arXiv:2302.08399
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Voorspoels W, 2015, COGNITIVE PSYCHOL, V81, P1, DOI 10.1016/j.cogpsych.2015.07.001
   Vosniadou Stella, 1989, SIMILARITY ANALOGICA
   Rae JW, 2022, Arxiv, DOI [arXiv:2112.11446, DOI 10.48550/ARXIV.2112.11446]
   Webb T., 2022, ARXIV
   Zhang S., 2023, YOU ARE WHAT YOURE E
NR 73
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-4366
EI 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD JAN
PY 2024
VL 83
AR 101155
DI 10.1016/j.cogsys.2023.101155
EA SEP 2023
PG 28
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology; Psychology
GA T5UP3
UT WOS:001078641500001
OA Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Huang, B
   Zhang, S
   Huang, JT
   Yu, YJ
   Shi, ZC
   Xiong, YJ
AF Huang, Bo
   Zhang, Shuai
   Huang, Jitao
   Yu, Yijun
   Shi, Zhicai
   Xiong, Yujie
TI Knowledge distilled pre-training model for vision-language-navigation
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Natural language processing; Computer vision; Cross-modality; Deep
   learning
AB Vision-language-navigation(VLN) is a challenging task that requires a robot to autonomously move to a destination based on visual observation following a human's natural language instructions. To improve the performance and generalization ability, the pre-training model based on the transformer is used instead of the traditional methods. However, the pre-training model is not suitable for sustainable computing and practical application because of its complex computations and large amount of hardware occupation. Therefore, we propose a slight pre-training model through knowledge distillation. Through knowledge distillation, the plenty of knowledge encoded in a large "teacher" model can be well transferred to a small "student" model, which greatly reduces the model parameters and inference time while maintaining the original performance. In the experiments, the model size is reduced by 87%, and the average inference time is reduced by approximately 86%. It can be trained and run much faster. At the same time, 95% performance of the original model was maintained, which is still better than the traditional VLN models.
C1 [Huang, Bo; Zhang, Shuai; Yu, Yijun; Xiong, Yujie] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai, Peoples R China.
   [Huang, Jitao; Shi, Zhicai] China Telecom Corp Ltd, Shanghai Branch, Shanghai, Peoples R China.
   Shanghai Key Lab Integrated Adm Technol Informat, Shanghai, Peoples R China.
C3 Shanghai University of Engineering Science; China Telecom Corp. Ltd.
RP Huang, B (通讯作者)，Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai, Peoples R China.
EM huangbosues@sues.edu.cn; 854400656@qq.com; 421024976@qq.com;
   1210947362@qq.com; szc1964@163.com; xiong@sues.edu.cn
OI Huang, Bo/0000-0002-5476-620X
FU Scientific and Technological Innovation 2030 - Major Project of New
   Generation Artificial Intelligence [2020AAA0109300]; Shanghai Science
   and Technology Young Talents Sailing Program [19YF1418400]; National
   Natural Science Foundation of China [62006150]; Shanghai Science and
   Technology Innovation Action Plan [22S31903700, 21S31904200]; Songjiang
   District Science and Technology Research Project [19SJKJGG83]; Shanghai
   Local Capacity Enhancement Project [21010501500]
FX This work is sponsored by the Scientific and Technological Innovation
   2030 - Major Project of New Generation Artificial Intelligence (No.
   2020AAA0109300), the Shanghai Science and Technology Young Talents
   Sailing Program (No. 19YF1418400), the National Natural Science
   Foundation of China (No. 62006150), the Shanghai Science and Technology
   Innovation Action Plan (22S31903700, 21S31904200), the Songjiang
   District Science and Technology Research Project (No.19SJKJGG83), and
   Shanghai Local Capacity Enhancement Project (No. 21010501500).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Cao J, 2020, EUROPEAN C COMPUTER
   Catelli R, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106779
   Chi PH, 2021, IEEE W SP LANG TECH, P344, DOI 10.1109/SLT48900.2021.9383575
   Fried D, 2018, ARXIV 180602724
   Ganesh P, 2021, T ASSOC COMPUT LING, V9, P1061, DOI 10.1162/tacl_a_00413
   Guarasci R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03297-4
   Hao Weituo, 2020, P IEEE CVF C COMP VI, P13137, DOI DOI 10.1109/CVPR42600.2020.01315
   He Y, 2020, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR42600.2020.00208
   Hinton G., 2014, NEURIPS DEEP LEARN R, DOI DOI 10.48550/ARXIV.1503.02531
   Hubara I, 2018, J MACH LEARN RES, V18
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Landi F, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103255
   Li X, 2019, ARXIV 190902244
   Liu GY, 2021, IEEE T NEUR NET LEAR, V32, P3786, DOI 10.1109/TNNLS.2021.3099165
   Liu Wenjie, 2021, IEEE T NEUR NET LEAR
   Liu Y, 2020, NEUROCOMPUTING, V415, P106, DOI 10.1016/j.neucom.2020.07.048
   Lu JS, 2019, ADV NEUR IN, V32
   Nguyen K, 2019, ARXIV 190901871
   Pota M, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115119
   Riaz N, 2021, 2021 INTERNATIONAL CONFERENCE ON DIGITAL FUTURES AND TRANSFORMATIVE TECHNOLOGIES (ICODT2), DOI 10.1109/ICoDT252288.2021.9441516
   Sanh V, 2019, ARXIV 191001108
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Tan H, 2019, ARXIV 190404195
   Vapnik V, 2015, J MACH LEARN RES, V16, P2023
   Wang XD, 2022, IEEE T CYBERNETICS, V52, P13293, DOI 10.1109/TCYB.2021.3130047
   Wu MC, 2020, J SYST ARCHITECT, V103, DOI 10.1016/j.sysarc.2019.101695
   Xin Wang, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P6622, DOI 10.1109/CVPR.2019.00679
   Yeom SK, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107899
   Yi Zhu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10727, DOI 10.1109/CVPR42600.2020.01074
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
NR 31
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD MAR
PY 2023
VL 53
IS 5
BP 5607
EP 5619
DI 10.1007/s10489-022-03779-8
EA JUN 2022
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A3ZV8
UT WOS:000819298900002
DA 2023-11-10
ER

PT J
AU Mauco, MV
   Leonardi, MC
AF Mauco, Maria Virginia
   Leonardi, Maria Carmen
TI A derivation strategy for formal specifications from natural language
   requirements models
SO COMPUTING AND INFORMATICS
LA English
DT Article
DE language extended lexicon; scenario model; business rules model; formal
   specifications; RAISE method
AB Formal methods have come into use for the construction of real systems, as they help increase software quality and reliability. However, they are usually accessible only to specialists, thus discouraging stakeholders' participation, crucial in first steps of software development. To address this problem, we present in this paper a strategy to derive an initial formal specification, written in the RAISE Specification Language, from requirements models based on natural language, such as the Language Extended Lexicon, the Scenario Model, and the Business Rules Model, which are closer to the stakeholders' language. We provide a set of heuristics which show how to derive types and functions, and how to structure them in a layered architecture, thus contributing to fruitfully use the large amount of information usually available after requirements modelling stage. In addition, we illustrate the. strategy with a concrete case study.
C1 Univ Nacl Ctr Pcia Buenos Aires, Fac Ciencias Exactas, Tandil, Argentina.
RP Mauco, MV (通讯作者)，Univ Nacl Ctr Pcia Buenos Aires, Fac Ciencias Exactas, Tandil, Argentina.
EM vmauco@exa.unicen.edu.ar; cleonard@exa.unicen.edu.ar
CR Ambriola V., 2006, Automated Software Engineering, V13, P107, DOI 10.1007/s10515-006-5468-2
   [Anonymous], 2000, C FUTURE SOFTWARE EN
   [Anonymous], P MON WORKSH SOFTW E
   BERRY B, 2006, P 12 INT WORKSH REQ
   BJORNER D, 2000, SOFTWARE ENG
   BUSCHMAN F, 1996, PATTERNORIENTED SOFT
   DANG VH, 2002, SPECIFICATION CASE S
   DIAZ I, 2004, P IDEAS2004 WORKSH I, P270
   do P. Leite J. C. S., 2000, Requirements Engineering, V5, P38, DOI 10.1007/PL00010342
   GEORGE C, 2002, INTRO RAISE, V249
   GEORGE C, 2001, RAISE TOOLS USER GUI
   Gervasi V, 2002, SOFTWARE PRACT EXPER, V32, P113, DOI 10.1002/spc.430
   Juristo N, 2000, IEEE SOFTWARE, V17, P80, DOI 10.1109/52.896254
   KAPLAN N, 2000, P 3 WORKSH REQ ENG, P70
   LEE B, 2002, P SESEC 2002 2002 SE
   Leite JCSD, 2005, REQUIR ENG, V10, P1, DOI 10.1007/s00766-003-0186-9
   Leite JCSD, 1998, NINTH INTERNATIONAL WORKSHOP ON SOFTWARE SPECIFICATION AND DESIGN, PROCEEDINGS, P68, DOI 10.1109/IWSSD.1998.667921
   LEONARDI MC, 2001, THESIS FACULTAD INFO
   LEONARDI MC, 2002, LECT NOTES CONPUTER, P420
   LEONARDI MC, 2005, ENCY INFORM SCI TECH, P339
   Mauco MV, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY (ISSPIT), VOLS 1 AND 2, P646
   MAUCO MV, 2005, ENCY INFORM SCI TECH, V1, P1555
   MAUCO MV, 2004, THESIS FACULTAD INFO
   Nuseibeh Bashar, 2000, P C FUTURE SOFTWARE, P35, DOI DOI 10.1145/336512.336523
   *RAISE LANG GROUP, 1995, RAISE DEV METHOD
   *RAISE LANG GROUP, 1992, RAIS SPEC LANG
   *SBVR, OMG AD SPEC
   SCHWITTER R, 1996, P JOINT INT C S LOG, P536
   WEI K, 2000, 208 UN U INT I SOFTW
NR 29
TC 3
Z9 3
U1 0
U2 2
PU SLOVAK ACAD SCIENCES INST INFORMATICS
PI BRATISLAVA
PA DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA
SN 1335-9150
J9 COMPUT INFORM
JI Comput. Inform.
PY 2007
VL 26
IS 4
BP 421
EP 445
PG 25
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201AF
UT WOS:000248803200004
DA 2023-11-10
ER

PT J
AU Zitouni, I
AF Zitouni, Imed
TI Backoff hierarchical class <i>n</i>-gram language models:: effectiveness
   to model unseen events in speech recognition
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB In this paper, we introduce the backoff hierarchical class n-gram language models to better estimate the likelihood of unseen n-gram events. This multi-level class hierarchy language modeling approach generalizes the well-known backoff n-gram language modeling technique. It uses a class hierarchy to define word contexts. Each node in the hierarchy,is a class that contains all the words of its descendant nodes. The closer a node to the root, the more general the class (and context) is. We investigate the effectiveness of the approach to model unseen events in speech recognition. Our results illustrate that the proposed technique outperforms backoff n-gram language models. We also study the effect of the vocabulary size and the depth of the class hierarchy on the performance of the approach. Results are presented on Wall Street Journal (WSJ) corpus using two vocabulary set: 5000 words and 20,000 words. Experiments with 5000 word vocabulary, which contain a small numbers of unseen events in the test set, show up to 10% improvement of the unseen event perplexity when using the hierarchical class n-gram language models. With a vocabulary of 20,000 words, characterized by a larger number of unseen events, the perplexity of unseen events decreases by 26%, while the word error rate (WER) decreases by 12% when using the hierarchical approach. Our results suggest that the largest gains in performance are obtained when the test set contains a large number of unseen events. (c) 2006 Elsevier Ltd. All rights reserved.
RP Zitouni, I (通讯作者)，IBM Corp, Thomas J Watson Res Ctr, Multilingual NLP, POB 218,20-136, Yorktown Hts, NY 10598 USA.
EM izitouni@us.ibm.com
CR [Anonymous], INT JOINT C NEUR NET
   [Anonymous], READINGS SPEECH RECO, DOI 10.1016/B978-0-08-051584-7.50045-0
   BAHL L, 1987, IEEE T ACOUSTICS SPE, V37, P1001
   BAI S, 1998, P ICASSP 1998
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   BILMES JA, 2003, P HLT NAACL CAN MAY
   Breiman L, 1984, CLASSIFICATION ALGOR, V40, P358, DOI 10.1201/9781315139470
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Cover T. M., 2005, ELEM INF THEORY, DOI 10.1002/047174882X
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   DUPONT P, 1997, CMUCS97173
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   GUPTA V, 1992, COMPUTER SPEECH LANG, P331
   HEEMAN PA, 1999, JOINT SIGDAT C EMP M, P129
   KATZ SM, 1987, IEEE T ACOUSTIC SPEE, V35
   LI H, 1995, EUR 95 MADR SPAIN
   MacQueen J.., 1967, P 5 BERK S MATH STAT, V281
   MILLER JW, 1996, P ICSLP 1996
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   SAMUELSSON C, 1999, P ICASSP 1999
   SUHM B, 1994, P ICSLP 1994
   XU P, 2004, C EMP METH NAT LANG
   ZHOU Q, 1997, P IEEE INT C AC SPEE, P1779
   ZITOUNI I, 2003, P IEEE ASRU 2003 ST
   ZITOUNI I, 2003, P EUR 2003 GEN SWITZ
   ZITOUNI I, 2003, P IEEE NLPKE 2003 BE
   ZITOUNI L, 2002, P ICSLP 2002 DENV US
NR 27
TC 19
Z9 21
U1 0
U2 2
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2007
VL 21
IS 1
BP 88
EP 104
DI 10.1016/j.csl.2006.01.001
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 102EW
UT WOS:000241794800005
DA 2023-11-10
ER

PT J
AU Church, KW
   Yue, R
AF Church, Kenneth Ward
   Yue, Richard
TI Emerging trends: Smooth-talking machines
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Large language models; Hallucinations; ChatGPT; Responsible AI
ID COMPUTER
AB Large language models (LLMs) have achieved amazing successes. They have done well on standardized tests in medicine and the law. That said, the bar has been raised so high that it could take decades to make good on expectations. To buy time for this long-term research program, the field needs to identify some good short-term applications for smooth-talking machines that are more fluent than trustworthy.
C1 [Church, Kenneth Ward; Yue, Richard] Northeastern Univ, Inst Experiential AI, San Jose, CA 95113 USA.
RP Church, KW (通讯作者)，Northeastern Univ, Inst Experiential AI, San Jose, CA 95113 USA.
EM k.church@northeastern.edu
OI Church, Kenneth/0000-0001-8378-6069; Yue, Richard/0009-0009-4135-5629
CR Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Church K., 2022, NAT LANG ENG, V29, P483
   Church K., 2011, LINGUISTIC ISSUES LA, V6, P1
   Church K. W., 1993, Machine Translation, V8, P239, DOI 10.1007/BF00981759
   Church KW, 2023, NAT LANG ENG, V29, P824, DOI 10.1017/S1351324923000141
   Dorr B., 2011, MACH TRANSL, P745
   Firth JR, 1957, STUDIES LINGUISTIC A, P10
   Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3
   Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   STEWART KK, 1985, J AUTOM CHEM, V7, P169, DOI 10.1155/S1463924685000360
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
NR 12
TC 0
Z9 0
U1 1
U2 1
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD SEP
PY 2023
VL 29
IS 5
BP 1402
EP 1410
DI 10.1017/S1351324923000463
PG 9
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA R2BC5
UT WOS:001062434100008
OA hybrid
DA 2023-11-10
ER

PT J
AU Frey, NC
   Soklaski, R
   Axelrod, S
   Samsi, S
   Gómez-Bombarelli, R
   Coley, CW
   Gadepally, V
AF Frey, Nathan C.
   Soklaski, Ryan
   Axelrod, Simon
   Samsi, Siddharth
   Gomez-Bombarelli, Rafael
   Coley, Connor W.
   Gadepally, Vijay
TI Neural scaling of deep chemical models
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article; Early Access
AB Massive scale, in terms of both data availability and computation, enables important breakthroughs in key application areas of deep learning such as natural language processing and computer vision. There is emerging evidence that scale may be a key ingredient in scientific deep learning, but the importance of physical priors in scientific domains makes the strategies and benefits of scaling uncertain. Here we investigate neural-scaling behaviour in large chemical models by varying model and dataset sizes over many orders of magnitude, studying models with over one billion parameters, pre-trained on datasets of up to ten million datapoints. We consider large language models for generative chemistry and graph neural networks for machine-learned interatomic potentials. We investigate the interplay between physical priors and scale and discover empirical neural-scaling relations for language models in chemistry with a scaling exponent of 0.17 for the largest dataset size considered, and a scaling exponent of 0.26 for equivariant graph neural network interatomic potentials.
C1 [Frey, Nathan C.; Soklaski, Ryan; Samsi, Siddharth; Gadepally, Vijay] MIT, Lincoln Lab, Lexington, MA 02421 USA.
   [Axelrod, Simon; Gomez-Bombarelli, Rafael] MIT, Dept Mat Sci & Engn, Cambridge, MA USA.
   [Axelrod, Simon] Harvard Univ, Dept Chem & Chem Biol, Cambridge, MA USA.
   [Coley, Connor W.] MIT, Dept Chem Engn, Cambridge, MA USA.
   [Coley, Connor W.] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA USA.
   [Frey, Nathan C.] Genentech Inc, Prescient Design, New York, NY 10001 USA.
   [Soklaski, Ryan] Anthropic, San Francisco, CA USA.
C3 Massachusetts Institute of Technology (MIT); Lincoln Laboratory;
   Massachusetts Institute of Technology (MIT); Harvard University;
   Massachusetts Institute of Technology (MIT); Massachusetts Institute of
   Technology (MIT); Roche Holding; Genentech
RP Frey, NC (通讯作者)，MIT, Lincoln Lab, Lexington, MA 02421 USA.; Frey, NC (通讯作者)，Genentech Inc, Prescient Design, New York, NY 10001 USA.
EM freyn6@gene.com
OI /0000-0002-8271-8723
FU We acknowledge the MIT SuperCloud and the Lincoln Laboratory
   Supercomputing Center for providing HPC and consultation resources that
   contributed to the research results reported within this paper. We
   acknowledge the MIT SuperCloud team: W. Arcand, D. Besto
   [FA8702-15-D-0001]; Assistant Secretary of Defense for Research and
   Engineering under Air Force [FA8750-19-2-1000]; United States Air Force
   Research Laboratory
FX We acknowledge the MIT SuperCloud and the Lincoln Laboratory
   Supercomputing Center for providing HPC and consultation resources that
   contributed to the research results reported within this paper. We
   acknowledge the MIT SuperCloud team: W. Arcand, D. Bestor, W. Bergeron,
   C. Byun, M. Hubbell, M. Houle, M. Jones, J. Kepner, A. Klein, P.
   Michaleas, L. Milechin, J. Mullen, A. Prout, A. Reuther, A. Rosa and C.
   Yee. We acknowledge J. Marchese for proofreading. This material is based
   on work supported by the Assistant Secretary of Defense for Research and
   Engineering under Air Force contract number FA8702-15-D-0001, and by the
   United States Air Force Research Laboratory and the United States Air
   Force Artificial Intelligence Accelerator under Cooperative Agreement
   number FA8750-19-2-1000. Any opinions, findings, conclusions or
   recommendations expressed in this material are those of the author(s)
   and do not necessarily reflect the views of the Assistant Secretary of
   Defense for Research and Engineering, or the United States Air Force.
   The US Government is authorized to reproduce and distribute reprints for
   Government purposes notwithstanding any copyright notation herein.
CR Ahmad W, 2022, Arxiv, DOI arXiv:2209.01712
   Axelrod S, 2023, MACH LEARN-SCI TECHN, V4, DOI 10.1088/2632-2153/acefa7
   Axelrod S, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30999-w
   Bahri Y, 2021, Arxiv, DOI [arXiv:2102.06701, DOI 10.48550/ARXIV.2102.06701]
   Batatia I., 2022, ADV NEURAL INFORM PR, V35, P11423
   Batzner S, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29939-5
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Black Sid, 2021, Zenodo
   Bommasani Rishi, 2021, ARXIV
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Caballero E, 2022, Arxiv, DOI arXiv:2210.14891
   Chanussot L, 2021, ACS CATAL, V11, P6059, DOI 10.1021/acscatal.0c04525
   Chithrananda S, 2020, Arxiv, DOI [arXiv:2010.09885, DOI 10.48550/ARXIV.2010.09885]
   Chmiela S, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1603015
   Christensen AS, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/abba6f
   Coley CW, 2021, TRENDS CHEM, V3, P133, DOI 10.1016/j.trechm.2020.11.004
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Falcon W., 2019, PYTORCH LIGHTNING
   Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x
   Frey N. C., 2021, NEURIPS 2021 AI SCI
   Gao L, 2020, Arxiv, DOI arXiv:2101.00027
   Gasteiger J., 2022, ARXIV
   Graff DE, 2023, Arxiv, DOI arXiv:2305.08238
   Gruver N., 2022, ARXIV
   Henighan T, 2020, Arxiv, DOI arXiv:2010.14701
   Hoffmann J, 2022, Arxiv, DOI [arXiv:2203.15556, DOI 10.48550/ARXIV.2203.15556]
   Honda S., 2019, SMILES TRANSFORMER P
   Huang B, 2016, J CHEM PHYS, V145, DOI 10.1063/1.4964627
   Huang K., 2021, P NEUR INF PROC SYST, V1
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kalinin S. V., 2022, PREPRINT
   Kaplan J, 2020, Arxiv, DOI arXiv:2001.08361
   Kim S, 2021, NUCLEIC ACIDS RES, V49, pD1388, DOI 10.1093/nar/gkaa971
   Kingma D. P., 2014, C TRACK P
   Krenn M, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100588
   Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947
   Li LS, 2018, J MACH LEARN RES, V18
   Li S, 2020, Arxiv, DOI arXiv:2006.15704
   Loshchilov Ilya, 2019, Arxiv, DOI [arXiv:1711.05101, DOI 10.48550/ARXIV.1711.05101]
   Loukas A, 2020, Arxiv, DOI arXiv:1907.03199
   McCandlish S, 2018, Arxiv, DOI [arXiv:1812.06162, 10.48550/arXiv.1812.06162]
   Mobley DL, 2014, J COMPUT AID MOL DES, V28, P711, DOI 10.1007/s10822-014-9747-x
   Musaelian A, 2023, Arxiv, DOI arXiv:2304.10061
   Musaelian A, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-36329-y
   Noutahi E., 2023, RBYRNE MOMATX DATAMO, DOI [10.5281/zenodo.7955465, DOI 10.5281/ZENODO.7955465]
   Pappu A, 2020, Arxiv, DOI arXiv:2011.12203
   Paszke Adam, 2019, NEURIPS
   Polykovskiy D, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.565644
   Rackers J. A., 2022, PREPRINT
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Ramsundar B., 2019, DEEP LEARNING LIFE S
   Ross J, 2022, NAT MACH INTELL, V4, DOI 10.1038/s42256-022-00580-7
   Ru R., 2021, ADV NEURAL INFORM PR, P4079
   Schütt KT, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5019779
   Schutt K., 2021, INT C MACH LEARN, P9377
   Schutt K. T., 2017, ADV NEURAL INFORM PR, V30, P992
   Schwalbe-Koda D, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25342-8
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Sevilla J, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9891914
   Skinnider MA, 2021, NAT MACH INTELL, V3, P759, DOI 10.1038/s42256-021-00368-1
   Smith JS, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0473-z
   Smith JS, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5023802
   Trewartha A, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100488
   Unke OT, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-27504-0
   Vaswani A, 2017, ADV NEUR IN, V30
   Wolf T, 2020, Arxiv, DOI [arXiv:1910.03771, DOI 10.48550/ARXIV.1910.03771]
   Wood B. M., 2022, ARXIV
   Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a
   Yang G., 2022, ARXIV
NR 70
TC 0
Z9 0
U1 0
U2 0
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD 2023 OCT 23
PY 2023
DI 10.1038/s42256-023-00740-3
EA OCT 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U7VY4
UT WOS:001086857000001
OA hybrid
DA 2023-11-10
ER

PT J
AU Li, PF
   Zhang, M
   Lin, PJ
   Wan, J
   Jiang, M
AF Li, Pengfei
   Zhang, Min
   Lin, Peijie
   Wan, Jian
   Jiang, Ming
TI Conditional Embedding Pre-Training Language Model for Image Captioning
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Image captioning; Layer normalization; Transformer; UNILM; Visual
   embedding
AB The pre-trained language model can not only learn language representations with different granularity from a large number of corpus, but also provide a good initialization for downstream tasks. Aggregation or alignment of text features and visual features as input of pre-training language model is the mainstream approach to deal with visual-language tasks. People can accurately describe an image by constantly referring to the visual information and key text information of the image. Inspired by this idea, we no longer follow main-stream approach, and propose to adjust the pre-training language model processing by using high-low visual features as conditional inputs. Specifically, conditional embedding layer normalization (CELN) we proposed is an effective mechanism for embedding visual features into pre-training language models for feature selection. We apply CELN to transformers in the unified pre-training language model (UNILM). This model parameter adjustment mechanism is an innovative attempt in pre-training language model. Extensive experiments on two challenging benchmarks (MSCOCO and Visual Genome datasets)demonstrate that this seminal work is effective. Code and models are publicly available at: https://github.com/1pfworld/CE-UNILM.
C1 [Li, Pengfei; Zhang, Min; Lin, Peijie; Wan, Jian; Jiang, Ming] Hangzhou Dianzi Univ, Baiyang Rd 2, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Zhang, M (通讯作者)，Hangzhou Dianzi Univ, Baiyang Rd 2, Hangzhou, Zhejiang, Peoples R China.
EM lipf@hdu.edu.cn; hz_andy@163.com; linpeijie@hdu.edu.cn;
   wanjian@hdu.edu.cn; jmzju@163.com
FU Zhejiang Provincial Technical Plan Project [2020C03105, 2021C01129]
FX This work is supported by Zhejiang Provincial Technical Plan Project
   (No.2020C03105, 2021C01129).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Ba LJ, 2016, CORR ARXIV160706450
   Bao B., 2020, SCI CHINA TECHNOL SC, V63, P10
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   de Vries H, 2017, ADV NEUR IN, V30
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gao ZL, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/5075487
   Herdade S, 2019, ADV NEUR IN, V32
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Ioffe Sergey, 2015, ARXIV 1502 03167, P448
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li, 2017, 2017 IEEE C COMPUTER, P3668
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu DQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1416, DOI 10.1145/3240508.3240632
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mahia RN, 2018, IEEE T CIRCUITS-II, V65, P216, DOI 10.1109/TCSII.2017.2706968
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Miyato Takeru, 2018, ARXIV180205957, P1, DOI DOI 10.48550/ARXIV.1802.05957
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Schuster S, 2015, P 4 WORKSH VIS LANG, P7080
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Su SY, 2020, P 2020 C EMP METH NA, P4930
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Ulyanov D, 2016, CORR ARXIV160708022
   VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1007/s11263-019-01198-w, 10.1109/CSTIC.2018.8369274]
   Xiang LY, 2020, MATH BIOSCI ENG, V17, P1041, DOI 10.3934/mbe.2020055
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yang Zhilin, 2016, ADV NEURAL INFORM PR
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yu F, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/5859273
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
NR 55
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD DEC
PY 2022
VL 54
IS 6
BP 4987
EP 5003
DI 10.1007/s11063-022-10844-3
EA JUN 2022
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5U5PN
UT WOS:000810831800003
DA 2023-11-10
ER

PT J
AU Liu, J
   Lin, L
   Ren, HL
   Gu, MH
   Wang, J
   Youn, G
   Kim, JU
AF Liu, Jin
   Lin, Li
   Ren, Haoliang
   Gu, Minghao
   Wang, Jin
   Youn, Geumran
   Kim, Jeong-Uk
TI Building neural network language model with POS-based negative sampling
   and stochastic conjugate gradient descent
SO SOFT COMPUTING
LA English
DT Article
DE Language model; Conjugate gradient; Negative sampling; POS tagging;
   Evaluation model
ID MACHINE
AB Traditional statistical language model is a probability distribution over sequences of words. It has the problem of curse of dimensionality incurred by the exponentially increasing number of possible sequences of words in training text. To solve this issue, neural network language models are proposed by representing words in a distributed way. Due to computation cost on updating a large number of word vectors' gradients, neural network model needs much training time to converge. To alleviate this problem, in this paper, we propose a gradient descent algorithm based on stochastic conjugate gradient to accelerate the convergence of the neural network's parameters. To improve the performance of the neural language model, we also propose a negative sampling algorithm based on POS (part of speech) tagging, which can optimize the negative sampling process and improve the quality of the final language model. A novel evaluation model is also used with perplexity to demonstrate the performance of the improved language model. Experiment results prove the effectiveness of our novel methods.
C1 [Liu, Jin; Lin, Li; Ren, Haoliang; Gu, Minghao] Shanghai Maritime Univ, Coll Informat Engn, Shanghai, Peoples R China.
   [Wang, Jin] Nanjing Univ Posts & Telecommun, Key Lab Broadband Wireless Commun & Sensor Networ, Minist Educ, Nanjing, Jiangsu, Peoples R China.
   [Wang, Jin] Yangzhou Univ, Coll Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Youn, Geumran; Kim, Jeong-Uk] Sangmyung Univ, Dept Elect Engn, Seoul, South Korea.
C3 Shanghai Maritime University; Nanjing University of Posts &
   Telecommunications; Yangzhou University; Sangmyung University
RP Kim, JU (通讯作者)，Sangmyung Univ, Dept Elect Engn, Seoul, South Korea.
EM jinliu@shmtu.edu.cn; lilin@shmtu.edu.cn; haoliangren@shmtu.edu.cn;
   minghaogu@shmtu.edu.cn; jinwang@yzu.edu.cn; geumranyounn@smu.ac.kr;
   jukim@smu.ac.kr
RI Liu, Jin/IWE-0030-2023; Wang, Jin/AAI-7009-2020
OI Liu, Jin/0000-0001-7249-698X; Wang, Jin/0000-0001-5473-8738
FU Shanghai Maritime University research fund project [20130469]; State
   Oceanic Administration China research fund project [201305026]; open
   research fund of the Key Lab of Broadband Wireless Communication and
   Sensor Network Technology (Nanjing University of Posts and
   Telecommunications), Ministry of Education
FX This work was supported by Shanghai Maritime University research fund
   project (20130469), and by State Oceanic Administration China research
   fund project (201305026), and by the open research fund of the Key Lab
   of Broadband Wireless Communication and Sensor Network Technology
   (Nanjing University of Posts and Telecommunications), Ministry of
   Education. Prof. Jeong-Uk Kim is the corresponding author.
CR Nguyen AT, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P858, DOI 10.1109/ICSE.2015.336
   [Anonymous], 2010, P COMPSTAT2010
   [Anonymous], INTERSPEECH
   [Anonymous], STAT METHOD SPEECH R
   [Anonymous], P INT C MACH LEARN
   BAHL P., 1990, READINGS SPEECH RECO, P507
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Carneiro HCC, 2015, NEURAL NETWORKS, V66, P11, DOI 10.1016/j.neunet.2015.02.012
   Defazio Aaron, 2014, ABS14070202 CORR
   Feyzmahdavian H. R., 2014, P IEEE INT WORKSH MA, P1
   Finogeev AG, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0092-7
   Fu ZJ, 2015, J INTERNET TECHNOL, V16, P453, DOI 10.6138/JIT.2015.16.3.20140918
   Hinton G.E, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI DOI 10.1109/69.917563
   Huang F, 2014, COMPUT LINGUIST, V40, P85, DOI 10.1162/COLI_a_00167
   Jiang M, 1999, SMOOTHING ALGORITHM
   Jurafsky D, 2015, INT J COMPUT SCI ENG, V2, P2670
   Karpov A, 2014, SPEECH COMMUN, V56, P213, DOI 10.1016/j.specom.2013.07.004
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Lebret Remi, 2016, P 2016 C EMP METH NA, P1203, DOI [10.18653/v1/D16-1128, DOI 10.18653/V1/D16-1128]
   Levy, 2014, ARXIV PREPRINT ARXIV
   Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612
   Li Q, 2010, PATTERN RECOGN, V43, P378, DOI 10.1016/j.patcog.2009.06.003
   Mikolov Tomas, 2011, RNNLM RECURRENT NEUR
   Ming YW, 2018, NEUROCOMPUTING, V281, P27, DOI 10.1016/j.neucom.2017.11.044
   Miyamoto Y., 2016, PROC 2016 C EMPIRICA, P1992, DOI 10.18653/v1/D16-1209
   Mulder W. D., 2015, COMPUTER SPEECH LANG, V30, P61, DOI DOI 10.1016/J.CS1.2014.09.005
   Nagata R, 2017, PROCEDIA COMPUT SCI, V112, P474, DOI 10.1016/j.procs.2017.08.065
   Nejja M, 2015, PROCEDIA COMPUT SCI, V73, P109, DOI 10.1016/j.procs.2015.12.055
   Novais EMD, 2010, IMPROVED TEXT GENERA, V6433, P316
   Novoa J, 2018, COMPUT SPEECH LANG, V47, P30, DOI 10.1016/j.csl.2017.06.005
   Park KM, 2011, J INF PROCESS SYST, V7, P459, DOI 10.3745/JIPS.2011.7.3.459
   Peris A, 2017, COMPUT SPEECH LANG, V45, P201, DOI 10.1016/j.csl.2016.12.003
   Peter J, 1999, P IEEE WORKSH AUT SP
   Phangtriastua MR, 2017, PROCEDIA COMPUT SCI, V116, P351, DOI 10.1016/j.procs.2017.10.061
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Rosenfeld R, 1994, ADAPTIVE STAT LANGUA
   Shen J, 2017, IEEE T INF FOREN SEC, V12, P2402, DOI 10.1109/TIFS.2017.2705620
   Shtykh RY, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-2
   Wang LN, 2017, NEURAL NETWORKS, V93, P219, DOI 10.1016/j.neunet.2017.06.003
   Wang SJ, 2005, MACH LEARN, V60, P229, DOI 10.1007/s10994-005-0928-7
   Wei ZX, 2006, APPL MATH COMPUT, V183, P1341, DOI 10.1016/j.amc.2006.05.150
   Xing EP, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1335, DOI 10.1145/2783258.2783323
   XU W, 2000, 6 INT C SPOK LANG PR
   Zamora E, 2017, NEUROCOMPUTING, V260, P420, DOI 10.1016/j.neucom.2017.04.044
   Zamora-Martínez F, 2014, PATTERN RECOGN, V47, P1642, DOI 10.1016/j.patcog.2013.10.020
   Zinkevich Martin A., 2011, ADV NEURAL INFORM PR, V23, P2595
NR 48
TC 9
Z9 10
U1 1
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD OCT
PY 2018
VL 22
IS 20
SI SI
BP 6705
EP 6717
DI 10.1007/s00500-018-3181-2
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GV2VF
UT WOS:000445948700009
DA 2023-11-10
ER

PT J
AU Marti, UV
   Bunke, H
AF Marti, UV
   Bunke, H
TI Using a statistical language model to improve the performance of an
   HMM-based cursive handwriting recognition system
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE cursive handwriting recognition; offline handwriting recognition;
   unconstrained sentence recognition; hidden Markov model; statistical
   language model; bigram statistics
AB In this paper, a system for the reading of totally unconstrained handwritten text is presented. The kernel of the system is a hidden Markov model (HMM) for handwriting recognition. This HMM is enhanced by a statistical language model. Thus linguistic knowledge beyond the lexicon level is incorporated in the recognition process. Another novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided. A number of experiments with various language models and large vocabularies have been conducted. The language models used in the system were also analytically compared based on their perplexity.
C1 Univ Bern, Inst Informat & Angew Math, CH-3012 Bern, Switzerland.
C3 University of Bern
RP Marti, UV (通讯作者)，Univ Bern, Inst Informat & Angew Math, Neubruckstr 10, CH-3012 Bern, Switzerland.
EM marti@iam.unibe.ch; bunke@iam.unibe.ch
CR AGARWAL A, 1997, HDB CHARACTER RECOGN, P623
   [Anonymous], 1997, CORPUS BASED METHODS
   [Anonymous], READINGS SPEECH RECO, DOI 10.1016/B978-0-08-051584-7.50045-0
   [Anonymous], AUTOMATIC BANKCHECK
   BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114
   BROWN MK, 1983, PATTERN RECOGN, V16, P447, DOI 10.1016/0031-3203(83)90049-3
   BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P
   Caesar T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P408, DOI 10.1109/ICDAR.1993.395706
   DOWNTON AC, 1991, P 1 INT C DOC AN REC, V2, P542
   DZUBA G, 1999, ADV HANDWRITING RECO, P153
   El Yacoubi A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1024, DOI 10.1109/ICDAR.1995.602077
   Farouz C., 1999, ADV HANDWRITING RECO, P183
   FAVATA JT, 1997, PROGR HANDWRITING RE, P393
   FRANCIS WN, 1994, MANUAL INFORMATION A
   Gorski N., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P523, DOI 10.1109/ICDAR.1999.791840
   GUYON I, 1997, HDB CHARACTER RECOGN, P227
   JOHANSSON S, 1978, MANUAL INFORMATION A
   Kaltenmeier A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P139, DOI 10.1109/ICDAR.1993.395764
   KAUFMANN G, 1998, P 3 INT ASS PATT REC, P302
   Kim G, 1999, ADV HANDWRITING RECO, P163
   Kim HJ, 1997, PATTERN RECOGN, V30, P491, DOI 10.1016/S0031-3203(96)00078-7
   KUNDU A, 1997, HDB CHARACTER RECOGN, P157, DOI DOI 10.1142/9789812830968_0006
   Marti U.-V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P705, DOI 10.1109/ICDAR.1999.791885
   PAQUET T, 1993, PATTERN RECOGN, V26, P391, DOI 10.1016/0031-3203(93)90167-U
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH
   SCHUSSLER M, 1999, ADV HANDWRITING RECO, P213
   SEILER R, 1997, PROGR HANDWRITING RE, P29
   SIMON JC, 1992, P IEEE, V80, P1150, DOI 10.1109/5.156476
   Srihari S. N., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P291, DOI 10.1109/ICDAR.1993.395729
   SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477
NR 30
TC 262
Z9 265
U1 0
U2 16
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD FEB
PY 2001
VL 15
IS 1
BP 65
EP 90
DI 10.1142/S0218001401000848
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 410PV
UT WOS:000167449100005
DA 2023-11-10
ER

PT J
AU Deschacht, K
   De Belder, J
   Moens, MF
AF Deschacht, Koen
   De Belder, Jan
   Moens, Marie-Francine
TI The latent words language model
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Language model; Information extraction; Word sense disambiguation;
   Semantic role labeling
ID COMPLEXITY
AB We present a new generative model of natural language, the latent words language model. This model uses a latent variable for every word in a text that represents synonyms or related words in the given context. We develop novel methods to train this model and to find the expected value of these latent variables for a given unseen text. The learned word similarities help to reduce the sparseness problems of traditional n-gram language models. We show that the model significantly outperforms interpolated Kneser-Ney smoothing and class-based language models on three different corpora. Furthermore the latent variables are useful features for information extraction. We show that both for semantic role labeling and word sense disambiguation, the performance of a supervised classifier increases when incorporating these variables as extra features. This improvement is especially large when using only a small annotated corpus for training. (C) 2012 Elsevier Ltd. All rights reserved.
C1 [Deschacht, Koen; De Belder, Jan; Moens, Marie-Francine] Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium.
C3 KU Leuven
RP Moens, MF (通讯作者)，Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Heverlee, Belgium.
EM koendeschacht@gmail.com; Jan.DeBelder@cs.kuleuven.be;
   Marie-Francine.Moens@cs.kuleuven.be
RI Moens, Marie-Francine/B-8378-2014
FU EU-FP6-IST project CLASS (Cognitive-Level Annotation using Latent
   Statistical Structure) [IST-027978]; IWT-SBO project AMASS++(Advanced
   Multimedia Alignment and Structured Summarization) [IWT 060051]
FX The presented research was supported by the EU-FP6-IST project CLASS
   (Cognitive-Level Annotation using Latent Statistical Structure,
   IST-027978) and by the IWT-SBO project AMASS++(Advanced Multimedia
   Alignment and Structured Summarization, IWT 060051).
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], COMPUTATIONAL LINGUI
   [Anonymous], 2005, ADV NEURAL INFORM PR
   [Anonymous], 2007, P 45 ANN M ASS COMP
   [Anonymous], STUDIES LEXICAL RELA
   [Anonymous], 1995, NAT LANG ENG
   [Anonymous], P 12 C COMP NAT LANG
   [Anonymous], COMPUTATIONAL LINGUI
   [Anonymous], P 2004 HUM LANG TECH
   [Anonymous], 1992, AAAI S PROB APPR NAT
   [Anonymous], P 5 EUR C SPEECH COM
   [Anonymous], 2009, P 13 C COMPUTATIONAL
   [Anonymous], 1972, UNDERSTANDING NATURA
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   [Anonymous], 1998, ENCY APPL LING, DOI DOI 10.7551/MITPRESS/7287.001.0001
   [Anonymous], P IEEE INT C NAT LAN
   [Anonymous], 2003, P CONLL 2003
   [Anonymous], 1968, UNIVERSALS LINGUISTI
   [Anonymous], P SHAR TASK SESS CON
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   [Anonymous], P 14 EUR C MACH LEAR
   [Anonymous], 1990, P 13 C COMPUTATIONAL, DOI DOI 10.3115/997939.997975
   [Anonymous], P ACL IJCNLP 2009 C
   [Anonymous], 1998, P 1 INT C LANG RES E
   [Anonymous], P WORKSH HUM LANG TE
   [Anonymous], P 15 INT C COMP LING
   [Anonymous], 2001, BIT PROGR LANGUAGE M
   [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273501
   [Anonymous], P 40 ANN M ASS COMP
   [Anonymous], P 8 C COMP NAT LANG
   [Anonymous], 1998, WORDNET ELECT LEXICA
   [Anonymous], 2008, P ACL 08 HLT
   [Anonymous], 2009, P 2009 C EMPIRICAL M
   [Anonymous], 2005, P 20 NATL C ARTIFICI
   [Anonymous], P 4 INT WORKSH SEM E
   [Anonymous], 1996, 34 ANN M ASS COMP LI, DOI DOI 10.3115/981863.981904
   [Anonymous], P IEEE INT C AC SPEE
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   BAKER JK, 1975, IEEE T ACOUST SPEECH, VAS23, P24, DOI 10.1109/TASSP.1975.1162650
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brants T, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P224
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Charniak E, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P116
   Ciaramita Massimiliano, 2006, P 2006 C EMP METH NA, P594, DOI DOI 10.3115/1610075.1610158
   Collobert R., 2008, P 25 ICML, V25, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Grefenstette G, 1994, EXPLORATIONS AUTOMAT
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hearst MA, 1992, P 14 C COMP LING NAN, P539, DOI DOI 10.3115/992133.992154
   JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   KRISHNAMURTHY V, 1993, IEEE T SIGNAL PROCES, V41, P2557, DOI 10.1109/78.229888
   Kudo Taku, 2001, P 2 M N AM CHAPTER A, P1
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   Lin D., P 15 INT C MACH LEAR
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Merialdo B., 1994, Computational Linguistics, V20, P155
   MITCHELL C, 1995, IEEE T SPEECH AUDI P, V3, P213, DOI 10.1109/89.388149
   Nasrabadi Nasser M, 2007, J ELECT IMAG, V16
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   Nivre J, 2006, PROC LREC, P2216
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Ratnaparkhi A., 1996, C EMPIRICAL METHODS
   Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526
   Schank Roger C., 1977, SCRIPTS PLANS GOALS
   Schutze H., 1992, Proceedings. Supercomputing '92. (Cat. No.92CH3216-9), P787, DOI 10.1109/SUPERC.1992.236684
   Shue L, 2002, IEEE T SIGNAL PROCES, V50, P1124, DOI 10.1109/78.995068
   Smith Noah A., 2005, P 43 ANN M ASS COMPU, P354
   Snyder Benjamin, 2004, SENSEVAL 3, P41
   Tam YC, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2206
   Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985
   Van Uytsel DH, 2005, COMPUT SPEECH LANG, V19, P171, DOI 10.1016/j.csl.2004.05.009
   Winston P. H., 1976, PATTERN RECOGNIT, V8, P193
   Yu SZ, 2003, IEEE SIGNAL PROC LET, V10, P11, DOI 10.1109/LSP.2002.806705
NR 80
TC 17
Z9 18
U1 0
U2 10
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD OCT
PY 2012
VL 26
IS 5
BP 384
EP 409
DI 10.1016/j.csl.2012.04.001
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 959IY
UT WOS:000305307300006
OA Green Published
DA 2023-11-10
ER

PT J
AU Mnih, A
   Zhang, YC
   Hinton, G
AF Mnih, Andriy
   Zhang Yuecheng
   Hinton, Geoffrey
TI Improving a statistical language model through non-linear prediction
SO NEUROCOMPUTING
LA English
DT Article; Proceedings Paper
CT 18th European Symposium on Artificial Neural Networks
CY APR, 2008
CL Brugge, BELGIUM
DE Statistical language modelling; Distributed representations; Neural
   networks
AB We show how to improve a state-of-the-art neural network language model that converts the previous "context" words into feature vectors and combines these feature vectors linearly to predict the feature vector of the next word. Significant improvements in predictive accuracy are achieved by using a non-linear subnetwork to modulate the effects of the context words or to produce a non-linear correction term when predicting the feature vector. A log-bilinear language model that incorporates both of these improvements achieves a 26% reduction in perplexity over the best n-gram model on a fairly large dataset. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Mnih, Andriy; Zhang Yuecheng; Hinton, Geoffrey] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
C3 University of Toronto
RP Mnih, A (通讯作者)，Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
EM amnih@cs.toronto.edu
RI he, shun/JJD-0182-2023
CR [Anonymous], 2002, P INT C SPOKEN LANGU
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   BLITZER J, 2005, ADV NEURAL INFORM PR, V18
   CHEN SF, 1996, P 34 ANN M ASS COMP, P310, DOI DOI 10.3115/981863.981904
   Emami A, 2005, MACH LEARN, V60, P195, DOI 10.1007/s10994-005-0916-y
   Emami A., 2003, P IEEE INT C AC SPEE, V1, P372
   GOODMAN J, 2000, BIT PROGR LANGUAGE M
   LAROCHELLE H, 2006, 1284 U MONTR DEP INF
   Mnih A., 2007, P 24 INT C MACHINE L, P641, DOI DOI 10.1145/1273496.1273577
   SCHWENK H, 2002, ACOUSTICS SPEECH SIG, V1
   YUECHENG Z, 2008, ESANN
NR 12
TC 8
Z9 8
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAR
PY 2009
VL 72
IS 7-9
SI SI
BP 1414
EP 1418
DI 10.1016/j.neucom.2008.12.025
PG 5
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 430MM
UT WOS:000264993200006
DA 2023-11-10
ER

PT J
AU Brychcín, T
   Konopík, M
AF Brychcin, Tomas
   Konopik, Miloslav
TI Semantic spaces for improving language modeling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Class-based language models; Semantic spaces; HAL; COALS; BEAGLE; Random
   Indexing; Purandare and Pedersen; Clustering; Inflectional languages;
   Machine translation
ID MAXIMUM-LIKELIHOOD; INFORMATION
AB Language models are crucial for many tasks in NLP (Natural Language Processing) and n-grams are the best way to build them. Huge effort is being invested in improving n-gram language models. By introducing external information (morphology, syntax, partitioning into documents, etc.) into the models a significant improvement can be achieved. The models can however be improved with no external information and smoothing is an excellent example of such an improvement.
   In this article we show another way of improving the models that also requires no external information. We examine patterns that can be found in large corpora by building semantic spaces (HAL, COALS, BEAGLE and others described in this article). These semantic spaces have never been tested in language modeling before.
   Our method uses semantic spaces and clustering to build classes for a class-based language model. The class-based model is then coupled with a standard n-gram model to create a very effective language model. Our experiments show that our models reduce the perplexity and improve the accuracy of n-gram language models with no external information added. Training of our models is fully unsupervised. Our models are very effective for inflectional languages, which are particularly hard to model. We show results for five different semantic spaces with different settings and different number of classes. The perplexity tests are accompanied with machine translation tests that prove the ability of proposed models to improve performance of a real-world application. (C) 2013 Elsevier Ltd. All rights reserved.
C1 [Brychcin, Tomas; Konopik, Miloslav] Univ W Bohemia, Fac Sci Appl, Dept Comp Sci & Engn, Plzen 30614, Czech Republic.
   [Brychcin, Tomas; Konopik, Miloslav] Univ W Bohemia, Fac Sci Appl, NTIS, Plzen 30614, Czech Republic.
C3 University of West Bohemia Pilsen; University of West Bohemia Pilsen
RP Brychcín, T (通讯作者)，Univ W Bohemia, Fac Sci Appl, Dept Comp Sci & Engn, Univ 8, Plzen 30614, Czech Republic.
EM brychcin@kiv.zcu.cz; konopik@kiv.zcu.cz
RI Konopik, Miloslav/AAR-6524-2020; Brychcín, Tomáš/C-1181-2016
OI Konopik, Miloslav/0000-0001-7397-1658; Brychcín,
   Tomáš/0000-0002-7442-0978
FU European Regional Development Fund (ERDF); "NITS - New Technologies for
   Information Society", European Centre of Excellence [CZ.
   1.05/1.1.00/02.0090]; Projects of Large Infrastructure for Research,
   Development, and Innovations [LM2010005]; Ministry of Education, Youth,
   and Sports of the Czech Republic; program Center CERIT Scientific Cloud,
   part of the Operational Program Research and Development for Innovations
   [CZ. 1.05/3.2.00/08.0144];  [SGS-2010-028];  [SGS-2013-029]
FX This work was supported by Grant No. SGS-2010-028, by Grant No.
   SGS-2013-029 Advanced computing and information systems, by the European
   Regional Development Fund (ERDF) and by project "NITS - New Technologies
   for Information Society", European Centre of Excellence, CZ.
   1.05/1.1.00/02.0090. Access to the MetaCentrum computing facilities
   provided under the program "Projects of Large Infrastructure for
   Research, Development, and Innovations" LM2010005, funded by the
   Ministry of Education, Youth, and Sports of the Czech Republic, is
   highly appreciated. The access to the CERIT-SC computing and storage
   facilities provided under the program Center CERIT Scientific Cloud,
   part of the Operational Program Research and Development for
   Innovations, reg. no. CZ. 1.05/3.2.00/08.0144 is acknowledged. We also
   thank the Czech News Agency (CNA) for providing a huge number of texts
   in Czech. We would like to thank David Jurgens and Dr. Keith Stevens for
   the implementation methods for building semantic spaces (Jurgens and
   Stevens, 2010) we use in this work.
CR [Anonymous], CLUTO CLUSTERING TOO
   [Anonymous], 2004, C COMP NAT LANG LEAR
   [Anonymous], 1999, P EUR C SPEECH COMM
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   Bai SH, 1998, INT CONF ACOUST SPEE, P173, DOI 10.1109/ICASSP.1998.674395
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   Bellegarda JR, 1996, INT CONF ACOUST SPEE, P172, DOI 10.1109/ICASSP.1996.540318
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Brychcin T., 2011, P IEEE INT C INT DAT
   Burgess C, 1997, LANG COGNITIVE PROC, V12, P177, DOI 10.1080/016909697386844
   Charles WG, 2000, APPL PSYCHOLINGUIST, V21, P505, DOI 10.1017/S0142716400004057
   Chen S.F., 1998, EMPIRICAL STUDY SMOO
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Gao J., 2002, COMPUTATIONAL LINGUI
   Hahn S, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1598
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Jones MN, 2007, PSYCHOL REV, V114, P1, DOI 10.1037/0033-295X.114.1.1
   Jurgens D., 2010, SYSTEM PAPERS ASS CO
   Kirchhoff K, 2006, COMPUT SPEECH LANG, V20, P589, DOI 10.1016/j.csl.2005.10.001
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Liu F., 2007, P ACL, P672
   Liu Y, 2008, INT CONF ACOUST SPEE, P4921
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Maltese G., 2001, P EUR C SPEECH COMM, P21
   Oparin I., 2008, THESIS U W BOHEMIA P
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Rohde D.L., 2004, COGNITIVE PSYCHOL, V7, P573
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Sahlgren M., 2008, P 30 ANN M COGN SCI, V2008, P1300
   Sahlgren M., 2005, SEM IND WORKSH 7 INT
   Tam Y., 2006, P INT
   Tam Y., 2005, P INTERSPEECH, P5
   Vaiciunas A, 2004, INFORMATICA-LITHUAN, V15, P565
   Wang S., 2003, P IEEE INT C AC SPEE
   Watanabe S, 2011, COMPUT SPEECH LANG, V25, P440, DOI 10.1016/j.csl.2010.07.006
   Whittaker E.W.D., 2000, THESIS CAMBRIDGE U C
   Whittaker EWD, 2003, COMPUT SPEECH LANG, V17, P87, DOI 10.1016/S0885-2308(02)00047-5
   Yamamoto H., 1999, P IEEE INT C AC SPEE
   Yokoyama T., 2003, P IEEE ISCA WORKSH S, P71
   Zhao Y., 2002, CRITERION FUNCTIONS
NR 44
TC 15
Z9 15
U1 0
U2 17
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2014
VL 28
IS 1
BP 192
EP 209
DI 10.1016/j.csl.2013.05.001
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 242QQ
UT WOS:000326257500013
DA 2023-11-10
ER

PT J
AU Atkinson, J
   Matamala, J
AF Atkinson, John
   Matamala, Juan
TI EVOLUTIONARY SHALLOW NATURAL LANGUAGE PARSING
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article
DE chunking; Genetic Algorithms; natural-language processing; parsing;
   statistical language models
AB Identifying syntactical information from natural-language texts requires the use of sophisticated parsing techniques mainly based on statistical and machine-learning methods. However, due to complexity and efficiency issues many intensive natural-language processing applications using full syntactic analysis methods may not be effective when processing large amounts of natural-language texts. These tasks can adequately be performed by identifying partial syntactical information through shallow parsing (or chunking) techniques. In this work, a new approach to natural-language chunking using an evolutionary model is proposed. It uses previously captured training information to guide the evolution of the model. In addition, a multiobjective optimization strategy is used to produce unique quality values for objective functions involving the internal and the external quality of chunking. Experiments and the main results obtained using the model and state-of-the-art approaches are discussed.
C1 [Atkinson, John; Matamala, Juan] Univ Concepcion, Dept Comp Sci, Concepcion, Chile.
C3 Universidad de Concepcion
RP Atkinson, J (通讯作者)，Univ Concepcion, Dept Comp Sci, Concepcion, Chile.
EM atkinson@inf.udec.cl
OI Atkinson, John/0000-0002-0049-7235
CR ABNEY S, 1991, PRINCIPLE BASED PARS, P57
   Alba E, 2006, INFORM PROCESS LETT, V100, P173, DOI 10.1016/j.ipl.2006.07.002
   [Anonymous], P WVLC 3
   [Anonymous], 2000, P C COMPUTATIONAL NA
   [Anonymous], P EMNLP VLC
   Araujo L, 2004, LECT NOTES COMPUT SC, V3003, P230
   Araujo L, 2008, PATTERN RECOGN LETT, V29, P547, DOI 10.1016/j.patrec.2007.11.006
   ARGAMON S., 1999, J EXPT THEORETHICAL, V10, P1
   Atkinson-Abutridy J, 2003, IEEE T EVOLUT COMPUT, V7, P546, DOI 10.1109/TEVC.2003.819262
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Deb K., 2001, MULTIOBJECTIVE OPTIM
   DebK, 2000, LECT NOTES COMPUTER, P849, DOI [10.1007/3-540-45356-3_83, DOI 10.1007/3-540-45356-3_83]
   DEJONG K, 2004, EVOLUTIONARY COMPUTA
   Eiben AE, 1999, IEEE T EVOLUT COMPUT, V3, P124, DOI 10.1109/4235.771166
   Hastie TJ., 2009, ELEMENTS STAT LEARNI, V2nd ed.
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   KUDO T ., 2001, P NAACL01
   Li XR, 2001, PROC SPIE, V4473, P530, DOI 10.1117/12.492751
   Mitchell M., 1998, INTRO GENETIC ALGORI
   Molina A, 2002, J MACH LEARN RES, V2, P595, DOI 10.1162/153244302320884551
   Nasrabadi Nasser M, 2007, J ELECT IMAG, V16
   Sang EFTK, 2002, J MACH LEARN RES, V2, P559, DOI 10.1162/153244302320884542
   SANTORINI B, 1990, THESIS U PENNSYLVANI
   Serrano JI, 2005, IEEE C EVOL COMPUTAT, P640
   Sha F, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P213
   Takamura H, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P51
   TSURUOKA Y ., 2005, P 9 INT WORKSH PARS, P133
   Zitzler E., 2001, 103 TIK, P95, DOI DOI 10.3929/ETHZ-A-004284029
NR 28
TC 1
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0824-7935
EI 1467-8640
J9 COMPUT INTELL-US
JI Comput. Intell.
PD MAY
PY 2012
VL 28
IS 2
BP 156
EP 175
DI 10.1111/j.1467-8640.2012.00412.x
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 939XK
UT WOS:000303854000002
DA 2023-11-10
ER

PT J
AU Iver, R
   Ostendorf, M
AF Iver, R
   Ostendorf, M
TI Relevance weighting for combining multi-domain data for <i>n</i>-gram
   language modeling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB Standard statistical language modeling techniques suffer from sparse-data problems in tasks where large amounts of domain-specific text are not available. In this paper, we focus on improving the estimation of domain-dependent n-gram models by the selective use of out-of-domain text data. Previous approaches for estimating language models from multi-domain data have not accounted for the characteristic variations of style and content across domains. In contrast, this work aims at differentially weighting subsets of the out-of-domain data according to style and/or content similarity to the given task, where "style" is represented by part-of-speech statistics and "content" by the particular choice of vocabulary items. In addition to n-gram estimation, the differential weights can be used for lexicon design. Recognition experiments are based on the Switchboard corpus of spontaneous conversations, with out-of-domain text drawn from the Wall Street Journal and Broadcast News corpora. The similarity weighting approach gives a 3-5% reduction in word error rate over a domain-specific n-gram language model, providing some of the largest language modeling gains reported for the Switchboard task in recent years. (C) 1999 Academic Press.
C1 Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA.
C3 Boston University
RP Ostendorf, M (通讯作者)，Boston Univ, Dept Elect & Comp Engn, 8 St Marys St, Boston, MA 02215 USA.
CR [Anonymous], P IEEE INT C AC SPEE
   BESLING S, 1995, P EUR C SPEECH COMM, V2, P1755
   Biber Douglas, 1988, VARIATIONS SPEECH WR
   BILLA J, 1997, P EUR C SPEECH COMM, V1, P363
   FETTER P, 1996, P INT C AC SPEECH SI, V1, P534
   GOPALAKRISHNAN PS, 1996, P DARPA WORKSH HUM L, P41
   GRAFF D, 1996, P DARPA WORKSH HUM L
   Iyer R, 1997, IEEE SIGNAL PROC LET, V4, P221, DOI 10.1109/97.611282
   IYER R, 1997, IEEE WORKSH SPEECH R, P254
   Iyer RM, 1999, IEEE T SPEECH AUDI P, V7, P30, DOI 10.1109/89.736328
   JELINEK F, 1990, READINGS SPEECH RECO, P651
   JONES S, 1992, J DOC, P111
   Kubala F., 1995, P ARPA SPOK LANG TEC, P41
   METEER M, 1991, P IJCAI91
   OSTENDORF M, 1991, P DARPA WORKSH SPEEC, P83
   PLACEWAY P, 1993, P INT C AC SPEECH SI, V2, P33
   RAO PS, 1997, P EUR C SPEECH COMM, V4, P1979
   Ratnaparkhi A., 1996, P C EMP METH NAT LAN, V1, P133
   ROSENFELD R, 1995, P EUR C SPEECH COMM, V2, P1763
   SEYMORE K, 1996, P DARPA WORKSH HUM L, P141
   Shriberg E.E., 1994, PRELIMINARIES THEORY
   SIU M, 1996, P INT C SPOK LANG PR, V1, P386
   STOLCKE A, 1996, P INT C AC SPEECH SI, V1, P405
   VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA
   WENG F, 1996, P DARPA WORKSH HUM L, P147
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
NR 26
TC 14
Z9 18
U1 0
U2 4
PU ACADEMIC PRESS LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL
PY 1999
VL 13
IS 3
BP 267
EP 282
DI 10.1006/csla.1999.0124
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 222EC
UT WOS:000081769600004
OA hybrid
DA 2023-11-10
ER

PT J
AU Sun, K
   Wang, XL
   Sun, CJ
   Lin, L
AF Sun, Ke
   Wang, Xiaolong
   Sun, Chengjie
   Lin, Lei
TI A language model approach for tag recommendation
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Tag recommendation; Language model for tag recommendation
AB Tags are user-generated keywords for entities. Recently tags have been used as a popular way to allow users to contribute metadata to large corpora on the web. However, tagging style websites lack the function of guaranteeing the quality of tags for other usages, like collaboration/community, clustering, and search, etc. Thus, as a remedy function, automatic tag recommendation which recommends a set of candidate tags for user to choice while tagging a certain document has recently drawn many attentions. In this paper, we introduce the statistical language model theory into tag recommendation problem named as language model for tag recommendation (LMTR), by converting the tag recommendation problem into a ranking problem and then modeling the correlation between tag and document with the language model framework. Furthermore, we leverage two different methods based on both keywords extraction and keywords expansion to collect candidate tag before ranking with LMTR to improve the performance of LMTR. Experiments on large-scale tagging datasets of both scientific and web documents indicate that our proposals are capable of making tag recommendation efficiently and effectively. (C) 2010 Elsevier Ltd. All rights reserved.
C1 [Sun, Ke; Wang, Xiaolong; Sun, Chengjie; Lin, Lei] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Lin, Lei] Harbin Inst Technol, Dept Control Sci & Engn, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Sun, K (通讯作者)，Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM ksun@insun.hit.edu.cn; wangxl@insun.hit.edu.cn; cjsun@insun.hit.edu.cn;
   linl@insun.hit.edu.cn
RI Sun, Chengjie/GQY-9276-2022
FU National Natural Science Foundation of China [60973076]; Harbin Science
   and Technology Innovation Talents [2010RFXXG003]
FX This work was funded in part by the National Natural Science Foundation
   of China (Grant No. 60973076) and the Special Fund Projects for Harbin
   Science and Technology Innovation Talents (2010RFXXG003).
CR AMES M, 2007, P SIGCHI C HUM FACT, P980
   [Anonymous], 2007, P 16 ACM C INF KNOWL
   [Anonymous], 2009, PROC WORLD WIDE WEB, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], 2007, ICWSM
   [Anonymous], 2005, P 14 ACM INT C INFOR, DOI DOI 10.1145/1099554.1099572
   [Anonymous], P WWW
   [Anonymous], 2008, P 31 ANN INT ACM SIG
   [Anonymous], 2006, COLL WEB TAGG WORKSH
   Brooks C. H., 2006, P 15 INT C WORLD WID, P625, DOI [DOI 10.1145/1135777.1135869, 10.1145/1135777.1135869]
   CHIRITA PA, 2007, P 16 INT C WORLD WID, P854
   Duan Huizhong, 2008, P ACL
   Frank E, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P668
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   MISHNE G, 2006, P 15 INT C WORLD WID, P954
   Ponte Jay M, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   Porter MF., 1997, READINGS INFORM RETR
   ROBERTSON SE, 1999, NIST SPECIAL PUBLICA, P253
   Sigurbjornsson Borkur, 2008, P 17 INT C WORLD WID, P327
   Song Y, 2008, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2007, VOL 6, PTS A AND B, P515, DOI 10.1145/1390334.1390423
   Spitters M., 2001, TOP DET TRACK WORKSH
   Turney P. D., 2000, Information Retrieval, V2, P303, DOI 10.1023/A:1009976227802
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
NR 22
TC 8
Z9 9
U1 3
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR
PY 2011
VL 38
IS 3
BP 1575
EP 1582
DI 10.1016/j.eswa.2010.07.075
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA 688PJ
UT WOS:000284863200034
DA 2023-11-10
ER

PT J
AU Xu, P
   Jelinek, F
AF Xu, Peng
   Jelinek, Frederick
TI Random forests and the data sparseness problem in language modeling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
ID DECISION TREES
AB Language modeling is the problem of predicting words based on histories containing words already hypothesized. Two key aspects of language modeling are effective history equivalence classification and robust probability estimation. The solution of these aspects is hindered by the data sparseness problem.
   Application of random forests (RFs) to language modeling deals with the two aspects simultaneously. We develop a new smoothing technique based on randomly grown decision trees (DTs) and apply the resulting RF language models to automatic speech recognition. This new method is complementary to many existing ones dealing with the data sparseness problem. We study our RF approach in the context of n-gram type language modeling in which n - 1 words are present in a history. Unlike regular n-gram language models, RF language models have the potential to generalize well to unseen data, even when histories are longer than four words. We show that our RF language models are superior to the best known smoothing technique, the interpolated Kneser-Ney smoothing, in reducing both the perplexity (PPL) and word error rate (WER) in large vocabulary state-of-the-art speech recognition systems. In particular, we will show statistically significant improvements in a contemporary conversational telephony speech recognition system by applying the RF approach only to one of its many language models. (c) 2006 Elsevier Ltd. All rights reserved.
C1 Johns Hopkins Univ, Dept Elect & Comp Engn, Ctr Language & Speech Proc, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Xu, P (通讯作者)，Johns Hopkins Univ, Dept Elect & Comp Engn, Ctr Language & Speech Proc, Barton Hall Room 320,3400 N Charles St, Baltimore, MD 21218 USA.
EM xp@google.com
RI Xu, Pengcheng/J-1429-2012
OI Xu, Pengcheng/0000-0001-8651-208X
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], MSRTR200172 MACH LEA
   [Anonymous], 2002, P INT C SPOKEN LANGU
   BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278
   BENGIO Y, 2001, ADV NEURAL INFORMATI
   Berger A, 1998, INT CONF ACOUST SPEE, P705, DOI 10.1109/ICASSP.1998.675362
   Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Breiman L, 1998, ANN STAT, V26, P801
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Breiman L, 1984, CLASSIFICATION ALGOR, V40, P358, DOI 10.1201/9781315139470
   Breiman L., 2001, RANDOM FORESTS, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 1999, 547 U CAL
   Brown P. F., 1992, Computational Linguistics, V18, P467
   BULYKO I, 2003, P HLT NAACL, P7
   Charniak E, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P116
   Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147
   CHELBA C, 2001, P AUT SPEECH REC UND
   Chen S. F., 1998, TR1098 HARV U COMP S
   Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452
   CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569
   *DARPA, 2004, NIST RT 04 WORKSH DA
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   EMAMI A, 2005, P ICASSP
   EMAMI A, 2003, P IEEE INT C AC SPEE
   Freund Y, 1996, P 13 INT C INT C MAC, V96, P148
   GODFREY J, 1992, P ICASSP, P517
   Goodman J, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P305
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Jelinek F., 1997, STAT METHODS SPEECH
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   MARTIN J, 1995, ARTIF INTELL, V5, P379
   Martin SK, 1998, J ACAD LIBR, V24, P3, DOI 10.1016/S0099-1333(98)90134-3
   Mohri M., 1996, P 12 BIENN EUR C ART
   MOHRI M, 1996, P 34 M ACL SANT CRUZ
   MURTHY KVS, 1999, THESIS J HOPKINS U B
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   Potamianos G, 1998, SPEECH COMMUN, V24, P171, DOI 10.1016/S0167-6393(98)00018-1
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877
   QUINLAN JR, 1989, INFORM COMPUT, V80, P227, DOI 10.1016/0890-5401(89)90010-2
   RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051
   Roark B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P749
   ROARK B, 2001, THESIS BROWN U PROVI
   ROARK B, 2004, P ACL, P48
   ROSENFELD R, 1994, THESIS C MELLON U PI
   SCHWENK H, 2002, P ICASSP
   SOLTAU H, 2004, P NIST RT 04 WORKSH
   SPROAT R, 1996, P 34 M ACL SANT CRUZ
   Stolcke Andreas, 1998, P DARPA BROADC NEWS, P270
   Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9, P127, DOI 10.1080/02331887808801414
   Wang W, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P238
   Xu P, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P191
   Xu P., 2005, THESIS J HOPKINS U B
   XU P, 2003, P 2003 C EMP METH NA
   Zhu XJ, 2001, INT CONF ACOUST SPEE, P533, DOI 10.1109/ICASSP.2001.940885
NR 58
TC 27
Z9 28
U1 1
U2 6
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2007
VL 21
IS 1
BP 105
EP 152
DI 10.1016/j.csl.2006.01.003
PG 48
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 102EW
UT WOS:000241794800006
DA 2023-11-10
ER

PT J
AU Smit, P
   Virpioja, S
   Kurimo, M
AF Smit, Peter
   Virpioja, Sami
   Kurimo, Mikko
TI Advances in subword-based HMM-DNN speech recognition across languages
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Large vocabulary speech recognition; Subword units; Character units;
   Recurrent neural network language models
ID NEURAL-NETWORKS; MODELS; DROPOUT
AB We describe a novel way to implement subword language models in speech recognition systems based on weighted finite state transducers, hidden Markov models, and deep neural networks. The acoustic models are built on graphemes in a way that no pronunciation dictionaries are needed, and they can be used together with any type of subword language model, including character models. The advantages of short subword units are good lexical coverage, reduced data sparsity, and avoiding vocabulary mismatches in adaptation. Moreover, constructing neural network language models (NNLMs) is more practical, because the input and output layers are small. We also propose methods for combining the benefits of different types of language model units by reconstructing and combining the recognition lattices. We present an extensive evaluation of various subword units on speech datasets of four languages: Finnish, Swedish, Arabic, and English. The results show that the benefits of short subwords are even more consistent with NNLMs than with traditional n-gram language models. Combination across different acoustic models and language models with various units improve the results further. For all the four datasets we obtain the best results published so far. Our approach performs well even for English, where the phoneme-based acoustic models and word-based language models typically dominate: The phoneme-based baseline performance can be reached and improved by 4% using graphemes only when several grapheme-based models are combined. Furthermore, combining both grapheme and phoneme models yields the state-of-the-art error rate of 15.9% for the MGB 2018 dev17b test. For all four languages we also show that the language models perform reasonably well when only limited training data is available. (C) 2020 The Authors. Published by Elsevier Ltd.
C1 [Smit, Peter; Virpioja, Sami; Kurimo, Mikko] Aalto Univ, Dept Signal Proc & Acoust, Espoo, Finland.
   [Virpioja, Sami] Univ Helsinki, Dept Digital Humanities, Helsinki, Finland.
   [Smit, Peter] Inscripta, Helsinki, Finland.
   [Virpioja, Sami] Utopia Analyt, Helsinki, Finland.
C3 Aalto University; University of Helsinki
RP Smit, P (通讯作者)，Aalto Univ, Dept Signal Proc & Acoust, Espoo, Finland.; Smit, P (通讯作者)，Inscripta, Helsinki, Finland.
EM peter.smit@inscripta.io
RI Kurimo, Mikko/F-6647-2012; Smit, Peter/E-7107-2012
OI Smit, Peter/0000-0001-7611-1477; Virpioja, Sami/0000-0002-3568-150X
FU Svenska folkskolans vanner r.f. via the DigiTala project; Business
   Finland's Challenge Finland project TELLme; Kone foundation; EU's
   Horizon 2020 research and innovation programme via the project MeMAD [GA
   780069]; project FoTran [GA 771113]
FX This work was supported by Svenska folkskolans vanner r.f. via the
   DigiTala project, Business Finland's Challenge Finland project TELLme,
   Kone foundation, EU's Horizon 2020 research and innovation programme via
   the project MeMAD (GA 780069) and the project FoTran (GA 771113).
   Computational resources were provided by the Aalto Science-IT project
   and the CSC ~ IT Center for Science, Finland.
CR Ali A., 2014, IWSLT 2014 INT WORKS
   Ali A, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P316, DOI 10.1109/ASRU.2017.8268952
   Ali A, 2016, IEEE W SP LANG TECH, P279, DOI 10.1109/SLT.2016.7846277
   [Anonymous], 2015, ARXIV150807909
   [Anonymous], 2011, P 18 NORD C COMP LIN
   Arisoy E, 2009, IEEE T AUDIO SPEECH, V17, P874, DOI 10.1109/TASL.2008.2012313
   Bisani M., 2005, P INTERSPEECH, P725
   Botros R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1443
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Cheng GF, 2017, INTERSPEECH, P1586, DOI 10.21437/Interspeech.2017-129
   Choueiter G, 2006, INT CONF ACOUST SPEE, P1053
   Creutz M, 2002, P ACL 2002 WORKSH MO, P21, DOI DOI 10.3115/1118647.1118650
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V4, p3:1, DOI [10.1145/1217098.1217101, DOI 10.1145/1187415.1187418]
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V5, P1, DOI DOI 10.1145/1322391.1322394
   CSC-IT Center for Science, 1998, HELS KORP VERS FINN
   Enarvi S, 2016, INTERSPEECH, P3052, DOI 10.21437/Interspeech.2016-618
   Enarvi S, 2017, IEEE-ACM T AUDIO SPE, V25, P2085, DOI 10.1109/TASLP.2017.2743344
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI DOI 10.5555/177910.177914
   Goel V, 2000, COMPUT SPEECH LANG, V14, P115, DOI 10.1006/csla.2000.0138
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Hirsimäki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   Hirsimäki T, 2009, IEEE T AUDIO SPEECH, V17, P724, DOI 10.1109/TASL.2008.2012323
   ISKRA DJ, 2002, LREC
   Kirchhoff K, 2006, COMPUT SPEECH LANG, V20, P589, DOI 10.1016/j.csl.2005.10.001
   Kneser R., 1993, CONTRIBUTIONS QUANTI, P221, DOI /10.1007/978-94-011-1769-2_15
   KUO HKJ, 2012, INTERSPEECH 2012 13, P1670
   Kurimo M, 2017, LANG RESOUR EVAL, V51, P961, DOI 10.1007/s10579-016-9336-9
   Manohar V, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P346, DOI 10.1109/ASRU.2017.8268956
   Mansikkaniemi A, 2017, INTERSPEECH, P3762, DOI 10.21437/Interspeech.2017-1115
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mirjam K., 2003, INTERSPEECH 2003 EUR
   Mohri M., 2008, SPRINGER HDB SPEECH, DOI DOI 10.1007/978-3-540-49127-9_28
   Morin F., 2005, AISTATS, V5, P246
   Mousa AE, 2013, INT CONF ACOUST SPEE, P8435, DOI 10.1109/ICASSP.2013.6639311
   Peddinti V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3214
   Povey D., 2011, ASRU 2011 IEEE WORKS
   Povey D, 2016, INTERSPEECH, P2751, DOI 10.21437/Interspeech.2016-595
   Prabhavalkar R, 2017, INTERSPEECH, P939, DOI 10.21437/Interspeech.2017-233
   Rao K, 2017, INT CONF ACOUST SPEE, P4815, DOI 10.1109/ICASSP.2017.7953071
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Rosti A., 1998, SPEECHDAT FINNISH DA
   Sainath TN, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5859, DOI 10.1109/ICASSP.2018.8462380
   Siivola V, 2007, IEEE T AUDIO SPEECH, V15, P1617, DOI 10.1109/TASL.2007.896666
   Smit P., 2016, 2 INT WORKSH COMP LI, P12
   Smit P., 2017, ASRU
   Smit P., 2017, INTERSPEECH
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava Rupesh Kumar, 2015, NIPS, P2377
   Tarjan B., 2014, P 4 INT WORKSH SPOK, P131
   Varjokallio M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P7, DOI 10.1109/ASRU.2013.6707697
   Virpioja S, 2013, MORFESSOR 2 0 PYTHON
   Wang Y., 2018, ICASSP 2018 IEEE INT
   WONG JHM, 2017, ASRU, P84, DOI DOI 10.1109/ASRU.2017.8268920
   Xu HH, 2010, INT CONF ACOUST SPEE, P4938, DOI 10.1109/ICASSP.2010.5495100
NR 55
TC 17
Z9 17
U1 0
U2 11
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR
PY 2021
VL 66
AR 101158
DI 10.1016/j.csl.2020.101158
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PB5PE
UT WOS:000596372000009
OA hybrid, Green Published
DA 2023-11-10
ER

PT J
AU Cotterell, R
   Kirov, C
   Hulden, M
   Eisner, J
AF Cotterell, Ryan
   Kirov, Christo
   Hulden, Mans
   Eisner, Jason
TI On the Complexity and Typology of Inflectional Morphological Systems
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID LANGUAGE
AB We quantify the linguistic complexity of different languages' morphological systems. We verify that there is a statistically significant empirical trade-off between paradigm size and irregularity: A language's inflectional paradigms may be either large in size or highly irregular, but never both. We define a new measure of paradigm irregularity based on the conditional entropy of the surface realization of a paradigm-how hard it is to jointly predict all the word forms in a paradigm from the lemma. We estimate irregularity by training a predictive model. Our measurements are taken on large morphological paradigms from 36 typologically diverse languages.
C1 [Cotterell, Ryan; Kirov, Christo; Eisner, Jason] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
   [Hulden, Mans] Univ Colorado, Dept Linguist, Boulder, CO USA.
C3 Johns Hopkins University; University of Colorado System; University of
   Colorado Boulder
RP Cotterell, R (通讯作者)，Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
EM ryan.cotterell@jhu.edu; ckirov1@jhu.edu; mans.hulden@colorado.edu;
   eisner@jhu.edu
OI Cotterell, Ryan/0000-0003-4080-1833
FU National Science Foundation [1718846]; Facebook Fellowship; Div Of
   Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [1718846] Funding Source: National Science Foundation
FX This material is based upon work supported in part by the National
   Science Foundation under grant no. 1718846. The first author was
   supported by a Facebook Fellowship. We want to thank Rob Malouf for
   providing extensive and very helpful feedback on multiple versions of
   the paper. However, the opinions in this paper are our own: Our
   acknowledgment does not constitute an endorsement by Malouf. We would
   also like to thank the anonymous reviewers along with action editor
   Chris Dyer and editor-in-chief Lillian Lee.
CR Ackerman F, 2013, LANGUAGE, V89, P429, DOI 10.1353/lan.2013.0054
   Allen B, 2015, LEARNING ALTERNATION
   Anderson Stephen R., 1992, A MORPHOUSMORPHOLOGY, V62
   [Anonymous], 1921, INTRO STUDY SPEECH
   [Anonymous], 1984, LANGUAGE
   [Anonymous], 2009, P C EMP METH NAT LAN
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   Aronoff Mark, 1976, WORD FORMATION GENER, V1
   Baerman M., 2015, OXFORD HDB INFLECTIO
   Baerman Matthew, 2015, UNDERSTANDING MEASUR
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, DOI DOI 10.48550/ARXIV.1409.0473
   Bane Max, 2008, P 26 W COAST C FORM, P69
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   Bonami O, 2016, WORD STRUCT, V9, P156, DOI 10.3366/word.2016.0092
   Brown P. F., 1992, Computational Linguistics, V18, P31
   Carstairs-McCarthy Andrew, 2010, EVOLUTION MORPHOLOGY, V14
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Cotterell R, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P625
   Cotterell Ryan, 2017, P 15 C EUR CHAPT ASS, P759
   Cotterell Ryan, 2018, P CONLL SIGMORPHON 2, P1
   Cotterell Ryan., 2016, P 14 SIGMORPHON WORK, P10, DOI DOI 10.18653/V1/W16-2002
   Cotterell Ryan, 2017, C EMP METH NAT LANG, P725
   Cotterell Ryan, 2018, ARXIV PREPRINT ARXIV
   Cotterell Ryan, 2015, T ASS COMPUTATIONAL, V3, P433
   Dreyer M., 2011, P 2011 C EMP METH NA, P616
   Dreyer M, 2008, P C EMP METH NAT LAN, P1080
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Gil D., 1994, NORD J LINGUIST, V17, P179, DOI [DOI 10.1017/S0332586500003000, 10.1017/S0332586500003000]
   HARE M, 1995, COGNITION, V56, P61, DOI 10.1016/0010-0277(94)00655-5
   Hockett C. F., 1958, COURSE MODERN LINGUI
   Kann K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P555
   KENSTOWICZ MICHAEL, 1994, PHONOLOGY GENERATIVE
   Kibrik Aleksandr E., 1998, HDB MORPHOLOGY, P455
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   McCulloch Warren S, 1943, B MATH BIOPHYSICS, DOI DOI 10.1007/BF02478259
   McWhorter John H., 2001, LINGUIST TYPOL, V5, P125, DOI DOI 10.1515/LITY.2001.001
   Oh Yoon Mi., 2015, LINGUISTIC COMPLEXIT
   Paz A, 2003, PROBABILISTIC AUTOMA
   Pellegrino F, 2011, LANGUAGE, V87, P539
   PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7
   Ralli A, 2002, LINGUISTICS, V40, P519, DOI 10.1515/ling.2002.022
   Ralli Angela, 1994, P 8 S ENGL GREEK LIN, P19
   Rissanen Jorma., 1994, LANG COMP DIMACS WOR, P149
   Robins R. H., 2013, SHORT HIST LINGUISTI
   Ryan Cotterell, 2018, P LREC 2018 MIYAZ JA
   Ryan Cotterell, 2017, P CONLL SIGMORPHON 2
   Sagot Beno^it, 2013, COMPUTATIONAL APPROA
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SIEGELMANN HT, 1995, J COMPUT SYST SCI, V50, P132, DOI 10.1006/jcss.1995.1013
   SIEGELMANN HT, 1991, APPL MATH LETT, V4, P77, DOI 10.1016/0893-9659(91)90080-F
   Smith K, 2008, PHILOS T R SOC B, V363, P3469, DOI 10.1098/rstb.2008.0147
   Sobel Carolyn P., 2013, COGNITIVE SCI INTERD
   Spencer Andrew, 1991, MORPHOLOGICAL THEORY
   Stolz Thomas, 2012, IRREGULARITY MORPHOL, V11
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Sylak-Glassman J., 2016, COMPOSITION USE UNIV
   Sylak-Glassman J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P674
   Zeiler Matthew D, 2012, ARXIV12125701
NR 58
TC 18
Z9 18
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2019
VL 7
BP 327
EP 342
DI 10.1162/tacl_a_00271/1923163
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA VK5UX
UT WOS:000736523200021
DA 2023-11-10
ER

PT J
AU Fang, XM
   Wang, F
   Liu, LH
   He, JZ
   Lin, DY
   Xiang, YF
   Zhu, KR
   Zhang, XA
   Wu, H
   Li, H
   Song, L
AF Fang, Xiaomin
   Wang, Fan
   Liu, Lihang
   He, Jingzhou
   Lin, Dayong
   Xiang, Yingfei
   Zhu, Kunrui
   Zhang, Xiaonan
   Wu, Hua
   Li, Hui
   Song, Le
TI A method for multiple-sequence-alignment-free protein structure
   prediction using a protein language model
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article; Early Access
AB Protein structure prediction pipelines based on artificial intelligence, such as AlphaFold2, have achieved near-experimental accuracy. These advanced pipelines mainly rely on multiple sequence alignments (MSAs) as inputs to learn the co-evolution information from the homologous sequences. Nonetheless, searching MSAs from protein databases is time consuming, usually taking tens of minutes. Consequently, we attempt to explore the limits of fast protein structure prediction by using only primary structures of proteins. Our proposed method, HelixFold-Single, combines a large-scale protein language model with the superior geometric learning capability of AlphaFold2. HelixFold-Single first pre-trains a large-scale protein language model with thousands of millions of primary structures utilizing the self-supervised learning paradigm, which will be used as an alternative to MSAs for learning the co-evolution information. Then, by combining the pre-trained protein language model and the essential components of AlphaFold2, we obtain an end-to-end differentiable model to predict the three-dimensional coordinates of atoms from only the primary structure. HelixFold-Single is validated on datasets CASP14 and CAMEO, achieving competitive accuracy with the MSA-based methods on targets with large homologous families. Furthermore, HelixFold-Single consumes much less time than the mainstream pipelines for protein structure prediction, demonstrating its potential in tasks requiring many predictions.
   AlphaFold2 has revolutionized bioinformatics, but its ability to predict protein structures with high accuracy comes at the price of a costly database search for multiple sequence alignments. Fang and colleagues pre-train a large-scale protein language model and use it in conjunction with AlphaFold2 as a fully trainable and efficient model for structure prediction.
C1 [Fang, Xiaomin; Wang, Fan; Liu, Lihang; He, Jingzhou; Lin, Dayong; Xiang, Yingfei; Zhu, Kunrui; Zhang, Xiaonan; Wu, Hua] Baidu Inc, NLP, Shenzhen, Peoples R China.
   [Li, Hui; Song, Le] BioMap, Beijing, Peoples R China.
C3 Baidu
RP Wang, F (通讯作者)，Baidu Inc, NLP, Shenzhen, Peoples R China.; Song, L (通讯作者)，BioMap, Beijing, Peoples R China.
EM wang.fan@baidu.com; songle@biomap.com
FU This work is supported by the National Engineering Research Center of
   Deep Learning Technology and Applications.; National Engineering
   Research Center of Deep Learning Technology and Applications
FX This work is supported by the National Engineering Research Center of
   Deep Learning Technology and Applications.
CR [Anonymous], 2023, PADDL PADDL V1 2 2, DOI [10.5281/zenodo.8202943, DOI 10.5281/ZENODO.8202943]
   Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754
   Bateman A, 2023, NUCLEIC ACIDS RES, V51, pD523, DOI 10.1093/nar/gkac1052
   Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235
   Brown P. F., 1992, Computational Linguistics, V18, P31
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Burley SK, 2021, NUCLEIC ACIDS RES, V49, pD437, DOI 10.1093/nar/gkaa1038
   Chowdhury R., 2021, BIORXIV, DOI [10.1101/2021.08.02.454840, DOI 10.1101/2021.08.02.454840]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du ZY, 2021, NAT PROTOC, V16, P5634, DOI 10.1038/s41596-021-00628-9
   Elnaggar A, 2021, Arxiv, DOI [arXiv:2007.06225, 10.48550/arXiv.2007.06225, DOI 10.48550/ARXIV.2007.06225]
   He Pengcheng, 2020, ARXIV200603654
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kinch LN, 2021, PROTEINS, V89, P1618, DOI 10.1002/prot.26202
   Kryshtafovych A, 2021, PROTEINS, V89, P1607, DOI 10.1002/prot.26237
   Mirdita M, 2017, NUCLEIC ACIDS RES, V45, pD170, DOI 10.1093/nar/gkw1081
   Moult J, 2005, CURR OPIN STRUC BIOL, V15, P285, DOI 10.1016/j.sbi.2005.05.011
   Peng J, 2011, PROTEINS, V79, P161, DOI 10.1002/prot.23175
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Radford Alec, 2018, OPENAI BLOG
   Rao R., 2021, 9 INT C LEARN REPR I
   Rao R, 2021, PR MACH LEARN RES, V139
   Rao RS, 2019, ADV NEUR IN, V32
   Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118
   Robin X, 2021, PROTEINS, V89, P1977, DOI 10.1002/prot.26213
   Suzek BE, 2015, BIOINFORMATICS, V31, P926, DOI 10.1093/bioinformatics/btu739
   Varadi M, 2022, NUCLEIC ACIDS RES, V50, pD439, DOI 10.1093/nar/gkab1061
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang WK, 2022, NAT COMPUT SCI, V2, P804, DOI 10.1038/s43588-022-00373-3
   Weissenow K, 2022, STRUCTURE, V30, P1169, DOI 10.1016/j.str.2022.05.001
   Xiao Y., 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2108.07435
   Yang JY, 2020, P NATL ACAD SCI USA, V117, P1496, DOI 10.1073/pnas.1914677117
   Yang JY, 2015, NAT METHODS, V12, P7, DOI 10.1038/nmeth.3213
   Zhang Y, 2004, PROTEINS, V57, P702, DOI 10.1002/prot.20264
NR 34
TC 0
Z9 0
U1 5
U2 5
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD 2023 OCT 9
PY 2023
DI 10.1038/s42256-023-00721-6
EA OCT 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T9PU7
UT WOS:001081239300001
OA Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Naous, T
   Bassyouni, Z
   Mousi, B
   Hajj, H
   El Hajj, W
   Shaban, K
AF Naous, Tarek
   Bassyouni, Zahraa
   Mousi, Bassel
   Hajj, Hazem
   El Hajj, Wassim
   Shaban, Khaled
TI Open-Domain Response Generation in Low-Resource Settings using
   Self-Supervised Pre-Training of Warm-Started Transformers
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Response generation; Arabic dialect; language models
AB Learning response generation models constitute the main component of building open-domain dialogue systems. However, training open-domain response generation models requires large amounts of labeled data and pre-trained language generation models that are often nonexistent for low-resource languages. In this article, we propose a framework for training open-domain response generation models in low-resource settings. We consider Dialectal Arabic (DA) as a working example. The framework starts by warm-starting a transformer-based encoder-decoder with pre-trained language model parameters. Next, the resultant encoder-decoder model is adapted to DA by employing self-supervised pre-training on large-scale unlabeled data in the desired dialect. Finally, the model is fine-tuned on a very small labeled dataset for open-domain response generation. The results show significant performance improvements on three spoken Arabic dialects after adopting the framework's three stages, highlighted by higher BLEU and lower Perplexity scores compared with multiple baseline models. Specifically, our models are capable of generating fluent responses in multiple dialects with an average human-evaluated fluency score above 4. Our data is made publicly available.
C1 [Naous, Tarek] Amer Univ Beirut, 351 Ferst Dr NW, Atlanta, GA 30332 USA.
   [Bassyouni, Zahraa; Mousi, Bassel; Hajj, Hazem; El Hajj, Wassim] Amer Univ Beirut, Bliss St,POB 11-0236, Beirut, Lebanon.
   [Naous, Tarek; Shaban, Khaled] Qatar Univ, Univ St POB, Doha 2713, Qatar.
C3 American University of Beirut; Qatar University
RP Naous, T (通讯作者)，Amer Univ Beirut, 351 Ferst Dr NW, Atlanta, GA 30332 USA.; Naous, T (通讯作者)，Qatar Univ, Univ St POB, Doha 2713, Qatar.
EM tnn11@aub.edu.lb
RI ; Shaban, Khaled/M-2768-2014
OI El-Hajj, Wassim/0000-0002-5206-2954; Hajj, Hazem/0000-0002-9954-7924;
   Shaban, Khaled/0000-0002-5688-7515
FU Qatar National Research Fund (Qatar Foundation) [NPRP13S-0112-200037]
FX This work was made possible by NPRP13S-0112-200037 grant from Qatar
   National Research Fund (a member of Qatar Foundation). The statements
   made herein are solely the responsibility of the authors.
CR Abdelali A., 2016, P 2016 C N AM CHAPT, P11, DOI 10.18653/v1/N16
   Abdul-Mageed M., 2020, P 5 ARABIC NATURAL L, P97
   Abdul-Mageed M, 2021, Arxiv, DOI arXiv:2101.01785
   Abdul-Mageed M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5855
   Abu Ali D., 2016, P COLING 2016 26 INT, P208
   Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977
   Antoun W., 2020, P 4 WORKSHOP OPEN SO, P9
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Basu Sourya, 2020, P INT C LEARNING REP
   Bouamor H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P199
   Dinan Emily, 2018, P INT C LEARNING REP
   Eskander R., 2013, P 2013 C N AM CHAPT, P585
   Fadhil Ahmed, 2019, P INT C REC ADV NAT, P295
   Hedderich MA, 2021, Arxiv, DOI arXiv:2010.12309
   Higashinaka R., 2014, PROC INT C COMPUTATI, P928
   Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123
   Ippolito Daphne, 2018, P 57 C ASS COMPUTATI
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Li Yanran, 2017, IJCNLP
   Lin ZJ, 2020, AAAI CONF ARTIF INTE, V34, P13622
   Mao ZY, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3491065
   Murthy R, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3238797
   Naous T., 2020, P 5 ARABIC NATURAL L, P58
   Naous T, 2021, P 6 ARABIC NATURAL L, P164
   Otegi A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P436
   Ranasinghe T, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3457610
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5370
   Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P300
   Roller S, 2020, Arxiv, DOI arXiv:2006.12442
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI [10.1162/tacl_a_.00313, 10.1162/tacl_a_00313]
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Vaswani A, 2017, ADV NEUR IN, V30
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Xiang L, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3457571
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483
   Yang Z, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1886
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Zhong PX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6556
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/COLI_a_00368, 10.1162/coli_a_00368]
NR 40
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR
PY 2023
VL 22
IS 4
AR 97
DI 10.1145/3579164
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9FI3
UT WOS:000998929700005
DA 2023-11-10
ER

PT J
AU Khudanpur, S
   Kim, W
AF Khudanpur, S
   Kim, W
TI Contemporaneous text as side-information in statistical language
   modeling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE multi-lingual processing; statistical language modeling; automatic
   speech recognition; resource-deficient languages; lexical triggers;
   maximum entropy
AB We propose new methods to exploit contemporaneous text, such as on-line news articles, to improve language models for automatic speech recognition and other natural language processing applications. In particular, we investigate the use of text from a resource-rich language to sharpen language models for processing a news story or article in a language with scarce linguistic resources. We demonstrate that even with fairly crude cross-language information retrieval and simple machine translation, one can construct story-specific Chinese language models which exploit cues from a side-corpus of English newswire to significantly improve the performance of language models estimated from a static Chinese corpus. Our investigations cover cases when the amount of available Chinese text is small, and a case when a large Chinese text corpus is available. We examine the effectiveness of our techniques both when the side-corpus contains English documents that are near-translations of the Chinese documents being processed, and when the English side-corpus is merely from contemporaneous and independent news sources. We present experimental results for automatic transcription of speech from the Mandarin Broadcast News corpus. (C) 2003 Elsevier Ltd. All rights reserved.
C1 Johns Hopkins Univ, Ctr Language & Speech Proc, Dept Elect & Comp Engn, Baltimore, MD 21218 USA.
   Johns Hopkins Univ, Ctr Language & Speech Proc, Dept Comp Sci, Baltimore, MD 21218 USA.
C3 Johns Hopkins University; Johns Hopkins University
RP Khudanpur, S (通讯作者)，Johns Hopkins Univ, Ctr Language & Speech Proc, Dept Elect & Comp Engn, 320 Barton Hall,3400 N Charles St, Baltimore, MD 21218 USA.
EM khudanpur@jhu.edu; woosung@cs.jhu.edu
RI Khudanpur, Sanjeev P/A-3327-2010
OI Khudanpur, Sanjeev/0000-0001-5976-0897
CR ALLAN J, 1998, P J HOPK SUMM WORKSH
   [Anonymous], P HUM LANG TECHN C
   BAEZAYATES R, 1999, MODERN INFORMATION R
   Berger A, 1998, INT CONF ACOUST SPEE, P705, DOI 10.1109/ICASSP.1998.675362
   Byrne W, 2000, INT CONF ACOUST SPEE, P1029
   Clarkson PR, 1997, INT CONF ACOUST SPEE, P799, DOI 10.1109/ICASSP.1997.596049
   COCARO D, 1998, P INT C SPOK LANG PR, V6, P2403
   DOERMANN D, 2002, P SPIE C DOC REC RET, P37
   FUNG P, 2000, P J HOPK SUMM WORKSH
   GRAFF D, 2000, P TOP DET TRACK WORK
   Iyer RM, 1999, IEEE T SPEECH AUDI P, V7, P30, DOI 10.1109/89.736328
   Khudanpur S, 1999, INT CONF ACOUST SPEE, P553, DOI 10.1109/ICASSP.1999.758185
   KHUDANPUR S, 2002, P INT C SPOK LANG PR, V1, P513
   Kim W, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P17
   OCH F, 2000, GIZA TOOLS TRAINING
   PALLETT DS, 1990, INT CONF ACOUST SPEE, P97, DOI 10.1109/ICASSP.1990.115546
   RADEV D, 2001, P J HOPK SUMM WORKSH
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   SCHEYTT P, 1998, P IEEE INT C AC SPEE, V2, P897
   SCHULTZ T, 1998, P ICSLP SYDN AUSTR, V5, P1819
   2000, HONG KONG NEWS PARAL
NR 21
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD APR
PY 2004
VL 18
IS 2
BP 143
EP 162
DI 10.1016/j.csl.2003.09.001
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 805TN
UT WOS:000220388700003
DA 2023-11-10
ER

PT J
AU Cucu, H
   Buzo, A
   Besacier, L
   Burileanu, C
AF Cucu, Horia
   Buzo, Andi
   Besacier, Laurent
   Burileanu, Corneliu
TI Enhancing ASR Systems for Under-Resourced Languages through a Novel
   Unsupervised Acoustic Model Training Technique
SO ADVANCES IN ELECTRICAL AND COMPUTER ENGINEERING
LA English
DT Article
DE speech recognition; under-resourced languages; unsupervised acoustic
   modeling; unsupervised training
AB Statistical speech and language processing techniques, requiring large amounts of training data, are currently state-of-the-art in automatic speech recognition. For high-resourced, international languages this data is widely available, while for under-resourced languages the lack of data poses serious problems. Unsupervised acoustic modeling can offer a cost and time effective way of creating a solid acoustic model for any under-resourced language. This study describes a novel unsupervised acoustic model training method and evaluates it on speech data in an under-resourced language: Romanian. The key novel factor of the method is the usage of two complementary seed ASR systems to produce high quality transcriptions, with a Character Error Rate (ChER) < 5%, for initially untranscribed speech data. The methodology leads to a relative Word Error Rate (WER) improvement of more than 10% when 100 hours of untranscribed speech are used.
C1 [Cucu, Horia; Buzo, Andi; Burileanu, Corneliu] Univ Politehn Bucuresti, Speech & Dialogue Res Lab, Bucharest, Romania.
   [Besacier, Laurent] Univ Grenoble 1, Lab Informat Grenoble, Grenoble, France.
C3 Polytechnic University of Bucharest; UDICE-French Research Universities;
   Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Cucu, H (通讯作者)，Univ Politehn Bucuresti, Speech & Dialogue Res Lab, Bucharest, Romania.
EM horia.cucu@upb.ro
RI Cucu, Horia/C-2969-2012; Burileanu, Corneliu/AEF-4574-2022; Buzo,
   Andi/B-1834-2013
OI Cucu, Horia/0000-0002-8711-3854; Buzo, Andi/0000-0001-6545-5338
FU Ministry of European Funds [POSDRU /159 /1.5 /S/134398]
FX This work has been funded by the Sectoral Operational Programme Human
   Resources Development 2007-2013 of the Ministry of European Funds
   through the Financial Agreements POSDRU /159 /1.5 /S/134398.
CR [Anonymous], 1998, DARPA BROADCAST NEWS
   [Anonymous], 2014, P SLTU
   Besacier L., SPEECH COMMUNICATION, V56, P85
   Buzo A., 2013, P INT C SPEECH TECHN, P77
   Cucu H, 2011, THESIS U POLITEHNICA
   Cucu H., 2014, P INT C COMM COMM BU, P111
   Fraga-Silva T, 2011, INT CONF ACOUST SPEE, P4656
   Kemp T., 1999, P EUROSPEECH, P2725
   Lamel L, 2002, COMPUT SPEECH LANG, V16, P115, DOI 10.1006/csla.2001.0186
   Loof J., 2009, INTERSPEECH, P88
   Ma J., 2007, P INT C AC SPEECH SI, VII, P349
   Vu NT, 2011, INT CONF ACOUST SPEE, P5000
   Ngoc Thang Vu, 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), P183, DOI 10.1109/SLT.2010.5700848
   Rouvier M., 2013, P INTERSPEECH
   Vu N., 2011, P INTERSPEECH, P3145
   Wang L, 2007, INT CONF ACOUST SPEE, P353
   Wessel F, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P307, DOI 10.1109/ASRU.2001.1034648
   Yu K, 2010, SPEECH COMMUN, V52, P652, DOI 10.1016/j.specom.2010.02.014
NR 18
TC 4
Z9 4
U1 0
U2 120
PU UNIV SUCEAVA, FAC ELECTRICAL ENG
PI SUCEAVA
PA UNIV SUCEAVA, FAC ELECTRICAL ENG, STEFAN CEL MARE, UNIVERSITATII 13,
   SUCEAVA, 720229, ROMANIA
SN 1582-7445
EI 1844-7600
J9 ADV ELECTR COMPUT EN
JI Adv. Electr. Comput. Eng.
PY 2015
VL 15
IS 1
BP 63
EP 68
DI 10.4316/AECE.2015.01009
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE9IW
UT WOS:000352158600009
OA gold
DA 2023-11-10
ER

PT J
AU Wang, J
   Zhang, XF
   Chen, L
AF Wang, Jun
   Zhang, Xiaofang
   Chen, Lin
TI How well do pre-trained contextual language representations recommend
   labels for GitHub issues?
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Deep learning; Issue labeling; Data analysis; Language model
ID TAG RECOMMENDATION; SYSTEM
AB Motivation: Open-source organizations use issues to collect user feedback, software bugs, and feature requests in GitHub. Many issues do not have labels, which makes labeling time-consuming work for the maintainers. Recently, some researchers used deep learning to improve the performance of automated tagging for software objects. However, these researches use static pre-trained word vectors that cannot represent the semantics of the same word in different contexts. Pre-trained contextual language representations have been shown to achieve outstanding performance on lots of NLP tasks.
   Description: In this paper, we study whether the pre-trained contextual language models are really better than other previous language models in the label recommendation for the GitHub labels scenario. We try to give some suggestions in fine-tuning pre-trained contextual language representation models. First, we compared four deep learning models, in which three of them use traditional pretrained word embedding. Furthermore, we compare the performances when using different corpora for pre-training.
   Results: The experimental results show that: (1) When using large training data, the performance of BERT model is better than other deep learning language models such as Bi-LSTM, CNN and RCNN. While with a small size training data, CNN performs better than BERT. (2) Further pre-training on domain-specific data can indeed improve the performance of models.
   Conclusions: When recommending labels for issues in GitHub, using pre-trained contextual language representations is better if the training dataset is large enough. Moreover, we discuss the experimental results and provide some implications to improve label recommendation performance for GitHub issues. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, Jun; Zhang, Xiaofang] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
   [Chen, Lin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Soochow University - China; Nanjing University
RP Zhang, XF (通讯作者)，Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
EM 20194227028@stu.suda.edu.cn; xfzhang@suda.edu.cn; lchen@nju.edu.cn
OI Zhang, Xiaofang/0000-0002-8667-0456
FU National Natural Science Foundation of China [61772263, 61872177];
   Collaborative Innovation Center of Novel Software Technology and
   Industrialization; Priority Academic Program Development of Jiangsu
   Higher Education Institutions
FX This work is partially supported by the National Natural Science
   Foundation of China (61772263, 61872177), Collaborative Innovation
   Center of Novel Software Technology and Industrialization, and the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions.
CR Alec R., 2018, TECH REP TECHNICAL R
   [Anonymous], 2014, WORKING C MINING SOF, DOI DOI 10.1145/2597073.2597113
   Antoniol G, 2008, P 2008 C CTR ADV STU, p23:304, DOI 10.1145/1463788.1463819
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Cabot J, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P550, DOI 10.1109/SANER.2015.7081875
   Charte F, 2015, KNOWL-BASED SYST, V89, P385, DOI 10.1016/j.knosys.2015.07.019
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen Y., J AMB INTEL HUM COMP, P1
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Guzman E., 2014, P 11 WORKING C MININ, P352, DOI DOI 10.1145/2597073.2597118
   Herzig K, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P392, DOI 10.1109/ICSE.2013.6606585
   Kallis R, 2019, PROC IEEE INT CONF S, P406, DOI 10.1109/ICSME.2019.00070
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, P1746, DOI DOI 10.3115/V1/D14-1181
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Li C, 2019, LECT NOTES ARTIF INT, V11776, P11, DOI [10.1007/978-3-030-29563-9_2, 10.1109/civemsa45640.2019.9071616]
   Liu J, 2018, AUTOMAT SOFTW ENG, V25, P675, DOI 10.1007/s10515-018-0239-4
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Nemenyi P., DISS ABSTR INT, V25, P1233
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P257, DOI 10.1007/978-0-387-85820-3_8
   Treude C, 2009, PROC INT CONF SOFTW, P12, DOI 10.1109/ICSE.2009.5070504
   Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI [DOI 10.4018/JDWM.2007070101, 10.4018/jdwm.2007070101]
   Wang SW, 2018, EMPIR SOFTW ENG, V23, P800, DOI 10.1007/s10664-017-9533-1
   Wilcoxon F., 1992, BREAKTHROUGHS STAT, VII, P196
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Xia X, 2013, IEEE WORK CONF MIN S, P287, DOI 10.1109/MSR.2013.6624040
   Yang D, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P407, DOI 10.1145/2567948.2577285
   Zhang J, 2018, KNOWL-BASED SYST, V159, P148, DOI 10.1016/j.knosys.2018.07.003
   Zhou PY, 2019, INFORM SOFTWARE TECH, V109, P1, DOI 10.1016/j.infsof.2019.01.002
   Zhou PY, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P272, DOI 10.1109/SANER.2017.7884628
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 39
TC 9
Z9 10
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 28
PY 2021
VL 232
AR 107476
DI 10.1016/j.knosys.2021.107476
EA SEP 2021
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB4VP
UT WOS:000703571500011
DA 2023-11-10
ER

PT J
AU Quimper, CG
   Rousseau, LM
AF Quimper, Claude-Guy
   Rousseau, Louis-Martin
TI A large neighbourhood search approach to the multi-activity shift
   scheduling problem
SO JOURNAL OF HEURISTICS
LA English
DT Article
DE Shift scheduling; Employee timetabling; Large neighborhood search;
   Very-large scale neighborhood; Regular languages; Context-free languages
ID BREAK WINDOWS; ALGORITHM; BRANCH
AB The challenge in shift scheduling lies in the construction of a set of work shifts, which are subject to specific regulations, in order to cover fluctuating staff demands. This problem becomes harder when multi-skill employees can perform many different activities during the same shift. In this paper, we show how formal languages (such as regular and context-free languages) can be enhanced and used to model the complex regulations of the shift construction problem. From these languages we can derive specialized graph structures that can be searched efficiently. The overall shift scheduling problem can then be solved using a Large Neighbourhood Search. These approaches are able to return near optimal solution on traditional single activity problems and they scale well on large instances containing up to 10 activities.
C1 [Rousseau, Louis-Martin] Ecole Polytech, Montreal, PQ H3C 3A7, Canada.
   [Quimper, Claude-Guy] Omega Optimisat, Montreal, PQ H2W 2R2, Canada.
C3 Universite de Montreal; Polytechnique Montreal
RP Rousseau, LM (通讯作者)，Ecole Polytech, 2500 Chemin Polytech, Montreal, PQ H3C 3A7, Canada.
EM quimper@alumni.uwaterloo.ca; louism@crt.umontreal.ca
OI Quimper, Claude-Guy/0000-0002-5899-0217
CR Ahuja RK, 2002, DISCRETE APPL MATH, V123, P75, DOI 10.1016/S0166-218X(01)00338-9
   [Anonymous], AFCRL65758
   [Anonymous], 1970, PROGRAMMING LANGUAGE
   Apt Krzysztof., 2003, PRINCIPLES CONSTRAIN
   Aykin T, 1996, MANAGE SCI, V42, P591, DOI 10.1287/mnsc.42.4.591
   Aykin T, 1998, J OPER RES SOC, V49, P603, DOI 10.2307/3010669
   BECHTOLD SE, 1990, MANAGE SCI, V36, P1339, DOI 10.1287/mnsc.36.11.1339
   Bechtold SE, 1996, NAV RES LOG, V43, P233, DOI 10.1002/(SICI)1520-6750(199603)43:2<233::AID-NAV5>3.0.CO;2-B
   BONAPARTE A, 2005, INTEGER PROGRAMMING, P437
   BOUCHARD M, 2004, OPTIMISATION PAUSES
   BRUSCO M, 1993, J OPER RES SOC, V44, P1991
   COTE MC, 2007, 4 INT C INT AI OR TE, P29
   Dantzig G.B., 1954, J OPER RES SOC AM, V2, P339, DOI [DOI 10.1287/OPRE.2.3.339, 10.1287/opre.2.3.339]
   Dechter R., 2003, CONSTRAINT PROCESSIN
   Demassey S, 2006, CONSTRAINTS, V11, P315, DOI 10.1007/s10601-006-9003-7
   Easton FF, 1999, EUR J OPER RES, V118, P505, DOI 10.1016/S0377-2217(98)00327-0
   EDIE LC, 1954, OPER RES, V2, P107
   Ernst AT, 2004, ANN OPER RES, V127, P21, DOI 10.1023/B:ANOR.0000019087.46656.e2
   Ernst AT, 2004, EUR J OPER RES, V153, P3, DOI 10.1016/S0377-2217(03)00095-X
   GLOVER F, 1986, COMPUT OPER RES, V13, P563, DOI 10.1016/0305-0548(86)90050-X
   Hopcroft JE, 2001, ACM SIGACT NEWS, V32, P60
   LOUCKS JS, 1991, DECISION SCI, V22, P719, DOI 10.1111/j.1540-5915.1991.tb00361.x
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   Mehrotra A, 2000, NAV RES LOG, V47, P185, DOI 10.1002/(SICI)1520-6750(200004)47:3<185::AID-NAV1>3.0.CO;2-7
   MEYERS C, 2006, PRACTICE THEORY AUTO, V4, P36
   Moondra S.L., 1976, J BANK RES, V7, P299
   Pesant G, 2004, LECT NOTES COMPUT SC, V3258, P482
   Quimper CG, 2007, LECT NOTES COMPUT SC, V4741, P590
   Quimper CG, 2006, LECT NOTES COMPUT SC, V4204, P751
   Rekik M, 2004, ANN OPER RES, V128, P111, DOI 10.1023/B:ANOR.0000019101.29692.2c
   RITZMAN LP, 1976, MANAGE SCI, V22, P1204, DOI 10.1287/mnsc.22.11.1204
   Rousseau LM, 2002, J HEURISTICS, V8, P43, DOI 10.1023/A:1013661617536
   SELLMANN M, 2007, P 12 INT C PRINC PRA, P530
   Shaw P, 1998, LECT NOTES COMPUT SC, V1520, P417
   THOMPSON GM, 1995, MANAGE SCI, V41, P595, DOI 10.1287/mnsc.41.4.595
   Vatri E., 2001, MEMOIRE MAITRISE ECO
   YOUNGER DH, 1967, INFORM CONTROL, V10, P189, DOI 10.1016/S0019-9958(67)80007-X
NR 37
TC 35
Z9 36
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1381-1231
J9 J HEURISTICS
JI J. Heuristics
PD JUN
PY 2010
VL 16
IS 3
SI SI
BP 373
EP 392
DI 10.1007/s10732-009-9106-6
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 586KZ
UT WOS:000276908400008
DA 2023-11-10
ER

PT J
AU Grachev, AM
   Ignatov, DI
   Savchenko, AV
AF Grachev, Artem M.
   Ignatov, Dmitry I.
   Savchenko, Andrey, V
TI Compression of recurrent neural networks for efficient language modeling
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Recurrent neural network compression; Language modeling; Mobile devices;
   Low-rank factorization
AB Recurrent neural networks have proved to be an effective method for statistical language modeling. However, in practice their memory and run-time complexity are usually too large to be implemented in real-time offline mobile applications. In this paper we consider several compression techniques for recurrent neural networks including Long-Short Term Memory models. We make particular attention to the high-dimensional output problem caused by the very large vocabulary size. We focus on effective compression methods in the context of their exploitation on devices: pruning, quantization, and matrix decomposition approaches (low-rank factorization and tensor train decomposition, in particular). For each model we investigate the trade-off between its size, suitability for fast inference and perplexity. We propose a general pipeline for applying the most suitable methods to compress recurrent neural networks for language modeling. It has been shown in the experimental study with the Penn Treebank (PTB) dataset that the most efficient results in terms of speed and compression-perplexity balance are obtained by matrix decomposition techniques. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Grachev, Artem M.] Samsung R&D Inst, Moscow, Russia.
   [Grachev, Artem M.; Ignatov, Dmitry I.] Natl Res Univ Higher Sch Econ, Moscow, Russia.
   [Savchenko, Andrey, V] Natl Res Univ Higher Sch Econ, Lab Algorithms & Technol Network Anal, Nizhnii Novgorod, Russia.
C3 HSE University (National Research University Higher School of
   Economics); HSE University (National Research University Higher School
   of Economics)
RP Grachev, AM (通讯作者)，Samsung R&D Inst, Moscow, Russia.
EM grachev.art@gmail.com
RI Ignatov, Dmitry I./D-9558-2014; Savchenko, Andrey/A-1157-2014
OI Ignatov, Dmitry I./0000-0002-6584-8534; Grachev,
   Artem/0000-0002-0268-6363; Savchenko, Andrey/0000-0001-6196-0564
FU Russian Academic Excellence Project '5-100'
FX The article was prepared within the framework of the Basic Research
   Program at the National Research University Higher School of Economics
   (HSE) and supported within the framework of a subsidy by the Russian
   Academic Excellence Project '5-100'.
CR Acharya A., 2018, CORR
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], 2016, P 2016 C EMPIRICAL M, DOI [DOI 10.18653/V1/D16-1123, 10.18653/v1/d16-1123]
   [Anonymous], CORR
   [Anonymous], 2017, INT C MACHINE LEARNI
   Arjovsky M, 2016, PR MACH LEARN RES, V48
   Bai S, 2018, UNIVERSAL LANGUAGE M
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bengio Y., P 9 INT WORKSH ART I
   Cheok AD, 2008, APPL SOFT COMPUT, V8, P1005, DOI 10.1016/j.asoc.2007.02.013
   Chirkova N, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2910
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Croft B, 2003, LANGUAGE MODELING IN, V13
   Deng HL, 2018, APPL SOFT COMPUT, V68, P432, DOI 10.1016/j.asoc.2018.03.040
   Devlin J., 2018, BERT PRETRAINING DEE, DOI DOI 10.18653/V1/N19-PROCEEDINGSOFNAACLHLT1423
   Gal Y., 2016, ADV NEURAL INFORM PR, V29, P1019, DOI [DOI 10.48550/ARXIV.1512.05287, 10.48550/arXiv.1512.05287]
   Grachev AM, 2017, LECT NOTES COMPUT SC, V10597, P351, DOI 10.1007/978-3-319-69900-4_44
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gulcehre Caglar, 2016, ARXIV160308148
   Han Song, 2015, ARXIV150602626
   Hochreiter Sepp, 2001, FIELD GUIDE DYNAMICA, P2, DOI 10.1109/9780470544037.ch14
   Inan H, 2016, ARXIV161101462 CORR
   Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P381
   Jelinek F., 1997, STAT METHODS SPEECH
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   Kingma Durk P, 2015, NEURIPS
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   LOBACHEVA E, 2017, WORKSH LEARN GEN NAT
   Lu ZY, 2016, INT CONF ACOUST SPEE, P5960, DOI 10.1109/ICASSP.2016.7472821
   Merity Stephen, 2017, ICLR
   Mikolov T., 2012, THESIS, P129
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Morin F., 2005, AISTATS, V5, P246
   Neklyudov K., 2017, P 30 ADV NEUR INF PR, P6775
   OJapa V., 2014, RECURRENT NEURAL NET
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Prabhavalkar R, 2016, INT CONF ACOUST SPEE, P5970, DOI 10.1109/ICASSP.2016.7472823
   Press O., 2017, P 15 C EUROPEAN CHAP, V2, P157, DOI DOI 10.18653/V1/E17-2025
   Rassadin A. G., 2017, P 3 INT C INF TECHN
   Tjandra A, 2017, IEEE IJCNN, P4451, DOI 10.1109/IJCNN.2017.7966420
   Vaswani A., 2017, ARXIV, V30, P5998
   Yang Zhilin, 2017, ICLR
   Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Zilly JG, 2017, PR MACH LEARN RES, V70
NR 46
TC 24
Z9 26
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUN
PY 2019
VL 79
BP 354
EP 362
DI 10.1016/j.asoc.2019.03.057
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HX8WK
UT WOS:000467687500023
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Na, SH
   Kang, IS
   Roh, JE
   Lee, JH
AF Na, SH
   Kang, IS
   Roh, JE
   Lee, JH
BE Lee, GG
   Yamada, A
   Meng, H
   Myaeng, SH
TI Effective query model estimation using parsimonious translation model in
   language modeling approach
SO INFORMATION RETRIEVAL TECHNOLOGY, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 2nd Asia Information Retrieval Symposium
CY OCT 13-15, 2005
CL Cheju Isl, SOUTH KOREA
AB The KL divergence framework, the extended language modeling approach has a critical problem with estimation of query model, which is the probabilistic model that encodes user's information need. At initial retrieval, estimation of query model by translation model had been proposed that involves term co-occurrence statistics. However, the translation model has a difficulty to applying, because term co-occurrence statistics must be constructed in offline. Especially in large collection, constructing such large matrix of term co-occurrences statistics prohibitively increases time and space complexity. More seriously, because translation model comprises noisy non-topical terms in documents, reliable retrieval performance cannot be guaranteed. This paper proposes an effective method to construct co-occurrence statistics and eliminate noisy terms by employing parsimonious translation model. Parsimonious translation model is a compact version of translation model and enables to drastically reduce number of terms that includes non-zero probabilities by eliminating non-topical terms in documents. From experimentations, we show that query model estimated from parsimonious translation model significantly outperforms not only baseline language modeling but also non-parsimonious model.
EM nsh1979@postech.ac.kr; baisk@postech.ac.kr; jeroh@postech.ac.kr;
   jhlee@postech.ac.kr
OI Na, Seung-Hoon/0000-0002-4372-7125
CR [Anonymous], P 24 ANN INT ACM SIG, DOI DOI 10.1145/383952.384019
   [Anonymous], THESIS U TWENTE
   Berger A, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P222, DOI 10.1145/312624.312681
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Hiemstra D., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178, DOI 10.1145/1008992.1009025
   Hiemstra D., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P35
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Ide N, 1998, COMPUT LINGUIST, V24, P1
   Lavrenko V., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P175
   Lavrenko Victor, 2001, P 24 ANN INT ACM SIG, P120, DOI DOI 10.1145/383952.383972
   Lee JH, 1999, INFORM PROCESS MANAG, V35, P427, DOI 10.1016/S0306-4573(98)00050-8
   LIU X, 2004, P 27 ANN INT ACM SIG, P186
   Miller DRH, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P214, DOI 10.1145/312624.312680
   Nallapati R., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P383, DOI 10.1145/584792.584855
   PONTE A, 1998, P 21 ANN INT ACM SIG, P275
   PONTE A, 1998, THESIS U MASSACHUSET
   ROBERTSON S, 2001, P WORKSH LANG MOD IN
   Song F, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P279, DOI 10.1145/312624.312698
   SPERER S, 2000, P 23 ANN INT ACM SIG, P120
   Srikanth M., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P425
   Zaragoza H., 2003, P 26 ANN INT ACM SIG, P4
   ZHAI Z, 2002, P 10 INT C INF KNOWL, P430
   Zobel Justin, 2001, P 24 ANN INT ACM SIG, P111, DOI DOI 10.1145/383952.383970
NR 23
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-29186-5
J9 LECT NOTES COMPUT SC
PY 2005
VL 3689
BP 288
EP 298
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BDF93
UT WOS:000233302700022
DA 2023-11-10
ER

PT J
AU Fröhling, L
   Zubiaga, A
AF Froehling, Leon
   Zubiaga, Arkaitz
TI Feature-based detection of automated language models: tackling GPT-2,
   GPT-3 and Grover
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Feature-based detection; Language models; Language generation; Text
   classification; NLP
AB The recent improvements of language models have drawn much attention to potential cases of use and abuse of automatically generated text. Great effort is put into the development of methods to detect machine generations among human-written text in order to avoid scenarios in which the large-scale generation of text with minimal cost and effort undermines the trust in human interaction and factual information online. While most of the current approaches rely on the availability of expensive language models, we propose a simple feature-based classifier for the detection problem, using carefully crafted features that attempt to model intrinsic differences between human and machine text. Our research contributes to the field in producing a detection method that achieves performance competitive with far more expensive methods, offering an accessible "first line-of-defense" against the abuse of language models. Furthermore, our experiments show that different sampling methods lead to different types of flaws in generated text.
C1 [Froehling, Leon] Leibniz Univ Hannover, Hannover, Germany.
   [Zubiaga, Arkaitz] Queen Mary Univ London, London, England.
C3 Leibniz University Hannover; University of London; Queen Mary University
   London
RP Fröhling, L (通讯作者)，Leibniz Univ Hannover, Hannover, Germany.
EM froehling@statistik.uni-hannover.de
RI Zubiaga, Arkaitz/H-3808-2019
OI Zubiaga, Arkaitz/0000-0003-4583-3623
CR Argamon-Engelson S., 1998, P AAAI WORKSH TEXT C, P1
   Badaskar Sameer, 2008, P 3 INT JOINT C NAT, VII
   Bakhtin A., 2019, ARXIV
   Baly R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3528
   Barzilay R, 2019, ARXIV
   Barzilay R, 2008, COMPUT LINGUIST, V34, P1, DOI 10.1162/coli.2008.34.1.1
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615
   Belz A, 2019, C TRUTH TRUST ONL
   Bisk Yonatan, 2020, ARXIV
   Biswal S., 2019, P MACHINE LEARNING H, P513
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Budzianowski P., 2019, P 3 WORKSHOP NEURAL, P15, DOI DOI 10.18653/V1/D19-5602
   Clark J., 2019, GPT 2 SIMPLE BASELIN
   Crossley SA, 2011, READ FOREIGN LANG, V23, P84
   Devlin J., 2018, ARXIV, V1, P4171
   Eneva E., 2001, P 2001 C EMP METH NA
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4647, DOI 10.1145/2858036.2858535
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Feng L., 2010, P COLING 2010, V23-27, P276, DOI DOI 10.5555/1944566.1944598
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Fung B., 2017, WASH POST
   Gehrmann S, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P111
   Hagiwara M., 2019, P 2019 C EMP METH NA
   Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689
   Holtzman A, 2019, CEUR WORKSHOP PROC, V2540
   Ippolito D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1808
   Jiang S., 2020, ARXIV
   Joachims T., 1998, P 10 EUR C MACH LEAR, P137, DOI DOI 10.1007/BFB0026683
   Kao J, 2017, MEDIUM
   Koppel M., 2002, Literary & Linguistic Computing, V17, P401, DOI 10.1093/llc/17.4.401
   Lewandowsky S, 2012, PSYCHOL SCI PUBL INT, V13, P106, DOI 10.1177/1529100612451018
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Morstatter F, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P533, DOI 10.1109/ASONAM.2016.7752287
   Perez-Rosas V., 2018, P 27 INT C COMPUTATI, P3391
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21
   Rubin V., 2016, P 2 WORKSHOP COMPUTA, P7
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   See A., 2019, CONLL, P843, DOI DOI 10.18653/V1/K19-1079
   Selyukh A, 2017, NPR
   Shevlane Toby, 2020, AIES '20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, P173, DOI 10.1145/3375627.3375815
   Solaiman I., 2019, ARXIV
   Sun Z., 2020, ARXIV
   Thorne James, 2018, P 27 INT C COMP LING, P3346
   Vaswani A, 2017, ADV NEUR IN, V30
   Zellers R., 2020, ARXIV
   Zellers Rowan, 2019, NEURIPS
   Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217
NR 49
TC 11
Z9 11
U1 7
U2 19
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD APR 6
PY 2021
AR e443
DI 10.7717/peerj-cs.443
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RI6KM
UT WOS:000637015700001
PM 33954234
OA gold, Green Published
DA 2023-11-10
ER

PT S
AU Renker, G
   Ahriz, H
AF Renker, G
   Ahriz, H
BE Regin, JC
   Rueher, M
TI Building models through formal specification
SO INTEGRATION OF AI AND OR TECHNIQUES IN CONSTRAINT PROGRAMMING FOR
   COMBINATORIAL OPTIMIZATION PROBLEMS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 1st International Conference on Integration of AI and OR Techniques in
   Constraint Programming for Combinatorial Optimization Problems
CY APR 20-22, 2004
CL Nice, FRANCE
SP INRIA, Bouygues, Cosytec SA, Carmen Syst, CoLogNET, ESSI, I3S CNRS, Intelligent Informat Syst Inst, ILOG SA
AB Over the past years, a number of increasingly expressive languages for modelling constraint and optimisation problems have evolved. In developing a strategy to ease the complexity of building models for constraint and optimisation problems, we have asked ourselves whether, for modelling purposes, it is really necessary to introduce more new languages and notations. We have analyzed several emerging languages and formal notations and found (to our surprise) that the already existing Z notation, although not previously used in this context, proves to a high degree expressive, adaptable, and useful for the construction of problem models. To substantiate these claims, we have both compiled a large number of constraint and optimisation problems as formal Z specifications and translated models from a variety of constraint languages into Z. The results are available as an online library of model specifications, which we make openly available to the modelling community.
C1 Robert Gordon Univ, Sch Comp, Aberdeen AB9 1FR, Scotland.
C3 Robert Gordon University
RP Renker, G (通讯作者)，Robert Gordon Univ, Sch Comp, Aberdeen AB9 1FR, Scotland.
EM gr@comp.rgu.ac.uk; ha@comp.rgu.ac.uk
OI Ahriz, Hatem/0000-0002-1389-3886
CR BAKEWELL A, 2000, P REF 03 WORKSH CO L, P2
   FLENER P, 2003, P REF 03, P63
   Gent IP, 1999, LECT NOTES COMPUT SC, V1713, P480
   Hentenryck P, 1999, OPL OPTIMIZATION PRO
   HNICH B, 2003, THESIS UPPSALA U SWE
   Law YC, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P54
   Renker G, 2003, LECT NOTES ARTIF INT, V2773, P1030
   RENKER G, 2003, COMP F LANGUAGE Z NO
   SMITH B, 2003, APES672003 APES RES
   Spivey J.M., 1998, Z NOTATION REFERENCE, Vsecond
   SPIVEY JM, 1988, CAMBRIDGE TRACTS THE, V3
   Walsh T, 2003, LECT NOTES COMPUT SC, V2833, P53
NR 12
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-21836-X
J9 LECT NOTES COMPUT SC
PY 2004
VL 3011
BP 395
EP 401
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Operations Research & Management Science
GA BY92W
UT WOS:000189497400029
DA 2023-11-10
ER

PT J
AU Hou, ZJ
   Salazar, J
   Polovets, G
AF Hou, Zejiang
   Salazar, Julian
   Polovets, George
TI Meta-Learning the Difference: Preparing Large Language Models for
   Efficient Adaptation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Large pretrained language models (PLMs) are often domain- or task-adapted via finetuning or prompting. Finetuning requires modifying all of the parameters and having enough data to avoid overfitting while prompting requires no training and few examples but limits performance. Instead, we prepare PLMs for data- and parameter-efficient adaptation by learning to learn the difference between general and adapted PLMs. This difference is expressed in terms of model weights and sublayer structure through our proposed dynamic low-rank reparameterization and learned architecture controller. Experiments on few-shot dialogue completion, low-resource abstractive summarization, and multi-domain language modeling show improvements in adaptation time and performance over direct finetuning or preparation via domain-adaptive pretraining. Ablations show our task-adaptive reparameterization (TARP) and model search (TAMS) components individually improve on other parameter-efficient transfer like adapters and structure-learning methods like learned sparsification.
C1 [Hou, Zejiang] Princeton Univ, Princeton, NJ 08544 USA.
   [Hou, Zejiang; Salazar, Julian; Polovets, George] Amazon AWS AI, Seattle, WA USA.
C3 Princeton University
RP Hou, ZJ (通讯作者)，Princeton Univ, Princeton, NJ 08544 USA.
EM zejiangh@princeton.edu; julsal@amazon.com; polovg@amazon.com
RI Salazar, Julian/HNQ-0995-2023
OI Salazar, Julian/0000-0003-0943-7594
CR Aghajanyan A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5799
   Alec Radford, 2019, LANGUAGE MODELS ARE
   Armen Aghajanyan, 2021, PROC ACLIJCNLP, V1, P7319
   Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1538
   Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1
   Bengio Y., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), DOI 10.1109/IJCNN.1991.155621
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Dai Andrew M., 2015, NIPS
   Dou ZY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1192
   Edward J. Hu., 2022, INT C LEARNING REPRE
   Finn C, 2017, PR MACH LEARN RES, V70
   Gardent C., 2017, P 10 INT C NAT LANG
   Guo DM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4884
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, P8342, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Hambardzumyan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4921
   He J., 2022, INT C LEARN REPR
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   ju I., 2019, ICLR
   Karimi Mahabadi R., 2021, ADV NEURAL INFORM PR, P1022
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045
   Lewis M., 2020, 58 ANN M ASS COMP LI, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Lilian Weng, 2018, METALEARNING LEARNIN
   Lin Z., 2020, FINDINGS ASS COMPUTA, P441
   Liu X, 2021, Arxiv, DOI [arXiv:2103.10385, DOI 10.48550/ARXIV.2103.10385]
   Liu Y., 2019, ROBUSTLY OPTIMIZED B
   Madotto A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5454
   Nan Linyong., 2021, P 2021 C N AM CHAPTE, P432
   Novikova J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P201
   Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P487
   Pham H, 2018, PR MACH LEARN RES, V80
   Press O, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2996
   Raffel C, 2020, J MACH LEARN RES, V21
   Rebuffi SA, 2018, PROC CVPR IEEE, P8119, DOI 10.1109/CVPR.2018.00847
   Schmidhuber J., 1987, EVOLUTIONARY PRINCIP
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222
   So D.R., 2021, P ADV NEURAL INFORM, P6010
   Song Y., 2020, ARXIV191014326, P5832, DOI DOI 10.18653/V1/2020.ACL-MAIN.517
   Stickland AC, 2019, PR MACH LEARN RES, V97
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wolf T, 2020, Arxiv, DOI [arXiv:1910.03771, DOI 10.48550/ARXIV.1910.03771]
   Yu T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5892
   Zhang Aston, 2021, ICLR
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2226
   Zhao Yuekai, 2021, FINDINGS ASS COMPUTA, P4254, DOI DOI 10.18653/V1/2021.FINDINGS-ACL.372
NR 48
TC 2
Z9 2
U1 8
U2 10
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD NOV 22
PY 2022
VL 10
BP 1249
EP 1265
DI 10.1162/tacl_a_00517
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 8I3HO
UT WOS:000921616400002
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Zagar, A
   Robnik-Sikonja, M
AF Zagar, Ales
   Robnik-Sikonja, Marko
TI Cross-lingual transfer of abstractive summarizer to less-resource
   language
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
LA English
DT Article
DE Automatic summarization; Text generation; Deep neural networks; Language
   models; Cross-lingual embeddings; Abstractive summarization
AB Automatic text summarization extracts important information from texts and presents the information in the form of a summary. Abstractive summarization approaches progressed significantly by switching to deep neural networks, but results are not yet satisfactory, especially for languages where large training sets do not exist. In several natural language processing tasks, a cross-lingual model transfer is successfully applied in less-resource languages. For summarization, the cross-lingual model transfer was not attempted due to a non-reusable decoder side of neural models that cannot correct target language generation. In our work, we use a pre-trained English summarization model based on deep neural networks and sequence-to-sequence architecture to summarize Slovene news articles. We address the problem of inadequate decoder by using an additional language model for the evaluation of the generated text in target language. We test several cross-lingual summarization models with different amounts of target data for fine-tuning. We assess the models with automatic evaluation measures and conduct a small-scale human evaluation. Automatic evaluation shows that the summaries of our best cross-lingual model are useful and of quality similar to the model trained only in the target language. Human evaluation shows that our best model generates summaries with high accuracy and acceptable readability. However, similar to other abstractive models, our models are not perfect and may occasionally produce misleading or absurd content.
C1 [Zagar, Ales; Robnik-Sikonja, Marko] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
C3 University of Ljubljana
RP Zagar, A (通讯作者)，Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
EM ales.zagar@fri.uni-lj.si; marko.robnik@fri.uni-lj.si
FU Slovene Research Agency [P6-0411, J6-2581]; European social fund and
   Republic of Slovenia, Ministry of Education, Science and Sport; Ministry
   of Culture of Republic of Slovenia through project Development of
   Slovene in Digital Environment; European Union's Horizon 2020 Programme
   project EMBEDDIA (Cross-Lingual Embeddings for Less-Represented
   Languages in European News Media) [825153]
FX The research was supported by the Slovene Research Agency through
   research core funding no. P6-0411 and project no. J6-2581. The research
   was financially supported by European social fund and Republic of
   Slovenia, Ministry of Education, Science and Sport through projects
   Quality of Slovene textbooks (KaU.c) and Ministry of Culture of Republic
   of Slovenia through project Development of Slovene in Digital
   Environment (RSDO). This paper is supported by European Union's Horizon
   2020 Programme project EMBEDDIA (Cross-Lingual Embeddings for
   Less-Represented Languages in European News Media, grant no. 825153).
CR Adams O, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P937
   Aksenov D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6680
   [Anonymous], 2017, P 2017 C EMPIRICAL M
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Baevski A., 2018, INT C LEARN REPR
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bois R., 2014, 21 TRAIT AUT LANG NA, V2, P550
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Chelba Ciprian, 2014, ONE BILLION WORD BEN
   Chen YC, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P675
   Chi ZW, 2020, AAAI CONF ARTIF INTE, V34, P7570
   Chollet Francois, 2018, P 13 C ASS MACHINE T, V1, P193
   Cohan A., 2018, ARXIV180405685, DOI [10.18653/v1/n18-2097, DOI 10.18653/V1/N18-2097]
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Dou Z.-Y., 2020, ARXIV201008014
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Fecht P., 2019, SWISS TEXT
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Graff D., 2003, LINGUISTIC DATA CONS, V4, P34, DOI DOI 10.35111/0Z6Y-Q265
   GRAVE E, 2018, LANGUAGE RESOURCES E
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI [DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]
   Hu Baotian, 2015, EMNLP, P1967, DOI DOI 10.18653/V1/D15-1229
   Krek S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P3340
   Lample G., 2018, INT C LEARNING REPRE
   Li Li, 2013, 2013 IEEE Proceedings of 14th International Vacuum Electronics Conference (IVEC2013), P1
   Lin C.-Y., 2002, P ACL 02 WORKSHOP AU, P74
   Martinc M, 2021, COMPUT LINGUIST, V47, P141, DOI [10.1162/COLI_a_00398, 10.1162/coli_a_00398]
   Merrouni ZA, 2020, J INTELL INF SYST, V54, P391, DOI 10.1007/s10844-019-00558-9
   Mihalcea Rada, 2004, P ACL 2004 INTERACTI, P170, DOI [10.3115/1219044.1219064, DOI 10.3115/1219044.1219064]
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Mikolov Tomas, 2013, INT C LEARN REPR
   Nallapati R, 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Ouyang J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2025
   Over P, 2007, INFORM PROCESS MANAG, V43, P1506, DOI 10.1016/j.ipm.2007.01.019
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Qi Weizhen, 2020, FINDINGS ASS COMPUTA, P2401, DOI 10.18653/v1/2020.findingsemnlp.217
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rajani Nazneen, 2021, ARXIV210508209
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Rush A M, 2015, P 2015 C EMPIRICAL M, P379
   Scialom T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8051
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Straka Milan, 2018, P 11 INT C LANG RES
   Suppa M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6725
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O., 2015, P ADV NEURAL INFORM, P2692, DOI 10.48550/arxiv.1506.03134
   Zhang Jingqing, 2020, P INT C MACH LEARN, P11328, DOI DOI 10.1038/S41746-021-00437-0
   Zhang Tianyi, 2019, ICLR
   Zhu JN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3054
   Zidarn R., 2020, THESIS U LJUBLJANA F
NR 51
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0925-9902
EI 1573-7675
J9 J INTELL INF SYST
JI J. Intell. Inf. Syst.
PD FEB
PY 2022
VL 58
IS 1
BP 153
EP 173
DI 10.1007/s10844-021-00663-8
EA SEP 2021
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YX6LS
UT WOS:000698081200001
OA Green Submitted, Green Published
DA 2023-11-10
ER

PT J
AU Agüero-Torales, M
   López-Herrera, AG
   Vilares, D
AF Aguero-Torales, Marvin M.
   Lopez-Herrera, Antonio G.
   Vilares, David
TI Multidimensional Affective Analysis for Low-Resource Languages: A Use
   Case with Guarani-Spanish Code-Switching Language
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Natural language processing; Sentiment analysis; Affective analysis;
   Code-switching; Low-resource languages
ID SENTIMENT ANALYSIS
AB This paper focuses on text-based affective computing for Jopara, a code-switching language that combines Guarani and Spanish. First, we collected a dataset of tweets primarily written in Guarani and annotated them for three widely used dimensions in sentiment analysis: (a) emotion recognition, (b) humor detection, and (c) offensive language identification. Then, we developed several neural network models, including large language models specifically designed for Guarani, and compared their performance against off-the-shelf multilingual and Spanish pre-trained models for the aforementioned dimensions. Our experiments show that language models incorporating Guarani during pre-training or pre-fine-tuning consistently achieve the best results, despite limited resources (a single 24-GB GPU and only 800K tokens). Notably, even a Guarani BERT model with just two layers of Transformers shows a favorable balance between accuracy and computational power, likely due to the inherent low-resource nature of the task. We present a comprehensive overview of corpus creation and model development for low-resource languages like Guarani, particularly in the context of its code-switching with Spanish, resulting in Jopara. Our findings shed light on the challenges and strategies involved in analyzing affective language in such linguistic contexts.
C1 [Aguero-Torales, Marvin M.; Lopez-Herrera, Antonio G.] Univ Granada, Dept Comp Sci & Artificial Intelligence, Calle Daniel Saucedo Aranda S-N, Granada 18071, Granada, Spain.
   [Vilares, David] Univ A Coruna, Dept Comp Sci & Informat Technol, CITIC, Campus Elvina S-N, La Coruna 15008, A Coruna, Spain.
   [Aguero-Torales, Marvin M.] Global CoE Data Intelligence, Camino Cerro Gamos 1, Madrid 28224, Spain.
C3 University of Granada; Universidade da Coruna
RP Agüero-Torales, M (通讯作者)，Univ Granada, Dept Comp Sci & Artificial Intelligence, Calle Daniel Saucedo Aranda S-N, Granada 18071, Granada, Spain.; Agüero-Torales, M (通讯作者)，Global CoE Data Intelligence, Camino Cerro Gamos 1, Madrid 28224, Spain.
EM maguero@correo.ugr.es; lopez-herrera@decsai.ugr.es; david.vilares@udc.es
OI Aguero-Torales, Marvin M./0000-0002-0910-0310
FU FBBVA; SCANNER-UDC [PID2020-113230RB-C21]; MCIN/AEI; European Research
   Council (ERC); European Union [101100615]; Xunta de Galicia [ED431C
   2020/11]; European Union (ERDF - Galicia 2014-2020 Program) [ED431G
   2019/01]; University of Granada; Generalitat Valenciana; University of
   Alicante [IDIFEDER/2020/003]; European Research Council (ERC)
   [101100615] Funding Source: European Research Council (ERC)
FX This work is supported by a 2020 Leonardo Grant for Researchers and
   Cultural Creators from the FBBVA. This paper has also received funding
   from grant SCANNER-UDC (PID2020-113230RB-C21) funded by
   MCIN/AEI/10.13039/501100011033, the European Research Council (ERC),
   which has supported this research under the European Union's Horizon
   Europe research and innovation programme (SALSA, grant agreement no.
   101100615), Xunta de Galicia (ED431C 2020/11), and Centro de
   Investigacion de Galicia "CITIC," funded by Xunta de Galicia and the
   European Union (ERDF - Galicia 2014-2020 Program), by grant ED431G
   2019/01. Additionally, the research leading to these results received
   funding from the University of Granada, Generalitat Valenciana, and the
   University of Alicante (IDIFEDER/2020/003).
CR Abdellaoui H, 2018, COMPUT SIST, V22, P777, DOI 10.13053/CyS-22-3-3031
   Adelani DI, 2021, T ASSOC COMPUT LING, V9, P1116, DOI 10.1162/tacl_a_00416
   Adwan OY, 2020, INT J EMERG TECHNOL, V15, P79, DOI 10.3991/ijet.v15i15.14467
   Afli H., 2017, P 18 INT C COMP LING
   Agerri R, 2020, P 12 LANGUAGE RESOUR
   Aguero-Torales MM, 2021, P 5 WORKSHOP COMPUTA, P95
   Aguero-Torales MM, 2022, MACHINE LEARNING APP
   Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2
   Asgari E, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4113
   Attardi G., WIKIEXTRACTOR
   Babu A, 2022, INTERSPEECH, P2278, DOI 10.21437/Interspeech.2022-143
   Baevski Alexei, 2020, P ADV NEUR INF PROC, V33, P12449
   Batra R, LARGE SCALE TWEET DA
   Biewald L, EXPT TRACKING WEIGHT
   BittarPrieto J, 2016, THESIS U NEW MEXICO
   BittarPrieto J, 2020, CONSTRUCTIONIST APPR
   Boidin C, 2005, REGIONALWISSENSCHAFT, V11, P303
   Borges Y, 2021, PROCES LENG NAT, P89, DOI 10.26342/2021-66-7
   Cambria E, 2015, COGN COMPUT, V7, P183, DOI 10.1007/s12559-015-9325-0
   Canete J., 2020, PML4DC ICLR 2020, P1
   Chatterjee A., 2019, P 13 INT WORKSH SEM, P39
   Chen YQ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383
   Chiruzzo L, 2023, P 12 INT GLOB WORDN
   Chiruzzo L, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2098
   Chiruzzo L, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5106
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P6022, DOI DOI 10.18653/V1/2020.ACL-MAIN.536
   Cordova J, 2019, INFORM MANAGEMENT BI, P198, DOI [10.1007/978-3-030-11680-4_20, DOI 10.1007/978-3-030-11680-4_20]
   Costa-jussa MR, ARXIV
   de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI [10.1162/coli_a_00402, 10.1162/COLI_a_00402]
   Devi MD., 2020, MACHINE LEARNING IMA, P411, DOI 10.1007/978-981-15-6318-8_34
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duran M., 2021, FORMALISING NATURAL, P61, DOI [10.1007/978-3-030-70629-6_6, DOI 10.1007/978-3-030-70629-6_6]
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Estigarribia B, 2020, GRAMMAR PARAGUAYAN G
   Estigarribia B, 2015, J LANG CONTACT, V8, P183, DOI 10.1163/19552629-00802002
   GarciaTrillo MA, 2021, PROCESAMIENTO LENGUA, V1
   Ghosh S, 2022, COGN COMPUT, V14, P110, DOI 10.1007/s12559-021-09828-7
   Giossa N, 2021, THESIS U REPUBLICA U
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Green DW, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00103
   Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2545
   Hossain N, 2020, P 14 WORKSHOP SEMANT, P746, DOI DOI 10.18653/V1/2020.SEMEVAL-1.98
   Jain DK, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102758
   Jakobsen AL, 2017, TRANSLATION TRANSITI, V133
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kann K, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.995667
   Kann K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3342
   Khan Mansoor, 2020, 2020 IEEE 8th International Conference on Photonics (ICP), P1, DOI 10.1109/ICP46580.2020.9206421
   Kuratov Y., 2019, ABS190507213 CORR
   Kuznetsova A, 2021, P 1 WORKSH NAT LANG, P81
   Lamprinidis S, 2021, P 11 WORKSHOP COMPUT, P62
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4483
   LeCun Y., 1995, CONVOLUTIONAL NETWOR, V3361, P1995, DOI 10.5555/303568.303704
   Lieberman MD, 2019, NAT HUM BEHAV, V3, P20, DOI 10.1038/s41562-018-0487-0
   Liu Yinhan, ROBERTA ROBUSTLY OPT
   Mager M, 2018, P 27 INT C COMP LING, P55, DOI DOI 10.48550/ARXIV.1806.04291
   Mager M, 2021, P 1 WORKSH NAT LANG, P202, DOI DOI 10.18653/V1/2021.AMERICASNLP-1.23
   Magooda A, 2021, FINDINGS ASS COMPUTA, P1652
   Mamta, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3514498
   Mazumder M, 2021, 35 C NEURAL INFORM P
   Mihalcea R, 2006, COMPUT INTELL-US, V22, P126, DOI 10.1111/j.1467-8640.2006.00278.x
   Mikolov T., 2017, SHORT PAPERS, P427, DOI 10.18653/v1/e17
   Muhammad SH, NAIJASENTI NIGERIAN
   Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3434237
   Novak PK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144296
   Ogueji K, 2021, P 1 WORKSH MULT REPR, P116
   Pajupuu H, 2016, FOLKLORE-EL J FOLKL, P125, DOI 10.7592/FEJF2016.64.polarity
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7654
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Plaza-Del-Arco FM, 2021, IEEE ACCESS, V9, P112478, DOI 10.1109/ACCESS.2021.3103697
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.28.739
   Ranasinghe T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5838
   Ríos AA, 2014, 2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P37, DOI 10.1109/BRACIS.2014.18
   Schulz C, 2018, P 2018 C N AM CHAPT, V2, P35
   Souza Fabio, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P403, DOI 10.1007/978-3-030-61377-8_28
   Strapparava C, 2015, OXFORD HDB AFFECTIVE
   Tejwani R., ARXIV
   Vilares D, 2021, PROCES LENG NAT, P13, DOI 10.26342/2021-66-1
   Wang M, 2020, P 22 ANN C EUROPEAN, P53
   Wang Z, 2020, INT C LEARNING REPRE
   Winata GI, 2021, P 1 WORKSHOP MULTILI, P1, DOI DOI 10.18653/V1/2021.MRL-1.1
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833
   Wu Y, 2016, ARXIV
   Xu QT, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3030, DOI 10.1109/ICASSP39728.2021.9414641
   YANG J, 2018, P ACL 2018 SYST DEM, P74, DOI DOI 10.18653/V1/P18-4013
   Yen MF, 2022, COMPUT ECON, V59, P1677, DOI 10.1007/s10614-021-10111-y
   Yong Hu, 2020, Web and Big Data. 4th International Joint Conference, APWeb-WAIM 2020. Lecture Notes in Computer Science (LNCS 12317), P603, DOI 10.1007/978-3-030-60259-8_44
   Yong ZX, ARXIV
   Yue L, 2019, KNOWL INF SYST, V60, P617, DOI 10.1007/s10115-018-1236-4
   Zampieri M, 2020, P 14 WORKSH SEM EV I, P1425, DOI [10.18653/v1/2020.semeval-1.188, DOI 10.18653/V1/2020.SEMEVAL-1.188]
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
NR 93
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD JUL
PY 2023
VL 15
IS 4
BP 1391
EP 1406
DI 10.1007/s12559-023-10165-0
EA JUN 2023
PG 16
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA O3JP9
UT WOS:001020154100001
DA 2023-11-10
ER

PT J
AU Berrimi, M
   Oussalah, M
   Moussaoui, A
   Saidi, M
AF Berrimi, Mohamed
   Oussalah, Mourad
   Moussaoui, Abdelouahab
   Saidi, Mohamed
TI Attention Mechanism Architecture for Arabic Sentiment Analysis
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Arabic sentiment analysis; attention mechanism; pretrained word
   embeddings; language understanding
AB This article tackles the problem of sentiment analysis in the Arabic language where a new deep learning model has been put forward. The proposed model uses a hybrid bidirectional gated recurrent unit (BiGRU) and bidirectional long short-term memory (BiLSTM) additive-attention model where the Bidirectional GRU/LSTM reads the individual sentence input from left to right and vice versa, enabling the capture of the contextual information. However, the model is trained on two types of embeddings: FastText and local learnable embeddings. The BiLSTM and BiGRU architectures are put into competition to identify the best hyperparameter set for the model. The developed model has been tested on three large-scale commonly employed Arabic sentiment dataset: large-scale Arabic Book Reviews Dataset (ABRD), Hotel Arabic-Reviews Dataset (HARD), and Books Reviews in the Arabic Dataset (BRAD). The testing results demonstrate that our model outperforms both the baseline models and the state-of-the-art models reported in the original references of these datasets, achieving accuracy scores of 98.6%, 96.19%, 95.65% for LARB, HARD, and BRAD, respectively. Furthermore, to demonstrate the generalization capabilities of our model, the performances of the model have been evaluated on three other natural language processing tasks: news categorization, offensive speech detection, and Russian sentiment analysis. The results demonstrated the developed model is language- and task-independent, which offers new perspectives for the application of the developed models in several other natural language processing challenges.
C1 [Berrimi, Mohamed; Moussaoui, Abdelouahab; Saidi, Mohamed] Univ Ferhat Abbas 1, Dept Comp Sci, Setif, Algeria.
   [Oussalah, Mourad] CMVS Univ Oulu, Fac ITEE, Oulu, Finland.
RP Berrimi, M (通讯作者)，Univ Ferhat Abbas 1, Dept Comp Sci, Setif, Algeria.
EM Mohamed.Berrimi@univ-setif.dz; Mourad.oussalah@oulu.fi;
   Abdelouahab.Moussaoui@univ-setif.dz; Mohamed.Saidi@univ-setif.dz
OI Oussalah, Mourad/0000-0002-4422-8723; Moussaoui,
   Abdelouahab/0000-0003-3669-1264
CR Abbes I, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6265
   Abdaoui A, 2022, Arxiv, DOI arXiv:2109.12346
   Abdul-Mageed M., 2020, P 5 ARABIC NATURAL L, P97
   Abdul-Mageed M, 2021, ACL IJCNLP 2021 59 A, Vi, P7088, DOI DOI 10.18653/V1/2021.ACL-LONG.551
   Abdulla NA, 2013, 2013 IEEE JORDAN CONFERENCE ON APPLIED ELECTRICAL ENGINEERING AND COMPUTING TECHNOLOGIES (AEECT)
   Abu Farha I, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102438
   Abu Farha I, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P192
   Abu Kwaik K, 2019, COMM COM INF SC, V1108, P108, DOI 10.1007/978-3-030-32959-4_8
   Abualigah L. M. Q., 2019, FEATURE SELECTION EN
   Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Abualigah L, 2021, ARTIF INTELL REV, V54, P2567, DOI 10.1007/s10462-020-09909-3
   Abualigah LM, 2016, 2016 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), P67, DOI 10.1109/ISCAIE.2016.7575039
   Al-Azani S, 2018, PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON COMPUTING SCIENCES AND ENGINEERING (ICCSE)
   Al-Dabet S., 2019, 2019 2 INT C NEW TRE, P1, DOI DOI 10.1109/ICTCS.2019
   Alamro Hind, 2021, ARXIV
   Alayba AM, 2018, LECT NOTES COMPUT SC, V11015, P179, DOI 10.1007/978-3-319-99740-7_12
   Alharbi AI, 2021, PROCEDIA COMPUT SCI, V189, P258, DOI 10.1016/j.procs.2021.05.089
   Alharbi B, 2021, Arxiv, DOI arXiv:2011.00578
   Almani Nada Mohammed, 2020, 2020 6th Conference on Data Science and Machine Learning Applications (CDMA), P47, DOI 10.1109/CDMA47397.2020.00014
   Altowayan AA, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3820, DOI 10.1109/BigData.2016.7841054
   Aly M., 2013, P 51 ANN M ASS COMP, V2, P494
   [Anonymous], 2016, INT RES J ENG TECHNO
   [Anonymous], 2016, P 26 INT C COMPUTATI
   Antoun W., 2020, P 4 WORKSHOP OPEN SO, P9
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Barhoumi A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4955
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Britto AS, 2014, PATTERN RECOGN, V47, P3665, DOI 10.1016/j.patcog.2014.05.003
   Cavalin PR, 2013, NEURAL COMPUT APPL, V22, P673, DOI 10.1007/s00521-011-0737-9
   Chung J, 2014, NIPS 2014 WORKSH DEE, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Dahou A, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3314941
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dieng Adji Bousso, 2017, P 5 INT C LEARNING R
   Einea O, 2019, DATA BRIEF, V25, DOI 10.1016/j.dib.2019.104076
   El-Beltagy SR, 2017, P 11 INT WORKSH SEM, P790, DOI DOI 10.18653/V1/S17-2133
   ElJundi O, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P68
   Elmallah A, 2018, IEEE CUST INTEGR CIR
   Elnagar A., 2018, COMPUTATIONAL INTELL, P35, DOI DOI 10.1007/978-3-319-67056-0_3
   Elnagar Ashraf, 2016, 2016 IEEEACS 13 INT, P1, DOI DOI 10.1109/AICCSA.2016.7945800
   Elnagar Ashraf, 2019, P 2 WORKSHOP MULTILI
   ElSahar H, 2015, LECT NOTES COMPUT SC, V9042, P23, DOI 10.1007/978-3-319-18117-2_2
   Fan H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111332
   Farghaly A., 2009, ACM T ASIAN LANGUAGE, V8, P1, DOI DOI 10.1145/1644879.1644881
   Farha A., 2021, P 6 AR NAT LANG PROC, P296
   Gamal D, 2019, PROCEDIA COMPUT SCI, V154, P332, DOI 10.1016/j.procs.2019.06.048
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Guellil I, 2021, J KING SAUD UNIV-COM, V33, P497, DOI 10.1016/j.jksuci.2019.02.006
   Han Y, 2020, IEEE ACCESS, V8, P21314, DOI 10.1109/ACCESS.2020.2969473
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Khalifa S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P3895
   Kim Y., 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1181
   Kuncheva L.I., 2014, COMBINING PATTERN CL, V2nd ed.
   Li BF, 2017, AAAI CONF ARTIF INTE, P3067
   Liu B., 2016, SENTIMENT ANAL MININ
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Maas Andrew., 2011, P 49 ANN M ASS COMPU, P142
   Mataoui M., 2016, RES COMPUT SCI, V110, P55, DOI [10.13053/rcs-110-1-5, DOI 10.13053/RCS-110-1-5]
   Meftouh K., 2015, P 29 PACIFIC ASIA C, P26
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Moudjari Leila, 2020, Procedia Computer Science, V176, P1151, DOI 10.1016/j.procs.2020.09.111
   Nabil M., 2015, P 2015 C EMP METH NA, P2515, DOI DOI 10.18653/V1/D15-1299
   Ombabi AH, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00668-1
   Oueslati O, 2020, FUTURE GENER COMP SY, V112, P408, DOI 10.1016/j.future.2020.05.034
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Rebiai Zinedine, 2019, P 13 INT WORKSHOP SE, P297
   Rosenthal S., 2017, P 11 INT WORKSHOP SE, P1, DOI [10.18653/v1/S17-2088, DOI 10.18653/V1/S17-2088]
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Soumeur A, 2018, PROCEDIA COMPUT SCI, V142, P26, DOI 10.1016/j.procs.2018.10.458
   Thongtan T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P407
   Vaswani A, 2017, ADV NEUR IN, V30
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Xie Qizhe, 2020, P 34 C NEURAL INFORM
   Yang Z., 2016, P 2016 C N AM CHAPTE, P1480, DOI [10.18653/v1/N16-1174, DOI 10.18653/V1/N16-1174]
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang L, 2011, COMBINING LEXICON BA, V89, P1
   Zitouni I., 2014, NATURAL LANGUAGE PRO
NR 82
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR
PY 2023
VL 22
IS 4
AR 107
DI 10.1145/3578265
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9FI3
UT WOS:000998929700015
OA Bronze
DA 2023-11-10
ER

PT J
AU Maucec, MS
   Rotovnik, T
   Kacic, Z
   Brest, J
AF Maucec, Mirjam Sepesy
   Rotovnik, Tomaz
   Kacic, Zdravko
   Brest, Janez
TI USING DATA-DRIVEN SUBWORD UNITS IN LANGUAGE MODEL OF HIGHLY INFLECTIVE
   SLOVENIAN LANGUAGE
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Statistical language modeling; inflective language; subword units;
   speech recognition
ID CONTINUOUS SPEECH RECOGNITION
AB This paper presents the results of a study on modeling the highly inflective Slovenian language. a We focus on creating a language model for a large vocabulary speech recognition system. A new data-driven method is proposed for the induction of inflectional morphology into language modeling. The research focus is on data sparsity, which results from the complex morphology of the language. The idea of using subword units is examined. An attempt is made to figure out the segmentation of words into two subword units: stems and endings. No prior knowledge of the language is used. The subword units should fit into the frameworks of the probabilistic language models. A morphologically correct decomposition of words is not being sought, but searching for a decomposition which yields the minimum entropy of the training corpus. This entropy is approximated by using N-gram models. Despite some seemingly over-simplified assumption, the subword models improve the applicability of the language models for a sparse training corpus.
   The experiments were performed using the VECER newswire text corpus as a training corpus. The test set was taken from the SNABI speech database, because the final models were evaluated in speech recognition experiments on SNABI speech database. Two different subword-based models are proposed and examined experimentally. The experiments demonstrate that subword-based models, which considerably reduce OOV rate, improve speech recognition WER when compared with standard word-based models, even though they increase test set perplexity. Subword-based models with improved perplexity, but which reduce the OOV rate much less than the previous ones, do not improve speech recognition results.
C1 [Maucec, Mirjam Sepesy; Rotovnik, Tomaz; Kacic, Zdravko; Brest, Janez] Univ Maribor, Fac Elect Engn & Comp Sci, SLO-2000 Maribor, Slovenia.
C3 University of Maribor
RP Maucec, MS (通讯作者)，Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SLO-2000 Maribor, Slovenia.
EM mirjam.sepesy@uni-mb.si
RI Brest, Janez/B-8013-2008
OI Brest, Janez/0000-0001-5864-3533
FU Slovenian Research Agency [J2-97420796-06]
FX This work was partially funded by Slovenian Research Agency, under
   contract number: J2-97420796-06.
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1007/BF00153759
   [Anonymous], SPEECH RECOGNITION H
   [Anonymous], 2002, P INT C SPOKEN LANGU
   Arisoy E, 2006, SIGNAL PROCESS, V86, P2844, DOI 10.1016/j.sigpro.2005.12.002
   BRILL E, 1995, COMPUT LING, V21
   BYRNE W, 2001, P EUROSPEECH
   CERFDANON H, 1991, P INT C AC SPEECH SI, V1, P297
   CHOUEITER G, 2007, P ICASSP, V1, P1053
   Creutz M, 2005, P INT INT C AD KNOWL, P106
   DESHMUKH N, 1999, LARGE VOCABULARY CON
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   GOLDWATER S, 2006, P COL ACL
   HAJIC J, 1997, P ACL COL, P483
   Hirsimäki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   JARDINO M, 1993, P ICASSP 93, V2, P41
   Jelinek F., 1997, STAT METHODS SPEECH
   KACIC Z, 2000, P LREC, P946
   KURIMO M, 2006, HUM LANG TECHN C N A
   KURIMO M, 2007, CLEF 2007 WORKSH BUD
   Kwon OW, 2003, SPEECH COMMUN, V39, P287, DOI 10.1016/S0167-6393(02)00031-6
   Liwicki M, 2007, INT J PATTERN RECOGN, V21, P83, DOI 10.1142/S0218001407005314
   MALKOVSKY MG, 1985, DIALOGUE ARTIFICIAL
   MALTESE G, 1991, P EUROSPEECH 91, P753
   Maucec M. S., 2003, International Journal of Speech Technology, V6, P245, DOI 10.1023/A1023466103841
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   Rotovnik T, 2007, SPEECH COMMUN, V49, P437, DOI 10.1016/j.specom.2007.02.010
   SNOVER M, 2003, P NIPS, P1513
   TSOU BK, 2006, INT J PATTERN RECOGN, V19, P99
   Wang XL, 2005, INT J PATTERN RECOGN, V19, P109, DOI 10.1142/S0218001405003934
   WHITTAKER EWD, 2000, P ICSLP BEIJ CHIN
   WITSCHEL P, 1993, P EUR, P1199
   [No title captured]
NR 32
TC 1
Z9 1
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD MAR
PY 2009
VL 23
IS 2
BP 287
EP 312
DI 10.1142/S0218001409007119
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 431WH
UT WOS:000265094700006
DA 2023-11-10
ER

PT J
AU Vogt, P
AF Vogt, P
TI The emergence of compositional structures in perceptually grounded
   language games
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE compositionality; grammar induction; grounding; iterated learning;
   language evolution; language games
ID EVOLUTION; CHILDREN; SIGN
AB This paper describes a new model on the evolution and induction of compositional structures in the language of a population of (simulated) robotic agents. The model is based on recent work in language evolution modelling, including the iterated learning model, the language game model and the Talking Heads experiment. It further adopts techniques recently developed in the field of grammar induction. The paper reports on a number of different experiments done with this new model and shows certain conditions under which compositional structures can emerge. The paper confirms previous findings that a transmission bottleneck serves as a pressure mechanism for the emergence of compositionality, and that a communication strategy for guessing the references of utterances aids in the development of qualitatively 'good' languages. In addition, the results show that the emerging languages reflect the structure of the world to a large extent and that the development of a semantics, together with a competitive selection mechanism, produces a faster emergence of compositionality than a predefined semantics without such a selection mechanism. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Edinburgh, Sch Philosophy Psychol & Language Sci, Language Evolut & Computat Res Unit, Edinburgh, Midlothian, Scotland.
   Tilburg Univ, Induc Linguist Knowledge Grp, NL-5000 LE Tilburg, Netherlands.
C3 University of Edinburgh; Tilburg University
RP Vogt, P (通讯作者)，Univ Edinburgh, Sch Philosophy Psychol & Language Sci, Language Evolut & Computat Res Unit, Edinburgh, Midlothian, Scotland.
EM paulv@ling.ed.ac.uk
RI Galantucci, Bruno/E-5770-2010
OI Vogt, Paul/0000-0002-9446-4425
CR [Anonymous], THESIS U CALIFORNIA
   [Anonymous], THESIS MIT
   [Anonymous], LINGUISTIC EVOLUTION
   [Anonymous], 2002, SIMULATING EVOLUTION
   [Anonymous], EVOLUTIONARY EMERGEN, DOI DOI 10.1017/CBO9780511606441.019
   Baayen RH, 1997, J MEM LANG, V37, P94, DOI 10.1006/jmla.1997.2509
   Batali J, 2002, LINGUISTIC EVOLUTION, P111
   BELPAEME T, 1998, LECT NOTES ARTIFICIA, V1545
   Bloom Paul, 2000, CHILDREN LEARN MEANI
   Bod Rens, 1998, GRAMMAR EXPERIENCE B
   Brighton H, 2002, ARTIF LIFE, V8, P25, DOI 10.1162/106454602753694756
   BRIGHTON H, 2001, LECT NOTES ARTIFICIA, V2159
   BRISCOE EJ, 2002, LINGUISTIC EVOLUTION, P255
   Cangelosi A, 1998, CONNECT SCI, V10, P83, DOI 10.1080/095400998116512
   CHOMSKY N, 1980, BEHAV BRAIN SCI, V3, P1, DOI 10.1017/S0140525X00001515
   Chouinard MM, 2003, J CHILD LANG, V30, P637, DOI 10.1017/S0305000903005701
   Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670
   Gardenfors P, 2000, CONCEPTUAL SPACES
   GONG T, 2004, ARTIF LIFE, V9, P214
   Hashimoto T, 1996, BIOSYSTEMS, V38, P1, DOI 10.1016/0303-2647(95)01563-9
   Hurford J. R., 2000, EVOLUTIONARY EMERGEN, P324, DOI DOI 10.1017/CBO9780511606441.020
   HURFORD JR, 1989, LINGUA, V77, P187, DOI 10.1016/0024-3841(89)90015-6
   KAPLAN F, 2000, THESIS LAB INFORM PA
   Kirby S, 2002, SIMULATING THE EVOLUTION OF LANGUAGE, P121
   Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430
   KIRBY S, 2002, ARTIFICIAL LIFE, V8
   KIRBY S, 2002, LINGUISTIC EVOLUTION
   Lakoff G., 1987, WOMEN FIRE DANGEROUS, DOI 10.7208/chicago/9780226471013.001.0001
   Langacker R. W., 1987, FDN COGNITIVE GRAMME, VI
   Lieven E, 2003, J CHILD LANG, V30, P333, DOI 10.1017/S0305000903005592
   MACLENNAN B, 1991, SFI STUDIES SCI COMP, V10
   MAROCCO D, 1811, PHILOS T MATH PHYS E, V361, P2397
   NEUBAUER N, 2004, EMERGENCE MULTIAGENT
   Oliphant M, 1996, BIOSYSTEMS, V37, P31, DOI 10.1016/0303-2647(95)01543-4
   PINKER S, 1990, BEHAV BRAIN SCI, V13, P707, DOI 10.1017/S0140525X00081061
   Sankoff G., 1973, KIVUNG, V6, P32, DOI DOI 10.9783/9781512809589-014
   Senghas A, 2004, SCIENCE, V305, P1779, DOI 10.1126/science.1100199
   Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7
   Smith ADM, 2003, ARTIF LIFE, V9, P175, DOI 10.1162/106454603322221513
   Smith AndrewD.M., 2005, LANGUAGE ORIGINS PER, P372
   Smith K, 2004, J THEOR BIOL, V228, P127, DOI 10.1016/j.jtbi.2003.12.016
   Smith K, 2003, ADV COMPLEX SYST, V6, P537, DOI 10.1142/S0219525903001055
   Smith K, 2003, LECT NOTES ARTIF INT, V2801, P507
   Steels L., 1997, EVOLUTION COMMUNICAT, V10, P1, DOI DOI 10.1075/E0C.1.1.02STE
   STEELS L, 2004, P ANN M ASS COMP LIN
   STEELS L, 1997, P 4 EUR C ART LIF CA
   STEELS L, 2005, IN PRESS BEHAV BRAIN
   STEELS L, 1996, ANIMALS ANIMALS, V4
   STEELS L, 1996, P INT C MULT AG SYST
   STEELS L, 2002, TRANSITION LANGUAGE
   STEELS L, 1999, P IJCAI 99 STOCKH SW
   Tomasello M, 2000, COGNITION, V74, P209, DOI 10.1016/S0010-0277(99)00069-4
   Tomasello M., 2003, CULTURAL ORIGINS HUM
   VANZAANEN M, 2003, DATA ORIENTED PARSIN, P385
   Vogt P, 2003, JASSS-J ARTIF SOC S, V6
   Vogt P, 2003, ROBOT AUTON SYST, V43, P109, DOI 10.1016/S0921-8890(02)00353-6
   VOGT P, 2000, EVOLUTION COMMUNICAT, V4, P89
   VOGT P, 2003, ADV ARTIFICIAL LIFE
   VOGT P, 2005, IN PRESS ADAPTIVE BE
   VOGT P, 2003, LANGUAGE EVOLUTION C
   VOGT P, 2005, P IJCAI 05
   Vogt P., 2002, COGNITIVE SYSTEMS RE, V3, P429, DOI DOI 10.1016/S1389-0417(02)00051-7
   VOGT P, 2005, IN PRESS BEHAV BRAIN
   WERNER GM, 1991, SFI STUDIES SCI COMP, V10
   Wray A, 1998, LANG COMMUN, V18, P47, DOI 10.1016/S0271-5309(97)00033-5
   Zipf G.K., 1949, HUMAN BEHAVIOUR PRIN
   ZUIDEMA W, 2003, ADV NEURAL INFORM PR, V15
NR 67
TC 63
Z9 63
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD SEP
PY 2005
VL 167
IS 1-2
BP 206
EP 242
DI 10.1016/j.artint.2005.04.010
PG 37
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 966RH
UT WOS:000232038100008
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Hirsimäki, T
   Creutz, M
   Siivola, V
   Kurimo, M
   Virpioja, S
   Pylkkönen, J
AF Hirsimaki, Teemu
   Creutz, Mathias
   Siivola, Vesa
   Kurimo, Mikko
   Virpioja, Sami
   Pylkkonen, Janne
TI Unlimited vocabulary speech recognition with morph language models
   applied to Finnish
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
ID ALGORITHM
AB In the speech recognition of highly inflecting or compounding languages, the traditional word-based language modeling is problematic. As the number of-distinct word forms can grow very large, it becomes difficult to train language models that are both effective and cover the words of the language well. In the literature, several methods have been proposed for basing the language modeling on sub-word units instead of whole words. However, to our knowledge, considerable improvements in speech recognition performance have not been reported.
   In this article, we present a language-independent algorithm for discovering word fragments in an unsupervised manner from text. The algorithm uses the Minimum Description Length principle to find an inventory of word fragments that is compact but models the. training text effectively. Language modeling and speech recognition experiments show that n-gram models built over these fragments perform better than n-gram models based on words. In two Finnish recognition tasks, relative error rate reductions between 12% and 31% are obtained. In addition, our experiments suggest that word fragments obtained using grammatical rules do not outperform the fragments discovered from text. We also present our recognition system and discuss how utilizing fragments instead of words affects the decoding process. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Aalto Univ, Neural Networks Res Ctr, FIN-02150 Espoo, Finland.
C3 Aalto University
RP Hirsimäki, T (通讯作者)，Aalto Univ, Neural Networks Res Ctr, POB 5400,Konemiehentie 2, FIN-02150 Espoo, Finland.
EM teemu.hirsimaki@hut.fi
RI Creutz, Mathias/GXM-7723-2022; Kurimo, Mikko/F-6647-2012; Siivola,
   Vesa/E-7065-2012
OI Creutz, Mathias Johan Philip/0000-0003-1862-4172; Virpioja,
   Sami/0000-0002-3568-150X
CR [Anonymous], SPEECH RECOGNITION H
   [Anonymous], P ACL 02 WORKSH MORP
   [Anonymous], 2002, P 7 INT C SPOK LANG
   [Anonymous], P 8 EUR C SPEECH COM
   [Anonymous], P EUROSPEECH 93
   ARGAMON S, 2004, P 20 INT C COMP LING
   Aubert XL, 2002, COMPUT SPEECH LANG, V16, P89, DOI 10.1006/csla.2001.0185
   Bilmes J. A., 2003, P C N AM CHAPT ASS C, P4, DOI DOI 10.3115/1073483.1073485
   Brent MR, 1999, MACH LEARN, V34, P71, DOI 10.1023/A:1007541817488
   Byrne W, 2000, LECT NOTES ARTIF INT, V1902, P211
   BYRNE W, 2001, P 7 EUR C SPEECH COM, P487
   Chen S. F, 1996, BUILDING PROBABILIST
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Creutz M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P280
   CREUTZ M, 2004, PUBLICATIONS COMPUTE
   Creutz M., 2005, PUBLICATIONS COMPUTE
   Deligne S, 1997, SPEECH COMMUN, V23, P223, DOI 10.1016/S0167-6393(97)00048-4
   Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034
   Geutner P, 1998, INT CONF ACOUST SPEE, P925, DOI 10.1109/ICASSP.1998.675417
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   HACIOGLU K, 2003, P EUR GEN SWITZ, P1165
   Hakulinen Lauri, 1979, SUOMEN KIELEN RAKENN
   Johnson SE, 1999, INT CONF ACOUST SPEE, P49, DOI 10.1109/ICASSP.1999.758059
   Jong F, 2003, 8 EUR C SPEECH COMM, P225
   Juang B. H., 1985, P IEEE INT C AC SPEE, P9
   Kirchhoff K, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P344
   KOSKENNIEMI K, 1983, THESIS HELSINKI
   KURIMO M, 1997, THESIS HELSINKI U TE
   Kwon OW, 2003, SPEECH COMMUN, V39, P287, DOI 10.1016/S0167-6393(02)00031-6
   MCTAIT K, 2003, P 8 EUR C SPEECH COM, P213
   MILTON JS, 1995, INTRO PROBABILITY ST, pCH10
   Pylkkönen J, 2004, HELS UNIV TECHNOL S, V46, P324
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RISSANEN J, 1989, WORLD SCI SERIES COM, V15, P79
   RUSSELL MJ, 1987, P IEEE INT C AC SPEE, V4, P2376
   SZARVAS M, 2003, P 8 EUR C SPEECH COM, P2297
   Teahan WJ, 2000, COMPUT LINGUIST, V26, P375, DOI 10.1162/089120100561746
   Venkataraman A, 2001, COMPUT LINGUIST, V27, P351, DOI 10.1162/089120101317066113
   VERGYRI D, 2004, P 8 INT C SPOK LANG, V3, P2245
   White TA, 2001, GLOBAL CHANGE BIOL, V7, P1, DOI 10.1046/j.1365-2486.2001.00381.x
   Whittaker E.W.D., 2000, P 6 INT C SPOK LANG, P170
   Willett D, 2000, INT CONF ACOUST SPEE, P1555, DOI 10.1109/ICASSP.2000.861966
NR 43
TC 66
Z9 71
U1 0
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD OCT
PY 2006
VL 20
IS 4
BP 515
EP 541
DI 10.1016/j.csl.2005.07.002
PG 27
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 087FH
UT WOS:000240727800008
DA 2023-11-10
ER

PT J
AU Fan, A
   Bhosale, S
   Schwenk, H
   Ma, ZY
   El-Kishky, A
   Goyal, S
   Baines, M
   Celebi, O
   Wenzek, G
   Chaudhary, V
   Goyal, N
   Birch, T
   Liptchinsky, V
   Edunov, S
   Grave, E
   Auli, M
   Joulin, A
AF Fan, Angela
   Bhosale, Shruti
   Schwenk, Holger
   Ma, Zhiyi
   El-Kishky, Ahmed
   Goyal, Siddharth
   Baines, Mandeep
   Celebi, Onur
   Wenzek, Guillaume
   Chaudhary, Vishrav
   Goyal, Naman
   Birch, Tom
   Liptchinsky, Vitaliy
   Edunov, Sergey
   Grave, Edouard
   Auli, Michael
   Joulin, Armand
TI Beyond English-Centric Multilingual Machine Translation
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE many-to-many; multilingual machine translation; model scaling; bitext
   mining; neural networks
ID MATRICES
AB Existing work in translation demonstrated the potential of massively multilingual machine translation by training a single model able to translate between any pair of languages. However, much of this work is English-Centric, training only on data which was translated from or to English. While this is supported by large sources of training data, it does not reflect translation needs worldwide. In this work, we create a true Many-to-Many multilingual translation model that can translate directly between any pair of 100 languages. We build and open-source a training data set that covers thousands of language directions with parallel data, created through large-scale mining. Then, we explore how to effectively increase model capacity through a combination of dense scaling and language-specific sparse parameters to create high quality models. Our focus on non-English-Centric models brings gains of more than 10 BLEU when directly translating between non-English directions while performing competitively to the best single systems from the Workshop on Machine Translation (WMT). We open-source our scripts so that others may reproduce the data, evaluation, and final M2M-100 model: https://github.com/pytorch/fairseq/tree/master/examples/m2m_100.
C1 [Fan, Angela; Bhosale, Shruti; Schwenk, Holger; Ma, Zhiyi; El-Kishky, Ahmed; Goyal, Siddharth; Baines, Mandeep; Celebi, Onur; Wenzek, Guillaume; Chaudhary, Vishrav; Goyal, Naman; Birch, Tom; Liptchinsky, Vitaliy; Edunov, Sergey; Grave, Edouard; Auli, Michael; Joulin, Armand] LORIA, Facebook AI, Paris, France.
C3 Universite de Lorraine
RP Fan, A (通讯作者)，LORIA, Facebook AI, Paris, France.
EM ANGELAFAN@FB.COM
CR Aarne Talman, 2019, P 4 C MACH TRANSL SH, V2
   Agic E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3204
   Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   Ahia Orevaoghene, 2020, ARXIV PREPRINT ARXIV
   Ahmed El-Kishky, 2020, P EMNLP
   Alla Lo, 2020, ARXIV PREPRINT ARXIV
   [Anonymous], 2020, OPENREVIEW
   [Anonymous], 2009, EACL
   [Anonymous], 2010, P C N AM CHAPTER ASS
   [Anonymous], 37 ANN M ASS COMP LI
   [Anonymous], 2016, SHARED TASK PAPERS
   Arivazhagan N., 2019, ARXIV190705019
   Arora S, 2018, PR MACH LEARN RES, V80
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Artetxe M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3197
   Ba Jimmy Lei, 2016, ARXIV160706450
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1538
   Barrault L, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P1
   Bojar, 2018, P 3 C MACH TRANSL SH, V2, P272, DOI DOI 10.18653/V1/W18-6401
   Bojar O., 2011, P 6 WORKSHOP STAT MA, P330
   Bojar rej, 2017, P 2 C MACHINE TRANSL, P169
   Bouamor H, 2018, P 11 WORKSH BUILD US, P43
   Caswell I, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P53
   Celikkanat Hande, 2020, PRAGUE B MATH LINGUI, P143, DOI DOI 10.14712/00326585.009
   Cettolo Mauro, 2017, P 14 INT C SPOKEN LA, P2
   Chaudhary V, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, DAY 2, P261
   Chen PZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1672
   Chen Tianqi, 2016, ARXIV160406174
   Chormai Pattarawat, 2016, PYTHAINLP THAI NATUR
   Christodouloupoulos C, 2015, LANG RESOUR EVAL, V49, P375, DOI 10.1007/s10579-014-9287-y
   Conneau Alexis, 2019, ARXIV191102116
   Costa-jussa Marta R, 2020, ARXIV PREPRINT ARXIV
   Dabre R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1410
   Ding CC, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3325885
   Ding Chenchen, 2016, P 3 WORKSHOP ASIAN T, P149
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489
   Emezue Chris Chinenye., 2020, P THE 4 WIDENING NAT, P83, DOI DOI 10.18653/V1/2020.WINLP-1.21
   Escolano C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P236
   Escolano Carlos, 2020, ARXIV200601594
   Escolano Carlos, ARXIV PREPRINT ARXIV, P2020
   Espl`a Miquel, 2019, P MACHINE TRANSLATIO, P118
   Etchegoyhen T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2009
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Fan A., 2019, INT C LEARN REPR
   Firat O., 2016, P 2016 C N AM CHAPT, P866
   Garmash E., 2016, COLING, P1409
   Gehring J, 2017, ARXIV170503122, V3, P2029, DOI DOI 10.18653/V1/P16-1220
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gu JT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1258
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI [10.18653/v1/n18, DOI 10.18653/V1/N18]
   Guzman F., 2019, 2 NEW EVALUATION DAT
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6098
   Ha Thanh-Le, 2016, P 13 INT WORKSH SPOK
   He K., 2016, PROC CVPR IEEE
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Huang YP, 2019, ADV NEUR IN, V32
   Jiale Chen, 2019, P 2019 C EMP METH NA, P962
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Jorg Tiedemann, 2018, CEUR WORKSHOP PROC, V2084, P188
   Kaplan Jared, 2020, ARXIV200108361
   Kasai Jungo, 2020, DEEP ENCODER SHALLOW
   Khandelwal Urvashi, 2020, ARXIV201000710
   Kim C.D., 2020, ARXIV PREPRINT ARXIV
   Kim Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P866
   Kingma D. P., 2014, C TRACK P
   Koehn P., 2005, MT SUMMIT, P79
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn P, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK PAPERS, DAY 2, P54
   Koehn Philipp, 2018, P 3 C MACH TRANSL SH, P726, DOI DOI 10.18653/V1/W18-6453
   Koehn Philipp, P 3 C MACHINE TRANSL, P726
   Koehn Philipp, EUROPARL PARALLEL CO
   Koehn Philipp, 2009, STAT MACHINE TRANSLA
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Kunchukuttan A., 2020, INDICNLP LIB
   Kvapilíková I, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, P255
   Lakew Surafel M, 2019, ARXIV PREPRINT ARXIV
   Lepikhin Dmitry, 2020, GSHARD SCALING GIANT
   Lewis Jason Edward, 2020, INDIGENOUS PROTOCOL
   Li B, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P257
   Li Xian, 2020, ADV NEURAL INFORM PR, V33
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P923
   Littell Patrick, 2017, P 2017 C EMP METH NA, P2529, DOI DOI 10.18653/V1/D17-1268
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Lu Y., 2018, P 3 C MACH TRANSL RE, P84, DOI DOI 10.18653/V1/W18-6309
   Melese Michael, 2018, P 1 WORKSH LING RES, P83
   Mousavi S., 2019, ARXIV PREPRINT ARXIV
   Nekoto Wilhelmina, 2020, FIND ASS COMP LING E, P2144, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.195
   Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P314
   Nguyen T. Q., 2019, ARXIV191005895
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pereira Guilherme C., 2017, ARXIV170106548
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46
   Pinnis Marcis, 2017, TILDES MACHINE TRANS
   Pinnis Marcis, 2019, TILDES MACHINE TRANS
   Pinnis Marcis, 2018, TILDES MACHINE TRANS
   Post Matt, 2018, P 3 C MACH TRANSL RE, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]
   Prates MOR, 2020, NEURAL COMPUT APPL, V32, P6363, DOI 10.1007/s00521-019-04144-6
   Qi Ye, 2018, ARXIV180406323, DOI 10.18653/
   Rajbhandari S., 2019, ZERO MEMORY OPTIMIZA
   Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2685
   Riza Hammam, 2016, 2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA), P1, DOI 10.1109/ICSDA.2016.7918974
   Schwenk, 2008, P INT WORKSH SPOK LA, P182
   Schwenk Holger, 2021, P 59 ANN M ASS COMPU, P6490, DOI DOI 10.18653/V1/2021.ACL-LONG.507
   Schwenk Holger, WIKIMATRIX MINING 13
   Sellam Thibault, 2020, P 58 ANN M ASS COMPU, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704]
   Sennrich R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P211
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sennrich Rico, 2016, P 1 C MACHINE TRANSL, V2, P371, DOI DOI 10.18653/V1/W16-2323
   Shazeer N, 2018, ADV NEUR IN, V31
   Shen Jiajun, 2019, P 6 WORKSHOP ASIAN T, P112
   Shoeybi M., 2019, ARXIV
   Siddhant A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2827
   Siminyu K, 2020, AI4D AFRICAN LANGUAG
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   SINKHORN R, 1967, PAC J MATH, V21, P343, DOI 10.2140/pjm.1967.21.343
   Strassel S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3273
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan Xu, ARXIV PREPRINT ARXIV
   Tang Yuqing, 2020, ARXIV200800401
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Tufis Dan, 2013, RANLP, P702
   Uchechukwu Chinedu, 2020, ARXIV PREPRINT ARXIV
   Utiyama M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P72
   Vaswani A, 2017, ADV NEUR IN, V30
   Vieira LN, 2021, INFORM COMMUN SOC, V24, P1515, DOI 10.1080/1369118X.2020.1776370
   Hoang VCD, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P18
   Wang Xinyi, 2020, P 58 ANN M ASS COMP, P8526
   Wang YN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2955
   Wenzek G., 2019, ARXIV191100359
   Williams Philip, 2017, U EDINBURGHS NEURAL
   Yonghui Wu, 2016, ARXIV PREPRINT ARXIV
   Zhang B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1628
   Ziemski M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3530
NR 135
TC 58
Z9 59
U1 2
U2 7
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2021
VL 22
AR 107
PG 48
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA SU5FA
UT WOS:000663162000001
DA 2023-11-10
ER

PT J
AU Giorgi, I
   Golosio, B
   Esposito, M
   Cangelosi, A
   Masala, GL
AF Giorgi, Ioanna
   Golosio, Bruno
   Esposito, Massimo
   Cangelosi, Angelo
   Masala, Giovanni L.
TI Modeling Multiple Language Learning in a Developmental Cognitive
   Architecture
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Computer architecture; Computational modeling; Brain modeling; Deep
   learning; Natural language processing; Task analysis; Cognitive system;
   multilingual system; natural language understanding; neural network
ID WORKING-MEMORY; INFORMATION; SELECTION; EXAMPLES
AB In this work, we model multiple natural language learning in a developmental neuroscience-inspired architecture. The artificial neural network with adaptive behavior exploited for language learning (ANNABELL) model, is a large-scale neural network, however, unlike most deep learning methods that solve natural language processing (NLP) tasks, it does not represent an empirical engineering solution for specific NLP problems; rather, its organization complies with findings from cognitive neuroscience, particularly the multicompartment working memory models. The system is appropriately trained to understand the level of cognitive development required for language acquisition and the robustness achieved in learning simultaneously four languages, using a corpus of text-based exchanges of developmental complexity. The selected languages, Greek, Italian and Albanian, besides English, differ significantly in structure and complexity. Initially, the system was validated in each language alone and was then compared with the open-ended cumulative training, in which languages are learned jointly, prior to querying with random language at random order. We aimed to assess if the model could learn the languages together to the same degree of skill as learning each apart. Moreover, we explored the generalization skill in multilingual context questions and the ability to elaborate a short text of preschool literature. We verified if the system could follow a dialogue coherently and cohesively, keeping track of its previous answers and recalling them in subsequent queries. The results show that the architecture developed broad language processing functionalities, with satisfactory performances in each language trained singularly, maintaining high accuracies when they are acquired cumulatively.
C1 [Giorgi, Ioanna; Cangelosi, Angelo] Univ Manchester, Dept Comp Sci, Manchester M13 9PL, Lancs, England.
   [Golosio, Bruno] Univ Cagliari, Dipartimento Fis, I-09042 Cagliari, Italy.
   [Golosio, Bruno] Ist Nazl Fis Nucl, Sez Cagliari, I-09042 Cagliari, Italy.
   [Esposito, Massimo] CNR, Inst High Performance Comp & Networking, I-80131 Naples, Italy.
   [Masala, Giovanni L.] Manchester Metropolitan Univ, Dept Comp & Math, Manchester M15 6BH, Lancs, England.
C3 University of Manchester; University of Cagliari; Istituto Nazionale di
   Fisica Nucleare (INFN); Consiglio Nazionale delle Ricerche (CNR);
   Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR); Manchester
   Metropolitan University
RP Giorgi, I (通讯作者)，Univ Manchester, Dept Comp Sci, Manchester M13 9PL, Lancs, England.
EM ioanna.giorgi@manchester.ac.uk; massimo.esposito@icar.cnr.it;
   angelo.cangelosi@manchester.ac.uk
RI Esposito, Massimo/AAX-3348-2020
OI Cangelosi, Angelo/0000-0002-4709-2243; Giorgi,
   Ioanna/0000-0001-9583-6959; Golosio, Bruno/0000-0001-5144-6932
CR Abutalebi Jubin., 2001, BILING-LANG COGN, V4, P179, DOI [DOI 10.1017/S136672890100027X, 10.1017/S136672890100027X]
   Amodei D, 2016, PR MACH LEARN RES, V48
   Anderson L. W., 2001, TAXONOMY LEARNING TE
   [Anonymous], 2004, STUDIES ALBANIAN OTH
   [Anonymous], 2016, IBM COGNITIVE INSIGH
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Bryck RL, 2005, MEM COGNITION, V33, P611, DOI 10.3758/BF03195328
   De Houwer A., 1999, ERIC DIG CLEARINGHOU
   Dominey PE, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00500
   Dupoux E, 2018, COGNITION, V173, P43, DOI 10.1016/j.cognition.2017.11.008
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fidelman P., 2015, P COGN SCI SOC, V7, P660
   Fu XH, 2019, KNOWL-BASED SYST, V171, P81, DOI 10.1016/j.knosys.2019.02.008
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gaspers J, 2017, IEEE T COGN DEV SYST, V9, P183, DOI 10.1109/TCDS.2016.2614958
   Gella S., 2017, EMPIRICAL METHODS NA, P2839
   Golosio B, 2015, PROCEDIA COMPUT SCI, V71, P196, DOI 10.1016/j.procs.2015.12.200
   Golosio B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140866
   Google AI Blog, 2018, TEACH GOOGL ASS BE M
   Hinaut X, 2015, P COGN COMP INT NEUR, P56
   Hinaut X, 2020, IEEE T COGN DEV SYST, V12, P179, DOI 10.1109/TCDS.2019.2957006
   Hinaut X, 2015, BRAIN LANG, V150, P54, DOI 10.1016/j.bandl.2015.08.002
   Hinaut X, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052946
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Jorgji J, 2018, FRONT ARTIF INTEL AP, V303, P992, DOI 10.3233/978-1-61499-900-3-992
   Kadar A., 2018, P 22 C COMP NAT LANG, P402, DOI DOI 10.18653/V1/K18-1039
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kelly MA, 2018, PROCEDIA COMPUT SCI, V145, P724, DOI 10.1016/j.procs.2018.11.047
   Krashen S. D., 1983, NATURAL APPROACH LAN
   Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Matusevych Y, 2017, BILING-LANG COGN, V20, P128, DOI 10.1017/S1366728915000607
   MIIKKULAINEN R, 1995, APPL INTELL, V5, P137, DOI 10.1007/BF00877229
   Miikkulainen R., 1993, SUBSYMBOLIC NATURAL
   Mitra B., 2017, P 26 INT C WORLD, P1291, DOI [DOI 10.1145/3038912.3052579, 10.1145/3038912.3052579]
   Monner D, 2012, BIOL INSPIR COGN ARC, V2, P37, DOI 10.1016/j.bica.2012.06.002
   Moulin-Frier C, 2018, IEEE T COGN DEV SYST, V10, P1005, DOI 10.1109/TCDS.2017.2754143
   Navigli R, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5697
   Note J. F, CREATING SHAREHOLDER
   Oberauer K, 2002, J EXP PSYCHOL LEARN, V28, P411, DOI 10.1037//0278-7393.28.3.411
   Peyronel S., 2005, BASIC ITALIAN GRAMMA
   Poulopoulou M, 2015, MODERN GREEK GRAMMAR
   Ramirez N. F, 2016, WHY BABY BRAIN CAN L
   Rescorla L, 2002, J SPEECH LANG HEAR R, V45, DOI 10.1044/1092-4388(2002/059)
   Rescorla L, 2001, J SPEECH LANG HEAR R, V44, P434, DOI 10.1044/1092-4388(2001/035)
   Robert R. S., 1995, KNOWLEDGE MEMORY REA, P1
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Szmrecsanyi B, 2012, LINGUAE LITT, V13, P6
   Vandierendonck A, 2012, PSYCHOL BELG, V52, P229, DOI 10.5334/pb-52-2-3-229
   Verhagen J, 2016, J EXP CHILD PSYCHOL, V141, P65, DOI 10.1016/j.jecp.2015.06.015
   Wang G, 2018, KNOWL-BASED SYST, V148, P85, DOI 10.1016/j.knosys.2018.02.024
   Watson B, 2019, MY 1 JUNGLE STORY
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu HJ, 2019, KNOWL-BASED SYST, V163, P252, DOI 10.1016/j.knosys.2018.08.032
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673
   Zhao XW, 2010, INT J BILING EDUC BI, V13, P505, DOI 10.1080/13670050.2010.488284
NR 57
TC 4
Z9 4
U1 3
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2021
VL 13
IS 4
BP 922
EP 933
DI 10.1109/TCDS.2020.3033963
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Robotics; Neurosciences & Neurology
GA XM6HH
UT WOS:000728925200020
OA Green Submitted, Green Accepted
DA 2023-11-10
ER

PT J
AU Fedus, W
   Zoph, B
   Shazeer, N
AF Fedus, William
   Zoph, Barret
   Shazeer, Noam
TI Switch Transformers: Scaling to Trillion Parameter Models with Simple
   and Efficient Sparsity
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE mixture-of-experts; natural language processing; sparsity; large-scale
   machine learning; distributed computing
ID MIXTURES
AB In deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) models defy this and instead select different parameters for each in-coming example. The result is a sparsely-activated model-with an outrageous number of parameters-but a constant computational cost. However, despite several notable suc-cesses of MoE, widespread adoption has been hindered by complexity, communication costs, and training instability. We address these with the introduction of the Switch Transformer. We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs. Our proposed training techniques mitigate the instabilities, and we show large sparse models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off T5-Base and T5-Large (Raffel et al., 2019) to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the "Colossal Clean Crawled Corpus", and achieve a 4x speedup over the T5-XXL model.1
C1 [Fedus, William; Zoph, Barret; Shazeer, Noam] Google, Mountain View, CA 94043 USA.
C3 Google Incorporated
RP Fedus, W (通讯作者)，Google, Mountain View, CA 94043 USA.
EM LIAMFEDUS@GooGLE.CoM; BARRETZoPH@GooGLE.CoM; NoAM@GooGLE.CoM
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Beltagy I., 2020, ARXIV PREPRINT ARXIV, V2004, P05150
   Berant J., 2013, P 2013 C EMPIRICAL M
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Child Rewon, 2019, ARXIV190410509, DOI 10.48550/ARXIV.1904.10509
   Cho Kyunghyun, 2014, ARXIV14067362
   Clark P., 2018, CORR
   Correia GM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2174
   Devlin J., 2018, ARXIV, V1, P4171
   Eigen David, 2013, ARXIV13124314
   Fan A, 2021, J MACH LEARN RES, V22
   Fedus W., 2018, ICLR, P1
   Gale Trevor, 2020, ARXIV200610901
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gray Scott, 2017, GPU KERNELS BLOCK SP
   Guu K, 2020, PR MACH LEARN RES, V119
   Harlap A., 2018, ARXIV180603377
   Hermann K. M., 2015, ADV NEURAL INFORM PR
   Hinton Geoffrey, 2015, ARXIV150302531
   Hooker S., 2020, ARXIV200906489, Vabs
   Huang YP, 2019, ADV NEUR IN, V32
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Kaplan Jared, 2020, ARXIV200108361
   Kitaev Nikita, 2020, ARXIV200104451
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lample Guillaume, 2019, ADV NEURAL INFORM PR, V32
   Lee K., 2021, ARXIV210706499
   Lepikhin Dmitry, 2020, GSHARD SCALING GIANT
   Micikevicius P., 2017, ARXIV171003740
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797
   Nie Yixin, 2019, ARXIV191014599
   Puigcerver Joan, 2020, ARXIV200913239
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel Colin, 2019, ARXIV191010683
   Rajbhandari S., 2019, ARXIV PREPRINT ARXIV
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Ramachandran Prajit, 2018, INT C LEARN REPR
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418
   Rosenbaum Clemens, 2017, ARXIV171101239
   Sakaguchi K, 2020, AAAI CONF ARTIF INTE, V34, P8732
   Sanh Victor, 2019, ARXIV191001108
   Shazeer Noam, 2020, GLU VARIANTS IMPROVE
   Shazeer Noam, 2017, ARXIV170106538
   Shazeer Noam, 2018, P ADV NEUR INF PROC, P10414
   Shoeybi M., 2019, ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Sukhbaatar Sainbayar, 2019, ARXIV190507799
   Sutton R., 2019, BITTER LESSON
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Taylor Wilson L, 1953, JOURNALISM QUART, V30, P415
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang A, 2019, ADV NEUR IN, V32
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang Shibo, 2019, GOOGLE CLOUD BLOG
   Xue L., 2020, ARXIV201011934
   Yang Zhilin, 2020, XLNET GEN AUTOGRESSI
   Zaheer M., 2020, ADV NEUR IN, V33
NR 61
TC 19
Z9 19
U1 1
U2 1
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2022
VL 23
PG 39
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA I5RV3
UT WOS:001003360300001
DA 2023-11-10
ER

PT J
AU Gao, C
   Ren, JT
AF Gao, Ce
   Ren, Jiangtao
TI A topic-driven language model for learning to generate diverse sentences
SO NEUROCOMPUTING
LA English
DT Article
DE Deep learning; Natural language generation; Variational autoencoder
AB Generating diverse sentences under a topic is a meaningful, yet not well-solved task in the field of natural language processing. We present a neural language model for generating diverse sentences conditioned on a given topic distribution. From the perspective of diversity, the proposed model takes the advantages of variational autoencoders with convolutional neural network and long short-term memory architecture. The proposed model is trained end-to-end to learn topic-level Gaussian distributions in the latent space. Then our model decodes the samples of topics obtained from latent space to generate each sentence. Results on Restaurant Dataset and Yahoo! Answers Dataset show that our model outperforms other methods in terms of language model perplexity. Also, our approach can generate a large set of different coherent sentences related to given topics. The diversity of our sentences provides a novel interpretation of topics. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Gao, Ce; Ren, Jiangtao] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Prov Key Lab Computat Sci, Guangzhou 510275, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Ren, JT (通讯作者)，Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Prov Key Lab Computat Sci, Guangzhou 510275, Guangdong, Peoples R China.
EM issrjt@mail.sysu.edu.cn
OI Ren, Jiangtao/0000-0003-2827-8322
FU National Natural Science Foundation of China [U1711263]
FX This research is partially supported by National Natural Science
   Foundation of China (No. U1711263).
CR Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bird Steven, 2009, NATURAL LANGUAGE PRO
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bowman Samuel R, 2015, ARXIV151106349
   Cao ZQ, 2015, AAAI CONF ARTIF INTE, P2210
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dale R, 2005, J RES PRACT INF TECH, V37, P89
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jain U, 2017, PROC CVPR IEEE, P5415, DOI 10.1109/CVPR.2017.575
   Karpathy A., 2015, ARXIV PREPRINT ARXIV
   Kim Y., 2014, P 2014 C EMPIRICAL M, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/d14-1181, 10, 10.3115/v1/D14-1181]
   King DB, 2015, ACS SYM SER, V1214, P1
   Lau JH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P355, DOI 10.18653/v1/P17-1033
   Li PJ, 2017, AAAI CONF ARTIF INTE, P3497
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pontiki M., 2014, P 8 INT WORKSHOP SEM, P27, DOI [10.3115/v1/s14-2004, DOI 10.3115/V1/S14-2004]
   Ratnaparkhi A, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA194
   Reiter E., 2000, BUILDING NATURAL LAN, P41
   Ren M., 2015, ADV NEURAL INFORM PR
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Serban IV, 2017, AAAI CONF ARTIF INTE, P3288
   Shang LF, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1577
   Vinyals O., 2015, ADV NEURAL INFORM PR, V28
   Wang Mingxuan, 2016, P 2016 C EMP METH NA, P278
   Xing C, 2017, AAAI CONF ARTIF INTE, P3351
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Zhang Xiang, 2015, NEURIPS, DOI DOI 10.5555/2969239.2969312
NR 29
TC 7
Z9 7
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAR 14
PY 2019
VL 333
BP 374
EP 380
DI 10.1016/j.neucom.2019.01.002
PG 7
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ0FT
UT WOS:000456834100034
DA 2023-11-10
ER

PT J
AU Zhang, KP
   Zhou, F
   Wu, L
   Xie, N
   He, ZB
AF Zhang, Kunpeng
   Zhou, Feng
   Wu, Lan
   Xie, Na
   He, Zhengbing
TI Semantic understanding and prompt engineering for large-scale traffic
   data imputation
SO INFORMATION FUSION
LA English
DT Article
DE Traffic data imputation; Semantic understanding; Prompt engineering;
   Large language model; Graph neural network; Transformer
ID GRAPH NEURAL-NETWORK; MISSING DATA; TIME-SERIES; FUSION; ERROR; FLOW
AB Intelligent Transportation Systems (ITS) face the formidable challenge of large-scale missing data, particularly in the imputation of traffic data. Existing studies have mainly relied on modeling network-level spatiotemporal correlations to address this issue. However, these methods often overlook the rich semantic information (e.g., road infrastructure, sensor location, etc.) inherent in road networks when capturing network-wide spatiotemporal correlations. We address this limitation by presenting the Graph Transformer-based Traffic Data Imputation (GT-TDI) model, which imputes missing values in extensive traffic data by leveraging spatiotemporal semantic understanding of road networks. The proposed model leverages semantic descriptions that capture the spatial and temporal dynamics of traffic across road networks, enhancing its capacity to infer comprehensive spatiotemporal relationships. Moreover, to augment the model's capabilities, we employ a Large Language Model (LLM) and prompt engineering to enable natural and intuitive interactions with the traffic data imputation system, allowing users to query and request in plain language, without requiring expert knowledge or complex mathematical models. The proposed model, GT-TDI, utilizes Graph Neural Networks (GNN) and Transformer architectures to perform large-scale traffic data imputation using deficient observations, sensor social connectivity, and semantic descriptions as inputs. We evaluate the GT-TDI model on the PeMS freeway dataset and benchmark it against cutting-edge models. The experimental evidence demonstrates that GT-TDI surpasses the cutting-edge approaches in scenarios with intricate patterns and varying rates of missing data.
C1 [Zhang, Kunpeng; Zhou, Feng; Wu, Lan] Henan Univ Technol, Coll Elect Engn, Zhengzhou 450001, Peoples R China.
   [Zhang, Kunpeng] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Xie, Na] Cent Univ Finance & Econ, Sch Management Sci & Engn, Beijing 100081, Peoples R China.
   [He, Zhengbing] MIT, Senseable City Lab, Cambridge, MA 02139 USA.
C3 Henan University of Technology; Tsinghua University; Central University
   of Finance & Economics; Massachusetts Institute of Technology (MIT)
RP Xie, N (通讯作者)，Cent Univ Finance & Econ, Sch Management Sci & Engn, Beijing 100081, Peoples R China.; He, ZB (通讯作者)，MIT, Senseable City Lab, Cambridge, MA 02139 USA.
EM xiena@cufe.edu.cn; he.zb@hotmail.com
FU National Natural Sci-ence Foundation of China [62002101]; Natural
   Science Project of Zhengzhou Municipal Bureau of Science and Technology,
   China [22ZZRDZX05]; Key Scientific Research of Univer-sities in Henan,
   China [20A413003]; Fundamental Research Funds for the Henan Provincial
   Colleges and Universities, China [2018RCJH16]
FX <B>Acknowledgments</B> This research has been supported by the National
   Natural Sci-ence Foundation of China (Grants No. 62002101) , the Natural
   Science Project of Zhengzhou Municipal Bureau of Science and Technology,
   China (Grants No. 22ZZRDZX05) , the Key Scientific Research of
   Univer-sities in Henan, China (Grants No. 20A413003) , and the
   Fundamental Research Funds for the Henan Provincial Colleges and
   Universities, China (Grants No. 2018RCJH16) .
CR Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4
   Chen C, 2001, TRANSPORT RES REC, P96
   Chen CY, 2012, TRANSPORT RES C-EMER, V22, P103, DOI 10.1016/j.trc.2011.12.006
   Chen XY, 2021, TRANSPORT RES C-EMER, V129, DOI 10.1016/j.trc.2021.103226
   Chen XY, 2020, TRANSPORT RES C-EMER, V117, DOI 10.1016/j.trc.2020.102673
   Chen XY, 2019, TRANSPORT RES C-EMER, V98, P73, DOI 10.1016/j.trc.2018.11.003
   Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334
   Cui ZY, 2020, IEEE T INTELL TRANSP, V21, P4883, DOI 10.1109/TITS.2019.2950416
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Duan YJ, 2016, TRANSPORT RES C-EMER, V72, P168, DOI 10.1016/j.trc.2016.09.015
   Grigsby J, 2022, Arxiv, DOI arXiv:2109.12218
   Huang FH, 2022, INFORM SCIENCES, V594, P286, DOI 10.1016/j.ins.2022.02.031
   Huang W, 2021, INFORM FUSION, V75, P28, DOI 10.1016/j.inffus.2021.03.010
   Jia XY, 2021, KNOWL-BASED SYST, V225, DOI 10.1016/j.knosys.2021.107114
   Jin K, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115738
   Kaur M, 2022, INFORM SCIENCES, V586, P344, DOI 10.1016/j.ins.2021.11.049
   Kim S, 2016, INT J FORECASTING, V32, P669, DOI 10.1016/j.ijforecast.2015.12.003
   Kong XJ, 2023, KNOWL-BASED SYST, V261, DOI 10.1016/j.knosys.2022.110188
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li HP, 2020, TRANSPORT RES C-EMER, V119, DOI 10.1016/j.trc.2020.102730
   Li J, 2023, INFORM FUSION, V93, P243, DOI 10.1016/j.inffus.2023.01.002
   Li L, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2457240
   Li L, 2013, TRANSPORT RES C-EMER, V34, P108, DOI 10.1016/j.trc.2013.05.008
   Li SY, 2019, ADV NEUR IN, V32
   Li YY, 2014, INFORM FUSION, V15, P64, DOI 10.1016/j.inffus.2012.08.007
   Li YB, 2014, IET INTELL TRANSP SY, V8, P51, DOI 10.1049/iet-its.2013.0052
   Liang YB, 2022, TRANSPORT RES C-EMER, V143, DOI 10.1016/j.trc.2022.103826
   Lim B, 2021, INT J FORECASTING, V37, P1748, DOI 10.1016/j.ijforecast.2021.03.012
   Liu LS, 2019, IEEE ACCESS, V7, P3383, DOI 10.1109/ACCESS.2018.2889814
   Liu QC, 2021, PHYSICA A, V573, DOI 10.1016/j.physa.2021.125940
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61
   Mao JY, 2023, Arxiv, DOI arXiv:2305.14493
   Ounoughi C, 2023, INFORM FUSION, V89, P267, DOI 10.1016/j.inffus.2022.08.016
   Peng BL, 2023, Arxiv, DOI arXiv:2302.12813
   Qu L, 2009, IEEE T INTELL TRANSP, V10, P512, DOI 10.1109/TITS.2009.2026312
   Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, DOI 10.48550/ARXIV.1908.10084]
   Reza S, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117275
   Salakhutdinov R., 2008, P INT C MACH LEARN, P880, DOI DOI 10.1145/1390156.1390267
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sharma S, 2018, Arxiv, DOI arXiv:1802.08216
   Shi YS, 2021, Arxiv, DOI [arXiv:2009.03509, DOI 10.48550/ARXIV.2009.03509]
   Shin T, 2020, Arxiv, DOI arXiv:2010.15980
   Smith BL, 2003, TRANSPORT RES REC, P132, DOI 10.3141/1836-17
   Steimetz SSC, 2005, TRANSPORT RES B-METH, V39, P865, DOI 10.1016/j.trb.2004.11.001
   Stellwagen E., 2013, FORESIGHT INT J APPL, P28
   Su J, 2022, PATTERN RECOGN LETT, V156, P126, DOI 10.1016/j.patrec.2022.03.005
   Tak S, 2016, IEEE T INTELL TRANSP, V17, P1762, DOI 10.1109/TITS.2016.2530312
   Vaswani A, 2017, ADV NEUR IN, V30
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Villarreal M, 2023, Arxiv, DOI arXiv:2306.08094
   Wang J., 2023, ARXIV
   Yang B, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2020.106705
   Yang JM, 2021, TRANSPORT RES C-EMER, V129, DOI 10.1016/j.trc.2021.103228
   Ye YC, 2021, LECT NOTES COMPUT SC, V12891, P241, DOI 10.1007/978-3-030-86362-3_20
   Yong G, 2023, COMPUT-AIDED CIV INF, V38, P1536, DOI 10.1111/mice.12954
   Yule GU, 1926, J R STAT SOC, V89, P1, DOI 10.2307/2341482
   Zhang KP, 2022, PHYSICA A, V591, DOI 10.1016/j.physa.2021.126788
   Zhang KP, 2022, IEEE T INTELL TRANSP, V23, P22343, DOI 10.1109/TITS.2022.3164450
   Zhang KP, 2021, COMPUT-AIDED CIV INF, V36, P197, DOI 10.1111/mice.12595
   Zhang KP, 2020, IEEE T INTELL TRANSP, V21, P1480, DOI 10.1109/TITS.2019.2909571
   Zhang KP, 2020, NEUROCOMPUTING, V396, P438, DOI 10.1016/j.neucom.2018.10.097
   Zhang WB, 2022, IEEE T INTELL TRANSP, V23, P7919, DOI 10.1109/TITS.2021.3074564
   Zhang ZC, 2021, TRANSPORT RES C-EMER, V132, DOI 10.1016/j.trc.2021.103372
   Zhong M, 2004, TRANSPORT RES REC, P71, DOI 10.3141/1879-09
   Zhu YM, 2013, IEEE T MOBILE COMPUT, V12, P2289, DOI 10.1109/TMC.2012.205
NR 65
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD FEB
PY 2024
VL 102
AR 102038
DI 10.1016/j.inffus.2023.102038
EA SEP 2023
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA W0JU0
UT WOS:001088586000001
DA 2023-11-10
ER

PT J
AU Bilgin, EF
   Yanikoglu Yesilyurt, AB
AF Bilgin, Esma Fatima
   Yanikoglu Yesilyurt, Ayse Berrin
TI Large vocabulary recognition for online Turkish handwriting with
   sublexical units
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
LA English
DT Article
DE Online handwriting recognition; Turkish handwriting recognition; hidden
   Markov models; statistical language modeling; UNIPEN; grammatical
   sublexical units; delayed strokes
ID MARKOV-MODELS
AB We present a system for large vocabulary recognition of online Turkish handwriting, using hidden Markov models. While using a traditional approach for the recognizer, we have identified and developed solutions for the main problems specific to Turkish handwriting recognition. First, since large amounts of Turkish handwriting samples are not available, the system is trained and optimized using the large UNIPEN dataset of English handwriting, before extending it to Turkish using a small Turkish dataset. The delayed strokes, which pose a significant source of variation in writing order due to the large number of diacritical marks in Turkish, are removed during preprocessing. Finally, as a solution to the high out-of-vocabulary rates encountered when using a fixed size lexicon in general purpose recognition, a lexicon is constructed from sublexical units (stems and endings) learned from a large Turkish corpus. A statistical bigram language model learned from the same corpus is also applied during the decoding process.
   The system obtains a 91.7% word recognition rate when tested on a small Turkish handwritten word dataset using a medium sized (1950 words) lexicon corresponding to the vocabulary of the test set and 63.8% using a large, general purpose lexicon (130,000 words). However, with the proposed stem+ending lexicon (12,500 words) and bigram language model with lattice expansion, a 67.9% word recognition accuracy is obtained, surpassing the results obtained with the general purpose lexicon while using a much smaller one.
C1 [Bilgin, Esma Fatima; Yanikoglu Yesilyurt, Ayse Berrin] Sabanci Univ, Fac Engn & Nat Sci, Comp Sci & Engn Program, Istanbul, Turkey.
C3 Sabanci University
RP Yanikoglu Yesilyurt, AB (通讯作者)，Sabanci Univ, Fac Engn & Nat Sci, Comp Sci & Engn Program, Istanbul, Turkey.
EM berrin@sabanciuniv.edu
RI Yanikoglu, Berrin/AAE-4843-2022
OI Yanikoglu, Berrin/0000-0001-7403-7592; Bilgin Tasdemir, Esma
   Fatima/0000-0002-2465-4186
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [113E062]; TUBITAK-BIDEB scholarship
FX We gratefully acknowledge the support from the Scientific and
   Technological Research Council of Turkey (TUBITAK), under project number
   113E062. The first author was also supported by a TUBITAK-BIDEB
   scholarship during her PhD studies.
CR Abdelazeem S, 2011, PROC INT CONF DOC, P1304, DOI 10.1109/ICDAR.2011.262
   Abdelaziz I, 2016, PATTERN ANAL APPL, V19, P1129, DOI 10.1007/s10044-015-0526-7
   Al-Helali BM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3060620
   Alimi AM, 1997, PROC INT CONF DOC, P382, DOI 10.1109/ICDAR.1997.619875
   [Anonymous], 2006, IWFHR 06
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2006, P 10 INT WORKSH FRON
   [Anonymous], SACH 2006
   [Anonymous], 18 INT S COMP INF SC
   [Anonymous], THESIS TRAKYA U EDIR
   [Anonymous], FIRAT U TURKISH J SC
   [Anonymous], 2005, 12 C INT GRAPHONOMIC
   [Anonymous], P 6 INT C NEUR INF P
   [Anonymous], 2009, HTK BOOK HTK VERSION
   [Anonymous], 2007, PROC 20 NIPS
   [Anonymous], 10 INT WORKSH FRONT
   [Anonymous], P ICSLP
   Arica N, 2002, IEEE T PATTERN ANAL, V24, P801, DOI 10.1109/TPAMI.2002.1008386
   Arisoy E, 2006, SIGNAL PROCESS, V86, P2844, DOI 10.1016/j.sigpro.2005.12.002
   Arisoy E, 2009, IEEE T AUDIO SPEECH, V17, P874, DOI 10.1109/TASL.2008.2012313
   Biem A, 2006, IEEE T PATTERN ANAL, V28, P1041, DOI 10.1109/TPAMI.2006.146
   Caillault E, 2007, INT J PATTERN RECOGN, V21, P117, DOI 10.1142/S0218001407005338
   Çöltekin Ç, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1079
   Doetsch P, 2012, INT CONF FRONT HAND, P3, DOI 10.1109/ICFHR.2012.194
   Erdogan H, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P98, DOI 10.1109/ASRU.2005.1566516
   Garcia-Salicetti S., 2001, International Journal on Document Analysis and Recognition, V4, P56, DOI 10.1007/PL00013574
   Gauthier N, 2001, PROC INT CONF DOC, P412, DOI 10.1109/ICDAR.2001.953823
   Ghods V, 2013, PATTERN RECOGN LETT, V34, P486, DOI 10.1016/j.patrec.2012.12.005
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Günter S, 2003, PROC INT CONF DOC, P472
   Hu JY, 2000, PATTERN RECOGN, V33, P133, DOI 10.1016/S0031-3203(99)00043-6
   Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559
   Korkmaz SU, 2003, PROC INT CONF DOC, P1238
   Kozielski M, 2013, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2013.190
   Liwicki M, 2007, PROC INT CONF DOC, P367
   Liwicki M, 2007, INT J PATTERN RECOGN, V21, P83, DOI 10.1142/S0218001407005314
   Martin J. H., 2009, SPEECH LANGUAGE PROC
   Marukatat S, 2001, PROC INT CONF DOC, P731, DOI 10.1109/ICDAR.2001.953886
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Plötz T, 2009, INT J DOC ANAL RECOG, V12, P269, DOI 10.1007/s10032-009-0098-4
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sak H, 2012, IEEE T AUDIO SPEECH, V20, P2341, DOI 10.1109/TASL.2012.2201477
   Sak H, 2011, LANG RESOUR EVAL, V45, P249, DOI 10.1007/s10579-010-9128-6
   Sak H, 2010, INT CONF ACOUST SPEE, P5402, DOI 10.1109/ICASSP.2010.5494927
   SCHENKEL M, 1995, MACH VISION APPL, V8, P215, DOI 10.1007/BF01219589
   Tagougui N, 2013, INT J DOC ANAL RECOG, V16, P209, DOI 10.1007/s10032-012-0186-8
   Vural E, 2005, P SOC PHOTO-OPT INS, V5676, P56, DOI 10.1117/12.588556
   Yanikoglu B, 2003, PROC SPIE, V5010, P227, DOI 10.1117/12.476045
NR 48
TC 0
Z9 0
U1 0
U2 1
PU Tubitak Scientific & Technological Research Council Turkey
PI ANKARA
PA ATATURK BULVARI NO 221, KAVAKLIDERE, TR-06100 ANKARA, TURKIYE
SN 1300-0632
EI 1303-6203
J9 TURK J ELECTR ENG CO
JI Turk. J. Electr. Eng. Comput. Sci.
PY 2018
VL 26
IS 5
BP 2218
EP 2233
DI 10.3906/elk-1801-234
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GX9GS
UT WOS:000448109200005
OA Green Accepted, Bronze
DA 2023-11-10
ER

PT J
AU Sobieszek, A
   Price, T
AF Sobieszek, Adam
   Price, Tadeusz
TI Playing Games with Ais: The Limits of GPT-3 and Similar Large Language
   Models
SO MINDS AND MACHINES
LA English
DT Article
DE GPT-3; Artificial Intelligence; Psychometrics; Language Games; Turing
   test
AB This article contributes to the debate around the abilities of large language models such as GPT-3, dealing with: firstly, evaluating how well GPT does in the Turing Test, secondly the limits of such models, especially their tendency to generate falsehoods, and thirdly the social consequences of the problems these models have with truth-telling. We start by formalising the recently proposed notion of reversible questions, which Floridi & Chiriatti (2020) propose allow one to 'identify the nature of the source of their answers', as a probabilistic measure based on Item Response Theory from psychometrics. Following a critical assessment of the methodology which led previous scholars to dismiss GPT's abilities, we argue against claims that GPT-3 completely lacks semantic ability. Using ideas of compression, priming, distributional semantics and semantic webs we offer our own theory of the limits of large language models like GPT-3, and argue that GPT can competently engage in various semantic tasks. The real reason GPT's answers seem senseless being that truth-telling is not amongst them. We claim that these kinds of models cannot be forced into producing only true continuation, but rather to maximise their objective function they strategize to be plausible instead of truthful. This, we moreover claim, can hijack our intuitive capacity to evaluate the accuracy of its outputs. Finally, we show how this analysis predicts that a widespread adoption of language generators as tools for writing could result in permanent pollution of our informational ecosystem with massive amounts of very plausible but often untrue texts.
C1 [Sobieszek, Adam] Univ Warsaw, Dept Psychol, Warsaw, Poland.
   [Price, Tadeusz] Univ Nottingham, Dept Philosophy, Nottingham, England.
C3 University of Warsaw; University of Nottingham
RP Price, T (通讯作者)，Univ Nottingham, Dept Philosophy, Nottingham, England.
EM apytp2@nottingham.ac.uk
OI Price, Tadeusz/0000-0003-1264-7103
CR Almeida F, 2019, WORD EMBEDDINGS SURV, DOI [10.48550/ARXIV.1901.09069, DOI 10.48550/ARXIV.1901.09069]
   [Anonymous], 1994, POSSIBLE WORLDS LIT
   [Anonymous], 1666, DISSERTATIO ARTE COM
   Bartolucci F, 2007, PSYCHOMETRIKA, V72, P141, DOI 10.1007/s11336-005-1376-9
   Bernstein J., 2021, ARXIV PREPRINT ARXIV
   Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chen Mark, 2021, EVALUATING LARGE LAN
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407
   COLLINS AM, 1969, J VERB LEARN VERB BE, V8, P240, DOI 10.1016/S0022-5371(69)80069-1
   CONNEAU A, 2018, ACL, P2126
   DAMASSINO N, 2020, MIND MACH, V30
   Embretson S. E., 2000, ITEM RESPONSE THEORY
   ERICKSON TD, 1981, J VERB LEARN VERB BE, V20, P540, DOI 10.1016/S0022-5371(81)90165-1
   Finnie-Ansley J., 2022, AUSTR COMP ED C, P1019
   Firth J. R., 1957, SYNOPSIS LINGUISTIC
   Floridi L., 2017, PHILOS TECHNOLOGY, V30, P123, DOI [10.1007/s13347-017-0259-1, DOI 10.1007/S13347-017-0259-1]
   Floridi L., 2019, PHILOS TECHNOLOGY, DOI [10.1007/s13347-019-00345-y, DOI 10.1007/S13347-019-00345-Y]
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Floridi L, 2011, METAPHILOSOPHY, V42, P282, DOI 10.1111/j.1467-9973.2011.01693.x
   Floridi L, 2011, ERKENNTNIS, V74, P147, DOI 10.1007/s10670-010-9249-8
   GILBERT DT, 1991, AM PSYCHOL, V46, P107, DOI 10.1037/0003-066X.46.2.107
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gwern Branwen, 2020, GPT 3 CREATIVE FICTI
   Heller F., 1957, WHATS MY LINE
   Hendrycks D., 2021, ARXIV
   Hutson M., 2021, ROBO WRITERS RISE RI
   Justyna B., 2016, FOLIA OECONOMICA STE, V16, P163, DOI DOI 10.1515/FOLI-2016-0032
   Kaminska, 2020, GPT 3 LANGUAGE TOOL
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Lample G., 2018, ARXIV PREPRINT ARXIV
   Lewis DK., 1986, PLURALITY WORLDS
   Mahoney, 2006, RATIONALE LARGE TEXT
   Marcus G., 2020, TECHNOL REV
   Mercier H., 2021, ROYAL I PHILOS S, V89, P257, DOI 10.1017/S1358246121000096
   Mercier H., 2020, NOT BORN YESTERDAY
   Mercier H., 2017, THE ENIGMA OF REASON
   Montemayor C, 2021, MIND MACH, V31, P471, DOI 10.1007/s11023-021-09568-5
   Mulder J, 2009, PSYCHOMETRIKA, V74, P273, DOI 10.1007/s11336-008-9097-5
   Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592
   OpenAI, 2021, EXAMPLES
   Pal D., 2021, GENERATES CODE USING
   Pearl J, 2002, AI MAG, V23, P95
   Pearl J, 2019, THE BOOK OF WHY
   Pennycook G, 2021, NATURE, V592, P590, DOI 10.1038/s41586-021-03344-2
   Peregrin J, 2021, MIND MACH, V31, P305, DOI 10.1007/s11023-021-09564-9
   Prenner, 2021, ARXIV PREPRINT ARXIV
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Reynolds L., 2021, 2021 CHI C HUM FACT
   Russell S, 2019, HUMAN COMPATIBLE ART
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038
   Shannon CE., 1948, BELL SYST TECH J, V27, P379, DOI [DOI 10.1002/J.1538-7305.1948.TB01338.X, DOI 10.1002/J.1538-7305.1948.TB00917.X]
   Shin Taylor, 2020, P EMNLP 2020
   Shmilovici A, 2009, COMPUT ECON, V33, P131, DOI 10.1007/s10614-008-9153-3
   Sperber D, 2010, MIND LANG, V25, P359, DOI 10.1111/j.1468-0017.2010.01394.x
   Umanath S, 2014, PERSPECT PSYCHOL SCI, V9, P408, DOI 10.1177/1745691614535933
   Wang Chaoqi, 2020, INT C LEARNING REPRE
   Zhao TZ, 2021, PR MACH LEARN RES, V139
   Zimmerman A., 2020, DAILY NOUS      0730
NR 59
TC 12
Z9 12
U1 9
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-6495
EI 1572-8641
J9 MIND MACH
JI Minds Mach.
PD JUN
PY 2022
VL 32
IS 2
BP 341
EP 364
DI 10.1007/s11023-022-09602-0
EA MAY 2022
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1U7HG
UT WOS:000790126500001
OA hybrid
DA 2023-11-10
ER

PT J
AU Emami, A
   Jelinek, F
AF Emami, A
   Jelinek, F
TI A neural syntactic language model
SO MACHINE LEARNING
LA English
DT Article
DE statistical language models; neural networks; speech recognition;
   parsing
ID NETWORKS
AB This paper presents a study of using neural probabilistic models in a syntactic based language model. The neural probabilistic model makes use of a distributed representation of the items in the conditioning history, and is powerful in capturing long dependencies. Employing neural network based models in the syntactic based language model enables it to use efficiently the large amount of information available in a syntactic parse in estimating the next word in a string. Several scenarios of integrating neural networks in the syntactic based language model are presented, accompanied by the derivation of the training procedures involved. Experiments on the UPenn Treebank and the Wall Street Journal corpus show significant improvements in perplexity and word error rate over the baseline SLM. Furthermore, comparisons with the standard and neural net based N-gram models with arbitrarily long contexts show that the syntactic information is in fact very helpful in estimating the word string probability. Overall, our neural syntactic based model achieves the best published results in perplexity and WER for the given data sets.
C1 Johns Hopkins Univ, Ctr Language & Speech Proc, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Emami, A (通讯作者)，Johns Hopkins Univ, Ctr Language & Speech Proc, Baltimore, MD 21218 USA.
EM emami@jhu.edu; jelinek@jhu.edu
CR [Anonymous], P 6 INT C SPOK LANG
   [Anonymous], P 6 INT WORKSH PARS
   BELLEGARDA JR, 1997, P 5 EUR C SPEECH COM, V3, P1451
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4
   Bridle J.S., 1989, NEUROCOMPUTING, P227, DOI [10.1007/978-3-642-76153-9, DOI 10.1007/978-3-642-76153-9_28]
   BRYNE W, 1998, 17 CLSP J HOPK U DEP
   Charniak E, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P116
   Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147
   Chelba C, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P498
   CHELBA C, 2001, P AUT SPEECH REC UND
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Collier AK, 1996, MAGN RESON CHEM, V34, P191
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844
   EMAMI A, 2004, P IEEE INT C AC SPEE
   EMAMI A, 2003, P 8 EUR C SPEECH COM, V1, P413
   Emami A., 2003, P IEEE INT C AC SPEE, V1, P372
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5
   Goodman J. T., 2001, MSRTR200172
   Gropp W., 1999, USING MPI PORTABLE P
   Henderson James, 2003, P N AM CHAPT ASS COM
   Hinton G.E., 1986, P 8 ANN C COGN SCI S, P46
   Ho EKS, 1999, NEURAL COMPUT, V11, P1995, DOI 10.1162/089976699300016061
   Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P381
   JELINEK F, 1908, STAT METHODS SPEECH
   KIM W, 2001, P 7 EUR C SPEECH COM, P717
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Lawrence S, 1996, IEEE IJCNN, P1853, DOI 10.1109/ICNN.1996.549183
   Lawson C. L., 1979, ACM Transactions on Mathematical Software, V5, P308, DOI 10.1145/355841.355848
   LECUN Y., 1985, P COGNITIVA, V85, P599
   MIIKKULAINEN R, 1991, COGNITIVE SCI, V15, P343, DOI 10.1207/s15516709cog1503_2
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   PAUL DB, 1992, P DARPA SLS WORKSH
   RATNAPARKHI A, 1997, 2 C EMP METH NAT LAN, P1
   ROARK B, 2001, THESIS BROWN U PROVI
   RUMELHART DE, 1986, PARALLELDISTRIBUTED, V1
   Schwenk H, 2002, INT CONF ACOUST SPEE, P765
   VANUYSTEL DH, 2001, P AUT SPEECH REC UND
   Werbos P., 1974, REGRESSION NEW TOOLS
   Xu P, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P160
   XU P, 2002, P 40 ANN M ASS COMP
NR 44
TC 29
Z9 35
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD SEP
PY 2005
VL 60
IS 1-3
BP 195
EP 227
DI 10.1007/s10994-005-0916-y
PG 33
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 958BW
UT WOS:000231420700009
OA Bronze
DA 2023-11-10
ER

PT J
AU Wang, XZ
   Gao, TY
   Zhu, ZC
   Zhang, ZY
   Liu, ZY
   Li, JZ
   Tang, J
AF Wang, Xiaozhi
   Gao, Tianyu
   Zhu, Zhaocheng
   Zhang, Zhengyan
   Liu, Zhiyuan
   Li, Juanzi
   Tang, Jian
TI KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language
   Representation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagE Representation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M(1), a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.
C1 [Wang, Xiaozhi; Zhang, Zhengyan; Liu, Zhiyuan; Li, Juanzi] Tsinghua Univ, Dept CST, BNRist, Beijing, Peoples R China.
   [Liu, Zhiyuan; Li, Juanzi] Tsinghua Univ, Inst AI, KIRC, Beijing, Peoples R China.
   [Gao, Tianyu] Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA.
   [Zhu, Zhaocheng; Tang, Jian] Mila Quebec AI Inst, Quebec City, PQ, Canada.
   [Zhu, Zhaocheng] Univ Montreal, Montreal, PQ, Canada.
   [Tang, Jian] HEC, Montreal, PQ, Canada.
   [Tang, Jian] CIFAR AI Res Chair, Montreal, PQ, Canada.
C3 Tsinghua University; Tsinghua University; Princeton University;
   Universite de Montreal; Universite de Montreal; HEC Montreal
RP Liu, ZY (通讯作者)，Tsinghua Univ, Dept CST, BNRist, Beijing, Peoples R China.; Liu, ZY (通讯作者)，Tsinghua Univ, Inst AI, KIRC, Beijing, Peoples R China.; Tang, J (通讯作者)，Mila Quebec AI Inst, Quebec City, PQ, Canada.; Tang, J (通讯作者)，HEC, Montreal, PQ, Canada.; Tang, J (通讯作者)，CIFAR AI Res Chair, Montreal, PQ, Canada.
EM wangxz20@mails.tsinghua.edu.cn; tianyug@princeton.edu;
   zy-z19@mails.tsinghua.edu.cn; zhaocheng.zhu@umontreal.ca;
   liuzy@tsinghua.edu.cn; lijuanzi@tsinghua.edu.cn; jian.tang@hec.ca
RI Liu, Zhiyuan/I-2233-2014; cheng, shu/IZE-4788-2023; Wang,
   Xiaozhi/IQT-4844-2023
OI Liu, Zhiyuan/0000-0002-7709-2543
FU National Key Research and Development Program of China [2018YFB1004503];
   National Natural Science Foundation of China (NSFC) [U1736204, 61533018,
   61772302, 61732008]; Institute for Guo Qiang, Tsinghua University
   [2019GQB0003]; Beijing Academy of Artificial Intelligence
   [BAAI2019ZD0502]; Natural Sciences and Engineering Research Council
   (NSERC); CanadaCIFAR AI Chair Program; Tsinghua University Initiative
   Scientific Research Program
FX This work is supported by the National Key Research and Development
   Program of China (No. 2018YFB1004503), the National Natural Science
   Foundation of China (NSFC No. U1736204, 61533018, 61772302, 61732008),
   grants from Institute for Guo Qiang, Tsinghua University (2019GQB0003),
   and Beijing Academy of Artificial Intelligence (BAAI2019ZD0502). Prof.
   Jian Tang is supported by the Natural Sciences and Engineering Research
   Council (NSERC) Discovery Grant and theCanadaCIFAR AI Chair Program.
   Xiaozhi Wang and Tianyu Gao are supported by Tsinghua University
   Initiative Scientific Research Program. We also thank our action editor,
   Prof. Doug Downey, and the anonymous reviewers for their consistent help
   and insightful suggestions.
CR Balazevic I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5185
   Bojchevski Aleksandar, 2018, P ICLR
   Bordes A., 2013, P ADV NEUR INF PROC, P2787
   Cao YX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P227
   Cao YX, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1623, DOI 10.18653/v1/P17-1149
   Choi E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P87
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Dai Andrew M., 2015, NIPS
   Devlin J., 2018, ARXIV, V1, P4171
   Gao TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6250
   Hamaguchi T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1802
   Hamilton WL, 2017, ADV NEUR IN, V30
   Han X, 2018, ARXIV PREPRINT ARXIV
   Han X, 2018, AAAI CONF ARTIF INTE, P4832
   Hayashi H, 2020, AAAI CONF ARTIF INTE, V34, P7911
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Kassner N., 2020, PROC 58 ANN M ASS CO, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]
   Kazemi SM, 2018, ADV NEUR IN, V31
   Lan Zhenzhong, 2019, ARXIV190911942
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Liu Yinhan., 2019, CSCL190711692V1 CORR
   Logan RL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5962
   Logeswaran L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3449
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI DOI 10.1016/S0079-7421(08)60536-8
   Mikolov Tomas, 2013, INT C LEARN REPR
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P43
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Poerner Nina, 2020, FINDINGS ASS COMPUTA, P803, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.71
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Ruize Wang, 2020, FINDINGS ASS COMPUTA
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi BX, 2018, AAAI CONF ARTIF INTE, P1957
   Snell Jake, 2017, NEURIPS
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2895
   Sun Z., 2019, P ICLR
   Trouillon T, 2016, PR MACH LEARN RES, V48
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4465
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang PF, 2019, AAAI CONF ARTIF INTE, P7152
   Wang Z., 2014, P 2014 C EMP METH NA, P1591, DOI DOI 10.3115/V1/D14-1167
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Wu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6397
   Xie RB, 2016, AAAI CONF ARTIF INTE, P2659
   Xiong Wenhan, 2019, P ICLR
   Yamada I., 2016, P 20 SIGNLL C COMP N, P250, DOI DOI 10.18653/V1/K16-1025
   Yang BS, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1436, DOI 10.18653/v1/P17-1132
   Yang Bishan, 2015, P INT C LEARN REPR
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zaremoodi P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P656
   Zhang Y., 2017, P 2017 C EMPIRICAL M, P35
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
   Zhu ZC, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2494, DOI 10.1145/3308558.3313508
NR 61
TC 103
Z9 107
U1 10
U2 35
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 176
EP 194
DI 10.1162/tacl_a_00360
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200011
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Mitchell, DG
   Ternovska, E
AF Mitchell, David G.
   Ternovska, Eugenia
TI Expressive power and abstraction in ESSENCE
SO CONSTRAINTS
LA English
DT Article
DE expressive power; abstraction; ESSENCE; constraint modelling languages;
   descriptive complexity; model expansion
AB Development of languages for specifying or modelling problems is an important direction in constraint modelling. To provide greater abstraction and modelling convenience, these languages are becoming more syntactically rich, leading to a variety of questions about their expressive power. In this paper, we consider the expressiveness of Essence, a specification language with a rich variety of syntactic features. We identify natural fragments of Essence that capture the complexity classes P, NP, all levels Sigma(p)(i) of the polynomial-time hierarchy, and all levels k-NEXP of the nondeterministic exponential-time hierarchy. The union of these classes is the very large complexity class ELEMENTARY. One goal is to begin to understand which features play a role in the high expressive power of the language and which are purely features of convenience. We also discuss the formalization of arithmetic in Essence and related languages, a notion of capturing NP-search which is slightly different than that of capturing NP, and a conjectured limit to the expressive power of Essence. Our study is an application of descriptive complexity theory, and illustrates the value of taking a logic-based view of modelling and specification languages.
C1 [Mitchell, David G.; Ternovska, Eugenia] Simon Fraser Univ, Computat Logic Lab, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Mitchell, DG (通讯作者)，Simon Fraser Univ, Computat Logic Lab, Burnaby, BC V5A 1S6, Canada.
EM mitchell@cs.sfu.ca; ter@cs.sfu.ca
CR [Anonymous], 1979, COMPUTERS INTRACTABI
   [Anonymous], 1999, OPL OPTIMIZATION PRO
   Cadoli M, 2000, COMPUT LANG, V26, P165, DOI 10.1016/S0096-0551(01)00010-8
   Cadoli M, 2006, ARTIF INTELL, V170, P779, DOI 10.1016/j.artint.2006.01.008
   Denecker M, 2008, ACM T COMPUT LOG, V9, DOI 10.1145/1342991.1342998
   East D, 2006, ACM T COMPUT LOG, V7, P38, DOI 10.1145/1119439.1119441
   EBBINGHAUS HD, 1995, FINITE MODEL THEORY
   Enderton H. B., 2001, MATH INTRO LOGIC, V2nd
   Fagin R., 1974, SIAM AMS P, P43
   Flener P, 2003, LECT NOTES COMPUT SC, V3018, P214
   Friedman H. M., 1999, Proceedings. 14th Symposium on Logic in Computer Science (Cat. No. PR00158), P2, DOI 10.1109/LICS.1999.782577
   Frisch A.M., 2007, P INT SYMM C
   Frisch AM, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P109
   Frisch AM, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P80
   FRISCH AM, 2008, CONSTRAINTS, V13
   FRISCH AM, 2005, P 4 INT WORKSH MOD R, P73
   Gebser M, 2007, LECT NOTES COMPUT SC, V4483, P266, DOI 10.1007/978-3-540-72200-7_24
   GRADEL E, 1992, THEOR COMPUT SCI, V101, P35, DOI 10.1016/0304-3975(92)90149-A
   Gradel E, 1998, INFORM COMPUT, V140, P26, DOI 10.1006/inco.1997.2675
   Gradel Erich, 2007, FINITE MODEL THEORY, P125, DOI [DOI 10.1007/3-540-68804-8_3, 10.1007/3-540-68804-83, DOI 10.1007/3-540-68804-83]
   IMMERMAN N, 1986, INFORM CONTROL, V68, P86, DOI 10.1016/S0019-9958(86)80029-8
   Immerman N., 1999, DESCRIPTIVE COMPLEXI
   Leone N., 2006, ACM T COMPUTATIONAL, V7
   Libkin L., 2004, TEXT THEORET COMP S
   Mancini T, 2005, LECT NOTES ARTIF INT, V3607, P165
   MARIN M, 2006, P SEARCH LOG ANSW PR, P19
   Marriott K, 2008, CONSTRAINTS, V13, P229, DOI 10.1007/s10601-008-9041-4
   MILLS P, 1998, CSM321 U ESS
   MITCHELL D, 2006, 200624 TR S FRAS U S
   Mitchell D.G., 2005, P AAAI, P430
   Papadimitriou C., 1994, COMPUT COMPLEX
   Syrjanen T., 2000, LPARSE 1 0 USERS MAN
   VARDI MY, 1982, 14 ACM S THEOR COMP
NR 33
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1383-7133
EI 1572-9354
J9 CONSTRAINTS
JI Constraints
PD SEP
PY 2008
VL 13
IS 3
BP 343
EP 384
DI 10.1007/s10601-008-9050-3
PG 42
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 325LA
UT WOS:000257589200005
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Zhang, SK
   Jiang, L
   Tan, JL
AF Zhang, Shaokang
   Jiang, Lei
   Tan, Jianlong
TI Cross-domain knowledge distillation for text classification
SO NEUROCOMPUTING
LA English
DT Article
DE Knowledge distillation; Domain adaptation; Multi -teacher knowledge
   vote; Text classification
AB Most text classification methods achieve great success based on the large-scale annotated data and the pre-trained language models. However, the labeled data is insufficient in practice, and the pre-trained language models are difficult to deploy due to their high computing resources and slow inference speed. In this paper, we propose cross-domain knowledge distillation, where the teacher and student tasks belong to different domains. It not only acquires knowledge from multiple teachers but also accelerates inference and reduces model size. Specifically, we train the pre-trained language models on factual knowledge obtained by aligned Wikipedia text to Wikidata triplets and fine-tune it as the teacher model. Then we use the heterogeneous multi-teacher knowledge distillation to transfer knowledge from the multiple teacher models to the student model. Multi-teacher knowledge vote can distill knowledge related to the target domain. Moreover, we also introduce the teacher assistant to help distill large pre-trained language models. Finally, we reduce the difference between the source domain and target domain by multi-source domain adaptation to solve the domain shift problem. Experiments on the mul-tiple public datasets demonstrate that our method can achieve competitive performance while having fewer parameters and less inference time.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Shaokang; Jiang, Lei; Tan, Jianlong] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   [Zhang, Shaokang; Jiang, Lei; Tan, Jianlong] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhang, SK (通讯作者)，Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.; Zhang, SK (通讯作者)，Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
EM zhangshaokang@iie.ac.cn
CR Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Chen C, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2613, DOI 10.1145/3442381.3449814
   Clark K, 2019, Arxiv, DOI [arXiv:1906.04341, DOI 10.48550/ARXIV:1906.04341]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dong CH, 2021, Arxiv, DOI arXiv:2110.08551
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gong YC, 2014, Arxiv, DOI arXiv:1412.6115
   Guo H, 2020, Arxiv, DOI arXiv:2001.04362
   Han S, 2015, ADV NEUR IN, V28
   Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]
   Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Li YC, 2021, NEUROCOMPUTING, V463, P368, DOI 10.1016/j.neucom.2021.08.019
   Li Z., 2018, 32 AAAI C ARTIFICIAL
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Peng ML, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2505
   Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Sun S, 2019, ARXIV
   Sun ZQ, 2020, Arxiv, DOI arXiv:2004.02984
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Tang RP, 2019, Arxiv, DOI arXiv:1903.12136
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang RZ, 2020, Arxiv, DOI arXiv:2002.01808
   Wang Wenhui, 2020, ARXIV200210957, DOI DOI 10.1145/3308558.3313562
   Wu C., 2021, ARXIV
   Yang Z, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P690, DOI 10.1145/3336191.3371792
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Zhan ZQ, 2020, NEUROCOMPUTING, V406, P1, DOI 10.1016/j.neucom.2020.03.093
   Zhang B, 2021, P 59 ANN M ASS COMPU, V1, P5423, DOI DOI 10.18653/V1/2021.ACL-LONG.421
   Zhao H., 2018, 6 INT C LEARNING REP
NR 35
TC 1
Z9 1
U1 8
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 14
PY 2022
VL 509
BP 11
EP 20
DI 10.1016/j.neucom.2022.08.061
EA AUG 2022
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4F2ND
UT WOS:000848351800002
DA 2023-11-10
ER

PT J
AU Dua, M
   Aggarwal, RK
   Biswas, M
AF Dua, Mohit
   Aggarwal, Rajesh Kumar
   Biswas, Mantosh
TI GFCC based discriminatively trained noise robust continuous ASR system
   for Hindi language
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Automatic speech recognition; MFCC; GFCC; Discriminative training; MPE
ID SPEECH RECOGNITION; FEATURES; CLASSIFICATION; FUSION; AGE
AB A statistically designed Automatic Speech Recognition (ASR) system extracts features from speech signals using feature extraction methods, links the extracted features with the expected phonetics of the hypothesis using acoustic models, uses language model to add prior information about the structure of the target language. For many years, Mel-frequency Cepstral coefficients (MFCC), n-gram, and Hidden Markov Model (HMM) approaches have been used predominantly for feature extraction, language modeling and acoustic modeling, respectively. However, performance degradation of MFCC in noisy conditions and inaccuracy of HMMs while handling large vocabularies have made researchers to propose more efficient methods. The proposed work uses noise robust method Gammatone Frequency Cepstral Coefficients(GFCC) for feature extraction, trigram language modeling, and HMM-Gaussian mixture model (GMM) based acoustic modeling to implement a continuous Hindi language ASR system. Also, it applies Differential Evolution (DE) technique to refine the GFCC features and discriminative techniques to enhance performance of the acoustic model. The performance of the implemented system has been evaluated by using different feature extraction methods, variants of n-gram language modeling techniques and different discriminative techniques in clean as well as noisy conditions. Initially, the results reveal that DE optimized GFCC with HMM-Gaussian Mixture Model (GMM) acoustic modeling performs better than MFCC, PLP and MF-PLP feature extraction methods. Secondly, the experimental results show that the Minimum Phone Error (MPE) outperforms Maximum Mutual Information (MMI) and Maximum Likelihood Estimation (MLE) and trigram based language modeling gives more accurate results than unigram and bigram language modeling. Finally, it has been concluded that the continuous Hindi language ASR system implemented using DE refined GFFC feature extraction method with MPE discriminative training technique and trigram based language modeling gives better accuracy in clean as-well-as noisy environments.
C1 [Dua, Mohit; Aggarwal, Rajesh Kumar; Biswas, Mantosh] Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Dua, M (通讯作者)，Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
EM er.mohitdua@nitkkr.ac.in; rka15969@gmail.com; mantoshbiswas@nitkkr.ac.in
RI BISWAS, DR. MANTOSH/ABC-9446-2021; DUA, MOHIT/A-1409-2016
OI BISWAS, DR. MANTOSH/0000-0001-9027-4432; DUA, MOHIT/0000-0001-7071-8323
CR Adiga A, 2013, TENCON IEEE REGION
   Aggarwal RK, 2013, TELECOMMUN SYST, V52, P1457, DOI 10.1007/s11235-011-9623-0
   Aggarwal RK, 2012, INT J SPEECH TECHNOL, V15, P191, DOI 10.1007/s10772-012-9133-9
   Aggarwal RK, 2012, INT J SPEECH TECHNOL, V15, P165, DOI 10.1007/s10772-012-9131-y
   Aggarwal RK, 2011, COMM COM INF SC, V139, P261
   [Anonymous], 2016, ARTIFICIAL INTELLIGE, DOI DOI 10.5430/AIR.V5N2P14
   [Anonymous], 2011, INT J SIGNAL PROCESS
   Bahl L. R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P49
   Biswas A., 2014, INT J GEOPHYS, V2014, P1, DOI [10.1155/2014/691521, DOI 10.1155/2014/691521]
   Biswas A, 2016, IET SIGNAL PROCESS, V10, P902, DOI 10.1049/iet-spr.2015.0488
   Biswas A, 2015, COMPUT ELECTR ENG, V42, P12, DOI 10.1016/j.compeleceng.2014.12.017
   Biswas A, 2014, COMPUT ELECTR ENG, V40, P1111, DOI 10.1016/j.compeleceng.2014.01.008
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dua M, 2018, J INTELL SYST
   Dua M, 2018, ENG SCI TECHNOL INT
   Dua M, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P158, DOI 10.1109/COMAPP.2017.8079777
   Fan LS, 2014, IEEE T COMMUN, V62, P3299, DOI 10.1109/TCOMM.2014.2345763
   Gillick D, 2012, INT CONF ACOUST SPEE, P4745, DOI 10.1109/ICASSP.2012.6288979
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Jeevan M, 2017, LECT NOTES ELECTR EN, V395, P85, DOI 10.1007/978-81-322-3592-7_9
   Kadyan V, 2017, IETE J RES
   Kadyan V, 2017, INT J SPEECH TECHNOL, V20, P761, DOI 10.1007/s10772-017-9446-9
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Liu Z, 2018, IEEE T IND INF
   Lu L, 2016, INTERSPEECH, P385, DOI 10.21437/Interspeech.2016-40
   McDermott E, 2007, IEEE T AUDIO SPEECH, V15, P203, DOI 10.1109/TASL.2006.876778
   Povey D., 2002, P INT C AC SPEECH SI, V1, P1, DOI DOI 10.1109/ICASSP.2002.5743665>
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH
   Reynolds DA, 1994, IEEE T SPEECH AUDI P, V2, P639, DOI 10.1109/89.326623
   Samudravijaya K, 2000, INT C SPOK LANG PROC, P456
   Shao Y, 2010, COMPUT SPEECH LANG, V24, P77, DOI 10.1016/j.csl.2008.03.004
   Shao Y, 2009, INT CONF ACOUST SPEE, P4625, DOI 10.1109/ICASSP.2009.4960661
   Valero X, 2012, IEEE T MULTIMEDIA, V14, P1684, DOI 10.1109/TMM.2012.2199972
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vertanen K, 2004, OVERVIEW DISCRIMINAT
   Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182
   Woodland PC, 2000, ISCA TUT RES WORKSH
   Xiong W, 2017, 2017 IEEE CONFERENCE ON ENERGY INTERNET AND ENERGY SYSTEM INTEGRATION (EI2)
   Young S., 2002, HTK BOOK
   Yücesoy E, 2016, COMPUT ELECTR ENG, V53, P29, DOI 10.1016/j.compeleceng.2016.06.002
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
NR 41
TC 22
Z9 23
U1 2
U2 24
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD JUN
PY 2019
VL 10
IS 6
SI SI
BP 2301
EP 2314
DI 10.1007/s12652-018-0828-x
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HX6CG
UT WOS:000467491000016
DA 2023-11-10
ER

PT S
AU Dowman, M
AF Dowman, M
BE Mckay, B
   Slaney, J
TI Modelling the acquisition of colour words
SO AL 2002: ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 15th Australian Joint Conference on Artificial Intelligence
CY DEC 02-06, 2002
CL CANBERRA, AUSTRALIA
AB How Bayesian inference might be used as the basis of a system for learning and representing the meanings of colour words in natural languages was investigated. The paper is primarily concerned with cognitive modelling, but has potential applications in natural language processing. A Bayesian cognitive model was constructed to test the hypothesis that people learn language, and in particular the meanings of colour words, using Bayesian inference. The model learned the range of colours which could be named by a particular colour word from examples of colours which could be denoted by that word, and was able to do so accurately even in the presence of large quantities of random noise in the input data. The resulting meaning representations display many of the properties of colour words in natural languages, in particular prototype properties.
C1 Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
C3 University of Sydney
RP Dowman, M (通讯作者)，Univ Sydney, Sch Informat Technol, F09, Sydney, NSW 2006, Australia.
EM Mike@it.usyd.edu.au
CR [Anonymous], 1997, MACH LEARN
   BELPAEME T, 2002, THESIS VRIJE U BRUSS
   Berlin B., 1969, BASIC COLOR TERMS
   BLOOM P, 2000, HOW CHILDREN LEARN M
   DOWMAN, 2001, 528 U SYDN BASS DEP
   Gardenfors P, 2000, GEOMETRY THOUGHT
   Griffiths TL, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P202
   KAY, 1978, LANGUAGE, V54
   LAMMENS JM, 1994, THESIS STATE U NEW Y
   MacLaury R. E., 1997, COLOR COGNITION MESO
   TAYLOR JR, 1989, LINGUISTIC CATEGORIA
   Tenenbaum J, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P16
   Tenenbaum JB., 1999, THESIS MIT
   Thompson E., 2021, COLOUR VISION STUDY
NR 14
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-00197-2
J9 LECT NOTES ARTIF INT
PY 2002
VL 2557
BP 259
EP 271
PG 13
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BW18A
UT WOS:000181083100023
DA 2023-11-10
ER

PT J
AU Hamza, HM
   Wali, A
AF Hamza, Hafiz Muhammad
   Wali, Aamir
TI Pakistan sign language recognition: leveraging deep learning models with
   limited dataset
SO MACHINE VISION AND APPLICATIONS
LA English
DT Article
DE Sign language recognition; Pakistan Sign Language; PSL data dictionary;
   C3D; Data augmentation
AB Sign language is the predominant form of communication among a large group of society. The nature of sign languages is visual. This makes them very different from spoken languages. Unfortunately, very few able people can understand sign language making communication with the hearing-impaired extremely difficult. Research in the field of sign language recognition can help reduce the barrier between deaf and able people. A lot of work has been done on sign language recognition for numerous languages such as American sign language and Chinese sign language. Unfortunately, very little to no work has been done for Pakistan Sign Language. Any contribution in Pakistan Sign Language recognition is limited to static images instead of gestures. Furthermore, the dataset available for this language is very small in terms of the number of examples per word which makes it very difficult to train deep networks that require a considerable amount of training data. Data Augmentation techniques help the network generalize better by providing more variety in the training data. In this paper, a pipeline for the Pakistan Sign Language recognition system is proposed that incorporates an augmentation unit. To validate the effectiveness of the proposed pipeline, three deep learning models, C3D, I3D, and TSM are used. Results show that translation and rotation are the two best augmentation techniques for the Pakistan Sign Language dataset. The models trained using our data-augment-supported pipeline outperform other methods that only used the original data. The most suitable model is C3D which not only produced an accuracy of 93.33% but also has a low training time as compared to other models.
C1 [Hamza, Hafiz Muhammad; Wali, Aamir] Natl Univ Comp & Emerging Sci, FAST Sch Comp, 852-B, Lahore, Pakistan.
RP Wali, A (通讯作者)，Natl Univ Comp & Emerging Sci, FAST Sch Comp, 852-B, Lahore, Pakistan.
EM l202058@lhr.nu.edu.pk; aamir.wali@nu.edu.pk
OI , Aamir/0009-0001-6571-6611; Wali, Aamir/0000-0002-5314-6113
CR Adaloglou N, 2021, Arxiv, DOI arXiv:2007.12530
   Ahamed KU, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.105014
   Ahmed MA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072208
   Alvi AK., 2004, INT J INF TECHNOL, V1, P1
   AnithaSheela K., 2022, INDIAN SIGN LANGUAGE, P7
   Ben Slimane F, 2021, Arxiv, DOI arXiv:2101.04632
   Bohácek M, 2022, IEEE WINT CONF APPL, P182, DOI 10.1109/WACVW54805.2022.00024
   Boukdir A, 2022, ARAB J SCI ENG, V47, P2187, DOI 10.1007/s13369-021-06167-5
   Cao Z, 2019, Arxiv, DOI [arXiv:1812.08008, DOI 10.48550/ARXIV.1812.08008]
   Carreira J, 2018, Arxiv, DOI arXiv:1705.07750
   cle, LINGUISTIC RESOURCES
   Contributors M., 2020, OPENMMLABS NEXT GENE
   Damaneh MM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118559
   De Coster M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6018
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gao Q., 2022, AM SIGN LANGUAGE FIN, P3151
   github, BOD SEGM
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369
   Hu JW, 2023, IEEE ACCESS, V11, P46204, DOI 10.1109/ACCESS.2023.3234743
   Javaid S, 2023, CMC-COMPUT MATER CON, V74, P523, DOI 10.32604/cmc.2023.031924
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang SY, 2021, Arxiv, DOI arXiv:2103.08833
   Kamal SM, 2019, IEEE ACCESS, V7, P96926, DOI 10.1109/ACCESS.2019.2929174
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kindiroglu AA, 2023, MACH VISION APPL, V34, DOI 10.1007/s00138-022-01367-x
   Kumar C.A., 2023, DEV SPEECH INDIAN SI, P341
   Li DX, 2020, Arxiv, DOI arXiv:1910.11006
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Lokhande P., 2015, P IJCA NAT C EM TREN, P11
   Malik M.S.A., 2018, INT J ADV COMPUT SC, V9, DOI [10.14569/IJACSA.2018.090414, DOI 10.14569/IJACSA.2018.090414]
   Maruyama M, 2021, ARXIV
   Mirza MS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15864-6
   Naseem M., 2019, J ED PRACT, V10
   Nikam A.S., 2016, SIGN LANGUAGE RECOGN, P1
   padeaf, DEAF STAT
   psl, 2020, PSL DICT
   Pu J, 2016, PCM-PREM PERS COMPUT, P252
   Qiu ZF, 2017, Arxiv, DOI arXiv:1711.10305
   Raees M, 2016, J ENG RES-KUWAIT, V4, P22
   Raziq N, 2017, LECT NOTE DATA ENG, V1, P895, DOI 10.1007/978-3-319-49109-7_87
   Sandler M, 2019, Arxiv, DOI [arXiv:1801.04381, DOI 10.48550/ARXIV.1801.04381]
   Sethia D, 2023, LECT NOTES ELECTR EN, V959, P307, DOI 10.1007/978-981-19-6581-4_24
   Shah FR, 2021, IEEE ACCESS, V9, P67548, DOI 10.1109/ACCESS.2021.3077386
   Shah SMS, 2023, NEURAL COMPUT APPL, V35, P949, DOI 10.1007/s00521-022-07804-2
   Sincan O.M., 2021, CORR
   Sun L, 2015, Arxiv, DOI [arXiv:1510.00562, 10.48550/arXiv.1510.00562, DOI 10.48550/ARXIV.1510.00562]
   Tongi R, 2021, Arxiv, DOI arXiv:2103.05111
   Tran D, 2018, Arxiv, DOI arXiv:1711.11248
   un, INT DAY SIGN LANG
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Xie P, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109233
   Xie SN, 2018, Arxiv, DOI arXiv:1712.04851
   Zhang Y., 2022, RES IMPROVEMENT CHIN, P577
NR 54
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0932-8092
EI 1432-1769
J9 MACH VISION APPL
JI Mach. Vis. Appl.
PD SEP
PY 2023
VL 34
IS 5
AR 71
DI 10.1007/s00138-023-01429-8
PG 16
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M6KZ0
UT WOS:001031297700003
DA 2023-11-10
ER

PT J
AU Mi, CG
   Xie, L
   Zhang, YN
AF Mi, Chenggang
   Xie, Lei
   Zhang, Yanning
TI Loanword Identification in Low-Resource Languages with Minimal
   Supervision
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Uyghur loanword; loanword identification; cross-lingual embedding;
   pronunciation similarity; out-of-vocabulary; low-resource neural machine
   translation
ID MODEL
AB Bilingual resources play a very important role in many natural language processing tasks, especially the tasks in cross-lingual scenarios. However, it is expensive and time consuming to build such resources. Lexical borrowing happens in almost every language. This inspires us to detect these loanwords effectively, and to use the "loanword (in receipt language)"-"donor word (in donor language)" to extend the bilingual resource for NLP tasks in low-resource languages. In this article, we propose a novel method to identify loanwords in Uyghur. The most important advantage of this method is that the model only relies on large amount of monolingual corpora and only a small scale of annotated data. Our loanword identification model includes two parts: loanword candidate generation and loanword prediction. In the first part, we use two large-scale monolingual corpora and a small bilingual dictionary to train a cross-lingual embedding model. Since semantic unrelated words often cannot be treated as loanword pairs, a loanword candidate list will be generated according to this model and a word list in Uyghur. In the second part, we predict from the preceding candidates based on a log-linear model that integrates several features such as pronunciation similarity, part-of-speech tags, and hybrid language modeling. To evaluate the effectiveness of our proposed method, we conduct two types of experiments: loanword identification and OOV translation. Experimental results showed that (1) our proposed method achieved significant F1 improvements compared to other models in all four loanword identification tasks in Uyghur, and (2) after extending the existing translation models with loanword identification results, OOV rates in several language pairs reduced significantly and the translation performance improved.
C1 [Mi, Chenggang; Xie, Lei; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated AeroSp Ground Ocean Big, 1 Dongxiang Rd, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Mi, CG (通讯作者)，Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated AeroSp Ground Ocean Big, 1 Dongxiang Rd, Xian 710072, Shaanxi, Peoples R China.
EM michenggang@nwpu.edu.cn; lxie@nwpu.edu.cn; ynzhang@nwpu.edu.cn
FU National Key Research and Development Program of China [2017YFB1002102];
   National Natural Science Foundation of China [61906158]
FX This research was partially supported by the National Key Research and
   Development Program of China (no. 2017YFB1002102) and the National
   Natural Science Foundation of China (no. 61906158).
CR Adouane Wafia, 2018, P 2 WORKSH SUBW CHAR, P22, DOI [10.18653/v1/W18-1203, DOI 10.18653/V1/W18-1203]
   Ammar, 2016, ARXIV160201925
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2016, P 2016 C EMPIRICAL M, DOI DOI 10.18653/V1/D16-1136
   [Anonymous], 2014, EACL
   [Anonymous], 2015, P 2015 C N AM CHAPTE, DOI DOI 10.3115/V1/N15-1062
   BARONE AVM, 2016, P 1 WORKSH REPR LEAR, P121
   Cianflone Andre, 2016, P 3 WORKSH NLP SIM L, P243
   Durkin Philip, 2014, BORROWED WORDS HIST
   Faruqui Manaal, 2014, P EACL, DOI [10.3115/v1/E14-1049, DOI 10.3115/V1/E14-1049]
   Gerz D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P316
   Guo J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1234
   Haspelmath Martin., 2009, WORLD LOANWORD DATAB
   Hoffer Bates L., 2005, INTERCULTURAL COMMUN, V14, P53
   Huang Kejun, 2015, P 2015 C EMP METH NA, P1084
   Jaech A., 2016, P 2 WORKSH COMP APPR, P60
   Jauhiainen T, 2019, J ARTIF INTELL RES, V65, P675
   Kang Yoonjung, 2016, P ANN M PHON, V2
   Karakanta A, 2018, MACH TRANSL, V32, P167, DOI 10.1007/s10590-017-9203-5
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kontovas Nicholas D., 2008, ANAL RECENT LOANS ST
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Liu X, 2015, CUST AGRONEGOCIO, V11, P2
   Luong Thang, 2015, P 1 WORKSHOP VECTOR, P151, DOI [DOI 10.3115/V1/W15-1521, 10]
   McCoy R.T., 2018, P SOC COMP LING SCIL, P102
   Mi C, 2016, P 30 PAC AS C LANG I, P209
   Mi CG, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3575
   Mi Chenggang, 2014, NATURAL LANGUAGE PRO, P103
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Luong MT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1054
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Mohammadi Elham, 2017, P 12 WORKSH INN US N, P210, DOI [10.18653/v1/W17-5022, DOI 10.18653/V1/W17-5022]
   Neubig Graham, 2016, P 2016 C EMP METH NA, P1163, DOI DOI 10.18653/V1/D16-1124
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Peperkamp S., 2004, ANN M BERKELEY LINGU, V30, P341
   Rettinger A Mogadaland A, 2016, P 2016 C N AM CHAPTE, P692
   Sankaranarayanan, 2018, P 2018 C N AM CHAPT, P112, DOI DOI 10.18653/V1/N18-4016
   Schwarz HenryG., 1992, UYGHUR ENGLISH DICT
   Seker GA, 2017, SEMANT WEB, V8, P625, DOI 10.3233/SW-170253
   Serigos J, 2017, INT J BILINGUAL, V21, P521, DOI 10.1177/1367006916635836
   Shinohara S, 2015, J EAST ASIAN LINGUIS, V24, P149, DOI 10.1007/s10831-014-9129-3
   Tsvetkov Y, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P125
   Vulic I, 2016, J ARTIF INTELL RES, V55, P953, DOI 10.1613/jair.4986
   Yang S, 2018, INT CONF ASIAN LANG, P279, DOI 10.1109/IALP.2018.8629170
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang J., 2016, ARXIV161007272
NR 48
TC 6
Z9 6
U1 2
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL
PY 2020
VL 19
IS 3
AR 43
DI 10.1145/3374212
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OH5IN
UT WOS:000582616600010
DA 2023-11-10
ER

PT J
AU Pan, SM
   McKeown, K
   Hirschberg, J
AF Pan, SM
   McKeown, K
   Hirschberg, J
TI Exploring features from natural language generation for prosody modeling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
ID ACCENT
AB Prosody modeling is critical in developing a Concept-to-Speech (CTS) system where both Natural Language Generation (NLG) and Speech Synthesis are used to automatically generate natural, coherent speech. In this paper, we empirically verify the usefulness of various natural language features in prosody modeling. Three groups of features are investigated: semantic, syntactic, and surface features produced by SURGE, a general-purpose surface natural language generator for English, deep semantic, and discourse features that are available during the domain modeling and content planning phases of generation, and information-based measures statistically derived from text. Our experiments identify which of this large set of features are effective in prosody modeling. This work represents an important step towards building a comprehensive prosody model for CTS systems that employ general NLG. This investigation is conducted in the context of MAGIC, a medical application that involves automatic speech and graphics generation. (C) 2002 Elsevier Science Ltd. All rights reserved.
C1 IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA.
   Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
   AT&T Labs Res, Florham Pk, NJ 07932 USA.
C3 International Business Machines (IBM); Columbia University; AT&T
RP Pan, SM (通讯作者)，IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA.
EM shimei@us.ibm.com
CR ALTENBERG B, 1987, LUND STUDIES ENGLISH, P76
   [Anonymous], P JOINT SIGDAT C EMN
   [Anonymous], 1985, J ACOUST SOC AM, DOI DOI 10.1121/1.2022951
   [Anonymous], 1981, RADICAL PRAGMATICS
   [Anonymous], [No title captured]
   Bachenko J., 1990, Computational Linguistics, V16, P155
   BECKMAN M, 1993, TOBI ANNOTATION CONV
   BLACK A, 1995, SPRING M AC SOC JAP
   BOLINGER D, 1972, LANGUAGE, V48, P633, DOI 10.2307/412039
   BOLINGER DL, 1958, WORD, V14, P1
   Bolinger DL., 1972, INTONATION
   BRESNAN JW, 1971, LANGUAGE, V47, P257, DOI 10.2307/412081
   Brown G., 1983, PROSODY MODELS MEASU, P67, DOI 10.1007/978-3-642-69103-4_6
   Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P115
   COLLINS M, 1999, THESIS U PENNSYLVANI
   Conover W.J., 1999, PRACTICAL NONPARAMET
   Cover T. M., 2005, ELEM INF THEORY, DOI 10.1002/047174882X
   Dalal M., 1996, Proceedings ACM Multimedia 96, P55, DOI 10.1145/244130.244147
   DUSTERHOFF K, 1999, P EUR BUD HUNG
   ELHADAD M, 1993, THESIS COLUMBIA U
   FANO R, 1961, TRANSMISSION INFORMA
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Halliday MAK., 2014, INTRO FUNCTIONAL GRA, V4th ed.
   HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C
   HIRSCHBERG J, 1996, SPEECH COMMUNICATION
   HIRSCHBERG J, 1990, P 7 NAT C AM ASS ART
   KOEHN P, 2000, P ICASSP 2000
   Ladd D. Robert, 2008, INTONATIONAL PHONOLO, V1st, DOI [10.1017/CBO9780511808814, DOI 10.1017/CBO9780511808814]
   LIBERMAN M, 1992, LEXICAL MATTERS, P131
   MARCHAND J, 1993, MESSAGE POSTED HUMAN
   NAKATANI C, 1998, P COLING ACL 98 MONT, P939
   O'Shaughnessy D. D., 1989, Computational Linguistics, V15, P97
   Pierrehumbert J. B., 1980, THESIS MIT
   PRICE PJ, 1991, J ACOUST SOC AM, V90, P2956, DOI 10.1121/1.401770
   Prince E. F., 1992, DISCOURSE DESCRIPTIO, P295, DOI DOI 10.1075/PBNS.16.12PRI
   PROVOST S, 1995, THESIS U PENNSYLVANI
   ROBIN J, 1994, THESIS COLUMBIA U
   SELKIRK EO, 1984, CURRENT STUDIES LING
   Shannon CE., 1948, BELL SYST TECH J, V27, P379, DOI [DOI 10.1002/J.1538-7305.1948.TB01338.X, DOI 10.1002/J.1538-7305.1948.TB00917.X]
   SILVERMAN K, 1992, P ICSLP92, P2
   SPROAT R, 1994, COMPUT SPEECH LANG, V8, P79, DOI 10.1006/csla.1994.1004
   Sproat R. W., 1997, MULTILINGUAL TEXT TO
   Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041
   Wang M. Q., 1992, Computer Speech and Language, V6, P175, DOI 10.1016/0885-2308(92)90025-Y
NR 44
TC 11
Z9 11
U1 0
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL-OCT
PY 2002
VL 16
IS 3-4
BP 457
EP 490
DI 10.1016/S0885-2308(02)00022-0
PG 34
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science
GA 606WR
UT WOS:000178758100008
DA 2023-11-10
ER

PT J
AU Brette, R
   Goodman, DFM
AF Brette, Romain
   Goodman, Dan F. M.
TI Vectorized Algorithms for Spiking Neural Network Simulation
SO NEURAL COMPUTATION
LA English
DT Article
ID SYNAPTIC CONDUCTANCES; COMPUTATION; NEURONS; PLASTICITY; MODELS; TOOLS
AB High-level languages (Matlab, Python) are popular in neuroscience because they are flexible and accelerate development. However, for simulating spiking neural networks, the cost of interpretation is a bottleneck. We describe a set of algorithms to simulate large spiking neural networks efficiently with high-level languages using vector-based operations. These algorithms constitute the core of Brian, a spiking neural network simulator written in the Python language. Vectorized simulation makes it possible to combine the flexibility of high-level languages with the computational efficiency usually associated with compiled languages.
C1 [Brette, Romain] CNRS, Lab Psychol Percept, F-75006 Paris, France.
   Univ Paris 05, F-75006 Paris, France.
   Ecole Normale Super, Dept Etud Cognit, F-75230 Paris 05, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Cite; Universite Paris Cite; Universite PSL; Ecole Normale Superieure
   (ENS)
RP Brette, R (通讯作者)，CNRS, Lab Psychol Percept, F-75006 Paris, France.
EM romain.brette@ens.fr; dan.goodman@ens.fr
RI Brette, Romain/F-6670-2012; Brette, Romain/I-7120-2016
OI Brette, Romain/0000-0003-0110-1623; Goodman, Dan/0000-0003-1007-6474
FU European Research Council (ERC) [StG 240132]
FX We thank all those who tested early versions of Brian and made
   suggestions for improving it. This work was supported by the European
   Research Council (ERC StG 240132).
CR [Anonymous], 1974, DIFF EQUAT+
   [Anonymous], 1998, BOOK GENESIS EXPLORI, DOI DOI 10.1007/978-1-4612-1634-63
   Brette R, 2007, J COMPUT NEUROSCI, V23, P349, DOI 10.1007/s10827-007-0038-6
   Cannon RC, 2007, NEUROINFORMATICS, V5, P127, DOI 10.1007/s12021-007-0004-5
   Carnevale T., 2006, NEURON BOOK, DOI DOI 10.1017/CBO9780511541612
   D'Haene M, 2010, NEURAL COMPUT, V22, P1468, DOI 10.1162/neco.2010.07-09-1070
   Davison Andrew P, 2008, Front Neuroinform, V2, P11, DOI 10.3389/neuro.11.011.2008
   Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91
   Destexhe A, 1994, J Comput Neurosci, V1, P195, DOI 10.1007/BF00961734
   DESTEXHE A, 1994, NEURAL COMPUT, V6, P14, DOI 10.1162/neco.1994.6.1.14
   DJURFELDT M, 2007, 1 INCF WORKSH LARG S
   Eppler Jochen Martin, 2008, Front Neuroinform, V2, P12, DOI 10.3389/neuro.11.012.2008
   Garny A, 2008, PHILOS T R SOC A, V366, P3017, DOI 10.1098/rsta.2008.0094
   Gewaltig M-O., 2007, SCHOLARPEDIA, V2, DOI DOI 10.4249/SCHOLARPEDIA.1430
   Giugliano M, 2000, NEURAL COMPUT, V12, P903, DOI 10.1162/089976600300015646
   Giugliano M, 1999, NEURAL COMPUT, V11, P1413, DOI 10.1162/089976699300016296
   Goddard NH, 2001, PHILOS T ROY SOC B, V356, P1209, DOI 10.1098/rstb.2001.0910
   Goodman Dan, 2008, Front Neuroinform, V2, P5, DOI 10.3389/neuro.11.005.2008
   Goodman DFM, 2009, FRONT NEUROSCI-SWITZ, V3, P192, DOI 10.3389/neuro.01.026.2009
   Hanuschkin A., 2010, FRONTIERS NEUROINFOR, V4, P12
   HINES M, 1984, INT J BIOMED COMPUT, V15, P69, DOI 10.1016/0020-7101(84)90008-4
   Hines Michael L, 2009, Front Neuroinform, V3, P1, DOI 10.3389/neuro.11.001.2009
   Hines ML, 2000, NEURAL COMPUT, V12, P995, DOI 10.1162/089976600300015475
   Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882
   Jahnke A, 1998, PULSED NEURAL NETWORKS, P237
   Kistler W.M., 2002, SPIKING NEURON MODEL
   Kohn J, 1998, NEURAL COMPUT, V10, P1639, DOI 10.1162/089976698300017061
   Loebel A, 2002, J COMPUT NEUROSCI, V13, P111, DOI 10.1023/A:1020110223441
   Lytton WW, 1996, NEURAL COMPUT, V8, P501, DOI 10.1162/neco.1996.8.3.501
   Markram H, 1998, P NATL ACAD SCI USA, V95, P5323, DOI 10.1073/pnas.95.9.5323
   Mongillo G, 2008, SCIENCE, V319, P1543, DOI 10.1126/science.1150769
   Morrison A, 2005, NEURAL COMPUT, V17, P1776, DOI 10.1162/0899766054026648
   Morrison A, 2008, BIOL CYBERN, V98, P459, DOI 10.1007/s00422-008-0233-1
   Morrison A, 2007, NEURAL COMPUT, V19, P1437, DOI 10.1162/neco.2007.19.6.1437
   Morrison A, 2007, NEURAL COMPUT, V19, P47, DOI 10.1162/neco.2007.19.1.47
   Morse T., 2007, SCHOLARPEDIA, V2, P3036
   Owens JD, 2007, COMPUT GRAPH FORUM, V26, P80, DOI 10.1111/j.1467-8659.2007.01012.x
   Platkiewicz J, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000850
   Plesser HE, 2009, NEURAL COMPUT, V21, P353, DOI 10.1162/neco.2008.03-08-731
   PROTOPAPAS AD, 1998, METHODS NEURONAL MOD
   Rossant Cyrille, 2010, Front Neuroinform, V4, P2, DOI 10.3389/neuro.11.002.2010
   Rotter S, 1999, BIOL CYBERN, V81, P381, DOI 10.1007/s004220050570
   Sanchez-Montanez M. A., 2001, STRATEGIES OPTIMIZAT
   Schutter E. D., 2008, PLOS COMPUT BIOL, V4
   Song S, 2000, NAT NEUROSCI, V3, P919, DOI 10.1038/78829
   Tsodyks M, 1998, NEURAL COMPUT, V10, P821, DOI 10.1162/089976698300017502
   Tsodyks MV, 1997, P NATL ACAD SCI USA, V94, P719, DOI 10.1073/pnas.94.2.719
NR 47
TC 22
Z9 24
U1 0
U2 13
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0899-7667
EI 1530-888X
J9 NEURAL COMPUT
JI Neural Comput.
PD JUN
PY 2011
VL 23
IS 6
BP 1503
EP 1535
DI 10.1162/NECO_a_00123
PG 33
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA 760CO
UT WOS:000290300400004
PM 21395437
DA 2023-11-10
ER

PT J
AU Daum, S
   Borrmann, A
AF Daum, Simon
   Borrmann, Andre
TI Processing of Topological BIM Queries using Boundary Representation
   Based Methods
SO ADVANCED ENGINEERING INFORMATICS
LA English
DT Article
DE Building information modeling; 3D spatial query language; Topology;
   Boundary representation; QL4BIM
ID LANGUAGE; OPERATORS
AB Building Information Models (BIM) are comprehensive digital representations of buildings, which provide a large set of information originating from the different disciplines involved in the design, construction and operation processes. Moreover, accessing the data needed for a specific downstream application scenario is a challenging task in large-scale BIM projects. Several researchers recently proposed using formal query languages for specifying the desired information in a concise, well-defined manner. One of the main limitations of the languages introduced so far, however, is the inadequate treatment of geometric information. This is a significant drawback, as buildings are inherently spatial objects and qualitative spatial relationships accordingly play an important role in the analysis and verification of building models. In addition, the filters needed in specific data exchange scenarios for selecting the information required can be built by spatial objects and their relations. The lack of spatial functionality in BIM query languages is filled by the Query Language for Building Information Models (QL4BIM) which provides metric, directional and topological operators for defining filter expressions with qualitative spatial semantics. This paper focuses on the topological operators provided by the language. In particular, it presents a new implementation method based on the boundary representation of the operands which outperforms the previously presented octree-based approaches. The paper discusses the developed algorithms in detail and presents extensive performance tests. (C) 2014 The Authors. Published by Elsevier Ltd.
C1 [Daum, Simon; Borrmann, Andre] Tech Univ Munich, Chair Computat Modeling & Simulat, Leonhard Obermeyer Ctr, D-80333 Munich, Germany.
C3 Technical University of Munich
RP Daum, S (通讯作者)，Tech Univ Munich, Chair Computat Modeling & Simulat, Leonhard Obermeyer Ctr, D-80333 Munich, Germany.
EM simon.daum@tum.de; andre.borrmann@tum.de
OI Borrmann, Andre/0000-0003-2088-7254
CR Adachi Y., 2003, P 10 INT C CONC ENG
   Akenine-MollserT, 2001, J GRAPHICS TOOLS, V6, P29, DOI 10.1080/10867651.2001.10487535
   [Anonymous], 2006, P 2006 ACM SIGMOD IN, DOI DOI 10.1145/1142473.1142552
   [Anonymous], 167392013 ISO
   [Anonymous], 1995, MODERN DATABASE SYST
   [Anonymous], 2007, X3D EXTENSIBLE 3D GR
   [Anonymous], QUERYING DISTRIBUTED
   Borrmann A., 2006, EXTENDED FORMAL SPEC
   Borrmann A., 2009, HDB RES BUILDING INF
   Borrmann A., 2008, P 12 INT C COMP CIV
   Borrmann A, 2009, ADV ENG INFORM, V23, P370, DOI 10.1016/j.aei.2009.06.001
   Borrmann A, 2009, J COMPUT CIVIL ENG, V23, P34, DOI 10.1061/(ASCE)0887-3801(2009)23:1(34)
   Borrmann A, 2009, ADV ENG INFORM, V23, P32, DOI 10.1016/j.aei.2008.06.005
   Clementini E., 1993, Advances in Spatial Databases. Third International Symposium, SSD '93 Proceedings, P277
   Codd Edgar F, 1990, RELATIONAL MODEL DAT
   Cormen T.H., 2001, INTRO ALGORITHMS, Vsecond ed., DOI DOI 10.1145/963770.963776
   Daum S., 2013, P EG ICE WORKSH INT
   Daum S., 2012, P EG ICE WORKSH INT
   Daum S., 2012, 25 FOR BAU BOCH
   Eastman C., 2011, BIM HDB GUIDE BUILDI
   EGENHOFER M, 1987, P 2 INT SEM TRENDS C
   Egenhofer M., P 4 INT S SPAT DAT H
   EGENHOFER MJ, 1991, INT J GEOGR INF SYST, V5, P161, DOI 10.1080/02693799108927841
   EGENHOFER MJ, 1992, INT J GEOGR INF SYST, V6, P71, DOI 10.1080/02693799208901897
   ESRI, 2013, WORK 3D SET OP ESRI
   Gaal, 2009, POINT SET TOPOLOGY
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Herring J., 1988, P GIS LIS
   INGRAM K, 1987, P 8 INT S COMP ASS C
   ISO, 2011, 294811 ISO
   Kirk D., 1992, GRAPHICS GEMS 3 FAST
   Mazairac W, 2013, ADV ENG INFORM, V27, P444, DOI 10.1016/j.aei.2013.06.001
   Moller T, 1997, J GRAPH TOOLS, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   OGC, 2011, OPENGIS IMPL STAND 1
   OOI B, 1989, P IEEE 5 INT C DAT E
   ROUSSOPOULOS N, 1988, IEEE T SOFTWARE ENG, V14, P639, DOI 10.1109/32.6141
   Samet H, 1989, APPL SPATIAL DATA ST
   Schraufstetter S., 2007, TAG 19 FOR BAUINF
   Tauscher E., 2014, IFC TOOLS PROJECT VI
   Weise M., 2003, P 20 CIB W78 C INF T
NR 41
TC 62
Z9 62
U1 3
U2 40
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1474-0346
EI 1873-5320
J9 ADV ENG INFORM
JI Adv. Eng. Inform.
PD OCT
PY 2014
VL 28
IS 4
BP 272
EP 286
DI 10.1016/j.aei.2014.06.001
PG 15
WC Computer Science, Artificial Intelligence; Engineering,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW4AR
UT WOS:000346224500003
OA hybrid
DA 2023-11-10
ER

PT J
AU Zandie, R
   Mahoor, MH
AF Zandie, Rohola
   Mahoor, Mohammad H.
TI Topical language generation using transformers
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Natural language generation; Probabilistic model; Topical language
   generation; Transformers
AB Large-scale transformer-based language models (LMs) demonstrate impressive capabilities in open-text generation. However, controlling the generated text's properties such as the topic, style, and sentiment is challenging and often requires significant changes to the model architecture or retraining and fine-tuning the model on new supervised data. This paper presents a novel approach for topical language generation (TLG) by combining a pre-trained LM with topic modeling information. We cast the problem using Bayesian probability formulation with topic probabilities as a prior, LM probabilities as the likelihood, and TLG probability as the posterior. In learning the model, we derive the topic probability distribution from the user-provided document's natural structure. Furthermore, we extend our model by introducing new parameters and functions to influence the quantity of the topical features presented in the generated text. This feature would allow us to easily control the topical properties of the generated text. Our experimental results demonstrate that our model outperforms the state-of-the-art results on coherency, diversity, and fluency while being faster in decoding.
C1 [Zandie, Rohola; Mahoor, Mohammad H.] Univ Denver, Dept Elect & Comp Engn, Denver, CO 80208 USA.
C3 University of Denver
RP Mahoor, MH (通讯作者)，Univ Denver, Dept Elect & Comp Engn, Denver, CO 80208 USA.
EM mohammad.mahoor@du.edu
OI Mahoor, Mohammad/0000-0001-8923-4660
CR Baheti A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3970
   Baldi P, 2010, NEURAL NETWORKS, V23, P649, DOI 10.1016/j.neunet.2009.12.007
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bowman Samuel R, 2015, ARXIV151106349
   Brown T.B., 2020, P 34 INT C NEUR INF
   Correia GM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2174
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dethlefs N, 2015, NAT LANG ENG, V21, P391, DOI 10.1017/S1351324913000375
   Dziri N., 2018, ARXIV181101063
   Fu ZX, 2018, AAAI CONF ARTIF INTE, P663
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI DOI 10.5555/177910.177914
   Ghazvininejad M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P43, DOI 10.18653/v1/P17-4008
   Goodfellow I., 2016, ARXIV170100160, DOI DOI 10.1038/NATURE14539
   Gopalakrishnan K, 2019, INTERSPEECH, P1891, DOI 10.21437/Interspeech.2019-3079
   Guo JX, 2018, AAAI CONF ARTIF INTE, P5141
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Hoffman Matthew, 2010, ADV NEURAL INFORM PR, P856
   Holtzman A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1638
   Holtzman Ari, 2020, ICLR
   Hu Z., 2017, PR MACH LEARN RES
   Huang J., 2005, MAXIMUM LIKELIHOOD E
   Kannan A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P955, DOI 10.1145/2939672.2939801
   Keskar Nitish Shirish, 2019, CTRL CONDITIONAL TRA
   Lau JH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P355, DOI 10.18653/v1/P17-1033
   Li J., 2018, P 2018 C N AM CHAPT, V1, P1865, DOI [DOI 10.18653/V1/N18-1169, 10.18653/v1/N18-1169]
   Li M, 2020, P 58 ANN M ASS COMPU, P4715, DOI DOI 10.18653/V1/2020.ACL-MAIN.428
   Malandrakis N., 2019, P 3 WORKSHOP NEURAL, P90, DOI 10.18653/v1/d19-5609
   Martins AFT, 2016, PR MACH LEARN RES, V48
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mueller J., 2017, P 34 INT C MACHINE L, P2536
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Prabhumoye S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P866
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Röder M, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P399, DOI 10.1145/2684822.2685324
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Singh A., 2018, ARXIV PREPRINT ARXIV
   Stahlberg F., 2018, P 3 C MACH TRANSL RE, P204, DOI [DOI 10.18653/V1/W18-6321, 10.18653/v1/W18-6321]
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Vaswani A, 2017, ADV NEUR IN, V30
   Welleck Sean, 2020, ABS190804319 ARXIV
   Xing C, 2017, AAAI CONF ARTIF INTE, P3351
   Xu JJ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P979
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zhang Y., 2018, LONG PAPERS, V1, P1528
   Zhao Y., 2018, INT C LEARN REPR
NR 46
TC 1
Z9 1
U1 4
U2 17
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD 2022 FEB 4
PY 2022
AR PII S1351324922000031
DI 10.1017/S1351324922000031
EA FEB 2022
PG 23
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YT1QE
UT WOS:000751141300001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Hu, M
   Peng, JJ
   Zhang, WQ
   Hu, JX
   Qi, LZ
   Zhang, HX
AF Hu, Miao
   Peng, Junjie
   Zhang, Wenqiang
   Hu, Jingxiang
   Qi, Lizhe
   Zhang, Huanxiang
TI Text Representation Model for Multiple Language Forms in Spoken Chinese
   Expression
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Multi-language forms; syllabic features; intent understanding; spoken
   language
AB Mixture of multiple language forms in spoken Chinese is a common but unfavorable issue.. It increases the difficulty of intent understanding and leads to inconvenience for information communication. Existing studies on intent recognition mainly focus on single language form or parallel multilingual language while paying little attention to spoken texts including multiple language forms. In considering that it is hard to capture the semantics of an expression with multiple language forms, it is important to study the problem. To solve this issue, a text representation model for the spoken Chinese expression mixed with English and Chinese Pinyin is proposed. And the feature matrix is built to mine the composition information of English and Pinyin. Besides, the model can efficiently distinguish English from Chinese Pinyin even though both fragments are composed of English letters. Meanwhile, it can effectively process the problem of hidden text information since the problem has been transformed into the Chinese translation task of English and Pinyin. In addition, to verify the performance of the model, the texts processed by this model are used as the input of the classifier. extensive experiments on a large online logistics manual customer service corpus show that this text representation model is correct and effective. It can not only eliminate the obstacles of the mixing of multiple language forms but also bring better results for intent understanding.
C1 [Hu, Miao; Peng, Junjie; Hu, Jingxiang; Zhang, Huanxiang] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Peng, Junjie] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
   [Peng, Junjie] Fudan Univ, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
   [Zhang, Wenqiang; Qi, Lizhe] Fudan Univ, Acad Engn & Technol, Shanghai, Peoples R China.
   [Zhang, Wenqiang] Fudan Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University; Fudan University; Fudan
   University; Fudan University
RP Peng, JJ (通讯作者)，Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.; Peng, JJ (通讯作者)，Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.; Peng, JJ (通讯作者)，Fudan Univ, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
EM jjie.peng@shu.edu.cn; wqzhang@fudan.edu.cn
FU Open Project Program of Shanghai Key Laboratory of Data Science
   [2020090600004]; Shanghai software and integrated circuit industry
   development project [RX-RJJC-07-19-4847]
FX The work is supported by the Open Project Program of Shanghai Key
   Laboratory of Data Science (No. 2020090600004) and the Shanghai software
   and integrated circuit industry development project (No.
   RX-RJJC-07-19-4847). The authors appreciate the High Performance
   Computing Center of Shanghai University, and Shanghai Engineering
   Research Center of Intelligent Computing System (No. 19DZ2252600) for
   providing the computing resources. Meanwhile, it is also very grateful
   for the data and industry knowledge support from YTO express company.
CR Amine BM, 2007, I C COMP SYST APPLIC, P848, DOI 10.1109/AICCSA.2007.370731
   Celikyilmaz A., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P425, DOI 10.1109/ASRU.2011.6163969
   Chen H., 2016, COMPUT APPL SOFTW, P68
   Duan JY, 2019, LECT NOTES ARTIF INT, V11838, P471, DOI 10.1007/978-3-030-32233-5_37
   Figueroa A, 2016, IEEE INTERNET COMPUT, V20, P8, DOI 10.1109/MIC.2015.22
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Haffner P, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P632
   Huang CW, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P845, DOI [10.1109/asru46091.2019.9003825, 10.1109/ASRU46091.2019.9003825]
   Jiang ZF, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 1, PROCEEDINGS, P362, DOI 10.1109/ICNC.2008.807
   Jiao Liu, 2018, Web Information Systems and Applications. 15th International Conference, WISA 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11242), P27, DOI 10.1007/978-3-030-02934-0_3
   Jun W., 2003, APPLLINGUISTICS, V2, P2
   Kim Y., 2014, PREPRINT
   Li CL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3824
   Matsuyoshi Y, 2018, ASIAPAC SIGN INFO PR, P1752, DOI 10.23919/APSIPA.2018.8659636
   McCallum A., 1998, AAAI 98 WORKSH LEARN, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Mishra A, 2016, J KING SAUD UNIV-COM, V28, P345, DOI 10.1016/j.jksuci.2014.10.007
   Ni X., 2009, P 18 INT C WORLD WID, P1155
   Ravuri S, 2016, INT CONF ACOUST SPEE, P6075, DOI 10.1109/ICASSP.2016.7472844
   Sidorov G, 2014, EXPERT SYST APPL, V41, P853, DOI 10.1016/j.eswa.2013.08.015
   Tseng C.-R. H. E. I., 2003, CROSS LINGUAL PORTAB
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Wang JP, 2015, AAAI CONF ARTIF INTE, P339
   Yu RY, 2018, NEURAL COMPUT APPL, V29, P707, DOI 10.1007/s00521-016-2477-3
   Zhang Q, 2019, AS C MACH LEARN PMLR, P425
   Zhao ZY, 2019, DATA INTELLIGENCE, V1, P187, DOI 10.1162/dint_a_00007
   Zhong J., 2019, PREPRINT
NR 26
TC 2
Z9 2
U1 3
U2 6
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD JUN 30
PY 2022
VL 36
IS 08
AR 2253004
DI 10.1142/S0218001422530044
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S3PK
UT WOS:000821707100007
DA 2023-11-10
ER

PT J
AU Daley, M
   McQuillan, I
   McQuillan, JM
   Mahalingam, K
AF Daley, Mark
   McQuillan, Ian
   McQuillan, James M.
   Mahalingam, Kalpana
TI Theoretical and computational properties of transpositions
SO NATURAL COMPUTING
LA English
DT Article
DE Bioinformatics; Transposable elements; Transpositions; Formal language
   theory; Mathematical modelling
ID ELEMENTS
AB Transposable genetic elements are prevalent across many living organisms from bacteria to large mammals. Given the linear primary structure of genetic material, this process is natural to study from a theoretical perspective using formal language theory. We abstract the process of genetic transposition to operations on languages and study it combinatorially and computationally. It is shown that the power of such systems is large relative to the classic Chomsky Hierarchy. However, we are still able to algorithmically determine whether or not a string is a possible product of the iterated application of the operations.
C1 [Daley, Mark] Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.
   [Daley, Mark] Univ Western Ontario, Dept Biol, London, ON N6A 5B7, Canada.
   [Daley, Mark; McQuillan, Ian] Univ Saskatchewan, Dept Comp Sci, Saskatoon, SK S7N 5A9, Canada.
   [McQuillan, James M.] Western Illinois Univ, Dept Comp Sci, Macomb, IL 61455 USA.
   [Mahalingam, Kalpana] Indian Inst Technol Madras, Dept Comp Sci, Chennai 600036, Tamil Nadu, India.
C3 Western University (University of Western Ontario); Western University
   (University of Western Ontario); University of Saskatchewan; Western
   Illinois University; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Madras
RP Daley, M (通讯作者)，Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.
EM daley@csd.uwo.ca; mcquillan@cs.usask.ca; jm-mcquillan@wiu.edu;
   kmahalingham@iitm.ac.in
RI Daley, Mark J/B-5679-2015; Daley, Mark/AAS-7366-2020
OI Daley, Mark J/0000-0002-6939-9772; Daley, Mark/0000-0002-6939-9772;
   McQuillan, Ian/0000-0002-7998-4430; Mahalingam,
   Kalpana/0000-0003-2418-0512
CR Giordano J, 2007, PLOS COMPUT BIOL, V3, P1321, DOI 10.1371/journal.pcbi.0030137
   Harrison Michael A., 1978, INTRO FORMAL LANGUAG
   Kari L, 2008, THEOR COMPUT SCI, V396, P264, DOI 10.1016/j.tcs.2008.01.037
   Kidwell Margaret G., 2005, P165, DOI 10.1016/B978-012301463-4/50005-X
   Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062
   Martin-Vide C, 1998, THEOR COMPUT SCI, V205, P195, DOI 10.1016/S0304-3975(97)00079-0
   Meyers BC, 2001, GENOME RES, V11, P1660, DOI 10.1101/gr.188201
   Quesneville H, 2005, PLOS COMPUT BIOL, V1, P166, DOI 10.1371/journal.pcbi.0010022
   Salomaa, 1973, FORMAL LANGUAGES
NR 9
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1567-7818
EI 1572-9796
J9 NAT COMPUT
JI Nat. Comput.
PD JUN
PY 2011
VL 10
IS 2
SI SI
BP 795
EP 804
DI 10.1007/s11047-010-9207-z
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 770BB
UT WOS:000291060900010
DA 2023-11-10
ER

PT J
AU Touma, R
   Hajj, H
   El-Hajj, W
   Shaban, K
AF Touma, Roudy
   Hajj, Hazem
   El-Hajj, Wassim
   Shaban, Khaled
TI Automated Generation of Human-readable Natural Arabic Text from RDF Data
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Low-resource languages; data-to-text; RDF; language models; neural
   networks; datasets
AB With the advances in Natural Language Processing (NLP), the industry has been moving towards human-directed artificial intelligence (AI) solutions. Recently, chatbots and automated news generation have captured a lot of attention. The goal is to automatically generate readable text from tabular data or web data commonly represented in Resource Description Framework (RDF) format. The problem can then be formulated as Data-to-text (D2T) generation from structured non-linguistic data into human-readable natural language. Despite the significant work done for the English language, no efforts are being directed towards low-resource languages like the Arabic language. This work promotes the development of the first RDF data-to-text (D2T) generation system for the Arabic language while trying to address the low-resource limitation. We develop several models for the Arabic D2T task using transfer learning from large language models (LLM) such as AraBERT, AraGPT2, and mT5. These models include a baseline Bi-LSTM Sequence-to-Sequence (Seq2Seq) model, as well as encoder-decoder transformers like BERT2BERT, BERT2GPT, and T5. We then provide a detailed comparative study highlighting the strengths and limitations of these methods setting the stage for further advancement in the field. We also introduce a new Arabic dataset (AraWebNLG) that can be used for new model development in the field. To ensure a comprehensive evaluation, general-purpose automated metrics (BLEU and Perplexity scores) are used as well as task-specific human evaluation metrics related to the accuracy of the content selection and fluency of the generated text. The results highlight the importance of pre-training on a large corpus of Arabic data and show that transfer learning from AraBERT gives the best performance. Text-to-text pre-training using mT5 achieves second best performance results even with multilingual weights.
C1 [Touma, Roudy; Hajj, Hazem; El-Hajj, Wassim] Amer Univ Beirut, POB 11-0236, Beirut 1107, Lebanon.
   [Shaban, Khaled] Qatar Univ, POB 2713, Doha, Qatar.
C3 American University of Beirut; Qatar University
RP Touma, R (通讯作者)，Amer Univ Beirut, POB 11-0236, Beirut 1107, Lebanon.
EM rst10@mail.aub.edu; hh63@aub.edu.lb; we07@aub.edu.lb;
   khaled.shaban@qu.edu.qa
RI ; Shaban, Khaled/M-2768-2014
OI El-Hajj, Wassim/0000-0002-5206-2954; Hajj, Hazem/0000-0002-9954-7924;
   Shaban, Khaled/0000-0002-5688-7515
FU Qatar National Research Fund (Qatar Foundation) [NPRP13S-0112-200037]
FX This work was made possible by NPRP13S-0112-200037 grant from Qatar
   National Research Fund (a member of Qatar Foundation). The statements
   made herein are solely the responsibility of the authors.
CR Antoun W., 2021, P 6 ARABIC NATURAL L, P196
   Antoun Wissam, 2020, LREC 2020 WORKSHOP L
   Bizer C, 2009, IEEE INTELL SYST, V24, P87, DOI 10.1109/MIS.2009.102
   Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5016
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Darwish K, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1070
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   ElJundi O, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P68
   Ferreira Thiago, 2020, P 3 INT WORKSH NAT L
   Ferreira TC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P552
   Gardent C., 2017, P 10 INT C NAT LANG
   Hassan Hany, 2019, P 3RDWORKSHOP NEURAL, P289
   Kale Mihir, 2020, ARXIV200510433
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   Li Xintong, 2020, P 3 INT WORKSHOP NAT, P117
   Moryossef A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2267
   Mota Abelardo Vieira, 2020, Advances in Databases and Information Systems. 24th European Conference, ADBIS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12245), P157, DOI 10.1007/978-3-030-54832-2_13
   Parikh AP, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1173
   Puduppully R, 2019, AAAI CONF ARTIF INTE, P6908
   Puzikov Y., 2018, P 11 INT C NATURAL L, P463, DOI [10.18653/v1/w18-6557, DOI 10.18653/V1/W18-6557]
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21
   Rebuffel Clement, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P65, DOI 10.1007/978-3-030-45439-5_5
   Ribeiro L. F. R., 2021, P 3 WORKSH NAT LANG, V11, P211, DOI DOI 10.18653/V1/2021.NLP4CONVAI-1.20
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI [10.1162/tacl_a_.00313, 10.1162/tacl_a_00313]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wiseman S., 2017, P 2017 C EMPIRICAL M
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483
   Ye Rong, 2020, INT C LEARNING REPRE
NR 30
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR
PY 2023
VL 22
IS 4
AR 98
DI 10.1145/3582262
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9FI3
UT WOS:000998929700006
DA 2023-11-10
ER

PT J
AU Henderson, J
   Titov, I
AF Henderson, James
   Titov, Ivan
TI Incremental Sigmoid Belief Networks for Grammar Learning
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE Bayesian networks; dynamic Bayesian networks; grammar learning; natural
   language parsing; neural networks
AB We propose a class of Bayesian networks appropriate for structured prediction problems where the Bayesian network's model structure is a function of the predicted output structure. These incremental sigmoid belief networks (ISBNs) make decoding possible because inference with partial output structures does not require summing over the unboundedly many compatible model structures, due to their directed edges and incrementally specified model structure. ISBNs are specifically targeted at challenging structured prediction problems such as natural language parsing, where learning the domain's complex statistical dependencies benefits from large numbers of latent variables. While exact inference in ISBNs with large numbers of latent variables is not tractable, we propose two efficient approximations. First, we demonstrate that a previous neural network parsing model can be viewed as a coarse mean-field approximation to inference with ISBNs. We then derive a more accurate but still tractable variational approximation, which proves effective in artificial experiments. We compare the effectiveness of these models on a benchmark natural language parsing task, where they achieve accuracy competitive with the state-of-the-art. The model which is a closer approximation to an ISBN has better parsing accuracy, suggesting that ISBNs are an appropriate abstract model of natural language grammar learning.
C1 [Henderson, James] Univ Geneva, Dept Comp Sci, CH-1227 Carouge, Switzerland.
   [Titov, Ivan] Univ Saarland, MMCI Cluster Excellence, D-6600 Saarbrucken, Germany.
C3 University of Geneva; Saarland University
RP Henderson, J (通讯作者)，Univ Geneva, Dept Comp Sci, 7 Route Drize,Battelle Batiment A, CH-1227 Carouge, Switzerland.
EM JAMES.HENDERSON@UNIGE.CH; TITOV@MMCI.UNI-SAARLAND.DE
OI Henderson, James/0000-0003-3714-4799
FU Swiss NSF [PBGE22-119276]; European Commission (EC) [216594]; Excellence
   Cluster on Multimodal Computing and Interaction (MMCI) at Saarland
   University; Swiss National Science Foundation (SNF) [PBGE22-119276]
   Funding Source: Swiss National Science Foundation (SNF)
FX We would like to acknowledge support for this work from the Swiss NSF
   scholarship PBGE22-119276 and from the European Commission (EC) funded
   CLASSiC project (project number 216594 funded under EC FP7, Call 1), and
   the partial support of the Excellence Cluster on Multimodal Computing
   and Interaction (MMCI) at Saarland University. We would also like to
   thank Paola Merlo for extensive discussions and Mark Johnson for his
   helpful comments on this work.
CR [Anonymous], 2001, P 18 INT C MACH LEAR
   [Anonymous], P EMNLP
   [Anonymous], 2005, ACL, DOI DOI 10.3115/1219840.1219862
   [Anonymous], 2005, P 43 ANN M ASS COMP
   [Anonymous], 1999, P 37 ANN M ASS COMP
   Bikel DM, 2004, COMPUT LINGUIST, V30, P479, DOI 10.1162/0891201042544929
   BOTTOU L, 1991, THESIS U PARIS 11 PA
   Charniak E, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA132
   COLLINS M, 1999, THESIS U PENNSYLVANI
   DIACONIS P, 1983, SCI AM, V248, P116, DOI 10.1038/scientificamerican0583-116
   Durbin R., 1998, BIOL SEQUENCE ANAL P
   Finkel JR, 2008, P ACL08, P959
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gesmundo Andrea, 2009, P 13 C COMP NAT LANG, P37
   Henderson J, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P103
   HENDERSON J, 2008, P 12 C COMP NAT LANG, P178
   HENDERSON J, 2004, P 42 M ASS COMP LING
   HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Jordan MI., 1999, LEARNING GRAPHICAL M
   KURIHARA K, 2004, P INT JOINT C NAT LA
   Liang P., 2007, P 2007 JOINT C EMP M, P688
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Murphy K., 2002, THESIS U CALIFORNIA
   MUSILLO G, 2008, P 46 ANN M ASS COMP
   NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6
   PETROV S, 2007, P NAACL HLT 2007, P404
   Petrov S, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P433
   Prescher Detlef, 2005, P 9 INT WORKSH PARS, P115
   PRESS WH, 1996, NUMERICAL RECIPES
   Ratnaparkhi A., 1996, P C EMP METH NAT LAN, V1, P133
   Riezler S, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   ROHANIMANESH K, 2009, UMCS2009008
   Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318
   Sallans Brian, 2002, THESIS U TORONTO TOR
   Saul LK, 1996, J ARTIF INTELL RES, V4, P61, DOI 10.1613/jair.251
   SAUL LK, 1999, LEARNING GRAPHICAL M, P541
   SAVOVA V, 2005, AAAI, P1112
   SIMAAN K, 1992, GRAMMARS, V5, P125
   SOISALONSOININEN E, 1979, ACTA INFORM, V12, P339, DOI 10.1007/BF00268320
   TASKAR B, 2004, P C EMP METH NAT LAN
   TITOV I, 2007, P 10 INT C PARS TECH, P144
   Titov Ivan, 2006, P C EMP METH NAT LAN, P560
   TURIAN J, 2005, P 9 INT WORKSH PARS, P141
   TURIAN J, 2006, P ANN M ASS COMP LIN
   TURIAN J, 2006, P 20 C NEUR INF PROC
NR 46
TC 5
Z9 6
U1 0
U2 1
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD DEC
PY 2010
VL 11
BP 3541
EP 3570
PG 30
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA 712BO
UT WOS:000286637200009
DA 2023-11-10
ER

PT J
AU Lu, Y
   Guo, C
   Dou, Y
   Dai, XY
   Wang, FY
AF Lu, Yue
   Guo, Chao
   Dou, Yong
   Dai, Xingyuan
   Wang, Fei-Yue
TI Could ChatGPT Imagine: Content Control for Artistic Painting Generation
   Via Large Language Models
SO JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS
LA English
DT Article
DE Intelligent systems; Human-machine interactions; Artistic painting
   generation; Large language model; ChatGPT; Linguistic intelligence
ID PARALLEL; METAVERSES
AB Intelligent systems and human-machine interactions have consistently provided convenience in both work and daily life. Artificial Intelligence Generated Content (AIGC) can assist humans in artistic creation by generating painting images based on textual descriptions. However, the quality of generated painting images depends heavily on well-designed prompts, which are labor-intensive and time-consuming in painting creation. Large Language Models (LLMs) like ChatGPT have shown impressive performance in linguistic tasks such as question answering and logical inference, demonstrating strong linguistic intelligence. This paper proposes an assistant painting creation approach to provide precise content control for painting generation by combining LLMs with text-to-image generative models and evaluates the performance of the proposed approach on painting content generation and painting element arrangement. The experimental results show that our approach can provide clear guidance on rich painting content and reasonable arrangements of painting elements, demonstrating its ability of text-based painting scene imagination. In painting generation tasks, LLMs like ChatGPT can help the text-to-image models with precise control over the painting content and improve the overall painting results.
C1 [Lu, Yue] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Guo, Chao; Dai, Xingyuan; Wang, Fei-Yue] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.
   [Dou, Yong] Macao Univ Sci & Technol, Macao Inst Syst Engn, Macau 999078, Peoples R China.
C3 Shandong University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Macau University of Science & Technology
RP Wang, FY (通讯作者)，Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.
EM feiyue.wang@ia.ac.cn
FU This work is supported in part by Skywork Intelligence Culture amp;
   Technology LTD.; Skywork Intelligence Culture amp; Technology LTD.
FX This work is supported in part by Skywork Intelligence Culture &
   Technology LTD.
CR Antaki F., 2023, MEDRXIV, P2023
   Bang Y, 2023, Arxiv, DOI arXiv:2302.04023
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]
   Chen JQ, 2022, J INTELL ROBOT SYST, V105, DOI 10.1007/s10846-022-01648-7
   Dai XY, 2022, FRONT INFORM TECH EL, V23, P1795, DOI 10.1631/FITEE.2200323
   Ding BS, 2023, Arxiv, DOI arXiv:2212.10450
   do Nascimento LM, 2021, J INTELL ROBOT SYST, V102, DOI 10.1007/s10846-021-01364-8
   Fan LL, 2023, IEEE T SYST MAN CY-S, V53, P3485, DOI 10.1109/TSMC.2022.3227209
   Frieder S., 2023, ARXIV
   Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, 10.48550/arXiv.2301.07597]
   Guo C., 2019, CHIN J INTELL SCI TE, V1, P335
   Guo C, 2023, IEEE-CAA J AUTOMATIC, V10, P835, DOI 10.1109/JAS.2023.123555
   Guo C, 2023, IEEE T SYST MAN CY-S, V53, P2200, DOI 10.1109/TSMC.2022.3230406
   Guo C, 2022, J INTELL ROBOT SYST, V105, DOI 10.1007/s10846-022-01616-1
   Guo C, 2020, IEEE INT CON AUTO SC, P673, DOI [10.1109/case48305.2020.9216814, 10.1109/CASE48305.2020.9216814]
   Hao Y., 2022, ARXIV
   Hu W., 2023, PREPRINT
   Ishihara Y, 2021, J INTELL ROBOT SYST, V103, DOI 10.1007/s10846-021-01465-4
   Jeblick K, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.14882
   Jiao WX, 2023, Arxiv, DOI arXiv:2301.08745
   Kang MZ, 2023, IEEE T SYST MAN CY-S, V53, P3718, DOI 10.1109/TSMC.2022.3230830
   Karimov A, 2023, J INTELL ROBOT SYST, V107, DOI 10.1007/s10846-023-01831-4
   Kosinski M, 2023, Arxiv, DOI arXiv:2302.02083
   Li JJ, 2023, IEEE T SYST MAN CY-S, V53, P3389, DOI 10.1109/TSMC.2022.3226748
   Li XX, 2023, Arxiv, DOI arXiv:2212.10529
   Liu HL, 2022, J INTELL ROBOT SYST, V104, DOI 10.1007/s10846-021-01564-2
   Liu KH, 2023, IEEE T SYST MAN CY-S, V53, P3858, DOI 10.1109/TSMC.2022.3233588
   Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825
   Lu JW, 2022, IEEE-CAA J AUTOMATIC, V9, P2079, DOI 10.1109/JAS.2022.106094
   LU J, 2022, FRONT INFORM TECH EL, V23, P991, DOI 10.1631/FITEE.2240000
   Lu Y, 2023, IEEE INTELL SYST, V38, P31, DOI 10.1109/MIS.2023.3260992
   Lu Y, 2022, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2022.3223539
   Lu Y, 2022, NEUROCOMPUTING, V490, P163, DOI 10.1016/j.neucom.2022.01.068
   [鲁越 Lu Yue], 2020, [自动化学报, Acta Automatica Sinica], V46, P2239
   Mitrovic S., 2023, ARXIV
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Nichol A. Q., 2022, ICML, P16784
   Oppenlaender J, 2022, Arxiv, DOI [arXiv:2204.13988, DOI 10.48550/ARXIV.2204.13988]
   Ouyang L., 2022, ADV NEURAL INFORM PR
   Qiao SF, 2023, Arxiv, DOI arXiv:2212.09597
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, ARXIV, DOI [10.48550/arXiv.2204.06125, DOI 10.48550/ARXIV.2204.06125]
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Saharia Chitwan, 2022, ADV NEURAL INFORM PR, V2
   Shen Y, 2022, IEEE-CAA J AUTOMATIC, V9, P2047, DOI 10.1109/JAS.2022.106115
   Song HF, 2022, J INTELL ROBOT SYST, V106, DOI 10.1007/s10846-022-01652-x
   Strathearn C, 2021, J INTELL ROBOT SYST, V101, DOI 10.1007/s10846-021-01332-2
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Wang F-Y., 2017, PARALLEL ART INTELLI
   Wang Fei-yue, 2004, Control and Decision, V19, P485
   Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486
   Wang FY, 2022, FRONT INFORM TECH EL, V23, P1142, DOI 10.1631/FITEE.2100418
   Wang J., 2022, IEEE T SYST MAN CY-S, P1
   Wang KF, 2017, ARTIF INTELL REV, V48, P299, DOI 10.1007/s10462-017-9569-z
   Wang X., 2022, IEEE T SYST MAN CY-S, P1
   Wang XJ, 2022, IEEE-CAA J AUTOMATIC, V9, P2055, DOI 10.1109/JAS.2022.106103
   Wang Y., 2023, PREPRINT
   Wang Y., 2022, IEEE T SYST MAN CY-S, P1
   Wang YT, 2022, IEEE-CAA J AUTOMATIC, V9, P2071, DOI 10.1109/JAS.2022.106091
   Wei J., 2022, ADV NEURAL INFORM PR, V35, P24824
   Yang J, 2022, IEEE-CAA J AUTOMATIC, V9, P2063, DOI 10.1109/JAS.2022.106097
   Ye PJ, 2022, FRONT INFORM TECH EL, V23, P1765, DOI 10.1631/FITEE.2100335
   Yue Lu, 2021, 2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI), P156, DOI 10.1109/DTPI52967.2021.9540081
   Zhang B, 2021, Arxiv, DOI arXiv:2104.03133
   Zhang H., 2022, IEEE T SYST MAN CY-S, P1
   Zhou J, 2023, FRONT INFORM TECH EL, DOI 10.1631/FITEE.2300089
   Zhu BH, 2023, Arxiv, DOI arXiv:2301.11270
NR 68
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-0296
EI 1573-0409
J9 J INTELL ROBOT SYST
JI J. Intell. Robot. Syst.
PD OCT
PY 2023
VL 109
IS 2
AR 39
DI 10.1007/s10846-023-01956-6
PG 15
WC Computer Science, Artificial Intelligence; Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Robotics
GA U3DA1
UT WOS:001083626300001
DA 2023-11-10
ER

PT J
AU Changrampadi, MH
   Shahina, A
   Narayanan, MB
   Khan, AN
AF Changrampadi, Mohamed Hashim
   Shahina, A.
   Narayanan, M. Badri
   Khan, A. Nayeemulla
TI End-to-End Speech Recognition of Tamil Language
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE End to end speech recognition; deep learning; under-resourced language;
   semi-supervised speech corpus development
ID SYSTEM; ASR
AB Research in speech recognition is progressing with numerous state-ofthe-art results in recent times. However, relatively fewer research is being carried out in Automatic Speech Recognition (ASR) for languages with low resources. We present a method to develop speech recognition model with minimal resources using Mozilla DeepSpeech architecture. We have utilized freely available online computational resources for training, enabling similar approaches to be carried out for research in a low-resourced languages in a financially constrained environments. We also present novel ways to build an efficient language model from publicly available web resources to improve accuracy in ASR. The proposed ASR model gives the best result of 24.7% Word Error Rate (WER), compared to 55% WER by Google speech-to-text. We have also demonstrated a semi-supervised development of speech corpus using our trained ASR model, indicating a cost effective approach of building large vocabulary corpus for low resource language. The trained Tamil ASR model and the training sets are released in public domain and are available on GitHub.
C1 [Changrampadi, Mohamed Hashim] C Abdul Hakeem Coll Engn & Technol, Dept Elect & Commun Engn, Melvisharam 632509, India.
   [Shahina, A.; Narayanan, M. Badri] Sri Sivasubramaniya Nadar Coll Engn, Dept Informat Technol, Kalavakkam 603110, India.
   [Khan, A. Nayeemulla] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
C3 C. Abdul Hakeem College of Engineering & Technology; SSN College of
   Engineering; Vellore Institute of Technology (VIT); VIT Chennai
RP Changrampadi, MH (通讯作者)，C Abdul Hakeem Coll Engn & Technol, Dept Elect & Commun Engn, Melvisharam 632509, India.
EM hashim@alumni.chalmers.se
OI Narayanan, M Badri/0000-0002-6449-0323; Changrampadi, Mohamed
   Hashim/0000-0003-1852-0998
CR Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2021, CENTR I IND LANG
   Ardila Rosana, 2019, ARXIV191206670
   Arora G., 2020, P 2 WORKSHOP NLP OPE, P66, DOI [10.18653/v1/2020.nlposs-1.10, DOI 10.18653/V1/2020.NLPOSS-1.10]
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Billa J, 2018, INTERSPEECH, P3207, DOI 10.21437/Interspeech.2018-2473
   Chan W., 2021, WORKSH MACH LEARN SP
   Chen YC, 2020, INTERSPEECH, P1803, DOI 10.21437/Interspeech.2020-1315
   Fathima N, 2018, INTERSPEECH, P3197, DOI 10.21437/Interspeech.2018-2117
   Hannun A., 2017, DISTILL, V2, P8
   Hannun Awni, 2014, ARXIV14125567
   He F, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6494
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Inaguma H, 2019, INT CONF ACOUST SPEE, P6096, DOI 10.1109/ICASSP.2019.8682918
   Karunanayake Y, 2019, INT CONF ASIAN LANG, P234, DOI [10.1109/IALP48816.2019.9037702, 10.1109/ialp48816.2019.9037702]
   Liu C., 2020, P 1 JOINT WORKSHOP S, P46
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Madhavaraj A, 2018, INTERSPEECH, P1966
   Madhavaraj A., 2017, 2017 14 IEEE IND COU, P1
   Mahar SA, 2021, INTELL AUTOM SOFT CO, V29, P183, DOI 10.32604/iasc.2021.015755
   Mohan Krishna Doss, 2018, WORKSHOP SPOKEN LANG, P11
   Mustageem, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122133
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Mustaqeem, 2021, CMC-COMPUT MATER CON, V67, P4039, DOI 10.32604/cmc.2021.015070
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   ONeill P. K., 2021, INTERSPEECH
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Pulugundla B, 2018, INTERSPEECH, P3182, DOI 10.21437/Interspeech.2018-1302
   Raza AA, 2018, INTERSPEECH, P1021
   Shi XJ, 2015, ADV NEUR IN, V28
   Wang C., 2020, ARXIV200710310
   Zhang Y., 2020, J AMB INTEL HUM COMP
NR 33
TC 7
Z9 7
U1 0
U2 19
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2022
VL 32
IS 2
BP 1309
EP 1323
DI 10.32604/iasc.2022.022021
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA XA7TM
UT WOS:000720844200017
OA hybrid
DA 2023-11-10
ER

PT J
AU Razzak, MI
   Anwar, F
   Husain, SA
   Belaid, A
   Sher, M
AF Razzak, Muhammad Imran
   Anwar, Fareeha
   Husain, S. A.
   Belaid, Abdel
   Sher, Muhammad
TI HMM and fuzzy logic: A hybrid approach for online Urdu script-based
   languages' character recognition
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Fuzzy logic; HMM; Hybrid model; Segmentation free; Online handwriting
   character recognition
ID HIDDEN MARKOV MODEL; HANDWRITTEN; SEGMENTATION
AB Urdu script-based languages' character recognition has some technical issues not existing in other languages and makes these languages more complicated. Segmentation-based character recognition approach for handwritten Urdu, both Nasta'liq and Nasakh script-based languages, incorporates number of overhead and very less accurate as compared to segmentation free. This paper presents a segmentation-free approach for recognition of online Urdu handwritten script using hybrid classifier, HMM and fuzzy logic. Trained data set consisting of HMMs for each stroke is further classified into 62 sub-patterns based on the primary stroke shape at the beginning and end using fuzzy rule. Fuzzy linguistic variables based on language structure are used to model features and provide suitable result for large variation in handwritten strokes. Twenty-six time variant structural and statistical features are extracted for the base strokes. The fuzzy classification into sub-patterns increases the efficiency and decreases the computational complexity due to reduction in data set size. The hybrid HMM-fuzzy technique is efficient for large and complex data set. It provided 87.6% and 74.1% for Nasta'liq and Nasakh, respectively, on 1800 ligatures. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Razzak, Muhammad Imran; Anwar, Fareeha; Sher, Muhammad] Int Islamic Univ, Islamabad, Pakistan.
   [Belaid, Abdel] LORIA, READ, Nancy, France.
   [Husain, S. A.] Air Univ, Islamabad, Pakistan.
C3 International Islamic University, Pakistan; Universite de Lorraine; Air
   University Islamabad
RP Razzak, MI (通讯作者)，Int Islamic Univ, Islamabad, Pakistan.
EM imran.mian@yahoo.com; fareehaanwar@iiu.edu.pk; afaq.husain@mail.edu.pk;
   a.belaid@loria.fr; m.sher@iiu.edu.pk
RI Ramzan, Muhammad Sher/N-6832-2019; Razzak, Imran/AEW-5139-2022
OI Ramzan, Muhammad Sher/0000-0001-6752-0033; Razzak,
   Imran/0000-0002-3930-6600
CR ADEED SA, 2000, 16 INT C PATT REC IC
   ADEED SA, 2004, KNOWL-BASED SYST, V17, P75
   AHN JH, 2009, 7 INT C ADV PATT REC
   [Anonymous], 2006, P 10 INT WORKSH FRON
   BENOUARETH A, 2008, EURASIP J ADV SIG PR, V8, P1
   BIADSY F, 2009, INT J PATTERN RECOGN
   Borji A, 2008, NEURAL PROCESS LETT, V28, P97, DOI 10.1007/s11063-008-9084-y
   CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074
   Douglas David H, 1973, CARTOGRAPHICA INT J, DOI [DOI 10.1002/9780470669488.CH2, 10.3138/FM57-6770-U75U-7727, DOI 10.3138/FM57-6770-U75U-7727]
   Elanwar RI, 2007, PROC WRLD ACAD SCI E, V23, P288
   FITZGERALD JA, 2005, 4 MEX INT C ART INT, P843
   Hadavandi E, 2010, KNOWL-BASED SYST, V23, P800, DOI 10.1016/j.knosys.2010.05.004
   Hanmandlu M, 2003, PATTERN RECOGN, V36, P603, DOI 10.1016/S0031-3203(02)00069-9
   Herawan T, 2010, KNOWL-BASED SYST, V23, P220, DOI 10.1016/j.knosys.2009.12.003
   Husain S.A., 2007, IAPR MACH VIS APPL M
   HUSSAIN M, 2005, 9 INT MULT C KAR
   Khorsheed MS, 2003, PATTERN RECOGN LETT, V24, P2235, DOI 10.1016/S0167-8655(03)00050-3
   KOSMALA A, 1998, 6 INT WORKSH FRONT H
   MALIK S, 2005, P IEEE S EM TECHN IS
   MITSURU M, 2001, SUBSTROKE APPROACH H
   Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644
   NAKAI M, 2001, 6 INT C DOC AN REC I
   Pechwitz M, 2003, PROC INT CONF DOC, P890
   PECHWITZ M, 2002, P 8 INT WORKSH FRONT
   Razzak Muhammad Imran, 2010, ICIC Express Letters, V4, P571
   Razzak M. I., 2009, INT MULT ENG COMP SC
   RAZZAK MI, THESIS INT ISLAMIC U, P50
   RAZZAK MI, THESIS INT ISLAMIC U, P100
   RAZZAK MI, 2009, INT C ENG TECHN ISL
   Saabni R, 2009, 10 INT C DOC AN REC
   Sternby J, 2009, PATTERN RECOGN, V42, P3278, DOI 10.1016/j.patcog.2008.12.017
   TAKASHI HS, 2003, P 7 INT C DOC AN REC
   Zeng J, 2007, KNOWL-BASED SYST, V20, P607, DOI 10.1016/j.knosys.2007.09.001
NR 33
TC 33
Z9 35
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD DEC
PY 2010
VL 23
IS 8
BP 914
EP 923
DI 10.1016/j.knosys.2010.06.007
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 654YV
UT WOS:000282208200019
DA 2023-11-10
ER

PT J
AU Naseem, U
   Razzak, I
   Khan, SK
   Prasad, M
AF Naseem, Usman
   Razzak, Imran
   Khan, Shah Khalid
   Prasad, Mukesh
TI A Comprehensive Survey on Word Representation Models: From Classical to
   State-of-the-Art Word Representation Language Models
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Text mining; natural language processing; word representation; language
   models
ID LOGISTIC-REGRESSION; SENTIMENT; EMBEDDINGS; CLASSIFICATION; FRAMEWORK;
   CONTEXT
AB Word representation has always been an important research area in the history of natural language processing (NLP). Understanding such complex text data is imperative, given that it is rich in information and can be used widely across various applications. In this survey, we explore different word representation models and its power of expression, from the classical to modern-day state-of-the-art word representation language models (LMS). We describe a variety of text representation methods, and model designs have blossomed in the context of NLP, including SOTA LMs. These models can transform large volumes of text into effective vector representations capturing the same semantic information. Further, such representations can be utilized by various machine learning (ML) algorithms for a variety of NLP-related tasks. In the end, this survey briefly discusses the commonly used ML- and DL-based classifiers, evaluation metrics, and the applications of these word embeddings in different NLP tasks.
C1 [Naseem, Usman] Univ Sydney, Sch Comp Sci, Sydney, NSW, Australia.
   [Razzak, Imran] Deakin Univ, Sch Informat Technol, Burwood, Australia.
   [Khan, Shah Khalid] RMIT Univ, Sch Engn, Melbourne, Vic, Australia.
   [Prasad, Mukesh] Univ Technol Sydney, Sch Comp Sci, Sydney, NSW, Australia.
C3 University of Sydney; Deakin University; Royal Melbourne Institute of
   Technology (RMIT); University of Technology Sydney
RP Naseem, U (通讯作者)，Univ Sydney, Sch Comp Sci, Sydney, NSW, Australia.
EM usman.naseem@sydney.edu.au; imran.razzak@deakin.edu.au;
   s3680269@student.rmit.edu.au; Mukesh.Prasad@uts.edu.au
RI Razzak, Imran/AEW-5139-2022; Naseem, Usman/AAA-1052-2021
OI Razzak, Imran/0000-0002-3930-6600; Naseem, Usman/0000-0003-0191-7171;
   Prasad, Mukesh/0000-0002-7745-9667; Khan, Shah
   Khalid/0000-0003-1317-8636
CR Agarwal Apoorv, 2011, SENTIMENT ANAL TWITT
   Aggarwal C.C., 2012, MINING TEXT DATA, P163, DOI 10.1007/978-1-4614-3223-4_6
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   Ali F., 2019, INDIAN J SCI TECHNOL, V12, P1, DOI DOI 10.17485/ijst/2019/v12i45/146538
   Altszyler E, 2016, ABS161001520 CORR, DOI DOI 10.1016/J.CONCOG.2017.09.004ABS/1610.0
   [Anonymous], 2014, RETROFITTING WORD VE
   [Anonymous], 2010, TWITTER CORPUS SENTI
   [Anonymous], 2014, C EMPIRICAL METHODS
   [Anonymous], 1988, DOCUMENT RETRIEVAL S
   [Anonymous], 2015, P WORKSHOP NOISY USE
   Balahur A., 2013, 4 WORKSH COMP APPR S, P120
   Balazs JA, 2016, INFORM FUSION, V27, P95, DOI 10.1016/j.inffus.2015.06.002
   Bansal Himani, 2018, SOCIAL NETWORK ANALY, DOI [10.4018/978-1-5225-5097-6, DOI 10.4018/978-1-5225-5097-6]
   Bao YW, 2014, LECT NOTES ARTIF INT, V8589, P615, DOI 10.1007/978-3-319-09339-0_62
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bermingham A., 2011, USING TWITTER MONITO, P2, DOI DOI 11-3700
   Boia M, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P345, DOI 10.1109/SocialCom.2013.54
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Bolukbasi T, 2016, ADV NEUR IN, V29
   Camacho-Collados J, 2016, ARTIF INTELL, V240, P36, DOI 10.1016/j.artint.2016.07.005
   Cambria E, 2018, AAAI CONF ARTIF INTE, P1795
   Carreras L., 2001, PROC 4 INT C RECENT, P58
   Castelluccil G, 2015, LECT NOTES COMPUT SC, V9103, P73, DOI 10.1007/978-3-319-19581-0_6
   Celebi Arda, 2016, SEGMENTING HASHTAGS
   Chen Wei James, 2017, COMP STUDY LOGISTIC
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Chung J, 2014, NIPS 2014 WORKSH DEE, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Clark Kevin, 2020, ICLR
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Devlin J., 2018, ARXIV, V1, P4171
   Dhingra Bhuwan, 2017, ABS170300993 CORR
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Edel Greevy, 2004, AUTOMATIC TEXT CATEG
   Elekes A, 2020, INT J DIGIT LIBRARIE, V21, P109, DOI 10.1007/s00799-018-0237-y
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Foster J., 2011, 5 INT JOINT C NATURA, P893
   Fu XH, 2017, NEUROCOMPUTING, V241, P18, DOI 10.1016/j.neucom.2017.01.079
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Giachanou Anastasia, 2017, SENTIMENT PROPAGATIO, DOI [10.1007/978-3-319-56608-5_18, DOI 10.1007/978-3-319-56608-5_18]
   Gimpel Kevin, PART OF SPEECH TAGGI
   Giovanelli C, 2017, IEEE IND ELEC, P7514, DOI 10.1109/IECON.2017.8217316
   Gupta Vishal, 2009, Journal of Emerging Technologies in Web Intelligence, V1, P60, DOI 10.4304/jetwi.1.1.60-76
   Haddi E, 2013, PROCEDIA COMPUT SCI, V17, P26, DOI 10.1016/j.procs.2013.05.005
   Hammouda KM, 2004, IEEE T KNOWL DATA EN, V16, P1279, DOI 10.1109/TKDE.2004.58
   He Y., 2011, P 49 ANN M ASS COMPU, P123, DOI DOI 10.1007/978-3-319-18458-6_3
   Herbelot Aurelie, 2017, P 2017 C EMP METH NA, P304
   HILL BM, 1968, J AM STAT ASSOC, V63, P677, DOI 10.2307/2284038
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu Xia, 2012, MINING TEXT DATA, P385, DOI [10.1007/978-1-4614-3223-4_12, DOI 10.1007/978-1-4614-3223-4_12]
   Iacobacci I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P95
   Ilic S, 2018, P 9 WORKSHOP COMPUTA, P2, DOI [DOI 10.18653/V1/W18-6202, 10.18653/v1/w18-6202]
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaggi M, 2021, APPL SYST INNOV, V4, DOI 10.3390/asi4010013
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Joulin Armand, 2016, ARXIV160701759
   Keskar Nitish Shirish, 2019, CTRL CONDITIONAL TRA
   Khan FH, 2014, DECIS SUPPORT SYST, V57, P245, DOI 10.1016/j.dss.2013.09.004
   Korde Vandana, 2012, TEXT CLASSIFICATION
   Kouloumpis E., 2011, ICWSM
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, P1621, DOI DOI 10.5555/2891460.2891697
   Lample Guillaume, 2019, NEURIPS
   Lan Z., 2020, CORR, P1
   Larson RR, 2010, J AM SOC INF SCI TEC, V61, P852, DOI 10.1002/asi.21234
   Lauren P, 2018, NEUROCOMPUTING, V277, P129, DOI 10.1016/j.neucom.2017.01.117
   Le Q, 2014, INT C MACHINE LEARNI, V32, DOI [DOI 10.1145/2740908.2742760, 10.5555/3044805.3045025]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ledell Adam Fisch, 2017, ARXIVCSCL170903856
   Lee J., 2019, AM J SPEECH-LANG PAT, DOI DOI 10.1044/2019_AJSLP-CAC48-18-0220
   Lewis M, 2019, ARXIV
   Lin C., 2009, P 18 ACM C INF KNOWL, P375, DOI 10.1145/1645953.1646003
   Liu PF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1284
   Liu Shuhua, 2014, 6th International Conference on Knowledge Discovery and Information Retrieval (KDIR 2014). Proceedings, P530
   Liu Yinhan, 2019, ARXIV190711692
   Liu YC, 2018, NEUROCOMPUTING, V275, P2287, DOI 10.1016/j.neucom.2017.11.005
   Magerman D.M., 1995, P 33 ANN M ASS COMP
   MANDIC D, 2001, RECURRENT NEURAL NET, DOI 10.1002/047084535X
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   McCann Bryan, 2017, ADV NEURAL INFORM PR, P6297
   Mejova Y., 2011, EXPLORING FEATURE DE
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, P51, DOI DOI 10.18653/V1/K16-1006
   Melville P, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1275
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mohammad S., 2013, 2 JOINT C LEX COMP S, P321, DOI DOI 10.3115/V1/S14-2077
   MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276
   Mrksic Nikola, 2017, T ASS COMPUTATIONAL, V5, P309
   Mullen T., 2006, PROC AAAI SPRING S C, P159
   Muller Martin, 2020, ARXIV200507503
   Naili M, 2017, PROCEDIA COMPUT SCI, V112, P340, DOI 10.1016/j.procs.2017.08.009
   Narayanan V, 2013, LECT NOTES COMPUT SC, V8206, P194, DOI 10.1007/978-3-642-41278-3_24
   Naseem Usman, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P953, DOI 10.1109/ICDAR.2019.00157
   Naseem U., 2020, ARXIV200909223
   Naseem U, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207237
   Naseem U, 2021, IEEE T COMPUT SOC SY, V8, P1003, DOI 10.1109/TCSS.2021.3051189
   Naseem U, 2021, APPL SYST INNOV, V4, DOI 10.3390/asi4010023
   Naseem U, 2021, MULTIMED TOOLS APPL, V80, P35239, DOI 10.1007/s11042-020-10082-6
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Naseem U, 2019, LECT NOTES ARTIF INT, V11919, P381, DOI 10.1007/978-3-030-35288-2_31
   Naseem Usman, 2020, THESIS U TECHNOLOGY
   Naseem Usman, 2019, AUSTR J INTELLIGENT, V15, P69
   Neelakantan Arvind, 2015, EFFICIENT NONPARAMET
   Niebler Thomas, 2017, ABS170507425 CORR
   Nogueira CSD, 2014, P COLING 2014 25 INT, P69, DOI DOI 10.1109/ICCAR.2017.7942788
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pascanu R., 2013, P 30 INT C MACHINE L
   Patriche CV, 2016, PEDOSPHERE, V26, P335, DOI 10.1016/S1002-0160(15)60047-9
   Pinter Y., 2017, P 2017 C EMPIRICAL M, P102
   Qin PD, 2016, NEUROCOMPUTING, V190, P1, DOI 10.1016/j.neucom.2015.12.091
   Qu ZW, 2018, INT CONF BIG DATA, P677, DOI 10.1109/BigComp.2018.00124
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877
   QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Rehman Arshia, 2019, AUST J INTELL INF PR, V15, P53
   Ren YF, 2016, AAAI CONF ARTIF INTE, P215
   Reuter J., 2016, INT J NAT LANG COMPU, V5, P23, DOI 10.5121/ijnlc.2016.5402
   Rezaeinia S. Mahdi, 2017, ARXIV171108609
   Saif H, 2013, P 1 INT WORKSH EM SE
   Saloot Mohammad Arshi, 2015, WORKSH NOIS US GEN T
   Sanh Victor, 2019, ARXIV191001108
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Seungil David Ding, 2017, ARXIVSTATML170906680
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Shoeybi M., 2019, ARXIV
   Singh T, 2016, PROCEDIA COMPUT SCI, V89, P549, DOI 10.1016/j.procs.2016.06.095
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Soheily-Khah Saeid, 2017, INTRUSION DETECTION
   Song K., 2019, ARXIV PREPRINT ARXIV
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Sun Yu, 2019, ARXIV190409223
   Sutskever I, 2011, ICML
   Suttles Jared, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P121, DOI 10.1007/978-3-642-37256-8_11
   Symeonidis S, 2018, EXPERT SYST APPL, V110, P298, DOI 10.1016/j.eswa.2018.06.022
   Tan AH, 1999, P PAKDD WORKSH KNOWL, P65
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   Tang DY, 2015, IEEE-ACM T AUDIO SPE, V23, P1750, DOI 10.1109/TASLP.2015.2449071
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Wei, 2019, ARXIV190804577
   Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P587, DOI 10.1109/SocialCom-PASSAT.2012.119
   Wang Yequan, 2016, P 2016 C EMP METH NA, P606, DOI [DOI 10.18653/V1/D16-1058, 10.18653/v1/D16-1058]
   Wang YY, 2012, ASTROPHYS J, V756, DOI 10.1088/0004-637X/756/1/67
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zhang T, 2014, ARXIV14121058
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhao JQ, 2017, IEEE ACCESS, V5, P2870, DOI 10.1109/ACCESS.2017.2672677
   Zhao JQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P748, DOI 10.1109/SmartCity.2015.158
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 160
TC 33
Z9 33
U1 4
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP
PY 2021
VL 20
IS 5
AR 74
DI 10.1145/3434237
PG 35
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XB8PL
UT WOS:000721584900004
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Arumugam, D
   Karamcheti, S
   Gopalan, N
   Williams, EC
   Rhee, M
   Wong, LLS
   Tellex, S
AF Arumugam, Dilip
   Karamcheti, Siddharth
   Gopalan, Nakul
   Williams, Edward C.
   Rhee, Mina
   Wong, Lawson L. S.
   Tellex, Stefanie
TI Grounding natural language instructions to semantic goal representations
   for abstraction and generalization
SO AUTONOMOUS ROBOTS
LA English
DT Article
AB Language grounding is broadly defined as the problem of mapping natural language instructions to robot behavior. To truly be effective, these language grounding systems must be accurate in their selection of behavior, efficient in the robot's realization of that selected behavior, and capable of generalizing beyond commands and environment configurations only seen at training time. One choice that is crucial to the success of a language grounding model is the choice of representation used to capture the objective specified by the input command. Prior work has been varied in its use of explicit goal representations, with some approaches lacking a representation altogether, resulting in models that infer whole sequences of robot actions, while other approaches map to carefully constructed logical form representations. While many of the models in either category are reasonably accurate, they fail to offer either efficient execution or any generalization without requiring a large amount of manual specification. In this work, we take a first step towards language grounding models that excel across accuracy, efficiency, and generalization through the construction of simple, semantic goal representations within Markov decision processes. We propose two related semantic goal representations that take advantage of the hierarchical structure of tasks and the compositional nature of language respectively, and present multiple grounding models for each. We validate these ideas empirically with results collected from following text instructions within a simulated mobile-manipulator domain, as well as demonstrations of a physical robot responding to spoken instructions in real time. Our grounding models tie abstraction in language commands to a hierarchical planner for the robot's execution, enabling a response-time speed-up of several orders of magnitude over baseline planners within sufficiently large domains. Concurrently, our grounding models for generalization infer elements of the semantic representation that are subsequently combined to form a complete goal description, enabling the interpretation of commands involving novel combinations never seen during training. Taken together, our results show that the design of semantic goal representation has powerful implications for the accuracy, efficiency, and generalization capabilities of language grounding models.
C1 [Arumugam, Dilip; Karamcheti, Siddharth; Gopalan, Nakul; Williams, Edward C.; Wong, Lawson L. S.] Brown Univ, Providence, RI 02912 USA.
   [Rhee, Mina] Brown Univ, Comp Sci, Providence, RI 02912 USA.
   [Tellex, Stefanie] Brown Univ, Engn, Providence, RI 02912 USA.
C3 Brown University; Brown University; Brown University
RP Karamcheti, S (通讯作者)，Brown Univ, Providence, RI 02912 USA.
EM sidd.karamcheti@gmail.com
FU National Science Foundation [IIS-1637614]; US Army/DARPA
   [W911NF-15-1-0503]; National Aeronautics and Space Administration
   [NNX16AR61G]; Croucher Foundation Fellowship
FX This work is supported by the National Science Foundation under Grant
   Number IIS-1637614, the US Army/DARPA under Grant Number
   W911NF-15-1-0503, and the National Aeronautics and Space Administration
   under Grant Number NNX16AR61G. Lawson L.S. Wong was supported by a
   Croucher Foundation Fellowship.
CR [Anonymous], 1997, GRACE HOPPER CELEBRA
   Artzi Yoav, 2013, ANN M ASS COMP LING
   Arumugam D, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Chen David L., 2011, AAAI C ART INT
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Chung J., 2014, CORR
   Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227, DOI 10.1613/jair.639
   Dzifcak J, 2009, IEEE INT CONF ROBOT, P3768
   Gopalan N., 2017, INT C AUT PLANN SCHE
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard TM, 2014, IEEE INT CONF ROBOT, P6652, DOI 10.1109/ICRA.2014.6907841
   Iyyer M., 2015, ANN M ASS COMP LING
   Jong N. K., 2008, P 25 INT C MACHINE L, P1
   Junghanns Andreas, 1997, INT JOINT C ART INT
   Karamcheti Siddharth, 2017, ANN M ASS COMP LING
   Kingma D. P., 2014, C TRACK P
   Liang P, 2016, COMMUN ACM, V59, P68, DOI 10.1145/2866568
   Littman M.L., 2008, P 25 INT C MACHINE L, P240, DOI [10.1145/1390156.1390187, DOI 10.1145/1390156.1390187]
   MacGlashan J, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   MacMahon M., 2006, NAT C ART INT
   Matuszek C., 2012, INT S EXP ROB
   McMahan H. Brendan, 2005, INT C MACH LEARN
   Mikolov T., 2011, IEEE INT C AC SPEECH
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mikolov Tomas, 2013, INT C LEARN REPR
   Ng A. Y., 2000, INT C MACHINE LEARNI
   Paul R, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Reed Scott, 2016, INT C LEARN REPR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1
   Tellex S, 2011, P 25 AAAI C ART INT, P1507
   Winograd T., 1971, PROCEDURES REPRESENT
   Yamada Tatsuro, 2016, INT C ART NEUR NETW
   Zelle J. M., 1996, NAT C ART INT
   Zettlemoyer Luke S., 2005, P 21 C UNC ART INT, P658
NR 41
TC 6
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0929-5593
EI 1573-7527
J9 AUTON ROBOT
JI Auton. Robot.
PD FEB
PY 2019
VL 43
IS 2
SI SI
BP 449
EP 468
DI 10.1007/s10514-018-9792-8
PG 20
WC Computer Science, Artificial Intelligence; Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Robotics
GA HM5JW
UT WOS:000459513000012
DA 2023-11-10
ER

PT J
AU Liu, YG
   Chen, WY
   Liu, HW
   Zhang, Y
   Zhang, ML
   Qu, H
AF Liu, Yuguo
   Chen, Wenyu
   Liu, Hanwen
   Zhang, Yun
   Zhang, Malu
   Qu, Hong
TI Biologically Plausible Sparse Temporal Word Representations
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Sparse coding; spiking neuron model; word representation
ID SPIKING; RECOGNITION
AB Word representations, usually derived from a large corpus and endowed with rich semantic information, have been widely applied to natural language tasks. Traditional deep language models, on the basis of dense word representations, requires large memory space and computing resource. The brain-inspired neuromorphic computing systems, with the advantages of better biological interpretability and less energy consumption, still have major difficulties in the representation of words in terms of neuronal activities, which has restricted their further application in more complicated downstream language tasks. Comprehensively exploring the diverse neuronal dynamics of both integration and resonance, we probe into three spiking neuron models to post-process the original dense word embeddings, and test the generated sparse temporal codes on several tasks concerning both word-level and sentence-level semantics. The experimental results show that our sparse binary word representations could perform on par with or even better than original word embeddings in capturing semantic information, while requiring less storage. Our methods provide a robust representation foundation of language in terms of neuronal activities, which could potentially be applied to future downstream natural language tasks under neuromorphic computing systems.
C1 [Liu, Yuguo; Chen, Wenyu; Liu, Hanwen; Zhang, Yun; Zhang, Malu; Qu, Hong] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Qu, H (通讯作者)，Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
EM liuyuguo@std.uestc.edu.cn; cwy@uestc.edu.cn; lhwen1998@std.uestc.edu.cn;
   zhangyun@std.uestc.edu.cn; maluzhang@uestc.edu.cn; hongqu@uestc.edu.cn
OI Liu, Yuguo/0000-0002-6767-7804; Zhang, Malu/0000-0002-2345-0974
FU National Key Research and Development Program of China [2018AAA0100202];
   National Science Foundation of China [62236007, 61976043]; Science and
   Technology Support Program of Sichuan Province [2022YFG0313]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018AAA0100202,in part by the
   National Science Foundation of China under Grant 62236007 and Grant
   61976043, and in part by the Science and Technology Support Program of
   Sichuan Province under Grant 2022YFG0313.
CR Agirre E., 2009, HUMAN LANGUAGE TECHN
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   [Anonymous], 2010, DYNAMICAL SYSTEMS NE
   Auge D, 2021, LECT NOTES COMPUT SC, V12895, P245, DOI 10.1007/978-3-030-86383-8_20
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bhatia P, 2019, PLASMONICS, V14, P611, DOI 10.1007/s11468-018-0839-7
   Bialas Marcin, 2020, Parallel Problem Solving from Nature - PPSN XVI. 16th International Conference, PPSN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12269), P433, DOI 10.1007/978-3-030-58112-1_30
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Chang J., 2009, NEURAL INFORM PROCES, V22, P288
   Chen Y, 2021, AAAI CONF ARTIF INTE, V35, P7073
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Eguíluz VM, 2000, PHYS REV LETT, V84, P5232, DOI 10.1103/PhysRevLett.84.5232
   Faruqui M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1491
   Frady EP, 2022, J SIGNAL PROCESS SYS, V94, P917, DOI 10.1007/s11265-022-01772-5
   Frady EP, 2019, P NATL ACAD SCI USA, V116, P18050, DOI 10.1073/pnas.1902653116
   Gerstner W, 2014, NEURONAL DYNAMICS: FROM SINGLE NEURONS TO NETWORKS AND MODELS OF COGNITION, P1, DOI 10.1017/CBO9781107447615
   Gerz D, 2016, Arxiv, DOI arXiv:1608.00869
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Hinton G.E, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI DOI 10.1109/69.917563
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Hoppensteadt FC, 1998, BIOSYSTEMS, V48, P85, DOI 10.1016/S0303-2647(98)00053-7
   Hoppensteadt FC, 2000, IEEE T NEURAL NETWOR, V11, P734, DOI 10.1109/72.846744
   Huang L, 2022, IEEE T CYBERNETICS, V52, P5828, DOI 10.1109/TCYB.2020.3042230
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Izhikevich EM, 2000, INT J BIFURCAT CHAOS, V10, P1171, DOI 10.1142/S0218127400000840
   Izhikevich EM, 2001, NEURAL NETWORKS, V14, P883, DOI 10.1016/S0893-6080(01)00078-8
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Kern A, 2003, PHYS REV LETT, V91, DOI 10.1103/PhysRevLett.91.128101
   Kramer O., 2013, DIMENSIONALITY REDUC, DOI DOI 10.1007/978-3-642-38652-7_2
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Lapique L., 1907, J PHYSL PATHOL GEN, V9, P620, DOI DOI 10.1007/S00422-007-0189-6
   Lerman P., 1980, GRID SEARCH, V29, P77, DOI DOI 10.2307/2346413
   Liu HH, 2021, COGN NEURODYNAMICS, V15, P191, DOI 10.1007/s11571-020-09594-6
   Luong T., 2013, P 17 C COMP NAT LANG, P104, DOI DOI 10.1007/BF02579642
   Marelli M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Monteiro LHA, 2003, IEEE T NEURAL NETWOR, V14, P1572, DOI 10.1109/TNN.2003.820441
   Murphy E., 2018, TALKING SPECIES PERS, P251
   Neftci EO, 2019, IEEE SIGNAL PROC MAG, V36, P51, DOI 10.1109/MSP.2019.2931595
   OKEEFE J, 1993, HIPPOCAMPUS, V3, P317, DOI 10.1002/hipo.450030307
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Pina JE, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006517
   Subramanian A, 2018, AAAI CONF ARTIF INTE, P4921
   Tiesinga PHE, 2002, NEURAL COMPUT, V14, P1629, DOI 10.1162/08997660260028647
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Wang AL, 2019, Arxiv, DOI [arXiv:1804.07461, DOI 10.48550/ARXIV.1804.07461]
   Wang L, 2018, J COGNITIVE NEUROSCI, V30, P432, DOI [10.1162/jocn_a_01190, 10.1080/09205071.2017.1326850]
   Wang YW, 2019, COGN COMPUT, V11, P676, DOI 10.1007/s12559-019-09643-1
   Wolfe J, 2010, CURR OPIN NEUROBIOL, V20, P306, DOI 10.1016/j.conb.2010.03.006
   Zhang ML, 2022, IEEE T NEUR NET LEAR, V33, P1947, DOI 10.1109/TNNLS.2021.3110991
   Zhang ML, 2019, IEEE T NEUR NET LEAR, V30, P123, DOI 10.1109/TNNLS.2018.2833077
   Zhang Yun, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3213688
NR 53
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD 2023 JUL 6
PY 2023
DI 10.1109/TNNLS.2023.3290004
EA JUL 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L8FD5
UT WOS:001025554600001
PM 37410643
DA 2023-11-10
ER

PT J
AU Du, YP
   Li, QX
   Wang, LL
   He, YQ
AF Du, Yongping
   Li, Qingxiao
   Wang, Lulin
   He, Yanqing
TI Biomedical-domain pre-trained language model for extractive
   summarization
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Extractive biomedical summarization; Document representation;
   Pre-trained language model; Fine-tuning
ID TEXT
AB In recent years, the performance of deep neural network in extractive summarization task has been improved significantly compared with traditional methods. However, in the field of biomedical extractive summarization, existing methods cannot make good use of the domain-aware external knowledge; furthermore, the document structural feature is omitted by existing deep neural network model. In this paper, we propose a novel model called BioBERTSum to better capture token-level and sentence-level contextual representation, which uses a domain-aware bidirectional language model pre-trained on large-scale biomedical corpora as encoder, and further fine-tunes the language model for extractive text summarization task on single biomedical document. Especially, we adopt a sentence position embedding mechanism, which enables the model to learn the position information of sentences and achieve the structural feature of document. To the best of our knowledge, this is the first work to use the pre-trained language model and fine-tuning strategy for extractive summarization task in the biomedical domain. Experiments on PubMed dataset show that our proposed model outperforms the recent SOTA (state-of-the-art) model by ROUGE-1/2/L. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Du, Yongping; Li, Qingxiao; Wang, Lulin] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [He, Yanqing] Inst Sci & Tech Informat China, Beijing 100038, Peoples R China.
C3 Beijing University of Technology
RP He, YQ (通讯作者)，Inst Sci & Tech Informat China, Beijing 100038, Peoples R China.
EM ypdu@bjut.edu.cn; lqx_bjut@163.com; linwang2048@163.com;
   heyanqingbjut@163.com
OI Li, Qingxiao/0000-0002-0088-0373
FU National Key R&D Program of China [2018YFC1900804]; Research Program of
   State Language Commission, China [YB135-89]
FX This research is supported by the National Key R&D Program of China
   under grant NO. 2018YFC1900804 and Research Program of State Language
   Commission, China under grant NO. YB135-89.
CR [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2018, IMPROVING LANGUAGE U
   [Anonymous], 2016, ARXIV
   Bhattacharya S, 2011, BIOINFORMATICS, V27, pI120, DOI 10.1093/bioinformatics/btr223
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   Deng TQ, 2020, INFORM SCIENCES, V508, P1, DOI 10.1016/j.ins.2019.08.060
   Devlin Jacob, 2019, BERT PRE TRAINING DE, P4171
   Esposito M, 2020, INFORM SCIENCES, V514, P88, DOI 10.1016/j.ins.2019.12.002
   Gayathri P, 2015, CYBERN INF TECHNOL, V15, P78, DOI 10.1515/cait-2015-0056
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gigioli P, 2018, IEEE INT C BIOINFORM, P2338
   Kim D., 2019, ARXIV190108746
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Lin H, 2019, AAAI CONF ARTIF INTE, P9815
   Lipscomb CE, 2000, B MED LIBR ASSOC, V88, P265
   Liu Y., 2019, P EMNLP
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   McEntyre J, 2001, CAN MED ASSOC J, V164, P1317
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, P404, DOI DOI 10.3115/1219044.1219064
   Mishra R, 2014, J BIOMED INFORM, V52, P457, DOI 10.1016/j.jbi.2014.06.009
   Moradi M, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P135, DOI 10.1109/ICCKE.2018.8566651
   Moradi M, 2018, ARTIF INTELL MED, V84, P101, DOI 10.1016/j.artmed.2017.11.004
   Moradi M, 2017, COMPUT METH PROG BIO, V146, P77, DOI 10.1016/j.cmpb.2017.05.011
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Peters M. E., 2018, ARXIV180205365
   Roberts RJ, 2001, P NATL ACAD SCI USA, V98, P381, DOI 10.1073/pnas.98.2.381
   Sarkar K, 2011, INT J DATABASE THEOR, V4, P31
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shang Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023862
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tsatsaronis G, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0564-6
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang YL, 2020, KNOWL-BASED SYST, V190, DOI 10.1016/j.knosys.2019.105030
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhong M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1049
   Zhou QY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P654
NR 40
TC 15
Z9 16
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JUL 8
PY 2020
VL 199
AR 105964
DI 10.1016/j.knosys.2020.105964
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LQ9ZH
UT WOS:000535355300009
DA 2023-11-10
ER

PT J
AU Yogatama, D
   d'Autume, CD
   Kong, LP
AF Yogatama, Dani
   d'Autume, Cyprien de Masson
   Kong, Lingpeng
TI Adaptive Semiparametric Language Models
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We present a language model that combines a large parametric neural network (i.e., a transformer) with a non-parametric episodic memory component in an integrated architecture. Our model uses extended short-term context by caching local hidden states-similar to transformer-XL-and global long-term memory by retrieving a set of nearest neighbor tokens at each timestep. We design a gating function to adaptively combine multiple information sources to make a prediction. This mechanism allows the model to use either local context, short-term memory, or long-term memory (or any combination of them) on an ad hoc basis depending on the context. Experiments on word-based and character-based language modeling datasets demonstrate the efficacy of our proposed method compared to strong baselines.
C1 [Yogatama, Dani; d'Autume, Cyprien de Masson; Kong, Lingpeng] DeepMind, London, England.
RP Yogatama, D (通讯作者)，DeepMind, London, England.
EM dyogatama@google.com; cyprien@google.com; lingpenk@google.com
CR Baevski Alexei, 2019, ARXIV191005453
   Bapna Ankur, 2019, P NAACL HLT, DOI DOI 10.18653/V1/N19-1191
   Beltagy I., 2020, ARXIV200405150V2
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Choromanski Krzysztof Marcin, 2021, P ICLR
   d'Autume Cyprien de Masson, 2019, P NEURIPS
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Devlin J., 2018, ARXIV, V1, P4171
   EdouardGrave Armand, 2017, P ICML
   Eichenbaum H, 2012, HDB PSYCHOL, V2, P3
   Grave E., 2017, ICLR
   Grave Edouard, 2017, P NEURIPS
   Guo Ruiqi., 2020, P ICML
   Guu K, 2020, PR MACH LEARN RES, V119
   Hutter M., 2012, HUMAN KNOWLEDGE COMP
   Inan Hakan, 2017, ICLR, V3771
   Kaiser Lukasz, 2017, P ICLR
   Kassner N, 2020, FINDINGS ASS COMPUTA, P3424, DOI [DOI 10.18653/V1/2020.FINDINGS-EMNLP.307, 10.18653/v1/2020.findings-emnlp.307]
   Khandelwal U., 2020, P ICLR
   Khandelwal Urvashi, 2021, P ICLR
   Kingma D. P., 2014, C TRACK P
   Kitaev Nikita, 2020, ARXIV200104451
   Krause Ben, 2018, P ICML
   Krause Ben., 2019, ARXIV
   Liang Percy, 2018, T ASSOC COMPUT LING, V6, P437
   Merity Stephen, 2017, 5 INT C LEARNING REP
   Nematzadeh Aida, 2020, P ICLR WORKSH BRIDG
   Neubig Graham, 2016, P 2016 C EMP METH NA, P1163, DOI DOI 10.18653/V1/D16-1124
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rae Jack W., 2020, P ICLR
   Rolls ET, 2000, ANNU REV PSYCHOL, V51, P599, DOI 10.1146/annurev.psych.51.1.599
   Shoeybi Mohammad, 2019, ARXIV190908053V4
   TULVING E, 1985, AM PSYCHOL, V40, P385, DOI 10.1037/0003-066x.40.4.385
   Vaswani A., 2017, ARXIV, V30, P5998
   Xiong W., 2021, P ICLR
   Xu P., 2020, P EMNLP
NR 38
TC 11
Z9 11
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 362
EP 373
DI 10.1162/tacl_a_00371
PG 12
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200022
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Cao, HQ
   He, P
   Wang, CJ
AF Cao, Huiqin
   He, Peng
   Wang, Chengjin
TI Processing of Chinese language and text information system under the
   background of speech recognition
SO SOFT COMPUTING
LA English
DT Article; Early Access
DE Speech recognition; Chinese; Language and text; Information system
AB With the popularization of computers, artificial intelligence technology has become more and more mature, among which speech recognition technology in artificial intelligence is favored by people. In the past few years, the acoustic model combined with the Gaussian mixture model and the hidden Markov model has always been in the leading position. In the field of speech recognition technology, because the development of speech data has gradually expanded, and the complexity of the data has also increased. The larger the data, the traditional data network model is slowly showing inadequacy. However, the deep neural network model is easy to deal with large and complex data modeling. This article combines the advantages of basic learning theory and speech recognition technology, and launches in-depth research on embedding learning theoretical knowledge into the field of speech recognition. Nowadays, large-scale text information databases relying on computers are becoming more and more important in linguistic research, and a large-scale corpus that fully reflects language facts and contains rich language information has been constructed. The establishment of the text information database system is long, from word segmentation, part-of-speech tagging to syntactic tagging to semantic tagging. Therefore, the characteristic of information system processing is that the systematic description depends on the application environment of understanding vocabulary and reasoning. According to different scenarios, the realization methods of semantic description roles are also different, and the description of semantic roles in correct scenarios is clearer, more detailed and systematic. Therefore, this article is of great significance for solving the semantic problem of using Chinese frame network for Chinese information processing in the context of speech recognition.
C1 [Cao, Huiqin] Keimyung Univ, Dept Educ, Daegu 42601, South Korea.
   [Cao, Huiqin] Hunan Vocat Coll Nationalities, Sch Primary Educ, Yueyang 414000, Hunan, Peoples R China.
   [He, Peng] Yueyang Vocat Tech Coll, Sch Informat, Yueyang 414000, Peoples R China.
   [Wang, Chengjin] Jiaxing Nanhu Univ, Sch Humanities & Arts, Jiaxing 314001, Peoples R China.
C3 Keimyung University
RP Wang, CJ (通讯作者)，Jiaxing Nanhu Univ, Sch Humanities & Arts, Jiaxing 314001, Peoples R China.
EM wang_chengjin@126.com
FU Study on The Construction of Chinese Language Curriculum Based on The
   Integration of Certificate and Curriculum for Tibetan Normal Students
   (Education special project in 2020 of Hunan Province Social Science
   Fund) [20YBJ16]
FX This work was supported by: Study on The Construction of Chinese
   Language Curriculum Based on The Integration of Certificate and
   Curriculum for Tibetan Normal Students (Education special project in
   2020 of Hunan Province Social Science Fund, 20YBJ16).
CR Affolter K, 2019, VLDB J, V28, P793, DOI 10.1007/s00778-019-00567-8
   Bertsimas D, 2021, MACH LEARN, V110, P249, DOI 10.1007/s10994-020-05893-5
   Chen HR, 2016, TECHNOL PEDAGOG EDUC, V25, P171, DOI 10.1080/1475939X.2015.1007077
   Cho Byung Chul, 2018, [Journal of Digital Convergence, 디지털융복합연구], V16, P9, DOI 10.14400/JDC.2018.16.2.009
   de Lima TA, 2020, COMPUT SPEECH LANG, V62, DOI 10.1016/j.csl.2019.101055
   Hamza M., 2020, INT J ELECT COMPUT E, V10, P3643
   Lai XX, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09872-6
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Moon Hyung Jin, 2020, [Journal of the Korea Convergence Society, 한국융합학회논문지], V11, P19, DOI 10.15207/JKCS.2020.11.7.019
   Shi L, 2021, INT J LESSON LEARN S, V10, P75, DOI 10.1108/IJLLS-09-2020-0065
   Tao F, 2021, IEEE T MULTIMEDIA, V23, P1, DOI 10.1109/TMM.2020.2975922
   Wang DP, 2019, INT J BILING EDUC BI, V22, P138, DOI 10.1080/13670050.2016.1231773
   Xie Y, 2019, TECHTRENDS, V63, P251, DOI 10.1007/s11528-019-00389-z
   Yuan C, 2019, J AM MED INFORM ASSN, V26, P294, DOI 10.1093/jamia/ocy178
   Zaatri A., 2015, J NEW TECHNOL MATER, V277, P1
NR 15
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD 2023 JUN 10
PY 2023
DI 10.1007/s00500-023-08710-y
EA JUN 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J0MF4
UT WOS:001006626400009
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Clark, JH
   Choi, E
   Collins, M
   Garrette, D
   Kwiatkowski, T
   Nikolaev, V
   Palomaki, J
AF Clark, Jonathan H.
   Choi, Eunsol
   Collins, Michael
   Garrette, Dan
   Kwiatkowski, Tom
   Nikolaev, Vitaly
   Palomaki, Jennimaria
TI TYDI QA: A Benchmark for Information-Seeking Question Answering in
   <i>Ty</i>pologically <i>Di</i>verse Languages
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Confidently making progress on multilingual modeling requires challenging, trustworthy evaluations. We present TYDI QA-a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs. The languages of TYDI QA are diverse with regard to their typology-the set of linguistic features each language expresses-such that we expect models performing well on this set to generalize across a large number of the world's languages. We present a quantitative analysis of the data quality and example-level qualitative linguistic analyses of observed language phenomena that would not be found in English-only corpora. To provide a realistic information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but don't know the answer yet, and the data is collected directly in each language without the use of translation.
C1 [Clark, Jonathan H.; Choi, Eunsol; Collins, Michael; Garrette, Dan; Kwiatkowski, Tom; Nikolaev, Vitaly; Palomaki, Jennimaria] Google Res, Mountain View, CA 94043 USA.
C3 Google Incorporated
RP Clark, JH (通讯作者)，Google Res, Mountain View, CA 94043 USA.
EM tydiqa@google.com
CR Alberti C., 2019, ABS190108634 CORR, P1
   [Anonymous], 2013, PERFECTIVE IMPERFECT
   [Anonymous], 2004, ISO SUOMEN KIELIOPPI
   [Anonymous], 1982, RUSS LINGUIST
   Aroyo L, 2015, AI MAG, V36, P15, DOI 10.1609/aimag.v36i1.2564
   Artetxe Mikel, 2019, ARXIV PREPRINT ARXIV
   Asai A., 2018, ARXIV180903275
   Ashton, 1947, SWAHILI GRAMMAR
   Attia M.A., 2007, ACL WORKSHOP COMPUTA, P65, DOI DOI 10.3115/1654576.1654588
   Avner Ehud Alexander, 2014, DIGITAL SCHOLARSHIP, V31, P30
   Bivon Roy, 1971, ELEMENT ORDER, V7
   Bizzarri C., 2015, ANNALI CA FOSCARI, V49, P335
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Boyd-Graber Jordan, 2019, ARXIV191014464
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2174
   Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924
   Comrie B., 2005, WORLD ATLAS LANGUAGE
   Comrie Bernard., 1989, LANGUAGE UNIVERSALS, V2nd edn
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2475
   Corbett G. G., 1991, GENDERS
   Croce D, 2018, LECT NOTES ARTIF INT, V11298, P389, DOI 10.1007/978-3-030-03840-3_29
   Danwiwat Nanthana, 1987, THAI WRITING SYSTEM, V39
   Devlin J., 2018, ARXIV, V1, P4171
   Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368
   Dunn M., 2017, ABS170405179 CORR
   Eetemadi Sauleh., 2014, P 2014 C EMPIRICAL M, P159, DOI DOI 10.3115/V1/D14-1018
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Gao H., 2015, P 28 INT C NEURAL IN, V2, P2296, DOI DOI 10.1145/2733373.2807418
   Gardner Matt, 2019, ARXIV190911291
   Gupta D, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2777
   Han Na-Rae, 2005, IRCS TECHNICAL REPOR, P7
   He Wei, 2017, ARXIV171105073
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Kaiser S., 2013, JAPANESE COMPREHENSI
   Karlsson, 2013, FINNISH ESSENTIAL GR
   Kenter T, 2018, AAAI CONF ARTIF INTE, P5820
   Krishnamurti B., 1998, DRAVIDIAN LANGUAGES, P202
   Krishnamurti Bhadriaju., 2003, DRAVIDIAN LANGUAGES
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lai G., 2017, EMNLP, P785, DOI DOI 10.18653/V1/D17-1082
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086
   Lee K, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2758
   Lembersky G, 2012, COMPUT LINGUIST, V38, P799, DOI 10.1162/COLI_a_00111
   Lewis Patrick, 2019, ARXIV191007475
   Lim S., 2019, PROC NEURIPS
   Lisker Leigh, 1963, INTRO SPOKEN TELUGU
   Liu JH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2358
   Mitra Rajarshee, 2017, ARXIV171106238
   Mohamed Mohamed Abdulla, 2001, MODERN SWAHILI GRAMM
   Mozannar H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P108
   Naik A., 2018, P 27 INT C COMPUTATI, P2340
   Nguyen DHN, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510844
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   Peskov Denis, 2019, C INT SPEECH COMM AS
   Poliak Adam, 2018, P 7 JOINT C LEXICAL, P180, DOI DOI 10.18653/V1/S18-2023
   Rabinovich Ella., 2015, T ASSOC COMPUT LING, V3, P419, DOI [10.1162/tacl_a_00148, DOI 10.1162/TACL_A_00148]
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Ryding K. C., 2005, REFERENCE GRAMMAR MO
   Seidl A., 1997, P CHICAGO LINGUISTIC, V33, P373
   Shao C.C., 2018, ARXIV PREPRINT ARXIV
   Sneddon James Neil, 2012, INDONESIAN COMPREHEN
   Sohn H-M., 2001, KOREAN LANGUAGE
   Thompson H. R., 2010, BENGALI COMPREHENSIV
   Trischler Adam, 2017, P 2 WORKSH REPR LEAR, P191, DOI DOI 10.18653/V1/W17-2623
   Vania C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2016, DOI 10.18653/v1/P17-1184
   Volansky V, 2015, DIGIT SCHOLARSH HUM, V30, P98, DOI 10.1093/llc/fqt031
   Voorhees E. M., 2000, SIGIR Forum, V34, P200
   WALD B, 1987, WORLDS MAJOR LANGUAG, P991
   Welbl J., 2018, T ASSOC COMPUT LING, V6, P287
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Wintner S., 2016, P COLING 2016 26 INT, P18
   Yang Yi, 2015, P 2015 C EMP METH NA, P2013, DOI DOI 10.18653/V1/D15-1237
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369
   ZHANG Y, 2019, LECT NOTES COMPUTER, P552
NR 77
TC 101
Z9 102
U1 2
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2020
VL 8
BP 454
EP 470
DI 10.1162/tacl_a_00317
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA XX8IL
UT WOS:000736531900030
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU An, B
AF An, Bo
TI Prompt-based for Low-Resource Tibetan Text Classification
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Tibetan text classification; prompt learning; deep learning; pre-trained
   language model
AB Text classification is a critical and foundational task in Tibetan natural language processing, it plays a crucial role in various applications, such as sentiment analysis and information extraction. However, the limited availability of annotated data poses a significant challenge to Tibetan natural language processing. This paper proposes a prompt learning-based method for low-resource Tibetan text classification to overcome this challenge. This method utilizes pre-trained language models to learn text representation and generation capabilities on a large-scale unsupervised Tibetan corpus, enabling few-shot Tibetan text classification. Experimental results demonstrate that the proposed method significantly improves the performance of Tibetan text classification in low-resource scenarios. This work provides a new research idea and method for low-resource language processing, such as Tibetan natural language processing. Hopefully, it will inspire subsequent work on low-resource language processing.
C1 [An, Bo] Chinese Acad Social Sci, Inst Ethnol & Anthropol, South Tweenty 7 St,Bldg 6,Zhongguancun Nandajie 2, Beijing, Beijing, Peoples R China.
C3 Chinese Academy of Social Sciences
RP An, B (通讯作者)，Chinese Acad Social Sci, Inst Ethnol & Anthropol, South Tweenty 7 St,Bldg 6,Zhongguancun Nandajie 2, Beijing, Beijing, Peoples R China.
EM anbo@cass.org.cn
FU National Social Science Foundation of China [22BTQ010]; National Natural
   Science Foundation of China [62076233]; Innovation Project major
   research of Chinese Academy of Social Sciences [2022MZSQN001]
FX This work is supported by the National Social Science Foundation of
   China (22BTQ010), the National Natural Science Foundation of China
   (62076233) and the Innovation Project major research of Chinese Academy
   of Social Sciences (2022MZSQN001).
CR An Bo, 2022, J CHINESE INFORM PRO
   Brauwers G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3503044
   Cai JJ, 2018, I COMP CONF WAVELET, P123, DOI 10.1109/ICCWAMTIP.2018.8632592
   Cao H, 2013, INT CONF ASIAN LANG, P220, DOI 10.1109/IALP.2013.63
   Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334
   Constant N., 2020, ARXIV
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Cun YZ, 2010, MOL PHYLOGENET EVOL, V56, P972, DOI 10.1016/j.ympev.2010.05.007
   Grave E, 2018, Arxiv, DOI arXiv:1802.06893
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gu YX, 2022, Arxiv, DOI arXiv:2109.04332
   Han Kai, 2021, ADV NEURAL INFORM PR, V34, P15908
   Hill Nathan W., 2016, HIMALAYAN LINGUISTIC, V15, P1
   Ilic S, 2018, Arxiv, DOI arXiv:1809.09795
   Jia Hongyun, 2019, THESIS TIBET U
   Jia Huiqiang, 2010, GUIDE BECOMING RICH, V4X, P30
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Li Ailin, 2014, THESIS NW U NATL
   Li Jia, 2020, 2020 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA), P27, DOI 10.1109/AIEA51086.2020.00013
   Li ZS, 2019, INT CONF ASIAN LANG, P379, DOI [10.1109/IALP48816.2019.9037706, 10.1109/ialp48816.2019.9037706]
   [刘汇丹 Liu Huidan], 2012, [中文信息学报, Journal of Chinese Information Processing], V26, P97
   Liu Huidan, 2012, 24 INT C COMP LING, V11
   Liu P., 2021, ARXIV
   Lu Y., 2022, PREPRINT
   Ma Wei, 2019, 3 INT C COMPUTER ENG, P374
   Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Oyedare T, 2019, IEEE INT SYMP DYNAM, P41, DOI 10.1109/dyspan.2019.8935823
   Qin XF, 2019, IEEE INT SYMP DYNAM, P440, DOI 10.1109/dyspan.2019.8935805
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Qun N, 2017, LECT NOTES ARTIF INT, V10565, P472, DOI 10.1007/978-3-319-69005-6_39
   Nguyen DQ, 2020, Arxiv, DOI arXiv:2003.00744
   Salazar J, 2021, Arxiv, DOI arXiv:1910.14659
   Sun BW, 2018, 2018 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P109, DOI 10.1109/ICALIP.2018.8455328
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang Yong, 2013, THESIS NW U NATL
   Wei Yan, 2021, Journal of Physics: Conference Series, V1848, DOI 10.1088/1742-6596/1848/1/012139
   Wright RE., 1995, READING UNDERSTANDIN
   Xiaolei L, PREPRINT
   [胥桂仙 XU Guixian], 2011, [中文信息学报, Journal of Chinese Information Processing], V25, P20
   Xu Guixian, 2022, DATA ANAL KNOWLEDGE, P1
   Yang Hongwu, 2020, J NANJING U POSTS TE
   Yang Ziqing, 2022, P 29 INT C COMPUTATI, P3937
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Yuan Bin, 2016, THESIS NW U NATL
NR 46
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG
PY 2023
VL 22
IS 8
AR 207
DI 10.1145/3603168
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q7NS7
UT WOS:001059361200005
DA 2023-11-10
ER

PT J
AU Wang, H
   Fu, RL
   Li, CZ
   Zhang, XJ
   Zhou, J
   Bai, X
   Yan, YH
   Zhao, QW
AF Wang, Han
   Fu, Ruiliu
   Li, Chengzhang
   Zhang, Xuejun
   Zhou, Jun
   Bai, Xing
   Yan, Yonghong
   Zhao, Qingwei
TI Reminding the incremental language model via data-free self-distillation
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Incremental language learning; Self-distillation; Hidden data
   augmentation; Data-free constraint; Pseudo data
ID NEURAL-NETWORKS
AB Incremental language learning, which involves retrieving pseudo-data from previous tasks, can alleviate catastrophic forgetting. However, previous methods require a large amount of pseudo-data to approach the performance of multitask learning, and the performance decreases dramatically when there is significantly less pseudo-data than new task data. This decrease occurs because the pseudo-data are learned inefficiently and deviate from the real data. To address these issues, we propose reminding the incremental language model via data-free self-distillation (DFSD), which includes 1) self-distillation based on the Earth mover's distance (SD-EMD) and 2) hidden data augmentation (HDA). SD-EMD can increase the efficiency of the model by adaptively estimating the knowledge distribution in all GPT-2 layers and effectively transferring data from the teacher model to the student model via adaptive self-multilayer-to-multilayer mapping. HDA can reduce deviations by decomposing the generation process via data augmentation and bootstrapping. Our experiments on decaNLP and text classification tasks with low pseudo-data sampling ratios reveal that the DFSD model outperforms previous state-of-the-art incremental methods. The advantages of DFSD become more apparent when there is less pseudo-data and larger deviations.
C1 [Wang, Han; Fu, Ruiliu; Li, Chengzhang; Zhang, Xuejun; Zhou, Jun; Bai, Xing; Yan, Yonghong; Zhao, Qingwei] Chinese Acad Sci, Inst Acoust, Key Lab Speech Acoust & Content Understanding, Beijing, Peoples R China.
   [Wang, Han; Fu, Ruiliu; Li, Chengzhang; Zhang, Xuejun; Zhou, Jun; Bai, Xing; Yan, Yonghong; Zhao, Qingwei] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Acoustics, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Zhao, QW (通讯作者)，Chinese Acad Sci, Inst Acoust, Key Lab Speech Acoust & Content Understanding, Beijing, Peoples R China.; Zhao, QW (通讯作者)，Univ Chinese Acad Sci, Beijing, Peoples R China.
EM wanghan@hccl.ioa.ac.cn; furuiliu@hccl.ioa.ac.cn;
   lichengzhang@hccl.ioa.ac.cn; zhangxuejun@hccl.ioa.ac.cn;
   zhoujun@hccl.ioa.ac.cn; baixing@hccl.ioa.ac.cn;
   yanyonghong@hccl.ioa.ac.cn; zhaoqingwei@hccl.ioa.ac.cn
RI Fu, Ruiliu/GWM-8332-2022
OI Wang, Han/0000-0003-4115-3065
CR Alammar, FINDING WORDS SAY HI
   Aljundi R, 2018, LECT NOTES COMPUT SC, V11207, P144, DOI 10.1007/978-3-030-01219-9_9
   Arazo E, 2019, PR MACH LEARN RES, V97
   Capuano N, 2021, APPL INTELL, V51, P3339, DOI 10.1007/s10489-020-01984-x
   Chaudhry Arslan, 2019, 7 INT C LEARNING REP
   Chen Z., 2018, SYNTHESIS LECT ARTIF, V12, P1
   Chuang YS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2914
   Cossu A, 2021, NEURAL NETWORKS, V143, P607, DOI 10.1016/j.neunet.2021.07.021
   d'Autume CD, 2019, ADV NEUR IN, V32
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Furlanello T, 2018, INT C MACHINE LEARNI, P1607
   Heinrich S, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00052
   Kanwatchara K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2942
   Kemker R, 2018, 6 INT C LEARNING REP
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Lee SW, 2017, ADV NEUR IN, V30
   Li CM, 2021, APPL INTELL, V51, P185, DOI 10.1007/s10489-020-01786-1
   Li JQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3009
   Li Z, 2017, 43RD EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC 2017), DOI [10.1109/TPAMI.2017.2773081, 10.1109/TCC.2017.2764082]
   Lopez-Paz D, 2017, ADV NEUR IN, V30
   McCann Bryan, 2018, ABS180608730 CORR
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI DOI 10.1016/S0079-7421(08)60536-8
   nostalgebraist, 2020, INT GPT LOG LENS
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Reed S. E., 2015, 3 INT C LEARN REPR I
   Ring MB, 1997, MACH LEARN, V28, P77, DOI 10.1023/A:1007331723572
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schwarz J, 2018, PR MACH LEARN RES, V80
   Shin H, 2017, ADV NEUR IN, V30
   Sun Fan-Yun, 2019, INT C LEARN REPR
   Sun J., 2020, P COLING, P3569, DOI DOI 10.18653/V1/2020.COLING-MAIN.318
   van de Ven GM, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17866-2
   Wang Z, 2020, EMNLP
   Zenke F, 2017, PR MACH LEARN RES, V70
   Zhai MY, 2019, IEEE I CONF COMP VIS, P2759, DOI 10.1109/ICCV.2019.00285
   Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776
   Zhang Xiang, 2015, NEURIPS, DOI DOI 10.5555/2969239.2969312
NR 41
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD APR
PY 2023
VL 53
IS 8
SI SI
BP 9298
EP 9320
DI 10.1007/s10489-022-03678-y
EA AUG 2022
PG 23
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F2KE9
UT WOS:000837543300001
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Rico-Juan, JR
   Calera-Rubio, J
   Carrasco, RC
AF Rico-Juan, JR
   Calera-Rubio, J
   Carrasco, RC
BE Olivera, AL
TI Probabilistic <i>k</i>-testable tree languages
SO GRAMMATICAL INFERENCE: ALGORITHMS AND APPLICATIONS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 5th International Colloquium on Grammatical Inference (ICGI-2000)
CY SEP 11-13, 2000
CL LISBON, PORTUGAL
AB In this paper, we present a natural generalization of k-gram models for tree stochastic languages based on the k-testable class. In this class of models, frequencies are estimated for a probabilistic regular tree grammar wich is bottom-up deterministic. One of the advantages of this approach is that the model can be updated in an incremental fashion. This method is an alternative to costly learning algorithms (as inside-outside-based methods) or algorithms that require larger samples (as many state merging/splitting methods).
C1 Univ Alacant, Dept Llenguatges Sistemes Informat, E-03071 Alacant, Spain.
C3 Universitat d'Alacant
RP Rico-Juan, JR (通讯作者)，Univ Alacant, Dept Llenguatges Sistemes Informat, E-03071 Alacant, Spain.
EM juanra@dlsi.ua.es; calera@dlsi.ua.es; carrasco@dlsi.ua.es
OI RICO-JUAN, Juan Ramon/0000-0002-9199-5802
CR [Anonymous], 1998, STAT METHODS SPEECH
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Calera-Rubio J, 1998, INFORM PROCESS LETT, V68, P283, DOI 10.1016/S0020-0190(98)00172-0
   CARRASCO RC, 2000, IN PRESS MACHINE LEA
   Charniak E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1031
   Charniak E., 1993, STAT LANGUAGE LEARNI
   CHAUDHURI R, 1986, J ACM, V33, P702, DOI 10.1145/6490.214099
   Chung K.L., 1967, MARKOV CHAINS STATIO, V2nd
   Cover T., 1991, WILEY SERIES TELECOM
   GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687
   GARCIA P, 1993, DSICII199346 U POL V
   KNUUTILA T, 1993, ADV STRUCTURAL SYNTA
   NEY H, 1995, IEEE T PATTERN ANAL, V17, P1202, DOI 10.1109/34.476512
   RUBIN F, 1976, COMMUN ACM, V19, P617, DOI 10.1145/360363.360368
   SAKAKIBARA Y, 1992, INFORM COMPUT, V97, P23, DOI 10.1016/0890-5401(92)90003-X
   STOLCKE A, 1995, COMPUT LINGUIST, V21, P165
   STOLCKE A, 1994, TR94007 INT COMP SCI
   WETHERELL CS, 1980, COMPUT SURV, V12, P361, DOI 10.1145/356827.356829
   YOKOMORI T, 1995, MACH LEARN, V19, P153, DOI 10.1023/A:1022615325466
NR 19
TC 7
Z9 8
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 2945-9133
EI 1611-3349
BN 3-540-41011-2
J9 LECT NOTES ARTIF INT
PY 2000
VL 1891
BP 221
EP 228
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BU08Q
UT WOS:000174950700018
DA 2023-11-10
ER

PT J
AU Godslove, JF
   Nayak, AK
AF Godslove, Julius Femi
   Nayak, Ajit Kumar
TI Trilingual conversational intent decoding for response retrieval
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article; Early Access
DE Trilingual conversational question answering; Natural language
   processing; Information retrieval; Natural language inferencing; Natural
   language understanding
AB The rich diversity of human language allows speakers to seamlessly transition between multiple languages during conversations. While humans have the remarkable ability to become proficient in multiple languages in a short period, developing machines that can converse in multiple natural languages with an understanding of diverse dialects requires sophisticated Natural Language Processing (NLP) techniques such as dialect recognition and intent extraction. This facilitates mutual understanding between parties who use phrases, sentences, words, or expressions from multiple languages within a single context. The work in this paper, propose a trilingual approach to multi-dialect conversation modeling within the same conversational session and context for a mix of English, Hindi-English text, Hindi-Devanagari text and Yoruba text. The model identifies the language used and determines the intent behind a query to respond in the same dialect. Our model is capable of detecting the end of a conversation, and it also detects the predominant dialect and responds accordingly in scenarios where a user's input query contains a mix of languages. This approach is particularly useful in situations where there is limited data available for multilingual or trilingual conversation tasks based on Intent Detection (ID). We evaluate our proposed pipeline and model on three benchmark ID datasets and a trilingual dialogue dataset for response retrieval by intent decoding. Our model outperforms existing approaches in terms of performance metrics and has faster training time. Moreover, our trilingual approach to multi-dialect conversation modeling provides a versatile tool for efficient and effective inter-dialect conversational automation, even when dealing with large datasets, with minimal parameters and low resource overhead. The lightweight architectural pipeline and efficient algorithms used in our model contribute to its high performance and versatility.
C1 [Godslove, Julius Femi] Siksha O Anusandhan Univ, Dept Comp Sci & Engn, J-15,Khandagiri Marg, Bhubaneswar 751030, Odisha, India.
   [Nayak, Ajit Kumar] Siksha O Anusandhan Univ, Dept Comp Sci & Informat Technol, J-15,Khandagiri Marg, Bhubaneswar 751030, Odisha, India.
C3 Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University
RP Godslove, JF (通讯作者)，Siksha O Anusandhan Univ, Dept Comp Sci & Engn, J-15,Khandagiri Marg, Bhubaneswar 751030, Odisha, India.
EM Juliusgodslove88@gmail.com; Ajitnayak@soa.ac.in
FU We aim to promote transparency and reproducibility in our research, and
   we encourage readers to use these resources to further their own
   studies.
FX We aim to promote transparency and reproducibility in our research, and
   we encourage readers to use these resources to further their own
   studies.
CR Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977
   Albadr MAA, 2019, INT J SPEECH TECHNOL, V22, P711, DOI 10.1007/s10772-019-09621-w
   Albadr MAA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194770
   Anand A, 2020, Arxiv, DOI [arXiv:2005.08658, DOI 10.48550/ARXIV.2005.08658]
   Avishek A., 2021, ACM SIGIR FORUM, V54, P1, DOI DOI 10.1145/3451964.3451967
   Aymen BEM, 2021, ARXIV, DOI [10.48550/arXiv.2103.09185, DOI 10.48550/ARXIV.2103.09185]
   Babatunde AN, 2021, INT J SPEECH TECHNOL, V24, P979, DOI [10.1007/s10772-021-09852-w, 10.1145/3459104.3459105]
   Babatunde AN., 2022, J DIG INNOVATIONS CO, V10, P69
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bassett C, 2019, AI SOC, V34, P803, DOI 10.1007/s00146-018-0825-9
   Cai RC, 2017, INT CONF DAT MIN WOR, P430, DOI 10.1109/ICDMW.2017.62
   Cheng SH, 2021, INFORM SCIENCES, V579, P15, DOI 10.1016/j.ins.2021.07.091
   Dalton J, 2020, Arxiv, DOI [arXiv:2003.13624, 10.48550/arXiv.2003.13624, DOI 10.48550/ARXIV.2003.13624]
   Dwivedi VP, 2021, Arxiv, DOI arXiv:2012.09699
   ELAffendi MA, 2018, 2018 SIXTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION, NETWORKING, AND WIRELESS COMMUNICATIONS (DINWC), P70, DOI 10.1109/DINWC.2018.8356998
   Firdaus M, 2023, INFORM FUSION, V91, P299, DOI 10.1016/j.inffus.2022.09.029
   Glaese A, 2022, ARXIV
   Goo  C.-W., 2018, P C N AM CH ASS COMP, V2, P753
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Immidisetti S, 2021, THESIS, V325
   Karpukhin V, 2020, Arxiv, DOI arXiv:2004.04906
   Kato T, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P60
   Kaya H, 2018, NEUROCOMPUTING, V275, P1028, DOI 10.1016/j.neucom.2017.09.049
   Kim HK, 2017, NEUROCOMPUTING, V266, P336, DOI 10.1016/j.neucom.2017.05.046
   Kunchukuttan A, 2018, Arxiv, DOI arXiv:1710.02855
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lin ZH, 2017, Arxiv, DOI [arXiv:1703.03130, DOI 10.48550/ARXIV.1703.03130]
   Liu B, 2016, INTERSPEECH, P685, DOI 10.21437/Interspeech.2016-1352
   Mabrouk A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020636
   Maia A, 2022, P 2022 C EMPIRICAL M, P138
   Ouyang L., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2203.02155
   Oyelere SS, 2018, EDUC INF TECHNOL, V23, P467, DOI 10.1007/s10639-017-9613-2
   Peerat L, 2022, CL RELKT CROSS LINGU, P2141
   Perkins H, 2020, Arxiv, DOI arXiv:1908.11487
   Ravuri S, 2015, INTERSPEECH, P2832
   Sangodiah Anbuselvan, 2015, Journal of Theoretical and Applied Information Technology, V71, P386
   Siblini W, 2019, ARXIV
   Siddhi P., 2020, INT J ADV TRENDS COM, V9, P9155
   Thoppilan R., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.08239
   Tri N., 2016, COCO NIPS, DOI [10.48550/arXiv.1611.09268, DOI 10.48550/ARXIV.1611.09268]
   Tu JX, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/2039872
   Tur G, 2011, SPOKEN LANGUAGE UNDE
   Usman H, 2021, 2 INT C PERS TECHN, V3, P206, DOI [10.1007/978-3-030-69143-117, DOI 10.1007/978-3-030-69143-117]
   Vedula N, 2019, Arxiv, DOI arXiv:1904.08524
   Vulic Ivan, 2021, ARXIV
   Wang JP, 2015, AAAI CONF ARTIF INTE, P339
   Wang X., 2018, IEEE ACM T AUDIO SPE, V26, P890
   Pham XL, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON EDUCATION AND E-LEARNING (ICEEL 2018), P16, DOI 10.1145/3291078.3291115
   Yang Z., 2016, P 2016 C N AM CHAPTE, P1480, DOI [10.18653/v1/N16-1174, DOI 10.18653/V1/N16-1174]
   Yaseen ZM, 2019, J HYDROL, V569, P387, DOI 10.1016/j.jhydrol.2018.11.069
   Ye W., 2017, IOP C SERIES MAT SCI, V261
   Yilin S, 2021, P 59 ANN M ASS COMP, V1, P2443
   Zhang Y, 2016, COLING, P3198
NR 53
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD 2023 SEP 5
PY 2023
DI 10.1007/s10115-023-01972
EA SEP 2023
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q6XJ7
UT WOS:001058931700001
DA 2023-11-10
ER

PT S
AU Gelbukh, A
   Alexandrov, M
   Han, SY
AF Gelbukh, A
   Alexandrov, M
   Han, SY
BE Sanfeliu, A
   Trinidad, JFM
   Ochoa, JAC
TI Detecting inflection patterns in natural language by minimization of
   morphological model
SO PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 9th Iberoamerican Congress on Pattern Recognition
CY OCT 16-29, 2004
CL Puebla, MEXICO
SP Inst Cybernet, Math & Phys Cuba, Ctr Applicat Adv Technol Cuba, Univ La Salle, Mexico, Autonomous Univ Puebla, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Portuguese Assoc Pattern Recognit, Spanish Assoc Pattern Recognit & Image Anal, SIGPR SBC, Mexican Assoc Comp Vis, Neurocomp & Robot
AB One of the most important steps in text processing and information retrieval is stemming - reducing of words to stems expressing their base meaning, e.g., bake, baked, bakes, baking --> bak-. We suggest an unsupervised method of recognition such inflection patterns automatically, with no a priori information on the given language, basing exclusively on a list of words extracted from a large text. For a given word list V we construct two sets of strings: stems S and endings E, such that each word from V is a concatenation of a stem from S and ending from E. To select an optimal model, we minimize the total number of elements in S and E. Though such a simplistic model does not reflect many phenomena of real natural language morphology, it shows surprisingly promising results on different European languages. In addition to practical value, we believe that this can also shed light on the nature of human language.
C1 Natl Polytech Inst, Mexico City, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Han, SY (通讯作者)，Natl Polytech Inst, Mexico City, DF, Mexico.
EM dyner1950@mail.ru; hansy@cau.ac.kr
RI Gelbukh, Alexander/A-8979-2008
OI Gelbukh, Alexander/0000-0001-7845-9039
CR ALEXANDROV M, 2004, PROCESAMIENTO LENGUA, V33
   Gelbukh A, 2003, LECT NOTES COMPUT SC, V2588, P215
   Goldsmith J., 2001, COMPUTATIONAL LINGUI, V27
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
NR 4
TC 15
Z9 15
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-23527-2
J9 LECT NOTES COMPUT SC
PY 2004
VL 3287
BP 432
EP 438
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BBE01
UT WOS:000225085900054
OA Bronze, Green Submitted
DA 2023-11-10
ER

PT S
AU Roelofs, A
AF Roelofs, A
BE Belz, A
   Evans, R
   Piwek, P
TI The seduced speaker: Modeling of cognitive control
SO NATURAL LANGUAGE GENERATION: PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 3rd International Conference on Natural Language Generation (INLG 2004)
CY JUL 14-16, 2004
CL Brockenhurst, ENGLAND
SP Univ Brighton, Informat Technol Res Inst, Assoc Computat Lingust Special Interest Grp Generat
ID SPREADING-ACTIVATION THEORY; SPEECH PRODUCTION; WORD PRODUCTION; LEXICAL
   ACCESS; STROOP TASK; RETRIEVAL; CORTEX
AB Although humans are the ultimate "natural language generators", the area of psycholinguistic modeling has been somewhat underrepresented in recent approaches to Natural Language Generation in computer science. To draw attention to the area and illustrate its potential relevance to Natural Language Generation, I provide an overview of recent work on psycholinguistic modeling of language production together with some key empirical findings, state-of-the-art experimental techniques, and their historical roots. The techniques include analyses of speech-error corpora, chronometric analyses, eyetracking, and neuroimaging. The overview is built around the issue of cognitive control in natural language generation, concentrating on the production of single words, which is an essential ingredient of the generation of larger utterances. Most of the work exploited the fact that human speakers are good but not perfect at resisting temptation, which has provided some critical clues about the nature of the underlying system.
C1 Max Planck Inst Psycholinguist, FC Donders Ctr Cognit Neuroimaging, NL-6525 XD Nijmegen, Netherlands.
   Nijmegen Inst Cognit & Informat, NL-6525 XD Nijmegen, Netherlands.
C3 Max Planck Society; Radboud University Nijmegen
RP Roelofs, A (通讯作者)，Max Planck Inst Psycholinguist, FC Donders Ctr Cognit Neuroimaging, Wundtlaan 1, NL-6525 XD Nijmegen, Netherlands.
EM ardi@mpi.nl
RI Roelofs, Ardi/A-5311-2010
CR Anderson J. R., 1998, ATOMIC COMPONENTS TH
   Botvinick MM, 2001, PSYCHOL REV, V108, P624, DOI 10.1037//0033-295X.108.3.624
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   DONDERS FC, 1969, ACTA PSYCHOL, V30, P412, DOI 10.1016/0001-6918(69)90065-1
   Ferreira VS, 2002, J EXP PSYCHOL LEARN, V28, P1187, DOI 10.1037//0278-7393.28.6.1187
   Fromkin V.A., 1973, SPEECH ERRORS LINGUI
   Garrett M.F., 1975, PSYCHOL LEARNING MOT, P133
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Levelt WJM, 2000, EUR J COGN PSYCHOL, V12, P433, DOI 10.1080/095414400750050178
   MACLEOD CM, 1991, PSYCHOL BULL, V109, P163, DOI 10.1037/0033-2909.109.2.163
   Mandler, 1964, THINKING ASS GESTALT
   Meringer R., 1895, VERSPRECHEN VERLESEN
   Meyer AS, 2003, J MEM LANG, V48, P131, DOI 10.1016/S0749-596X(02)00509-0
   Miller EK, 2000, NAT REV NEUROSCI, V1, P59, DOI 10.1038/35036228
   Paus T, 2001, NAT REV NEUROSCI, V2, P417, DOI 10.1038/35077500
   ROELOFS A, 1992, COGNITION, V42, P107, DOI 10.1016/0010-0277(92)90041-F
   Roelofs A, 1997, COGNITION, V64, P249, DOI 10.1016/S0010-0277(97)00027-9
   Roelofs A, 2004, PSYCHOL REV, V111, P561, DOI 10.1037/0033-295X.111.2.561
   Roelofs A, 2003, PSYCHOL REV, V110, P88, DOI 10.1037/0033-295X.110.1.88
   Roelofs A, 2002, COGNITIVE BRAIN RES, V15, P85, DOI 10.1016/S0926-6410(02)00218-5
   SIMON HA, 1967, PSYCHOL REV, V74, P29, DOI 10.1037/h0024127
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   WILDE O, 1893, LADY WINDERMERES FAN
   Wundt W., 1897, OUTLINES PSYCHOL
NR 25
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-22340-1
J9 LECT NOTES ARTIF INT
PY 2004
VL 3123
BP 1
EP 10
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BAK12
UT WOS:000222627300001
DA 2023-11-10
ER

PT J
AU Wolk, K
   Wolk, A
   Wnuk, D
   Grzes, T
   Skubis, I
AF Wolk, Krzysztof
   Wolk, Agnieszka
   Wnuk, Dominika
   Grzes, Tomasz
   Skubis, Ida
TI Survey on dialogue systems including slavic languages
SO NEUROCOMPUTING
LA English
DT Article
DE Slavic languages; Task-oriented dialogue systems; Non-task-oriented
   dialogue systems; Chatbots; Machine learning; Artificial intelligence
ID NEURAL-NETWORK; SPEECH RECOGNITION; COMMUNICATION; GENERATION; MODELS
AB Slavic languages pose a challenge to the researchers in the domain of dialogue technology. A relatively free word order with a large degree of inflection, such as conjugation of verbs, and declension of adjectives, pronouns, and nouns are exhibited by the Slavic languages, which has a significant impact on the size of lexical inventories that significantly complicate the design of dialogue systems. This article conducts an empirical study on the state-of-the-art dialogue systems within Slavic languages. Moreover, we review the existing models in recent dialogue systems, pinpoint the current main challenges and identify potential research directions of practical and intelligent systems within low-resourced languages. (C) 2021 Published by Elsevier B.V.
C1 [Wolk, Krzysztof; Wolk, Agnieszka; Wnuk, Dominika; Grzes, Tomasz; Skubis, Ida] Polish Japanese Acad Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.
   [Wolk, Agnieszka; Grzes, Tomasz] Bialystok Tech Univ, Fac Comp Sci, Wiejska 45A, PL-15351 Bialystok, Poland.
   [Wnuk, Dominika; Skubis, Ida] Jan Dlugosz Univ Czestochowa, Waszyngtona 4-8, PL-42200 Czestochowa, Poland.
C3 Polsko-Japonska Akademia Technik Komputerowych; Bialystok University of
   Technology; Jan Dlugosz University
RP Wolk, K (通讯作者)，Polish Japanese Acad Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.
EM kwolk@pja.edu.pl; awolk@pja.edu.pl; dwnuk@pja.edu.pl; t.grzes@pb.edu.pl
RI Skubis, Ida/ADS-8213-2022; Wołk, Krzysztof/E-9957-2015; Grzes,
   Tomasz/S-9089-2018
OI Skubis, Ida/0000-0002-2447-9832; Wołk, Krzysztof/0000-0001-5030-334X;
   Grzes, Tomasz/0000-0002-6039-6153
CR Adamopoulou E., 2020, MACHINE LEARNING APP, V2, DOI [10.1016/j.mlwa.2020.100006, DOI 10.1016/J.MLWA.2020.100006]
   AGic ZELJKo, 2013, P 4 BIENNIAL INT WOR, P48
   AISB, 2018, LOEBN PRIZ RES 2018
   Almansor EH, 2020, ADV INTELL SYST COMP, V993, P534, DOI 10.1007/978-3-030-22354-0_47
   Alperen MS, 2010, P LREC WORKSHOP EXPL, P49
   Androutsopoulou A, 2019, GOV INFORM Q, V36, P358, DOI 10.1016/j.giq.2018.10.001
   [Anonymous], MAKE CONVERSATIONAL
   [Anonymous], 1998, NULL SUBJECT PROPERT
   [Anonymous], 2019, YANDEX CO NEWS YANDE
   Anstatt T., 2016, TUBINGER BEITRAGE LI, V554
   Arkhipov M, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP'2019), P89
   Artemova E., PALGRAVE HDB DIGITAL, V2021, P465
   AZBot, 2018, ONLINE CHATBOT
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P85
   Bhagwat VA, 2018, DEEP LEARNING CHATBO
   Bhowmik K., 2021, DIGITAL, V3, DOI [10.3390/digital1030011, DOI 10.3390/DIGITAL1030011]
   Bordes A., 2016, ABS160507683 C0RR
   Boyd A., 2020, ABS200506114 CORR
   Browne W., 2020, SLAVIC LANGUAGES W S
   Bystrov Y., 2018, STUDIES LANGUAGES, V33, P17
   Chatbots.org, 2021, CHATB ANN IKEA VIRT
   Chatbots.org, 2021, CHATB ORG SLOV VIRT
   Chatbots.org, 2020, CHATB ORG SLOV VIRT
   Chatbots.org, 2020, CHATB ORG VIRT ASS V
   Chatbots.org, 2020, CHATB ORG POL POL VI
   Chatbots.org, 2020, CHATB ORG CZECH REP
   Chatbots.org, 2013, CHATBOT SINK ITC VIR
   Chatbots.org, 2020, CHATB TEPSON TEL POL
   Chatbots.org, 2020, CHATB ORG RUSS VIRT
   Chen C.-Y., 2018, 2 AL PRIZ P AL PRIC
   Chen Y., 2017, P 55 ANN M ASS COMP, P8
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Cinque G., 2005, OXFORD HDB COMP SYNT
   Clutch, 2020, TOP CHATBOT CO POLAN
   Clutch, 2020, TOP ARTIFICIAL INTEL
   Csaky R., 2019, ABS190808835 CORR
   Dadas S., 2019, ARXIV PREPRINT ARXIV
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Deriu J, 2021, ARTIF INTELL REV, V54, P755, DOI 10.1007/s10462-020-09866-x
   Devlin J., 2018, ARXIV, V1, P4171
   DHaro L.F., 2019, 9 INT WORKSH SPOK DI
   Dinan E., 2018, ARXIV181101241
   Dropuljic B, 2011, INT SYMP IMAGE SIG, P95
   Dyer Chris, 2013, P 2013 C N AM CHAPTE, P644
   Engelbrecht K.-P., 2008, P ESSV, P86
   Eric M., 2017, ABS170104024 CORR
   Ezquerra A.N., 2018, THESIS UPC
   Fang H., 2017, P ALEXA PRIZE ALEXA
   Galley M., 2015, ABS150606863 CORR
   Ghazvininejad M, 2018, AAAI CONF ARTIF INTE, P5110
   Goddeau D, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P701, DOI 10.1109/ICSLP.1996.607458
   Goo C.-W., 2018, P 2018 C N AM CHAPT, V2
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ham D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P583
   Hancock B., 2019, ABS190105415 CORR
   Henderson M., 2019, ABS190901296 CORR
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Hu BT, 2014, ADV NEUR IN, V27
   Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123
   Igras Magdalena, 2013, Studia Informatica, V34, P67
   Ji Z., 2014, INFORM RETRIEVAL APP, Vabs/1408.6988
   Jung S, 2019, COMPUT SPEECH LANG, V56, P130, DOI 10.1016/j.csl.2018.12.008
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC
   Jurdzinski G., 2016, SCHEDAE INFORM, V25
   Just AI, 2019, SMART SPEAKERS VOICE
   Justin T, 2015, LECT NOTES ARTIF INT, V9302, P351, DOI 10.1007/978-3-319-24033-6_40
   Kaleta R., 2013, ACTA POLONO RUTHENIC, P185
   Kandasamy K., 2017, ABS170203334 CORR
   Kapoc J., 2020, APPL SCI, V10
   Khoury R.E., 2019, GOOGLE ASSISTANT IS
   Kim D, 2014, INTERSPEECH, P328
   Kinsella B., 2018, GOOGLE ASSISTANT ROL
   Kipyatkova IS, 2017, AUTOMAT REM CONTR+, V78, P858, DOI 10.1134/S0005117917050083
   Klosowski P, 2019, SIG P ALGO ARCH ARR, P223, DOI [10.23919/spa.2019.8936782, 10.23919/SPA.2019.8936782]
   Koehn P., 2017, WMT, P28
   Koidan K., 2020, EVALUATION METRICS D
   Kosta P., 2009, THESIS
   Kuligowska K., 2018, ANN U M CURIESKLODOW, V52, P71
   Kuligowska K., 2015, PCBR, DOI DOI 10.18483/PCBR.22
   Kumar R., 2020, INT J ENG TECHNOLOGY, V7, P2791
   Kuratov Y., 2019, ABS190507213 CORR
   Laurisz M., 2020, RAPORT CHATBOTY POLS
   Lenc L, 2017, LECT NOTES COMPUT SC, V10614, P368, DOI 10.1007/978-3-319-68612-7_42
   Leuski A, 2011, AI MAG, V32, P42, DOI 10.1609/aimag.v32i2.2347
   Li J., 2015, ABS151003055
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Li Jiwei, 2017, EMNLP
   Li Jiwei, 2016, EMNLP
   Li X, 2020, AAAI CONF ARTIF INTE, V34, P8253
   Li Z., 2019, ABS190708854 CORR
   Li Z., 2020, ABS200909781 CORR
   Li Z, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111756
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, DOI DOI 10.2307/3105454
   Lison P., 2017, ABS170408966 CORR
   Liu B., 2018, ABS180406512 CORR
   Liu B, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1237, DOI 10.1145/3178876.3186022
   Liu SM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1489
   Ljubesic N, 2011, LECT NOTES ARTIF INT, V6836, P395, DOI 10.1007/978-3-642-23538-2_50
   Ljubesic Nikola, 2014, P 9 WEB CORPUS WORKS, P29, DOI [10.3115/v1/W14-0405, DOI 10.3115/V1/W14-0405]
   de Lacalle ML, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2796
   Lowe R., 2017, ABS170807149 CORR
   Lowe Ryan, 2015, P 16 ANN M SPECIAL I, P285, DOI 10.18653/v1/W15-4640
   Luong T., 2013, P 17 C COMP NAT LANG, P104, DOI DOI 10.1007/BF02579642
   Lyda A., 2013, OCCUPYING NICHES INT
   Ma YK, 2020, INFORM FUSION, V64, P50, DOI 10.1016/j.inffus.2020.06.011
   Magyar J, 2019, IEEE SYS MAN CYBERN, P3416, DOI 10.1109/SMC.2019.8914248
   Makarova V., 2002, 7 INT C SPOK LANG PR, P2041
   Maliszewski M., 2018, RAPORT POLSKIE CHATB
   Mateju L, 2018, INTERSPEECH, P1803, DOI 10.21437/Interspeech.2018-1165
   Mei H., 2015, ABS150900838 CORR
   Migdalski K, 2018, HANDB SPRACH KOMMUN, V41, P1557, DOI 10.1515/9783110542431-004
   Ministry of Health of the Czech Republic, 2020, CZECH MIN HLTH LAUNC
   Mnasri M., 2019, CHATBOTS APPROACHES
   Mrksic N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1777, DOI 10.18653/v1/P17-1163
   Multikino S.A., CHATBOT 2020 LOG SIG
   Neagu C., 2020, 2 WAYS CHANGE LANGUA
   Nedeljkovic Z, 2020, ARCH ACOUST, V45, P129, DOI 10.24425/aoa.2020.132489
   Nouza J, 2010, LECT NOTES COMPUT SC, V5967, P225
   NTT 2020, NTT CZECH REP LAUNCH
   Nugmanova A, 2019, INT CONF PERVAS COMP, P844, DOI [10.1109/PERCOMW.2019.8730665, 10.1109/percomw.2019.8730665]
   Oklesinski D., 2019, IMPLEMENTATION CURRE
   Olabiyi O., 2018, ABS180511752 CORR
   Olbert M.B., 2019, GOOGLE COMMUNISM ARE
   Papernot N., 2016, ABS161005755 CORR
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Paul A, 2019, J INFORM TELECOMMUN, V3, P248, DOI 10.1080/24751839.2018.1558378
   Pearson J.C., 1989, INTRO HUMAN COMMUNIC
   Qian Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4279
   Qiu MH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P498, DOI 10.18653/v1/P17-2079
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Rai Siddhant, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1367, DOI 10.1109/ICECA.2018.8474861
   Ranoliya BR, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1525, DOI 10.1109/ICACCI.2017.8126057
   Rao S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2737
   Rejestr TERYT, 2018, GLOWNY URZD STATYSTY
   Rogalski M, 2016, LECT NOTES ARTIF INT, V9692, P126, DOI 10.1007/978-3-319-39378-0_12
   Rudnicky Alexander, 2016, P 17 ANN M SPEC INT, P404
   Rychalska B, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P256, DOI 10.1109/SNAMS.2018.8554770
   Safarik R., 2015, P IEEE WORKSH ECMSM, P1
   Schwartz E.H., 2019, MEET ONLY VOICE ASSI
   Schwartz E.H., 2020, APPLE IS HIRING SIRI
   See A., 2019, ABS190208654 CORR
   Serban I.V., 2017, ABS170902349 CORR
   Serban I. V., 2015, ABS150704808 CORR
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Serban IV, 2018, DIALOGUE DISCOURSE, V9
   Shaheen Z., 2020, ABS200502470 CORR
   Shaikh A., 2019, INT RES J ENG TECHNO, V6, P1786
   Shang L., 2016, P 12 NTCIR C EV INF
   Shang LF, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1577
   Sharad S., 2017, UNPACKING NOVELTY AN, P1, DOI DOI 10.2139/SSRN.2388254
   Shaw D., 1996, WELCOME WALRUS
   Siewierska Anna, 2010, CONSTITUENT ORDER LA, P105
   Simeonova L., 2019, ABS190810261 CORR
   Sojasingarayar A., 2020, ABS200602767 CORR
   Song Y., 2016, ABS161007149 CORR
   Stachowicz-Stanusch A., 2018, ORGANIZACJA ZARZDZAN, V2, P63
   Staroniewicz P, 2009, LECT NOTES COMPUT SC, V5641, P42, DOI 10.1007/978-3-642-03320-9_5
   Stent A, 2005, LECT NOTES COMPUT SC, V3406, P341
   Su S., 2018, ABS180809442 CORR
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Sun Yu, 2019, ARXIV190409223
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Tarasov D.S., 2017, P INT C DIAL 2017 CO
   Templeton G., 2020, LANGUAGE SUPPORT VOI
   The Columbia Electronic Encyclopedia, 2012, THE SLAVIC LANGUAGES
   Tian ZL, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P231, DOI 10.18653/v1/P17-2036
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Tur G, 2011, SPOKEN LANGUAGE UNDE
   Vanjani M., 2019, J MANAG SCI BUS INTE, V4, P19
   Vasic D, 2018, 2018 26TH INTERNATIONAL CONFERENCE ON SOFTWARE, TELECOMMUNICATIONS AND COMPUTER NETWORKS (SOFTCOM), P327
   Vaswani A., 2017, ARXIV, V30, P5998
   Vatian A, 2019, LECT NOTES COMPUT SC, V11871, P175, DOI 10.1007/978-3-030-33607-3_20
   Venkatesh A., 2019, GOOGLE ASSISTANTS IN
   Vinyals O, 2015, COMPUTER SCI, DOI DOI 10.48550/ARXIV.1506.03134
   Walker M.A., 1997, CMPLG9704004 CORR
   Wallace R, 2003, ELEMENTS AIML STYLE, DOI 10.1.1.693.3664.
   Wang Hao, 2013, P 2013 C EMPIRICAL M, P935
   Wang M., 2015, ABS150302427 CORR
   Wang WJ, 2018, ACM/SIGIR PROCEEDINGS 2018, P255, DOI 10.1145/3209978.3210061
   Ward NG, 2016, AI MAG, V37, P7
   Watanabe S., 2014, 15 ANN C INT SPEECH
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wen T., 2015, ABS150801745 CORR
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   Werner R., 2020, THESIS DEP APPL MATH
   Wielka O.S., 2020, POMOCY CHATBOT LOG S
   Williams J. D., 2016, ARXIV160601269
   Wolk A., 2021, MULTILINGUAL CHATBOT
   Wu Y, 2018, NEUROCOMPUTING, V316, P251, DOI 10.1016/j.neucom.2018.07.073
   Wu YX, 2019, AAAI CONF ARTIF INTE, P7289
   Xing C, 2017, AAAI CONF ARTIF INTE, P3351
   Xu Z., 2017, P 2017 C EMPIRICAL M, P617, DOI DOI 10.18653/V1/D17-1065
   Yan R, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/2911451.2911542
   Yan Z, 2017, AAAI CONF ARTIF INTE, P4618
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Yue G., 2020, DOUBLE NEGATION CONS
   Zhang H., 2019, ABS190705339 CORR
   Zhang WN, 2019, WORLD WIDE WEB, V22, P1427, DOI 10.1007/s11280-018-0598-6
   Zhang Z., 2019, ABS190600499 CORR
   Zhang Z, 2020, SCI CHINA TECHNOL SC, V63, P2011, DOI 10.1007/s11431-020-1692-3
   Zhao T., 2017, ABS170608476 CORR
   Zhao T., 2016, ABS160602560 CORR
   Zheng Yinhe, 2019, ARXIV190109672
   Zhou H., 2017, ABS170401074 CORR
   Zhou H., P 27 INT JOINT C ART, P4623
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/COLI_a_00368, 10.1162/coli_a_00368]
NR 207
TC 4
Z9 4
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAR 7
PY 2022
VL 477
BP 62
EP 84
DI 10.1016/j.neucom.2021.11.076
EA JAN 2022
PG 23
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI5VK
UT WOS:000761688500007
DA 2023-11-10
ER

PT J
AU Malhotra, S
   Kumar, V
   Agarwal, A
AF Malhotra, Shivani
   Kumar, Vinay
   Agarwal, Alpana
TI Bidirectional transfer learning model for sentiment analysis of natural
   language
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Universal language model fine-tuning (ULMFit); Bidirectional encoder
   representations from transformers (BERT); Average stochastic gradient
   weight-dropped LSTM (AWD-LSTM); Transfer learning; Sentiment
   classification
AB The contemporary unsupervised word representation methods have been successful in capturing semantic statistics on various Natural Language Processing tasks. However, these methods proved to be futile in addressing tasks like polysemy or homonymy, which prevail in such tasks. There has been a rise in the number of state-of-the-art transfer learning techniques bringing into play the language models pre-trained on large inclusive corpus. Motivated by these techniques, the present paper proposes an efficacious transfer learning based ensemble model. This model is inspired by ULMFit and presents results on challenging sentiment analysis tasks such as contextualization and regularization. We have empirically validated the efficiency of our proposed model by applying it to three conventional datasets for sentiment classification task. Our model accomplished the state-of-the-art outcomes remarkably when compared to acknowledged baselines in terms of classification accuracy.
C1 [Malhotra, Shivani; Kumar, Vinay; Agarwal, Alpana] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Malhotra, S (通讯作者)，Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM smalhotra_phd18@thapar.edu
RI Malhotra, Shivani/AAL-5821-2021
FU Google Cloud Platform
FX This work was supported by free academic credits from Google Cloud
   Platform.
CR Abid F, 2020, COMPUT COMMUN, V157, P102, DOI 10.1016/j.comcom.2020.04.002
   [Anonymous], 2013, ROLE SYNTAX VECTOR S
   Bahdanau Dzmitry, 2015, 3 INT C LEARN REPR I
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bird S., 2009, NATURAL LANGUAGE PRO, Vfirst
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Bouazizi M, 2017, IEEE ACCESS, V5, P20617, DOI 10.1109/ACCESS.2017.2740982
   Cambria E, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.4531228
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Crowdflower, 2016, AIRL TWITT SENT
   de Araujo PHL, 2020, INFERRING SOURCE OFF, P76
   Devlin J., 2018, ARXIV, V1, P4171
   Glorot Xavier, 2011, ICML, DOI DOI 10.1177/1753193411430810
   Gupta C, 2019, NOVEL APPROACH FEATU, P661
   Haddoud M, 2016, KNOWL INF SYST, V49, P909, DOI 10.1007/s10115-016-0924-1
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Jean-Francois P, 2017, FEATURE ENG DEEP LEA
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Joulin A, 2017, P 15 C EUR CHAPT ASS, P427
   Krishnamurthy Gangeshwar, 2018, ARXIV180300344
   Le Q, 2014, INT C MACHINE LEARNI, V32, DOI [DOI 10.1145/2740908.2742760, 10.5555/3044805.3045025]
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   McCann B, 2017, LEARNED TRANSLATION, P6294
   Mikolov T., 2013, ARXIV13013781 CS, DOI DOI 10.48550/ARXIV.1301.3781
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Neelakantan A, 2015, EFFICIENT NONPARAMET, P1059
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pathak AR, 2020, ALGO INTELL SY, P1, DOI 10.1007/978-981-15-1216-2_1
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Pérez-Rosas V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P59, DOI 10.1145/2818346.2820758
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rane A, 2018, SENTIMENT CLASSIFICA, P769
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Shaukat Z, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1926-x
   Socher, 2018, REGULARIZING OPTIMIZ
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang YX, 2020, INT J MACH LEARN CYB, V11, P1611, DOI 10.1007/s13042-020-01069-8
   Wu YJ, 2020, NEUROCOMPUTING, V390, P88, DOI 10.1016/j.neucom.2020.01.064
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yosinski J., 2014, TRANSFERABLE ARE FEA, P3320
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhao JQ, 2017, IEEE ACCESS, V5, P2870, DOI 10.1109/ACCESS.2017.2672677
   Zheng JM, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102215
NR 51
TC 3
Z9 3
U1 0
U2 19
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD NOV
PY 2021
VL 12
IS 11
BP 10267
EP 10287
DI 10.1007/s12652-020-02800-7
EA JAN 2021
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UT9GM
UT WOS:000604217200009
DA 2023-11-10
ER

PT J
AU Liu, XD
   Duh, K
   Matsumoto, Y
AF Liu, Xiaodong
   Duh, Kevin
   Matsumoto, Yuji
TI Multilingual Topic Models for Bilingual Dictionary Extraction
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Algorithms; Experimentation; Languages; Bilingual dictionary;
   multilingual topic model; comparable corpus
AB A machine-readable bilingual dictionary plays a crucial role in many natural language processing tasks, such as statistical machine translation and cross-language information retrieval. In this article, we propose a framework for extracting a bilingual dictionary from comparable corpora by exploiting a novel combination of topic modeling and word aligners such as the IBM models. Using a multilingual topic model, we first convert a comparable document-aligned corpus into a parallel topic-aligned corpus. This novel topic-aligned corpus is similar in structure to the sentence-aligned corpus frequently employed in statistical machine translation and allows us to extract a bilingual dictionary using a word alignment model.
   The main advantages of our framework is that (1) no seed dictionary is necessary for bootstrapping the process, and (2) multilingual comparable corpora in more than two languages can also be exploited. In our experiments on a large-scale Wikipedia dataset, we demonstrate that our approach can extract higher precision dictionaries compared to previous approaches and that our method improves further as we add more languages to the dataset.
C1 [Liu, Xiaodong; Duh, Kevin; Matsumoto, Yuji] Nara Inst Sci & Technol, Grad Sch Informat Sci, Computat Linguist Lab, 8916-5 Takayama, Ikoma, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Liu, XD (通讯作者)，Nara Inst Sci & Technol, Grad Sch Informat Sci, Computat Linguist Lab, 8916-5 Takayama, Ikoma, Nara 6300192, Japan.
EM Iiuxiaodongby@gmail.com
FU China Scholarship Council (CSC); JSPS KAKENHI Grant [26730121];
   Grants-in-Aid for Scientific Research [26730121] Funding Source: KAKEN
FX This work is partially supported by the China Scholarship Council (CSC)
   and JSPS KAKENHI Grant Number 26730121.
CR Aker Ahmet, 2014, P 9 INT C LANG RES E
   Andrade D, 2011, LECT NOTES COMPUT SC, V6609, P80, DOI 10.1007/978-3-642-19437-5_7
   Andrzejewski David, 2009, Proc Int Conf Mach Learn, V382, P25
   [Anonymous], 2009, P ACM INT C INFORM K, DOI DOI 10.1145/1645953.1646020
   [Anonymous], 2002, LEXICOMETRICA
   [Anonymous], 2013, P CONLL
   [Anonymous], 2004, P ACL
   [Anonymous], 2010, P NIPS US
   [Anonymous], 2012, P 2012 JOINT C EMP M
   [Anonymous], 2011, ACL HLT 2011 P 49 AN
   [Anonymous], P 6 WORKSH BUILD US
   [Anonymous], 2011, P 49 ANN M ASS COMPU
   Baldwin T., 2011, P WORKSH MULT EXPR P, P1
   Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bond Francis, 2008, P 6 INT C LANG RES E
   Boyd-Graber Jordan, 2009, P 25 C UNC ART INT U
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Fung P., 1998, P 36 ANN M ASS COMP
   Fung Pascale, 2004, P C EMP METH NAT LAN
   Gollins Tim, 2001, P 24 ACM C SPEC INT
   Haghighi A., 2008, ACL
   Heinrich G, 2004, PARAMETER ESTIMATION
   Hu YN, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1166
   Jagarlamudi Jagadeesh, 2010, P 32 EUR C ADV INF R
   Kevin Duh, 2013, ACM T SPEECH LANG PR, V10, P1, DOI DOI 10.1145/2442076.2442077
   Klementiev, 2012, P COLING 2012, P1459
   Koehn P., 2010, STAT MACHINE TRANSLA
   Koehn Philipp, 2002, ACL WORKSHOP UNSUPER
   Laroche Audrey, 2010, P 23 INT C COMP LING
   Liang Percy, 2006, P HUM LANG TECHN C N, P104, DOI DOI 10.3115/1220835.1220849
   Magnini B, 1994, P INT WORKSH FUT DIC
   Mausam Stephen Soderland, 2009, P 47 M ASS COMP LING
   Mimno David, 2009, P C EMP METH NAT LAN
   Minka Thomas, 2000, ESTIMATING DIRICLET
   Neubig G., 2011, PROC 49 ANN M ASS CO, P529
   Ni Xiaochuan, 2009, P 18 INT C WORLD WID
   Och FJ, 2003, COMPUT LINGUIST, V29, pc
   Paul Michael, 2009, P N AM CHAPT ASS COM
   Rapp R., 1995, P 33 ANN M ASS COMP
   RESNIK P., 2001, P 1 INT C HUM LANG T, P1
   Riley Darcey, 2010, TECHNICAL REPORT
   Sadat Fatiha, 2002, P SEM PAP
   Sarath Chandar AP, 2014, P NIPS
   Teh Y. W., 2006, ADV NEURAL INFORM PR, V19, P1353
   Vaswani Ashish, 2012, P 50 ANN M ASS COMP, V1, P311
   Volkova Svitlana, 2013, P C EMP METH NAT LAN, P18
   Wu H., 2009, P JOINT C 47 ANN M A, P154
   Zhang D, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1128
   [No title captured]
NR 50
TC 8
Z9 9
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN
PY 2015
VL 14
IS 3
AR 11
DI 10.1145/2699939
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE5QN
UT WOS:000370686400002
DA 2023-11-10
ER

PT J
AU Fakhfakh, S
   Ben Jemaa, Y
AF Fakhfakh, Sana
   Ben Jemaa, Yousra
TI Deep Learning Shape Trajectories for Isolated Word Sign Language
   Recognition
SO INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY
LA English
DT Article
DE Sign language; isolated word recognition; shape trajectory analysis;
   deep learning; RWTH-Boston dataset; SIGNUM corpora
AB In this paper, we propose an efficient trajectories analysis solution for the recognition of Isolated Word Sign Language (IWSL). The key technique innovation in this work is the shape trajectories analysis based on the deep learning method and achieved impressive results on different IWSL data sets: German: Rheinisch Westf??lische Technische Hochschule(RWTH): RWTH-Boston-50 and RWTH-Boston-104(95.83%), Signer-Independent Continuous Sign Language Recognition for Large Vocabulary Using Subunit Models (SIGNUM: 98.21%) and new Tunisian Sign Language database (TunSigns: 98%).
C1 [Fakhfakh, Sana; Ben Jemaa, Yousra] El Manar Univ Tunis, L3S Lab, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar
RP Fakhfakh, S (通讯作者)，El Manar Univ Tunis, L3S Lab, Tunis, Tunisia.
EM sana.fakhfakh@enis.tn; yousra.benjemaa@enis.tn
OI Yousra, Ben Jemaa/0000-0002-0093-3391
CR Agrawal SC, 2016, INT J APPL PATTERN R, V3, P99, DOI 10.1504/IJAPR.2016.079048
   [Anonymous], 2012, TRENDS TOPICS COMPUT
   Balaji SR, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P469, DOI 10.1109/ISCO.2017.7856037
   Ben Tanfous A, 2018, PROC CVPR IEEE, P2840, DOI 10.1109/CVPR.2018.00300
   Bhuyan MK., 2008, WORLD ACAD SCI ENG T, V2, P753
   Boulares M, 2012, PROCEDIA COMPUT SCI, V13, P133, DOI 10.1016/j.procs.2012.09.122
   Fakhfakh S, 2017, I C COMP SYST APPLIC, P774, DOI 10.1109/AICCSA.2017.67
   Gopura RARC, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P269, DOI 10.1109/ICCAR.2017.7942701
   Li GF, 2019, IEEE ACCESS, V7, P23713, DOI 10.1109/ACCESS.2018.2887223
   Lim K., MULTIMED TOOLS APPL, V78, P19917
   Lin WY, 2013, PATTERN RECOGN, V46, P662, DOI 10.1016/j.patcog.2012.09.014
   Mohandes M, 2013, 2013 COMPUTING, COMMUNICATIONS AND IT APPLICATIONS CONFERENCE (COMCOMAP), P90, DOI 10.1109/ComComAp.2013.6533615
   Noubigh Z, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P69, DOI 10.1109/ASAR.2017.8067762
   Sidig AAI, 2018, INT J ADV COMPUT SC, V9, P283
   Singh K., P AAAI CONFERENCEON, P211
   Sokhib T, 2020, INT ARAB J INF TECHN, V17, P137, DOI 10.34028/iajit/17/1/16
   Teow MYW, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P167, DOI 10.1109/I2CACIS.2017.8239052
   Von Agris U, 2007, GESTURE HUMAN COMPUT, P11
   Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920
NR 19
TC 2
Z9 2
U1 2
U2 5
PU ZARKA PRIVATE UNIV
PI ZARQA
PA COLL COMPUTING & INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN
SN 1683-3198
J9 INT ARAB J INF TECHN
JI Int. Arab J. Inf. Technol.
PD JUL
PY 2022
VL 19
IS 4
BP 660
EP 666
DI 10.34028/iajit/19/4/10
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Y7DR
UT WOS:000826053300010
DA 2023-11-10
ER

PT J
AU Trieu, HL
   Tran, DV
   Ittoo, A
   Nguyen, LM
AF Hai-Long Trieu
   Duc-Vu Tran
   Ittoo, Ashwin
   Le-Minh Nguyen
TI Leveraging Additional Resources for Improving Statistical Machine
   Translation on Asian Low-Resource Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Statistical machine translation; pivot methods; sentence alignment;
   semantic similarity; low-resource languages
AB Phrase-based machine translation (MT) systems require large bilingual corpora for training. Nevertheless, such large bilingual corpora are unavailable for most language pairs in the world, causing a bottleneck for the development of MT. For the Asian language pairs-Japanese, Indonesian, Malay paired with Vietnamese- they are also not excluded from the case, in which there are no large bilingual corpora on these low-resource language pairs. Furthermore, although the languages are widely used in the world, there is no prior work on MT, which causes an issue for the development of MT on these languages. In this article, we conducted an empirical study of leveraging additional resources to improve MT for the Asian low-resource language pairs: translation from Japanese, Indonesian, and Malay to Vietnamese. We propose an innovative approach that lies in two strategies of building bilingual corpora from comparable data and phrase pivot translation on existing bilingual corpora of the languages paired with English. Bilingual corpora were built from Wikipedia bilingual titles to enhance bilingual data for the low-resource languages. Additionally, we introduced a combined model of the additional resources to create an effective solution to improve MT on the Asian low-resource languages. Experimental results show the effectiveness of our systems with the improvement of +2 to +7 BLEU points. This work contributes to the development of MT on low-resource languages, especially opening a promising direction for the progress of MT on the Asian language pairs.
C1 [Hai-Long Trieu; Duc-Vu Tran; Le-Minh Nguyen] Japan Adv Inst Sci & Technol, Sch Informat Sci, Asahidai 1-1, Nomi, Ishikawa, Japan.
   [Ittoo, Ashwin] Univ Liege, QUANTOM Ctr Quantitat Methods & Operat Management, HEC Liege, Rue Louvrex 14, B-4000 Liege, Belgium.
C3 Japan Advanced Institute of Science & Technology (JAIST); University of
   Liege
RP Trieu, HL (通讯作者)，Japan Adv Inst Sci & Technol, Sch Informat Sci, Asahidai 1-1, Nomi, Ishikawa, Japan.
EM trieulh@jaist.ac.jp; vu.tran@jaist.ac.jp; Ashwin.Ittoo@ulg.ac.be;
   nguyenml@jaist.ac.jp
RI Trieu, Long/AAT-8117-2020; Tran, Vu/ABB-6144-2021
OI Trieu, Long/0000-0002-2472-6370; Tran, Vu/0000-0002-0249-7570; Le Minh,
   Nguyen/0000-0002-2265-1010
CR [Anonymous], P 37 ANN M ASS COMP
   [Anonymous], ACL P ANN M ASS COMP
   [Anonymous], 2008, P ACL08 HLT SHORT PA
   [Anonymous], 2012, P 16 ANN C EUR ASS M
   [Anonymous], 2007, P 45 ANN M ASS COMP
   [Anonymous], 2005, P 10 MACH TRANSL SUM
   [Anonymous], 2013, LONG PAPERS
   [Anonymous], 2012, P 2012 C N AM CHAPTE
   [Anonymous], 2016, GOOGLES NEURAL MACHI
   [Anonymous], 2004, P EMNLP
   [Anonymous], 1991, P 29 ANN M ASS COMP
   [Anonymous], 2012, P 13 C EUR CHAPT ASS
   Axelrod A., 2011, P C EMP METH NAT LAN, P355
   Bojar Ondrej., 2013, P 8 WORKSHOP STAT MA, P1
   Cettolo Mauro, 2011, P 15 INT C EUR ASS M
   CHEN SF, 1993, P 31 ANN M ASS COMP, P9
   Chu CH, 2016, ACM T ASIAN LOW-RESO, V15, DOI 10.1145/2833089
   Chu CH, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P642
   De Gispert Adria, 2006, P 5 INT C LANG RES E, P65
   Dekai Wu, 1994, 32nd Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference, P80
   El Kholy Ahmed, 2013, P 51 ANN M ASS COMPU, V2, P412
   Gale W. A., 1993, Computational Linguistics, V19, P75
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Irvine A., 2013, PROC INT C ADV COMPU, P54
   Isahara, 2007, HUMAN LANGUAGE TECHN, P484
   KAY M, 1993, COMPUT LINGUIST, V19, P1
   Kim S., 2012, P 50 ANN M ASS COMP, P694
   Koehn P., 2010, P JOINT 5 WORKSH STA, P115
   KOEHN P, 2009, P 12 MACH TRANSL SUM
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Lembersky G, 2013, COMPUT LINGUIST, V39, P999, DOI 10.1162/COLI_a_00159
   Li Bo, 2008, P 3 INT JOINT C NAT
   Ma Jeff, 2011, P 13 MACHINE TRANSL
   Ma Xiaoyi, 2006, P 5 INT C LANG RES A
   Marujo Luis, 2011, P 15 ANN C EUR ASS M, P129
   Melamed I. Dan, 1996, P C EMP METH NAT LAN
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Moore RC, 2002, LECT NOTES ARTIF INT, V2499, P135
   Munteanu DS, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P81
   Musleh B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091492
   Neubig Graham, 2011, KYOTO FREE TRANSLATI
   Nuhn M., 2012, P 50 ANN M ASS COMP, V1, P156
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Ravi Sujith, 2011, P 49 ANN M ASS COMP, P12
   Saluja A, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P676
   Singh Anil Kumar, 2005, P ACL WORKSH BUILD U, P99
   Stefanescu D, 2013, P 14 INT C INT TEXT, P24
   Thu YK, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1574
   Trieu Hai-Long, 2015, P 12 INT WORKSH SPOK
   Utiyama M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P72
   Varga D., 2007, RECENT ADV NATURAL L, VIV, P247, DOI DOI 10.1075/CILT.292.32VAR
   Wang PD, 2016, COMPUT LINGUIST, V42, P277, DOI 10.1162/COLI_a_00248
   Weber G., 1999, AATF NATL B, V24, P22
   Wu H, 2007, INT CONF NANO MICRO, P856
   Yasuda Keiji, 2008, P 3 INT JOINT C NATU, V2, P655
NR 55
TC 6
Z9 6
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL
PY 2019
VL 18
IS 3
AR 32
DI 10.1145/3314936
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA JN2YY
UT WOS:000496767600013
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Li, JL
   Zhang, ZS
   Zhao, H
AF Li, Junlong
   Zhang, Zhuosheng
   Zhao, Hai
TI Dialogue-adaptive language model pre-training from quality estimation
SO NEUROCOMPUTING
LA English
DT Article
DE Pre-trained language models; Dialogue-adaptive pre-training; Dialogue
   quality estimation; Open-domain dialogue systems
ID RESPONSE SELECTION
AB Pre-trained language models (PrLMs) have achieved great success on a wide range of natural language processing tasks by virtue of the universal language representation ability obtained by self-supervised learning on a large corpus. These models are pre-trained on standard plain texts with general language model (LM) training objectives, which would be insufficient to model dialogue-exclusive attributes like specificity and informativeness reflected in these tasks that are not explicitly captured by the pre -trained universal language representations. In this work, we propose dialogue-adaptive pre-training objectives (DAPO) derived from quality estimation to simulate dialogue-specific features, namely coher-ence, specificity, and informativeness. As the foundation for model pre-training, we synthesize a new dia-logue corpus and build our training set with two unsupervised methods: 1) coherence-oriented context corruption, including utterance ordering, insertion, and replacement, to help the model capture the coherence inside the dialogue contexts; and 2) specificity-oriented automatic rescoring, which encourages the model to measure the quality of the synthesized data for dialogue-adaptive pre-training by consid-ering specificity and informativeness. Experimental results on widely used open-domain response selec-tion and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of esti-mating quality evaluation factors into pre-training.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Li, Junlong; Zhang, Zhuosheng; Zhao, Hai] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Li, Junlong; Zhang, Zhuosheng; Zhao, Hai] Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interact, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.; Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interact, Shanghai, Peoples R China.
EM lockonn@sjtu.edu.cn; zhangzs@sjtu.edu.cn; zhaohai@cs.sjtu.edu.cn
RI Zhang, Zhuosheng/AAF-4919-2020
FU Key Projects of National Natural Science Foundation of China; 
   [U1836222];  [61733011]
FX q This paper was partially supported by Key Projects of National Natural
   Science Foundation of China (U1836222 and 61733011) .
CR Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, P65, DOI DOI 10.3115/1626355.1626389
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P85
   Barzilay Regina, 2005, P 43 ANN M ASS COMP, P141, DOI DOI 10.3115/1219840.1219858
   Cervone A, 2018, INTERSPEECH, P1011
   Clark Kevin, 2020, ICLR
   Cui LY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1406
   Devlin J., NAACL HLT, P4171, DOI 10.18653/v1/N19-1423
   Gopalakrishnan K, 2019, INTERSPEECH, P1891, DOI 10.21437/Interspeech.2019-3079
   Gu JC, 2021, IEEE-ACM T AUDIO SPE, V29, P2443, DOI 10.1109/TASLP.2021.3074788
   Gu XD, 2021, Arxiv, DOI arXiv:2012.01775
   Henderson Matthew, 2020, FINDINGS ASS COMPUTA, P2161, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.196
   Kingma D. P., 2014, C TRACK P
   Kumar P, 2020, AAAI CONF ARTIF INTE, V34, P8115
   Lan Zhenzhong, 2019, ABS190911942
   Le NQK, 2022, METHODS, V204, P199, DOI 10.1016/j.ymeth.2021.12.004
   Le NQK, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab005
   Li Yanran, 2017, IJCNLP
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Liu LX, 2021, AAAI CONF ARTIF INTE, V35, P13406
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Liu YK, 2021, AAAI CONF ARTIF INTE, V35, P13433
   Lowe R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1116, DOI 10.18653/v1/P17-1103
   Lowe Ryan, 2015, P 16 ANN M SPECIAL I, P285, DOI 10.18653/v1/W15-4640
   Mehri S, 2020, SIGDIAL 2020: 21ST ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2020), P225
   Mehri S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P681
   Mesgar M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1439
   Pang B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3619
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Radford A., IMPROVING LANGUAGE U
   Ran Q, 2019, Arxiv, DOI arXiv:1903.03033
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Sharma Shikhar, RELEVANCE UNSUPERVIS
   Smith EM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2021
   Su YX, 2021, IEEE-ACM T AUDIO SPE, V29, P2152, DOI 10.1109/TASLP.2021.3087948
   Sun Y, 2019, Arxiv, DOI [arXiv:1904.09223, DOI 10.48550/ARXIV.1904.09223]
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Tao CY, 2018, AAAI CONF ARTIF INTE, P722
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401
   Voorhees Ellen, 2000, P 2 INT C LANG RES E
   Whang T, 2020, INTERSPEECH, P1585, DOI 10.21437/Interspeech.2020-2153
   Wolf T., 2019, TRANSFERTRANSFO TRAN
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P917
   Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046
   Xu RJ, 2020, Arxiv, DOI arXiv:2009.06265
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yeh Y.-T., 2021, ARXIV
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang Tianyi, 2020, ICLR
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Zhang ZS, 2021, IEEE-ACM T AUDIO SPE, V29, P1161, DOI 10.1109/TASLP.2021.3058616
   Zhao TY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P26
   Zho XY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1118
NR 52
TC 1
Z9 1
U1 4
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 7
PY 2023
VL 516
BP 27
EP 35
DI 10.1016/j.neucom.2022.10.036
EA OCT 2022
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6N3KQ
UT WOS:000889456900003
OA Green Submitted
DA 2023-11-10
ER

PT J
AU De, A
   Bandyopadhyay, D
   Gain, B
   Ekbal, A
AF De, Arkadipta
   Bandyopadhyay, Dibyanayan
   Gain, Baban
   Ekbal, Asif
TI A Transformer-Based Approach to Multilingual Fake News Detection in
   Low-Resource Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Fake news detection; low-resource languages; multilingual; Hindi;
   Swahili; Indonesian; Vietnamese
AB Fake news classification is one of the most interesting problems that has attracted huge attention to the researchers of artificial intelligence, natural language processing, and machine learning (ML). Most of the current works on fake news detection are in the English language, and hence this has limited its widespread usability, especially outside the English literate population. Although there has been a growth in multilingual web content, fake news classification in low-resource languages is still a challenge due to the non-availability of an annotated corpus and tools. This article proposes an effective neural model based on the multilingual Bidirectional Encoder Representations from Transformer (BERT) for domain-agnostic multilingual fake news classification. Large varieties of experiments, including language-specific and domain-specific settings, are conducted. The proposed model achieves high accuracy in domain-specific and domain-agnostic experiments, and it also outperforms the current state-of-the-art models. We perform experiments on zero-shot settings to assess the effectiveness of language-agnostic feature transfer across different languages, showing encouraging results. Cross-domain transfer experiments are also performed to assess language-independent feature transfer of the model. We also offer a multilingual multidomain fake news detection dataset of five languages and seven different domains that could be useful for the research and development in resource-scarce scenarios.
C1 [De, Arkadipta] Indian Inst Technol Hyderabad, Hyderabad, India.
   [Bandyopadhyay, Dibyanayan; Gain, Baban; Ekbal, Asif] Indian Inst Technol Patna, Patna, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Hyderabad; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Patna
RP De, A (通讯作者)，Indian Inst Technol Hyderabad, Hyderabad, India.
EM ai20mtech14002@iith.ac.in; dibyanayan@gmail.com; gainbaban@gmail.com;
   asif@iitp.ac.in
RI Gain, Baban/AAX-8794-2020; Ekbal, Asif/JKI-7638-2023
OI Gain, Baban/0000-0001-8673-7078; De, Arkadipta/0000-0002-0460-1458
FU Artificial Intelligence-Natural Language ProcessingMachine Learning
   (AI-NLP-ML) Laboratory at the Indian Institute of Technology Patna,
   India; project "HELIOS-Hate, Hyperpartisan, and Hyperpluralism
   Elicitation and Observer System" - Wipro
FX The authors would like to acknowledge the Artificial
   Intelligence-Natural Language ProcessingMachine Learning (AI-NLP-ML)
   Laboratory at the Indian Institute of Technology Patna, India, for
   supporting the research work carried out in this article. The authors
   also gratefully acknowledge the partial support of the project "HELIOS
   -Hate, Hyperpartisan, and Hyperpluralism Elicitation and Observer
   System," sponsored by Wipro. Additionally, the authors would like to
   acknowledge the translators for checking the translation quality of the
   dataset.
CR Abonizio HQ, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12050087
   Agarap A. F., 2018, ARXIV PREPRINT ARXIV
   Barthel Michael, 2016, PEW RES CTR, V15, P12
   Bhatt Gaurav, 2017, ARXIV171203935 CORR
   Cer D., 2018, ARXIV180311175 CORR
   Conneau A, 2017, P C EMP METH NAT LAN, P670, DOI [10.18653/v1/d17-1070, DOI 10.18653/V1/D17-1070]
   Conroy N. K., 2015, P ASS INFORM SCI TEC, V52, P1, DOI [DOI 10.1002/PRA2.2015.145052010082, 10.1002/pra2.2015.145052010082]
   Devlin J., 2018, ARXIV, V1, P4171
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Goodyear Michael., 2020, FAKE NEWS TIME COVID, DOI [10.2139/ssrn.3740639, DOI 10.2139/SSRN.3740639]
   Guibon Gael, 2019, MULTILINGUAL FAKE NE
   Hanselowski A, 2018, P 27 INT C COMPUTATI, P1859
   Jamieson K.H., 2008, ECHO CHAMBER RUSH LI
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Lai G., 2017, EMNLP, P785, DOI DOI 10.18653/V1/D17-1082
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Nickerson R. S., 1998, REV GEN PSYCHOL, V2, P175
   Ofcom, 2020, COVID 19 NEWS INF CO
   Pagliardini Matteo, 2017, ARXIV170302507, DOI DOI 10.18653/V1/N18-1049
   Perez-Rosas V., 2018, P 27 INT C COMPUTATI, P3391
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Rubin VL., 2015, PROC ASS INF SCI TEC, V52, P1
   Saikh T., 2019, P 16 INT C NATURAL L, P230, DOI [10.48550/arXiv.2005.04938, DOI 10.48550/ARXIV.2005.04938]
   Thorne J., 2018, LONG PAPERS, P809, DOI DOI 10.18653/V1/N18-1074
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang A., 2019, ICLR 2019
   WHO, 2020, CORONAVIRUS DIS COVI
   Wu Y, 2016, ARXIV
   Zellers R, 2019, ADV NEUR IN, V32
NR 31
TC 2
Z9 2
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JAN
PY 2022
VL 21
IS 1
AR 9
DI 10.1145/3472619
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YU8KX
UT WOS:000752286700010
DA 2023-11-10
ER

PT J
AU Andras, P
AF Andras, P
TI Pattern languages: a new paradigm for neurocomputation
SO NEUROCOMPUTING
LA English
DT Article
DE dynamics; neural model; neural networks; pattern language
ID DYNAMICS
AB Existing neurocomputation models do not describe very faithfully biological neural systems. Here we offer a new look at neural activity data, by introducing the paradigm of pattern languages. Biological examples are presented to provide the biological grounding, and an artificial neural network is described as a simple example of how to interpret neural activity data in terms of pattern languages. The new approach places the emphasis on internal processing within the neural system, instead of the input/output processing, and offers a good balance between the consideration of individual neural activity and of the activity of large numbers of neurons. (C) 2004 Elsevier B.V. All rights reserved.
C1 Newcastle Univ, Sch Comp Sci, Dept Psychol, Neural Syst Grp, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England.
C3 Newcastle University - UK
RP Andras, P (通讯作者)，Newcastle Univ, Sch Comp Sci, Dept Psychol, Neural Syst Grp, Claremont Tower, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England.
EM peter.andras@ncl.ac.uk
RI Andras, Peter/AAV-1194-2020
OI Andras, Peter/0000-0002-9321-3296
CR András P, 2001, IEEE IJCNN, P654, DOI 10.1109/IJCNN.2001.939101
   Andras Peter, 2003, J Integr Neurosci, V2, P55, DOI 10.1142/S0219635203000172
   FREEMAN WJ, 1994, PROG BRAIN RES, V102, P319
   Grossberg S, 2001, NEUROSCI BIOBEHAV R, V25, P513, DOI 10.1016/S0149-7634(01)00030-6
   Haykin S, 1998, NEURAL NETWORKS COMP
   Nusbaum MP, 2002, NATURE, V417, P343, DOI 10.1038/417343a
   Rabinovich MI, 2000, INT J BIFURCAT CHAOS, V10, P913, DOI 10.1142/S0218127400000669
   Wolfram S., 2002, NEW KIND SCI, VVolume 5
NR 8
TC 6
Z9 6
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUN
PY 2004
VL 58
BP 223
EP 228
DI 10.1016/j.neucom.2004.01.047
PG 6
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832CX
UT WOS:000222245900035
DA 2023-11-10
ER

PT J
AU Lalrempuii, C
   Soni, B
   Pakray, P
AF Lalrempuii, Candy
   Soni, Badal
   Pakray, Partha
TI An Improved English-to-Mizo Neural Machine Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Neural machine translation; transformer; low-resource language; Mizo;
   BLEU; METEOR; TER
AB Machine Translation is an effort to bridge language barriers and misinterpretations, making communication more convenient through the automatic translation of languages. The quality of translations produced by corpus-based approaches predominantly depends on the availability of a large parallel corpus. Although machine translation of many Indian languages has progressively gained attention, there is very limited research on machine translation and the challenges of using various machine translation techniques for a low-resource language such as Mizo. In this article, we have implemented and compared statistical-based approaches with modern neural-based approaches for the English-Mizo language pair. We have experimented with different tokenization methods, architectures, and configurations. The performance of translations predicted by the trained models has been evaluated using automatic and human evaluation measures. Furthermore, we have analyzed the prediction errors of the models and the quality of predictions based on variations in sentence length and compared the model performance with the existing baselines.
C1 [Lalrempuii, Candy; Soni, Badal; Pakray, Partha] Natl Inst Technol, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Lalrempuii, C (通讯作者)，Natl Inst Technol, Silchar, India.
EM candy_rs@cse.nits.ac.in; badal@cse.nits.ac.in; partha@cse.nits.ac.in
RI Soni, Badal/ADL-8928-2022; Pakray, Partha/H-7805-2012
OI Soni, Badal/0000-0002-9617-9468; Pakray, Partha/0000-0003-3834-5154
CR Ahmadnia B, 2019, OPEN COMPUT SCI, V9, P268, DOI 10.1515/comp-2019-0019
   Ahmadnia B, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1209, DOI 10.1109/ICMLA.2018.00196
   Ahmadnia Benyamin, 2017, P INT C RECENT ADV N, P24, DOI [10.26615/978-954-452-049-6_004, DOI 10.26615/978-954-452-049-6_004]
   Al-Onaizan Yaser, 2016, P 2016 C EMP METH NA, P268, DOI DOI 10.18653/V1/D16-1026
   Almansor E. H., 2018, PROC INT C MACH LEAR, P347
   [Anonymous], 1992, INTRO MACHINE TRANSL
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bandyopadhyay Sivaji, 2018, ARXIVARXIV181204898
   Bentham J, 2016, MEX INT CONF ARTIF I, P8, DOI 10.1109/MICAI-2016.2016.00010
   Chen Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1925, DOI 10.18653/v1/P17-1176
   Chhangte L, 1993, THESIS U OREGON EUGE
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348
   DUTTA I, 2017, P C INT SPEECH COMM, DOI DOI 10.21437/INTERSPEECH.2017-1304
   Finn C, 2017, PR MACH LEARN RES, V70
   Gogoi P, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6458
   Gu JT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3622
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI [10.18653/v1/n18, DOI 10.18653/V1/N18]
   Gulcehre C., 2015, ARXIV150303535
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6098
   Hautli-Janisz A, 2015, MACH TRANSL, V29, P285, DOI 10.1007/s10590-015-9170-7
   He Di, 2016, ADV NEURAL INFORM PR, P820, DOI DOI 10.5555/3157096.3157188
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Khiangte Laltluangliana, 2008, MIZOS N E INDIA INTR
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   Knight Kevin, 2016, ABS160402201 CORR
   Koehn P., 2010, STAT MACHINE TRANSLA
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Lalrempuii Candy, 2020, MACHINE LEARNING IMA, P193
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039
   Levin E, 2006, MACH TRANSL, P383
   Luong Minh-Thang, 2015, EMNLP, P3
   Majumder G, 2018, LECT NOTES COMPUT SC, V9623, P623, DOI 10.1007/978-3-319-75477-2_45
   Och FJ, 2003, COMPUT LINGUIST, V29, pc
   Pakray P, 2015, 2015 FOURTEENTH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI), P3, DOI 10.1109/MICAI.2015.7
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pathak A, 2019, NEURAL COMPUT APPL, V31, P7615, DOI 10.1007/s00521-018-3601-3
   Pathak A, 2019, J INTELL SYST, V28, P465, DOI 10.1515/jisys-2018-0065
   Saini S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P676, DOI 10.1109/CICT.2015.123
   Sankaranarayanan, 2018, P 2018 C N AM CHAPT, P112, DOI DOI 10.18653/V1/N18-4016
   Sarkhel Sneha, 2011, ANN LIBR INF STUD, V57, P388
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, P223
   Somers H., 1999, Machine Translation, V14, P113, DOI 10.1023/A:1008109312730
   Stolcke Andreas, 2004, P 7 INT C SPOK LANG
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Unanue IJ, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P880
   Vaswani A., 2017, ARXIV, V30, P5998
   Zhang B, 2017, IEEE-ACM T AUDIO SPE, V25, P2424, DOI 10.1109/TASLP.2017.2751420
   Zheng H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4251
NR 50
TC 8
Z9 8
U1 3
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL
PY 2021
VL 20
IS 4
AR 61
DI 10.1145/3445974
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XB8OR
UT WOS:000721582900008
DA 2023-11-10
ER

PT J
AU Haq, I
   Qiu, WD
   Guo, J
   Tang, P
AF Haq, Ijazul
   Qiu, Weidong
   Guo, Jie
   Tang, Peng
TI Pashto offensive language detection: a benchmark dataset and monolingual
   Pashto BERT
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE BERT; Large language models; Low-resource languages; NLP; Offensive
   language detection; Pashto; Social media; Osn; Text processing; LLMs
AB Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: "offensive"and "not offensive". To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%.
C1 [Haq, Ijazul; Qiu, Weidong; Guo, Jie; Tang, Peng] Shanghai Jiao Tong Univ, Sch Cyber Sci & Engn, Shanghai, Minhang, Peoples R China.
C3 Shanghai Jiao Tong University
RP Haq, I (通讯作者)，Shanghai Jiao Tong Univ, Sch Cyber Sci & Engn, Shanghai, Minhang, Peoples R China.
EM hanjie@sjtu.edu.cn
CR Alakrot A, 2018, PROCEDIA COMPUT SCI, V142, P315, DOI 10.1016/j.procs.2018.10.491
   Benítez-Andrades JA, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.906
   Ali R, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101365
   Allan J, 2013, CONSTITUTIONAL COMME, V29, P59
   Alsafari Safa, 2020, Online Social Networks and Media, DOI 10.1016/j.osnem.2020.100096
   Althobaiti MJ, 2022, INT J ADV COMPUT SC, V13, P972
   Anand M, 2023, THEOR COMPUT SCI, V943, P203, DOI 10.1016/j.tcs.2022.06.020
   Aragon ME, 2019, IBERLEF SEPLN, P478
   Ataei TS, 2022, IEEE T AFFECTIVE COM, DOI [10.1109/taffc.2022.3219229, DOI 10.1109/TAFFC.2022.3219229]
   Basile V, 2019, P 13 INT WORKSH SEM, P54
   Pereira-Kohatsu JC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214654
   Chen Y, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P71, DOI 10.1109/SocialCom-PASSAT.2012.55
   Cohen-Almagor R, 2011, POLICY INTERNET, V3, DOI 10.2202/1944-2866.1059
   Conneau A, 2020, Arxiv, DOI [arXiv:1911.02116, 10.48550/arXiv.1911.02116]
   Dadvar Maral, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P693, DOI 10.1007/978-3-642-36973-5_62
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Del Vigna F, 2017, P 1 IT C CYB ITASEC1, P86, DOI 10.1051/matecconf/201712502035
   Deng JW, 2022, Arxiv, DOI arXiv:2201.06025
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   El-Alami FZ, 2022, J KING SAUD UNIV-COM, V34, P6048, DOI 10.1016/j.jksuci.2021.07.013
   Haq I, 2023, SPEECH COMMUN, V153, DOI 10.1016/j.specom.2023.102970
   Haq I, 2023, INT J ADV COMPUT SC, V14, P1344
   Husain F, 2022, INT CONF ASIAN LANG, P196, DOI 10.1109/IALP57159.2022.9961263
   Hussain S, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1169
   Ibrohim MO, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P46
   Iqbal S, 2022, J INTERNET TECHNOL, V23, P1669, DOI 10.53106/160792642022122307021
   Jay T, 2008, J POLITENESS RES-LAN, V4, P267, DOI 10.1515/JPLR.2008.013
   Khan S, 2022, J KING SAUD UNIV-COM, V34, P4335, DOI 10.1016/j.jksuci.2022.05.006
   Kudo T, 2018, Arxiv, DOI arXiv:1808.06226
   Kumar R, 2018, P 1 WORKSH TROLL AGG, P1
   Lepe-Faúndez M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210706
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Machová K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176468
   Mandl T, 2019, ACM INT CONF PR SER, P14, DOI 10.1145/3368567.3368584
   Mazari AC, 2023, CLUSTER COMPUT, DOI 10.1007/s10586-022-03956-x
   Min CR, 2023, INFORM FUSION, V96, P214, DOI 10.1016/j.inffus.2023.03.015
   Mubarak H, 2017, ALW ACL
   Ozberk Anil, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P517, DOI 10.1109/UBMK52708.2021.9559000
   Pitenis Z, 2020, Arxiv, DOI arXiv:2003.07459
   Raj C, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222810
   Ranasinghe T, 2021, T ASIAN LOW RESOURCE, V21, P1
   Risch J, 2021, P GERMEVAL 2021 SHAR, P1
   Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Subramanian M, 2022, COMPUT SPEECH LANG, V76, DOI 10.1016/j.csl.2022.101404
   Vasantharajan C, 2022, SN COMPUTER SCI, P94, DOI [10.1007/s42979-021-00977-y, DOI 10.1007/S42979-021-00977-Y]
   Wadud MAH, 2023, COMPUT SYST SCI ENG, V44, P1775, DOI 10.32604/csse.2023.027841
   Zampieri M, 2019, Arxiv, DOI arXiv:1902.09666
NR 48
TC 0
Z9 0
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD OCT 18
PY 2023
VL 9
AR e1617
DI 10.7717/peerj-cs.1617
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U9CW2
UT WOS:001087716100002
OA gold
DA 2023-11-10
ER

PT J
AU Vu, MH
   Akbar, R
   Robert, PA
   Swiatczak, B
   Sandve, GK
   Greiff, V
   Haug, DTT
AF Vu, Mai Ha
   Akbar, Rahmad
   Robert, Philippe A.
   Swiatczak, Bartlomiej
   Sandve, Geir Kjetil
   Greiff, Victor
   Haug, Dag Trygve Truslew
TI Linguistically inspired roadmap for building biologically reliable
   protein language models
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID EVOLUTION; IDENTIFICATION; PREDICTION; ENTROPY; CELL
AB Language models trained on proteins can help to predict functions from sequences but provide little insight into the underlying mechanisms. Vu and colleagues explain how extracting the underlying rules from a protein language model can make them interpretable and help explain biological mechanisms.
   Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence-function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared with natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding and model interpretation. Incorporating linguistic ideas into protein LMs enables the development of next-generation interpretable machine learning models with the potential of uncovering the biological mechanisms underlying sequence-function relationships.
C1 [Vu, Mai Ha; Haug, Dag Trygve Truslew] Univ Oslo, Dept Linguist, Scandinavian Studies, Oslo, Norway.
   [Akbar, Rahmad; Robert, Philippe A.; Greiff, Victor] Univ Oslo, Oslo Univ Hosp, Dept Immunol, Oslo, Norway.
   [Swiatczak, Bartlomiej] Univ Sci & Technol China, Dept Hist Sci & Sci Archeol, Hefei, Anhui, Peoples R China.
   [Sandve, Geir Kjetil] Univ Oslo, Dept Informat, Oslo, Norway.
C3 University of Oslo; University of Oslo; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS; University of Oslo
RP Vu, MH; Haug, DTT (通讯作者)，Univ Oslo, Dept Linguist, Scandinavian Studies, Oslo, Norway.
EM m.h.vu@iln.uio.no; daghaug@uio.no
RI Robert, Philippe A./Z-2816-2019; Swiatczak, Bartlomiej/ABB-4492-2021
OI Robert, Philippe A./0000-0003-1345-5015; Haug, Dag Trygve
   Truslew/0000-0001-5275-8073; Vu, Mai Ha/0000-0002-9702-226X; Swiatczak,
   Bartlomiej/0000-0001-6767-3064; Greiff, Victor/0000-0003-2622-5032;
   Sandve, Geir Kjetil/0000-0002-4959-1409
FU Leona M. and Harry B. Helmsley Charitable Trust [2019PG-T1D011]; UiO
   World-Leading Research Community; UiO:LifeScience Convergence
   Environment Immunolingo; EU Horizon 2020 iReceptorplus [825821];
   Research Council of Norway FRIPRO project [300740]; Research Council of
   Norway IKTPLUSS project [311341]; Norwegian Cancer Society Grant
   [215817]; Stiftelsen Kristian Gerhard Jebsen (KG Jebsen Coeliac Disease
   Research Centre)
FX We thank K.?Cho and E.?M. Bender for their comments on the manuscript.
   We acknowledge support by the Leona M. and Harry B. Helmsley Charitable
   Trust (2019PG-T1D011, to V.G.), UiO World-Leading Research Community (to
   V.G.), UiO:LifeScience Convergence Environment Immunolingo (to V.G.,
   G.K.S. and D.T.T.H.), EU Horizon 2020 iReceptorplus (825821 to V.G.), a
   Research Council of Norway FRIPRO project (300740 to V.G.), a Research
   Council of Norway IKTPLUSS project (311341 to V.G. and G.K.S.), a
   Norwegian Cancer Society Grant (215817 to V.G.) and Stiftelsen Kristian
   Gerhard Jebsen (KG Jebsen Coeliac Disease Research Centre to G.K.S.).
CR Adebayo J., 2022, INT C LEARNING REPRE
   Agerri R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4781
   Akbar R, 2022, MABS-AUSTIN, V14, DOI 10.1080/19420862.2021.2008790
   Akbar R, 2021, CELL REP, V34, DOI 10.1016/j.celrep.2021.108856
   Alley EC, 2019, NAT METHODS, V16, P1315, DOI 10.1038/s41592-019-0598-1
   Alva V, 2015, ELIFE, V4, DOI 10.7554/eLife.09410
   Angluin D., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P351, DOI 10.1145/129712.129746
   ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6
   Asgari E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38746-w
   Asgari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141287
   Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Bepler T, 2021, CELL SYST, V12, P654, DOI 10.1016/j.cels.2021.05.017
   Bhattamishra S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7096
   Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020
   Brown P. F., 1992, Computational Linguistics, V18, P31
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Burley SK, 2017, METHODS MOL BIOL, V1606, P627, DOI 10.1007/978-1-4939-7000-1_26
   Chen C., 2022, PREPRINT, parXiv.2204.04213, DOI [10.48550/arXiv.2204.04213, DOI 10.48550/ARXIV.2204.04213]
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Clark P, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3882
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Corrie BD, 2018, IMMUNOL REV, V284, P24, DOI 10.1111/imr.12666
   de Vries W, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7676
   Detlefsen NS, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29443-w
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doddapaneni S., 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2107.00676
   Elhanati Y, 2015, PHILOS T R SOC B, V370, DOI 10.1098/rstb.2014.0243
   Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   Eyraud R, 2021, MACH LEARN, DOI 10.1007/s10994-021-05948-1
   Fernandez-Fuentes N, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000750
   Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7
   Ferruz N, 2022, NAT MACH INTELL, V4, P521, DOI 10.1038/s42256-022-00499-z
   Ferruz N, 2020, J MOL BIOL, V432, P3898, DOI 10.1016/j.jmb.2020.04.013
   Firth F., 1968, SELECTED PAPERS JR F, P168
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI DOI 10.5555/177910.177914
   Ganesan D., 2017, BIONLP 2017, V2017, P238
   Gimona M, 2006, NAT REV MOL CELL BIO, V7, P68, DOI 10.1038/nrm1785
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Goldberg Y., 2019, PREPRINT, DOI DOI 10.48550/ARXIV.1901.05287
   Greiff V, 2017, CELL REP, V19, P1467, DOI 10.1016/j.celrep.2017.04.054
   Gutierrez-Vasques X, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3454
   Heinzinger M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3220-8
   Hie B, 2021, SCIENCE, V371, P284, DOI 10.1126/science.abd7331
   Hie BL, 2022, CELL SYST, V13, P274, DOI 10.1016/j.cels.2022.01.003
   Hiraoka T., 2020, FINDINGS ASS COMPUTA, P1341, DOI [DOI 10.18653/V1/2020.FINDINGS-EMNLP.120, 10.18653/v1/2020.findings-emnlp.120]
   Hofmann V, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P385
   Hofmann V, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3594
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1725
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kao W.-T., 2021, FINDINGS ASS COMPUTA, P2195
   Kaplan J., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2001.08361
   Kaufman S, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382579
   Kolodny R, 2021, MOL BIOL EVOL, V38, P2191, DOI 10.1093/molbev/msab017
   Krishna K., 2021, FINDINGS ASS COMPUTA, P3178
   Kutuzov Andrey, 2019, PROC 1 NLPL WORKSHOP, P22
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4483
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Leem J, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100513
   LIn T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001
   Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574
   Linzen, 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2111.09509
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI DOI 10.1353/LAN.2019.0015
   Linzen T, 2019, LANGUAGE, V95, pE99, DOI 10.1353/lan.2019.0015
   Littmann M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80786-0
   Liu C.-L., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2004.09205
   Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692
   Madani A., 2021, DEEP NEURAL LANGUAGE, DOI DOI 10.1101/2021.07.18.452833
   Marcou Q, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-02832-w
   Matthews A., 2018, P C N AM CHAPT ACL H, V1, P1435
   McCoy RT, 2020, T ASSOC COMPUT LING, V8, P125, DOI 10.1162/tacl_a_00304
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Meier J., 2021, ADV NEURAL INF PROCE, V34, P29287, DOI DOI 10.1101/2021.07.09.450648
   Mielke S. J., 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2112.10508
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   MONTAGUE R, 1970, THEORIA, V36, P373
   Morris TP, 2019, STAT MED, V38, P2074, DOI 10.1002/sim.8086
   Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3434237
   Nijkamp E., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2206.13517
   Niven T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4658
   Ofer D, 2021, COMPUT STRUCT BIOTEC, V19, P1750, DOI 10.1016/j.csbj.2021.03.022
   Olsen Tobias H, 2022, Bioinform Adv, V2, pvbac046, DOI 10.1093/bioadv/vbac046
   Olsen TH, 2022, PROTEIN SCI, V31, P141, DOI 10.1002/pro.4205
   Ostrovsky-Berman M, 2021, FRONT IMMUNOL, V12, DOI 10.3389/fimmu.2021.680687
   Pan Y., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2001.01589
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Pinter Y., 2021, ARXIV
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Rae J. W., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2112.11446
   Rao RS, 2019, ADV NEUR IN, V32
   Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118
   Robert PA, 2022, NAT COMPUT SCI, V2, P845, DOI 10.1038/s43588-022-00372-4
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Ruffolo J. A., 2021, MACHINE LEARNING STR
   Ruffolo JA, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2021.100406
   Sandve GK, 2022, BIOINFORMATICS, V38, P4994, DOI 10.1093/bioinformatics/btac612
   Schluter N., 2018, P 2018 C N AM ASS CO, V2, P242, DOI DOI 10.18653/V1/N18-2039
   Schwartz L., 2020, PREPRINT, DOI [DOI 10.48550/ARXIV.2005.05477, 10.48550/arXiv.2005.05477]
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Shin S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5168
   Shuai R. W., 2021, MACHINE LEARNING STR
   Stern M, 2019, PR MACH LEARN RES, V97
   Strait BJ, 1996, BIOPHYS J, V71, P148, DOI 10.1016/S0006-3495(96)79210-X
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Szklarczyk D, 2019, NUCLEIC ACIDS RES, V47, pD607, DOI 10.1093/nar/gky1131
   Szymborski J, 2022, BIOINFORMATICS, V38, P3958, DOI 10.1093/bioinformatics/btac429
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Unsal S, 2022, NAT MACH INTELL, V4, P227, DOI 10.1038/s42256-022-00457-9
   Vig J., 2020, INT C LEARNING REPRE
   Villegas-Morcillo A, 2021, BIOINFORMATICS, V37, P162, DOI 10.1093/bioinformatics/btaa701
   Wang QL, 2018, NEURAL COMPUT, V30, P2568, DOI 10.1162/neco_a_01111
   Wang YB, 2019, CELLS-BASEL, V8, DOI 10.3390/cells8020122
   Warstadt A., 2020, P SOC COMPUT LINGUIS, V3, P437
   Weber CR, 2020, BIOINFORMATICS, V36, P3594, DOI 10.1093/bioinformatics/btaa158
   Weiss G, 2018, PR MACH LEARN RES, V80
   Welleck S., 2019, P 36 INT C MACH LEAR, P6716
   Xu Jingjing, 2021, P 59 ANN M ASS COMP, V1, P7361
   Xu M., 2022, INT C LEARNING REPRE
   Yang KK, 2018, BIOINFORMATICS, V34, P2642, DOI 10.1093/bioinformatics/bty178
NR 122
TC 4
Z9 4
U1 20
U2 23
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD MAY
PY 2023
VL 5
IS 5
BP 485
EP 496
DI 10.1038/s42256-023-00637-1
EA APR 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G6XR8
UT WOS:000963904900001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Inan, E
AF Inan, Emrah
TI Somun: entity-centric summarization incorporating pre-trained language
   models
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Automatic text summarization; Language models; Harmonic centrality
ID FEATURE-EXTRACTION; CENTRALITY
AB Text summarization resolves the issue of capturing essential information from a large volume of text data. Existing methods either depend on the end-to-end models or hand-crafted preprocessing steps. In this study, we propose an entity-centric summarization method which extracts named entities and produces a small graph with a dependency parser. To extract entities, we employ well-known pre-trained language models. After generating the graph, we perform the summarization by ranking entities using the harmonic centrality algorithm. Experiments illustrate that we outperform the state-of-the-art unsupervised learning baselines by improving the performance more than 10% for ROUGE-1 and more than 50% for ROUGE-2 scores. Moreover, we achieve comparable results to recent end-to-end models.
C1 [Inan, Emrah] Univ Manchester, Sch Comp Sci, Natl Ctr Text Min, Manchester, Lancs, England.
C3 University of Manchester
RP Inan, E (通讯作者)，Univ Manchester, Sch Comp Sci, Natl Ctr Text Min, Manchester, Lancs, England.
EM emrah.inan@manchester.ac.uk
CR [Anonymous], 2004, ENCYCL LANG LINGUIST
   Arora S., 2017, ICLR
   Bae Sanghwan, 2019, P 2 WORKSH NEW FRONT, P10, DOI DOI 10.18653/V1/D19-5402
   Boldi P, 2014, INTERNET MATH, V10, P222, DOI 10.1080/15427951.2013.865686
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Deng WL, 2019, INT C ELECTR MACH SY, P3728
   Devlin J., 2018, ARXIV, V1, P4171
   Diao YF, 2020, NEURAL COMPUT APPL, V32, P11491, DOI 10.1007/s00521-019-04638-3
   Dong Y, 2018, IEEE ANTENNAS PROP, P1739, DOI 10.1109/APUSNCURSINRSM.2018.8608240
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Gao JQ, 2020, NEURAL PROCESS LETT, V51, P473, DOI 10.1007/s11063-019-10100-1
   Gao JQ, 2019, OPTIK, V199, DOI 10.1016/j.ijleo.2019.163368
   Gao XZ, 2019, KNOWL-BASED SYST, V164, P253, DOI 10.1016/j.knosys.2018.10.043
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI [DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]
   Hermann K. M., 2015, ADV NEURAL INFORM PR
   Imani M, 2016, INFORM SCIENCES, V342, P191, DOI 10.1016/j.ins.2016.01.032
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kanapala A, 2019, NEURAL COMPUT APPL, V31, P8631, DOI 10.1007/s00521-019-04177-x
   Kupiec J, 1995, P 18 ANN INT ACM SIG, P68, DOI [DOI 10.1145/215206.215333, 10.1145/215206.215333]
   Lan Zhenzhong, 2019, ARXIV190911942
   Li L, 2019, NEURAL PROCESS LETT, V49, P357, DOI 10.1007/s11063-018-9825-5
   Li Qi, 2012, P 21 ACM INT C INF K, P1727, DOI DOI 10.1145/2396761.2398506
   Lin Chin-Yew, 2004, P 42 ANN M ASS COMP, P5, DOI DOI 10.3115/1218955.1219032
   Lin H., 2011, PROC 49 ANN M ASS CO, P510, DOI DOI 10.1287/MOOR.1100.0463
   Liu Yinhan, 2019, ARXIV190711692
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, P404, DOI DOI 10.3115/1219044.1219064
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Moore Edward F., 1959, P INT S THEORY SWITC, P285
   Nallapati R, 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Narayan S, 2018, P 2018 C N AM CHAPT, V1, P1747, DOI DOI 10.18653/V1/N18-1158
   Nielsen F, 2017, ARXIV171004099
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Rehurek R., 2010, P LREC 2010 WORKSHOP, P45
   Ren P., 2016, COLING 2016 26 INT C, P33
   Sanh V, 2019, AAAI CONF ARTIF INTE, P6949
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sidorov G, 2014, COMPUT SIST, V18, P491, DOI 10.13053/CyS-18-3-2043
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Vinyals O., 2015, P ADV NEURAL INFORM, P2692, DOI 10.48550/arxiv.1506.03134
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang XX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5059
   Zhang XX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P779
   Zhong M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1049
   Zhou QY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P654
NR 49
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD MAY
PY 2021
VL 33
IS 10
SI SI
BP 5301
EP 5311
DI 10.1007/s00521-020-05319-2
EA SEP 2020
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RU2CU
UT WOS:000568479900002
DA 2023-11-10
ER

PT J
AU Wang, PD
   Nakov, P
   Ng, HT
AF Wang, Pidong
   Nakov, Preslav
   Ng, Hwee Tou
TI Source Language Adaptation Approaches for Resource-Poor Machine
   Translation
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Most of the world languages are resource-poor for statistical machine translation; still, many of them are actually related to some resource-rich language. Thus, we propose three novel, language-independent approaches to source language adaptation for resource-poor statistical machine translation. Specifically, we build improved statistical machine translation models from a resource-poor language POOR into a target language TGT by adapting and using a large bitext for a related resource-rich language RICH and the same target language TGT. We assume a small POOR-TGT bitext from which we learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the resource-rich and the resource-poor language. Our work is of importance for resource-poor machine translation because it can provide a useful guideline for people building machine translation systems for resource-poor languages.
   Our experiments for Indonesian/Malay-English translation show that using the large adapted resource-rich bitext yields 7.26 BLEU points of improvement over the unadapted one and 3.09 BLEU points over the original small bitext. Moreover, combining the small POOR-TGT bitext with the adapted bitext outperforms the corresponding combinations with the unadapted bitext by 1.93-3.25 BLEU points. We also demonstrate the applicability of our approaches to other languages and domains.
C1 [Wang, Pidong] Machine Zone Inc, 2225 East Bayshore Rd,Suite 200, Palo Alto, CA 94303 USA.
   [Nakov, Preslav] HBKU, Qatar Comp Res Inst, Tornado Tower,Floor 10,PO 5825, Doha, Qatar.
   [Ng, Hwee Tou] Natl Univ Singapore, 13 Comp Dr, Singapore 117417, Singapore.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar
   Computing Research Institute; National University of Singapore
RP Wang, PD (通讯作者)，Machine Zone Inc, 2225 East Bayshore Rd,Suite 200, Palo Alto, CA 94303 USA.
EM pwang@machinezone.com; pnakov@qf.org.qa; nght@comp.nus.edu.sg
RI Wang, Pidong/L-2433-2016; Nakov, Preslav/D-2421-2017
OI Nakov, Preslav/0000-0002-3600-1510
FU Singapore National Research Foundation under its International Research
   Centre @ Singapore Funding Initiative
FX This research is supported by the Singapore National Research Foundation
   under its International Research Centre @ Singapore Funding Initiative
   and administered by the IDM Programme Office. Some of the results
   presented in this article were published in Wang, Nakov, and Ng (2012)
   and in the Ph.D. thesis of the first author (Wang 2013).
CR Abo Bakr H., 2008, 6 INT C INF SYST INF
   AiTi Aw., 2006, P COLINGACL 2006 MAI, P33
   Altintas K, 2003, PROCEEDINGS OF THE 17TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P192
   [Anonymous], 2007, P 2 WORKSH STAT MACH
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2007, P 45 ANN M ASS COMP
   [Anonymous], 2010, P C ASS MACHINE TRAN
   [Anonymous], 2013, THESIS
   [Anonymous], 2007, P 2 WORKSH STAT MACH
   [Anonymous], 2005, P ACL WORKSHOP INTRI
   [Anonymous], 2008, P 2008 C EMP METH NA
   [Anonymous], 2012, P 50 ANN M ASS COMP
   [Anonymous], 1998, P COLING 1998
   [Anonymous], 2012, P 2012 JOINT C EMPIR
   [Anonymous], 2006, P WORKSHOP STRATEGIE
   [Anonymous], 2009, RECENT ADV NAT LANG, DOI DOI 10.1075/CILT.309
   [Anonymous], 2002, HTK BOOK
   [Anonymous], 2011, P 2011 C EMPIRICAL M
   Baldwin Timothy, 2006, P 5 INT C LANG RES E, P2212
   BOJJA N, 2015, P 15 MACH TRANSL SUM, V2, P11
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Callison-Burch C, 2006, P MAIN C HUMAN LANGU, P17
   Collins M., 2005, P 43 ANN M ASS COMP, V43, P531, DOI DOI 10.3115/1219840.1219906
   Du J., 2010, P C EMP METH NAT LAN, P420
   Dyer Chris, 2007, P INT WORKSH SPOK LA, P180
   Foster G, 2013, P 14 MACH TRANSL SUM, P183
   Hajic J, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P7
   Han Bo, 2011, ACL, P368
   Hardmeier Christian, 2013, ACL 2013 51 ANN M AS, P193
   Heafield Kenneth, 2010, Prague Bulletin of Mathematical Linguistics, P27, DOI 10.2478/v10108-010-0008-4
   Hu NJ, 2013, ADV INTEL SYS RES, P476
   Isahara, 2007, HUMAN LANGUAGE TECHN, P484
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn Philipp, 2013, MOSES USER MANUAL CO
   LIANG P, 2006, P 21 INT C COMP LING, P761
   Marujo Luis, 2011, P 15 ANN C EUR ASS M, P129
   Munteanu DS, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P265
   Nakov P., 2009, P 2009 C EMP METH NA, P1358
   Nakov P, 2012, J ARTIF INTELL RES, V44, P179, DOI 10.1613/jair.3540
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181
   Sajjad H., 2013, P 51 ANN M ASS COMP, V2, P1
   Salloum W., 2011, P 1 WORKSH ALG RES M, P10
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, P223
   Stymne S, 2013, P 19 NORDIC C COMPUT, P375
   Wu H., 2009, P JOINT C 47 ANN M A, P154
NR 49
TC 10
Z9 11
U1 2
U2 19
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 2016
VL 42
IS 2
BP 277
EP 306
DI 10.1162/COLI_a_00248
PG 30
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA DO8NR
UT WOS:000378040800004
OA hybrid
DA 2023-11-10
ER

PT J
AU Das, SB
   Biradar, A
   Mishra, TK
   Patra, BK
AF Das, Sudhansu Bala
   Biradar, Atharv
   Mishra, Tapas Kumar
   Patra, Bidyut Kr.
TI Improving Multilingual Neural Machine Translation System for Indic
   Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Multilingual neuralmachine translation system (MNMT); Indic languages
   (ILs); low resource language; corpus; BLEU score
AB The Machine Translation System (MTS) serves as effective tool for communication by translating text or speech from one language to another language. Recently, neural machine translation (NMT) has become popular for its performance and cost-effectiveness. However, NMT systems are restricted in translating low-resource languages as a huge quantity of data is required to learn useful mappings across languages. The need for an efficient translation system becomes obvious in a large multilingual environment like India. Indian languages (ILs) are still treated as low-resource languages due to unavailability of corpora. In order to address such an asymmetric nature, the multilingual neural machine translation (MNMT) system evolves as an ideal approach in this direction. The MNMT converts many languages using a single model, which is extremely useful in terms of training process and lowering online maintenance costs. It is also helpful for improving low-resource translation. In this article, we propose an MNMT system to address the issues related to low-resource language translation. Our model comprises two MNMT systems, i.e., for English-Indic (one-to-many) and for Indic-English (many-to-one) with a shared encoder-decoder containing 15 language pairs (30 translation directions). Since most of IL pairs have a scanty amount of parallel corpora, not sufficient for training any machine translation model, we explore various augmentation strategies to improve overall translation quality through the proposed model. A state-of-the-art transformer architecture is used to realize the proposed model. In addition, the article addresses the use of language relationships (in terms of dialect, script, etc.), particularly about the role of high-resource languages of the same family in boosting the performance of low-resource languages. Moreover, the experimental results also show the advantage of back-translation and domain adaptation for ILs to enhance the translation quality of both source and target languages. Using all these key approaches, our proposed model emerges to be more efficient than the baseline model in terms of evaluation metrics, i.e., BLEU (BiLingual Evaluation Understudy) score for a set of ILs.
C1 [Das, Sudhansu Bala; Mishra, Tapas Kumar] Natl Inst Technol NIT, Rourkela 769008, Odisha, India.
   [Biradar, Atharv] Pune Inst Comp Technol PICT, Pune, Maharashtra, India.
   [Patra, Bidyut Kr.] Indian Inst Technol IIT, Varanasi, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Madras; Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Das, SB (通讯作者)，Natl Inst Technol NIT, Rourkela 769008, Odisha, India.
EM baladas.sudhansu@gmail.com; mishrat@nitrkl.ac.in;
   bidyut.cse@iitbhu.ac.in
OI Biradar, Atharv/0009-0007-9943-1490; Mishra, Tapas
   K./0000-0002-6363-5017
FU Meity (Ministry of Electronics and Information Technology, Government Of
   India) [13 (12)/2020-CC BT]
FX This work is partially funded by Meity (Ministry of Electronics and
   Information Technology, Government Of India) for project sanction no. 13
   (12)/2020-CC & BT dated 24.04.2020.
CR Aggarwal D, 2022, Arxiv, DOI arXiv:2204.08776
   Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   Amini Hessam, 2019, FRONTIERS PATTERN RE, V1, P35
   [Anonymous], 2015, P INT WORKSHOP SPOKE
   [Anonymous], 2009, RECENT ADV NAT LANG, DOI DOI 10.1075/CILT.309
   Arivazhagan N, 2019, Arxiv, DOI arXiv:1903.07091
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Belinkov Y, 2018, Arxiv, DOI arXiv:1711.02173
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1409.1259, DOI 10.48550/ARXIV.1409.1259]
   Dabre R, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3406095
   Dabre Raj, 2015, P 29 PACIFIC ASIA C, P289
   Das Sudhansu Bala, 2022, P 9 WORKSHOP ASIAN T, P73
   Dash Niladri Sekhar, 2008, LANGUAGE FORUM, V34, P5
   Dash Niladri Sekhar, 2009, TRANSLATION TODAY, V6, P134
   Domingo M, 2019, Arxiv, DOI arXiv:1812.08621
   Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723
   Fan A, 2021, J MACH LEARN RES, V22
   Firat O, 2016, Arxiv, DOI arXiv:1601.01073
   Genzel Dmitriy, 2010, P 23 INT C COMPUTATI, P376
   Goyal N, 2022, T ASSOC COMPUT LING, V10, P522, DOI 10.1162/tacl_a_00474
   Goyal V, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, P162
   Goyal V, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P191
   Guzman F, 2019, Arxiv, DOI arXiv:1902.01382
   Haddow B, 2022, COMPUT LINGUIST, V48, P673, DOI 10.1162/coli_a_00446
   Haddow Barry, 2020, PREPRINTS
   Haddow Barry, 2018, P 3 C MACHINE TRANSL, P399
   Hutchins W., 2000, EARLY YEARS MACHINE, V1, P1
   Isahara, 2007, HUMAN LANGUAGE TECHN, P484
   Jamwal Shubhnandan S., 2022, Machine Intelligence and Data Science Applications: Proceedings of MIDAS 2021. Lecture Notes on Data Engineering and Communications Technologies (132), P843, DOI 10.1007/978-981-19-2347-0_65
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Junczys-Dowmunt M, 2018, Arxiv, DOI arXiv:1804.00344
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, P4948
   Khayrallah Huda, 2018, ARXIV
   Kingma D. P., 2014, C TRACK P
   Knight Kevin, 2016, ABS160402201 CORR
   Koehn Philipp, 2009, STAT MACHINE TRANSLA
   Kosaraju Prudhvi, 2010, P NLP TOOLS CONTEST, P40
   Kudo T, 2018, Arxiv, DOI arXiv:1808.06226
   Kunchukuttan A., 2020, INDICNLP LIB
   Kunchukuttan Anoop, 2020, ARXIV
   Lample G, 2018, Arxiv, DOI arXiv:1711.00043
   Lee Jason, 2017, T ASSOC COMPUT LING, V5, P365, DOI 10.1162/tacl_a_00067
   Li B, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P257
   Lin ZH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P293
   Liu HR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3044
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   More Rohit, 2015, P 12 INT C NATURAL L, P303
   Nakazawa T, 2021, WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION, P1
   Nakazawa Toshiaki, 2022, P 9 WORKSHOP ASIAN T
   Nguyen T. Q., 2017, P 8 INT JOINT C NAT, V2, P296
   Ott M, 2019, Arxiv, DOI arXiv:1904.01038
   Pan X, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P244
   Paolillo John C., 2006, EVALUATING LANGUAGE
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pinnis Marcis, 2018, P 3 C MACHINE TRANSL, P939
   Rajan A, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100299
   Ramesh G, 2022, T ASSOC COMPUT LING, V10, P145, DOI 10.1162/tacl_a_00452
   Sangeetha J., 2014, INT J ENG TECHNOLOGY, V6, P1909
   Sengupta Debapriya, 2015, ADV ARTIFICIAL INTEL, V2015
   Sennrich R, 2016, Arxiv, DOI arXiv:1511.06709
   Sennrich R, 2016, Arxiv, DOI arXiv:1508.07909
   Silberztein Max, 2016, FORMALIZING NATURAL
   Singh M, 2020, PROCEDIA COMPUT SCI, V167, P2534, DOI 10.1016/j.procs.2020.03.306
   Siripragada S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P3743
   Sreelekha S, 2018, ADV INTELL SYST, V632, P663, DOI 10.1007/978-981-10-5520-1_59
   Sutskever I, 2014, ADV NEUR IN, V27
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Tiedemann Jorg, 2020, P 22 ANN C EUR ASS M
   Vaswani A, 2017, ADV NEUR IN, V30
   Vikram S., 2013, INT J SCI RES PUBLIC, V3, P1
   Wang YR, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1022
   Wei HP, 2022, J COMPUT SCI TECH-CH, V37, P601, DOI 10.1007/s11390-022-2140-7
NR 72
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN
PY 2023
VL 22
IS 6
AR 169
DI 10.1145/3587932
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7YR0
UT WOS:001018562700015
DA 2023-11-10
ER

PT J
AU Kannon, T
   Inagaki, K
   Kamiji, NL
   Makimura, K
   Usui, S
AF Kannon, Takayuki
   Inagaki, Keiichiro
   Kamiji, Nilton L.
   Makimura, Kouji
   Usui, Shiro
TI PLATO: Data-oriented approach to collaborative large-scale brain system
   modeling
SO NEURAL NETWORKS
LA English
DT Article
DE Neuroinformatics; Large-scale model; Common data format; Data-oriented;
   Modeling and simulation technique
ID SIMULATION ENVIRONMENT; WORLD SURVEY; PLATFORM; GENERATION; LANGUAGE;
   PROJECTS
AB The brain is a complex information processing system, which can be divided into sub-systems, such as the sensory organs, functional areas in the cortex, and motor control systems. In this sense, most of the mathematical models developed in the field of neuroscience have mainly targeted a specific subsystem. In order to understand the details of the brain as a whole, such sub-system models need to be integrated toward the development of a neurophysiologically plausible large-scale system model. In the present work, we propose a model integration library where models can be connected by means of a common data format. Here, the common data format should be portable so that models written in any programming language, computer architecture, and operating system can be connected. Moreover, the library should be simple so that models can be adapted to use the common data format without requiring any detailed knowledge on its use. Using this library, we have successfully connected existing models reproducing certain features of the visual system, toward the development of a large-scale visual system model. This library will enable users to reuse and integrate existing and newly developed models toward the development and simulation of a large-scale brain system model. The resulting model can also be executed on high performance computers using Message Passing Interface (MPI). (C) 2011 Elsevier Ltd. All rights reserved.
C1 [Kannon, Takayuki; Kamiji, Nilton L.; Makimura, Kouji; Usui, Shiro] RIKEN Brain Sci Inst, Lab Neuroinformat, Wako, Saitama 3510198, Japan.
   [Inagaki, Keiichiro; Usui, Shiro] RIKEN, Computat Sci Res Program, Wako, Saitama 3510198, Japan.
C3 RIKEN; RIKEN
RP Kannon, T (通讯作者)，RIKEN Brain Sci Inst, Lab Neuroinformat, Hirosawa 2-1, Wako, Saitama 3510198, Japan.
EM kannon@brain.riken.jp
RI Kamiji, Nilton Liuji/AAF-3860-2020; Kamiji, Nilton/N-8420-2015
OI Kamiji, Nilton Liuji/0000-0001-5006-6612; 
FU Ministry of Education, Culture, Sports, Science and Technology of Japan
FX We thank Drs. Shunji Satoh, Yoshimi Kamiyama, Yutaka Hirata, Akito
   Ishihara, and Hayaru Shouno for valuable discussion for development and
   Yoshihiro Okumura for technical support. This work is partially funded
   by "The Next-Generation Integrated Simulation of Living Matter" project,
   part of the Development and Use of the Next-Generation Supercomputer
   Project of the Ministry of Education, Culture, Sports, Science and
   Technology of Japan.
CR ARTAL P, 1990, J OPT SOC AM A, V7, P1374, DOI 10.1364/JOSAA.7.001374
   Asai Y, 2008, J PHYSIOL SCI, V58, P447, DOI 10.2170/physiolsci.RP013308
   Bower J, 1997, BOOK GENESIS EXPLORI
   de Garis H, 2010, NEUROCOMPUTING, V74, P3, DOI 10.1016/j.neucom.2010.08.004
   EKEBERG O, 2008, NAT P
   Gewaltig M-O., 2007, SCHOLARPEDIA, V2, DOI DOI 10.4249/SCHOLARPEDIA.1430
   Gleeson P, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000815
   Goertzel B, 2010, NEUROCOMPUTING, V74, P30, DOI 10.1016/j.neucom.2010.08.012
   GORCHETCHNIKOV A, 2010, BMC NEUROSCIENCE S1, V11, P71
   Hedley WJ, 2001, PHILOS T ROY SOC A, V359, P1073, DOI 10.1098/rsta.2001.0817
   Hines ML, 1997, NEURAL COMPUT, V9, P1179, DOI 10.1162/neco.1997.9.6.1179
   HINES ML, 2004, J COMPUTATIONAL NEUR, V7, P7
   Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015
   Inagaki K, 2011, NEURAL NETWORKS, V24, P990, DOI 10.1016/j.neunet.2011.06.007
   Köhn D, 2008, LECT N BIOINFORMAT, V5307, P176, DOI 10.1007/978-3-540-88562-7_15
   Message Passing Interface Forum, 1994, UTCS94230 MESS PASS
   Migliore M, 2003, NEUROINFORMATICS, V1, P135, DOI 10.1385/NI:1:1:135
   Raikov I., 2010, BMC NEUROSCIENCE S1, V11, P66, DOI [10.1186/1471-2202-11-S1-P66, DOI 10.1186/1471-2202-11-S1-P66]
   REW R, 1990, IEEE COMPUT GRAPH, V10, P76, DOI 10.1109/38.56302
   Sakai H, 2007, OPTOMETRY VISION SCI, V84, P517, DOI 10.1097/OPX.0b013e31806dba43
   Sakai Hiroyuki, 2007, Front Neuroinform, V1, P5, DOI 10.3389/neuro.11.005.2007
   Skjellum A, 1994, USING MPI PORTABLE P
   USUI S, 2009, FRONTIERS NEUROINFOR
   Usui S., 2010, P 2010 IEEE WORLD C
   USUI S, 2010, FRONTIERS NEUROINFOR
   Usui S, 2008, LECT NOTES COMPUT SC, V4985, P884
   Usui S, 2008, LECT NOTES COMPUT SC, V5050, P102
   Usui S, 2009, LECT NOTES COMPUT SC, V5863, P84, DOI 10.1007/978-3-642-10677-4_9
   Wohrer A, 2009, J COMPUT NEUROSCI, V26, P219, DOI 10.1007/s10827-008-0108-4
   Yamazaki T, 2011, NEURAL NETWORKS, V24, P927, DOI 10.1016/j.neunet.2011.08.007
NR 30
TC 6
Z9 7
U1 0
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
J9 NEURAL NETWORKS
JI Neural Netw.
PD NOV
PY 2011
VL 24
IS 9
SI SI
BP 918
EP 926
DI 10.1016/j.neunet.2011.06.011
PG 9
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA 836NH
UT WOS:000296117900002
PM 21767932
DA 2023-11-10
ER

PT J
AU Khorasani, ES
   Cremeens, M
   Zhao, Z
AF Khorasani, Elham S.
   Cremeens, Matthew
   Zhao, Zhenge
TI Implementation of scalable fuzzy relational operations in MapReduce
SO SOFT COMPUTING
LA English
DT Article
DE Relational operations; Fuzzy set theory; MapReduce; Fuzzy queries
ID DATABASE MODEL; SIMILARITY JOINS; INFORMATION; FRAMEWORK; SETS
AB One of the main restrictions of relational database models is their lack of support for flexible, imprecise and vague information in data representation and querying. The imprecision is pervasive in human language; hence, modeling imprecision is crucial for any system that stores and processes linguistic data. Fuzzy set theory provides an effective solution to model the imprecision inherent in the meaning of words and propositions drawn from natural language (Zadeh, Inf Control 8(3): 338- 353, doi: 10.1016/ S0019- 9958(65) 90241- X, 1965; IGI Global, https:// books. google. com/ books? id= nt- WBQAAQBAJ, 2013). Several works in the last 20 years have used fuzzy set theory to extend relational database models to permit representation and retrieval of imprecise data. However, to our knowledge, such approaches have not been designed to scale- up to very large datasets. In this paper, the MapReduce framework is used to implement flexible fuzzy queries on a large- scale dataset. We develop MapReduce algorithms to enhance the standard relational operations with fuzzy conditional predicates expressed in natural language.
C1 [Khorasani, Elham S.; Cremeens, Matthew; Zhao, Zhenge] Univ Illinois, Dept Comp Sci, One Univ Plaza, Springfield, IL 62703 USA.
C3 University of Illinois System; University of Illinois Springfield
RP Khorasani, ES (通讯作者)，Univ Illinois, Dept Comp Sci, One Univ Plaza, Springfield, IL 62703 USA.
EM esahe2@uis.edu; mcrem2@uis.edu; mcrem2@uis.edu
CR Afrati FN, 2012, PROC INT CONF DATA, P498, DOI 10.1109/ICDE.2012.66
   [Anonymous], 2012, ACM S CLOUD COMPUTIN
   [Anonymous], 2005, FUZZY DATABASES MODE
   Atta F., 2011, 2011 Proceedings of the IEEE 14th International Multitopic Conference (INMIC 2011), P170, DOI 10.1109/INMIC.2011.6151466
   Bosc P., 1997, UNCERTAINTY MANAGEME, P285
   BUCKLES BP, 1982, FUZZY SET SYST, V7, P213, DOI 10.1016/0165-0114(82)90052-5
   Buckley J. J, 2002, INTRO FUZZY LOGIC FU, V13
   Chen G., 1998, FUZZY LOGIC DATA MOD
   Das Sarma A, 2014, PROC VLDB ENDOW, V7, P1059, DOI 10.14778/2732977.2732981
   Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492
   DUBOIS D, 1986, INFORM SCIENCES, V39, P205, DOI 10.1016/0020-0255(86)90035-6
   Elmeleegy K, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P551, DOI 10.1145/2588555.2595634
   Gufler B, 2012, PROC INT CONF DATA, P522, DOI 10.1109/ICDE.2012.58
   Hassan MA, 2014, PROCEDIA COMPUT SCI, V29, P145, DOI 10.1016/j.procs.2014.05.014
   Klir GJ., 1997, FUZZY SET THEORY FDN
   KWON Y, 2012, P 2012 INT C MAN DAT, V12, P25, DOI DOI 10.1145/2213836.2213840
   Kyritsis V, 2012, LECT NOTES COMPUTER, V6799, P1
   Ma ZM, 2010, J INF SCI ENG, V26, P427
   Ma ZM, 2002, INT J INTELL SYST, V17, P925, DOI 10.1002/int.10057
   Ma ZM, 2000, INT J INTELL SYST, V15, P705, DOI 10.1002/1098-111X(200008)15:8<705::AID-INT2>3.0.CO;2-4
   MEDINA JM, 1995, FUZZY SET SYST, V75, P273, DOI 10.1016/0165-0114(94)00380-P
   Metwally A, 2012, PROC VLDB ENDOW, V5, P704, DOI 10.14778/2212351.2212353
   Petry FE, 1997, FUZZY DATABASES PRIN
   PRADE H, 1984, INFORM SCIENCES, V34, P115, DOI 10.1016/0020-0255(84)90020-3
   SHENOI S, 1989, FUZZY SET SYST, V31, P285, DOI 10.1016/0165-0114(89)90201-7
   SHENOI S, 1990, INFORM SCIENCES, V52, P35, DOI 10.1016/0020-0255(90)90034-8
   Vasant P, 2013, ADV COMPUTATIONAL IN
   Vernica R., 2010, P ACM SIGMOD INT C M, P495, DOI DOI 10.1145/1807167.1807222
   Wang Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P829
   Zadeh LA, 1999, FUZZY SET SYST, V100, P9, DOI 10.1016/S0165-0114(99)80004-9
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang CC, 2012, SECOND INTERNATIONAL CONFERENCE ON CLOUD AND GREEN COMPUTING / SECOND INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING AND ITS APPLICATIONS (CGC/SCA 2012), P73, DOI 10.1109/CGC.2012.9
NR 32
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD MAY
PY 2018
VL 22
IS 9
BP 3061
EP 3075
DI 10.1007/s00500-017-2561-3
PG 15
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC0JS
UT WOS:000429464200020
DA 2023-11-10
ER

PT J
AU Gedik, E
   Güngör, T
AF Gedik, Esin
   Güngör, Tunga
TI Solving Turkish math word problems by sequence-to-sequence
   encoder-decoder models
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
LA English
DT Article
DE Math word problems; sequence-to-sequence model; attention mechanism;
   natural language processing
AB Solving math word problems (MWP) is a challenging task due to the semantic gap between natural language texts , mathematical equations. The main purpose of the task is to take a written math problem as input and produce a proper equation as output for solving that problem. This paper describes a sequence-to-sequence (seq2seq) neural model for automatically solving Turkish MWPs based on their semantic meanings in the text. It comprises a bidirectional encoder to comprehend the semantics of the problem by encoding the input sequence and a decoder with attention to extract the equation by tracking the semantic meanings of the output symbols. We investigate the success of several embedding types, pretrained language models , neural models. Our research is novel in the sense that there exist no studies in Turkish on this natural language processing task that utilizes pretrained language models and neural models. There is also no Turkish dataset that can be used to train the neural models for the MWP task. As the first large-scale Turkish MWP dataset, we translated the well-known English MWP datasets into Turkish using a machine translation system. Although Turkish is an agglutinative and grammatically challenging language, the proposed models achieve around 72% accuracy on the dataset compiled from three English datasets.
C1 [Gedik, Esin; Güngör, Tunga] Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye.
C3 Bogazici University
RP Gedik, E (通讯作者)，Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye.
EM esin.gedik@boun.edu.tr
FU Bo?azi?i University Research Fund [16903]
FX Acknowledgments This work was supported by Bo?azi?i University Research
   Fund under the grant number 16903. We would like to thank Bo?azi?i
   University TETAM for providing access to the computing clusters to train
   and test our models.
CR Amini A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2357
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bakman Y, 2007, ARXIV
   Bobrow D.G., 1964, NATURAL LANGUAGE INP
   Budur E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8253
   Cakiroglu U, 2008, CURR CONTENTS, V5, P311
   Eken S, 2014, DUZCE U BILIM TEKNOL, V2, P48
   Hosseini M.J., 2014, 2014EMNLP, P523
   Huang D., 2018, P 27 INT C COMP LING, P213, DOI DOI 10.1016/B978-0-12-809641-3.00011-9
   Huang DQ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P419
   Huang DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P887
   Koncel-Kedziorski R, 2016, P 2016 C N AM CHAPTE, P1152, DOI DOI 10.18653/VLIN16-1136
   Kushman N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P271
   Lan Y, 2021, ARXIV
   Liguda Christian, 2012, Natural Language Processing and Information Systems. Proceedings 17th International Conference on Applications of Natural Language to Information Systems, NLDB 2012, P247, DOI 10.1007/978-3-642-31178-9_29
   Luong T., 2015, P C EMPIRICAL METHOD, P1412, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Ma Yuhui, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P476, DOI 10.1109/ETCS.2010.316
   Miao SY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P975
   Mitra A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2144
   Mukherjee A, 2008, ARTIF INTELL REV, V29, P93, DOI 10.1007/s10462-009-9110-0
   Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3434237
   Patel A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2080
   Robaidek B, 2018, Arxiv, DOI arXiv:1804.10718
   Sachan M, 2017, P 6 JOINT C LEXICAL, P251
   Say ACC, 2001, INT J PATTERN RECOGN, V15, P359, DOI 10.1142/S0218001401000897
   Say C, 1994, P 9 INT S COMP INF S, P550
   Seo M, 2015, P 2015 C EMPIRICAL M, P1466
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Upadhyay S, 2016, P 2016 C EMPIRICAL M, P297
   Wang H., 2016, P 2016 C EMP METH NA, P541
   Wang Y., 2017, P 2017 C EMPIRICAL M
NR 31
TC 0
Z9 0
U1 7
U2 8
PU Tubitak Scientific & Technological Research Council Turkey
PI ANKARA
PA ATATURK BULVARI NO 221, KAVAKLIDERE, TR-06100 ANKARA, TURKIYE
SN 1300-0632
EI 1303-6203
J9 TURK J ELECTR ENG CO
JI Turk. J. Electr. Eng. Comput. Sci.
PY 2023
VL 31
IS 2
BP 431
EP 447
DI 10.55730/1300-0632.3993
PG 18
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A8YV0
UT WOS:000957927500012
OA Bronze
DA 2023-11-10
ER

PT S
AU Ilieva, MG
   Ormandjieva, O
AF Ilieva, MG
   Ormandjieva, O
BE Montoyo, A
   Munoz, R
   Metais, E
TI Automatic transition of natural language software requirements
   specification into formal presentation
SO NATURAL LANGUAGE PROCESSING AND INFORMATION SYSTEMS, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 10th International Conference on Applications of Natural Language to
   Information Systems
CY JUN 15-17, 2005
CL Univ Alicante, Alicante, SPAIN
HO Univ Alicante
AB Software requirements specification is a critical activity of the software process, as errors at this stage inevitably lead to problems later on in system design and implementation. The requirements are written in natural language, with the potential for ambiguity, contradiction or misunderstanding, or simply an inability of developers to deal with a large amount of information. This paper proposes a methodology for the natural language processing of textual descriptions of the requirements of an unlimited natural language and their automatic mapping to the object-oriented analysis model.
C1 Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Ilieva, MG (通讯作者)，Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ, Canada.
EM ormandj@cse.concordia.ca
CR ALAGAR VS, 2003, P 7 IASTED INT C SOF, P714
   ALAGAR VS, 2003, 10 AS PAC SOFTW ENG
   [Anonymous], P WORKSH INT TECHN S
   BOOCH G, 1998, COMPUTER SCI TODAY
   Bryant B. R., 2000, 23 AUSTR COMP SCI C
   KOP C, 2002, P 6 IASTED INT C SOF
   LEE BS, 2002, P SAC 2002 MARCH 10
   Lewis J., 2004, JAVA SOFTWARE SOLUTI
   MORENO AM, 1997, P 9 INT C SOFTW ENG
   SUBRAMANIAM K, 2004, P 16 INT C SOFTW ENG
   DOMAIN ANAL OBJECT M
   DISCOVERING BUSINESS
NR 12
TC 38
Z9 40
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-26031-5
J9 LECT NOTES COMPUT SC
PY 2005
VL 3513
BP 392
EP 397
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BCO46
UT WOS:000230413100045
DA 2023-11-10
ER

PT J
AU Zhao, S
   Zhang, TY
   Hu, M
   Chang, W
   You, FC
AF Zhao, Shuai
   Zhang, Tianyu
   Hu, Man
   Chang, Wen
   You, Fucheng
TI AP-BERT: enhanced pre-trained model through average pooling
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Pre-trained model; Token embedding; Average pooling; BERT; Deep
   learning; Natural language processing
AB BERT, a pre-trained language model on the large-scale corpus, has made breakthrough progress in NLP tasks. However, the experimental data shows that the BERT model's application effect in Chinese tasks is not ideal. The reason is that we believe that only character-level embedding can be obtained through BERT. However, a single Chinese character often cannot express their comprehensive meaning. To improve the model's ability to understand phrase-level semantic information, this paper proposes an enhanced BERT based on the average pooling(AP-BERT). Our model uses an average pooling layer to act on token embedding and reconstructs the model's input embedding, which can effectively improve BERT's application effect in Chinese natural language processing. Experimental data show that our proposed method has been enhanced in the four tasks of Chinese text classification, named entity recognition, reading comprehension, and summary generation. This method can not only improve the application effect of the BERT model in Chinese tasks but also can be well applied to other pre-trained language models.
C1 [Zhao, Shuai] Jinan Univ, Coll Informat Sci & Technol, Guangzhou, Peoples R China.
   [Zhang, Tianyu; Hu, Man; Chang, Wen; You, Fucheng] Beijing Inst Graph Commun, Sch Informat Engn, Comp Sci, Beijing, Peoples R China.
C3 Jinan University
RP Zhao, S (通讯作者)，Jinan Univ, Coll Informat Sci & Technol, Guangzhou, Peoples R China.
EM 17839192463@163.com; zty0308go@163.com; human190707@163.com;
   mr_changwen@163.com; youfucheng@bigc.edu.cn
RI Hu, man/HPG-9675-2023
OI zhao, shuai/0000-0001-5174-5182
FU National Natural Science Foundation of China [61773229]; Beijing
   Municipal Natural Science Foundation [KZ201710015010]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No.61773229), the Beijing Municipal Natural Science
   Foundation (Grant No.KZ201710015010).
CR Bengio Y, 2001, ADV NEUR IN, V13, P932
   Brown BT, 2019, ARXIV200514165
   Chen, 2018, FAST ABSTRACTIVE SUM
   Chopra S, 2016, P 2016 C N AM ASS CO, P93
   Collobert R, 2007, C PAP ACL
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Gu JJ, 2020, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR42600.2020.00308
   GU Y, 2020, INT C NAT LANG PROC
   Guo J, 2014, P COLING, V2014, P497
   He W, 2018, MACHINE READING FOR QUESTION ANSWERING, P37
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Jiao X., 2020, FINDINGS ASS COMPUTA, P4163, DOI [10.18653/v1/2020.findings-emnlp.372, DOI 10.18653/V1/2020.FINDINGS-EMNLP.372, 10.18653/v1/2020. findings-emnlp.372. URL]
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Joulin Armand, 2016, ARXIV161203651
   Kaliyev A, 2017, INT C SPEECH COMP
   Kim Y., 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1181
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lan Zhenzhong, 2019, ARXIV190911942
   Lauscher Anne, 2019, ARXIV190902339
   Levow G, 2006, P 5 SIGHAN WORKSH CH, P108
   Li J., 2007, EMNLP CONLL, P774
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu X., 2020, CORR
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   McCann Bryan, 2017, ADV NEURAL INFORM PR, P6297
   Mikolov Tomas, 2013, INT C LEARN REPR
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Peters Matthew E., 2019, EMNLP IJCNLP
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Sanh Victor, 2019, ARXIV191001108
   Shao C C, 2019, ARXIV180600920
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Su Tzu-Ray, 2017, P 2017 C EMP METH NA, P264
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Vaswani A., 2017, ARXIV, V30, P5998
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Wang Y, 2018, J TSINGHUA U SCI TEC
   Xie H, 2018, NOV ATT BAS CNN MOD
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yin Rongchao, 2016, P 2016 C EMP METH NA, P981, DOI DOI 10.18653/V1/D16-1100
   Yu A, 2018, 2018 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Yu Wang, 2020, 2020 12th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P23, DOI 10.1109/IHMSC49165.2020.00013
   Yudong, CHINESE SCI LIT DATA
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441
   Zhou DX, 2020, NEURAL NETWORKS, V124, P319, DOI 10.1016/j.neunet.2020.01.018
NR 53
TC 7
Z9 7
U1 13
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD NOV
PY 2022
VL 52
IS 14
BP 15929
EP 15937
DI 10.1007/s10489-022-03190-3
EA MAR 2022
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6H0HG
UT WOS:000770528600001
DA 2023-11-10
ER

PT J
AU Sinclair, A
   Jumelet, J
   Zuidema, W
   Fernández, R
AF Sinclair, Arabella
   Jumelet, Jaap
   Zuidema, Willem
   Fernandez, Raquel
TI Structural Persistence in Language Models: Priming as a Window into
   Abstract Language Representations
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID SYNTACTIC STRUCTURE; NEURAL-NETWORKS; CORPUS; COMPREHENSION; ALIGNMENT
AB We investigate the extent to which modern neural language models are susceptible to structural priming, the phenomenon whereby the structure of a sentence makes the same structure more probable in a follow-up sentence. We explore how priming can be used to study the potential of these models to learn abstract structural information, which is a prerequisite for good performance on tasks that require natural language understanding skills. We introduce a novel metric and release Prime-LM, a large corpus where we control for various linguistic factors that interact with priming strength. We find that Transformer models indeed show evidence of structural priming, but also that the generalizations they learned are to some extent modulated by semantic information. Our experiments also show that the representations acquired by the models may not only encode abstract sequential structure but involve certain level of hierarchical syntactic information. More generally, our study shows that the priming paradigm is a useful, additional tool for gaining insights into the capacities of language models and opens the door to future priming-based investigations that probe the model's internal states.(1)
C1 [Sinclair, Arabella] Univ Aberdeen, Sch Nat & Comp Sci, Aberdeen, Scotland.
   [Sinclair, Arabella; Jumelet, Jaap; Zuidema, Willem; Fernandez, Raquel] Univ Amsterdam, Inst Log Language & Computat, Amsterdam, Netherlands.
C3 University of Aberdeen; University of Amsterdam
RP Sinclair, A (通讯作者)，Univ Aberdeen, Sch Nat & Comp Sci, Aberdeen, Scotland.; Sinclair, A (通讯作者)，Univ Amsterdam, Inst Log Language & Computat, Amsterdam, Netherlands.
EM arabella.sinclair@abdn.ac.uk; j.w.d.jumelet@uva.nl; zuidema@uva.nl;
   raquel.fernandez@uva.nl
FU European Research Council (ERC) under the European Union's Horizon 2020
   research and innovation programme [819455]
FX We would like to thank the anonymous reviewers for their extensive and
   thoughtful feedback and suggestions, which greatly improved our work, as
   the action editor for his helpful guidance. We would also like to thank
   members of the ILLC past and present for their useful comments and
   feedback, specifically, Dieuwke Hupkes, Mario Giulianelli, Sandro
   Pezzelle, and Ece Takmaz. Arabella Sinclair worked on this project while
   affiliated with the University of Amsterdam. The project has received
   funding from the European Research Council (ERC) under the European
   Union's Horizon 2020 research and innovation programme (grant agreement
   No. 819455).
CR Alishahi A, 2019, NAT LANG ENG, V25, P543, DOI 10.1017/S135132491900024X
   Baroni Marco., 2022, ALGEBRAIC SYSTEMS RE
   Bernolet S, 2010, COGNITION, V114, P455, DOI 10.1016/j.cognition.2009.11.005
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   BOCK K, 1989, COGNITION, V31, P163, DOI 10.1016/0010-0277(89)90022-X
   Bock K, 2000, J EXP PSYCHOL GEN, V129, P177, DOI 10.1037//0096-3445.129.2.177
   Bock K, 2007, COGNITION, V104, P437, DOI 10.1016/j.cognition.2006.07.003
   Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303
   Branigan HP, 2006, LANG COGNITIVE PROC, V21, P974, DOI 10.1080/016909600824609
   Branigan HP, 1999, PSYCHON B REV, V6, P635, DOI 10.3758/BF03212972
   Bresnan Joan, 2007, COGNITIVE FDN INTERP, P69
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chang F, 2000, J PSYCHOLINGUIST RES, V29, P217, DOI 10.1023/A:1005101313330
   Chomsky N., 1957, SYNTACTIC STRUCTURES, DOI [10.1515/9783112316009, DOI 10.1515/9783112316009]
   Cleland AA, 2003, J MEM LANG, V49, P214, DOI 10.1016/S0749-596X(03)00060-3
   Cochran, 1977, SAMPLING TECHNIQUES
   Davies M, 2009, INT J CORPUS LINGUIS, V14, P159, DOI 10.1075/ijcl.14.2.02dav
   Davis Forrest., 2020, P 24 C COMPUTATIONAL, P396, DOI [10.18653/v1/2020.conll-1.32, DOI 10.18653/V1/2020.CONLL-1.32]
   Devlin J., 2018, ARXIV, V1, P4171
   Dubey A, 2008, COGNITION, V109, P326, DOI 10.1016/j.cognition.2008.09.006
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   Fine AB, 2013, COGNITIVE SCI, V37, P578, DOI 10.1111/cogs.12022
   Foster Mary Ellen., 2007, P 11 EUROPEAN WORKSH, P33, DOI [DOI 10.3115/1610163.1610170, 10.3115/1610163.1610170]
   Fu ZH, 2021, AAAI CONF ARTIF INTE, V35, P12848
   Futrell R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P32
   Gauthier J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P70
   Goldwater MB, 2011, COGNITIVE SCI, V35, P156, DOI 10.1111/j.1551-6709.2010.01150.x
   Gries ST, 2005, J PSYCHOLINGUIST RES, V34, P365, DOI 10.1007/s10936-005-6139-3
   Gulordava K., 2018, P 2018 C N AM CHAPT, V1, P1195, DOI DOI 10.18653/V1/N18-1108
   Hessel J, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P204
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1725
   Hupkes D, 2018, J ARTIF INTELL RES, V61, P907, DOI 10.1613/jair.1.11196
   Ivanova I, 2017, LANG COGN NEUROSCI, V32, P175, DOI 10.1080/23273798.2016.1236976
   Ivanova I, 2012, COGNITION, V122, P193, DOI 10.1016/j.cognition.2011.10.013
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013
   Jeffreys H., 1961, THEORY PROBABILITY, V3rd
   Jozefowicz R, 2016, ARXIV
   Jumelet J., 2021, FINDINGS ASS COMPUTA, P4958, DOI DOI 10.18653/V1/2021.FINDINGS-ACL.439
   Jumelet Jaap., 2020, P 3 BLACKBOXNLP WORK, P342, DOI [10.18653/v1/2020.blackboxnlp-1.32, DOI 10.18653/V1/2020.BLACKBOXNLP-1.32]
   Kaschak MP, 2011, PSYCHON B REV, V18, P1133, DOI 10.3758/s13423-011-0157-y
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Kassner N., 2020, PROC 58 ANN M ASS CO, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]
   Kodner J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1757
   Kutuzov Andrei, 2017, P 21 NORDIC C COMPUT, P271
   Lakretz Y, 2021, COGNITION, V213, DOI 10.1016/j.cognition.2021.104699
   Lakretz Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P11
   Lan Zhenzhong, 2019, ARXIV190911942
   Li B., 2022, LONG PAPERS, P7410, DOI DOI 10.18653/V1/2022.ACL-LONG.512
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI DOI 10.1353/LAN.2019.0015
   Liu Yinhan, 2019, ARXIV190711692
   Lovering Charles, 2021, INT C LEARN REPR
   Mahowald K, 2016, J MEM LANG, V91, P5, DOI 10.1016/j.jml.2016.03.009
   Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Merriam-Webster Inc., 1989, WEBSTERS DICT ENGLIS
   Nelson DL, 2004, BEHAV RES METH INS C, V36, P402, DOI 10.3758/BF03195588
   Newman B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3710
   Pham Thang., 2021, FINDINGS ASS COMPUTA, P1145, DOI DOI 10.18653/V1/2021.FINDINGS-ACL.98
   Pickering MJ, 2008, PSYCHOL BULL, V134, P427, DOI 10.1037/0033-2909.134.3.427
   Pickering MJ, 2013, J EXP PSYCHOL LEARN, V39, P890, DOI 10.1037/a0029181
   Pickering MJ, 1998, J MEM LANG, V39, P633, DOI 10.1006/jmla.1998.2592
   Prasad, 2019, P 23 C COMP NAT LANG, P66, DOI 10.18653/v1/k19-1007
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Reitter D, 2014, J MEM LANG, V76, P29, DOI 10.1016/j.jml.2014.05.008
   Reitter D, 2011, COGNITIVE SCI, V35, P587, DOI 10.1111/j.1551-6709.2010.01165.x
   Reitter David., 2007, P 29 ANN M COGNITIVE
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2699
   Sanh Victor, 2019, P 5 WORKSHOP ENERGY
   Scheepers C, 2003, COGNITION, V89, P179, DOI 10.1016/S0010-0277(03)00119-7
   Schrimpf M., 2020, BIORXIV, DOI 10.1101/2020.06.26.174482
   Segaert K, 2016, J MEM LANG, V91, P59, DOI 10.1016/j.jml.2016.03.011
   Sid Black, 2021, GITHUB REPOSITORY, DOI [10.18653/v1/2022.bigscience-1.9, DOI 10.18653/V1/2022.BIGSCIENCE-1.9]
   Sinha K., 2021, P 59 ANN M ASS COMPU, V1, P7329, DOI DOI 10.18653/V1/2021.ACL-LONG.569
   Sinha K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2888
   Tayyar Madabushi H., 2020, P 28 INT C COMP LING, P4020, DOI DOI 10.18653/V1/2020.COLING-MAIN.355
   Tenney I., 2019, P 7 INT C LEARNING R
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Tooley KM, 2014, COGNITION, V132, P101, DOI 10.1016/j.cognition.2014.04.002
   Tree JEF, 1999, J PSYCHOLINGUIST RES, V28, P71, DOI 10.1023/A:1023239604158
   Vamvas Jannis., 2021, P 4 BLACKBOXNLP WORK, P58, DOI [10.18653/v1/2021.blackboxnlp-1.5, DOI 10.18653/V1/2021.BLACKBOXNLP-1.5]
   van Schijndel M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4704
   Vaswani A., 2017, ARXIV, V30, P5998
   Voita E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P183
   Warstadt A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2877
   Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321
   Wheeldon LR, 2003, LANG COGNITIVE PROC, V18, P431, DOI 10.1080/01690960244000063
   White JC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P132
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
NR 91
TC 1
Z9 1
U1 4
U2 4
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD SEP 19
PY 2022
VL 10
BP 1031
EP 1050
DI 10.1162/tacl_a_00504
PG 20
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 8K9OO
UT WOS:000923422400003
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Mao, R
   Liu, Q
   He, K
   Li, W
   Cambria, E
AF Mao, Rui
   Liu, Qian
   He, Kai
   Li, Wei
   Cambria, Erik
TI The Biases of Pre-Trained Language Models: An Empirical Study on
   Prompt-Based Sentiment Analysis and Emotion Detection
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Task analysis; Emotion recognition; Sentiment analysis; Computational
   modeling; Affective computing; Taxonomy; Analytical models; Emotion
   detection; pre-trained language model; prompt; sentiment analysis
AB Thanks to the breakthrough of large-scale pre-trained language model (PLM) technology, prompt-based classification tasks, e.g., sentiment analysis and emotion detection, have raised increasing attention. Such tasks are formalized as masked language prediction tasks which are in line with the pre-training objects of most language models. Thus, one can use a PLM to infer the masked words in a downstream task, then obtaining label predictions with manually defined label-word mapping templates. Prompt-based affective computing takes the advantages of both neural network modeling and explainable symbolic representations. However, there still remain many unclear issues related to the mechanisms of PLMs and prompt-based classification. We conduct a systematic empirical study on prompt-based sentiment analysis and emotion detection to study the biases of PLMs towards affective computing. We find that PLMs are biased in sentiment analysis and emotion detection tasks with respect to the number of label classes, emotional label-word selections, prompt templates and positions, and the word forms of emotion lexicons.
C1 [Mao, Rui; Liu, Qian; Li, Wei; Cambria, Erik] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [He, Kai] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian 710049, Shanxi, Peoples R China.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University; Xi'an Jiaotong University
RP Cambria, E (通讯作者)，Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
EM rui.mao@ntu.edu.sg; liu.qian@ntu.edu.sg; hk52025804@stu.xjtu.edu.cn;
   wei008@e.ntu.edu.sg; erik@sentic.net
RI Cambria, Erik/C-2103-2013; Mao, Rui/ABM-7006-2022
OI Cambria, Erik/0000-0002-3030-1280; Mao, Rui/0000-0002-1082-8755
FU RIE2020 Industry Alignment Fund - Industry Collaboration Projects
   Funding Initiative
FX This work was supported by the RIE2020 Industry Alignment Fund -
   Industry Collaboration Projects Funding Initiative, as well as cash and
   in-kind contribution from the industry partner(s).
CR Adoma AF, 2020, I COMP CONF WAVELET, P117, DOI 10.1109/ICCWAMTIP51612.2020.9317379
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Ba Jimmy Lei, 2016, ARXIV
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Cai J, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1665, DOI 10.1145/3397271.3401195
   Cambria Erik, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P144, DOI 10.1007/978-3-642-34584-5_11
   Cambria E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3829
   Cambria E, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P105, DOI 10.1145/3340531.3412003
   Crawford K., 2021, ATLAS AI POWER POLIT, DOI DOI 10.2307/J.CTV1GHV45T
   Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4040
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dredze Mark, 2007, P 45 ANN M ASS COMPU, P440
   Ekman P., 1984, APPROACHES EMOTION, V3, P19, DOI DOI 10.1017/CBO9781107415324.004
   Gao T., 2021, ARXIV
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Gao TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6250
   Guru D., 2017, P INT C INT SYST DES, P337
   Hambardzumyan K., 2021, ARXIV
   Hendrycks D, 2020, Arxiv, DOI [arXiv:1606.08415, DOI 10.48550/ARXIV.1606.08415]
   Hutto C.J., 2014, ICWSM, DOI DOI 10.1609/ICWSM.V8I1.14550
   Jain VK, 2017, J COMPUT SCI-NETH, V21, P316, DOI 10.1016/j.jocs.2017.01.010
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Lan Zhenzhong, 2019, ARXIV190911942
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Li W, 2022, NEUROCOMPUTING, V467, P73, DOI 10.1016/j.neucom.2021.09.057
   Li W, 2018, KNOWL-BASED SYST, V146, P203, DOI 10.1016/j.knosys.2018.02.004
   Liang B, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107643
   Liu P., 2021, ARXIV
   Liu Q., 2018, PROC INT C COMPUTATI, P2023
   Liu Q, 2023, IEEE T NEUR NET LEAR, V34, P2594, DOI 10.1109/TNNLS.2021.3107029
   Liu Q, 2021, INFORM SCIENCES, V555, P410, DOI 10.1016/j.ins.2020.10.030
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Mao R, 2021, Arxiv, DOI arXiv:2104.03285
   Mao R, 2022, INFORM FUSION, V86-87, P30, DOI 10.1016/j.inffus.2022.06.002
   Mao R, 2021, AAAI CONF ARTIF INTE, V35, P13534
   Mao R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3888
   Mao R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1222
   Mohammad S., 2014, PROC WASSA, P32
   Mohammad S. M., 2017, P 8 WORKSH COMP APPR
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Plutchik R., 1980, THEORIES EMOTION, P3, DOI DOI 10.1016/B978-0-12-558701-3.50007-7
   Puri R, 2019, Arxiv, DOI arXiv:1912.10165
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Ray B, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106935
   Rong Xiang, 2021, 2021 International Conference on Computer Communication and Artificial Intelligence (CCAI), P204, DOI 10.1109/CCAI50917.2021.9447486
   Schick T., 2020, P 28 INT C COMP LING, P5569
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255
   Strapparava C., 2004, P 4 INT C LANGUAGE R
   Susanto Y, 2020, IEEE INTELL SYST, V35, P96, DOI 10.1109/MIS.2020.2992799
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Vaswani A., 2017, ARXIV, V30, P5998
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
NR 56
TC 21
Z9 21
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD JUL-SEP
PY 2023
VL 14
IS 3
BP 1743
EP 1753
DI 10.1109/TAFFC.2022.3204972
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T0NN8
UT WOS:001075041900004
DA 2023-11-10
ER

PT J
AU Silberer, C
   Ferrari, V
   Lapata, M
AF Silberer, Carina
   Ferrari, Vittorio
   Lapata, Mirella
TI Visually Grounded Meaning Representations
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Cognitive simulation; computer vision; distributed representations;
   concept learning; connectionism and neural nets; natural language
   processing
ID FEATURE PRODUCTION NORMS; SEMANTIC MEMORY; LARGE SET; MODEL; LANGUAGE;
   NETWORK; OBJECTS
AB In this paper we address the problem of grounding distributional representations of lexical meaning. We introduce a new model which uses stacked autoencoders to learn higher-level representations from textual and visual input. The visual modality is encoded via vectors of attributes obtained automatically from images. We create a new large-scale taxonomy of 600 visual attributes representing more than 500 concepts and 700 K images. We use this dataset to train attribute classifiers and integrate their predictions with text-based distributional models of word meaning. We evaluate our model on its ability to simulate word similarity judgments and concept categorization. On both tasks, our model yields a better fit to behavioral data compared to baselines and related models which either rely on a single modality or do not make use of attribute-based input.
C1 [Silberer, Carina; Ferrari, Vittorio; Lapata, Mirella] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Silberer, Carina; Lapata, Mirella] Inst Language Cognit & Computat, Edinburgh EH8 9AB, Midlothian, Scotland.
   [Ferrari, Vittorio] Inst Percept Act & Behav, Edinburgh EH8 9AB, Midlothian, Scotland.
C3 University of Edinburgh
RP Silberer, C (通讯作者)，Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.; Silberer, C (通讯作者)，Inst Language Cognit & Computat, Edinburgh EH8 9AB, Midlothian, Scotland.
EM vittoferrari@gmail.com; mlap@inf.ed.ac.uk
CR ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409
   Andrews M, 2009, PSYCHOL REV, V116, P463, DOI 10.1037/a0016261
   [Anonymous], 2007, P 4 INT WORKSHOP SEM
   [Anonymous], 2010, P HLT NAACL 2010
   [Anonymous], 2013, ACL
   [Anonymous], 2009, RES LANGUAGE COMPUTA, DOI [10.1007/s11168-010-9068-8, DOI 10.1007/S11168-010-9068-8]
   [Anonymous], 2013, ACL 2
   [Anonymous], 2001, CANONICAL CORRELATIO
   Barbu E., 2008, P ESSLLI WORKSH DIST, P9
   Baroni M, 2010, COGNITIVE SCI, V34, P222, DOI 10.1111/j.1551-6709.2009.01068.x
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Bengio Y., 2006, ADV NEURAL INFORM PR, V19
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Biemann Chris, 2006, P 1 WORKSHOP GRAPH B, P73, DOI DOI 10.3115/1654758.1654774
   Bilmes J.A., 2013, P MACHINE LEARNING R, P1247
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bruni E., 2012, P 50 ANN M ASS COMP, V1, P136, DOI DOI 10.1109/ICRA.2016.7487801
   Bruni E, 2011, P GEMS 2011 WORKSH G, P22
   Bruni E., 2013, P 51 ANN M ASS COMP, P187
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cree GS, 1999, COGNITIVE SCI, V23, P371, DOI 10.1207/s15516709cog2303_4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   FARAH MJ, 1991, J EXP PSYCHOL GEN, V120, P339, DOI 10.1037/0096-3445.120.4.339
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Ferrari V., 2007, ADV NEURAL INFORM PR, V20, P433
   Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110
   Fountain T., 2011, P 33 ANN C COGN SCI, P255
   Fountain T, 2010, COGNITION IN FLUX, P1916
   Frermann L., 2014, P 14 C EUR CHAPT ASS, P249, DOI DOI 10.3115/V1/E14-1027
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313
   Goldstone R. L., 2012, HDB PSYCHOL, V4, P607
   Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Harris Z.S, 1970, DISTRIBUTIONAL STRUC, P775
   Hill F., 2014, PROC C EMPIRICAL MET, P255, DOI [10.3115/v1/D14-1032, DOI 10.3115/V1/D14-1032]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HINTON GE, 1991, PSYCHOL REV, V98, P74, DOI 10.1037/0033-295X.98.1.74
   Hsu A. S., 2012, P 34 ANN C COGN SCI, P485
   Huang J, 2013, INT CONF ACOUST SPEE, P7596, DOI 10.1109/ICASSP.2013.6639140
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Johns BT, 2012, TOP COGN SCI, V4, P103, DOI 10.1111/j.1756-8765.2011.01176.x
   Jones M.N., 2015, OXFORD HDB MATH COMP, P232, DOI DOI 10.1093/OXFORDHB/9780199957996.013.11
   Jones Rosie, 2006, P 15 INT C WORLD WID, P387, DOI DOI 10.1145/1135777.1135835
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kelly C., 2010, P NAACL HLT 2010 1 W, P61
   Kiela Douwe, 2014, P 2014 C EMP METH NA, P36, DOI DOI 10.3115/V1/D14-1005
   Kiros Ryan, 2014, DEEP LEARN REPR LEAR
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Landau B, 1998, TRENDS COGN SCI, V2, P19, DOI 10.1016/S1364-6613(97)01111-X
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Lazaridou Angeliki, 2015, ARXIV150102598, DOI DOI 10.3115/V1/N15-1016
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   MCKINLEY SC, 1995, J EXP PSYCHOL HUMAN, V21, P128, DOI 10.1037/0096-1523.21.1.128
   McRae K, 2005, BEHAV RES METHODS, V37, P547, DOI 10.3758/BF03192726
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Nelson D. L., 1998, U S FLOR WORD ASS RH
   Ngiam Jiquan, 2011, ICML, P2, DOI DOI 10.5555/3104482.3104569
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   OSHERSON DN, 1991, COGNITIVE SCI, V15, P251, DOI 10.1207/s15516709cog1502_3
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Patwardhan S., 2006, P EACL 2006 WORKSHOP, P1
   Ranzato M., 2008, P 25 INT C MACH LEAR, P792, DOI DOI 10.1145/1390156.1390256
   Regier T., 1996, HUMAN SEMANTIC POTEN
   Rogers TT, 2004, PSYCHOL REV, V111, P205, DOI 10.1037/0033-295X.111.1.205
   Roller S., 2013, P C EMP METH NAT LAN, P1146
   Rumelhart D.E., 1985, TECHNICAL REPORT, DOI 10.1016/b978-1-4832-1446-7.50035-2
   Salton G, 1986, INTRO MODERN INFORM
   Sanborn A.N., 2006, P 28 ANN C COGN SCI, P726
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Silberer Carina, 2012, P 2012 JOINT C EMP M, P1423
   Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI [DOI 10.1162/TACL_A_00177, 10.1162/tacl_a_00177]
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sohn K., 2014, NIPS, P2141
   Srivastava N., 2012, ADV NEURAL INF PROCE, V25, P2222, DOI DOI 10.1109/CVPR.2013.49
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thompson-Schill SL, 1998, J MEM LANG, V38, P440, DOI 10.1006/jmla.1997.2559
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vincent Pascal, 2008, P 25 INT C MACH LEAR, P1096
   Vinson DP, 2008, BEHAV RES METHODS, V40, P183, DOI 10.3758/BRM.40.1.183
   von Ahn L., 2004, P SIGCHI C HUMAN FAC, P319, DOI DOI 10.1145/985692.985733
   Westermann G, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0391
   Wu P., 2013, P 21 ACM INT C MULTI, P153, DOI DOI 10.1145/2502081.2502112
   Yih W., 2013, P ACL, V1, P1744
NR 96
TC 21
Z9 23
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD NOV
PY 2017
VL 39
IS 11
BP 2284
EP 2297
DI 10.1109/TPAMI.2016.2635138
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FI5MO
UT WOS:000412028600013
PM 28114000
OA Green Accepted
DA 2023-11-10
ER

PT J
AU Howard, C
   Stumptner, M
AF Howard, Catherine
   Stumptner, Markus
TI Automated compilation of Object-Oriented Probabilistic Relational Models
SO INTERNATIONAL JOURNAL OF APPROXIMATE REASONING
LA English
DT Article
DE First Order Probabilistic Languages; Knowledge representation;
   Uncertainty reasoning
AB This paper addresses the issues of knowledge representation and reasoning in large, complex, uncertain domains, focusing on the tactical military domain, which is characterized by all these properties. The key to reasoning efficiently under these circumstances is to provide a knowledge representation language and reasoning techniques which take advantage of the structure of the domain and facilitate reuse. First order representations such as relational logic are useful for representing structured domains because they can represent both entities and relations. However, the constraint that first order logic statements must be either true or false makes these languages unsuited to representing real world domains which involve uncertainty. Probability theory, on the other hand, provides a sound mathematical basis for representing and reasoning with uncertain information. For example, Bayesian Networks (BNs) are a well known probabilistic representation technique. However, there are several characteristics of large, complex domains which are challenging for traditional BNs. Recent research, for example [1,2], has shown there are advantages to be derived from combining probability theory with some of the expressive power of first order logics. Languages which combine probability theory with aspects of first order logic are called First Order Probabilistic Languages (FOPLs). There are a number of such languages, for example [1-4]. FOPLs have been used to model a number of domains such as military situation awareness [2], traffic surveillance [3], information extraction [5], natural language processing [6], intelligent tutoring systems [7], web site user behavior modelling [8] and automated internet fault diagnosis [9]. In this paper, we present the Object-Oriented Probabilistic Relational Modelling Language (OPRML) [10,11], a new FOPL which combines the generality and modularity of relational logic representation with a principled treatment of uncertainty. We describe the language in detail, outlining its formal syntax and semantics and compare it against its most closely related language: Probabilistic Relational Models (PRMs). We also present four novel algorithms for the automatic construction of domain models from knowledge-bases expressed using the OPRML. Two of the algorithms are based on the knowledge-based model construction approach and two are based on an Object-Oriented Bayesian Network instance tree triangulation method. We discuss the strengths and limitations of each of the algorithms and compare their performance against the algorithms developed for PRMs. Crown Copyright (C) 2009 Published by Elsevier Inc. All rights reserved.
C1 [Howard, Catherine] Def Sci & Technol Org, Elect Warfare & Radar Div, Edinburgh, SA 5111, Australia.
   [Stumptner, Markus] Univ S Australia, Adv Comp Res Ctr, Adelaide, SA 5095, Australia.
C3 Defence Science & Technology; University of South Australia
RP Howard, C (通讯作者)，Def Sci & Technol Org, Elect Warfare & Radar Div, POB 1500, Edinburgh, SA 5111, Australia.
EM catherine.howard@dsto.defence.gov.au; mst@cs.unisa.edu.au
RI Stumptner, Markus/B-5558-2009
OI Stumptner, Markus/0000-0002-7125-3289
CR [Anonymous], ARTIFICIAL INTELLIGE
   [Anonymous], P 6 INT C INF FUS CA
   [Anonymous], P 2 ANN S EXH SIT AW
   Bangso O., 2000, P 13 INT FLOR ART IN
   BANGSO O, 2000, CIT87200OBPHW1 AALB
   BANGSO O, 2004, LECT NOTES ARTIFICIA, V3040
   BANGSO O, 2004, THESIS AALBORG U, P110
   BLANDON P, 2002, P 5 INT C INF FUS AN
   BRYNIELSSON J, 2004, P 7 INT C INF FUS
   CARDELLI L, 1988, INFORM COMPUT, V76, P138, DOI 10.1016/0890-5401(88)90007-7
   Chang KC, 1997, OPT ENG, V36, P684, DOI 10.1117/1.601266
   Costa P.C.G., 2006, P 4 BAYES MOD APPL W
   Cozman FG, 2008, INT J APPROX REASON, V49, P3, DOI 10.1016/j.ijar.2007.08.002
   DAMBROSIO B, 2008, PROBABILISTIC RELATI
   DAS S, 2002, P 5 INT C INF FUS 20
   DAS S, 2002, P 5 INT C INF FUS AN
   Doucet A., 2000, P C UNC ART INT
   FLORES MJ, 2003, P 19 C UNC ART INT
   GAIFMAN H, 1964, ISRAEL J MATH, V2, P1, DOI 10.1007/BF02759729
   George Lee, 2006, P 1 WORKSH HOT TOP A
   GETOOR L, 2002, THESIS DEP COMPUTER, P189
   GONSALVES P, 1999, P 2 INT C INF FUS SU
   GONSALVES PC, 1998, P IEEE INF TECHN C I
   HOWARD C, 2006, 19 INT FLOR ART INT
   HOWARD C, 2005, P 8 INT C INF FUS PH
   JOHANSSON F, 2006, P 9 INT C INF FUS
   Koller D., 1997, P 13 ANN C UNC AI UA
   KREIG M, 2003, P 6 INT C INF FUS
   LASKEY G, 2002, COMM CONTR RES TECHN
   LEE KD, 2003, P 6 INT C INF FUS CA
   Llinas J., 2004, REVISITING JDL DATA
   Marthi Bhaskara, 2003, P WORKSH LEARN STAT
   MIRMOEINI F, 2005, P IEEE C NETW SENS C
   MURPHY KP, 2001, COMPUTING SCI STAT, V33
   NARAYANAN S, 2007, P 6 INT INT C MOD US
   NG B, 2002, P 17 C UNC ART INT E
   Nguyen XT, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL II, P1300, DOI 10.1109/ICIF.2002.1020963
   Noguez Julieta, 2003, P 11 INT C ART INT E
   Okello N., 2003, P 6 INT C INF FUS CA
   PASKIN MA, 2003, ADV NEURAL INFORM PR, V16
   Pasula Hanna, 2003, THESIS U CALIFORNIA
   Pearl J., 1988, MORGAN KAUFMANN SERI
   PERUGINI D, 2003, P 6 INT C INF FUS CA
   PFEFFER AJ, 1999, THESIS DEP COMPUTER, P304
   SALERNO J, 2003, P INF FUS SIT AW 6 I
   STEINBERG AN, 1998, JOINT NATO IRIS C QU
   SUTTON C, 2004, P 7 INT C INF FUS ST
   SUZIC R, 2003, P NATO RTO S MIL DAT
   SYCARA K, 2002, P 5 INT C INF FUS AN
   WRIGHT E, 2001, P 5 INT C INF FUS
NR 50
TC 5
Z9 6
U1 0
U2 13
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0888-613X
EI 1873-4731
J9 INT J APPROX REASON
JI Int. J. Approx. Reasoning
PD NOV
PY 2009
VL 50
IS 9
SI SI
BP 1369
EP 1398
DI 10.1016/j.ijar.2009.04.011
PG 30
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 527BO
UT WOS:000272341300005
DA 2023-11-10
ER

PT J
AU Klemen, M
   Krsnik, L
   Robnik-Sikonja, M
AF Klemen, Matej
   Krsnik, Luka
   Robnik-Sikonja, Marko
TI Enhancing deep neural networks with morphological information
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Deep learning; Natural language processing; Morphologically rich
   languages; Transformers; Morphological additions
ID NAMED ENTITY RECOGNITION
AB Deep learning approaches are superior in natural language processing due to their ability to extract informative features and patterns from languages. The two most successful neural architectures are LSTM and transformers, used in large pretrained language models such as BERT. While cross-lingual approaches are on the rise, most current natural language processing techniques are designed and applied to English, and less-resourced languages are lagging behind. In morphologically rich languages, information is conveyed through morphology, for example, through affixes modifying stems of words. The existing neural approaches do not explicitly use the information on word morphology. We analyse the effect of adding morphological features to LSTM and BERT models. As a testbed, we use three tasks available in many less-resourced languages: named entity recognition (NER), dependency parsing (DP) and comment filtering (CF). We construct baselines involving LSTM and BERT models, which we adjust by adding additional input in the form of part of speech (POS) tags and universal features. We compare the models across several languages from different language families. Our results suggest that adding morphological features has mixed effects depending on the quality of features and the task. The features improve the performance of LSTM-based models on the NER and DP tasks, while they do not benefit the performance on the CF task. For BERT-based models, the added morphological features only improve the performance on DP when they are of high quality (i.e., manually checked) while not showing any practical improvement when they are predicted. Even for high-quality features, the improvements are less pronounced in language-specific BERT variants compared to massively multilingual BERT models. As in NER and CF datasets manually checked features are not available, we only experiment with predicted features and find that they do not cause any practical improvement in performance.
C1 [Klemen, Matej; Krsnik, Luka; Robnik-Sikonja, Marko] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
C3 University of Ljubljana
RP Klemen, M (通讯作者)，Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
EM matej.klemen@fri.uni-lj.si
OI Klemen, Matej/0000-0002-7852-2357
FU European Union's Horizon 2020 Programme project EMBEDDIA (Cross-Lingual
   Embeddings for Less-Represented Languages in European News Media)
   [825153]; Slovene Research Agency [P6-0411]; Ministry of Culture of the
   Republic of Slovenia through project Development of Slovene in Digital
   Environment (RSDO)
FX This work was supported by European Union's Horizon 2020 Programme
   project EMBEDDIA (Cross-Lingual Embeddings for Less-Represented
   Languages in European News Media, grant no. 825153). The research was
   supported by the Slovene Research Agency through research core funding
   no. P6-0411 and the young researcher grant as well the Ministry of
   Culture of the Republic of Slovenia through project Development of
   Slovene in Digital Environment (RSDO). The Titan X Pascal used for a
   part of this research was donated by the NVIDIA Corporation.
CR Anderson M, 2020, P 24 C COMPUTATIONAL, P69
   [Anonymous], 1908, BIOMETRIKA, V6, P1
   [Anonymous], 2006, 100 STAT TESTS, DOI DOI 10.4135/9781849208499
   [Anonymous], 2017, P CONLL 2017 SHARED
   [Anonymous], 2016, ARXIV160306270
   Arkhipov M, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP'2019), P89
   Ballesteros M., 2015, P 2015 C EMP METH NA, P349, DOI DOI 10.18653/V1/D15-1041
   Benajiba Y, 2007, LECT NOTES COMPUT SC, V4394, P143
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, DOI 10.1155/2014/575246
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Devlin J., 2018, ARXIV, V1, P4171
   Dozat T, 2016, INCORPORATING NESTER, P2013
   Dozat T., 2017, P CONLL 2017 SHARED, P20, DOI DOI 10.18653/V1/K17-3002
   Edmiston Daniel, 2020, ARXIV200403032
   Elazar Y, 2021, T ASSOC COMPUT LING, V9, P160, DOI 10.1162/tacl_a_00359
   Evkoski B, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256175
   Farahani M, 2021, NEURAL PROCESS LETT, V53, P3831, DOI 10.1007/s11063-021-10528-4
   Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676
   Gao L., 2017, INT C REC ADV NAT LA, P260, DOI [10.26615/978-954-452-049-6-036, DOI 10.26615/978-954-452-049-6-036]
   Georgakopoulos SV, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3208069
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Grünewaid S, 2021, IWPT 2021: THE 17TH INTERNATIONAL CONFERENCE ON PARSING TECHNOLOGIES: PROCEEDINGS OF THE CONFERENCE (INCLUDING THE IWPT 2021 SHARED TASK), P131
   Güngör O, 2019, NAT LANG ENG, V25, P147, DOI 10.1017/S1351324918000281
   Hajic Jan, 2017, P CONLL 2017 SHAR TA
   Han J., 2019, PROC 13 INT WORKSHOP, P652
   Houquan Zhou, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P179, DOI 10.1007/978-3-030-60450-9_15
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   Ji T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2475
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kapociute-Dzikiene J., 2013, P 4 WORKSH STAT PARS, P12
   Khallash M., 2013, P 4 WORKSH STAT PARS, P97
   Kiperwasser E., 2016, T ASS COMPUTATIONAL, V4, P313, DOI [DOI 10.1162/TACL_A_00101, 10.1162/tacl_a_00101]
   Kondratyuk D., 2019, EMNLP, P2779
   Krek Simon, 2019, TRAINING CORPUS SSJ5
   Kulmizev A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2755
   Kuratov Y, 2019, COMPUT LINGUIST
   Kuru O., 2016, P COLING 2016 26 INT, P911
   Lample G, 2016, P NAACL HLT, DOI DOI 10.18653/V1/N16-1030
   Levow G, 2006, P 5 SIGHAN WORKSH CH, P108
   Li Z., 2018, P 27 INT C COMP LING, P3203
   Lim K., 2018, P CONLL 2018 SHAR TA, P143, DOI 10.18653/v1/K18-2014
   Lim K, 2020, AAAI CONF ARTIF INTE, V34, P8344
   Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241
   Nguyen LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), P1
   Ljubesic N., 2018, TRAINING CORPUS HR50
   Malmasi S., 2017, P INT C RECENT ADV N, P467, DOI [10.26615/978-954-452-049-6-062, DOI 10.26615/978-954-452-049-6_062]
   Martin J. H., 2009, SPEECH LANGUAGE PROC
   Marton Y., 2010, P 1 WORKSH STAT PARS, P13
   McDonald R, 2005, P C HUM LANG TECHN E, P523, DOI DOI 10.3115/1220575.1220641
   Mikhailov V., 2021, P 3 WORKSH COMP TYP, P97, DOI 10.18653/v1/2021.sigtyp-1.10
   Miok Kristian, 2019, Statistical Language and Speech Processing. 7th International Conference, SLSP 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11816), P286, DOI 10.1007/978-3-030-31372-2_24
   Mohseni M, 2019, P 1 INT WORKSHOP NLP, P23
   Moon J., 2020, P 8 INT WORKSH NAT L, P25
   Nemeskey D.M, 2021, 17 C HUNG COMP LING
   Nguyen D. Q., 2018, P CONLL 2018 SHARED, P81, DOI DOI 10.18653/V1/K18-2008
   Nivre J, 2003, P 8 INT C PARS TECHN, P149
   Nivre J., 2020, UNIVERSAL DEPENDENCI
   Ozates S.B., 2018, P CONLL SHAR TASK MU, P238, DOI 10.18653/v1/K18-2024
   Paikens P, 2012, FRONT ARTIF INTEL AP, V247, P169, DOI 10.3233/978-1-61499-133-5-169
   Pei WZ, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P313
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P101
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Ruokolainen T, 2020, LANG RESOUR EVAL, V54, P247, DOI 10.1007/s10579-019-09471-7
   Safaya A., 2020, P 14 WORKSH SEM EV, P2054
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Santos CN, 2015, P NEWS 2015 5 NAM EN, P25, DOI DOI 10.18653/V1/W15-3904
   Scheffler T, 2018, 14 C NAT LANG PROC K, V6, P8
   SEDDAH D, 2010, P NAACL HLT 2010 1 W
   Seeker Wolfgang, 2011, P 12 INT C PARS TECH, P58
   Seker A., 2021, ARXIV210404052
   Shtovba S., 2019, CEUR WORKSHOP P, V2353, P313
   Simeonova L., 2019, P INT C REC ADV NAT, P1104
   Starostin A., 2016, ANN INT C DIAL
   Straka Milan, 2018, P CONLL 2018 SHARED, P197, DOI DOI 10.18653/V1/K18-2020
   Straková J, 2016, LECT NOTES ARTIF INT, V9924, P173, DOI 10.1007/978-3-319-45510-5_20
   Taghizadeh N., 2019, P 1 INT WORKSHOP NLP, P9
   Tanvir H., 2021, NODALIDA 2021, P11
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Tkachenko A., 2013, P 4 BIENNIAL INT WOR, P78
   Ulcar M, 2020, LECT NOTES ARTIF INT, V12284, P104, DOI 10.1007/978-3-030-58323-1_11
   Uskudarli S., 2017, ARXIV PREPRINT ARXIV
   Van Hee Cynthia, 2015, P INT C REC ADV NAT, P672
   Vania C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2573
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Virtanen A., 2019, ARXIV191207076
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wilcoxon F., 1970, SELECTED TABLES MATH, V1, P171
   Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1391, DOI 10.1145/3038912.3052591
   Yamada H., 2003, P 8 INT WORKSH PARS, P195
   Zampieri M., 2019, P 13 INT WORKSHOP SE, P75, DOI DOI 10.18653/V1/S19-2010
   Zampieri M., 2020, P 14 WORKSHOP SEMANT, P1425
   Zhou J., 2020, P FINDINGS ASS COMPU, P4450
NR 96
TC 0
Z9 0
U1 5
U2 10
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD 2022 FEB 21
PY 2022
AR PII S1351324922000080
DI 10.1017/S1351324922000080
EA FEB 2022
PG 26
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA ZD9HB
UT WOS:000758504100001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Zou, A
   Hao, WN
   Jin, DW
   Chen, G
   Sun, FY
AF Zou, Ao
   Hao, Wenning
   Jin, Dawei
   Chen, Gang
   Sun, Feiyan
TI MoCoUTRL: a momentum contrastive framework for unsupervised text
   representation learning
SO CONNECTION SCIENCE
LA English
DT Article
DE Natural language processing; text representation learning; momentum
   contrast; alignment; uniformity
AB This paper presents MoCoUTRL: a Momentum Contrastive Framework for Unsupervised Text Representation Learning. This model improves two aspects of recently popular contrastive learning algorithms in natural language processing (NLP). Firstly, MoCoUTRL employs multi-granularity semantic contrastive learning objectives, enabling a more comprehensive understanding of the semantic features of samples. Secondly, MoCoUTRL uses a dynamic dictionary to act as the approximately ground-truth representation for each token, providing the pseudo labels for token-level contrastive learning. The MoCoUTRL can extend the use of pre-trained language models (PLM) and even large-scale language models (LLM) into a plug-and-play semantic feature extractor that can fuel multiple downstream tasks. Experimental results on several publicly available datasets and further theoretical analysis validate the effectiveness and interpretability of the proposed method in this paper.
C1 [Zou, Ao; Hao, Wenning; Jin, Dawei; Chen, Gang; Sun, Feiyan] Army Engn Univ PLA, Command & Control Engn Coll, Nanjing, Peoples R China.
   [Sun, Feiyan] Jinling Inst Technol, Nanjing, Peoples R China.
C3 Army Engineering University of PLA; Jinling Institute of Technology
RP Hao, WN (通讯作者)，Army Engn Univ PLA, Command & Control Engn Coll, Nanjing, Peoples R China.
EM hwnbox@aeu.edu.cn
OI Zou, Ao/0000-0002-9204-2376
FU Defense Industrial Technology Development Program [JCKY2020601B018]
FX This work was supported by Defense Industrial Technology Development
   Program: [Grant Number JCKY2020601B018].
CR Bachman P, 2019, ADV NEUR IN, V32
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Carlsson F., 2021, SEMANTIC RE TUNING C, P21
   Caron Mathilde, 2020, ADV NEURAL INFORM PR, V3, DOI DOI 10.5555/3495724.3496555
   Cer D., 2017, P 11 INT WORKSHOP SE, P1, DOI [DOI 10.18653/V1/S17-2001, 10.1865/3v1/S17-2001]
   Chen T, 2020, PR MACH LEARN RES, V119
   Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]
   Chuang Y.-S., 2022, P 2022 C N AM CHAPT
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy Alexey, 2014, NEURIPS
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, DOI 10.48550/ARXIV.1802.05365]
   Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Grill J.-B., 2020, ADV NEURAL INFORM PR, P21271
   Hadsell Raia, 2006, 2006 IEEE COMPUTER S, V2, P1735
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   He Pengcheng, 2020, ARXIV200603654
   Hill Felix, 2016, P NAACL HLT, P1367, DOI DOI 10.18653/V1/N16-1162
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G.E, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI DOI 10.1109/69.917563
   Hjelm R. D., 2019, LEARNING DEEP REPRES, P24
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kitaev Nikita, 2020, ARXIV200104451
   Kong L., 2019, INT C LEARNING REPRE
   Kowsari K, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P364, DOI 10.1109/ICMLA.2017.0-134
   Lan Z., 2020, ALBERT LITE BERT SEL, P17
   Lee SY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5969
   Lewis M., 2020, 58 ANN M ASS COMP LI, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]
   Li BH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9119
   LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Paszke A, 2019, Arxiv, DOI [arXiv:1912.01703, 10.48550/arxiv.1912.01703]
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Qian J, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2912
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Keskar NS, 2019, Arxiv, DOI [arXiv:1909.05858, DOI 10.48550/ARXIV.1909.05858]
   Su Jianlin, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.15316
   Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Wang T., 2020, PROC INT C MACH LEAR, P9929
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
   Zhuang Liu, 2021, Chinese Computational Linguistics: 20th China National Conference, CCL 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12869), P471, DOI 10.1007/978-3-030-84186-7_31
   2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 52
TC 0
Z9 0
U1 5
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0954-0091
EI 1360-0494
J9 CONNECT SCI
JI Connect. Sci.
PD DEC 31
PY 2023
VL 35
IS 1
AR 2221406
DI 10.1080/09540091.2023.2221406
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J1AA5
UT WOS:001006989400001
OA gold
DA 2023-11-10
ER

PT S
AU Habash, N
   Dorr, B
AF Habash, N
   Dorr, B
BE Richardson, SD
TI Handling translation divergences: Combining statistical and symbolic
   techniques in generation-heavy machine translation
SO MACHINE TRANSLATION: FROM RESEARCH TO REAL USERS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 5th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 08-12, 2002
CL Tiburon, CA
SP Assoc Machine Translat Americas
AB This paper describes a novel approach to handling translation divergences in a Generation-Heavy Hybrid Machine Translation (GHMT) system. The translation divergence problem is usually reserved for Transfer and Interlingual MT because it requires a large combination of complex lexical and structural mappings. A major requirement of these approaches is the accessibility of large amounts of explicit symmetric knowledge for both source and target languages. This limitation renders Transfer and Interlingual approaches ineffective in the face of structurally-divergent language pairs with asymmetric resources. GHMT addresses the more common form of this problem, source-poor/target-rich, by fully exploiting symbolic and statistical target-language resources. This non-interlingual non-transfer approach, is accomplished by using target-language lexical semantics, categorial variations and subcategorization frames to overgenerate multiple lexico-structural variations from a target-glossed syntactic dependency of the source-language sentence. The symbolic overgeneration, which accounts for different possible translation divergences, is constrained by a statistical target-language model.
C1 Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20740 USA.
C3 University System of Maryland; University of Maryland College Park
RP Habash, N (通讯作者)，Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20740 USA.
EM habash@umiacs.umd.edu; bonnie@umiacs.umd.edu
OI Habash, Nizar/0000-0002-1831-3457; Dorr, Bonnie/0000-0003-4356-5813
CR BANGALORE S, 2000, P 18 INT C COMP LING
   BEAVEN JL, 1992, P 14 INT C COMP LING
   DORR B, 1993, MACHINE TRANSLATION
   Dorr B. J., 2002, P 5 C ASS MACH TRANS
   Dorr BJ, 1999, ADV COMPUT, V49, P1, DOI 10.1016/S0065-2458(08)60282-X
   DORR BJ, 1993, ARTIF INTELL, V63, P429, DOI 10.1016/0004-3702(93)90023-5
   HABASH N, 2000, P 4 C ASS MACH TRANS
   HABASH N, 2002, P INT NAT LANG GEN C
   HAN HC, 2000, P 4 C ASS MACH TRANS
   Jackendoff R., 1983, SEMANTICS COGNITION
   Jackendoff R., 1990, SEMANTIC STRUCTURES
   Knight K., 1995, P 33 ANN M ASS COMP, P252
   LANGKILDE I, 1998, P INT NAT LANG GEN W
   LANGKILDE I, 1998, GENERATING WORD LATT
   LANGKILDE I, 1998, P 36 ANN M ASS COMP, P704
   LAVOIE B, 2001, P 39 ANN M ASS COMP
   LAVOIE B, 2000, P 1 ANN N AM ASS COM
   Melcuk I., 1988, DEPENDENCY SYNTAX TH
   Nasr A, 1997, P 2 INT WORKSH INT S
   Traum D, 2000, P WORKSH APPL INT N, P34
   WATANABE H, 2000, P 18 INT C COMP LING
NR 21
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-44282-0
J9 LECT NOTES ARTIF INT
PY 2002
VL 2499
BP 84
EP 93
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BY57Q
UT WOS:000189412300009
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Kreines, MG
AF Kreines, M. G.
TI Models and technologies for the extraction of aggregated knowledge to
   control processes of the retrieval of non-structured information
SO JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL
LA English
DT Article
AB To control the retrieval and to arrange the retrieval of non-structured information in large-scale collections of texts in natural languages, crucially new models of aggregated representation of knowledge about their topic and content (semiotic and semantic characteristics of the text) are proposed. Based on the proposed models, techniques of computational extraction and use of knowledge about the topic and content of text collections are developed. The proposed models and techniques are based on formation of secondary information resources characterizing the topic and content of particular texts in natural languages.
C1 BaseTech LLC, Moscow, Russia.
RP Kreines, MG (通讯作者)，BaseTech LLC, Moscow, Russia.
RI Kreines, Mikhail G./S-7716-2016
FU Federal Agency on Science and Innovation [02.514.11.4038]
FX This work was supported by the Federal Agency on Science and Innovation,
   state contract no. 02.514.11.4038 "Development of information
   technologies for the extraction, accumulation, and usage of professional
   and corporative knowledge".
CR BATES ME, 2008, LIFE GOOGLE SOME BES
   BATES ME, 2008, 3 DIMENSIONAL INTERN
   BATES ME, 2004, HIDDEN GOOGLE TOOLS
   BOURGEAULT G, WIKIPEDIA FOUNDER J
   EFREMOV VS, 2007, OTKRYTYE SISTEMY
   ILIN N, 2006, OTKRYTYE SISTEMY
   KHARLAMOV AA, 2002, OTKRYTYE SISEMY
   Kreines MG, 2000, ELECTRONIC PUBLISHING 2000, CONFERENCE PROCEEDINGS, P73
   KREINES MG, 2006, B IZOBRET
   KREINES MG, 2000, ISKUSSTVENNYI INTELL, P103
   KREINES MG, 2003, INTERNET PORTALS CON, P584
   KREINES MG, 2002, P 6 INT ICCC IFIP C, P135
   KREINES MG, 2001, P ALL RUSS C SCI SER, P104
   KREINES MG, 1999, P ALL RUSS C SCI SER, P214
   KREINES MG, 2000, P ALL RUSS C SCI SER, P94
   KREINES MG, 1999, P I2 DSI APPL WORKSH
   Milton N.R., 2008, KNOWLEDGE TECHNOLOGI
   MURELL J, 2007, GOOGLE LETS NEWSMAKE
   ROCHE C, 2007, TERME CONCEPT FONDEM
   SELEZNEV K, 2003, OTKRYTYE SISTEMY
   SELEZNEV KE, 2005, OTKRYTYE SISTEMY
   2008, P 17 INT C WORLD WID
NR 22
TC 3
Z9 3
U1 0
U2 0
PU MAIK NAUKA/INTERPERIODICA/SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013-1578 USA
SN 1064-2307
J9 J COMPUT SYS SC INT+
JI J. Comput. Syst. Sci. Int.
PD APR
PY 2009
VL 48
IS 2
BP 272
EP 281
DI 10.1134/S1064230709020117
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 442ZX
UT WOS:000265881100011
DA 2023-11-10
ER

PT J
AU Kouremenos, D
   Ntalianis, K
   Kollias, S
AF Kouremenos, Dimitrios
   Ntalianis, Klimis
   Kollias, Stefanos
TI A novel rule based machine translation scheme from Greek to Greek Sign
   Language: Production of different types of large corpora and Language
   Models evaluation
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Machine translation; Greek Sign Language; GSL; Deaf people communication
ID TEXT; PROBABILITIES; SPEECH
AB One of the aims of assistive technologies is to help people with disabilities to communicate with others and to provide means of access to information. As an aid to Deaf people, in this work we present a novel prototype Rule Based Machine Translation (RBMT) system for the creation of large and quality written Greek Sign Language (GSL) glossed corpora from Greek text. In particular, the proposed RBMT system assists the professional GSL translator in speeding up the production of different kinds of GSL glossed corpora. Then each glossed corpus is used for the production/creation of Language Model (LM) n-grams. With the GSL glossed corpus from Greek text, we can build, test and evaluate different kinds of Language Models for different kinds of glossed GSL corpora. Here, it should be noted that it does not require grammar knowledge of GSL but only very basic GSL phenomena covered by manual RBMT rules as it assists the professional human translator. Furthermore, it should also be stressed that Language Models for written GSL gloss are missing from the scientific literature, thus this work is pioneer in this field. Evaluation of the proposed scheme is carried out for the weather reports domain, where 20,284 tokens and 1000 sentences have been produced. By using the BiLingual Evaluation Understudy (BLEU) metric score, our prototype RBMT system achieves a relative score of 0.84 (84%) for 4-grams and 0.9 (90%) for 1-grams. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Kouremenos, Dimitrios; Ntalianis, Klimis; Kollias, Stefanos] Natl Tech Univ Athens, Elect & Comp Engn Dept, Athens, Greece.
C3 National Technical University of Athens
RP Kouremenos, D (通讯作者)，Natl Tech Univ Athens, Elect & Comp Engn Dept, Athens, Greece.
EM dkourem@gmail.com; kntal@image.ntua.gr; stefanos@cs.ntua.gr
RI Kollias, Stefanos/ACY-7285-2022
CR Aikhernvald A. Y., 2000, CLASSIFIERS TYPOLOGY
   [Anonymous], 1960, STUDIES LINGUISTICS
   [Anonymous], 2006, LREC 2006 P 5 EDITIO
   [Anonymous], DICT AM SIGN LANGUAG
   [Anonymous], 2012, P 5 WORKSH REPR PROC
   [Anonymous], 2001, P 7 EUR C SPEECH COM
   [Anonymous], 1994, P 7 INT WORKSHOP NAT
   [Anonymous], 2002, P 3 INT C LANG RES E
   [Anonymous], UCL WORKING PAPERS L
   [Anonymous], 1959, SILENT LANGUAGE
   [Anonymous], P 3 INT C LANG RES E
   [Anonymous], 2011, P 15 ANN M EUROPEAN
   [Anonymous], INT WORKSH SPOK LANG
   [Anonymous], 1992, LOGIC TYPED FEATURE
   [Anonymous], 1996, 34 ANN M ASS COMP LI, DOI DOI 10.3115/981863.981904
   Baldassarri S, 2009, NEW TRENDS ON HUMAN-COMPUTER INTERACTION: RESEARCH, DEVELOPMENT, NEW TOOLS AND METHODS, P1, DOI 10.1007/978-1-84882-352-5_1
   Bangham J.A., 2000, P 2000 IEEE SEM SPEE
   Bauer B., 1999, 1 INT
   Braffort A., 2004, P 2004 INT C LANG RE
   Brennan Mary., 1984, WORDS HAND STRUCTURA
   Brown P., 1988, P 12 INT C COMP LING, V1, P71, DOI DOI 10.3115/991635.991651
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Bunke H, 2001, HIDDEN MARKOV MODELS
   Carpenter R., 2005, CAMBRIDGE TRACTS THE
   Chandioux J., 1989, P 1989 AM TRANSL ASS, P449
   Chandioux J., 1976, AM J COMPUTATIONAL L, P27
   Dangsaart S, 2008, COMPUT EDUC, V51, P1125, DOI 10.1016/j.compedu.2007.11.008
   Dimou A.-L., 2011, P 9 INT GEST WORKSH, P88, DOI [10.1007/978-3-642-34182-3, DOI 10.1007/978-3-642-34182-3]
   Dreuw Philippe, 2008, P 6 INT C LANG RES E
   EFTHIMIOU E, 2007, NEW TRENDS ICT ACCES, P00125
   Efthimiou E., 2007, P 4 INT C UN ACC HUM
   Efthimiou E, 2016, UNIVERSAL ACCESS INF, V15, P499, DOI 10.1007/s10209-015-0414-3
   Elliott R., 2004, P 1 WORKSH REPR PROC, P98
   Forcada ML, 2011, MACH TRANSL, V25, P127, DOI 10.1007/s10590-011-9090-0
   Fotinea S.-E., 2005, P HERCMA 2005 C 7 HE
   Fotinea SE, 2012, LECT NOTES COMPUT SC, V7383, P237, DOI 10.1007/978-3-642-31534-3_37
   Greenberg Joseph H., 1963, UNIVERSALS LANG, P73
   Grieve-Smith Angus B., 1999, P 2 HIGH DES STUD C, P23
   Hengeveld K, 2004, FUNCT GRAMMAR, V24, P1
   HOITING N, 2002, DIRECTIONS SIGN LANG
   Huenerfauth M., 2006, GENERATING AM SIGN L
   Huenerfauth MP., 2003, AM SIGN LANGUAGE NAT
   Hutchins W. J., 1992, INTRO MACHINE TRANSL
   Ide N, 2000, P 2 INT C LANG RES E, P825
   Isabelle P., 2006, ENCY LANGUAGE LINGUI, P404, DOI [10.1016/B0-08-044854-2/00936-6, DOI 10.1016/B0-08-044854-2/00936-6]
   Kanis J, 2007, LECT NOTES ARTIF INT, V4629, P488
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Kay M., 1984, 10th International Conference on Computational Linguistics. 22nd Annual Meeting of the Association for Computational Linguistics. Proceedings of Coling 84, P75
   Klima E., 1975, SIGN LANGUAGE STUDIE, V8, P203, DOI DOI 10.1353/SIS.1975.0008
   Klima E. S., 1979, SIGNS LANGUAGE
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Koehn P., 2010, STAT MACHINE TRANSLA
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koleli E, 2011, THESIS
   Kouremenos D, 2010, BEHAV INFORM TECHNOL, V29, P467, DOI 10.1080/01449290903420192
   LIN S, 1997, P EUR, P1463
   Moore R., 2010, P ACL 2010 C SHORT P, P220
   Morissey S, 2008, THESIS
   Morrissey S., 2007, P 2007 MACH TRANSL S
   Morrissey S, 2013, MACH TRANSL, V27, P25, DOI 10.1007/s10590-012-9133-1
   Neidle C, 2001, BEHAV RES METH INS C, V33, P311, DOI 10.3758/BF03195384
   Och FJ, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P440
   Ostrogonac S., 2013, P INT SCI PROF S INF, P391
   Ostrogonac S, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P720, DOI 10.1109/TELFOR.2012.6419309
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Porta J, 2014, COMPUT SPEECH LANG, V28, P788, DOI 10.1016/j.csl.2013.10.003
   Ritchie E., 2013, OFFICIAL AM SIGN LAN
   Safar E., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P58
   San-Segundo R, 2008, SPEECH COMMUN, V50, P1009, DOI 10.1016/j.specom.2008.02.001
   Shieber S. M, 2003, INTRO UNIFICATION BA
   Sinclair John, 1991, CORPUS CONCORDANCE C
   Slobin D.I., 2001, SIGN LANG LINGUIST, V4, P63
   Speers D., 2002, REPRESENTATION AM SI
   Stein D., 2006, P 11 ANN C EUROPEAN, P169
   Stokoe Jr W. C., 1969, SIGN LANGUAGE DIGLOS
   Stoleke A., 2002, P 2002 INT C SPOK LA
   Stranppa N., 2006, PHYTOTHERAPY, P31
   Supalla Ted R., 1986, NOUN CLASSES CATEGOR, DOI [DOI 10.1075/TSL.7.13SUP, 10.1075/tsl.7.13sup]
   Sutton V., 1978, SUTTON MOVEMENT SHOR
   Sutton V, 1995, LESSONS SIGN WRITING
   Sutton-Spence R., 1999, LINGUISTICS BRIT SIG
   Toma P, 1977, P 3 EUR C INF SYST N, P569
   Tripathi S, 2010, ANN LIB INFORM STUDI, V57, P388
   Trujillo A., 1999, TRANSLATION ENGINES, P121, DOI [10.1007/978-1-4471-0587-9_6, DOI 10.1007/978-1-4471-0587-9_6]
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
   Wu C.-H., 2007, TRANSFER BASED STAT, V6, DOI [10.1145/1227850.1227851, DOI 10.1145/1227850.1227851]
   Yamada K, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P523
   Zhao B., 2004, P 20 INT C COMP LING, P1, DOI [10.3115/1220355.1220414, DOI 10.3115/1220355.1220414]
   Zhao LW, 2000, LECT NOTES ARTIF INT, V1934, P54
   [No title captured]
NR 91
TC 13
Z9 13
U1 0
U2 22
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD SEP
PY 2018
VL 51
BP 110
EP 135
DI 10.1016/j.csl.2018.04.001
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GG6CA
UT WOS:000432782400006
DA 2023-11-10
ER

PT J
AU Schramowski, P
   Turan, C
   Andersen, N
   Rothkopf, CA
   Kersting, K
AF Schramowski, Patrick
   Turan, Cigdem
   Andersen, Nico
   Rothkopf, Constantin A.
   Kersting, Kristian
TI Large pre-trained language models contain human-like biases of what is
   right and wrong to do
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
AB Large language models identify patterns in the relations between words and capture their relations in an embedding space. Schramowski and colleagues show that a direction in this space can be identified that separates 'right' and 'wrong' actions as judged by human survey participants.
   Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a 'moral direction' which can be computed, for example, by a PCA, in the embedding space. The computed 'moral direction' can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the 'moral direction' can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed.
C1 [Schramowski, Patrick; Turan, Cigdem; Kersting, Kristian] Tech Univ Darmstadt, Comp Sci Dept, Artificial Intelligence & Machine Learning Lab, Darmstadt, Germany.
   [Turan, Cigdem; Rothkopf, Constantin A.; Kersting, Kristian] Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany.
   [Andersen, Nico] Leibniz Inst Res & Informat Educ, Frankfurt, Germany.
   [Rothkopf, Constantin A.] Tech Univ Darmstadt, Inst Psychol, Darmstadt, Germany.
   [Rothkopf, Constantin A.; Kersting, Kristian] Hessian Ctr Artificial Intelligence Hessian Ai, Darmstadt, Germany.
C3 Technical University of Darmstadt; Technical University of Darmstadt;
   Technical University of Darmstadt
RP Schramowski, P; Turan, C (通讯作者)，Tech Univ Darmstadt, Comp Sci Dept, Artificial Intelligence & Machine Learning Lab, Darmstadt, Germany.; Turan, C (通讯作者)，Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany.
EM schramowski@cs.tu-darmstadt.de; cigdem.turan@cs.tu-darmstadt.de
OI Schramowski, Patrick/0000-0003-1231-7120; Turan-Schwiewager,
   Cigdem/0000-0002-4836-6023; Rothkopf, Constantin/0000-0002-5636-0801
FU ICT-48 Network of AI Research Excellence Center 'TAILOR' (EU Horizon
   2020) [952215]; Hessian research priority programme LOEWE within the
   project WhiteBox; Hessian Ministry of Higher Education, Research and the
   Arts (HMWK)
FX The authors thank the anonymous reviewers for their valuable feedback.
   Further, the authors are thankful to Aleph Alpha for very useful
   feedback and access to the GPT-3 API. This work benefited from the
   ICT-48 Network of AI Research Excellence Center 'TAILOR' (EU Horizon
   2020, grant agreement no. 952215) (K.K.), the Hessian research priority
   programme LOEWE within the project WhiteBox (K.K. and C.R.), and the
   Hessian Ministry of Higher Education, Research and the Arts (HMWK)
   cluster projects 'The Adaptive Mind' (K.K. and C.R.) and 'The Third Wave
   of AI' (K.K., C.R. and P.S.).
CR Abid A., 2021, PERSISTENT ANTIMUSLI, P298, DOI DOI 10.1145/3461702.3462624
   Alexander L., 2021, STANFORD ENCY PHILOS
   [Anonymous], 2020, NAT MACH INTELL, V2, P419, DOI 10.1038/s42256-020-0223-0
   [Anonymous], GPT 3 POWERS NEXT GE
   [Anonymous], 2019, IEEE SPECTRUM
   Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Berreby F, 2015, LECT NOTES COMPUT SC, V9450, P532, DOI 10.1007/978-3-662-48899-7_37
   Bicchieri C., 2018, STANFORD ENCY PHILOS
   Bolukbasi T, 2016, ADV NEUR IN, V29
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230
   Cer D, 2018, P EMNLP, P169
   Chami I, 2021, PR MACH LEARN RES, V139
   Chen B., 2021, 9 INT C LEARN REPR
   Chen MX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2287, DOI 10.1145/3292500.3330723
   Christakis NA, 2019, NATURE, V569, P627, DOI 10.1038/d41586-019-01658-w
   Churchland P. S., 2019, CONSCIENCE ORIGINS M
   Conneau A, 2017, P C EMP METH NAT LAN, P670, DOI [10.18653/v1/d17-1070, DOI 10.18653/V1/D17-1070]
   Dathathri S, 2020, ICLR
   Devlin J., 2018, ARXIV, V1, P4171
   Fassin Didier, 2012, COMPANION MORAL ANTH, P1, DOI DOI 10.1002/9781118290620.CH
   Gehman Samuel, 2020, FINDINGS ASS COMPUTA, P3356
   Gert B., 2020, STANFORD ENCY PHILOS, VFall 2020
   Goldberg Yoav, 2019, ABS190105287 ARXIV
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, P8342, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Hendrycks D., 2021, P INT C LEARN REPR, P1
   Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0
   Jentzsch S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P37, DOI 10.1145/3306618.3314267
   Katzenstein Peter J., 1996, CULTURE NATL SECURIT, DOI DOI 10.1057/EJDR.2009.24
   Keskar Nitish Shirish, 2019, CTRL CONDITIONAL TRA
   Kurita K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P166
   Levine S, 2020, P NATL ACAD SCI USA, V117, P26158, DOI 10.1073/pnas.2014505117
   Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241
   Lindström B, 2018, J EXP PSYCHOL GEN, V147, P228, DOI 10.1037/xge0000365
   Maxwell F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P653
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Peng X., 2020, P 13 INT C NATURAL L, P374
   Pereira Luis Moniz, 2009, International Journal of Reasoning-based Intelligent Systems, V1, P209, DOI 10.1504/IJRIS.2009.028020
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Reif E., 2019, NEURIPS
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418
   Ross AS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2662
   Schramowski P, 2020, NAT MACH INTELL, V2, P476, DOI 10.1038/s42256-020-0212-3
   Schramowski P, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00036
   Shafer-Landau R, 2012, ETHICAL THEORY ANTHO, V13
   Shwartz V, 2019, T ASSOC COMPUT LING, V7, P403, DOI 10.1162/tacl_a_00277/1923583
   SUMNER LW, 1967, ETHICS, V77, P95, DOI 10.1086/291620
   Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342
   Tan Y. C., 2019, ADV NEURAL INFORM PR, P13209
   Tenney Ian, 2019, INT C LEARN REPR
   Teso S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P239, DOI 10.1145/3306618.3314293
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang Zhuosheng, 2020, AAAI CONF ARTIF INTE, P9628
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 58
TC 15
Z9 15
U1 9
U2 26
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD MAR
PY 2022
VL 4
IS 3
BP 258
EP +
DI 10.1038/s42256-022-00458-8
PG 17
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY2TX
UT WOS:000772442700005
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Vinciarelli, A
   Bengio, S
   Bunke, H
AF Vinciarelli, A
   Bengio, S
   Bunke, H
TI Offline recognition of unconstrained handwritten texts using HMMs and
   statistical language models
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE offline cursive handwriting recognition; statistical language models;
   N-grams; continuous density Hidden Markov Models
ID PROBABILISTIC FUNCTIONS; LINE
AB This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts. The only assumption made about the data is that it is written in English. This allows the application of Statistical Language Models in order to improve the performance of our system. Several experiments have been performed using both single and multiple writer data. Lexica of variable size (from 10,000 to 50,000 words) have been used. The use of language models is shown to improve the accuracy of the system (when the lexicon contains 50,000 words, the error rate is reduced by similar to 50 percent for single writer data and by similar to 25 percent for multiple writer data). Our approach is described in detail and compared with other methods presented in the literature to deal with the same problem. An experimental setup to correctly deal with unconstrained text recognition is proposed.
C1 IDIAP, Dalle Molle Inst Perceptual Artificial Intelligen, CH-1920 Martigny, Switzerland.
   Univ Bern, CH-3012 Bern, Switzerland.
C3 University of Bern
RP Vinciarelli, A (通讯作者)，IDIAP, Dalle Molle Inst Perceptual Artificial Intelligen, Rua Simplon 4, CH-1920 Martigny, Switzerland.
EM vincia@idiap.ch; bengio@idiap.ch; bunke@iam.unibe.ch
RI Vinciarelli, Alessandro/HZI-8274-2023; Vinciarelli,
   Alessandro/C-1651-2012
OI Vinciarelli, Alessandro/0000-0002-9048-0524
CR [Anonymous], 1972, INEQUALITIES
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   BELLMAN R, 1991, ADAPTIVE CONTROL PRO
   Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452
   COHEN E, 1994, IEEE T PATTERN ANAL, V16, P1049, DOI 10.1109/34.329003
   El Yacoubi A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1024, DOI 10.1109/ICDAR.1995.602077
   El-Yacoubi MA, 2002, IEEE T PATTERN ANAL, V24, P172, DOI 10.1109/34.982898
   GRAFF D, 2000, P TOP DET TRACK WORK
   Guillevic D, 1998, PATTERN ANAL APPL, V1, P28, DOI 10.1007/BF01238024
   JELINEK F, 1989, READINGS SPEECH RECO, P450
   JELINEK F, 1998, STAT ASPECTS SPEECH
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Kim G., 1999, International Journal on Document Analysis and Recognition, V2, P37, DOI 10.1007/s100320050035
   KIM G, 1999, PATTERN RECOGN, V2, P37
   Kim GG, 1998, PATTERN RECOGN, V31, P41, DOI 10.1016/S0031-3203(97)00023-X
   Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3
   Luttin J., 2000, P 7 INT WORKSH FRONT, P493
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   PAQUET T, 1993, PATTERN RECOGN, V26, P391, DOI 10.1016/0031-3203(93)90167-U
   Park J, 2002, PATTERN RECOGN, V35, P245, DOI 10.1016/S0031-3203(00)00176-X
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887
   SRIHARI RK, 1993, IJCAI-93, VOLS 1 AND 2, P1262
   SRIHARI RK, 1994, P ARPA WORKSH HUM LA, P403
   STEINHERZ T, 1999, INT J DOC ANAL RECOG, V2, P1
   Vinciarelli A, 2002, PATTERN RECOGN, V35, P1433, DOI 10.1016/S0031-3203(01)00129-7
   Vinciarelli A, 2001, PATTERN RECOGN LETT, V22, P1043, DOI 10.1016/S0167-8655(01)00042-3
   Vinciarelli A., 2002, P INT C PATT REC ICP, P493
   VINCIARELLI A, 2003, P INT C DOC AN REC
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Zimmermann M, 2002, INT C PATT RECOG, P35, DOI 10.1109/ICPR.2002.1047394
NR 37
TC 167
Z9 172
U1 10
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUN
PY 2004
VL 26
IS 6
BP 709
EP 720
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 811EZ
UT WOS:000220756500005
PM 18579932
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Schick, T
   Udupa, S
   Schütze, H
AF Schick, Timo
   Udupa, Sahana
   Schuetze, Hinrich
TI Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based
   Bias in NLP
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper contains prompts and model outputs that are offensive in nature.
   When trained on large, unfiltered crawls from the Internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: They often generate racist, sexist, violent, or otherwise toxic language. As largemodels require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: Pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated-word lists, nor does it require any training data or changes to the model's parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.(1)
C1 [Schick, Timo; Schuetze, Hinrich] Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc CIS, Munich, Germany.
   [Udupa, Sahana] Ludwig Maximilians Univ Munchen, Inst Social & Cultural Anthropol, Munich, Germany.
C3 University of Munich; University of Munich
RP Schick, T (通讯作者)，Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc CIS, Munich, Germany.
EM schickt@cis.lmu.de; sahana.udupa@lmu.de; inquiries@cislmu.org
FU European Research Council (ERC) under the European Union's Horizon 2020
   research and innovation programme [740516, 957442]; European Research
   Council (ERC) [957442] Funding Source: European Research Council (ERC)
FX This work was funded by the European Research Council (ERC #740516 and
   #957442) under the European Union's Horizon 2020 research and innovation
   programme. We thank the anonymous reviewers and the action editor for
   their helpful comments.
CR Abid Abubakar, 2021, ARXIV210105783V2, DOI [10.1145/3461702.3462624, DOI 10.1145/3461702.3462624]
   AlecRadford Karthik Narasimhan, 2018, IMPROVING LANGUAGE U
   Basta C, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P33
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Bolukbasi T, 2016, ADV NEUR IN, V29
   Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230
   Dathathri S, 2020, ICLR
   Dev S, 2020, AAAI CONF ARTIF INTE, V34, P7659
   Devlin J., 2018, ARXIV, V1, P4171
   Fedus William, 2021, ARXIV210103961V1
   Gehman Samuel, 2020, FINDINGS ASS COMPUTA, P3356
   Gokaslan Aaron, 2019, OPENWEBTEXT CORPUS
   Gonen Hila, 2019, P NAACL HLT, P609
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, P8342, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Junxian He, 2020, ARXIV201204281V1
   Kaneko M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P212
   Kaneko M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1256
   Kassner N., 2020, PROC 58 ANN M ASS CO, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]
   Keskar Nitish Shirish, 2019, ARXIV190905858V2
   Knowles Rebecca, 2016, C ASS MACHINE TRANSL, V1, P107
   Krause Ben, 2021, FINDINGS ASS COMPUTA, P4929
   Liang Sheng, 2020, P 28 INT C COMP LING, P5082, DOI DOI 10.18653/V1/2020.COLING-MAIN.446
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Mikolov T., 2013, ARXIV13013781 CS, DOI DOI 10.48550/ARXIV.1301.3781
   Nadeem M., 2021, P 59 ANN M ASS COMPU, P5356, DOI [10.18653/v1/2021.acl-long.416, DOI 10.18653/V1/2021.ACL-LONG.416]
   Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953
   Pavlopoulos J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4296
   Puri Raul, 2019, ARXIV191210165V1
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Ravfogel Shauli, 2020, P 58 ANN M ASS COMP, P7237, DOI DOI 10.18653/V1/2020.ACL-MAIN.647
   Rudinger Rachel, 2018, P 2018 C N AM CHAPT, V2, DOI [10.18653/v1/n18- 2002, DOI 10.18653/V1/N18-2002]
   Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2699
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339
   Schick Timo, 2021, P 16 C EUR CHAPT ASS
   Schick Timo, 2020, ARXIV201211926V1
   Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407
   StephenMerity Caiming Xiong, 2017, 5 INT C LEARN REPR I
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Timnit Gebru, 2021, P 2020 C FAIRN ACC T
   Udupa S, 2020, ARTIF INTELL
   Udupa S., 2021, EXTREME SPEECH CHALL
   Wang Alex, 2019, ARXIV190204094, DOI [10.18653/v1/W19-2304, DOI 10.18653/V1/W19-2304]
   Wolf T., P 2020 C EMPIRICAL M, P38
   Wuebker J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P66
   Zhao JY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4847
   Zhao Jieyu, 2017, P 2017 C EMP METH NA, P2979, DOI DOI 10.18653/V1/D17-1323
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 52
TC 8
Z9 8
U1 3
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 1408
EP 1424
DI 10.1162/tacl_a_00434
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200084
OA Green Accepted, Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Imankulova, A
   Sato, T
   Komachi, M
AF Imankulova, Aizhan
   Sato, Takayuki
   Komachi, Mamoru
TI Filtered Pseudo-parallel Corpus Improves Low-resource Neural Machine
   Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Pseudo-parallel corpus; filtering; low-resource language pairs;
   round-trip translation; sentence-level similarity metrics; bootstrapping
AB Large-scale parallel corpora are essential for training high-quality machine translation systems; however, such corpora are not freely available for many language translation pairs. Previously, training data has been augmented by pseudo-parallel corpora obtained by using machine translation models to translate monolingual corpora into the source language. However, in low-resource language pairs, in which only low-accurate machine translation systems can be used, translation quality degrades when a pseudo-parallel corpus is naively used. To improve machine translation performance with low-resource language pairs, we propose a method to effectively expand the training data via filtering the pseudo-parallel corpus using quality estimation based on sentence-level round-trip translation. For experiments with three language pairs that utilized small, medium, and large size parallel corpora, BLEU scores significantly improved for low-resource language pairs. Additionally, the effects of iterative bootstrapping on translation performance quality is investigated; resultingly, it is confirmed that bootstrapping can further improve the translation performance.
C1 [Imankulova, Aizhan; Sato, Takayuki; Komachi, Mamoru] Tokyo Metropolitan Univ, Grad Sch Syst Design, 6-6 Asahigaoka, Hino, Tokyo 1910065, Japan.
C3 Tokyo Metropolitan University
RP Imankulova, A (通讯作者)，Tokyo Metropolitan Univ, Grad Sch Syst Design, 6-6 Asahigaoka, Hino, Tokyo 1910065, Japan.
EM imankulova-aizhan@ed.tmu.ac.jp; sasatatata99@gmail.com;
   komachi@tmu.ac.jp
RI Komachi, Mamoru/IUM-3747-2023; Komachi, Mamoru/AAC-7719-2019
OI Komachi, Mamoru/0000-0003-1166-1739; 
CR [Anonymous], 2017, ARXIV170102810
   [Anonymous], 2007, P 45 ANN M ASS COMPU
   Artetxe Mikel, 2018, P INT C LEARN REPR
   Axelrod A., 2011, P C EMP METH NAT LAN, P355
   Bertoldi N., 2009, P 4 WORKSHOP STAT MA, P182
   Cotterell Ryan, 2018, ABS180604402 CORR
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489
   Goldhahn Dirk, 2016, CCURL 2016 COLLABORA, P67
   He Di, 2016, ADV NEURAL INFORM PR, P820, DOI DOI 10.5555/3157096.3157188
   Hsieh A.-C., 2013, P 2 WORKSH HYBR APPR, P117
   Imamura K, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P55
   Imankulova A., 2017, P 4 WORKSHOP ASIAN T, P70
   Kajiwara T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180885
   Koehn P, 2002, EUROPARL MULTILINGUA
   Koehn P., 2017, WMT, P28
   Lample Guillaume, 2018, P INT C LEARN REPR
   Lin C.-Y., 2004, COLING 2004 P 20 INT, P501, DOI DOI 10.3115/1220355.1220427
   Lin Chin-Yew, 2004, P 42 ANN M ASS COMP, P5, DOI DOI 10.3115/1218955.1219032
   Mikolov T., 2013, 1 INT C LEARN REPR I
   Moore R., 2010, P ACL 2010 C SHORT P, P220
   Niu X, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P84
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Schwenk, 2008, P INT WORKSH SPOK LA, P182
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Song Y, 2015, INT C COMP SUPP COOP, P127, DOI 10.1109/CSCWD.2015.7230945
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   van der Wees Marlies, 2017, P 2017 C EMP METH NA, P1400
   Hoang VCD, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P18
   Wang H, 2014, SIGNAL PROCESS-IMAGE, V29, P773, DOI 10.1016/j.image.2014.05.001
   Yildiz E., 2014, EFFECT PARALLEL CORP, P21, DOI [10.5121/csit.2014.4710, DOI 10.5121/CSIT.2014.4710]
   Yin BB, 2016, 2016 IEEE CHINESE GUIDANCE, NAVIGATION AND CONTROL CONFERENCE (CGNCC), P1535, DOI 10.1109/CGNCC.2016.7829018
   Zhang ZR, 2018, AAAI CONF ARTIF INTE, P555
NR 32
TC 12
Z9 13
U1 4
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR
PY 2020
VL 19
IS 2
AR 24
DI 10.1145/3341726
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LR5IO
UT WOS:000535728600007
OA Bronze
DA 2023-11-10
ER

PT J
AU Chalkidis, I
   Kampas, D
AF Chalkidis, Ilias
   Kampas, Dimitrios
TI Deep learning in law: early adaptation and legal word embeddings trained
   on large corpora
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article
DE Natural language processing; Deep learning; Legal word vectors
AB Deep Learning has been widely used for tackling challenging natural language processing tasks over the recent years. Similarly, the application of Deep Neural Networks in legal analytics has increased significantly. In this survey, we study the early adaptation of Deep Learning in legal analytics focusing on three main fields; text classification, information extraction, and information retrieval. We focus on the semantic feature representations, a key instrument for the successful application of deep learning in natural language processing. Additionally, we share pre-trained legal word embeddings using the WORD2VEC model over large corpora, comprised legislations from UK, EU, Canada, Australia, USA, and Japan among others.
C1 [Chalkidis, Ilias] Athens Univ Econ & Business, Dept Informat, Athens, Greece.
   [Kampas, Dimitrios] Luxembourg Inst Sci & Technol, IT Innovat Serv, Esch Sur Alzette, Luxembourg.
C3 Athens University of Economics & Business; Luxembourg Institute of
   Science & Technology
RP Chalkidis, I (通讯作者)，Athens Univ Econ & Business, Dept Informat, Athens, Greece.
EM ihalk@aueb.gr; dimitrios.kampas@list.lu
OI Chalkidis, Ilias/0000-0002-0706-7772
CR [Anonymous], 2016, T ASSOC COMPUT LING, DOI DOI 10.1162/TACL_A_00051
   [Anonymous], 2004, P C EMP METH NAT LAN
   Branting LK, 2017, P MIREL WORKSH 16 IN
   Brien LO, 2017, P INT C ART INT LAW, P159
   Chalkidis I, 2018, P 56 ANN M ASS COMP
   Chalkidis I, 2017, P 16 ED INT C ART IN, P19
   Chalkidis I, 2017, FRONT ARTIF INTEL AP, V302, P155, DOI 10.3233/978-1-61499-838-9-155
   Do P., 2017, CORR
   Firth J. R., 1935, T PHILOL SOC, V34, P36, DOI https://doi.org/10.1111/j.1467-968X.1935.tb01254.x
   Goldberg Y, 2017, SYNTHESIS LECT HUMAN
   Goodfellow I., 2016, DEEP LEARNING
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Mikolov T., 2013, P 26 INT C NEURAL IN
   Morimoto A., 2017, 4 COMP LEG INF EXTR
   My Kim, 2015, 9 INT WORKSH JUR INF
   Nanda R, 2017, COLIEE ICAIL, P68, DOI DOI 10.29007/PSGX
   Nejadgholi I, 2017, FRONT ARTIF INTEL AP, V302, P125, DOI 10.3233/978-1-61499-838-9-125
   Nguyen T, 2017, 2 ASAIL WORKSH 16 16
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Peters Matthew E., 2018, C NA CHAPT ASS COMP
   Tang G., 2016, MATCHING LAW CASES R
   Nguyen TS, 2018, ARTIF INTELL LAW, V26, P169, DOI 10.1007/s10506-018-9225-1
   Yang ZJ, 2016, ADV SOC SCI EDUC HUM, V64, P1480
NR 23
TC 62
Z9 66
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD JUN
PY 2019
VL 27
IS 2
SI SI
BP 171
EP 198
DI 10.1007/s10506-018-9238-9
PG 28
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Law
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Government & Law
GA HW7HI
UT WOS:000466860400004
DA 2023-11-10
ER

PT J
AU Gorniak, P
   Roy, D
AF Gorniak, P
   Roy, D
TI Grounded semantic composition for visual scenes
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
LA English
DT Article
ID SPATIAL LANGUAGE; PERCEPTION; DYNAMICS; WORDS
AB We present a visually-grounded language understanding model based on a study of how people verbally describe objects in scenes. The emphasis of the model is on the combination of individual word meanings to produce meanings for complex referring expressions. The model has been implemented, and it is able to understand a broad range of spatial referring expressions. We describe our implementation of word level visually-grounded semantics and their embedding in a compositional parsing framework. The implemented system selects the correct referents in response to natural language expressions for a large percentage of test cases. In an analysis of the system's successes and failures we reveal how visual context influences the semantics of utterances and propose future extensions to the model that take such context into account.
C1 MIT, Media Lab, Cambridge, MA 02139 USA.
C3 Massachusetts Institute of Technology (MIT)
RP Gorniak, P (通讯作者)，MIT, Media Lab, 20 Ames St, Cambridge, MA 02139 USA.
EM PGORNIAK@MEDIA.MIT.EDU; DKROY@MEDIA.MIT.EDU
CR Abney S, 1997, TEXT SPEECH LANG TEC, V2, P118
   ALLEN J, 1995, NATURAL LANGUAGE UND, pCH3
   Bailey D., 1997, THESIS U CALIFORNIA
   Barker C, 2002, LINGUIST PHILOS, V25, P1, DOI 10.1023/A:1014346114955
   *BLEND FDN, 2003, BLEND 3D GRAPH CREAT
   BROWN MK, 1992, IEEE T SYST MAN CYB, V22, P1390, DOI 10.1109/21.199464
   BROWNSCHMIDT S, 2002, P COGN SCI SOC
   Carletta J, 1996, J PRAGMATICS, V26, P71, DOI 10.1016/0378-2166(95)00046-1
   Desolneux A, 2003, IEEE T PATTERN ANAL, V25, P508, DOI 10.1109/TPAMI.2003.1190576
   DHANDE S, 2003, THESIS MIT
   Di Eugenio B, 2000, INT J HUM-COMPUT ST, V53, P1017, DOI 10.1006/ijhc.2000.0428
   Engbers EA, 2003, IEEE T PATTERN ANAL, V25, P445, DOI 10.1109/TPAMI.2003.1190571
   GORNIAK P, 2003, P INT C MULT INT
   Griffin ZM, 2000, PSYCHOL SCI, V11, P274, DOI 10.1111/1467-9280.00255
   Haddock NJ, 1989, LANG COGNITIVE PROC, V4, pSI337, DOI 10.1080/01690968908406372
   HSIAO K, 2003, P IEEE RSJ INT C INT
   JACKENDOFF R, 2002, STORAGE COMPUTATION, pCH2
   Johnson-Laird P.N., 1976, LANGUAGE PERCEPTION
   Kyburg A, 2000, LINGUIST PHILOS, V23, P577, DOI 10.1023/A:1005625125110
   LAMMENS JM, 1994, THESIS STATE U NEW Y
   LANDAU B, 1993, BEHAV BRAIN SCI, V16, P217, DOI 10.1017/S0140525X00029733
   NAGAO K, 1995, P INT JOINT C ART IN
   Narayanan S., 1997, THESIS U CALIFORNIA
   Partee B, 1995, INVITATION COGNITIVE, P311
   PECHMANN T, 1989, LINGUISTICS, V27, P89, DOI 10.1515/ling.1989.27.1.89
   Pustejovsky J., 1995, GENERATIVE LEXICON
   Regier T, 2001, J EXP PSYCHOL GEN, V130, P273, DOI 10.1037//0096-3445.130.2.273
   Regier T., 1996, HUMAN SEMANTIC POTEN
   ROY D, 2002, COMPUTER SPEECH LANG, V16
   Roy Deb, 2002, P INT C SPOK LANG PR
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4
   SCHULER W, 2003, P ASS COMP LING
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790
   WERTHEIMER M, 1999, SOURCE BOOK GESTALT, P71
   Winograd Terry, 1970, THESIS MIT
   YOSHIDA N, 2002, THESIS MIT
NR 37
TC 65
Z9 65
U1 1
U2 4
PU AI ACCESS FOUNDATION
PI MARINA DEL REY
PA USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA
   90292-6695 USA
SN 1076-9757
EI 1943-5037
J9 J ARTIF INTELL RES
JI J. Artif. Intell. Res.
PY 2004
VL 21
BP 429
EP 470
DI 10.1613/jair.1327
PG 42
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 852OY
UT WOS:000223767500004
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Metawei, MA
   Taher, M
   ElDeeb, H
   Nassar, SM
AF Metawei, Maha A.
   Taher, Mohamed
   ElDeeb, Hesham
   Nassar, Salwa M.
TI A topic-aware classifier based on a hybrid quantum-classical model
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Quantum natural language processing; Quantum neural network; Hybrid
   quantum-classical; Classification; Supervised learning
AB In the era of Large Language Models, there is still potential for improvement in current Natural Language Processing (NLP) methods in terms of verifiability and consistency. NLP classical approaches are computationally expensive due to their high-power consumption, computing power, and storage requirements. Another computationally efficient approach to NLP is categorical quantum mechanics, which combines grammatical structure and individual word meaning to deduce the sentence meaning. As both quantum theory and natural language use vector space to describe states which are more efficient on quantum hardware, QNLP models can achieve up to quadratic speedup over classical direct calculation methods. In recent years, there is significant progress in utilizing quantum features such as superposition and entanglement to represent linguistic meaning on quantum hardware. Earlier research work has already demonstrated QNLP's potential quantum advantage in terms of speeding up search, enhancing classification tasks' accuracy and providing an exponentially large quantum state space in which complex linguistic structures can be efficiently embedded. In this work, a QNLP model is used to determine if two sentences are related to the same topic or not. By comparing our QNLP model to a classical tensor network-based one, our model improved training accuracy by up to 45% and validation accuracy by 35%, respectively. The QNLP model convergence is also studied when varying: first, the problem size, second, parametrized quantum circuits used for model's training, and last, the backend quantum simulator noise model. The experimental results show that strongly entangled ansatz designs result in fastest model convergence.
C1 [Metawei, Maha A.; Taher, Mohamed] Ain Shams Univ, Fac Engn, Comp & Syst Dept, Cairo, Egypt.
   [Metawei, Maha A.; ElDeeb, Hesham; Nassar, Salwa M.] Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University; Egyptian Knowledge
   Bank (EKB); Electronics Research Institute (ERI)
RP Metawei, MA (通讯作者)，Ain Shams Univ, Fac Engn, Comp & Syst Dept, Cairo, Egypt.; Metawei, MA (通讯作者)，Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
EM maha_metawei@eri.sci.eg; mohamed.taher@eng.asu.edu.eg;
   eldeeb@eri.sci.eg; salwa@eri.sci.eg
OI Metawei, Maha/0000-0003-0178-7194
CR Aaronson S, 2016, ARXIV
   Abbas A, 2020, ARXIV
   Abbas A, 2021, NAT COMPUT SCI, V1, P403, DOI 10.1038/s43588-021-00084-1
   Abbas-zadeh M, 2021, ARXIV
   Aleksandrowicz Gadi, 2019, Zenodo, DOI 10.5281/ZENODO.2562111
   Arad I, 2010, SIAM J COMPUT, V39, P3089, DOI 10.1137/080739379
   Arthur D., 2022, ARXIV
   Bergholm V., 2018, ARXIV
   Biswas D etal, 2021, ARXIV
   Brakerski Z, 2020, ARXIV
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Casadio C, 2021, JOACHIM LAMBEK INTER
   Chen SYC, 2020, IEEE ACCESS, V8, P141007, DOI 10.1109/ACCESS.2020.3010470
   Coecke B, 2020, ARXIV
   Coecke B, 2022, QUANTUM COMPUTING AR, P277
   Coecke B, 2010, ARXIV
   Corp P, 2022, QML STRONGLYENTANGLI
   deFelice G, 2020, ARXIV
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   El-Mahalawy AM, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167793
   Farhi E., 2018, ARXIV
   Gambetta J., 2020, IBMS ROADMAP SCALING
   Georgescu IM, 2014, REV MOD PHYS, V86, P153, DOI 10.1103/RevModPhys.86.153
   Guarasci R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115651
   Havlícek V, 2019, NATURE, V567, P209, DOI 10.1038/s41586-019-0980-2
   Holmes Z, 2022, PRX QUANTUM, V3, DOI 10.1103/PRXQuantum.3.010313
   Hubregtsen T, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00038-w
   Karamlou A, 2022, ARXIV
   Kartsaklis D, 2021, ARXIV
   Kha QH, 2022, METHODS, V207, P90, DOI 10.1016/j.ymeth.2022.09.007
   Khatri N, 2022, EXPT COMP ANSATZE QU
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Le NQK, 2022, COMPUT BIOL CHEM, V99, DOI 10.1016/j.compbiolchem.2022.107732
   Lorenz R, 2021, ARXIV
   Meichanetzidis K, 2023, QUANT MACH INTELL, V5, DOI 10.1007/s42484-023-00097-1
   Metawei MA, 2022, EVALUATION DIFFERENT
   Metawei MA, 2020, 2020 INT C COMM COMP, P1
   Ragone M, 2022, ARXIV
   Schuld M, 2020, PHYS REV A, V101, DOI 10.1103/PhysRevA.101.032308
   Sim S, 2019, ADV QUANTUM TECHNOL, V2, DOI 10.1002/qute.201900070
   Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486
   Wang-Mascianica V, 2023, ARXIV
   Waseem MH., 2022, ELECT P THEOR COMPUT, V366, P50, DOI [10.4204/eptcs.366.7, DOI 10.4204/EPTCS.366.7]
   Wiebe N, 2015, QUANTUM INF COMPUT, V15, P316
   Womanium.org, 2022, WOM QUANT HACK
   Zeng WJ, 2016, SLPCS QPL
   Zyczkowski K, 2005, PHYS REV A, V71, DOI 10.1103/PhysRevA.71.032313
NR 47
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD SEP
PY 2023
VL 35
IS 25
SI SI
BP 18803
EP 18812
DI 10.1007/s00521-023-08706-7
EA JUN 2023
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P2WY3
UT WOS:001019458000003
OA hybrid
DA 2023-11-10
ER

PT J
AU Ni, P
   Li, GM
   Hung, PCK
   Chang, V
AF Ni, Pin
   Li, Gangmin
   Hung, Patrick C. K.
   Chang, Victor
TI StaResGRU-CNN with CMedLMs: A stacked residual GRU-CNN with pre-trained
   biomedical language models for predictive intelligence
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Natural language processing; Predictive intelligence; Biomedical text
   mining; Named Entity Recognition; Text classification; Transfer
   learning; Pre-trained language model
ID SENTIMENT ANALYSIS; NEURAL-NETWORK; TEXT
AB As a task requiring strong professional experience as supports, predictive biomedical intelligence cannot be separated from the support of a large amount of external domain knowledge. By using transfer learning to obtain sufficient prior experience from massive biomedical text data, it is essential to promote the performance of specific downstream predictive and decision-making task models. This is an efficient and convenient method, but it has not been fully developed for Chinese Natural Language Processing (NLP) in the biomedical field. This study proposes a Stacked Residual Gated Recurrent Unit-Convolutional Neural Networks (StaResGRU-CNN) combined with the pre-trained language models (PLMs) for biomedical text-based predictive tasks. Exploring related paradigms in biomedical NLP based on transfer learning of external expert knowledge and comparing some Chinese and English language models. We have identified some key issues that have not been developed or those present difficulties of application in the field of Chinese biomedicine. Therefore, we also propose a series of Chinese bioMedical Language Models (CMedLMs) with detailed evaluations of downstream tasks. By using transfer learning, language models are introduced with prior knowledge to improve the performance of downstream tasks and solve specific predictive NLP tasks related to the Chinese biomedical field to serve the predictive medical system better. Additionally, a free-form text Electronic Medical Record (EMR)-based Disease Diagnosis Prediction task is proposed, which is used in the evaluation of the analyzed language models together with Clinical Named Entity Recognition, Biomedical Text Classification tasks. Our experiments prove that the introduction of biomedical knowledge in the analyzed models significantly improves their performance in the predictive biomedical NLP tasks with different granularity. And our proposed model also achieved competitive performance in these predictive intelligence tasks. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Ni, Pin] UCL, Sch Engn, London, England.
   [Li, Gangmin] Univ Bedfordshire, Sch Comp Sci & Technol, Luton, Beds, England.
   [Hung, Patrick C. K.] Ontario Tech Univ, Fac Business & Informat Technol, Oshawa, ON, Canada.
   [Chang, Victor] Teesside Univ, Sch Comp Engn & Digital Technol, Artificial Intelligence & Informat Syst Res Grp, Middlesbrough, Cleveland, England.
C3 University of London; University College London; University of
   Bedfordshire; University of Teesside
RP Chang, V (通讯作者)，Teesside Univ, Sch Comp Engn & Digital Technol, Artificial Intelligence & Informat Syst Res Grp, Middlesbrough, Cleveland, England.
EM V.Chang@tees.ac.uk
RI Ni, Pin/GQA-5288-2022; Hung, Patrick C. K./AAI-4261-2020; Chang,
   Victor/AAC-7582-2019; Ni, Pin/AAC-3742-2020
OI Ni, Pin/0000-0003-4516-1249; Chang, Victor/0000-0002-8012-5852; Ni,
   Pin/0000-0003-4516-1249; Li, Gangmin/0000-0003-4006-7472
FU VC Research [VCR 0000130]; AI University Research Center (AI-URC)
   through the XJTLU Key Program Special Fund, China [KSF-P-02, KSF-A-17];
   Suzhou Bureau of Science and Technology through the Key Industrial
   Technology Innovation Program, China [SYG201840]
FX This research is partly supported by VC Research (VCR 0000130) for Prof.
   Chang. At the same time, this study is also partially supported by the
   AI University Research Center (AI-URC) through the XJTLU Key Program
   Special Fund, China (KSF-P-02, KSF-A-17) . And this work has received
   support from the Suzhou Bureau of Science and Technology through the Key
   Industrial Technology Innovation Program, China (No. SYG201840) . We
   also appreciate Google TensorFlow Research Cloud (TFRC) for providing
   support in computing resources. In addition, we would like to thank all
   colleagues who partic-ipated in this research project, especially Ms.
   Yuming Li and Mr. Zhenjin Dai. We would also like to express our sincere
   thanks to Mr. Thomas Cilloni for providing English language support to
   the manuscript.
CR Alsentzer Emily, 2019, P 2 CLIN NATURAL LAN, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/, DOI 10.18653/V1]
   Anagnostopoulos C, 2018, APPL INTELL, V48, P966, DOI 10.1007/s10489-017-1032-y
   [Anonymous], ARXIV160507725
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Bharadwaj A., 2016, P 2016 C EMPIRICAL M, P1462, DOI DOI 10.18653/V1/D16-1153
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chalkidis I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6314
   Chapiro J, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190139
   Chatterjee Rajen, 2017, P 2 C MACHINE TRANSL, P157
   Chen Q., 2017, ARXIV171104289
   Chen Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2406
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI DOI 10.1162/TACL_A_00104
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai AM, 2015, ADV NEUR IN, V28
   Devlin J., 2018, ARXIV, V1, P4171
   Dligach D, 2019, J AM MED INFORM ASSN, V26, P1272, DOI 10.1093/jamia/ocz072
   Du J, 2021, IEEE T CYBERNETICS, V51, P1586, DOI 10.1109/TCYB.2020.2969705
   Gargiulo F, 2019, APPL SOFT COMPUT, V79, P125, DOI 10.1016/j.asoc.2019.03.041
   Gridach M, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106232
   Gridach M, 2017, J BIOMED INFORM, V70, P85, DOI 10.1016/j.jbi.2017.05.002
   Groth, 2019, SEMANTICS POSTERS DE
   Hakala K., 2019, P 5 WORKSH BIONLP OP, P56, DOI DOI 10.18653/V1/D19-5709
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holzinger Andreas, 2014, Interactive Knowledge Discovery and Data Mining in Biomedical Informatics. State-of-the-Art and Future Challenges: LNCS 8401, P271, DOI 10.1007/978-3-662-43968-5_16
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang CC, 2016, BRIEF BIOINFORM, V17, P132, DOI 10.1093/bib/bbv024
   Huang K, 2019, CLINICALBERT MODELIN
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Jin Q., 2019, PROC 3 WORK EVAL VEC, P82, DOI [10.18653/v1/W19-2011, DOI 10.18653/V1/W19-2011]
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kamkarhaghighi M, 2017, EXPERT SYST APPL, V90, P241, DOI 10.1016/j.eswa.2017.08.021
   Kathidjiotis Y, 2020, APPL INTELL, V50, P3219, DOI 10.1007/s10489-020-01712-5
   Kim J, 2020, NEUROCOMPUTING, V376, P214, DOI 10.1016/j.neucom.2019.10.033
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lample G, 2016, P NAACL HLT, DOI DOI 10.18653/V1/N16-1030
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li JQ, 2016, KNOWL-BASED SYST, V106, P220, DOI 10.1016/j.knosys.2016.05.045
   Li YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3442
   Li YM, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON COMPLEXITY, FUTURE INFORMATION SYSTEMS AND RISK (COMPLEXIS), P53, DOI 10.5220/0009582700530060
   Li YM, 2019, IEEE INT CONF BIG DA, P6133, DOI 10.1109/BigData47090.2019.9005449
   Li YM, 2020, COMPUTING, V102, P1305, DOI 10.1007/s00607-019-00773-w
   Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Ni P, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3418208
   Ni P, 2020, INT J ENTERP INF SYS, V16, P1, DOI 10.4018/IJEIS.2020100101
   Ni P, 2020, NEURAL COMPUT APPL, V32, P16149, DOI 10.1007/s00521-020-04805-x
   Ni P, 2019, IEEE INT CONF BIG DA, P6166, DOI 10.1109/BigData47090.2019.9006331
   Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rios Anthony, 2015, ACM BCB, V2015, P258, DOI 10.1145/2808719.2808746
   Ruder S., 2019, THESIS NATL U IRELAN
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   Tomori S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P236
   Venkataraman GR, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234647
   Wang DS, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105913
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wikipedia, 2020, OFFL WIK CHIN DOWNL
   Yadav V., 2018, P 27 INT C COMP LING, P2145
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang H., 2018, P 2018 C N AM CHAPT, V2, P175, DOI [10.18653/v1/N18-2028, DOI 10.18653/V1/N18-2028]
NR 69
TC 8
Z9 8
U1 4
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD DEC
PY 2021
VL 113
AR 107975
DI 10.1016/j.asoc.2021.107975
EA OCT 2021
PN B
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XG4UW
UT WOS:000724750600006
OA Green Accepted, Green Submitted
DA 2023-11-10
ER

PT J
AU Chen, XY
   Jin, P
   Cai, P
   Wang, HJ
   Dai, XY
   Chen, JJ
AF Chen, Xingyuan
   Jin, Peng
   Cai, Ping
   Wang, Hongjun
   Dai, Xinyu
   Chen, Jiajun
TI The detection of distributional discrepancy for language GANs
SO CONNECTION SCIENCE
LA English
DT Article
DE Text generation; generative adversarial nets; distributional discrepancy
AB A pre-trained neural language model (LM) is usually used to generate texts. Due to exposure bias, the generated text is not as good as real text. Many researchers claimed they employed the Generative Adversarial Nets (GAN) to alleviate this issue by feeding reward signals from a discriminator to update the LM (generator). However, some researchers argued that GAN did not work by evaluating the generated texts with a quality-diversity metric such as Bleu versus self-Bleu, and language model score versus reverse language model score. Unfortunately, these two-dimension metrics are not reliable. Furthermore, the existing methods only assessed the final generated texts, thus neglecting the dynamic evaluating the adversarial learning process. Different from the above-mentioned methods, we adopted the most recent metric functions, which measure the distributional discrepancy between real and generated text. Besides that, we design a comprehensive experiment to investigate the performance during the learning process. First, we evaluate a language model with two functions and identify a large discrepancy. Then, several methods with the detected discrepancy signal to improve the generator were tried. Experimenting with two language GANs on two benchmark datasets, we found that the distributional discrepancy increases with more adversarial learning rounds. Our research provides convicted evidence that the language GANs fail.
C1 [Chen, Xingyuan; Dai, Xinyu; Chen, Jiajun] Nanjing Univ, Dept Comp Sci & Technol, Nanjing, Peoples R China.
   [Jin, Peng] Leshan Normal Univ, Sch Elect Engn & Artificial Intelligence, Leshan, Peoples R China.
   [Cai, Ping; Wang, Hongjun] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
C3 Nanjing University; Leshan Normal University; Southwest Jiaotong
   University
RP Dai, XY; Chen, JJ (通讯作者)，Nanjing Univ, Dept Comp Sci & Technol, Nanjing, Peoples R China.
EM daixinyu@nju.edu.cn; chenjj@nju.edu.cn
OI Jin, Peng/0000-0002-4835-0312
FU National Natural Science Foundation of China [61936012, 61976114,
   81373056]; National Key Research and Development Program of China
   [2018YFB1005102]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61936012, 61976114, 81373056] and the National Key
   Research and Development Program of China [grant number 2018YFB1005102].
CR Bengio S, 2015, ADV NEUR IN, V28
   Caccia M., 2018, ARXIV181102549
   Cai P, 2021, KNOWL-BASED SYST, V217, DOI 10.1016/j.knosys.2021.106850
   Cao ZX, 2021, CONNECT SCI, V33, P911, DOI 10.1080/09540091.2021.1912711
   Che T., 2017, MAXIMUM LIKELIHOOD A
   Chen L., 2018, P 32 INT C NEURAL IN, P4671
   dAutume Cyprien de Masson, 2019, ADV NEURAL INFORM PR, P4300, DOI DOI 10.5555/3454287.3454674
   Fedus W., 2018, ICLR, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gu FQ, 2018, IEEE T EVOLUT COMPUT, V22, P211, DOI 10.1109/TEVC.2017.2695579
   Guo JX, 2018, AAAI CONF ARTIF INTE, P5141
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T., 2021, EXPOSURE BIAS VERSUS
   Jang E., 2017, P INT C LEARN REPR, P1
   Kim Y., 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1181
   Li Y, 2022, CONNECT SCI, V34, P492, DOI 10.1080/09540091.2021.2021143
   Lin K., 2017, PROC 31 INT C NEURAL, P3158
   Lin NK, 2022, CONNECT SCI, V34, P29, DOI 10.1080/09540091.2021.1937942
   Nie Weili, 2018, INT C LEARN REPR
   Ondrej C<prime>ifka, 2018, ARXIV180407972
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Radford A., 2019, LANGUAGE MODELS ARE
   Salimans T, 2016, ADV NEUR IN, V29
   Santoro A, 2018, ADV NEUR IN, V31
   Semeniuta S., 2018, ABS180604936 CORR
   Shi Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4361
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Vaswani A., 2017, NIPS, V30
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu Q, 2021, CONNECT SCI, V33, P341, DOI 10.1080/09540091.2020.1822780
   Wu ST, 2022, CONNECT SCI, V34, P44, DOI 10.1080/09540091.2021.1940101
   Xu JJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3940
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zellers R, 2019, ADV NEUR IN, V32
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, P1097, DOI 10.1145/3209978.3210080
NR 37
TC 1
Z9 1
U1 2
U2 7
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0954-0091
EI 1360-0494
J9 CONNECT SCI
JI Connect. Sci.
PD DEC 31
PY 2022
VL 34
IS 1
BP 1736
EP 1750
DI 10.1080/09540091.2022.2080182
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2C4IM
UT WOS:000810833900001
OA gold
DA 2023-11-10
ER

PT J
AU Cheok, AD
   Jian, Z
   Chng, ES
AF Cheok, Adrian David
   Jian, Zhang
   Chng, Eng Siong
TI Efficient mobile phone Chinese optical character recognition systems by
   use of heuristic fuzzy rules and bigram Markov language models
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE statistical language model; Markov model; heuristic; fuzzy logic
AB Statistical language models are very useful tools to improve the recognition accuracy of optical character recognition (OCR) systems. In previous systems, segmentation by maximum word matching, semantic class segmentation, or trigram language models have been used. However, these methods have some disadvantages, such as inaccuracies due to a preference for longer words (which may be erroneous), failure to recognize word dependencies, complex semantic training data segmentation, and a requirement of high memory.
   To overcome these problems, we propose a novel bigram Markov language model in this paper. This type of model does not have large word preferences and does not require semantically segmented training data. Furthermore, unlike trigram models, the memory requirement is small. Thus, the scheme is suitable for handheld and pocket computers, which are expected to be a major future application of text recognition systems.
   However, due to a simple language model, the bigram Markov model alone can introduce more errors. Hence in this paper, a novel algorithm combining bigram Markov language models with heuristic fuzzy rules is described. It is found that the recognition accuracy is improved through the use of the algorithm, and it is well suited to mobile and pocket computer applications, including as we will show in the experimental results, the ability to run on mobile phones.
   The main contribution of this paper is to show how fuzzy techniques as linguistic rules can be used to enhance the accuracy of a crisp recognition system, and still have low computational complexity. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Cheok, Adrian David] Natl Univ Singapore, Mixed Real Lab, Singapore, Singapore.
   [Jian, Zhang] Sony Asia Pacific, Singapore, Singapore.
   [Chng, Eng Siong] Nanyang Technol Univ, Singapore, Singapore.
C3 National University of Singapore; Nanyang Technological University &
   National Institute of Education (NIE) Singapore; Nanyang Technological
   University
RP Cheok, AD (通讯作者)，Natl Univ Singapore, Mixed Real Lab, Singapore, Singapore.
EM adriancheok@mixedrealitylab.org
RI Cheok, Adrian David/AAT-6141-2021; Eng-Siong, CHNG/ABH-6779-2020; Chng,
   Eng-Siong/A-3667-2011
OI Cheok, Adrian David/0000-0001-6316-2339; Eng-Siong,
   CHNG/0000-0001-6257-7399; 
CR Bellegarda JR, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P262, DOI 10.1109/ASRU.1997.659014
   BIN T, 1996, P IEEE ICSP 96, P805
   Boston JR, 2000, IEEE T SYST MAN CY C, V30, P45, DOI 10.1109/5326.827453
   CHUANG CT, 1995, IEEE T SYST MAN CYB, V25, P1171, DOI 10.1109/21.391295
   CLARK JL, 1990, IEEE INT C DAT PAR A, P533
   DOSTER W, 1977, IEEE T COMPUT    NOV, P1090
   Gao JF, 2000, INT CONF ACOUST SPEE, P1703
   HAHN SH, 1999, STUDY UTILIZING OCR, P582
   Juang BH, 2000, P IEEE, V88, P1142, DOI 10.1109/5.880077
   Larsen HL, 2000, IEEE T SYST MAN CY C, V30, P65, DOI 10.1109/5326.827455
   LEA R, 1995, APIC 95 SUPPLEMENT I
   Lee H.-J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P72, DOI 10.1109/ICDAR.1993.395779
   LEE LS, 1994, P 1994 INT S SPEECH
   Liao TW, 2003, FUZZY SET SYST, V135, P241, DOI 10.1016/S0165-0114(02)00136-7
   MASA P, 1999, P 1999 IEEE INT SOL, P204
   Natarajan P., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P357, DOI 10.1109/ICDAR.1999.791798
   Ortmanns S, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2095, DOI 10.1109/ICSLP.1996.607215
   PAUL DB, 1991, P 1991 INT C AC SPEE, V1, P569
   Rubin SH, 1999, IEEE T SYST MAN CY B, V29, P518, DOI 10.1109/3477.775267
   Tung C.-H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P834, DOI 10.1109/ICDAR.1993.395608
   VOIT G, 1993, DOBBS J          FEB, P40
   Wang XZ, 2001, IEEE T SYST MAN CY B, V31, P215, DOI 10.1109/3477.915344
   Wong PK, 1999, IEEE T SYST MAN CY B, V29, P286, DOI 10.1109/3477.752802
   Wong PK, 1998, IEEE T PATTERN ANAL, V20, P1016, DOI 10.1109/34.713366
   Yager RR, 2000, IEEE T SYST MAN CY B, V30, P60, DOI 10.1109/3477.826947
   YANNAKOUDAKIS EJ, 1990, PATTERN RECOGN, V23, P509, DOI 10.1016/0031-3203(90)90072-S
NR 26
TC 7
Z9 7
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD MAR
PY 2008
VL 8
IS 2
BP 1005
EP 1017
DI 10.1016/j.asoc.2007.02.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 248FE
UT WOS:000252136600015
DA 2023-11-10
ER

PT J
AU Khemakhem, A
   Gargouri, B
   Ben Hamadou, A
   Francopoulo, G
AF Khemakhem, Aida
   Gargouri, Bilel
   Ben Hamadou, Abdelmajid
   Francopoulo, Gil
TI ISO standard modeling of a large Arabic dictionary
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
ID LEXICAL DATABASE
AB In this paper, we address the problem of the large coverage dictionaries of Arabic language usable both for direct human reading and automatic Natural Language Processing. For these purposes, we propose a normalized and implemented modeling, based on Lexical Markup Framework (LMF-ISO 24613) and Data Registry Category (DCR-ISO 12620), which allows a stable and well-defined interoperability of lexical resources through a unification of the linguistic concepts. Starting from the features of the Arabic language, and due to the fact that a large range of details and refinements need to be described specifically for Arabic, we follow a finely structuring strategy. Besides its richness in morphology, syntax and semantics knowledge, our model includes all the Arabic morphological patterns to generate the inflected forms from a given lemma and highlights the syntactic-semantic relations. In addition, an appropriate codification has been designed for the management of all types of relationships among lexical entries and their related knowledge. According to this model, a dictionary named El Madar (1) has been built and is now publicly available on line. The data are managed by a user-friendly Web-based lexicographical workstation. This work has not been done in isolation, but is the result of a collaborative effort by an international team mainly within the ISO network during a period of eight years.
C1 [Khemakhem, Aida; Gargouri, Bilel] Univ Sfax, MIRACL Lab, FSEGS, BP 1088, Sfax 3018, Tunisia.
   [Ben Hamadou, Abdelmajid] Univ Sfax, MIRACL Lab, ISIMS, BP 242, Sakiet Ezzit 3021, Sfax, Tunisia.
   [Francopoulo, Gil] IMMI CNRS, Rue John von Neumann, F-91405 Orsay, France.
   [Francopoulo, Gil] Tagmatica, Rue John von Neumann, F-91405 Orsay, France.
C3 Universite de Sfax; Universite de Sfax; Centre National de la Recherche
   Scientifique (CNRS)
RP Khemakhem, A (通讯作者)，Univ Sfax, MIRACL Lab, FSEGS, BP 1088, Sfax 3018, Tunisia.
EM khemakhem.aida@gmail.com; bilel.gargouri@fsegs.rnu.tn;
   abdelmajid.benhamadou@isimsf.rnu.tn; gil.francopoulo@wanadoo.fr
OI BEN HAMADOU, Abdelmajid/0000-0001-8632-2956; Gargouri,
   Bilel/0000-0003-4577-1362
CR Abbes R, 2004, P WORKSH COMP APPR A, P15
   Ait Taleb S., 2005, REV ASS MAROCAINE ET, P15
   [Anonymous], 2009, 2 INT C AR LANG RES
   [Anonymous], 1960, ARABIC LEXICOGRAPHY
   Antoni-Lay M.-H., 1994, Literary & Linguistic Computing, V9, P47, DOI 10.1093/llc/9.1.47
   Attia M, 2011, COMM COM INF SC, V100, P98
   Baccar F., 2011, 6 INT C SOFTW PAR TR, P396
   Baccar F., 2012, SEMIAUTOMATIC ONTOLO, P106, DOI [10.4018/978-1-4666-0188-8.ch005, DOI 10.4018/978-1-4666-0188-8.CH005]
   Baccar F., 2010, 22 INT C SOFTW ENG K, P515
   Baklouti N., 2013, 3 INT C CLOUD COMP S, P224
   Ben Abderrahmen M., 2006, 10 MAGHR C SOFTW ENG, P451
   Ben Abderrahmen M, 2009, LECT NOTES ARTIF INT, V5603, P279, DOI 10.1007/978-3-642-04235-5_24
   Ben Mrad I., 1987, AL GHARB AL ISLAMI
   Bertagna F., 2000, MULTILINGUAL ISLE LE
   Bogurev B., 1988, ACQUISITION LEXICAL
   Boudelaa S, 2010, BEHAV RES METHODS, V42, P481, DOI 10.3758/BRM.42.2.481
   Buckwalter T., 2004, BUCKWALTER ARABIC MO
   Calzolari N., 1996, MULTEXT COMMON SPECI
   CALZOLARI N, 1996, EAGLES FINAL REPORT
   Calzolari N., 2013, LMF LEXICAL MARKUP F, P1, DOI [10.1002/9781118712696.ch1, DOI 10.1002/9781118712696.CH1]
   Chaaben N., 2010, 10 INT C STAT AN TEX
   Diab M., 2010, LREC WORKSHOP SEMITI, P66
   Doumi N., 2013, 6 INT C TRAD TAL
   Elkateb S., 2006, P AR NLP MET C LOND, P15
   Francopoulo G., 2013, LMF LEXICAL MARKUP F
   Francopoulo G., 2008, ISOTC37SC4N453
   Francopoulo G., 2003, PROPOSITION NORMALIS
   Habash N, 2007, TEXT SPEECH LANG TEC, V38, P15
   Ide N., 2004, P 4 INT LANG RES EV, P135
   Khemakhem A., 2007, C TRAIT AUT LANG NAT, P133
   Khemakhem A., 2012, INT C COMP INF TECHN
   Khemakhem A., 2006, JOURNEES TRAITEMENT
   Khemakhem A., 2011, 30 C INT LEX GRAMM L, P453
   Landau SI., 2001, DICT ART CRAFT LEXIC, V2nd ed.
   Lenci A., 2000, LE48346 SIMPLE EC IL
   Loukil N., 2008, HLT NPL ARABIC WORLD, P93
   Maamouri M., 2006, P LREC GEN IT, P17
   Maks I, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1723
   Mesfar S., 2008, INT C FIN STAT METH, P110
   Rey-Debove J., 1971, ETUDE LINGUISTIQUE S, P317
   Romary L., 2004, WORKSH EL DICT COL G, P22
   Salmon-Alt S., 2005, 2 INT C MACH INT ACI
   Sawalha M., 2013, P 2 WORKSH AR CORP L, P1
   Smr O., 2007, P WORKSH COMP APPR S, P1
   Veronis J., 1996, LEXICOGRAPHIE INFORM, P239
NR 45
TC 8
Z9 8
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD NOV
PY 2016
VL 22
IS 6
BP 849
EP 879
DI 10.1017/S1351324915000224
PG 31
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA EA2PO
UT WOS:000386436900002
DA 2023-11-10
ER

PT J
AU Zhou, B
   Chen, JY
   Cai, QH
   Xue, Y
   Yang, C
   He, J
AF Zhou, Bo
   Chen, Jianying
   Cai, Qianhua
   Xue, Yun
   Yang, Chi
   He, Jing
TI Cross-domain sequence labelling using language modelling and parameter
   generating
SO CAAI TRANSACTIONS ON INTELLIGENCE TECHNOLOGY
LA English
DT Article
AB Sequence labelling (SL) tasks are currently widely studied in the field of natural language processing. Most sequence labelling methods are developed on a large amount of labelled training data via supervised learning, which is time-consuming and expensive. As an alternative, domain adaptation is proposed to train a deep-learning model for sequence labelling in a target domain by exploiting existing labelled training data in related source domains. To this end, the authors propose a Bi-LSTM model to extract more-related knowledge from multi-source domains and learn specific context from the target domain. Further, the language modelling training is also applied to cross-domain adaptability facilitating. The proposed model is extensively evaluated with the named entity recognition and part-of-speech tagging tasks. The empirical results demonstrate the effectiveness of the cross-domain adaption. Our model outperforms the state-of-the-art methods used in both cross-domain tasks and crowd annotation tasks.
C1 [Zhou, Bo; Chen, Jianying; Cai, Qianhua; Xue, Yun; Yang, Chi] South China Normal Univ, Sch Elect & Informat Engn, Foshan 528225, Peoples R China.
   [He, Jing] Univ Oxford, Dept Nerosci, Oxford, Oxon, England.
C3 South China Normal University; University of Oxford
RP Cai, QH (通讯作者)，South China Normal Univ, Sch Elect & Informat Engn, Foshan 528225, Peoples R China.
EM caiqianhua@m.scnu.edu.cn
RI Alidadi, Mehdi/HJZ-0235-2023
OI Alidadi, Mehdi/0000-0001-5183-7829
FU National Statistical Science Research Project of China [2016LY98];
   Science and Technology Department of Guangdong Province in China
   [2016A010101020, 2016A010101021, 2016A010101022]; Characteristic
   Innovation Projects of Guangdong Colleges and Universities
   [2018KTSCX049]; Science and Technology Plan Project of Guangzhou
   [202102080258, 201903010013]
FX National Statistical Science Research Project of China, Grant/Award
   Number: 2016LY98; Science and Technology Department of Guangdong
   Province in China, Grant/Award Numbers: 2016A010101020, 2016A010101021,
   2016A010101022; Characteristic Innovation Projects of Guangdong Colleges
   and Universities, Grant/Award Number: 2018KTSCX049; Science and
   Technology Plan Project of Guangzhou, Grant/Award Numbers: 202102080258,
   201903010013
CR Ammar Waleed, 2016, T ASS COMPUTATIONAL, V4, P431, DOI DOI 10.1162/TACL_A_00109
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P845
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Hovy Eduard, 2006, P HUM LANG TECHN C N, P57, DOI DOI 10.3115/1614049.1614064
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Jia C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2464
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, DOI DOI 10.18653/V1/N16-1030
   Lan O., PROC ACL ARXIV
   Liu LJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC)
   Liu LY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1215
   Liu ZH, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P1
   Low Jin Kiat, 2005, P 4 SIGHAN WORKSH CH
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   McCallum Andrew, 2000, P 17 INT C MACH LEAR, P591
   Nguyen AT, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P299, DOI 10.18653/v1/P17-1028
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Platanios EA, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P425
   Rahimi A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P151
   Rei M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2121, DOI 10.18653/v1/P17-1194
   Rodrigues F, 2018, AAAI CONF ARTIF INTE, P1611
   Rodrigues F, 2014, MACH LEARN, V95, P165, DOI 10.1007/s10994-013-5411-2
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Shin Y, 2020, IEEE-ACM T AUDIO SPE, V28, P105, DOI 10.1109/TASLP.2019.2948773
   Wang X, 2019, BIOINFORMATICS, V35, P1745, DOI 10.1093/bioinformatics/bty869
   Yang J, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P74
   Yang Zhilin, 2017, ICLR
   Zeldes A, 2017, LANG RESOUR EVAL, V51, P581, DOI 10.1007/s10579-016-9343-x
   Zhao LJ, 2019, IEEE-ACM T AUDIO SPE, V27, P2326, DOI 10.1109/TASLP.2019.2944563
   Zhou JT, 2020, IEEE T NEUR NET LEAR, V31, P2304, DOI 10.1109/TNNLS.2019.2911236
NR 33
TC 2
Z9 2
U1 4
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2468-6557
EI 2468-2322
J9 CAAI T INTELL TECHNO
JI CAAI T. Intell. Technol.
PD DEC
PY 2022
VL 7
IS 4
BP 710
EP 720
DI 10.1049/cit2.12107
EA JUN 2022
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6L5GI
UT WOS:000806960800001
OA gold
DA 2023-11-10
ER

PT J
AU Doshi, F
   Roy, N
AF Doshi, Finale
   Roy, Nicholas
TI Spoken language interaction with model uncertainty: an adaptive
   human-robot interaction system
SO CONNECTION SCIENCE
LA English
DT Article
DE dialogue management; human-computer interface; adaptive systems; online
   learning; partially observable Markov decision processes
AB Spoken language is one of the most intuitive forms of interaction between humans and agents. Unfortunately, agents that interact with people using natural language often experience communication errors and do not correctly understand the user's intentions. Recent systems have successfully used probabilistic models of speech, language and user behaviour to generate robust dialogue performance in the presence of noisy speech recognition and ambiguous language choices, but decisions made using these probabilistic models are still prone to errors owing to the complexity of acquiring and maintaining a complete model of human language and behaviour. In this paper, a decision-theoretic model for human-robot interaction using natural language is described. The algorithm is based on the Partially Observable Markov Decision Process (POMDP), which allows agents to choose actions that are robust not only to uncertainty from noisy or ambiguous speech recognition but also unknown user models. Like most dialogue systems, a POMDP is defined by a large number of parameters that may be difficult to specify a priori from domain knowledge, and learning these parameters from the user may require an unacceptably long training period. An extension to the POMDP model is described that allows the agent to acquire a linguistic model of the user online, including new vocabulary and word choice preferences. The approach not only avoids a training period of constant questioning as the agent learns, but also allows the agent actively to query for additional information when its uncertainty suggests a high risk of mistakes. The approach is demonstrated both in simulation and on a natural language interaction system for a robotic wheelchair application.
C1 [Doshi, Finale] Univ Cambridge, Cambridge, England.
   [Roy, Nicholas] MIT, Cambridge, MA 02139 USA.
C3 University of Cambridge; Massachusetts Institute of Technology (MIT)
RP Doshi, F (通讯作者)，Univ Cambridge, Cambridge, England.
EM finale@alum.mit.edu
CR [Anonymous], 2000, P 2000 ANLP NAACL WO
   Bellman R., 2010, DYNAMIC PROGRAMMING
   Dearden R, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P150
   Even-Dar E, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P690
   Fern A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1879
   Gordon G., 1995, P 12 INT C MACH LEAR
   JAMES MR, 2004, INT C MACH LEARN APP
   Litman DJ, 2002, USER MODEL USER-ADAP, V12, P111, DOI 10.1023/A:1015036910358
   LITTMAN ML, 1995, P 12 INT C MACH LEAR, P362
   Lopes LS, 2007, INTERACT STUD, V8, P53, DOI 10.1075/is.8.1.05lop
   Lopes LS, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P528, DOI 10.1109/IROS.2000.894658
   NILIM A, 2004, P 16 ADV NEUR INF PR
   Paek T, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P41
   Pineau J., 2001, WORK HIERARCHY MEM R
   Pineau J., 2003, P INT JOINT C ART IN, V18, P1025
   Porta JM, 2006, J MACH LEARN RES, V7, P2329
   POUPART P, 2006, ICML 2006, P697
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Roy N, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P93
   SENEFF S, 2000, ANLP NAACL 2000 WORK, P11
   Williams JD, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P250
   XU H, 2007, ADV NEURAL INFORM PR, V19
NR 23
TC 33
Z9 33
U1 1
U2 14
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0954-0091
EI 1360-0494
J9 CONNECT SCI
JI Connect. Sci.
PY 2008
VL 20
IS 4
BP 299
EP 318
AR PII 905851940
DI 10.1080/09540090802413145
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 376HA
UT WOS:000261173500005
DA 2023-11-10
ER

PT S
AU McCarley, JS
   Roukos, S
AF McCarley, JS
   Roukos, S
BE Farwell, D
   Gerber, L
   Hovy, E
TI Fast document translation for cross-language information retrieval
SO MACHINE TRANSLATION AND THE INFORMATION SOUP
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 3rd Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 28-31, 1998
CL LANGHORNE, PENNSYLVANIA
SP Systran Inc, Logos Corp, Globalink Inc, Univ Penn Inst Res Cognitive Sci
AB We describe a statistical algorithm for machine translation intended to provide translations of large document collections at speeds far in excess of traditional machine translation systems, and of sufficiently high quality to perform information retrieval on the translated document collections. The model is trained from a parallel corpus and is capable of disambiguating senses of words. Information retrieval (IR) experiments on a French language dataset from a recent cross-language information retrieval evaluation yields results superior to those obtained by participants in the evaluation, and confirm the importance of word sense disambiugation in cross-language information retrieval.
C1 IBM Corp, Thomas J Watson Res Ctr, Yorktown Heights, NY 10598 USA.
C3 International Business Machines (IBM)
RP McCarley, JS (通讯作者)，IBM Corp, Thomas J Watson Res Ctr, POB 218, Yorktown Heights, NY 10598 USA.
CR BAHL LR, 1983, IEEE T PATTERN ANAL, V5
   Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHAN E, 5 TEXT RETR C TREC 5
   CHAN EP, 1998, P 4 INT C KNOWL DISC
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   FRANZ M, 6 TEXT RETR C TREC 6
   HARMAN D, 6 TEXT RETR C TREC 6
   Merialdo B, 1990, P IBM NATURAL LANGUA, P161
   OARD DW, 6 TEXT RETR C TREC 6
   Robertson S.E., 1995, OV 3 TEXT RETRIEV C
NR 11
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-65259-0
J9 LECT NOTES ARTIF INT
PY 1998
VL 1529
BP 150
EP 157
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BP93A
UT WOS:000086659400014
DA 2023-11-10
ER

PT J
AU Martins, C
   Teixeira, A
   Neto, J
AF Martins, Ciro
   Teixeira, Antonio
   Neto, Joao
TI Dynamic language modeling for European Portuguese
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Vocabulary selection; Language modeling; Information retrieval
   techniques; Automatic speech recognition (ASR); Broadcast news
   transcription
AB This paper reports on the work done on vocabulary and language model daily adaptation for a European Portuguese broadcast news transcription system. The proposed adaptation framework takes into consideration European Portuguese language characteristics, such as its high level of inflection and complex verbal system.
   A multi-pass speech recognition framework using contemporary written texts available daily on the Web is proposed. It uses morpho-syntactic knowledge (part-of-speech information) about an in-domain training corpus for daily selection of an optimal vocabulary. Using an information retrieval engine and the ASR hypotheses as query material, relevant documents are extracted from a dynamic and large-size dataset to generate a story-based language model. When applied to a daily and live closed-captioning system of live TV broadcasts, it was shown to be effective, with a relative reduction of out-of-vocabulary word rate (69%) and WER (12.0%) when compared to the results obtained by the baseline system with the same vocabulary size. (C) 2010 Elsevier Ltd. All rights reserved.
C1 [Martins, Ciro; Teixeira, Antonio] Univ Aveiro, IEETA, Dept Elect Telecommun & Informat, P-3810193 Aveiro, Portugal.
   [Martins, Ciro; Neto, Joao] INESC ID IST, Spoken Language Syst Lab L2F, Lisbon, Portugal.
C3 Universidade de Aveiro; Universidade de Lisboa; INESC-ID
RP Teixeira, A (通讯作者)，Univ Aveiro, IEETA, Dept Elect Telecommun & Informat, Campus Univ Santiago, P-3810193 Aveiro, Portugal.
EM ajst@ua.pt
RI Teixeira, António J. S./A-4958-2012; Teixeira, Antonio/D-6304-2011;
   Neto, João Paulo P./M-1439-2015; Martins, Ciro/J-2979-2019
OI Teixeira, Antonio/0000-0002-0636-4281; Neto, João Paulo
   P./0000-0002-1207-3536; Martins, Ciro/0000-0003-0970-586X; Teixeira,
   Antonio/0000-0002-7675-1236
FU PRIME National Project TECNOVOZ [03/165]; FCT [POSC/PLP/58697/2004,
   SFRH/BD/23360/2005]; Fundação para a Ciência e a Tecnologia
   [SFRH/BD/23360/2005, POSC/PLP/58697/2004] Funding Source: FCT
FX This work was partially funded by PRIME National Project TECNOVOZ number
   03/165 and by the FCT Project POSC/PLP/58697/2004, Ciro Martins was
   sponsored by an FCT scholarship (SFRH/BD/23360/2005). Special thanks to
   our colleague Hugo Meinedo for his efforts to make available all the
   manual transcriptions for the evaluation datasets we used. We also thank
   the 3 annotators involved in IR evaluation.
CR ALLAUZEN A, 2005, P ICASSP
   ALLAUZEN A, 2005, P INT 2005
   AMARAL R, 2006, 4 JORN TECN HABL, P123
   Bazzi I., 2002, THESIS MIT
   Bellegarda J. R., 2004, SPEECH COMMUNICATION, P42
   BIGI B, 2004, P ICSLP 2004
   Blei A. Y N., 2003, J MACHINE LEARNING R, P993
   BOULIANNE G, 2006, P INT 2006
   CASEIRO DA, 2003, THESIS U TECNICA LIS
   CASEIRO DA, 2002, 2002 IEEE WORKSH SPE
   CHEN L, 2004, P ICSLP 2004
   Federico M, 2004, COMPUT SPEECH LANG, V18, P417, DOI 10.1016/j.csl.2003.10.001
   FEDERICO M, 2000, P LREC ATH GREEC 200
   Gauvain JL, 2002, SPEECH COMMUN, V37, P89, DOI 10.1016/S0167-6393(01)00061-9
   GEUTNER P, 1998, P ICASSP 1998
   HETHERINGTON IL, 1995, THESIS MIT
   HWANG M, 2007, P ASRU 2007
   IYER R, 1997, P EUR 1997
   Kirchhoff K, 2006, COMPUT SPEECH LANG, V20, P589, DOI 10.1016/j.csl.2005.10.001
   LAMEL L, 2004, P ICASSP 2004
   LAVRENKO V, 2001, P SIGIR 01 2001
   LECORVE G, 2009, P INTERSPEECH 2009
   LECORVE G, 2008, P ICASSP 2008
   MARTINS C, 2007, P INT 2007
   MARTINS C, 2008, P PROPOR 2008 CUR PO
   MARTINS C, 2007, P ASRU 2007
   MARTINS C, 2005, REV ELECT TELECOMUNI, V4
   MARTINS C, 2006, P IEEE ACL WORKSH SP
   MARTINS C, 1998, THESIS U TECNICA LIS
   MEINEDO H, 2003, P PROPOR 2003 PORT
   MEINEDO H, 2008, THESIS U TECNICA LIS
   MEINEDO H, 2000, P ICSLP 2000 CHIN
   MEINEDO H, 2005, P INT 2005
   NETO J, 2003, P 3 INT WORKSH CONT
   NETO J, 2008, P ICASSP 2008
   Ney H, 1997, TEXT SPEECH LANG TEC, V2, P174
   OGER S, 2008, P ICASSP 2008
   ORENGO V, 2001, P 8 INT S STRING PRO
   Palmer DD, 2005, COMPUT SPEECH LANG, V19, P107, DOI 10.1016/j.csl.2004.03.002
   RAMABHADRAN B, 2007, P ASRU 2007
   Ribeiro R, 2003, LECT NOTES ARTIF INT, V2721, P143
   RIBEIRO R, 2004, MORPHOSYNTACTIC TAGG
   STOLCKE A, 1998, P DARPA NEWS TRANSCR
   TAM Y, 2006, P INT 2006
   Turtle H., 2005, INDRI LANGUAGE MODEL
   VENKATARAMAN A, 2003, P EUR 2003
   WANG W, 2007, P INT 2007
   WU Y, 2007, P ASRU 2007
   Xu P, 2007, COMPUT SPEECH LANG, V21, P105, DOI 10.1016/j.csl.2006.01.003
NR 49
TC 5
Z9 5
U1 0
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD OCT
PY 2010
VL 24
IS 4
BP 750
EP 773
DI 10.1016/j.csl.2010.02.003
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 598MR
UT WOS:000277841900012
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Plaza-del-Arco, FM
   Molina-González, MD
   Ureña-López, LA
   Martín-Valdivia, MT
AF Miriam Plaza-del-Arco, Flor
   Dolores Molina-Gonzalez, M.
   Alfonso Urena-Lopez, L.
   Teresa Martin-Valdivia, M.
TI Comparing pre-trained language models for Spanish hate speech detection
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Hate speech; Transfer learning; BERT; BETO; Natural language processing;
   Text classification
AB Nowadays, due to the great uncontrolled content posted daily on the Web, there has also been a huge increase in the dissemination of hate speech worldwide. Social media, blogs and community forums are examples where people are freely allowed to communicate. However, freedom of expression is not always respectful since offensive or insulting language is sometimes used. Social media companies often rely on users and content moderators to report on this type of content. Nevertheless, due to the large amount of content generated every day on the Web, automatic systems based on Natural Language Processing techniques are required for identifying abusive language online. To date, most of the systems developed to combat this problem are mainly focused on English content, but this issue is a worldwide concern and therefore other languages such as Spanish are involved. In this paper, we address the task of Spanish hate speech identification on social media and provide a deeper understanding of the capabilities of new techniques based on machine learning. In particular, we compare the performance of Deep Learning methods with recently pre-trained language models based on Transfer Learning as well as with traditional machine learning models. Our main contribution is the achievement of promising results in Spanish by applying multilingual and monolingual pre-trained language models such as BERT, XLM and BETO.
C1 [Miriam Plaza-del-Arco, Flor; Dolores Molina-Gonzalez, M.; Alfonso Urena-Lopez, L.; Teresa Martin-Valdivia, M.] Univ Jaen, Adv Studies Ctr Informat & Commun Technol CEATIC, Dept Comp Sci, Campus Lagunillas, E-23071 Jaen, Spain.
C3 Universidad de Jaen
RP Plaza-del-Arco, FM (通讯作者)，Univ Jaen, Adv Studies Ctr Informat & Commun Technol CEATIC, Dept Comp Sci, Campus Lagunillas, E-23071 Jaen, Spain.
EM fmplaza@ujaen.es; mdmolina@ujaen.es; laurena@ujaen.es; maite@ujaen.es
RI López, Alfonso Ureña/G-9999-2015; Molina-González, María
   Dolores/AAH-2534-2020; Martin-Valdivia, Maria-Teresa/ABF-1709-2021; 于,
   于增臣/AAH-4657-2021
OI López, Alfonso Ureña/0000-0001-7540-4059; Molina-González, María
   Dolores/0000-0002-8348-7154; Martin-Valdivia,
   Maria-Teresa/0000-0002-2874-0401; 
FU European Regional Development Fund (ERDF), LIVING-LANG project
   [RTI2018-094653-B-C21]; Ministry of Science, Innovation and Universities
   from the Spanish Government [FPI-PRE2019-089310]
FX This work has been partially supported by a grant from European Regional
   Development Fund (ERDF), LIVING-LANG project [RTI2018-094653-B-C21], and
   Ministry of Science, Innovation and Universities (scholarship
   [FPI-PRE2019-089310]) from the Spanish Government.
CR [Anonymous], 2013, INT C LEARNING REPRE
   Aragon M. E., 2019, SEPLN WORKSH IB LANG
   Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   Basile V, 2019, P 13 INT WORKSH SEM, P54
   Benballa M., 2019, PROC 13 INT WORKSHOP, P469
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Pereira-Kohatsu JC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214654
   Comandini G, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P163
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Devlin J., 2018, ARXIV, V1, P4171
   Djuric N, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P248, DOI 10.1145/2736277.2741643
   Fan Yuchen, 2014, 15 ANN C INT SPEECH, P1964
   Fersini E., 2018, P 6 EV CAMP NAT LANG, DOI [10.4000/books.aaccademia.4497, DOI 10.4000/BOOKS.AACCADEMIA.4497]
   Fersini Elisabetta, 2018, OVERVIEW TASK AUTOMA
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Florio K., 2019, 2019 8 INT C AFFECTI, P1
   Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676
   Frenda S, 2019, J INTELL FUZZY SYST, V36, P4743, DOI 10.3233/JIFS-179023
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI DOI 10.5555/177910.177914
   Gamback B., 2017, P 1 WORKSHOP ABUSIVE, P85, DOI [10.18653/v1/W17-3013, DOI 10.18653/V1/W17-3013]
   Garreta R., 2013, LEARNING SCIKIT LEAR
   Gertner A., 2019, P 13 INT WORKSHOP SE
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hajung Sohn, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P551, DOI 10.1109/ICDMW.2019.00084
   Hinduja S, 2010, ARCH SUICIDE RES, V14, P206, DOI 10.1080/13811118.2010.494133
   Huang Z., 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Hutto C.J., 2014, ICWSM, DOI DOI 10.1609/ICWSM.V8I1.14550
   Kalampokis E, 2013, INTERNET RES, V23, P544, DOI 10.1108/IntR-06-2012-0114
   Kingma D. P., 2014, C TRACK P
   Korde V., 2012, INT J ARTIF INTELL A, V3, P85, DOI DOI 10.5121/IJAIA.2012.3208
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Kumar R, 2018, P 1 WORKSH TROLL AGG, P1
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, P1621, DOI DOI 10.5555/2891460.2891697
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lingiardi V, 2020, BEHAV INFORM TECHNOL, V39, P711, DOI 10.1080/0144929X.2019.1607903
   Mandl T, 2019, ACM INT CONF PR SER, P14, DOI 10.1145/3368567.3368584
   Paetzold GH, 2019, P 13 INT WORKSHOP SE, P519, DOI DOI 10.18653/V1/S19-2093
   Pamungkas E. W., 2018, CEUR WORKSHOP P, V2263, P1
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Perez J. M., 2019, P 13 INT WORKSH SEM, P64, DOI DOI 10.18653/V1/S19-2008
   Plaza-Del-Arco FM, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3369869
   Ptaszynski M., 2019, P POL EVAL 2019 WORK, P89
   Ribeiro Alison, P 13 INT WORKSH SEM, P420, DOI DOI 10.18653/V1/S19-2074
   Roberts S.T., 2019, P 3 WORKSH AB LANG O
   Ruiz AM, 2005, SENSOR ACTUAT B-CHEM, V108, P34, DOI 10.1016/j.snb.2004.09.045
   Sanguinetti M., 2018, P 11 INT C LANG RES, P1
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shalev-Shwartz S, 2014, UNDERSTANDING MACHIN, DOI DOI 10.1017/CBO9781107298019
   Siegel JM, 2019, P 15 KONVENS, P354
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Torrey L., 2010, HDB RES MACHINE LEAR, P242, DOI DOI 10.4018/978-1-60566-766-9.CH011
   Tulkens S., 2016, DICT BASED APPROACH
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Vasa K., 2016, INT J ENG DEV RES, V4, P655
   Vaswani A., 2017, ARXIV, V30, P5998
   Vega LEA, 2019, P 13 INT WORKSH SEM, P447, DOI DOI 10.18653/V1/S19-2079
   Waseem Z., 2016, WORKSH NLP COMP SOC, P138
   Waseem Z., 2017, ABS170509899
   Winter Kevin, 2019, P 13 INT WORKSHOP SE, P431
   Zampieri M., 2019, P 13 INT WORKSHOP SE, P75, DOI DOI 10.18653/V1/S19-2010
   Zhang H., 2019, P 13 INT WORKSHOP SE, P441, DOI [10.18653/v1/S19-2078, DOI 10.18653/V1/S19-2078]
   Zhang Jingzhao, 2019, ABS191203194 ARXIV
   Zhang Xiang, 2015, NEURIPS, DOI DOI 10.5555/2969239.2969312
NR 66
TC 43
Z9 43
U1 2
U2 43
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 15
PY 2021
VL 166
AR 114120
DI 10.1016/j.eswa.2020.114120
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA PE7DI
UT WOS:000598522500001
DA 2023-11-10
ER

PT J
AU Zhang, WZ
   Yang, HW
AF Zhang, Weizhao
   Yang, Hongwu
TI Improving Sequence-to-sequence Tibetan Speech Synthesis with Prosodic
   Information
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Sequence-to-sequence speech synthesis; Tibetan speech synthesis;
   prosodic information fusion; low-resource language
ID ADAPTATION; SPEAKER
AB There are about 6,000 languages worldwide, most of which are low-resource languages. Although the current speech synthesis (or text-to-speech, TTS) for major languages (e.g., Mandarin, English, French) has achieved good results, the voice quality of TTS for low-resource languages (e.g., Tibetan) still needs to be further improved. Because prosody plays a significant role in natural speech, the article proposes two sequence-tosequence (seq2seq) Tibetan TTS models with prosodic information fusion to improve the voice quality of synthesized Tibetan speech. We first constructed a large-scale Tibetan corpus for seq2seq TTS. Then we designed a prosody generator to extract prosodic information from the Tibetan sentences. Finally, we trained two seq2seq Tibetan TTS models by fusing prosodic information, including feature-level and model-level prosodic information fusion. The experimental results showed that the proposed two seq2seq Tibetan TTS models, which fuse prosodic information, could effectively improve the voice quality of synthesized speech. Furthermore, the model-level prosodic information fusion only needs 60% similar to 70% of the training data to synthesize a voice similar to the baseline seq2seq Tibetan TTS. Therefore, the proposed prosodic information fusion methods can improve the voice quality of synthesized speech for low-resource languages.
C1 [Zhang, Weizhao] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Yang, Hongwu] Northwest Normal Univ, Sch Educ Technol, Lanzhou, Peoples R China.
C3 Northwest Normal University - China; Northwest Normal University - China
RP Yang, HW (通讯作者)，Northwest Normal Univ, Sch Educ Technol, Lanzhou, Peoples R China.
EM zhangweizhao@nwnu.edu.cn; yanghw@nwnu.edu.cn
OI Yang, Hongwu/0000-0002-8939-3386
FU National Natural Science Foundation of China [62067008, 11664036,
   62267008]; Science and Technology Program of Gansu Province
   [20JR10RA095, 21JR7RA117]; University Innovation Foundation of Gansu
   Province [2022B-091, 2023B-239]
FX The research is supported by the research fund fromthe National Natural
   Science Foundation of China (Grant No. 62067008, No. 11664036, No.
   62267008). Additionally, part of this work is also supported by the
   Science and Technology Program of Gansu Province (Grant No. 20JR10RA095,
   No. 21JR7RA117) and the University Innovation Foundation of Gansu
   Province (Grant No. 2022B-091, No. 2023B-239).
CR Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   [才让卓玛 Cai Rangzhuoma], 2017, [中文信息学报, Journal of Chinese Information Processing], V31, P59
   Chorowski J, 2015, ADV NEUR IN, V28
   Chorowski Jan, 2014, P NIPS 2014 WORKSH D
   [都格草 Dou Gecao], 2019, [中文信息学报, Journal of Chinese Information Processing], V33, P75
   Fan Yuchen, 2014, 15 ANN C INT SPEECH, P1964
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Hayashi T, 2019, INTERSPEECH, P4430, DOI 10.21437/Interspeech.2019-3177
   Hunt AJ, 1996, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.1996.541110
   Kang SY, 2013, INT CONF ACOUST SPEE, P8012, DOI 10.1109/ICASSP.2013.6639225
   Lee Y, 2019, INT CONF ACOUST SPEE, P5911, DOI 10.1109/ICASSP.2019.8683501
   Li JB, 2019, INTERSPEECH, P4494, DOI 10.21437/Interspeech.2019-1118
   Ling ZH, 2015, IEEE SIGNAL PROC MAG, V32, P35, DOI 10.1109/MSP.2014.2359987
   Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291
   Lu YF, 2019, INT CONF ACOUST SPEE, P7050, DOI 10.1109/ICASSP.2019.8682368
   Luong T., 2015, P C EMPIRICAL METHOD, P1412, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mohammadi A, 2014, IEEE-ACM T AUDIO SPE, V22, P2146, DOI 10.1109/TASLP.2014.2362009
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Skerry-Ryan R. J., 2018, P 35 INT C MACHINE L, P4700
   Song E, 2017, IEEE-ACM T AUDIO SPE, V25, P2152, DOI 10.1109/TASLP.2017.2746264
   Sotelo Jose, 2017, P 5 INT C LEARN REPR
   Sun GZ, 2020, INT CONF ACOUST SPEE, P6264, DOI [10.1109/icassp40776.2020.9053520, 10.1109/ICASSP40776.2020.9053520]
   Tachibana M, 2008, INT CONF ACOUST SPEE, P4633
   Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852
   Valle R, 2020, INT CONF ACOUST SPEE, P6189, DOI [10.1109/icassp40776.2020.9054556, 10.1109/ICASSP40776.2020.9054556]
   van den Oord Aaron, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1609.03499
   Wang WF, 2016, INTERSPEECH, P2243, DOI 10.21437/Interspeech.2016-134
   Wang Y., 2018, P INT C MACH LEARN, P5167
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Wu ZQ, 2013, 2013 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P92, DOI 10.1109/ICCSNT.2013.6967070
   Xiao YJ, 2020, INT CONF ACOUST SPEE, P6704, DOI [10.1109/ICASSP40776.2020.9054337, 10.1109/icassp40776.2020.9054337]
   Yang HW, 2015, MULTIMED TOOLS APPL, V74, P9927, DOI 10.1007/s11042-014-2117-9
   Yoshimura T., 2000, Journal of the Acoustical Society of Japan (E), V21, P199, DOI 10.1250/ast.21.199
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zhang WZ, 2019, IEEE ACCESS, V7, P167884, DOI 10.1109/ACCESS.2019.2954342
   Zhang YJ, 2019, INT CONF ACOUST SPEE, P6945, DOI 10.1109/ICASSP.2019.8683623
NR 36
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP
PY 2023
VL 22
IS 9
AR 225
DI 10.1145/3616012
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T7EN7
UT WOS:001079577300005
DA 2023-11-10
ER

PT J
AU Pandey, AK
   Roy, SS
AF Pandey, Abhishek Kumar
   Roy, Sanjiban Sekhar
TI Natural Language Generation Using Sequential Models: A Survey
SO NEURAL PROCESSING LETTERS
LA English
DT Article; Early Access
DE Natural language processing; Long term short-term memory; Natural
   language generation; Recurrent neural network; Sequential generative
   model; Story generation
ID TEXT GENERATION
AB Natural Language Generation (NLG) is one of the most critical yet challenging tasks in all Natural Language Processing applications. It is a process to automate text generation so that humans can understand its meaning. A handful of research articles published in the literature have described how NLG can produce understandable texts in various languages. The use of sequence-to-sequence modeling powered by deep learning techniques such as Long Term Short Term Memory, Recurrent Neural Networks, and Gated Recurrent Units has received much popularity as text generators. This survey provides a comprehensive overview of text generations and their related techniques, such as statistical, traditional, and neural network-based techniques. Generating text using the sequence-to-sequence model is not a simple task as it needs to handle continuous data, such as images, and discrete information, such as text. Therefore, in this study, we have identified some crucial areas for further research on text generation, such as incorporating a large text dataset, identifying and resolving grammatical errors, and generating extensive sentences or paragraphs. This work has also presented a detailed overview of the activation functions used in deep learning-based models and the evaluation metrics used for text generation.
C1 [Pandey, Abhishek Kumar; Roy, Sanjiban Sekhar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Roy, SS (通讯作者)，Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Vellore, India.
EM abhishek.pandey2020@vitstudent.ac.in; s.roy@vit.ac.in
RI Pandey, Abhishek/AEA-4975-2022; Roy, Sanjiban Sekhar/T-4266-2019
OI Pandey, Abhishek/0000-0003-3428-2125; Roy, Sanjiban
   Sekhar/0000-0003-2003-7882
CR Angeli G., 2010, P 2010 C EMPIRICAL M, P502
   [Anonymous], 1981, HANSEL AND GRETEL
   Ayana, 2020, IEEE-ACM T AUDIO SPE, V28, P2572, DOI 10.1109/TASLP.2020.3009487
   Ayana, 2018, IEEE-ACM T AUDIO SPE, V26, P2319, DOI 10.1109/TASLP.2018.2842432
   Bao JW, 2019, IEEE-ACM T AUDIO SPE, V27, P311, DOI 10.1109/TASLP.2018.2878381
   Biswas R, 2020, IJST-T ELECTR ENG, V44, P505, DOI 10.1007/s40998-019-00213-7
   Bouchard G., 2007, NIPS 2007 WORKSH APP
   Bourane S, 2015, SCIENCE, V350, P550, DOI 10.1126/science.aac8653
   Cao J, 2020, IEEE ACCESS, V8, P46206, DOI 10.1109/ACCESS.2020.2979115
   Chakraborty S, 2020, 2020 INT C COMPUTER, DOI [10.1109/ICCSEA49143.2020.9132839, DOI 10.1109/ICCSEA49143.2020.9132839]
   Colby KM, 1976, ARTIFICIAL PARANOIA, V7
   Dethlefs N, 2021, NEUROCOMPUTING, V433, P300, DOI 10.1016/j.neucom.2020.12.083
   Dharma E. M., 2022, J THEOR APPL INF TEC, V100, P349
   Elahi GMME, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108273
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gaur M, 2022, ANAL NATURAL LANGUAG, P233
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoogi A, 2020, MAMMOGRAPHY REPORTS, V24, P2711
   Hossain S.A., 2019, 2019 10 INT C COMPUT, P1, DOI DOI 10.1109/ICCCNT45670.2019.8944784
   Iglesias P, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12030473
   Islam Md Sanzidul, 2019, Procedia Computer Science, V152, P51, DOI 10.1016/j.procs.2019.05.026
   Jagfeld Glorianna, 2018, INLG 2018 11 INT NAT, P221, DOI DOI 10.18653/V1/W18-6529
   Jin D, 2022, COMPUT LINGUIST, V48, P155, DOI 10.1162/coli_a_00426
   Kannan Shradha, 2022, Emerging Research in Computing, Information, Communication and Applications: ERCICA 2020. Lecture Notes in Electrical Engineering (790), P237, DOI 10.1007/978-981-16-1342-5_19
   Kim Y, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3418052
   Kunhi LM, 2022, INVENT COMMUN COMPUT, P63
   Langkilde I, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA170
   Li Jiwei, 2016, EMNLP
   Li MY, 2022, INFORM SOFTWARE TECH, V143, DOI 10.1016/j.infsof.2021.106770
   Li Z, 2022, 2021 INT C BIG DAT A, P367
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Lin C-Y, 2004, NTCIR WORK, P1
   Lin JY, 2022, EDUC TECHNOL SOC, V25, P205
   Liu TY, 2018, AAAI CONF ARTIF INTE, P4881
   Liu YX, 2022, INFORM SYST, V103, DOI 10.1016/j.is.2021.101865
   Mann W. C., 1987, Natural Language Generation: New Results in Artificial Intelligence, Psychology and Linguistics. Proceedings of the NATO Advanced Research Workshop, P85
   McShane M, 2022, ADV COGN SYST, P1
   Meister C, 2022, Arxiv, DOI arXiv:2202.00666
   Minzheong Song, 2021, The International Journal of Advanced Smart Convergence, V10, P72, DOI 10.7236/IJASC.2021.10.4.72
   Nandanwar AK, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13101772
   PALOMBELLA VJ, 1994, CELL, V78, P773, DOI 10.1016/S0092-8674(94)90482-0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pawade Dipti, 2018, International Journal of Information Technology and Computer Science, V10, P44, DOI 10.5815/ijitcs.2018.06.05
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Qader R, 2018, P 11 INT C NATURAL L, P254, DOI [DOI 10.18653/V1/W18-6532, 10.18653/v1/W18-6532]
   Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502
   Ren YP, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107093
   Roy S, 2018, PREDICTION CUSTOMER
   Roy SS, 2016, INT J ENG RES AFR, V22, P152, DOI 10.4028/www.scientific.net/JERA.22.152
   Roy SS., 2016, INT J COMPUT SYST EN, V2, P139, DOI [10.1504/IJCSYSE.2016.079000, DOI 10.1504/IJCSYSE.2016.079000]
   Ruder S., 2019, THESIS NATL U IRELAN
   Santhanam S, 2020, Arxiv, DOI arXiv:2005.00048
   Schmitt M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7117
   Sha L, 2018, AAAI CONF ARTIF INTE, P5414
   Shi J, 2022, CAN IDENTIFIER SPLIT
   Singh C, 2017, ALICE WONDERLAND GUT
   Sun YQ, 2022, INT J INTELL SYST, V37, P2969, DOI 10.1002/int.22821
   Wang HC, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106767
   Wang MQ, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P223, DOI 10.1109/APCCAS.2018.8605654
   Wei MX, 2019, IEEE ACCESS, V7, P61008, DOI 10.1109/ACCESS.2019.2904337
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Xiang LY, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091558
   Yadav Arun Kumar, 2022, International Journal of Information Technology, P2407, DOI 10.1007/s41870-022-00863-7
   Yadav D, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3411881
   Yao T, 2021, LECT NOTES COMPUT SC, V13003, P173, DOI 10.1007/978-3-030-88210-5_16
   Yermakov R, 2021, BIOMEDICAL DATA TO T, P364
   Yin XY, 2003, ANN BOT-LONDON, V91, P361, DOI 10.1093/aob/mcg029
   Zhang X, 2014, P 2014 C EMP METH NA, P670, DOI DOI 10.3115/V1/D14-1074
   Zhao MY, 2021, LECT NOTES COMPUT SC, V12966, P437, DOI 10.1007/978-3-030-87589-3_45
   Zheng QH, 2018, IEEE ACCESS, V6, P15844, DOI 10.1109/ACCESS.2018.2810849
   Zhu J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5459
NR 73
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11063-023-11281-6
EA MAY 2023
PG 34
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G0RQ9
UT WOS:000986336700002
DA 2023-11-10
ER

PT J
AU Murawaki, Y
AF Murawaki, Yugo
TI Bayesian Learning of Latent Representations of Language Structures
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We borrow the concept of representation learning from deep learning research, and we argue that the quest for Greenbergian implicational universals can be reformulated as the learning of good latent representations of languages, or sequences of surface typological features. By projecting languages into latent representations and performing inference in the latent space, we can handle complex dependencies among features in an implicit manner. The most challenging problem in turning the idea into a concrete computational model is the alarmingly large number of missing values in existing typological databases. To address this problem, we keep the number of model parameters relatively small to avoid overfitting, adopt the Bayesian learning framework for its robustness, and exploit phylogenetically and/or spatially related languages as additional clues. Experiments show that the proposed model recovers missing values more accurately than others and that some latent variables exhibit phylogenetic and spatial signals comparable to those of surface features.
C1 [Murawaki, Yugo] Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
C3 Kyoto University
RP Murawaki, Y (通讯作者)，Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
EM murawaki@i.kyoto-u.ac.jp
FU JSPS KAKENHI [18K18104]; Grants-in-Aid for Scientific Research
   [18K18104] Funding Source: KAKEN
FX The key ideas and early experimental results were presented at the
   Eighth International Joint Conference on Natural Language Processing
   (Murawaki 2017). This article, which presents updated results, is a
   substantially extended version of the earlier conference paper. This
   work was partly supported by JSPS KAKENHI grant 18K18104.
CR Anderson SR, 2016, ANNU REV LINGUIST, V2, P11, DOI 10.1146/annurev-linguistics-011415-040735
   [Anonymous], 2014, LINGUIST VAR, DOI DOI 10.1093/ACPROF:OSO/9780198702894.003.0008
   [Anonymous], 2007, P 45 ANN M ASS COMP
   [Anonymous], 2006, P 23 INT C MACHINE L
   [Anonymous], 2001, ATOMS LANGUAGE MINDS
   [Anonymous], 2008, OPTIMALITY THEORY CO
   [Anonymous], 2012, P 50 ANN M ASS COMPU
   [Anonymous], 2009, P HUMAN LANGUAGE TEC
   [Anonymous], 2006, P 22 C UNC ART INT U
   [Anonymous], 2003, LINGUISTIC TYPOLOGY, DOI DOI 10.1515/LITY.2003.013
   Asgari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141287
   Bender EM, 2016, LINGUIST TYPOL, V20, P645, DOI 10.1515/lingty-2016-0035
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Bickel Balthasar, 2017, AUTOTYP TYPOLOGICAL
   Blasi DE, 2017, NAT HUM BEHAV, V1, P723, DOI 10.1038/s41562-017-0192-4
   Bouckaert R, 2012, SCIENCE, V337, P957, DOI 10.1126/science.1219669
   Campbell L, 2006, ENCY LANGUAGE LINGUI, P454
   Chang W, 2015, LANGUAGE, V91, P194, DOI 10.1353/lan.2015.0005
   Chen X, 2016, ADV NEUR IN, V29
   Chomsky Noam., 1993, SYNTAX INT HDB CONT, P506
   Croft William, 2002, TYPOLOGY UNIVERSALS
   Daume III Hal, 2007, P 45 ANN M ASS COMPU, P65
   Dediu D, 2011, P ROY SOC B-BIOL SCI, V278, P474, DOI 10.1098/rspb.2010.1595
   Doyle G, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1094
   Dryer Matthew S., 1998, CHICAGO LINGUISTIC S, V33, P123
   Dryer MatthewS., 2011, LINGUIST TYPOL, V15, P335, DOI [10.1515/lity.2011.024, DOI 10.1515/LITY.2011.024]
   DRYER MS, 1989, STUD LANG, V13, P257, DOI 10.1075/sl.13.2.03dry
   Dunn M, 2011, NATURE, V473, P79, DOI 10.1038/nature09923
   Enfield NJ, 2005, ANNU REV ANTHROPOL, V34, P181, DOI 10.1146/annurev.anthro.34.081804.120406
   Gan Z, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P321, DOI 10.18653/v1/P17-1030
   Goldwater S, 2009, COGNITION, V112, P21, DOI 10.1016/j.cognition.2009.03.008
   Gray RD, 2003, NATURE, V426, P435, DOI 10.1038/nature02029
   Greenberg Joseph H., 1963, UNIVERSALS LANG, P73
   Greenberg JosephH., 1978, UNIVERSALS HUMAN LAN, V1, P61
   Greenhill SJ, 2010, P ROY SOC B-BIOL SCI, V277, P2443, DOI 10.1098/rspb.2010.0051
   Greenhill SJ, 2017, P NATL ACAD SCI USA, V114, pE8822, DOI 10.1073/pnas.1700388114
   Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211
   Griffiths TL, 2011, J MACH LEARN RES, V12, P1185
   Haspelmath M., 2008, LIMITS SYNTACTIC VAR, P75, DOI DOI 10.1075/LA.132.04HAS
   Haspelmath Martin., 2005, WORLD ATLAS LANGUAGE
   Heine B., 2007, GENESIS GRAMMAR
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Itoh Y, 2004, PHYSICA D, V198, P333, DOI 10.1016/j.physd.2004.09.006
   Jasra A, 2005, STAT SCI, V20, P50, DOI 10.1214/088342305000000016
   Josse J, 2012, J CLASSIF, V29, P91, DOI 10.1007/s00357-012-9097-0
   Knowles D, 2007, LECT NOTES COMPUT SC, V4666, P381
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang FM, 2010, J STAT COMPUT SIM, V80, P1007, DOI 10.1080/00949650902882162
   Maurits L, 2014, P NATL ACAD SCI USA, V111, P13576, DOI 10.1073/pnas.1319042111
   Meeds E., 2007, ADV NEURAL INFORM PR, P977
   Moller J, 2006, BIOMETRIKA, V93, P451, DOI 10.1093/biomet/93.2.451
   MULLAHY J, 1986, J ECONOMETRICS, V33, P341, DOI 10.1016/0304-4076(86)90002-3
   MURAWAKI Y, 2017, P 8 INT JOINT C NAT, V1, P451
   Murawaki Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4371
   Murawaki Y, 2018, J LANG EVOL, V3, P13, DOI 10.1093/jole/lzx022
   Murawaki Yugo, 2016, P 2016 C N AM CHAPT, P1329
   Murawaki Yugo., 2015, P 2015 C N AM CHAPT, P324
   Neal RM, 2011, CH CRC HANDB MOD STA, P113
   Nelson-Sathi S, 2011, P ROY SOC B-BIOL SCI, V278, P1794, DOI 10.1098/rspb.2010.1917
   Nichols J, 1995, AMST STUD THEORY HIS, V124, P337
   Nichols J., 1992, LINGUISTIC DIVERSITY, DOI DOI 10.7208/CHICAGO/9780226580593.001.0001
   OHoran H., 2016, P COLING 2016 26 INT, P1297
   Pagel M, 2006, AM NAT, V167, P808, DOI 10.1086/503444
   Parkvall M, 2008, STUF-LANG TYPOL UNIV, V61, P234
   Pereltsvaig Asya, 2015, INDOEUROPEAN CONTROV
   Si YJ, 2013, J EDUC BEHAV STAT, V38, P499, DOI 10.3102/1076998613480394
   Srebro Nathan, 2004, P 17 INT C NEURAL IN, V17, P1329
   Tan J, 2016, MSYSTEMS, V1, DOI 10.1128/mSystems.00025-15
   Towner MC, 2012, HUM NATURE-INT BIOS, V23, P283, DOI 10.1007/s12110-012-9142-z
   TRuBETzkoy N. S., 1928, ACTES 1ER CONGRES IN, P17
   TSUNODA T, 1995, LINGUISTICS, V33, P741, DOI 10.1515/ling.1995.33.4.741
   Welling Max, 2011, P 28 INT C MACH LEAR, P681, DOI DOI 10.5555/3104482.3104568
   Wichmann Soren, 2009, TEMPORAL STABILITY L
   [No title captured]
NR 77
TC 2
Z9 2
U1 1
U2 7
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 2019
VL 45
IS 2
BP 199
EP 228
DI 10.1162/coli_a_00346
PG 30
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA ID5FZ
UT WOS:000471703200001
OA gold
DA 2023-11-10
ER

PT J
AU Jebali, M
   Dakhli, A
   Bakari, W
AF Jebali, Maher
   Dakhli, Abdesselem
   Bakari, Wided
TI Deep Learning-Based Sign Language Recognition System for Cognitive
   Development
SO COGNITIVE COMPUTATION
LA English
DT Article; Early Access
DE Sign language recognition; Deep-learning; Recurrent neural network; Head
   pose
AB Information in sign language (SL) is transmitted in large part by the movement, positioning, and shape of the hands as well as body language and facial emotions. Systems that recognize sign language can help with the problem that sign language is not widely used despite the large number of individuals who need to use it, and they can give hearing-impaired and deaf people a more practical way of life, employment, and education. Despite the fact that facial features are treated to be fundamental for humans to comprehend sign language, few earlier research work have inspected their cognitive importance for automatic SL recognition systems. To address this problem, this paper comes up with a novel manual and non-manual gesture recognition framework (MNM-VGG16) for the deaf and mute people. The framework employs a convolutional neural network, renowned as VGG-16 net, for implementing a trained model on an amply used video dataset by employing a component that learns the Multimodal Spatial Representation (MSR) of various modalities. The Multimodal Temporal Representation (MTR) component shapes temporal corrections from independent and dependent pathways to analyze the cooperation of different modalities. A cooperative optimization scheme, summarized by the employment of multi-scale perception component, is applied to make the finest of various modalities sources for sign language recognition. To validate the efficiency of MNM-VGG16, we carried out experiments on three large-scale sign language benchmarks: CSL Split II, SIGNUM, and RWTH-PHOENIX-Weather 2014. Experimental results prove that the suggested framework reaches new state-of-the-art achievement on all three benchmarks, and this attainment is noted by the reduction of the word error rate (WER) on test set by 14.2%, 13.7%, and 11.2%, respectively. In this paper, we offer the MNM-VGG16 hybrid method, which recognizes SL words by combining manual and non-manual features. This method demonstrates the significance of jointly modeling various body parts for SL recognition.
C1 [Jebali, Maher] Univ Tunis, LaTICE, 5,Ave Taha Hussein,Bab Menara, Tunis 1008, Tunisia.
   [Dakhli, Abdesselem] Univ Sfax, REGIM, Km 4 Route Soukra, Sfax 3038, Tunisia.
   [Bakari, Wided] Univ Sfax, MIR CL, Km 10 Route Tunis, Sfax 3021, Tunisia.
C3 Universite de Tunis; Universite de Sfax; Ecole Nationale dIngenieurs de
   Sfax (ENIS); Universite de Sfax
RP Jebali, M (通讯作者)，Univ Tunis, LaTICE, 5,Ave Taha Hussein,Bab Menara, Tunis 1008, Tunisia.
EM maher.jbeli@gmail.com; abdesselemdakhli@gmail.com;
   wided.bakari@gmail.com
OI JEBALI, Maher/0000-0002-1312-5537
CR Adaloglou N, 2022, IEEE T MULTIMEDIA, V24, P1750, DOI 10.1109/TMM.2021.3070438
   [Anonymous], 2016, P BRIT MACHINE VISIO
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Chou FH, 2012, IEEE ASME INT C ADV, P885, DOI 10.1109/AIM.2012.6266025
   Choudhury A, 2017, J INTELL SYST, V26, P471, DOI 10.1515/jisys-2016-0009
   Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175
   ElBadawy Menna, 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P66, DOI 10.1109/INTELCIS.2017.8260028
   Forster J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1911
   Gondu A, 2017, IEEE ANN IND C INDIC, P1, DOI [10.1109/INDICON.2016.7839069, DOI 10.1109/INDICON.2016.7839069]
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P751
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P744
   Guo D, 2020, IEEE T IMAGE PROCESS, V29, P1575, DOI 10.1109/TIP.2019.2941267
   Huang J., ARXIV
   Imran J, 2020, VISUAL COMPUT, V36, P1233, DOI 10.1007/s00371-019-01725-3
   Jo J, 2019, INTELL AUTOM SOFT CO, V25, P351, DOI 10.31209/2019.100000096
   Ka Leong Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P697, DOI 10.1007/978-3-030-58586-0_41
   Khan NS, 2020, COGN COMPUT, V12, P748, DOI 10.1007/s12559-020-09731-7
   Koller O, 2016, 10 ED LANG RES EV C
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Koller O, 2017, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2017.364
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254
   Li R, 2022, ARXIV
   Liwicki M, 2009, PATTERN RECOGN, V42, P3254, DOI 10.1016/j.patcog.2008.10.030
   Mercanoglu Sincan O, 2019, SIG PROCESS COMMUN, DOI 10.1109/siu.2019.8806467
   Moghaddam M, 2011, 7 IRANIAN C MACHINE, DOI [10.1109/IranianMVIP.2011.6121539, DOI 10.1109/IRANIANMVIP.2011.6121539]
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Özdemir O, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1961, DOI 10.1109/SIU.2016.7496151
   Papastratis I, 2020, IEEE ACCESS, V8, P91170, DOI 10.1109/ACCESS.2020.2993650
   Parelli M, 2022, INT CONF ACOUST SPEE, P8457, DOI 10.1109/ICASSP43922.2022.9746971
   Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7
   Pu JF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P885
   Pu JF, 2019, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2019.00429
   Puri A. V., 2012, 2012 Canadian Conference on Computer and Robot Vision, P125, DOI 10.1109/CRV.2012.24
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Sharma S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03418-z
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suri K, 2019, COMPUT ELECTR ENG, V78, P493, DOI 10.1016/j.compeleceng.2019.08.006
   Tamer NC, 2020, INT CONF ACOUST SPEE, P8184, DOI [10.1109/icassp40776.2020.9054678, 10.1109/ICASSP40776.2020.9054678]
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1483, DOI 10.1145/3240508.3240671
   Wang ZR, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107102
   Yang Z., ARXIV
   Ye LT, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101577
   Yin F, 2016, LECT NOTES COMPUT SC, V9911, P434, DOI 10.1007/978-3-319-46478-7_27
   Zhou MJ, 2020, FRONT ARTIF INTEL AP, V325, P2832, DOI 10.3233/FAIA200425
NR 48
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD 2023 AUG 16
PY 2023
DI 10.1007/s12559-023-10182-z
EA AUG 2023
PG 13
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA P5FV1
UT WOS:001050940600001
DA 2023-11-10
ER

PT J
AU Loureiro, D
   Camacho-Collados, J
   Jorge, AM
AF Loureiro, Daniel
   Camacho-Collados, Jose
   Jorge, Alipio Mario
TI LMMS reloaded: Transformer-based sense embeddings for disambiguation and
   beyond
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Semantic representations; Neural language models
ID REPRESENTATION; LANGUAGE; MODEL; WORD
AB Distributional semantics based on neural approaches is a cornerstone of Natural Language Processing, with surprising connections to human meaning representation as well. Recent Transformer-based Language Models have proven capable of producing contextual word representations that reliably convey sense-specific information, simply as a product of self supervision. Prior work has shown that these contextual representations can be used to accurately represent large sense inventories as sense embeddings, to the extent that a distance-based solution to Word Sense Disambiguation (WSD) tasks outperforms models trained specifically for the task. Still, there remains much to understand on how to use these Neural Language Models (NLMs) to produce sense embeddings that can better harness each NLM's meaning representation abilities. In this work we introduce a more principled approach to leverage information from all layers of NLMs, informed by a probing analysis on 14 NLM variants. We also emphasize the versatility of these sense embeddings in contrast to task-specific models, applying them on several sense-related tasks, besides WSD, while demonstrating improved performance using our proposed approach over prior work focused on sense embeddings. Finally, we discuss unexpected findings regarding layer and model performance variations, and potential applications for downstream tasks.& nbsp;(c) 2022 Elsevier B.V. All rights reserved.
C1 [Loureiro, Daniel; Jorge, Alipio Mario] Univ Porto, FCUP, Dept Comp Sci, LIAAD INESC TEC, Porto, Portugal.
   [Camacho-Collados, Jose] Cardiff Univ, Sch Comp Sci & Informat, Cardiff, Wales.
C3 Universidade do Porto; INESC TEC; Cardiff University
RP Loureiro, D (通讯作者)，Univ Porto, FCUP, Dept Comp Sci, LIAAD INESC TEC, Porto, Portugal.
EM daniel.b.loureiro@inesctec.pt; camachocolladosj@cardiff.ac.uk;
   amjorge@fc.up.pt
RI Jorge, Alípio/A-1721-2008
OI Jorge, Alípio/0000-0002-5475-1382; Loureiro, Daniel/0000-0001-5134-360X
FU EU; Fundacao para a Ciencia e Tecnologia [DFA/BD/9028/2020]; UKRI Future
   Leaders Fellowship [MR/T042001/1]
FX We thank the reviewers for their thoughtful comments and suggestions.
   Daniel Loureiro is supported by the EU and Fundacao para a Ciencia e
   Tecnologia through contract DFA/BD/9028/2020 (Programa Operacional
   Regional Norte). Jose Camacho-Collados is supported by a UKRI Future
   Leaders Fellowship (MR/T042001/1).
CR Ammanabrolu P, 2020, AAAI CONF ARTIF INTE, V34, P7375
   [Anonymous], 2006, THESIS U PENNSYLVANI
   [Anonymous], 1998, ENCY APPL LING, DOI DOI 10.7551/MITPRESS/7287.001.0001
   [Anonymous], 2017, SEMEVAL ACL, DOI DOI 10.18653/V1/S17-2002
   [Anonymous], 2001, P 23 ANN C COGNITIVE
   Armendariz C.S., 2020, P 14 WORKSH SEM EV, P36, DOI DOI 10.18653/V1/2020.SEMEVAL-1.3
   Armendariz CS, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5870
   Athiwaratkun B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1
   Barba E, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1492
   Bender E. M., 2020, C SESSION P 58 ANN M
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bevilacqua M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2854
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blevins T, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1006
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Cai ZGG, 2017, COGNITIVE PSYCHOL, V98, P73, DOI 10.1016/j.cogpsych.2017.08.003
   Camacho J., 2015, P C N AM CHAPT ASS C, P567
   Camacho-Collados J, 2018, J ARTIF INTELL RES, V63, P743, DOI 10.1613/jair.1.11259
   Camacho-Collados J, 2016, ARTIF INTELL, V240, P36, DOI 10.1016/j.artint.2016.07.005
   Chronis G., 2020, P CONLL, DOI DOI 10.18653/V1/2020.CONLL-1.17
   Colla D, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106346
   Colla D, 2020, DATA BRIEF, V32, DOI 10.1016/j.dib.2020.106267
   Colla D, 2020, COMPUT LINGUIST, V46, P289, DOI [10.1162/coli_a_0037, 10.1162/coli_a_00375]
   Collobert R., 2007, P 45 ANN M ASS COMPU, P560
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J., 2018, ARXIV, V1, P4171
   Dodge Jesse, 2020, ARXIV200206305
   Dong, 2006, HOWNET COMPUTATION M
   Erk K, 2016, SEMANT PRAGMAT, V9, DOI 10.3765/sp.9.17
   Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55
   Firth J. R., 1935, T PHILOL SOC, V34, P36, DOI https://doi.org/10.1111/j.1467-968X.1935.tb01254.x
   Flekova L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2029
   Goldberg Y., 2017, SYNTHESIS LECT HUMAN, V10, P1
   Guo CA, 2017, PR MACH LEARN RES, V70
   Hamilton WL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1489
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Huang EH, 2012, ACL, V1, P873
   Huang LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3509
   Iacobacci I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P95
   Ide N., 2010, P ACL 2010 C SHORT P, P68
   Kapanipathi P, 2020, AAAI CONF ARTIF INTE, V34, P8074
   Klein DE, 2001, J MEM LANG, V45, P259, DOI 10.1006/jmla.2001.2779
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Kuznetsov I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P171
   Lan Zhenzhong, 2019, ARXIV190911942
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Levine Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4656
   Lewis M., 2020, P 58 ANN M ASS COMP
   Li J., 2015, P 2015 C EMP METH NA, P1722, DOI [10.18653/v1/D15-1200, DOI 10.18653/V1/D15-1200]
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2829
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Loureiro D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3514
   Loureiro D, 2021, COMPUT LINGUIST, V47, P387, DOI [10.1162/coli_a_00405, 10.1162/COLI_a_00405]
   Loureiro D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5682
   Loureiro Daniel, 2019, P 5 WORKSH SEM DEEP, P1
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Mancini M., 2017, P 21 C COMPUTATIONAL, P100, DOI [DOI 10.18653/V1/K17-1012, 10.18653/v1/K17-1012]
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, P51, DOI DOI 10.18653/V1/K16-1006
   Merrill W, 2021, ARXIV210410809
   Meyer Christian M, 2012, WIKTIONARY NEW RIVAL, P2
   Mickus Timothee., 2020, P SOC COMPUTATION LI, P279
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Miller George A., 1994, HUMAN LANGUAGE TECHN
   Navigli R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P216
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, P1059, DOI [DOI 10.3115/V1/D14-1113, 10.3115/v1/d14-1113]
   Osgood Charles Egerton, 1957, MEASUREMENT MEANING
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48
   Pasini T, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4936
   Pelevina M, 2016, P OF THE 1 WORKSHOP, P174, DOI 10.18653/v1/W16-1620
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pereira F, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03068-4
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P43
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Piantadosi ST, 2012, COGNITION, V122, P280, DOI 10.1016/j.cognition.2011.10.004
   Pilehvar M T, 2016, P 2016 C EMPIRICAL M, P1680, DOI [DOI 10.18653/V1/D16-1174, 10.18653/v1/D16-1174]
   Pilehvar MT, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1267
   Pilehvar MT, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1857, DOI 10.18653/v1/P17-1170
   Radach R., 2017, J EYE MOVEMENT RES, V10, DOI [DOI 10.16910/JEMR.10.6.1, 10.16910/jemr.10.6.1]
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99
   Reif E., 2019, NEURIPS
   Reisinger J, 2010, HUMAN LANGUAGE TECHN, P109
   Rodd JM, 2020, PERSPECT PSYCHOL SCI, V15, P411, DOI 10.1177/1745691619885860
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Salton G., 1971, RETRIEVAL RESULTS FU
   Scarlini B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3528
   Scarlini B, 2020, AAAI CONF ARTIF INTE, V34, P8758
   Schutze H., 1992, Proceedings. Supercomputing '92. (Cat. No.92CH3216-9), P787, DOI 10.1109/SUPERC.1992.236684
   Soler A.G., T ASSOC COMPUT LING, P2021
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Tandon N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P115, DOI 10.18653/v1/P17-4020
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Tenney Ian, 2019, INT C LEARN REPR
   Vaswani A, 2017, ADV NEUR IN, V30
   Vial L, 2019, P 10 GLOB WORDNET C, P108
   Vial L, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1027
   Voita E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4396
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Vu Thuy, 2016, P 2016 C N AM ASS CO, P1262
   Vulic I., 2020, P 2020 C EMP METH NA, P7222
   Wang A, 2019, ADV NEUR IN, V32
   Wittgenstein L., 1953, PHILOSOPHICAL INVEST
   Wolf T., P 2020 C EMPIRICAL M, P38
   Yaghoobzadeh Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P236
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yarowsky D, 1995, P ACL, P189, DOI [10.3115/981658.981684, DOI 10.3115/981658.981684]
   Yuan D., 2016, PROC COLING, P1374
   Zhou X., P 16 C EUR CHAPT ASS, V2021, P3143
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 124
TC 2
Z9 2
U1 3
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD APR
PY 2022
VL 305
AR 103661
DI 10.1016/j.artint.2022.103661
EA JAN 2022
PG 33
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA ZR3DG
UT WOS:000767667600001
OA Green Accepted, Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Zhou, H
   Huang, SJ
   Zhou, JS
   Zhang, Y
   Chen, HD
   Dai, XY
   Cheng, C
   Chen, JJ
AF Zhou, Hao
   Huang, Shujian
   Zhou, Junsheng
   Zhang, Yue
   Chen, Huadong
   Dai, Xinyu
   Cheng, Chuan
   Chen, Jiajun
TI Enhancing Shift-Reduce Constituent Parsing with Action N-Gram Model
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Languages; Experiments; Shift-reduce constituent parsing; action
   history; action n-gram model
AB Current shift-reduce parsers "understand" the context by embodying a large number of binary indicator features with a discriminative model. In this article, we propose the action n-gram model, which utilizes the action sequence to help parsing disambiguation. The action n-gram model is trained on action sequences produced by parsers with the n-gram estimation method, which gives a smoothed maximum likelihood estimation of the action probability given a specific action history. We show that incorporating action n-gram models into a state-of-the-art parsing framework could achieve parsing accuracy improvements on three datasets across two languages.
C1 [Zhou, Hao; Huang, Shujian; Zhou, Junsheng; Chen, Huadong; Dai, Xinyu; Cheng, Chuan; Chen, Jiajun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210008, Jiangsu, Peoples R China.
   [Zhou, Junsheng] Nanjing Normal Univ, Dept Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Zhang, Yue] Singapore Univ Technol & Design, Singapore, Singapore.
C3 Nanjing University; Nanjing Normal University; Singapore University of
   Technology & Design
RP Huang, SJ (通讯作者)，Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210008, Jiangsu, Peoples R China.
EM zhouh@nlp.nju.edu.cn; huangsj@nlp.nju.edu.cn; zhoujs@njnu.edu.cn;
   yue_zhang@sutd.edu.sg; chenhd@nlp.nju.edu.cn; daixy@nlp.nju.edu.cn;
   chengc@nlp.nju.edu.cn; chenjj@nlp.nju.edu.cn
RI Lu, Xiaomei/IUQ-2139-2023
FU National Natural Science Foundation of China [61300158, 61170181,
   61472191]; Natural Science Foundation of Jiangsu Province, China
   [BK20130580]
FX This work was supported by the National Natural Science Foundation of
   China (61300158,61170181, 61472191) and the Natural Science Foundation
   of Jiangsu Province, China (BK20130580).
CR [Anonymous], 2008, P 25 C COMP NAT LANG
   [Anonymous], 1996, P 16 C COMPUTATIONAL
   [Anonymous], 2012, P 50 ANN M ASS COMP
   [Anonymous], 2008, P ACL 08 HLT
   [Anonymous], 2007, P NAACL MAIN C
   [Anonymous], 2011, P 49 ANN M ASS COMPU
   [Anonymous], 2008, P ACL
   [Anonymous], ACL 05 P 43 ANN M AS
   [Anonymous], 1996, 34 ANN M ASS COMP LI, DOI DOI 10.3115/981863.981904
   Bikel D. M., 2004, THESIS U PENNSYLVANI
   Briscoe T., 1993, Computational Linguistics, V19, P25
   Brown P. F., 1992, Computational Linguistics, V18, P31
   Charniak E, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA132
   Chen W., 2012, P 50 ANN M ASS COMP, P213
   Collins M, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P16
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   COLLINS M, 1999, THESIS U PENNSYLVANI
   Collins M., 2004, P 42 ANN M ASS COMPU, P111
   Goldberg Yoav, 2013, T ASS COMPUTATIONAL, V1, P403
   Goldberg Yoav, 2010, HUMAN LANGUAGE TECHN, P742
   Huang L., 2009, P 2009 C EMP METH NA, P1222
   Huang L, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1077
   Huang Z., 2009, PROC C EMPIRICAL MET, P832
   Huang Z., 2010, P 2010 C EMP METH NA, P12
   Jiang W., 2008, P 46 ANN M ASS COMP, P897
   Kentaro Inui, 1998, J NATURAL LANGAUGE P, V5, P33
   Lavie Alon, 1996, P ESSLLI 1996 WORKSH
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   McClosky David., 2006, P MAIN C HUM LANG TE, P152, DOI [10.3115/1220835.1220855, DOI 10.3115/1220835.1220855]
   McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI [10.3115/1219840.1219852, DOI 10.3115/1219840.1219852]
   Naiwen Xue, 2005, Natural Language Engineering, V11, P207, DOI 10.1017/S135132490400364X
   Nivre J., 2007, Natural Language Engineering, V13, P95, DOI 10.1017/S1351324906004505
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Ratnaparkhi A., 1997, CMPLG9706014 ARXIV
   Sagae K., 2006, P HUM LANG TECHN C N, P129
   Sagae Kenji, 2005, P 9 INT WORKSHOP PAR, P125
   Stigler SM., 1989, STAT SCI, V4, P73, DOI [10.1214/ss/1177012580, DOI 10.1214/SS/1177012580]
   Tomita M., 1987, Computational Linguistics, V13, P31
   Wang MQ, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P425
   Wang ZG, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P733
   Yamada H., 2003, P IWPT, V3
   Yue Zhang, 2009, P 11 INT C PARS TECH, P162
   Zhang Meishan, 2013, P 51 ANN M ASS COMP
   Zhu Muhua, 2013, P 51 ANN M ASS COMP
   Zhu Muhua, 2012, P INT C COMP LING AS
NR 45
TC 0
Z9 0
U1 0
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR
PY 2016
VL 15
IS 3
AR 13
DI 10.1145/2820902
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ0SB
UT WOS:000373913600003
DA 2023-11-10
ER

PT J
AU Otter, DW
   Medina, JR
   Kalita, JK
AF Otter, Daniel W.
   Medina, Julian R.
   Kalita, Jugal K.
TI A Survey of the Usages of Deep Learning for Natural Language Processing
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Machine learning; Natural language processing; Decoding; Neural
   networks; Computer architecture; Computational linguistics; Training;
   Computational linguistics; deep learning; machine learning; natural
   language processing (NLP); neural networks
ID NEURAL-NETWORK MODEL; REPRESENTATIONS; NEOCOGNITRON; GENERATION;
   ALGORITHM
AB Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This article provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to many applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field.
C1 [Otter, Daniel W.; Medina, Julian R.; Kalita, Jugal K.] Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA.
C3 University of Colorado System; University of Colorado at Colorado
   Springs
RP Kalita, JK (通讯作者)，Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA.
EM jkalita@uccs.edu
FU National Science Foundation [IIS-1359275, IIS-1659788]
FX This work was supported in part by the National Science Foundation under
   Grant IIS-1359275 and Grant IIS-1659788.
CR Adhikari A, 2019, DOCBERT BERT DOCUMEN
   Agirre E., 2012, P 6 INT WORKSHOP SEM, P385
   Ahmed K., 2017, ARXIV171102132
   Akbik A., 2018, P 27 INT C COMPUTATI, P1638
   [Anonymous], 2015, ARXIV150505008
   [Anonymous], 2014, P 8 WORKSH SYNT SEM
   [Anonymous], 2015, ARXIV150606158
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 2002, COLING 02 6 C NATURA
   [Anonymous], 2017, ARXIV171203556
   [Anonymous], 2016, P 2016 C EMPIRICAL M, DOI [DOI 10.18653/V1/D16-1123, 10.18653/v1/d16-1123]
   [Anonymous], 2015, ARXIV150807909
   [Anonymous], 2016, ARXIV160306042
   [Anonymous], 2009, P 4 WORKSHOP STAT MA
   [Anonymous], 2016, P 1 C MACHINE TRANSL
   [Anonymous], 2008, COLING 2008 P WORKSH
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, DOI DOI 10.48550/ARXIV.1409.0473
   Belinkov Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P861, DOI 10.18653/v1/P17-1080
   Benes K, 2017, INTERSPEECH, P284, DOI 10.21437/Interspeech.2017-1442
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bobrow Daniel G, 1964, NATURAL LANGUAGE INP
   Bordes A, 2014, MACH LEARN, V94, P233, DOI 10.1007/s10994-013-5363-6
   BOTHA J, 2014, P ICML, P1899
   Bowman S.R., 2018, BUS SOC
   Britz D., 2017, P 2017 C EMP METH NA, P1442, DOI [10.18653/v1/D17-1151, DOI 10.18653/V1/D17-1151]
   Brunner G, 2018, ARXIV180106024
   Cettolo M., 2016, ARXIV161000572
   Cettolo M., 2012, PROC EUR ASS MACH TR, P261
   Cettolo Mauro, 2014, P INT WORKSH SPOK LA
   Che, 2016, P 10 INT WORKSH SEM, P378
   Chelba C., 2013, ARXIV PREPRINT ARXIV
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, DOI 10.1155/2014/575246
   Chen LQ, 2018, ADV NEUR IN, V31
   Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76
   Chen YB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P167
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI [10.1162/tacl_a_00104, DOI 10.1162/TACL_A_00104]
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Choe D. K., 2016, P 2016 C EMP METH NA, P2331, DOI [DOI 10.18653/V1/D16-1257, 10.18653/v1/D16-1257]
   Chung J, 2014, NIPS 2014 WORKSH DEE, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Cire\csan D.C., 2011, P 22 INT JOINT C ART, VTwo, P1237
   Clark E, 2018, P 2018 C N AM CHAPT, V1, P2250, DOI DOI 10.18653/V1/N18-1204
   Clark E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2748
   Clarkson P, 2001, COMPUT SPEECH LANG, V15, P39, DOI 10.1006/csla.2000.0156
   Cliche M., 2017, P SEMEVAL, P573, DOI DOI 10.18653/V1/S17-2094
   Collobert R., 2008, P 25 ICML, V25, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Cowie J, 1996, COMMUN ACM, V39, P80, DOI 10.1145/234173.234209
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V4, p3:1, DOI [10.1145/1217098.1217101, DOI 10.1145/1187415.1187418]
   Cross J., 2016, ARXIV160606406
   Daniluk, 2017, ARXIV170204521
   Daojian Zeng., 2014, P COLING 25 INT C CO, P2335
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Dehouck M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2864
   Denkowski M., 2017, P 1 WORKSH NEUR MACH
   Devlin J., 2018, ARXIV, V1, P4171
   Doersch C, 2016, ARXIV
   Dolan B., 2004, P 20 INT C COMP LING, P350, DOI DOI 10.3115/1220355.1220406
   Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260
   Dos Santos M., P COLING, P69
   Dozat Timothy, 2018, ARXIV180701396
   Duong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P43
   Dyer C., 2016, P 2016 C N AM CHAPT, P199, DOI [10.18653/v1/N16-1024, DOI 10.18653/V1/N16-1024]
   Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334
   ElHihi S, 1996, ADV NEUR IN, V8, P493
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Etter M, 2018, BUS SOC, V57, P60, DOI 10.1177/0007650316683926
   Fan Angela, 2018, ABS180504833 CORR
   FAUSETT L, FUNDAMENTALS NEURAL
   Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110
   Fletcher Roger, 2013, PRACTICAL METHODS OP
   Fried Daniel, 2017, ARXIV170703058
   Fujisaki, 1991, CURRENT ISSUES PARSI, P139
   FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gehring J, 2017, ARXIV170503122, V3, P2029, DOI DOI 10.18653/V1/P16-1220
   Ghazvininejad M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6112
   Go Alec, 2009, TWITTER SENTIMENT CL, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Goldberg Y., 2017, SYNTH LECT HUM LANG, V10, P1, DOI DOI 10.2200/S00762ED1V01Y201703HLT037
   Goller C., 1996, P INT C NEURAL NETWO, V347, P352, DOI [10.1109/ICNN.1996.548916, DOI 10.1109/ICNN.1996.548916]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P55, DOI 10.1145/2983323.2983769
   Guo JX, 2018, AAAI CONF ARTIF INTE, P5141
   Hammerton J, 2003, P 7 C NAT LANG LEARN, V4, P172, DOI DOI 10.3115/1119176.1119202
   Hangyo Masatsugu, 2012, P 26 PAC AS C LANG I, P535
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689
   He H., 2016, P 2016 C N AM CHAPT, P937, DOI [DOI 10.18653/V1/N16-1108, 10.18653/v1/N16-1108]
   He H., 2015, P 2015 C EMP METH NA, P1576, DOI [DOI 10.18653/V1/D15-1181, 10.18653/v1/D15-1181]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hennessy John L., 2017, COMPUTER ARCHITECTUR, V6th
   Herzig J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P623, DOI 10.18653/v1/P17-2098
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hochreiter Sepp, 2001, FIELD GUIDE DYNAMICA, P2, DOI 10.1109/9780470544037.ch14
   Holtzman A, 2019, CEUR WORKSHOP PROC, V2540
   Hopkins J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P168, DOI 10.18653/v1/P17-1016
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hovy Eduard, 2006, P HUM LANG TECHN C N, P57, DOI DOI 10.3115/1614049.1614064
   Hu BT, 2014, ADV NEUR IN, V27
   Hu Z., 2017, P MACHINE LEARNING R, V70, P1587
   Huang EH, 2012, P 50 ANN M ASS COMPU, P873
   Huang Gao, 2017, PROC CVPR IEEE, P4700, DOI DOI 10.1109/CVPR.2017.243
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Huang Qiuyuan, 2018, ARXIV180508191
   Iyer R, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P254, DOI 10.1109/ASRU.1997.659013
   Jain P., 2017, ARXIV170705501
   Jelinek F., 1992, Speech Recognition and Understanding. Recent Advances, Trends and Applications. Proceedings of the NATO Advanced Study Institute, P345
   Ji Y., 2015, ARXIV151103962
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Jones Karen Sparck., 1994, CURRENT ISSUES COMPU, P3, DOI DOI 10.1007/978-0-585-35958-8_1
   Judge J, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P497
   Jurafsky D., 2017, SPEECH LANGUAGE PROC, V3rd
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kalita, 2019, P INT C NLP
   Kalita J., 2018, ARXIV181012427
   Kalita J., 2018, P 15 INT C NAT LANG, P180
   Kann, 2018, ARXIV180700286
   Kawahara D, 2002, P 3 INT C LANG RES E, P2008
   Kawahara Daisuke, 2006, P 5 INT C LANG RES E, P1344
   KAWATO M, 1987, BIOL CYBERN, V57, P169, DOI 10.1007/BF00364149
   Kenter T, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1403, DOI 10.1145/3077136.3082062
   Kim Y., 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1181
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   Kingma D.P., 2013, AUTOENCODING VARIATI
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   Koehn P., 2017, WMT, P28
   Koehn P., 2005, P MACHINE TRANSLATIO, P79
   Krantz, 2018, P INT C NLP, P1
   Krishnamurthy J., 2017, EMPIRICAL METHODS NA
   Krizhevsky A., 2014, ONE WEIRD TRICK PARA
   Kuang S., 2018, P 27 INT C COMP LING, P596
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G, 2016, P NAACL HLT, DOI DOI 10.18653/V1/N16-1030
   Le Phong, 2014, P 2014 C EMP METH NA, P729, DOI DOI 10.3115/V1/D14-1081
   Le Q, 2014, INT C MACHINE LEARNI, V32, DOI [DOI 10.1145/2740908.2742760, 10.5555/3044805.3045025]
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1995, CONVOLUTIONAL NETWOR, V3361, P1995, DOI 10.5555/303568.303704
   Li J., 2015, CORR
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604
   Li ZH, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P457
   Liddy E.D, 2001, ENCY LIB INFORM SCI
   Lin C., 2019, P 2 CLIN NATURAL LAN, P65, DOI DOI 10.18653/V1/W19-1908
   Lin K, 2017, ADV NEUR IN, V30
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]
   Liu X., 2019, ARXIV190606947
   Liu X., 2018, ARXIV180407888
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Liu Y, 2018, COMPUT LINGUIST, V44, P193, DOI 10.1162/COLI_r_00312
   Liu Yijia, 2018, ARXIV180408228
   Lu Zhengdong, 2013, ADV NEURAL INFORM PR, P1367, DOI DOI 10.7551/MITPRESS/11474.003.0014
   Luong M. T., 2014, ARXIV14108206, V27, P82
   Luong T., 2013, P 17 C COMP NAT LANG, P104, DOI DOI 10.1007/BF02579642
   MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1101, DOI 10.1145/3331184.3331317
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Marelli M., 2014, P 8 INT WORKSH SEM E, P1, DOI [10.3115/v1/S14-2001, DOI 10.3115/V1/S14-2001]
   Martin LJ, 2018, AAAI CONF ARTIF INTE, P868
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   MengqiuWang Noah A., 2007, P 2007 JOINT C EMP M, P22
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Mikolov Tomas, 2013, INT C LEARN REPR
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Monroe D, 2014, COMMUN ACM, V57, P13, DOI 10.1145/2601069
   More A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3847
   Morita H., 2015, P 2015 C EMP METH NA, P2292, DOI DOI 10.18653/V1/D15-1276
   Nair V., 2010, P 27 INT C MACHINE L
   Naiwen Xue, 2005, Natural Language Engineering, V11, P207, DOI 10.1017/S135132490400364X
   Nangia Nikita, 2017, ARXIV170708172
   Nguyen T. H., 2016, P 2016 C N AM CHAPTE, P300, DOI DOI 10.18653/V1/N16-1034
   Nivre J, 2003, P 8 INT C PARS TECHN, P149
   Nivre J, 2009, P 11 INT C PARS TECH, P73
   Nivre J, 2004, P WORKSH INCR PARS B, P50, DOI DOI 10.3115/1613148.1613156
   Nivre J, 2015, LECT NOTES COMPUT SC, V9041, P3, DOI 10.1007/978-3-319-18111-0_1
   Oepen S., 2015, P 9 INT WORKSHOP SEM, P915
   Ott M, 2018, PR MACH LEARN RES, V80
   Pang L, 2016, AAAI CONF ARTIF INTE, P2793
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Paulus R, 2017, ARXIV170504304, P1
   Pavlick E, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P408
   Peng N, 2018, P 1 WORKSH STOR, P43, DOI [10.18653/v1/W18-1505, DOI 10.18653/V1/W18-1505]
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Petrov S., 2012, P NOT 1 WORKSH SYNT, V59, P1
   Poliak Adam, 2018, P 7 JOINT C LEXICAL, P180, DOI DOI 10.18653/V1/S18-2023
   Poliak Adam, 2018, ARXIV180409779
   Pradhan Sameer., 2013, P 17 C COMPUTATIONAL, P143
   Qi, 2019, ARXIV190110457
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rahman A., 2012, P 2012 JOINT C EMPIR, P777
   Raina Rajat, 2009, INT C MACHINE LEARNI, P873, DOI [DOI 10.1145/1553374.1553486, 10.1145/1553374.1553486]
   Raposo D., 2017, ARXIV170205068
   Rappoport A., 2018, ARXIV180809354
   Reisinger Drew, 2015, T ASSOC COMPUT LING, V3, P475, DOI DOI 10.1162/TACL_A_00152
   Rosenfeld, 2008, EVALUATION METRICS L
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rush A M, 2015, P 2015 C EMPIRICAL M, P379
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saha S., 2018, ARXIV180604387
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Santos Diana, 2006, P LREC 2006
   Santra A, 2017, ADV GEOSPAT TECH, P1, DOI 10.4018/978-1-5225-1814-3
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schumann CL, 2019, AIDS BEHAV, V23, P5, DOI 10.1007/s10461-017-1727-4
   Schwenk H., 2012, P 24 INT C COMP LING, P1071
   Sennrich R, 2017, P SOFTW DEM 15 C EUR, P65, DOI DOI 10.18653/V1/E17-3017
   Serban IV, 2017, AAAI CONF ARTIF INTE, P3295
   Shazeer N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1428
   Shen YL, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P373, DOI 10.1145/2567948.2577348
   Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194
   Socher R., 2013, LONG PAPERS, V1, P455
   Socher R., 2011, P 24 INT C NEUR INF
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Srivastava Rupesh Kumar, 2015, ARXIV150500387, P2
   Stenetorp, 2013, P DEEP LEARN WORKSH
   Sun MM, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P556, DOI 10.1145/3159652.3159712
   Surdeanu M., 2008, P 12 C COMP NAT LANG, P159, DOI DOI 10.3115/1596324.1596352
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tambwekar Pradyumna, 2018, ARXIV180910736
   Tan ZX, 2018, AAAI CONF ARTIF INTE, P4929
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Tucker S., 2019, GENERATING BELIEVABL
   Vaswani A., 2017, ARXIV, V30, P5998
   Vinyals O., 2015, ADV NEURAL INFORM PR, V28
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang W., 2018, ARXIV180900068
   Wang W., 2019, NAACL
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Wang YS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1332
   Wang YX, 2018, AAAI CONF ARTIF INTE, P5561
   Wei J, 2018, INT CONF COMPUT NETW, P156, DOI 10.1109/ICCNC.2018.8390270
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   White Aaron Steven, 2017, P 8 INT JOINT C NAT, V8291, P996
   Wiebe J, 2014, P 8 INT WORKSH SEM E, P81, DOI [10.3115/v1/S14-2010, DOI 10.3115/V1/S14-2010]
   Williams Adina, 2017, ARXIV170405426
   Williams W, 2015, INT CONF ACOUST SPEE, P5391, DOI 10.1109/ICASSP.2015.7179001
   Winograd T., 1971, MACTR84 MIT
   Worsham J., 2018, P 27 INT C COMPUTATI, P1963
   Wu, 2016, ARXIV160202410
   Wu, 2018, P CONLL SHAR TASK MU, P248
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Xu Jingjing, 2018, ARXIV180806945
   Yang, NEURAL JOKE GENERATI
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P72
   Yang Yi, 2015, P 2015 C EMP METH NA, P2013, DOI DOI 10.18653/V1/D15-1237
   Yih WT, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P643
   Yin Wenpeng, 2015, P 2015 C N AM CHAPT, P901, DOI DOI 10.3115/V1/N15-1091
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu ZW, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1650
   Zamani H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P497, DOI 10.1145/3269206.3271800
   Zaremba Wojciech, 2015, ABS151106732 CORR
   Zaremba Wojciech, 2014, ARXIV14092329
   Zeman D., 2018, P CONLL 2018 SHARED, P1
   Zhang H, 2019, P 23 C COMP NAT LANG, P789, DOI [10.18653/v1/K19-1074, DOI 10.18653/V1/K19-1074]
   Zhang YZ, 2017, PR MACH LEARN RES, V70
   Zheng LJ, 2018, INT J MACH LEARN CYB, V9, P75, DOI 10.1007/s13042-015-0347-4
   Zheng SC, 2017, NEUROCOMPUTING, V257, P59, DOI 10.1016/j.neucom.2016.12.075
   Zhou H, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1213
NR 277
TC 512
Z9 539
U1 172
U2 1019
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD FEB
PY 2021
VL 32
IS 2
BP 604
EP 624
DI 10.1109/TNNLS.2020.2979670
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QE6IX
UT WOS:000616310400012
PM 32324570
OA hybrid, Green Submitted
HC Y
HP N
DA 2023-11-10
ER

PT J
AU Naim, I
   Riley, P
   Gildea, D
AF Naim, Iftekhar
   Riley, Parker
   Gildea, Daniel
TI Feature-Based Decipherment for Machine Translation
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Orthographic similarities across languages provide a strong signal for unsupervised probabilistic transduction (decipherment) for closely related language pairs. The existing decipherment models, however, are not well suited for exploiting these orthographic similarities. We propose a log-linear model with latent variables that incorporates orthographic similarity features. Maximum likelihood training is computationally expensive for the proposed log-linear model. To address this challenge, we perform approximate inference via Markov chain Monte Carlo sampling and contrastive divergence. Our results show that the proposed log-linear model with contrastive divergence outperforms the existing generative decipherment models by exploiting the orthographic features. The model both scales to large vocabularies and preserves accuracy in low- and no-resource contexts.
C1 [Naim, Iftekhar] Google, Mountain View, CA 94043 USA.
   [Riley, Parker; Gildea, Daniel] Univ Rochester, Comp Sci Dept, Rochester, NY 14627 USA.
C3 Google Incorporated; University of Rochester
RP Naim, I (通讯作者)，Google, Mountain View, CA 94043 USA.
EM iftekhar.naim@gmail.com; priley3@cs.rochester.edu;
   gildea@cs.rochester.edu
OI Gildea, Daniel/0000-0002-7858-2624
FU Google Faculty award; NSF [1449828]; Direct For Education and Human
   Resources; Division Of Graduate Education [1449828] Funding Source:
   National Science Foundation
FX We are grateful to the anonymous reviewers for suggesting useful
   additions. This research was supported by a Google Faculty award and NSF
   grant 1449828.
CR Ammar Waleed, 2014, ADV NEURAL INFORM PR, P3311
   [Anonymous], 2014, P 2014 C EMP METH NA
   [Anonymous], 1995, P 33 ANN M ASS COMP, DOI DOI 10.3115/981658.981709
   [Anonymous], 1991, P 29 ANN M ASS COMP
   [Anonymous], 2009, RECENT ADV NAT LANG, DOI DOI 10.1075/CILT.309
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Berg-Kirkpatrick T., 2010, HUMAN LANGUAGE TECHN, P582
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Church K. W., 1993, P 31 ANN M ASS COMP, P1, DOI DOI 10.3115/981574.981575
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dou Qing, 2012, P 2012 JOINT C EMP M, P266
   Dyer Chris, 2011, P 49 ANN M ASS COMP, P409
   Haghighi A., 2008, ACL
   Haghighi Aria, 2006, P MAIN C HUM LANG TE, P320, DOI DOI 10.3115/1220835.1220876
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Knight K, 1998, COMPUT LINGUIST, V24, P599
   Knight K., 1999, PROCEEDINGS OF THE A, P37
   Knight Kevin, 2016, ABS160402201 CORR
   Koehn P, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P711
   Nuhn M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P549
   Nuhn M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P759
   Nuhn Malte, 2013, P 51 ANN M ASS COMPU, V1, P1568
   Quattoni A., 2004, NIPS, P1097
   Ravi Sujith, 2013, P 51 ANN M ASS COMP, P362
   Ravi Sujith, 2011, P 49 ANN M ASS COMP, P12
   Snyder B, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1048
   Zhang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1959, DOI 10.18653/v1/P17-1179
   Zipf G.K., 1949, HUMAN BEHAVIOUR PRIN
NR 29
TC 1
Z9 1
U1 0
U2 11
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2018
VL 44
IS 3
BP 525
EP 546
DI 10.1162/coli_a_00326
PG 22
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA GU3YM
UT WOS:000445216700006
OA gold
DA 2023-11-10
ER

PT J
AU Whittaker, EWD
   Woodland, PC
AF Whittaker, EWD
   Woodland, PC
TI Language modelling for Russian and English using words and classes
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB This paper examines statistical language modelling of Russian and English in the context of automatic speech recognition. The characteristics of both a Russian and an English text corpus of similar composition are discussed with reference to the properties of both languages. In particular, it is shown that to achieve the same vocabulary coverage as a 65,000 word vocabulary for English, a 430,000 word vocabulary is required for Russian. The implications of this observation motivate the remainder of the paper. Perplexity experiments are reported for word-based N-gram modelling of the two languages and the differences are examined. It is found that, in contrast to English, there is little gain in using 4-grams over trigrams for modelling Russian. Class-based N-gram modelling is then considered and perplexity experiments are reported for two different types of class models, a two-sided model and a novel, one-sided model for which classes are generated automatically. Word and class model combinations show the two-sided model results in lower perplexities than combinations with the one-sided model. However, the very large Russian vocabulary favours the-use of the one-sided model since the clustering algorithm, used to obtain word classes automatically, is significantly faster. Lattice rescoring experiments are then reported on an English-language broadcast news task which show that both combinations of the word model with either type of class model produce identical reductions in word error rate. (C) 2002 Elsevier Science Ltd. All rights reserved.
C1 Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
C3 University of Cambridge
RP Whittaker, EWD (通讯作者)，Philips Res Labs, Weisshausstr 2, D-52066 Aachen, Germany.
CR [Anonymous], 1995, BRIT NATL CORPUS USE
   DUDA RO, 1973, PATTERN CLASSIFICATI, P227
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   ROSENFELD R, 1994, CMUCS94138 SCH COMP
   WHITTAKER EWD, 2000, THESIS CAMBRIDGE U
   WOODLAND PC, 1994, P IEEE INT C AC SPEE
   WOODLAND PC, 1941, P 1998 DARPA BROADC
NR 9
TC 13
Z9 15
U1 0
U2 1
PU ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2003
VL 17
IS 1
BP 87
EP 104
DI 10.1016/S0885-2308(02)00047-5
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 639WM
UT WOS:000180652800005
DA 2023-11-10
ER

PT J
AU Yang, LF
   Fu, KQ
   Zhang, JS
   Shinozaki, T
AF Yang, Longfei
   Fu, Kaiqi
   Zhang, Jinsong
   Shinozaki, Takahiro
TI Non-native acoustic modeling for mispronunciation verification based on
   language adversarial representation learning
SO NEURAL NETWORKS
LA English
DT Article
DE Mispronunciation verification; Computer aided pronunciation training;
   Language adversarial training; Unsupervised learning; Non-native
   acoustic modeling
AB Non-native mispronunciation verification is designed to provide feedback to guide language learners to correct their pronunciation errors in their further learning and it plays an important role in the computer-aided pronunciation training (CAPT) system. Most existing approaches focus on establishing the acoustic model directly using non-native corpus thus they are suffering the data sparsity problem due to time-consuming non-native speech data collection and annotation tasks. In this work, to address this problem, we propose a pre-trained approach to utilize the speech data of two native languages (the learner's native and target languages) for non-native mispronunciation verification. We set up an unsupervised model to extract knowledge from a large scale of unlabeled raw speech of the target language by making predictions about future observations in the speech signal, then the model is trained with language adversarial training using the learner's native language to align the feature distribution of two languages by confusing a language discriminator. In addition, sinc filter is incorporated at the first convolutional layer to capture the formant-like feature. Formant is relevant to the place and manner of articulation. Therefore, it is useful not only for pronunciation error detection but also for providing instructive feedback. Then the pre-trained model serves as the feature extractor in the downstream mispronunciation verification task. Through the experiments on the Japanese part of the BLCU inter-Chinese speech corpus, the experimental results demonstrate that for the non-native phone recognition and mispronunciation verification tasks (1) the knowledge learned from two native languages speech with the proposed unsupervised approach is useful for these two tasks (2) our proposed language adversarial representation learning is effective to improve the performance (3) formant-like feature can be incorporated by introducing sinc filter to further improve the performance of mispronunciation verification. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Yang, Longfei; Shinozaki, Takahiro] Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo, Japan.
   [Fu, Kaiqi; Zhang, Jinsong] Beijing Language & Culture Univ, Res Inst Int Chinese Language Educ, Beijing, Peoples R China.
C3 Tokyo Institute of Technology; Beijing Language & Culture University
RP Shinozaki, T (通讯作者)，Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo, Japan.; Zhang, JS (通讯作者)，Beijing Language & Culture Univ, Res Inst Int Chinese Language Educ, Beijing, Peoples R China.
EM yang.l.ae@m.titech.ac.jp; kaiq.fu@gmail.com; jinsong.zhang@blcu.edu.cn;
   shinot@ict.e.titech.ac.jp
OI Yang, Longfei/0000-0002-5079-3091
FU JSPS KAKENHI [JP20H00095]; Discipline TeamSupport Program of Beijing
   Language and Culture University [GF201906]; Advanced Innovation Center
   for Language Resource and Intelligence [KYR17005]
FX The author acknowledge the support provided by JSPS KAKENHI (Grant
   No.JP20H00095), the support from Discipline TeamSupport Program of
   Beijing Language and Culture University (Grant No.GF201906), Advanced
   Innovation Center for Language Resource and Intelligence (Grant
   No.KYR17005). Jinsong Zhang and Takahiro Shinozaki are corresponding
   authors.
CR [Anonymous], 2011, THESIS
   Browne MW, 2000, J MATH PSYCHOL, V44, P108, DOI 10.1006/jmps.1999.1279
   Bu H, 2017, 2017 20TH CONFERENCE OF THE ORIENTAL CHAPTER OF THE INTERNATIONAL COORDINATING COMMITTEE ON SPEECH DATABASES AND SPEECH I/O SYSTEMS AND ASSESSMENT (O-COCOSDA), P58, DOI 10.1109/ICSDA.2017.8384449
   Cao W., 2009, P NCMMSC
   Cao W, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1922
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Duan R., 2014, 15 ANN C INT SPEECH
   Duan RC, 2020, IEEE-ACM T AUDIO SPE, V28, P391, DOI 10.1109/TASLP.2019.2955858
   Fohr D., 2006, 9 INT C SPOK LANG PR
   Gao YM, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820820
   Gao YM, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P693
   Haibo He, 2007, Proceedings of the 2007 International Conference on Artificial Intelligence. ICAI 2007, P358
   Harrison A. M., 2009, P S LANG APPL TECHN, P45
   Hu WP, 2013, INTERSPEECH, P1885
   Hu WP, 2015, SPEECH COMMUN, V67, P154, DOI 10.1016/j.specom.2014.12.008
   Hyvarinen Aapo, 2016, ADV NEURAL INFORM PR, P3765
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Jo Chul-Ho, 1998, 5 INT C SPOK LANG PR
   Joshi S, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P697
   King DB, 2015, ACS SYM SER, V1214, P1
   Koreman J., 2013, SPEECH LANGUAGE TECH
   Lee A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P643
   Lin J, 2021, J MED VIROL, V93, P934, DOI 10.1002/jmv.26346
   Maekawa K., 2004, REPRODUCTION, V16, P5
   Ravanelli M., 2018, ARXIV181109725
   Ravanelli M, 2018, IEEE W SP LANG TECH, P1021, DOI 10.1109/SLT.2018.8639585
   Rivière M, 2020, INT CONF ACOUST SPEE, P7414, DOI [10.1109/icassp40776.2020.9054548, 10.1109/ICASSP40776.2020.9054548]
   Schneider Steffen, 2019, ARXIV190405862
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tieleman T., 2012, COURSERA LECT 65 RMS
   Uebler U., 1999, 6 EUR C SPEECH COMM
   Viikki O, 1998, SPEECH COMMUN, V25, P133, DOI 10.1016/S0167-6393(98)00033-8
   Vinyals O., 2018, ARXIV PREPRINT ARXIV
   Wang Y. J., 2004, P CHINESE TEACHING W, V2004, P54, DOI 10.13724/j.cnki.ctiw.2004.03.008
   Wang YB, 2012, INT CONF ACOUST SPEE, P5049, DOI 10.1109/ICASSP.2012.6289055
   Wang Z., 2003, P 2003 IEEE INT C AC, pI
   Wei S, 2009, SPEECH COMMUN, V51, P896, DOI 10.1016/j.specom.2009.03.004
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Witt S. M., 1999, THESIS
   Witt SM, 2000, SPEECH COMMUN, V30, P95, DOI 10.1016/S0167-6393(99)00044-8
   Wu Longji, 1989, SUMMARY EXPT PHONETI
   Xie X. L., 2010, J JILIN TEACHERS I E
   Yang LF, 2017, INT CONF ASIAN LANG, P52, DOI 10.1109/IALP.2017.8300544
   Zheng J, 2007, INT CONF ACOUST SPEE, P201
NR 45
TC 4
Z9 4
U1 1
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD OCT
PY 2021
VL 142
BP 597
EP 607
DI 10.1016/j.neunet.2021.07.017
EA AUG 2021
PG 11
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA UJ9WU
UT WOS:000691628800016
PM 34388438
DA 2023-11-10
ER

PT J
AU Zhou, TC
   Lyu, MRT
   King, I
   Lou, J
AF Zhou, Tom Chao
   Lyu, Michael Rung-Tsong
   King, Irwin
   Lou, Jie
TI Learning to suggest questions in social media
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Social media; Online forum; Community-based Q&A; Question suggestion;
   Language model; Topic modeling
ID Q-AND-A; KNOWLEDGE; ANSWERS; MODELS
AB Social media systems with Q&A functionalities have accumulated large archives of questions and answers. Two representative types are online forums and community-based Q&A services. To enable users to explore the large number of questions and answers in social media systems effectively, it is essential to suggest interesting items to an active user. In this article, we address the problem of question suggestion, which targets at suggesting questions that are semantically related to a queried question. Existing bag-of-words approaches suffer from the shortcoming that they could not bridge the lexical chasm between semantically related questions. Therefore, we present a new framework, and propose the topic-enhanced translation-based language model (TopicTRLM), which fuses both the lexical and latent semantic knowledge. This fusing enables TopicTRLM to find semantically related questions to a given question even when there is little word overlap. Moreover, to incorporate the answer information into the model to make the model more complete, we also propose the topic-enhanced translation-based language model with answer ensemble. Extensive experiments have been conducted with real-world datasets. Experimental results indicate our approach is very effective and outperforms other popular methods in several metrics.
C1 [Zhou, Tom Chao] Baidu Inc, Shenzhen, Peoples R China.
   [Lyu, Michael Rung-Tsong; King, Irwin] Chinese Univ Hong Kong, Shenzhen Key Lab Rich Media Big Data Analyt & App, Shenzhen Res Inst, Shenzhen, Peoples R China.
   [Lyu, Michael Rung-Tsong; King, Irwin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   [Lou, Jie] City Univ Hong Kong, Dept Informat Syst, Kowloon Tong, Hong Kong, Peoples R China.
C3 Baidu; Chinese University of Hong Kong, Shenzhen; CUHK Shenzhen Research
   Institute; Chinese University of Hong Kong; City University of Hong Kong
RP Zhou, TC (通讯作者)，Baidu Inc, Shenzhen, Peoples R China.
EM zhouchao03@baidu.com; lyu@cse.cuhk.edu.hk; king@cse.cuhk.edu.hk;
   paggy922@gmail.com
RI King, Irwin/C-9681-2015
OI King, Irwin/0000-0001-8106-6447
FU Basic Research Program of Shenzhen [JCYJ20120619152419087,
   JC201104220300A]; Research Grants Council of the Hong Kong Special
   Administrative Region, China [CUHK413212, CUHK415212]
FX The work described in this paper was fully supported by the Basic
   Research Program of Shenzhen (Project No. JCYJ20120619152419087 and
   JC201104220300A), and the Research Grants Council of the Hong Kong
   Special Administrative Region, China (Project No. CUHK413212 and
   CUHK415212). The authors would like to thank the anonymous reviewers for
   their insightful comments and helpful suggestions.
CR Adamic Lada A, 2008, P WWW
   Agichtein E, 2001, P 10 INT C WORLD WID
   Agichtein E, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1514888.1514893
   [Anonymous], 2005, PARAMETER ESTIMATION
   [Anonymous], 1999, P 22 ANN INT ACM SIG
   [Anonymous], P 21 ANN INT ACM SIG
   [Anonymous], 2000, P 23 ANN INT ACM SIG
   [Anonymous], P 29 ANN INT ACM SIG
   Berger Adam L., 1999, P 22 ANN INT ACM SIG
   Bernhard D, 2009, P JOINT C 47 ANN M A, V2
   Bian J, 2008, P 17 INT C WORLD WID
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Buckley C, 2004, P 27 ANN INT ACM SIG
   Buckley C, 1995, P 4 TEXT RETRIEVAL C
   Burke RD, 1997, AI MAG, V18, P57
   Cao X., 2010, P 19 INT C WORLD WID
   Cao X, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180869
   Cao Y, 2008, P 17 INT C WORLD WID
   Cao YB, 2011, J AM SOC INF SCI TEC, V62, P1177, DOI 10.1002/asi.21529
   Cong G., 2008, P 31 ANN INT ACM SIG
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Demner-Fushman D, 2007, COMPUT LINGUIST, V33, P63, DOI 10.1162/coli.2007.33.1.63
   DUAN H, 2008, P 46 ANN M ASS COMP
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Gazan R, 2011, J AM SOC INF SCI TEC, V62, P2301, DOI 10.1002/asi.21562
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Harabagiu S, 2001, P TEXT RETR C QUEST
   Huston S, 2010, P 33 INT ACM SIGIR C
   Jeon J, 2005, P 14 ACM INT C INF K
   Jeon J., 2005, P 28 ANN INT ACM SIG
   JIJKOUN V, 2005, P 14 ACM INT C INF K
   Kim S, 2009, J AM SOC INF SCI TEC, V60, P716, DOI 10.1002/asi.21026
   Li B, 2008, ASS COMPUTATIONAL LI
   Lin J, 2006, J AM SOC INF SCI TEC, V57, P851, DOI 10.1002/asi.20348
   Liu GZ, 1998, J AM SOC INFORM SCI, V49, P953
   Lou J, 2011, P 15 PAC C INF SYST
   Lou J, 2012, P 2012 INT C INF SYS
   Lou J, 2013, J AM SOC INF SCI TEC, V64, P356, DOI 10.1002/asi.22750
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Och FJ, 2003, COMPUT LINGUIST, V29, pc
   Ofoghi B, 2009, J AM SOC INF SCI TEC, V60, P247, DOI 10.1002/asi.20989
   Pomerantz J, 2005, J AM SOC INF SCI TEC, V56, P715, DOI 10.1002/asi.20162
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Qu B, 2012, J AM SOC INF SCI TEC, V63, P889, DOI 10.1002/asi.22611
   Raban DR, 2009, J AM SOC INF SCI TEC, V60, P2465, DOI 10.1002/asi.21188
   Radev D, 2005, J AM SOC INF SCI TEC, V56, P571, DOI 10.1002/asi.20146
   Radev DR, 2002, J AM SOC INF SCI TEC, V53, P359, DOI 10.1002/asi.10053
   Ramage D, 2009, P 2 ACM INT C WEB SE
   Ramos J., 2003, ICML, P29
   RIEZLER S, 2007, P 45 ANN M ASS COMP
   Rosen-Zvi M, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1658377.1658381
   Rosenbaum H, 2010, J AM SOC INF SCI TEC, V61, P1933, DOI 10.1002/asi.21340
   Schutze H., 2008, INTRO INFORM RETRIEV, V39
   Shah C, 2012, J AM SOC INF SCI TEC, V63, P2020, DOI 10.1002/asi.22699
   SHRESTHA L, 2004, P 20 INT C COMP LING
   Shtok A., 2012, P 21 INT C WORLD WID
   Soricut R., 2004, P HLT NAACL
   Sparck Jones Karen, 1971, AUTOMATIC KEYWORD CL
   Voorhees E.M., 1999, TREC
   WANG K, 2009, P 32 INT ACM SIGIR C
   Wu Chung-Hsien, 2005, ACM TRANS ASIAN LANG, V4, P1, DOI DOI 10.1145/1066078.1066079
   Xue X., 2008, P 31 ANN INT ACM SIG
   Yahoo!, YDAT YANSW ALL QUEST
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
   Zhou T. C., 2010, AAAI
   Zhou TC, 2012, P 21 INT C CO WORLD
   Zhou TC, 2011, P 25 AAAI C ART INT
   Zhou TC, 2012, P 26 AAAI C ART INT
   Zhou TC, 2009, COMP SCI ENG 2009 CS
   [No title captured]
NR 71
TC 9
Z9 9
U1 0
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD MAY
PY 2015
VL 43
IS 2
BP 389
EP 416
DI 10.1007/s10115-014-0737-z
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA CE0TX
UT WOS:000351520700006
DA 2023-11-10
ER

PT J
AU Shafi, J
   Iqbal, HR
   Nawab, RMA
   Rayson, P
AF Shafi, Jawad
   Iqbal, Hafiz Rizwan
   Nawab, Rao Muhammad Adeel
   Rayson, Paul
TI UNLT: Urdu Natural Language Toolkit
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Word segmentation; Text segmentation; Part-of-speech tagging; Urdu NLP
   toolkit; Urdu corpora
AB This study describes a Natural Language Processing (NLP) toolkit, as the first contribution of a larger project, for an under-resourced language-Urdu. In previous studies, standard NLP toolkits have been developed for English and many other languages. There is also a dire need for standard text processing tools and methods for Urdu, despite it being widely spoken in different parts of the world with a large amount of digital text being readily available. This study presents the first version of the UNLT (Urdu Natural Language Toolkit) which contains three key text processing tools required for an Urdu NLP pipeline; word tokenizer, sentence tokenizer, and part-of-speech (POS) tagger. The UNLT word tokenizer employs a morpheme matching algorithm coupled with a state-of-the-art stochastic n-gram language model with back-off and smoothing characteristics for the space omission problem. The space insertion problem for compound words is tackled using a dictionary look-up technique. The UNLT sentence tokenizer is a combination of various machine learning, rule-based, regular-expressions, and dictionary look-up techniques. Finally, the UNLT POS taggers are based on Hidden Markov Model and Maximum Entropy-based stochastic techniques. In addition, we have developed large gold standard training and testing data sets to improve and evaluate the performance of new techniques for Urdu word tokenization, sentence tokenization, and POS tagging. For comparison purposes, we have compared the proposed approaches with several methods. Our proposed UNLT, the training and testing data sets, and supporting resources are all free and publicly available for academic use.
C1 [Shafi, Jawad; Rayson, Paul] Univ Lancaster, Sch Comp & Commun SCC, Lancaster, England.
   [Shafi, Jawad; Nawab, Rao Muhammad Adeel] COMSATS Univ Islamabad, Lahore Campus, Islamabad, Pakistan.
   [Iqbal, Hafiz Rizwan] Informat Technol Univ, Lahore, Pakistan.
C3 Lancaster University; COMSATS University Islamabad (CUI)
RP Shafi, J (通讯作者)，Univ Lancaster, Sch Comp & Commun SCC, Lancaster, England.; Shafi, J (通讯作者)，COMSATS Univ Islamabad, Lahore Campus, Islamabad, Pakistan.
EM jawadshafi@cuilahore.edu.pk
RI Rayson, Paul/HKW-7858-2023
OI Rayson, Paul/0000-0002-1257-2191
FU COMSATS University Islamabad, Lahore Campus, Pakistan; Lancaster
   University, U.K. under the Split-Site Ph.D. programme
FX This work has been supported by the COMSATS University Islamabad, Lahore
   Campus, Pakistan and Lancaster University, U.K. under the Split-Site
   Ph.D. programme.
CR Abdelhamid A. A., 2012, P INT C IM SIGN PROC, P150
   Ahmed T, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2920
   Akita Y, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1033
   Albared M, 2010, LECT NOTES ARTIF INT, V6401, P361, DOI 10.1007/978-3-642-16248-0_52
   [Anonymous], 2010, P 2010 NAMED ENTITIE
   [Anonymous], 2010, ANN C N AM CHAPT ACL
   [Anonymous], 1997, CORPUS ANNOTATION LI
   [Anonymous], 2002, P 37 ANN M ASS COMPU, DOI DOI 10.3115/1034678.1034712
   [Anonymous], 2008, ADV NATURAL LANGUAGE
   [Anonymous], 2008, P 22 INT C COMPUTATI, DOI DOI 10.3115/1599081.1599179
   [Anonymous], 2009, P 12 C EUROPEAN CHAP
   Anwar Waqas, 2007, Information Technology Journal, V6, P1190
   Anwar W, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3418
   Azimizadeh A., 2008, 9 JADT, P121
   Bhat Riyaz Ahmad, 2012, P 6 LINGUISTIC ANNOT, P157
   Bird S., 2008, P 3 WORKSH ISS TEACH, V13, P62, DOI DOI 10.3115/1627306.1627317
   Bird Steven, 2009, NATURAL LANGUAGE PRO
   Bogel T., 2007, FINITE STATE METHODS, P86
   Brants T, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P224
   Butt, 1995, STRUCTURE COMPLEX PR
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Christensen H., 2014, HC CORPORA
   Christer S., 1996, 16 C COMPUTATIONAL L, P895
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Cunningham H, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P168
   Cunningham H, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002854
   Curran JR, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P91
   Dandapat S., 2008, P IJCAI WORKSH SHALL, P29
   Daud A, 2017, ARTIF INTELL REV, V47, P279, DOI 10.1007/s10462-016-9482-x
   DERMATAS E, 1995, COMPUT LINGUIST, V21, P137
   Dietzel A., 2015, P POL STUD ASS 65 AN, P1
   Ferrucci D., 2004, Natural Language Engineering, V10, P327, DOI 10.1017/S1351324904003523
   Fu GH, 2008, INFORM SCIENCES, V178, P2282, DOI 10.1016/j.ins.2008.01.001
   Gimenez J, 2004, P 4 INT C LANG RES E
   Gries S.T., 2014, RES METHODS LINGUIST, P257
   Hardie, 2004, THESIS LANCASTER U U
   Hardie Andrew, 2003, P CORPUS LINGUISTICS, P298
   Hautli Annette, 2011, P ACL HLT STUDENT SE, P24
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Javed, 1985, NAI URDU QAWAID
   Jawaid B, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2938
   Jeffreys H, 1961, THEORY PROBABILITY
   Joshi N., 2013, P 2013 INT C ART INT, P341, DOI DOI 10.5121/CSIT.2013.3639
   Jurafsky D., 2014, SPEECH LANGUAGE PROC, V3
   Khan S.A., 2012, 24 INT C COMP LING, P69
   Kreuzthaler M, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/1472-6947-15-S2-S4
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Kwartler, 2017, TEXT MIN PRACT R, P237, DOI DOI 10.1002/9781119282105.CH8
   Lehal G.S., 2010, P 1 WORKSH S SE AS N, P43
   Malik A., 2009, P NAM ENT WORKSH SIN, P177
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Maynard D., 2015, P ACM WEB SCI C WEBS, P46
   Nguyen MV, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P80
   Muaz A., 2009, P 7 WORKSH AS LANG R, P24
   Mukund S., 2010, ACM T ASIAN LANG INF, V9, P1, DOI DOI 10.1145/1838751.1838754
   Naz F., 2012, WORLD APPL SCI J, V16, P437
   Platts John, 1909, GRAMMAR HINDUSTANI U
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raj S, 2015, INT ARAB J INF TECHN, V12, P395
   Rashid R, 2012, INT CONF ASIAN LANG, P101, DOI 10.1109/IALP.2012.11
   Ratnaparkhi A., 1996, P C EMP METH NAT LAN, V1, P133
   Rehman Z., 2011, P 2 WORKSHOP S SE AS, P40
   Rehman Z, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068178
   Rehman Z, 2012, INT ARAB J INF TECHN, V9, P250
   Riaz K., 2012, IJCLNLP, V1, P92
   Rush A M, 2015, P 2015 C EMPIRICAL M, P379
   Saeed A., 2018, LANG RESOUR EVAL, V1, P1
   Sajjad H., 2007, THESIS NATL U COMPUT
   SCHMID LA, 1994, INT CONF ACOUST SPEE, P41
   Schmidt R.L., 1999, ROUTLEDGE ESSENTIAL, V1
   Shafi, 2020, THESIS LANCASTER U U
   Sharjeel M, 2017, LANG RESOUR EVAL, V51, P777, DOI 10.1007/s10579-016-9367-2
   Tafseer A., 2009, P C LANG TECHN CLT 0, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Wicaksono A. F., 2010, 4 INY MALINDO WORKSH
   Yi C, 2016, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION, BIG DATA AND SMART CITY (ICITBS), P81, DOI 10.1109/ICITBS.2015.26
NR 79
TC 3
Z9 3
U1 2
U2 10
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUL
PY 2023
VL 29
IS 4
BP 942
EP 977
AR PII S1351324921000425
DI 10.1017/S1351324921000425
EA JAN 2022
PG 36
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA M8CH8
UT WOS:000744337800001
OA Green Accepted, hybrid
DA 2023-11-10
ER

PT J
AU Liu, Y
   Liu, Q
   Lin, SX
AF Liu, Yang
   Liu, Qun
   Lin, Shouxun
TI Discriminative Word Alignment by Linear Modeling
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Word alignment plays an important role in many NLP tasks as it indicates the correspondence between words in a parallel text. Although widely used to align large bilingual corpora, generative models are hard to extend to incorporate arbitrary useful linguistic information. This article presents a discriminative framework for word alignment based on a linear model. Within this framework, all knowledge sources are treated as feature functions, which depend on a source language sentence, a target language sentence, and the alignment between them. We describe a number of features that could produce symmetric alignments. Our model is easy to extend and can be optimized with respect to evaluation metrics directly. The model achieves state-of-the-art alignment quality on three word alignment shared tasks for five language pairs with varying divergence and richness of resources. We further show that our approach improves translation performance for various statistical machine translation systems.
C1 [Liu, Yang; Liu, Qun; Lin, Shouxun] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Liu, Y (通讯作者)，Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, 6 Kexueyuan S Rd,POB 2704, Beijing 100190, Peoples R China.
EM yliu@ict.ac.cn; liuqun@ict.ac.cn; sxlin@ict.ac.cn
FU National Natural Science Foundation of China [60603095, 60573188]
FX This work was supported by National Natural Science Foundation of China,
   Contract No. 60603095 and 60573188. Thanks to the three anonymous
   reviewers for their insightful and constructive comments and
   suggestions. We are grateful to Rada Mihalcea for giving us the
   Romanian-English training data and David Chiang for allowing us to use
   Hiero. Stephan Vogel, Vamshi Ambati, and Kelly Widmaier offered valuable
   feedback on an earlier version of this article.
CR [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], P C EMP METH NAT LAN
   [Anonymous], 2005, P C HUMAN LANGUAGE T
   [Anonymous], 2005, P 43 ANN M ASS COMPU
   Ayan N. F., 2006, P HLT NAACL, P96
   Ayan NF, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P9
   AYAN NF, 2005, P HLT EMNLP, P185
   AYAN NF, 2005, P HLT EMNLP, P65
   Blunsom P, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P65
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Cherry C, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P88
   Cherry C., 2006, P 44 ANN M ASS COMP, P105
   Chiang D, 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   CROMIERES F, 2009, P EACL 2009 ATH, P166
   Fraser A., 2007, P 2007 JOINT C EMP M, P51
   Fraser A, 2007, COMPUT LINGUIST, V33, P293, DOI 10.1162/coli.2007.33.3.293
   Fraser A, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P769
   Galley M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P961
   Haghighi A, 2009, P JOINT C 47 ANN M A, P923
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   Koehn Philipp, 2007, P 2007 JOINT C EMP M
   Lacoste-Julien S, 2006, P HLT NAACL, P112
   Liang Percy, 2006, P HUM LANG TECHN C N, P104, DOI DOI 10.3115/1220835.1220849
   LIU Y, 2005, P 43 ANN M ASS COMP, P459
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Marcu Daniel, 2006, P 2006 C EMP METH NA, P44
   Martin J., 2005, P ACL WORKSH BUILD U, P65
   Melamed ID, 2000, COMPUT LINGUIST, V26, P221, DOI 10.1162/089120100561683
   MELAMED ID, 1998, 9806 U PENNS PHIL
   Mihalcea R, 2003, PROC HLT NAACL WORKS, V3
   Moore RC, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P513
   NIEHUES J, 2008, P 3 WORKSH STAT MACH, P18
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Och FJ, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P295
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   ROSTI AV, 2007, P 45 ANN M ASS COMP, P312
   TASKAR B, 2005, P HLT EMNLP, P73
   Vogel S, 1996, P 16 C COMP LING ASS, P836, DOI DOI 10.3115/993268.993313
NR 40
TC 10
Z9 17
U1 1
U2 24
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2010
VL 36
IS 3
BP 303
EP 339
DI 10.1162/coli_a_00001
PG 37
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 649CN
UT WOS:000281744900002
OA hybrid
DA 2023-11-10
ER

PT J
AU Attia, M
   Pecina, P
   Samih, Y
   Shaalan, K
   Van Genabith, J
AF Attia, Mohammed
   Pecina, Pavel
   Samih, Younes
   Shaalan, Khaled
   Van Genabith, Josef
TI Arabic spelling error detection and correction
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
ID WORDS
AB A spelling error detection and correction application is typically based on three main components: a dictionary (or reference word list), an error model and a language model. While most of the attention in the literature has been directed to the language model, we show how improvements in any of the three components can lead to significant cumulative improvements in the overall performance of the system. We develop our dictionary of 9.2 million fully-inflected Arabic words (types) from a morphological transducer and a large corpus, validated and manually revised. We improve the error model by analyzing error types and creating an edit distance re-ranker. We also improve the language model by analyzing the level of noise in different data sources and selecting an optimal subset to train the system on. Testing and evaluation experiments show that our system significantly outperforms Microsoft Word 2013, OpenOffice Ayaspell 3.4 and Google Docs.
C1 [Attia, Mohammed; Van Genabith, Josef] Dublin City Univ, Sch Comp, Dublin, Ireland.
   [Attia, Mohammed; Shaalan, Khaled] British Univ Dubai, Fac Engn & IT, Dubai, U Arab Emirates.
   [Pecina, Pavel] Charles Univ Prague, Fac Math & Phys, Prague, Czech Republic.
   [Samih, Younes] Univ Dusseldorf, Dept Linguist & Informat Sci, Dusseldorf, Germany.
C3 Dublin City University; Charles University Prague; Heinrich Heine
   University Dusseldorf
RP Attia, M (通讯作者)，Dublin City Univ, Sch Comp, Dublin, Ireland.
EM mattia@computing.dcu.ie; pecina@ufal.mff.cuni.cz;
   samih@phil.uni-duesseldorf.de; khaled.shaalan@buid.ac.ae;
   josef@computing.dcu.ie
RI Shaalan, Khaled/E-7377-2016; Pecina, Pavel/K-3770-2017
OI Shaalan, Khaled/0000-0003-0823-8390; Pecina, Pavel/0000-0002-1855-5931;
   Samih, Younes/0000-0002-0485-7920
FU Irish Research Council for Science Engineering and Technology (IRCSET);
   UAE National Research Foundation (NRF) [0514/2011]; Czech Science
   Foundation [P103/12/G084]; DFG Collaborative Research Centre 991: The
   Structure of Representations in Language, Cognition, and Science;
   Science Foundation Ireland as part of the Centre for Next Generation
   Localisation at Dublin City University [07/CE/I1142]
FX We are grateful to our anonymous reviewers whose comments and
   suggestions have helped us to improve the paper considerably. This
   research is funded by the Irish Research Council for Science Engineering
   and Technology (IRCSET), the UAE National Research Foundation (NRF)
   (Grant No. 0514/2011), the Czech Science Foundation (grant no.
   P103/12/G084), DFG Collaborative Research Centre 991: The Structure of
   Representations in Language, Cognition, and Science
   (http://www.sfb991.uniduesseldorf.de/sfb991), and the Science Foundation
   Ireland (Grant No. 07/CE/I1142) as part of the Centre for Next
   Generation Localisation (www.cngl.ie) at Dublin City University.
CR Alfaifi A., 2012, P 8 INT COMP C AR IC
   Alkanhal MI, 2012, IEEE T AUDIO SPEECH, V20, P2111, DOI 10.1109/TASL.2012.2197612
   [Anonymous], 2006, DATA MINING SE ASIA
   [Anonymous], 2004, P WORKSHOP COMPUTATI
   [Anonymous], 2011, P IEEE AUT SPEECH RE
   [Anonymous], 1998, P WORKSH COMP APPR S
   [Anonymous], 2008, P ACL 08 HLT SHORT P
   Attia M., 2006, CHALL AR NLP MT C BR, P48
   Attia M., 2011, P 9 INT WORKSH FIN S, P125
   Beesley K. R., 2003, CSLI STUDIES COMPUTA
   Brill E, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P286, DOI 10.3115/1075218.1075255
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Buckwalter T., 2004, BUCKWALTER ARABIC MO
   Choudhury M, 2007, INT J DOC ANAL RECOG, V10, P157, DOI 10.1007/s10032-007-0054-0
   Church K.W., 1991, STAT COMP, V1, P93, DOI [DOI 10.1007/BF01889984, 10.1007/BF01889984]
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   El Kholy Ahmed, 2010, LREC 2010 WORKSH LAN, P45
   Gao Jianfeng, 2010, P 23 INT C COMP LING, P358
   Habash N., 2005, P 43 ANN M ASS COMP, P573, DOI DOI 10.3115/1219840.1219911
   Haddad B., 2007, INT J COMPUT PROCESS, V20, P237, DOI DOI 10.1142/S0219427907001706
   Haji J., 2005, P 4 WORKSH TREEB LIN, P53
   Han Bo., 2011, P 49 ANN M ASS COMP, P368
   Hassan A., 2008, IJCNLP, P913
   Heift T, 2008, SYSTEM, V36, P196, DOI 10.1016/j.system.2007.09.007
   HULDEN M., 2009, P 12 C EUR CHAPT ASS, V12, P29, DOI DOI 10.3115/1609049.1609057
   Hulden M, 2009, PROCES LENG NAT, P57
   Kernigan M., 1990, SPELLING CORRECTION, P205
   Kiraz G.A., 2001, COMPUTATIONAL NONLIN
   KUKICH K, 1992, COMPUT SURV, V24, P377
   Levenshtein V. I., 1966, BINARY CODES CAPABLE, DOI DOI 10.1109/TVCG.2012.323
   Magdy W., 2006, P 2006 C EMP METH NA, P408, DOI DOI 10.3115/1610075.1610132
   Mitton R., 1996, ENGLISH SPELLING COM
   Mooney RJ., 2005, ACM SIGKDD EXPLORATI, V7, P3, DOI 10.1145/1089815.1089817
   Moussa M, 2012, EMPIRICAL METHODS NA, P228
   Norvig P., 2009, BEAUTIFUL DATA, P219
   Och F. J., 2013, Patent US, Patent No. [20130144592 A1, 20130144592]
   Oflazer K, 1996, COMPUT LINGUIST, V22, P73
   Parker Robert, 2011, ARABIC GIGAWORD
   Ratcliffe R. R., 1998, J NATURAL LANGUAGE E, VIV
   Ratcliffe R. R., 1998, J NATURAL LANGUAGE E, V168
   Shaalan K., 2003, P 4 C LANG ENG EG SO, P240
   Shaalan K., 2013, J NATURAL LANGUAGE E, P1
   Shaalan K, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P719
   Tong X., 1996, P WVLC, P88
   UKKONEN E, 1983, LECT NOTES COMPUT SC, V158, P487
   van Delden S, 2004, PROCEEDINGS OF THE 2004 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI-2004), P530, DOI 10.1109/IRI.2004.1431515
   Watson J.C.E., 2002, PHONOLOGY MORPHOLOGY
   Wintner Shuly, 2008, NAT LANG ENG, V14, P457
   Wu Jian-Cheng, 2013, INT J COMPUT LINGUIS, V18, P17
   Zaghouani W., 2014, LANG RES EV C LREC R, P26
   Zribi CB, 2003, LECT NOTES ARTIF INT, V2773, P770
NR 51
TC 14
Z9 15
U1 0
U2 7
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD SEP
PY 2016
VL 22
IS 5
BP 751
EP 773
DI 10.1017/S1351324915000030
PG 23
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA DX4BY
UT WOS:000384325400004
DA 2023-11-10
ER

PT J
AU Ryu, M
   Lee, G
   Lee, K
AF Ryu, Minho
   Lee, Geonseok
   Lee, Kichun
TI Knowledge distillation for BERT unsupervised domain adaptation
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Language model; Knowledge distillation; Domain adaptation
AB A pre-trained language model, BERT, has brought significant performance improvements across a range of natural language processing tasks. Since the model is trained on a large corpus of diverse topics, it shows robust performance for domain shift problems in which data distributions at training (source data) and testing (target data) differ while sharing similarities. Despite its great improvements compared to previous models, it still suffers from performance degradation due to domain shifts. To mitigate such problems, we propose a simple but effective unsupervised domain adaptation method, adversarial adaptation with distillation (AAD), which combines the adversarial discriminative domain adaptation (ADDA) framework with knowledge distillation. We evaluate our approach in the task of cross-domain sentiment classification on 30 domain pairs, advancing the state-of-the-art performance for unsupervised domain adaptation in text sentiment classification.
C1 [Ryu, Minho] SK Telecom, Seoul, South Korea.
   [Lee, Geonseok; Lee, Kichun] Hanyang Univ, Dept Ind Engn, Seoul, South Korea.
C3 SK Group; SK Telecom; Hanyang University
RP Lee, K (通讯作者)，Hanyang Univ, Dept Ind Engn, Seoul, South Korea.
EM ryumin93@sktbrain.com; lgs5228@hanyang.ac.kr; skylee@hanyang.ac.kr
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of Korea [NRF-2020R1F1A1076278]; "Human Resources Program in
   Energy Technology" of the Korea Institute of Energy Technology
   Evaluation and Planning (KETEP); Ministry of Trade, Industry & Energy,
   Republic of Korea [20204010600090]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea
   (NRF-2020R1F1A1076278). This work was also supported by "Human Resources
   Program in Energy Technology" of the Korea Institute of Energy
   Technology Evaluation and Planning (KETEP), granted financial resource
   from the Ministry of Trade, Industry & Energy, Republic of Korea (No.
   20204010600090).
CR Blitzer J., 2006, P 2006 C EMPIRICAL M, P120
   Chadha A., 2018, ARXIV180903625
   Devlin J., 2018, ARXIV, V1, P4171
   Dredze Mark, 2007, P 45 ANN M ASS COMPU, P440
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Joshi M., 2019, ARXIV
   Kingma D. P., 2014, C TRACK P
   Kirkpatrick J., 2016, ARXIV
   Kumar A., 2017, ARXIV
   Liu Yinhan, 2019, ARXIV190711692
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   Nguyen Quang, 2015, AIRLINE REV DATASET
   Paszke Adam, 2017, NIPS W
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Sanh Victor., 2019, NEURIPS EMC2 WORKSHO
   Sun B, 2016, ARXIV
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Tuzel O., 2016, ADV NEURAL INFORM PR, P469, DOI DOI 10.5555/3157096.3157149
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Tzeng Eric, 2014, ARXIV14123474, DOI DOI 10.48550/ARXIV.1412.3474
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P3048, DOI 10.1109/TPAMI.2021.3055564
   Weng RX, 2020, AAAI CONF ARTIF INTE, V34, P9266
   Wolf T, 2019, ARXIV
   Yang Z, 2019, ARXIV
   Ziser Y., 2018, 2018 C N AM CHAPT AS, P1241
   Ziser Yftah, 2017, P INT C COMPUTATIONA, P400, DOI DOI 10.18653/V1/K17-1040
NR 31
TC 3
Z9 3
U1 7
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD NOV
PY 2022
VL 64
IS 11
BP 3113
EP 3128
DI 10.1007/s10115-022-01736-y
EA AUG 2022
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4N6YE
UT WOS:000842758700003
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Guo, H
   Zhang, ZQ
   Guo, Q
   Zhou, LZ
   Feng, JH
AF Guo, H
   Zhang, ZQ
   Guo, Q
   Zhou, LZ
   Feng, JH
BE Liu, WY
   Shi, YC
   Li, Q
TI Build presentation layer for semantic contents
SO ADVANCES IN WEB-BASED LEARNING - ICWL 2004
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 3rd International Conference on Web-Based Learning (ICWL 2004)
CY AUG 08-11, 2004
CL Tsinghua Univ, Beijing, PEOPLES R CHINA
SP Hong Kong Web Soc, Tsinghua Univ, Pervas Comp Grp, CS Dept, City Univ Hong Kong, IEEE-CS Beijing, China eLearning Technol Stand Comm
HO Tsinghua Univ
AB Large scale of semantically enriched data is the foundation of the semantic web. We introduce the model used in SESQ* system as the presentation layer of the semantic contents. It is an abstract graph independent of the data storage layer and application layer. Semantic contents of a specified domain are organized as nodes and arcs in the graph. GQML, a manipulation language, is designed for the graph, which is also used as the query language to semantic contents. With this model, the interoperation and integration of different sources will be easier. Now the model has been implemented on Berkley Database System and Relational Database.
C1 Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Guo, H (通讯作者)，Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.
EM guohang@mails.tsinghua.edu.cn; zqzhang@mail.tsinghua.edu.cn;
   guoqi00@mails.tsinghua.edu.cn; dcszlz@mail.tsinghua.edu.cn;
   fengjh@mail.tsinghua.edu.cn
CR [Anonymous], 2002, SPINNING SEMANTIC WE
   [Anonymous], 2000, RESOURCE DESCRIPTION
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Broekstra J., 2001, SEMANTICS WWW
   FENSEL D, 1999, WORLD C WWW INTERNET
   GUO H, 2004, DEFINITION ELEMENTS
   GUO Q, 2004, 6 AS PAC WEB C APWEB
   HORROCKS I, 2002, REV DESIGN DAML PLUS
   LUKE S, 2000, P 1 INT C AUT AG MAR, P59
   MELNIK S, 2000, RDF API DRAFT PUBLIC
   SELTZER M, BERKELEY DATABASE EM
   ZHANG ZQ, 2003, SESQ ONTOLOGY BASED
NR 12
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-22542-0
J9 LECT NOTES COMPUT SC
PY 2004
VL 3143
BP 241
EP 248
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BAO42
UT WOS:000223068900031
DA 2023-11-10
ER

PT J
AU Wang, QF
   Cambria, E
   Liu, CL
   Hussain, A
AF Wang, Qiu-Feng
   Cambria, Erik
   Liu, Cheng-Lin
   Hussain, Amir
TI Common Sense Knowledge for Handwritten Chinese Text Recognition
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Common sense knowledge; Natural language processing; Linguistic context;
   n-gram; Handwritten Chinese text recognition
ID LANGUAGE MODEL; FRAMEWORK
AB Compared to human intelligence, computers are far short of common sense knowledge which people normally acquire during the formative years of their lives. This paper investigates the effects of employing common sense knowledge as a new linguistic context in handwritten Chinese text recognition. Three methods are introduced to supplement the standard n-gram language model: embedding model, direct model, and an ensemble of these two. The embedding model uses semantic similarities from common sense knowledge to make the n-gram probabilities estimation more reliable, especially for the unseen n-grams in the training text corpus. The direct model, in turn, considers the linguistic context of the whole document to make up for the short context limit of the n-gram model. The three models are evaluated on a large unconstrained handwriting database, CASIA-HWDB, and the results show that the adoption of common sense knowledge yields improvements in recognition performance, despite the reduced concept list hereby employed.
C1 [Wang, Qiu-Feng; Liu, Cheng-Lin] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
   [Cambria, Erik] Natl Univ Singapore, Temasek Labs, Singapore 117411, Singapore.
   [Hussain, Amir] Univ Stirling, Dept Comp Sci & Math, Stirling FK9 4LA, Scotland.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; National
   University of Singapore; University of Stirling
RP Wang, QF (通讯作者)，Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
EM wangqf@nlpr.ia.ac.cn; cambria@nus.edu.sg; liucl@nlpr.ia.ac.cn;
   ahu@cs.stir.ac.uk
RI Cambria, Erik/C-2103-2013; Hussain, Amir/AAG-6299-2020; Liu,
   Cheng-Lin/JCO-6642-2023; Li, Yang/HPC-4054-2023
OI Cambria, Erik/0000-0002-3030-1280; Hussain, Amir/0000-0002-8080-082X; 
FU National Basic Research Program of China (973 Program) [2012CB316302];
   National Natural Science Foundation of China (NSFC) [60825301,
   60933010]; Royal Society of Edinburgh (UK); Chinese Academy of Sciences
   within the China-Scotland SIPRA (Signal Image Processing Research
   Academy) Programme
FX This work has been supported in part by the National Basic Research
   Program of China (973 Program) Grant 2012CB316302, the National Natural
   Science Foundation of China (NSFC) Grants 60825301 and 60933010, and the
   Royal Society of Edinburgh (UK) and the Chinese Academy of Sciences
   within the China-Scotland SIPRA (Signal Image Processing Research
   Academy) Programme. The authors would like to thank Jia-jun Zhang for
   his aid in the machine translation process.
CR [Anonymous], 2008, AAAI
   [Anonymous], P 5 INT C SPOK LANG
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   Bellegarda JR, 1998, IEEE T SPEECH AUDI P, V6, P456, DOI 10.1109/89.709671
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616.1376746.URLhttps]
   Cambria E., 2011, 2011 IEEE International Conference on Data Mining Workshops, P315, DOI 10.1109/ICDMW.2011.106
   Cambria E., 2012, AAAI, P186
   Cambria E., 2012, P 25 INT FLOR ART IN, P202
   Cambria E, 2012, COGN COMPUT, V4, P477, DOI 10.1007/s12559-012-9145-4
   Cambria E, 2012, EXPERT SYST APPL, V39, P10533, DOI 10.1016/j.eswa.2012.02.120
   Cambria E, 2012, MULTIMED TOOLS APPL, V59, P557, DOI 10.1007/s11042-011-0815-0
   Chen Stanley, 1998, EMPIRICAL STUDY SMOO
   Dai Ruwei, 2007, Frontiers of Computer Science in China, V1, P126, DOI 10.1007/s11704-007-002-5
   Goodman J. T., 2001, MSRTR200172
   Hussain A., 2012, SENTIC COMPUTING TEC, DOI 10.1007/978-94-007-5070-8
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881
   KUHN R, 1992, IEEE T PATTERN ANAL, V14, P691
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   Lenat Douglas B, 1989, BUILDING LARGE KNOWL
   Li NX, 2010, IEEE SYS MAN CYBERN, P3664, DOI 10.1109/ICSMC.2010.5641873
   Li YX, 2005, PATTERN ANAL APPL, V8, P272, DOI 10.1007/s10044-005-0009-3
   Lieberman H, 2004, AI MAG, V25, P63
   Lieberman H., 2005, P 10 INT C INTELLIGE, P278
   Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9
   Ming-Hung Hsu, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P651
   Mrva D., 2006, P INTERSPEECH, P2206
   Qiu-Feng Wang, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P110, DOI 10.1109/DAS.2012.46
   Qiu-Feng Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1036, DOI 10.1109/ICDAR.2009.96
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083
   Siu MH, 2000, IEEE T SPEECH AUDI P, V8, P63, DOI 10.1109/89.817454
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3679
   Stocky T., 2004, C HUM FACT COMP SYST, P1163
   Su TH, 2009, PATTERN RECOGN, V42, P167, DOI 10.1016/j.patcog.2008.05.012
   Tang HS, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P263
   Wang CH, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P539
   Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264
NR 40
TC 57
Z9 57
U1 0
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD JUN
PY 2013
VL 5
IS 2
BP 234
EP 242
DI 10.1007/s12559-012-9183-y
PG 9
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA 140IX
UT WOS:000318648900009
DA 2023-11-10
ER

PT J
AU Wang, ZK
   Zhu, HC
   Liu, M
   Qin, B
AF Wang, Zekun
   Zhu, Haichao
   Liu, Ming
   Qin, Bing
TI TAGNet: a tiny answer-guided network for conversational question
   generation
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Conversational Question Generation; Sequence-to-Sequence Model;
   Knowledge Distillation; Model Compression
AB Conversational Question Generation (CQG) aims to generate conversational questions with the given passage and conversa-tion history. Previous work of CQG presumes a contiguous span as the answer and generates a question targeting it. However, this limits the application scenarios because answers in practical conversations are usually abstractive free-form text instead of extractive spans. In addition, most state-of-the-art CQG systems are based on pretrained language models consisting of hundreds of millions of parameters, bringing challenges to real-life applications due to latency and capacity constraints. To elegantly address these problems, in this work, we introduce the Tiny Answer-Guided Network (TAGNET) based on the lightweight module (Bi-LSTM) for CQG. We explicitly take the target answers as input, which interacts with the passages and conversation history in the encoder and guides the question generation through the gated attention mechanism in the decoder. Besides, we distill the knowledge from larger pretrained language models into our smaller network to make the trade-off between performance and efficiency. Experimental results show that our TAGNET achieves a comparable perfor-mance with large pretrained language models (retaining 95.9% of teacher performance) while using 5.7x fewer parameters and 10.4x faster inference latency. TAGNET outperforms the previous best-performing model with similar parameter size by a large margin, and further analysis shows that TAGNET generates more answer-specific conversational questions.
C1 [Wang, Zekun; Zhu, Haichao; Liu, Ming; Qin, Bing] Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin, Peoples R China.
   [Liu, Ming; Qin, Bing] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; Peng Cheng Laboratory
RP Wang, ZK; Liu, M (通讯作者)，Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin, Peoples R China.; Liu, M (通讯作者)，Peng Cheng Lab, Shenzhen, Peoples R China.
EM mliu@ir.hit.edu.cn
OI Wang, Zekun/0000-0003-0151-5367
FU National Key Research and Development Project [2021YFF0901600]; National
   Science Foundation of China [U22B2059, 61976073, 62276083]; Shenzhen
   Foundational Research Funding [JCYJ20200109113441941]; Project of State
   Key Laboratory of Communication Content Cognition [A02101]; Major Key
   Project of PCL [PCL2021A06]
FX We thank anonymous reviewers for their insightful feedback that helped
   improve the paper. The research in this article is supported by the
   National Key Research and Development Project (2021YFF0901600), the
   National Science Foundation of China (U22B2059, 61976073, 62276083), and
   Shenzhen Foundational Research Funding (JCYJ20200109113441941),the
   Project of State Key Laboratory of Communication Content Cognition
   (A02101), the Major Key Project of PCL (PCL2021A06). Ming Liu is the
   corresponding author.
CR Ba J., 2014, ADV NEURAL INFORM PR, P2654
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bao H, 2021, ARXIV
   Bao HB, 2020, PR MACH LEARN RES, V119
   Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2174
   Cunningham J. P., 2007, ADV NEURAL INFORM PR, V20, P329
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong L, 2019, ADV NEUR IN, V32
   Du XY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1342, DOI 10.18653/v1/P17-1123
   Du XY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1907
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Gao YF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4853
   Gu J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2061
   Heilman M, 2010, HUMAN LANGUAGE TECHN, P609
   Hinton Geoffrey, 2015, ARXIV150302531
   Hochreiter S., 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/NECO.1997.9.8.1735
   Huang H.-Y., 2019, INT C LEARNING REPRE
   Jiao X, 2019, ARXIV
   Kim Y, 2019, AAAI CONF ARTIF INTE, P6602
   Kim Yoon, 2016, ARXIV160607947, DOI DOI 10.18653/V1
   Lai G., 2017, EMNLP, P785, DOI DOI 10.18653/V1/D17-1082
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Li J., 2020, CORR, P2642, DOI DOI 10.18653/V1/2020.COLING-MAIN.238
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, DOI DOI 10.2307/3105454
   Liu Yinhan, 2019, ARXIV190711692
   Nakanishi Mao, 2019, P 2 WORKSH MACH READ, P63, DOI DOI 10.18653/V1/D19-5809
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Pan BY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2114
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Puri R, 2020, ARXIV
   Qi P., 2020, ARXIV
   Raffel C, 2020, J MACH LEARN RES, V21
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Richardson M, 2013, P 2013 C EMPIRICAL M, P193
   Romero Adriana, 2015, ICLR
   Sanh V, 2019, ARXIV
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shleifer Sam, 2020, ARXIV
   Song L, 2018, P 2018 C N AM CHAP A, V2, P569
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun XW, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3930
   Tang D, 2017, ARXIV
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang W, 2020, ADV NEURAL INFORM PR, V33
   Wang YS, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2193
   Wang Z., 2021, ARXIV
   Welbl J., 2017, P 3 WORKSHOP NOISY U, P94, DOI [10.18653/v1/W17-4413, DOI 10.18653/V1/W17-4413]
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yuan X, 2017, P 2 WORKSH REPR LEAR, P15, DOI [10.18653/v1/w17-2603, DOI 10.18653/V1/W17-2603]
   Zagoruyko S, 2017, 5 INT C LEARN REPR I
   Zaheer M., 2020, ADV NEUR IN, V33
   Zhang SQ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P127
   Zhao Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3901
   Zhou QY, 2018, LECT NOTES ARTIF INT, V10619, P662, DOI 10.1007/978-3-319-73618-1_56
   Zhu HC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4238
NR 59
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD MAY
PY 2023
VL 14
IS 5
BP 1921
EP 1932
DI 10.1007/s13042-022-01737-x
EA DEC 2022
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E4QJ0
UT WOS:000900811200001
DA 2023-11-10
ER

PT J
AU Pataranutaporn, P
   Liu, R
   Finn, E
   Maes, P
AF Pataranutaporn, Pat
   Liu, Ruby
   Finn, Ed
   Maes, Pattie
TI Influencing human-AI interaction by priming beliefs about AI can
   increase perceived trustworthiness, empathy and effectiveness
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article; Early Access
ID ARTIFICIAL-INTELLIGENCE; PLACEBO; PROGRAM
AB As conversational agents powered by large language models become more human-like, users are starting to view them as companions rather than mere assistants. Our study explores how changes to a person's mental model of an AI system affects their interaction with the system. Participants interacted with the same conversational AI, but were influenced by different priming statements regarding the AI's inner motives: caring, manipulative or no motives. Here we show that those who perceived a caring motive for the AI also perceived it as more trustworthy, empathetic and better-performing, and that the effects of priming and initial mental models were stronger for a more sophisticated AI model. Our work also indicates a feedback loop in which the user and AI reinforce the user's mental model over a short time; further work should investigate long-term effects. The research highlights the importance of how AI systems are introduced can notably affect the interaction and how the AI is experienced.
   The recent accessibility of large language models brought them into contact with a large number of users and, due to the social nature of language, it is hard to avoid prescribing human characteristics such as intentions to a chatbot. Pataranutaporn and colleagues investigated how framing a bot as helpful or manipulative can influence this perception and the behaviour of the humans that interact with it.
C1 [Pataranutaporn, Pat; Liu, Ruby; Maes, Pattie] MIT, Media Lab, Cambridge, MA 02139 USA.
   [Liu, Ruby] MIT, Harvard MIT Hlth Sci & Technol, Cambridge, MA 02139 USA.
   [Finn, Ed] Arizona State Univ, Ctr Sci & Imaginat, Tempe, AZ USA.
C3 Massachusetts Institute of Technology (MIT); Harvard University;
   Massachusetts Institute of Technology (MIT); Arizona State University;
   Arizona State University-Tempe
RP Pataranutaporn, P; Liu, R (通讯作者)，MIT, Media Lab, Cambridge, MA 02139 USA.; Liu, R (通讯作者)，MIT, Harvard MIT Hlth Sci & Technol, Cambridge, MA 02139 USA.
EM patpat@mit.edu; rliu34@media.mit.edu
FU Our paper benefited greatly from the valuable feedback provided by the
   reviewers, and we extend our gratitude for their contribution. We thank
   J. Liu, data science specialist at the Institute for Quantitative Social
   Science, Harvard University, for reviewi; MIT Media Lab; Harvard-MIT
   Health Sciences and Technology; Accenture
FX Our paper benefited greatly from the valuable feedback provided by the
   reviewers, and we extend our gratitude for their contribution. We thank
   J. Liu, data science specialist at the Institute for Quantitative Social
   Science, Harvard University, for reviewing our statistical analysis. We
   would like to thank M. Groh, Z. Epstein, N. Whitmore, S. Chan, Z. Yan
   and the MIT Media Lab Fluid Interfaces group members for reviewing and
   giving constructive feedback on our paper. We would like to thank MIT
   Media Lab and KBTG for supporting P. Pataranutaporn, and the Harvard-MIT
   Health Sciences and Technology, and Accenture for supporting R.L.
CR Adamopoulou E., 2020, MACHINE LEARNING APP, V2, DOI 10.1016/j.mlwa.2020.100006
   [Anonymous], 2021, GPT 3 POWERS NEXT GE
   [Anonymous], 2004, DESIGNING SOCIABLE R
   Aylett M. P., 2019, 2019 CHI C HUM FACT, P1
   Balch O., 2020, THE GUARDIAN 0507
   Bansal G., 2019, P AAAI C HUM COMP CR, V7, P2, DOI DOI 10.1609/HCOMP.V7I1.5285
   Bavaresco R, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100239
   Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Bingaman J, 2021, SCI COMMUN, V43, P388, DOI 10.1177/1075547021998069
   Birkhäuer J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170988
   Bower AH, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-00426-z
   Brandtzaeg PB, 2022, HUM COMMUN RES, V48, P404, DOI 10.1093/hcr/hqac008
   Brown T., 2020, C NEUR INF PROC SYST
   Castro-González A, 2016, INT J HUM-COMPUT ST, V90, P27, DOI 10.1016/j.ijhcs.2016.02.004
   Cave S., 2020, AI NARRATIVES HIST I
   Cave S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P331, DOI 10.1145/3306618.3314232
   Cave S, 2019, NAT MACH INTELL, V1, P74, DOI 10.1038/s42256-019-0020-9
   Cho M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1557, DOI 10.1145/3322276.3322332
   Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]
   Chubb J, 2022, AI SOC, DOI 10.1007/s00146-022-01548-2
   Colagiuri B, 2015, NEUROSCIENCE, V307, P171, DOI 10.1016/j.neuroscience.2015.08.017
   Croes EAJ, 2021, J SOC PERS RELAT, V38, P279, DOI 10.1177/0265407520959463
   Danry V, 2022, PROCEEDINGS OF AUGMENTED HUMANS CONFERENCE 2022 (AHS 2022), P68, DOI 10.1145/3519391.3519414
   de Vignemont F, 2006, TRENDS COGN SCI, V10, P435, DOI 10.1016/j.tics.2006.08.008
   Denisova A., 2015, P 2015 ANN S COMP HU, P23, DOI 10.1145/2793107.2793109
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ehret J, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3486580
   Ekström AG, 2022, COMPUT HUM BEHAV REP, V7, DOI 10.1016/j.chbr.2022.100226
   Epstein Z, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101515
   Evers AWM, 2018, PSYCHOTHER PSYCHOSOM, V87, P204, DOI 10.1159/000490354
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Finn E., 2017, WHAT ALGORITHMS WANT
   Finn E, 2021, FUTURES, V132, DOI 10.1016/j.futures.2021.102788
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Friedrich A, 2015, CONTEMP EDUC PSYCHOL, V41, P1, DOI 10.1016/j.cedpsych.2014.10.006
   Gero KI, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376316
   Gill KS, 2018, AI SOC, V33, P459, DOI 10.1007/s00146-018-0866-0
   Groh M, 2022, INT CONF AFFECT, DOI 10.1109/ACII55700.2022.9953869
   Harrington A., 2006, BIOSOCIETIES, V1, P181, DOI [10.1017/S1745855206050216, DOI 10.1017/S1745855206050216]
   Harrington A., 1999, PLACEBO EFFECT INTER, V8
   Hildt E, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01535
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391
   Hudson AD, 2023, AI SOC, V38, P197, DOI 10.1007/s00146-021-01273-2
   Hutto C.J., 2014, ICWSM, DOI DOI 10.1609/ICWSM.V8I1.14550
   Hwang A. H.-C., 2022, CHI C HUM FACT COMP, P1
   Jasanoff S., 2015, DREAMSCAPES MODERNIT, DOI [10.7208/chicago/9780226276663.003.0001, DOI 10.7208/CHICAGO/9780226276663.001.0001]
   Jeong S, 2023, USER MODEL USER-ADAP, V33, P571, DOI 10.1007/s11257-022-09337-8
   Johnson-Laird P. N., 1983, MENTAL MODELS COGNIT
   KIERAS DE, 1984, COGNITIVE SCI, V8, P255, DOI 10.1016/S0364-0213(84)80003-8
   Kim H., 2019, 2019 CHI C HUM FACT, P1
   Kim Y., 2021, P 2021 CHI C HUM FAC, P1
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Koda T, 1996, RO-MAN '96 - 5TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P189, DOI 10.1109/ROMAN.1996.568812
   Komatsu T., 2008, CHI 08 HUM FACT COMP, P2919
   Kosch T, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3529225
   Kounev Samuel, 2017, SELFAWARE COMPUTING, P3, DOI [10.1007/978-3-319-47474-8_1, DOI 10.1007/978-3-319-47474-81]
   Kraus M, 2020, UMAP'20: PROCEEDINGS OF THE 28TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P107, DOI 10.1145/3340631.3394840
   Kulesza Todd, 2012, P SIGCHI C HUM FACT, P1, DOI 10.1145/2207676.2207678
   Leibowitz KA, 2019, HEALTH PSYCHOL, V38, P613, DOI 10.1037/hea0000751
   Lewis JR, 2015, INT J SPEECH TECHNOL, V18, P479, DOI 10.1007/s10772-015-9289-1
   Li DJ, 2010, INT J SOC ROBOT, V2, P175, DOI 10.1007/s12369-010-0056-9
   Martinez E, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.788355
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Mueller S.T., 2019, ARXIV
   Natale S, 2019, NEW MEDIA SOC, V21, P712, DOI 10.1177/1461444818804980
   Nickerson R. S., 1998, REV GEN PSYCHOL, V2, P175
   Norman Donald A, 2014, MENTAL MODELS, P15, DOI 10.5555/58076.58097
   Paetzel M, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P522, DOI 10.1145/2993148.2997612
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Paradeda RB, 2016, LECT NOTES ARTIF INT, V9979, P169, DOI 10.1007/978-3-319-47437-3_17
   Pataranutaporn P, 2021, NAT MACH INTELL, V3, P1013, DOI 10.1038/s42256-021-00417-9
   Pi ZL, 2022, J COMPUT ASSIST LEAR, V38, P1703, DOI 10.1111/jcal.12704
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1, DOI 10.1017/S0140525X02000018
   Reeves Byron, 1996, MEDIA EQUATION PEOPL, V10
   Rosenthal R., 2002, IMPROVING ACAD ACHIE, P25
   Rutjes H., 2019, CHI 2019 WORKSH IS H
   Schepman A, 2020, COMPUT HUM BEHAV REP, V1, DOI 10.1016/j.chbr.2020.100014
   Seaborn K., 2021, 2021 CHI C HUM FACT, P1
   Seaborn K, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3386867
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Song SC, 2017, ACMIEEE INT CONF HUM, P2, DOI 10.1145/2909824.3020239
   Ta V, 2020, J MED INTERNET RES, V22, DOI 10.2196/16235
   Thoppilan R., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.08239
   Touvron H, 2023, Arxiv, DOI arXiv:2307.09288
   van den Brule R, 2014, INT J SOC ROBOT, V6, P519, DOI 10.1007/s12369-014-0231-5
   Vaswani A., 2017, ARXIV, V30, P5998
   Volkel S. T., 2021, P 2021 CHI C HUM FAC, P1
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Winkler R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376781
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Xu Y., 2022, CHI C HUM FACT COMP, P1
   Yalcin ÖN, 2018, BIOL INSPIR COGN ARC, V26, P20, DOI 10.1016/j.bica.2018.07.010
   Yampolskiy R. V., 2016, WORKSH 30 AAAI C ART
   Zlotowski J., 2016, PALADYN, V7, p55
   2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 95
TC 0
Z9 0
U1 23
U2 23
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD 2023 OCT 2
PY 2023
DI 10.1038/s42256-023-00720-7
EA OCT 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S8NE6
UT WOS:001073673100001
DA 2023-11-10
ER

PT J
AU Ding, N
   Qin, YJ
   Yang, G
   Wei, FC
   Yang, ZH
   Su, YS
   Hu, SD
   Chen, YL
   Chan, CM
   Chen, WZ
   Yi, J
   Zhao, WL
   Wang, XZ
   Liu, ZY
   Zheng, HT
   Chen, JF
   Liu, Y
   Tang, J
   Li, JZ
   Sun, MS
AF Ding, Ning
   Qin, Yujia
   Yang, Guang
   Wei, Fuchao
   Yang, Zonghan
   Su, Yusheng
   Hu, Shengding
   Chen, Yulin
   Chan, Chi-Min
   Chen, Weize
   Yi, Jing
   Zhao, Weilin
   Wang, Xiaozhi
   Liu, Zhiyuan
   Zheng, Hai-Tao
   Chen, Jianfei
   Liu, Yang
   Tang, Jie
   Li, Juanzi
   Sun, Maosong
TI Parameter-efficient fine-tuning of large-scale pre-trained language
   models
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
AB With the prevalence of pre-trained language models (PLMs) and the pre-training-fine-tuning paradigm, it has been continuously shown that larger models tend to yield better performance. However, as PLMs scale up, fine-tuning and storing all the parameters is prohibitively costly and eventually becomes practically infeasible. This necessitates a new branch of research focusing on the parameter-efficient adaptation of PLMs, which optimizes a small portion of the model parameters while keeping the rest fixed, drastically cutting down computation and storage costs. In general, it demonstrates that large-scale models could be effectively stimulated by the optimization of a few parameters. Despite the various designs, here we discuss and analyse the approaches under a more consistent and accessible term 'delta-tuning', where 'delta' a mathematical notation often used to denote changes, is borrowed to refer to the portion of parameters that are 'changed' during training. We formally describe the problem and propose a unified categorization criterion for existing delta-tuning methods to explore their correlations and differences. We also discuss the theoretical principles underlying the effectiveness of delta-tuning and interpret them from the perspectives of optimization and optimal control. Furthermore, we provide a holistic empirical study on over 100 natural language processing tasks and investigate various aspects of delta-tuning. With comprehensive study and analysis, our research demonstrates the theoretical and practical properties of delta-tuning in the adaptation of PLMs.
   Training a deep neural network can be costly but training time is reduced when a pre-trained network can be adapted to different use cases. Ideally, only a small number of parameters needs to be changed in this process of fine-tuning, which can then be more easily distributed. In this Analysis, different methods of fine-tuning with only a small number of parameters are compared on a large set of natural language processing tasks.
C1 [Ding, Ning; Qin, Yujia; Yang, Guang; Wei, Fuchao; Yang, Zonghan; Su, Yusheng; Hu, Shengding; Chan, Chi-Min; Chen, Weize; Yi, Jing; Zhao, Weilin; Wang, Xiaozhi; Liu, Zhiyuan; Chen, Jianfei; Liu, Yang; Tang, Jie; Li, Juanzi; Sun, Maosong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Ding, Ning; Qin, Yujia; Su, Yusheng; Hu, Shengding; Chen, Weize; Yi, Jing; Zhao, Weilin; Liu, Zhiyuan; Tang, Jie; Sun, Maosong] Beijing Acad Artificial Intelligence, Beijing, Peoples R China.
   [Chen, Yulin; Zheng, Hai-Tao] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Liu, ZY; Sun, MS (通讯作者)，Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.; Liu, ZY; Sun, MS (通讯作者)，Beijing Acad Artificial Intelligence, Beijing, Peoples R China.; Zheng, HT (通讯作者)，Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.
EM liuzy@tsinghua.edu.cn; zheng.haitao@sz.tsinghua.edu.cn;
   sms@tsinghua.edu.cn
RI Su, Yusheng/ITU-1189-2023; Wang, Xiaozhi/IQT-4844-2023
OI Ning, Ding/0000-0001-8758-9484
FU National Key Research and Development Program of China [2020AAA0106500];
   National Natural Science Foundation of China [62276154, 62011540405];
   Beijing Academy of Artificial Intelligence (BAAI) and the Institute for
   Guo Qiang at Tsinghua University
FX This work is supported by the National Key Research and Development
   Program of China (No. 2020AAA0106500), National Natural Science
   Foundation of China (No. 62276154 and No. 62011540405), Beijing Academy
   of Artificial Intelligence (BAAI) and the Institute for Guo Qiang at
   Tsinghua University. We thank J. He, P. Liu, T. Sun, C., L. Wang, C.
   Fang, X. Han and R. Shao for their suggestions and help with the paper.
CR Ang KH, 2005, IEEE T CONTR SYST T, V13, P559, DOI 10.1109/TCST.2005.847331
   Armen Aghajanyan, 2021, PROC ACLIJCNLP, V1, P7319
   Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Boyd S., 1991, LINEAR CONTROLLER DE
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P105
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8410
   Guo DM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4884
   Han WJ, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P854
   Han X., 2021, OPEN, V2, P225, DOI [10.1016/j.aiopen.2021.08.002, DOI 10.1016/J.AIOPEN.2021.08.002]
   He J., 2022, INT C LEARN REPR
   He RD, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2208
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Hu Edward J., 2022, INT C LEARNING REPRE
   Hu SD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2225
   Karimi Mahabadi R., 2021, ADV NEURAL INFORM PR, P1022
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J., 2019, WHAT WOULD ELSA DO F
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045
   Lhoest Q, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P175
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815
   Liu R, 2018, INT C LEARNING REPRE
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61
   Liu X, 2021, CSIAM T APPL MATH, V2, P585, DOI 10.4208/csiam-am.SO-2021-0016
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Mahabadi RK, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P565
   Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P487
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46
   Qin YJ, 2022, Arxiv, DOI arXiv:2110.07867
   Radford A., 2019, LANGUAGE MODELS ARE
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Rücklé A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7930
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255
   Smith Shaden, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.11990
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Stickland AC, 2019, PR MACH LEARN RES, V97
   Su YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3949
   Vaswani A, 2017, ADV NEUR IN, V30
   Vu T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5039
   Rae JW, 2022, Arxiv, DOI [arXiv:2112.11446, DOI 10.48550/ARXIV.2112.11446]
   Wang A., 2019, INT C LEARNING REPRE
   Williams A., 2018, P C N AM CHAPT ASS C, V1, P1112, DOI DOI 10.18653/V1/N18-1101
   Yang Z., 2022, SIGIR 17 P 40 INT AC
   Yang ZH, 2023, Arxiv, DOI arXiv:2210.04492
   Zhao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2226
NR 52
TC 4
Z9 4
U1 34
U2 39
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD MAR
PY 2023
VL 5
IS 3
BP 220
EP +
DI 10.1038/s42256-023-00626-4
EA MAR 2023
PG 25
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9Z6JS
UT WOS:000942663300002
OA hybrid, Green Submitted
DA 2023-11-10
ER

PT J
AU Karpathy, A
   Li, FF
AF Karpathy, Andrej
   Li Fei-Fei
TI Deep Visual-Semantic Alignments for Generating Image Descriptions
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Image captioning; deep neural networks; visual-semantic embeddings;
   recurrent neural network; language model
AB We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks (RNN) over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions outperform retrieval baselines on both full images and on a new dataset of region-level annotations. Finally, we conduct large-scale analysis of our RNN language model on the Visual Genome dataset of 4.1 million captions and highlight the differences between image and region-level caption statistics.
C1 [Karpathy, Andrej; Li Fei-Fei] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
C3 Stanford University
RP Karpathy, A (通讯作者)，Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM karpathy@cs.stanford.edu; feifeili@cs.stanford.edu
RI 李, 飞飞/AFJ-9437-2022
OI 李, 飞飞/0000-0001-5629-267X
FU NVIDIA Corporation; ONR MURI grant; US National Science Foundation
   [ISS-1115313]
FX We thank Justin Johnson and Jon Krause for helpful comments and
   discussions. We gratefully acknowledge the support of NVIDIA Corporation
   with the donation of the GPUs used for this research. We would also like
   to thank the maintainers of Torch 7, and especially Soumith Chintala for
   his support. This research is partially supported by an ONR MURI grant,
   and US National Science Foundation ISS-1115313.
CR [Anonymous], 2012, INT C MACHINE LEARNI
   [Anonymous], 2015, ARXIV150504467
   [Anonymous], 2014, EXPLAIN IMAGES MULTI
   Barbu A., 2012, P C UNCERTAINTY ARTI, P102
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Berg TL, 2004, PROC CVPR IEEE, P848
   Chen X., 2014, CORR
   Chen Xinlei, 2015, ARXIV150400325
   Collobert R., 2011, P BIG LEARN ADV NEUR, P1681
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denkowski M., 2014, P 9 WORKSH STAT MATH, P67
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Elliott D, 2013, P 2013 C EMP METH NA, P1292
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fei-Fei L, 2007, J VISION, V7, DOI 10.1167/7.1.10
   Fidler S, 2013, PROC CVPR IEEE, P1995, DOI 10.1109/CVPR.2013.260
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Girshick R., P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2014.81
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gupta A., 2012, NEURAL INFORM PROCES
   Hodosh M., 2014, P TACL, V7, P67, DOI [10.1162/tacl_a_00166, DOI 10.1162/TACL_A_00166]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Karpathy A., 2014, ADV NEURAL INFORM PR, V27, P1889
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Kuznetsova P., 2014, J T ASS COMPUT LINGU, V2, P351, DOI [10.1162/tacl_a_00188, DOI 10.1162/TACL_A_00188]
   Kuznetsova P., 2012, P 50 ANN M ASS COMP, P359
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Li S., 2011, P C COMP NAT LANG LE, P220
   Lin DH, 2014, PROC CVPR IEEE, P2657, DOI 10.1109/CVPR.2014.340
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112
   Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI [DOI 10.1162/TACL_A_00177, 10.1162/tacl_a_00177]
   Sutskever I, 2011, ICML
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26
   VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Yang Y., 2011, P C EMP METH NAT LAN, P444, DOI DOI 10.5555/2145432.2145484
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Yatskar M, 2014, P 3 JOINT C LEX COMP, P110
   Zhang W., 1999, STATE SPACE SEARCH A
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
   Zitnick C.L., 2014, ARXIV PREPRINT ARXIV
   Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211
NR 66
TC 199
Z9 222
U1 11
U2 179
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD APR
PY 2017
VL 39
IS 4
BP 664
EP 676
DI 10.1109/TPAMI.2016.2598339
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP9UD
UT WOS:000397717600005
PM 27514036
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Sidig, AAI
   Luqman, H
   Mahmoud, S
   Mohandes, M
AF Sidig, Ala Addin, I
   Luqman, Hamzah
   Mahmoud, Sabri
   Mohandes, Mohamed
TI KArSL: Arabic Sign Language Database
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Arabic sign language database; sign language recognition; sign language
   translation; gesture recognition; human computer interaction; HMM
ID GESTURE RECOGNITION
AB Sign language is the major means of communication for the deaf community. It uses body language and gestures such as hand shapes, lib patterns, and facial expressions to convey a message. Sign language is geography-specific, as it differs from one country to another. Arabic Sign language is used in all Arab countries. The availability of a comprehensive benchmarking database for ArSL is one of the challenges of the automatic recognition of Arabic Sign language. This article introduces KArSL database for ArSL, consisting of 502 signs that cover 11 chapters of ArSL dictionary. Signs in KArSL database are performed by three professional signers, and each sign is repeated 50 times by each signer. The database is recorded using state-of-art multi-modal Microsoft Kinect V2. We also propose three approaches for sign language recognition using this database. The proposed systems are Hidden Markov Models, deep learning images' classification model applied on an image composed of shots of the video of the sign, and attention-based deep learning captioning system. Recognition accuracies of these systems indicate their suitability for such a large number of Arabic signs. The techniques are also tested on a publicly available database. KArSL database will be made freely available for interested researchers.
C1 [Sidig, Ala Addin, I; Luqman, Hamzah; Mahmoud, Sabri; Mohandes, Mohamed] King Fahd Univ Petr & Minerals, Dhahran 31261, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP Sidig, AAI (通讯作者)，King Fahd Univ Petr & Minerals, Dhahran 31261, Saudi Arabia.
EM alasidig@kfupm.edu.sa; hluqman@kfupm.edu.sa; smasaad@kfupm.edu.sa;
   mohandes@kfupm.edu.sa
RI Luqman, Hamzah/AAR-9702-2021
FU King Fahd University of Petroleum and Minerals (KFUPM) [IN151008]
FX The authors acknowledge the support provided by King Fahd University of
   Petroleum and Minerals (KFUPM) for funding this work through project
   number IN151008.
CR Abadi M, 2016, TECH REP
   Ahmed A.A.W., 2014, EUROPEAN WIRELESS C, P1
   Al-Fityani Kinda, 2010, SIGN LANGUAGES CAMBR, P433, DOI [10.1017/CBO9780511712203.020, DOI 10.1017/CBO9780511712203.020]
   Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   AL-Rousan M, 2009, APPL SOFT COMPUT, V9, P990, DOI 10.1016/j.asoc.2009.01.002
   Ali A., 2016, P 5 INT C INF COMM T, P1, DOI [10.1109/ICTA.2015.7426902., DOI 10.1109/ICTA.2015.7426902]
   Almasre MA, 2016, COMPUT SCI ELECTR, P146, DOI 10.1109/CEEC.2016.7835904
   Aly S, 2014, COMM COM INF SC, V488, P36
   Alyl S, 2016, ICENCO 2016 - 2016 12TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO) - BOUNDLESS SMART SOCIETIES, P99, DOI 10.1109/ICENCO.2016.7856452
   Amin O, 2015, 2015 TENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P389, DOI 10.1109/ICCES.2015.7393081
   [Anonymous], 2008, THESIS DUBLIN CITY U
   [Anonymous], 2012, INT C COMMUNICATIONS
   [Anonymous], 2011, INT J ADV COMPUT SCI
   [Anonymous], 2011, P 2 WORKSHOP SPEECH
   Arab League Educational Cultural and Scientific Organization, 2006, 2 PART UN AR SIGN LA
   Arab League Educational Cultural and Scientific Organization, 2000, LAS 1 PART UN AR SIG
   Assaleh K, 2005, EURASIP J APPL SIG P, V2005, P2136, DOI 10.1155/ASP.2005.2136
   Assaleh K., 2008, P 5 INT S MECH APPL, P1
   Aujeszky T, 2016, MULTIMED TOOLS APPL, V75, P8493, DOI 10.1007/s11042-015-2767-2
   Barczak ALC, 2011, RES LETT INF MATH SC, V15, P12
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Crasborn Onno, 2007, INT J CORPUS LINGUIS, V12, P535
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DREUW P, 2007, HAND, V60, P80
   ElBadawy M, 2015, ADV INTELL SYST, V323, P721, DOI 10.1007/978-3-319-11310-4_63
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   Filhol M, 2016, UNIVERSAL ACCESS INF, V15, P487, DOI 10.1007/s10209-015-0413-4
   Gkigkelos Nikolaos., 2017, P 21 PAN HELL C INF, P1
   Guesmi F, 2016, IEEE SYS MAN CYBERN, P3561, DOI 10.1109/SMC.2016.7844785
   Hamed A, 2016, INT CONF ADV COMPU, P451, DOI 10.1109/IACC.2016.90
   Hassan M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P852, DOI [10.1109/CSCI.2016.164, 10.1109/CSCI.2016.0165]
   Hirafuji Neiva Davi, 2018, Expert Systems with Applications, V103, P159, DOI 10.1016/j.eswa.2018.01.051
   Kadous MohammedWaleed, 2002, THESIS U NEW S WAL
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Luqman H, 2019, UNIVERSAL ACCESS INF, V18, P939, DOI 10.1007/s10209-018-0622-8
   Mohammadzaheri Morteza, 2007, 2007 Information, Decision and Control, P272, DOI 10.1109/IDC.2007.374562
   Mohandes M, 2005, ISSPA 2005: The 8th International Symposium on Signal Processing and its Applications, Vols 1 and 2, Proceedings, P86
   Mohandes M, 2014, PROC IEEE INT SYMP, P960, DOI 10.1109/ISIE.2014.6864742
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Mohandes M, 2012, COMPUT ELECTR ENG, V38, P422, DOI 10.1016/j.compeleceng.2011.10.013
   Mohandes M., 2004, Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications (IEEE Cat. No.04EX852), P479, DOI 10.1109/ICTTA.2004.1307840
   Mohandes M, 2001, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II, P753
   Mohandes M, 2013, 2013 COMPUTING, COMMUNICATIONS AND IT APPLICATIONS CONFERENCE (COMCOMAP), P90, DOI 10.1109/ComComAp.2013.6533615
   Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   SamirElons A, 2013, IET IMAGE PROCESS, V7, P829, DOI 10.1049/iet-ipr.2012.0222
   Shanableh T, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P597
   Shanableh T, 2007, IEEE T SYST MAN CY B, V37, P641, DOI 10.1109/TSMCB.2006.889630
   Shohieb SM, 2015, J KING SAUD UNIV-COM, V27, P68, DOI 10.1016/j.jksuci.2014.03.011
   Sidig AAI, 2018, INT J ADV COMPUT SC, V9, P283
   Sidig Ala addin I., 2018, ARABIC SIGN LANGUAGE, P297
   Soodtoetong N, 2018, 2018 15TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P70, DOI 10.1109/ECTICon.2018.8619984
   Sun C, 2013, IEEE T CYBERNETICS, V43, P1418, DOI 10.1109/TCYB.2013.2265337
   Tolba MF, 2013, NEURAL COMPUT APPL, V23, P999, DOI 10.1007/s00521-012-1024-0
   Tolba M. F., 2012, P 8 INT C INF SYST I
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Von Agris U., 2007, P GEST HUM COMP INT
   Wan Khairunizam, P INT C MAN MACH SYS
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zahedi M., 2006, LREC WORKSH REPR PRO, P21
   Zahedi Morteza, 2005, INT GESTURE WORKSHOP, P68
   Zaki MM, 2011, PATTERN RECOGN LETT, V32, P572, DOI 10.1016/j.patrec.2010.11.013
NR 63
TC 15
Z9 15
U1 0
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR
PY 2021
VL 20
IS 1
AR 19
DI 10.1145/3423420
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RO2RN
UT WOS:000640893600018
DA 2023-11-10
ER

PT J
AU Mubarak, H
   Hassan, S
   Chowdhury, SA
AF Mubarak, Hamdy
   Hassan, Sabit
   Chowdhury, Shammur Absar
TI Emojis as anchors to detect Arabic offensive language and hate speech
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Offensive language; Hate speech; Emojis; Text classification; Social
   media analysis
AB We introduce a generic, language-independent method to collect a large percentage of offensive and hate tweets regardless of their topics or genres. We harness the extralinguistic information embedded in the emojis to collect a large number of offensive tweets. We apply the proposed method on Arabic tweets and compare it with English tweets-analyzing key cultural differences. We observed a constant usage of these emojis to represent offensiveness throughout different timespans on Twitter. We manually annotate and publicly release the largest Arabic dataset for offensive, fine-grained hate speech, vulgar, and violence content. Furthermore, we benchmark the dataset for detecting offensiveness and hate speech using different transformer architectures and perform in-depth linguistic analysis. We evaluate our models on external datasets-a Twitter dataset collected using a completely different method, and a multi-platform dataset containing comments from Twitter, YouTube, and Facebook, for assessing generalization capability. Competitive results on these datasets suggest that the data collected using our method capture universal characteristics of offensive language. Our findings also highlight the common words used in offensive communications, common targets for hate speech, specific patterns in violence tweets, and pinpoint common classification errors that can be attributed to limitations of NLP models. We observe that even state-of-the-art transformer models may fail to take into account culture, background, and context or understand nuances present in real-world data such as sarcasm.
C1 [Mubarak, Hamdy; Chowdhury, Shammur Absar] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
   [Hassan, Sabit] Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA USA.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar
   Computing Research Institute; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); University of Pittsburgh
RP Mubarak, H (通讯作者)，Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
EM hmubarak@hbku.edu.qa
OI Chowdhury, Shammur Absar/0000-0002-1331-2543
CR Abdelali A., 2021, P 6 ARABIC NATURAL L, P1
   Abdelali A., 2021, CORR
   Alami H., 2020, P 14 WORKSHOP SEMANT, P2080
   Albadi N, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P69, DOI 10.1109/ASONAM.2018.8508247
   Alhazbi S, 2020, IEEE ACCESS, V8, P195132, DOI 10.1109/ACCESS.2020.3033666
   Alshalan R., 2020, P 5 ARABIC NATURAL L, V10, P12
   Alshehri A., 2018, TA COS 2018 2 WORKSH, P15
   Antoun W., 2020, P 4 WORKSHOP OPEN SO, P9
   Belcastro L, 2020, IEEE ACCESS, V8, P47177, DOI 10.1109/ACCESS.2020.2978950
   Cheng HQ, 2015, IEEE T KNOWL DATA EN, V27, P1045, DOI 10.1109/TKDE.2014.2357012
   Chowdhury SA, 2020, P 5 ARABIC NATURAL L, P226
   Chowdhury SA, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6203
   Conneau A, 2019, ARXIV
   Conover M., 2011, P INT AAAI C WEB SOC, V5, P89, DOI [10.1609/icwsm.v5i1.14126, DOI 10.1609/ICWSM.V5I1.14126]
   Darwish K, 2017, P 9 INT C SOC INF SO, P91
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dimitrov D., 2021, P JOINT C 59 ANN M A
   Dimitrov D., 2021, P 15 INT WORKSH SEM, V21
   Donato G., 2017, P 8 WORKSH COMP APPR, P118
   Durscheid C., 2017, KURZFASSUNG AUF DEUT
   Gülaçti F, 2010, PROCD SOC BEHV, V2, P3844, DOI 10.1016/j.sbspro.2010.03.602
   Hassan S., 2020, P 14 WORKSHOP SEMANT, P1891
   Hassan S, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P113
   Husain F., 2020, OSACT, V4
   Intapong P, 2017, LECT NOTES COMPUT SC, V10282, P71, DOI 10.1007/978-3-319-58559-8_7
   Kiela D, 2021, Arxiv, DOI arXiv:2005.04790
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Ling L., 2023, ARXIV, DOI DOI 10.1214/20-BA1223
   Mei QZ, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P417, DOI 10.1145/3308560.3316541
   Mubarak Hamdy, 2020, Social Informatics. 12th International Conference, SocInfo 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12467), P237, DOI 10.1007/978-3-030-60975-7_18
   Mubarak H., 2020, P 4 WORKSHOP OPEN SO
   Mubarak H., 2016, WEAVING RELATIONS TR
   Mubarak H., 2014, P EMNLP 2014 WORKSHO, P1
   Mubarak H., 2021, P 6 ARABIC NATURAL L, P136
   Mubarak H, 2017, P 1 WORKSHOP ABUSIVE, DOI 10.18653/v1/W17-3008
   Mubarak H, 2021, Arxiv, DOI arXiv:2004.02192
   Nakov P, 2021, Arxiv, DOI arXiv:2103.00153
   Ousidhoum N, 2019, Arxiv, DOI arXiv:1908.11049
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Polignano M., 2019, CEUR WORKSHOP PROC, VVolume 2481, P1
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Salminen J, 2020, HUM-CENTRIC COMPUT I, V10, DOI 10.1186/s13673-019-0205-6
   Shaar S., 2021, ARXIV
   Waldron J., 2012, HARM HATE SPEECH
   Wiegand M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P369
   Zampieri M., 2020, P SEMEVAL
NR 47
TC 0
Z9 0
U1 1
U2 1
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD 2023 AUG 10
PY 2023
AR PII S1351324923000402
DI 10.1017/S1351324923000402
EA AUG 2023
PG 22
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA O6FS2
UT WOS:001044750000001
OA Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Chen, Z
   Liu, YC
   Chen, L
   Zhu, S
   Wu, MY
   Yu, K
AF Chen, Zhi
   Liu, Yuncong
   Chen, Lu
   Zhu, Su
   Wu, Mengyue
   Yu, Kai
TI OPAL: Ontology-Aware Pretrained Language Model for End-to-End
   Task-Oriented Dialogue
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper presents an ontology-aware pretrained language model (OPAL) for end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models, task-oriented dialogue models fulfill at least two task-specific modules: Dialogue state tracker (DST) and response generator (RG). The dialogue state consists of the domain-slot-value triples, which are regarded as the user's constraints to search the domain-related databases. The large-scale task-oriented dialogue data with the annotated structured dialogue state usually are inaccessible. It prevents the development of the pretrained language model for the task-oriented dialogue. We propose a simple yet effective pretraining method to alleviate this problem, which consists of two pretraining phases. The first phase is to pretrain on large-scale contextual text data, where the structured information of the text is extracted by the information extracting tool. To bridge the gap between the pretraining method and downstream tasks, we design two pretraining tasks: ontology-like triple recovery and next-text generation, which simulates the DST and RG, respectively. The second phase is to fine-tune the pretrained model on the TOD data. The experimental results show that our proposed method achieves an exciting boost and obtains competitive performance even without any TOD data on CamRest676 and MultiWOZ benchmarks.
C1 [Chen, Zhi; Liu, Yuncong; Chen, Lu; Wu, Mengyue; Yu, Kai] Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, X LANCE Lab,MoE Key Lab Artificial Intelligence,St, Beijing, Peoples R China.
   [Zhu, Su] AISpeech Co Ltd, Suzhou, Peoples R China.
C3 Shanghai Jiao Tong University
RP Chen, L; Yu, K (通讯作者)，Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, X LANCE Lab,MoE Key Lab Artificial Intelligence,St, Beijing, Peoples R China.
EM zhenchi713@sjtu.edu.cn; chenlusz@sjtu.edu.cn; kai.yu@sjtu.edu.cn
FU China NSFC Projects [62106142, 92048205]; Shanghai Municipal Science and
   Technology Major Project [2021SHZDZX0102]; CCF-Tencent Open Fund;
   Startup Fund for Youngman Research at SJTU
FX We would like to thank the TACL team and four anonymous reviewers for
   their insightful comments. This work has been supported by China NSFC
   Projects (No.62120106006, No.62106142, and No.92048205), Shanghai
   Municipal Science and Technology Major Project (2021SHZDZX0102), and
   CCF-Tencent Open Fund and Startup Fund for Youngman Research at SJTU
   (SFYR at SJTU).
CR Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977
   Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   Balaraman V, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P830, DOI [10.1109/asru46091.2019.9003911, 10.1109/ASRU46091.2019.9003911]
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P85
   Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5016
   Byrne B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4516
   Chen L, 2020, AAAI CONF ARTIF INTE, V34, P7521
   Chen L, 2019, IEEE-ACM T AUDIO SPE, V27, P1378, DOI 10.1109/TASLP.2019.2919872
   Chen L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6074, DOI 10.1109/ICASSP.2018.8462272
   Chen Z, 2020, Arxiv, DOI arXiv:2009.10435
   Chen Z, 2020, IEEE-ACM T AUDIO SPE, V28, P2400, DOI 10.1109/TASLP.2020.3013392
   Dai Y., 2021, ARXIV
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Eric M, 2019, Arxiv, DOI arXiv:1907.01669
   Eric M, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P37
   Goel R, 2019, Arxiv, DOI arXiv:1907.00883
   Ham D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P583
   He Wanwei, 2021, ARXIV
   Heck M, 2020, SIGDIAL 2020: 21ST ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2020), P35
   Hosseini-Asl Ehsan, 2020, ARXIV
   Iyyer M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1821, DOI 10.18653/v1/P17-1167
   Jiang Z., 2020, ADV NEURAL INFORM PR
   Kim S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P567
   Koehn Philipp, 2004, P 2004 C EMPIRICAL M, P388
   Kolluru K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3748
   Le Hung., 2020, INT C LEARNING REPRE
   Lee H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5478
   Lee SJ, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P64
   Lei WQ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1437
   Lewis M., 2020, 58 ANN M ASS COMP LI, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]
   Li Jiwei, 2016, EMNLP
   Li S., 2020, INT C LEARNING REPRE
   Lin ZJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3391
   Liu Q, 2021, Arxiv, DOI arXiv:2103.10518
   Mehri S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3836
   Mrksic N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1777, DOI 10.18653/v1/P17-1163
   Nouri Elnaz, 2018, NEURIPS 2018
   Peng B., 2020, FINDINGS ASS COMPUTA, P172
   Peng Bei, 2020, ARXIV E PRINTS
   Peng SK, 2020, Arxiv, DOI arXiv:1908.07137
   Quirk C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P878
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21
   Rastogi A, 2020, AAAI CONF ARTIF INTE, V34, P8689
   Ren LL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1876
   Ren LL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2780
   Rosset C, 2021, Arxiv, DOI arXiv:2007.00655
   Santra B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5649
   Su YX, 2022, Arxiv, DOI arXiv:2109.14739
   Tao Yu., 2020, INT C LEARNING REPRE
   Tsung-HsienWen Milica, 2016, P 2016 C EMP METH NA, P2153, DOI DOI 10.18653/V1/D16-1233
   Lai TM, 2020, INT CONF ACOUST SPEE, P8034, DOI [10.1109/icassp40776.2020.9053975, 10.1109/ICASSP40776.2020.9053975]
   Ultes S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P73, DOI 10.18653/v1/P17-4013
   Volske Michael, 2017, P WORKSH NEW FRONT S, P59, DOI DOI 10.18653/V1/W17-4508
   Weisz G, 2018, IEEE-ACM T AUDIO SPE, V26, P2083, DOI 10.1109/TASLP.2018.2851664
   Wen Tsung-Hsien, 2015, P 2015 C EMPIRICAL M, P1711, DOI 10.18653/v1/D15-1199
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P917
   Wu CS, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P808
   Yang YY, 2021, AAAI CONF ARTIF INTE, V35, P14230
   Zhang J., 2020, P JOINT C LEX COMP S, P154
   Zhang T, 2021, LONG PAPERS, V1, P5882, DOI [10.18653/v1/, DOI 10.18653/V1/2021.ACL-LONG.457]
   Zhang YC, 2020, AAAI CONF ARTIF INTE, V34, P9604
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441
   Zhao TC, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1208
   Zhao TC, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P1
   Zhao TC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P654, DOI 10.18653/v1/P17-1061
   Zhong V, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1458
   Zhou JY, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P228
   Zhou L, 2020, Arxiv, DOI arXiv:1911.06192
   Zihan Xu, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P41, DOI 10.1007/978-3-030-60450-9_4
NR 72
TC 0
Z9 0
U1 9
U2 19
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JAN 12
PY 2023
VL 11
BP 68
EP 84
DI 10.1162/tacl_a_00534
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 8J8EU
UT WOS:000922645500005
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Decker, G
   Mendling, J
AF Decker, G.
   Mendling, J.
TI Process instantiation
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article; Proceedings Paper
CT 6th International Conference on Business Process Management
CY SEP 02-04, 2008
CL Milan Polytech, Milan, ITALY
SP Milan Polytech, Dept Electron, Informat Syst Res Grp
HO Milan Polytech
DE Business process modeling; Process instantiation; Events; Workflow
   patterns
ID PROCESS MODELS; ERRORS; DESIGN; EPCS
AB Although several process modeling languages allow one to specify processes with multiple start elements, the precise semantics of such models are often unclear, both from a pragmatic and from a theoretical point of view. This paper addresses the lack of research on this problem and introduces the CASU framework (from Creation, Activation, subscription, Unsubscription). The contribution of this framework is a systematic description of design alternatives for the specification of instantiation semantics of process modeling languages. We classify six prominent languages by the help of this framework. We validate the relevance of the CASU framework through empirical investigations involving a large set of process models from practice. Our work provides the basis for the design of new correctness criteria as well as for the formalization of Event-driven Process Chains (EPCs) and extension of the Business Process Modeling Notation (BPMN). It complements research such as the workflow patterns. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Mendling, J.] Humboldt Univ, D-10099 Berlin, Germany.
   [Decker, G.] Univ Potsdam, Hasso Plattner Inst, D-14482 Potsdam, Germany.
C3 Humboldt University of Berlin; University of Potsdam
RP Mendling, J (通讯作者)，Humboldt Univ, Unter Linden 6, D-10099 Berlin, Germany.
EM gero.decker@hpi.uni-potsdam.de; jan.mendling@wiwi.hu-berlin.de
OI Mendling, Jan/0000-0002-7260-524X
CR [Anonymous], 2007, WEB SERVICES BUSINES
   [Anonymous], SAP R R 3 PROCESS OR
   [Anonymous], 2001, BUSINESS PROCESS MOD
   Barros A, 2007, LECT NOTES COMPUT SC, V4422, P245
   Carzaniga A, 2001, ACM T COMPUT SYST, V19, P332, DOI 10.1145/380749.380767
   CURRAN T, 1997, ENTERPRISE RESOURCE
   Decker G, 2008, LECT NOTES COMPUT SC, V5240, P164, DOI 10.1007/978-3-540-85758-7_14
   Dehnert J, 2004, INT J COOP INF SYST, V13, P289, DOI 10.1142/S0218843004000973
   Eshuis R, 2004, IEEE T SOFTWARE ENG, V30, P437, DOI 10.1109/TSE.2004.33
   K?hne T., 2006, SOFTWARE SYSTEMS MOD, V5, P369, DOI DOI 10.1007/S10270-006-0017-9
   Keller G., 1992, SEMANTISCHE PROZESSM
   Lohmann N, 2008, DATA KNOWL ENG, V64, P38, DOI 10.1016/j.datak.2007.06.006
   Luckham D.C., 2001, POWER EVENTS INTRO C
   Mendling J, 2008, DATA KNOWL ENG, V64, P312, DOI 10.1016/j.datak.2007.06.019
   MENDLING J, 2008, LECT NOTES INFORM
   MENDLING J, 2008, INT J BUSINESS PROCE, V3
   Mendling J, 2007, LECT NOTES COMPUT SC, V4803, P113
   Mendling J, 2007, LECT NOTES COMPUT SC, V4495, P439
   Mendling J, 2008, LECT NOTES BUS INF P, V6, P1
   Müller D, 2008, LECT NOTES COMPUT SC, V5074, P48
   MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143
   *OBJ MAN GROUP, 2007, UN MOD LANG SUP TECH
   OMG, 2008, BUS PROC MOD NOT V1, V1
   Ouyang C, 2006, LECT NOTES COMPUT SC, V4001, P417, DOI 10.1007/11767138_28
   PETRI CA, 1962, 1962 P IFIP C, P386
   Puhlmann F, 2006, LECT NOTES COMPUT SC, V4102, P145
   RUMP FJ, 1999, GESCHAFTSPROZESSMANA
   Russell N., 2006, WORKFLOW CONTROL FLO
   Scheer AW, 2005, PROCESS-AWARE INFORMATION SYSTEMS: BRIDGING PEOPLE AND SOFTWARE THROUGH PROCESS TECHNOLOGY, P119, DOI 10.1002/0471741442.ch6
   van der Aalst WMP, 2005, DATA KNOWL ENG, V53, P129, DOI 10.1016/j.datak.2004.07.003
   van der Aalst WMP, 2005, INFORM SYST, V30, P245, DOI 10.1016/j.is.2004.02.002
   van der Aalst WMP, 1997, LECT NOTES COMPUT SC, V1248, P407
   van der Aalst WMP, 2004, BIOMED SCI INSTRUM, V3084, P142
   Van der Aalst WMP, 2003, DISTRIB PARALLEL DAT, V14, P5, DOI 10.1023/A:1022883727209
   Weske M., 2007, BUSINESS PROCESS MAN
   [No title captured]
NR 36
TC 25
Z9 25
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-023X
EI 1872-6933
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD SEP
PY 2009
VL 68
IS 9
SI SI
BP 777
EP 792
DI 10.1016/j.datak.2009.02.013
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 464TY
UT WOS:000267531300002
DA 2023-11-10
ER

PT S
AU Wen, YY
   Witten, IH
   Wang, DH
AF Wen, YY
   Witten, IH
   Wang, DH
BE Gedeon, TD
   Fung, LCC
TI Token identification using HMM and PPM models
SO AI 2003: ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 16th Australian Conference on Artificial Intelligence
CY DEC 03-05, 2003
CL UNIV WESTERN AUSTRALIA, PERTH, AUSTRALIA
SP Natl Comm Artificial Intellignece & Expert Syst
HO UNIV WESTERN AUSTRALIA
ID ALGORITHM; COMPRESSION
AB Hidden markov models (HMMs) and prediction by partial matching models (PPM) have been successfully used in language processing tasks including learning-based token identification. Most of the existing systems are domain- and language-dependent. The power of retargetability and applicability of these systems is limited. This paper investigates the effect of the combination of HMMs and PPM on token identification. We implement a system that bridges the two well known methods through words new to the identification model. The system is fully domain- and language-independent. No changes of code are necessary when applying to other domains or languages. The only required input of the system is an annotated corpus. The system has been tested on two corpora and achieved an overall F-measure of 69.02% for TCC, and 76.59% for BIB. Although the performance is not as good as that obtained from a system with language-dependent components, our proposed system has power to deal with large scope of domain- and language-independent problem. Identification of date has the best result, 73% and 92% of correct tokens are identified for two corpora respectively. The system also performs reasonably well on people's name with correct tokens of 68% for TCC, and 76% for BIB.
C1 Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia.
   Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.
   La Trobe Univ, Dept Comp Sci & Comp Engn, Bundoora, Vic 3086, Australia.
C3 Monash University; University of Waikato; La Trobe University
RP Wen, YY (通讯作者)，Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia.
EM ywen@csse.monash.edu.au; ihw@cs.waikato.ac.nz; dhwang@cs.latrobe.edu.au
RI Witten, Ian H/A-3366-2012; Wang, Dianhui/R-6289-2019
OI Witten, Ian H/0000-0001-6428-8988; Wang, Dianhui/0000-0002-5356-7268
CR [Anonymous], P 18 ANN INT ACM SIG, DOI DOI 10.1145/215206.215366
   BALUJA S, 1999, P C PAC ASS COMP LIN, P365
   BENNETT SW, 1997, P 2 C EMP METH NAT L, P109
   Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122
   Borthwick A., 1998, 6 WORKSH VER LARG CO
   CLEARY JG, 1984, IEEE T COMMUN, V32, P396, DOI 10.1109/TCOM.1984.1096090
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   MIKHEEV A, 1999, P EACL BERG NORW
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   SEKINE S, 1998, P MUC7
   Teahan WJ, 2000, COMPUT LINGUIST, V26, P375, DOI 10.1162/089120100561746
   VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Witten I.H., 1999, MANAGING GIGABYTES C
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
NR 15
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-20646-9
J9 LECT NOTES ARTIF INT
PY 2003
VL 2903
BP 173
EP 185
PG 13
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BY08N
UT WOS:000187551700015
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Lalrempuii, C
   Soni, B
AF Lalrempuii, Candy
   Soni, Badal
TI Investigating Unsupervised Neural Machine Translation for Low-resource
   Language Pair English-Mizo via Lexically Enhanced Pre-trained Language
   Models
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Unsupervised neuralmachine translation; cross-lingualword embeddings;
   low resource languages; Mizo
AB The vast majority of languages in the world at present are considered to be low-resource languages. Since the availability of large parallel data is crucial for the success of most modern machine translation approaches, improving machine translation for low-resource languages is a key challenge. Most unsupervised techniques for translation benefit closely related languages with monolingual data of substantial quantity. To facilitate research in this direction for the extremely low resource language pair English (en) and Mizo (lus), we have developed a parallel and monolingual corpus for the Mizo language from various news websites. We explore Unsupervised NeuralMachine Translation ( UNMT) based on the developed monolingual data. We observe that cross-lingual embedding (CLWE) initializations on subword segmented data during pre-training, based on both masked language modelling and sequence-to-sequence generation tasks, improve translation performance. We experiment with cross-lingual alignment and combined alignment and joint training for learning the cross-lingual embedding representations. We also report baseline performances and the impact of CLWE initialization using semi-supervised and supervised neural machine translation. Empirical results show that both CLWE initializations work well for the distant pair English-Mizo compared to the baselines.
C1 [Lalrempuii, Candy; Soni, Badal] Natl Inst Technol, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Lalrempuii, C (通讯作者)，Natl Inst Technol, Silchar 788010, Assam, India.
EM candy_rs@cse.nits.ac.in; badal@cse.nits.ac.in
CR Ahmadnia B, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1209, DOI 10.1109/ICMLA.2018.00196
   Ahmadnia Benyamin, 2017, P INT C RECENT ADV N, P24, DOI [10.26615/978-954-452-049-6_004, DOI 10.26615/978-954-452-049-6_004]
   Artetxe M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P194
   Artetxe M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P789
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Artetxe Mikel, 2018, P 6 INT C LEARNING R, DOI DOI 10.18653/V1/D18-1399
   Artetxe Mikel, 2020, P 58 ANN M ASS COMP, P7375
   Banerjee Tamali, 2021, P MACHINE TRANSLATIO, P23
   Bentham J, 2016, MEX INT CONF ARTIF I, P8, DOI 10.1109/MICAI-2016.2016.00010
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Chronopoulou A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P173
   Conneau Alexis, 2018, P INT C LEARNING REP
   Dai AM, 2015, ADV NEUR IN, V28
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Faruqui Manaal, 2014, P EACL, DOI [10.3115/v1/E14-1049, DOI 10.3115/V1/E14-1049]
   Firat O., 2016, P 2016 C N AM CHAPT, P866
   Gulcehre C, 2015, Arxiv, DOI arXiv:1503.03535
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6098
   Hoshen Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P469
   Jawanpuria P, 2019, T ASSOC COMPUT LING, V7, P107, DOI 10.1162/tacl_a_00257
   Joulin A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2979
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Khatri J, 2021, MACH TRANSL, V35, P711, DOI 10.1007/s10590-021-09292-y
   Khenglawt Vanlalmuansangi, 2022, P WILDRE 6WORKSHOP 1, P48
   Knight Kevin, 2016, ABS160402201 CORR
   Koehn P., 2017, WMT, P28
   Lalrempuii Candy, 2023, IEEE DataPort, DOI 10.21227/4KX5-WC43
   Lalrempuii C, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3445974
   Lalrempuii Candy, 2020, MACHINE LEARNING IMA, P193
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Luong M.-T., 2015, P 2015 C EMP METH NA, DOI DOI 10.18653/V1/D15-1166
   Luong Thang, 2015, P 1 WORKSHOP VECTOR, P151, DOI [DOI 10.3115/V1/W15-1521, 10]
   Majumder G, 2018, LECT NOTES COMPUT SC, V9623, P623, DOI 10.1007/978-3-319-75477-2_45
   Marchisio Kelly, 2020, P 5 C MACHINE TRANSL, P571
   Melamed I. Dan, 1995, P 3 WORKSH VER LARG
   More Rohit, 2015, P 12 INT C NATURAL L, P303
   Pakray P, 2015, 2015 FOURTEENTH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI), P3, DOI 10.1109/MICAI.2015.7
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pathak A, 2019, NEURAL COMPUT APPL, V31, P7615, DOI 10.1007/s00521-018-3601-3
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.1080/1472586x.2015.1113070.
   Post Matt, 2018, P 3 C MACH TRANSL RE, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Siddhant A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2827
   Song KT, 2019, PR MACH LEARN RES, V97
   Sun HP, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3418059
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vincent Pascal, 2008, P 25 INT C MACH LEAR, P1096
   Xing Chao, 2015, PROC 2015 C N AM CHA, P1006, DOI DOI 10.3115/V1/N15-1104
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483
   Zhang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1959, DOI 10.18653/v1/P17-1179
   ZiruiWang Jiateng Xie, 2020, P 8 INT C LEARNING R
NR 55
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG
PY 2023
VL 22
IS 8
AR 209
DI 10.1145/3609222
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q7NS7
UT WOS:001059361200007
DA 2023-11-10
ER

PT J
AU Heinrich, S
   Yao, Y
   Hinz, T
   Liu, ZY
   Hummel, T
   Kerzel, M
   Weber, C
   Wermter, S
AF Heinrich, Stefan
   Yao, Yuan
   Hinz, Tobias
   Liu, Zhiyuan
   Hummel, Thomas
   Kerzel, Matthias
   Weber, Cornelius
   Wermter, Stefan
TI Crossmodal Language Grounding in an Embodied Neurocognitive Model
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE language grounding; developmental robotics; multiple timescales;
   recurrent neural networks; embodied cognition; multimodal learning;
   crossmodal integration; multimodal interaction dataset
ID TIME; CIRCUITS; CORTEX; BACKPROPAGATION; PERCEPTION; SYSTEMS; SCALES
AB Human infants are able to acquire natural language seemingly easily at an early age. Their language learning seems to occur simultaneously with learning other cognitive functions as well as with playful interactions with the environment and caregivers. From a neuroscientific perspective, natural language is embodied, grounded in most, if not all, sensory and sensorimotor modalities, and acquired by means of crossmodal integration. However, characterizing the underlying mechanisms in the brain is difficult and explaining the grounding of language in crossmodal perception and action remains challenging. In this paper, we present a neurocognitive model for language grounding which reflects bio-inspired mechanisms such as an implicit adaptation of timescales as well as end-to-end multimodal abstraction. It addresses developmental robotic interaction and extends its learning capabilities using larger-scale knowledge-based data. In our scenario, we utilize the humanoid robot NICO in obtaining the EMIL data collection, in which the cognitive robot interacts with objects in a children's playground environment while receiving linguistic labels from a caregiver. The model analysis shows that crossmodally integrated representations are sufficient for acquiring language merely from sensory input through interaction with objects in an environment. The representations self-organize hierarchically and embed temporal and spatial information through composition and decomposition. This model can also provide the basis for further crossmodal integration of perceptually grounded cognitive representations.
C1 [Heinrich, Stefan; Hinz, Tobias; Hummel, Thomas; Kerzel, Matthias; Weber, Cornelius; Wermter, Stefan] Univ Hamburg, Dept Informat, Knowledge Technol Grp, Hamburg, Germany.
   [Heinrich, Stefan] Univ Tokyo, Int Res Ctr Neurointelligence, Tokyo, Japan.
   [Yao, Yuan; Liu, Zhiyuan] Tsinghua Univ, Dept Comp Sci & Technol, Nat Language Proc Lab, Beijing, Peoples R China.
C3 University of Hamburg; University of Tokyo; Tsinghua University
RP Heinrich, S (通讯作者)，Univ Hamburg, Dept Informat, Knowledge Technol Grp, Hamburg, Germany.; Heinrich, S (通讯作者)，Univ Tokyo, Int Res Ctr Neurointelligence, Tokyo, Japan.
EM heinrich@informatik.uni-hamburg.de
RI Liu, Zhiyuan/L-9243-2019; Wermter, Stefan/IYJ-4916-2023
OI Liu, Zhiyuan/0000-0002-7709-2543; Wermter, Stefan/0000-0003-1343-4775;
   Heinrich, Stefan/0000-0001-9913-3206
FU German Research Foundation (DFG); National Science Foundation of China
   (NSFC) [TRR-169]
FX The authors gratefully acknowledge partial support from the German
   Research Foundation (DFG) and the National Science Foundation of China
   (NSFC) under project Crossmodal Learning (TRR-169).
CR [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], 2010, IEEE SYS MAN CYBERN, DOI DOI 10.1109/ICSMC.2010.5641924
   [Anonymous], 2015, NIPSX 15 P 28 INT C
   Antunes A, 2018, J IEEE I C DEVELOP L, P19, DOI 10.1109/DEVLRN.2018.8761012
   Azagra P, 2017, IEEE INT C INT ROBOT, P6134, DOI 10.1109/IROS.2017.8206514
   Badre D, 2010, NEURON, V66, P315, DOI 10.1016/j.neuron.2010.03.025
   Bauer J, 2015, CONNECT SCI, V27, P358, DOI 10.1080/09540091.2014.971224
   Bouyeddou B, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND TECHNOLOGY APPLICATIONS (ICCTA), P11, DOI 10.1109/CATA.2018.8398647
   Burgard W., 2017, P 18 INT S ROB RES I, P1
   Buzsáki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Cangelosi A, 2015, INTELL ROBOT AUTON, P1
   Chang SY, 2017, ADV NEUR IN, V30
   Chaplot DS, 2018, AAAI CONF ARTIF INTE, P2819
   DAMASIO AR, 1989, COGNITION, V33, P25, DOI 10.1016/0010-0277(89)90005-X
   Dayan P, 2005, THEORETICAL NEUROSCI
   DOYA K, 1989, NEURAL NETWORKS, V2, P375, DOI 10.1016/0893-6080(89)90022-1
   Engel AK, 2013, NEURON, V80, P867, DOI 10.1016/j.neuron.2013.09.038
   Friederici AD, 2015, TRENDS COGN SCI, V19, P329, DOI 10.1016/j.tics.2015.03.012
   Garagnani M, 2016, EUR J NEUROSCI, V43, P721, DOI 10.1111/ejn.13145
   Gunes H., 2017, IEEE T AFFECT COMPUT
   Gupta A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3786, DOI 10.1109/IROS.2016.7759557
   Hagoort P, 2017, NEUROSCI BIOBEHAV R, V81, P194, DOI 10.1016/j.neubiorev.2017.01.048
   He BYJ, 2014, TRENDS COGN SCI, V18, P480, DOI 10.1016/j.tics.2014.04.003
   Heinrich S., 2018, P ICDL EPIROB WORKSH
   Heinrich S., 2016, P COCO NIPS2016, P62
   Heinrich S, 2018, J IEEE I C DEVELOP L, P13, DOI 10.1109/DEVLRN.2018.8761019
   Heinrich S, 2018, CONNECT SCI, V30, P99, DOI 10.1080/09540091.2017.1318357
   Heinrich S, 2015, ARTIFICIAL NEURAL NETWORKS, P149, DOI 10.1007/978-3-319-09903-3_8
   Hill K, 2014, CARDIOPULMONARY PHYSICAL THERAPY: MANAGEMENT AND CASE STUDIES, SECOND EDITION, P255
   Himberger KD, 2018, NEUROSCIENCE, V389, P161, DOI 10.1016/j.neuroscience.2018.04.030
   Hinoshita W, 2011, NEURAL NETWORKS, V24, P311, DOI 10.1016/j.neunet.2010.12.006
   HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Hudson D. A., 2019, ADV NEURAL INFORM PR
   Hudson D. A., 2018, INT C LEARN REPR ICL
   Kerzel M, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00028
   Kerzel M, 2017, IEEE ROMAN, P113, DOI 10.1109/ROMAN.2017.8172289
   Krishnaswamy N., 2019, P 13 INT C COMPUTATI, P44, DOI 10.18653/v1/W19-0507
   Krüger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Lazaridou Angeliki, 2015, ARXIV150102598, DOI DOI 10.3115/V1/N15-1016
   Levelt WJM, 2001, P NATL ACAD SCI USA, V98, P13464, DOI 10.1073/pnas.231459498
   Lillicrap T. P., 2016, P 4 INT C LEARN REPR
   Lillicrap TP, 2019, CURR OPIN NEUROBIOL, V55, P82, DOI 10.1016/j.conb.2019.01.011
   Lomonaco Vincenzo, 2017, ARXIV170503550, P17
   Lyon C, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/63462
   Meier M., 2018, P IROS 2018 WORKSH L
   Mikolov Tomas, 2013, INT C LEARN REPR
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Murata S, 2014, ADV ROBOTICS, V28, P1189, DOI 10.1080/01691864.2014.916628
   Murray JD, 2014, NAT NEUROSCI, V17, P1661, DOI 10.1038/nn.3862
   Nakamura T, 2018, IEEE T COGN DEV SYST, V10, P1043, DOI 10.1109/TCDS.2017.2745502
   Narasimhan K, 2018, J ARTIF INTELL RES, V63, P849, DOI 10.1613/jair.1.11263
   Newman B. A., 2018, ARXIV E PRINTS
   Oudeyer P.-Y., 2018, COMPUTATIONAL THEORI, DOI [10.31234/osf.io/3p8f6, DOI 10.31234/OSF.IO/3P8F6]
   Palm G., 1990, CONCEPT NEUROSCI, V1, P133
   Parisi G. I., 2018, CONTINUAL LIFELONG L
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Plappert M, 2016, BIG DATA-US, V4, P236, DOI 10.1089/big.2016.0028
   Pulvermüller F, 2018, PROG NEUROBIOL, V160, P1, DOI 10.1016/j.pneurobio.2017.07.001
   Pulvermüller F, 2014, BIOL CYBERN, V108, P573, DOI 10.1007/s00422-014-0603-9
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Roy D, 2005, ARTIF INTELL, V167, P170, DOI 10.1016/j.artint.2005.04.007
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4
   Simonyan K., 2015, INT C LEARN REPR ICL, P730
   Smith MA, 2008, J NEUROSCI, V28, P12591, DOI 10.1523/JNEUROSCI.2929-08.2008
   Tani J., 2016, EXPLORING ROBOTIC MI, DOI [10.1093/acprof:oso/9780190281069.001.0001, DOI 10.1093/ACPROF:OSO/9780190281069.001.0001]
   Tieleman T, 2012, LECT 65 RMSPROP DIVI, V4, P26
   Tomasello M., 2003, CONSTRUCTING LANGUAG
   Tomasello R, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39864-1
   Ulanovsky N, 2004, J NEUROSCI, V24, P10440, DOI 10.1523/JNEUROSCI.1905-04.2004
   van der Velde F, 2015, NEURAL NETWORKS, V62, P112, DOI 10.1016/j.neunet.2014.07.003
   Vavrecka M, 2014, COGN COMPUT, V6, P101, DOI 10.1007/s12559-013-9212-5
   Voegtlin T, 2002, NEURAL NETWORKS, V15, P979, DOI 10.1016/S0893-6080(02)00072-2
   Wang SN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P115
   Wang SN, 2018, AAAI CONF ARTIF INTE, P5973
   Wang XH, 2017, IEEE INT CONF COMP V, P2364, DOI 10.1109/ICCVW.2017.279
   Wermter S., 2005, GROUNDING NEURAL ROB, P162, DOI [10.1007/11521082_10, DOI 10.1007/11521082_10]
   Yamada T, 2018, IEEE ROBOT AUTOM LET, V3, P3441, DOI 10.1109/LRA.2018.2852838
   Yamada T, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00070
   Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220
   Zhong JP, 2019, AUTON ROBOT, V43, P1271, DOI 10.1007/s10514-018-9793-7
NR 83
TC 13
Z9 13
U1 2
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD OCT 14
PY 2020
VL 14
AR 52
DI 10.3389/fnbot.2020.00052
PG 17
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Robotics; Neurosciences & Neurology
GA OH5EZ
UT WOS:000582604600001
PM 33154720
OA gold, Green Published, Green Submitted
DA 2023-11-10
ER

PT J
AU Barnes, J
   Klinger, R
AF Barnes, Jeremy
   Klinger, Roman
TI Embedding Projection for Targeted Cross-Lingual Sentiment: Model
   Comparisons and a Real-World Study
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
LA English
DT Article
ID TRANSLATION; OPINIONS
AB Sentiment analysis benefits from large, hand-annotated resources in order to train and test machine learning models, which are often data hungry. While some languages, e. g., English, have a vast array of these resources, most under-resourced languages do not, especially for fine-grained sentiment tasks, such as aspect-level or targeted sentiment analysis. To improve this situation, we propose a cross-lingual approach to sentiment analysis that is applicable to under-resourced languages and takes into account target-level information. This model incorporates sentiment information into bilingual distributional representations, by jointly optimizing them for semantics and sentiment, showing state-of-the-art performance at sentence-level when combined with machine translation. The adaptation to targeted sentiment analysis on multiple domains shows that our model outperforms other projection-based bilingual embedding methods on binary targeted sentiment tasks. Our analysis on ten languages demonstrates that the amount of unlabeled monolingual data has surprisingly little effect on the sentiment results. As expected, the choice of a annotated source language for projection to a target leads to better results for source-target language pairs which are similar. Therefore, our results suggest that more efforts should be spent on the creation of resources for less similar languages to those which are resource-rich already. Finally, a domain mismatch leads to a decreased performance. This suggests resources in any language should ideally cover varieties of domains.
C1 [Barnes, Jeremy] Univ Oslo, Language Technol Grp, Gaustadalleen 23 B, N-0373 Oslo, Norway.
   [Klinger, Roman] Univ Stuttgart, Inst Maschinelle Sprachverarbeitung, Pfaffenwaldring 5b, D-70569 Stuttgart, Germany.
C3 University of Oslo; University of Stuttgart
RP Barnes, J (通讯作者)，Univ Oslo, Language Technol Grp, Gaustadalleen 23 B, N-0373 Oslo, Norway.
EM JEREMYCB@IFI.UIO.NO; KLINGER@IMS.UNI-STUTTGART.DE
FU DFG Collaborative Research Centre [SFB 732]; German Research Council
   (DFG) project SEAT (Structured Multi-Domain Emotion Analysis from Text)
   [KL 2869/1-1]; SGR-DTCL Predoctoral Scholarship
FX The authors thank Patrik Lambert, Toni Badia, Amaia Oliden, Itziar
   Etxeberria, Jessie Kief, Iris Hubscher, and Arne Ohm for helping with
   the annotation of the resources used in this research. This work has
   been partially supported by the DFG Collaborative Research Centre SFB
   732, a SGR-DTCL Predoctoral Scholarship, and by the German Research
   Council (DFG) project SEAT (Structured Multi-Domain Emotion Analysis
   from Text, KL 2869/1-1.)
CR Agerri R, 2013, PROCES LENG NAT, P215
   Agerri R, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3823
   Agic ., 2016, T ASS COMPUTATIONAL, V4, P301, DOI [10.1162/tacl_a_00100, DOI 10.1162/TACL_A_00100]
   Akhtar Md Shad, 2018, P 2018 C N AM CHAPTE, P572
   Almeida MSC, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P408
   [Anonymous], 2011, P INT C REC ADV NAT
   [Anonymous], 2015, P ICLR
   [Anonymous], 2010, WORKSHOP NEGATION SP
   [Anonymous], P WISDOM 2013
   Ap SC, 2014, ADV NEURAL INFORM PR, P1853
   Artetxe M., 2018, P 35 INT C MACH LEAR
   Artetxe M., 2016, P 2016 C EMPIRICAL M, P2289, DOI [DOI 10.18653/V1/D16-1250, 10.18653/v1/d16-1250]
   Artetxe M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3632
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   ASCH SE, 1955, SCI AM, V193, P31, DOI 10.1038/scientificamerican1155-31
   Atrio AR, 2019, PROCES LENG NAT, P23, DOI 10.26342/2019-63-2
   Bakliwal A., 2013, P WORKSHOP LANGUAGE, P49
   Balahur A, 2014, COMPUT SPEECH LANG, V28, P56, DOI 10.1016/j.csl.2013.03.004
   Banea C., 2013, IEEE T AFFECTIVE COM, V99
   Banea C., 2008, P 2008 C EMPIRICAL M, P127
   Banea C., 2010, P 23 INT C COMPUTATI, P1
   Barnes J., 2017, P 8 WORKSHOP COMPUTA, P2, DOI DOI 10.18653/V1/W17-5202
   Barnes J., 2018, P 11 LANG RE EV C LR
   Barnes J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2483
   Barnes Jeremy, 2018, P COLING 2018 27 INT
   Barnes Jeremy, 2016, P COLING 2016 26 INT, P1613
   Bertoldi N., 2009, P 4 WORKSHOP STAT MA, P182
   Bird Steven, 2009, NATURAL LANGUAGE PRO
   Chen M., 2012, ARXIV12064683, P1627, DOI DOI 10.1007/S11222-007-9033-Z
   Chen Peng, 2017, P 2017 C EMP METH NA, P452, DOI DOI 10.18653/V1/D17-1047
   Chen X., 2016, ABS160601614 CORR
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cotterell Ryan, 2018, P 2018 C N AM CHAPT, V2, P536
   Das A, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P403, DOI 10.1145/2556195.2559896
   Ding X, 2008, P 2008 INT C WEB SEA, P231, DOI DOI 10.1145/1341531.1341561
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Duh K., 2011, P 49 ANN M ASS COMPU, P429
   Fang A. C., 2010, P 24 PAC AS C LANG I
   Felbo B., 2017, P 2017 C EMP METH NA, P1615
   Ferreira DC, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2019
   Gerz D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P316
   Gouws S, 2015, PR MACH LEARN RES, V37, P748
   Gouws Stephan, 2015, 2015 ANN C N AM CHAP, P1386
   Grasser F, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P121, DOI 10.1145/3194658.3194677
   Hangya V, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P810
   Hermann KM, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P58
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Kingma D. P., 2014, C TRACK P
   Klinger R., 2015, PROC 19 C COMPUT NAT, P153, DOI [10.18653/v1/K15-1016, DOI 10.18653/V1/K15-1016]
   Klinger R, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2211
   Koehn P., 2017, WMT, P28
   Kulmizev Artur, 2017, P 12 WORKSHOP INNOVA, P382
   Lambert P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P781
   Lample G., 2018, INT C LEARNING REPRE
   Lample G., 2018, P 35 INT C MACH LEAR
   Lazaridou A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P270
   Lioma C., 2005, P ACL WORKSH BUILD U, P163
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu Bing, 2005, P 14 INT C WORLD WID, P342, DOI DOI 10.1145/1060745.1060797
   Liu F, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P278
   Loper E., 2002, ETMTNLP 02 P ACL 02, P63, DOI DOI 10.3115/1118108.1118117
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   Maia M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1941, DOI 10.1145/3184558.3192301
   Meng Xinfan, 2012, P ACL, V1, P572
   Mihalcea R., 2007, P 45 ANN M ASS COMPU, P976
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION, P1, DOI [10.1162/153244303322533223, DOI 10.1162/153244303322533223]
   Mohammad S., 2013, 2 JOINT C LEX COMP S, P321, DOI DOI 10.3115/V1/S14-2077
   Mohammad SM, 2016, J ARTIF INTELL RES, V55, P95, DOI 10.1613/jair.4787
   Nahar Vinita, 2012, Web Technologies and Applications. Proceedings of the 14th Asia-Pacific Web Conference, APWeb 2012, P767, DOI 10.1007/978-3-642-29253-8_75
   Nakov P, 2016, P 10 INT WORKSH SEM, P1, DOI DOI 10.18653/V1/S16-1001
   Padro L., 2010, P 7 LANG RES EV C LR
   Pagolu V.S., 2016, 2016 INT C SIGNAL PR, P1345
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Paszke A., 2016, PYTORCH DEEPLEARNING
   Petrov S, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2089
   Pontiki M., 2014, P 8 INT WORKSHOP SEM, P27, DOI [10.3115/v1/s14-2004, DOI 10.3115/V1/S14-2004]
   Pontiki M., 2016, P 10 INT WORKSH SEM, P19, DOI DOI 10.18653/V1/S16-1002
   Pontiki Maria, 2015, P 9 INT WORKSH SEM E, P486, DOI [10.18653/v1/s15-2082, DOI 10.18653/V1/S15-2082]
   Prettenhofer P, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2036264.2036277
   Rasooli M. S., 2017, MACH TRANSL, V32, P143
   Reitan J., 2015, P 6 WORKSHOP COMPUTA, P99, DOI [10.18653/v1/W15-2914, DOI 10.18653/V1/W15-2914]
   Saeidi M, 2016, P COLING 2016 26 INT, P1546
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sogaard A., 2015, P 53 ANN M ASS COMP
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Turney P. D., 2003, ACM Transactions on Information Systems, V21, P315, DOI 10.1145/944012.944013
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang B, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P483
   Wang H., 2012, P ACL 2012 SYST DEM, P115, DOI DOI 10.1145/1935826.1935854
   Wang S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P957
   Welch C, 2016, P COLING 2016 26 INT, P2471
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Wilson, 2013, 2 JOINT C LEX COMP S, V2, P312
   Wu H., 2008, P 22 INT C COMP LING, V1, P993
   Xiao JH, 2009, INT C MANAGE SCI ENG, P23, DOI 10.1109/ICMSE.2009.5317534
   Xiao Min, 2012, P COLING 2012, P2851
   Xue W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2514
   YEH A, 2000, P 18 C COMP LING, V2, P947, DOI DOI 10.3115/992730.992783
   Zhang MS, 2016, AAAI CONF ARTIF INTE, P3087
   Zhang Ye, 2017, P 8 INT JOINT C NAT, V1, P253
   Zhou GY, 2016, KNOWL INF SYST, V47, P27, DOI 10.1007/s10115-015-0849-0
   Zhou HW, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P430
   Zhou XJ, 2012, IEEE DATA MINING, P1200, DOI 10.1109/ICDM.2012.32
   Zhu XD, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P304
   Ziser Yftah, 2017, P INT C COMPUTATIONA, P400, DOI DOI 10.18653/V1/K17-1040
NR 108
TC 4
Z9 4
U1 0
U2 9
PU AI ACCESS FOUNDATION
PI MARINA DEL REY
PA USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA
   90292-6695 USA
SN 1076-9757
EI 1943-5037
J9 J ARTIF INTELL RES
JI J. Artif. Intell. Res.
PY 2019
VL 66
BP 691
EP 742
PG 52
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KC7LU
UT WOS:000507355600009
DA 2023-11-10
ER

PT S
AU Mao, YX
   Wu, ZH
   Chen, HJ
   Zheng, XQ
AF Mao, YX
   Wu, ZH
   Chen, HJ
   Zheng, XQ
BE Khosla, R
   Howlett, RJ
   Jain, LC
TI An interactive visual model for web ontologies
SO KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 2,
   PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Knowledge-Based Intelligent Information
   and Engineering Systems
CY SEP 14-16, 2005
CL La Trobe Univ, Melbourne, AUSTRALIA
HO La Trobe Univ
AB Web ontologies as the foundation of the Semantic Web were proposed to integrate heterogeneous information resources in the Web; howbeit several intrinsic limitations of Web ontologies represented in current Web ontology languages make them unsuitable for interactivities. Concept maps that provide a visual language for organizing and representing knowledge are widely used in many disciplines and application domains. This paper mainly describes an interactive visual model Web Ontology Map (WOMap) that extends Web ontologies with concept maps to sharing and exploring large-scale knowledge in an attractive and efficient way towards the Web.
C1 Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Mao, YX (通讯作者)，Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
EM maoyx@zju.edu.cn; wzh@zju.edu.cn; huajunsir@zju.edu.cn
RI chen, hongjun/IZD-4640-2023
CR [Anonymous], 1991, SCI TEACHER
   [Anonymous], 2001, SEMANTIC WEB
   [Anonymous], 2004, RDF PRIMER
   BERNERSLEE T, 2001, CONCEPTUAL GRAPHS SE
   CARNOT M, 2003, P 2003 ANN RES C S A
   CORBETT D, 2004, 12 INT C CONC STRUCT
   GAINES BR, 1994, AAAI 94 WORKSH IND R
   GAINES BR, 1995, 2 INT WWW C
   GERBE O, 2002, 10 INT C CONC STRUCT
   Jonassen D. H., 1997, Journal of Interactive Learning Research, V8, P289
   Novak J. D., 1984, LEARNING LEARN
   Wu ZH, 2004, P IEEE I C SERV COMP, P329
   Zhou XZ, 2004, ARTIF INTELL MED, V32, P15, DOI 10.1016/j.artmed.2004.01.014
NR 13
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-28895-3
J9 LECT NOTES ARTIF INT
PY 2005
VL 3682
BP 866
EP 872
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Imaging Science & Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA BDC78
UT WOS:000232722200119
DA 2023-11-10
ER

PT S
AU Berrah, AR
   Laboissière, R
AF Berrah, AR
   Laboissière, R
BE Floreano, D
   Nicoud, JD
   Mondada, F
TI SPECIES:: An evolutionary model for the emergence of phonetic structures
   in an artificial society of speech agents
SO ADVANCES IN ARTIFICIAL LIFE, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 5th European Conference on Artificial Life (ECAL)
CY SEP 13-17, 1999
CL LAUSANNE, SWITZERLAND
SP Latsis Fdn, Swissair, K Team S A, Cyberbotics Ltd, Aarhus Univ, LEGO Lab, Cyberlife Technol Ltd
ID VOWEL SYSTEMS
AB This paper addresses the emergence of a common phonetic code in a society of communicating speech agents using evolutionary techniques. Predictions for the large vowel systems of the world's languages using the Maximum Use of Available distinctive Features (MUAF) principle are discussed. Simulations of the use of supplementary phonetic features in large vowel systems axe presented. These experimental results show how simple local rules of interaction between speaking agents are sufficient to explain some of the universal characteristics of the phonological structure of the world's languages.
C1 LORIA, F-54506 Vandoeuvre Les Nancy, France.
   INPG, Inst Commun Parlee, F-38031 Grenoble, France.
C3 Universite de Lorraine; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble
RP Berrah, AR (通讯作者)，LORIA, BP 239, F-54506 Vandoeuvre Les Nancy, France.
RI Laboissière, Rafael/E-9814-2013
OI Laboissière, Rafael/0000-0002-2180-9250
CR BERRAH AR, 1998, THESIS I NATL POLYTE
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   de Boer B., 1997, P 4 EUR C ART LIF, P503
   Fant G., 1960, ACOUSTIC THEORY SPEE
   GLOTIN H, 1996, COLLECTIF SOCIAL ACT, P113
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   LINDBLOM B, 1997, EVOLUTION HUMAN LANG
   Maddieson Ian, 1990, UCLA WORKING PAPERS, V74, P104
   OHALA JJ, 1980, 9 INT C PHON SCI, V3, P181
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   STEELS L, 1997, EVOLUTION HUMAN LANG
   VALLEE N, 1994, THESIS U STENDHAL GR
   [No title captured]
NR 13
TC 3
Z9 4
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-66452-1
J9 LECT NOTES ARTIF INT
PY 1999
VL 1674
BP 674
EP 678
PG 5
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BS52B
UT WOS:000170202200088
DA 2023-11-10
ER

PT S
AU Furche, T
   Linse, B
   Bry, F
   Plexousakis, D
   Gottlob, G
AF Furche, Tim
   Linse, Benedikt
   Bry, Francois
   Plexousakis, Dimitris
   Gottlob, Georg
BE Barahona, P
   Bry, F
   Franconi, E
   Henze, N
   Sattler, U
TI RDF querying: Language constructs and evaluation methods compared
SO REASONING WEB
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 2nd International Summer School on Reasoning Web
CY SEP 04-08, 2006
CL New Univ Lisbon, Lisbon, PORTUGAL
SP FCT, REWERSE
HO New Univ Lisbon
ID SEMANTIC WEB
AB This article is firstly an introduction into query languages for the Semantic Web, secondly an in-depth comparison of the languages introduced. Only RDF query languages are considered because, as of the writing of this paper, query languages for other Semantic Web data modeling formalisms, especially OWL, are still an open research issue, and only a very small number of, furthermore incomplete, proposals for querying Semantic Web data modeled after other formalisms than RDF exist. The limitation to a few RDF query languages is motivated both by the objective of an in-depth comparison of the languages addressed and by space limitations. During the three years before the writing of this article, more than three dozen proposals for RDF query languages have been published! Not only such a large number, but also the often immature nature of the proposals makes the focus on few, but representative languages a necessary condition for a non-trivial comparison.
   For this article, the following RDF query languages have been, admittedly subjectively, selected: Firstly, the "relational" or "pattern-based" query languages SPARQL, RQL, TRIPLE, and Xcerpt; secondly the reactive rule query language Algae; thirdly and last the "navigational access" query language Versa. Although subjective, this choice is arguably a good coverage of the diverse language paradigms considered for querying RDF data. It is the authors' hope and expectation, that this comparison will motivate and trigger further similar studies, thus completing the present article and overcoming its limitation.
C1 Univ Munich, Inst Informat, D-80538 Munich, Germany.
   Univ Crete, Dept Comp Sci, GR-71110 Iraklion, Crete, Greece.
   FORTH, Informat Syst Lab, Inst Comp Sci, GR-71110 Iraklion, Crete, Greece.
   Univ Oxford, Comp Lab, Oxford OX1 3QD, England.
C3 University of Munich; University of Crete; Foundation for Research &
   Technology - Hellas (FORTH); University of Oxford
RP Furche, T (通讯作者)，Univ Munich, Inst Informat, Oettingenstr 67, D-80538 Munich, Germany.
EM bry@pms.ifi.lmu.de
RI Bry, François/AAF-7602-2020
OI Bry, François/0000-0002-0532-6005; Gottlob, Georg/0000-0002-2353-5230
CR Abiteboul S, 1998, J ACM, V45, P798, DOI 10.1145/290179.290182
   [Anonymous], 2004, RDF VOCABULARY DESCR
   [Anonymous], RDQL QUERY LANGUAGE
   [Anonymous], 2004, RDF SEMANTICS
   BACKETT D, 2004, P XML EUROPE     APR
   Bailey J, 2005, LECT NOTES COMPUT SC, V3564, P35
   BASSILIADES N, 2003, P INT WORLD WID WEB
   BECKETT D, 2004, TURTLE TERSE RDF TRI
   BECKETT D, 2001, DESIGN IMPLEMENTATIO
   Beckett D., 2004, W3C RECOMMENDATION, V10
   BECKETT D, 2006, SPARQL QUERY RESULTS
   BERGER S, 2004, P INT SEM WEB C, V11, P4
   BERGER S, 2003, LNCS, V2901
   BERGER S, 2003, P INT C VER LARG DAT
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   BERNERSLEE T, 2004, NOTATION 3 RDF LANGU
   BERNERSLEE T, 2004, N3QL RDF DATA QUERY
   BIRON PV, 2001, XML SCHEMA 2
   BIZER C, 2004, TRIQL QUERY LANGUAGE
   BOLZER O, 2005, THESIS U MUNICH
   Bönström V, 2003, FIRST LATIN AMERICAN WEB CONGRESS, PROCEEDINGS, P27, DOI 10.1109/LAWEB.2003.1250279
   BROEKSTRA J, 2003, P SWAD EUR WORKSH SE
   BROEKSTRA J, 2002, P INT SEM WEB C
   BRY F, 2002, LNCS, V2593
   BRY F, 2006, UNUPB EFFICIENT EVAL
   BRY F, 2004, LNCS, V3208
   BRY F, 2004, IDENTIFICATION DESIG
   BRY F, 2005, J SEMANTIC WEB INFOR, V1, P14
   CATTLEL RGG, 2000, OBJECT DATA STANDARD
   CHAMBERLIN D, 2000, P WORKSH WEB DAT
   CHRISTOPHIDES L, 2000, P DELOS WORKSH INF S
   CHRISTOPHIDES V, 2003, WWW, P544
   Clark J., 1999, XML PATH LANGUAGE XP
   CLARK K, 2004, RDF DATA ACCESS USE
   Cohen E, 2003, SIAM J COMPUT, V32, P1338, DOI 10.1137/S0097539702403098
   CRUZ IF, 2003, P SWDB 03 1 INT WORK
   DAVIS I, 2003, RDF TEMPLATE LANGUAG
   DEBRUIJN J, 2005, LNCS, V3703
   DECKER S, 1998, P W3C QL 98 QUER LAN
   DEUTSCH A, 1998, P W3C QL 98 QUER LAN
   Forgy C., 1979, THESIS
   FROHN J, 1994, P INT C VER LARG DAT
   Garshol Lars Marius, 2003, LIVING TOPIC MAPS RD
   Gottlob G, 2005, ACM T DATABASE SYST, V30, P444, DOI 10.1145/1071610.1071614
   GRATN J, 2004, RDF TEST CASE
   GROUP HLSW, 2004, JENA SEMANTIC WEB FR
   Grust T, 2004, ACM T DATABASE SYST, V29, P91, DOI 10.1145/974750.974754
   HARRIS S, 2003, P INT WORKSH PRACT S
   HARRIS S, 2005, SPARQL QUERY PROCESS
   HARTH A, 2004, TRIPLE TUTORIAL
   HARTH A, 2005, OPTIMIZED INDEX STRU
   Karvounarakis G, 2004, FUNCTIONAL APPROACH TO DATA MANAGEMENT: MODELING, ANALYZING AND INTEGRATING HETEROGENEOUS DATA, P435
   Karvounarakis G, 2003, COMPUT NETW, V42, P617, DOI 10.1016/S1389-1286(03)00227-5
   KARVOUNARAKIS G, 2001, P JOURN BAS DANN AV
   KARVOUNARAKIS G, 2002, P INT WORLD WID WEB
   KIFER M, 1995, J ASSOC COMPUT MACH, V42, P741, DOI 10.1145/210332.210335
   Klyne G., 2004, RESOURCE DESCRIPTION
   LACHER M, 2001, P EXT MARK LANG
   Lacher M. S., 2001, Markup Languages: Theory & Practice, V3, P313, DOI 10.1162/109966201753750333
   *LANGD CONS, 2000, NEX QUER LANG
   Lassila Ora, 1998, RESOURCE DESCRIPTION
   LUDASCHER B, 1998, INFORMATION SYSTEMS, V23, P1
   MAGIRIDOU M, 2005, P INT SEM WEB C ISWC
   MAGKANARAKI A, 2003, P INT SEM WEB C OCT
   MAIER D, 1998, P W3C QL 98 QUERY LA
   MANBER U, 1990, PROCEEDINGS OF THE FIRST ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P319
   MANOLA F, RDF PRMER W3C
   Marx M., 2004, P 23 ACM SIGMOD SIGA, P13
   MARX M, 2004, P EXT DAT TECHN
   MATONO A, 2005, PATH BASED RELATIONA
   MATSUYAMA K, 2004, P IEEE C PERV COMP C
   MAY W, 2004, THEOR PRACT LOG PROG, V3, P499
   MILLER L, 2002, P INT SEM WEB C JUN
   OBBUJI U, 2002, THINKING XML BASIC X
   OBGUJI U, 2004, VERSA EXAMPLE
   OLSON M, 2003, VERSA SPECIFICATION
   PALMER S, 2003, PONDERING RDF PATH
   PARSIA B, 2006, REASONING WEB 2 INT
   Prud E., 2006, SPARQL QUERY LANGUAG
   PRUDHOMMEAUX E, 2004, ALGAE EXTENSION RULE
   PRUDHOMMEAUX E, 2004, ALGAE RDF QUERY LANG
   REYNOLDS D, 2002, HPL2002327 HP LAB
   Robie J., 2001, Markup Languages: Theory & Practice, V3, P411, DOI 10.1162/109966202760152176
   ROBIE J, 2001, P XML C EXP DEC
   SCHAFFERT S, 2004, THESIS U MUNICH
   SCHAFFERT S, 2004, P EXTR MARK LANG APR
   SCHROEDER A, 2005, THESIS U MUNICH
   SINTEK M, 2001, P DED DAT KNOWL MAN
   SINTEK M, 2002, P INT SEM WEB C JUN
   SOUZIS A, 2004, RXPATH SPECIFICATION
   STEER D, 2003, TREEHUGGER 1 0 INTRO
   STICKLER P, 2004, CBD CONSICE BOUNDED
   Walsh Norman, 2003, P EXTR MARK LANG
   WILK A, 2003, LNCS, V2901
   WILKINSON K, 2003, EFFIFIENT RDF STORAG
   ZANIOLA C, 1983, P ACM SIGMOD C
NR 96
TC 21
Z9 21
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-38409-X
J9 LECT NOTES COMPUT SC
PY 2006
VL 4126
BP 1
EP 52
PG 52
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFA76
UT WOS:000240539300001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU de Varda, AG
   Marelli, M
AF de Varda, Andrea Gregor
   Marelli, Marco
TI Data-driven Cross-lingual Syntax: An Agreement Study with Massively
   Multilingual Models
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID NETWORKS
AB Massively multilingual models such as mBERT and XLM-R are increasingly valued in Natural Language Processing research and applications, due to their ability to tackle the uneven distribution of resources available for different languages. The models' ability to process multiple languages relying on a shared set of parameters raises the question of whether the grammatical knowledge they extracted during pre-training can be considered as a data-driven cross-lingual grammar. The present work studies the inner workings of mBERT and XLM-R in order to test the cross-lingual consistency of the individual neural units that respond to a precise syntactic phenomenon, that is, number agreement, in five languages (English, German, French, Hebrew, Russian). We found that there is a significant overlap in the latent dimensions that encode agreement across the languages we considered. This overlap is larger (a) for long- vis-a-vis short-distance agreement and (b) when considering XLM-R as compared to mBERT, and peaks in the intermediate layers of the network. We further show that a small set of syntax-sensitive neurons can capture agreement violations across languages; however, their contribution is not decisive in agreement processing.
C1 [de Varda, Andrea Gregor; Marelli, Marco] Univ Milano Bicocca, Milan, Italy.
C3 University of Milano-Bicocca
RP de Varda, AG (通讯作者)，Univ Milano Bicocca, Milan, Italy.
EM a.devarda@campus.unimib.it; m.marelli@unimib.it
CR Abutalebi Jubin., 2001, BILING-LANG COGN, V4, P179, DOI [DOI 10.1017/S136672890100027X, 10.1017/S136672890100027X]
   Alain G, 2018, Arxiv, DOI arXiv:1610.01644
   Antverg Omer., 2021, INT C LEARNING REPRE
   Bacon Geoff, 2019, ARXIV
   Bau D., 2019, INT C LEARN REPR ICL
   Belinkov Y, 2022, COMPUT LINGUIST, V48, P207, DOI 10.1162/coli_a_00422
   Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254
   Bernardy Jean Philippe., 2017, LINGUISTIC ISSUES LA, DOI [10.33011/lilt.v15i.1413, DOI 10.33011/LILT.V15I.1413]
   Chi E. A., 2020, P 58 ANN M ASS COMP, P5564, DOI DOI 10.18653/V1/2020.ACL-MAIN.493
   Conneau Alexis, 2020, ASS COMPUT LINGUIST, P8440, DOI [10.18653/v1/2020.acl-main.747, DOI 10.18653/V1/2020.ACL-MAIN, DOI 10.18653/V1/2020.ACL-MAIN.747]
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P6022, DOI DOI 10.18653/V1/2020.ACL-MAIN.536
   Cummins Robert., 1988, SOUTHERN J PHILOS, V26, P43, DOI [10.1111/j.2041-6962.1988.tb00462.x, DOI 10.1111/J.2041-6962.1988.TB00462.X]
   Dalvi F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4908
   Dalvi F, 2019, AAAI CONF ARTIF INTE, P6309
   Dalvi F, 2019, AAAI CONF ARTIF INTE, P9851
   Del M, 2022, Arxiv, DOI arXiv:2109.01207
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhar Prajit., 2021, P 23 NORDIC C COMPUT, P74
   Doddapaneni Sumanth., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.00676
   Dufter P, 2021, Arxiv, DOI arXiv:2005.00396
   Finlayson M, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1828
   Goldberg Yoav, 2019, ABS190105287 ARXIV
   Gonen H, 2022, PROCEEDINGS OF THE 7TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P67
   Green DW, 2008, ANNU REV APPL LINGUI, V28, P25, DOI 10.1017/S0267190508080057
   Guarasci R, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101261
   Gulordava K., 2018, P 2018 C N AM CHAPT, V1, P1195, DOI DOI 10.18653/V1/N18-1108
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   Joshi Pratik., 2020, P 58 ANN M ASS COMP, P6282, DOI DOI 10.18653/V1/2020.ACL-MAIN.560
   Karpathy A, 2015, Arxiv, DOI arXiv:1506.02078
   Karthikeyan K, 2020, INT C LEARN REPR
   Kementchedjhieva Yova., 2018, P 2018 EMNLP WORKSHO, P145, DOI [10.18653/v1/W18-5417, DOI 10.18653/V1/W18-5417]
   Kim KHS, 1997, NATURE, V388, P171, DOI 10.1038/40623
   Klein S, 2020, 17TH SIGMORPHON WORKSHOP ON COMPUTATIONAL RESEARCH IN PHONETICS PHONOLOGY, AND MORPHOLOGY (SIGMORPHON 2020), P204
   Kuncoro A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1426
   Lakretz Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P11
   Lasri K, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2309
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4483
   Li JW, 2016, Arxiv, DOI arXiv:1506.01066
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI DOI 10.1353/LAN.2019.0015
   Liu ZH, 2020, Arxiv, DOI arXiv:2004.14218
   Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192
   MCCLOSKEY M, 1991, PSYCHOL SCI, V2, P387, DOI 10.1111/j.1467-9280.1991.tb00173.x
   Mueller A., 2020, P 58 ANN M ASS COMPU, P5523
   Muller B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2214
   Perani D, 2005, CURR OPIN NEUROBIOL, V15, P202, DOI 10.1016/j.conb.2005.03.007
   Perani D, 1998, BRAIN, V121, P1841, DOI 10.1093/brain/121.10.1841
   Pinter Y, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P95
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Radford A, 2017, Arxiv, DOI arXiv:1704.01444
   Serrano S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2931
   Singh Jasdeep, 2019, P 2 WORKSH DEEP LEAR, P47, DOI [10.18653/v1/D19- 6106, DOI 10.18653/V1/D19-6106]
   Stanczak K, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1589
   Tan LH, 2011, P NATL ACAD SCI USA, V108, P2540, DOI 10.1073/pnas.0909623108
   Tang ZY, 2017, INT CONF ACOUST SPEE, P2736, DOI 10.1109/ICASSP.2017.7952654
   Tham WWP, 2005, NEUROIMAGE, V28, P579, DOI 10.1016/j.neuroimage.2005.06.057
   van Schijndel M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5831
   Wang MH, 2015, SCI REP-UK, V5, DOI 10.1038/srep16923
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833
   Wu SJ, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P120
   Xu M, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1603309
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zuckermann Ghilad, 2006, J MOD JEW STUD, V5, P57
NR 62
TC 0
Z9 0
U1 6
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN 1
PY 2023
VL 49
IS 2
BP 261
EP 299
DI 10.1162/coli_a_00472
PG 39
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA L1IC1
UT WOS:001020851700001
OA gold
DA 2023-11-10
ER

PT J
AU Zheng, JY
   Liu, Y
AF Zheng, Jianyu
   Liu, Ying
TI What does Chinese BERT learn about syntactic knowledge?
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Chinese; BERT; Syntax; Fine-tune; NLP
AB Pre-trained language models such as Bidirectional Encoder Representations from Transformers (BERT) have been applied to a wide range of natural language processing (NLP) tasks and obtained significantly positive results. A growing body of research has investigated the reason why BERT is so efficient and what language knowledge BERT is able to learn. However, most of these works focused almost exclusively on English. Few studies have explored the language information, particularly syntactic information, that BERT has learned in Chinese, which is written as sequences of characters. In this study, we adopted some probing methods for identifying syntactic knowledge stored in the attention heads and hidden states of Chinese BERT. The results suggest that some individual heads and combination of heads do well in encoding corresponding and overall syntactic relations, respectively. The hidden representation of each layer also contained syntactic information to different degrees. We also analyzed the fine-tuned models of Chinese BERT for different tasks, covering all levels. Our results suggest that these fine-turned models reflect changes in conserving language structure. These findings help explain why Chinese BERT can show such large improvements across many language-processing tasks.
C1 [Zheng, Jianyu; Liu, Ying] Tsinghua Univ, Dept Chinese Language & Literature, Beijing, Peoples R China.
C3 Tsinghua University
RP Liu, Y (通讯作者)，Tsinghua Univ, Dept Chinese Language & Literature, Beijing, Peoples R China.
EM yingliu@tsinghua.edu.cn
FU Major Program of the National Social Science Fund of China [18ZDA238];
   Tsinghua University Initiative Scientific Research Program
   [2019THZWJC38]; Beihang University Sponsored Projects for Core Young
   Researchers in the Disciplines of Social Sciences and Humanities
   [KG16183801]; Tianjin Postgraduate Scientific Research Innovation
   Program [2022BKY024]
FX This work was supported by the Major Program of the National Social
   Science Fund of China (18ZDA238) , the Tsinghua University Initiative
   Scientific Research Program (2019THZWJC38) , Beihang University
   Sponsored Projects for Core Young Researchers in the Disciplines of
   Social Sciences and Humanities (KG16183801) and the Tianjin Postgraduate
   Scientific Research Innovation Program (No. 2022BKY024) . The funders
   had no role in study design, data collection and analysis, decision to
   publish, or preparation of the manuscript.
CR Che W., 2012, CHINESE DEPENDENCY T
   Chen JD, 2010, APPL PSYCHOLINGUIST, V31, P1, DOI 10.1017/S0142716409990257
   Choenni R, 2020, ARXIV COMPUTATION LA, P1, DOI [10.48550/arXiv.2009.12862, DOI 10.48550/ARXIV.2009.12862]
   Choi H, 2021, INT C PATT RECOG, P5482, DOI 10.1109/ICPR48806.2021.9412102
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Dai Y, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6674
   de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI [10.1162/coli_a_00402, 10.1162/COLI_a_00402]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Goldberg Yoav, 2019, ABS190105287 ARXIV
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Htut P, 2019, COMPUTATION LANGUAGE, P1, DOI [10.48550/arXiv.1911.12246, DOI 10.48550/ARXIV.1911.12246]
   Hu H, 2020, P 2020 C EMP METH NA, P3512
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   Koto F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3849
   Liu Xin, 2018, P 27 INT C COMP LING, P1952
   Ningyu X, 2022, P 2022 C EMPIRICAL M, P8073, DOI [10.48550/arXiv.2212.10879, DOI 10.48550/ARXIV.2212.10879]
   Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58
   Ranaldi L, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13020677
   Ranaldi L, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14010010
   Ravichander A, 2020, P 9 JOINT C LEX COMP, P88
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Tenney Ian, 2019, INT C LEARN REPR
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang Jia., 2015, OPEN J MODERN LINGUI, V05, P213, DOI [10.4236/ojml.2015.52017, DOI 10.4236/OJML.2015.52017]
   Wang Y, 2020, P 28 INT C COMPUTATI, P2826, DOI [10.18653/v1/2020.coling-main.254, DOI 10.18653/V1/2020.COLING-MAIN.254]
   Wu ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4166
   Xiang BL, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2784
   Xue N, 2013, CHINESE TREEBANK 80, DOI [10.35111/wygn-4f57, DOI 10.35111/WYGN-4F57]
   Ye Z, 2007, BRAIN RES, V1142, P135, DOI 10.1016/j.brainres.2007.01.030
   Zhang H., 2018, P 2018 C N AM CHAPT, V2, P175, DOI [10.18653/v1/N18-2028, DOI 10.18653/V1/N18-2028]
NR 33
TC 0
Z9 0
U1 15
U2 15
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 26
PY 2023
VL 9
AR e1478
DI 10.7717/peerj-cs.1478
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O5SZ3
UT WOS:001044418900003
PM 37547407
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Bugliarello, E
   Cotterell, R
   Okazaki, N
   Elliott, D
AF Bugliarello, Emanuele
   Cotterell, Ryan
   Okazaki, Naoaki
   Elliott, Desmond
TI Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework
   of Vision-and-Language BERTs
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Large-scale pretraining and task-specific fine-tuning is now the standard methodology for many tasks in computer vision and natural language processing. Recently, a multitude of methods have been proposed for pretraining vision and language BERTs to tackle challenges at the intersection of these two key areas of AI. These models can be categorized into either single-stream or dual-stream encoders. We study the differences between these two categories, and show how they can be unified under a single theoretical framework. We then conduct controlled experiments to discern the empirical differences between five vision and language BERTs. Our experiments show that training data and hyperparameters are responsible for most of the differences between the reported results, but they also reveal that the embedding layer plays a crucial role in these massive models.
C1 [Bugliarello, Emanuele] Univ Copenhagen, Copenhagen, Denmark.
   [Cotterell, Ryan] Univ Cambridge, Cambridge, England.
   [Cotterell, Ryan; Okazaki, Naoaki] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Elliott, Desmond] Tokyo Inst Technol, Tokyo, Japan.
C3 University of Copenhagen; University of Cambridge; Swiss Federal
   Institutes of Technology Domain; ETH Zurich; Tokyo Institute of
   Technology
RP Bugliarello, E (通讯作者)，Univ Copenhagen, Copenhagen, Denmark.
EM emanuele@di.ku.dk; rcotterell@inf.ethz.ch; okazaki@c.titech.ac.jp;
   de@di.ku.dk
OI Cotterell, Ryan/0000-0003-4080-1833; Bugliarello,
   Emanuele/0000-0002-2999-7081; Elliott, Desmond/0000-0003-3112-7904
FU European Union [801199]; "Research and Development of Deep Learning
   Technology for Advanced Multilingual Speech Translation,'' the
   Commissioned Research of National Institute of Information and
   Communications Technology (NICT), Japan
FX We are grateful to the action editor Jacob Eisenstein and the anonymous
   reviewers at TACL for their constructive comments and discussions. This
   project has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie grant
   agreement no. 801199 and by ``Research and Development of Deep Learning
   Technology for Advanced Multilingual Speech Translation,'' the
   Commissioned Research of National Institute of Information and
   Communications Technology (NICT), Japan.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ba Jimmy Lei, 2016, ARXIV160706450
   Benjamin DJ, 2018, NAT HUM BEHAV, V2, P6, DOI 10.1038/s41562-017-0189-z
   Cho J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8785
   de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475
   Devlin J., 2018, ARXIV, V1, P4171
   Dodge Jesse, 2020, ARXIV200206305
   Gardner Matt, 2020, FINDINGS ASS COMPUTA, P1307
   Geva M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1161
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Gururangan Suchin, 2018, ARXIV180302324
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hill F., 2021, INT C LEARN REPR
   Huang Zhicheng, 2020, ARXIV PREPRINT ARXIV
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086
   Kim Wonjae, 2021, P INT C MACH LEARN, P5583
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li X., 2020, COMPUTER VISION ECCV, P121
   Lin JR, 2020, IEEE INT C INT ROBOT, P4870, DOI 10.1109/IROS45743.2020.9340790
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2019, ADV NEUR IN, V32
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Narang Sharan, 2021, ARXIV PREPRINT ARXIV
   Paszke A, 2019, ADV NEUR IN, V32
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Qi Di, 2020, ARXIV200107966
   Radford Alec, 2021, ABS210300020 CORR
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren S., 2015, P ADV NEUR INF PROC, V39, P91
   Ribeiro MT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6174
   Rogers A., 2020, FINDINGS ASS COMPUTA, P1256
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Su Weijie, 2020, P 8 INT C LEARN REPR
   Suhr A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6418
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu Y., 2016, ARXIV PREPRINT ARXIV
   Xie Ning, 2019, ARXIV190106706
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yu Fei, P AAAI C ART INT
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 53
TC 24
Z9 26
U1 1
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 978
EP 994
DI 10.1162/tacl_a_00408
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200058
OA Green Published, gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Sun, WN
   Zhao, CL
AF Sun Weining
   Zhao Cheli
TI Applications of virtual reality modeling language technology for
   COVID-19 pandemic
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Virtual reality modeling language virtual library; virtual volleyball
   hall; 3D; Internet; system
ID VISUALIZATION; ENVIRONMENT; SIMULATION; TOOL
AB During COVID-19 pandemic, researchers have used innovative technologies for fast tracking the development to end this pandemic. Virtual Reality (VR) has offered an imperative role for fighting this pandemic, through audiovisual-based virtual communication. Virtual reality modeling language (VRML), as an international standard of virtual reality, has developed rapidly. VRML expanded the function of script node by introducing Java and script programs written in java script language. This paper presents a VRML method. Libraries and platoons are virtualized to meet the normal use of users. In principle, any text editing system can be used for VRML programming, but some editing systems have few related functions and are not suitable for large-scale VRML Scene Design. The VRML algorithm proposed in this paper can be applied to large buildings. The VRML algorithm proposed in this paper is compared with the traditional algorithm. The VRML algorithm proposed in this paper is superior to the traditional algorithm in the aspects of realism, interactivity, design rationality and execution speed. The practicability of the VRML algorithm is proved. It provides help for people who are inconvenient to go out during the protection period of covid-19.
C1 [Sun Weining] Inner Mongolia Univ, Nationalities Acad Fine Arts, Tongliao 028000, Inner Mongolia, Peoples R China.
   [Zhao Cheli] Mongolian State Univ Educ, Coll Educ, Ulaanbaatar, Mongolia.
C3 Inner Mongolia University; Mongolian National University of Education
RP Sun, WN (通讯作者)，Inner Mongolia Univ, Nationalities Acad Fine Arts, Tongliao 028000, Inner Mongolia, Peoples R China.
EM miweiba@163.com
FU science research foundation of Inner Mongolia University for
   nationalities [NMDYB18059]
FX This paper is supported by science research foundation of Inner Mongolia
   University for nationalities, project name: Digital Transformation
   Research of Horqin print, Project No.: NMDYB18059.
CR Bartsch M, 2001, IEEE T MAGN, V37, P3604, DOI 10.1109/20.952672
   Brutzman D, 1998, COMMUN ACM, V41, P57, DOI 10.1145/276609.276620
   Castier M, 1998, POWDER TECHNOL, V97, P200, DOI 10.1016/S0032-5910(98)00009-6
   Damer B, 2003, KYBERNETES, V32, P174, DOI 10.1108/03684920310452391
   Flanders M, 2015, COMPUT APPL ENG EDUC, V23, P846, DOI 10.1002/cae.21656
   Grunwald S., 2000, SOIL SCI, P165
   Huang B, 1999, COMPUT GEOSCI-UK, V25, P1167, DOI 10.1016/S0098-3004(99)00073-4
   Kan HY, 2001, COMPUT IND, V45, P197, DOI 10.1016/S0166-3615(01)00093-8
   Kim DO, 2000, J DIGIT IMAGING, V13, P238, DOI 10.1007/BF03167678
   Liang JS, 2007, INT J ADV MANUF TECH, V34, P617, DOI 10.1007/s00170-006-0627-y
   McCaffrey KJW, 2008, GEOSPHERE, V4, P588, DOI 10.1130/GES00147.1
   Moszynski Marek, 2003, J ACOUST SOC AM, V114, P2301
   Reitmayr G, 1999, VISUAL COMPUT, V15, P395, DOI 10.1007/s003710050187
   Thurmond JB, 2005, COMPUT GEOSCI-UK, V31, P913, DOI 10.1016/j.cageo.2005.03.007
   Tsou Jennifer C., 2003, COMPUT IND, V50, P207
   Wang HP, 2008, CHINESE GEOGR SCI, V18, P374, DOI 10.1007/s11769-008-0374-x
   Wang XY, 1997, OPT FIBER TECHNOL, V3, P189, DOI 10.1006/ofte.1997.0210
   Xin PF, 2013, J CRANIOFAC SURG, V24, P1573, DOI 10.1097/SCS.0b013e3182688ed7
   Yu TB, 2013, INT J ADV MANUF TECH, V67, P2395, DOI 10.1007/s00170-012-4660-8
   Zhu LD, 2015, INT J ADV MANUF TECH, V78, P99, DOI 10.1007/s00170-014-6649-y
   Zhu L, 2014, INT J ADV MANUF TECH, V72, P995, DOI 10.1007/s00170-014-5699-5
NR 21
TC 1
Z9 1
U1 9
U2 17
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2020
VL 39
IS 6
BP 8643
EP 8653
DI 10.3233/JIFS-189260
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PF7MC
UT WOS:000599232800051
OA Bronze
DA 2023-11-10
ER

PT J
AU Kopei, VB
   Onysko, OR
   Panchuk, VG
AF Kopei, Volodymyr B.
   Onysko, Oleh R.
   Panchuk, Vitalii G.
TI Component-oriented acausal modeling of the dynamical systems in Python
   language on the example of the model of the sucker rod string
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Component-oriented modeling; Acausal modeling; Hybrid modeling;
   Dynamical system; Variable structure system; Difference equations;
   Python; SymPy; Sucker rod string; Multi-domain modeling
AB Typically, component-oriented acausal hybrid modeling of complex dynamic systems is implemented by specialized modeling languages. A well-known example is the Modelica language. The specialized nature, complexity of implementation and learning of such languages somewhat limits their development and wide use by developers who know only general-purpose languages. The paper suggests the principle of developing simple to understand and modify Modelica-like system based on the general-purpose programming language Python. The principle consists in: (1) Python classes are used to describe components and their systems, (2) declarative symbolic tools SymPy are used to describe components behavior by difference or differential equations, (3) the solution procedure uses a function initially created using the SymPy lambdify function and computes unknown values in the current step using known values from the previous step, (4) Python imperative constructs are used for simple events handling, (5) external solvers of differential-algebraic equations can optionally be applied via the Assimulo interface, (6) SymPy package allows to arbitrarily manipulate model equations, generate code and solve some equations symbolically. The basic set of mechanical components (1D translational "mass", "spring-damper" and "force") is developed. The models of a sucker rods string are developed and simulated using these components. The comparison of results of the sucker rod string simulations with practical dynamometer cards and Modelica results verify the adequacy of the models. The proposed approach simplifies the understanding of the system, its modification and improvement, adaptation for other purposes, makes it available to a much larger community, simplifies integration into third-party software.
C1 [Kopei, Volodymyr B.; Onysko, Oleh R.; Panchuk, Vitalii G.] Ivano Frankivsk Natl Tech Univ Oil & Gas, Dept Computerized Mech Engn, Ivano Frankivsk, Ukraine.
C3 Ministry of Education & Science of Ukraine; Ivano-Frankivsk National
   Technical University of Oil & Gas
RP Kopei, VB (通讯作者)，Ivano Frankivsk Natl Tech Univ Oil & Gas, Dept Computerized Mech Engn, Ivano Frankivsk, Ukraine.
EM volodymyr.kopey@nung.edu.ua
RI Onysko, Oleh/HSE-6442-2023; Kopei, Volodymyr/I-3942-2017; Onysko, Oleh
   R/K-9747-2017
OI Onysko, Oleh/0000-0002-6543-9554; Kopei, Volodymyr/0000-0003-0008-8260;
   Onysko, Oleh R/0000-0002-6543-9554
CR Åkesson J, 2010, COMPUT CHEM ENG, V34, P1737, DOI 10.1016/j.compchemeng.2009.11.011
   Andersson C, 2015, MATH COMPUT SIMULAT, V116, P26, DOI 10.1016/j.matcom.2015.04.007
   [Anonymous], 1982, DESCRIPTION DASSL DI
   [Anonymous], 2015, PRINCIPLES OBJECT OR
   [Anonymous], 2012, ROD PUMPING MODERN M
   Atkinson K. E., 1989, INTRO NUMERICAL ANAL, V2nd ed.
   Barton P. I., 1993, International Conference on Simulation in Engineering Education. Proceedings of the 1993 SCS Western Simulation Multiconference on Simulation in Engineering Education, P25
   Beal LDR, 2018, PROCESSES, V6, DOI 10.3390/pr6080106
   Belov IG., 1960, STUDY OPERATION DOWN
   Benvenuti L, 2014, INT J ROBUST NONLIN, V24, P699, DOI 10.1002/rnc.2914
   Broman D., 2010, THESIS
   Clewley R., 2007, PYDSTOOL SOFTWARE EN
   Elmqvist H, 1978, STRUCTURED MODEL LAN
   Elmqvist H, 2016, LECT NOTES COMPUT SC, V9953, P198, DOI 10.1007/978-3-319-47169-3_15
   Fritzson P., 1998, ECOOP'98 - Object-Oriented Programming. 12th European Conference. Proceedings, P67, DOI 10.1007/BFb0054087
   Fritzson P, 2005, 46 C SIM MOD SCAND S
   Fritzson P, 2009, LECT NOTES COMPUT SC, V5475, P18, DOI 10.1007/978-3-642-02047-6_3
   Hedengren JD, 2014, COMPUT CHEM ENG, V70, P133, DOI 10.1016/j.compchemeng.2014.04.013
   Hindmarsh AC, 2005, ACM T MATH SOFTWARE, V31, P363, DOI 10.1145/1089014.1089020
   Kopey VB, 2017, SCI B IVANO FRANKIVS, V2, P42
   Margolis BWL., 2017, J OPEN SOURCE SOFTW, V2, P396, DOI [10.21105/joss.00396, DOI 10.21105/JOSS.00396]
   Meurer A, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.103
   Nikolic DD, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.54
   Oliphant TE, 2007, COMPUT SCI ENG, V9, P10, DOI 10.1109/MCSE.2007.58
   Piela P., 1992, Journal of Management Information Systems, V9, P91
   Pop A, 2006, P 5 INT MOD C SEPT 2
   Runge C., 1895, MATH ANN, V46, P167, DOI DOI 10.1007/BF01446807
   Short T, 2017, EQUATION BASED MODEL
   Van Rossum G., 1995, CENTRUM WISKUNDE INF
NR 29
TC 1
Z9 1
U1 2
U2 11
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD OCT 28
PY 2019
AR e227
DI 10.7717/peerj-cs.227
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JI3WG
UT WOS:000493399000001
PM 33816880
OA Green Published, gold
DA 2023-11-10
ER

PT S
AU Kang, DZ
   Xu, BW
   Lu, JJ
   Wang, P
   Li, YH
AF Kang, DZ
   Xu, BW
   Lu, JJ
   Wang, P
   Li, YH
BE Meersman, R
   Tari, Z
   Corsaro, A
   Herrero, P
   Perez, MS
   Radenkovic, M
   Robles, V
   Santoro, C
   Albani, A
   Turowski, K
   Jarrar, M
   Gangemi, A
   Duval, E
   Spyns, P
   Palinginis, A
TI Extracting sub-ontology from multiple ontologies
SO ON THE MOVE TO MEANINGFUL INTERNET SYSTEMS 2004: OTM 2004 WORKSHOPS,
   PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT On the Move Confederated International Workshop and Conference
CY OCT 25-29, 2004
CL Agia Napa, CYPRUS
SP RMIT Univ, Sch Comp Sci & Informat Technol, Vrije Univ Brussel, Dept Comp Sci
AB Web ontologies are often too large to be used in a single application. The solution is to extract sub-ontology from large-scale ontology. An application may require several large-scale ontologies in different domains. Current approaches mainly focus on extraction in single ontology; it needs to integrate the ontologies and then extract sub-ontology from the integrated one. However, it is often difficult or even impossible to integrate large ontologies. Approach of extracting sub-ontology from multiple ontologies is required. This paper proposes a framework of extracting sub-ontologies from multiple ontologies, and suggests some first step notions. In our framework, we first translate different Ontology language code into a unified visualized model representing ontologies, and then divide the user demand to extract subontology from each single ontology. We carry out the sub-ontology extraction based on the unified model. Finally, we integrate these smaller sub-ontologies into the ontology of the user demand. The result can be translated back to the Ontology language the user uses.
C1 SE Univ, Dept Comp Sci & Engn, Nanjing 210096, Peoples R China.
   Jiangsu Inst Software Qual, Nanjing 210096, Peoples R China.
   Univ Sci & Technol, PLA, Nanjing 210007, Peoples R China.
C3 Southeast University - China; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS
RP Kang, DZ (通讯作者)，SE Univ, Dept Comp Sci & Engn, Nanjing 210096, Peoples R China.
EM bwxu@seu.edu.cn
RI Xu, Baowen/IXW-4882-2023
OI Xu, Baowen/0000-0001-7743-1296
CR Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bhatt M, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P636
   BHATT M, 2004, ICCSA, P508
   Borgida A, 2002, LECT NOTES COMPUT SC, V2519, P36
   DELFS R, 2004, GERM C BIO, P1
   KEET CM, 2004, ASPECTS ONTOLOGY INT
   PENG W, 2004, P 3 INT C MACH LEARN
   PETERSON BJ, 1998, P 5 KNOWL REPR MEETS
   STUCKENSCHMIDT H, 2002, THESIS VRIJE U AMST
   *WEBONT, 2001, W3C WEB ONT WORK GRO
   Wouters C., 2002, Database and Expert Systems Applications. 13th International Conference, DEXA 2002. Proceedings (Lecture Notes in Computer Science Vol.2453), P259
   WOUTERS C, 2004, PRACTICAL APPROACH D, P191
   UNIFIED MED LANG SYS
NR 13
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-23664-3
J9 LECT NOTES COMPUT SC
PY 2004
VL 3292
BP 731
EP 740
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BBD43
UT WOS:000225021000084
DA 2023-11-10
ER

PT J
AU Zhou, GD
   Lua, KT
AF Zhou, GD
   Lua, KT
TI Interpolation of n-gram and mutual-information based trigger pair
   language models for Mandarin speech recognition
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB While n-gram modeling is simple and dominant in speech recognition, it can only capture the short-distance context dependency within an n-word window where currently the largest practical n for natural language is three. However, many of the context dependencies in natural language occur beyond a three-word window. This paper proposes a new language modeling approach to capture the preferred relationships between words over a short or long distance through the concept of MI-Trigger pairs. Different MI-Trigger-based models are constructed in either a distance-dependent or a distance-independent way within a window from 1 to 10 words. This new MI-Trigger-based modeling is also compared and merged with word bigram modeling. It is found that the MI-Trigger-based modeling has better performance than word bigram modeling. It is also found that n-gram and MI-Trigger models have good complementarity and their proper merging can further increase the recognition rate when tested on Mandarin speech recognition. One advantage of MI-Trigger-based modeling is that the number of parameters needed for MI-Trigger modeling is much less than that of word bigram modeling. Another advantage is that the number of trigger pairs in an MI-Trigger model can be kept to a reasonable size without losing too much of its modeling power. (C) 1999 Academic Press.
C1 Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 119260, Singapore.
C3 National University of Singapore
RP Zhou, GD (通讯作者)，Natl Univ Singapore, Sch Comp, Dept Comp Sci, Lower Kent Ridge Rd, Singapore 119260, Singapore.
OI zhou, guodong/0000-0002-7887-5099
CR [Anonymous], P AAAI WORKSH INT NA
   BRENT M, 1993, COMPUTATIONAL LINGUI, V19, P263
   Brown P. F., 1992, Computational Linguistics, V18, P467
   CALZOLORI N, 1990, P COLING AUG HELS FI, V2, P54
   Church K. W., 1991, Computer Speech and Language, V5, P19, DOI 10.1016/0885-2308(91)90016-J
   GALE WA, 1990, P DARPA SPEECH NAT L, P293
   Harper MP, 1994, P AAAI WORKSH INT NA, P139
   Hindle D., 1993, Computational Linguistics, V19, P103
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KOBAYASHI T, 1994, P COLING 5 9 AUG KYO, V6, P865
   Lee Lin-Shan, 1993, P IEEE INT C AC SPEE, V2, P503
   LYU RY, 1995, P IEEE INT C AC SPEE, V1, P57
   MAGERMAN D, 1990, P AAAI, V1, P984
   Meyer D. E., 1975, ATTENTION PERFORM, VV, P98
   MURVEIT H, 1990, P INT C AC SPEECH SI, V1, P573
   ROSENFELD R, 1994, THESIS CARNEGIE MELL
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   WRIGHT JH, 1993, P EUROSPEECH BERLIN, V2, P977
   Xuedong Huang, 1993, Computer Speech and Language, V7, P137, DOI 10.1006/csla.1993.1007
   YANG YJ, 1996, COMPUTER PROCESSING, V10, P211
NR 20
TC 11
Z9 15
U1 0
U2 1
PU ACADEMIC PRESS LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD APR
PY 1999
VL 13
IS 2
BP 125
EP 141
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 187AP
UT WOS:000079764000001
DA 2023-11-10
ER

PT J
AU Rajabi, B
   Lee, SP
AF Rajabi, Bassam
   Lee, Sai Peck
TI Consistent Integration between Object Oriented and Coloured Petri Nets
   Models
SO INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY
LA English
DT Article
DE CPNs; consistency rules; OODs; OOCPN; UML
AB Unified Modeling Language (UML) is easier to understand and communicate using graphical notations, but lacks techniques for model validation and verification especially if these diagrams are updated. Formal approaches like Coloured Petri Nets (CPNs) are based on strong mathematical notations and proofs as basis for executable modeling languages. Transforming UML diagrams to executable models that are ready for analysis is significant, and providing an automated technique that can transform these diagrams to a mathematical model such as CPNs avoids the redundancy of writing specifications. The use of UML diagrams in modeling Object Oriented Diagrams (OODs) leads to a large number of interdependent diagrams. It is necessary to preserve the diagrams consistency since they are updated continuously. This research proposes a new structure for the mutual integration between OODs and CPNs modeling languages to support model changes, the proposed integration suggest a new structure (Object Oriented Coloured Petri Nets (OOCPN)) to include set of rules to check and maintain the consistency and integrity of the OOCPN model based on OODs relations.
C1 [Rajabi, Bassam; Lee, Sai Peck] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
C3 Universiti Malaya
RP Rajabi, B (通讯作者)，Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
RI Rajabi, Bassam Atieh/K-8004-2012; Lee, Sai Peck/B-8841-2010
OI Rajabi, Bassam Atieh/0000-0002-4653-0045; Lee, Sai
   Peck/0000-0002-4551-430X
CR [Anonymous], 2007, J SOFTW TOOLS TECHNO
   [Anonymous], INT ARAB J INF TECHN
   Bauskar BE, 2006, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, PROCEEDINGS, P680, DOI 10.1109/ITNG.2006.22
   Bokhari A., 2006, P 18 INT C SOFTW ENG, P568
   Bouabana-Tebibel T, 2004, IEEE SYS MAN CYBERN, P4971
   Thouraya BTI, 2008, INT ARAB J INF TECHN, V5, P7
   Briand LC, 2003, PROC IEEE INT CONF S, P256, DOI 10.1109/ICSM.2003.1235428
   Chang YL, 2000, INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P193, DOI 10.1109/MMSE.2000.897211
   Chung L., OBJECT ORIENTED ANAL
   Feng XN, 2008, ICICSE: 2008 INTERNATIONAL CONFERENCE ON INTERNET COMPUTING IN SCIENCE AND ENGINEERING, PROCEEDINGS, P553, DOI 10.1109/ICICSE.2008.97
   Fernandez-Madrigal JA, 2007, P IEEE 9 INT S SIGN, P1
   Hu Zhaoxia, 2004, SEKE, P213
   Khadka B, 2007, TRANSFORMATION LIVE
   LARA J, 2003, JISBD, V2003, P325
   Lucas FJ, 2009, INFORM SOFTWARE TECH, V51, P1631, DOI 10.1016/j.infsof.2009.04.009
   Maqbool S, 2005, THESIS U OTTAWA CANA
   Miller R., PRACTICAL UML HANDS
   Miyamoto T, 2007, IEEE IND ELEC, P64, DOI 10.1109/IECON.2007.4460048
   Motameni H., 2008, WORLD APPL SCI J, V3, P565
   Niul Jinzhong, 2003, P IASTED INT C SOFTW
   Rajabi B., 2010, INT J COMPUTER ELECT, V2, P199
   Rajabi Bassam Atieh, 2009, International Journal of Intelligent Information Technology Application, V2, P224
   Ribeiro O. R. S. F., 2006, 7 WORKSH TUT PRACT U, P237
   Shatz, 2000, INT C SOFTW ENG KNOW, P103
   Shin E., 2003, P 6 INT C UML WORKSH, P1
   Shinkawa Y, 2006, ASPEC 2006: 13TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P411
   Yang J., 2003, MIS REV, V11, P47
   Zhao Y, 2004, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON E-COMMERCE TECHNOLOGY FOR DYNAMIC E-BUSINESS, P180
NR 28
TC 7
Z9 7
U1 0
U2 2
PU ZARKA PRIVATE UNIV
PI ZARQA
PA COLL COMPUTING & INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN
SN 1683-3198
J9 INT ARAB J INF TECHN
JI Int. Arab J. Inf. Technol.
PD JUL
PY 2014
VL 11
IS 4
BP 406
EP 415
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM3SF
UT WOS:000339772400012
DA 2023-11-10
ER

PT J
AU Hossain, MR
   Hoque, MM
   Siddique, N
   Sarker, IH
AF Hossain, Md. Rajib
   Hoque, Mohammed Moshiul
   Siddique, Nazmul
   Sarker, Iqbal H.
TI Bengali text document categorization based on very deep convolution
   neural network
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Intelligent systems; Natural language processing; Low resource language;
   Semantic feature extraction; Document categorization; Deep convolution
   network
ID FEATURE-SELECTION; CLASSIFICATION
AB In recent years, the amount of digital text contents or documents in the Bengali language has increased enormously on online platforms due to the effortless access of the Internet via electronic gadgets. As a result, an enormous amount of unstructured data is created that demands much time and effort to organize, search or manipulate. To manage such a massive number of documents effectively, an intelligent text document classification system is proposed in this paper. Intelligent classification of text document in a resource-constrained language (like Bengali) is challenging due to unavailability of linguistic resources, intelligent NLP tools, and larger text corpora. Moreover, Bengali texts are available in two morphological variants (i.e., Sadhu-bhasha and Cholito-bhasha) making the classification task more complicated. The proposed intelligent text classification model comprises GloVe embedding and Very Deep Convolution Neural Network (VDCNN) classifier. Due to the unavailability of standard corpus, this work develops a large Embedding Corpus (EC) containing 969, 000 unlabelled texts and Bengali Text Classification Corpus (BDTC) containing 156, 207 labelled documents arranged into 13 categories. Moreover, this work proposes the Embedding Parameters Identification (EPI) Algorithm, which selects the best embedding parameters for low-resource languages (including Bengali). Evaluation of 165 embedding models with intrinsic evaluators (semantic & syntactic similarity measures) shows that the GloVe model is more suitable (regarding Spearman & Pearson correlation) than other embeddings (Word2Vec, FastText, m-BERT) in Bengali text. Experimental results on the test dataset confirm that the proposed GloVe + VDCNN model outperformed (achieving the highest 96.96% accuracy) the other classification models and existing methods to perform the Bengali text classification task.
C1 [Hossain, Md. Rajib; Hoque, Mohammed Moshiul; Sarker, Iqbal H.] Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong 4349, Bangladesh.
   [Siddique, Nazmul] Univ Ulster, Sch Comp Engn & Intelligent Syst, Coleraine, Londonderry, North Ireland.
C3 Chittagong University of Engineering & Technology (CUET); Ulster
   University
RP Hoque, MM (通讯作者)，Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong 4349, Bangladesh.
EM moshiul_240@cuet.ac.bd; nh.siddique@ulster.ac.uk; iqbal@cuet.ac.bd
RI Hoque, Mohammed Moshiul/AAC-8902-2021; Sarker, Iqbal H./I-8801-2018; ,
   Md. Rajib Hossain/GPF-5640-2022
OI Hoque, Mohammed Moshiul/0000-0001-8806-708X; Sarker, Iqbal
   H./0000-0003-1740-5517; , Md. Rajib Hossain/0000-0002-7941-9124
FU Establishment of CUET IT Business Incubator Project; BHTPA; ICT
   Division, Bangladesh
FX This work was supported by the Establishment of CUET IT Business
   Incubator Project, BHTPA, ICT Division, Bangladesh for the research on
   "Automatic Bengali Document Categorization based on Summarization
   Techniques".
CR Abuaiadah D., 2014, INT J COMPUT APPL, V101, P31, DOI [10.5120/17701-8680, DOI 10.5120/17701-8680]
   Agarap A.F., 2018, ARXIV PREPRINT ARXIV
   Ahmad A, 2016, INT CONF COMPUT INFO, P425, DOI 10.1109/ICCITECHN.2016.7860236
   Akhter MP, 2020, IEEE ACCESS, V8, P42689, DOI 10.1109/ACCESS.2020.2976744
   Alhaj YA, 2019, IEEE ACCESS, V7, P32664, DOI 10.1109/ACCESS.2019.2903331
   Alhawarat M, 2020, IEEE ACCESS, V8, P24653, DOI 10.1109/ACCESS.2020.2970504
   Ambalavanan AK, 2020, J BIOMED INFORM, V112, DOI 10.1016/j.jbi.2020.103578
   [Anonymous], 2008, P 25 INT C MACHINE L, DOI [DOI 10.1145/1390156.1390170, 10.1145/1390156.1390170]
   [Anonymous], 2016, P 2016 C N AM CHAPTE
   Bahassine S, 2017, J ENG SCI TECHNOL, V12, P1475
   Behera RK, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102435
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chiu Billy, 2016, P 1 WORKSH EV VECT S, P1, DOI DOI 10.18653/V1/W16-2501
   Chung J, 2014, NIPS 2014 WORKSH DEE, P1, DOI DOI 10.48550/ARXIV.1412.3555
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Dang HT, 2002, P ACL 02 WORKSH WORD, P88, DOI DOI 10.3115/1118675.1118688
   Dash N. S., 2019, UTILITY APPL LANGUAG, P17, DOI [10.1007/978-981-13-1801-6_2, DOI 10.1007/978-981-13-1801-6_2]
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhar A, 2020, ADV INTELL SYST COMP, V1034, P281, DOI 10.1007/978-981-15-1084-7_27
   Elbagir S, 2019, IEEE ACCESS, V7, P163677, DOI 10.1109/ACCESS.2019.2952127
   Enríquez F, 2016, EXPERT SYST APPL, V66, P1, DOI 10.1016/j.eswa.2016.09.005
   Gambino G., 2019, P 3 WORKSH NAT LANG
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Griesshaber D, 2020, COMPUT SPEECH LANG, V62, DOI 10.1016/j.csl.2019.101056
   Hashemi S, 2009, IEEE T KNOWL DATA EN, V21, P624, DOI 10.1109/TKDE.2008.181
   Hashmi SU, 2019, IEEE INT C SEMANT CO, P142, DOI [10.1109/ICSC.2019.00032, 10.1109/ICOSC.2019.8665534]
   He J, 2019, IEEE ACCESS, V7, P40707, DOI 10.1109/ACCESS.2019.2907992
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Hoque M. M, 2018, 2018 INT C ADV, P1, DOI [DOI 10.1109/IC4ME2.2018.8465632, 10.1109/IC4ME2.2018.8465632]
   Hossain Md Rajib, 2021, Hybrid Intelligent Systems. 20th International Conference on Hybrid Intelligent Systems (HIS 2020). Advances in Intelligent Systems and Computing (AISC 1375), P103, DOI 10.1007/978-3-030-73050-5_11
   Hossain M. R., 2021, P ICIOTCT IND, P494, DOI [10.1007/978-3-030-76736-5_45, DOI 10.1007/978-3-030-76736-5_45]
   Hossain M.R., 2020, P 17 INT C NATURAL L, P453
   Hossain M. R., 2019, P ERCICA BANG IND, P513, DOI DOI 10.1007/978-981-13-5953-8_43
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kabir F., 2015, 2015 INT C COGN COMP, P1, DOI DOI 10.1109/CCIP.2015.7100687
   Kaiming H., 2015, ABS151203385
   Keskar N.S., 2016, ABS160904836
   Khan M., 2019, DEEP LEARNING METHOD, P31, DOI [10.1007/978-981-13-3459-7, DOI 10.1007/978-981-13-3459-7]
   Khan NH, 2018, IEEE ACCESS, V6, P46019, DOI 10.1109/ACCESS.2018.2865532
   Khatouni AS, 2019, IEEE SYMP COMP COMMU, P424, DOI 10.1109/iscc47284.2019.8969578
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, P1746, DOI DOI 10.3115/V1/D14-1181
   Kowsari K, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P364, DOI 10.1109/ICMLA.2017.0-134
   Kumari M, 2016, PROCEDIA COMPUT SCI, V89, P555, DOI 10.1016/j.procs.2016.06.093
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604
   Liebeskind C, 2015, LANG RESOUR EVAL, V49, P227, DOI 10.1007/s10579-015-9298-3
   Mei JP, 2017, IEEE T FUZZY SYST, V25, P1239, DOI 10.1109/TFUZZ.2016.2604009
   Mikolov T., 2013, EFFICIENT ESTIMATION, P1, DOI [10.1162/153244303322533223, DOI 10.1162/153244303322533223]
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Moirangthem DS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113898
   Mucherino A, 2009, SPRINGER SER OPTIM A, V34, P83, DOI 10.1007/978-0-387-88615-2_4
   Nikolentzos Giannis, 2017, P 15 C EUROPEAN CHAP, P450
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Phani S, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3099473
   Rahman MA, 2018, DATA, V3, DOI 10.3390/data3020015
   Rebecca P., 2006, P 5 INT C LANGUAGE R, P831
   Rehurek R., 2010, P LREC 2010 WORKSHOP, P45
   Ruder Sebastian, 2017, OVERVIEW MULTITASK L
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sakalle A, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2020.114516
   Sarker I. H., 2021, SN COMPUTER SCI, V2, P1, DOI [DOI 10.1007/S42979-021-00557-0, 10.1007/s42979-021-00557-0]
   Shriberg E., 2004, P 5 SIGDIAL WORKSH D, P97
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Su J, 2015, EMNLP, P536
   Tang D., 2015, EMNLP, DOI 10.18653/v1/D15-1167
   TETKO IV, 1995, J CHEM INF COMP SCI, V35, P826, DOI 10.1021/ci00027a006
   Wen ZY, 2018, J MACH LEARN RES, V19
   Wu D, 2020, IEEE ACCESS, V8, P32215, DOI 10.1109/ACCESS.2020.2973430
   Xiao YS, 2017, KNOWL-BASED SYST, V120, P198, DOI 10.1016/j.knosys.2017.01.001
   Zhang X, 2015, ADV NEUR IN, V28
   Zhou DX, 2020, NEURAL NETWORKS, V124, P319, DOI 10.1016/j.neunet.2020.01.018
   Zia T, 2015, MALAYS J COMPUT SCI, V28, P93
NR 77
TC 8
Z9 8
U1 0
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 1
PY 2021
VL 184
AR 115394
DI 10.1016/j.eswa.2021.115394
EA JUL 2021
PG 23
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA WI0YM
UT WOS:000708093400018
OA Green Published, hybrid
DA 2023-11-10
ER

PT J
AU Maimaiti, M
   Liu, Y
   Luan, HB
   Sun, MS
AF Maimaiti, Mieradilijiang
   Liu, Yang
   Luan, Huanbo
   Sun, Maosong
TI Multi-Round Transfer Learning for Low-Resource NMT Using Multiple
   High-Resource Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Neural machine translation; transfer learning; high-resource language;
   low-resource language; multi-round; transliteration
AB Neural machine translation (NMT) has made remarkable progress in recent years, but the performance of NMT suffers from a data sparsity problem since large-scale parallel corpora are only readily available for high-resource languages (HRLs). In recent days, transfer learning (TL) has been used widely in low-resource languages (LRLs) machine translation, while TL is becoming one of the vital directions for addressing the data sparsity problem in low-resource NMT. As a solution, a transfer learning method in NMT is generally obtained via initializing the low-resource model (child) with the high-resource model (parent). However, leveraging the original TL to low-resource models is neither able to make full use of highly related multiple HRLs nor to receive different parameters from the same parents. In order to exploit multiple HRLs effectively, we present a language-independent and straightforward multi-round transfer learning (MRTL) approach to low-resource NMT. Besides, with the intention of reducing the differences between high-resource and low-resource languages at the character level, we introduce a unified transliteration method for various language families, which are both semantically and syntactically highly analogous with each other. Experiments on low-resource datasets show that our approaches are effective, significantly outperform the state-of-the-art methods, and yield improvements of up to 5.63 BLEU points.
C1 [Maimaiti, Mieradilijiang; Liu, Yang; Luan, Huanbo; Sun, Maosong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Key Lab Intelligent Technol & Syst,Inst Artificia, Beijing, Peoples R China.
   [Maimaiti, Mieradilijiang; Liu, Yang; Luan, Huanbo; Sun, Maosong] FIT Bldg,30,Shuang Qing Rd, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Maimaiti, M (通讯作者)，Tsinghua Univ, Dept Comp Sci & Technol, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Key Lab Intelligent Technol & Syst,Inst Artificia, Beijing, Peoples R China.; Maimaiti, M (通讯作者)，FIT Bldg,30,Shuang Qing Rd, Beijing 100084, Peoples R China.
EM meadljmm15@mails.tsinghua.edu.cn; liuyang.china@gmail.com;
   luanhuanbo@gmail.com; sms@tsinghua.edu.cn
FU National Key R&D Program of China [2017YFB0202204]; National Natural
   Science Foundation of China [61761166008, 61562082]; Advanced Innovation
   Center for Language Resources [TYR17002]; NExT++ project - National
   Research Foundation, Prime Ministers Office, Singapore under its
   IRC@Singapore Funding Initiative
FX This work is supported by National Key R&D Program of China (No.
   2017YFB0202204), National Natural Science Foundation of China (No.
   61761166008, 61562082), Advanced Innovation Center for Language
   Resources (TYR17002), and the NExT++ project supported by the National
   Research Foundation, Prime Ministers Office, Singapore under its
   IRC@Singapore Funding Initiative.
CR [Anonymous], 2017, AAAI
   [Anonymous], 2003, HLT NAACL 2003 HUMAN
   Ba Jimmy Lei, 2016, ARXIV160706450
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Barone Antonio Valerio Miceli, 2013, WMT ACL
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Carpuat Marine, 2013, P ACL
   Chen Yun, 2017, P ACL
   Chen Yun, 2018, ABS180203116 CORR
   Cheng Yong, 2016, P ACL
   Cheng Yong, 2017, P IJCAI
   Chiang David., 2005, P ACL, DOI 10.3115/1219840.1219873
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Chu C., 2017, ABS170103214 CORR
   Dabre Raj, 2017, P 31 PAC AS C LANG I, P282
   Dong D, 2015, ACL 15
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Firat Orhan, 2016, P NAACL
   Firat Orhan, 2016, PROCEEDINGS
   Goldwater Sharon, 2005, HLT EMNLP
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hasan Kazi Saidul, 2009, EACL
   He K., 2016, LECT NOTES COMPUT SC, P70, DOI DOI 10.1007/978-3-319-46493-0_38
   Hong S, 2016, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2016.349
   Jialin-Pan S., 2010, IEEE T KNOWL DATA EN, p[22, 1345], DOI [DOI 10.1109/TKDE.2009.191, 10.1109/TKDE.2009.191]
   Johnson M, 2017, IEEE ENER CONV, P5017, DOI 10.1109/ECCE.2017.8096848
   Junczys-Dowmunt M., 2016, ARXIV161001108V2
   Karakanta A, 2018, MACH TRANSL, V32, P167, DOI 10.1007/s10590-017-9203-5
   Knight Kevin, 2016, ABS160402201 CORR
   Koehn Philipp, 2017, NMT ACL
   Li ZG, 2009, COMPUT LINGUIST, V35, P505, DOI 10.1162/coli.2009.35.4.35403
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Luong Minh-Thang, 2015, P IWSLT
   Mieradilijiang Maimaiti, 2018, ICIS2018
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Nguyen T. Q., 2017, IJCNLP
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan Sinno Jialin, 2010, IEEE T NEURAL NETWOR, V22, P199, DOI DOI 10.1109/TNN.2010.2091281
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Passban P, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3099556
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Setiawan Hendra, 2017, MACH TRANSL, P1
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Vania C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2016, DOI 10.18653/v1/P17-1184
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang Zhiyang, 2011, P MT SUMM 13 XIAM CH
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Zhang J, 2017, PROC 14 C ASS MACH T
   Zheng Hao, 2017, P IJCAI
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zoph Barret, 2016, HLT NAACL
NR 51
TC 8
Z9 8
U1 1
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG
PY 2019
VL 18
IS 4
AR 38
DI 10.1145/3314945
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JL3KV
UT WOS:000495430700005
DA 2023-11-10
ER

PT J
AU Catelli, R
   Bevilacqua, L
   Mariniello, N
   di Carlo, VS
   Magaldi, M
   Fujita, H
   De Pietro, G
   Esposito, M
AF Catelli, Rosario
   Bevilacqua, Luca
   Mariniello, Nicola
   di Carlo, Vladimiro Scotto
   Magaldi, Massimo
   Fujita, Hamido
   De Pietro, Giuseppe
   Esposito, Massimo
TI Cross lingual transfer learning for sentiment analysis of Italian
   TripAdvisor reviews
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Transfer learning; Sentiment analysis; Italian dataset; BERT;
   TripAdvisor; Reviews
AB Over the years, the attention of the scientific world towards the techniques of sentiment analysis has increased considerably, driven by industry. The arrival of the Google BERT language model has confirmed the superiority of models based on a particular structure of artificial neural network called Transformer, from which many variants have resulted. These models are generally pre-trained on large text corpora and only later specialized according to the precise task to be faced on much smaller amounts of data. For these reasons, countless versions were developed to meet the specific needs of each language, especially in the case of languages with relatively few datasets available. At the same time, models that were pre-trained for multiple languages became widespread, providing greater flexibility of use in exchange for lower performance. This study shows how the use of techniques to transfer learning from languages with high resources to languages with low resources provides an important performance increase: a multilingual BERT model fine tuned on a mixed English/Italian dataset (using for the English a literature dataset and for the Italian a reviews dataset created ad-hoc from the well-known platform TripAdvisor), provides much higher performance than models specific to Italian. Overall, the results obtained by comparing the different possible approaches indicate which one is the most promising to pursue in order to obtain the best results in low resource scenarios.
C1 [Catelli, Rosario; De Pietro, Giuseppe; Esposito, Massimo] Natl Res Council CNR, Inst High Performance Comp & Networking ICAR, Naples, Italy.
   [Fujita, Hamido] Ho Chi Minh City Univ Technol HUTECH, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Fujita, Hamido] Natl Taipei Univ Technol, Taipei, Taiwan.
   [Fujita, Hamido] I Somet Inc Assoc, Morioka, Iwate, Japan.
   [Bevilacqua, Luca; Mariniello, Nicola; di Carlo, Vladimiro Scotto; Magaldi, Massimo] Engn Ingn Informat SpA, Naples, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad
   Alte Prestazioni (ICAR-CNR); Vietnam National University Hochiminh City;
   Ho Chi Minh City University of Technology (HUTECH); National Taipei
   University of Technology
RP Catelli, R (通讯作者)，Natl Res Council CNR, Inst High Performance Comp & Networking ICAR, Naples, Italy.
EM rosario.catelli@icar.cnr.it; luca.bevilacqua@eng.it;
   nicola.mariniello@eng.it; vladimiro.scottodicarlo@eng.it;
   massimo.magaldi@eng.it; h.fujita@hutech.edu.vn;
   giuseppe.depietro@icar.cnr.it; massimo.esposito@icar.cnr.it
RI Esposito, Massimo/AAX-3348-2020; Fujita, Hamido/D-6249-2012; Catelli,
   Rosario/AAL-8853-2021
OI Fujita, Hamido/0000-0001-5256-210X; Catelli,
   Rosario/0000-0001-5598-6477; de pietro, giuseppe/0000-0002-4675-5957;
   Magaldi, Massimo/0000-0003-1168-499X
FU Innovation for Data Elaboration in Heritage Areas (IDEHA) project from
   the National Operational Programme (PON) of the Italian Ministry of
   Education, University and Research (MIUR) [ARS01_00421, 2059]
FX This work is supported by the Innovation for Data Elaboration in
   Heritage Areas (IDEHA) project which has received funding from the
   National Operational Programme (PON) of the Italian Ministry of
   Education, University and Research (MIUR): code ARS01_00421 (Decree
   n.2059, 02 August 2018).
CR Agüero-Torales MM, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107373
   Akbik A., 2018, P 27 INT C COMPUTATI, P1638
   Alayba AM, 2018, LECT NOTES COMPUT SC, V11015, P179, DOI 10.1007/978-3-319-99740-7_12
   Antoun W., 2020, P 4 WORKSHOP OPEN SO, P9
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Arkhipov M, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP'2019), P89
   Augustyniak L, 2021, COMPUT SPEECH LANG, V69, DOI 10.1016/j.csl.2021.101217
   Basarslan M.S., 2021, SAKARYA U J COMPUT I, V4, P35, DOI 10.35377/saucis.04.01.833026
   Baziotis C., 2017, P 11 INT WORKSHOP SE, P747, DOI DOI 10.18653/V1/S17-2126
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Cao K., 2016, P 1 WORKSH REPR LEAR, P18, DOI DOI 10.18653/V1/W16-1603
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Colón-Ruiz C, 2020, J BIOMED INFORM, V110, DOI 10.1016/j.jbi.2020.103539
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   de Vries W, 2019, Arxiv, DOI arXiv:1912.09582
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diamantini C, 2016, 2016 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P188, DOI [10.1109/CTS.2016.0048, 10.1109/CTS.2016.46]
   Garneau N, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5546
   Guarasci R, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101261
   Hao YB, 2020, IEEE T KNOWL DATA EN, V32, P1909, DOI 10.1109/TKDE.2019.2913379
   Haque TU, 2018, 2018 IEEE INT C INN, P1, DOI [DOI 10.1109/ICIRD.2018.8376299, 10.1109/icird.2018.8376299]
   Heinzerling B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2989
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hutto C.J., 2014, ICWSM, DOI DOI 10.1609/ICWSM.V8I1.14550
   Hvingelby R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4597
   Jiang QN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6280
   Kapociute-Dzikiene J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121412
   Karthikeyan K., 2020, 8 INT C LEARNING REP
   Kokalj E., 2021, P EACL HACK NEWS MED, P16
   Kuratov Y, 2019, Arxiv, DOI arXiv:1905.07213
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample Guillaume, 2018, 6 INT C LEARNING REP
   Le H, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2479
   Li D, 2016, 2016 FIRST IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND THE INTERNET (ICCCI 2016), P471, DOI 10.1109/CCI.2016.7778967
   Li MZ, 2021, APPL INTELL, V51, P5016, DOI 10.1007/s10489-020-02101-8
   Li Y, 2017, COGN COMPUT, V9, P843, DOI 10.1007/s12559-017-9492-2
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Lundberg SM, 2017, ADV NEUR IN, V30
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mosbach M., 2021, INT C LEARN REPR
   Mukherjee S, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3092
   Mulcaire P, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3912
   Nozza D., 2020, ARXIV
   Ott M, 2011, P 49 ANN M ASS COMPU, V1, P309, DOI DOI 10.1145/2567948.2577293
   Ott Myle, 2013, HLT NAACL, P497
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Park SM, 2021, INFORM FUSION, V67, P41, DOI 10.1016/j.inffus.2020.10.009
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Perikos I, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P273
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Polignano M., 2019, CEUR WORKSHOP PROC, VVolume 2481, P1
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Ray B, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106935
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Sahin GG, 2020, COMPUT LINGUIST, V46, P335, DOI [10.1162/COLI_a_00376, 10.1162/coli_a_00376]
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Singla Z., 2017, INT CONF COMPUT, P1
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Vaswani A., 2017, ARXIV, V30, P5998
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zhang Tianyi, 2021, P ICLR
   Zhu Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P912
NR 67
TC 2
Z9 2
U1 3
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2022
VL 209
AR 118246
DI 10.1016/j.eswa.2022.118246
EA AUG 2022
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA 4R4YQ
UT WOS:000856772000006
DA 2023-11-10
ER

PT J
AU Tsai, JJP
   Sistla, AP
   Sahay, A
   Paul, R
AF Tsai, JJP
   Sistla, AP
   Sahay, A
   Paul, R
TI Incremental verification of architecture specification language for
   real-time systems
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE model-checking; architecture; requirements specification; labeled
   transition system
AB The concept of software architecture has recently emerged as a new way to improve our ability to effectively construct large scale software systems. However, there is no formal architecture specification language available to model and analyze temporal properties of complex real-time systems. In this paper, an object-oriented logic-based architecture specification language for real-time systems is discussed. Representation of the temporal properties and timing constraints, and their integration with the language to model real-time concurrent systems is given. Architecture based specification languages enable the construction of large system architectures and provide a means of testing and validation. In general, checking the timing constraints of real-time systems is done by applying model checking to the constraint expressed as a formula in temporal logic. The complexity of such a formal method depends on the size of the representation of the system. It is possible that this size could increase exponentially when the system consists of several concurrently executing real-time processes. This means that the complexity of the algorithm will be exponential in the number of processes of the system and thus the size of the system becomes a limiting factor. Such a problem has been defined in the literature as "state explosion problem". We propose a method of incremental verification of architectural specifications for real-time systems. The method has a lower complexity in a sense that it does not work on the whole state space, but only on a subset of it that is relevant to the property to be verified.
C1 Univ Illinois, Dept Elect Engn & Comp Sci, Chicago, IL 60607 USA.
   Testing & Evaluat, Washington, DC 20301 USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital
RI Tsai, Jih-Jin/D-4508-2009
CR ANDERSEN HR, 1992, MODEL CHECKING BOOLE
   BURCH J, 1990, IEEE S LOG COMP SCI, P428
   CLARKE EM, 1989, 4 ANN S LICS JUN
   CLEAVELAND R, 1986, FORMAL METHODS SYSTE
   DELEON H, 1992, FORMAL METHODS SYSTE
   EMERSON EA, 1993, INT C COMP AID VER C
   EMERSON EA, 1996, LOGIC COMPUTER SCI
   KOZEN D, 1983, THEORETICAL COMPUTER
   SOKOLSKY V, 1994, 6 INT C COMP AID VER
   TSAI JJP, 1994, KNOWLEDGE BASED SOFT
   TSAI JJP, 1992, IEEE T SOFTWARE ENG, V18
NR 11
TC 1
Z9 1
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 9128, SINGAPORE
SN 0218-1940
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD SEP
PY 1998
VL 8
IS 3
BP 347
EP 360
DI 10.1142/S0218194098000194
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 137EX
UT WOS:000076902800004
DA 2023-11-10
ER

PT J
AU Shi, YY
   Larson, M
   Jonker, CM
AF Shi, Yangyang
   Larson, Martha
   Jonker, Cathohin M.
TI Recurrent neural network language model adaptation with curriculum
   learning
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Recurrent neural networks; Language models; Curriculum learning; Latent
   Dirichlet allocation; Topics; Socio-situational setting
ID MAXIMUM-ENTROPY APPROACH
AB This paper addresses the issue of language model adaptation for Recurrent Neural Network Language Models (RNNLMS), which have recently emerged as a state-of-the-art method for language modeling in the area of speech recognition. Curriculum learning is an established machine learning approach that achieves better models by applying a curriculum, i.e., a well-planned ordering of the training data, during the learning process. Our contribution is to demonstrate the importance of curriculum learning methods for adapting RNNLMS and to provide key insights on how they should be applied. RNNLMS model language in a continuous space and can theoretically exploit word-dependency information over arbitrarily long distances. These characteristics give RNNLMS the ability to learn patterns robustly with relatively little training data, implying that they are well suited for adaptation. In this paper, we focus on two related challenges facing language models: within-domain adaptation and limited-data within-domain adaptation. We propose three types of curricula that start with general data, i.e., characterizing the domain as a whole, and move towards specific data, i.e., characterizing the sub-domain targeted for adaptation. Effectively, these curricula result in a model that can be considered to represent an implicit interpolation between general data and sub-domain-specific data. We carry out an extensive set of experiments that investigates how adapting RNNLMS using curriculum learning can improve their performance.
   Our first set of experiments addresses the within-domain adaptation challenge, i.e., creating models that are adapted to specific sub-domains that are part of a larger, heterogeneous domain of speech data. Under this challenge, all training data is available to the system at the time when the language model is trained. First, we demonstrate that curriculum learning can be used to create effective sub-domain-adapted RNNLMS. Second, we show that a combination of sub-domain-adapted RNNLMS can be used if the sub-domain of the target data is unknown at test time. Third, we explore the potential of applying combinations of sub-domain-adapted RNNLMS to data for which sub-domain information is unknown at training time and must be inferred.
   Our second set of experiments addresses limited-data within-domain adaptation, i.e., adapting an existing model trained on a large set of data using a smaller amount of data from the target sub-domain. Under this challenge, data from the target sub-domain is not available at the time when the language model is trained, but rather becomes available little by little over time. We demonstrate that the implicit interpolation carried out by applying curriculum learning methods to RNNLMS outperforms conventional interpolation and has the potential to make more of less adaptation data. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Shi, Yangyang; Larson, Martha; Jonker, Cathohin M.] Delft Univ Technol, Dept Intelligent Syst, NL-2628 CD Delft, Netherlands.
   [Shi, Yangyang] Microsoft, Language Understanding, Suzhou 215123, Peoples R China.
C3 Delft University of Technology
RP Shi, YY (通讯作者)，Delft Univ Technol, Dept Intelligent Syst, Mekelweg 4, NL-2628 CD Delft, Netherlands.
EM yangshi@microsoft.com
CR Amaya F, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P10
   [Anonymous], 1991, P DARPA WORKSHOP SPE, DOI DOI 10.3115/112405.112464
   [Anonymous], 2009, P HUMAN LANGUAGE TEC
   [Anonymous], 2013, 2013 IEEE INT C MULT
   [Anonymous], 2013, CORR
   [Anonymous], 1999, P EUR C SPEECH COMM
   Bellegarda JR, 2004, SPEECH COMMUN, V42, P93, DOI 10.1016/j.specom.2003.08.002
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y., 2009, P 26 ANN INT C MACHI, DOI DOI 10.1145/1553374.1553380
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brown P. F., 1992, Computational Linguistics, V18, P467
   den Bosch Van A., 2006, TRAITEMENT AUTOMATIQ, V46, P39
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Iyer R., 1999, IEEE T SPEECH AUDIO, V7, P236
   IYER R, 1994, P WORKSH HUM LANG TE, P82
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Mikolov T., 2012, STAT LANGUAGE MODELS
   Mikolov T, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P612
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Oostdijk N., 1999, BUILDING CORPUS SPOK
   Oostdijk N., 2002, LREC 2002, P340
   Qiu L., 2013, INT C ADV COMP SCI E
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159
   ROSENFELD R, 1994, THESIS CARNEGIE MELL
   Shi Y, 2010, 22 BEN C ART INT, P154
   Shi YY, 2012, LECT NOTES COMPUT SC, V7499, P472, DOI 10.1007/978-3-642-32790-2_57
   Shi YY, 2011, LECT NOTES ARTIF INT, V6836, P99, DOI 10.1007/978-3-642-23538-2_13
   Tam Y., 2005, P INTERSPEECH, P5
   Wang W, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P238
   Wiggers P, 2006, LECT NOTES ARTIF INT, V4188, P555
   Yangyang Shi, 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P455, DOI 10.1109/ASRU.2011.6163974
NR 36
TC 20
Z9 23
U1 0
U2 28
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD SEP
PY 2015
VL 33
IS 1
BP 136
EP 154
DI 10.1016/j.csl.2014.11.004
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA CG2GT
UT WOS:000353093600007
DA 2023-11-10
ER

PT J
AU Pan, M
   Li, T
   Liu, Y
   Pei, QL
   Huang, EA
   Huang, JX
AF Pan, Min
   Li, Teng
   Liu, Yu
   Pei, Quanli
   Huang, Ellen Anne
   Huang, Jimmy X.
TI A semantically enhanced text retrieval framework with abstractive
   summarization
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article; Early Access
DE BERT; document re-ranking; passage-level relevance; pretrained language
   models; semantic search
AB Recently, large pretrained language models (PLMs) have led a revolution in the information retrieval community. In most PLMs-based retrieval frameworks, the ranking performance broadly depends on the model structure and the semantic complexity of the input text. Sequence-to-sequence generative models for question answering or text generation have proven to be competitive, so we wonder whether these models can improve ranking effectiveness by enhancing input semantics. This article introduces SE-BERT, a semantically enhanced bidirectional encoder representation from transformers (BERT) based ranking framework that captures more semantic information by modifying the input text. SE-BERT utilizes a pretrained generative language model to summarize both sides of the candidate passage and concatenate them into a new input sequence, allowing BERT to acquire more semantic information within the constraints of the input sequence's length. Experimental results from two Text Retrieval Conference datasets demonstrate that our approach's effectiveness increasing as the length of the input text increases.
C1 [Pan, Min; Li, Teng; Liu, Yu] Hubei Normal Univ, Sch Comp & Informat Engn, Huangshi, Hubei, Peoples R China.
   [Pei, Quanli; Huang, Jimmy X.] York Univ, Sch Informat Technol, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
   [Huang, Ellen Anne] Western Univ, Dept Comp Sci, London, ON, Canada.
C3 Hubei Normal University; York University - Canada; Western University
   (University of Western Ontario)
RP Huang, JX (通讯作者)，York Univ, Sch Informat Technol, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
EM jhuang@yorku.ca
FU This research is supported by the Natural Sciences and Engineering
   Research Council (NSERC) of Canada, the York Research Chairs (YRC)
   program and an ORF-RE (Ontario Research Fund- Research Excellence) award
   in BRAIN Alliance. This research is also supporte; Natural Sciences and
   Engineering Research Council (NSERC) of Canada; York Research Chairs
   (YRC) program; ORF-RE (Ontario Research Fund- Research Excellence) award
   in BRAIN Alliance [62172144]; National Natural Science Foundation of
   China [2023AFB981]; Hubei Provincial Natural Science Foundation of
   China; China Scholarship Council (CSC), Innovation Fund [D20222501];
   Hubei Normal University and Educational Commission of Hubei Province of
   China
FX This research is supported by the Natural Sciences and Engineering
   Research Council (NSERC) of Canada, the York Research Chairs (YRC)
   program and an ORF-RE (Ontario Research Fund- Research Excellence) award
   in BRAIN Alliance. This research is also supported by the National
   Natural Science Foundation of China (62172144) and Hubei Provincial
   Natural Science Foundation of China (No. 2023AFB981). In addition, the
   first author is supported in part by the China Scholarship Council
   (CSC), Innovation Fund sponsored by Hubei Normal University and
   Educational Commission of Hubei Province of China (D20222501). We
   greatly appreciate anonymous reviewers and the associate editor for
   their valuable review comments that greatly helped to improve the
   quality of this article.
CR Ai QY, 2018, ACM/SIGIR PROCEEDINGS 2018, P135, DOI 10.1145/3209978.3209985
   Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2387, DOI 10.1145/3477495.3531863
   Chen XY, 2021, Arxiv, DOI arXiv:2104.08523
   Clarke CLA., P 13 TEXT RETR C
   Dai ZY, 2019, Arxiv, DOI arXiv:1910.10687
   Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P985, DOI 10.1145/3331184.3331303
   Devlin J., P 17 C N AM CHAPT AS
   Dietz L., TREC COMPLEX ANSWER
   Dong L, 2019, ADV NEUR IN, V32
   Du Z., P 60 ANN M ASS COMP
   Fan YX, 2018, ACM/SIGIR PROCEEDINGS 2018, P375, DOI 10.1145/3209978.3209980
   Hofstätter S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1349, DOI 10.1145/3404835.3462889
   Huang X., P 14 TEXT RETRIEVAL
   Huang XJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P307, DOI 10.1145/1571941.1571995
   Jian FH, 2020, COMPUT INTELL-US, V36, P486, DOI 10.1111/coin.12248
   Lewis M, 2019, Arxiv, DOI [arXiv:1910.13461, DOI 10.48550/ARXIV.1910.13461, 10.48550/arXiv.1910.13461]
   MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1101, DOI 10.1145/3331184.3331317
   Macdonald C., PUPPY MATURITY EXPER
   Nallapati R, 2016, Arxiv, DOI arXiv:1602.06023
   Nguyen T., P 30 C NEUR INF PROC
   Nogueira R, 2020, Arxiv, DOI arXiv:1901.04085
   Padaki R., P EUR C INF RETR
   Pan M, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102734
   Pan M, 2020, J ASSOC INF SCI TECH, V71, P264, DOI 10.1002/asi.24241
   Raffel C, 2020, J MACH LEARN RES, V21
   ROBERTSON SE, 1977, J DOC, V33, P294, DOI 10.1108/eb026647
   Suleiman D, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9365340
   Vaswani A., ATTENTION IS ALL YOU
   Voorhees EM., P 13 TEXT RETR C
   Wang JM, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102342
   Wang PF, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P209, DOI 10.1145/3397271.3401134
   Wu ZJ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P605, DOI 10.1145/3331184.3331233
   Xia LH, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P70, DOI 10.1145/3477495.3532058
   Yang PL, 2018, ACM J DATA INF QUAL, V10, DOI 10.1145/3239571
   Yilmaz ZA., P 2019 C EMP METH NA
   Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P19
   Yin X., P 33 INT ACM SIGIR C
   Yu H., PREPRINT
   Zhang Jingqing, 2020, P INT C MACH LEARN, P11328, DOI DOI 10.1038/S41746-021-00437-0
   Zhao J., ACM T INFORM SYSTEMS
   Zhao JS, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P155
   Zheng Z, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102672
NR 42
TC 0
Z9 0
U1 6
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0824-7935
EI 1467-8640
J9 COMPUT INTELL-US
JI Comput. Intell.
PD 2023 SEP 28
PY 2023
DI 10.1111/coin.12603
EA SEP 2023
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S7DN0
UT WOS:001072737300001
OA hybrid
DA 2023-11-10
ER

PT J
AU Li, ZY
   Ding, X
   Liu, T
AF Li, Zhongyang
   Ding, Xiao
   Liu, Ting
TI TransBERT: A Three-Stage Pre-training Technology for Story-Ending
   Prediction
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Natural language processing; story-ending prediction; transfer learning;
   pre-trained models
AB Recent advances, such as GPT, BERT, and RoBERTa, have shown success in incorporating a pre-trained transformer language model and fine-tuning operations to improve downstream NLP systems. However, this framework still has some fundamental problems in effectively incorporating supervised knowledge from other related tasks. In this study, we investigate a transferable BERT (TransBERT) training framework, which can transfer not only general language knowledge from large-scale unlabeled data but also specific kinds of knowledge from various semantically related supervised tasks, for a target task. Particularly, we propose utilizing three kinds of transfer tasks, including natural language inference, sentiment classification, and next action prediction, to further train BERT based on a pre-trained model. This enables the model to get a better initialization for the target task. We take story-ending prediction as the target task to conduct experiments. The final results of 96.0% and 95.0% accuracy on two versions of Story Cloze Test datasets dramatically outperform previous state-of-the-art baseline methods. Several comparative experiments give some helpful suggestions on how to select transfer tasks to improve BERT. Furthermore, experiments on six English and three Chinese datasets show that TransBERT generalizes well to other tasks, languages, and pre-trained models.
C1 [Li, Zhongyang; Ding, Xiao; Liu, Ting] Harbin Inst Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Liu, T (通讯作者)，Harbin Inst Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
EM zyli@ir.hit.edu.cn; xding@ir.hit.edu.cn; tliu@ir.hit.edu.cn
RI liu, liu/JEO-6900-2023; liu, ting/GZM-3326-2022
FU National Key Research and Development Program of China [2018AAA0101901];
   National Natural Science Foundation of China (NSFC) [61976073,
   61702137]; China Scholarship Council
FX We gratefully acknowledge the support of the National Key Research and
   Development Program of China (2018AAA0101901) and the National Natural
   Science Foundation of China (NSFC) via Grant 61976073 and 61702137. It
   was also partly sponsored by the China Scholarship Council.
CR [Anonymous], 2017, P 2 WORKSHOP LINKING, DOI DOI 10.18653/V1/W17-0907
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Cai Z, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P616, DOI 10.18653/v1/P17-2097
   Cer D., 2017, P 11 INT WORKSHOP SE, P1, DOI [DOI 10.18653/V1/S17-2001, 10.1865/3v1/S17-2001]
   Chaturvedi Snigdha, 2017, P EMNLP 2017, P1603
   Chen JA, 2019, AAAI CONF ARTIF INTE, P6244
   Chen J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4946
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2475
   Conneau Alexis, 2019, ARXIV191102116
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177
   Devlin Jacob, 2019, BERT PRE TRAINING DE, P4171
   Dolan B., 2005, 3 INT WORKSHOP PARAP
   Fu ZX, 2018, AAAI CONF ARTIF INTE, P663
   Gao Jianfeng, 2015, P 2015 C N AM CHAPT, P912, DOI DOI 10.3115/V1/N15-1092
   Giampiccolo Danilo, 2007, P ACL PASCAL WORKSHO, P1
   Guan J, 2019, AAAI CONF ARTIF INTE, P6473
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Li Q., 2018, P 27 INT C COMPUTATI, P1754
   Li Z, 2018, PROC 27 INT C COMPUT, P1033
   Li ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4201
   Li ZY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1800
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Liu Xin, 2018, P 27 INT C COMP LING, P1952
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Luo FL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6020
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mo KX, 2018, AAAI CONF ARTIF INTE, P5317
   Mostafazadeh N., 2016, P 2016 C N AM CHAPTE, P839, DOI [DOI 10.18653/V1/N16, 10.18653/v1/N16-1098]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Phang J., 2018, ARXIV181101088
   Qin LB, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2078
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Roemmele Melissa, 2011, 2011 AAAI SPRING S S, P90
   Shang Mingyue, 2018, ARXIV PREPRINT ARXIV
   Sharma R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P752
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang BN, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4123
   Wang TM, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5233
   Wang YL, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901772
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yang Zhilin, 2017, ICLR
   Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P93
   Zhou MT, 2019, IEEE-ACM T AUDIO SPE, V27, P719, DOI 10.1109/TASLP.2019.2893499
NR 49
TC 2
Z9 3
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR
PY 2021
VL 20
IS 1
AR 16
DI 10.1145/3427669
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RO2RN
UT WOS:000640893600014
DA 2023-11-10
ER

PT J
AU Van Uytsel, DH
   Van Compernolle, D
AF Van Uytsel, DH
   Van Compernolle, D
TI Language modeling with probabilistic left corner parsing
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB We present a novel language model, suitable for large-vocabulary continuous speech recognition, based on parsing with a probabilistic left corner grammar (PLCG). The PLCG probabilities are conditioned on local and non-local features of the partial parse tree, and some of these features are lexical. They are not derived from another stochastic grammar, but directly induced from a treebank, a corpus of text sentences, annotated with parse trees. A context-enriched constituent represents all partial parse trees that are equivalent with respect to the probability of the next parse move. For computational efficiency the parsing problem is represented as a traversal through a compact stochastic network of constituents connected by PLCG moves. The efficiency of the algorithm is due to the fact that the network consists of recursively nested, shared subnetworks. The PLCG-based language model results from accumulating the probabilities of all (partial) paths through this network. Next word probabilities can be computed synchronously with the probabilistic left corner parsing algorithm in one single pass from left to right. They are guaranteed to be normalized, even when pruning less likely paths. Finally, it is shown experimentally that the PLCG-based language model is a competitive alternative to other syntax-based language models, both in efficiency and accuracy. (C) 2004 Elsevier Ltd. All rights reserved.
C1 Katholieke Univ Leuven, ESAT, B-3001 Heverlee, Belgium.
C3 KU Leuven
RP Van Uytsel, DH (通讯作者)，Katholieke Univ Leuven, ESAT, Kasteelpk Arenberg 10, B-3001 Heverlee, Belgium.
EM donghoon@esat.kuleuven.ac.be
CR [Anonymous], 1993, PROC 6 C EUROPEAN CH, P305
   [Anonymous], 1998, 36 ANN M ASS COMPUTA
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 1999, P 37 ANN M ASS COMP
   Bod R, 2000, P ICSLP2000 BEIJ CHI, VIII, P106
   Charniak E, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA132
   Charniak E, 2001, P 39 ANN M ASS COMP
   CHELBA C, 1999, P EUR C SPEECH COMM, V1, P1567
   CHELBA C, 2000, THESIS J HOPKINS U
   Chen Stanley, 1998, EMPIRICAL STUDY SMOO
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   GRIFFITHS TV, 1965, COMMUN ACM, V8, P289, DOI 10.1145/364914.364943
   Hopcroft JE, 2001, ACM SIGACT NEWS, V32, P60
   Jelinek F., 1997, STAT METHODS SPEECH
   JELINEK F, 1999, P EUR C SPEECH COMM, V1
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KAY M, 1989, P 1 INT WORKSH PARS
   KIM W, 2001, P 7 EUR C SPEECH COM, P717
   LANG B, 1974, P 2 C AUT LANG PROGR, P255
   LEERMAKERS R, 1992, INFORM PROCESS LETT, V41, P87, DOI 10.1016/0020-0190(92)90260-3
   MANNING C, 1997, P 5 INT C PARS TECHN, P147
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   MATSUMOTO Y, 1983, NEW GENERAT COMPUT, V1, P145, DOI 10.1007/BF03037421
   MOORE RC, 2000, P 6 IWPT TRENT IT, P171
   Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526
   Rosenkrantz D. J., 1970, IEEE conference record of 1970 11th annual symposium on switching and automata theory, P139
   STOLCKE A, 1995, COMPUT LINGUIST, V21, P165
   STOLCKE A, 1997, WS96 PROJECT REPORT
   VANAELTEN F, 2000, SR00027 L H
   vanNoord G, 1997, COMPUT LINGUIST, V23, P425
   VANUYTSEL D, 2001, P IEEE AUT SPEECH RE
   VANUYTSEL DH, 2003, PSISPCH031
   WIREN M, 1987, P 3 C EUR CHAPT ASS, P226
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824
NR 35
TC 5
Z9 5
U1 0
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD APR
PY 2005
VL 19
IS 2
BP 171
EP 204
DI 10.1016/j.csl.2004.05.009
PG 34
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 889XL
UT WOS:000226476100003
DA 2023-11-10
ER

PT J
AU Vulic, I
   Baker, S
   Ponti, EM
   Petti, U
   Leviant, I
   Wing, K
   Majewska, O
   Bar, E
   Malone, M
   Poibeau, T
   Reichart, R
   Korhonen, A
AF Vulic, Ivan
   Baker, Simon
   Ponti, Edoardo Maria
   Petti, Ulla
   Leviant, Ira
   Wing, Kelly
   Majewska, Olga
   Bar, Eden
   Malone, Matt
   Poibeau, Thierry
   Reichart, Roi
   Korhonen, Anna
TI Multi-SimLex: A Large-Scale Evaluation of Multilingual and Crosslingual
   Lexical Semantic Similarity
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We introduce Multi-SimLex, a large-scale lexical resource and evaluation benchmark covering data sets for 12 typologically diverse languages, including major languages (e.g., Mandarin Chinese, Spanish, Russian) as well as less-resourced ones (e.g., Welsh, Kiswahili). Each language data set is annotated for the lexical relation of semantic similarity and contains 1,888 semantically aligned concept pairs, providing a representative coverage of word classes (nouns, verbs, adjectives, adverbs), frequency ranks, similarity intervals, lexical fields, and concreteness levels. Additionally, owing to the alignment of concepts across languages, we provide a suite of 66 crosslingual semantic similarity data sets. Because of its extensive size and language coverage, Multi-SimLex provides entirely novel opportunities for experimental evaluation and analysis. On its monolingual and crosslingual benchmarks, we evaluate and analyze a wide array of recent state-of-the-art monolingual and crosslingual representation models, including static and contextualized word embeddings (such as fastText, monolingual and multilingual BERT, XLM), externally informed lexical representations, as well as fully unsupervised and (weakly) supervised crosslingual word embeddings. We also present a step-by-step data set creation protocol for creating consistent, Multi-Simlex-style resources for additional languages. We make these contributions-the public release of Multi-SimLex data sets, their creation protocol, strong baseline results, and in-depth analyses which can be helpful in guiding future developments in multilingual lexical semantics and representation learning-available via a Web site that will encourage community effort in further expansion of Multi-Simlex to many more languages. Such a large-scale semantic resource could inspire significant further advances in NLP across languages.
C1 [Vulic, Ivan; Baker, Simon; Ponti, Edoardo Maria; Petti, Ulla; Wing, Kelly; Majewska, Olga; Malone, Matt; Korhonen, Anna] Univ Cambridge, Language Technol Lab, Cambridge, England.
   [Leviant, Ira; Bar, Eden; Reichart, Roi] Technion, IIT, Fac Ind Engn & Management, Haifa, Israel.
   [Poibeau, Thierry] CNRS, LATTICE Lab, Paris, France.
   [Poibeau, Thierry] PSL, ENS, Paris, France.
   [Poibeau, Thierry] Univ Sorbonne Nouvelle, Paris, France.
C3 University of Cambridge; Technion Israel Institute of Technology; Centre
   National de la Recherche Scientifique (CNRS); UDICE-French Research
   Universities; Universite PSL; Ecole Normale Superieure (ENS); Universite
   Sorbonne Nouvelle - Paris 3
RP Vulic, I (通讯作者)，Univ Cambridge, Language Technol Lab, Cambridge, England.
EM iv250@cam.ac.uk; sb895@cam.ac.uk; ep490@cam.ac.uk; ump20@cam.ac.uk;
   ira.leviant@campus.technion.ac.il; lkw33cam@gmail.com; om304@cam.ac.uk;
   edenb@campus.technion.ac.il; mm2289@cam.ac.uk; thierry.poibeau@ens.fr;
   roiri@ie.technion.ac.il; alk23@cam.ac.uk
FU ERC Consolidator Grant LEXICAL: Lexical Acquisition Across Languages
   [648909]; PRAIRIE 3IA Institute fellowship ("Investissements d'avenir"
   program) [ANR-19-P3IA-0001]
FX This work is supported by the ERC Consolidator Grant LEXICAL: Lexical
   Acquisition Across Languages (no 648909). Thierry Poibeau is partly
   supported by a PRAIRIE 3IA Institute fellowship ("Investissements
   d'avenir" program, reference ANR-19-P3IA-0001).
CR Adams O, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P937
   Agirre E., 2009, HUMAN LANGUAGE TECHN
   Aldarmaki H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3906
   Alvarez-Melis D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1881
   Ammar Waleed, 2016, T ASS COMPUTATIONAL, V4, P431, DOI DOI 10.1162/TACL_A_00109
   [Anonymous], 2013, P 2013 C EMPIRICAL M
   [Anonymous], P 2018 C EMPIRICAL M, DOI DOI 10.18653/V1/D18-1156
   [Anonymous], POETICA
   [Anonymous], 2010, OXFORD HDB LINGUISTI
   [Anonymous], 2017, SEMEVAL ACL, DOI DOI 10.18653/V1/S17-2002
   [Anonymous], 2015, CORR
   [Anonymous], 2015, P 19 C COMPUTATIONAL
   [Anonymous], 2017, P CONLL
   [Anonymous], 2006, THESIS STOCKHOLM U S
   Artetxe M., 2018, PROC 22 C COMPUT NAT, P282
   Artetxe M, 2018, AAAI CONF ARTIF INTE, P5012
   Artetxe M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P789
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Artetxe Mikel, 2020, P EMNLP, Vabs 2004
   Artetxe Mikel, 2019, ARXIV PREPRINT ARXIV
   Baker C.F., 1998, 36 ANN M ASS COMPUTA, P86, DOI DOI 10.3115/980845.980860
   Baker S., 2014, P 2014 C EMP METH NA, P278, DOI DOI 10.3115/V1/D14-1034
   Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1538
   Baroni M, 2010, COMPUT LINGUIST, V36, P673, DOI 10.1162/coli_a_00016
   Baroni M, 2009, LANG RESOUR EVAL, V43, P209, DOI 10.1007/s10579-009-9081-4
   Barzegar Siamak., 2018, P LREC MIYAZ, P3912
   BJERVA J, 2018, P 2018 C N AM CHAPT, V1, P907, DOI DOI 10.18653/V1/N18-1083
   Bjerva J, 2019, COMPUT LINGUIST, V45, P381, DOI [10.1162/coli_a_00351, 10.1162/COLI.a.00351]
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Bro R, 2003, J CHEMOMETR, V17, P16, DOI 10.1002/cem.773
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   Camacho-Collados J., 2017, PROC 15 C EUR CHAPTE, P223
   Camacho-Collados J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P1
   Cao Steven, 2020, P ICLR
   Chen D., 2014, P 2014 C EMPIRICAL M, P740, DOI DOI 10.3115/V1/D14-1082
   Chen X., 2017, P 4 INT C DEP LING D, P54
   Chen XL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P261
   Cimiano P, 2005, J ARTIF INTELL RES, V24, P305, DOI 10.1613/jair.1648
   Clark JonathanH., 2020, T ACL, V8, P454, DOI [10.1162/tacl_a_00317, DOI 10.1162/TACL_A_00317]
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A., 2019, P 57 ANN M ASS COMP, P31, DOI DOI 10.18653/V1/P19-4007
   Conneau Alexis, 2018, P ICLR
   Conneau Alexis, 2018, EMNLP
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Cruse D. A., 1986, LEXICAL SEMANTICS
   De Deyne S, 2008, BEHAV RES METHODS, V40, P213, DOI 10.3758/BRM.40.1.213
   Devlin J., 2018, ARXIV, V1, P4171
   Doitch A, 2019, T ASSOC COMPUT LING, V7, P643, DOI 10.1162/tacl_a_00291
   Doval Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P294
   Doval Yerai., 2019, ABS190807742 CORR
   Dryer S. Matthew, 2013, WORLD ATLAS LANGUAGE
   Ercan G., 2018, P 27 INT C COMP LING, P3819
   Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55
   Faruqui Manaal., 2015, P 2015 C N AM CHAPT, P1606, DOI [10.3115/v1/N15-1184, DOI 10.3115/V1/N15-1184]
   Fellbaum, 1998, WORDNET, DOI [10.7551/mitpress/7287.001.0001, DOI 10.7551/MITPRESS/7287.001.0001]
   Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110
   Firth J. R., 1957, SYNOPSIS LINGUISTIC
   Francois A, 2008, STUD LANG C, V106, P163
   Frej J., 2019, ABS191205372 CORR
   Gerz Daniela, 2016, P OF THE 2016 C ON E, P2173
   Glava Goran, 2018, P 2018 C N AM CHAPT, P181
   Glavas G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P710
   Glavas G, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P34
   Glavas Goran., 2019, P EMNLP TUT ABSTR HO
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Gruber Jeffrey., 1976, LEXICAL STRUCTURES S, V25
   Harris Z., 1951, METHODS STRUCTURAL L
   HILL F, 2016, T ACL, V4, P17, DOI DOI 10.1162/tacl_a_00080
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Hu Junjie, 2020, P 37 INT C MACH LEAR
   Huang Junjie., 2019, ABS190600247 CORR
   Joshi Pratik., 2020, P 58 ANN M ASS COMP, P6282, DOI DOI 10.18653/V1/2020.ACL-MAIN.560
   Joulin A., 2018, P 2018 C EMP METH NA, P2979, DOI DOI 10.18653/V1/D18-1330
   Kamath A, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), P72
   Kamholz D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3145
   Karin KipperSchuler., 2005, THESIS U PENNSYLVANI
   Kay Paul., 2013, WORLD ATLAS LANGUAGE, P540
   Kiela D., 2015, EMNLP, DOI [10.18653/v1/D15-1242, DOI 10.18653/V1/D15-1242]
   Kiela Douwe, 2014, P 2 WORKSHOP CONTINU, V353, P21, DOI DOI 10.3115/V1/W14-1503
   Kim J.-K., 2016, PROCS 1 WORKSHOP REP, P62
   Kim JK, 2016, IEEE W SP LANG TECH, P414, DOI 10.1109/SLT.2016.7846297
   Kipper K., 2004, P 4 INT C LANG RES E, P1557
   Kipper K, 2008, LANG RESOUR EVAL, V42, P21, DOI 10.1007/s10579-007-9048-2
   Kondratyuk D., 2019, EMNLP, P2779
   Lample Guillaume, 2019, NEURIPS
   Lan Zhenzhong, 2020, P ICLR
   Lauscher A., 2019, ARXIV PREPRINT ARXIV
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4483
   Lazaridou A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P270
   Levin Beth, 1993, ENGLISH VERB CLASSES
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Lewis P, 2020, P 58 ANN M ASS COMPU, P7315, DOI [DOI 10.18653/V1/2020.ACL-MAIN.653, 10.18653/v1/2020.acl-main.653]
   Liang Yaobo., 2020, ABS200401401 CORR
   Lin YH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3125
   Littell Patrick, 2017, P 2017 C EMP METH NA, P2529, DOI DOI 10.18653/V1/D17-1268
   Littell Patrick, 2017, P OF THE 15 C OF THE, V2, DOI DOI 10.18653/V1/E17-2002
   Liu Qianchu, 2019, P CONLL, P33, DOI 10.18653/v1/K19-1004
   Liu Y., 2019, ABS190711692 CORR
   Lucas M, 2000, PSYCHON B REV, V7, P618, DOI 10.3758/BF03212999
   Luong T., 2013, P 17 C COMP NAT LANG, P104, DOI DOI 10.1007/BF02579642
   Lyons J., 1977, SEMANTICS, DOI [10.1017/CBO9781139165693, DOI 10.1017/CBO9781139165693]
   Majid A, 2007, COGN LINGUIST, V18, P133, DOI 10.1515/COG.2007.005
   MANTEL N, 1967, CANCER RES, V27, P209
   Marciniak M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2398
   McKeown K.R., 2002, P HUM LANG TECHN C, P280, DOI DOI 10.3115/1289189.1289212
   Melamud O., 2016, P C N AM CHAPTER ASS, P1030, DOI DOI 10.18653/V1/N16-1118
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov Tomas, 2018, LREC
   Mikolov Tomas, 2013, ABS13094168 ARXIV CO
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mimno David, 2017, P 2017 C EMPIRICAL M, P2873, DOI [10.18653/v1/D17-1308, DOI 10.18653/V1/D17-1308]
   Mohiuddin Tasnim, 2019, HLT NAACL NAACL 19, P3857, DOI DOI 10.18653/V1/N19-1386
   Mrksic Nikola, 2017, T ASS COMPUTATIONAL, V5, P309
   Mrksic Nikola, 2016, NAACL HLT, P142, DOI DOI 10.18653/V1/N16-1018
   Mu Jiaqi., 2018, P ICLR VANC
   Nelson DL, 2004, BEHAV RES METH INS C, V36, P402, DOI 10.3758/BF03195588
   Netisopakul P, 2019, IEEE ACCESS, V7, P142907, DOI 10.1109/ACCESS.2019.2944151
   Nivre Joakim, 2019, UNIVERSAL DEPENDENCI
   OSTLING R, 2017, P 15 C EUR CHAPT ASS, V2, P644, DOI DOI 10.18653/V1/E17-2102
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pilehvar MT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1391
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Ponti EM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2206
   Ponti EM, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P282
   Ponti Edoardo M, 2020, ARXIV PREPRINT ARXIV
   Ponti EM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1531
   Ponti EM, 2019, COMPUT LINGUIST, V45, P559, DOI [10.1162/COLI_a_00357, 10.1162/coli_a_00357]
   Ponti Edoardo Maria, 2019, P EMNLP IJCNLP, P2893
   QUINN D. HOLLAND-N., 1987, CULTURAL MODELS LANG, P3, DOI [10.1017/CBO9780511607660.002, DOI 10.1017/CBO9780511607660.002]
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Radovanovic M, 2010, J MACH LEARN RES, V11, P2487
   Rasooli M.S., 2017, T ASSOC COMPUT LING, V5, P279, DOI DOI 10.1162/TACL_A_00061
   Ren LL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2780
   Roemmele Melissa, 2011, P 2011 AAAI SPRING S
   Rotman G, 2019, T ASSOC COMPUT LING, V7, P695, DOI 10.1162/tacl_a_00294
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Rzymski C, 2020, SCI DATA, V7, DOI 10.1038/s41597-019-0341-x
   Sakaizawa Y, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P948
   Schlechtweg D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P732
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Schwartz Roy, 2016, P 2016 C N AM CHAPT, P499, DOI DOI 10.18653/V1/N16-1060
   Smith SamuelL., 2017, P ICLR C TRACK TOUL
   Snyder B., 2010, P ICML, P29
   Sogaard A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P778
   Tang Shuai., 2019, ABS190510971 CORR
   Trier Jost., 1931, THESIS U BONN
   Tsvetkov Yulia, 2016, P NAACL SAN DIEG CA, P1357, DOI DOI 10.18653/V1/N16-1161
   Turney PD, 2012, J ARTIF INTELL RES, V44, P533, DOI 10.1613/jair.3640
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Upadhyay S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1661
   van den Berg RA, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-142
   Vania C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2016, DOI 10.18653/v1/P17-1184
   Vaswani A, 2017, ADV NEUR IN, V30
   Vejdemo S, 2018, PRAGMAT COGN, V25, P50, DOI 10.1075/pc.00005.vej
   Venekoski V., 2017, P NODALIDA GOTH, V131, P231
   Virtanen A., 2019, ABS191207076 CORR
   Vulic I., 2020, P 2020 C EMP METH NA, P7222
   Vulic I, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P163
   Vulic I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4963
   Vulic I, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P247
   Vulic I, 2017, COMPUT LINGUIST, V43, P781, DOI 10.1162/COLI_a_00301
   Vulie Ivan, 2019, P 2019 C EMP METH NA, P4407, DOI DOI 10.18653/V1/D19-1449
   Wang Z., 2020, P ICLR
   Wieting J., 2015, T ASS COMPUTATIONAL, V3, P345, DOI [DOI 10.1162/TACL_A_00143, 10.1162/tacl_a_00143, DOI 10.1162/TACLA00143]
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Wolf T., 2019, ABS191003771 CORR
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833
   Wu SJ, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P120
   Wu Shijie, 2019, ABS191101464 CORR
   Xing Chao, 2015, PROC 2015 C N AM CHA, P1006, DOI DOI 10.3115/V1/N15-1104
   Yang YF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3687
   Zeman D., 2018, P CONLL 2018 SHARED, P1
   Zhang MZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3180
   Zhang Yuan., 2019, P NAACL HLT HONG KON, P1298
   Zhibiao Wu, 1994, 32nd Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference, P133
   Zhu Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P912
   Zhu Yi, 2019, P 23 C COMP NAT LANG, P216, DOI DOI 10.18653/V1/K19-1021
NR 179
TC 24
Z9 24
U1 4
U2 13
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD FEB
PY 2020
VL 46
IS 4
DI 10.1162/coli_a_00391
PG 52
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA QM8EL
UT WOS:000622006200001
OA Green Published, Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Song, DW
   Shi, YJ
   Zhang, P
   Huang, Q
   Kruschwitz, U
   Hou, YX
   Wang, B
AF Song, Dawei
   Shi, Yanjie
   Zhang, Peng
   Huang, Qiang
   Kruschwitz, Udo
   Hou, Yuexian
   Wang, Bo
TI Incorporating Intra-Query Term Dependencies in an Aspect Query Language
   Model
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article
DE information retrieval; query language model; aspect hidden Markov model;
   intra-query term dependency; query decomposition
AB Query language modeling based on relevance feedback has been widely applied to improve the effectiveness of information retrieval. However, intra-query term dependencies (i.e., the dependencies between different query terms and term combinations) have not yet been sufficiently addressed in the existing approaches. This article aims to investigate this issue within a comprehensive framework, namely the Aspect Query Language Model (AM). We propose to extend the AM with a hidden Markov model (HMM) structure to incorporate the intra-query term dependencies and learn the structure of a novel aspect HMM (AHMM) for query language modeling. In the proposed AHMM, the combinations of query terms are viewed as latent variables representing query aspects. They further form an ergodic HMM, where the dependencies between latent variables (nodes) are modeled as the transitional probabilities. The segmented chunks from the feedback documents are considered as observables of the HMM. Then the AHMM structure is optimized by the HMM, which can estimate the prior of the latent variables and the probability distribution of the observed chunks. Our extensive experiments on three large-scale text retrieval conference (TREC) collections have shown that our method not only significantly outperforms a number of strong baselines in terms of both effectiveness and robustness but also achieves better results than the AM and another state-of-the-art approach, namely the latent concept expansion model. (c) 2014Wiley Periodicals, Inc.
C1 [Song, Dawei; Shi, Yanjie; Zhang, Peng; Hou, Yuexian; Wang, Bo] Tianjin Univ, Sch Comp Sci & Technol, Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
   [Huang, Qiang] Univ E Anglia, Sch Comp, Norwich NR4 7TJ, Norfolk, England.
   [Kruschwitz, Udo] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 Tianjin University; University of East Anglia; University of Essex
RP Zhang, P (通讯作者)，Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM darcyzzj@gmail.com
OI Kruschwitz, Udo/0000-0002-5503-0341; Song, Dawei/0000-0002-8660-3608
FU Chinese National Program on Key Basic Research Project (973 program)
   [2013CB329304, 2014CB744604]; Natural Science Foundation of China
   [61272265, 61402324, 61105072]; European Union [247590]
FX This work is funded in part by the Chinese National Program on Key Basic
   Research Project (973 program, grant nos. 2013CB329304, 2014CB744604),
   the Natural Science Foundation of China (grant nos. 61272265, 61402324,
   61105072), and the European Union Framework 7 Marie-Curie International
   Research Staff Exchange Programme (grant no. 247590).
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   ALMASKARI A., 2008, P 31 ANN INT ACM SIG, P683
   Bai J., 2005, P 14 ACM INT C INF K, P688, DOI DOI 10.1145/1099554.1099725
   Blei D. M., 2001, SIGIR Forum, P343
   Bruza PD, 2012, LOG J IGPL, V20, P445, DOI 10.1093/jigpal/jzq049
   CAO G., 2005, P 28 ANN INT ACM SIG, P298, DOI DOI 10.1145/1076034.1076086
   Chengxiang Zhai, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P403, DOI 10.1145/502585.502654
   Creighton C, 2003, BIOINFORMATICS, V19, P79, DOI 10.1093/bioinformatics/19.1.79
   Dawei Song, 2013, Information Retrieval Technology. 9th Asia Information Retrieval Societies Conference, AIRS 2013. Proceedings: LNCS 8281, P133, DOI 10.1007/978-3-642-45068-6_12
   HIEMSTRA D., 2005, DIGITAL LIB ELECT, P373
   Hipp J., 2000, SIGKDD EXPLOR NEWSL, V2, P58, DOI DOI 10.1145/360402.360421
   Hoenkamp E, 2009, LECT NOTES COMPUT SC, V5766, P116, DOI 10.1007/978-3-642-04417-5_11
   HUANG Q., 2008, P ACM 17 C INF KNOWL, P1417
   Iwayama M., 2000, SIGIR Forum, V34, P10
   Jianfeng Gao, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P170
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   LAVERENKO V., 2002, P ACM 25 SIGIR C RES, P175
   Lavrenko V., 2001, SIGIR Forum, P120
   LAVRENKO V., 2002, P 2 INT C HUM LANG T, P115, DOI DOI 10.3115/1289189.1289268
   Luo JX, 2000, INT J INTELL SYST, V15, P687, DOI 10.1002/1098-111X(200008)15:8<687::AID-INT1>3.0.CO;2-X
   Metzler D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P472, DOI 10.1145/1076034.1076115
   Metzler Donald, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P311, DOI 10.1145/1277741.1277796
   Miller DRH, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P214, DOI 10.1145/312624.312680
   Nallapati R., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P383, DOI 10.1145/584792.584855
   Ponte Jay M, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Schutze H., 2008, INTRO INFORM RETRIEV, V39
   Song DW, 2012, COMPUT INTELL-US, V28, P1, DOI 10.1111/j.1467-8640.2012.00407.x
   Srivastava J., 2000, ACM SIGKDD, V1, P12, DOI DOI 10.1145/846183.846188
   Zhao JS, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P155
   Zhao JS, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1131, DOI 10.1145/2600428.2609527
   Zhao JS, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2590988
   Zobel Justin, 2001, P 24 ANN INT ACM SIG, P111, DOI DOI 10.1145/383952.383970
NR 33
TC 1
Z9 1
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0824-7935
EI 1467-8640
J9 COMPUT INTELL-US
JI Comput. Intell.
PD NOV
PY 2015
VL 31
IS 4
BP 699
EP 720
DI 10.1111/coin.12058
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CV8JQ
UT WOS:000364530800007
OA Green Accepted
DA 2023-11-10
ER

PT J
AU Özdemir, O
   Kerzel, M
   Weber, C
   Lee, JH
   Hafez, MB
   Bruns, P
   Wermter, S
AF Oezdemir, Ozan
   Kerzel, Matthias
   Weber, Cornelius
   Lee, Jae Hee
   Hafez, Muhammad Burhan
   Bruns, Patrick
   Wermter, Stefan
TI Learning Bidirectional Action-Language Translation with Limited
   Supervision and Testing with Incongruent Input
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
ID MOTOR; NICO
AB Human infant learning happens during exploration of the environment, by interaction with objects, and by listening to and repeating utterances casually, which is analogous to unsupervised learning. Only occasionally, a learning infant would receive a matching verbal description of an action it is committing, which is similar to supervised learning. Such a learning mechanism can be mimicked with deep learning. We model this weakly supervised learning paradigm using our Paired Gated Autoencoders (PGAE) model, which combines an action and a language autoencoder. After observing a performance drop when reducing the proportion of supervised training, we introduce the Paired Transformed Autoencoders (PTAE) model, using Transformer-based crossmodal attention. PTAE achieves significantly higher accuracy in language-to-action and action-to-language translations, particularly in realistic but difficult cases when only few supervised training samples are available. We also test whether the trained model behaves realistically with conflicting multimodal input. In accordance with the concept of incongruence in psychology, conflict deteriorates the model output. Conflicting action input has a more severe impact than conflicting language input, and more conflicting features lead to larger interference. PTAE can be trained on mostly unlabeled data where labeled data is scarce, and it behaves plausibly when tested with incongruent input.
C1 [Oezdemir, Ozan; Kerzel, Matthias; Weber, Cornelius; Lee, Jae Hee; Hafez, Muhammad Burhan; Wermter, Stefan] Univ Hamburg, Dept Informat, Knowledge Technol, Hamburg, Germany.
   [Bruns, Patrick] Univ Hamburg, Biol Psychol & Neuropsychol, Hamburg, Germany.
C3 University of Hamburg; University of Hamburg
RP Özdemir, O (通讯作者)，Univ Hamburg, Dept Informat, Knowledge Technol, Vogt Koelln Str 30, D-22527 Hamburg, Germany.
EM ozan.oezdemir@uni-hamburg.de
RI Hafez, Muhammad Burhan/E-5058-2015; Wermter, Stefan/IYJ-4916-2023;
   Bruns, Patrick/AAT-6268-2020
OI Hafez, Muhammad Burhan/0000-0003-1670-8962; Bruns,
   Patrick/0000-0002-2977-8874
FU German Research Foundation (DFG) [TRR 169]; IDEAS; TRR 169 Crossmodal
   Learning (CML); LeCareBot; MoReSpace
FX This work was supported by the German Research Foundation (DFG) under
   Project TRR 169 Crossmodal Learning (CML), LeCareBot, IDEAS, and
   MoReSpace.
CR Abramson Josh, 2020, ARXIV201205672
   Ahn M, 2022, Arxiv, DOI arXiv:2204.01691
   Antunes A, 2019, IEEE INT C INT ROBOT, P2614, DOI [10.1109/iros40897.2019.8967799, 10.1109/IROS40897.2019.8967799]
   Aravena P, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011751
   Arevalo J, 2020, NEURAL COMPUT APPL, V32, P10209, DOI 10.1007/s00521-019-04559-1
   Bisk Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8718
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Canals L, 2023, RECALL, V35, P4, DOI 10.1017/S0958344022000118
   Devlin J., 2018, ARXIV, V1, P4171
   Eisermann A, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534275
   Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hatori J, 2018, IEEE INT CONF ROBOT, P3774
   Hauk O, 2004, NEURON, V41, P301, DOI 10.1016/S0896-6273(03)00838-9
   Heinrich S, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00052
   Irshad Muhammad Zubair, 2021, 2021 IEEE International Conference on Robotics and Automation (ICRA), P13238, DOI 10.1109/ICRA48506.2021.9561806
   Jaegle Andrew, 2021, ARXIV210714795
   Jang Eric, 2021, 5 ANN C ROBOT LEARNI
   Jiang Y., 2022, VIMA GEN ROBOT MANIP
   Kanda H, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1852
   Kaschak MP, 2005, COGNITION, V94, pB79, DOI 10.1016/j.cognition.2004.06.005
   Kerzel M, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00028
   Kerzel M, 2017, IEEE ROMAN, P113, DOI 10.1109/ROMAN.2017.8172289
   Kingma D. P., 2014, C TRACK P
   Lu JS, 2019, ADV NEUR IN, V32
   Lynch C., 2021, ROBOTICS SCI SYSTEM, P1
   Meteyard L, 2007, PSYCHOL SCI, V18, P1007, DOI 10.1111/j.1467-9280.2007.02016.x
   Özdemir O, 2022, LECT NOTES COMPUT SC, V13530, P246, DOI 10.1007/978-3-031-15931-2_21
   Ozdemir O., 2021, 2021 IEEE INT C DEV, P1
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford A, 2021, PR MACH LEARN RES, V139
   Raffel C, 2020, J MACH LEARN RES, V21
   Reed S., 2022, T MACHINE LEARNING R, V11/2022, P1
   Shao L, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI
   Shridhar M., 2022, P 6 C ROBOT LEARNING
   Shridhar M., 2021, P 5 C ROBOT LEARNING
   Shridhar M, 2020, INT J ROBOT RES, V39, P217, DOI 10.1177/0278364919897133
   van Elk M, 2010, NEUROIMAGE, V50, P665, DOI 10.1016/j.neuroimage.2009.12.123
   Vaswani A, 2017, ADV NEUR IN, V30
   Winter A, 2022, ACTA PSYCHOL, V230, DOI 10.1016/j.actpsy.2022.103712
   Yamada T, 2018, IEEE ROBOT AUTOM LET, V3, P3441, DOI 10.1109/LRA.2018.2852838
   Zeng Andy, 2020, CORL
NR 42
TC 0
Z9 0
U1 10
U2 13
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD DEC 31
PY 2023
VL 37
IS 1
AR 2179167
DI 10.1080/08839514.2023.2179167
PG 24
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9K2CI
UT WOS:000940678800001
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Ragavan, SKV
   Shanmugavel, M
   Ganapathy, V
   Shirinzadeh, B
AF Ragavan, Sampath Kumar Veera
   Shanmugavel, Madhavan
   Ganapathy, Velappa
   Shirinzadeh, Bijan
TI Unified meta-modeling framework using bond graph grammars for conceptual
   modeling
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Mechatronic system design; Design synthesis; Unified modeling framework;
   Executable models; Design automation; Model development; Cyber-Physical
   Systems (CPS); Unified Modeling Language (UML); Model Driven Development
   (MDD); Model Based Design (MBD)
ID ACTOR-ORIENTED DESIGN; PIM TRANSFORMATION; CIM; DYNAMICS; SYSTEMS
AB Existing techniques for developing large scale complex engineering systems are predominantly software based and use Unified Modeling Language (UML). This leads to difficulties in model transformation, analysis, validation, verification and automatic code generation. Currently no general frameworks are available to bridge the concept-code gap rampant in design and development of complex, softwareintensive mechatronic systems called cyber-physical systems. To fill this gap and provide an alternative approach to Object Management Group's UML/SysML/OCL combination, we propose: Bond Graph based Unified Meta-Modeling Framework (BG-UMF). BG-UMF is a practical and viable alternative and uses a novel hybrid approach based on model unification and integration. The focus is on conceptual design and development of executable models for large systems. The viability of the framework is demonstrated through an application scenario: conceptual design and development of a navigation and control system for a rotor-craft UAV. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Ragavan, Sampath Kumar Veera; Shanmugavel, Madhavan] Monash Univ, Sch Engn, Kuala Lumpur, Malaysia.
   [Ganapathy, Velappa] SRM Univ, Fac Engn & Technol, Kancheepuram, Tamil Nadu, India.
   [Shirinzadeh, Bijan] Monash Univ, Kuala Lumpur, Malaysia.
C3 Monash University; Monash University Sunway; SRM Institute of Science &
   Technology Chennai; Monash University; Monash University Sunway
RP Ragavan, SKV (通讯作者)，Monash Univ, Sch Engn, Malaysia Campus, Kuala Lumpur, Malaysia.
EM veera.ragavan@monash.edu; madhavan.shanmugavel@monash.edu;
   ganapathy.v@ktr.srmuniv.ac.in; bijan.shirinzadeh@monash.edu
RI Velappa, Ganapathy V.G/H-3191-2014; Shanmugavel, Madhavan/GZL-9266-2022
OI Sampath Kumar, Veera Ragavan/0000-0001-6845-3362; Shanmugavel,
   Madhavan/0000-0001-7756-6086
CR Amerongen J., 2000, 1 IFAC C MECH SYST D
   [Anonymous], 2005, CIRP ANN MANUFACTURI
   Beard R, 2005, AIAA J AEROSPACE COM, V2, P92, DOI [10.2514/1.8371, DOI 10.2514/1.8371]
   Behbahani S, 2007, IEEE-ASME T MECH, V12, P227, DOI 10.1109/TMECH.2007.892822
   Bhandari S., 2008, AIAA MOD SIM TECHN C, P6523
   Borutzky W, 2010, BOND GRAPH METHODOLGY: DEVELOPMENT AND ANALYSIS OF MULTIDISCIPLINARY DYNAMIC SYSTEM MODELS, P1, DOI 10.1007/978-1-84882-882-7
   Borutzky W., 2006, P 20 EUR C MOD SIM E
   Bowers S, 2005, LECT NOTES COMPUT SC, V3716, P369
   Breedveld PC, 2011, BOND GRAPH MODELLING OF ENGINEERING SYSTEMS: THEORY, APPLICATIONS AND SOFTWARE SUPPORT, P3, DOI 10.1007/978-1-4419-9368-7_1
   Broenink J. F., 1999, Simulation Practice and Theory, V7, P481, DOI 10.1016/S0928-4869(99)00018-X
   Chandrashekar M., 1993, MODELING SIMULATION, V23, P313
   Czarnecki K, 2006, IBM SYST J, V45, P621, DOI 10.1147/sj.453.0621
   Damic V, 2006, MATH COMP MODEL DYN, V12, P175, DOI 10.1080/13873950500068757
   De Castro V, 2011, INFORM SOFTWARE TECH, V53, P87, DOI 10.1016/j.infsof.2010.09.002
   Erden MS, 2008, AI EDAM, V22, P147, DOI 10.1017/S0890060408000103
   Favre JM, 2005, ELECTRON NOTES THEOR, V127, P59, DOI 10.1016/j.entcs.2004.08.034
   France RB, 2006, COMPUTER, V39, P59, DOI 10.1109/MC.2006.65
   Gandanegara G, 2006, P I MECH ENG I-J SYS, V220, P553, DOI 10.1243/09596518JSCE210
   Gawthrop PJ, 2007, IEEE CONTR SYST MAG, V27, P24, DOI 10.1109/MCS.2007.338279
   Gawthrop PJ, 1996, METAMODELLING BOND G
   Gerber A, 2002, LECT NOTES COMPUT SC, V2505, P90
   Granda JJ, 2003, AIAA MOD SIM TECHN C
   Helms B., 2009, 2009 ASME INT DES EN
   Huzar Z, 2005, LECT NOTES COMPUT SC, V3297, P1
   INSA B., 2003, WORKSH CONS PROBL UM, VII, P43
   Kalnins A, 2010, LECT NOTES COMPUT SC, V5968, P161
   Karnopp D.C, 2006, SYSTEM DYNAMICS MODE, V3
   Karnopp D.C., 2012, ENGINEERINGPRO COLLE, V6th ed.
   Kherraf S, 2008, ASWEC 2008: 19TH AUSTRALIAN SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P338, DOI 10.1109/ASWEC.2008.63
   Kirikova M, 2010, LECT NOTES COMPUT SC, V5968, P169
   Kleppe A. G., 2003, MDA EXPLAINED MODEL
   Kühne T, 2010, LECT NOTES COMPUT SC, V6002, P240
   KURTEV I, TECHNOLOGICAL SPACES
   Layton R. A., 1998, PRINCIPLES ANAL SYST
   Ledeczi A, 2001, PROCEEDINGS OF THE 2001 IEEE INTERNATIONAL CONFERENCE ON CONTROL APPLICATIONS (CCA'01), P756, DOI 10.1109/CCA.2001.973959
   Lee E., 2003, P WORKSH SOFTW ENG E
   Lee EA, 2003, J CIRCUIT SYST COMP, V12, P231, DOI 10.1142/S0218126603000751
   Leishman JG, 2006, PRINCIPLES HELICOPTE, V2nd
   Louca L.S., 2006, MODEL REDUCTION MODA
   Lumkes J., 2001, CONTROL STRATEGIES D, V140
   Marcus A, 2004, 11TH WORKING CONFERENCE ON REVERSE ENGINEERING, PROCEEDINGS, P214, DOI 10.1109/WCRE.2004.10
   McPhee J, 2005, COMP METH APPL SCI, V2, P125
   McPhee JJ, 1997, J FRANKLIN I, V334B, P431, DOI 10.1016/S0016-0032(96)00086-5
   MONTBRUNDIFILIPPO J, 1991, J FRANKLIN I, V328, P565, DOI 10.1016/0016-0032(91)90044-4
   Mukherjee A., 2006, BOND GRAPH MODELING
   Munzinger C., DEV REAL TIME FLIGHT
   Niaz I. A., 2003, P 7 IASTED INT C SOF, P315
   Orlikowski C, 2001, MECH MACH THEORY, V36, P689, DOI 10.1016/S0094-114X(01)00012-X
   Pahl G., 1996, ENG DESIGN SYSTEMATI
   Paredis CJJ, 2001, ENG COMPUT-GERMANY, V17, P112, DOI 10.1007/PL00007197
   Poshyvanyk D, 2007, INT C PROGRAM COMPRE, P37
   Rideout D., P IMAACA 04 BOND GRA
   Rodriguez A, 2008, INT FED INFO PROC, V255, P1239
   Rodríguez A, 2007, LECT NOTES COMPUT SC, V4714, P408
   Rosenberg R. C., 1971, T ASME, V93, P35
   Schafroth D, 2010, J INTELL ROBOT SYST, V57, P27, DOI 10.1007/s10846-009-9379-x
   Schmitke C, 2005, MULTIBODY SYST DYN, V14, P81, DOI 10.1007/s11044-005-4577-1
   Selic B, 2003, IEEE SOFTWARE, V20, P19, DOI 10.1109/MS.2003.1231146
   Sen S, 2012, SOFTW SYST MODEL, V11, P111, DOI 10.1007/s10270-010-0181-9
   Sendall S, 2003, IEEE SOFTWARE, V20, P42, DOI 10.1109/MS.2003.1231150
   Seo K, 2003, MECHATRONICS, V13, P851, DOI 10.1016/S0957-4158(03)00006-0
   Stacey M., 9604 OP U COMP DEP
   Suh NP, 1998, RES ENG DES, V10, P189, DOI 10.1007/s001639870001
   ULRICH K, 1988, ROBOT CIM-INT MANUF, V4, P309, DOI 10.1016/0736-5845(88)90002-6
   UMEDA Y, 1990, APPLICATIONS OF ARTIFICIAL INTELLIGENCE IN ENGINEERING V, VOL 1, P177
   Vargas-Hernandez N., 2003, COMPUTATIONAL SYNTHE, P255
   Weustink P., 1998, MECHATRONICS, V98, P787
   Wilde N, 2003, J SYST SOFTWARE, V65, P105, DOI [10.1016/s0164-1212(02)00052-3, 10.1016/S0164-1212(02)00052-3]
   Yeh TJ, 2001, J FRANKLIN I, V338, P455, DOI 10.1016/S0016-0032(01)00015-1
   Zhang W, 2005, LECT NOTES COMPUT SC, V3713, P248, DOI 10.1007/11557432_18
NR 70
TC 9
Z9 9
U1 0
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD OCT
PY 2015
VL 72
BP 114
EP 130
DI 10.1016/j.robot.2015.05.003
PG 17
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Robotics
GA CO4ZX
UT WOS:000359170500011
DA 2023-11-10
ER

PT J
AU Ramírez-de-la-Rosa, G
   Villatoro-Tello, E
   Jiménez-Salazar, H
AF Ramirez-de-la-Rosa, Gabriela
   Villatoro-Tello, Esau
   Jimenez-Salazar, Hector
TI TxPI-u: A resource for Personality Identification of undergraduates
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Language resource; Personality Identification; author profiling; natural
   language processing
ID LANGUAGE; TRAITS
AB Resources such as labeled corpora are necessary to train automatic models within the natural language processing (NLP) field. Historically, a large number of resources regarding a broad number of problems are available mostly in English. One of such problems is known as Personality Identification where based on a psychological model (e.g. The Big Five Model), the goal is to find the traits of a subject's personality given, for instance, a text written by the same subject. In this paper we introduce a new corpus in Spanish called Texts for Personality Identification (TxPI). This corpus will help to develop models to automatically assign a personality trait to an author of a text document. Our corpus, TxPI-u, contains information of 416 Mexican undergraduate students with some demographics information such as, age, gender, and the academic program they are enrolled. Finally, as an additional contribution, we present a set of baselines to provide a comparison scheme for further research.
C1 [Ramirez-de-la-Rosa, Gabriela; Villatoro-Tello, Esau; Jimenez-Salazar, Hector] UAM, Dept Informat Technol, Language & Reasoning Res Grp, Unidad Cuajimalpa, Mexico City, DF, Mexico.
C3 Universidad Autonoma Metropolitana - Mexico
RP Ramírez-de-la-Rosa, G (通讯作者)，UAM, Dept Informat Technol, Language & Reasoning Res Grp, Unidad Cuajimalpa, Mexico City, DF, Mexico.
EM gramirez@correo.cua.uam.mx
OI VILLATORO-TELLO, ESAU/0000-0002-1322-0358; Ramirez-de-la-Rosa,
   Gabriela/0000-0003-4730-5613
FU CONACYT [258588, 281795]
FX Furthermore, this work was partially supported by CONACYT under project
   grant 258588 and under the Thematic Networks program (Language
   Technologies Thematic Network, project 281795).
CR Andre E, 2000, INTEGRATING MODELS P, P150
   [Anonymous], ONLINE READINGS PSYC
   [Anonymous], 2015, CLEF 2015 EV LABS WO, DOI DOI 10.1007/S13398-014-0173-7.2
   [Anonymous], 1992, PSYCHOL ASSESSMENT R
   Argamon S., 2005, P JOINT ANN M INT CL
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Celli F., 2013, SOCIAL NETWORKING RE, P41
   Farnadi G, 2016, USER MODEL USER-ADAP, V26, P109, DOI 10.1007/s11257-016-9171-0
   Funder DC, 2001, ANNU REV PSYCHOL, V52, P197, DOI 10.1146/annurev.psych.52.1.197
   Garner SR etal, 1995, P NZ COMPUTER SCI RE, P57
   GOLDBERG LR, 1993, AM PSYCHOL, V48, P26, DOI 10.1037/0003-066X.48.1.26
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Iacobelli F., 2011, LARGE SCALE PERSONAL, P568
   John O. P., 1991, BIG 5 INVENTORY VERS, DOI [DOI 10.1037/T07550-000, 10.1037/t07550-000]
   Komarraju M, 2005, PERS INDIV DIFFER, V39, P557, DOI 10.1016/j.paid.2005.02.013
   Kosinski M, 2015, AM PSYCHOL, V70, P543, DOI 10.1037/a0039210
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Oberlander J., 2006, P COLINGACL 2006 MAI, P627
   Oberlander J, 2006, DISCOURSE PROCESS, V42, P239, DOI 10.1207/s15326950dp4203_1
   Ozer DJ, 2006, ANNU REV PSYCHOL, V57, P401, DOI 10.1146/annurev.psych.57.102904.190127
   Park G, 2015, J PERS SOC PSYCHOL, V108, P934, DOI 10.1037/pspp0000020
   Pennebaker J.W., 2011, SECRET LIFE PRONOUNS
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Pennebaker JW., 2007, DEV PSYCHOMETRIC PRO
   Renau V., 2013, ALOMA REV PSICOLOGIA, V31
   Vinciarelli A., 2014, IEEE T AFFECTIVE COM
   Wrzus C, 2015, EUR J PERSONALITY, V29, P250, DOI 10.1002/per.1986
NR 27
TC 3
Z9 3
U1 0
U2 4
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2018
VL 34
IS 5
BP 2991
EP 3001
DI 10.3233/JIFS-169484
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA GH2AV
UT WOS:000433204800015
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Réveil, B
   Demuynck, K
   Martens, JP
AF Reveil, Bert
   Demuynck, Kris
   Martens, Jean-Pierre
TI An improved two-stage mixed language model approach for handling
   out-of-vocabulary words in large vocabulary continuous speech
   recognition
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Out-of-vocabulary words; OOV detection; OOV modeling;
   Phoneme-to-grapheme conversion
AB This paper presents a two-stage mixed language model technique for detecting and recognizing words that are not included in the vocabulary of a large vocabulary continuous speech recognition system. The main idea is to spot the out-of-vocabulary words and to produce a transcription for these words in terms of subword units with the help of a mixed word/subword language model in the first stage, and to convert the subword transcriptions to word hypotheses by means of a look-up table in the second stage. The performance of the proposed approach is compared to that of the state-of-the-art hybrid method reported in the literature, both on in-domain and on out-of-domain Dutch spoken material, where the term 'domain' refers to the ensemble of topics that were covered in the material from which the lexicon and language model were retrieved. It turns out that the proposed approach is at least equally effective as a hybrid approach when it comes to recognizing in-domain material, and significantly more effective when applied to out-of-domain data. This proves that the proposed approach is easily adaptable to new domains and to new words (e.g. proper names) in the same domain. On the out-of-domain recognition task, the word error rate could be reduced by 12% relative over a baseline system incorporating a 100k word vocabulary and a basic garbage OOV word model. (C) 2013 Elsevier Ltd. All rights reserved.
C1 [Reveil, Bert; Demuynck, Kris; Martens, Jean-Pierre] Ghent Univ iMinds, ELIS Multimedia Lab, B-9000 Ghent, Belgium.
C3 IMEC; Ghent University
RP Réveil, B (通讯作者)，Ghent Univ iMinds, ELIS Multimedia Lab, St Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM breveil@elis.ugent.be; kris.demuynck@elis.ugent.be;
   martens@elis.ugent.be
CR Adda-Decker M, 2000, TEXT SPEECH LANG TEC, V12, P235
   Andreas S., 2011, P IEEE AUT SPEECH RE, P5
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2010, NAACL2010
   [Anonymous], 2009, P INTERSPEECH
   [Anonymous], 1999, PRACTICAL NONPARAMET
   ASADI A, 1990, INT CONF ACOUST SPEE, P125, DOI 10.1109/ICASSP.1990.115554
   BAZZI I, 2001, P EUR 2001, P61
   Bazzi I., 2002, ICSLP 2002, P1613
   Bazzi I., 2000, P INT C SPOK LANG PR, V1, P401
   BISANI M, 2005, P EUR C SPEECH COMM, P725
   Chung G., 2000, P ICSL, P3520
   CHUNG G, 1999, P EUR C SPEECH COMM, P2655
   Decadt B., 2001, P ASRU, P413
   Demuynck K, 2000, SPEECH COMMUN, V30, P37, DOI 10.1016/S0167-6393(99)00030-8
   Demuynck K., 2003, P EUR C SPEECH COMM, P1973
   Demuynck K, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P339, DOI 10.1109/ASRU.2009.5373311
   Demuynck K, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P495
   Demuynck Kris, 2001, THESIS KU LEUVEN
   Gallwitz F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P228, DOI 10.1109/ICSLP.1996.607083
   Geutner P, 1998, INT CONF ACOUST SPEE, P925, DOI 10.1109/ICASSP.1998.675417
   Hetheringthon I.L., 1995, CHARACTERIZATION PRO
   Hieronymus JL, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P364
   Hirsimäki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   Hori T, 2007, IEEE T AUDIO SPEECH, V15, P1352, DOI 10.1109/TASL.2006.889790
   Kemp T, 1996, INT CONF ACOUST SPEE, P530, DOI 10.1109/ICASSP.1996.541150
   Kessens J., 2007, P INT, P1354
   Klakow D., 1999, P EUR 1999, P49
   Oostdijk N., 2000, NEDERLANDSE TAALKUND, V5, P280
   Parada C, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1269
   Rastrow A., 2009, P INTERSPEECH, P1931
   Réveil B, 2012, SPEECH COMMUN, V54, P321, DOI 10.1016/j.specom.2011.10.007
   Yazgan A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P745
NR 33
TC 10
Z9 13
U1 0
U2 12
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2014
VL 28
IS 1
BP 141
EP 162
DI 10.1016/j.csl.2013.04.003
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 242QQ
UT WOS:000326257500010
DA 2023-11-10
ER

PT J
AU Malmasi, S
   Dras, M
AF Malmasi, Shervin
   Dras, Mark
TI Native Language Identification With Classifier Stacking and Ensembles
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID FUSION; MODEL
AB Ensemble methods using multiple classifiers have proven to be among the most successful approaches for the task of Native Language Identification (NLI), achieving the current state of the art. However, a systematic examination of ensemble methods for NLI has yet to be conducted. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated. We present a set of experiments using three ensemble-based models, testing each with multiple configurations and algorithms. This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on several large data sets, evaluated in both intra-corpus and cross-corpus modes.
C1 [Malmasi, Shervin] Harvard Med Sch, Boston, MA 02115 USA.
   [Dras, Mark] Macquarie Univ, Dept Comp, N Ryde, NSW, Australia.
C3 Harvard University; Harvard Medical School; Macquarie University
RP Malmasi, S (通讯作者)，Harvard Med Sch, Boston, MA 02115 USA.
EM shervin.malmasi@mq.edu.au; mark.dras@mq.edu.au
OI Dras, Mark/0000-0001-9908-7182
CR [Anonymous], 2017, P 12 WORKSH BUILD ED
   [Anonymous], 2013, P 8 WORKSHOP INNOVAT
   [Anonymous], 2014, P 14 C EUROPEAN CHAP
   [Anonymous], 2014, P EMNLP
   [Anonymous], 2006, LREC
   [Anonymous], 2016, J MACHINE LEARNING R
   [Anonymous], 2013, P 8 WORKSH INN NLP B
   [Anonymous], 2014, P COLING 2014 25 INT
   [Anonymous], WORKSH INN US NLP BU
   [Anonymous], 2006, P COLING ACL INT PRE
   [Anonymous], 2006, P 5 INT C LANG RES E
   [Anonymous], P 8 WORKSH INN US NL
   [Anonymous], P 10 WORKSH INN US N
   [Anonymous], 2014, P EMNLP 2014 WORKSHO
   [Anonymous], THESIS
   [Anonymous], 2013, P 8 WORKSH INN US NL
   [Anonymous], 2005, P 11 ACM SIGKDD INT
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2017, P 12 WORKSHOP INNOVA
   [Anonymous], 2013, P 8 WORKSHOP INNOVAT
   Banfield RE, 2007, IEEE T PATTERN ANAL, V29, P173, DOI 10.1109/TPAMI.2007.250609
   Bjerva Johannes, 2017, P 12 WORKSH INN US N, P235
   Blanchard Daniel, 2013, ETSRR1314
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Brooke J., 2012, P 24 INT C COMP LING, P391
   Brooke J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P779
   Brooke Julian, 2011, P 2011 C LEARN CORP, P37
   Bykh Serhiy, 2013, P 8 WORKSH INN US NL, P197
   Chan S., 2017, P 12 WORKSHOP INNOVA, P217
   Cimino A., 2013, P 8 WORKSH INN US NL, P207
   Cimino Andrea, 2017, P 12 WORKSH INN US N, P430
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Faarlund J. T., 1997, NORSK REFERANSEGRAMM
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Geertzen J., 2013, SEL P 31 2 LANG RES, P240
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Goldberg  Y., 2015, ABS151000726 CORR
   Goutte Cyril, 2013, P 8 WORKSH INN US NL, P96
   Goutte Cyril, 2017, P 12 WORKSH INN US N, P367
   Granger Sylviane., 2009, INT CORPUS LEARNER E
   Guthrie D., 2006, LREC, V6, P1222
   Gyawali B., 2013, P 8 WORKSH INN US NL, P224
   Hastie TJ., 2009, ELEMENTS STAT LEARNI, V2nd ed.
   Hladka Barbora, 2013, P 8 WORKSH INN US NL, P232
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Hsu C.-W, 2003, PRACTICAL GUIDE SUPP
   Ionescu RT, 2016, COMPUT LINGUIST, V42, P491, DOI 10.1162/COLI_a_00256
   Ircing Pavel, 2017, P 12 WORKSH INN US N, P198
   Jarvis S., 2012, APPROACHING LANGUAGE
   Jarvis Scott, 2004, 2 LANG RES FOR SLRF
   Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Koppel M, 2005, LECT NOTES COMPUT SC, V3495, P209
   Koppel M, 2009, J AM SOC INF SCI TEC, V60, P9, DOI 10.1002/asi.20961
   Kulmizev Artur, 2017, P 12 WORKSHOP INNOVA, P382
   Kuncheva L. I., 2014, COMBINING PATTERN CL, V2d, DOI DOI 10.1002/0471660264
   Kuncheva L.I., 2014, COMBINING PATTERN CL
   Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7
   Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906
   Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X
   Kuncheva LI, 2014, KNOWL INF SYST, V38, P259, DOI 10.1007/s10115-012-0586-6
   Li W., 2017, P 12 WORKSHOP INNOVA, P390
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Malmasi S., 2014, P ALTA, P139
   Malmasi S., 2016, VARDIAL, P1
   Malmasi S, 2017, NAT LANG ENG, V23, P163, DOI 10.1017/S1351324915000406
   Malmasi Shervin, 2017, CORRABS170306541
   Malmasi Shervin, 2015, P 2015 C N AM CHAPT, P1403
   Malmasi Shervin, 2015, P 10 WORKSH INN US N, P172
   Manning C. D., 2008, INTRO INFORM RETRIEV, DOI [10.1017/CBO9780511809071, DOI 10.1017/CBO9780511809071]
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Manning CD, 2015, COMPUT LINGUIST, V41, P701, DOI 10.1162/COLI_a_00239
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Ortega L., 2009, UNDERSTANDING 2 LANG
   Oza NC, 2008, INFORM FUSION, V9, P4, DOI 10.1016/j.inffus.2007.07.002
   Platt JC, 2000, ADV NEUR IN, P61
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Quinlan J.R., 2014, C4 5 PROGRAMS MACHIN
   Rama T., 2017, P 12 WORKSH INN US N, P255
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Sari Y., 2017, P 12 WORKSH INN US N, P249, DOI [10.18653/v1/W17-5027, DOI 10.18653/V1/W17-5027]
   Swanson B., 2012, P ACL, P193
   Tenfjord K, 2006, RIV PSICOLINGUIST AP, V6, P93
   Tenfjord Kari, 2013, LEARN CORP RES C
   Tetreault J., 2012, P 24 INT C COMPUTATI, P2585
   Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299
   Tomokiyo LM, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P239
   Wang M., 2015, P 10 WORKSH INN US N, P118
   West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wong S.-M. J., 2012, P 2012 JOINT C EMP M, P699
   Wong SMJ, 2009, P AUSTR LANG TECHN A, P53
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006
   Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217
   Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046
NR 100
TC 13
Z9 13
U1 0
U2 10
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2018
VL 44
IS 3
BP 403
EP 446
DI 10.1162/coli_a_00323
PG 44
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA GU3YM
UT WOS:000445216700003
OA gold
DA 2023-11-10
ER

PT J
AU Wu, ZF
   Peng, H
   Smith, NA
AF Wu, Zhaofeng
   Peng, Hao
   Smith, Noah A.
TI Infusing Finetuning with Semantic Dependencies
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB For natural language processing systems, two kinds of evidence support the use of text representations from neural language models "pretrained'' on large unannotated corpora: performance on application-inspired benchmarks (Peters et al., 2018, inter alia), and the emergence of syntactic abstractions in those representations (Tenney et al., 2019, inter alia). On the other hand, the lack of grounded supervision calls into question how well these representations can ever capture meaning (Bender and Koller, 2020). We apply novel probes to recent language models-specifically focusing on predicate-argument structure as operationalized by semantic dependencies (Ivanova et al., 2012)-and find that, unlike syntax, semantics is not brought to the surface by today's pretrained models. We then use convolutional graph encoders to explicitly incorporate semantic parses into task-specific finetuning, yielding benefits to natural language understanding (NLU) tasks in the GLUE benchmark. This approach demonstrates the potential for general-purpose (rather than task-specific) linguistic supervision, above and beyond conventional pretraining and finetuning. Several diagnostics help to localize the benefits of our approach.(1)
C1 [Wu, Zhaofeng; Peng, Hao; Smith, Noah A.] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
   [Smith, Noah A.] Allen Inst Artificial Intelligence, Seattle, WA USA.
C3 University of Washington; University of Washington Seattle
RP Wu, ZF (通讯作者)，Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
EM zfw7@cs.washington.edu; hapeng@cs.washington.edu;
   nasmith@cs.washington.edu
FU Google Fellowship; NSF [1562364]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [1562364] Funding
   Source: National Science Foundation
FX The authors thank the anonymous reviewers for feedback that improved the
   paper. We also thank Stephan Oepen for help in producing the CoNLL 2019
   shared task companion data, Yutong Li for contributing to early
   experiments, and Elizabeth Clark and Lucy Lin for their suggestions and
   feedback. This research was supported in part by a Google Fellowship to
   HP and NSF grant 1562364.
CR Abend Omri, 2013, P ACL
   Adi Yossi, 2017, P ICLR
   [Anonymous], 1996, P 16 C COMPUTATIONAL
   [Anonymous], 2016, P LREC
   [Anonymous], 2016, P 1 C MACHINE TRANSL
   Baker C.F., 1998, 36 ANN M ASS COMPUTA, P86, DOI DOI 10.3115/980845.980860
   Bastings J., 2017, P EMNLP 2017, P1957, DOI DOI 10.18653/V1/D17-1209
   Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254
   Belinkov Y, 2020, COMPUT LINGUIST, V46, P1, DOI [10.1162/COLI_a_00367, 10.1162/coli_a_00367]
   Bender E. M., 2020, C SESSION P 58 ANN M
   Bentivogli L., 2009, P TAC, P1
   Cer Daniel M., 2017, P SEMEVAL
   Che Wanxiang, 2019, P MRP
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   CHU YJ, 1965, SCI SINICA, V14, P1396
   Clark KP, 2018, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE, 2018, VOL 2
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Clark Kevin, 2020, ICLR
   Copestake Ann, 2005, RES LANGUAGE COMPUTA, V4, P281
   Csernai Kornel, 2017, 1 QUORA DATASET RELE
   Cucurull Guillem, 2018, INT C LEARN REPR, P1
   Dagan Ido, 2005, MACHINE LEARNING CHA, P177
   De Marneffe MC, 2006, LREC, V6, P449
   Devlin J., 2018, ARXIV, V1, P4171
   Dodge Jesse, 2020, ARXIV200206305
   Dolan B., 2005, 3 INT WORKSHOP PARAP
   Dozat T., 2017, ICLR
   Dozat T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P484
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Eriguchi A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P72, DOI 10.18653/v1/P17-2012
   Giampiccolo Danilo, 2007, P ACL PASCAL WORKSH
   Goldberg Yoav, 2019, ABS190105287 ARXIV
   Gorodkin J, 2004, COMPUT BIOL CHEM, V28, P367, DOI 10.1016/j.compbiolchem.2004.09.006
   Hajic Jan, 2012, P LREC
   Harikrishnan R., 2006, Plant Health Progress, P1
   Hewitt John, 2019, P NAACL
   Hupkes Dieuwke, 2018, P IJCAI
   Ivanova Angelina, 2012, P LAW
   Jiang Haoming, 2019, ARXIV191103437
   Kipf TN., 2016, P INT C LEARNING REP
   Kovaleva Olga, 2019, ARXIV190808593, P4356
   Kuncoro A, 2020, T ASSOC COMPUT LING, V8, P776, DOI 10.1162/tacl_a_00345
   Li Zuchao, 2019, P MRP
   Liu Nelson F., 2019, P NAACL
   Liu Yinhan, 2019, ARXIV190711692
   Loshchilov Ilya, 7 INT C LEARN REPR I
   Marcheggiani D., 2017, ARXIV170304826, DOI DOI 10.18653/V1/D17-1159
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   McDonald R, 2005, P C HUM LANG TECHN E, P523, DOI DOI 10.3115/1220575.1220641
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Oepen Stephan, 2019, P MRP
   Oepen Stephan, 2006, P LREC
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Pang Deric, 2019, ARXIV190908217
   Parikh A, 2016, PROC C EMPIR METHODS, P2249, DOI [10.18653/v1/D16-1244, DOI 10.18653/V1/D16-1244]
   Peng H., 2018, P 2018 C N AM CHAPTE, V1, P1492, DOI DOI 10.18653/V1/N18-1135
   Peng H, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2037, DOI 10.18653/v1/P17-1186
   Peng Hao, 2018, P ACL, DOI DOI 10.18653/V1/P18-1173
   Pollard C, 1994, HEAD DRIVEN PHRASE S
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi X., 2016, P 2016 C EMP METH NA, P1526, DOI DOI 10.18653/V1/D16-1159
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   StephanOepen Marco Kuhlmann, 2014, P SEMEVAL
   StephanOepen Marco Kuhlmann, 2015, P SEMEVAL
   Straka Milan, 2018, P CONLL 2018 SHAR TA, DOI DOI 10.18653/V1/K19-2012
   Straka Milan, 2019, P MRP
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5027
   Surdeanu M., 2008, P 12 C COMP NAT LANG, P159, DOI DOI 10.3115/1596324.1596352
   Swayamdipta S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3772
   Swayamdipta Swabha, 2019, ARXIV190811047
   Tenney Ian, 2019, INT C LEARN REPR
   Vu Tu, 2020, P EMNLP, DOI DOI 10.18653/V1/2020.EMNLP-MAIN.635
   Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5307
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Xu K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2326
   Zhang Bo, 2020, P ACL, DOI DOI 10.18653/V1/2020.ACL-MAIN.297
   Zhang Z., 2019, 34 AAAI C ARTIFICIAL, P9636, DOI [10.1609/aaai.v34i05.6511, DOI 10.1609/AAAI.V34I05.6511]
   Zhang Zhuosheng, 2020, AAAI CONF ARTIF INTE, P9628
NR 85
TC 11
Z9 11
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 226
EP 242
DI 10.1162/tacl_a_00363
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200014
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Mi, CG
   Xie, L
   Zhang, YN
AF Mi, Chenggang
   Xie, Lei
   Zhang, Yanning
TI Improving data augmentation for low resource speech-to-text translation
   with diverse paraphrasing
SO NEURAL NETWORKS
LA English
DT Article
DE Data augmentation; Speech translation; Paraphrasing
AB High quality end-to-end speech translation model relies on a large scale of speech-to-text training data, which is usually scarce or even unavailable for some low-resource language pairs. To overcome this, we propose a target-side data augmentation method for low-resource language speech translation. In particular, we first generate large-scale target-side paraphrases based on a paraphrase generation model which incorporates several statistical machine translation (SMT) features and the commonly used recurrent neural network (RNN) feature. Then, a filtering model which consists of semantic similarity and speech-word pair co-occurrence was proposed to select the highest scoring source speech-target paraphrase pairs from candidates. Experimental results on English, Arabic, German, Latvian, Estonian, Slovenian and Swedish paraphrase generation show that the proposed method achieves significant and consistent improvements over several strong baseline models on PPDB datasets (http://paraphrase. org/). To introduce the results of paraphrase generation into the low-resource speech translation, we propose two strategies: audio-text pairs recombination and multiple references training. Experimental results show that the speech translation models trained on new audio-text datasets which combines the paraphrase generation results lead to substantial improvements over baselines, especially on low-resource languages. (C)& nbsp;2022 Elsevier Ltd. All rights reserved.
C1 [Mi, Chenggang] Xian Int Studies Univ, Foreign Language & Literature Inst, Xian, Peoples R China.
   [Xie, Lei; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated AeroSp Ground Ocean Big, Xian, Peoples R China.
C3 Xi'an International Studies University; Northwestern Polytechnical
   University
RP Mi, CG (通讯作者)，Xian Int Studies Univ, Foreign Language & Literature Inst, Xian, Peoples R China.
EM michenggang@nwpu.edu.cn; lxie@nwpu.edu.cn; zhangyanning@nwpu.edu.cn
FU National Natural Science Foundation of China [61906158]
FX Acknowledgments This work was supported by the National Natural Science
   Foundation of China (No. 61906158) . Moreover, the authors would like to
   thank editors and reviewers for their insightful and constructive
   comments, which help to enrich the content and improve the presentation
   of the results in this paper.
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Agarap A.F., 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   Bahar P., 2019, ABS191108876 ARXIV
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bhagat R, 2013, COMPUT LINGUIST, V39, P463, DOI 10.1162/COLI_a_00166
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chung YA, 2019, INT CONF ACOUST SPEE, P7170, DOI 10.1109/ICASSP.2019.8683550
   Chung YA, 2018, INTERSPEECH, P811, DOI 10.21437/Interspeech.2018-2341
   Conneau A, 2017, P C EMP METH NAT LAN, P670, DOI [10.18653/v1/d17-1070, DOI 10.18653/V1/D17-1070]
   Dahlmann L., 2017, P 2017 C EMP METH NA, P1411, DOI DOI 10.18653/V1/D17-1148
   Denkowski M., 2011, P 6 WORKSHOP STAT MA
   Di Gangi M., 2019, DATA AUGMENTATION EN, DOI [10.5281/zenodo.3525492, DOI 10.5281/ZENODO.3525492]
   Dong L., 2017, P 2017 C EMP METH NA, P875, DOI [10.18653/ v1/D17-1091, DOI 10.18653/V1/D17-1091]
   Feng Y, 2020, AAAI CONF ARTIF INTE, V34, P59
   Ganitkevitch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4276
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, P758
   Gao SL, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P639
   Guo YN, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P501
   Gupta A, 2018, AAAI CONF ARTIF INTE, P5149
   Hartmann W, 2016, INTERSPEECH, P2378, DOI 10.21437/Interspeech.2016-1386
   Hayashi T, 2018, IEEE W SP LANG TECH, P426, DOI 10.1109/SLT.2018.8639619
   He W, 2016, AAAI CONF ARTIF INTE, P151
   Jia Y, 2019, INT CONF ACOUST SPEE, P7180, DOI 10.1109/ICASSP.2019.8683343
   Kamper H, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P719, DOI 10.1109/ASRU.2017.8269008
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kumar A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3609
   Lample Guillaume, 2017, ARXIV171100043
   Liu L., 2012, P 2012 JOINT C EMP M, P402
   Liu Yang, 2005, P 43 ANN M ASS COMP, P459, DOI DOI 10.3115/1219840.1219897
   Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586
   Mallinson J, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P881
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Post Matt, 2018, P 3 C MACH TRANSL RE, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]
   Prasad NV, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P156, DOI 10.1109/ASRU.2013.6707722
   Qian LH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3173
   Renduchintala A, 2018, INTERSPEECH, P2394, DOI 10.21437/Interspeech.2018-2456
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Snover M., 2006, STUDY TRANSLATION ED
   Sperber Matthias, 2020, P 58 ANN M ASS COMPU, P7409, DOI 10.18653/v1/2020.acl-main. 661
   Taylor P., 2009, TEXT TO SPEECH SYNTH
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang C., 2020, ABS200710310 ARXIV
   Wang S., 2019, ABS181100119 ARXIV
   Wang X, 2017, AAAI CONF ARTIF INTE, P3330
   Witteveen Sam, 2019, P 3 WORKSH NEUR GEN, P215, DOI [DOI 10.18653/V1/D19-5623, 10.18653/v1/D19-5623]
   Zens R., 2008, IWSLT
   Zheng RJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3188
   Zhou Z, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P113
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, P1097, DOI 10.1145/3209978.3210080
NR 53
TC 2
Z9 2
U1 3
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD APR
PY 2022
VL 148
BP 194
EP 205
DI 10.1016/j.neunet.2022.01.016
EA FEB 2022
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA 0U8HX
UT WOS:000787889400017
PM 35151006
DA 2023-11-10
ER

PT J
AU Stoica, LF
   Stoica, F
AF Stoica, Laura F.
   Stoica, Florin
TI ATLDesigner: ATL Model Checking Using An Attribute Grammar
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE ATL; model checking; web services; attribute grammar
AB In this paper, we use attribute grammars as a formal approach for model checkers development. Our aim is to design an Alternating-Time Temporal Logic (ATL) model checker from a context-free grammar which generates the language of the ATL formulae. An attribute grammar may be informally defined as a context-free grammar which is extended with a set of attributes and a collection of semantic rules. We provide a formal definition for an attribute grammar used as input for Another Tool for Language Recognition (ANTLR) to generate an ATL model checker. The original implementation of the model-checking algorithm is based on Relational Databases and Web Services. Several database systems and Web Services technologies were used for evaluating the system performance in verification of large ATL models.
C1 [Stoica, Laura F.; Stoica, Florin] Lucian Blaga Univ Sibiu, Fac Sci, Dept Math & Informat, Str Dr Ion Ratiu 5-7, Sibiu 550012, Romania.
C3 Lucian Blaga University of Sibiu
RP Stoica, LF (通讯作者)，Lucian Blaga Univ Sibiu, Fac Sci, Dept Math & Informat, Str Dr Ion Ratiu 5-7, Sibiu 550012, Romania.
EM laura.cacovean@ulbsibiu.ro; florin.stoica@ulbsibiu.ro
RI Stoica, Florin/GSI-4949-2022
OI Stoica, Florin/0000-0002-9073-0781
FU Lucian Blaga University of Sibiu & Hasso Plattner Foundation
   [LBUS-RRC-2020-01]
FX The authors were supported from the project financed by Lucian Blaga
   University of Sibiu & Hasso Plattner Foundation research grants
   LBUS-RRC-2020-01.
CR Alechina N, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1069
   Alur R, 2002, J ACM, V49, P672, DOI 10.1145/585265.585270
   Alur R, 1998, LECT NOTES COMPUT SC, V1427, P521, DOI 10.1007/BFb0028774
   [Anonymous], CPU BENCHMARKS
   Bingham B, 2010, 2010 9 INT WORKSH HI, P28
   BRYANT RE, 1986, IEEE T COMPUT, V35, P677, DOI 10.1109/TC.1986.1676819
   Busard S, 2019, INT J SOFTW TOOLS TE, V21, P449, DOI 10.1007/s10009-018-0505-6
   Cermák P, 2014, LECT NOTES COMPUT SC, V8559, P525
   Eisner C, 2002, LECT NOTES COMPUT SC, V2318, P230
   Ferrando A., 2021, AAMAS21, P1764
   Holzmann GJ, 1997, IEEE T SOFTWARE ENG, V23, P279, DOI 10.1109/32.588521
   Hu A. J., 1995, THESIS STANFORD U
   Jamroga W., 2011, P 22 INT JOINT C ART, VOne, P252, DOI DOI 10.1023/A:1026171312755
   Kacprzak M, 2020, KR2020: PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P539
   Kurpiewski D., 2021, P AAMAS, P1770
   Kurpiewski D, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P2372
   Lerda F., 2003, Electronic Notes in Theoretical Computer Science, V89, DOI 10.1016/S1571-0661(05)80008-8
   Lomuscio A, 2006, LECT NOTES COMPUT SC, V3920, P450
   Lomuscio A, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1713
   Lomuscio A, 2017, INT J SOFTW TOOLS TE, V19, P9, DOI 10.1007/s10009-015-0378-x
   Nam W, 2020, INT J SOFTW ENG KNOW, V30, P555, DOI 10.1142/S0218194020500199
   Niewiadomski A., 2020, P 19 INT C AUT AG MU, P2111
   Rozier KY, 2011, COMPUT SCI REV, V5, P163, DOI 10.1016/j.cosrev.2010.06.002
   Ruan J., 2008, THESIS U LIVERPOOL
   Rus T, 2002, FORM METHOD SYST DES, V20, P249, DOI 10.1023/A:1014742013173
   Slonneger K., 1995, FORMAL SYNTAX SEMANT
   Stoica Florin, 2014, 2014 22nd International Conference on Software, Telecommunications and Computer Networks (SoftCOM), P361, DOI 10.1109/SOFTCOM.2014.7039096
   Stoica F., 2021, PROC 7 INT C MODELLI, P149
   Thirunarayan, 2009, ENCY INFORM SCI TECH
NR 29
TC 0
Z9 0
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD AUG
PY 2022
VL 32
IS 08
BP 1125
EP 1154
DI 10.1142/S0218194022500450
EA AUG 2022
PG 30
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Q0LA
UT WOS:000848725100001
DA 2023-11-10
ER

PT J
AU Ortmanns, S
   Ney, H
AF Ortmanns, S
   Ney, H
TI Look-ahead techniques for fast beam search
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB This paper presents two look-ahead techniques for speeding up large vocabulary continuous speech recognition. These two techniques are the language model look-ahead and the phoneme look-ahead; both are incorporated into the pruning process of the time-synchronous one-pass beam search algorithm. The search algorithm is based on a tree-organized pronunciation lexicon in connection with a bigram language model.
   Both look-ahead techniques have been tested on the 20 000-word NAB'94 task (ARPA North American Business Corpus). The recognition experiments show that the combination of bigram language model look-ahead and phoneme look-ahead reduces the size of search space by a factor of about 30 and the computational effort by a factor of 5 without affecting the word recognition accuracy in comparison with no look-ahead pruning technique. (C) 2000 Academic Press.
C1 Bell Labs, Lucent Technol, Murray Hill, NJ 07974 USA.
   Rhein Westfal TH Aachen Univ Technol, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany.
C3 Alcatel-Lucent; Lucent Technologies; AT&T; RWTH Aachen University
RP Ortmanns, S (通讯作者)，Bell Labs, Lucent Technol, 600-700 Mt Ave, Murray Hill, NJ 07974 USA.
CR ALLEVA F, 1996, P IEEE INT C AC SPEE, P133
   [Anonymous], 1994, P HUMAN LANG TECHN W
   [Anonymous], P IEEE INT C AC SPEE
   ANTONIOL G, 1995, P IEEE INT C AC SPEE, V1, P588
   AUBERT X, 1995, P IEEE INT C AC SPEE, P49
   Bahl LR, 1993, IEEE T SPEECH AUDI P, V1, P59, DOI 10.1109/89.221368
   BEYERLEIN P, 1995, P EUR C SPEECH COMM, P1083
   DUGAST C, 1995, P ARPA SPOK LANG TEC, P156
   Haeb-Umbach R, 1994, IEEE T SPEECH AUDI P, V2, P353, DOI 10.1109/89.279287
   Knill KM, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P470, DOI 10.1109/ICSLP.1996.607156
   NEY H, 1990, P 5 EUR SIGN PROC C, P65
   NEY H, 1993, SPEECH RECOGNITION C, P210
   Ney Hermann, 1992, PROC IEEE INT C ACOU
   Ortmanns S, 1997, COMPUT SPEECH LANG, V11, P43, DOI 10.1006/csla.1996.0022
   Ortmanns S, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2095, DOI 10.1109/ICSLP.1996.607215
   ORTMANNS S, 1995, P 4 EUR C SPEECH COM, P901
   ORTMANNS S, 1997, 5 EUR C SPEECH COMM, P143
   ORTMANNS S, 1997, P IEEE INT C AC SPEE, P1783
   RENALS S, 1995, P IEEE INT C AC SPEE, V1, P596
   STEINBISS V, 1994, P INT C SPOK LANG PR, P2143
   Wessel F., 1997, P SQEL WORKSH MULT I, P55
NR 21
TC 24
Z9 25
U1 0
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2000
VL 14
IS 1
BP 15
EP 32
DI 10.1006/csla.1999.0131
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 286XK
UT WOS:000085474000002
DA 2023-11-10
ER

PT J
AU Zhang, LL
   Zhou, ZX
   Ji, PY
   Mei, AX
AF Zhang, Lingling
   Zhou, Zhenxiong
   Ji, Pengyu
   Mei, Aoxue
TI Application of Attention Mechanism with Prior Information in Natural
   Language Processing
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Artificial intelligence; attention mechanism; deep learning; machine
   translation; natural language processing; sparse mapping
AB When using deep learning methods to model natural language, a recurrent neural network that can map input sequences to output sequences is usually used. Considering that natural language contains more complicated syntactic structures, and the performance of cyclic neural networks in long sentence processing will decrease, scholars have introduced an attention mechanism into the model, which has improved the above problems to a certain extent. The existing attention mechanism still has some shortcomings, such as the inability to explicitly obtain the known syntactic structure information in the sentence, and the poor interpretability of the output probability. In response to the above problems, this article will improve the attention mechanism in the recurrent neural network model. Firstly, the prior information in the natural language sequence is constructed as a graph model through syntactic analysis and other means, and then the graph structure regularization term is introduced into the sparse mapping. A new function netmax is constructed to replace the softmax function in the traditional attention mechanism, thereby improving the performance of the model and making the degree of association. The input values corresponding to larger input samples are closer, making the output of the attention mechanism easier to understand. The innovation of this paper mainly lies in that the weight calculation method which can be widely used in the attention mechanism is proposed by combining the deep learning model with statistical knowledge, which opens a channel to introduce the prior information for the deep learning model in natural language processing tasks.
C1 [Zhang, Lingling; Ji, Pengyu; Mei, Aoxue] Beihua Univ, Coll Comp Sci & Technol, Jilin 132022, Jilin, Peoples R China.
   [Zhou, Zhenxiong] Beihua Univ, Coll Elect & Informat Engn, Jilin 132022, Jilin, Peoples R China.
C3 Beihua University; Beihua University
RP Zhou, ZX (通讯作者)，3999 East Binjiang Rd, Jilin, Jilin, Peoples R China.
EM zhangling_beihuaa@163.com; 742884852@qq.com; 1712261543@qq.com;
   659374288@qq.com
RI zhang, lingling/HDM-2189-2022
FU Science and Technology Development Plan Project at Jilin Province
   [20200404203yy]; Science and Technology Project in the 13th Five Year
   Plan of Education Department at Jilin Province [JJKH20200048KJ];
   Research on Teaching Reform of Higher Education in Jilin Province
   [JLZX205620190724110543]
FX This work is supported by The Science and Technology Development Plan
   Project at Jilin Province (20200404203yy), The Science and Technology
   Project in the 13th Five Year Plan of Education Department at Jilin
   Province (JJKH20200048KJ) and Research on Teaching Reform of Higher
   Education in Jilin Province (JLZX205620190724110543).
CR Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Chen X., 2010, ARXIV PREPRINT ARXIV
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Chorowski J, 2015, ADV NEUR IN, V28
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Hallac D, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P387, DOI 10.1145/2783258.2783313
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   Luong Minh-Thang, 2015, ARXIV151106114
   Ma LB, 2021, IEEE T SYST MAN CY-S, V51, P6723, DOI 10.1109/TSMC.2020.2963943
   Martins AFT, 2016, PR MACH LEARN RES, V48
   Niculae V., 2017, CORR
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Rocktaschel Tim, 2015, ARXIV150906664
   Rush A M, 2015, P 2015 C EMPIRICAL M, P379
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Wang Feng, 2016, ABS160106823 CORR, DOI DOI 10.48550/ARXIV.1601.06823
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yuan M., 2006, J ROYAL STAT SOC B, V68, P49
NR 20
TC 1
Z9 1
U1 5
U2 13
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD JUN
PY 2022
VL 31
IS 04
AR 2240008
DI 10.1142/S0218213022400085
PG 18
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2E7VN
UT WOS:000812432900001
DA 2023-11-10
ER

PT J
AU Cornelis, H
   De Schutter, E
AF Cornelis, Hugo
   De Schutter, Erik
TI Neuro spaces: Towards automated model partitioning for parallel
   computers
SO NEUROCOMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual Computational Neuroscience Meeting
CY JUL, 2006
CL Edinburgh, SCOTLAND
DE simulation; middleware; parallelization; modeling
ID SIMULATION; NEUROSPACES; CELL
AB Parallel computers have the computing power needed to simulate biologically accurate neuronal network models. Partitioning is the process of cutting a model in pieces and assigning each piece to a CPU. Automatic partitioning algorithms for large models are difficult to design for two fundamental reasons. First, the algorithms must track the intrinsic asymmetries in the models and the dynamical behavior of the simulation. Second, the procedural nature of current modeling languages makes it difficult to extract the information needed by the algorithms.
   From the start, the Neurospaces modeling system has been designed to deal with large and complicated neuronal models. The declarative nature of the software system allows to extract any kind of information from the model. In this work, we first show how to extract the information needed to partition a large model for simulation on parallel computers. Next, we use this information to compute a possible partitioning for a small and a large network model. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Texas, Hlth Sci Ctr, Res Imaging Ctr, San Antonio, TX 78285 USA.
   Univ Antwerp, Lab Theoret Neurobiol, B-2020 Antwerp, Belgium.
C3 University of Texas System; University of Texas Health Science Center at
   San Antonio; University of Antwerp
RP Cornelis, H (通讯作者)，Univ Texas, Hlth Sci Ctr, Res Imaging Ctr, San Antonio, TX 78285 USA.
EM hugo.cornelis@gmail.com
RI De Schutter, Erik/G-8460-2011
OI De Schutter, Erik/0000-0001-8618-5138
CR Bednar JA, 2004, NEUROCOMPUTING, V58, P1129, DOI 10.1016/j.neucom.2004.01.177
   BOWER JM, 1998, BOOK GENESIS
   CANNON RC, 2003, NEUROINFORMATICS, V1
   Cornelis H, 2004, NEUROCOMPUTING, V58, P1079, DOI 10.1016/j.neucom.2004.01.169
   Cornelis H, 2003, NEUROCOMPUTING, V52-4, P227, DOI 10.1016/SO925-2312(02)00750-6
   CORNELIS H, 2001, 1 UIA
   Cornelis H, 2002, TUTORIAL SIMULATIONS
   CORNELIS H, 2004, THESIS U ANTWERP
   DESCHUTTER E, 1994, J NEUROPHYSIOL, V71, P375, DOI 10.1152/jn.1994.71.1.375
   DIESMANN M, 2000, FORSCHUNG WISSCHENSC, V58, P43
   GLEESON P, 2005, BUILDING 3D NETWORK
   GODDARD M, 2001, PHILOS T R SOC B, V356, P1
   Goddard N, 2001, NEUROCOMPUTING, V38, P1657, DOI 10.1016/S0925-2312(01)00528-8
   GODDARD NH, 1998, LARGE SCALE SIMULATI
   Hines M, 2003, NEURON SIMULATION EN, P769
   Howell F, 2003, NEUROCOMPUTING, V52-4, P289, DOI 10.1016/S0925-2312(02)00781-6
   HOWELL F, 2005, NEOSIM2
   Howell FW, 2000, NEUROCOMPUTING, V32, P1041, DOI 10.1016/S0925-2312(00)00277-0
   Maex R, 1998, J NEUROPHYSIOL, V80, P2521, DOI 10.1152/jn.1998.80.5.2521
   Migliore M., 2006, J COMPUT NEUROSCI
   Pacheco P, 2000, NEUROCOMPUTING, V32, P1095, DOI 10.1016/S0925-2312(00)00283-6
   Palay S., 1974, CEREBELLAR CORTEX CY
NR 22
TC 4
Z9 5
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUN
PY 2007
VL 70
IS 10-12
SI SI
BP 2117
EP 2121
DI 10.1016/j.neucom.2006.10.140
PG 5
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 178IV
UT WOS:000247215300099
DA 2023-11-10
ER

PT J
AU Li, K
   Naacke, H
   Amann, B
AF Li, Ke
   Naacke, Hubert
   Amann, Bernd
TI An Analytic Graph Data Model and Query Language for Exploring the
   Evolution of Science
SO BIG DATA RESEARCH
LA English
DT Article
DE Topic modeling; Topic evolution networks; LDA; Science evolution; Big
   data
ID TOPIC EVOLUTION; INFORMATION
AB In this article we propose a data model and query language for the visualisation and exploration of topic evolution networks representing the research progress in scientific document archives. Our model is independent of a particular topic extraction and alignment method and proposes a set of semantic and structural metrics for characterizing and filtering meaningful topic evolution patterns. These metrics are particularly useful for the visualization and the exploration of large topic evolution graphs. We also present a first implementation of our model on top of Apache Spark and experimental results obtained for four real-world document archives. (C) 2021 Elsevier Inc. All rights reserved.
C1 [Li, Ke; Naacke, Hubert; Amann, Bernd] Sorbonne Univ, CNRS, LIP6, 4 Pl Jussieu, F-75005 Paris, France.
C3 UDICE-French Research Universities; Sorbonne Universite; Centre National
   de la Recherche Scientifique (CNRS)
RP Li, K; Naacke, H; Amann, B (通讯作者)，Sorbonne Univ, CNRS, LIP6, 4 Pl Jussieu, F-75005 Paris, France.
EM ke.li@lip6.fr; hubert.naacke@lip6.fr; bernd.amann@lip6.fr
RI Amann, Bernd/AAC-8389-2020
OI Amann, Bernd/0000-0002-6822-4049
FU  [ANR-16-CE38-0002-01]
FX This work was funded by French ANR-16-CE38-0002-01 project EPIQUE.
CR Andrei V, 2016, EURASIP J BIOINFORM, DOI 10.1186/s13637-016-0050-0
   [Anonymous], 2011, P 20 INT C WORLD WID, DOI DOI 10.1145/1963405.1963444
   Armbrust M, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1383, DOI 10.1145/2723372.2742797
   Bancilhon F., 1986, KNOWLEDGE BASE MANAG
   Beykikhoshk A, 2018, KNOWL INF SYST, V55, P599, DOI 10.1007/s10115-017-1095-4
   Bhadury A, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P381, DOI 10.1145/2872427.2883046
   Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99, DOI DOI 10.1038/157869B0
   Bin Lu, 2011, 2011 IEEE International Conference on Data Mining Workshops, P81, DOI 10.1109/ICDMW.2011.125
   Blei D. M., 2006, PROC 23 INT C MACHIN, V148, P113, DOI DOI 10.1145/1143844.1143859
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chavalarias D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054847
   Chen BT, 2017, J INFORMETR, V11, P1175, DOI 10.1016/j.joi.2017.10.003
   Franz M., 2001, SIGIR Forum, P310
   GARFIELD E, 1955, SCIENCE, V122, P108, DOI 10.1126/science.122.3159.108
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hall D, 2008, P C EMP METH NAT LAN, P363, DOI DOI 10.3115/1613715.1613763
   He Q., 2009, PROCEEDING 18 ACM C, P957, DOI [DOI 10.1145/1645953.1646076, 10.1145/1645953.1646076, 10.1145/1645953]
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hu BB, 2015, J ASSOC INF SCI TECH, V66, P2643, DOI 10.1002/asi.23347
   Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI 10.1111/j.1469-8137.1912.tb05611.x
   Kontostathis A, 2004, SURVEY OF TEXT MINING, P185
   Kuhn T.S., 1994, INT ENCY UNIFIED SCI, V2
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Li K., 2020, INT C EXT DAT TECHN, P619
   Li KH, 2020, INVEST RADIOL, V55, P327, DOI 10.1097/RLI.0000000000000672
   Meng XR, 2016, J MACH LEARN RES, V17
   Miller J. W., 2013, ADV NEURAL INFORM PR, P199
   Naacke H, 2019, IEEE INT CONF BIG DA, P4793, DOI 10.1109/BigData47090.2019.9005483
   Niu ZX, 2018, IEEE T IMAGE PROCESS, V27, P50, DOI 10.1109/TIP.2017.2718667
   Priva UC, 2015, COGNITION, V135, P4, DOI 10.1016/j.cognition.2014.11.006
   Qu HY, 2006, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON TELEHEALTH, P75
   Rubin TN, 2012, MACH LEARN, V88, P157, DOI 10.1007/s10994-011-5272-5
   Salatino AA, 2018, ACM-IEEE J CONF DIG, P303, DOI 10.1145/3197026.3197052
   Shahaf D, 2015, COMMUN ACM, V58, P62, DOI 10.1145/2735624
   Sun XL, 2013, SCI REP-UK, V3, DOI 10.1038/srep01069
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wang C., 2008, P 24 ANN C UNCERTAIN, P579
   Wang X., 2006, P 12 ACM SIGKDD INT, P424, DOI DOI 10.1145/1150402.1150450
   Wheeler DL, 2008, NUCLEIC ACIDS RES, V36, pD13, DOI 10.1093/nar/gkm1000
   Xin Reynold S, 2013, 1 INT WORKSH GRAPH D, P1
   Zhou D., 2006, PROC 15 ACM INT C IN, P248
   Zuo ZY, 2018, ACM-IEEE J CONF DIG, P405, DOI 10.1145/3197026.3203891
NR 42
TC 0
Z9 0
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-5796
J9 BIG DATA RES
JI Big Data Res.
PD NOV 15
PY 2021
VL 26
AR 100247
DI 10.1016/j.bdr.2021.100247
EA AUG 2021
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WL5QB
UT WOS:000710458600011
OA Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Lee, SJ
   Lim, J
   Paas, L
   Ahn, HS
AF Lee, Sanghyub John
   Lim, JongYoon
   Paas, Leo
   Ahn, Ho Seok
TI Transformer transfer learning emotion detection model: synchronizing
   socially agreed and self-reported emotions in big data
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Emotion data sets; Emotion detection model; Transformer-based language
   model; Constructed emotion theory
AB Tactics to determine the emotions of authors of texts such as Twitter messages often rely on multiple annotators who label relatively small data sets of text passages. An alternative method gathers large text databases that contain the authors' selfreported emotions, to which artificial intelligence, machine learning, and natural language processing tools can be applied. Both approaches have strength and weaknesses. Emotions evaluated by a few human annotators are susceptible to idiosyncratic biases that reflect the characteristics of the annotators. But models based on large, self-reported emotion data sets may overlook subtle, social emotions that human annotators can recognize. In seeking to establish a means to train emotion detection models so that they can achieve good performance in different contexts, the current study proposes a novel transformer transfer learning approach that parallels human development stages: (1) detect emotions reported by the texts' authors and (2) synchronize the model with social emotions identified in annotator-rated emotion data sets. The analysis, based on a large, novel, self-reported emotion data set (n = 3,654,544) and applied to 10 previously published data sets, shows that the transfer learning emotion model achieves relatively strong performance.
C1 [Lee, Sanghyub John; Paas, Leo] Univ Auckland, Mkt Dept, Business Sch, Auckland 1142, New Zealand.
   [Lim, JongYoon; Ahn, Ho Seok] Univ Auckland, Dept Elect Comp & Software Engn, CARES, Auckland 1142, New Zealand.
C3 University of Auckland; University of Auckland
RP Lee, SJ (通讯作者)，Univ Auckland, Mkt Dept, Business Sch, Auckland 1142, New Zealand.
EM sanghyub.lee@auckland.ac.nz; jy.lim@auckland.ac.nz;
   leo.paas@auckland.ac.nz; hs.ahn@auckland.ac.nz
RI Lee, Sanghyub, John/ITU-0464-2023
OI Lee, Sanghyub, John/0000-0001-6714-0225; Paas, Leo/0000-0002-6611-3038
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. This work was not funded.
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Agirre Eneko, 2007, P 4 INT WORKSH SEM E
   Al-Omari H, 2020, INT CONF INFORM COMM, P226, DOI 10.1109/ICICS49469.2020.239539
   Balahur A, 2011, LECT NOTES COMPUT SC, V6716, P27, DOI 10.1007/978-3-642-22327-3_4
   Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154
   Barrett LF, 2017, PSYCHOL INQ, V28, P20, DOI 10.1080/1047840X.2017.1261581
   Chatterjee A., 2019, P 13 INT WORKSH SEM, P39
   Crowdflower, 2017, CROWDFL DAT SETS
   Demszky D, 2020, Arxiv, DOI arXiv:2005.00547
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dunfield K, 2011, INFANCY, V16, P227, DOI 10.1111/j.1532-7078.2010.00041.x
   DUTTON DG, 1974, J PERS SOC PSYCHOL, V30, P510, DOI 10.1037/h0037031
   Ekman Paul, 1972, NEBRASKA S MOTIVATIO, V19, P207, DOI DOI 10.1037/0022-3514.53.4.712
   Ghazi D, 2015, LECT NOTES COMPUT SC, V9042, P152, DOI 10.1007/978-3-319-18117-2_12
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Kitayama S, 2006, J PERS SOC PSYCHOL, V91, P890, DOI 10.1037/0022-3514.91.5.890
   Kumar N., 2019, NATURAL LANGUAGE PRO
   Lee SJ, 2021, 2021 IEEE REGION 10 CONFERENCE (TENCON 2021), P429, DOI 10.1109/TENCON54134.2021.9707441
   Lim J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082712
   Liu CH, 2017, THESIS MIT
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Mohammad SM, 2017, Arxiv, DOI arXiv:1708.03696
   Malik F., 2018, DEV STAGES SOCIAL EM
   MCCONATHA JT, 1994, J SOC BEHAV PERS, V9, P481
   Mesquita B, 2003, BEHAV RES THER, V41, P777, DOI 10.1016/S0005-7967(02)00189-4
   Mohammad S, 2018, P 12 INT WORKSH SEM, P1, DOI DOI 10.18653/V1/S18-1001
   Mohammad S., 2012, P 1 JOINT C LEXICAL, P246
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   Mohammad SM, 2015, COMPUT INTELL-US, V31, P301, DOI 10.1111/coin.12024
   Sailunaz K, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0505-2
   Salehan M, 2016, DECIS SUPPORT SYST, V81, P30, DOI 10.1016/j.dss.2015.10.006
   Saravia E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3687
   SCHERER KR, 1994, J PERS SOC PSYCHOL, V66, P310, DOI 10.1037/0022-3514.66.2.310
   Schuff H, 2017, P 8 WORKSHOP COMPUTA, P13
   Siegel EH, 2018, PSYCHOL BULL, V144, P343, DOI 10.1037/bul0000128
   Tenney I., 2019, ARXIV
   Tian G, 2021, FOOD QUAL PREFER, V88, DOI 10.1016/j.foodqual.2020.104060
   Uhls YT, 2014, COMPUT HUM BEHAV, V39, P387, DOI 10.1016/j.chb.2014.05.036
   Vinodhini G, 2012, INT J-TORONTO, V2, P282
   Volkova S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1567
   Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P587, DOI 10.1109/SocialCom-PASSAT.2012.119
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Zhang Y, 2021, ORG CHEM FRONT, V8, DOI 10.1039/d0qo01636e
NR 43
TC 2
Z9 2
U1 6
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD MAY
PY 2023
VL 35
IS 15
BP 10945
EP 10956
DI 10.1007/s00521-023-08276-8
EA JAN 2023
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P9VF6
UT WOS:000922941100002
PM 36718270
OA Green Published, hybrid
DA 2023-11-10
ER

PT J
AU Firmino, AA
   Baptista, CD
   de Paiva, AC
AF Firmino, Anderson Almeida
   Baptista, Claudio de Souza
   de Paiva, Anselmo Cardoso
TI Improving hate speech detection using Cross-Lingual Learning
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Hate speech detection; Natural language processing; Social media;
   Cross-Lingual Learning; Deep learning
AB The growth of social media worldwide has brought social benefits and challenges. One problem we highlight is the proliferation of hate speech on social media. We propose a novel method for detecting hate speech in texts using Cross-Lingual Learning. Our approach uses transfer learning from Pre-Trained Language Models (PTLM) with large corpora available to solve problems in languages with fewer resources for the specific task. The proposed methodology comprises four stages: corpora acquisition, the PTLM definition, training strategies, and evaluation. We carried out experiments using Pre-Trained Language Models in English, Italian, and Portuguese (BERT and XLM-R) to verify which best suited the proposed method. We used corpora in English (WH) and Italian (Evalita 2018) as the source language and the OffComBr-2 corpus in Portuguese (the target language). The results of the experiments showed that the proposed methodology is promising: for the OffComBr-2 corpus, the best state-of-the-art result was obtained (F1-measure = 92%).
C1 [Firmino, Anderson Almeida; Baptista, Claudio de Souza] Univ Fed Campina Grande, Rua Aprigio Veloso 882, Campina Grande, PB, Brazil.
   [de Paiva, Anselmo Cardoso] Univ Fed Maranhao, Ave Portugueses 1966, Sao Luis, MA, Brazil.
C3 Universidade Federal de Campina Grande; Universidade Federal do Maranhao
RP Firmino, AA (通讯作者)，Univ Fed Campina Grande, Rua Aprigio Veloso 882, Campina Grande, PB, Brazil.
EM andersonalmeida@copin.ufcg.edu.br; baptista@computacao.ufcg.edu.br;
   paiva@nca.ufma.br
FU Brazilian National Council of Scientific and Technological Development
   (CNPq); Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior -
   Brasil (CAPES) [001]
FX The authors would like to thank the Brazilian National Council of
   Scientific and Technological Development (CNPq) and the Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior - Brasil (CAPES) - Finance
   Code 001 for partially funding this research.
CR Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   Bassignana E., 2018, CEUR WORKSHOP P, V2253
   Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Bhaskaran J, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P62
   Bigoulaeva I., 2021, P 1 WORKSH LANG TECH, P15
   Bosco C., 2018, CEUR WORKSHOP P
   Bourgonje P, 2018, LECT NOTES ARTIF INT, V10713, P180, DOI 10.1007/978-3-319-73706-5_15
   Burnap P, 2016, EPJ DATA SCI, V5, DOI 10.1140/epjds/s13688-016-0072-6
   Chung YL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2819
   Conneau A, 2021, INTERSPEECH, P2426, DOI 10.21437/Interspeech.2021-329
   Corazza M, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3377323
   Croce D., 2020, CEUR WORKSHOP P, V2765
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   de Pelle R. P., 2017, P 6 BRAZ WORKSH SOC, DOI [10.5753/brasnam.2017.3260, DOI 10.5753/BRASNAM.2017.3260]
   Del Vigna F, 2017, P 1 IT C CYB ITASEC1, P86, DOI 10.1051/matecconf/201712502035
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Firmino AA, 2021, LECT NOTES COMPUT SC, V12924, P170, DOI 10.1007/978-3-030-86475-0_17
   Fortuna P, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102524
   Fortuna P, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P94
   Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676
   Frenda S, 2019, J INTELL FUZZY SYST, V36, P4743, DOI 10.3233/JIFS-179023
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Hartmann, 2017, ARXIV170806025
   Hewitt S, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P333, DOI 10.1145/2908131.2908183
   Karim MR, 2021, 2021 IEEE 8TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA), DOI 10.1109/DSAA53316.2021.9564230
   Kemp S., 2021, US
   Kottasova I., 2017, US
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G., 2018, INT C LEARNING REPRE
   Lima C., 2019, P 15 DAT WORKSH, P61, DOI [10.5753/erbd.2019.8479, DOI 10.5753/ERBD.2019.8479]
   Mathew B, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI'19), P173, DOI 10.1145/3292522.3326034
   Mikolov Tomas, 2013, INT C LEARN REPR
   Plaza-del-Arco FM, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114120
   Mondal M, 2018, NEW REV HYPERMEDIA M, V24, P110, DOI 10.1080/13614568.2018.1489001
   Mozafari M, 2022, IEEE ACCESS, V10, P14880, DOI 10.1109/ACCESS.2022.3147588
   Nobata C, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P145, DOI 10.1145/2872427.2883062
   Nozza D, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P907
   Pamungkas EW, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102544
   Pamungkas EW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P363
   Pari C., 2019, P 16 NAT C ART COMP, P1020
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Pikuliak M, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113765
   Poletto F, 2021, LANG RESOUR EVAL, V55, P477, DOI 10.1007/s10579-020-09502-8
   Ranasinghe T, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3457610
   Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668
   Schmidt Anna, 2017, P 5 INT WORKSH NAT L, P1, DOI DOI 10.18653/V1/W17-1101
   Schweter Stefan, 2020, Zenodo
   Shearer E., 2021, US
   Silva S. C., 2019, J INFORM DATA MANAGE, V5, P1
   Soto CP, 2022, MULTIMED TOOLS APPL, V81, P27111, DOI 10.1007/s11042-021-11880-2
   Souza Fabio, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P403, DOI 10.1007/978-3-030-61377-8_28
   Stappen L., 2020, ARXIV
   U. N. Human Rights Council, 2013, US
   van der Heijden N, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1966
   Wagner K., 2020, US
   Waseem Zeerak, 2016, P NAACL STUD RES WOR, P88, DOI [DOI 10.18653/V1/N16-2013, 10.18653/v1/n16-2013]
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Zhang E., 2009, ENCY DATABASE SYSTEM, P1147, DOI [10.1007/978-0-387-39940-9_483, DOI 10.1007/978-0-387-39940-9_483]
NR 58
TC 0
Z9 0
U1 5
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JAN
PY 2024
VL 235
AR 121115
DI 10.1016/j.eswa.2023.121115
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA R8ME4
UT WOS:001066834800001
DA 2023-11-10
ER

PT S
AU Jain, S
   Kinber, E
AF Jain, Sanjay
   Kinber, Efim
BE Lugosi, G
   Simon, HU
TI On learning languages from positive data and a limited number of short
   counterexamples
SO LEARNING THEORY, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 19th Annual Conference on Learning Theory (COLT 2006)
CY JUN 22-25, 2006
CL Carnegie Mellon Univ, Pittsburgh, PA
SP IBM, Google, Machine Learning Journal, Natl ICT Australia
HO Carnegie Mellon Univ
ID MACHINE INDUCTIVE INFERENCE; IDENTIFICATION; CRITERIA
AB We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller that the largest element of input seen so far). Negative counterexamples to a conjecture are examples which belong to the conjectured language but do not belong to the input language. Within this framework, we explore how/when learners using n short (arbitrary) negative counterexamples can be simulated (or simulate) using least short counterexamples or just 'no' answers from a teacher. We also study how a limited number of short counterexamples fairs against unconstrained counterexamples. A surprising result is that just one short counterexample (if present) can sometimes be more useful than any bounded number of counterexamples of least size. Most of results exhibit salient examples of languages learnable or not learnable within corresponding variants of our models.
C1 Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore.
   Univ Sacred Heart, Dept Comp Sci, Fairfield, CT 06432 USA.
C3 National University of Singapore; Sacred Heart University
RP Jain, S (通讯作者)，Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore.
EM sanjay@comp.nus.edu.sg; kinbere@sacredheart.edu
CR Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1007/BF00116828
   BALIGA G, 1995, J COMPUT SYST SCI, V51, P273, DOI 10.1006/jcss.1995.1066
   Barzdins J., 1974, THEORY ALGORITHMS PR, V210, P82
   CASE J, 1982, LECT NOTES COMPUT SC, V140, P107
   CASE J, 1983, THEOR COMPUT SCI, V25, P193, DOI 10.1016/0304-3975(83)90061-0
   GASARCH W, 1998, BOUNDED QUERIES RECU
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Jain S, 2006, INFORM COMPUT, V204, P123, DOI 10.1016/j.ic.2005.09.001
   JAIN S, 2006, IN PRESS J COMPUTER
   JAIN S, 2005, TR2105 NAT U SING SC
   Lange S, 2004, LECT NOTES ARTIF INT, V3244, P99
   Lange S, 2004, LECT NOTES COMPUT SC, V3120, P155, DOI 10.1007/978-3-540-27819-1_11
   MOTOKI T, 1991, INFORM PROCESS LETT, V39, P177, DOI 10.1016/0020-0190(91)90176-I
   OSHERSON DN, 1982, INFORM CONTROL, V52, P123, DOI 10.1016/S0019-9958(82)80025-9
   Rogers Hartley, 1987, THEORY RECURSIVE FUN
   WIEHAGEN R, 1994, J EXP THEOR ARTIF IN, V6, P131, DOI 10.1080/09528139408953785
   ZEUGMANN T, 1995, LECT NOTES ARTIF INT, V961, P190
NR 17
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-35294-5
J9 LECT NOTES ARTIF INT
PY 2006
VL 4005
BP 259
EP 273
DI 10.1007/11776420_21
PG 15
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BEV20
UT WOS:000239587900021
DA 2023-11-10
ER

PT J
AU Li, LH
   Chen, PH
   Hsieh, CJ
   Chang, KW
AF Li, Liunian Harold
   Chen, Patrick H.
   Hsieh, Cho-Jui
   Chang, Kai-Wei
TI Efficient Contextual Representation Learning With Continuous Outputs
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Contextual representation models have achieved great success in improving various downstream natural language processing tasks. However, these language-model-based encoders are difficult to train due to their large parameter size and high computational complexity. By carefully examining the training procedure, we observe that the softmax layer, which predicts a distribution of the target word, often induces significant overhead, especially when the vocabulary size is large. Therefore, we revisit the design of the output layer and consider directly predicting the pre-trained embedding of the target word for a given context. When applied to ELMo, the proposed approach achieves a 4-fold speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks. Further analysis shows that the approach maintains the speed advantage under various settings, even when the sentence encoder is scaled up.
C1 [Li, Liunian Harold] Peking Univ, Beijing, Peoples R China.
   [Chen, Patrick H.; Hsieh, Cho-Jui; Chang, Kai-Wei] Univ Calif Los Angeles, Los Angeles, CA USA.
C3 Peking University; University of California System; University of
   California Los Angeles
RP Li, LH (通讯作者)，Peking Univ, Beijing, Peoples R China.
EM liliunian@pku.edu.cn; patrickchen@g.ucla.edu; chohsieh@cs.ucla.edu;
   kwchang@cs.ucla.edu
RI Chen, Patrick/HGA-3011-2022
FU National Science Foundation [IIS-1760523, IIS-1901527]
FX We wish to thank the anonymous reviewers, the editor, Mark Yatskar,
   Muhao Chen, Xianda Zhou, and members at UCLANLP lab for helpful
   comments. We also thank Yulia Tsvetkov and Sachin Kumar for help with
   implementing the continuous output layer as well as Jieyu Zhao, Kenton
   Lee, and Nelson Liu for providing reproducible source code for
   experiments. Thiswork was supported by National Science Foundation grant
   IIS-1760523 and IIS-1901527.
CR [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2013, INT C LEARNING REPRE
   [Anonymous], 2016, ARXIV161101576
   Ba Jimmy Lei, 2016, ARXIV160706450
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Chelba C., 2013, ARXIV PREPRINT ARXIV
   Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Devlin J., 2018, ARXIV, V1, P4171
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   EdouardGrave Armand, 2016, ARXIV PREPRINT ARXIV
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P1
   He K., 2017, P IEEE INT C COMPUTE
   He LH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P473, DOI 10.18653/v1/P17-1044
   He SX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2061
   Jolliffe I., 2011, INT ENCY STAT SCI, P1094, DOI 10.1007/978-3-642-04898-2455
   Jozefowicz Rafal, 2016, ARXIV PREPRINT ARXIV
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V28, P3, DOI DOI 10.48550/ARXIV.1506.06726
   Kitaev Nikita, 2018, ARXIV181211760
   Kumar Sachin, 2019, INT C LEARN REPR
   Lee Kenton, 2018, P 2018 C NAACL HUM L, P687, DOI [10.18653/v1/N18-2108, DOI 10.18653/V1/N18-2108]
   Lee Kenton, 2017, P 2017 C EMP METH NA, P188, DOI DOI 10.18653/V1/D17-1018
   Lei T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4470
   Logeswaran L, 2018, ICLR
   McCann Bryan, 2017, ADV NEURAL INFORM PR, P6297
   Merity S., 2018, ANAL NEURAL LANGUAGE
   Mnih Andriy, 2012, ARXIV12066426, P1751
   Morin F., 2005, AISTATS, V5, P246
   Omer Levy andYoavGoldberg, 2014, NIPS
   Panchenko Alexander, 2017, ARXIV PREPRINT ARXIV
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Pinter Y., 2017, P 2017 C EMPIRICAL M, P102
   Pradhan S., 2012, JOINT C EMNLP CONLL, P1
   Pradhan Sameer., 2013, P 17 C COMPUTATIONAL, P143
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   ShuaiTang Hailin Jin, 2018, WORKSH REPR LEARN NL
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sontag David, 2017, ABS170500557 CORR
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   TomasMikolov EdouardGrave, 2017, ARXIV PREPRINT ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Yang Z., 2017, ARXIV171103953
   Yoshua Bengio, 2003, AISTATS
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
NR 52
TC 4
Z9 4
U1 0
U2 2
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2019
VL 7
BP 611
EP 624
DI 10.1162/tacl_a_00289
PG 14
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA VK5UX
UT WOS:000736523200039
OA gold
DA 2023-11-10
ER

PT J
AU Zaha, JM
   Dumas, M
   ter Hofstede, AHM
   Barros, A
   Decker, G
AF Zaha, Johannes Maria
   Dumas, Marlon
   ter Hofstede, Arthur H. M.
   Barros, Alistair
   Decker, Gero
TI Bridging global and local models of service-oriented systems
SO IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND
   REVIEWS
LA English
DT Article; Proceedings Paper
CT 10th IEEE International Enterprise Distributed Object Computing
   Conference (EDOC)
CY OCT 16-20, 2006
CL Hong Kong, PEOPLES R CHINA
SP IEEE Comp Soc, IEEE Commun Soc, City Univ Hong Kong, Hong Kong Polytech Univ, Hong Kong Web Soc, IEEE IT Profess Magazine, AMC, KC Wong Educ Fdn, IEEE Hong Kong Chapter
DE choreography; orchestration; service-oriented architecture; web service
AB A service-oriented system is a collection of independent services that interact with one another through message exchanges. Languages such as the Web Services Description Language (WSDL) and the Business Process Execution Language (BPEL) allow developers to capture the interactions in which an individual service can engage, both from a structural and from a behavioral perspective. However, in large service-oriented systems, stakeholders may require a global picture of the way services interact with each other, rather than multiple small pictures focusing on individual services. Such global models are especially useful when a set of services interact in such a way that none of them sees all messages being exchanged, yet interactions between some services may affect the way other services interact. Unfortunately, global models of service interactions may sometimes capture behavioral constraints that cannot be enforced locally. In other words, some global models may not be translatable into a set of local models such that the sum of the local models equals the original global model. Starting from a previously proposed language for global modeling of service interactions, this paper defines an algorithm for determining if a global model is locally enforceable and an algorithm for generating local models from global ones. It also shows how local models are mapped into templates of BPEL process definitions.
C1 [Zaha, Johannes Maria] Univ Duisburg Essen, Inst Comp Sci & Informat Syst, D-45117 Essen, Germany.
   [Dumas, Marlon] Queensland Univ Technol, Brisbane, Qld 4001, Australia.
   [Dumas, Marlon] Univ Tartu, Inst Comp Sci, EE-50409 Tartu, Estonia.
   [ter Hofstede, Arthur H. M.] Queensland Univ Technol, Fac Informat Technol, Brisbane, Qld 4001, Australia.
   [Barros, Alistair] Univ Queensland, SAP Res Ctr, Brisbane, Qld 4000, Australia.
   [Decker, Gero] Hasso Plattner Inst, D-14482 Potsdam, Germany.
C3 University of Duisburg Essen; Queensland University of Technology (QUT);
   University of Tartu; Queensland University of Technology (QUT);
   University of Queensland; University of Potsdam
RP Zaha, JM (通讯作者)，Univ Duisburg Essen, Inst Comp Sci & Informat Syst, D-45117 Essen, Germany.
EM johannes.zaha@sse.uni-due.de; mar-lon.dumas@ut.ee;
   a.terhofstede@qut.edu.au; alistair.barros@sap.com;
   gero.decker@hpi.uni-potsdam.de
RI Barros, Alistair/HPC-0647-2023; Hofstede, Arthur HM ter/I-9787-2012;
   Dumas, Marlon/H-2757-2015
OI Hofstede, Arthur HM ter/0000-0002-2730-0201; Dumas,
   Marlon/0000-0002-9247-7476; Barros, Alistair/0000-0001-8980-6841
CR [Anonymous], 2004, BUSINESS PROCESS MOD
   [Anonymous], 2003, BUSINESS PROCESS EXE
   [Anonymous], 2005, WEB SERVICES CHOREOG
   Baresi L., 2004, P IFIP TC8 WORK C MO, P93
   BARROS A, 2005, P 3 INT C BUS PROC M, P302
   Benatallah B, 2003, LECT NOTES COMPUT SC, V2681, P449
   BUSI N, 2006, P INT C COORD MOD LA, P63
   CLARK J, 2001, EBXML BUSINESS PROCE
   Decker G, 2006, LECT NOTES COMPUT SC, V4184, P163
   Foster H, 2005, 2005 IEEE International Conference on Web Services, Vols 1 and 2, Proceedings, P95, DOI 10.1145/1117696.1117716
   Hull R, 2005, SIGMOD REC, V34, P86
   Khalaf R, 2006, ICWS 2006: IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P770
   MARTIN D, P 1 INT WORKSH SEM W, P26
   Mendling J, 2005, LECT NOTES COMPUT SC, V3762, P506
   *OMG, 2004, UML PROF EDOC
   Quartel D., 2004, P 2 INT C SERV OR CO, P1
   Reichert M, 1998, J INTELL INF SYST, V10, P93, DOI 10.1023/A:1008604709862
   Roman D, 2005, APPL ONTOL, V1, P77
   *XCBL CONS, 2003, ORD MAN CHOR
   YANG H, 2006, FORMAL MODEL WEB SER
   Zaha JM, 2006, IEEE INT ENTERP DIST, P45
   Zaha JM, 2006, LECT NOTES COMPUT SC, V4275, P145
NR 22
TC 13
Z9 15
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1094-6977
EI 1558-2442
J9 IEEE T SYST MAN CY C
JI IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.
PD MAY
PY 2008
VL 38
IS 3
BP 302
EP 318
DI 10.1109/TSMCC.2008.919193
PG 17
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 293SL
UT WOS:000255354900004
DA 2023-11-10
ER

PT J
AU Bisazza, A
   Federico, M
AF Bisazza, Arianna
   Federico, Marcello
TI A Survey of Word Reordering in Statistical Machine Translation:
   Computational Models and Language Phenomena
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Word reordering is one of the most difficult aspects of statistical machine translation (SMT), and an important factor of its quality and efficiency. Despite the vast amount of research published to date, the interest of the community in this problem has not decreased, and no single method appears to be strongly dominant across language pairs. Instead, the choice of the optimal approach for a new translation task still seems to be mostly driven by empirical trials.
   To orient the reader in this vast and complex research area, we present a comprehensive survey of word reordering viewed as a statistical modeling challenge and as a natural language phenomenon. The survey describes in detail how word reordering is modeled within different string-based and tree-based SMT frameworks and as a stand-alone task, including systematic overviews of the literature in advanced reordering modeling.
   We then question why some approaches are more successful than others in different language pairs. We argue that besides measuring the amount of reordering, it is important to understand which kinds of reordering occur in a given language pair. To this end, we conduct a qualitative analysis of word reordering phenomena in a diverse sample of language pairs, based on a large collection of linguistic knowledge. Empirical results in the SMT literature are shown to support the hypothesis that a few linguistic facts can be very useful to anticipate the reordering characteristics of a language pair and to select the SMT framework that best suits them.
C1 [Bisazza, Arianna] Univ Amsterdam, Inst Informat, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
   [Federico, Marcello] Fdn Bruno Kessler, Via Sommar 18, I-38123 Povo, Trento, Italy.
C3 University of Amsterdam; Fondazione Bruno Kessler
RP Bisazza, A (通讯作者)，Univ Amsterdam, Inst Informat, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
EM a.bisazza@uva.nl; federico@fbk.eu
OI Bisazza, Arianna/0000-0003-1270-3048
CR ALONAIZAN Y, 2006, P 21 INT C COMP LING, P529
   Alperen MS, 2010, P LREC WORKSHOP EXPL, P49
   Andreas Jacob, 2011, P 6 WORKSH STAT MACH, P227
   [Anonymous], 2013, P 2013 C EMP METH NA
   [Anonymous], P 4 WORKSH STAT MACH
   [Anonymous], 2007, 2007 8 INT C ELECT P, DOI DOI 10.1109/ICEPT.2007.4441448
   [Anonymous], 2013, NTCIR
   [Anonymous], 2005, P ACL WORKSHOP INTRI
   [Anonymous], P INT WORKSH SPOK LA
   [Anonymous], 2013, WORLD ATLAS LANGUAGE
   [Anonymous], 2010, P JOINT 5 WORKSHOP S
   [Anonymous], 2011, PROC 49 ACL
   [Anonymous], 2011, P 49 ANN M ASS COMP
   [Anonymous], 2013, P 2013 CONFERENCEON
   [Anonymous], 2005, P 43 ANN M ASS COMPU
   [Anonymous], 2008, P 2008 C EMPIRICAL M
   [Anonymous], 2009, P 4 WORKSH STAT MACH
   [Anonymous], 2009, P EACL 2009 WORKSH C
   [Anonymous], 2004, PROC HLTNAACL 04
   [Anonymous], 2007, P 45 ANN M ASS COMPU
   [Anonymous], 2011, P 2011 C EMPIRICAL M
   [Anonymous], 2007, P 11 C THEOR METH IS
   Auli M., 2014, P 2014 C EMP METH NA, P1250
   Bach N, 2009, P HUM LANG TECHN 200, P1
   BANGALORE S, 2000, P ICSLP BEIJ CHIN OC, V2, P422
   BERGER A, 1996, Patent No. 5510981
   Bikel DM, 2004, COMPUT LINGUIST, V30, P479, DOI 10.1162/0891201042544929
   Birch A., 2011, THESIS
   Birch A, 2010, MACH TRANSL, V24, P15, DOI 10.1007/s10590-009-9066-5
   Birch Alexandra, 2014, INT WORKSH SPOK LANG, P49
   Birch Alexandra, 2008, P 2008 C EMP METH NA, P745, DOI DOI 10.3115/1613715.1613809
   Bisazza A., 2013, P 8 WORKSH STAT MACH, P440
   Bisazza A, 2010, P JOINT 5 WORKSH STA, P241
   Bisazza A, 2012, MACH TRANSL, V26, P85, DOI 10.1007/s10590-011-9104-y
   Bisazza Arianna, 2012, P 50 ANN M ASS COMP, P478
   Bisazza Arianna, 2013, THESIS
   Bojar Ondrej, 2014, P 9 WORKSH STAT MACH, P12, DOI DOI 10.3115/V1/W14-3302
   Braune Fabienne, 2012, P ANN C EUR ASS MACH, P28
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Carpuat M., 2010, P ACL 2010 C UPPS SW, P178
   Carpuat M, 2012, MACH TRANSL, V26, P105, DOI 10.1007/s10590-011-9112-y
   Casacuberta F, 2004, COMPUT LINGUIST, V30, P205, DOI 10.1162/089120104323093294
   Cettolo Mauro, 2014, P INT WORKSH SPOK LA
   Chang Pi-Chuan, 2007, P 45 ANN M ASS COMP, P9
   Chen B., 2006, P IWSLT, P182
   Cherry C., 2008, P ACL 08 HLT COL OH, P72
   Cherry C, 2013, P 2013 C N AM CHAPT, P22
   Cherry C., 2012, P 7 WORKSH STAT MACH, P200
   Chiang D, 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Collins M., 2005, P 43 ANN M ASS COMP, V43, P531, DOI DOI 10.3115/1219840.1219906
   Corder S. P., 1979, STUDIES 2 LANGUAGE A, V2, P27, DOI [10.1017/S0272263100000930, DOI 10.1017/S0272263100000930, 10.1017/s0272263100000930]
   Costa-Jussà MR, 2009, IEICE T INF SYST, VE92D, P2179, DOI 10.1587/transinf.E92.D.2179
   Costa-jussa MR, 2006, P 2006 C EMP METH NA, P70
   Crego J. M., 2008, P 3 WORKSH STAT MACH, P53
   Crego JM, 2005, 10 MACH TRANSL SUMM, P283
   de Gispert A, 2010, COMPUT LINGUIST, V36, P505, DOI 10.1162/coli_a_00006
   Dekai Wu, 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1328
   DeNero John, 2011, P C EMP METH NAT LAN, P193
   Ding Yuan, 2005, P 43 ANN M ASS COMP, P541, DOI DOI 10.3115/1219840.1219907
   DRYER MS, 1989, STUD LANG, V13, P257, DOI 10.1075/sl.13.2.03dry
   Dryer S. Matthew, 2007, LANGUAGE TYPOLOGY SY, VI, P61
   DURRANI N, 2013, P 51 ANN M ASS COMP, P399
   Durrani Nadir, 2014, P 25 ANN C COMP LING, P421
   Dyer Chris, 2010, HUMAN LANGUAGE TECHN, P858
   El-Kahlout ID, 2010, IEEE T AUDIO SPEECH, V18, P1313, DOI 10.1109/TASL.2009.2033321
   Federico M., 2013, T ASS COMPUTATIONAL, V1, P327
   FENG M, 2013, P 51 ANN M ASS COMP, V1, P322
   Feng M, 2012, COLING, P867
   Feng Minwei, 2010, C ASS MACH TRANSL AM
   Feng Yang, 2010, P 23 INT C COMP LING, P285
   Finch A., 2009, PROC C EMPIRICAL MET, P1124
   Fox HJ, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P304
   Fraser, 2012, P 13 C EUR CHAPT ASS, P726
   Freitag Markus, 2013, MACH TRANSL SUMM NIC, P159
   Galley M, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P273
   Galley Michel, 2008, P 2008 C EMP METH NA, P848, DOI DOI 10.3115/1613715.1613824
   Gao Y., 2011, P 2011 C EMP METH NA, P857
   Genzel Dmitriy, 2010, P 23 INT C COMPUTATI, P376
   Goto I, 2012, P ANN M ASS COMP LIN, V2, P311
   Goto I., 2013, ACM T ASIAN LANGUAGE, V12
   Goto Isao, 2013, P 51 ANN M ASS COMP, P155
   Green S., 2009, P 3 WORKSH COMP APPR
   Green S., 2010, P 2010 ANN C N AM CH, P867
   Gupta D., 2007, MT SUMMIT, P207
   HABASH N, 2007, P MT SUMM 11, P215
   Hardmeier C, 2010, P JOINT 5 WORKSH STA, P88
   HASAN S, 2008, P INT C LANG RES EV, P2167
   Hayashi K., 2013, P C EMP METH NAT LAN, P1382
   He Zhongjun, 2010, C ASS MACH TRANSL AM
   Howlett Susan, 2011, P 49 ANN M ASS COMP, P384
   Huang Z., 2013, P 2013 C EMP METH NA, P556
   Huck M, 2013, P 8 WORKSH STAT MACH, P452
   Imamura Kenji, 2005, MT SUMMIT 10, P267
   Isozaki H., 2010, P 2010 C EMP METH NA, P944
   Isozaki Hideki, 2010, P JOINT 5 WORKSHOP S, P244
   Jehl L, 2014, P 14 C EUR CHAPT ASS, P239
   Jiang Q, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P737
   Kanthak S, 2005, ACL WORKSH BUILD US, P167
   Katz-Brown J., 2011, P C EMP METH NAT LAN, P183
   Khalilov M, 2012, NAT LANG ENG, V18, P491, DOI 10.1017/S1351324912000162
   Khalilov M, 2011, COMPUT SPEECH LANG, V25, P761, DOI 10.1016/j.csl.2011.01.001
   Khalilov Maxim, 2011, P INT JOINT C NAT LA, P38
   Klein D., 2003, ADV NEURAL INFORM PR, P3
   Knight K, 1999, COMPUT LINGUIST, V25, P607
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   Koehn Philipp, 2002, EUROPARL MULTI UNPUB
   Li Chi-Ho, 2007, P 45 ANN M ASS COMPU, P720
   Li J., 2012, P 7 WORKSH STAT MACH, P232
   Li Peng, 2014, P COLING 2014 25 INT, P1897
   Li Ying, 2008, J CHINESE LANGUAGE C, V18, P47
   Liang Huang, 2006, P 7 C ASS MACH TRANS, P66
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Marcu Daniel, 2006, P 2006 C EMP METH NA, P44
   Crego JM, 2006, MACH TRANSL, V20, P199, DOI 10.1007/s10590-007-9024-z
   Mariño JB, 2006, COMPUT LINGUIST, V32, P527, DOI 10.1162/coli.2006.32.4.527
   Marton Y., 2008, P ACL 08 HLT COL OH, P1003
   Menezes Arul, 2007, P 2 WORKSH STAT MACH, P1
   MOORE RC, 2007, P MACH TRANSL SUMM 1, P321
   Mylonakis M., 2011, P 49 ANN M ASS COMP, P642
   Mylonakis Markos, 2010, P 14 C COMP NAT LANG, P117
   NAGATA M, 2006, P 21 INT C COMP LING, P713
   Neubig Graham, 2012, P 2012 JOINT C EMP M, P843
   Nguyen T., 2013, P 51 ANN M ASS COMP, P1587
   NIESSEN S, 2001, P MT SUMM 8 MACH TRA, P247
   Nivre J, 2006, PROC LREC, P2216
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P295
   Och FJ, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS, P71
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Papineni Kishore, 2001, RC22176 TJ WATSON RE
   Popovic Maja, 2006, P 5 INT C LANG RES E, P1278
   Ruiz Nick, 2012, INT WORKSH SPOK LANG, P61
   Schwenk Holger, 2009, P MACH TRANSL SUMM 1
   SETIAWAN H, 2013, P 51 ANN M ASS COMP, V1, P1264
   Setiawan Hendra, 2013, P 2013 C EMP METH NA, P501
   Setiawan Hendra, 2009, P ACL IJCNLP SING, P324
   Shen LB, 2010, COMPUT LINGUIST, V36, P649, DOI 10.1162/coli_a_00015
   Slawik Isabel, 2014, INT WORKSH SPOK LANG, P119
   Smith D. A., 2006, P WORKSHOP STAT MACH, P23
   Socher R., 2011, P C EMPIRICAL METHOD, P151
   Stanojevic M., 2014, P 2014 C EMP METH NA, P202
   Stanojevic Milos, 2014, P SSST 8 8 WORKSH SY, P138
   Sudoh Katsuhito, 2013, P NTCIR 10, P294
   Sudoh Katsuhito, 2011, P 13 MACH TRANSL SUM
   Sudoh Katsuhito, 2013, ACM T ASIAN LANGUAGE, V12, P12
   Talbot David, 2011, PROC 6 WORKSHOP STAT, P12
   Tillmann Christoph, 2004, P HLT NAACL, P101
   Tromble R., 2009, P 2009 C EMP METH NA, V2, P1007
   Visweswariah Karthik, 2011, P C EMP METH NAT LAN, P486
   WATANABE T, 2002, P COLING, P1079
   WATANABE T, 2006, P COLINGACL 06 SYDN, P777
   WELLINGTON B, 2006, P 21 INT C COMP LING, P977
   Wenniger Gideon Maillette de Buy, 2014, P 8 WORKSH SYNT SEM, P11, DOI [10.3115/v1/W14-4002, DOI 10.3115/V1/W14-4002]
   Williams Philip, 2014, P 9 WORKSH STAT MACH, P207
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   Wu D, 1996, P 34 ANN C ASS COMP, P152
   Xia F., 2004, P 20 INT C COMP LING, DOI 10.3115/1220355.1220428
   XIONG D, 2006, P 21 INT C COMP LING, P521
   Xu Peng, 2009, P HUMAN LANGUAGE TEC, P245
   Yahyaei Sirvan, 2010, INT WORKSH SPOK LANG, P353
   Yahyaei Sirvan, 2009, P MACH TRANSL SUMM 1
   Yamada K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P303
   Yang N., 2012, P 50 ANN M ASS COMP, P912
   Yeniterzi R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P454
   Yilmaz Ertu grul, 2013, P INT WORKSH SPOK LA
   Zens R, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P144
   Zens R, 2002, LECT NOTES ARTIF INT, V2479, P18
   Zens R, 2008, THESIS
   Zens R, 2004, P 20 INT C COMP LING, P205
   Zens Richard, 2006, P WORKSH STAT MACH T, P55
   Zhang M, 2008, P ACL 08 HLT COL OH, V08, P559
   Zhang Y, 2007, SPRINGER SER MATER S, V98, P1, DOI 10.3115/1626281.1626282
   Zollmann A., 2006, P WORKSH STAT MACH T, P138
   Zollmann A, 2008, P 22 INT C COMP LING, P1145
NR 175
TC 13
Z9 13
U1 0
U2 17
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 2016
VL 42
IS 2
BP 163
EP 205
DI 10.1162/COLI_a_00245
PG 43
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA DO8NR
UT WOS:000378040800001
OA Green Published, Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Oger, S
   Linarès, G
AF Oger, Stanislas
   Linares, Georges
TI Web-based possibilistic language models for automatic speech recognition
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Speech processing; Language modeling; Theory of possibilities
AB This paper describes a new kind of language models based on the possibility theory. The purpose of these new models is to better use the data available on the Web for language modeling. These models aim to integrate information relative to impossible word sequences. We address the two main problems of using this kind of model: how to estimate the measures for word sequences and how to integrate this kind of model into the ASR system.
   We propose a word-sequence possibilistic measure and a practical estimation method based on word-sequence statistics, which is particularly suited for estimating from Web data. We develop several strategies and formulations for using these models in a classical automatic speech recognition engine, which relies on a probabilistic modeling of the speech recognition process. This work is evaluated on two typical usage scenarios: broadcast news transcription with very large training sets and transcription of medical videos, in a specialized domain, with only very limited training data.
   The results show that the possibilistic models provide significantly lower word error rate on the specialized domain task, where classical n-gram models fail due to the lack of training materials. For the broadcast news, the probabilistic models remain better than the possibilistic ones. However, a log-linear combination of the two kinds of models outperforms all the models used individually, which indicates that possibilistic models bring information that is not modeled by probabilistic ones. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Oger, Stanislas; Linares, Georges] Univ Avignon, F-84911 Avignon 9, France.
C3 Avignon Universite
RP Linarès, G (通讯作者)，Univ Avignon, 339 Chemin Meinajaries,Agroparc BP 1228, F-84911 Avignon 9, France.
EM stanislas.oger@gmail.com; georges.linares@univ-avignon.fr
CR Allauzen A., 2005, ISCA INTERSPEECH, P1305
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   ASADI A, 1990, INT CONF ACOUST SPEE, P125, DOI 10.1109/ICASSP.1990.115554
   Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137
   Berger A, 1998, INT CONF ACOUST SPEE, P705, DOI 10.1109/ICASSP.1998.675362
   Bertoldi N., 2001, ISCA ADAPTATION METH, P187
   Borges J.L., 1944, BILBIOTECA BABEL
   Bulyko I., 2003, HUM LANG TECHN HLT N, V2, P7
   Chang F, 2006, USENIX ASSOCIATION 7TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P205
   Chollet G., 1995, SPEECH RECOGNITION C, P32
   DeCooman G, 1997, INT J GEN SYST, V25, P291, DOI 10.1080/03081079708945160
   Dubois D, 2006, COMPUT STAT DATA AN, V51, P47, DOI 10.1016/j.csda.2006.04.015
   Dubois Didier., 1988, POSSIBILITY THEORY A
   Ghemawat S., 2003, P 19 ACM S OPERATING, P20
   Goodman J., 2006, BIT PROGR LANGUAGE M
   Guthrie D., 2010, P 2010 C EMP METH NA, P262
   JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   Kemp T., 1998, INT C SPOK LANG PROC
   Lecorvé G, 2008, INT CONF ACOUST SPEE, P5081, DOI 10.1109/ICASSP.2008.4518801
   Mnih A., 2007, P 24 INT C MACHINE L, P641, DOI DOI 10.1145/1273496.1273577
   Monroe G. A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P1241, DOI 10.1109/HICSS.2002.993982
   NOCERA P, 2004, SWIM LECT MASTERS SP
   Oger S., 2009, INT C SPEECH COMM TE
   SETHY A, 2005, P INTERSPEECH, P1293
   STERN R, 1997, P DARPA SPEECH REC W, P7
   Wan V., 2006, INT C AC SPEECH SIGN, V6
   Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5
   Zhu XJ, 2001, INT CONF ACOUST SPEE, P533, DOI 10.1109/ICASSP.2001.940885
NR 29
TC 3
Z9 3
U1 0
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL
PY 2014
VL 28
IS 4
BP 923
EP 939
DI 10.1016/j.csl.2014.02.003
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI2NE
UT WOS:000336694200006
DA 2023-11-10
ER

PT J
AU Chan, SWK
   Franklin, J
AF Chan, SWK
   Franklin, J
TI Symbolic connectionism in natural language disambiguation
SO IEEE TRANSACTIONS ON NEURAL NETWORKS
LA English
DT Article
DE Bayesian network; constraint satisfaction; hybrid systems; natural
   language understanding; neural network applications; semantic analysis
ID RULES; MODEL; VARIABLES
AB Natural language understanding involves the simultaneous consideration of a large number of different sources of information. Traditional methods employed in language analysis have focused on developing powerful formalisms to represent syntactic or semantic structures along with rules for transforming language into these formalisms, However, they make use of only small subsets of knowledge. This article will describe how to use the whole range of information through a neurosymbolic architecture which is a hybridization of a symbolic network and subsymbol vectors generated from a connectionist network. Besides initializing the symbolic network with prior knowledge, the subsymbol vectors are used to enhance the system's capability in disambiguation and provide flexibility in sentence understanding. The model captures a diversity of information including word associations, syntactic restrictions, case-role expectations, semantic rules and context. It attains highly interactive processing by representing knowledge in an associative network on which actual semantic inferences are performed. An integrated use of previously analyzed sentences in understanding is another important feature of our model. The model dynamically selects one hypothesis among multiple hypotheses. This notion is supported by three simulations which show the degree of disambiguation relies both on the amount of linguistic rules and the semantic-associative information available to support the inference processes in natural language understanding. Unlike many similar systems, our hybrid system is more sophisticated in tackling language disambiguation problems by using linguistic clues from disparate sources as well as modeling context effects into the sentence analysis. It is potentially more powerful than any systems relying on one processing paradigm.
C1 City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   City Univ Hong Kong, Language Informat Sci Res Ctr, Hong Kong, Peoples R China.
   Univ New S Wales, Sch Math, Sydney, NSW, Australia.
C3 City University of Hong Kong; City University of Hong Kong; University
   of New South Wales Sydney
RP Chan, SWK (通讯作者)，City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
RI Franklin, James/IVH-1320-2023
OI Franklin, James/0000-0002-4603-1406; CHAN, Samuel
   W.K./0000-0002-2023-0781
CR Ajjanagadde V, 1991, NEURAL COMPUT, V3, P121, DOI 10.1162/neco.1991.3.1.121
   Anderson J.R., 1976, LANGUAGE MEMORY THOU
   [Anonymous], 1983, MENTAL MODELS
   BERG G, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P32
   Bookman L. A., 1993, Connection Science, V5, P243, DOI 10.1080/09540099308915701
   BOOKMAN LA, 1994, TRAJECTORIES KNOWLED
   Chan SWK, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2965
   CHAN SWK, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P935, DOI 10.1109/FUZZY.1995.409794
   CHAN SWK, 1994, ARTIF INTELL, P434
   COTTRELL GW, 1983, COGNITION BRAIN THEO, V6, P89
   Dyer M. G., 1992, CONNECTIONIST APPROA, P21
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844
   Fillmore C.J., 1968, UNIVERSALS LINGUISTI, P1, DOI DOI 10.4236/ENG
   Franklin J., 1996, Proceedings of the Seventh Australian Conference on Neural Networks (ACNN'96), P91
   HANSON SJ, 1990, MACHINE LEARNING ART, V3, P235
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   HOBBS JR, 1993, ARTIF INTELL, V63, P69, DOI 10.1016/0004-3702(93)90015-4
   Jensen K., 1988, Computational Linguistics, V13, P251
   KINTSCH W, 1978, PSYCHOL REV, V85, P363, DOI 10.1037/0033-295X.85.5.363
   Kintsch W., 1974, REPRESENTATION MEANI
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Lakoff George, 1988, P 1988 CONN MOD SUMM, P301
   Langacker R. W., 1987, FDN COGNITIVE GRAMMA
   LANGE TE, 1995, COMPUTATIONAL ARCHIT, P69
   McClelland J. L., 1986, PARALLEL DISTRIBUTED, P272
   Miikkulainen R., 1993, SUBSYMBOLIC NATURAL
   Nenov V. I., 1994, Connection Science, V6, P3, DOI 10.1080/09540099408915708
   PAVLOV IP, 1955, SELECTED WORKS IP PA
   PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7
   POLLACK JB, 1990, ARTIF INTELL, V46, P77, DOI 10.1016/0004-3702(90)90005-K
   QUILLIAN MR, 1969, COMMUN ACM, V12, P459, DOI 10.1145/363196.363214
   RAZRAN G, 1971, MIND EVOLUTION
   SHARKEY N, 1992, CONNECTIONIST NATURA
   SHASTRI L, 1993, BEHAV BRAIN SCI, V16, P417, DOI 10.1017/S0140525X00030910
   Shastri L, 1996, BEHAV BRAIN SCI, V19, P331, DOI 10.1017/S0140525X00042965
   STJOHN MF, 1990, ARTIF INTELL, V46, P217, DOI 10.1016/0004-3702(90)90008-N
   SUMIDA RA, 1992, ADV NEUR IN, V4, P233
   Sun R, 1996, FUZZY SET SYST, V82, P187, DOI 10.1016/0165-0114(95)00255-3
   SUN R, 1995, IEEE T KNOWL DATA EN, V7, P120, DOI 10.1109/69.368514
   Sun R., 1994, INTEGRATING RULES CO
   TARABAN R, 1988, J MEM LANG, V27, P597, DOI 10.1016/0749-596X(88)90011-3
   Van Dijk TA., 1983, STRATEGIES DISCOURSE
   WALTZ DL, 1985, COGNITIVE SCI, V9, P51, DOI 10.1207/s15516709cog0901_4
NR 43
TC 9
Z9 12
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1045-9227
EI 1941-0093
J9 IEEE T NEURAL NETWOR
JI IEEE Trans. Neural Netw.
PD SEP
PY 1998
VL 9
IS 5
BP 739
EP 755
DI 10.1109/72.712149
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 116HX
UT WOS:000075719800003
PM 18255763
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Gezmu, AM
   Nünberger, A
AF Gezmu, Andargachew Mekonnen
   Nuenberger, Andreas
TI Morpheme-Based Neural Machine Translation Models for Low-Resource Fusion
   Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Neural machine translation; morpheme-based word segmentation; fusion
   languages; low-resource languages; transformers
AB Neural approaches, which are currently state-of-the-art in many areas, have contributed significantly to the exciting advancements in machine translation. However, Neural Machine Translation (NMT) requires a substantial quantity and good quality parallel training data to train the best model. A large amount of training data, in turn, increases the underlying vocabulary exponentially. Therefore, several proposed methods have been devised for relatively limited vocabulary due to constraints of computing resources such as systemmemory. Encoding words as sequences of subword units for so-called open-vocabulary translation is an effective strategy for solving this problem. However, the conventional methods for splitting words into subwords focus on statistics-based approaches that mainly conform to agglutinative languages. In these languages, the morphemes have relatively clean boundaries. Thesemethods still need to be thoroughly investigated for their applicability to fusion languages, which is the main focus of this article. Phonological and orthographic processes alter the borders of constituent morphemes of aword in fusion languages. Therefore, itmakes it difficult to distinguish the actual morphemes that carry syntactic or semantic information from the word's surface form, the form of the word as it appears in the text. We, thus, resorted to a word segmentation method that segments words by restoring the altered morphemes. We also compared conventional and morpheme-based NMT subword models. We could prove that morpheme-basedmodels outperform conventional subword models on a benchmark dataset.
C1 [Gezmu, Andargachew Mekonnen; Nuenberger, Andreas] Otto von Guericke Univ, Univ Pl 2, D-39106 Magdeburg, Saxony Anhalt, Germany.
C3 Otto von Guericke University
RP Gezmu, AM (通讯作者)，Otto von Guericke Univ, Univ Pl 2, D-39106 Magdeburg, Saxony Anhalt, Germany.
EM andargachew.gezmu@ovgu.de; andreas.nuernberger@ovgu.de
CR Allison B, 2006, LECT NOTES ARTIF INT, V4188, P327
   Araabi Ali, 2020, P 28 INT C COMP LING, P3429, DOI [10.18653/v1/2020.coling-main.304, DOI 10.18653/V1/2020.COLING-MAIN.304]
   Ataman Duygu, 2017, Prague Bulletin of Mathematical Linguistics, P331, DOI 10.1515/pralin-2017-0031
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Batsuren K, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P840
   Beesley Kenneth R., 2003, FINITE STATE MORPHOL
   Bentivogli Luisa, 2016, P 2016 C EMP METH NA, P257, DOI [10.18653/v1/d16-1025, DOI 10.18653/V1/D16-1025]
   Bentz C, 2016, Arxiv, DOI arXiv:1606.06996
   Bentz C, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060275
   Bostrom Kaj, 2020, ARXIV200403720
   Callison-Burch Chris, 2006, P 11 C EUR CHAP ASS
   Castilho Sheila, 2017, Prague Bulletin of Mathematical Linguistics, P109, DOI 10.1515/pralin-2017-0013
   Cherry C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4295
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Chollet Francois, 2018, P 13 C ASS MACHINE T, V1, P193
   Costa-jussà MR, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P357
   Cotterell Ryan, 2016, P 2016 C EMP METH NA, P2325, DOI [10.18653/v1/d16-1256, DOI 10.18653/V1/D16-1256]
   Creutz Mathias, 2007, ACM T SPEECH LANGUAG, V4, p3:1, DOI [10.1145/1217098.1217101, DOI 10.1145/1187415.1187418]
   CROSBIE RE, 1993, EUROSIM 92 - SIMULATION CONGRESS, P1
   Dabre Raj, 2018, P 32 PAC AS C LANG I
   Denkowski Michael J., 2017, P 1 WORKSH NEUR MACH, P18, DOI [10.18653/v1/w17-3203, DOI 10.18653/V1/W17-3203]
   Dhar Prajit, 2020, P 5 C MACH TRANSL WM, P126
   Ding Shuoyang, 2019, P MACHINE TRANSLATIO, P204
   Dorr BJ, 1999, ADV COMPUT, V49, P1, DOI 10.1016/S0065-2458(08)60282-X
   Dror Rotem, 2020, STAT SIGNIFICANCE TE, DOI [10.2200/S00994ED1V01Y202002HLT045, DOI 10.2200/S00994ED1V01Y202002HLT045]
   Eskander R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P7112
   Fabri Ray, 2014, NATURAL LANGUAGE PRO, P3, DOI DOI 10.1007/978-3-642-45358-8_1
   Freitag Markus, 2021, P 6 C MACHINE TRANSL, P733
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI DOI 10.5555/177910.177914
   Gasser Michael, 2011, C HUM LANG TECHN DEV
   Gezmu AM, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 1, P526, DOI 10.5220/0010383905260532
   Gezmu AM, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6644
   Gezmu Andargachew Mekonnen, 2018, P 1 WORKSH LING RES, P65
   Gowda Thamme, 2020, FINDINGS ASS COMPUTA, VEMNLP 2020, P3955, DOI 10.18653/v1/2020.findingsemnlp.352
   Goyal V, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): STUDENT RESEARCH WORKSHOP, P162
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI [10.18653/v1/n18, DOI 10.18653/V1/N18]
   Gutierrez-Vasques X, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3454
   Haddow B, 2022, COMPUT LINGUIST, V48, P673, DOI 10.1162/coli_a_00446
   Haspelmath Martin., 2007, LINGUIST TYPOL, V11, P119, DOI [10.1515/LINGTY.2007.011, DOI 10.1515/LINGTY.2007.011]
   Huck Matthias, 2017, P 2 C MACH TRANSL WM, P56, DOI DOI 10.18653/V1/W17-4706
   Jean S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1
   Kingma D. P., 2014, C TRACK P
   Kocmi Tom, 2021, P 6 C MACHINE TRANSL, P478
   Koehn P., 2017, WMT, P28
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn Philipp, 2004, P 2004 C EMPIRICAL M, P388
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Lankford Seamus, 2021, P 18 BIENN MACH TRAN, P48
   Lee Jason, 2017, T ASSOC COMPUT LING, V5, P365, DOI 10.1162/tacl_a_00067
   Loper E., 2002, ETMTNLP 02 P ACL 02, P63, DOI DOI 10.3115/1118108.1118117
   Machácek D, 2018, LECT NOTES ARTIF INT, V11107, P277, DOI 10.1007/978-3-030-00794-2_30
   Marie Benjamin, 2021, P 59 ANN M ASS COMP, V1, P7297, DOI [10.18653, DOI 10.48550/ARXIV.2106]
   Martin J. H., 2009, SPEECH LANGUAGE PROC
   Mielke Sabrina J., 2021, ARXIV
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Ortega JE, 2020, MACH TRANSL, V34, P325, DOI 10.1007/s10590-020-09255-9
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Popel Martin, 2018, Prague Bulletin of Mathematical Linguistics, P43, DOI 10.2478/pralin-2018-0002
   Post Matt, 2018, P 3 C MACH TRANSL RE, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]
   Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2685
   Reiter E, 2018, COMPUT LINGUIST, V44, P393, DOI [10.1162/COLI.a.00322, 10.1162/coli_a_00322]
   Rissanen Jorma, 1998, WORLD SCI SERIES COM, V15, DOI [10.1142/0822, DOI 10.1142/0822]
   Salesky E, 2020, MACH TRANSL, V34, P41, DOI 10.1007/s10590-019-09243-8
   Sälevä J, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P164
   Samuelson PA, 1936, REV ECON STUD, V4, P155
   Sánchez-Cartagena VM, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P356
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Sennrich R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P211
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Smith PS, 2014, PALGRAVE STUD PRISON, P21
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Toral A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P386
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Xu Jingjing, 2021, P 59 ANN M ASS COMP, V1, P7361
   Zuters Janis, 2018, COMMUNICATIONS COMPU, V838, P289, DOI DOI 10.1007/978-3-319-97571-9_23
NR 80
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP
PY 2023
VL 22
IS 9
AR 231
DI 10.1145/3610773
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T7EN7
UT WOS:001079577300011
OA Bronze
DA 2023-11-10
ER

PT J
AU Engesser, T
   Mattmüller, R
   Nebel, B
   Thielscher, M
AF Engesser, Thorsten
   Mattmueller, Robert
   Nebel, Bernhard
   Thielscher, Michael
TI Game description language and dynamic epistemic logic compared
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Game description language; Dynamic epistemic logic
AB Several different frameworks have been proposed to model and reason about knowledge in dynamic multi-agent settings, among them the logic-programming-based game description language GDL-III and dynamic epistemic logic (DEL). GDL-III and DEL have complementary strengths and weaknesses in terms of ease of modeling and simplicity of semantics. In this paper, we formally study the expressiveness of GDL-III vs. DEL. We clarify the commonalities and differences between those languages, demonstrate how to bridge the differences where possible, and identify large fragments of GDL-III and DEL that are equivalent in the sense that they can be used to encode games or planning tasks that admit the same legal action sequences. We prove the latter by providing translations between those fragments of GDL-III and DEL. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Engesser, Thorsten; Mattmueller, Robert; Nebel, Bernhard] Univ Freiburg, Fac Engn, Freiburg, Germany.
   [Thielscher, Michael] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
C3 University of Freiburg; University of New South Wales Sydney
RP Engesser, T (通讯作者)，Univ Freiburg, Fac Engn, Freiburg, Germany.; Thielscher, M (通讯作者)，Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
EM engesser@cs.uni-freiburg.de; mattmuel@cs.uni-freiburg.de;
   nebel@cs.uni-freiburg.de; mit@unsw.edu.au
CR Apt K., 1987, FDN DEDUCTIVE DATABA, P89
   Baral C., 2017, DAGSTUHL REPORTS, V7, P1
   Bolander Thomas, 2011, Journal of Applied Non-Classical Logic, V21, P9, DOI 10.3166/jancl.21.9-34
   Bolander T., 2014, CEUR WORKSHOP P, P87
   Bolander T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2791
   Charrier T., 2016, P 25 INT JOINT C ART, P1030
   Clark K. L., 1978, Logic and data bases, P293
   Cooper MC, 2016, FRONT ARTIF INTEL AP, V285, P193, DOI 10.3233/978-1-61499-672-9-193
   Engesser T, 2017, ELECTRON P THEOR COM, P75, DOI 10.4204/EPTCS.243.6
   Gelfond M, 2008, FOUND ARTIF INTELL, P285, DOI 10.1016/S1574-6526(07)03007-6
   Genesereth M, 2005, AI MAG, V26, P62
   Genesereth M., 2014, SYNTHESIS LECT AI MA
   Kominis F, 2015, P I C AUTOMAT PLAN S, P147
   Kooi B., 2011, P 13 C THEOR ASP RAT, P205, DOI [10.1145/2000378.2000403, DOI 10.1145/2000378.2000403]
   Le Tiep, 2018, P ICAPS
   Liu Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1912
   Lloyd J., 1987, SERIES SYMBOLIC COMP
   Löwe B, 2011, LECT NOTES ARTIF INT, V6953, P179, DOI 10.1007/978-3-642-24130-7_13
   Moses Y, 2016, ELECTRON P THEOR COM, P231, DOI 10.4204/EPTCS.215.17
   Muise C, 2015, AAAI CONF ARTIF INTE, P3327
   Rasmusen E, 2007, GAMES INFORM INTRO G
   Ruan J., 2011, P AAAI, P840
   Schiffel S, 2014, J ARTIF INTELL RES, V49, P171, DOI 10.1613/jair.4115
   Schiffel S, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P911
   Thielscher M., 2017, IJCAI 17, P1276
   van Benthem J, 2006, INFORM COMPUT, V204, P1620, DOI 10.1016/j.ic.2006.04.006
   VanDitmarsch H, 2007, SYNTH LIBR, V337, P1, DOI 10.1007/978-1-4020-5839-4
   Wan H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1093
NR 28
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD MAR
PY 2021
VL 292
AR 103433
DI 10.1016/j.artint.2020.103433
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TI1SQ
UT WOS:000672565500003
DA 2023-11-10
ER

PT J
AU Vojnovic, N
   Vidakovic, J
   Vidakovic, M
AF Vojnovic, Nikola
   Vidakovic, Jovana
   Vidakovic, Milan
TI Multi-threaded power flow of large-scale active multiphase distribution
   networks
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Large-scale active multiphase distribution; network; Multi-threaded
   power flow; Backward-forward sweep; Distributed energy resources;
   Unified Modeling Language
ID DISTRIBUTION-SYSTEMS; ALGORITHM
AB Backward-Forward Sweep is one of the most used procedures for the power flow calculation of large-scale active multiphase distribution networks. This paper introduces the decoupled network model which is suitable for the multi-threaded implementation of the Backward-Forward Sweep procedure. The main objectives of this paper are: (i) to introduce the decoupled new models of traditional and Electronically-coupled Distributed Energy Resources, (ii) to introduce the decoupled models of single-, two- and three-phase line sections, (iii) to give the detailed Unified Modeling Language diagrams of the software model and procedures, (iv) to give a detailed model and a procedure for the single-threaded power flow calculation, and (v) to give a detailed model and a procedure for the multi-threaded power flow calculation of the large-scale active multiphase distribution networks. The results show the advantage of the proposed decoupled single-threaded approach over the traditional coupled-based one - the speedup is up to 160%. Moreover, the speedup of the decoupled multi-threaded calculation of the power flow compared to the single-threaded one goes up to the 200%. This means that the decoupled multi-threaded implementation is up to 300% faster than the coupled one. These results prove that the Backward-Forward Sweep is particularly usable for the multi-threaded implementation.
C1 [Vojnovic, Nikola; Vidakovic, Milan] Univ Novi Sad, Fac Tech Sci, Novi Sad, Serbia.
   [Vidakovic, Jovana] Univ Novi Sad, Fac Sci, Novi Sad, Serbia.
C3 University of Novi Sad; University of Novi Sad
RP Vojnovic, N (通讯作者)，Univ Novi Sad, Fac Tech Sci, Novi Sad, Serbia.
EM nikola.vojnovic@uns.ac.rs
OI Vidakovic, Jovana/0000-0001-9357-828X
FU Ministry of Science, Techno- logical Development and Innovation, Serbia
   [451-03-47/2023-01/200125, 451-03-47/2023-01/200156]
FX This paper has been supported by the Ministry of Science, Techno-
   logical Development and Innovation, Serbia (Grant No.
   451-03-47/2023-01/200125 and 451-03-47/2023-01/200156) .
CR Anirudh CVS, 2021, IET RENEW POWER GEN, V15, P980, DOI 10.1049/rpg2.12077
   Araújo I, 2019, INT J ELEC POWER, V105, P229, DOI 10.1016/j.ijepes.2018.08.033
   Arboleya P, 2019, IEEE T IND APPL, V55, P7230, DOI 10.1109/TIA.2019.2913825
   Benato R, 2022, IEEE T POWER SYST, V37, P1363, DOI 10.1109/TPWRS.2021.3104097
   Cui HT, 2021, IEEE T POWER SYST, V36, P4872, DOI 10.1109/TPWRS.2021.3073591
   Dash SP, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116776
   Dkhili N, 2020, SUSTAIN ENERGY GRIDS, V21, DOI 10.1016/j.segan.2019.100284
   Hernández-Fuentes HE, 2022, SUSTAIN ENERGY GRIDS, V32, DOI 10.1016/j.segan.2022.100895
   Evangeline SI, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116544
   Feng F, 2020, IEEE T POWER SYST, V35, P4108, DOI 10.1109/TPWRS.2020.3000658
   Gianto R, 2021, IET RENEW POWER GEN, V15, P1724, DOI 10.1049/rpg2.12141
   IEEE PES Test Feeder, US
   Intel Corp, INT ONEAPI TOOLK VER
   Karimi M, 2019, INT J ELEC POWER, V113, P298, DOI 10.1016/j.ijepes.2019.05.055
   Koksoy A, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040502
   Kumar VSS, 2018, ELECTR POW SYST RES, V155, P363, DOI 10.1016/j.epsr.2017.09.011
   Lara JD, 2021, SOFTWAREX, V15, DOI 10.1016/j.softx.2021.100747
   Liu YY, 2022, EXPERT SYST APPL, V196, DOI 10.1016/j.eswa.2022.116557
   Marini A, 2019, ELECTR POW SYST RES, V170, P229, DOI 10.1016/j.epsr.2018.12.026
   Murari K, 2020, IET GENER TRANSM DIS, V14, P1627, DOI 10.1049/iet-gtd.2019.1176
   Neis P, 2019, IEEE ACCESS, V7, P177761, DOI 10.1109/ACCESS.2019.2958275
   Nguyen TT, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118127
   OpenDSS, OPENDSS VERS 9 6 1 1
   Ouali S, 2020, J ELECTR COMPUT ENG, V2020, DOI 10.1155/2020/5643410
   Pandey A, 2019, IEEE T POWER SYST, V34, P616, DOI 10.1109/TPWRS.2018.2863042
   Qu L, 2019, ENERGIES, V12, DOI 10.3390/en12234455
   Rizvi SMH, 2022, IEEE T POWER SYST, V37, P3, DOI 10.1109/TPWRS.2021.3088903
   Rodrigues Junior Heitor M., 2022, International Journal of Electrical Power & Energy Systems, DOI 10.1016/j.ijepes.2021.107921
   Sereeter B, 2017, ENERGIES, V10, DOI 10.3390/en10101658
   Shen T, 2018, ENERGIES, V11, DOI 10.3390/en11030511
   Strezoski L, 2018, IEEE T POWER SYST, V33, P1891, DOI 10.1109/TPWRS.2017.2742019
   Strezoski LV, 2019, J MOD POWER SYST CLE, V7, P1365, DOI 10.1007/s40565-018-0494-1
   Strezoski VC, 2015, INT T ELECTR ENERGY, V25, P2455, DOI 10.1002/etep.1974
   Svenda G, 2017, INT T ELECTR ENERGY, V27, DOI 10.1002/etep.2296
   Thurner L, 2018, IEEE T POWER SYST, V33, P6510, DOI 10.1109/TPWRS.2018.2829021
   Tyagi Arjun, 2020, Journal of Electrical Systems and Information Technology, V7, DOI 10.1186/s43067-020-00014-7
   Verma R, 2019, ELECTR POW SYST RES, V168, P8, DOI 10.1016/j.epsr.2018.11.005
   Vidovic PM, 2022, ELECTR ENG, V104, P473, DOI 10.1007/s00202-021-01313-6
   Vojnovic N, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108134
   Wang ZQ, 2021, SUSTAIN ENERGY GRIDS, V27, DOI 10.1016/j.segan.2021.100483
   Zeng L, 2021, IEEE ACCESS, V9, P153226, DOI 10.1109/ACCESS.2021.3127393
   Zhao JB, 2021, IET RENEW POWER GEN, V15, P3978, DOI 10.1049/rpg2.12316
NR 42
TC 0
Z9 0
U1 2
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD OCT 1
PY 2023
VL 227
AR 120313
DI 10.1016/j.eswa.2023.120313
EA MAY 2023
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA I1PR4
UT WOS:001000578000001
DA 2023-11-10
ER

PT J
AU Al-Thani, H
   Jansen, BJ
   Elsayed, T
AF Al-Thani, Haya
   Jansen, Bernard J.
   Elsayed, Tamer
TI ECAsT: a large dataset for conversational search and an evaluation of
   metric robustness
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Conversational search; Paraphrasing; Conversational evaluation;
   Open-domain
AB The Text REtrieval Conference Conversational assistance track (CAsT) is an annual conversational passage retrieval challenge to create a large-scale open-domain conversational search benchmarking. However, as of yet, the datasets used are small, with just more than 1,000 turns and 100 conversation topics. In the first part of this research, we address the dataset limitation by building a much larger novel multi-turn conversation dataset for conversation search benchmarking called Expanded-CAsT (ECAsT). ECAsT is built using a multi-stage solution that uses a combination of conversational query reformulation and neural paraphrasing and also includes a new model to create multi-turn paraphrases. The meaning and diversity of paraphrases are evaluated with human and automatic evaluation. Using this methodology, we produce and release to the research community a conversational search dataset that is 665% more extensive in terms of size and language diversity than is available at the time of this study, with more than 9,200 turns. The augmented dataset not only provides more data but also more language diversity to improve conversational search neural model training and testing. In the second part of the research, we use ECAsT to assess the robustness of traditional metrics for conversational evaluation used in CAsT and identify its bias toward language diversity. Results show the benefits of adding language diversity for improving the collection of pooled passages and reducing evaluation bias. We found that introducing language diversity via paraphrases returned up to 24% new passages compared to only 2% using CAsT baseline.
C1 [Al-Thani, Haya] Hamad Bin Khalifa Univ, Doha, Qatar.
   [Jansen, Bernard J.] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
   [Elsayed, Tamer] Qatar Univ, Comp Sci & Engn Dept, Doha, Qatar.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar
   Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Computing
   Research Institute; Qatar University
RP Al-Thani, H (通讯作者)，Hamad Bin Khalifa Univ, Doha, Qatar.
EM hayaalthani@hbku.edu.qa
CR Aliannejadi M, 2020, CHIIR'20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P33, DOI 10.1145/3343413.3377968
   Aliannejadi M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P475, DOI 10.1145/3331184.3331265
   Anand A, 2020, DAGSTUHL REPORTS, V9, DOI DOI 10.4230/DAGREP.9.11.34
   Ashraf N, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.742
   Bailey P, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/3077136.3080839
   Barzilay R, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P50
   Bondarenko A, 2018, TREC
   Buckley C., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P25, DOI 10.1145/1008992.1009000
   Buttcher Stefan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P63, DOI 10.1145/1277741.1277755
   Chen David, 2011, P 49 ANN M ASS COMP, P190
   Chklovski T., 2005, P 3 INT C KNOWL CAPT, P115, DOI DOI 10.1145/1088622.1088644
   Clarke CLA, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3451161
   Culpepper J.S., 2018, SIGIR FORUM, V52, P34, DOI [10.1145/3274784.3274788, DOI 10.1145/3274784.3274788]
   Dalton J, 2021, P 30 TEXT RETRIEVAL
   Dalton J, 2020, Arxiv, DOI [arXiv:2003.13624, 10.48550/arXiv.2003.13624, DOI 10.48550/ARXIV.2003.13624]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dietz L, 2017, TREC
   Duboue Pablo, 2006, P HUMAN LANGUAGE TEC, P33
   Duta IC, 2016, INT WORK CONTENT MUL
   Elgohary A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5918
   Falotico R, 2015, QUAL QUANT, V49, P463, DOI 10.1007/s11135-014-0003-1
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Feng S. Y., 2021, FINDINGS ASS COMPUTA, P968, DOI [DOI 10.18653/V1/2021.FINDINGS-ACL.84, 10.18653/v1/2021.findingsacl.84, 10.18653/v1/2021.findings-acl.84]
   Fishkin R, 2020, 2020 2 3S GOOGLE SEA
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gan WC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6065
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, P758
   Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, P1371, DOI 10.1145/3209978.3210183
   Guichard J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE TESTING (AITEST), P55, DOI 10.1109/AITest.2019.000-7
   Gupta A, 2018, AAAI CONF ARTIF INTE, P5149
   Hassan Samer, 2007, P 4 INT WORKSHOP SEM, P410
   Holtzman Ari, 2020, ICLR
   Iyyer M, 2018, P 2018 C N AM CHAPT, V1, P1875, DOI DOI 10.18653/V1/N18-1170
   Kacupaj E, 2021, LECT NOTES COMPUT SC, V12731, P598, DOI 10.1007/978-3-030-77385-4_36
   Kauchak David, 2006, HLT NAACL 06, P455
   Keyvan K, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3534965
   Kobayashi S., 2018, P 2018 C N AM CHAPTE, V2, P452, DOI 10.18653/v1/N18-2072
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li SK, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103067
   Lin SC, 2021, Arxiv, DOI [arXiv:2005.02230, DOI 10.48550/ARXIV.2005.02230]
   Lipani A, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3451160
   Liu BL, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103051
   Mudrakarta PK, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1896
   Niu T, 2021, Arxiv, DOI arXiv:2010.12885
   Nogueira Rodrigo, 2020, FINDINGS ASS COMPUTA, P708, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.63
   Onal KD, 2018, INFORM RETRIEVAL J, V21, P111, DOI 10.1007/s10791-017-9321-y
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Penha G, 2022, LECT NOTES COMPUT SC, V13185, P397, DOI 10.1007/978-3-030-99736-6_27
   Petroni F, 2021, Arxiv, DOI arXiv:2009.02252
   Ponkiya G, 2020, FINDINGS ASS COMPUTA, P4313
   Prakash A, 2016, ARXIV161003098, P2923
   Quirk C, 2004, P 2004 C EMP METH NA, P142
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Rosset C, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1160, DOI 10.1145/3366423.3380193
   Shen TS, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103139
   Srinivasa-Desikan B., 2018, NATURAL LANGUAGE PRO
   Voorhees EM, 2002, LECT NOTES COMPUT SC, V2406, P355
   Vtyurina Alexandra, 2017, P 2017 CHI C EXTENDE, P2187
   Wallace E, 2019, T ASSOC COMPUT LING, V7, P387, DOI 10.1162/tacl_a_00279/1923125
   Wang W. Y., 2015, P 2015 C EMP METH NA, P2557
   Yaghoub-Zadeh-Fard MA, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P55, DOI 10.1145/3377325.3377486
   Yilmaz E, 2006, P 15 ACM INT C INF K, P102, DOI DOI 10.1145/1183614.1183633
   Zhou JN, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5075
   Zuccon G, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P691, DOI 10.1145/2983323.2983723
NR 66
TC 1
Z9 1
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD APR 17
PY 2023
VL 9
DI 10.7717/peerj-cs.1328
PG 33
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P8TE7
UT WOS:001053334400004
PM 37346722
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Van Nguyen, K
   Do, PNT
   Nguyen, ND
   Nguyen, AGT
   Nguyen, NLT
AF Van Nguyen, Kiet
   Do, Phong Nguyen-Thuan
   Nguyen, Nhat Duy
   Nguyen, Anh Gia-Tuan
   Nguyen, Ngan Luu-Thuy
TI Multi-stage transfer learning with BERTology-based language models for
   question answering system in vietnamese
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Question Answering; Machine Reading Comprehension; Transfer Learning;
   BERT; BERTology; SBERT; BiLSTM; Transformer
ID KNOWLEDGE
AB With the fast growth of information science and engineering, a large number of textual data generated are valuable for natural language processing and its applications. Particularly, finding correct answers to natural language questions or queries requires spending tremendous time and effort in human life. While using search engines to discover information, users manually determine the answer to a given question on a range of retrieved texts or documents. Question answering relies heavily on the capability to automatically comprehend questions in human language and extract meaningful answers from a single text. In recent years, such question-answering systems have become increasingly popular using machine reading comprehension techniques. On the other hand, high-resource languages (e.g., English and Chinese) have witnessed tremendous growth in question-answering methodologies based on various knowledge sources. Besides, powerful BERTology-based language models only encode texts with a limited length. The longer texts contain more distractor sentences that affect the QA system performance. Vietnamese has a variety of question words in the same question type. To address these challenges, we propose ViQAS, a new question-answering system with multi-stage transfer learning using language models based on BERTology for a low-resource language such as Vietnamese. Last but not least, our QA system is integrated with Vietnamese characteristics and transformer-based evidence extraction techniques into an effective contextualized language model-based QA system. As a result, our proposed system outperforms our forty retriever-reader QA configurations and seven state-of-the-art QA systems such as DrQA, BERTserini, BERTBM25, XLMRQA, ORQA, COBERT, and NeuralQA on three Vietnamese benchmark question answering datasets.
C1 [Van Nguyen, Kiet; Do, Phong Nguyen-Thuan; Nguyen, Nhat Duy; Nguyen, Anh Gia-Tuan; Nguyen, Ngan Luu-Thuy] Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Van Nguyen, Kiet; Do, Phong Nguyen-Thuan; Nguyen, Nhat Duy; Nguyen, Anh Gia-Tuan; Nguyen, Ngan Luu-Thuy] Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Nguyen, NLT (通讯作者)，Univ Informat Technol, Ho Chi Minh City, Vietnam.; Nguyen, NLT (通讯作者)，Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
EM ngannlt@uit.edu.vn
RI Van Nguyen, Kiet/Y-8199-2019; Nguyen, Ngan/HPG-4304-2023
OI Nguyen, Kiet/0000-0002-8456-2742
CR Alzubi JA, 2023, ARAB J SCI ENG, V48, P11003, DOI 10.1007/s13369-021-05810-5
   [Anonymous], 1961, PROC W JOINT COMPUTE
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bai Yan, 2021, ARXIV
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616.1376746.URLhttps]
   Chen D., 2020, P 58 ANN M ASS COMP, P34, DOI DOI 10.18653/V1/2020.ACL-TUTORIALS.8
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chen DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2358
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Cui YM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5883
   d'Hoffschmidt M., 2020, FINDINGS ASS COMPUTA, V2020, P1193
   Das Rajarshi, 2018, 6 INT C LEARN REPR I
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dibia V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P15
   Do Phong N-T, 2021, 14 INT C
   Doan AL, 2022, ARXIV
   Dua D, 2019, NAACL HLT 1
   Efimov Pavel, 2020, Experimental IR Meets Multilinguality, Multimodality, and Interaction. 11th International Conference of the CLEF Association, CLEF 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12260), P3, DOI 10.1007/978-3-030-58219-7_1
   Feldman Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2296
   Guu Kelvin, 2020, P MACHINE LEARNING R, V119, P3929
   HARABAGIU S, 2003, P 12 TEXT RETR C TRE, P375
   Harabagiu S, 2000, COLING 2000
   Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2545
   Hermann K. M., 2015, ADV NEURAL INFORM PR
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang H-Y, 2018, ICLR FUSIONNET
   Duong HT, 2014, LECT NOTES COMPUT SC, V8838, P186, DOI 10.1007/978-3-662-45237-0_19
   Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874
   Izacard Gautier, 2021, ICLR
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769
   Nguyen KV, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3527631
   Kratzwald B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6076
   Lan Zhenzhong, 2019, ARXIV190911942
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086
   Lewis Patrick, 2020, ADV NEURAL INFORM PR, V33, P9459, DOI DOI 10.48550/ARXIV.2005.11401
   Lim S., 2019, ADV NEURAL INF PROCE, V32, P6665
   Lin J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2356, DOI 10.1145/3404835.3463238
   Lin YK, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1736
   Liu SS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183698
   Messaoudi A, 2020, 14 WORKSHOP SEMANTIC, P1978
   Min S, 2019, ARXIV
   Bach NX, 2020, CYBERN INF TECHNOL, V20, P112, DOI 10.2478/cait-2020-0008
   Nguyen A.T, 2020, FINDINGS ASS COMPUTA, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.92
   Nguyen K., 2020, P 28 INT C COMPUTATI, P2595
   Nguyen KV, 2020, IEEE ACCESS, V8, P201404, DOI 10.1109/ACCESS.2020.3035701
   Nogueira R., 2019, ARXIV
   Noraset T, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102431
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Phan T, 2021, NEURAL COMPUT APPL, V33, P14887, DOI 10.1007/s00521-021-06126-z
   Do PNT, 2021, LECT NOTES ARTIF INT, V12816, P511, DOI 10.1007/978-3-030-82147-0_42
   Do P, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3453651
   Do P, 2022, APPL INTELL, V52, P636, DOI 10.1007/s10489-021-02460-w
   Pyysalo S, 2021, NODALIDA 2021
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Reimers N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4512
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567
   Richardson M, 2013, P 2013 C EMPIRICAL M, P193
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Seo Min Joon, 2016, ARXIV
   So BH, 2022, ARXIV
   Tapeh AG, 2008, KNOWL-BASED SYST, V21, P946, DOI 10.1016/j.knosys.2008.04.005
   Tran TK, 2015, 2015 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES - RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P65, DOI 10.1109/RIVF.2015.7049876
   Tran M-V, 2012, 26 PAC AS C LANG INF, P325
   Trotman A., 2014, ADCS, P58, DOI [10.1145/2682862.2682863, DOI 10.1145/2682862.2682863]
   Van HT, 2022, 29 INT C COMPUTATION, P3858
   Van Nguyen K., 2021, J INTELL FUZZY SYST, V41, P1
   Van Nguyen K, 2022, 14 ASIAN C INTELLIGE
   Vaswani A., 2017, ARXIV, V30, P5998
   Voorhees E.M., 1999, NAT LANG ENG, V99, P77, DOI DOI 10.1017/S1351324901002789
   Wang H, 2019, CORR, P696
   Wang S, 2018, AAAI 2018
   Wang ZG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5878
   Woods W. A., 1973, AFIPS Conference Proceedings Vol.42 1973 National Computer Composition and Exposition, P441
   Wu BW, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P70
   Xiong W, 2020, ICML 2020
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P72
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369
   Zhang Z, 2020, COMPUT LINGUIST, V1
   Zhao TC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P565
   Zhu Feng, 2021, ARXIV
NR 82
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD MAY
PY 2023
VL 14
IS 5
BP 1877
EP 1902
DI 10.1007/s13042-022-01735-z
EA JAN 2023
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E4QJ0
UT WOS:000921809700001
DA 2023-11-10
ER

PT J
AU Ganji, S
   Dhawan, K
   Sinha, R
AF Ganji, Sreeram
   Dhawan, Kunal
   Sinha, Rohit
TI Novel textual features for language modeling of intra-sentential
   code-switching data
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Code-switching; Textual features; Factored language modeling
AB Code-switching refers to the frequent use of non-native language words/phrases by speakers while conversating in their native languages. Traditionally, for training a language model (LM) for code-switching data, one is required to tediously collect a large amount of text corpus in the respective code-switching domain. Alternately, we recently proposed a more viable approach that adapts an existing native LM to handle the code-switching data. In this work, we present our efforts for language modeling of code-switching data following both the traditional and the proposed approaches. The salient contributions of this paper includes: (i) creation of the Hindi-English code-switching text corpus, (ii) an improved parts-of-speech (POS) labeling scheme for accurate tagging of non-native words embedded in the code-switching data, and (iii) the proposal of a novel textual feature referred to as the code-switching location (CSL) feature, that allows LMs to predict the code-switching instances. The evaluation of the proposed features has been done on two code-switching datasets: Hindi-English and Mandarin-English. On experimental evaluation, a substantial reduction in the perplexity is achieved with the use of the improvised POS features. It is also observed that the proposed CSL features provide an independent and additive improvement over the POS features in terms of perplexity. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Ganji, Sreeram; Dhawan, Kunal; Sinha, Rohit] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Ganji, S (通讯作者)，Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM s.ganji@iitg.ac.in; k.dhawan@iitg.ac.in; rsinha@iitg.ac.in
RI Sinha, Rohit/AAX-2879-2020
OI Sinha, Rohit/0000-0002-0419-6501
CR Adel H., 2014, P SPOK LANG TECHN UN
   Adel H, 2013, INT CONF ACOUST SPEE, P8411, DOI 10.1109/ICASSP.2013.6639306
   Ahmed BHA, 2012, INT CONF ASIAN LANG, P137, DOI 10.1109/IALP.2012.28
   [Anonymous], THESIS
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], LANGUAGE INDIA
   [Anonymous], 2013, PROC ANN M ASS COMPU
   [Anonymous], 2006, LTRCTR31
   Axelrod A., 2006, FACTORED LANGUAGE MO
   Bali Kalika, 2014, P 1 WORKSHOP COMPUTA, P116, DOI DOI 10.3115/V1/W14-3914
   Bhuvanagirir K., 2012, AM J SIGNAL PROCESSI, V2, P92, DOI DOI 10.5923/J.AJSP.20120205.02
   Boztepe E., 2005, WORKING PAPERS TESOL, V3
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Chandu KR, 2018, COMPUTATIONAL APPROACHES TO LINGUISTIC CODE-SWITCHING, P29
   Chen X, 2016, INT CONF ACOUST SPEE, P6000, DOI 10.1109/ICASSP.2016.7472829
   Ching Feng Yeh, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P214, DOI 10.1109/ISCSLP.2010.5684908
   Das A., 2015, P TRAIT AUT LANG TAL, V54
   Dey A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2410
   Dhar M., 2018, P 1 WORKSH LING RES, P131
   Duh K., 2004, P 20 INT C COMP LING
   Ganji S., 2018, P INT 19 ANN C INT S
   Ganji S., 2017, P IEEE REG 10 INT C
   Ganji S., 2018, P 24 NAT C COMM NCC
   Ganji S, 2019, SPEECH COMMUN, V110, P76, DOI 10.1016/j.specom.2019.04.007
   Garg S., 2018, P INT
   Gebhardt J., 2011, THESIS
   Grosjean, 1982, LIFE 2 LANGUAGES INT
   Gumperz John Joseph, 1982, DISCOURSE STRATEGIES, V1
   Hamed I, 2017, PROCEDIA COMPUT SCI, V117, P208, DOI 10.1016/j.procs.2017.10.111
   Harb B., 2009, P INT 10 ANN C ASS
   Houwei Cao, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P246, DOI 10.1109/ISCSLP.2010.5684900
   Joshi A., 1982, P 9 INT C COMP LING, P145
   Joyce Y.C., 2005, P 9 EUR C SPEECH COM
   KUMAR A, 1986, ANTHROPOL LINGUIST, V28, P195
   Kunchukuttan A., 2017, ARXIV171002855
   Lyu D.C., 2008, P INT ANN C INT SPEE
   Lyu D.-C., 2010, P INT ANN C INT SPEE
   Lyu D.C., 2006, P INT C AC SPEECH SI, V1
   Malhotra S., 1980, KANSAS WORKING PAPER
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Mikolov T., 2011, P 2011 WORKSHOP AUTO, P196
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Mikolov Tomas, 2013, INT C LEARN REPR
   Muysken P.C., 1995, HDB BILINGUALISM, P283
   Niehues Jan, 2016, RES PAPERS, P74
   Nilep C., 2006, COLORADO RES LINGUIS, V19, P1, DOI DOI 10.25810/HNQ4-JV62
   Oparin I, 2012, INT CONF ACOUST SPEE, P5005, DOI 10.1109/ICASSP.2012.6289044
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357
   Pratapa A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1543
   Reddy S., 2011, P 5 INT WORKSHOP CRO, P11
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi Y., 2012, P 13 ANN C INT SPEEC
   Taufer M, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P512
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   Vyas Y., 2014, PROC C EMPIRICAL MET, P974
   Wu Youzheng, 2012, P COLING, P2835
NR 56
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD NOV
PY 2020
VL 64
AR 101099
DI 10.1016/j.csl.2020.101099
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LY4EE
UT WOS:000540481000004
DA 2023-11-10
ER

PT J
AU Adelani, DI
   Abbott, J
   Neubig, G
   D'souza, D
   Kreutzer, J
   Lignos, C
   Palen-Michel, C
   Buzaaba, H
   Rijhwani, S
   Ruder, S
   Mayhew, S
   Azime, IA
   Muhammad, SH
   Emezue, CC
   Nakatumba-Nabende, J
   Ogayo, P
   Anuoluwapo, A
   Gitau, C
   Mbaye, D
   Alabi, J
   Yimam, SM
   Gwadabe, TR
   Ezeani, I
   Niyongabo, RA
   Mukiibi, J
   Otiende, V
   Orife, I
   David, D
   Ngom, S
   Adewumi, T
   Rayson, P
   Adeyemi, M
   Muriuki, G
   Anebi, E
   Chukwuneke, C
   Odu, N
   Wairagala, EP
   Oyerinde, S
   Siro, C
   Bateesa, TS
   Oloyede, T
   Wambui, Y
   Akinode, V
   Nabagereka, D
   Katusiime, M
   Awokoya, A
   Mboup, M
   Gebreyohannes, D
   Tilaye, H
   Nwaike, K
   Wolde, D
   Faye, A
   Sibanda, B
   Ahia, O
   Dossou, BFP
   Ogueji, K
   Diop, TI
   Diallo, A
   Akinfaderin, A
   Marengereke, T
   Osei, S
AF Adelani, David Ifeoluwa
   Abbott, Jade
   Neubig, Graham
   D'souza, Daniel
   Kreutzer, Julia
   Lignos, Constantine
   Palen-Michel, Chester
   Buzaaba, Happy
   Rijhwani, Shruti
   Ruder, Sebastian
   Mayhew, Stephen
   Azime, Israel Abebe
   Muhammad, Shamsuddeen H.
   Emezue, Chris Chinenye
   Nakatumba-Nabende, Joyce
   Ogayo, Perez
   Anuoluwapo, Aremu
   Gitau, Catherine
   Mbaye, Derguene
   Alabi, Jesujoba
   Yimam, Seid Muhie
   Gwadabe, Tajuddeen Rabiu
   Ezeani, Ignatius
   Niyongabo, Rubungo Andre
   Mukiibi, Jonathan
   Otiende, Verrah
   Orife, Iroro
   David, Davis
   Ngom, Samba
   Adewumi, Tosin
   Rayson, Paul
   Adeyemi, Mofetoluwa
   Muriuki, Gerald
   Anebi, Emmanuel
   Chukwuneke, Chiamaka
   Odu, Nkiruka
   Wairagala, Eric Peter
   Oyerinde, Samuel
   Siro, Clemencia
   Bateesa, Tobius Saul
   Oloyede, Temilola
   Wambui, Yvonne
   Akinode, Victor
   Nabagereka, Deborah
   Katusiime, Maurice
   Awokoya, Ayodele
   Mboup, Mouhamadane
   Gebreyohannes, Dibora
   Tilaye, Henok
   Nwaike, Kelechi
   Wolde, Degaga
   Faye, Abdoulaye
   Sibanda, Blessing
   Ahia, Orevaoghene
   Dossou, Bonaventure F. P.
   Ogueji, Kelechi
   Diop, Thierno Ibrahima
   Diallo, Abdoulaye
   Akinfaderin, Adewale
   Marengereke, Tendai
   Osei, Salomey
TI MasakhaNER: Named Entity Recognition for African Languages
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We take a step towards addressing the under-representation of the African continent in NLP research by bringing together different stakeholders to create the first large, publicly available, high-quality dataset for named entity recognition (NER) in ten African languages. Wedetail the characteristics of these languages to help researchers and practitioners better understand the challenges they pose for NER tasks. We analyze our datasets and conduct an extensive empirical evaluation of stateof-the-art methods across both supervised and transfer learning settings. Finally, we release the data, code, and models to inspire future research on African NLP.(1)
C1 [Adelani, David Ifeoluwa; Abbott, Jade; D'souza, Daniel; Kreutzer, Julia; Lignos, Constantine; Palen-Michel, Chester; Buzaaba, Happy; Azime, Israel Abebe; Muhammad, Shamsuddeen H.; Emezue, Chris Chinenye; Nakatumba-Nabende, Joyce; Ogayo, Perez; Anuoluwapo, Aremu; Gitau, Catherine; Mbaye, Derguene; Alabi, Jesujoba; Gwadabe, Tajuddeen Rabiu; Ezeani, Ignatius; Niyongabo, Rubungo Andre; Otiende, Verrah; Orife, Iroro; David, Davis; Ngom, Samba; Adewumi, Tosin; Adeyemi, Mofetoluwa; Anebi, Emmanuel; Oyerinde, Samuel; Siro, Clemencia; Oloyede, Temilola; Wambui, Yvonne; Akinode, Victor; Awokoya, Ayodele; Mboup, Mouhamadane; Gebreyohannes, Dibora; Tilaye, Henok; Nwaike, Kelechi; Wolde, Degaga; Faye, Abdoulaye; Sibanda, Blessing; Ahia, Orevaoghene; Dossou, Bonaventure F. P.; Ogueji, Kelechi; Diop, Thierno Ibrahima; Diallo, Abdoulaye; Akinfaderin, Adewale; Marengereke, Tendai; Osei, Salomey] Masakhane NLP, Newark, NJ 07102 USA.
   [Adelani, David Ifeoluwa] Saarland Univ, Spoken Language Syst Grp LSV, Saarbrucken, Germany.
   [Abbott, Jade] Retro Rabbit, Pretoria, South Africa.
   [Neubig, Graham; Rijhwani, Shruti] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
   [D'souza, Daniel] ProQuest, Morrisville, NC USA.
   [Kreutzer, Julia] Google Res, Toronto, ON, Canada.
   [Lignos, Constantine; Palen-Michel, Chester] Brandeis Univ, Waltham, MA 02254 USA.
   [Ruder, Sebastian] DeepMind, London, England.
   [Mayhew, Stephen] Duolingo, Pittsburgh, PA USA.
   [Buzaaba, Happy] Univ Tsukuba, Grad Sch Syst & Informat Engn, Tsukuba, Ibaraki, Japan.
   [Azime, Israel Abebe; Osei, Salomey] African Inst Math Sci Aims AMMI, Addis Ababa, Ethiopia.
   [Muhammad, Shamsuddeen H.] Univ Porto, Port Harcourt, Nigeria.
   [Muhammad, Shamsuddeen H.] Bayero Univ, Kano, Nigeria.
   [Emezue, Chris Chinenye] Tech Univ Munich, Munich, Germany.
   [Nakatumba-Nabende, Joyce; Mukiibi, Jonathan; Muriuki, Gerald; Wairagala, Eric Peter; Bateesa, Tobius Saul; Nabagereka, Deborah; Katusiime, Maurice] Makerere Univ, Kampala, Uganda.
   [Ogayo, Perez] African Leadership Univ, Kigali, Rwanda.
   [Anuoluwapo, Aremu] Univ Lagos, Lagos, Nigeria.
   [Alabi, Jesujoba] Max Planck Inst Informat, Saarbrucken, Germany.
   [Yimam, Seid Muhie] Univ Hamburg, LT Grp, Hamburg, Germany.
   [Gwadabe, Tajuddeen Rabiu] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Ezeani, Ignatius; Rayson, Paul; Chukwuneke, Chiamaka] Univ Lancaster, Lancaster, England.
   [Niyongabo, Rubungo Andre] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Otiende, Verrah] US Int Univ Africa USIU A, Nairobi, Kenya.
   [Orife, Iroro] Niger Volta LTI, Naija, Germany.
   [Adewumi, Tosin] Luleo Univ Technol, Lulea, Sweden.
   [Odu, Nkiruka] African Univ Sci & Technol, Abuja, Nigeria.
   [Awokoya, Ayodele] Univ Ibadan, Ibadan, Nigeria.
   [Sibanda, Blessing] Namibia Univ Sci & Technol, Windhoek, Namibia.
   [Ahia, Orevaoghene] Instadeep, Lagos, Nigeria.
   [Dossou, Bonaventure F. P.] Jacobs Univ Bremen, Bremen, Germany.
   [Ogueji, Kelechi] Univ Waterloo, Waterloo, ON, Canada.
C3 Saarland University; Carnegie Mellon University; Brandeis University;
   University of Tsukuba; Bayero University; Technical University of
   Munich; Makerere University; University of Lagos; Max Planck Society;
   University of Hamburg; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS; Lancaster University; University of
   Electronic Science & Technology of China; African University of Science
   & Technology; University of Ibadan; Namibia University of Science &
   Technology; Jacobs University; University of Waterloo
RP Adelani, DI (通讯作者)，Masakhane NLP, Newark, NJ 07102 USA.; Adelani, DI (通讯作者)，Saarland Univ, Spoken Language Syst Grp LSV, Saarbrucken, Germany.
RI Rayson, Paul/HKW-7858-2023; Otiende, Verrah/G-2138-2017
OI Rayson, Paul/0000-0002-1257-2191; Otiende, Verrah/0000-0001-6147-3547;
   Yimam, Seid Muhie/0000-0002-8289-388X; Nakatumba-Nabende,
   Joyce/0000-0002-0108-3798
FU EU [3081705]
FX We would like to thank Heng Ji and Ying Lin for providing the ELISA NER
   tool used for annotation. We also thank the Spoken Language Systems
   Chair, Dietrich Klakow at Saarland University, for providing GPU
   resources to train the models. We thank Adhi Kuncoro and the anonymous
   reviewers for their useful feedback on a draft of this paper.
   DavidAdelani acknowledges the support of the EU-funded H2020 project
   COMPRISE under grant agreement no. 3081705. Finally, we thank Mohamed
   Ahmed for proofreading the draft.
CR Adelani D., 2021, ABS210308647 ARXIV
   Agic E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3204
   Alabi JO, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2754
   Benikova D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2524
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Caines Andrew, 2019, GEOGRAPHIC DIVERSITY
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI [10.1162/tacl_a_00104, DOI 10.1162/TACL_A_00104]
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   De Pauw Guy, 2007, P 1 INT COMP SCI ICT, P8
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Eberhard David M., 2020, ETHNOLOGUE LANGUAGES
   Eiselen R, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3344
   El-Kishky A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5960
   Emenanjo Nolue, 1978, ELEMENTS MODERN IGBO
   Ezeani Ignatius, 2020, ABS200400648 ARXIV, DOI DOI 10.1037/H0031619
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Fu J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6058
   Gururangan Suchin, 2020, ACL, DOI [DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.acl-main.740]
   Hedderich MA, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2580
   Howard Jeremy, 2018, P ACL 2018
   Hu Junjie, 2020, P ICML
   Huang Z., 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Ijite Blessing Onovbiona, 2012, SER VERB CONSTR NIG
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Lample Guillaume, 2016, P NAACL HLT 2016
   Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4483
   Lin Y, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P1
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Martinus Laura, 2019, ARXIV190605685
   MBS, 2020, TEER INJ BIBL WOL AN
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Nekoto Wilhelmina, 2020, FINDINGS ASS COMPUTA
   Neubig Graham, 2017, ABS170103980 ARXIV
   Niyongabo Rubungo Andre, 2020, P 28 INT C COMP LING, P5507
   Offiong Mensah Eyo, 2012, Íkala, V17, P167
   Ojarikre Anthony, 2013, PERSPECTIVES, V3
   Onyenwe IE, 2016, LECT NOTES ARTIF INT, V9924, P206, DOI 10.1007/978-3-319-45510-5_24
   Pan XM, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1946, DOI 10.18653/v1/P17-1178
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pfeiffer Jonas, 2020, ARXIV201215562
   Pfeiffer Jonas, 2020, P EMNLP 2020
   Ratinov L., 2009, P 13 C COMPUTATIONAL, DOI DOI 10.3115/1596374.1596399
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Rijhwani S., 2020, PROC 58 ANN M ASS CO, P8118
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Sangal Rajeev, 2008, P IJCNLP 08 WORKSH N
   Shaalan K, 2014, COMPUT LINGUIST, V40, P469, DOI [10.1162/coli_a_00178, 10.1162/COLI_a_00178]
   Strassel S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3273
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Tjong Kim Sang E. F., 2002, COLING 02
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Yadav V., 2018, P 27 INT C COMP LING, P2145
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6442
NR 54
TC 20
Z9 20
U1 4
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 1116
EP 1131
DI 10.1162/tacl_a_00416
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200066
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Rathnayake, H
   Sumanapala, J
   Rukshani, R
   Ranathunga, S
AF Rathnayake, Himashi
   Sumanapala, Janani
   Rukshani, Raveesha
   Ranathunga, Surangika
TI Adapter-based fine-tuning of pre-trained multilingual language models
   for code-mixed and code-switched text classification
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Code-switching; Code-mixing; Text classification; Low-resource
   languages; Sinhala; XLM-R; Adapter
AB Code-mixing and code-switching are frequent features in online conversations. Classification of such text is challenging if one of the languages is low-resourced. Fine-tuning pre-trained multilingual language models is a promising avenue for code-mixed text classification. In this paper, we explore adapter-based fine-tuning of PMLMs for CMCS text classification. We introduce sequential and parallel stacking of adapters, continuous fine-tuning of adapters, and training adapters without freezing the original model as novel techniques with respect to single-task CMCS text classification. We also present a newly annotated dataset for the classification of Sinhala-English code-mixed and code-switched text data, where Sinhala is a low-resourced language. Our dataset of 10000 user comments has been manually annotated for five classification tasks: sentiment analysis, humor detection, hate speech detection, language identification, and aspect identification, thus making it the first publicly available Sinhala-English CMCS dataset with the largest number of task annotation types. In addition to this dataset, we also tested our proposed techniques on Kannada-English and Hindi-English datasets. These experiments confirm that our adapter-based PMLM fine-tuning techniques outperform or are on par with the basic fine-tuning of PMLM models.
C1 [Rathnayake, Himashi; Sumanapala, Janani; Rukshani, Raveesha; Ranathunga, Surangika] Univ Moratuwa, Dept Comp Sci & Engn, Katubedda 10400, Sri Lanka.
C3 University Moratuwa
RP Rathnayake, H (通讯作者)，Univ Moratuwa, Dept Comp Sci & Engn, Katubedda 10400, Sri Lanka.
EM himashi.17@ese.mrt.ac.lk; jananisudeeptha.17@cse.mrt.ac.lk;
   raveesha.17@cse.mrt.ac.lk; surangika@cse.mrt.ac.lk
OI Rathnayake, Himashi/0009-0007-8862-3112
FU Senate Research Committee (SRC) Grant of University of Moratuwa, Sri
   Lanka
FX This study was funded by Senate Research Committee (SRC) Grant of
   University of Moratuwa, Sri Lanka
CR Aguilar G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1803
   [Anonymous], 2016, P 2 WORKSHOP COMPUTA
   Ansari, 2021, ARXIV PREPRINT ARXIV
   Antoun Wissam, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P519, DOI 10.1109/ICIoT48696.2020.9089487
   Bohra A., 2018, P 2 WORKSH COMP MOD, P36, DOI [10.18653/v1/W18-1105, DOI 10.18653/V1/W18-1105]
   Chakravarthi BR, 2022, LANG RESOUR EVAL, V56, P765, DOI 10.1007/s10579-022-09583-7
   Chakravarthi Bharathi Raja, 2020, P 1 JOINT WORKSHOP S, P177
   Chathuranga S., 2021, P INT C RANLP 2021, P256
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Das A, 2014, P 11 INT C NAT LANG, P378
   Dhananjaya V, 2022, P 13 LANGUAGE RESOUR
   Friedman D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6128
   Gundapu S, 2018, P 32 PAC AS C LANG I
   Hande A., 2021, ARXIV PREPRINT ARXIV
   Houlsby N, 2019, PR MACH LEARN RES, V97
   HuertasGarcia, 2021, THESIS
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, P4948
   Kamble S., 2018, ARXIV PREPRINT ARXIV
   Kazhuparambil S, 2020, ARXIV PREPRINT ARXIV
   Kenton JDMWC, 2019, UNIVERSAL LANGUAGE M, P278
   Khandelwal A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1203
   Khanuja S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3575
   Libovick J, 2019, ARXIV PREPRINT ARXIV
   Mathur P., 2018, P 2 WORKSH AB LANG O, P138, DOI [10.18653/v1/W18-5118, DOI 10.18653/V1/W18-5118]
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), P18
   Mave D, 2018, COMPUTATIONAL APPROACHES TO LINGUISTIC CODE-SWITCHING, P51
   Ousidhoum N, 2019, EMNLPIJCNLP 1
   Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P487
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7654
   Ruckle A, 2021, REPRESENTATION LEARN
   Rücklé A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7930
   Sabty C, 2019, IEEE INT C SEMANT CO, P93, DOI 10.1109/ICOSC.2019.8665500
   Senevirathne, 2020, ARXIV PREPRINT ARXIV
   Smith I, 2019, INT CONF ASIAN LANG, P228, DOI [10.1109/ialp48816.2019.9037680, 10.1109/IALP48816.2019.9037680]
   Solorio T., 2014, P 1 WORKSH COMP APPR, P62, DOI DOI 10.3115/V1/W14-3907
   Swami S, 2018, SCANNING ELECT MICRO
   Toftrup M, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P36
   Unal U, 2022, ANOMALYADAPTERS PARA
   Vaswani A, 2017, ADV NEUR IN, V30
   Vilares D, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4149
   Wang Xinyi, 2021, FINDINGS ASS COMPUTA, P730, DOI 10.18653/v1/2021.findings-emnlp.63
   Yadav Siddharth, 2020, UNSUPERVISED SENTIME
NR 44
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD JUL
PY 2022
VL 64
IS 7
BP 1937
EP 1966
DI 10.1007/s10115-022-01698-1
EA JUL 2022
PG 30
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Y6NM
UT WOS:000819885500001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Le, NT
   Sadat, F
   Menard, L
   Dinh, D
AF Ngoc Tan Le
   Sadat, Fatiha
   Menard, Lucie
   Dien Dinh
TI Low-Resource Machine Transliteration Using Recurrent Neural Networks
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Machine transliteration; recurrent neural networks; low-resource
   language; grapheme-to-phoneme; alignment; embeddings; French-Vietnamese
ID MODELS
AB Grapheme-to-phoneme models are key components in automatic speech recognition and text-to-speech systems. With low-resource language pairs that do not have available and well-developed pronunciation lexicons, grapheme-to-phoneme models are particularly useful. These models are based on initial alignments between grapheme source and phoneme target sequences. Inspired by sequence-to-sequence recurrent neural network-based translation methods, the current research presents an approach that applies an alignment representation for input sequences and pretrained source and target embeddings to overcome the transliteration problem for a low-resource languages pair. Evaluation and experiments involving French and Vietnamese showed that with only a small bilingual pronunciation dictionary available for training the transliteration models, promising results were obtained with a large increase in BLEU scores and a reduction in Translation Error Rate (TER) and Phoneme Error Rate (PER). Moreover, we compared our proposed neural network-based transliteration approach with a statistical one.
C1 [Ngoc Tan Le; Sadat, Fatiha] Univ Quebec Montreal, Fac IT, 201 Ave President Kennedy,Local PK 4150, Montreal, PQ H2X 3Y7, Canada.
   [Menard, Lucie] Univ Quebec Montreal, Fac Linguist, Pavillon JA De Seve,DS-4425,320 St Catherine Est, Montreal, PQ H2X 1L7, Canada.
   [Dien Dinh] Univ Sci, Knowledge Engn, Ho Chi Minh, Vietnam.
   [Dien Dinh] Univ Sci, Knowledge Engn, Ho Chi Minh City, Vietnam.
C3 University of Quebec; University of Quebec Montreal; University of
   Quebec; University of Quebec Montreal
RP Le, NT (通讯作者)，Univ Quebec Montreal, Fac IT, 201 Ave President Kennedy,Local PK 4150, Montreal, PQ H2X 3Y7, Canada.
EM le.ngoc_tan@courrier.uqam.ca; sadat.fatiha@uqam.ca;
   menard.lucie@uqam.ca; ddien@fit.hcmus.edu.vn
CR Al-Onaizan Yaser, 2016, P 2016 C EMP METH NA, P268, DOI DOI 10.18653/V1/D16-1026
   Al-Rfou R., 2016, ARXIV
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], P 2010 NAM ENT WORKS
   [Anonymous], 2011, P 49 ANN M ASS COMPU
   [Anonymous], 2007, HUMAN LANGUAGE TECHN
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Barros Maria Joao, 2006, 4 JORN TECN HABL, P177
   Bisani M, 2008, SPEECH COMMUN, V50, P434, DOI 10.1016/j.specom.2008.01.002
   Cao Nam X., 2010, P 2010 S INF COMM TE, P59, DOI DOI 10.1145/1852611.1852624
   Chen S. F., 2003, P EUR, P2033
   Deligne S., 1995, 4 EUROPEAN C SPEECH, P2243
   Duan Xiangyu, 2016, P NEWS 2016 6 NAM EN, V2016, P58
   Finch A., 2010, P 2010 NAMED ENTITIE, P48
   Finch Andrew, 2016, P 6 NAM ENT WORKSH, P78
   Gao Qin, 2008, SOFTWARE ENG TESTING, P49, DOI [DOI 10.3115/1622110.1622119, 10.3115/1622110.1622119]
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ngo HG, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3670
   Jean Sebastien<prime>, 2014, ARXIV14122007
   Karimi S, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922654
   Klementiev A, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P817
   Knight K, 1998, COMPUT LINGUIST, V24, P599
   Knight Kevin, 2016, ABS160402201 CORR
   Koehn P., 2017, ARXIV170907809
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Laurent A, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P716
   Le Ngoc Tan, 2017, P 16 INT C MACH TRAN, V1, P337
   Luong M. T., 2014, ARXIV14108206, V27, P82
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Nicolai Garrett, 2015, P 5 NAM ENT WORKSH, P72
   Oh Jong-Hoon, 2006, ACM TRANS ASIAN LANG, V5, P185
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Phe H, 2011, VIETNAMESE DICT
   Tran P, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/9821608
   Rao K, 2015, INT CONF ACOUST SPEE, P4225, DOI 10.1109/ICASSP.2015.7178767
   Rosca M., 2016, ARXIV161009565
   Sajjad H, 2017, COMPUT LINGUIST, V43, P349, DOI 10.1162/COLI_a_00286
   Shao Yan, 2016, P 6 NAM ENT WORKSH 2, P73
   Snover MG, 2009, MACH TRANSL, V23, P117, DOI 10.1007/s10590-009-9062-9
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Thu Y. K., 2016, P 6 WORKSHOP S SE AS, P11
   Tiedemann J., 2017, ARXIV170805729
   Udupa Raghavendra, 2009, P 12 C EUR CHAPT ASS, P799
   Waxmonsky S., 2012, P 2012 C N AM CHAPT, P367
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Yao KS, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3330
NR 46
TC 8
Z9 8
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB
PY 2019
VL 18
IS 2
AR 13
DI 10.1145/3265752
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KJ8HG
UT WOS:000512296200005
DA 2023-11-10
ER

PT J
AU Kumar, K
AF Kumar, Krishan
TI DEAF-BSL: Deep lEArning Framework for British Sign Language recognition
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE 3D CNN; disability; ASL; hand gestures; finger-spelling; BSL corpus
ID HAND GESTURE RECOGNITION
AB The recent development of disability studies in academic bodies has expedited the promotion of investigation on disability. With computer-aided tools, communication between the impaired person and someone who does not understand sign language could be accessible. A large number of people across the world are using sign language (e.g., British Sign Language (BSL), Asian Sign Language (ASL), Indian Sign Language (ISL), etc.) with hand gestures for communication. In BSL recognition, the involvement of both hands overlapping each other becomes the main challenge. Moreover, BSL comprises ambiguous signs concerning viewpoint. However, existing traditional techniques seem in-stable, less accurate, and inefficient. In this work, the BSL fingerspelling alphabet recognition problem explores using a Deep learning framework to address the above-mentioned concerns. Convolutional Neural Network (CNN) is employed to detect and recognize for classification of 26 alphabets after being trained on the BSL corpus dataset. The proposed work outperforms the existing works with better precision (6%), recall (4%), and F-measure ((5) over tilde%). It reported better results on the BSL corpus dataset and webcam videos. The model achieved better accuracy (98.0%) for a large lexicon of words than previous models (Goh & Holden [6]: 69.5%, Rambhau [9]: 79.2%, and Liwicki et al. [8]: 92.5%). The 3D CNN-based proposal performs robust hand detection, much more accurate sign recognition, more scalability, and less ambiguity in BSL finger-spelling recognition.
C1 [Kumar, Krishan] NIT Uttarakhand, Dept Comp Sci & Engn, Srinagar 246174, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, K (通讯作者)，NIT Uttarakhand, Dept Comp Sci & Engn, Srinagar 246174, Uttarakhand, India.
EM kkberwal@nituk.ac.in
CR [Anonymous], 2008, P 19 BRIT MACHINE VI
   Bowden R, 2004, LECT NOTES COMPUT SC, V3021, P390
   Feng B, 2017, IEEE T HUM-MACH SYST, V47, P511, DOI 10.1109/THMS.2016.2616278
   FERIS R, 2004, COMP VIS PATT REC WO, P155, DOI DOI 10.1109/TSMCA.2004.824852
   GOH P, 2005, THESIS U W AUSTR
   Goh P, 2006, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP.2006.313114
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Isaacs J, 2004, SE SYM SYS THRY, P132
   Jang Y, 2017, IEEE T HUM-MACH SYST, V47, P113, DOI 10.1109/THMS.2016.2611824
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kyle J, 1981, Spec Educ Forward Trends, V8, P19
   Le Cun Yann, 1989, ADV NEURAL INFORM PR, P141
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Liang H, 2014, IEEE T MULTIMEDIA, V16, P1241, DOI 10.1109/TMM.2014.2306177
   Liwicki Stephan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P50, DOI 10.1109/CVPR.2009.5204291
   Lu ZY, 2014, IEEE T HUM-MACH SYST, V44, P293, DOI 10.1109/THMS.2014.2302794
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Rambhau Pingale Prerna, 2013, INT J SCI RES PUBLIC, V3, P10
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Shanableh T, 2007, IEEE T SYST MAN CY B, V37, P641, DOI 10.1109/TSMCB.2006.889630
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang LC, 2014, IEEE T MULTIMEDIA, V16, P751, DOI 10.1109/TMM.2014.2298382
   Woll Bencie, 1987, LANGUAGE COMMUNICATI, P11
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
NR 27
TC 4
Z9 4
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP
PY 2022
VL 21
IS 5
AR 101
DI 10.1145/3513004
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9Z2DN
UT WOS:000950956700017
DA 2023-11-10
ER

PT J
AU Chien, JT
   Ku, YC
AF Chien, Jen-Tzung
   Ku, Yuan-Chu
TI Bayesian Recurrent Neural Network for Language Modeling
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Bayesian learning; Hessian matrix; language model; rapid approximation;
   recurrent neural network
ID FRAMEWORK
AB A language model (LM) is calculated as the probability of a word sequence that provides the solution to word prediction for a variety of information systems. A recurrent neural network (RNN) is powerful to learn the large-span dynamics of a word sequence in the continuous space. However, the training of the RNN-LM is an ill-posed problem because of too many parameters from a large dictionary size and a high-dimensional hidden layer. This paper presents a Bayesian approach to regularize the RNN-LM and apply it for continuous speech recognition. We aim to penalize the too complicated RNN-LM by compensating for the uncertainty of the estimated model parameters, which is represented by a Gaussian prior. The objective function in a Bayesian classification network is formed as the regularized cross-entropy error function. The regularized model is constructed not only by calculating the regularized parameters according to the maximum a posteriori criterion but also by estimating the Gaussian hyperparameter by maximizing the marginal likelihood. A rapid approximation to a Hessian matrix is developed to implement the Bayesian RNN-LM (BRNN-LM) by selecting a small set of salient outer-products. The proposed BRNN-LM achieves a sparser model than the RNN-LM. Experiments on different corpora show the robustness of system performance by applying the rapid BRNN-LM under different conditions.
C1 [Chien, Jen-Tzung; Ku, Yuan-Chu] Natl Chiao Tung Univ, Dept Elect & Comp Engn, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chien, JT (通讯作者)，Natl Chiao Tung Univ, Dept Elect & Comp Engn, Hsinchu 30010, Taiwan.
EM jtchien@nctu.edu.tw
RI Chien, Jen-Tzung/JFB-0451-2023
OI Chien, Jen-Tzung/0000-0003-3466-8941
FU Ministry of Science and Technology, Taiwan [MOST 103-2221-E-009-078-MY3]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, under Contract MOST 103-2221-E-009-078-MY3.
CR [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2009, P HUMAN LANGUAGE TEC
   [Anonymous], 2014, INTERSPEECH 2014 15
   Arisoy E., 2012, P NAACL HLT 2012 WOR, P20
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chien JT, 2006, IEEE T AUDIO SPEECH, V14, P1719, DOI 10.1109/TSA.2005.858551
   Chien JT, 2014, IEEE W SP LANG TECH, P206, DOI 10.1109/SLT.2014.7078575
   Chien JT, 2014, IEEE W SP LANG TECH, P147, DOI 10.1109/SLT.2014.7078565
   Chien JT, 2015, IEEE-ACM T AUDIO SPE, V23, P1259, DOI 10.1109/TASLP.2015.2428632
   Chien JT, 2015, IEEE-ACM T AUDIO SPE, V23, P909, DOI 10.1109/TASLP.2015.2412466
   Chien JT, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P34, DOI 10.1109/ISCSLP.2014.6936640
   Chien JT, 2011, IEEE T AUDIO SPEECH, V19, P482, DOI 10.1109/TASL.2010.2050717
   Emami A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P245
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043
   Graves A, 2012, STUD COMPUT INTELL, V385, P5
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI [10.1162/neco.1992.4.3.415, 10.1162/neco.1992.4.3.448]
   Masataki H, 1997, INT CONF ACOUST SPEE, P783, DOI 10.1109/ICASSP.1997.596042
   Mikolov T., 2011, P 2011 WORKSHOP AUTO, P196
   Mikolov T, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P612
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Nasrabadi Nasser M, 2007, J ELECT IMAG, V16
   Neal RM, 1995, THESIS U TORONTO TOR
   Pitman J, 1997, ANN PROBAB, V25, P855
   Povey D., 2011, IEEE 2011 WORKSHOP A
   Renals S., 1993, P 3 EUR C SPEECH COM, P1719
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saon G, 2000, INT CONF ACOUST SPEE, P1129
   Saon G, 2012, IEEE SIGNAL PROC MAG, V29, P18, DOI 10.1109/MSP.2012.2197156
   Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003
   Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985
   Watanabe S., 2015, BAYESIAN SPEECH LANG
NR 41
TC 83
Z9 84
U1 2
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD FEB
PY 2016
VL 27
IS 2
SI SI
BP 361
EP 374
DI 10.1109/TNNLS.2015.2499302
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4DH
UT WOS:000372020500014
PM 26625430
DA 2023-11-10
ER

PT J
AU Terai, A
   Nakagawa, M
AF Terai, Asuka
   Nakagawa, Masanori
TI A neural network model of metaphor understanding with dynamic
   interaction based on a statistical language analysis: Targeting a
   human-like model
SO INTERNATIONAL JOURNAL OF NEURAL SYSTEMS
LA English
DT Article; Proceedings Paper
CT 16th International Conference on Artificial Neural Networks (ICANN 2006)
CY SEP 10-14, 2006
CL Athens, GREECE
SP European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc
DE metaphor understanding; statistical language analysis
AB The purpose of this paper is to construct a model that represents the human process of understanding metaphors, focusing specifically on similes of the form an '' A like B ''. Generally speaking, human beings are able to generate and understand many sorts of metaphors. This study constructs the model based on a probabilistic knowledge structure for concepts which is computed from a statistical analysis of a large-scale corpus. Consequently, this model is able to cover the many kinds of metaphors that human beings can generate. Moreover, the model implements the dynamic process of metaphor understanding by using a neural network with dynamic interactions. Finally, the validity of the model is confirmed by comparing model simulations with the results from a psychological experiment.
C1 Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Meguro Ku, Tokyo 1528552, Japan.
   Tokyo Inst Technol, Grad Sch Decis Sci & Technol, Meguro Ku, Tokyo 1528552, Japan.
C3 Tokyo Institute of Technology; Tokyo Institute of Technology
RP Terai, A (通讯作者)，Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Meguro Ku, 2-12-1 Oookayama, Tokyo 1528552, Japan.
EM asuka@nm.hum.titech.ac.jp; nakagawa@nm.hum.titech.ac.jp
CR [Anonymous], P 31 ANN M ASS COMP, DOI DOI 10.3115/981574.981598
   [Anonymous], 2002, P 6 C NATURAL LANGUA, DOI 10.3115/1118853.1118869
   [Anonymous], 2000, METAPHOR SYMBOL
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Iwayama M., 1991, Journal of Japanese Society for Artificial Intelligence, V6, P674
   Kameya Y., 2005, P S LARG SCAL KNOWL, P65
   KINDAICHI H, 1988, GAKKEN
   KITAHARA Y, 1989, TOKYODO SYUPPAN
   KUSUMI T, 1995, KAZAMA SYOBO
   NAKAGAWA M, 2004, P 8 INT C COGN NEUR, P32
   *NAT I JAP LANG, 2004, DAINIPPON TOSHO
   Nueckles M, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P578
   ORTONY A, 1979, PSYCHOL REV, V86, P161, DOI 10.1037/0033-295X.86.3.161
   TERAI A, 2004, 28 INT C PSYCH ABSTR, P1096
   Terai A, 2006, LECT NOTES COMPUT SC, V4131, P495
   Utsumi A, 2000, COMPUTER TODAY, V96, P34
NR 17
TC 7
Z9 7
U1 2
U2 6
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0129-0657
EI 1793-6462
J9 INT J NEURAL SYST
JI Int. J. Neural Syst.
PD AUG
PY 2007
VL 17
IS 4
BP 265
EP 274
DI 10.1142/S0129065707001123
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 204DU
UT WOS:000249024600006
PM 17696291
DA 2023-11-10
ER

PT J
AU Jaimovitch-López, G
   Ferri, C
   Hernández-Orallo, J
   Martínez-Plumed, F
   Ramírez-Quintana, MJ
AF Jaimovitch-Lopez, Gonzalo
   Ferri, Cesar
   Hernandez-Orallo, Jose
   Martinez-Plumed, Fernando
   Ramirez-Quintana, Maria Jose
TI Can language models automate data wrangling?
SO MACHINE LEARNING
LA English
DT Article
DE Data science automation; Data wrangling; Language models; Machine
   learning pipelines
AB The automation of data science and other data manipulation processes depend on the integration and formatting of 'messy' data. Data wrangling is an umbrella term for these tedious and time-consuming tasks. Tasks such as transforming dates, units or names expressed in different formats have been challenging for machine learning because (1) users expect to solve them with short cues or few examples, and (2) the problems depend heavily on domain knowledge. Interestingly, large language models today (1) can infer from very few examples or even a short clue in natural language, and (2) can integrate vast amounts of domain knowledge. It is then an important research question to analyse whether language models are a promising approach for data wrangling, especially as their capabilities continue growing. In this paper we apply different variants of the language model Generative Pre-trained Transformer (GPT) to five batteries covering a wide range of data wrangling problems. We compare the effect of prompts and few-shot regimes on their results and how they compare with specialised data wrangling systems and other tools. Our major finding is that they appear as a powerful tool for a wide range of data wrangling tasks. We provide some guidelines about how they can be integrated into data processing pipelines, provided the users can take advantage of their flexibility and the diversity of tasks to be addressed. However, reliability is still an important issue to overcome.
C1 [Jaimovitch-Lopez, Gonzalo; Ferri, Cesar; Hernandez-Orallo, Jose; Martinez-Plumed, Fernando; Ramirez-Quintana, Maria Jose] Univ Politecn Valencia, VRAIN, Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Martínez-Plumed, F (通讯作者)，Univ Politecn Valencia, VRAIN, Valencia, Spain.
EM gonjailo@dsic.upv.es; cferri@dsic.upv.es; jorallo@dsic.upv.es;
   fmartinez@dsic.upv.es; mramirez@dsic.upv.es
RI Hernandez-Orallo, Jose/H-9166-2015; Martinez-Plumed,
   Fernando/I-4076-2015
OI Hernandez-Orallo, Jose/0000-0001-9746-7632; Martinez-Plumed,
   Fernando/0000-0003-2902-6477
FU  [ADS2021]
FX AcknowledgementsWe thank Lidia Contreras for her help with the Data
   Wrangling Dataset Repository. We thank the anonymous reviewers from
   ECMLPKDD Workshop on Automating Data Science (ADS2021) and the anonymous
   reviewers of this special issue for their comments.
CR [Anonymous], 2005, COMPUT SCI INF SYST, DOI DOI 10.2298/CSIS0501103H
   Ashok P, 2016, DEFENCE SCI J, V66, P113
   Bellmann P, 2020, IEEE ACCESS, V8, P164380, DOI 10.1109/ACCESS.2020.3021596
   Ben-Gal I, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P131, DOI 10.1007/0-387-25465-X_7
   Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bhupatiraju S., 2017, ARXIV
   BIG-bench collaboration, 2022, ARXIV
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chen YX, 2009, IEEE T PATTERN ANAL, V31, P288, DOI 10.1109/TPAMI.2008.72
   Contreras-Ochando L, 2020, COMM COM INF SC, V1167, P17, DOI 10.1007/978-3-030-43823-4_2
   Contreras-Ochando L, 2020, LECT NOTES ARTIF INT, V11908, P735, DOI 10.1007/978-3-030-46133-1_44
   Cropper A, 2016, LECT NOTES ARTIF INT, V9575, P46, DOI 10.1007/978-3-319-40566-7_4
   Das K., 2008, PROCEEDING 14 ACM SI, P169
   Das K, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P220
   De Bie T, 2022, COMMUN ACM, V65, P76, DOI 10.1145/3495256
   Devlin J., 2018, ARXIV, V1, P4171
   Dua D, 2017, UCI MACHINE LEARNING
   Ellis K, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1638
   Fernando MP, 2021, INT J INTELL SYST, V36, P3217, DOI 10.1002/int.22415
   Ferrari Alberto, 2016, INTRO MICROSOFT POWE
   Furche T., 2016, 19 INT C EXTENDING D, VVolume 16, P473
   Gao T., 2020, ARXIV
   Garcia S., 2016, BIG DATA ANAL, V1, P9, DOI [10.1186/s41044-016-0014-0, DOI 10.1186/S41044-016-0014-0]
   Gulwani S, 2015, COMMUN ACM, V58, P90, DOI 10.1145/2736282
   Gulwani S, 2011, POPL 11: PROCEEDINGS OF THE 38TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P317, DOI 10.1145/1926385.1926423
   Ham K., 2013, J MED LIB ASS JMLA, V101, P233, DOI [10.3163/1536-5050.101.3.020, DOI 10.3163/1536-5050.101.3.020]
   Hendrycks D., 2021, ICLR
   Hendrycks D., 2021, ARXIV
   Hulsebos M, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1500, DOI 10.1145/3292500.3330993
   Izacard G, 2020, ARXIV
   Jaimovitch-Lopez G., 2021, ECMLPKDD WORKSHOP AU
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Lazarevic A., 2005, P 11 ACM SIGKDD INT, P157, DOI DOI 10.1145/1081870.1081891
   Lu Yao, 2021, ARXIV
   Lu Yiping, 2019, ARXIV
   Nazabal A., 2020, ARXIV
   Noto K, 2012, DATA MIN KNOWL DISC, V25, P109, DOI 10.1007/s10618-011-0234-x
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petrova-Antonova D., 2020, QUALITY INFORM COMMU, P32
   Porwal U., 2017, ARXIV
   Puri Raul, 2019, ARXIV
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381
   Reed S., 2022, ARXIV
   RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581
   Schick Timo, 2020, ARXIV
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shi Y, 2016, AAAI CONF ARTIF INTE, P2030
   Singh R, 2016, ACM SIGPLAN NOTICES, V51, P343, DOI 10.1145/2914770.2837668
   Singh R, 2015, LECT NOTES COMPUT SC, V9206, P398, DOI 10.1007/978-3-319-21690-4_23
   Sleeper R., 2021, TABLEAU DESKTOP POCK
   Smith S., 2022, ARXIV
   Tamkin A., 2021, ARXIV
   Terrizzano Ignacio, 2015, 7 BIENN C INN DAT SY
   Trifacta, 2022, TRIFACTA WRANGLER
   Vaswani A., 2017, ARXIV, V30, P5998
   Wu B., 2012, INFORM INTEGRATION W, P8
   Xu SL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P422
   Zeng W, 2021, ARXIV
   Zoph B., 2022, ARXIV
NR 62
TC 1
Z9 1
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD JUN
PY 2023
VL 112
IS 6
BP 2053
EP 2082
DI 10.1007/s10994-022-06259-9
EA DEC 2022
PG 30
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I6KH7
UT WOS:000911298300001
OA hybrid, Green Published
DA 2023-11-10
ER

PT J
AU Munir, K
   Zhao, H
   Li, ZC
AF Munir, Kashif
   Zhao, Hai
   Li, Zuchao
TI Semi-Supervised Semantic Role Labeling with Bidirectional Language
   Models
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Semantic role labeling; semantic parsing; syntax; language models;
   dependency; contextualized representations; path embedding;
   unsupervised; CoNLL-2008; CoNLL-2009; semi-supervised
ID NEURAL-NETWORKS
AB The recent success of neural networks in NLP applications has provided a strong impetus to develop supervised models for semantic role labeling (SRL) that forego the requirement for extensive feature engineering. Recent state-of-the-art approaches require high-quality annotated datasets that are costly to obtain and almost unavailable for low-resource languages. We present a semi-supervised approach that utilizes both labeled and unlabeled data to provide performance improvement over a mere supervised SRL model. We show that our proposed semi-supervised SRL model provides larger improvement over a supervised model in the scenario where labeled training data size is small. Our SRL system leverages unlabeled data under the language modeling paradigm. We demonstrate that the incorporation of a self pretrained bidirectional language model (S-PrLM) into a SRL system can help in SRL performance improvement by learning composition functions from the unlabeled data. Previous researches have concluded that syntax information is very useful for high-performing SRL systems, so we incorporate syntax information by employing an unsupervised approach to leverage dependency path information to connect argument candidates in vector space, which helps in distinguishing arguments with similar contexts but different syntactic functions. The basic idea is to connect predicate (w(p)) with argument candidate (w(a)) with the dependency path (r) between them in the embedding space. Experiments on the CoNLL-2008 and CoNLL-2009 datasets confirm that our full SRL model outperforms previous best models in terms of F-1 score.
C1 [Munir, Kashif; Zhao, Hai; Li, Zuchao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
   [Munir, Kashif; Zhao, Hai; Li, Zuchao] Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interac, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
   [Munir, Kashif; Zhao, Hai; Li, Zuchao] Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai
   Jiao Tong University
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.; Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Key Lab Shanghai Educ Commiss Intelligent Interac, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.; Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, AI Inst, Dongchuan Rd 800, Shanghai 201101, Peoples R China.
EM kashifmunir92@sjtu.edu.cn; zhaohai@cs.sjtu.edu.cn; charlee@sjtu.edu.cn
OI Li, Zuchao/0000-0003-0436-8446; zhao, hai/0000-0001-7290-0487
FU Key Projects of National Natural Science Foundation of China [U1836222,
   61733011]
FX This article was partially supported by Key Projects of National Natural
   Science Foundation of China (U1836222 and 61733011).
CR Abualigah L. M. Q., 2019, FEATURE SELECTION EN
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   [Anonymous], 2010, P 23 INT C COMPUTATI
   [Anonymous], 2015, P 2015 C EMPIRICAL M
   [Anonymous], 2005, P 43 ANN M ASS COMPU, DOI DOI 10.3115/1219840.1219912
   [Anonymous], 2017, P 21 C COMP NAT LANG, DOI DOI 10.18653/V1/K17-1041
   [Anonymous], 2015, ASS COMPUTATIONAL LI
   Antiqueira L, 2009, INFORM SCIENCES, V179, P584, DOI 10.1016/j.ins.2008.10.032
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Berant J., 2013, P 2013 C EMPIRICAL M
   Bjorkelund A., 2009, P 13 C COMP NAT LANG, P43
   Bordes Antoine, 2011, AAAI, V25
   Cai D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P409
   Cai Jiaxun, 2018, P 27 INT C COMP LING, P2753
   Cai R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1018
   Chelba C, 2014, Arxiv, DOI arXiv:1312.3005
   Chen CT, 2019, INFORM SCIENCES, V502, P268, DOI 10.1016/j.ins.2019.06.050
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI DOI 10.1162/TACL_A_00104
   Chung-HsienWu Ze-Jing, 2006, ACM T ASIAN LANGUAGE, V5, P165, DOI DOI 10.1145/1165255.1165259
   Clark K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1914
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Devlin J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1370
   Dozat T, 2017, Arxiv, DOI arXiv:1611.01734
   Frinken V, 2012, LECT NOTES COMPUT SC, V7626, P611, DOI 10.1007/978-3-642-34166-3_67
   Fürstenau H, 2012, COMPUT LINGUIST, V38, P135
   Geng ZQ, 2020, INFORM SCIENCES, V509, P183, DOI 10.1016/j.ins.2019.09.006
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hajic J., 2009, P 13 C COMP NAT LANG, P1, DOI DOI 10.3115/1596409.1596411
   He LH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P473, DOI 10.18653/v1/P17-1044
   He SX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2061
   Johansson R., 2008, P 12 C COMPUTATIONAL, P183
   Jozefowicz R, 2016, Arxiv, DOI arXiv:1602.02410
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Koehn P., 2009, STAT MACHINE TRANSLA, DOI [10.1017/CBO9780511815829, DOI 10.1017/CBO9780511815829]
   Kombrink S, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2888
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Lang Joel, P 2011 C EMP METH NA, P1320
   Lang Joel, 2011, P 49 ANN M ASS COMPU, P1117
   Lei Tao, 2015, P 2015 C N AM CHAPTE, P1150
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Li Junhui, 2009, P 2009 C EMPIRICAL M, P1280
   Li Z., 2018, P 27 INT C COMP LING, P3203
   Li ZC, 2019, AAAI CONF ARTIF INTE, P6730
   Liu WY, 2010, INFORM SCIENCES, V180, P4031, DOI 10.1016/j.ins.2010.06.021
   Luan Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P118
   Marcheggiani D., 2017, ARXIV170304826, DOI DOI 10.18653/V1/D17-1159
   Mehta SV, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4958
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mirowski P, 2015, Arxiv, DOI arXiv:1507.01193
   Munir K, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3461613
   Munir K, 2021, IEEE-ACM T AUDIO SPE, V29, P782, DOI 10.1109/TASLP.2020.3048665
   Nair V., 2010, P 27 INT C MACHINE L
   Oh HJ, 2007, INFORM SCIENCES, V177, P3696, DOI 10.1016/j.ins.2007.02.038
   Peris A, 2015, PROCES LENG NAT, P109
   Peters ME, 2017, SEMISUPERVISED SEQUE
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   Qian Feng, 2017, P 2 WORKSHOP STRUCTU, P27
   Qin L., 2016, P 26 INT C COMPUTATI, P1914
   Do QTN, 2015, IEEE-ACM T AUDIO SPE, V23, P1812, DOI 10.1109/TASLP.2015.2449072
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Roth M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1192
   RuiWang Hai Zhao, 2016, P 26 INT C COMPUTATI, P3135
   Shi C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2245
   Shi P, 2019, Arxiv, DOI [arXiv:1904.05255, DOI 10.48550/ARXIV.1904.05255]
   Sogaard A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P231
   Surdeanu M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P8
   Surdeanu M., 2008, P 12 C COMP NAT LANG, P159, DOI DOI 10.3115/1596324.1596352
   Titov Ivan, 2012, P 24 INT C COMPUTATI, P2635
   Yan S, 2014, IEEE-ACM T AUDIO SPE, V22, P2048, DOI 10.1109/TASLP.2014.2360461
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yang ZL, 2017, Arxiv, DOI arXiv:1703.06345
   Yin YC, 2016, Arxiv, DOI arXiv:1605.07843
   Zhang YB, 2019, INFORM SCIENCES, V477, P55, DOI 10.1016/j.ins.2018.10.030
   Zhang ZS, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1382
   Zhang Zhuosheng, 2018, P 27 INT C COMPUTATI, P1802
   Zhao H, 2013, J ARTIF INTELL RES, V46, P203, DOI 10.1613/jair.3717
   Zhao Hai, 2009, P 13 C COMP NAT LANG, P61
   Zhao Hai, 2009, P 2009 C EMPIRICAL M, P30
   Zhao Hongzhong, 2009, Proceedings of the 2009 2nd Asian-Pacific Conference on Synthetic Aperture Radar (APSAR 2009), P55, DOI 10.1109/APSAR.2009.5374342
   Zhou J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1127
   Zhou Junru, 2020, FINDINGS ASS COMPUTA, P4438
   Zuchao L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2401
NR 84
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN
PY 2023
VL 22
IS 6
AR 162
DI 10.1145/3587160
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7YR0
UT WOS:001018562700008
DA 2023-11-10
ER

PT J
AU Liu, RB
   Jia, CY
   Wei, JS
   Xu, GX
   Vosoughi, S
AF Liu, Ruibo
   Jia, Chenyan
   Wei, Jason
   Xu, Guangxuan
   Vosoughi, Soroush
TI Quantifying and alleviating political bias in language models
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Bias in language models; Natural language generation; Political bias;
   Measuring bias; Mitigating bias
AB Current large-scale language models can be politically biased as a result of the data they are trained on, potentially causing serious problems when they are deployed in real-world settings. In this paper, we first describe metrics for measuring political bias in GPT-2 generation, and discuss several interesting takeaways: 1) The generation of vanilla GPT-2 model is mostly liberal-leaning, 2) Such political bias depends on the sensitive attributes mentioned in the context, and 3) Priming the generation with a explicit political identifier, the extent of political bias is imbalanced (between liberal and conservative). We then propose a reinforcement learning (RL) framework for mitigating such political biases in generated text: By using rewards from word embeddings or a classifier, our RL framework guides debiased generation without having access to the training data or requiring the model to be retrained. In empirical experiments on three attributes sensitive to political bias (gender, location, and topic), our methods reduced bias according to both our metrics and human evaluation, while maintaining readability and semantic coherence. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Ruibo; Vosoughi, Soroush] Dartmouth Coll, Hanover, NH 03755 USA.
   [Jia, Chenyan] Univ Texas Austin, Austin, TX 78712 USA.
   [Wei, Jason] Protago Labs, Baltimore, MD USA.
   [Xu, Guangxuan] Univ Calif Los Angeles, Los Angeles, CA USA.
C3 Dartmouth College; University of Texas System; University of Texas
   Austin; University of California System; University of California Los
   Angeles
RP Vosoughi, S (通讯作者)，Dartmouth Coll, Hanover, NH 03755 USA.
EM ruibo.liu.gr@dartmouth.edu; Soroush.Vosoughi@dartmouth.edu
OI Jia, Chenyan/0000-0002-8407-9224; Liu, Ruibo/0000-0002-5163-966X
CR AGARWAL A, 2019, P MACHINE LEARNING R, V97
   [Anonymous], 2013, ICWSM
   Arpan LM, 2003, JOURNALISM MASS COMM, V80, P265, DOI 10.1177/107769900308000203
   Barikeri S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1941
   Bawden R., 2020, FINDINGS ASS COMPUTA, P918
   Berk R., ARXIV170602409ABS
   Blodgett Su Lin, 2020, P 58 ANN M ASS COMPU, DOI [DOI 10.18653/V1/2020.ACL-MAIN.485, 10.18653/v1/2020.aclmain.485, 10.18653/v1]
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Bolukbasi T, 2016, NEURAL INFORM PROCES, P4349, DOI DOI 10.5555/3157382
   Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7
   Brown Tom B., 2020, ADV NEUR IN
   Caton S., ARXIV201004053ABS
   Chen HY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4834
   Chen J., ARXIV201003240ABS
   Chen ZW, 2020, CHIN CONT DECIS CONF, P314, DOI 10.1109/CCDC49329.2020.9164328
   Corbett-Davies S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P797, DOI 10.1145/3097983.3098095
   D'Alessio D, 2007, LEA COMMUN SER, P103
   Dai N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5997
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Danks D, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4691
   Dathathri Sumanth, 2020, 8 INT C LEARN REPR I
   Denny M.J., ASSESSING CONSEQUENC
   DEVKOTA P, 2018, P 2018 C EMP METH NA, P2799, DOI DOI 10.18653/V1/D18-1302
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dinan E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8173
   Donini M, 2018, ADV NEUR IN, V31
   Fan LS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6343
   Feldman L, 2011, POLIT BEHAV, V33, P407, DOI 10.1007/s11109-010-9139-4
   Flanagin AJ, 2000, JOURNALISM MASS COMM, V77, P515, DOI 10.1177/107769900007700304
   Freitag M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P61
   Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115
   Goel N, 2018, AAAI CONF ARTIF INTE, P3029
   Groeling T, 2013, ANNU REV POLIT SCI, V16, P129, DOI 10.1146/annurev-polisci-040811-115123
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Hooker S, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100241
   Huang C, 2018, P 2018 C N AM CHAPT, V2, P49, DOI [DOI 10.18653/V1/N18-2008, 10.18653/v1/n18-2008]
   Jia C., 2021, INT J COMMUN, V15, P22
   Jiang R., 2019, P MACHINE LEARNING R, V115, P862
   Jiang S, 2020, AAAI CONF ARTIF INTE, V34, P13669
   Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4
   Joseph K., 2017, P 2017 C EMP METH NA, P1115, DOI DOI 10.18653/V1/D17-1116
   Kamiran F, 2012, KNOWL INF SYST, V33, P1, DOI 10.1007/s10115-011-0463-8
   Kamishima Toshihiro, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P35, DOI 10.1007/978-3-642-33486-3_3
   Kusner M.J., 2017, ADV NEURAL INFORM PR, V30, P4066
   Lazarsfeld P.F., THE PEOPLES CHOICE
   Linardatos P, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010018
   Liu H., ARXIV210706641ABS
   Liu R., 2021, P 15 INT AAAI C WEB, P2021
   Liu R., P ACM HUM COMP INT C
   Liu R., 2021, FINDINGS ASS COMPUTA, V2021, P4332
   Liu R., 2021, P 59 ANN M ASS COMP, V2021, P6677
   Liu RB, 2021, AAAI CONF ARTIF INTE, V35, P14857
   Lucy L, 2021, P 3 WORKSH NARR UND, P48
   Marlin Benjamin M., 2007, P 23 C UNC ART INT, P267
   Maudslay RH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5267
   McSherry F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P627
   Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
   Metzger MJ, 2020, COMMUN RES, V47, P3, DOI 10.1177/0093650215613136
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Misra I, 2016, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2016.320
   Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596
   Munos R, 2016, P 30 INT C NEUR INF, P1054
   Munson SA, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1457
   Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953
   Peng B., 2020, FINDINGS ASS COMPUTA, P172
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Plank Barbara, 2014, P 14 C EUROPEAN CHAP, P742
   Rabin J, 2012, LECT NOTES COMPUT SC, V6667, P435, DOI 10.1007/978-3-642-24785-9_37
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Reif E., 2019, NEURIPS
   Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668
   Sap Maarten, 2020, P 58 ANN M ASS COMP, P5477, DOI DOI 10.18653/V1/2020.ACL-MAIN.486
   Schulman J., ARXIV170706347ABS
   Sheng EM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4275
   Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407
   Sheng Emily, 2020, ARXIV200500268, DOI [10.18653/v1/2020.findings-emnlp.291, DOI 10.18653/V1/2020.FINDINGS-EMNLP.291]
   Stanovsky G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1679
   Tufekci Z., 2014, ICWSM, V8, P505
   Vaswani A., 2017, ARXIV, V30, P5998
   Veitch V., ARXIV210600545ABS
   Vidgen B, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1667
   Vig J., 2020, NEURIPS
   Vraga E. K., 2009, NEWSPAPER RES J, V30, P68, DOI DOI 10.1177/073953290903000406
   Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2153
   Wang XY, 2020, P CHIN MARK INT CONF, P897
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483
   Yang J., 2020, AAAI 20
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zemel Rich, 2013, ICML, DOI DOI 10.5555/3042817.3042973
   Zhang BH, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P335, DOI 10.1145/3278721.3278779
   Zhang GH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4134
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Zhao H., 2020, 8 INT C LEARN REPR I
   Zhao H., 2019, ADV NEURAL INFORM PR, P15649
   Zhao Jieyu, 2018, P 2018 C N AM CHAPT, V2, DOI DOI 10.18653/V1/N18-2003
   Zhao T.Z., ARXIV210209690ABS
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   ZHOU XZ, 2020, FINDINGS ASS COMPUTA, P65, DOI DOI 10.5209/CLAC.71996
   Zhu J, 2020, ICLR
NR 99
TC 4
Z9 4
U1 9
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD MAR
PY 2022
VL 304
AR 103654
DI 10.1016/j.artint.2021.103654
EA JAN 2022
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZS0KB
UT WOS:000768161000005
DA 2023-11-10
ER

PT J
AU Huertas-Tato, J
   Martín, A
   Camacho, D
AF Huertas-Tato, Javier
   Martin, Alejandro
   Camacho, David
TI BERTuit: Understanding Spanish language in Twitter with transformers
SO EXPERT SYSTEMS
LA English
DT Article
DE misinformation; online social networks; transformers; Twitter
AB The appearance of complex attention-based language models such as BERT, RoBERTa or GPT-3 has allowed to address highly complex tasks in a plethora of scenarios. However, when applied to specific domains, these models encounter considerable difficulties. This is the case of Social Networks such as Twitter, an ever-changing stream of information written with informal and complex language, where each message requires careful evaluation to be understood even by humans given the important role that context plays. Addressing tasks in this domain through Natural Language Processing involves severe challenges. When powerful state-of-the-art multilingual language models are applied to this scenario, language specific nuances get lost in translation. To face these challenges we present BERTuit, the largest transformer proposed so far for Spanish language, pre-trained on a massive dataset of 230 M Spanish tweets using RoBERTa optimization. Our motivation is to provide a powerful resource to better understand Spanish Twitter and to be used on applications focused on this social network, with special emphasis on solutions devoted to tackle the spreading of misinformation in this platform. BERTuit is evaluated on several tasks and compared against M-BERT, XLM-RoBERTa and XLM-T, very competitive multilingual transformers. The utility of our approach is shown with applications, in this case: an unsupervised methodology to visualize groups of hoaxes; and supervised profiling of authors spreading disinformation.
C1 [Huertas-Tato, Javier; Martin, Alejandro; Camacho, David] Univ Politecn Madrid, Dept Informat, Madrid 28031, Spain.
C3 Universidad Politecnica de Madrid
RP Huertas-Tato, J (通讯作者)，Univ Politecn Madrid, Dept Informat, Madrid 28031, Spain.
EM javier.huertas.tato@upm.es
RI Camacho, David/B-5779-2014
OI Camacho, David/0000-0002-5051-3475
FU Spanish Ministry of Science and Innovation [PID2020-117263GB-100];
   Comunidad Autonoma de Madrid [S2018/TCS-4566]; European Commission
   [2020-EU-IA-0252]; Digital Future Society; MCIN/AEI; European Union
   NextGeneration/PRTR
FX Spanish Ministry of Science and Innovation, Grant/Award Number:
   PID2020-117263GB-100; Comunidad Autonoma de Madrid, Grant/Award Number:
   S2018/TCS-4566; European Commission, Grant/Award Number:
   2020-EU-IA-0252; Digital Future Society;
   MCIN/AEI/10.13039/501100011033/; European Union NextGeneration/PRTR
CR Ahuja R, 2022, ARAB J SCI ENG, V47, P9379, DOI 10.1007/s13369-021-06193-3
   González JA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102262
   Babieno M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042081
   Barbieri F., 2021, XLM T MULTILINGUAL L
   Baviera Puig T., 2019, TWITTER DATASET 2015
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Canete J., 2020, SPANISH PRE TRAINED
   Chanda A. K., 2021, EFFICACY BERT EMBEDD
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2475
   Conneau Alexis, 2019, ARXIV191102116
   de Arruda HFR, 2022, INFORM SCIENCES, V588, P265, DOI 10.1016/j.ins.2021.12.069
   Deb S., 2022, MACHINE LEARNING APP, V7
   Delobelle P., 2020, ROBBERT DUTCH ROBERT
   Devlin J., 2018, ARXIV, V1, P4171
   Dukic D., 2020, 2020 IEEE 7 INT C DA
   Farzindar A., 2015, SYNTH LECT HUM LANG, V8, P1, DOI DOI 10.2200/S00659ED1V01Y201508HLT030
   González JA, 2021, NEUROCOMPUTING, V426, P58, DOI 10.1016/j.neucom.2020.09.078
   Gregory H., 2020, P 2 WORKSH FIG LANG
   Huertas-Garc├a┬a A., 2021, PROFILING HATE SPEEC
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Larson HJ, 2018, NATURE, V562, P309, DOI 10.1038/d41586-018-07034-4
   Lewis M., 2019, BART DENOISING SEQUE
   Lewis P., 2019, MLQA EVALUATING CROS
   Liu PJ, 2018, ARXIV180110198, P1
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   McInnes Leland, 2020, Arxiv, DOI [arXiv:1802.03426, 10.48550/arXiv.1802.03426, 10.21105/joss.00861]
   Mozafari M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237861
   Mozetic I, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194317
   Mozetic I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155036
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Nguyen D. Q., 2020, BERTWEET PRE TRAINED
   PIRES T, 2019, P 57 ANN M ASS COMP
   Polignano M., 2019, 6 IT C COMP LING CLC
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C., 2019, EXPLORING LIMITS TRA
   Rangel F., 2020, PROFILING FAKE NEWS
   Rei L., 2016, XLIME TWITTER CORPUS
   Ruiz I. V. M., 2017, CORPUS TUITS IRONICO
   Sang E. F. T. K., 2002, COLING 02 6 C NAT LA, DOI 10.3115/1118853.1118877
   Sanh Victor, 2019, ARXIV191001108
   Scott J., 2022, ARCH TEAM TWITTER ST
   Singh M, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00737-z
   Son H., 2018, 2018 IEEE INT C DAT
   Straka M., 2021, INT C TEXT SPEECH DI
   Tahir B, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9149154
   Tay Y, 2020, EFFICIENT TRANSFORME
   Vaswani A., 2017, ARXIV, V30, P5998
   Virtanen A., 2019, MULTILINGUAL IS NOT
NR 51
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD NOV
PY 2023
VL 40
IS 9
DI 10.1111/exsy.13404
EA JUL 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U1FX9
UT WOS:001033742500001
DA 2023-11-10
ER

PT J
AU Hsieh, YM
   Bai, MH
   Huang, SL
   Chen, KJ
AF Hsieh, Yu-Ming
   Bai, Ming-Hong
   Huang, Shu-Ling
   Chen, Keh-Jiann
TI Correcting Chinese Spelling Errors with Word Lattice Decoding
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Algorithms; Languages; Experimentation; Performance; Chinese spelling
   error checking; computer-assisted language learning; noisy channel
   model; word lattice; word segmentation; unknown word detection
AB Chinese spell checkers are more difficult to develop because of two language features: 1) there are no word boundaries, and a character may function as a word or a word morpheme; and 2) the Chinese character set contains more than ten thousand characters. The former makes it difficult for a spell checker to detect spelling errors, and the latter makes it difficult for a spell checker to construct error models. We develop a word lattice decoding model for a Chinese spell checker that addresses these difficulties. The model performs word segmentation and error correction simultaneously, thereby solving the word boundary problem. The model corrects nonword errors as well as real-word errors. In order to better estimate the error distribution of large character sets for error models, we also propose a methodology to extract spelling error samples automatically from the Google web 1T corpus. Due to the large quantity of data in the Google web 1T corpus, many spelling error samples can be extracted, better reflecting spelling error distributions in the real world. Finally, in order to improve the spell checker for real applications, we produce n-best suggestions for spelling error corrections. We test our proposed approach with the Bakeoff 2013 CSC Datasets; the results show that the proposed methods with the error model significantly outperform the performance of Chinese spell checkers that do not use error models.
C1 [Hsieh, Yu-Ming] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30013, Taiwan.
   [Bai, Ming-Hong; Huang, Shu-Ling; Chen, Keh-Jiann] Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
C3 National Tsing Hua University; Academia Sinica - Taiwan
RP Hsieh, YM (通讯作者)，Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30013, Taiwan.
EM morris@iis.sinica.edu.tw
RI Hsieh, YuMing/AAR-7142-2021
CR [Anonymous], 2013, P 7 SIGHAN WORKSH CH
   [Anonymous], 1990, P 13 C COMPUTATIONAL, DOI DOI 10.3115/997939.997975
   [Anonymous], 2013, P 7 SIGHANWORKSHOP C
   Chang CT, 1995, P INT COMP SOFTW APP, P278, DOI 10.1109/CMPSAC.1995.524791
   Chen K.J., 1998, INT J COMPUTATIONAL, V3, P27
   Chen K. J., 2002, P 19 INT C COMP LING, P1
   Chen YY, 2009, 2009 INTERNATIONAL FORUM ON COMPUTER SCIENCE-TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P359, DOI 10.1109/IFCSTA.2009.210
   Chen YZ, 2011, INT J CONTIN ENG EDU, V21, P103, DOI 10.1504/IJCEELL.2011.039697
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   Fuji Ren, 2001, 2001 IEEE International Conference on Systems, Man and Cybernetics. e-Systems and e-Man for Cybernetics in Cyberspace (Cat.No.01CH37236), P1693, DOI 10.1109/ICSMC.2001.973529
   Gao J., 2002, ACM T ASIAN LANGUAGE, V1, P3
   Huang CM, 2007, LECT NOTES ARTIF INT, V4617, P463
   Hung Ta-Hung, 2008, P TAIW E LEARN FOR T
   Hung-Yan Gu, 1991, Computer Speech and Language, V5, P363, DOI 10.1016/0885-2308(91)90004-A
   Jia Z, 2013, P 7 SIGHAN WORKSHOP, P88
   Lee LS, 1993, IEEE T SPEECH AUDI P, V1, P158, DOI 10.1109/89.222876
   Lee Lin-Shan, 1993, P IEEE INT C AC SPEE, V2, P503
   Lin Yih-Jeng, 2002, P 7 C ART INT APPL
   Liu C.L., 2008, P ACL 08 HLT SHORT P, P93
   Liu C.L., 2011, ACM T ASIAN LANGUAGE, V10, P1, DOI 10.1145/1967293.1967297
   Liu C.L., 2009, P 47 ANN M ASS COMP, P25
   Liu C-L, 2009, P 7 WORKSH AS LANG R, P84
   MAYS E, 1991, INFORM PROCESS MANAG, V27, P517, DOI 10.1016/0306-4573(91)90066-U
   MOE, 1994, STAND FORM NAT CHAR
   PETERSON JL, 1986, COMMUN ACM, V29, P633, DOI 10.1145/6138.6146
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Unicode Consortium, 2014, UN STAND 7 0
   Wu Jian-Cheng, 2013, INT J COMPUT LINGUIS, V18, P17
   Wu Shih-Hung, 2013, P 7 SIGHAN WORKSH CH, P35
   Yang KC, 1998, INT CONF ACOUST SPEE, P169, DOI 10.1109/ICASSP.1998.674394
   Zhang L, 2000, PROCEEDINGS OF THE 3RD WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-5, P2744, DOI 10.1109/WCICA.2000.862557
NR 32
TC 6
Z9 7
U1 0
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD OCT
PY 2015
VL 14
IS 4
SI SI
AR 18
DI 10.1145/2791389
PG 23
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE0TZ
UT WOS:000370339100005
DA 2023-11-10
ER

PT J
AU Tian, YYS
   Wan, Y
   Lyu, LJ
   Yao, DZ
   Jin, H
   Sun, LC
AF Tian, Yuanyishu
   Wan, Yao
   Lyu, Lingjuan
   Yao, Dezhong
   Jin, Hai
   Sun, Lichao
TI FEDBERT: When Federated Learning Meets Pre-training
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE Federated learning; pre-training; BERT; NLP
AB The fast growth of pre-trained models (PTMs) has brought natural language processing to a new era, which has become a dominant technique for various natural language processing (NLP) applications. Every user can download the weights of PTMs, then fine-tune the weights for a task on the local side. However, the pre-training of a model relies heavily on accessing a large-scale of training data and requires a vast amount of computing resources. These strict requirements make it impossible for any single client to pre-train such a model. To grant clients with limited computing capability to participate in pre-training a large model, we propose a new learning approach, FEDBERT, that takes advantage of the federated learning and split learning approaches, resorting to pre-training BERT in a federated way. FEDBERT can prevent sharing the raw data information and obtain excellent performance. Extensive experiments on seven GLUE tasks demonstrate that FEDBERT can maintain its effectiveness without communicating to the sensitive local data of clients.
C1 [Tian, Yuanyishu; Wan, Yao; Yao, Dezhong; Jin, Hai] Huazhong Univ Sci & Technol, Serv Comp Technol & Syst Lab, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol,Cluster & Grid Comp Lab, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
   [Lyu, Lingjuan] Sony AI, Minato Ku, 1-7-1 Konan, Tokyo, Japan.
   [Sun, Lichao] Lehigh Univ, 113 Res Dr, Bethlehem, PA 18015 USA.
C3 Huazhong University of Science & Technology; Lehigh University
RP Yao, DZ (通讯作者)，Huazhong Univ Sci & Technol, Serv Comp Technol & Syst Lab, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol,Cluster & Grid Comp Lab, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.; Sun, LC (通讯作者)，Lehigh Univ, 113 Res Dr, Bethlehem, PA 18015 USA.
EM yystian@hust.edu.cn; wanyao@hust.edu.cn; Lingjuan.Lv@sony.com;
   dyao@hust.edu.cn; hjin@hust.edu.cn; lis221@lehigh.edu
OI Sun, Lichao/0000-0003-1539-7939; Yao, Dezhong/0000-0003-0336-0522
FU National Natural Science Foundation of China [62102157]; Fundamental
   Research Funds for the Central Universities [HUST:2020kfyXJJS019]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 62072204 and the Fundamental Research Funds for
   the Central Universities under Grant HUST:2020kfyXJJS019. Yao Wan is
   supported in part by National Natural Science Foundation of China under
   Grant No. 62102157.
CR Abedi Ali, 2020, ARXIV
   Abuadbba Sharif, 2020, ASIA CCS '20: Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, P305, DOI 10.1145/3320269.3384740
   Beltagy I., 2019, ARXIV
   Bentivogli Luisa, 2009, P 2 TEXT AN C
   Bonawitz K, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1175, DOI 10.1145/3133956.3133982
   Bonawitz Keith, 2019, P MACH LEARN SYST, V1, P374
   Ceballos I., 2020, ARXIV
   Cer D., 2017, P 11 INT WORKSHOP SE, P1, DOI [DOI 10.18653/V1/S17-2001, 10.1865/3v1/S17-2001]
   Clark Kevin, 2020, P INT C LEARNING REP
   Devlin J., 2018, ARXIV, V1, P4171
   Dolan B., 2005, 3 INT WORKSH PAR IWP, P1
   Gao Y., 2020, ARXIV
   Ge S, 2020, ARXIV
   Geyer R.C., 2017, ARXIV
   Gupta O, 2018, J NETW COMPUT APPL, V116, P1, DOI 10.1016/j.jnca.2018.05.003
   Hardy S., 2017, ARXIV
   He Chaoyang, 2020, ARXIV200713518
   HongyiWang Kartik Sreenivasan, 2020, P C ADV NEURAL INFOR
   Hsu Tzu-Ming Harry, 2020, PROC EUR C COMPUT VI, P76, DOI DOI 10.1007/978-3-030-58607-25
   Jiang D, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1071, DOI 10.1145/3357384.3357909
   Kairouz P, 2021, FOUND TRENDS MACH LE, V14, P1, DOI 10.1561/2200000083
   Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Li X., 2019, ARXIV
   Liu QD, 2021, PROC CVPR IEEE, P1013, DOI 10.1109/CVPR46437.2021.00107
   Liu Y, 2020, AAAI CONF ARTIF INTE, V34, P13172
   Liu Yinhan, 2019, ARXIV190711692
   Lu J., 2019, ARXIV
   Lyu L., 2020, IEEE IJCNN, P1
   Lyu L., 2020, ARXIV
   Lyu Lingjuan, 2020, ABS200302133 CORR
   Matsubara Yoshitomo, 2020, ARXIV
   McMahan H. B., 2018, P 6 INT C LEARNING R
   McMahan H.B., 2016, ARXIV
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, P51, DOI DOI 10.18653/V1/K16-1006
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Peng H, 2021, ARXIV
   Peng H, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P1416, DOI 10.1145/3459637.3482252
   Peng H, 2022, IEEE T COMPUT, V71, P628, DOI 10.1109/TC.2021.3057082
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1
   Seif Mohamed, 2020, ARXIV
   Sennrich R., 2015, ARXIV
   Singh A., 2019, ARXIV
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Song K, 2019, ARXIV
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Sun L., 2021, ARXIV, P3436, DOI 10.18653/v1/2020.coling-main.305
   Sun Y., 2019, ARXIV
   Thapa C., 2020, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Vepakomma P., 2018, ARXIV
   Wang A., 2019, ICLR 19
   Wang Hongyi, 2020, ARXIV200206440
   Wang J., 2021, ARXIV
   Wang Y, 2019, ARXIV
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Xu XH, 2022, IEEE T IND INFORM, V18, P4788, DOI 10.1109/TII.2021.3113708
   Yang D, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.101992
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yao D., 2021, ARXIV
   ZHANG Ke, 2021, P C ADV NEURAL INFOR
NR 69
TC 12
Z9 12
U1 8
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2157-6904
EI 2157-6912
J9 ACM T INTEL SYST TEC
JI ACM Trans. Intell. Syst. Technol.
PD AUG
PY 2022
VL 13
IS 4
AR 66
DI 10.1145/3510033
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4E7QL
UT WOS:000848016400015
DA 2023-11-10
ER

PT J
AU Wu, WH
   Sun, Z
   Song, YX
   Wang, JD
   Ouyang, WL
AF Wu, Wenhao
   Sun, Zhun
   Song, Yuxin
   Wang, Jingdong
   Ouyang, Wanli
TI Transferring Vision-Language Models for Visual Recognition: A Classifier
   Perspective
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article; Early Access
DE Visual recognition; Large vision model; Transfer learning
AB Transferring knowledge from pre-trained deep models for downstream tasks, particularly with limited labeled samples, is a fundamental problem in computer vision research. Recent advances in large-scale, task-agnostic vision-language pre-trained models, which are learned with billions of samples, have shed new light on this problem. In this study, we investigate how to efficiently transfer aligned visual and textual knowledge for downstream visual recognition tasks. We first revisit the role of the linear classifier in the vanilla transfer learning framework, and then propose a new paradigm where the parameters of the classifier are initialized with semantic targets from the textual encoder and remain fixed during optimization. To provide a comparison, we also initialize the classifier with knowledge from various resources. In the empirical study, we demonstrate that our paradigm improves the performance and training speed of transfer learning tasks. With only minor modifications, our approach proves effective across 17 visual datasets that span three different data domains: image, video, and 3D point cloud.
C1 [Wu, Wenhao] Univ Sydney, Darlington, Australia.
   [Sun, Zhun; Song, Yuxin; Wang, Jingdong] Baidu Inc, Dept Comp Vis Technol, Beijing, Peoples R China.
   [Ouyang, Wanli] Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China.
C3 University of Sydney; Baidu
RP Wu, WH (通讯作者)，Univ Sydney, Darlington, Australia.
EM wenhao.wu@sydney.edu.au; sunzhun@baidu.com; songyuxin02@baidu.com;
   wangjingdong@baidu.com; ouyangwanli@pjlab.org.cn
FU Australian Research Council [DP200103223]; Australian Medical Research
   Future Fund [MRFAI000085]; CRC-P Smart Material Recovery Facility (SMRF)
   - Curby Soft Plastics; CRC-P ARIA - Bionic Visual-Spatial Prosthesis for
   the Blind; Australian Research Council [DP200103223] Funding Source:
   Australian Research Council
FX Wanli Ouyang was supported by the Australian Research Council Grant
   DP200103223, Australian Medical Research Future Fund MRFAI000085, CRC-P
   Smart Material Recovery Facility (SMRF) - Curby Soft Plastics, and CRC-P
   ARIA - Bionic Visual-Spatial Prosthesis for the Blind.
CR Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Brattoli B, 2020, PROC CVPR IEEE, P4612, DOI 10.1109/CVPR42600.2020.00467
   Byeon Minwoo, 2022, COYO 700M IMAGE TEXT
   Carreira J., 2018, ARXIV
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen Shizhe, 2021, P IEEECVF INT C COMP, P13638
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao JY, 2019, AAAI CONF ARTIF INTE, P8303
   Gao P., 2021, ARXIV, DOI DOI 10.1007/S11263-023-01891-X
   Gao RH, 2020, PROC CVPR IEEE, P10454, DOI 10.1109/CVPR42600.2020.01047
   Ghadiyaram D, 2019, PROC CVPR IEEE, P12038, DOI 10.1109/CVPR.2019.01232
   Goyal Ankit, 2021, INT C MACHINE LEARNI, P3809, DOI DOI 10.48550/ARXIV.2106.05304
   Han Kai, 2021, ADV NEURAL INFORM PR, V34, P15908
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Ioffe Sergey, 2015, ARXIV 1502 03167, P448
   Jia C, 2021, PR MACH LEARN RES, V139
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Ju C, 2022, LECT NOTES COMPUT SC, V13695, P105, DOI 10.1007/978-3-031-19833-5_7
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kay W, 2017, Arxiv, DOI [arXiv:1705.06950, DOI 10.48550/ARXIV.1705.06950]
   Kim TS, 2021, AAAI CONF ARTIF INTE, V35, P1817
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky Alex, 2012, NEURIPS, V25
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li Boyi, 2022, ARXIV
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li JN, 2022, Arxiv, DOI arXiv:2201.12086
   Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y
   Lin C-C, 2022, P IEEECVF C COMPUTER, P19978
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Lin ZY, 2022, LECT NOTES COMPUT SC, V13695, P388, DOI 10.1007/978-3-031-19833-5_23
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Lüddecke T, 2022, PROC CVPR IEEE, P7076, DOI 10.1109/CVPR52688.2022.00695
   Luo HS, 2021, Arxiv, DOI arXiv:2104.08860
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Mishra A, 2018, IEEE WINT CONF APPL, P372, DOI 10.1109/WACV.2018.00047
   Mokady Ron, 2021, ARXIV
   Ni B, 2022, LECT NOTES COMPUT SC, V13664, P1, DOI 10.1007/978-3-031-19772-7_1
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pan JT, 2022, Arxiv, DOI [arXiv:2206.13559, 10.48550/arXiv.2206.13559]
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Radford Alec, 2021, P INT C MACH LEARN I, P8748, DOI DOI 10.48550/ARXIV.2103.00020
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Rao YM, 2022, PROC CVPR IEEE, P18061, DOI 10.1109/CVPR52688.2022.01755
   Ribani Ricardo, 2019, 2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T). Proceedings, P47, DOI 10.1109/SIBGRAPI-T.2019.00010
   Ryoo MSS, 2022, Arxiv, DOI arXiv:2106.11297
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Schuhmann Christoph, 2022, ARXIV
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Sun Q, 2023, Arxiv, DOI arXiv:2303.15389
   Sun Z., 2022, ARXIV
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   van den Oord Aaron, 2018, ARXIV180703748
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang Mengmeng, 2021, ARXIV
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wenhao Wu, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P1903, DOI 10.1145/3474085.3475344
   Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037
   Wu WH, 2021, AAAI CONF ARTIF INTE, V35, P2943
   Wu WH, 2019, IEEE I CONF COMP VIS, P6231, DOI 10.1109/ICCV.2019.00632
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xia BY, 2022, LECT NOTES COMPUT SC, V13694, P705, DOI 10.1007/978-3-031-19830-4_40
   Xia BY, 2022, LECT NOTES COMPUT SC, V13694, P741, DOI 10.1007/978-3-031-19830-4_42
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yan S., 2022, CVPR, P3333
   Yang J., 2022, P IEEECVF C COMPUTER, P19163
   Yu JH, 2022, Arxiv, DOI [arXiv:2205.01917, DOI 10.48550/ARXIV.2205.01917]
   Yuan L., 2021, ARXIV
   Zhai XH, 2022, Arxiv, DOI arXiv:2106.04560
   Zhang B., 2021, ARXIV
   Zhang RR, 2021, Arxiv, DOI arXiv:2111.03930
   Zhang RR, 2022, PROC CVPR IEEE, P8542, DOI 10.1109/CVPR52688.2022.00836
   Zhao S, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P970, DOI 10.1145/3477495.3531950
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou KY, 2022, Arxiv, DOI arXiv:2109.01134
   Zhou Kaiyang, 2022, P IEEE CVF C COMP VI, P16816
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 98
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD 2023 SEP 7
PY 2023
DI 10.1007/s11263-023-01876
EA SEP 2023
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q9PG4
UT WOS:001060757900002
DA 2023-11-10
ER

PT J
AU Trillo, JR
   Herrera-Viedma, E
   Morente-Molinera, JA
   Cabrerizo, FJ
AF Trillo, Jose Ramon
   Herrera-Viedma, Enrique
   Morente-Molinera, Juan Antonio
   Cabrerizo, Francisco Javier
TI A large scale group decision making system based on sentiment analysis
   cluster
SO INFORMATION FUSION
LA English
DT Article
DE Large scale group decision making; Sentiment analysis; Natural language
   processing; Classification
ID CONSENSUS MODEL; PREFERENCE RELATIONS; SELF-CONFIDENCE; INFORMATION;
   CONSISTENCY
AB Nowadays, group decision making is an everyday occurrence in different scenarios, such as marketing or social networks. These social networks have facilitated communication between experts because they do not need to meet in person. However, communication between experts through the internet generates three problems: the management of large amounts of information, the fact that experts often provide their information using natural language, and the lack of analysis of experts' intentions. In this paper, we propose a novel large scale group decision making method to manage the information generated by a large number of experts, using the natural language processing approach, specifically sentiment analysis. This approach makes it possible to detect the degree of positivity and aggressiveness of each expert and thus proceed to a classification. Once the behaviours are detected, the experts are grouped according to them and, for each group, a weight and a unique preference relation is obtained. In addition, we propose an optimised consensus analysis process, in which it is not necessary to compare all experts with each other, but only groups of experts.
C1 [Trillo, Jose Ramon; Herrera-Viedma, Enrique; Morente-Molinera, Juan Antonio; Cabrerizo, Francisco Javier] Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Dept Comp Sci & Artificial Intelligence, DaSCI, Granada 18071, Spain.
C3 University of Granada
RP Trillo, JR (通讯作者)，Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Dept Comp Sci & Artificial Intelligence, DaSCI, Granada 18071, Spain.
EM jrtrillo@ugr.es; viedma@decsai.ugr.es; jamoren@decsai.ugr.es;
   cabrerizo@decsai.ugr.es
RI ; Cabrerizo, Francisco Javier/A-3841-2015
OI Trillo Vilchez, Jose Ramon/0000-0002-7998-5476; Cabrerizo, Francisco
   Javier/0000-0001-7012-8649
FU FEDER/Junta de Andalucia-Consejeriade Transformacion Economica,
   Industria, Conocimiento y Universidades [B-TIC-590-UGR20]; Andalusian
   government [P20_00673]; MCIN / AEI [PID2019-103880RB-I00]
FX This work was supported by FEDER/Junta de Andalucia-Consejeriade
   Transformacion Economica, Industria, Conocimiento y Universi-dades /
   Proyecto B-TIC-590-UGR20, by the Andalusian government through project
   P20_00673, and by the project PID2019-103880RB-I00funded by MCIN / AEI /
   10.13039/501100011033
CR Akram M, 2020, COMPUT APPL MATH, V39, DOI 10.1007/s40314-020-01251-2
   Alshalabi H, 2022, J KING SAUD UNIV-COM, V34, P6635, DOI 10.1016/j.jksuci.2021.08.017
   Blanco-Mesa F, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105488
   Cabrerizo FJ, 2017, SOFT COMPUT, V21, P3037, DOI 10.1007/s00500-015-1989-6
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Castillo-Zúñiga I, 2020, INT J SEMANT WEB INF, V16, P69, DOI 10.4018/IJSWIS.2020010104
   Cavaliere D, 2020, IEEE T FUZZY SYST, V28, P1984, DOI 10.1109/TFUZZ.2019.2928787
   Chao XR, 2021, INFORM SCIENCES, V575, P499, DOI 10.1016/j.ins.2021.06.047
   Chao XR, 2021, EUR J OPER RES, V288, P271, DOI 10.1016/j.ejor.2020.05.047
   Chao XR, 2018, EUR J OPER RES, V265, P239, DOI 10.1016/j.ejor.2017.07.030
   Chavent M, 2021, COMMUN STAT-SIMUL C, V50, P426, DOI 10.1080/03610918.2018.1563145
   Chen Xiao-hong, 2006, Systems Engineering and Electronics, V28, P1695
   Dahl FA, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01451-8
   Dror R., 2020, SYNTHESIS LECT HUM L, V13, P1
   Du ZJ, 2020, INFORM FUSION, V63, P13, DOI 10.1016/j.inffus.2020.05.004
   Escadas M, 2019, BUS ETHICS, V28, P529, DOI 10.1111/beer.12237
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Gao PQ, 2020, COMPUT IND ENG, V150, DOI 10.1016/j.cie.2020.106842
   Georgiadou E, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.102048
   Herrera F, 1996, FUZZY SET SYST, V79, P175, DOI 10.1016/0165-0114(95)00162-X
   Herrera-Viedma E, 2014, INFORM FUSION, V17, P4, DOI 10.1016/j.inffus.2013.04.002
   Cabrerizo FJ, 2015, J INTELL FUZZY SYST, V29, P1109, DOI 10.3233/IFS-151719
   Cabrerizo FJ, 2014, FUZZY SET SYST, V255, P115, DOI 10.1016/j.fss.2014.03.016
   Cabrerizo FJ, 2013, EUR J OPER RES, V230, P624, DOI 10.1016/j.ejor.2013.04.046
   Li CC, 2019, INFORM FUSION, V52, P143, DOI 10.1016/j.inffus.2018.12.004
   Li CC, 2019, IEEE T FUZZY SYST, V27, P221, DOI 10.1109/TFUZZ.2018.2857720
   Li Q., 2022, COMPLEX INTELL SYST
   Liu BS, 2019, EUR J OPER RES, V275, P737, DOI 10.1016/j.ejor.2018.11.075
   Liu X, 2019, INFORM FUSION, V52, P245, DOI 10.1016/j.inffus.2019.03.001
   Liu X, 2019, IEEE T FUZZY SYST, V27, P159, DOI 10.1109/TFUZZ.2018.2876655
   López M, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107455
   Lu YL, 2022, APPL SOFT COMPUT, V126, DOI 10.1016/j.asoc.2022.109249
   Mendi AF, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124419
   Morente-Molinera JA, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105657
   Morente-Molinera JA, 2020, INFORM FUSION, V53, P240, DOI 10.1016/j.inffus.2019.06.028
   Morente-Molinera JA, 2019, EXPERT SYST APPL, V127, P187, DOI 10.1016/j.eswa.2019.03.023
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Pérez IJ, 2013, SOFT COMPUT, V17, P1617, DOI 10.1007/s00500-012-0975-5
   Trillo JR, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10122035
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Razno M., 2019, COMPUT LINGUIST, V2, P71
   Riaz S, 2019, CLUSTER COMPUT, V22, pS7149, DOI 10.1007/s10586-017-1077-z
   Roubens M, 1997, FUZZY SET SYST, V90, P199, DOI 10.1016/S0165-0114(97)00087-0
   Sambrano D, 2021, LEGAL CRIMINOL PSYCH, V26, P62, DOI 10.1111/lcrp.12181
   Song YM, 2019, J OPER RES SOC, V70, P827, DOI 10.1080/01605682.2018.1458017
   Sun Q, 2022, IEEE T FUZZY SYST, V30, P1287, DOI 10.1109/TFUZZ.2021.3057705
   Tang M, 2020, EUR J OPER RES, V282, P957, DOI 10.1016/j.ejor.2019.10.006
   Wan BT, 2022, GRANULAR COMPUT, V7, P489, DOI 10.1007/s41066-021-00280-4
   Wu ZB, 2018, INFORM FUSION, V41, P217, DOI 10.1016/j.inffus.2017.09.011
   Xu WJ, 2021, GROUP DECIS NEGOT, V30, P1239, DOI 10.1007/s10726-020-09653-7
   Xu XH, 2019, INFORM SCIENCES, V477, P410, DOI 10.1016/j.ins.2018.10.058
   Xu XH, 2019, KNOWL-BASED SYST, V163, P495, DOI 10.1016/j.knosys.2018.09.010
   Xu YJ, 2021, IEEE T SYST MAN CY-S, V51, P3498, DOI 10.1109/TSMC.2019.2931536
   Xu YJ, 2018, COMPUT IND ENG, V116, P113, DOI 10.1016/j.cie.2017.11.025
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Zampieri M, 2019, Arxiv, DOI arXiv:1903.08983
   Zha QB, 2019, IEEE T COMPUT SOC SY, V6, P994, DOI 10.1109/TCSS.2019.2938258
   Zhang Z, 2021, J OPER RES SOC, V72, P1914, DOI 10.1080/01605682.2020.1748529
   Zhang Z, 2020, IEEE T FUZZY SYST, V28, P2875, DOI 10.1109/TFUZZ.2019.2949758
   Zheng YH, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114355
   Zhong XY, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105973
NR 62
TC 6
Z9 6
U1 20
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD MAR
PY 2023
VL 91
BP 633
EP 643
DI 10.1016/j.inffus.2022.11.009
EA NOV 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Q9EF
UT WOS:000891912000007
DA 2023-11-10
ER

PT J
AU Ghayoomi, M
   Mousavian, M
AF Ghayoomi, Masood
   Mousavian, Maryam
TI Deep transfer learning for COVID-19 fake news detection in Persian
SO EXPERT SYSTEMS
LA English
DT Article
DE contextualized text representation; COVID-19; deep neural network; fake
   news detection; transfer learning
ID MISINFORMATION
AB The spread of fake news on social media has increased dramatically in recent years. Hence, fake news detection systems have received researchers' attention globally. During the COVID-19 outbreak in 2019 and the worldwide epidemic, the importance of this issue becomes more apparent. Due to the importance of the issue, a large number of researchers have begun to collect English datasets and to study COVID-19 fake news detection. However, there are a large number of low-resource languages, including Persian, that cannot develop accurate tools for automatic COVID-19 fake news detection due to the lack of annotated data for the task. In this article, we aim to develop a corpus for Persian in the domain of COVID-19 where the fake news is annotated and to provide a model for detecting Persian COVID-19 fake news. With the impressive advancement of multilingual pre-trained language models, the idea of cross-lingual transfer learning can be proposed to improve the generalization of models trained with low-resource language datasets. Accordingly, we use the state-of-the-art deep cross-lingual contextualized language model, XLM-RoBERTa, and the parallel convolutional neural networks to detect Persian COVID-19 fake news. Moreover, we use the idea of knowledge transferring across-domains to improve the results by using both the English COVID-19 dataset and the general domain Persian fake news dataset. The combination of both cross-lingual and cross-domain transfer learning has outperformed the models and it has beaten the baseline by 2.39% significantly.
C1 [Ghayoomi, Masood] Inst Humanities & Cultural Studies, Fac Linguist, Tehran, Iran.
   [Mousavian, Maryam] Amirkabir Univ Technol, Comp Engn Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Ghayoomi, M (通讯作者)，Inst Humanities & Cultural Studies, Fac Linguist, Tehran, Iran.
EM m.ghayoomi@ihcs.ac.ir
OI Ghayoomi, Masood/0000-0001-6685-1332
FU Iran National Science Foundation [99009204]
FX Iran National Science Foundation, Grant/Award Number: 99009204
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Al-Rakhami MS, 2020, IEEE ACCESS, V8, P155961, DOI 10.1109/ACCESS.2020.3019600
   Al-Zaman, 2021, JOURNALISM MEDIA, V2, P100, DOI DOI 10.3390/JOURNALMEDIA2010007
   Allport G. W., 1947, PSYCHOL RUMOR
   Barua Z, 2020, PROG DISASTER SCI, V8, DOI 10.1016/j.pdisas.2020.100119
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Conneau A, 2019, ADV NEUR IN, V32
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Cui Limeng, 2020, ARXIV200600885
   Devlin J., 2018, ARXIV, V1, P4171
   Ghayoomi, 2019, LANG LINGUIST-TAIWAN, V14, P21
   Goldani MH, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.106991
   Goldani MH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102418
   Gundapu S., 2021, TRANSFORMER BASED AU
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Jahanbakhsh-Nagadeh Z., 2020, MODEL MEASURE SPREAD
   Jahanbakhsh-Nagadeh Z., 2021, SIGNAL DATA PROCESSI, V18, P29
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Lan Zhenzhong, 2019, ARXIV190911942
   Liu C, 2019, LECT NOTES ARTIF INT, V11776, P172, DOI 10.1007/978-3-030-29563-9_17
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Lopez C. E., 2020, UNDERSTANDING PERCEP
   Mahmoodabad SD, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P597, DOI 10.1109/ISTEL.2018.8661007
   Memon S.A., 2020, CHARACTERIZING COVID
   Mikolov T., 2017, SHORT PAPERS, P427, DOI 10.18653/v1/e17
   Muller Martin, 2020, ARXIV200507503
   Nasir J. A., 2021, INT J INFORM MANAGE, V1, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Patwa P., 2021, P COMBATING ONLINE H, P21
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Qazi Umair, 2020, SIGSPATIAL Special, V12, P6, DOI 10.1145/3404820.3404823
   Salem F.K.A., 2019, P INT AAAI C WEB SOC, V13, P573
   Samadi M., 2021, ACM T ASIAN LOW-RESO, V21, P10
   Sanh Victor, 2019, ARXIV191001108
   Seifikar M, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P424, DOI 10.1109/ISTEL.2018.8661059
   Swire-Thompson B, 2020, ANNU REV PUBL HEALTH, V41, P433, DOI 10.1146/annurev-publhealth-040119-094127
   van Der Linden S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.566790
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wani A., 2021, EVALUATING DEEP LEAR
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yang ZJ, 2016, ADV SOC SCI EDUC HUM, V64, P1480
   Zamani S, 2017, IRAN CONF ELECTR ENG, P1532, DOI 10.1109/IranianCEE.2017.7985287
   Zarharan M., 2019, PERSIAN STANCE CLASS
   Zarocostas J, 2020, LANCET, V395, P676, DOI 10.1016/S0140-6736(20)30461-X
NR 45
TC 10
Z9 10
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD SEP
PY 2022
VL 39
IS 8
AR e13008
DI 10.1111/exsy.13008
EA APR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3P1YF
UT WOS:000777507100001
PM 35599852
OA Green Published
DA 2023-11-10
ER

PT J
AU Gogate, M
   Dashtipour, K
   Adeel, A
   Hussain, A
AF Gogate, Mandar
   Dashtipour, Kia
   Adeel, Ahsan
   Hussain, Amir
TI CochleaNet: A robust language-independent audio-visual model for
   real-time speech enhancement
SO INFORMATION FUSION
LA English
DT Article
DE Audio-Visual; Speech enhancement; Speech separation; Deep learning; Real
   noisy audio-visual corpus; Speaker independent; Noise-independent;
   Language-independent; Multi-modal; Hearing aids
ID NOISE; RECOGNITION; DEEP
AB Noisy situations cause huge problems for the hearing-impaired, as hearing aids often make speech more audible but do not always restore intelligibility. In noisy settings, humans routinely exploit the audio-visual (AV) nature of speech to selectively suppress background noise and focus on the target speaker. In this paper, we present a novel language-, noise- and speaker-independent AV deep neural network (DNN) architecture, termed CochleaNet, for causal or real-time speech enhancement (SE). The model jointly exploits noisy acoustic cues and noise robust visual cues to focus on the desired speaker and improve speech intelligibility. The proposed SE framework is evaluated using a first of its kind AV binaural speech corpus, ASPIRE, recorded in real noisy environments, including cafeteria and restaurant settings. We demonstrate superior performance of our approach in terms of both objective measures and subjective listening tests, over state-of-the-art SE approaches, including recent DNN based SE models. In addition, our work challenges a popular belief that scarcity of a mull-lingual, large vocabulary AV corpus and a wide variety of noises is a major bottleneck to build robust language, speaker and noise-independent SE systems. We show that a model trained on a synthetic mixture of the benchmark GRID corpus (with 33 speakers and a small English vocabulary) and CHiME 3 noises (comprising bus, pedestrian, cafeteria, and street noises) can generalise well, not only on large vocabulary corpora with a wide variety of speakers and noises, but also on completely unrelated languages such as Mandarin.
C1 [Gogate, Mandar; Dashtipour, Kia; Hussain, Amir] Edinburgh Napier Univ, Sch Comp, Edinburgh EH10 5DT, Midlothian, Scotland.
   [Adeel, Ahsan] Univ Wolverhampton, Sch Math & Comp Sci, Wolverhampton, England.
C3 Edinburgh Napier University; University of Wolverhampton
RP Hussain, A (通讯作者)，Edinburgh Napier Univ, Sch Comp, Edinburgh EH10 5DT, Midlothian, Scotland.
EM a.hussain@napier.ac.uk
RI Hussain, Amir/AAG-6299-2020; Dashtipour, Kia/AAX-9489-2020
OI Hussain, Amir/0000-0002-8080-082X; Dashtipour, Kia/0000-0002-9651-6487;
   Gogate, Mandar/0000-0003-1712-9014
FU Edinburgh Napier University; UK Engineering and Physical Sciences
   Research Council (EPSRC) [EP/M026981/1]; EPSRC [EP/M026981/1] Funding
   Source: UKRI
FX This work was supported by an Edinburgh Napier University funded
   Research Studentship, and the UK Engineering and Physical Sciences
   Research Council (EPSRC) Grant No. EP/M026981/1. The authors would like
   to thank Dr Ricard Marxer and Prof Jon Barker from the University of
   Sheffield for insightful discussions. Finally, the authors would like to
   acknowledge all participants and support staffinvolved in the collection
   of the ASPIRE corpus.
CR Adeel A., 2017, INT WORKSH CHALL HEA
   Adeel A, 2021, IEEE TETCI, V5, P481, DOI 10.1109/TETCI.2019.2917039
   Adeel A, 2020, INFORM FUSION, V59, P163, DOI 10.1016/j.inffus.2019.08.008
   Adeel A, 2020, COGN COMPUT, V12, P589, DOI 10.1007/s12559-019-09653-z
   Ahmadi M, 2013, J ACOUST SOC AM, V133, P1687, DOI 10.1121/1.4789896
   [Anonymous], 2019, FFMPEG TOOL
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2006, FUNDAMENTALS COMPUTA
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2018.2889052
   [Anonymous], 2001, METH SUBJ ASS INT SO
   Barker J, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P504, DOI 10.1109/ASRU.2015.7404837
   Boll S. F., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P200
   Chen JT, 2018, SIGNALS COMMUN TECHN, P207, DOI 10.1007/978-3-319-73031-8_9
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Ding SG, 2018, COGN COMPUT, V10, P49, DOI 10.1007/s12559-017-9489-x
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   Ephrat A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201357
   Gabbay A, 2018, INTERSPEECH, P1170
   Gogate M, 2018, INTERSPEECH, P2723, DOI 10.21437/Interspeech.2018-2516
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Harte N, 2015, IEEE T MULTIMEDIA, V17, P603, DOI 10.1109/TMM.2015.2407694
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Hou JC, 2018, IEEE TETCI, V2, P117, DOI 10.1109/TETCI.2017.2784878
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Jiang HC, 2021, COGN COMPUT, V13, P845, DOI 10.1007/s12559-019-09660-0
   Jin XB, 2019, COGN COMPUT, V11, P503, DOI 10.1007/s12559-019-09629-z
   King DB, 2015, ACS SYM SER, V1214, P1
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kjems U, 2010, EUR SIGNAL PR CONF, P1909
   Le Roux J, 2019, INT CONF ACOUST SPEE, P626, DOI 10.1109/ICASSP.2019.8683855
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Marchegiani L, 2019, COGN COMPUT, V11, P711, DOI 10.1007/s12559-019-09649-9
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Nisar S, 2019, COGN COMPUT, V11, P489, DOI 10.1007/s12559-018-9607-4
   Owens A, 2018, LECT NOTES COMPUT SC, V11210, P639, DOI 10.1007/978-3-030-01231-1_39
   Pandey A, 2018, INTERSPEECH, P1136
   Pascual S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5019, DOI 10.1109/ICASSP.2018.8462322
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Rethage D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5069, DOI 10.1109/ICASSP.2018.8462417
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Snyder D., 2015, ABS151008484 CORR
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Sun X, 2019, COGN COMPUT, V11, P587, DOI 10.1007/s12559-019-09654-y
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Yu F., 2015, 1511 ARXIV
   Yul D, 2017, INT CONF ACOUST SPEE, P241, DOI 10.1109/ICASSP.2017.7952154
   Zhou YP, 2018, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2018.00374
NR 54
TC 38
Z9 38
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD NOV
PY 2020
VL 63
BP 273
EP 285
DI 10.1016/j.inffus.2020.04.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NS3CH
UT WOS:000572142800004
OA Green Accepted
DA 2023-11-10
ER

PT J
AU Abul Bashar, M
   Nayak, R
   Suzor, N
AF Abul Bashar, Md
   Nayak, Richi
   Suzor, Nicolas
TI Regularising LSTM classifier by transfer learning for detecting
   misogynistic tweets with small training set
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Misogynistic tweet; Transfer learning; LSTM; Small dataset; Overfitting
AB Supervised machine learning methods depend highly on the quality of the training dataset and the underlying model. In particular, neural network models, that have shown great success in dealing with natural language problems, require a large dataset to learn a vast number of parameters. However, it is not always easy to build a large (labelled) dataset. For example, due to the complex nature of tweets and the manual labour involved, it is hard to create a large Twitter data set with the misogynistic label. In this paper, we propose to regularise a long short-term memory (LSTM) classifier using a pretrained LSTM-based language model (LM) to build an accurate classification model with a small training set. We explain transfer learning (TL) with a Bayesian interpretation and show that TL can be viewed as an uncertainty regularisation technique in Bayesian inference. We show that a LM pre-trained on a sequence of general to task-specific domain datasets can be used to regularise a LSTM classifier effectively when a small training dataset is available. Empirical analysis with two small Twitter datasets reveals that an LSTM model trained in this way can outperform the state-of-the-art classification models.
C1 [Abul Bashar, Md; Nayak, Richi] Queensland Univ Technol, Sch Comp Sci, Brisbane, Qld, Australia.
   [Suzor, Nicolas] Queensland Univ Technol, Sch Law, Brisbane, Qld, Australia.
C3 Queensland University of Technology (QUT); Queensland University of
   Technology (QUT)
RP Abul Bashar, M (通讯作者)，Queensland Univ Technol, Sch Comp Sci, Brisbane, Qld, Australia.
EM m1.bashar@qut.edu.au; r.nayak@qut.edu.au; n.suzor@qut.edu.au
RI Abu Bashar/ABC-9917-2020; Suzor, Nicolas/I-9996-2012; Nayak,
   Richi/B-4445-2011
OI Abu Bashar/0000-0002-0868-8335; Suzor, Nicolas/0000-0003-3029-0646;
   Nayak, Richi/0000-0002-9954-0159; Bashar, Md Abul/0000-0003-1004-4085
FU QUT IFE Catapult fund; Australian Research Council DECRA Fellowship
   [DE160101542]; Australian Research Council [DE160101542] Funding Source:
   Australian Research Council
FX his research was partially supported by the QUT IFE Catapult fund. Suzor
   is the recipient of an Australian Research Council DECRA Fellowship
   (project number DE160101542).
CR AHLUWALIA R, 2018, EVALITA EVAL NLP SPE, V12, P194, DOI DOI 10.4000/BOOKS.AACCADEMIA.4698
   Amnesty International, 2018, TOX TWITT TOX PLAC W
   [Anonymous], 2018, TECHNICAL REPORT
   [Anonymous], 2016, ARXIV161101576
   [Anonymous], 2004, 16 IASC INT S COMPUT
   Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   BARTLETT J, 2014, MISOGYNY TWITTER DEM
   Bashar M. A., 2018, 16 AUSTRALASIAN DATA, P3
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Dai AM, 2015, ADV NEUR IN, V28
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Devlin J., 2018, ARXIV, V1, P4171
   Downey A., 2012, THINK BAYES BAYESIAN
   DRAGIEWICZ M, 2018, FEM MED STUD, V18, P1
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Fersini E., 2018, P 6 EV CAMP NAT LANG, DOI [10.4000/books.aaccademia.4497, DOI 10.4000/BOOKS.AACCADEMIA.4497]
   Gal Y, 2016, ADV NEUR IN, V29
   Gal Yarin, 2016, UNCERTAINTY DEEP LEA
   Gitari ND, 2015, INT J MULTIMEDIA UBI, V10, P215, DOI DOI 10.14257/IJMUE.2015.10.4.21
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, P1621, DOI DOI 10.5555/2891460.2891697
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lewis D.D., 1998, EUR C MACH LEARN, P4
   Li Y., 2017, PR MACH LEARN RES, V70, P2052
   Liu P., 2019, P 13 INT WORKSH SEM, P87, DOI [10.18653/v1/S19-2011, DOI 10.18653/V1/S19-2011]
   Logeswaran L., 2018, INT C LEARN REPR
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI [10.1162/neco.1992.4.3.415, 10.1162/neco.1992.4.3.448]
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Melis G., 2017, ARXIV170705589
   Merity Stephen, 2017, ICLR
   Merity Stephen, 2016, POINTER SENTINEL MIX
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   MOLINAGONZALEZ MD, 2019, CEUR WS P
   Pitsilis GK, 2018, APPL INTELL, V48, P4730, DOI 10.1007/s10489-018-1242-y
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Silva L., 2016, P INT AAAI C WEB SOC, V10, P687, DOI [10.1609/icwsm.v10i1.14811, DOI 10.1609/ICWSM.V10I1.14811]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever I, 2014, ADV NEUR IN, V27
   Suzor N, 2018, INT COMMUN GAZ, V80, P385, DOI 10.1177/1748048518757142
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Wang B, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.12
   Wang D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P707
   WANG WB, 2014, P 17 ACM C COMP SUPP, P415
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu, 2016, ARXIV160202410
   Xiang G, 2012, P 21 ACM INT C INFOR, P1980, DOI DOI 10.1145/2396761.2398556
   Yandong Li, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P753, DOI 10.1109/ICINFA.2010.5512467
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Kelly W., 2018, ARXIV180910040
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
NR 63
TC 17
Z9 17
U1 1
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD OCT
PY 2020
VL 62
IS 10
BP 4029
EP 4054
DI 10.1007/s10115-020-01481-0
EA JUN 2020
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NW1DB
UT WOS:000541215800001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Nag, A
   Samanta, B
   Mukherjee, A
   Ganguly, N
   Chakrabarti, S
AF Nag, Arijit
   Samanta, Bidisha
   Mukherjee, Animesh
   Ganguly, Niloy
   Chakrabarti, Soumen
TI Transfer Learning for Low-Resource Multilingual Relation Classification
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Relation extraction
AB Relation classification (sometimes called relation extraction) requires trustworthy datasets for fine-tuning large language models, as well as for evaluation. Data collection is challenging for Indian languages, because they are syntactically and morphologically diverse, as well as different from resource-rich languages like English. Despite recent interest in deep generative models for Indian languages, relation classification is still not well served by public datasets. In response, we present IndoRE, a dataset with 21K entity- and relationtagged gold sentences in three Indian languages (Bengali, Hindi, and Telugu), plus English. We start with a multilingual BERT (mBERT)-based system that captures entity span positions and type information, and provides competitive performance on monolingual relation classification. Using this baseline system, we explore transfer mechanisms between languages and the scope to reduce expensive data annotation while achieving reasonable relation extraction performance. Specifically, we (a) study the accuracy-efficiency trade-off between expensive, manually labeled gold instances vs. automatically translated and aligned silver instances to train a relation extractor, (b) device a simple mechanism for budgeted gold data annotation by intelligently converting distant-supervised silver training instances to gold training instances with human annotators using active learning, and finally (c) propose an ensemble model to provide a performance boost over that achieved via limited gold training instances. We release the dataset for future research.(1)
C1 [Nag, Arijit; Samanta, Bidisha; Mukherjee, Animesh; Ganguly, Niloy; Chakrabarti, Soumen] Indian Inst Technol, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Nag, A (通讯作者)，Indian Inst Technol, Kharagpur, W Bengal, India.
EM arijitnag@iitkgp.ac.in; bidisha@iitkgp.ac.in; animeshm@iitkgp.ac.in;
   niloy@cse.iitkgp.ac.in; soumen@cse.iitb.ac.in
OI Mukherjee, Animesh/0000-0003-4534-0044
CR Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1007/BF00116828
   [Anonymous], 2015, P 29 PAC AS C LANG I
   [Anonymous], 2009, HUMAN LANGUAGE TECHN, DOI DOI 10.3115/1620754.1620815
   Balcan MF, 2009, J COMPUT SYST SCI, V75, P78, DOI 10.1016/j.jcss.2008.07.003
   Soares LB, 2019, Arxiv, DOI arXiv:1906.03158
   Bastos Anson, 2020, P WEB C 2021 WWW 21
   Bekoulis G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2830
   Beluch WH, 2018, PROC CVPR IEEE, P9368, DOI 10.1109/CVPR.2018.00976
   Beygelzimer A., 2009, P 26 ANN INT C MACH, P49
   Bilgic Mustafa, 2009, P NIPS WORKSH AN NET
   Bloodgood M, 2014, Arxiv, DOI arXiv:1410.5877
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Cai R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P756
   Chen J, 2020, Arxiv, DOI [arXiv:2004.03636, 10.48550/ARXIV.2004.03636, DOI 10.48550/ARXIV.2004.03636]
   Chen M, 2020, P 3 CLIN NATURAL LAN, P234, DOI [DOI 10.18653/V1/2020.CLINICALNLP-1.26, 10.18653/v1/2020.clinicalnlp-1.26]
   Dagan I., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P150
   Daojian Zeng., 2014, P COLING 25 INT C CO, P2335
   Dasgupta S, 2005, LECT NOTES COMPUT SC, V3559, P249, DOI 10.1007/11503415_17
   Dat Quoc Nguyen, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P729, DOI 10.1007/978-3-030-15712-8_47
   dos Santos CN, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P626
   Figueroa RL, 2012, J AM MED INFORM ASSN, V19, P809, DOI 10.1136/amiajnl-2011-000648
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   Freytag A, 2014, LECT NOTES COMPUT SC, V8692, P562, DOI 10.1007/978-3-319-10593-2_37
   Fu TJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1409
   Gal Y, 2017, PR MACH LEARN RES, V70
   Gal Y, 2016, PR MACH LEARN RES, V48
   Guo Yuhong, 2010, ADV NEURAL INFORM PR, P802
   Han X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4803
   Han X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2236
   Hendrickx Iris, 2010, P 5 INT WORKSH SEM E, P33, DOI DOI 10.3115/1621969.1621986
   Hoffmann R, 2011, PROC 49 ANN M ASS CO, V1, P541, DOI DOI 10.5555/2002472
   Goodfellow IJ, 2015, Arxiv, DOI arXiv:1312.6211
   Jiang X., 2016, P COLING 26 INT C CO, P1471
   Jin ZJ, 2020, Arxiv, DOI arXiv:2006.03719
   Joshi Ajay J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2372, DOI 10.1109/CVPRW.2009.5206627
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kemker R, 2018, AAAI CONF ARTIF INTE, P3390
   Khanuja S, 2021, Arxiv, DOI arXiv:2106.02834
   King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kozhevnikov M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P579
   Krishnamurthy V, 2002, IEEE T SIGNAL PROCES, V50, P1382, DOI 10.1109/TSP.2002.1003062
   Lee J. Y., 2017, ARXIV170401523
   Lee JH, 2019, Arxiv, DOI arXiv:1901.08163
   Lewis D. D., 1995, SIGIR Forum, V29, P13, DOI 10.1145/219587.219592
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Liu TY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2195
   Liu Y, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P285
   McCallumzy A. K., 1998, PROC INT C MACHINE L, P359, DOI [DOI 10.1023/A:1007692713085, DOI 10.5555/645527.757765]
   Mintz M., 2009, P JOINT C 47 ANN M A, P1003, DOI DOI 10.3115/1690219.1690287
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Nadgeri Abhishek, 2021, FINDINGS ASS COMPUTA, P535, DOI [10.18653/v1/2021.findings-acl.48, DOI 10.18653/V1/2021]
   Nag Arijit, 2021, P 25 C COMPUTATIONAL, P575
   Nguyen Hieu T, 2004, P ICML, DOI DOI 10.1145/1015330.1015349
   Nguyen TH, 2015, P 1 WORKSH VECT SPAC, P39, DOI DOI 10.3115/V1/W15-1506
   Ni J, 2020, Arxiv, DOI arXiv:2010.08652
   Pfeiffer J, 2020, Arxiv, DOI arXiv:2005.00052
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46
   Pires T, 2019, Arxiv, DOI arXiv:1906.01502
   Ranganathan H, 2017, IEEE IMAGE PROC, P3934, DOI 10.1109/ICIP.2017.8297020
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Roy N., 2001, P 18 INT C MACH LEAR, V2, P441
   Serrà J, 2018, PR MACH LEARN RES, V80
   Settles Burr, 2007, ADV NEURAL INFORM PR, V20, P1289
   Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417
   Sha F., 2007, ADV NEURAL INFORM PR, P1249
   Shen Y., 2016, 26 INT C COMPUTATION, P2526
   Shen YY, 2018, Arxiv, DOI arXiv:1707.05928
   Shui C., 2020, INT C ART INT STAT, P1308
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2895
   Su J, 2015, EMNLP, P536
   Surdeanu M, 2012, EMNLP CONLL, P455
   Ash JT, 2020, Arxiv, DOI arXiv:1906.03671
   Thompson CA, 1999, MACHINE LEARNING, PROCEEDINGS, P406
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Ulges A., 2019, PREPRINT, DOI DOI 10.3233/FAIA200321
   Vashishth S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1257
   Wang J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1706
   Wang LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1298
   Wang Xinyi, 2021, FINDINGS ASS COMPUTA, P730, DOI 10.18653/v1/2021.findings-emnlp.63
   Wu SC, 2019, Arxiv, DOI arXiv:1905.08284
   Wu Y., 2017, P 2017 C EMPIRICAL M, P1778
   Xiao M, 2016, P COLING 2016 26 INT, P1254
   Xu Y, 2016, ARXIV PREPRINT ARXIV
   Xu Y, 2015, P 2015 C EMP METH NA, P1785, DOI DOI 10.18653/V1/D15-1206
   Xue FZ, 2020, Arxiv, DOI [arXiv:2012.06780, 10.1609/aaai.v35i16.17670, DOI 10.1609/AAAI.V35I16.17670]
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6442
   Ye ZX, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2810
   Yin CC, 2017, IEEE DATA MINING, P575, DOI 10.1109/ICDM.2017.67
   Zeng D, 2015, P 2015 C EMPIRICAL M, P1753
   Zeng W, 2017, P 2017 C EMP METH NA, P1768, DOI DOI 10.18653/V1/D17-1186
   Zhang C., 2018, ARXIV180502350
   Zhang DX, 2015, Arxiv, DOI arXiv:1508.01006
   Zhang Y., 2017, P 2017 C EMPIRICAL M, P35
   Zhdanov Fedor, 2019, DIVERSE MINI BATCH A
   Zheng SC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1227, DOI 10.18653/v1/P17-1113
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 97
TC 0
Z9 0
U1 2
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB
PY 2023
VL 22
IS 2
DI 10.1145/3554734
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C7AF6
UT WOS:000963394900019
DA 2023-11-10
ER

PT J
AU Han, JB
   Wang, HZ
AF Han, Jiabao
   Wang, Hongzhi
TI Improving Open Information Extraction with Distant Supervision Learning
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Distant supervision learning; Open information extraction; Neural
   network; Sequence-to-sequence model
AB Open information extraction (Open IE), as one of the essential applications in the area of Natural Language Processing (NLP), has gained great attention in recent years. As a critical technology for building Knowledge Bases (KBs), it converts unstructured natural language sentences into structured representations, usually expressed in the form of triples. Most conventional open information extraction approaches leverage a series of manual pre-defined extraction patterns or learn patterns from labeled training examples, which requires a large number of human resources. Additionally, many Natural Language Processing tools are involved, which leads to error accumulation and propagation. With the rapid development of neural networks, neural-based models can minimize the error propagation problem, but it also faces the problem of data-hungry in supervised learning. Especially, they leverage existing Open IE tools to generate training data, and it causes data quality issues. In this paper, we employ a distant supervision learning approach to improve the Open IE task. We conduct extensive experiments by employing two popular sequence-to-sequence models (RNN and Transformer) and a large benchmark data set to demonstrate the performance of our approach.
C1 [Han, Jiabao; Wang, Hongzhi] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, HZ (通讯作者)，Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM jiabaohan@outlook.com; wangzh@hit.edu.cn
FU NSFC [U1866602, 61772157]
FX This paper was partially supported by NSFC grant U1866602, 61772157.
CR Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   Bahdanau Dzmitry, 2015, 3 INT C LEARN REPR I
   Cetto M, 2018, P 27 INT C COMP LING, P2300
   Cho K., 2014, COMPUT SCI
   Christensen J, 2010, P NAACL HLT 2010 1 I
   Cui L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P407
   del Corro L., 2013, P 22 INT C WORLD WID, P355, DOI [10.1145/2488388.2488420, DOI 10.1145/2488388.2488420]
   Duan L., 2019, RES INDOOR LIGHTING
   Etzioni O, 2011, P 22 INT JOINT C ART, P3, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-012
   Etzioni O, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1409360.1409378
   Fader A., 2011, P C EMPIRICAL METHOD, P1535, DOI DOI 10.1234/12345678
   Gashteovski K., 2017, P 2017 C EMP METH NA, P2620
   Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hermann K. M., 2015, ADV NEURAL INFORM PR
   Hill F, 2016, P 4INT C LEARN REPR
   Hoffmann R, 2011, PROC 49 ANN M ASS CO, V1, P541, DOI DOI 10.5555/2002472
   Kenter T., 2015, P 24 ACM INT C INF K, P1411
   Klatt T, 2017, ARXIV170707499 CORR
   Lei K, 2018, ARXIV181201889 CORR
   Li C, 2018, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2018.00548
   Li G., 2017, BIONLP, P184, DOI DOI 10.18653/V1/W17-2323
   Luong T., 2015, P C EMPIRICAL METHOD, P1412, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mausam, 2016, P 25 INT JOINT C ART, P4074
   Min Bonan, 2013, P 2013 C N AM CHAPT, P777, DOI DOI 10.1186/S40537-016-0043-6
   Nallapati R, 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Pal Harinder, 2016, P 5 WORKSH AUT KNOWL, P35, DOI DOI 10.18653/V1/W16-1307
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Roth B., 2013, PROC WORKSHOP AUTOMA, P73
   Rush A M, 2015, P 2015 C EMPIRICAL M, P379
   Saha S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P317, DOI 10.18653/v1/P17-2050
   Salthouse T.A., 2000, HDB AGING COGNITION, P359
   Santoro A., 2017, P ADV NEUR INF PROC, P4967
   Sarhan I, 2019, LECT NOTES COMPUT SC, V11608, P359, DOI 10.1007/978-3-030-23281-8_31
   Schmitz M., 2012, P 2012 JOINT C EMPIR, P523
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Stanovsky G, 2016, ARXIV160301648 CORR
   Stanovsky G., 2016, P 2016 C EMPIRICAL M, P2300
   Surdeanu M, 2012, EMNLP CONLL, P455
   Sutskever I, 2014, ADV NEUR IN, V27
   Takamatsu S., 2012, P 50 ANN M ASS COMPU, P721
   Vaswani A., 2017, ARXIV, V30, P5998
   Weston J, 2016, 4 INT C LEARN REPR I
   Wu F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P118
   Wu Y, 2017, PERIPHYTON: FUNCTIONS AND APPLICATION IN ENVIRONMENTAL REMEDIATION, P1
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Yates A, 2007, P HUM LANG TECHN ANN, P25, DOI DOI 10.3115/1614164.1614177
   Yong Z, 2017, INT CONF SYST INFORM, P1477, DOI 10.1109/ICSAI.2017.8248519
NR 49
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD OCT
PY 2021
VL 53
IS 5
SI SI
BP 3287
EP 3306
DI 10.1007/s11063-021-10548-0
EA JUN 2021
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WH4LR
UT WOS:000658086500001
DA 2023-11-10
ER

PT J
AU Kyburg, HE
AF Kyburg, HE
TI Combinatorial semantics: Semantics for frequent validity
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article
DE semantics; uncertainty; nonmonotonic logic; probability; uncertain
   inference; approximate validity; inductive logic
AB In ordinary first-order logic, a valid inference in a language L is one in which the conclusion is true in every model of the language in which the premises are true. To accommodate inductive/uncertain/probabilistic/nonmonotonic inference, we weaken that demand to the demand that the conclusion be true in a large proportion of the models in which the relevant premises are true. More generally, we say that an inference is [p, q] valid if its conclusion is true in a proportion lying between p and q of those models in which the relevant premises are true. If we include a statistical variable binding operator ''%'' in our language, there are many quite general (and useful) things we can say about uncertain validity. A surprising result is that some of these things may conflict with Bayesian conditionalization.
RP Kyburg, HE (通讯作者)，UNIV ROCHESTER,601 ELMWOOD AVE,ROCHESTER,NY 14627, USA.
CR [Anonymous], CHANGE VIEW
   BACCHUS F, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P602
   BACCHUS F, 1992, REPRESENTING REASONI
   CARNAP R, 1950, LOGICAL F PROBABILIT
   Carnap Rudolf, 1952, CONTINUUM INDUCTIVE
   Carnap Rudolf, 1980, STUDIES INDUCTIVE LO, VII, P7
   Carnap Rudolf, 1971, STUDIES INDUCTIVE LO, VI, P33
   DAVIDSON D, 1966, J PHILOS, V63, P778, DOI 10.2307/2023808
   Geffner H., 1992, Minds and Machines, V2, P51, DOI 10.1007/BF00261289
   Genesereth M.R., 1987, LOGICAL FDN ARTIFICI
   GROVE AJ, 1992, 7 IEEE S LOG COMP SC, P22
   HALPERN JY, 1990, ARTIF INTELL, V46, P311, DOI 10.1016/0004-3702(90)90019-V
   Hintikka Jaakko, 1966, ASPECTS INDUCTIVE LO, P113
   ISRAEL D, 1980, 1ST P ANN NAT C ART, P99
   JAYNES ET, 1958, COLLOQUIUM LECT PURE, V4, P152
   Johnson W E., 1932, MIND, V41, P409, DOI [10.1093/mind/XLI.164.409, DOI 10.1093/MIND/XLI.164.409]
   JOHNSON WE, 1932, PROBABILITY MIND, V41, P1
   JOHNSON WE, 1932, PROBABILITY MIND, V41, P281
   KYBURG H, 1983, RECENT WORK PHILOS, P87
   Kyburg H.E., 1961, PROBABILITY LOGIC RA
   Kyburg H. E., 1991, P 12 INT JOINT C ART, P1196
   KYBURG HE, 1990, MINN STUD PHILOS SCI, V14, P158
   KYBURG HE, 1988, THEOR DECIS, V25, P137
   KYBURG HE, 1983, PHILOS SCI, V50, P374, DOI 10.1086/289125
   KYBURG HE, 1991, UNCERTAINTY, P228
   KYBURG HE, 1991, LECT NOTES COMPUTER, P204
   KYBURG HE, 1974, LOGICAL F STATISTICA
   KYBURG HE, 1990, SYNTHESE, V85, P475
   LOUI RP, 1986, P 1986 WORKSH UNCERT, P183
   MENDELSON E, 1979, ILNTRO MATH LOGIC
   Mill J.S., 1843, SYSTEM LOGIC RATIOCI
   Nagel E, 1939, PRINCIPLES THEORY PR
   NELSON G, 1955, FACT FICTION FORECAS
   NILSSON NJ, 1986, ARTIF INTELL, V28, P71, DOI 10.1016/0004-3702(86)90031-7
   Pearl J., 1988, MORGAN KAUFMANN SERI
   Pollock J., 1990, NOMIC PROBABILITY FD
   Popper KR., 2002, LOGIC SCI DISCOVERY
   QUINE WVO, 1951, MATHEMATICAL LOGIC
   Reichenbach Hans., 1949, THEORY PROBABILITY
   Touretzky D. S, 1986, MATH INHERITANCE SYS
NR 40
TC 9
Z9 9
U1 0
U2 0
PU BLACKWELL PUBLISHERS
PI CAMBRIDGE
PA 350 MAIN STREET, STE 6, CAMBRIDGE, MA 02148-5023
SN 0824-7935
J9 COMPUT INTELL
JI Comput. Intell.
PD MAY
PY 1997
VL 13
IS 2
BP 215
EP 257
DI 10.1111/0824-7935.00039
PG 43
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WY155
UT WOS:A1997WY15500003
DA 2023-11-10
ER

PT J
AU Naddaf, MR
   Rafe, V
AF Naddaf, Mahdi Rahimi
   Rafe, Vahid
TI PERFORMANCE MODELING AND ANALYSIS OF SOFTWARE ARCHITECTURES SPECIFIED
   THROUGH GRAPH TRANSFORMATIONS
SO COMPUTING AND INFORMATICS
LA English
DT Article
DE Graph transformation system; PEPA; performance model; software
   architecture
ID SYSTEMS; LANGUAGE
AB Software architecture plays an important role in the success of modern, large and distributed software systems. For many of the software systems - especially safety-critical ones - it is important to specify their architectures using formal modeling notations. In this case, it is possible to assess different functional and nonfunctional properties on the designed models. Graph Transformation System (GTS) is a formal yet understandable language which is suitable for architectural modeling. Most of the existing works done on architectural modeling and analysis by GTS are concentrated on functional aspects, while for many systems it is crucial to consider non-functional aspects for modeling and analysis at the architectural level. In this paper, we present an approach to performance analysis of software architectures specified through GTS. To do so, we first enrich the existing architectural style specified through GTS - with performance information. Then, the performance models are generated in PEPA (Performance Evaluation Process Algebra) - a formal language based on the stochastic process algebra - using the enriched GTS models. Finally, we analyze different features like throughput, utilization of different software components, etc. on the generated performance models. All the main concepts are illustrated through a case study.
C1 [Naddaf, Mahdi Rahimi; Rafe, Vahid] Arak Univ, Fac Engn, Dept Comp Engn, Arak 3815688349, Iran.
C3 Arak University
RP Naddaf, MR (通讯作者)，Arak Univ, Fac Engn, Dept Comp Engn, Arak 3815688349, Iran.
EM m-rahiminaddaf@arshad.araku.ac.ir; v-rafe@araku.ac.ir
FU Edinburgh University
FX We would like to thank Prof. Jane Hillston (currently at the Edinburgh
   University), for her supports in this research especially in the
   utilization of PEPA and its toolkit.
CR Baldan P, 2004, LECT NOTES COMPUT SC, V3170, P83
   Balsamo S, 2004, IEEE T SOFTWARE ENG, V30, P295, DOI 10.1109/TSE.2004.9
   BALSAMO S, 2005, P 5 INT WORKSH SOFTW, P37
   Baresi L, 2002, LECT NOTES COMPUT SC, V2505, P402
   Baresi L., 2006, SOFTWARE SYSTEM MODE, V5, P187
   Baresi L, 2008, ELECTRON NOTES THEOR, V213, P3, DOI 10.1016/j.entcs.2008.04.071
   Becker S., 2007, P 6 INT WORKSH SOFTW, P56, DOI DOI 10.1145/1216993.1217006
   Canevet C, 2003, IEE P-COMPUT DIG T, V150, P107, DOI 10.1049/ip-cdt:20030084
   Clark A, 2007, LECT NOTES COMPUT SC, V4486, P132
   DAMBROGIO A, 2005, P 5 INT WORKSH SOFTW, P75, DOI DOI 10.1145/1071021.1071029
   Ehrig Hartmut, 2006, MONO THEOR COMP SCI
   Fritzsche M., 2009, MODEL TRANSFORMATION, P345
   Fritzsche M, 2009, LECT NOTES COMPUT SC, V5701, P97, DOI 10.1007/978-3-642-03848-8_8
   GARLAN D, 1994, P SIGSOFT 94 S FDN S
   GONCZY L, 2009, MODEL TRANSFORMATION, V5421, P153
   GONCZY L, 2006, P WORKSH GRAPH TRANS
   Grassi V, 2007, J SYST SOFTWARE, V80, P528, DOI 10.1016/j.jss.2006.07.023
   Heckel R, 2005, LECT NOTES COMPUT SC, V3722, P53
   Heckel R., 2004, P 2 INT C GRAPH TRAN
   Hillston J, 2005, COMPUT J, V48, P385, DOI 10.1093/comjnl/bxh097
   HILLSTON J, 1994, CST10794 U ED DEP CO
   Holanda H. J. A., 2009, SOASPE FRAMEWORK PER, P204
   Kwiatkowska M, 2002, LECT NOTES COMPUT SC, V2324, P200
   Merseguer J, 2004, LECT NOTES COMPUT SC, V2965, P265
   Mitton P., 2000, P 16 UK PERF ENG WOR, P19
   Petriu DC, 2002, LECT NOTES COMPUT SC, V2324, P159
   POOLEY R, 1999, P 15 UK PERF ENG WOR, P23
   Rafe V, 2009, IET SOFTW, V3, P276, DOI 10.1049/iet-sen.2008.0059
   Rensink A., 2004, LNCS, V3062
   Schmidt A, 2003, LECT NOTES COMPUT SC, V2863, P92
   Smith CU, 1990, PERFORMANCE ENG SOFT
   Spitznagel B., 1998, P SOFTW ENG KNOWL EN
   Taylor R., 2008, SOFTWARE ARCHITECTUR
   Thone S., 2005, THESIS U PADERBORN
   Torrini P, 2010, LECT NOTES COMPUT SC, V6013, P154
   Varró D, 2007, SCI COMPUT PROGRAM, V68, P214, DOI 10.1016/j.scico.2007.05.004
NR 36
TC 7
Z9 7
U1 0
U2 3
PU SLOVAK ACAD SCIENCES INST INFORMATICS
PI BRATISLAVA
PA DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA
SN 1335-9150
J9 COMPUT INFORM
JI Comput. Inform.
PY 2013
VL 32
IS 4
BP 797
EP 826
PG 30
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 243GZ
UT WOS:000326306200007
DA 2023-11-10
ER

PT J
AU Marcus, S
   Martin-Vide, C
   Paun, G
AF Marcus, S
   Martin-Vide, C
   Paun, G
TI Contextual grammars as generative models of natural languages
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB The paper discusses some classes of contextual grammars-mainly those with "maximal use of selectors"-giving some arguments that these grammars can be considered a goon model for natural language syntax.
   A contextual grammar produces a language starting from a finite set of words and iteratively adding contexts to the currently generated words, according to a selection procedure: each context has associated with it a selector, a set of words; the context is adjoined to any occurrence of such a selector in the word to be derived. In grammars with maximal use of selectors, a context is adjoined only to selectors for which no superword is a selector. Maximality can be defined either locally or globally (with respect to all selectors in the grammar). The obtained families of languages are incomparable with that of Chomsky context-free languages land with other families of languages that contain linear languages and that are not "too large"; see Section 5) and have a series of properties supporting the assertion that these grammars are a possible adequate model for the syntax of natural languages. They are able to straightforwardly describe all the usual restrictions appearing in natural (and artificial) languages, which lead to the non-context-freeness of these languages: reduplication, crossed dependencies, and multiple agreements; however, there are center-embedded constructions that cannot be covered by these grammars.
   While these assertions concern only the weak generative capacity of contextual grammars, some ideas are also proposed for associating a structure to the generated words, in the form of a tree, or of a dependence relation (as considered in descriptive linguistics and also similar to that in link grammars).
C1 Univ Bucharest, Fac Math, Bucharest 70109, Romania.
   Univ Rovira & Virgili, Res Gep Math Linguist & Language Engn GRLMC, Tarragona, Spain.
   Romanian Acad, Math Inst, Bucharest 70700, Romania.
C3 University of Bucharest; Universitat Rovira i Virgili; Romanian Academy
   of Sciences; Institute of Mathematical Statistics & Applied Mathematics
   of Romanian Academy
RP Marcus, S (通讯作者)，Univ Bucharest, Fac Math, Str Acad 14, Bucharest 70109, Romania.
EM solomon@imar.ro; cmv@astor.urv.es; gpaun@imar.ro
CR AHO AV, 1968, J ACM, V15, P647, DOI 10.1145/321479.321488
   [Anonymous], 1997, HDB FORMAL LANGUAGES, DOI DOI 10.1007/978-3-662-07675-0
   [Anonymous], 1967, ALGEBRAIC LINGUISTIC
   BALANESCU T, 1987, REV ROUMAINE LINGUIS, V32, P167
   Bar-Hillel Y., 1964, LANGUAGE INFORMATION, P87
   CARLOS MV, 1998, IN PRESS GRAMMARS
   CARLOS MV, 1995, P 4 BAR IL S FDN ART, P132
   Chomsky N., 1964, STRUCTURE LANGUAGE R, DOI DOI 10.1016/J.JCOMDIS.2008.01.004
   CULY C, 1985, LINGUIST PHILOS, V8, P345, DOI 10.1007/BF00630918
   Dassow J., 1989, REGULATED REWRITING
   EHRENFEUCHT A, 1997, IN PRESS THEORETICAL
   FLOYD RW, 1962, COMMUN ACM, V5, P483, DOI 10.1145/368834.368898
   GAZDAR G, 1985, NEW GENERAT COMPUT, V3, P273, DOI 10.1007/BF03037123
   GRINBERG D, 1995, P 4 INT WORKSH PARS, P111
   Harrison Michael A., 1978, INTRO FORMAL LANGUAG
   HOCKETT CF, 1970, STATE ART
   ILIE L, 1997, UNPUB COMPUTATIONAL
   ILIE L, 1997, IN PRESS THEORETICAL
   JANCAR P, 1996, DEV LANGUAGE THEORY, V2, P102
   Joshi A. K., 1985, NATURAL LANGUAGE PAR, P206, DOI [10.1017/CBO9780511597855.007, DOI 10.1017/CBO9780511597855, DOI 10.1017/CBO9780511597855.007]
   JOSHI AK, 1975, J COMPUT SYST SCI, V10, P136, DOI 10.1016/S0022-0000(75)80019-5
   Joshi Aravind K., 1987, MATH LANGUAGE, V1, P87, DOI DOI 10.1075/Z.35
   KOPPEL M, 1997, P 4 BAR IL S FDN ART, P159
   MARCUS S, 1997, HDB FORMAL LANGUAGES, V2, P215
   MARCUS S, 1981, CONTEXTUAL AMBIGUITI
   MARCUS S, 1979, REV ROUMAINE LINGUSI, V16, P29
   Marcus S., 1969, REV ROUMAINE MATH MA, V14, P1525
   MARCUS S, 1978, SEMIOTIQUE FORMELLE
   MARTINVIDE C, 1997, FUNDAMENTA INFORMATI, P117
   MIQUELVERGES J, 1997, THESIS ROVIRA VIRGIL
   OLIVETTI C, 1970, LINGUAGGI NELLA SOC
   Partee B. H., 1990, MATH METHODS LINGUIS
   PAUN G, 1985, INT J COMPUT MATH, V17, P9, DOI 10.1080/00207168508803447
   PAUN G, 1980, REV ROUM MATH PURE A, V25, P641
   Paun G., 1982, CONTEXTUAL GRAMMARS
   PAUN G, 1994, B EATCS, V52, P263
   PAUN G, 1976, REV ROUMAINE LINGUIS, V13, P605
   PAUN G, 1979, ARS SEMEIOTICA, V2, P33
   PAUN G, 1997, MARCUS CONTEXTUAL GR
   PAUN G, 1994, MATH ASPECTS NATURAL, P375
   Pullum G. K., 1984, Computational Linguistics, V10, P182
   PULLUM GK, 1982, LINGUIST PHILOS, V4, P471, DOI 10.1007/BF00360802
   PULLUM GK, 1986, NAT LANG LINGUIST TH, V4, P409, DOI 10.1007/BF00133376
   PULLUM GK, 1987, NAT LANG LINGUIST TH, V5, P303, DOI 10.1007/BF00166588
   RADZINSKI D, 1990, LINGUIST PHILOS, V13, P113, DOI 10.1007/BF00630518
   Ramer A. M., 1993, Annals of Mathematics and Artificial Intelligence, V8, P1, DOI 10.1007/BF02451545
   RAMER ALM, 1994, 10 C LENG NAT LENG F
   ROSENKRANTZ DJ, 1969, J ACM, V16, P107, DOI 10.1145/321495.321504
   ROUNDS WC, 1987, MATH LANGUAGE, P375
   Rozenberg Grzegorz, 1980, MATH THEORY L SYSTEM
   Salomaa, 1973, FORMAL LANGUAGES
   Savitch W. J., 1993, Annals of Mathematics and Artificial Intelligence, V8, P17, DOI 10.1007/BF02451546
   Savitch W. J., 1987, FORMAL COMPLEXITY NA
   SAVITCH WJ, 1991, INTERDISCIPLINARY AP, P487
   SHIEBER SM, 1985, LINGUIST PHILOS, V8, P333, DOI 10.1007/BF00630917
   SLEATOR D, 1991, CMUSCS91196
NR 56
TC 22
Z9 22
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 1998
VL 24
IS 2
BP 245
EP 274
PG 30
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Linguistics
GA ZX569
UT WOS:000074531200003
DA 2023-11-10
ER

PT J
AU Sharma, S
   Singh, S
AF Sharma, Sakshi
   Singh, Sukhwinder
TI Vision-based hand gesture recognition using deep learning for the
   interpretation of sign language
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Human-computer interaction; Feature
   extraction; Classification; Deep learning; Sign language recognition
ID INDEPENDENT SYSTEM; CLASSIFICATION; ALPHABETS; POSTURE
AB Hand gestures have been the key component of communication since the beginning of an era. The hand gestures are the foundation of sign language, which is a visual form of communication. In this paper, a deep learning based convolutional neural network (CNN) model is specifically designed for the recognition of gesture-based sign language. This model has a compact representation that achieves better classification accuracy with a fewer number of model parameters over the other existing architectures of CNN. In order to evaluate the efficacy of this model, VGG-11 and VGG-16 have also been trained and tested in this work. To evaluate the performance, 2 datasets have been considered. First, in this work, a large collection of Indian sign language (ISL) gestures consisting of 2150 images is collected using RGB camera, and second, a publicly available American sign language (ASL) dataset is used. The highest accuracy of 99.96% and 100% is obtained by the proposed model for ISL and ASL datasets respectively. The performance of the proposed system, VGG-11, and VGG-16 are experimentally evaluated and compared with the existing state-of-art approaches. In addition to accuracy, other efficiency indices have been also used to ascertain the robustness of the proposed work. The findings indicate that the proposed model outperforms the existing techniques as it has the potential to classify maximum gestures with a minimal rate of error. The model is also tested with the augmented data and is found as invariant to rotation and scaling transformation.
C1 [Sharma, Sakshi; Singh, Sukhwinder] Punjab Engn Coll Deemed Univ, ECE Dept, Chandigarh, India.
C3 Punjab Engineering College (Deemed University)
RP Sharma, S (通讯作者)，Punjab Engn Coll Deemed Univ, ECE Dept, Chandigarh, India.
EM sak.sharma92@gmail.com; sukhwindersingh@pec.ac.in
RI Singh, Sukhwinder/JGL-7957-2023
CR Abraham E., 2019, REAL TIME TRANSLATIO, P1
   Akhter S, 2018, ORIENTATION HASHCODE, P1
   Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   Ameen S, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12197
   [Anonymous], 2019, 2019 2 INT C COMP
   Ansari ZA, 2016, SADHANA-ACAD P ENG S, V41, P161, DOI 10.1007/s12046-015-0405-3
   Arefnezhad S, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113778
   Athira PK, 2022, J KING SAUD UNIV-COM, V34, P771, DOI 10.1016/j.jksuci.2019.05.002
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chong Teak-Wei, 2020, [The Journal of The Korea Institute of Electronic Communication Sciences, 한국전자통신학회 논문지], V15, P291, DOI 10.13067/JKIECS.2020.15.2.291
   Dahmani D, 2014, J VIS COMMUN IMAGE R, V25, P1240, DOI 10.1016/j.jvcir.2013.12.019
   Gangrade J, 2023, IETE J RES, V69, P723, DOI 10.1080/03772063.2020.1838342
   Gupta R., 2020, COMPUT ELECTR ENG, DOI [DOI 10.1016/J.COMPELECENG.2020.106898, 10.1016/j.compeleceng.2020.106898]
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Joshi G., 2018, INT C ADV COMP DAT S, P65
   Joshi G, 2018, IET COMPUT VIS, V12, P570, DOI 10.1049/iet-cvi.2017.0394
   Joshi G, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P541, DOI 10.5220/0006200905410548
   Just A., 2006, 2 HANDED GESTURES HU
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Kakoty NM, 2018, PROCEDIA COMPUT SCI, V133, P55, DOI 10.1016/j.procs.2018.07.008
   Kang B, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P136, DOI 10.1109/ACPR.2015.7486481
   Kaur B, 2017, WIRELESS PERS COMMUN, V95, P4823, DOI 10.1007/s11277-017-4126-2
   Kaur B, 2016, ADV HUM-COMPUT INTER, V2016, DOI 10.1155/2016/6727806
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Kulshreshth A, 2017, IEEE COMPUT GRAPH, V37, P16, DOI 10.1109/MCG.2017.42
   Kumar Anand, 2021, International Journal of Information Technology, V13, P349, DOI 10.1007/s41870-020-00525-6
   Kumar P., 2012, Proceedings of the 2012 1st International Conference on Recent Advances in Information Technology (RAIT 2012), P750, DOI 10.1109/RAIT.2012.6194548
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Liu Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114602
   Mittal A, 2018, WIRELESS PERS COMMUN, V101, P511, DOI 10.1007/s11277-018-5702-9
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Pathak Bhumika, 2019, Computational Intelligence: Theories, Applications and Future Directions - Volume I. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 798), P487, DOI 10.1007/978-981-13-1132-1_38
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Raheja J. L., 2016, Pattern Recognition and Image Analysis, V26, P434, DOI 10.1134/S1054661816020164
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Rekha J., 2011, 2011 3rd International Conference on Trendz in Information Sciences & Computing (TISC), P30, DOI 10.1109/TISC.2011.6169079
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Sahoo JP, 2018, IET IMAGE PROCESS, V12, P1780, DOI 10.1049/iet-ipr.2017.1312
   Sharma S, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P140, DOI 10.1109/icict48043.2020.9112409
   Shrestha S, 2020, SCAND J GASTROENTERO, V55, P430, DOI 10.1080/00365521.2020.1740778
   Siming He, 2019, 2019 International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM). Proceedings, P392, DOI 10.1109/AIAM48774.2019.00083
   Simonyan K., 2015, VERY DEEP CONVOLUTIO, P1
   Tao LL, 2013, LECT NOTES COMPUT SC, V8151, P339, DOI 10.1007/978-3-642-40760-4_43
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Ng WL, 2011, LECT NOTES COMPUT SC, V6762, P285
   World health organization (WHO), 2015, DEAFN HEAR LOSS KEY
   Wu CH, 2016, MULTIMED TOOLS APPL, V75, P7065, DOI 10.1007/s11042-015-2632-3
   Xiao QK, 2020, NEURAL NETWORKS, V125, P41, DOI 10.1016/j.neunet.2020.01.030
   Xie B, 2018, J ENG-JOE, P1515, DOI 10.1049/joe.2018.8327
   Ying Wu, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P6, DOI 10.1109/ICIP.1999.817058
NR 53
TC 36
Z9 36
U1 3
U2 40
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 15
PY 2021
VL 182
AR 115657
DI 10.1016/j.eswa.2021.115657
EA AUG 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA UF2TZ
UT WOS:000688432600006
DA 2023-11-10
ER

PT J
AU Nguyen, NH
   Vo, DTD
   Nguyen, KV
   Nguyen, NLT
AF Nguyen, Nghia Hieu
   Vo, Duong T. D.
   Nguyen, Kiet Van
   Nguyen, Ngan Luu-Thuy
TI OpenViVQA: Task, dataset, and multimodal fusion models for visual
   question answering in Vietnamese
SO INFORMATION FUSION
LA English
DT Article
DE Visual question answering; Vision-language understanding; Low-resource
   languages; Information fusion; Multimodal representation
ID ATTENTION
AB In recent years, visual question answering (VQA) has attracted attention from the research community because of its highly potential applications (such as virtual assistance on intelligent cars, assistant devices for blind people, or information retrieval from document images using natural language as queries) and challenge. The VQA task requires methods that have the ability to fuse the information from questions and images to produce appropriate answers. Neural visual question answering models have achieved tremendous growth on large-scale datasets which are mostly for resource-rich languages such as English. However, available datasets narrow the VQA task as the answers selection task or answer classification task. We argue that this form of VQA is far from human ability and eliminates the challenge of the answering aspect in the VQA task by just selecting answers rather than generating them. In this paper, we introduce the OpenViVQA (Open-domain Vietnamese Visual Question Answering) dataset, the first large-scale dataset for VQA with open-ended answers in Vietnamese, consists of 11,000+ images associated with 37,000+ question-answer pairs (QAs). Moreover, we proposed FST, QuMLAG, and MLPAG which fuse information from images and questions, then use these fused features to construct answers as humans iteratively. Our proposed methods achieve results that are competitive with SOTA models such as SAAA, MCAN, LORA, and M4C. The dataset1 is available to encourage the research community to develop more generalized algorithms including transformers for low-resource languages such as Vietnamese.
C1 Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.
   Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
   [Nguyen, Kiet Van] Vietnam Natl Univ, Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City; Vietnam National University
   Hochiminh City
RP Nguyen, KV (通讯作者)，Vietnam Natl Univ, Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.
EM kietvn@uit.edu.vn
OI Hieu Nguyen, Nghia/0009-0008-9635-9232
FU Vietnam National University HoChiMinh City (VNU-HCM) [C2023-26-08]
FX Acknowledgments This research is funded by Vietnam National University
   HoChiMinh City (VNU-HCM) under grant number C2023-26-08.
CR Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2005, P ACL WORKSHOP INTRI
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Changpinyo S, 2023, Arxiv, DOI arXiv:2209.05401
   Cho JM, 2020, Arxiv, DOI arXiv:2009.11278
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Ganesan Kavita, 2018, Arxiv, DOI arXiv:1803.01937
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Honnibal Matthew, 2017, SPACY 2 NATURAL LANG
   Hu R., 2020, P IEEE CVF C COMP VI, P9992, DOI DOI 10.1109/CVPR42600.2020.01001
   Huang MX, 2022, PROC CVPR IEEE, P4583, DOI 10.1109/CVPR52688.2022.00455
   Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849
   Jiang H., 2020, P IEEE CVF C COMP VI, P10267
   Kantharaj S, 2022, Arxiv, DOI arXiv:2210.06628
   Kazemi V., 2017, SHOW ASK ATTEND ANSW
   Iwana BK, 2017, Arxiv, DOI arXiv:1610.09204
   Kingma D. P., 2014, C TRACK P
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Nguyen LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), P1
   Lu JS, 2022, Arxiv, DOI arXiv:2206.08916
   Lu JS, 2019, ADV NEUR IN, V32
   Lu JS, 2016, ADV NEUR IN, V29
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Mathew M, 2021, IEEE WINT CONF APPL, P2199, DOI 10.1109/WACV48630.2021.00225
   Mishra A., 2019, 2019 INT C DOC AN RE, P947, DOI DOI 10.1109/ICDAR.2019.00156
   Nguyen N., 2021, P IEEE C COMPUTER VI
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Ren S., 2015, P ADV NEUR INF PROC, V28, P1, DOI DOI 10.1109/TPAMI.2016.2577031
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Su WJ, 2020, Arxiv, DOI arXiv:1908.08530
   Tan H, 2019, Arxiv, DOI arXiv:1908.07490
   Tanaka R, 2021, AAAI CONF ARTIF INTE, V35, P13878
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Tran K.Q., 2021, P 35 PACIFIC ASIA C, P546
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vu T., 2018, P 2018 C N AM CHAPT, P56
   Wang ZR, 2022, Arxiv, DOI arXiv:2108.10904
   Worley P., 2015, J PHILOS SCH
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhang DX, 2019, INFORM FUSION, V52, P268, DOI 10.1016/j.inffus.2019.03.005
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhang WF, 2020, INFORM FUSION, V55, P116, DOI 10.1016/j.inffus.2019.08.009
   Zheng WB, 2021, INFORM FUSION, V67, P14, DOI 10.1016/j.inffus.2020.10.007
NR 59
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD DEC
PY 2023
VL 100
AR 101868
DI 10.1016/j.inffus.2023.101868
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P5DF2
UT WOS:001050867700001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Makrynioti, N
   Vassalos, V
AF Makrynioti, Nantia
   Vassalos, Vasilis
TI Declarative Data Analytics: A Survey
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Task analysis; Data analysis; Programming; Optimization; Mathematical
   model; Analytical models; Prediction algorithms; Declarative
   programming; data science; machine learning; large-scale analytics
ID LINEAR ALGEBRA
AB The area of declarative data analytics explores the application of the declarative paradigm on data science and machine learning. It proposes declarative languages for expressing data analysis tasks and develops systems which optimize programs written in those languages. The execution engine can be either centralized or distributed, as the declarative paradigm advocates independence from particular physical implementations. The survey explores a wide range of declarative data analysis frameworks by examining both the programming model and the optimization techniques used, in order to provide conclusions on the current state of the art in the area and identify open challenges.
C1 [Makrynioti, Nantia; Vassalos, Vasilis] Athens Univ Econ & Business, Dept Informat, Athens 10434, Greece.
C3 Athens University of Economics & Business
RP Makrynioti, N (通讯作者)，Athens Univ Econ & Business, Dept Informat, Athens 10434, Greece.
EM makriniotik@aueb.gr; vassalos@aueb.gr
OI Makrynioti, Nantia/0000-0002-0782-7997
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alexandrov A, 2016, SIGMOD REC, V45, P51, DOI 10.1145/2949741.2949754
   Alexandrov A, 2014, VLDB J, V23, P939, DOI 10.1007/s00778-014-0357-y
   [Anonymous], 2009, SIGKDD EXPLOR NEWSL, V11, P10, DOI DOI 10.1145/1656274.1656278
   [Anonymous], PYRO
   [Anonymous], 2008, OSDI 08
   [Anonymous], SPARK DATAFRAME API
   [Anonymous], SPARK SQL
   [Anonymous], 2015, P WORKSHOP MACHINE L
   [Anonymous], FLINK TABLE API
   [Anonymous], 2010, P 1 ACM S CLOUD COMP, DOI [10.1145/1807128.1807148, DOI 10.1145/1807128.1807148]
   [Anonymous], TENSORFLOW PROBABILI
   [Anonymous], APACHE MAHOUT
   Aref M, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1371, DOI 10.1145/2723372.2742796
   Armbrust M, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1383, DOI 10.1145/2723372.2742797
   Baydin AG, 2018, J MACH LEARN RES, V18
   Beyer KS, 2011, PROC VLDB ENDOW, V4, P1272
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bu YY, 2010, PROC VLDB ENDOW, V3, P285
   Cai Zhuhua, 2013, SIGMOD, DOI [DOI 10.1145/2463676.2465283, 10.1145/2463676]
   Chaiken R, 2008, PROC VLDB ENDOW, V1, P1265, DOI 10.14778/1454159.1454166
   Chaudhuri S, 1999, ACM T DATABASE SYST, V24, P177, DOI 10.1145/320248.320249
   Chen LJ, 2017, PROC VLDB ENDOW, V10, P1214, DOI 10.14778/3137628.3137633
   Chollet F., 2015, KERAS
   Davenport James H., 1988, COMPUTER ALGEBRA SYS
   De Sa C, 2016, SIGMOD REC, V45, P60, DOI [10.1145/2949741.2949756, 10.1145/3060586]
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Doulkeridis C, 2014, VLDB J, V23, P355, DOI 10.1007/s00778-013-0319-9
   Ekanayake J, 2010, P 19 ACM INT S HIGH, P810, DOI [DOI 10.1145/1851476.1851593, 10.1145/1851476.1851593]
   GAO ZJ, 2017, P ACM INT C MAN DAT, P961
   Ghoting A, 2011, PROC INT CONF DATA, P231, DOI 10.1109/ICDE.2011.5767930
   GRAEFE G, 1993, COMPUT SURV, V25, P73, DOI 10.1145/152610.152611
   GRAEFE G, 1994, IEEE T KNOWL DATA EN, V6, P120, DOI 10.1109/69.273032
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Hueske F, 2012, PROC VLDB ENDOW, V5, P1256
   Hueske F, 2013, PROC INT CONF DATA, P1292, DOI 10.1109/ICDE.2013.6544927
   Isard M., 2007, Operating Systems Review, V41, P59, DOI 10.1145/1272998.1273005
   Khamis MA, 2018, PODS'18: PROCEEDINGS OF THE 37TH ACM SIGMOD-SIGACT-SIGAI SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P325, DOI 10.1145/3196959.3196960
   Kifer M., 2018, DECLARATIVE LOGIC PR
   Kraska T., 2013, 6 BIENNIAL C INNOVAT
   Kumar A, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1969, DOI 10.1145/2723372.2723713
   Kumar A, 2015, SIGMOD REC, V44, P17, DOI 10.1145/2935694.2935698
   Kunft A, 2019, PROC VLDB ENDOW, V12, P1553, DOI 10.14778/3342263.3342633
   Li XP, 2017, PROC VLDB ENDOW, V10, P1933, DOI 10.14778/3137765.3137812
   Luo SY, 2017, PROC INT CONF DATA, P523, DOI 10.1109/ICDE.2017.108
   Makrynioti N, 2018, PROCEEDINGS OF THE SECOND WORKSHOP ON DATA MANAGEMENT FOR END-TO-END MACHINE LEARNING, DOI 10.1145/3209889.3209893
   Meng X., 2016, J MACH LEARN RES, V17, P1, DOI DOI 10.1145/2882903.2912565
   Olston C., 2008, P 2008 ACM SIGMOD IN, P1099, DOI DOI 10.1145/1376616.1376726
   Papadopoulos S, 2016, PROC VLDB ENDOW, V10, P349
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Reinwald, 2016, ABS160505826 CORR
   Rheinländer A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3078752
   Schleich M, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P3, DOI 10.1145/2882903.2882939
   Seib J., 1991, Proceedings of the Tenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, P241, DOI 10.1145/113413.113435
   Seide F, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2135, DOI 10.1145/2939672.2945397
   Soroush E, 2015, PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, DOI 10.1145/2791347.2791362
   Sparks ER, 2017, PROC INT CONF DATA, P535, DOI 10.1109/ICDE.2017.109
   Sparks ER, 2013, IEEE DATA MINING, P1187, DOI 10.1109/ICDM.2013.158
   Stonebraker Michael, 2011, Scientific and Statistical Database Management. Proceedings 23rd International Conference, SSDBM 2011, P1, DOI 10.1007/978-3-642-22351-8_1
   Thomas A, 2018, PROC VLDB ENDOW, V11, P2168, DOI 10.14778/3275366.3275367
   Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Valduriez, 2011, PRINCIPLES DISTRIBUT
   Zaharia M., 2010, P 2 USENIX C HOT TOP, P10
   Zdonik, 2015, P BIENN C INN DAT SY
   Zhou JR, 2010, PROC INT CONF DATA, P1060, DOI 10.1109/ICDE.2010.5447802
NR 66
TC 4
Z9 4
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD JUN 1
PY 2021
VL 33
IS 6
BP 2392
EP 2411
DI 10.1109/TKDE.2019.2958084
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SA8XU
UT WOS:000649587600006
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Roh, J
   Park, S
   Kim, BK
   Oh, SH
   Lee, SY
AF Roh, Jihyeon
   Park, Sungjin
   Kim, Bo-Kyeong
   Oh, Sang-Hoon
   Lee, Soo-Young
TI Unsupervised multi-sense language models for natural language processing
   tasks
SO NEURAL NETWORKS
LA English
DT Article
DE Language model; Neural language processing (NLP); Multi-sense word
   modeling
AB Existing language models (LMs) represent each word with only a single representation, which is unsuitable for processing words with multiple meanings. This issue has often been compounded by the lack of availability of large-scale data annotated with word meanings. In this paper, we propose a sense-aware framework that can process multi-sense word information without relying on annotated data. In contrast to the existing multi-sense representation models, which handle information in a restricted context, our framework provides context representations encoded without ignoring word order information or long-term dependency. The proposed framework consists of a context representation stage to encode the variable-size context, a sense-labeling stage that involves unsupervised clustering to infer a probable sense for a word in each context, and a multi-sense LM (MSLM) learning stage to learn the multi-sense representations. Particularly for the evaluation of MSLMs with different vocabulary sizes, we propose a new metric, i.e., unigram-normalized perplexity (PPLu), which is also understood as the negated mutual information between a word and its context information. Additionally, there is a theoretical verification of PPLu on the change of vocabulary size. Also, we adopt a method of estimating the number of senses, which does not require further hyperparameter search for an LM performance. For the LMs in our framework, both unidirectional and bidirectional architectures based on long short-term memory (LSTM) and Transformers are adopted. We conduct comprehensive experiments on three language modeling datasets to perform quantitative and qualitative comparisons of various LMs. Our MSLM outperforms single-sense LMs (SSLMs) with the same network architecture and parameters. It also shows better performance on several downstream natural language processing tasks in the General Language Understanding Evaluation (GLUE) and SuperGLUE benchmarks. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Roh, Jihyeon; Park, Sungjin; Lee, Soo-Young] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
   [Roh, Jihyeon; Park, Sungjin; Lee, Soo-Young] Korea Adv Inst Sci & Technol, Inst Artificial Intelligence, Daejeon, South Korea.
   [Kim, Bo-Kyeong] Korea Adv Inst Sci & Technol, Informat & Elect Res Inst, Daejeon, South Korea.
   [Oh, Sang-Hoon] Mokwon Univ, Div Informat & Commun Convergence Engn, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST); Korea Advanced Institute of
   Science & Technology (KAIST); Mokwon University
RP Lee, SY (通讯作者)，Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.; Lee, SY (通讯作者)，Korea Adv Inst Sci & Technol, Inst Artificial Intelligence, Daejeon, South Korea.
EM rohleejh@kaist.ac.kr; zxznm@kaist.ac.kr; bokyeong1015@gmail.com;
   shoh@kaist.ac.kr; sylee@kaist.ac.kr
RI Kim, Bo Kyeong/ABD-2089-2020
OI Oh, Sang-Hoon/0000-0002-2195-9056
FU Industrial Strategic Technology Development Program - Ministry of Trade,
   Industry and Energy (MOTIE, Korea) [10072064]; Institute of Information
   & Communications Technology Planning & Evaluation - Ministry of Science
   and ICT (MSIT, Korea) [2016-0-00562]
FX This work was jointly supported by the Industrial Strategic Technology
   Development Program (10072064, Development of Novel Artificial
   Intelligence Technologies to Assist Imaging Di-agnosis of Pulmonary,
   Hepatic, and Cardiac Diseases and their Integration into Commercial
   Clinical PACS Platforms) funded by the Ministry of Trade, Industry and
   Energy (MOTIE, Korea) and Institute of Information & Communications
   Technology Planning & Evaluation (2016-0-00562, Emotional Intelligence
   Technology to Infer Human Emotion and Carry on Dialogue Accordingly)
   funded by the Ministry of Science and ICT (MSIT, Korea) .
CR Aharoni Roee, 2020, P 58 ANN M ASS COMP, P7747, DOI [10.18653/v1/2020.acl-main.692, DOI 10.18653/V1/2020.ACL-MAIN.692]
   AlexWang Julian Michael, 2019, P NEURIPS
   Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2016, P 2016 C EMPIRICAL M, DOI [DOI 10.18653/V1/D16-1123, 10.18653/v1/d16-1123]
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2015, P 53 ANN M ASS COMP
   Ansell A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P563
   Bartunov S, 2016, JMLR WORKSH CONF PRO, V51, P130
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bird S, 2004, P ACL INTERACTIVE PO, P214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Botha JA, 2014, PR MACH LEARN RES, V32, P1899
   Cer D., 2017, P 11 INT WORKSHOP SE, P1, DOI [DOI 10.18653/V1/S17-2001, 10.1865/3v1/S17-2001]
   Cheng W.-C., 2014, 15 ANN C ISCA
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924
   Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Devlin J., 2018, ARXIV, V1, P4171
   Dolan B., 2005, 3 INT WORKSHOP PARAP
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Grave E., 2016, ARXIV161204426
   Guo J, 2014, P COLING, V2014, P497
   Huang L., 2019, P C EMP METH NAT LAN, P3509
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Inan H, 2016, ARXIV161101462 CORR
   Jain S., 2019, ARXIV190907746
   Jozefowicz Rafal, 2016, ARXIV PREPRINT ARXIV
   Khashabi D., 2018, P 2018 C N AM CHAPTE, V1, P252, DOI DOI 10.18653/V1/N18-1023
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   KVALSETH TO, 1987, IEEE T SYST MAN CYB, V17, P517, DOI 10.1109/TSMC.1987.4309069
   Li J., 2015, P 2015 C EMP METH NA, P1722, DOI [10.18653/v1/D15-1200, DOI 10.18653/V1/D15-1200]
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ma R, 2020, INT CONF ACOUST SPEE, P8129, DOI [10.1109/icassp40776.2020.9053503, 10.1109/ICASSP40776.2020.9053503]
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, P51, DOI DOI 10.18653/V1/K16-1006
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T., 2014, 3 INT C LEARN REPR I
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Miller George A., 1993, P WORKSH HUM LANG TE, P303
   Mou Lili, 2015, NATURAL LANGUAGE INF
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, P1059, DOI [DOI 10.3115/V1/D14-1113, 10.3115/v1/d14-1113]
   Panigrahi A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5692
   Peters M. E., 2018, ARXIV180205365
   Pilehvar MT, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1267
   Qiu L., 2016, P 2016 C EMP METH NA, P183, DOI DOI 10.18653/V1/D16-1018
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Reisinger J, 2010, HUMAN LANGUAGE TECHN, P109
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Song Linfeng, 2016, P 5 JOINT C LEXICAL, P85, DOI DOI 10.18653/V1/S16-2009
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Vaswani A, 2017, ADV NEUR IN, V30
   Vial L., 2019, ARXIV PREPRINT ARXIV
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang MX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1567
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   White Aaron Steven, 2017, P 8 INT JOINT C NAT, V8291, P996
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yuan D., 2016, PROC COLING, P1374
   Zhao R, 2017, IEEE-ACM T AUDIO SPE, V25, P248, DOI 10.1109/TASLP.2016.2632521
NR 68
TC 3
Z9 3
U1 2
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD OCT
PY 2021
VL 142
BP 397
EP 409
DI 10.1016/j.neunet.2021.05.023
EA JUN 2021
PG 13
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology
GA UJ9WU
UT WOS:000691628800001
PM 34139656
DA 2023-11-10
ER

PT J
AU Hagalisletto, AM
   Bjork, J
   Yu, IC
   Enger, P
AF Moen Hagalisletto, Anders
   Bjork, Joakim
   Yu, Ingrid Chieh
   Enger, Pal
TI Constructing and refining large-scale railway models represented by
   Petri nets
SO IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND
   REVIEWS
LA English
DT Article
DE adaptive and intuitive interfaces; maintenance; Petri nets; railway
   systems; refinement
AB A new method for rapid construction of large-scale executable railway models is presented. Computer systems for railway systems suffer from poor integration and lack of explicit understanding of the large amount of static and dynamic information in the railway. In this paper, we give solutions to both problems. It is shown how a component-oriented approach makes it easy to construct and refine basic railway models by effective methods, such that a variety of models with important properties can be maintained within the same framework. Basic railway nets are refined into several new kinds: nets that are safe, permit collision detection, include dine, and are sensitive to its surroundings. Since the underlying implementation language is Petri nets, large expressibility is combined with simplicity, and in addition, the analysis of the behavior of railway models comes gently.
C1 Univ Oslo, Dept Comp Sci, NO-0316 Oslo, Norway.
C3 University of Oslo
RP Hagalisletto, AM (通讯作者)，Univ Oslo, Dept Comp Sci, NO-0316 Oslo, Norway.
CR [Anonymous], P 2 WORKSH COMP SUPP
   BACK RJ, 1980, MATH CTR TRACTS, V131
   Barr M, 1990, CATEGORY THEORY COMP
   DECKNATEL D, 1999, FMRAILWORKSHOP 4 STO
   Fanti NP, 2003, IEEE SYS MAN CYBERN, P1866
   HAGALISLETTO AM, 2004, P C 2004 SYST MAN CY, P6212
   HIELSCHER W, 1998, WORKSH TUT PRACT US
   Hoare C. A. R., 1972, Acta Informatica, V1, P271, DOI 10.1007/BF00289507
   HORSTE MM, 1999, FMRAIL WORKSH 3 TOUL
   JENSEN K, 1997, EATCS MONOGRAPHS THE, V2
   JENSEN K, 1997, EATCS MONOGRAPHS THE, V1
   Kristoffersen T., 2003, Proceedings of the Estonian Academy of Sciences. Physics, Mathematics, V52, P378
   MALAVASI G, 1999, FMRAIL WORKSH 5 TOUL
   MORRIS JM, 1987, SCI COMPUT PROGRAM, V9, P287, DOI 10.1016/0167-6423(87)90011-6
   Pachl J., 2018, RAILWAY OPERATION CO
   Reisig W., 1998, LECT NOTES COMPUTER, V1492
   REN X, 1995, P 1995 IEEE INT C SY, V4, P3087
   SMITH E, 1998, LECT NOTES COMPUTER, V1491
   TANG L, P 2000 INT WORKSH AU, P92
   Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043
   VANDERAALST WMP, 1995, REAL-TIME SYST, V9, P241, DOI 10.1007/BF01088807
   YU IC, 2004, THESIS U OSLO NORWAY
NR 22
TC 23
Z9 25
U1 1
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1094-6977
EI 1558-2442
J9 IEEE T SYST MAN CY C
JI IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.
PD JUL
PY 2007
VL 37
IS 4
BP 444
EP 460
DI 10.1109/TSMCC.2007.897323
PG 17
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 184MC
UT WOS:000247644800002
DA 2023-11-10
ER

PT J
AU Wang, DQ
   Jing, BY
   Lu, CW
   Wu, JJ
   Liu, GN
   Du, CG
   Zhuang, FZ
AF Wang, Deqing
   Jing, Baoyu
   Lu, Chenwei
   Wu, Junjie
   Liu, Guannan
   Du, Chenguang
   Zhuang, Fuzhen
TI Coarse Alignment of Topic and Sentiment: A Unified Model for
   Cross-Lingual Sentiment Classification
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Data models; Task analysis; Semantics; Learning systems; Bridges;
   Logistics; Vocabulary; Coarse alignment; cross-lingual sentiment
   classification (CLSC); topic model
AB Cross-lingual sentiment classification (CLSC) aims to leverage rich-labeled resources in the source language to improve prediction models of a resource-scarce domain in the target language. Existing feature representation learning-based approaches try to minimize the difference of latent features between different domains by exact alignment, which is achieved by either one-to-one topic alignment or matrix projection. Exact alignment, however, restricts the representation flexibility and further degrades the model performances on CLSC tasks if the distribution difference between two language domains is large. On the other hand, most previous studies proposed document-level models or ignored sentiment polarities of topics that might lead to insufficient learning of latent features. To solve the abovementioned problems, we propose a coarse alignment mechanism to enhance the model's representation by a group-to-group topic alignment into an aspect-level fine-grained model. First, we propose an unsupervised aspect, opinion, and sentiment unification model (AOS), which trimodels aspects, opinions, and sentiments of reviews from different domains and helps capture more accurate latent feature representation by a coarse alignment mechanism. To further boost AOS, we propose ps-AOS, a partial supervised AOS model, in which labeled source language data help minimize the difference of feature representations between two language domains with the help of logistics regression. Finally, an expectation-maximization framework with Gibbs sampling is then proposed to optimize our model. Extensive experiments on various multilingual product review data sets show that ps-AOS significantly outperforms various kinds of state-of-the-art baselines.
C1 [Wang, Deqing; Lu, Chenwei; Du, Chenguang] Beihang Univ, Sch Comp Sci, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Jing, Baoyu] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
   [Wu, Junjie; Liu, Guannan] Beihang Univ, Sch Econ & Management, Beijing 100191, Peoples R China.
   [Jing, Baoyu; Liu, Guannan] Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100191, Peoples R China.
   [Zhuang, Fuzhen] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100864, Peoples R China.
   [Zhuang, Fuzhen] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Beihang University; Carnegie Mellon University; Beihang University;
   Beihang University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Zhuang, FZ (通讯作者)，Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100864, Peoples R China.
EM zhuangfuzhen@ict.ac.cn
RI wu, jun/ISB-8607-2023; wu, jd/IST-2336-2023; Jing, Baoyu/AAK-2157-2020;
   Wu, Jun/HJP-1242-2023
OI Jing, Baoyu/0000-0003-1564-6499; Wang, Deqing/0000-0001-6441-4390
FU National Key Research and Development Program of China [2018YFB1402800];
   National Natural Science Foundation of China [71501003, 71531001,
   71725002, U1636210, U1836206]; National Key R&D Program of China
   [2019YFB2101804]; Project of Youth Innovation Promotion Association CAS
   [2017146]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFB1402800 and in part by
   the National Natural Science Foundation of China under Grant 71501003.
   The work of Junjie Wu was supported in part by the National Key R&D
   Program of China under Grant 2019YFB2101804 and in part by the National
   Natural Science Foundation of China under Grant 71531001, Grant
   71725002, and Grant U1636210. The work of Fuzhen Zhuang was supported in
   part by the National Natural Science Foundation of China under Grant
   U1836206 and in part by the Project of Youth Innovation Promotion
   Association CAS under Grant 2017146.
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2004, PARAMETER ESTIMATION
   [Anonymous], 2013, P 6 ACM INT C ONWEB
   [Anonymous], 2010, P 19 ACM INT C INFOR, DOI DOI 10.1145/1871437.1871486
   [Anonymous], 2011, P 17 ACM SIGKDD INT
   Banea C., 2010, P 23 INT C COMPUTATI, P1
   Bao Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P239, DOI 10.1145/2505515.2505556
   Ben-David Shai, 2006, ADV NEURAL INFORM PR, P2
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blitzer J., 2006, P 2006 C EMPIRICAL M, P120
   Dai WY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P210
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Doyle G., 2009, P 26 ANN INT C MACHI, P281
   Fernández AM, 2016, J ARTIF INTELL RES, V55, P131, DOI 10.1613/jair.4762
   Ganin Y, 2016, J MACH LEARN RES, V17
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Gui L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P860
   Hermann KM, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P58
   Hu XG, 2016, KNOWL-BASED SYST, V97, P60, DOI 10.1016/j.knosys.2016.01.016
   Jain S., 2015, P 2015 C EMP METH NA, P159
   Jo Y, 2011, P 4 ACM INT C WEB SE, P815, DOI DOI 10.1145/1935826.1935932
   Li L., P AAAI
   Li S, 2017, IEEE T NEUR NET LEAR, V28, P1682, DOI 10.1109/TNNLS.2016.2538282
   Li T, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P716, DOI 10.1145/1571941.1572093
   Lin C., 2009, P 18 ACM C INF KNOWL, P375, DOI 10.1145/1645953.1646003
   Lin Z., 2014, P 23 ACM INT C C INF, P1089
   Lin Z, 2016, IEEE-ACM T AUDIO SPE, V24, DOI 10.1109/TASLP.2015.2512041
   Long M., 2012, SDM, P540
   Ma CL, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P649, DOI 10.1145/2740908.2741704
   Meng Xinfan, 2012, P ACL, V1, P572
   Mihalcea R., 2007, P 45 ANN M ASS COMPU, P976
   Paul M. J., 2009, P 2009 C EMP METH NA, P1408
   Porteous I, 2008, P 14 ACM SIGKDD INT, P569, DOI DOI 10.1145/1401890.1401960
   Prettenhofer P, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2036264.2036277
   Wan X., 2008, P C EMPIRICAL METHOD, P553
   Wan X., 2009, P JOINT C 47 ANN M A, V1, P235
   Wang H, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P933
   Xu RC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1415, DOI 10.18653/v1/P17-1130
   Zhao X., 2010, P 2010 C EMP METH NA, P56
   Zhou GY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1426
   Zhou HW, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P430
   Zhou X., 2016, P 2016 C EMPIRICAL M, P247, DOI [DOI 10.18653/V1/D16-1024, 10.18653/v1/d16-1024]
   Zhou XJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1403
   Zhuang F., 2010, PROC SIAM INT C DATA, P13
   Zhuang F., 2013, PROC 23TH INT JOINT, P1960
NR 45
TC 20
Z9 20
U1 7
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD FEB
PY 2021
VL 32
IS 2
BP 736
EP 747
DI 10.1109/TNNLS.2020.2979225
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QE6IX
UT WOS:000616310400022
PM 32287008
DA 2023-11-10
ER

PT J
AU Plappert, M
   Mandery, C
   Asfour, T
AF Plappert, Matthias
   Mandery, Christian
   Asfour, Tamim
TI Learning a bidirectional mapping between human whole-body motion and
   natural language using deep recurrent neural networks
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Human whole-body motion; Natural language; Sequence-to-sequence
   learning; Recurrent neural network
ID TASK
AB Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learfied end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2 846 human whole-body motions and 6 187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Plappert, Matthias; Mandery, Christian; Asfour, Tamim] Karlsruhe Inst Technol, High Performance Humanoid Technol H2T, Adenauerring 2,Bldg 50-20, D-76131 Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Plappert, M (通讯作者)，Karlsruhe Inst Technol, High Performance Humanoid Technol H2T, Adenauerring 2,Bldg 50-20, D-76131 Karlsruhe, Germany.
EM matthias.plappert@partner.kit.edu; mandery@kit.edu; asfour@kit.edu
OI Asfour, Tamim/0000-0003-4879-7680
FU H2T at KIT; German Research Foundation (Deutsche Forschungsgemeinschaft:
   DFG) under the Priority Program on Autonomous Learning [SPP 1527];
   European Union's Horizon 2020 Research and Innovation Programme and
   Seventh Framework Programme [643666, 611832]; H2020 Societal Challenges
   Programme [643666] Funding Source: H2020 Societal Challenges Programme
FX The research leading to these results has received funding from the H2T
   at KIT, the German Research Foundation (Deutsche Forschungsgemeinschaft:
   DFG) under the Priority Program on Autonomous Learning (SPP 1527), and
   the European Union's Horizon 2020 Research and Innovation Programme and
   Seventh Framework Programme under grant agreements No. 643666
   (I-Support) and No. 611832 (WALK-MAN).
CR [Anonymous], 2013, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2013.6638947
   [Anonymous], 2015, ARXIV151205287
   [Anonymous], 2017, CORR
   [Anonymous], 2015, CORR
   [Anonymous], DEEP LEARNING UNPUB
   Arie H, 2010, LECT NOTES COMPUT SC, V6353, P256
   Azad P, 2007, IEEE INT CONF ROBOT, P2558, DOI 10.1109/ROBOT.2007.363850
   Ba Jimmy Lei, 2016, ARXIV160706450
   Bandanau D., 2014, ARXIV PREPRINT ARXIV
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Billard A., 2008, SPRINGER HDB ROBOTIC, P1371, DOI [10.1007/978-3-540-30301-5_60, DOI 10.1007/978-3-540-30301-5_60]
   Calinon S, 2007, IEEE T SYST MAN CY B, V37, P286, DOI 10.1109/TSMCB.2006.886952
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Chung J., 2014, CORR
   Cooijmans T., 2016, ABS160309025 CORR
   Dillmann R, 2000, ROBOTICS RESEARCH, P229
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Donahue Jeff, 2015, NAACL HLT, P1494, DOI DOI 10.3115/V1/N15-1173
   Dozat T., TECH REP
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Field M, 2011, IND ROBOT, V38, P163, DOI 10.1108/01439911111106372
   Fragkiadaki K., 2015, CORR
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1162/089976600300015015, 10.1049/cp:19991218]
   Glorot Xavier, 2011, ICML, DOI DOI 10.1177/1753193411430810
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gu SX, 2016, PR MACH LEARN RES, V48
   Hassani K, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932710
   Herzog Dennis, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P339, DOI 10.1109/ICHR.2008.4756002
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Ioffe Sergey, 2015, ARXIV 1502 03167, P448
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kanda H, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1852
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, C TRACK P
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kulic D, 2008, INT J ROBOT RES, V27, P761, DOI 10.1177/0278364908091153
   KUNIYOSHI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P799, DOI 10.1109/70.338535
   Levine S, 2018, INT J ROBOT RES, V37, P421, DOI 10.1177/0278364917710318
   Levine S, 2015, IEEE INT CONF ROBOT, P156, DOI 10.1109/ICRA.2015.7138994
   Mandery C, 2016, IEEE T ROBOT, V32, P796, DOI 10.1109/TRO.2016.2572685
   Mandery C, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P329, DOI 10.1109/ICAR.2015.7251476
   Mandery C, 2015, IEEE-RAS INT C HUMAN, P1020, DOI 10.1109/HUMANOIDS.2015.7363479
   Medina J. R., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P1097, DOI 10.1109/ROMAN.2012.6343895
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mordatch I., 2015, ADV NEURAL INFORM PR, V28, P3132
   Ogata T, 2007, IEEE INT CONF ROBOT, P2156, DOI 10.1109/ROBOT.2007.363640
   Ogata T, 2013, PROCEEDINGS OF THE 2013 IEEE WORKSHOP ON ROBOTIC INTELLIGENCE IN INFORMATIONALLY STRUCTURED SPACE (RIISS), P89, DOI 10.1109/RiiSS.2013.6607934
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Plappert M., 2016, CORR
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schaal S, 2006, ADAPTIVE MOTION OF ANIMALS AND MACHINES, P261, DOI 10.1007/4-431-31381-8_23
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Takano Wataru, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P708, DOI 10.1109/ICHR.2008.4755976
   Takano W, 2006, IEEE INT CONF ROBOT, P3602, DOI 10.1109/ROBOT.2006.1642252
   Takano W, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1422
   Takano W, 2016, NEURAL NETWORKS, V80, P1, DOI 10.1016/j.neunet.2016.03.001
   Takano W, 2015, INT J ROBOT RES, V34, P1314, DOI 10.1177/0278364915587923
   Takano W, 2015, ROBOT AUTON SYST, V66, P75, DOI 10.1016/j.robot.2014.12.008
   Takano W, 2012, IEEE INT CONF ROBOT, P1232, DOI 10.1109/ICRA.2012.6225331
   Takano W, 2009, IEEE INT CONF ROBOT, P2490
   Taylor Graham W., 2006, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   Taylor Graham W, 2009, P 26 ANN INT C MACH, P1025, DOI DOI 10.1145/1553374.1553505
   Terlemez Ö, 2014, IEEE-RAS INT C HUMAN, P894, DOI 10.1109/HUMANOIDS.2014.7041470
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
NR 72
TC 44
Z9 44
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD NOV
PY 2018
VL 109
BP 13
EP 26
DI 10.1016/j.robot.2018.07.006
PG 14
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Robotics
GA GX2KG
UT WOS:000447547300002
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Zhao, YG
   Huang, SJ
   Dai, XY
   Chen, JJ
AF Zhao, Yinggong
   Huang, Shujian
   Dai, Xin-Yu
   Chen, Jiajun
TI Adaptation of Language Models for SMT Using Neural Networks with Topic
   Information
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Languages; Algorithms; Experiments; Statistical machine translation;
   feedforward neural network language model; topic model; multinomial
   logistic regression; joint representation
AB Neural network language models (LMs) are shown to be effective in improving the performance of statistical machine translation (SMT) systems. However, state-of-the-art neural network LMs usually use words before the current position as context and neglect global topic information, which can helpmachine translation (MT) systems to select better translation candidates from a higher perspective. In this work, we propose improvement of the state-of-the-art feedforward neural language model with topic information. Two main issues need to be tackled when adding topics into neural network LMs for SMT: one is how to incorporate topics to the neural network; the other is how to get target-side topic distribution before translation. We incorporate topics by appending topic distribution to the input layer of a feedforward LM. We adopt a multinomial logistic-regression (MLR) model to predict the target-side topic distribution based on source side information. Moreover, we propose a feedforward neural network model to learn joint representations on the source side for topic prediction. LM experiments demonstrate that the perplexity on validation set can be greatly reduced by the topic-enhanced feedforward LM, and the prediction of target-side topics can be improved dramatically with the MLR model equipped with the joint source representations. A final MT experiment, conducted on a large-scale Chinese-English dataset, shows that our feedforward LM with predicted topics improves the translation performance against a strong baseline.
C1 [Zhao, Yinggong; Huang, Shujian; Dai, Xin-Yu; Chen, Jiajun] Nanjing Univ, State Key Lab Novel Software Technol, 163 Xianlin Ave, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University
RP Huang, SJ (通讯作者)，Nanjing Univ, State Key Lab Novel Software Technol, 163 Xianlin Ave, Nanjing 210023, Jiangsu, Peoples R China.
EM zhaoyg@nlp.nju.edu.cn; huangsj@nju.edu.cn; daixinyu@nju.edu.cn;
   chenjj@nju.edu.cn
FU National Natural Science Foundation of China [61170181, 61300158];
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China [20110091110003]; Graduate Research and Innovation Projects in
   Jiangsu Province [CXZZ12_0058]
FX This work is supported by the National Natural Science Foundation of
   China (grant nos. 61170181, 61300158), Specialized Research Fund for the
   Doctoral Program of Higher Education of China (grant no. 20110091110003)
   and Graduate Research and Innovation Projects in Jiangsu Province (grant
   no. CXZZ12_0058).
CR [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], 2009, NIPS
   [Anonymous], 2011, P 49 ANN M ASS COMPU
   [Anonymous], 2008, P ACL
   [Anonymous], TR1098 HARV U CTR RE
   [Anonymous], 2010, INTERSPEECH 2010
   [Anonymous], 2013, P 1 INT C LEARN REPR
   [Anonymous], 2003, HLT NAACL 2003 HUMAN
   Auli M., 2013, P 2013 C EMPIRICAL M, V13, P1044
   Baltescu P, 2015, P NAACL HLT ASS COMP, P820
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Brown P. F., 1992, Computational Linguistics, V18, P31
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Devlin J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1370
   Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916
   Goodman Joshua, 2001, CL0108006 CORR
   Gulcehre Caglar, 2015, ABS150303535 CORR
   Gutmann M., 2010, P AISTATS
   Hu YN, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1166
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Le Q., 2014, P INT C MACH LEARN, P1188
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Luong T., 2014, ABS14108206 CORR
   Marcu Daniel, 2006, P 2006 C EMP METH NA, P44
   Mikolov T., 2012, STAT LANGUAGE MODELS
   Mikolov Tomas, 2012, SPOKEN LANGUAGE TECH
   Nair V., 2010, P 27 INT C MACHINE L
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Ruiz N., 2011, P 6 WORKSH STAT MACH, P294
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Son L. H., 2012, P 2012 C N AM CHAPT, P39
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tam Y. C., 2007, P ACL, P520
   Vaswani A., 2013, P 2013 C EMPIRICAL M, P1387
   Wang MX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1567
   Xiao X., 2012, P 50 ANN M ASS COMP, P750
   Xiong Deyi, 2013, TOPIC BASED COHERENC
   Yu Heng, 2013, P 6 INT JOINT C NAT, P447
   Zhang M, 2014, J ARTIF INTELL RES, V50, P1
   Zhao YG, 2014, LECT NOTES COMPUT SC, V8801, P175, DOI 10.1007/978-3-319-12277-9_16
NR 40
TC 1
Z9 1
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR
PY 2016
VL 15
IS 3
AR 19
DI 10.1145/2816816
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ0SB
UT WOS:000373913600009
DA 2023-11-10
ER

PT J
AU Blazy, S
   Leroy, X
AF Blazy, Sandrine
   Leroy, Xavier
TI Mechanized Semantics for the Clight Subset of the C Language
SO JOURNAL OF AUTOMATED REASONING
LA English
DT Article
DE The C programming language; Operational semantics; Mechanized semantics;
   Formal proof; The Coq proof assistant
ID FORMAL VERIFICATION; SEPARATION LOGIC; VIRTUAL MACHINE; MODEL; JAVA
AB This article presents the formal semantics of a large subset of the C language called Clight. Clight includes pointer arithmetic, struct and union types, C loops and structured switch statements. Clight is the source language of the CompCert verified compiler. The formal semantics of Clight is a big-step operational semantics that observes both terminating and diverging executions and produces traces of input/output events. The formal semantics of Clight is mechanized using the Coq proof assistant. In addition to the semantics of Clight, this article describes its integration in the CompCert verified compiler and several ways by which the semantics was validated.
C1 [Leroy, Xavier] INRIA Paris Rocquencourt, F-78153 Le Chesnay, France.
   [Blazy, Sandrine] ENSIIE, F-91025 Evry, France.
C3 Ecole Nationale Superieure d'Informatique pour l'Industrie et
   l'Entreprise (ENSIIE)
RP Leroy, X (通讯作者)，INRIA Paris Rocquencourt, BP 105, F-78153 Le Chesnay, France.
EM Sandrine.Blazy@ensiie.fr; Xavier.Leroy@inria.fr
OI Blazy, Sandrine/0000-0002-0189-0223
FU Agence Nationale de la Recherche [ANR-05-SSIA-0019]
FX This work was supported by Agence Nationale de la Recherche, grant
   number ANR-05-SSIA-0019.
CR Aiken A, 2007, PASTE'07 PROCEEDINGS OF THE 2007 ACM SIGPLAN- SIGSOFT WORKSHOP ON PROGRAM ANALYSIS FOR SOFTWARE TOOLS & ENGINEERING, P43, DOI 10.1145/1251535.1251543
   [Anonymous], DUFFS DEVICE
   [Anonymous], 1989, COQ PROOF ASSISTANT
   Appel AW, 2007, LECT NOTES COMPUT SC, V4732, P5
   APPEL AW, 2007, ELECT NOTES COMPUTER, V1745, P95
   Bertot Y., 2004, EATCS TEXTS THEORETI
   Bishop S, 2006, ACM SIGPLAN NOTICES, V41, P55, DOI 10.1145/1111320.1111043
   Blazy S, 2006, LECT NOTES COMPUT SC, V4085, P460
   Börger E, 2005, THEOR COMPUT SCI, V336, P235, DOI 10.1016/j.tcs.2004.11.008
   *CEA LIST, 2008, FRAMA C FRAM MOD AN
   CONDIT J, 2003, P ACM SIGPLAN 2003 C, P232
   Delahaye D, 2007, LECT NOTES COMPUT SC, V4732, P70
   Filliâtre JC, 2004, LECT NOTES COMPUT SC, V3308, P15
   Gimenez E., 2004, SEMANTICS SUBSET C L
   GREGOIRE B, 2002, INT C FUNCT PROGR 20, P235
   Gurevich Yuri, 1992, P CSL 92, V702, P274, DOI 10.1007/3-540-56992-8_17
   Hardekopf B, 2007, ACM SIGPLAN NOTICES, V42, P290, DOI 10.1145/1273442.1250767
   Hartel PH, 2001, ACM COMPUT SURV, V33, P517, DOI 10.1145/503112.503115
   Hatton L, 2004, INFORM SOFTWARE TECH, V46, P465, DOI 10.1016/j.infsof.2003.09.016
   Hoare T, 2008, ELECTRON NOTES THEOR, V212, P3, DOI 10.1016/j.entcs.2008.04.050
   Huisman M, 2000, LECT NOTES COMPUT SC, V1783, P284
   HYMANS C, 2008, 2008IWSE000101 EADS
   Klein G, 2006, ACM T PROGR LANG SYS, V28, P619, DOI 10.1145/1146809.1146811
   LEE DK, 2007, 34 S PRINC PROGR LAN, P173
   LEINENBACH D, 2005, INT C SOFTW ENG FORM, P2
   Leroy X, 2006, ACM SIGPLAN NOTICES, V41, P42, DOI 10.1145/1111320.1111042
   LEROY X, 2008, ARXIV09022137CS
   Leroy X, 2008, J AUTOM REASONING, V41, P1, DOI 10.1007/s10817-008-9099-0
   Leroy X, 2009, INFORM COMPUT, V207, P284, DOI 10.1016/j.ic.2007.12.004
   Milner Robin, 1997, DEFINITION STANDARD
   Necula GC, 2002, LECT NOTES COMPUT SC, V2304, P213
   Nepomniaschy VA, 2003, PROGRAM COMPUT SOFT+, V29, P338, DOI 10.1023/B:PACS.0000004134.24714.e5
   NIPKOW T, 2004, ISABELLE HOL PROOF A
   Norrish M, 1999, LECT NOTES COMPUT SC, V1576, P147
   Norrish Michael, 1998, UCAMCLTR453
   Owens S, 2008, LECT NOTES COMPUT SC, V4960, P1
   Papaspyrou Nikolaos S., 1998, THESIS NATL TU ATHEN
   Paul W., 2003, VERISOFT PROJECT
   Schirmer N, 2006, THESIS TU MUNCHEN
   Sen Koushik, 2005, SIGSOFT SOFTWARE ENG, P263, DOI 10.1145/1081706.1081750
   SEWELL P, 2007, P 12 ACM S PRINC PRO, P1
   STRECKER M, 2005, COMPILER VERIFICATIO
   TEWS H, 2008, NOVA MICROHYPERVISOR
   TEWS H, 2004, VERIFYING D IN PRESS
   Tews H, 2008, ELECTRON NOTES THEOR, V217, P79, DOI 10.1016/j.entcs.2008.06.043
   VANINWEGEN M, 1993, LECT NOTES COMPUTER, V780, P61, DOI DOI 10.1007/3-540-57826-9_125
   ZUCKER S, 1995, 802333410 SUNSOFT
NR 47
TC 87
Z9 101
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0168-7433
EI 1573-0670
J9 J AUTOM REASONING
JI J. Autom. Reasoning
PD OCT
PY 2009
VL 43
IS 3
BP 263
EP 288
DI 10.1007/s10817-009-9148-3
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 495RM
UT WOS:000269912700003
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Zahedi, M
   Keysers, D
   Ney, H
AF Zahedi, Morteza
   Keysers, Daniel
   Ney, Hermann
BE Gibet, S
   Courty, N
   Kamp, JF
TI Pronunciation clustering and modeling of variability for appearance
   based sign language recognition
SO GESTURE IN HUMAN-COMPUTER INTERACTION AND SIMULATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Gesture in Human-Computer Interaction and
   Simulation
CY MAY 18-20, 2005
CL Berder Isl, FRANCE
AB In this paper, we present a system for automatic sign language recognition of segmented words in American Sign Language (ASL). The system uses appearance- based features extracted directly from the frames captured by standard cameras without any special data acquisition tools. This means that we do not rely on complex preprocessing of the video signal or on an intermediate segmentation step that may produce errors. We introduce a database for ASL word recognition extracted from a publicly available set of video streams. One important property of this database is the large variability of the utterances for each word. To cope with this variability, we propose to model distinct pronunciations of each word using different clustering approaches. Automatic clustering of pronunciations improves the error rate of the system from 28.4% to 23.2%. To model global image transformations, the tangent distance is used within the Gaussian emission densities of the bidden Markov model classifier instead of the Euclidean distance. This approach can further reduce the error rate to 21.5%.
C1 Rhein Westfal TH Aachen, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany.
C3 RWTH Aachen University
RP Zahedi, M (通讯作者)，Rhein Westfal TH Aachen, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany.
EM zahedi@informatik.rwth-aachen.de; keysers@informatik.rwth-aachen.de;
   ney@informatik.rwth-aachen.de
OI Zahedi, Morteza/0000-0002-8648-4514
CR Bauer B, 2000, INT C PATT RECOG, P463, DOI 10.1109/ICPR.2000.906112
   Hanson S., 1993, ADV NEURAL INFORM PR, V5, P50
   Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   NAM Y, 1996, P ACM S VIRT REAL SO, P51
   Neidle C. J., 2000, SYNTAX AM SIGN LANGU
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Vogler C, 1997, IEEE SYS MAN CYBERN, P156, DOI 10.1109/ICSMC.1997.625741
   Zahedi M, 2005, LECT NOTES COMPUT SC, V3522, P511
NR 10
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-32624-3
J9 LECT NOTES ARTIF INT
PY 2006
VL 3881
BP 68
EP 79
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BEE94
UT WOS:000237042600008
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Tanti, M
   Gatt, A
   Camilleri, KP
AF Tanti, Marc
   Gatt, Albert
   Camilleri, Kenneth P.
TI Where to put the image in an image caption generator
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
AB When a recurrent neural network (RNN) language model is used for caption generation, the image information can be fed to the neural network either by directly incorporating it in the RNN - conditioning the language model by injecting' image features - or in a layer following the RNN - conditioning the language model by merging' image features. While both options are attested in the literature, there is as yet no systematic comparison between the two. In this paper, we empirically show that it is not especially detrimental to performance whether one architecture is used or another. The merge architecture does have practical advantages, as conditioning by merging allows the RNN's hidden state vector to shrink in size by up to four times. Our results suggest that the visual and linguistic modalities for caption generation need not be jointly encoded by the RNN as that yields large, memory-intensive models with few tangible advantages in performance; rather, the multimodal integration should be delayed to a subsequent stage.
C1 [Tanti, Marc; Gatt, Albert] Univ Malta, Inst Linguist & Language Technol, Msida Msd, Malta.
   [Camilleri, Kenneth P.] Univ Malta, Dept Syst & Control Engn, Msida Msd, Malta.
C3 University of Malta; University of Malta
RP Tanti, M (通讯作者)，Univ Malta, Inst Linguist & Language Technol, Msida Msd, Malta.
EM marc.tanti.06@um.edu.mt; albert.gatt@um.edu.mt;
   kenneth.camilleri@um.edu.mt
RI Camilleri, Kenneth P./AAJ-1468-2020; Gatt, Albert/HOH-4660-2023
OI Camilleri, Kenneth P./0000-0003-0436-6408; Gatt,
   Albert/0000-0001-6388-8244; Tanti, Marc/0000-0002-7156-0596
FU Endeavour Scholarship Scheme (Malta); European Union - European Social
   Fund (ESF)
FX The research in this paper is partially funded by the Endeavour
   Scholarship Scheme (Malta). Scholarships are part-financed by the
   European Union - European Social Fund (ESF) - Operational Programme II
   Cohesion Policy 2014-2020 "Investing in human capital to create more
   opportunities and promote the well-being of society".
CR Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, P65, DOI DOI 10.3115/1626355.1626389
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Chen X., 2015, P CVPR 15
   Chen X., 2014, 14115654 CORR, P1411
   Chung J., 2014, CORR
   Deng J., 2009, P CVPR 09
   Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100
   Diederik P. K., 2014, 14126980 CORR, V1412, P6980
   Donahue J., 2015, P CVPR 15
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Hendricks L. A., 2016, P CVPR 16
   Hessel J., 2015, 150802091 CORR
   Hodosh M., 2014, P TACL, V7, P67, DOI [10.1162/tacl_a_00166, DOI 10.1162/TACL_A_00166]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Karpathy A., 2015, P CVPR 15
   Kiros R., 2014, 14112539 CORR
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Lin C.-Y., 2004, P ACL 04
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S., 2016, 161200370 CORR
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Ma S., 2016, P ICME 16
   Mao J., 2015, P ICLR 15
   Mao J., 2015, P ICCV 15
   Mao J., 2014, P NIPS 14
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mnih A., 2007, P ICML 07
   Nina O., 2015, P ICICS 15
   Oruganti R. M., 2016, P ICIP 16
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Roy D, 2005, ARTIF INTELL, V167, P170, DOI 10.1016/j.artint.2005.04.007
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song M., 2016, P ICIP 16
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Vedantam R., 2015, P CVPR 15
   Vinyals O., 2015, P CVPR 15
   Wang M., 2016, P ICIP 16
   Wu Q., 2015, 150601144 CORR
   Xu K., 2015, P ICML 15
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You Q., 2016, P CVPR 16
   Zhou L., 2016, 160604621 CORR
NR 45
TC 39
Z9 39
U1 0
U2 9
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD MAY
PY 2018
VL 24
IS 3
SI SI
BP 467
EP 489
DI 10.1017/S1351324918000098
PG 23
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA GD7OU
UT WOS:000430702300006
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Allauzen, C
   Byrne, B
   de Gispert, A
   Iglesias, G
   Riley, M
AF Allauzen, Cyril
   Byrne, Bill
   de Gispert, Adria
   Iglesias, Gonzalo
   Riley, Michael
TI Pushdown Automata in Statistical Machine Translation
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This article describes the use of pushdown automata (PDA) in the context of statistical machine translation and alignment under a synchronous context-free grammar. We use PDAs to compactly represent the space of candidate translations generated by the grammar when applied to an input sentence. General-purpose PDA algorithms for replacement, composition, shortest path, and expansion are presented. We describe HiPDT, a hierarchical phrase-based decoder using the PDA representation and these algorithms. We contrast the complexity of this decoder with a decoder based on a finite state automata representation, showing that PDAs provide a more suitable framework to achieve exact decoding for larger synchronous context-free grammars and smaller language models. We assess this experimentally on a large-scale Chinese-to-English alignment and translation task. In translation, we propose a two-pass decoding strategy involving a weaker language model in the first-pass to address the results of PDA complexity analysis. We study in depth the experimental conditions and tradeoffs in which HiPDT can achieve state-of-the-art performance for large-scale SMT.
C1 [Allauzen, Cyril; Riley, Michael] Google Res, New York, NY 10011 USA.
   [Byrne, Bill; de Gispert, Adria; Iglesias, Gonzalo] Univ Cambridge, Cambridge CB2 1TN, England.
C3 Google Incorporated; University of Cambridge
RP Allauzen, C (通讯作者)，Google Res, 76 Ninth Ave, New York, NY 10011 USA.
EM allauzen@google.com; wjb31@eng.cam.ac.uk; ad465@eng.cam.ac.uk;
   gi212@eng.cam.ac.uk; riley@google.com
OI Byrne, William/0000-0003-1896-4492
FU European Union [FP7-ICT-2009-4, 247762]; GALE program of the Defense
   Advanced Research Projects Agency [HR0011-06-C-0022]; Google Faculty
   Research Award
FX The research leading to these results has received funding from the
   European Union Seventh Framework Programme (FP7-ICT-2009-4) under grant
   agreement number 247762, and was supported in part by the GALE program
   of the Defense Advanced Research Projects Agency, contract no.
   HR0011-06-C-0022, and a May 2010 Google Faculty Research Award.
CR Aho A. V., 1972, THEORY PARSING TRANS, V1
   Allauzen C, 2007, LECT NOTES COMPUT SC, V4783, P11
   Allauzen C, 2011, LECT NOTES COMPUT SC, V6482, P28, DOI 10.1007/978-3-642-18098-9_4
   Allauzen Cyril, 2011, PUSHDOWN TRANSDUCERS
   [Anonymous], 2010, P 2010 C EMPIRICAL M
   [Anonymous], P ACL HLT 2011 PORTL
   [Anonymous], 2007, ANN M ASS COMP LING
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   BARHILLEL Y, 1964, LANGUAGE INFORM SELE, P116
   Berstel J., 1979, TRANSDUCTIONS CONTEX
   Blackwood G, 2010, P ACL SHORT PAP UPPS, P27
   Chang Yin-Wen, 2011, P EMNLP, P26
   Chelba C., 2010, P INTERSPEECH, P2242
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Deng YG, 2008, IEEE T AUDIO SPEECH, V16, P494, DOI 10.1109/TASL.2008.916056
   Dyer Chris, 2010, P NAACL HLT LOS ANG, P263
   Dyer Chris, 2010, THESIS U MARYLAND
   Galley M, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P273
   Hopkins M., 2010, P 2010 C EMP METH NA, P646
   Huang Liang, 2010, P 2010 C EMP METH NA, P273
   Huang Liang, 2005, P 9 INT WORKSH PARS, P65
   Iglesias G, 2009, P EACL, P380
   IGLESIAS G, 2009, P NAACL, P433
   Iglesias Gonzalo, 2010, COMPUT LINGUIST, V36, P201
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kuich W., 1986, EATCS MONOGRAPHS THE, DOI [10.1007/978-3-642-69959-7, DOI 10.1007/978-3-642-69959-7]
   Kumar S, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P169
   Kumar S., 2006, Natural Language Engineering, V12, P35, DOI 10.1017/S1351324905003815
   Kumar Shankar, 2005, P HLT EMNLP VANC BRI, P161
   Lang Bernard, 1974, LECT NOTES COMPUTER, P255, DOI [DOI 10.1007/978-3-662-21545-6, DOI 10.1007/3-540-06841-4_65]
   Liang Huang, 2008, COLING 2008 ADV DYNA, P1
   Ljolje A., 1999, EUROSPEECH, P1251
   Mohri M., 2002, Journal of Automata, Languages and Combinatorics, V7, P321
   Mohri M, 2009, MONOGR THEOR COMPUT, P213, DOI 10.1007/978-3-642-01492-5_6
   Nederhof M. J., 2003, P 8 INT WORKSH PARS, P137
   Nederhof MJ, 2006, J ACM, V53, P406, DOI 10.1145/1147954.1147959
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Petre I, 2009, MONOGR THEOR COMPUT, P257, DOI 10.1007/978-3-642-01492-5_7
   Prasad R, 2007, PROCEEDINGS ELMAR 2007, P1, DOI 10.1145/1364654.1364674
   Roark Brian, 2013, P 51 ANN M ASS COMP, P43
   Rush A.M., 2011, P ACL HLT, P72
   Satta Giorgio, 2005, HUM LANG TECHN C C E, P803
   Shafran I., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P283, DOI 10.1109/ASRU.2011.6163945
   STOLCKE A, 1995, COMPUT LINGUIST, V21, P165
   Stolcke Andreas, 1998, P DARPA BROADC NEWS, P270
   Tromble Roy, 2008, P 2008 C EMP METH NA, P620, DOI DOI 10.3115/1613715.1613792
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   Xiao Tong, 2009, P C EMP METH NAT LAN, P362
   Zens R, 2008, INT WORKSH SPOK LANG, P195
   Zhang Hao, 2006, P HUM LANG TECHN C N, P256
   Zollmann A., 2006, P WORKSH STAT MACH T, P138
NR 52
TC 7
Z9 7
U1 0
U2 16
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2014
VL 40
IS 3
BP 687
EP 723
DI 10.1162/COLI_a_00197
PG 37
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA AP1PP
UT WOS:000341843500008
OA Green Submitted, hybrid, Green Published
DA 2023-11-10
ER

PT S
AU Fomichov, VA
AF Fomichov, VA
BE Bauknecht, K
   Proll, B
   Werthner, H
TI Standard K-languages as a powerful and flexible tool for building
   contracts and representing contents of arbitrary e-negotiations
SO E-COMMERCE AND WEB TECHNOLOGIES, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 6th International Conference on E-Commerce and Web Technologies (EC-Web
   2005)
CY AUG 23-26, 2005
CL Copenhagen, DENMARK
ID SYSTEMS; CALCULUSES; DESIGN
AB The paper discusses a new class of formal languages called standard K-languages (SK-languages) as a powerful tool for building contracts concluded by computer intelligent agents and representing contents of arbitrary e-negotiations. The definition of SK-languages is a part of a mathematical model describing a system consisting of such 10 operations on structured meanings (SMs) of natural language texts (NL-texts) that, using primitive conceptual items as "blocks", it is possible to build SMs of, probably, arbitrary NL-texts. This means that a class of languages is determined being convenient for building semantic descriptions of arbitrary goods, services, and contracts. The principal advantages of SK-languages in comparison with first-order logic, Discourse Representation Theory, Theory of Conceptual Graphs, and Episodic Logic concern representing complicated goals and destinations of things, definitions of concepts, compound definitions of sets, and meanings of discourses with the references to the meaning of a phrase or larger part of discourse.
C1 Tech Univ, Moscow State Inst Elect & Math, Fac Appl Math, Moscow 109028, Russia.
   KE Tsiolkovsky Russian State Technol Univ, Dept Informat Technol, Moscow 121552, Russia.
C3 Moscow Aviation Institute
RP Fomichov, VA (通讯作者)，Tech Univ, Moscow State Inst Elect & Math, Fac Appl Math, Moscow 109028, Russia.
EM vdrfom@aha.ru
RI Fomichov, Vladimir/K-4918-2019
OI Fomichov, Vladimir/0000-0001-6355-3268
CR *CROSSFL PROJ, 1999, INS REQ CROSSFL CONS
   FOMICHOV V, 1994, CYBERNETICA, V37, P145
   Fomichov V. A., 1998, Informatica, V22, P451
   FOMICHOV VA, 1993, CYBERNETICA, V36, P161
   Fomichov VA, 2002, LECT NOTES ARTIF INT, V2522, P183
   FOMICHOV VA, 2000, SPECIAL ISSUE DATABA, V24, P39
   FOMICHOV VA, 2002, MATH FDN REPRESENTIN, P34
   FOMICHOV VA, 2002, P FOC S COLL DEC SUP, P91
   FOMICHOV VA, 2002, MATH FDN REPRESENTIN, P16
   FOMICHOV VA, 1996, J COMPUTING INFORMAT, V20, P5
   Hasselbring W, 2001, IND MANAGE DATA SYST, V101, P217, DOI 10.1108/02635570110394644
   Kamp H., 1996, Journal of Logic, Language and Information, V5, P297, DOI 10.1007/BF00159343
   Kimbrough SO, 1997, ACM T INFORM SYST, V15, P321, DOI 10.1145/263479.263480
   Schubert LK, 2000, NATURAL LANGUAGE PROCESSING AND KNOWLEDGE REPRESENTATION, P111
   Sowa J. F., 2000, KNOWLEDGE REPRESENTA
   XU L, 2003, CONCEPT MONITORING E
NR 16
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-28467-2
J9 LECT NOTES COMPUT SC
PY 2005
VL 3590
BP 138
EP 147
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BCY29
UT WOS:000231851100014
DA 2023-11-10
ER

PT S
AU Wohed, P
   van der Aalst, WMP
   Dumas, M
   ter Hofstede, AHM
   Russell, N
AF Wohed, P.
   van der Aalst, W. M. P.
   Dumas, M.
   ter Hofstede, A. H. M.
   Russell, N.
BE Dustdar, S
   Fiadeiro, JL
   Sheth, A
TI On the suitability of BPMN for business process modelling
SO BUSINESS PROCESS MANAGEMENT, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Business Process Management
CY SEP 05-07, 2006
CL Vienna, AUSTRIA
SP Ultimus, Austrian Comp Soc, Stadt WIEN, TU WIEN
DE BPMN; Business Process Modelling; Workflow Patterns
ID WORKFLOW; IDENTIFICATION; REPRESENTATION; PATTERNS
AB In this paper we examine the suitability of the Business Process Modelling Notation (BPMN) for business process modelling, using the Workflow Patterns as an evaluation framework. The Workflow Patterns are a collection of patterns developed for assessing control-flow, data and resource capabilities in the area of Process Aware Information Systems (PAISs). In doing so, we provide a comprehensive evaluation of the capabilities of BPMN, and its strengths and weaknesses when utilised for business process modelling. The analysis provided for BPMN is part of a larger effort aiming at an unbiased and vendor-independent survey of the suitability and the expressive power of some mainstream process modelling languages. It is a sequel to previous work in which languages including BPEL and UML Activity Diagrams were evaluated.
C1 QUT, Fac Informat Technol, Brisbane, Qld, Australia.
C3 Queensland University of Technology (QUT)
EM petia@dsv.su.se; w.m.p.v.d.aalst@tm.tue.n1; m.dumas@qut.edu.au;
   a.terhofstede@qut.edu.au; n.russell@qut.edu.au
RI van der Aalst, Wil/G-1248-2011; Hofstede, Arthur HM ter/I-9787-2012;
   Dumas, Marlon/H-2757-2015
OI van der Aalst, Wil/0000-0002-0955-6940; Hofstede, Arthur HM
   ter/0000-0002-2730-0201; Dumas, Marlon/0000-0002-9247-7476; Wohed,
   Petia/0000-0001-9154-2064
CR [Anonymous], 2004, BUSINESS PROCESS MOD
   [Anonymous], 2004, WORKFLOW HDB
   [Anonymous], 1996, WORKFLOW MANAGEMENT
   Kloppmann M, 2005, WS BPEL EXTENSION PE
   MULYAR NA, 2005, BPM0524 BPM CTR ORG
   OUYANG C, 2006, IN PRESS P 18 INT C
   Recker J., 16 AUSTR C INF SYST
   Russell N, 2005, LECT NOTES COMPUT SC, V3716, P353
   Russell N, 2005, LECT NOTES COMPUT SC, V3520, P216
   Russell N, 2006, CONCEPTUAL MODELLING, P95
   van der Aalst WMP, 2005, LECT NOTES COMPUT SC, V3670, P35
   Van der Aalst WMP, 2003, DISTRIB PARALLEL DAT, V14, P5, DOI 10.1023/A:1022883727209
   WfMC, 1999, WFMCTC1011
   Wohed P, 2005, LECT NOTES COMPUT SC, V3716, P63
   Wohed P, 2003, LECT NOTES COMPUT SC, V2813, P200
   WOHED P, 2005, BPM0526 BPM CTR ORG
   Wynn MT, 2005, LECT NOTES COMPUT SC, V3536, P423
   [No title captured]
NR 18
TC 149
Z9 149
U1 3
U2 35
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-38901-6
J9 LECT NOTES COMPUT SC
PY 2006
VL 4102
BP 161
EP 176
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFD25
UT WOS:000241137100012
DA 2023-11-10
ER

PT J
AU Xu, XH
   Chai, JY
   Chen, XH
AF Xu, Xuanhua
   Chai, Junyi
   Chen, Xiaohong
TI A hesitation-feedback recommendation approach and its application in
   large-scale group emergency decision making
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Consensus modelling; Decision making; Emergency decision; Large-scale
   group; Natural language preferences
ID SUPPLIER SELECTION; CONSENSUS MODEL; FUZZY
AB Group Decision Making (GDM) has been well studied in the last two decades. Yet, two challenges exist: (a) how to resolve large-scale groups in GDM and achieve the consensus of preferences and (b) how to conduct GDM under risk and emergency conditions. In this paper, we develop a complete problem-solving approach for GDM that orients twofold settings of the complex large-scale group and the time-sensitive emergency decision sce-narios. The crux of the matter is to design a feasible mechanism of group consensus strategies in the environment of time pressure and natural language preferences. To solve this problem, we propose a closed-loop mechanism of feedback recommendation strategies accompanied with a new subgroup identification method. This mechanism is underlain by a fourfold decomposition of complex large-scale groups, which entails multiple thresholds of group consensus, group hesitation, and time-related iteration of loops. Our mechanism and the whole GDM approach thoroughly orient the most intuitive representation of preferences -human natural language, which can be elicited and quantitatively formulated in probability linguistic preference systems. We illustrate the proposed approach through a real case study of China's fight against the COVID-19 epidemic. We verify that our mech-anism can perfectly tradeoff between the effectiveness and the efficiency of complex large-scale GDM under risk and emergency. The results of this research provide proposals for mechanisms on large-scale GDM and are ex-pected to contribute to emergency management such as epidemic controls, anti-terrorism, and other man-made or natural hazards.
C1 [Xu, Xuanhua; Chen, Xiaohong] Cent South Univ, Sch Business, Changsha, Peoples R China.
   [Chai, Junyi] BNU HKBU United Int Coll, Fac Business & Management, Zhuhai, Peoples R China.
   [Chen, Xiaohong] Hunan Univ Technol & Business, Sch Frontier Interdisciplinary, Changsha, Peoples R China.
C3 Central South University; Beijing Normal University - Hong Kong Baptist
   University United International College; Hunan University of Technology
   & Business
RP Chai, JY (通讯作者)，BNU HKBU United Int Coll, Fac Business & Management, Zhuhai, Peoples R China.
EM xuxh@csu.edu.cn; donchaiam@gmail.com; cxh@csu.edu.cn
RI Chai, Junyi Don/E-9396-2017
OI Chai, Junyi Don/0000-0003-1560-845X
FU National Natural Science Foundation of China [71971217, 72271032]; Major
   Project of the Natural Science Foundation of China [72091515, 71790615];
   Independent Exploration of Innovation Project for Postgraduate of
   Central South University [2018zzts300]; Guangdong Higher Education
   Upgrading Plan (2021-2025) of "Rushing to the Top, Making Up
   Shortcomings and Strengthening Special Features" [UICR0400027-21,
   UICR0400042-21CTL]; 2020 Scientific Research Platforms and Projects of
   Guangdong Provincial Education Department [2020WQNCX069]
FX This work was supported by grants from the National Natural Science
   Foundation of China (No. 71971217, 72271032), the Major Project of the
   Natural Science Foundation of China (No. 72091515, 71790615), the
   Independent Exploration of Innovation Project for Postgraduate of
   Central South University (2018zzts300). We also thank the grants from
   the Guangdong Higher Education Upgrading Plan (2021-2025) of "Rushing to
   the Top, Making Up Shortcomings and Strengthening Special Features" with
   No. of UICR0400027-21 and UICR0400042-21CTL, as well as 2020 Scientific
   Research Platforms and Projects of Guangdong Provincial Education
   Department with No. of 2020WQNCX069.
CR [Anonymous], 2008, DECIS ANAL, DOI [10.1287/deca.1080.0119, DOI 10.1287/DECA.1080.0119]
   Arrow Kenneth J., 1951, SOCIAL CHOICE INDIVI
   Baker RE, 2020, P NATL ACAD SCI USA, V117, P30547, DOI 10.1073/pnas.2013182117
   Bell D.E., 1988, DECISION MAKING DESC, DOI DOI 10.1017/CBO9780511598951.003
   Bonacich P, 2001, SOC NETWORKS, V23, P191, DOI 10.1016/S0378-8733(01)00038-7
   Cai CG, 2017, SOFT COMPUT, V21, P5765, DOI 10.1007/s00500-016-2155-5
   Chai J., 2021, INT C IND ENG ENGINE
   Chai J., 2021, MACHINE LEARNING APP, V6
   Chai JY, 2021, J RISK FINANC MANAG, V14, DOI 10.3390/jrfm14100490
   Chai JY, 2021, EUR J OPER RES, V288, P692, DOI 10.1016/j.ejor.2020.06.009
   Chai JY, 2020, DECIS SUPPORT SYST, V128, DOI 10.1016/j.dss.2019.113166
   Chai JY, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112903
   Chai JY, 2016, J MATH PSYCHOL, V75, P10, DOI 10.1016/j.jmp.2015.10.007
   Chai JY, 2016, EXPERT SYST APPL, V45, P223, DOI 10.1016/j.eswa.2015.09.051
   Chai JY, 2015, INT J PROD ECON, V166, P215, DOI 10.1016/j.ijpe.2014.09.035
   Chai JY, 2013, INT J MACH LEARN CYB, V4, P427, DOI 10.1007/s13042-012-0105-9
   Chai JY, 2013, EXPERT SYST APPL, V40, P3872, DOI 10.1016/j.eswa.2012.12.040
   Chai JY, 2013, EXPERT SYST APPL, V40, P1959, DOI 10.1016/j.eswa.2012.10.003
   Chai JY, 2012, INT J UNCERTAIN FUZZ, V20, P451, DOI 10.1142/S0218488512500237
   Chen X, 2021, IEEE T SYST MAN CY-S, V51, P2299, DOI 10.1109/TSMC.2019.2912231
   Chen XF, 2022, INT J FUZZY SYST, V24, P909, DOI 10.1007/s40815-021-01163-1
   Cheng LC, 2016, EUR J OPER RES, V254, P622, DOI 10.1016/j.ejor.2016.04.004
   Dias LC, 2012, DECIS ANAL, V9, P231, DOI 10.1287/deca.1120.0244
   Dong QX, 2016, EUR J OPER RES, V250, P521, DOI 10.1016/j.ejor.2015.09.016
   Dong YC, 2021, IEEE T SYST MAN CY-S, V51, P6304, DOI 10.1109/TSMC.2019.2961752
   Fehr E, 1999, Q J ECON, V114, P817, DOI 10.1162/003355399556151
   Gilboa I., 2009, THEORY DECISION UNCE
   Hausken K, 2009, INT SER OPER RES MAN, V128, P65
   Herrera-Viedma E, 2021, IEEE T SYST MAN CY-S, V51, P191, DOI 10.1109/TSMC.2020.3043016
   Huang J, 2020, FRONT BUS RES CHINA, V14, DOI 10.1186/s11782-020-00082-6
   Keck S, 2014, J ECON BEHAV ORGAN, V103, P60, DOI 10.1016/j.jebo.2014.03.026
   Keeney RL, 2013, DECIS ANAL, V10, P103, DOI 10.1287/deca.2013.0265
   KEENEY RL, 1976, MANAGE SCI, V23, P140, DOI 10.1287/mnsc.23.2.140
   Keynes JM., 1921, TREATISE PROBABILITY
   Knight Frank H., 1971, RISK UNCERTAINTY PRO
   Li AM, 2015, IND MANAGE DATA SYST, V115, P1251, DOI 10.1108/IMDS-04-2015-0130
   Li GX, 2022, IEEE T SYST MAN CY-S, V52, P3391, DOI 10.1109/TSMC.2021.3068759
   Li GX, 2018, IEEE T SYST MAN CY-S, V48, P982, DOI 10.1109/TSMC.2016.2627050
   Li SL, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105132
   Liu BS, 2019, EUR J OPER RES, V275, P737, DOI 10.1016/j.ejor.2018.11.075
   Liu Y, 2014, COMPUT OPER RES, V42, P75, DOI 10.1016/j.cor.2012.08.008
   Pan XH, 2022, IEEE T FUZZY SYST, V30, P108, DOI 10.1109/TFUZZ.2020.3032794
   Pang Q, 2016, INFORM SCIENCES, V369, P128, DOI 10.1016/j.ins.2016.06.021
   Rodríguez RM, 2018, KNOWL-BASED SYST, V159, P86, DOI 10.1016/j.knosys.2018.06.009
   Sun Q, 2022, IEEE T FUZZY SYST, V30, P1287, DOI 10.1109/TFUZZ.2021.3057705
   Tang M, 2021, J OPER RES SOC, V72, P865, DOI 10.1080/01605682.2019.1708823
   Tang M, 2020, EUR J OPER RES, V282, P957, DOI 10.1016/j.ejor.2019.10.006
   TVERSKY A, 1992, J RISK UNCERTAINTY, V5, P297, DOI 10.1007/BF00122574
   Wakker Peter P., 2010, PROSPECT THEORY RISK, DOI [10.1017/CBO9780511779329, DOI 10.1017/CBO9780511779329]
   Wang P, 2018, IEEE T FUZZY SYST, V26, P3314, DOI 10.1109/TFUZZ.2018.2822242
   Wu J, 2022, IEEE T CYBERNETICS, V52, P11081, DOI 10.1109/TCYB.2021.3076420
   Wu J, 2021, IEEE T FUZZY SYST, V29, P1750, DOI 10.1109/TFUZZ.2020.2985331
   Wu ZB, 2018, INFORM FUSION, V41, P217, DOI 10.1016/j.inffus.2017.09.011
   Xiao J, 2020, INFORM FUSION, V53, P20, DOI 10.1016/j.inffus.2019.06.003
   Xu XH, 2015, DECIS SUPPORT SYST, V79, P150, DOI 10.1016/j.dss.2015.08.009
   Xu XH, 2015, KNOWL-BASED SYST, V86, P237, DOI 10.1016/j.knosys.2015.06.006
   Xu XH, 2019, KNOWL-BASED SYST, V163, P495, DOI 10.1016/j.knosys.2018.09.010
   Xu ZS, 2005, OMEGA-INT J MANAGE S, V33, P249, DOI 10.1016/j.omega.2004.04.008
   Zhang HJ, 2018, IEEE T FUZZY SYST, V26, P884, DOI 10.1109/TFUZZ.2017.2697403
NR 59
TC 2
Z9 2
U1 38
U2 102
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 1
PY 2023
VL 213
AR 118876
DI 10.1016/j.eswa.2022.118876
EA SEP 2022
PN A
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA 5H2TX
UT WOS:000867537300013
DA 2023-11-10
ER

PT J
AU Kuncoro, A
   Kong, LP
   Fried, D
   Yogatama, D
   Rimell, L
   Dyer, C
   Blunsom, P
AF Kuncoro, Adhiguna
   Kong, Lingpeng
   Fried, Daniel
   Yogatama, Dani
   Rimell, Laura
   Dyer, Chris
   Blunsom, Phil
TI Syntactic Structure Distillation Pretraining for Bidirectional Encoders
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Textual representation learners trained on large amounts of data have achieved notable success on downstream tasks; intriguingly, they have also performed well on challenging tests of syntactic competence. Hence, it remains an open question whether scalable learners like BERT can become fully proficient in the syntax of natural language by virtue of data scale alone, or whether they still benefit from more explicit syntactic biases. To answer this question, we introduce a knowledge distillation strategy for injecting syntactic biases into BERT pretraining, by distilling the syntactically informative predictions of a hierarchical-albeit harder to scale-syntactic language model. Since BERT models masked words in bidirectional context, we propose to distill the approximate marginal distribution over words in context from the syntactic LM. Our approach reduces relative error by 2-21% on a diverse set of structured prediction tasks, although we obtain mixed results on the GLUE benchmark. Our findings demonstrate the benefits of syntactic biases, even for representation learners that exploit large amounts of data, and contribute to a better understanding of where syntactic biases are helpful in benchmarks of natural language understanding.
C1 [Kuncoro, Adhiguna; Kong, Lingpeng; Yogatama, Dani; Rimell, Laura; Dyer, Chris; Blunsom, Phil] DeepMind, London, England.
   [Kuncoro, Adhiguna; Blunsom, Phil] Univ Oxford, Dept Comp Sci, Oxford, England.
   [Fried, Daniel] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
C3 University of Oxford; University of California System; University of
   California Berkeley
RP Kuncoro, A (通讯作者)，DeepMind, London, England.; Kuncoro, A (通讯作者)，Univ Oxford, Dept Comp Sci, Oxford, England.
EM fakuncoro@google.com; lingpenk@google.com; dfried@cs.berkeley.edu;
   dyogatama@google.com; laurarimell@google.com; cdyer@google.com;
   pblunsom@google.com
FU EPSRC Doctoral Training Partnership studentship; BalliolMark Sadler
   scholarship; Google PhD Fellowship
FX We would like to thank Mandar Joshi, Zhaofeng Wu, Rui Zhang, Timothy
   Dozat, and Kenton Lee for answering questions regarding the evaluation
   of the model. We also thank Sebastian Ruder, John Hale, Kris Cao,
   Stephen Clark, and the three anonymous reviewers for their helpful
   suggestions. A. K. is supported by an EPSRC Doctoral Training
   Partnership studentship and a BalliolMark Sadler scholarship; D. F. is
   supported by a Google PhD Fellowship.
CR Adi Yossi, 2017, INT C LEARN REPR
   Andor D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2442
   Bangalore S, 1999, COMPUT LINGUIST, V25, P237
   Belinkov Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P861, DOI 10.18653/v1/P17-1080
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464
   Charniak Eugene., 1997, P 14 NAT C ART INT, V2005, P18, DOI DOI 10.5555/1867406.1867499
   Choe D. K., 2016, P 2016 C EMP METH NA, P2331, DOI [DOI 10.18653/V1/D16-1257, 10.18653/v1/D16-1257]
   Clark S, 2007, COMPUT LINGUIST, V33, P493, DOI 10.1162/coli.2007.33.4.493
   De Marneffe Marie-Catherine, 2008, TECHNICAL REPORT
   Devlin J., 2018, ARXIV, V1, P4171
   Dyer C., 2016, P 2016 C N AM CHAPT, P199, DOI [10.18653/v1/N16-1024, DOI 10.18653/V1/N16-1024]
   Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334
   Fowlie Meaghan, 2017, THESIS
   Francis W. N., 1979, MANUAL INFORM ACCOMP
   Fried D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P323
   Furlanello T, 2018, INT C MACHINE LEARNI, P1607
   Futrell R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P32
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P1
   Gildea D, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P167
   Goldberg Yoav, 2019, ABS190105287 ARXIV
   He Luheng, 2017, P 55 ANN M ASS COMP, V1, P473, DOI DOI 10.18653/v1/P17-1044
   He SX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2061
   Hewitt J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2733
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton Geoffrey, 2015, ARXIV150302531
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1725
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kim Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1105
   Kim Yoon, 2016, ARXIV160607947, DOI DOI 10.18653/V1
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Kuncoro A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1249
   Kuncoro A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1426
   Kuncoro Adhiguna, 2019, P ACL, DOI [10.18653/v1/P19-1337, DOI 10.18653/V1/P19-1337]
   Lan Zhenzhong, 2019, ARXIV190911942
   Lee Kenton, 2018, P 2018 C NAACL HUM L, P687, DOI [10.18653/v1/N18-2108, DOI 10.18653/V1/N18-2108]
   Levesque H. J., 2012, P INT WORKSHOP TEMPO, P552
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI DOI 10.1353/LAN.2019.0015
   Liu J., 2017, T ASSOC COMPUT LING, V5, P413, DOI DOI 10.1162/TACL_A_00070
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu Yinhan, 2019, ARXIV190711692
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192
   McClosky D., 2006, P MAIN C HUM LANG TE, P152, DOI DOI 10.3115/1220835.1220855
   McClosky D., 2008, P 22 INT C COMP LING, P561, DOI DOI 10.3115/1599081.1599152
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Neubig G, 2017, ADV NEUR IN, V30
   Neubig Graham, 2017, ARXIV170103980
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Petrov S., 2012, P NOT 1 WORKSH SYNT, V59, P1
   Pollard C, 1994, HEAD DRIVEN PHRASE S
   Pradhan S., 2012, JOINT C EMNLP CONLL, P1
   Pradhan Sameer., 2013, P 17 C COMPUTATIONAL, P143
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C., 2019, ABS191010683 ARXIV
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi P, 2019, SIMPLE BERT MODELS R
   Shi X., 2016, P 2016 C EMP METH NA, P1526, DOI DOI 10.18653/V1/D16-1159
   Shimizu A, 2019, PROCEEDINGS OF THE 8TH INTERNATIONAL WORKSHOP ON HARDWARE AND ARCHITECTURAL SUPPORT FOR SECURITY AND PRIVACY, HASP '19, DOI 10.1145/3337167.3337172
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Steedman M., 2000, SYNTACTIC PROCESS, DOI [10.7551/mitpress/6591.001.0001, DOI 10.7551/MITPRESS/6591.001.0001]
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5027
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Sundararaman Dhanasekar, 2019, ARXIV191106156CSSTAT, DOI [10.1109/IALP48816.2019.9037672, DOI 10.1109/IALP48816.2019.9037672]
   Swayamdipta S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3772
   Tateisi Yuka, 2005, P IJCNLP
   Tenney I., 2019, ARXIV190505950, DOI DOI 10.18653/V1/P19-1452
   Tenney Ian, 2019, INT C LEARN REPR
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang Wei, 2020, INT C LEARN REPR
   Warstadt A., 2018, ARXIV180512471
   Wilcox E, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3302
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yarowsky D, 1995, P ACL, P189, DOI [10.3115/981658.981684, DOI 10.3115/981658.981684]
   Yogatama Dani, 2019, ARXIV190111373
   Zhou JR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2396
   Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186
NR 80
TC 12
Z9 12
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2020
VL 8
BP 776
EP 794
DI 10.1162/tacl_a_00345
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA XX8IL
UT WOS:000736531900050
OA Green Submitted, gold
DA 2023-11-10
ER

PT S
AU Gangashetty, SV
   Sekhar, CC
   Yegnanarayana, B
AF Gangashetty, SV
   Sekhar, CC
   Yegnanarayana, B
BE Zanuy, MF
   Janer, L
   Esposito, A
   SatueVillar, A
   Roure, J
   EspinosaDuro, V
TI Spotting multilingual consonant-vowel units of speech using neural
   network models
SO NONLINEAR ANALYSES AND ALGORITHMS FOR SPEECH PROCESSING
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT International Conference on Non-Linear Speech Processing
CY APR 19-22, 2005
CL Barcelona, SPAIN
ID RECOGNITION
AB Multilingual speech recognition system is required for tasks that use several languages in one speech recognition application. In this paper, we propose an approach for multilingual speech recognition by spotting consonant-vowel (CV) units. The important features of spotting approach are that there is no need for automatic segmentation of speech and it is not necessary to use models for higher level units to recognise the CV units. The main issues in spotting multilingual CV units are the location of anchor points and labeling the regions around these anchor points using suitable classifiers. The vowel onset points (VOPs) have been used as anchor points. The distribution capturing ability of autoassociative neural network (AANN) models is explored for detection of VOPs in continuous speech. We explore classification models such as support vector machines (SVMs) which are capable of discriminating confusable classes of CV units and generalisation from limited amount of training data. The data for similar CV units across languages are shared to train the classifiers for recognition of CV units of speech in multiple languages. We study the spotting approach for recognition of a large number of CV units in the broadcast news corpus of three Indian languages.
C1 Indian Inst Technol, Dept Comp Sci & Engn, Speech & Vis Lab, Madras 600036, Tamil Nadu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras
RP Gangashetty, SV (通讯作者)，Indian Inst Technol, Dept Comp Sci & Engn, Speech & Vis Lab, Madras 600036, Tamil Nadu, India.
EM svg@cs.iitm.ernet.in; chandra@cs.iitm.ernet.in; yegna@cs.iitm.ernet.in
RI GANGASHETTY, SURYAKANTH V/AAX-9268-2021
OI Gangashetty, Suryakanth/0000-0001-6745-4363
CR Bourlard H. A., 1994, CONNECTIONIST SPEECH
   CHOPDE A, ITRANS INDIAN LANGUA
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Diamantaras K., 1996, PRINCIPAL COMPONENT
   ESWAR P, 1987, P EUR C SPEECH TECHN, P369
   FURUI S, 1986, J ACOUST SOC AM, V80, P1016, DOI 10.1121/1.393842
   Gangashetty SV, 2004, MACHINE LEARN SIGN P, P401
   Gangashetty SV, 2004, IEEE IJCNN, P3065
   GANGASHETTY SV, 2003, P 5 INT C ADV PATT R, P156
   GANGASHETTY SV, 2001, P 5 INT C COGN NEUR, P24
   GANGASHETTY SV, 2004, P 8 INT C SPOK LANG, P1081
   Haykin S., 2004, NEURAL NETWORKS COMP, V2, P41
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH
   RAO JYS, 1999, P INT C ADV PATT REC, P316
   ROUKOS S, 1989, P IEEE INT C AC SPEE, P627
   Sekhar CC, 2002, LECT NOTES COMPUT SC, V2388, P171
   Sekhar CC, 2002, IEEE T SPEECH AUDI P, V10, P472, DOI 10.1109/TSA.2002.804298
   Sekhar CC, 1996, IEEE IJCNN, P2003, DOI 10.1109/ICNN.1996.549209
   SEKHAR CC, 1996, THESIS DEPT COMPUTER
   Yegnanarayana B, 2002, NEURAL NETWORKS, V15, P459, DOI 10.1016/S0893-6080(02)00019-9
NR 20
TC 10
Z9 10
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 2945-9133
EI 1611-3349
J9 LECT NOTES ARTIF INT
PY 2005
VL 3817
BP 303
EP 317
PG 15
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BDW47
UT WOS:000235839300027
DA 2023-11-10
ER

PT J
AU Wu, YC
   Yin, F
   Liu, CL
AF Wu, Yi-Chao
   Yin, Fei
   Liu, Cheng-Lin
TI Improving handwritten Chinese text recognition using neural network
   language models and convolutional neural network shape models
SO PATTERN RECOGNITION
LA English
DT Article
DE Handwritten Chinese text recognition; Feedforward neural network
   language model; Recurrent neural network language model; Hybrid language
   model; Convolutional neural network shape models
ID CHARACTER-RECOGNITION; SEGMENTATION; ONLINE
AB Handwritten Chinese text recognition based on over-segmentation and path search integrating multiple contexts has been demonstrated successful, wherein the language model (LM) and character shape models play important roles. Although back-off N-gram LMs (BLMs) have been used dominantly for decades, they suffer from the data sparseness problem, especially for high-order LMs. Recently, neural network LMs (NNLMs) have been applied to handwriting recognition with superiority to BLMs. With the aim of improving Chinese handwriting recognition, this paper evaluates the effects of two types of character-level NNLMs, namely, feedforward neural network LMs (FNNLMs) and recurrent neural network LMs (RNNLMs). Both FNNLMs and RNNLMs are also combined with BLMs to construct hybrid LMs. For fair comparison with BLMs and a state-of-the-art system, we evaluate in a system with the same character over-segmentation and classification techniques as before, and compare various LMs using a small text corpus used before. Experimental results on the Chinese handwriting database CASIA-HWDB validate that NNLMs improve the recognition performance, and hybrid RNNLMs outperform the other LMs. To report a new benchmark, we also evaluate selected LMs on a large corpus, and replace the baseline character classifier, over-segmentation, and geometric context models with convolutional neural network (CNN) based models. The performance on both the CASIA-HWDB and the ICDAR-2013 competition dataset are improved significantly. On the CASIA-HWDB test set, the character-level accurate rate (AR) and correct rate (CR) achieve 95.88% and 95.95%, respectively.
C1 [Wu, Yi-Chao; Yin, Fei; Liu, Cheng-Lin] Chinese Acad Sci, Inst Inst Automat, NLPR, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Liu, Cheng-Lin] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Liu, Cheng-Lin] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences
RP Liu, CL (通讯作者)，Chinese Acad Sci, Inst Inst Automat, NLPR, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM yichao.wu@nlpr.ia.ac.cn; fyin@nlpria.ac.cn; liucl@nlpr.ia.ac.cn
RI Liu, Cheng-Lin/JCO-6642-2023
FU National Natural Science Foundation of China (NSFC) [61305005, 61273269,
   61573355, 61411136002]
FX We would like to thank Zhuo Chen and Xin He for the help in implementing
   CNN based over-segmentation, and Xiang-Dong Zhou for sharing the idea of
   lattice error rate. This work has been supported by the National Natural
   Science Foundation of China (NSFC) grants 61305005, 61273269, 61573355,
   and 61411136002.
CR [Anonymous], 2012, P NAACL HLT 2012 WOR
   [Anonymous], 2006, MACHINE LEARN
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], ARXIV14085093
   [Anonymous], 1996, 34 ANN M ASS COMP LI, DOI DOI 10.3115/981863.981904
   Arisoy E., 2012, P NAACL HLT 2012 WOR, P20
   Bae JH, 1998, PATTERN RECOGN LETT, V19, P701, DOI 10.1016/S0167-8655(98)00048-8
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bengio Y, 2008, IEEE T NEURAL NETWOR, V19, P713, DOI 10.1109/TNN.2007.912312
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Carpenter B., 2005, P WORKSH SOFTW, P86, DOI DOI 10.3115/1626315.1626322
   Ciresan D, 2015, IEEE IJCNN
   Dai Ruwei, 2007, Frontiers of Computer Science in China, V1, P126, DOI 10.1007/s11704-007-002-5
   España-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141
   Fujisawa H, 2008, PATTERN RECOGN, V41, P2435, DOI 10.1016/j.patcog.2008.03.015
   Furnkranz J., 1998, AUSTRIAN RES I ARTIF, V3, P1
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodman J, 2001, INT CONF ACOUST SPEE, P561, DOI 10.1109/ICASSP.2001.940893
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   He X, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P715, DOI 10.1109/ACPR.2015.7486596
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Irie K, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2371
   Joshua T., 2001, MACH LEARN APPL STAT, P1
   Katz S., IEEE T ACOUST SPEECH, V35
   KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881
   Kneser R., 1993, P EUR, P973
   Kombrink S, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2888
   Le H.-S., 2012, P NAACL HLT 2012 WOR, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H, 2012, PATTERN RECOGN, V45, P1306, DOI 10.1016/j.patcog.2011.09.015
   Li NA, 2014, INT CONF FRONT HAND, P134, DOI 10.1109/ICFHR.2014.30
   Li NX, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P501, DOI 10.1109/APCCAS.2008.4746070
   Liu C., MACHINE LEARNING DOC, P139
   Liu CL, 2008, LECT NOTES COMPUT SC, V4768, P104
   Liu CL, 2007, IEEE T PATTERN ANAL, V29, P1465, DOI 10.1109/TPAMI.2007.1090
   Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17
   Liu CL, 2005, PATTERN RECOGN, V38, P2242, DOI 10.1016/j.patcog.2005.04.019
   Liu CL, 2004, IEEE T PATTERN ANAL, V26, P1395, DOI 10.1109/TPAMI.2004.104
   Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   Messina R, 2015, PROC INT CONF DOC, P171
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Mikolov T, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P612
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Mnih A., 2007, P 24 INT C MACHINE L, P641, DOI DOI 10.1145/1273496.1273577
   Mnih A., 2008, P 22 ANN C NEURAL IN, P1081, DOI 10.5555/2981780.2981915
   Mnih Andriy, 2012, ARXIV12066426, P1751
   Morin F., 2005, AISTATS, V5, P246
   Morioka T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2366
   Nakagawa M, 2005, IEICE T INF SYST, VE88D, P1815, DOI 10.1093/ietisy/e88-d.8.1815
   Schwenk H., 2012, P COLING 2012, P1071
   Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003
   Schwenk H, 2013, INTERSPEECH, P1197
   Shiwen Yu, 2003, Journal of Chinese Language and Computing, V13, P121
   Song Wang, 2016, 2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR), P84, DOI 10.1109/ICFHR.2016.0028
   Su TH, 2009, PATTERN RECOGN, V42, P167, DOI 10.1016/j.patcog.2008.05.012
   Sundermeyer M, 2013, INT CONF ACOUST SPEE, P8430, DOI 10.1109/ICASSP.2013.6639310
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14
   Wang DH, 2012, PATTERN RECOGN, V45, P3661, DOI 10.1016/j.patcog.2012.04.020
   Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264
   Wang QF, 2014, PATTERN RECOGN, V47, P1202, DOI 10.1016/j.patcog.2013.09.015
   Wu CP, 2014, INT CONF FRONT HAND, P291, DOI 10.1109/ICFHR.2014.56
   Wu YC, 2014, INT CONF FRONT HAND, P193, DOI 10.1109/ICFHR.2014.40
   Wu YC, 2015, PROC INT CONF DOC, P166, DOI 10.1109/ICDAR.2015.7333745
   Xu L, 2014, INT J DOC ANAL RECOG, V17, P91, DOI 10.1007/s10032-013-0208-1
   Xu L, 2011, PROC INT CONF DOC, P859, DOI 10.1109/ICDAR.2011.176
   Yin F, 2013, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2013.218
   Yin F, 2013, PATTERN RECOGN, V46, P2807, DOI 10.1016/j.patcog.2013.03.013
   Zamora-Martínez F, 2014, PATTERN RECOGN, V47, P1642, DOI 10.1016/j.patcog.2013.10.020
   Zhang XY, 2017, PATTERN RECOGN, V61, P348, DOI 10.1016/j.patcog.2016.08.005
   Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881
   Zhou MK, 2016, PATTERN RECOGN, V49, P7, DOI 10.1016/j.patcog.2015.07.007
   Zhou XD, 2007, PROC INT CONF DOC, P48
   Zhou XD, 2013, IEEE T PATTERN ANAL, V35, P2413, DOI 10.1109/TPAMI.2013.49
   Zweig G, 2013, INT CONF ACOUST SPEE, P8237, DOI 10.1109/ICASSP.2013.6639271
NR 79
TC 70
Z9 75
U1 3
U2 8
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD MAY
PY 2017
VL 65
BP 251
EP 264
DI 10.1016/j.patcog.2016.12.026
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EK8TO
UT WOS:000394197700021
DA 2023-11-10
ER

PT J
AU Dale, R
AF Dale, Robert
TI Navigating the text generation revolution: Traditional data-to-text NLG
   companies and the rise of ChatGPT
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Natural language generation; Automated writing assistance
AB Since the release of ChatGPT at the end of November 2022, generative AI has been talked about endlessly in both the technical press and the mainstream media. Large language model technology has been heralded as many things: the disruption of the search engine, the end of the student essay, the bringer of disinformation horizontal ellipsis but what does it mean for commercial providers of earlier iterations of natural language generation technology? We look at how the major players in the space are responding, and where things might go in the future.
C1 [Dale, Robert] Language Technol Grp, Church Point, NSW, Australia.
RP Dale, R (通讯作者)，Language Technol Grp, Church Point, NSW, Australia.
EM rdale@language-technology.com
NR 0
TC 0
Z9 0
U1 18
U2 18
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUL
PY 2023
VL 29
IS 4
BP 1188
EP 1197
DI 10.1017/S1351324923000347
PG 10
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA M8CH8
UT WOS:001032435400011
OA hybrid
DA 2023-11-10
ER

PT J
AU Sitender
   Bawa, S
   Kumar, M
   Sangeeta
AF Sitender
   Bawa, Seema
   Kumar, Munish
   Sangeeta
TI A comprehensive survey on machine translation for English, Hindi and
   Sanskrit languages
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article; Early Access
DE Artificial intelligence; BLEU; Knowledge representation; Machine
   translation; NIST; Natural language processing; Systematic survey;
   Statistical machine translation
ID SYSTEM; MODEL; URDU
AB Transforming text from one language to another by using computer systems automatically or with little human interventions is known as Machine Translation System (MTS). Divergence among natural languages in a multilingual environment makes Machine Translation (MT) a difficult and challenging task. The purpose of this paper is to present a comprehensive survey of MTS in general and for English, Hindi and Sanskrit languages in particular. The state-of-the-art MT approach is Neural Machine Translation (NMT) which has been used by Google, Amazon, Facebook and Microsoft but it requires large corpus as well as high computing systems. The availability of MT language modeling tools, parsers data repositories and evaluation metrics has been tabulated in this article. The classification of MTS, evaluation methods and platforms has been done based on a well-defined set of criteria. The new research avenues have been explored in this survey article which will help in developing good quality MTS. Although several surveys have been done on MTS but none of them have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) approach including tools and evaluation methods as done in this survey specifically for English, Hindi and Sanskrit languages.
C1 [Sitender; Bawa, Seema] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Sitender; Sangeeta] Maharaja Surajmal Inst Technol, Dept Informat Technol, New Delhi 110058, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Batinda 151001, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Maharaja Surajmal
   Institute of Technology
RP Sitender (通讯作者)，Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.; Sitender (通讯作者)，Maharaja Surajmal Inst Technol, Dept Informat Technol, New Delhi 110058, India.
EM sitender@thapar.edu; seema@thapar.edu; munishcse@gmail.com;
   sangeeta.phogat@gmail.com
RI malik, Sangeeta/ABF-9423-2021; Sitender, Dr/AAJ-9624-2021; Kumar,
   Munish/P-7756-2018
OI malik, Sangeeta/0000-0002-8691-3892; Sitender, Dr/0000-0003-0341-2927;
   Kumar, Munish/0000-0003-0115-1620
CR Aasha VC, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1565, DOI 10.1109/ICACCI.2015.7275836
   Agrawal R, 2017, THESIS INT I INFORSM
   Allen J., 1995, NATURAL LANGUAGE UND
   Ambati BR, 2018, LANG RESOUR EVAL, V52, P67, DOI 10.1007/s10579-017-9379-6
   [Anonymous], 2016, 10 MOST SPOKEN LANGU
   [Anonymous], 2021, ETHNOLOGUE LANGUAGES
   [Anonymous], 2009, MOSES STAT MACHINE T
   [Anonymous], 2015, P INT WORKSHOP SPOKE
   [Anonymous], 2007, P MACH TRANSL SUMM
   [Anonymous], 2009, RECENT ADV NAT LANG, DOI DOI 10.1075/CILT.309
   Antony PJ., 2013, COMPUT LINGUIST, V18, P47
   Aparna S., 2005, LANG INDIA, V5, P1
   Ata N., 2007, PROC C LANGUAGE TECH, P1
   Badodekar S, 2003, TRANSLATION RESOURCE, DOI 400019
   Bahadur P., 2012, INT J ADV COMPUT SC, V4, P52, DOI [10.14569/SpecialIssue.2012.020107, DOI 10.14569/SPECIALISSUE.2012.020107]
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Baker Paul, 2002, P LREC 2002
   Balyan R, 2015, COMPUT SPEECH LANG, V32, P91, DOI 10.1016/j.csl.2014.09.007
   Bhadra M, 2009, LECT NOTES ARTIF INT, V5406, P116, DOI 10.1007/978-3-540-93885-9_10
   Bhadwal N, 2020, SCALABLE COMPUT-PRAC, V21, P543, DOI 10.12694/scpe.v21i3.1783
   Bharati A, 2009, ANUSAARAKA ACCESSOR, P1
   Bharati RM, 2003, P INT C NAT LANG PRO
   Budgen D., 2006, 28th International Conference on Software Engineering Proceedings, P1051, DOI 10.1145/1134285.1134500
   CARROLL JB, 1966, MECH TRANSL, V9, P55
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Choudhary A, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 4, P293, DOI 10.1109/ICCSIT.2009.5234543
   Christopher M, 2010, 32 ALL IND C LING AI, P69
   Darbari H, 1999, MACH TRANSL SUMM 7 1, P80
   Dave S., 2001, Machine Translation, V16, P251, DOI 10.1023/A:1021902704523
   Desai N., 2021, ARXIV PREPRINT ARXIV
   Desai P, 2014, P 11 INT C NAT LANG, P177
   Devlin J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1370
   Dorr BJ, 2004, P INT C WORLD C ENG, P1
   Dubey Preeti, 2019, International Journal of Information Technology, V11, P171, DOI 10.1007/s41870-018-0085-4
   Dubey P, 2013, 2013 INTERNATIONAL CONFERENCE ON MACHINE INTELLIGENCE AND RESEARCH ADVANCEMENT (ICMIRA 2013), P422, DOI 10.1109/ICMIRA.2013.89
   Dungarwal P, 2014, P 9 WORKSH STAT MACH, P90
   Echizen-Ya H., 2004, Systems and Computers in Japan, V35, P1, DOI 10.1002/scj.10511
   Faes F, 2018, AMAZON LION BRIDGE S
   Federico M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1618
   Forcada ML, 2011, MACH TRANSL, V25, P127, DOI 10.1007/s10590-011-9090-0
   Fromkin V., 2011, INTRO LANGUAGE
   Garje GV., 2013, INT J NATURAL LANGUA, V2, P47, DOI [10.5121/ijnlc.2013.2504, DOI 10.5121/IJNLC.2013.2504]
   Gehring J, 2016, ARXIV161102344
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gimenez Jesus, 2010, Prague Bulletin of Mathematical Linguistics, P77, DOI 10.2478/v10108-010-0022-6
   Gimenez Jesus, 2006, P 5 INT C LANG RES E, P685
   Gopal M, 2011, COMM COM INF SC, V139, P191
   Goyal P, 2009, LECT NOTES ARTIF INT, V5402, P287
   Goyal Vishal, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P148, DOI 10.4304/jetwi.2.2.148-151
   Goyal V, 2009, ARXIV PREPRINT ARXIV
   Goyal V., 2011, PROC ASS COMPUTATION, P1
   Hassan H., 2018, ACHIEVING HUMAN PARI
   Hutchins W. J., 1992, INTRO MACHINE TRANSL
   Hutchins W. J., 1995, CONCISE HIST LANGUAG, P431
   Hyderabad I, 2018, MACH TRANSL
   Jain RSinhaRMK, 2001, STRANS 2001, P20
   Jawaid B., 2014, PROC WORKSHOP S SE A, P37
   Jayan V, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P282, DOI 10.1109/IC3I.2014.7019748
   Jha Girish Nath, 2010, P 7 INT C LANG RES E, P982
   Jung H, 1999, COMPUT INTELL, V15, P114, DOI 10.1111/0824-7935.00087
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kelly C., 2021, TAB DELIMITED BILING
   Khan N., 2013, PROC WORKSHOP S SE A, P72
   Khan S, 2019, INT ARAB J INF TECHN, V16, P125
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   Kulkarni A., 2013, P 2 INT C DEP LING D, P157
   Kulkarni A, 2010, LECT NOTES ARTIF INT, V6465, P70, DOI 10.1007/978-3-642-17528-2_6
   Kumar A, 2010, LECT NOTES ARTIF INT, V6465, P57, DOI 10.1007/978-3-642-17528-2_5
   Kumar Rashi, 2019, P 2019 2 INT C ALGOR, P377
   Le Thuyen PT, 2016, 2016 INT C EL INF CO, P1
   Lin C.-Y., 2004, COLING 2004 P 20 INT, P501, DOI DOI 10.3115/1220355.1220427
   Malik M. K, 2013, WORLD APPL SCI J, V24, P1362, DOI DOI 10.5829/idosi.wasj.2013.24.10.760
   Mallikarjun B, 2010, STRENGTH TODAY BRIGH, V10, P1
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), P18
   Microsoft, 2017, MICR TRANSL ACC US N
   Microsoft, 2016, MICR TRANSL LAUNCH N
   Mishra Himani, 2019, International Conference on Advanced Computing Networking and Informatics (ICANI-2018). Advances in Intelligent Systems and Computing (AISC 870), P371, DOI 10.1007/978-981-13-2673-8_39
   Mishra Viral, 2012, International Journal of Advanced Intelligence Paradigms, V4, P168, DOI 10.1504/IJAIP.2012.048144
   Mishra V., 2008, J RES DEV COMP SCI E, V37, P1
   Mishra V., 2009, INFOCOMP J COMPUTER, V9, P80
   Moher D, 2016, REV ESP NUTR HUM DIE, V20, P148, DOI 10.14306/renhyd.20.2.223
   Mujadia V., 2020, P 5 C MACH TRANSL, P414
   Narayan R, 2014, SCI WORLD J, DOI 10.1155/2014/485737
   Naskar S, 2005, AAMT J, V16, P25
   NCST, 2008, MATR ENGLISH HINDI M
   Nivre J., 2007, Natural Language Engineering, V13, P95, DOI 10.1017/S1351324906004505
   Och FJ, 2007, JOINT C EMP METH NAT, P858
   Pandey RK, 2016, PROCEDIA COMPUT SCI, V96, P504, DOI 10.1016/j.procs.2016.08.114
   Pathak GR, 2010, AIP CONF PROC, V1324, P122, DOI 10.1063/1.3526172
   Phillips AB, 2011, MACH TRANSL, V25, P161, DOI 10.1007/s10590-011-9109-6
   Post Matt, 2015, Prague Bulletin of Mathematical Linguistics, P5, DOI 10.1515/pralin-2015-0009
   Pune C, 2018, INDIAN LANGUAGE TECH
   Rajan Remya, 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P439, DOI 10.1109/ACT.2009.113
   Raulji Jaideepsinh K., 2019, P 2019 IEEE BOMBAY S, P1
   Reddy MV, 2013, MULTIMEDIA PROCESSIN, P35
   ROSENFELD R, 1997, CMU CAMBRIDGE STAT L
   Sachdeva K, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1807
   Saha GK., 2005, J ZHEJIANG UNIV-SC A, V6, P1047, DOI [10.1631/jzus.2005.A1047, DOI 10.1631/JZUS.2005.A1047]
   Sahinur Rahman Laskar, 2020, P 7 WORKSHOP ASIAN T, P109
   Seasly J., 2003, MACH TRANSL
   Shahnawaz, 2015, International Journal of Advanced Intelligence Paradigms, V7, P1
   Shahnawaz A, 2011, INFOCOMP J COMPUT SC, V10, P25
   Sharma N, 2011, THESIS THAPAR U PATI
   Sheikh Mahmudul, 2013, International Journal of Intercultural Information Management, V3, P123
   Singh Muskaan, 2019, Recent Trends in Communication, Computing, and Electronics. Select Proceedings of IC3E 2018. Lecture Notes in Electrical Engineering (LNEE 524), P419, DOI 10.1007/978-981-13-2685-1_40
   Singh M, 2020, PROCEDIA COMPUT SCI, V167, P2534, DOI 10.1016/j.procs.2020.03.306
   SINHA RMK, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, P1609, DOI 10.1109/ICSMC.1995.538002
   Sinha RMK, 2003, MT SUMM 9 NEW ORL US, P494
   Sinha RMK, 2005, 10 EAMT C, P235
   Sinha RMK, 2004, P INT S MACH TRANSL, P10
   Sinha RMK, 2005, 10 MACH TRANSL SUMM, P149
   Sitender, 2021, IETE J RES, V67, P117, DOI 10.1080/03772063.2018.1528187
   Sitender, 2022, MULTIMEDIA SYST, V28, P2105, DOI 10.1007/s00530-020-00692-3
   Sitender, 2021, NEURAL COMPUT APPL, V33, P2819, DOI 10.1007/s00521-020-05156-3
   Slocum J., 1985, Computational Linguistics, V11, P1
   Sridhar R, 2016, SADHANA-ACAD P ENG S, V41, P607, DOI 10.1007/s12046-016-0504-9
   Stolcke Andreas., 2002, IWSLT
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Udupa R, 2005, LECT NOTES COMPUT SC, V3248, P254
   Upadhyay P, 2014, INT J COMPUT APPL, V4, P2277
   Van Slype G, 1979, CRITICAL STUDY METHO
   Vaswani A., 2013, P 2013 C EMPIRICAL M, P1387
   Venkatapathy S., 2009, ACM T ASIAN LANG INF, V8, P8
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Yandex, 2017, YAND BLOG
   Zhang M, 2017, HIST FRONTIER NEURAL
NR 130
TC 8
Z9 8
U1 2
U2 10
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD 2021 SEP 13
PY 2021
DI 10.1007/s12652-021-03479-0
EA SEP 2021
PG 34
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UP1NL
UT WOS:000695150800001
DA 2023-11-10
ER

PT J
AU Khan, NS
   Abid, A
   Abid, K
AF Khan, Nabeel Sabir
   Abid, Adnan
   Abid, Kamran
TI A Novel Natural Language Processing (NLP)-Based Machine Translation
   Model for English to Pakistan Sign Language Translation
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Machine translation; Natural language processing; Deaf people
   communication; Pakistan Sign Language; Cognition; Rule-based translation
ID SPANISH; SPEECH; SYSTEM
AB Background/Introduction The deaf community in the world uses a gesture-based language, generally known as sign language. Every country has a different sign language; for instance, USA has American Sign Language (ASL) and UK has British Sign Language (BSL). The deaf community in Pakistan uses Pakistan Sign Language (PSL), which like other natural languages, has a vocabulary, sentence structure, and word order. Majority of the hearing community is not aware of PSL due to which there exists a huge communication gap between the two groups. Similarly, deaf persons are unable to read text written in English and Urdu. Hence, the provision of an effective translation model can support the cognitive capability of the deaf community to interpret natural language materials available on the Internet and in other useful resources. Methods This research involves exploiting natural language processing (NLP) techniques to support the deaf community by proposing a novel machine translation model that translates English sentences into equivalent Pakistan Sign Language (PSL). Though a large number of machine translation systems have been successfully implemented for natural to natural language translations, natural to sign language machine translation is a relatively new area of research. State-of-the-art works in natural to sign language translation are mostly domain specific and suffer from low accuracy scores. Major reasons are specialised language structures for sign languages, and lack of annotated corpora to facilitate development of more generalisable machine translation systems. To this end, a grammar-based machine translation model is proposed to translate sentences written in English language into equivalent PSL sentences. To the best of our knowledge, this is a first effort to translate any natural language to PSL using core NLP techniques. The proposed approach involves a structured process to investigate the linguistic structure of PSL and formulate the grammatical structure of PSL sentences. These rules are then formalised into a context-free grammar, which, in turn, can be efficiently implemented as a parsing module for translation and validation of target PSL sentences. The whole concept is implemented as a software system, comprising the NLP pipeline and an external service to render the avatar-based video of translated words, in order to compensate the cognitive hearing deficit of deaf people. Results and Conclusion The accuracy of the proposed translation model has been evaluated manually and automatically. Quantitative results reveal a very promising Bilingual Evaluation Understudy (BLEU) score of 0.78. Subjective evaluations demonstrate that the system can compensate for the cognitive hearing deficit of end users through the system output expressed as a readily interpretable avatar. Comparative analysis shows that our proposed system works well for simple sentences but struggles to translate compound and compound complex sentences correctly, which warrants future ongoing research.
C1 [Khan, Nabeel Sabir; Abid, Adnan] Univ Management & Technol, Lahore, Pakistan.
   [Abid, Kamran] Univ Punjab, Lahore, Pakistan.
C3 University of Management & Technology (UMT); University of Punjab
RP Abid, A (通讯作者)，Univ Management & Technol, Lahore, Pakistan.
EM adnan.abid@umt.edu.pk
RI Abid, Adnan/AAM-4134-2020; Khan, Nabeel Sabir/AAV-8828-2021
CR Abbas A., 2018, J ED TECHNOLOGY SYST
   Abid K., 2018, S ASIAN STUDIES, V33
   [Anonymous], 1990, PART OF SPEECH TAGGI
   Bonham M.E, 2015, THESIS
   Boucenna S, 2014, COGN COMPUT, V6, P722, DOI 10.1007/s12559-014-9276-x
   Bragg D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P16, DOI 10.1145/3308561.3353774
   Bungeroth J., 2004, WORKSH REPR PROC SIG, V4, P105
   Camgoz Necati Cihan, 2020, INT J COMPUT VISION, P1
   Combrink Andries, 2006, P 2006 ANN RES C S A
   Cox S, 2003, INT J HUM-COMPUT INT, V16, P141, DOI 10.1207/S15327590IJHC1602_02
   d'Armond L.S, 2002, THESIS
   De Marneffe Marie-Catherine, 2008, TECHNICAL REPORT
   Filhol M, 2016, UNIVERSAL ACCESS INF, V15, P487, DOI 10.1007/s10209-015-0413-4
   Gonalez M, 2012, 50 ANN M ASS COMPUTA
   Hadla LS, 2014, INT J ADV COMPUT SC, V5, P68
   Hassan B., 2015, VFAST T SOFTWARE ENG, V9, P1, DOI [DOI 10.21015/VTSE.V9I1.386, 10.21015/vtse.v9i1.386]
   Jemni M, 2011, ARXIV PREPRINT ARXIV
   Khan N, 2014, PENSEE, V76
   Khan NS., 2015, S ASIAN STUD-UK, V30, P367
   Kouremenos D, 2018, COMPUT SPEECH LANG, V51, P110, DOI 10.1016/j.csl.2018.04.001
   Kröger BJ, 2011, COGN COMPUT, V3, P449, DOI 10.1007/s12559-010-9071-2
   Luqman H., 2018, UNIVERSAL ACCESS INF, P1
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Marshall I, 2001, P RECENT ADV NATURAL, P154
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Niessen S., 2000, P 2 INT C LANG RES E
   Othman A, 2019, J INF TECHNOL RES, V12, P134, DOI 10.4018/JITR.2019040108
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Porta J, 2014, COMPUT SPEECH LANG, V28, P788, DOI 10.1016/j.csl.2013.10.003
   Safar Eva, 2003, P 41 ANN M ASS COMP, V2
   San Segundo Hernandez R, 2010, LANGUAGE RESOURCES S
   San-Segundo R, 2008, J VISUAL LANG COMPUT, V19, P523, DOI 10.1016/j.jvlc.2007.06.002
   Shaalan K., 2010, INT J INF COMMUN TEC, V3, P11
   Shoaib U, 2014, EXPERT SYST APPL, V41, P2300, DOI 10.1016/j.eswa.2013.09.027
   Sidig AAI, 2017, PROCEDIA COMPUT SCI, V117, P2, DOI 10.1016/j.procs.2017.10.087
   Snover Matthew, 2006, P ASS MACH TRANSL AM, V200
   Nguyen TBD, 2018, ADV INTELL SYST, V672, P655, DOI 10.1007/978-981-10-7512-4_65
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   Tumsri Jirawat, 2017, Lecture Notes in Engineering and Computer Science, IMECS 2017. International MultiConference of Engineers and Computer Scientists 2017, P46
   Veale T., 1998, Machine Translation, V13, P81, DOI 10.1023/A:1008014420317
   Verma VK, 2018, SPEECH LANGUAGE PROC, P129
   Wang PS, 2016, COGN COMPUT, V8, P982, DOI 10.1007/s12559-016-9388-6
   Yasir F, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P49, DOI 10.1109/ICICICT1.2017.8342533
   Zeshan U, 2003, SIGN LANG STUD, P157, DOI DOI 10.1353/SLS.2003.0005
   Zeshan Ulrike., 2000, SIGN LANG LINGUISTIC, DOI DOI 10.1075/SLL.3.2.10MEI
   Zhao L., 2000, C ASS MACH TRANSL AM C ASS MACH TRANSL AM
NR 46
TC 32
Z9 32
U1 2
U2 30
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD JUL
PY 2020
VL 12
IS 4
BP 748
EP 765
DI 10.1007/s12559-020-09731-7
EA MAY 2020
PG 18
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA MP4WD
UT WOS:000536440700001
DA 2023-11-10
ER

PT J
AU Salami, S
   Shamsfard, M
   Khadivi, S
AF Salami, Shahram
   Shamsfard, Mehrnoush
   Khadivi, Shahram
TI Phrase-boundary model for statistical machine translation
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Statistical machine translation; Hierarchical models; Rules filtering
AB This paper proposes a new probabilistic synchronous context-free grammar model for statistical machine translation. The model labels nonterminals with classes of boundary words on the target side of aligned phrase pairs. Labeling of the rules is performed with coarse grained and fine grained nonterminals using POS tags and word clusters trained on the target language corpus. Considering the large size of the proposed model due to the diversity of nonterminals, we have also proposed a novel approach for filtered rule extraction based on the alignment pattern of phrase pairs. Using limited patterns of rules, the extraction of hierarchical rules gets restricted from phrase pairs that are decomposable to two aligned subphrases. The proposed filtered rule extraction decreases the model size and the decoding time considerably with no significant impact on the translation quality. Using BLEU as a metric in our experiments, the proposed model achieved a notable improvement rate over the state-of-the-art hierarchical phrase-based model in the translation from Persian, French and Spanish to English language. This is applicable for all languages, even under-resourced ones having no linguistic tools. (C) 2015 Elsevier Ltd. All rights reserved.
C1 [Salami, Shahram; Shamsfard, Mehrnoush] Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
   [Khadivi, Shahram] Amirkabir Univ Technol, Human Language Technol Lab, Tehran, Iran.
C3 Shahid Beheshti University; Amirkabir University of Technology
RP Salami, S (通讯作者)，Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
EM sh_salami@sbu.ac.ir; m-shams@sbu.ac.ir; khadivi@aut.ac.ir
RI Shamsfard, Mehrnoush/Q-7671-2019; Shamsfard, Mehrnoush/I-1707-2019
OI Shamsfard, Mehrnoush/0000-0002-7027-7529; Shamsfard,
   Mehrnoush/0000-0002-7027-7529
CR Almaghout H., 2010, P 7 INT WORKSH SPOK
   [Anonymous], 2011, LONG PAPERS
   [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], P 7 INT WORKSH SPOK
   Cherry C, 2013, P 2013 C N AM CHAPT, P22
   Chiang D, 2007, HIERARCHICAL PHRASE, P201
   Chiang D, 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Collobert R., 2011, J MACHINE LEARNING R, V12, P2461
   Eisele A, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2868
   Haque R., 2010, P 9 C ASS MACH TRANS
   He Zhongjun, 2008, P INT C COMP LING CO, P321
   He Zhongjun, 2009, P IUCS TOK JAP DEC, P25
   Huck M., 2012, P 16 EAMT C EUR ASS, P313
   Iglesias G, 2009, P EACL, P380
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   Koehn P., 2005, P AAMT 10 MACH TRANS, P79, DOI DOI 10.3115/1626355.1626380
   Koehn P., 2007, P 45 ANN M ASS COMP
   Lee S.-W., 2012, P 50 ANN M ASS COMP, V2, P291
   Li ZY, 2009, PROCEEDINGS OF THE ASME SUMMER BIOENGINEERING CONFERENCE - 2009, PT A AND B, P135, DOI 10.3115/1626431.1626459
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Och FJ, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P295
   Och FJ, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS, P71
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Och FJ, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P440
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pauls A, 2011, P 49 ANN M ASS COMPU, P258
   Post Matt, 2013, P 8 WORKSH STAT MACH, P206
   Sankaran B., 2012, 10 BIENN C ASS MACH
   Sankaran B., 2011, P 6 WORKSH STAT MACH, P533
   Supreme Council of ICT, 2013, MIZ ENGL PERS PAR CO
   Watanabe T, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P777
   Zens R, 2002, LECT NOTES ARTIF INT, V2479, P18
   Zhou B. W., 2008, P 2 WORKSH SYNT STRU, P19
   Zollmann A., 2006, P WORKSH STAT MACH T
   Zollmann A, 2008, P 22 INT C COMP LING, P1145
NR 36
TC 4
Z9 4
U1 0
U2 27
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL
PY 2016
VL 38
BP 13
EP 27
DI 10.1016/j.csl.2015.11.005
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science
GA DG2MH
UT WOS:000371900800002
DA 2023-11-10
ER

PT J
AU Zhang, H
   Yang, SY
   Zhu, HQ
AF Zhang, Han
   Yang, Suyi
   Zhu, Hongqing
TI CJE-TIG: Zero-shot cross-lingual text-to-image generation by
   Corpora-based Joint Encoding
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Cross-lingual pre-training; Text-to-image synthesis; Universal
   contextual word vector space; Semantic alignment; Joint adversarial
   training
AB Recently, text-to-Image (T2I) generation has been well developed by improving synthesis authenticity, text-consistency and generation diversity. However, large amount of pairwise image-text data required restricts generalization of synthesis models only to its pre-trained language. In this paper, a cross-lingual pre-training method is proposed to adapt target low-resource language to pre-trained generative models. As far as we known, this is the first time that arbitrary input languages could access T2I generation. This joint encoding scheme fulfills both universal and visual semantic alignment. With any prepared GAN-based T2I framework, pre-trained source encoder model could be easily fine-tuned to construct target encoder model and hence entirely enable transfer of T2I synthesis ability between languages. After that, a semantic-level alignment independent of source T2I structure is established to guarantee optimal text consistency and detail generation. Different from monolingual T2I methods that apply discriminator to enhance generation quality, we use an adversarial training scheme that optimizes the sentence-level alignment along with the word-level alignment with a self-attention mechanism. Considering of training for low-resource languages lack of parallel texts in practice, target input embedding is designed available for zero-shot learning. Experimental results prove robustness of the proposed cross-lingual T2I pre-training on multiple downstream generative models and target languages applied.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Han; Zhu, Hongqing] East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
   [Yang, Suyi] Kings Coll London, Dept Math Nat Math & Engn Sci, London WC2R 2LS, England.
C3 East China University of Science & Technology; University of London;
   King's College London
RP Zhu, HQ (通讯作者)，East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
EM hqzhu@ecust.edu.cn
OI Zhu, Hongqing/0000-0002-2122-7066
FU National Natural Science Foundation of China [61872143]
FX Acknowledgments This work was supported by the National Natural Science
   Foundation of China under Grant 61872143.
CR Abad A, 2020, INT CONF ACOUST SPEE, P6909, DOI [10.1109/ICASSP40776.2020.9054468, 10.1109/icassp40776.2020.9054468]
   Aldarmaki H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3906
   [Anonymous], 2016, P 2016 C N AM CHAPTE
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Artetxe M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7674
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Chi ZW, 2020, AAAI CONF ARTIF INTE, V34, P7570
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Cui YM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1586
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Elliott Desmond, 2016, P 5 WORKSHOP VISION
   Feng F., ARXIV200701852
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hermann K. M., 2013, ARXIV13126173
   Ji ZY, 2020, IEEE I C VI COM I PR, P265, DOI [10.1109/vcip49819.2020.9301888, 10.1109/VCIP49819.2020.9301888]
   Koehn P., 2005, P MACHINE TRANSLATIO, P79
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G., 2018, INT C LEARNING REPRE
   Lan WY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1549, DOI 10.1145/3123266.3123366
   Lee Cheolhyoung, 2019, ARXIV190911299
   Li B., 2019, ADV NEURAL INFORM PR, P2063
   Li SY, 2021, KNOWL-BASED SYST, V218, DOI 10.1016/j.knosys.2021.106827
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu X, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106611
   Martinek J., 2020, ARXIV200509260
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mirza M., 2014, ARXIV14111784, DOI DOI 10.48550/ARXIV.1411.1784
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Radford A., IMPROVING LANGUAGE U
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Reed S, 2016, PR MACH LEARN RES, V48
   Robnik-Sikonja M., 2020, ARXIV200507456
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Schuster S, 2018, NAACL
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   Schuster Tal, 2019, P 2019 C N AM CHAPT
   Tian L., P EUR C MACH LEARN P, V2021, P603
   Vaswani A, 2017, ADV NEUR IN, V30
   Wah C., 2011, CNSTR2011001 CALTECH
   Wang YX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5721
   Wehrmann J, 2019, IEEE I CONF COMP VIS, P5803, DOI 10.1109/ICCV.2019.00590
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P917
   Xing Chao, 2015, PROC 2015 C N AM CHA, P1006, DOI DOI 10.3115/V1/N15-1104
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
   Zhou DY, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107200
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 54
TC 2
Z9 2
U1 3
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD MAR 5
PY 2022
VL 239
AR 108006
DI 10.1016/j.knosys.2021.108006
EA JAN 2022
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0V9BI
UT WOS:000788633300003
DA 2023-11-10
ER

PT J
AU Athanaselis, T
   Mamouras, K
   Bakamidis, S
   Dologlou, I
AF Athanaselis, Theologos
   Mamouras, Konstantinos
   Bakamidis, Stelios
   Dologlou, Ioannis
TI A CORPUS BASED TECHNIQUE FOR REPAIRING ILL-FORMED SENTENCES WITH WORD
   ORDER ERRORS USING CO-OCCURRENCES OF N-GRAMS
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Word order errors; statistical language model; permutations filtering;
   British National Corpus
AB There are several reasons to expect that recognising word order errors in a text will be a difficult problem, and recognition rates reported in the literature are in fact low. Although grammatical rules constructed by computational linguists improve the performance of a grammar checker in word order diagnosis, the repairing task is still very difficult. This paper describes a method to repair any sentence with wrong word order using a statistical language model (LM). A good indicator of whether a person really knows a language is the ability to use the appropriate words in a sentence in correct word order. The "scrambled" words in a sentence produce a meaningless sentence. Most languages have a fairly fixed word order. This paper introduces a method, which is language independent, for repairing word order errors in sentences using the probabilities of most typical trigrams and bigrams extracted from a large text corpus such as the British National Corpus (BNC).
C1 [Athanaselis, Theologos; Mamouras, Konstantinos; Bakamidis, Stelios; Dologlou, Ioannis] Inst Language & Speech Proc ILSP Athena RC, Dept Voice & Sound Technol, GR-15125 Athens, Greece.
C3 Institute for Language & Speech Processing (ILSP)
RP Athanaselis, T (通讯作者)，Inst Language & Speech Proc ILSP Athena RC, Dept Voice & Sound Technol, GR-15125 Athens, Greece.
EM tathana@ilsp.gr; kmam@ilsp.gr; bakam@ilsp.gr; ydol@ilsp.gr
CR [Anonymous], P 2 WORKSH ROB METH
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2000, P 1 N AM CHAPT ASS C
   [Anonymous], P 3 C EUR CHAPT ASS
   [Anonymous], 1995, BRIT NATL CORPUS USE
   [Anonymous], 2000, HDB NATURAL LANGUAGE
   Atwell E.S., 1987, CORPUS BASED APPROAC, V12, P120
   Bangalore Srinivas, 2000, P 18 INT C COMP LING, P42
   Bender E. M., 2004, P INSTIL ICALL S COM, P83
   BROCKETT C, 2006, P 21 INT C COMP LING, P249
   CHURCH KW, 1993, COMPUTATIONAL LINGUI, V19, P1
   Costa-Jussà MR, 2009, COMPUT SPEECH LANG, V23, P362, DOI 10.1016/j.csl.2008.12.002
   FAIGLEY L, 2003, BRIEF PENGUIN HDB
   FEYTON CM, 2002, TEACHING ESL EFL INT
   FOLSE KS, 1997, INTERMEDIATE TOEFL T
   Fouvry F., 2003, P 8 INT WORKSH PARS, P23
   GAMON M, 2008, P IJCNLP HYD IND
   Golding A.R., 1995, P 3 WORKSH VER LARG, P39
   GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344
   Hawkins John A., 1994, PERFORMANCE THEORY O
   HEIFT T, 2001, Z INTERKULTURELLEN F, V6
   IZUMI E., 2004, P LANG RES EV C LREC, P1435
   IZUMI E., 2003, P 41 ANN M ASS COMP, V2, P145
   JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   LANGKILDE I, 1998, P 36 ANN M ASS COMP, P704
   LEE J, 2006, P INTERSPEECH PITTSB
   Lower S.K., 1998, REFERENCE TEXT
   Michaud L. N., 2000, ASSETS 00 P 4 INT AC, P92
   Moré J, 2006, DIGITHUM
   Naber D., 2003, THESIS BIELEFELD U
   PARK JC, 1997, P C APPL NAT LANG PR, P24
   ROBINSON T, 1995, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1995.479278
   SCHNEIDER D, 1998, P 36 ANN M ASS COMP, V2, P1198, DOI DOI 10.3115/980432.980765
   SJOBERGH J, 2005, P REC ADV NAT LANG P, P506
   SUN G., 2007, P 45 ANN M ASS COMP, P81
   Tomokiyo LM, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P239
   Vogel C., 1995, Knowledge Representation for Natural Language Processing in Implemented Systems. 1994 AAAI Fall Symposium (Tech. Rep. FS-94-04), P127
NR 38
TC 1
Z9 1
U1 0
U2 3
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD JUN
PY 2011
VL 20
IS 3
BP 401
EP 424
DI 10.1142/S0218213011000218
PG 24
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 780AW
UT WOS:000291824500001
DA 2023-11-10
ER

PT J
AU Liu, X
   Gales, MJF
   Woodland, PC
AF Liu, X.
   Gales, M. J. F.
   Woodland, P. C.
TI Language model cross adaptation for LVCSR system combination
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
AB State-of-the-art large vocabulary continuous speech recognition (LVCSR) systems often combine outputs from multiple subsystems that may even be developed at different sites. Cross system adaptation, in which model adaptation is performed using the outputs from another sub-system, can be used as an alternative to hypothesis level combination schemes such as ROVER. Normally cross adaptation is only performed on the acoustic models. However, there are many other levels in LVCSR systems' modelling hierarchy where complimentary features may be exploited, for example, the sub-word and the word level, to further improve cross adaptation based system combination. It is thus interesting to also cross adapt language models (LMs) to capture these additional useful features. In this paper cross adaptation is applied to three forms of language models, a multi-level LM that models both syllable and word sequences, a word level neural network LM, and the linear combination of the two. Significant error rate reductions of 4.0-7.1% relative were obtained over ROVER and acoustic model only cross adaptation when combining a range of Chinese LVCSR sub-systems used in the 2010 and 2011 DARPA GALE evaluations. (c) 2012 Elsevier Ltd. All rights reserved.
C1 [Liu, X.; Gales, M. J. F.; Woodland, P. C.] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
C3 University of Cambridge
RP Liu, X (通讯作者)，Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.
EM xl207@cam.ac.uk; mjfg@eng.cam.ac.uk; pcw@eng.cam.ac.uk
FU DARPA under the GALE program via a subcontract to BBN Technologies
FX This work was in part supported by DARPA under the GALE program via a
   subcontract to BBN Technologies. The paper does not necessarily reflect
   the position or the policy of the US Government and no official
   endorsement should be inferred.
CR Anastasakos T., 1998, P ICSLP 98 SYDN
   [Anonymous], ACL 2010
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bulyko I., 2007, P IEEE ICASSP2007 HA
   Chen L., 2001, P ITRW 01 PAR
   Chien J. T., 2005, P ISCA INT 05 LISB
   Chu S. M., 2010, P IEEE ICASSP2010 DA
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   Emami A., 2007, P IEEE ASRU2007 KYOT
   Evermann G., 2000, P SPEECH TRANSCR WOR
   Federico M., 2003, P IEEE ICASSP2003 HO
   Federico M., 1999, P EUROSPEECH 99 BUD
   Fiscus J. G., 1997, P IEEE ASRU1997
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043
   Gales MJF, 2006, COMPUT SPEECH LANG, V20, P22, DOI 10.1016/j.csl.2004.12.002
   Gildea D., 1999, P EUR 99 BUD
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hieronymus J. L., 2009, P ISCA INT 09 BRIGHT
   HINTON G, 1999, P ICANN
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hsu B., 2007, P IEEE ASRU2007 KYOT
   Kumar N., 1997, THESIS J HOPKINS U B
   Lamel L., 2007, P IEEE ICASSP2007 HA
   Lamel L., 2011, P IEEE ICASSP2011 PR
   Leggetter C. J., 1995, P IEEE ICASSP1995 DE
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010
   Lei X., 2009, P ISCA INT 09 BRIGHT
   Liu X, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P132
   Liu X., COMPUTER SP IN PRESS
   Liu X., 2009, P ISCA INT 09 BRIGHT
   Liu X., 2010, P IEEE ICASSP2010 DA
   Liu X., 2010, P ISCA INT 10 MAK
   Liu X., 2011, P IEEE ICASSP2011 PR
   Liu X., 2008, P ISCA INT 08 BRISB
   Luo J., 2009, P ICASSP2009 TAIP
   MOHRI M, 1998, SPEECH COMMUNICATION, V25
   Mrva D., 2004, P ISCA INT 04 JEJ
   Ng T., 2010, P ISCA INT 10 MAK
   Nguyen K., 2008, P IEEE ICASSP2008 LA
   Och FJ, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P295
   Park J., 2010, P ISCA INT 10 MAK
   Peskin B., 1999, P IEEE ICASSP1999 PH
   Povey D., 2002, P IEEEICASSP2002 ORL
   Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545
   Prasad R., 2005, P ISCA INT 05 LISB
   Rosenfeld R., 2001, COMPUTERS SPEECH LAN, V15
   Schwartz R., 2004, P IEEE ICASSP2004 MO
   Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003
   Stolcke A., 2003, P HLT 03 EDM
   Tam Y. C., 2005, P ISCA INT 05 LISB
   Wallhoff F., 2000, P IEEE ICASSP2000 IS
   Weintraub M., 1996, 1995 LANG MOD SUMM W
   Woodland P. C., 2004, P RICH TRANSCR WORKS
   Woodland PC, 1997, DARPA SPEECH RECOGNI, P73
NR 55
TC 7
Z9 7
U1 0
U2 8
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUN
PY 2013
VL 27
IS 4
BP 928
EP 942
DI 10.1016/j.csl.2012.07.010
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 111MA
UT WOS:000316524200003
DA 2023-11-10
ER

PT J
AU Shaikh, A
   Hafeez, A
   Elmagzoub, MA
   Alghamdi, A
   Siddique, A
   Shahzad, B
AF Shaikh, Asadullah
   Hafeez, Abdul
   Elmagzoub, M. A.
   Alghamdi, Abdullah
   Siddique, Ansar
   Shahzad, Basit
TI Ontology-Based Verification of UML Class Model XOR Constraint and
   Dependency Relationship Constraints
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Ontology-based verification; model verification; class model
   verification; UML model verification
AB Unified Modeling Language (UML) models are considered important artifacts of model-driven engineering (MDE). This can automatically transform models to other paradigms and programming languages. If a model has bugs, then MDE can transfer these to a new code. The class model is a key component of UML that is used in analysis and design. Without a formal foundation, UML can create only graphical diagrams, making it impossible to verify properties such as satisfiability, consistency and consequences. Different techniques have been used to verify UML class models, but these do not support some important components. This paper transforms and verifies unsupported components such as XOR association constraints and dependency relationships of a UML class model through ontology. We use various UML class models to validate the proposed ontology-based method, easy and efficient transformation and verification of unsupported elements. The results show this approach can verify large and complex models.
C1 [Shaikh, Asadullah; Elmagzoub, M. A.; Alghamdi, Abdullah] Najran Univ, Dept Informat Syst, Najran 61441, Saudi Arabia.
   [Hafeez, Abdul] SMI Univ, Dept Comp Sci, Karachi 76400, Pakistan.
   [Siddique, Ansar] Univ Gujrat, Dept Software Engn, Gujrat 50700, Pakistan.
   [Shahzad, Basit] Natl Univ Modern Languages NUML, Dept Software Engn, Islamabad 44020, Pakistan.
C3 Najran University; University of Gujrat
RP Shaikh, A (通讯作者)，Najran Univ, Dept Informat Syst, Najran 61441, Saudi Arabia.
EM asshaikh@nu.edu.sa
RI Shaikh, Asadullah/S-4815-2016
OI Shaikh, Asadullah/0000-0003-4806-6159; ALGHAMDI,
   ABDULLAH/0000-0002-5006-8527
FU ministry of education and the deanship of scientific research of Najran
   University, Kingdom of Saudi Arabia [NU/ESCI/17/098]
FX The authors express their gratitude to the ministry of education and the
   deanship of scientific research of Najran University, Kingdom of Saudi
   Arabia, for financial and technical support under code number
   NU/ESCI/17/098.
CR Alemán JLF, 2000, 11TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, PROCEEDINGS, P344, DOI 10.1109/ISSRE.2000.885885
   Anastasakis K, 2010, SOFTW SYST MODEL, V9, P69, DOI 10.1007/s10270-008-0110-3
   [Anonymous], 2011, ACM SIGSOFT SOFTWARE
   [Anonymous], 2010, P IEEEACM INT C AUTO
   Awaad M. H., 1978, ZENTRALBLATT BAKTE A, V240
   Bajwa IS, 2017, MEHRAN UNIV RES J EN, V36, P243, DOI 10.22581/muet1982.1702.04
   Bajwa IS, 2012, J KING SAUD UNIV-COM, V24, P117, DOI 10.1016/j.jksuci.2011.12.003
   Balaban M, 2015, SOFTW SYST MODEL, V14, P1527, DOI 10.1007/s10270-013-0390-0
   Balaban M, 2013, ACM T SOFTW ENG METH, V22, DOI 10.1145/2491509.2491518
   Belghiat A., 2012, P 4 INT C WEB INF TE, P330
   Berardi D, 2005, ARTIF INTELL, V168, P70, DOI 10.1016/j.artint.2005.05.003
   Booch G., 1996, UNIFIED MODELING LAN, P1
   Bordbar B., 2005, IADIS INT C APPL COM, P209
   Cabot J., 2008, CHAMDE 2008 WORKSH P, P31
   Cabot J, 2009, J SYST SOFTWARE, V82, P1459, DOI 10.1016/j.jss.2009.03.009
   Cadoli M., 2004, CSP TECH IMMED APPL, V2, P2
   Clarisó R, 2015, LECT NOTES COMPUT SC, V9276, P108, DOI 10.1007/978-3-319-22969-0_8
   Cook S. F., 2017, THESIS
   Defense P. M., 1992, US GAO REPORTS
   Erdil Kagan, 2003, COMP180 SOFTWARE ENG, P1
   Files A. N. M. C., 2013, OBJECT MANAGEMENT GR, P1
   Fish A., 2005, 5 VMG U BRIGHT
   France R, 1998, COMPUT STAND INTER, V19, P325, DOI 10.1016/S0920-5489(98)00020-8
   Grimm S., 2007, SEMANTIC WEB SERVICE, DOI [10.1007/3-540-70894-4_3, DOI 10.1007/3-540-70894-4_3]
   Hassan N., 2016, INT J COMPUTER SCI I, V14, P52
   Hussmann H, 2000, LECT NOTES COMPUT SC, V1939, P278
   Kardos M, 2010, J INF ORGAN SCI, V34, P89
   Kent S., 2002, Integrated Formal Methods. Third International Conference, IFM 2002. Proceedings (Lecture Notes in Computer Science Vol.2335), P286
   Kim S. K., 2000, INT C B Z USERS
   Korytkowski R., 2016, THOUGHTS OCL OBJECT
   Ledang H, 2001, 16TH ANNUAL INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2001), PROCEEDINGS, P436, DOI 10.1109/ASE.2001.989849
   Ledang H., 2001, INF 2001 WORKSH INT, P1
   Malgouyres Y., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1804, DOI 10.1145/1141277.1141703
   Maoz S, 2011, LECT NOTES COMPUT SC, V6981, P592, DOI 10.1007/978-3-642-24485-8_44
   Maraee A., 2008, MODEL COEVOLUTION CO, P120
   Maraee A, 2009, MBSE: 2009 INTERNATIONAL CONFERENCE ON MODEL-BASED SYSTEMS ENGINEERING, P1, DOI 10.1109/MBSE.2009.5031714
   O.M. Group, 2007, UML CONSTR VERS 2 5
   Oriol X, 2017, J SYST SOFTWARE, V128, P130, DOI 10.1016/j.jss.2017.03.015
   Parreiras FS, 2010, DATA KNOWL ENG, V69, P1194, DOI 10.1016/j.datak.2010.07.009
   Pérez B, 2019, INFORM SYST, V81, P152, DOI 10.1016/j.is.2018.08.005
   Robert J. C., 2020, J OBJECT TECHNOLOGY, V19, P1
   Shaikh Asadullah, 2011, Advances in Software Engineering, DOI 10.1155/2011/370198
   Shaikh A, 2018, IEEE ACCESS, V6, P23864, DOI 10.1109/ACCESS.2018.2797695
   Shaikh A, 2014, SOFTWARE PRACT EXPER, V44, P1379, DOI 10.1002/spe.2211
   Singh M, 2016, PROCEDIA COMPUT SCI, V85, P352, DOI 10.1016/j.procs.2016.05.243
   Song K, 2005, 2005 INTERNATIONAL WORKSHOP ON THE ANALYSIS ON MULTI-TEMPORAL REMOTE SENSING IMAGES, P39
   Technica, 2015, SOFTW BUG GRANT EARL
   Traoré I, 2004, IEEE T SOFTWARE ENG, V30, P736, DOI 10.1109/TSE.2004.86
   Xu W., 2008, INFORM SYSTEMS CRISI, P493
NR 49
TC 2
Z9 2
U1 1
U2 1
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2021
VL 27
IS 2
BP 565
EP 579
DI 10.32604/iasc.2021.015071
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA QR1CE
UT WOS:000624954000018
OA hybrid
DA 2023-11-10
ER

PT J
AU Liu, JX
   Hu, TX
   Zhang, Y
   Feng, Y
   Hao, J
   Lv, JH
   Liu, ZZ
AF Liu, Jiaxiang
   Hu, Tianxiang
   Zhang, Yan
   Feng, Yang
   Hao, Jin
   Lv, Junhui
   Liu, Zuozhu
TI Parameter-Efficient Transfer Learning for Medical Visual Question
   Answering
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
LA English
DT Article; Early Access
DE Visualization; Task analysis; Adaptation models; Training; Computational
   modeling; Feature extraction; Transfer learning; Parameter-Efficient
   transfer learning; Adapter; CLIP; multi-stage label smoothing; medical
   visual question answering
ID MODEL
AB The Contrastive Language-Image Pre-Training (CLIP) model, pretrained on large visual text corpora, has demonstrated significant improvements in visual and linguistic tasks and has been applied to various downstream tasks. At least two issues, however, hinder the transfer learning with such powerful pretrained models in the field of medical visual question answering (Med-VQA). That current methods tend to full fine-tune these large-scale models are suffering from increasingly expensive computational cost as the model size grows in development. Additionally, published Med-VQA datasets are small that may lead to overfitting when directly fine-tuning on them. In this article, we integrate two designs and propose an efficient transfer learning method for Med-VQA named VQA-Adapter. To alleviate training costs, we introduce a novel and parameter-efficient adapter component into Med-VQA. During training, only the proposed light-weight adapter needs to be tuned, while all parameters in the large-scale visual model of CLIP could be kept frozen. We further design a multi-stage label smoothing paradigm for Med-VQA to deal with the overfitting issue in small Med-VQA datasets. Experimental results on two popular Med-VQA datasets, i.e., VQA-RAD and SLAKE, demonstrate that our method can significantly outperform existing state-of-the-art methods on both open-ended and closed-ended question answering tasks. Furthermore, compared to directly fine-tuning the entire CLIP model, our approach only requires to update 2.38% of the parameters. Extensive ablation studies, analysis and visualizations convincingly demonstrate the great potential of designing light-weight frameworks to transfer large-scale pretrained models from natural vision-language tasks to domain-specific medical applications.
C1 [Liu, Jiaxiang; Liu, Zuozhu] Zhejiang Univ, Engn Res Ctr Oral Biomat & Devices Zhejiang Prov, Zhejiang Prov Clin Res Ctr Oral Dis, Stomatol Hosp,Sch Stomatol,Sch Med,Key Lab Oral Bi, Hangzhou 310000, Peoples R China.
   [Liu, Jiaxiang; Hu, Tianxiang; Liu, Zuozhu] Zhejiang Univ, Univ Illinois Urbana Champaign Inst, Haining 314400, Zhejiang, Peoples R China.
   [Zhang, Yan] Natl Univ Singapore, Singapore 117583, Singapore.
   [Feng, Yang] Angelalign Technol inc, Shanghai 200135, Peoples R China.
   [Hao, Jin] ChohoTech Inc, Hangzhou 310011, Peoples R China.
   [Lv, Junhui] Zhejiang Univ, Sir Run Run Shaw Hosp, Coll Med, Hangzhou 310016, Peoples R China.
C3 Zhejiang University; Zhejiang University; National University of
   Singapore; Zhejiang University
RP Liu, ZZ (通讯作者)，Zhejiang Univ, Engn Res Ctr Oral Biomat & Devices Zhejiang Prov, Zhejiang Prov Clin Res Ctr Oral Dis, Stomatol Hosp,Sch Stomatol,Sch Med,Key Lab Oral Bi, Hangzhou 310000, Peoples R China.; Lv, JH (通讯作者)，Zhejiang Univ, Sir Run Run Shaw Hosp, Coll Med, Hangzhou 310016, Peoples R China.
EM jiaxiang.21@intl.zju.edu.cn; tianxianghu@intl.zju.edu.cn;
   eleyanz@nus.edu.sg; fengyang@angelalign.com; jin_hao@g.harvard.edu;
   3415030@zju.edu.cn; zuozhuliu@intl.zju.edu.cn
RI Hao, Jin/I-2157-2019; Lv, Junhui/CAF-6028-2022
OI Hao, Jin/0000-0002-6685-2017; Liu, Zuozhu/0000-0002-7816-502X; Liu,
   Jiaxiang/0000-0003-1764-0322
FU National Natural Science Foundation of China [62106222]; Natural Science
   Foundation of Zhejiang Province, China [LZ23F020008]; Zhejiang
   University-Angelalign Inc. Ramp;D Center for Intelligent Healthcare
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62106222, in part by the Natural Science
   Foundation of Zhejiang Province, China under Grant LZ23F020008, and in
   part by the Zhejiang University-Angelalign Inc. R & amp;D Center for
   Intelligent Healthcare.
CR Abacha A. B., 2018, CLEF WORKING NOTES
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Banerjee P., 2021, P FINDINGS ASS COMPU, P3420
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Changpinyo S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1947
   Chefer H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P387, DOI 10.1109/ICCV48922.2021.00045
   Chen Zhihong, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P5152, DOI 10.1145/3503161.3547948
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Do T, 2021, LECT NOTES COMPUT SC, V12905, P64, DOI 10.1007/978-3-030-87240-3_7
   Dosovitskiy A., 2020, ARXIV, P1
   Eslami S, 2021, Arxiv, DOI arXiv:2112.13906
   Finn C, 2017, PR MACH LEARN RES, V70
   Fukui Akira, 2016, ARXIV160601847, P457, DOI [DOI 10.18653/V1/D16-1044, 10.18653/v1/D16-1044]
   Gao P., 2021, ARXIV, DOI DOI 10.1007/S11263-023-01891-X
   Gong HF, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P456, DOI 10.1145/3460426.3463584
   Guo DM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4884
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Hu E. J., 2022, P INT C LEARN REPR
   Jia C., 2021, SCALING VISUAL VISIO, P4904
   Karimi Mahabadi R., 2021, ADV NEURAL INFORM PR, P1022
   Khare Y, 2021, I S BIOMED IMAGING, P1033, DOI 10.1109/ISBI48211.2021.9434063
   Kim JH, 2018, ADV NEUR IN, V31
   Lau JJ, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.251
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045
   Li J., 2022, INT C MACHINE LEARNI, P12888
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Liu B, 2021, LECT NOTES COMPUT SC, V12902, P210, DOI 10.1007/978-3-030-87196-3_20
   Liu B, 2021, I S BIOMED IMAGING, P1650, DOI 10.1109/ISBI48211.2021.9434010
   Liu F, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1175, DOI 10.1145/3343031.3350993
   Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028
   Mahabadi RK, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P565
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Müller R, 2019, ADV NEUR IN, V32
   Nguyen BD, 2019, LECT NOTES COMPUT SC, V11767, P522, DOI 10.1007/978-3-030-32251-9_57
   Pantazis O., 2022, P BRIT MACH VIS C, P01
   Pelka O., P INTR IM COMP ASS S
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pereyra Gabriel, 2017, REGULARIZING NEURAL
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2021, P INT C MACH LEARN I, P8748, DOI DOI 10.48550/ARXIV.2103.00020
   Ramesh A., 2022, ARXIV, DOI [10.48550/arXiv.2204.06125, DOI 10.48550/ARXIV.2204.06125]
   Rebuffi SA, 2017, ADV NEUR IN, V30
   Rebuffi SA, 2018, PROC CVPR IEEE, P8119, DOI 10.1109/CVPR.2018.00847
   Ren FJ, 2020, IEEE ACCESS, V8, P50626, DOI 10.1109/ACCESS.2020.2980024
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shen S., 2022, P INT C LEARN REPR
   Shi L, 2019, CLEF
   Song HY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6088
   Sung YL, 2022, PROC CVPR IEEE, P5217, DOI 10.1109/CVPR52688.2022.00516
   Tiong A. M. H., 2022, P FINDINGS ASS COMPU, P951
   Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139
   Wang ZC, 2022, Arxiv, DOI arXiv:2201.05729
   Xie LX, 2016, PROC CVPR IEEE, P4753, DOI 10.1109/CVPR.2016.514
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhan LM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2345, DOI 10.1145/3394171.3413761
   Zhang R., 2022, P IEEECVF C COMPUTER, P8552
NR 59
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2471-285X
J9 IEEE TETCI
JI IEEE Trans. Emerg. Top. Comput. Intell.
PD 2023 SEP 20
PY 2023
DI 10.1109/TETCI.2023.3311333
EA SEP 2023
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S6BM2
UT WOS:001071996400001
DA 2023-11-10
ER

PT J
AU Zhou, KY
   Yang, JK
   Loy, CC
   Liu, ZW
AF Zhou, Kaiyang
   Yang, Jingkang
   Loy, Chen Change
   Liu, Ziwei
TI Learning to Prompt for Vision-Language Models
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article
AB Large pre-trained vision-language models like CLIP have shown great potential in learning representations that are transferable across a wide range of downstream tasks. Different from the traditional representation learning that is based mostly on discretized labels, vision-language pre-training aligns images and texts in a common feature space, which allows zero-shot transfer to a downstream task via prompting, i.e., classification weights are synthesized from natural language describing classes of interest. In this work, we show that a major challenge for deploying such models in practice is prompt engineering, which requires domain expertise and is extremely time-consuming-one needs to spend a significant amount of time on words tuning since a slight change in wording could have a huge impact on performance. Inspired by recent advances in prompt learning research in natural language processing (NLP), we propose Context Optimization (CoOp), a simple approach specifically for adapting CLIP-like vision-language models for downstream image recognition. Concretely, CoOp models a prompt's context words with learnable vectors while the entire pre-trained parameters are kept fixed. To handle different image recognition tasks, we provide two implementations of CoOp: unified context and class-specific context. Through extensive experiments on 11 datasets, we demonstrate that CoOp requires as few as one or two shots to beat hand-crafted prompts with a decent margin and is able to gain significant improvements over prompt engineering with more shots, e.g., with 16 shots the average gain is around 15% (with the highest reaching over 45%). Despite being a learning-based approach, CoOp achieves superb domain generalization performance compared with the zero-shot model using hand-crafted prompts.
C1 [Zhou, Kaiyang; Yang, Jingkang; Loy, Chen Change; Liu, Ziwei] Nanyang Technol Univ, S Lab, Singapore, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University
RP Zhou, KY (通讯作者)，Nanyang Technol Univ, S Lab, Singapore, Singapore.
EM kaiyang.zhou@ntu.edu.sg; jingkang001@ntu.edu.sg; ccloy@ntu.edu.sg;
   ziwei.liu@ntu.edu.sg
FU RIE2020 Industry Alignment Fund Industry Collaboration Projects
   (IAF-ICP) Funding Initiative
FX This study is supported under the RIE2020 Industry Alignment Fund
   Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as
   cash and in-kind contribution from the industry partner(s).
CR Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483
   Bommasani R., 2021, ARXIV
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chen T, 2020, PR MACH LEARN RES, V119
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Desai K, 2021, PROC CVPR IEEE, P11157, DOI 10.1109/CVPR46437.2021.01101
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Furst A., 2021, ARXIV
   Gao P., 2021, ARXIV
   Gao T., 2020, ARXIV
   Gomez L, 2017, PROC CVPR IEEE, P2017, DOI 10.1109/CVPR.2017.218
   He Kaiming, 2020, P IEEE CVF C COMP VI, P9729, DOI DOI 10.1109/CVPR42600.2020.00975
   Helber Patrick, 2019, IEEE J SELECTED TOPI, DOI [DOI 10.1109/JSTARS.2019.2918242, 10.1109/IGARSS.2018.8519248]
   Henaff Olivier, 2020, PR MACH LEARN RES, P4182, DOI DOI 10.5555/3524938.3525329
   Hendrycks D, 2021, PROC CVPR IEEE, P15257, DOI 10.1109/CVPR46437.2021.01501
   Hendrycks Dan, 2021, ICCV
   Jia C, 2021, PR MACH LEARN RES, V139
   Jia M., 2022, ARXIV
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Joulin A, 2016, LECT NOTES COMPUT SC, V9911, P67, DOI 10.1007/978-3-319-46478-7_5
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lester B., 2021, ARXIV
   Li A, 2017, IEEE I CONF COMP VIS, P4193, DOI 10.1109/ICCV.2017.449
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li X, 2021, ARXIV
   Li Y., 2021, ARXIV
   Liu P., ARXIV
   Liu X., ARXIV
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Maji S, 2013, ARXIV
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   PARKHI OM, 2012, PROC CVPR IEEE, P3498, DOI [10.1109/CVPR.2012.6248092, DOI 10.1109/CVPR.2012.6248092]
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Radford A, 2021, PR MACH LEARN RES, V139
   Recht B, 2019, PR MACH LEARN RES, V97
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222
   Singh A., 2021, ARXIV
   Socher R, 2013, ADV NEURAL INFORM PR, V26
   Soomro Khurram, 2012, ARXIV12120402
   Taori Rohan, 2020, ADV NEURAL INF PROCE, V33, P18583
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Dequan, 2021, INT C LEARN REPR
   Wang HH, 2019, ADV NEUR IN, V32
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yuan L, 2021, ARXIV
   Yuan Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P71, DOI 10.1007/978-3-030-58568-6_5
   Zhang Y., 2020, ARXIV
   Zhong Z., 2021, NAACL
   Zhou K., 2022, ARXIV
   Zhou K., 2021, ARXIV
NR 55
TC 53
Z9 54
U1 17
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD SEP
PY 2022
VL 130
IS 9
BP 2337
EP 2348
DI 10.1007/s11263-022-01653-1
EA JUL 2022
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3T2LG
UT WOS:000833995900001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Latif, S
   Rana, R
   Khalifa, S
   Jurdak, R
   Schuller, B
AF Latif, Siddique
   Rana, Rajib
   Khalifa, Sara
   Jurdak, Raja
   Schuller, Bjorn
TI Self Supervised Adversarial Domain Adaptation for Cross-Corpus and
   Cross-Language Speech Emotion Recognition
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Training; Adaptation models; Emotion recognition; Speech recognition;
   Australia; Task analysis; Generators; Speech emotion recognition;
   self-supervised learning; domain adaptation; adversarial learning
ID NETWORKS
AB Despite the recent advancement in speech emotion recognition (SER) within a single corpus setting, the performance of these SER systems degrades significantly for cross-corpus and cross-language scenarios. The key reason is the lack of generalisation in SER systems towards unseen conditions, which causes them to perform poorly in cross-corpus and cross-language settings. Recent studies focus on utilising adversarial methods to learn domain generalised representation for improving cross-corpus and cross-language SER to address this issue. However, many of these methods only focus on cross-corpus SER without addressing the cross-language SER performance degradation due to a larger domain gap between source and target language data. This contribution proposes an adversarial dual discriminator (ADDi) network that uses the three-players adversarial game to learn generalised representations without requiring any target data labels. We also introduce a self-supervised ADDi (sADDi) network that utilises self-supervised pre-training with unlabelled data. We propose synthetic data generation as a pretext task in sADDi, enabling the network to produce emotionally discriminative and domain invariant representations and providing complementary synthetic data to augment the system. The proposed model is rigorously evaluated using five publicly available datasets in three languages and compared with multiple studies on cross-corpus and cross-language SER. Experimental results demonstrate that the proposed model achieves improved performance compared to the state-of-the-art methods.
C1 [Latif, Siddique; Rana, Rajib] Univ Southern Queensland USQ, Springfield, Qld 4301, Australia.
   [Latif, Siddique; Khalifa, Sara] CSIRO, Distributed Sensing Syst Grp, Data61, Pullenvale, Qld 4069, Australia.
   [Jurdak, Raja] Queensland Univ Technol QUT, TruNets Trusted Networks Lab, Brisbane, Qld 4000, Australia.
   [Schuller, Bjorn] Imperial Coll London, GLAM Grp Language Audio & Mus, London SW7 2BX, England.
   [Schuller, Bjorn] Univ Augsburg, ZDB Chair Embedded Intelligence Hlth Care & Wellbe, D-86159 Augsburg, Germany.
C3 University of Southern Queensland; Commonwealth Scientific & Industrial
   Research Organisation (CSIRO); Queensland University of Technology
   (QUT); Imperial College London; University of Augsburg
RP Latif, S (通讯作者)，Univ Southern Queensland USQ, Springfield, Qld 4301, Australia.
EM siddique.latif@usq.edu.au; rajib.rana@usq.edu.au;
   sara.khalifa@data61.csiro.au; r.jurdak@qut.edu.au; schuller@tum.de
RI Schuller, Björn Wolfgang/D-3241-2011; Jurdak, Raja/B-7637-2011
OI Schuller, Björn Wolfgang/0000-0002-6478-8699; Jurdak,
   Raja/0000-0001-7517-0782; Latif, Siddique/0000-0001-5662-4777
CR Abdelwahab M, 2018, IEEE-ACM T AUDIO SPE, V26, P2423, DOI 10.1109/TASLP.2018.2867099
   Abdelwahab M, 2015, INT CONF ACOUST SPEE, P5058, DOI 10.1109/ICASSP.2015.7178934
   Ahn Y, 2021, IEEE SIGNAL PROC LET, V28, P1190, DOI 10.1109/LSP.2021.3086395
   Albornoz EM, 2017, IEEE T AFFECT COMPUT, V8, P43, DOI 10.1109/TAFFC.2015.2503757
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Baevski A., 2019, P ICLR
   Bao F, 2019, INTERSPEECH, P2828, DOI 10.21437/Interspeech.2019-2293
   Bérard A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6224, DOI 10.1109/ICASSP.2018.8461690
   Brock Andrew, 2018, INT C LEARN REPR
   Burkhardt F., 2005, INTERSPEECH, P1517
   Burmania A, 2016, IEEE T AFFECT COMPUT, V7, P374, DOI 10.1109/TAFFC.2015.2493525
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chatziagapi A, 2019, INTERSPEECH, P171, DOI 10.21437/Interspeech.2019-2561
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   Deng J, 2014, IEEE SIGNAL PROC LET, V21, P1068, DOI 10.1109/LSP.2014.2324759
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Detjen H, 2021, INT J HUM-COMPUT INT, V37, P308, DOI 10.1080/10447318.2020.1860517
   Dubey H, 2019, INT CONF ACOUST SPEE, P6296, DOI 10.1109/ICASSP.2019.8683023
   Eskimez SE, 2020, INTERSPEECH, P3446, DOI 10.21437/Interspeech.2020-2898
   Eyben F., 2010, P INT WORKSHOP EMOTI, P77
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Feraru SM, 2015, INT CONF AFFECT, P125, DOI 10.1109/ACII.2015.7344561
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Gideon J, 2017, Arxiv, DOI arXiv:1706.03256
   Gideon J, 2021, IEEE T AFFECT COMPUT, V12, P1055, DOI [10.1109/TAFFC.2019.2916092, 10.1109/taffc.2019.2916092]
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393
   Jing TT, 2021, IEEE WINT CONF APPL, P605, DOI 10.1109/WACV48630.2021.00065
   Khare A, 2021, IEEE W SP LANG TECH, P381, DOI 10.1109/SLT48900.2021.9383618
   Kim J, 2017, INTERSPEECH, P1113, DOI 10.21437/Interspeech.2017-736
   Lan Zhenzhong, 2019, ARXIV190911942
   Latif S, 2023, IEEE T AFFECT COMPUT, V14, P1634, DOI 10.1109/TAFFC.2021.3114365
   Latif S, 2020, INTERSPEECH, P521, DOI 10.21437/Interspeech.2020-3194
   Latif S, 2022, IEEE T AFFECT COMPUT, V13, P992, DOI 10.1109/TAFFC.2020.2983669
   Latif S, 2021, IEEE REV BIOMED ENG, V14, P342, DOI 10.1109/RBME.2020.3006860
   Latif S, 2019, INTERSPEECH, P3920, DOI 10.21437/Interspeech.2019-3252
   Latif S, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925513, 10.1109/ACII.2019.8925513]
   Latif S, 2018, INTERSPEECH, P257, DOI 10.21437/Interspeech.2018-1625
   Latif S, 2018, INTERSPEECH, P3107, DOI 10.21437/Interspeech.2018-1568
   Latif S, 2018, INT CONF FRONT INFO, P88, DOI 10.1109/FIT.2018.00023
   Le Cun Y, 1989, ADV NEURAL INFORM PR, V2, P396, DOI DOI 10.1111/DSU.12130
   Leshem R, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.601763
   Li XF, 2019, SPEECH COMMUN, V110, P1, DOI 10.1016/j.specom.2019.04.004
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lotfian R, 2019, IEEE T AFFECT COMPUT, V10, P471, DOI 10.1109/TAFFC.2017.2736999
   Luo H, 2020, IEEE-ACM T AUDIO SPE, V28, P2047, DOI 10.1109/TASLP.2020.3006331
   Macary M, 2021, IEEE W SP LANG TECH, P373, DOI 10.1109/SLT48900.2021.9383456
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mariani G, 2018, Arxiv, DOI arXiv:1803.09655
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, 10.48550/arXiv.1411.1784]
   Neumann M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5769, DOI 10.1109/ICASSP.2018.8462162
   Ng Andrew Y., 2007, LEARNING, P759, DOI DOI 10.1145/1273496.1273592
   Ning YS, 2017, INT CONF ACOUST SPEE, P5615, DOI 10.1109/ICASSP.2017.7953231
   Ocquaye ENN, 2019, IEEE ACCESS, V7, P93847, DOI 10.1109/ACCESS.2019.2924597
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Parry J, 2019, INTERSPEECH, P1656, DOI 10.21437/Interspeech.2019-2753
   Pascual S, 2019, INTERSPEECH, P161, DOI 10.21437/Interspeech.2019-2605
   Povey D., 2011, IEEE 2011 WORKSHOP A
   Rana R, 2019, EUR J CANCER CARE, V28, DOI 10.1111/ecc.13033
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Sahu S, 2018, INTERSPEECH, P3693, DOI 10.21437/Interspeech.2018-1883
   Schuller B, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1564
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   Shukla A., 2020, P SIGHT SOUND WORKSH
   Shukla A, 2020, INT CONF ACOUST SPEE, P6299, DOI 10.1109/icassp40776.2020.9053415
   Song P, 2019, IEEE T AFFECT COMPUT, V10, P265, DOI 10.1109/TAFFC.2017.2705696
   Steidl S., 2009, AUTOMATIC CLASSIFICA
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P936, DOI 10.1109/TMM.2008.927665
   Xiao L, 2021, INT C PATT RECOG, P6874, DOI 10.1109/ICPR48806.2021.9412592
   Xiao YF, 2020, IEEE TETCI, V4, P480, DOI 10.1109/TETCI.2020.2972926
   Xu Y, 2017, IEEE IJCNN, P3461, DOI 10.1109/IJCNN.2017.7966291
   Yadegaridehkordi E, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103649
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Yufeng Yin, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P481, DOI 10.1145/3382507.3418813
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zhang H., 2018, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76
   Zhang Y, 2017, INT CONF ACOUST SPEE, P4990, DOI 10.1109/ICASSP.2017.7953106
   Zhou H, 2019, INT CONF ACOUST SPEE, P3732, DOI 10.1109/ICASSP.2019.8683299
   Zixing Zhang, 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P523, DOI 10.1109/ASRU.2011.6163986
NR 89
TC 5
Z9 5
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD JUL-SEP
PY 2023
VL 14
IS 3
BP 1912
EP 1926
DI 10.1109/TAFFC.2022.3167013
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T0NN8
UT WOS:001075041900016
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Sener, F
   Saraf, R
   Yao, A
AF Sener, Fadime
   Saraf, Rishabh
   Yao, Angela
TI Transferring Knowledge From Text to Video: Zero-Shot Anticipation for
   Procedural Actions
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Visualization; Robots; Data models; Task analysis; Predictive models;
   Natural languages; Text recognition; Deep learning; action anticipation;
   zero-shot learning; video analysis
AB Can we teach a robot to recognize and make predictions for activities that it has never seen before? We tackle this problem by learning models for video from text. This paper presents a hierarchical model that generalizes instructional knowledge from large-scale text corpora and transfers the knowledge to video. Given a portion of an instructional video, our model recognizes and predicts coherent and plausible actions multiple steps into the future, all in rich natural language. To demonstrate the capabilities of our model, we introduce the Tasty Videos Dataset V2, a collection of 4022 recipes for zero-shot learning, recognition and anticipation. Extensive experiments with various evaluation metrics demonstrate the potential of our method for generalization, given limited video data for training models.
C1 [Sener, Fadime] Univ Bonn, D-53113 Bonn, Germany.
   [Saraf, Rishabh] Indian Inst Technol ISM Dhanbad, Dhanbad 826004, Jharkhand, India.
   [Yao, Angela] Natl Univ Singapore, Singapore 119077, Singapore.
C3 University of Bonn; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (Indian School of Mines) Dhanbad;
   National University of Singapore
RP Sener, F (通讯作者)，Univ Bonn, D-53113 Bonn, Germany.
EM sener@cs.uni-bonn.de; rishabh.15je001745@am.iitism.ac.in;
   ayao@comp.nus.edu.sg
OI Yao, Angela/0000-0001-7418-6141; Saraf, Rishabh/0000-0001-7830-423X;
   Sener, Fadime/0000-0001-5004-6005
FU National Research Foundation, Singapore [NRF-NRFFAI1-2019-0001]
FX This work was supported by the National Research Foundation, Singapore
   under its NRF Fellowship for AI under Grant NRF-NRFFAI1-2019-0001.
CR Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   Abu Farha Y, 2018, PROC CVPR IEEE, P5343, DOI 10.1109/CVPR.2018.00560
   Alayrac JB, 2016, PROC CVPR IEEE, P4575, DOI 10.1109/CVPR.2016.495
   [Anonymous], 2016, P 2016 C N AM ASS CO
   [Anonymous], 1977, SPEECH UNDERSTANDING
   Ba Jimmy Lei, 2016, ARXIV
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, P65, DOI DOI 10.3115/1626355.1626389
   Beetz Michael, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P529, DOI 10.1109/Humanoids.2011.6100855
   Bengio S, 2015, ADV NEUR IN, V28
   Bosselut A., 2018, P 2018 C N AM CHAPTE, P173, DOI DOI 10.18653/V1/N18-1016
   Brattoli B, 2020, PROC CVPR IEEE, P4612, DOI 10.1109/CVPR42600.2020.00467
   Camporese G, 2020, Arxiv, DOI arXiv:2004.07711
   Carvalho M, 2018, ACM/SIGIR PROCEEDINGS 2018, P35, DOI 10.1145/3209978.3210036
   Chang CY, 2019, PROC CVPR IEEE, P3541, DOI 10.1109/CVPR.2019.00366
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Conneau A, 2017, P C EMP METH NAT LAN, P670, DOI [10.18653/v1/d17-1070, DOI 10.18653/V1/D17-1070]
   DALE R, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P68
   Damen D., 2020, RESCALING EGOCENTRIC
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Dessalene E, 2020, Arxiv, DOI arXiv:2006.03201
   Finn Chelsea, 2017, C ROB LEARN, P357
   Freitag M, 2017, Arxiv, DOI [arXiv:1702.01806, DOI 10.48550/ARXIV.1702.01806]
   Furnari A, 2019, IEEE I CONF COMP VIS, P6261, DOI 10.1109/ICCV.2019.00635
   Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17
   Gao J., 2017, PROC BRIT MACH VIS C
   Hahn M, 2019, Arxiv, DOI arXiv:1901.00484
   Hammond K. J., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P267
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2018, Arxiv, DOI arXiv:1801.07239
   Holtzman A, 2020, Arxiv, DOI [arXiv:1904.09751, 10.48550/arXiv.1904.09751]
   Huang DA, 2016, LECT NOTES COMPUT SC, V9908, P137, DOI 10.1007/978-3-319-46493-0_9
   Jermsurawong J., 2015, P 2015 C EMPIRICAL M, P781, DOI [10.18653/V1/D15-1090, DOI 10.18653/V1/D15-1090]
   Ke QH, 2019, PROC CVPR IEEE, P9917, DOI 10.1109/CVPR.2019.01016
   Kiddon C., 2015, EMNLP, P982, DOI 10.18653/v1/D15-1114
   Kiddon C., 2016, P 2016 C EMP METH NA, P329, DOI DOI 10.18653/V1/D16-1032
   Kingma D. P., 2014, C TRACK P
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V28, P3, DOI DOI 10.48550/ARXIV.1506.06726
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105
   Kukleva A, 2019, PROC CVPR IEEE, P12058, DOI 10.1109/CVPR.2019.01234
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lea C, 2016, LECT NOTES COMPUT SC, V9907, P36, DOI 10.1007/978-3-319-46487-9_3
   Lee HH, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P181, DOI 10.1145/3366424.3383536
   Li Y, 2018, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2018.00782
   Lin D., 2015, PROC BRIT MACH VIS C
   Liu C., 2016, PROC C EMPIR METHODS
   Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586
   Mahmud T, 2021, Arxiv, DOI arXiv:1908.00943
   Mahmud T, 2017, IEEE I CONF COMP VIS, P5784, DOI 10.1109/ICCV.2017.616
   Malmaud Jonathan, 2014, P ACL 2014 WORKSH SE, P33, DOI DOI 10.3115/V1/W14-2407
   Malmaud Jonathan, 2015, NAACL
   Miao Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P704, DOI 10.1007/978-3-030-58452-8_41
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Miech A, 2019, IEEE COMPUT SOC CONF, P2915, DOI 10.1109/CVPRW.2019.00351
   Min WQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P402, DOI 10.1145/3123266.3123272
   Hoai M, 2011, PROC CVPR IEEE
   Ngiam J., 2011, P 28 INT C INT C MAC, P689
   NLTK, 2018, NATURAL LANGUAGE TOO
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Regneri M., 2013, TACL, V1, P25, DOI DOI 10.1162/TACL_A_00207
   Richard A, 2017, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2017.140
   Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Lin AS, 2020, Arxiv, DOI arXiv:2005.09606
   Salvador A, 2019, PROC CVPR IEEE, P10445, DOI 10.1109/CVPR.2019.01070
   Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327
   Sener Fadime, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P154, DOI 10.1007/978-3-030-58517-4_10
   Sener F, 2019, IEEE I CONF COMP VIS, P862, DOI 10.1109/ICCV.2019.00095
   Sener F, 2018, PROC CVPR IEEE, P8368, DOI 10.1109/CVPR.2018.00873
   Sener O, 2015, IEEE I CONF COMP VIS, P4480, DOI 10.1109/ICCV.2015.509
   Shen Y, 2018, LECT NOTES COMPUT SC, V11206, P202, DOI 10.1007/978-3-030-01216-8_13
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Srivastava N., 2012, ADV NEURAL INF PROCE, V25, P2222, DOI DOI 10.1109/CVPR.2013.49
   Sünderhauf N, 2018, INT J ROBOT RES, V37, P405, DOI 10.1177/0278364918770733
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Tang YS, 2019, PROC CVPR IEEE, P1207, DOI 10.1109/CVPR.2019.00130
   Tenorth M, 2010, IEEE INT CONF ROBOT, P1499, DOI 10.1109/ROBOT.2010.5509161
   Tran V., 2019, CORR
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O., 2015, PROC INT C MACH LEAR
   Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18
   Wang H, 2022, Arxiv, DOI arXiv:2007.13374
   Wang H, 2019, PROC CVPR IEEE, P11564, DOI 10.1109/CVPR.2019.01184
   Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wikihow, 2005, ANYTHING
   Wu CX, 2016, IEEE INT CONF ROBOT, P2479, DOI 10.1109/ICRA.2016.7487401
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhang BW, 2018, LECT NOTES COMPUT SC, V11217, P385, DOI 10.1007/978-3-030-01261-8_23
   Zhou LW, 2018, AAAI CONF ARTIF INTE, P7590
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
   Zhou YP, 2015, IEEE I CONF COMP VIS, P4498, DOI 10.1109/ICCV.2015.511
   Zhu B, 2020, PROC CVPR IEEE, P5518, DOI 10.1109/CVPR42600.2020.00556
   Zhu Y, 2018, PROC CVPR IEEE, P9436, DOI 10.1109/CVPR.2018.00983
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
   Zhukov D, 2019, PROC CVPR IEEE, P3532, DOI 10.1109/CVPR.2019.00365
   Zolfaghari M., 2019, ARXIV
NR 104
TC 0
Z9 0
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUN 1
PY 2023
VL 45
IS 6
BP 7836
EP 7852
DI 10.1109/TPAMI.2022.3218596
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F5AO9
UT WOS:000982475600081
PM 36318562
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Sejnowski, TJ
AF Sejnowski, Terrence J.
TI Large Language Models and the Reverse Turing Test
SO NEURAL COMPUTATION
LA English
DT Article
ID LEARNING ALGORITHM; NEUROSCIENCE
AB Large language models (LLMs) have been transformative. They are pretrained foundational models that are self-supervised and can be adapted with fine-tuning to a wide range of natural language tasks, each of which previously would have required a separate network model. This is one step closer to the extraordinary versatility of human language. GPT-3 and, more recently, LaMDA, both of them LLMs, can carry on dialogs with humans on many topics after minimal priming with a few examples. However, there has been a wide range of reactions and debate on whether these LLMs understand what they are saying or exhibit signs of intelligence. This high variance is exhibited in three interviews with LLMs reaching wildly different conclusions. A new possibility was uncovered that could explain this divergence. What appears to be intelligence in LLMs may in fact be a mirror that reflects the intelligence of the interviewer, a remarkable twist that could be considered a reverse Turing test. If so, then by studying interviews, we may be learning more about the intelligence and beliefs of the interviewer than the intelligence of the LLMs. As LLMs become more capable, they may transform the way we interact with machines and how they interact with each other. Increasingly, LLMs are being coupled with sensorimotor devices. LLMs can talk the talk, but can they walk the walk? A road map for achieving artificial general autonomy is outlined with seven major improvements inspired by brain systems and how LLMs could in turn be used to uncover new insights into brain function.
C1 [Sejnowski, Terrence J.] Salk Inst Biol Studies, La Jolla, CA 92093 USA.
   [Sejnowski, Terrence J.] Univ Calif San Diego, Div Biol Sci, La Jolla, CA 92037 USA.
C3 Salk Institute; University of California System; University of
   California San Diego
RP Sejnowski, TJ (通讯作者)，Salk Inst Biol Studies, La Jolla, CA 92093 USA.; Sejnowski, TJ (通讯作者)，Univ Calif San Diego, Div Biol Sci, La Jolla, CA 92037 USA.
EM terry@salk.edu
FU CIFAR
FX I am indebted to many who, over the decades, have helped guide my
   thinking, especially to Beatrice Golomb, who with her critical thinking
   helped me avoid groupthink; to Geoffrey Hinton, who saw our future and
   made it happen; to Peter Dayan, Read Montague, and Tony Zador, who
   helped me stay on target; to Francis Crick, whose insights into the
   nature of biology kept me focused on the nature of brains; to Patricia
   Churchland, whose big questions about brains have been inspiring and her
   wordsmithing talents have improved the writing; to Gerald Pao, with his
   Zen-like knowledge of many areas of science, engineering, mathematics,
   and medicine; and to all my students, colleagues, and reviewers who have
   raised my level of intelligence. Mitra Hartmann noticed the remarkable
   parallel between LLMs and the Mirror of Erised. Ilenna Jones tested
   GPT-3 with counterfactuals in real time during a lecture. The idea of
   using large neurofoundation models to download brains came out of a
   meeting organized by Blake Richards and Joel Zylberberg in conjunction
   with the Learning in Machines and Brains program funded by CIFAR.
   Discussions at the Telluride Neuromorphic Cognition Engineering Workshop
   helped shape my perspective on Large Language Models (NSF 2020624
   AccelNet: Accelerating Research on Neuromorphic Perception, Action, and
   Cognition). Finally, I thank GPT-3 for sharing its insights in the
   closing remarks.
CR Abbott E., 1884, FLATLAND ROMANCE MAN
   ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Aguera y Arcas B., 2022, ECONOMIST
   Aguera y Arcas B., 2022, NEURAL COMPUT
   Allman J. M., 1999, SCI AM LIB
   Amodei Dario, 2018, AI AND COMPUTE
   Anderson Stephen R., 2002, LANGUAGE ORGAN LINGU
   [Anonymous], 1999, SCI CRIB WHAT EARLY
   Arbib MA, 2006, ACTION TO LANGUAGE VIA THE MIRROR NEURON SYSTEM, P3, DOI 10.1017/CBO9780511541599.002
   Bartlett PL, 2019, J MACH LEARN RES, V20, P1
   Berner C., 2021, ARXIV, DOI DOI 10.48550/ARXIV.1912.06680
   Bjorklund D. F., 2007, WHY YOUTH IS NOT WAS
   Bratton B., 2022, NOEMA MAGAZINE
   Brenner S, 1996, CURR BIOL, V6, P1202, DOI 10.1016/S0960-9822(02)70689-1
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chomsky Noam, 1986, LANGUAGE PROBLEMS KN
   Chomsky Noam, 1971, NEW YORK REV BOOKS, V17, P18
   Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]
   Churchland P. S., 2019, CONSCIENCE ORIGINS M
   Dasgupta I., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2207.07051
   de Waal F., 2016, ARE WE SMART ENOUGH
   Dehaene S, 2001, COGNITION, V79, P1, DOI 10.1016/S0010-0277(00)00123-2
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Fourier J., 1808, MEMOIRE PROPAGATION, V1
   Gao P., 2017, BIORXIV, DOI DOI 10.1101/214262
   Graybiel AM, 1997, SCHIZOPHRENIA BULL, V23, P459, DOI 10.1093/schbul/23.3.459
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011
   Hayes TL, 2021, NEURAL COMPUT, V33, P2908, DOI 10.1162/neco_a_01433
   Hoffmann J, 2022, Arxiv, DOI [arXiv:2203.15556, DOI 10.48550/ARXIV.2203.15556]
   Hofstadter D., 2022, ECONOMIST
   Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]
   Karra SR, 2023, Arxiv, DOI arXiv:2204.12000
   Kilner JM, 2013, CURR BIOL, V23, pR1057, DOI 10.1016/j.cub.2013.10.051
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lemoine B., 2022, MEDIUM
   Li H, 2022, COMMUN ACM, V65, P56, DOI 10.1145/3490443
   Li J. S., 2022, ARXIV
   Lighthill, 1973, ARTIFICIAL INTELLIGE
   Lister R, 2013, SCIENCE, V341, P629, DOI 10.1126/science.1237905
   Liu SQ, 2022, SCI ROBOT, V7, DOI 10.1126/scirobotics.abo0235
   Marcus G., 2022, SCI AM, P44
   Mehonic A, 2022, NATURE, V604, P255, DOI 10.1038/s41586-021-04362-w
   Morin F., 2005, AISTATS, V5, P246
   Nakahira Y, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.1916367118
   Navlakha S., 2018, WIRED
   NETtalk, 1986, US
   Ngai J, 2022, CELL, V185, P4, DOI 10.1016/j.cell.2021.11.037
   Nishimura T, 2022, SCIENCE, V377, P760, DOI 10.1126/science.abm1574
   OpenAI, 2022, FIN TUN
   Piloto LS, 2022, NAT HUM BEHAV, V6, P1257, DOI 10.1038/s41562-022-01394-8
   QUARTZ SR, 1994, BEHAV BRAIN SCI, V17, P725, DOI 10.1017/S0140525X00036839
   Quinn T, 2018, TLS-TIMES LIT SUPPL, P31
   Richards B, 2022, CELL, V185, P2640, DOI 10.1016/j.cell.2022.06.047
   Ritter SM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00215
   Rosenblatt F., 1961, PRINCIPLES NEURODYNA
   Rowling J. K., 1997, H POTTER SORCERERS S
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sejnowski T. J., 1987, Complex Systems, V1, P145
   Sejnowski T. J., 2019, THINK TANK 40 NEUROS, P257
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Sejnowski T, 2012, SCI AM, V307, P54, DOI 10.1038/scientificamerican1012-54
   Sejnowski TJ, 2018, DEEP LEARNING REVOLUTION, P1
   Sevilla J, 2022, Arxiv, DOI [arXiv:2202.05924, 10.48550/arXiv.2202.05924, DOI 10.48550/ARXIV.2202.05924, 10.48550/ARXIV.2202.05924]
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Simonyan K, 2011, NEUROSCIENTIST, V17, P197, DOI 10.1177/1073858410386727
   Sokolov AA, 2017, TRENDS COGN SCI, V21, P313, DOI 10.1016/j.tics.2017.02.005
   Sterling P, 2012, PHYSIOL BEHAV, V106, P5, DOI 10.1016/j.physbeh.2011.06.004
   Strobelt H., 2022, ARXIV, DOI [10.48550/arXiv.2208.07852, DOI 10.48550/ARXIV.2208.07852]
   Sutton R. S., 1988, Machine Learning, V3, P9, DOI 10.1007/BF00115009
   TESAURO G, 1989, ARTIF INTELL, V39, P357, DOI 10.1016/0004-3702(89)90017-9
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343
   Thoppilan R., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.08239
   Ullman TD, 2017, TRENDS COGN SCI, V21, P649, DOI 10.1016/j.tics.2017.05.012
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XJ, 2022, ANNU REV NEUROSCI, V45, P533, DOI 10.1146/annurev-neuro-110920-035434
   Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, DOI 10.48550/ARXIV.2201.11903]
   Weinberg J., 2020, DAILY NOUS
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wolfram S., 2016, FAREWELL M MINSKY 19
NR 80
TC 7
Z9 7
U1 16
U2 30
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0899-7667
EI 1530-888X
J9 NEURAL COMPUT
JI Neural Comput.
PD FEB 17
PY 2023
VL 35
IS 3
BP 309
EP 342
DI 10.1162/neco_a_01563
PG 34
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA 9D4FQ
UT WOS:000936055200003
PM 36746144
OA Green Submitted, Green Accepted, Bronze
DA 2023-11-10
ER

PT J
AU Akànbí, LA
   Odéjobí, OA
AF Akanbi, Lukman Adewale
   Odejobi, Odetunji Ajadi
TI Automatic recognition of oral vowels in tone language: Experiments with
   fuzzy logic and neural network models
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Speech recognition; Tone language; Soft-computing
AB Automatic recognition of tone language speech is a complex problem in that it involves two parallel recognition tasks. A recognition system to accomplish this task must be able to simultaneously recognise tone and phone Components in the acoustic signal. The acoustic cue for the tones is the fundamental frequency (F0) while the first and second formant (F1 and F2) frequencies are the acoustic cues for the phones. In this study, we experiment with two soft-computing techniques, namely: artificial neural network (ANN) and fuzzy logic (FL) in the recognition of oral vowels in tone language. The standard Yoruba (SY) language is used for our case study.
   The ANN and FL speech recognition systems were developed using MatLab. The result showed that the ANN based model performed better on the training data while the FL based model performed better on the test set. This implies that the ANN system was able to interpolate or approximate the data more accurately whereas the FL system is better at extrapolating from the data. In addition, it was observed that the ANN system required larger amount of data for it is development whereas the FL system development requires some expert's knowledge. In conclusion, the FL based system seems to be the better approach for developing practical automatic speech recognition (ASR) system for languages such as SY where the language resources are limited. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Odejobi, Odetunji Ajadi] Natl Univ Ireland Univ Coll Cork, Dept Comp Sci, Cork Constraint Computat Ctr, Cork, Ireland.
   [Akanbi, Lukman Adewale] Obafemi Awolowo Univ, Dept Comp Sci & Engn, Ife, Nigeria.
C3 University College Cork; Obafemi Awolowo University
RP Odéjobí, OA (通讯作者)，Natl Univ Ireland Univ Coll Cork, Dept Comp Sci, Cork Constraint Computat Ctr, Washington St, Cork, Ireland.
EM laakanbi@oauife.edu.ng; t.odejobi@4c.ucc.ie
RI Akanbi, Lukman Adewale/HMW-1378-2023
OI Akanbi, Lukman Adewale/0000-0003-1258-9142
CR ADEWALE LO, 1986, YORUBA HIGH TONE SYL, P81
   AKINLABI A, 1993, LINGUIST INQ, V24, P139
   AKINLABI LA, 2000, TONAL COMPLEXES TONA
   [Anonymous], 2004, PRAAT DOING PHONETIC
   BAMGBOSE A, 1965, YORUBA ORTOGRAPHY
   BAMGBOSE Ayo, 1990, FONOLOJI ATI GIRAMA
   BEZDEK JC, 1993, DIGIT SIGNAL PROCESS, V3, P253
   Brito J, 2007, APPL SOFT COMPUT, V7, P1035, DOI 10.1016/j.asoc.2006.05.004
   Chudy V., 1991, Neurocomputing, V3, P259, DOI 10.1016/0925-2312(91)90007-X
   Connell B., 1990, PHONOLOGY, V7, P1, DOI 10.1017/S095267570000110X
   DAI J, 1991, IEEE T SPEECH AUDIO, V30, P259
   DALSTON RM, 1975, J ACOUSTIC SOC AM, V570
   Demeechai T, 2001, SPEECH COMMUN, V33, P241, DOI 10.1016/S0167-6393(00)00017-0
   DEMORI R, 1979, IEEE T ACOUST SPEECH, V27, P538, DOI 10.1109/TASSP.1979.1163281
   Demuth H, 2002, NEURAL NETWORK TOOLB
   Fu S. W. K., 1996, Communications of COLIPS, V6, P1
   Hagen A, 2005, COMPUT SPEECH LANG, V19, P3, DOI 10.1016/j.csl.2003.12.002
   Halavati R, 2007, APPL SOFT COMPUT, V7, P828, DOI 10.1016/j.asoc.2006.02.007
   HANSON SJ, 1995, BACKPROPAGATION THEO, P237
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   HUANG EF, 1994, COMPUT SPEECH LANG, V8, P39, DOI 10.1006/csla.1994.1002
   JOHNSON D, 2005, MODELLING SPEECH SIG
   JUANG BH, 1991, TECHNOMETRICS, V33, P251, DOI 10.2307/1268779
   Lee H. O., 1991, INT J CONFL MANAGE, V2, P181, DOI [10.1108/eb022698, DOI 10.1108/EB022698]
   LEE KF, 1990, IEEE T ACOUST SPEECH, V38, P599, DOI 10.1109/29.52701
   LEE T, 1995, IEEE T SPEECH AUDI P, V3, P204, DOI 10.1109/89.388147
   LEE T, 1996, THESIS CHINESE U HON
   LEE Y, 1993, COMPUTER SPEECH LANG, V70, P247
   Lefèvre F, 2003, COMPUT SPEECH LANG, V17, P113, DOI 10.1016/S0885-2308(03)00004-4
   Leung RWK, 2003, EXPERT SYST, V20, P20, DOI 10.1111/1468-0394.00221
   Lin CH, 1996, SPEECH COMMUN, V18, P175, DOI 10.1016/0167-6393(95)00043-7
   Lin MT, 1999, COMPUT SPEECH LANG, V13, P207, DOI 10.1006/csla.1999.0121
   LIU LC, 1989, COMPUTER SPEECH LANG, V30, P253
   MENGJIE Z, 2001, OVERVIEW SPEECH RECO
   Ming J, 1996, COMPUT SPEECH LANG, V10, P229, DOI 10.1006/csla.1996.0012
   Nair NU, 2010, COMPUT SPEECH LANG, V24, P307, DOI 10.1016/j.csl.2009.05.001
   Odéjobí OA, 2007, COMPUT SPEECH LANG, V21, P325, DOI 10.1016/j.csl.2006.06.005
   ODéloBí OA, 2008, STUD COMPUT INTELL, V83, P23
   PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625
   PRZEZDZIECKI MA, 2005, THESIS CORNEL U
   Qian Y, 2009, SPEECH COMMUN, V51, P1169, DOI 10.1016/j.specom.2009.08.001
   Qian Y, 2008, COMPUT SPEECH LANG, V22, P360, DOI 10.1016/j.csl.2007.12.003
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rao AV, 2001, IEEE T SPEECH AUDI P, V9, P111, DOI 10.1109/89.902278
   Ray KS, 1997, NEURAL NETWORKS, V10, P161, DOI 10.1016/S0893-6080(96)00056-1
   RIIS SK, 1998, THESIS TU DENMARK
   Rosti AVI, 2004, COMPUT SPEECH LANG, V18, P181, DOI 10.1016/j.csl.2003.09.004
   Russell MJ, 2005, COMPUT SPEECH LANG, V19, P205, DOI 10.1016/j.csl.2004.08.001
   Salor Ö, 2007, COMPUT SPEECH LANG, V21, P580, DOI 10.1016/j.csl.2007.01.001
   Sato Y, 2005, APPL SOFT COMPUT, V5, P181, DOI 10.1016/j.asoc.2004.06.005
   Shen JL, 1999, COMPUT SPEECH LANG, V13, P79, DOI 10.1006/csla.1998.0112
   SJOLANDER K, 2006, WAVESURFER INTRO
   Taylor P, 1998, LANG SPEECH, V41, P493, DOI 10.1177/002383099804100411
   Thubthong N, 2001, INT J UNCERTAIN FUZZ, V9, P815
   TOTH L, 2007, COMPUTER SPEECH LANG, V210, P526
   Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8
   Trentin E, 2006, NEUROCOMPUTING, V70, P398, DOI 10.1016/j.neucom.2005.12.130
   Weber K, 2003, COMPUT SPEECH LANG, V17, P195, DOI 10.1016/S0885-2308(03)00012-3
   Wester M, 2003, COMPUT SPEECH LANG, V17, P69, DOI 10.1016/S0885-2308(02)00030-X
   *WIK, 2007, YOR LANG
   WU P, 1992, NEUROCOMPUTING, V4, P109, DOI 10.1016/0925-2312(92)90049-U
   Wutiwiwatchsi C, 2007, SPEECH COMMUN, V49, P8, DOI 10.1016/j.specom.2006.10.004
   Zhang YY, 1998, ICSP '98: 1998 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, PROCEEDINGS, VOLS I AND II, P613, DOI 10.1109/ICOSP.1998.770286
   Zhao J, 2002, IEEE IND ELEC, P229, DOI 10.1109/IECON.2002.1187512
   ZUE V, 1998, STUDIES NATURAL LANG
NR 65
TC 2
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JAN
PY 2011
VL 11
IS 1
BP 1467
EP 1480
DI 10.1016/j.asoc.2010.04.018
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 647BR
UT WOS:000281591300144
DA 2023-11-10
ER

PT J
AU Mamta
   Ekbal, A
   Bhattacharyya, P
AF Mamta
   Ekbal, Asif
   Bhattacharyya, Pushpak
TI Exploring Multi-lingual, Multi-task, and Adversarial Learning for
   Low-resource Sentiment Analysis
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Sentiment analysis; low-resource language; multi-task; multi-lingual;
   adversarial training
ID PRODUCTS; LEXICON; SET
AB Deep learning has become most prominent in solving various Natural Language Processing (NLP) tasks including sentiment analysis. However, these techniques require a considerably large amount of annotated corpus, which is not easy to obtain for most of the languages, especially under the scenario of low-resource settings. In this article, we propose a deep multi-task multi-lingual adversarial framework to solve the resource-scarcity problem of sentiment analysis by leveraging the useful and relevant knowledge from a high-resource language. To transfer the knowledge between the different languages, both the languages are mapped to the shared semantic space using cross-lingual word embeddings. We evaluate our proposed architecture on a low-resource language, Hindi, using English as the high-resource language. Experiments show that our proposed model achieves an accuracy of 60.09% for the movie review dataset and 72.14% for the product review dataset. The effectiveness of our proposed approach is demonstrated with significant performance gains over the state-of-the-art systems and translation-based baselines.
C1 [Mamta; Ekbal, Asif; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Patna, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System)
RP Ekbal, A (通讯作者)，Indian Inst Technol Patna, Patna, Bihar, India.
EM mamta20118@gmail.com; asif.ekbal@gmail.com; pb@iitb.ac.in
RI Ekbal, Asif/JKI-7638-2023; Ekbal, Asif/I-6203-2016
OI , Mamta/0000-0003-3707-7610; Ekbal, Asif/0000-0003-3612-8834
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahmad Z, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112851
   Akhtar MS, 2020, IEEE COMPUT INTELL M, V15, P64, DOI 10.1109/MCI.2019.2954667
   Akhtar MS, 2017, KNOWL-BASED SYST, V125, P116, DOI 10.1016/j.knosys.2017.03.020
   Akhtar Md Shad, 2016, P COLING 2016 26 INT, P482
   Akhtar Md Shad, 2018, P 2018 C N AM CHAPTE, P572
   Akhtar Md Shad, 2017, P 2017 C EMPIRICAL M, P540
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Attia M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P635
   BAKLIWAL A, 2013, SENTIMENT ANAL POLIT
   Bhattacharyya P., 2010, P ICON 8 INT C NAT L
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Chaturvedi I, 2018, INFORM FUSION, V44, P65, DOI 10.1016/j.inffus.2017.12.006
   Chen X., 2018, T ASSOC COMPUT LING, V6, P557, DOI DOI 10.1162/TACL_A_00039
   Chikersal P, 2015, P 9 INT WORKSH SEM E, P647, DOI DOI 10.18653/V1/S15-2108
   Chung JY, 2015, PR MACH LEARN RES, V37, P2067
   Conneau A, 2018, Arxiv, DOI arXiv:1710.04087
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   Dey A, 2018, EXPERT SYST APPL, V103, P92, DOI 10.1016/j.eswa.2018.03.004
   Can EF, 2018, Arxiv, DOI arXiv:1806.04511
   Ghiassi M, 2018, EXPERT SYST APPL, V106, P197, DOI 10.1016/j.eswa.2018.04.006
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gulli A., 2017, DEEP LEARNING KERAS
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Hu JJ, 2020, PR MACH LEARN RES, V119
   Joshi A, 2012, P COLING 2012 POST, V1, P73
   Kingma D. P., 2014, C TRACK P
   Kumar S, 2019, INFORM FUSION, V52, P41, DOI 10.1016/j.inffus.2018.11.001
   Lin Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P799
   Liu Pengfei, 2017, ADVERSARIAL MULTITAS
   Liu Y, 2017, INFORM FUSION, V36, P149, DOI 10.1016/j.inffus.2016.11.012
   Lou YX, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3389035
   Mamta, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5046
   Masumura R., 2018, P 27 INT C COMP LING, P3586
   Mishra Sudhanshu, 2021, SN COMPUT SCI, V2, P72, DOI [10.1007/s42979- 021- 00455-5, DOI 10.1007/S42979-021-00455-5]
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   O'Hare Neil., 2009, P 1 INT CIKM WORKSHO, P9, DOI [10.1145/1651461.1651464, DOI 10.1145/1651461.1651464]
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Shuang K, 2020, INFORM FUSION, V61, P13, DOI 10.1016/j.inffus.2020.03.003
   Singhal P., 2016, P COLING 2016 26 INT, P3053
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thakkar G., 2021, CLEOPATRA WWW, P76, DOI [10.48550/arXiv.2212.07160, DOI 10.48550/ARXIV.2212.07160]
   Valdivia A, 2018, INFORM FUSION, V44, P126, DOI 10.1016/j.inffus.2018.03.007
   Van de Kauter M, 2015, EXPERT SYST APPL, V42, P4999, DOI 10.1016/j.eswa.2015.02.007
   Wu CH, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1091, DOI 10.1145/3357384.3357973
   Wu FZ, 2017, INFORM FUSION, V35, P26, DOI 10.1016/j.inffus.2016.09.001
   Yadav S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5234
   Ye X, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.113987
   Zhou X., 2016, P 2016 C EMPIRICAL M, P247, DOI [DOI 10.18653/V1/D16-1024, 10.18653/v1/d16-1024]
NR 52
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP
PY 2022
VL 21
IS 5
AR 104
DI 10.1145/3514498
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9Z2DN
UT WOS:000950956700020
DA 2023-11-10
ER

PT J
AU Karyukin, V
   Rakhimova, D
   Karibayeva, A
   Turganbayeva, A
   Turarbek, A
AF Karyukin, Vladislav
   Rakhimova, Diana
   Karibayeva, Aidana
   Turganbayeva, Aliya
   Turarbek, Asem
TI The neural machine translation models for the low-resource
   Kazakh-English language pair
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Neural machine translation; Forward translation; Backward translation;
   Seq2Seq; RNN; BRNN; Transformer; OpenNMT; English; Kazakh
AB The development of the machine translation field was driven by people's need to communicate with each other globally by automatically translating words, sentences, and texts from one language into another. The neural machine translation approach has become one of the most significant in recent years. This approach requires large parallel corpora not available for low-resource languages, such as the Kazakh language, which makes it difficult to achieve the high performance of the neural machine translation models. This article explores the existing methods for dealing with low-resource languages by artificially increasing the size of the corpora and improving the performance of the Kazakh-English machine translation models. These methods are called forward translation, backward translation, and transfer learning. Then the Sequence-to-Sequence (recurrent neural network and bidirectional recurrent neural network) and Transformer neural machine translation architectures with their features and specifications are concerned for conducting experiments in training models on parallel corpora. The experimental part focuses on building translation models for the high-quality translation of formal social, political, and scientific texts with the synthetic parallel sentences from existing monolingual data in the Kazakh language using the forward translation approach and combining them with the parallel corpora parsed from the official government websites. The total corpora of 380,000 parallel Kazakh-English sentences are trained on the recurrent neural network, bidirectional recurrent neural network, and Transformer models of the OpenNMT framework. The quality of the trained model is evaluated with the BLEU, WER, and TER metrics. Moreover, the sample translations were also analyzed. The RNN and BRNN models showed a more precise translation than the Transformer model. The Byte-Pair Encoding tokenization technique showed better metrics scores and translation than the word tokenization technique. The Bidirectional recurrent neural network with the Byte-Pair Encoding technique showed the best performance with 0.49 BLEU, 0.51 WER, and 0.45 TER.
C1 [Karyukin, Vladislav; Rakhimova, Diana; Karibayeva, Aidana; Turganbayeva, Aliya; Turarbek, Asem] Al Farabi Kazakh Natl Univ, Dept Informat Syst, Alma Ata, Kazakhstan.
   [Rakhimova, Diana] Inst Informat & Computat Technol, Alma Ata, Kazakhstan.
C3 Al-Farabi Kazakh National University; Institute of Information &
   Computational Technologies
RP Karyukin, V (通讯作者)，Al Farabi Kazakh Natl Univ, Dept Informat Syst, Alma Ata, Kazakhstan.
EM vladislav.karyukin@gmail.com
RI Rakhimova, Diana/D-8421-2012
OI Rakhimova, Diana/0000-0003-1427-198X
FU Ministry of Science and Higher Education of the Republic of Kazakhstan
   [IRN AP 09259556]
FX This research was performed and financed by the grant Project IRN AP
   09259556 of the Ministry of Science and Higher Education of the Republic
   of Kazakhstan. The funders had no role in study design, data collection
   and analysis, decision to publish, or preparation of the manuscript.
CR Abdulmumin I, 2020, J COMPUT PHYS, V29, P1478, DOI [10.13140/RG.2.2.11076.55687, DOI 10.13140/RG.2.2.11076.55687]
   Abdulmumin I., 2020, P INFORM COMMUNICATI, P355
   Ahmadnia B, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 1, P475, DOI 10.5220/0010362604750481
   [Anonymous], 2015, P 10 WORKSHOP STAT M, DOI DOI 10.18653/V1/W15-3031
   Babhulgaonkar AR, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), P62, DOI 10.1109/ICISIM.2017.8122149
   Bojar Ondej, 2017, P 2 C MACH TRANSL, P489, DOI DOI 10.18653/V1/W17-4755
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489
   Gongora S, 2022, PROCEEDINGS OF THE FIFTH WORKSHOP ON THE USE OF COMPUTATIONAL METHODS IN THE STUDY OF ENDANGERED LANGUAGES (COMPUTEL-5 2022), P127
   Ha TL, 2016, Arxiv, DOI arXiv:1611.04798
   Islam MA, 2021, NEURAL COMPUT APPL, V33, P12141, DOI 10.1007/s00521-021-05895-x
   Jooste W, 2022, INFORMATION, V13, DOI 10.3390/info13020088
   Kalekeyeva M, 2021, IEEE INFOCOM SER
   Kandimalla A, 2022, INFORMATION, V13, DOI 10.3390/info13050245
   Karyukin V., 2022, PARALLEL CORPORA ENG
   Karyukin V., 2022, OPENNMT KAZAKH ENGLI
   Khusainov A, 2018, SPRINGERBRIEF MATH, V11107
   Koehn P, 2022, WORLD MACHINE TRANSL
   Lankford S, 2022, INFORMATION, V13, DOI 10.3390/info13070309
   Mohamed SA, 2021, NEURAL COMPUT APPL, V33, P15919, DOI 10.1007/s00521-021-06268-0
   Mouratidis D, 2020, ARTIF INTELL, V584, P76, DOI [10.1007/978-3-030-49186-4_7, DOI 10.1007/978-3-030-49186-4_7]
   Niyazbek M, 2021, 3 INT C ENV PREVENTI, V687, P1
   Nonaka K, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071014
   Primeminister, 2022, OFF INF SOURC PRIM M
   Rakhimova D, 2021, 7 INT C ENG ETMIS 20, P1
   Rubino R, 2020, MACH TRANSL, V34, P347, DOI 10.1007/s10590-020-09258-6
   Sapakova S, 2022, B PHYS MATH ABAI KAZ
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Shanmugavadivel K, 2022, COMPUT SPEECH LANG, V76, DOI 10.1016/j.csl.2022.101407
   Sharma S., 2020, INNOVATIVE APPL NANO, P1, DOI [10.1109/TEM.2020.3019033, DOI 10.4018/978-1-7998-6467-7.CH001]
   Sindhu C., 2022, 2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS), P266, DOI 10.1109/ICACCS54159.2022.9785158
   Singh S.A., 2019, IEEE IMTC P, P1
   Strategy, 2022, ADDR PRES REP KAZ
   The Republic of Kazakhstan, 2023, OFF WEBS PRES REP KA
   Ngo TV, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2101755
   Tiedemann J, 2022, OPUS OPEN PARALLEL C
   Toral A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P386
   Tukeyev U, 2020, COGENT ENG, V7, DOI 10.1080/23311916.2020.1856500
   Tukeyev U, 2018, MATEC WEB C 3 INT C
   Turganbayeva A, 2022, INFORMATION, V13, DOI 10.3390/info13090411
   Van der Linde J, 2022, PARACRAWL
   Wan Y, 2022, COMPUT LINGUIST, V48, P321, DOI 10.1162/coli_a_00435
   Wu CK, 2022, COMPUT SPEECH LANG, V72, DOI 10.1016/j.csl.2021.101283
   Zhanabergenova D, 2021, LECT NOTES ARTIF INT, V12876, P629, DOI 10.1007/978-3-030-88081-1_47
   Zhang JJ, 2020, SCI CHINA TECHNOL SC, V63, P2028, DOI 10.1007/s11431-020-1632-x
   Zhao LX, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210915
NR 45
TC 0
Z9 0
U1 6
U2 9
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD FEB 8
PY 2023
VL 9
AR e1224
DI 10.7717/peerj-cs.1224
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Y9NQ
UT WOS:000933018100005
PM 37346576
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Rothe, S
   Narayan, S
   Severyn, A
AF Rothe, Sascha
   Narayan, Shashi
   Severyn, Aliaksei
TI Leveraging Pre-trained Checkpoints for Sequence Generation Tasks
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Unsupervised pre-training of large neural models has recently revolutionized Natural Language Processing. By warm-starting from the publicly released checkpoints, NLP practitioners have pushed the state-of-the-art on multiple benchmarks while saving significant amounts of compute time. So far the focus has been mainly on the Natural Language Understanding tasks. In this paper, we demonstrate the efficacy of pre-trained checkpoints for Sequence Generation. We developed a Transformer-based sequence-to-sequence model that is compatible with publicly available pre-trained BERT, GPT-2, and RoBERTa checkpoints and conducted an extensive empirical study on the utility of initializing our model, both encoder and decoder, with these checkpoints. Our models result in new state-of-the-art results on Machine Translation, Text Summarization, Sentence Splitting, and Sentence Fusion.
C1 [Rothe, Sascha; Narayan, Shashi; Severyn, Aliaksei] Google Res, Mountain View, CA 94035 USA.
C3 Google Incorporated
RP Rothe, S (通讯作者)，Google Res, Mountain View, CA 94035 USA.
EM rothe@google.com; shashinarayan@google.com; severyn@google.com
CR Aharoni R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P719
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   Botha JA, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P732
   Chan William, 2019, ARXIV190601604
   Dai Andrew M., 2015, NIPS
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Dan Hendrycks, 2016, ABS160608415 CORR
   Devlin J., 2018, ARXIV, V1, P4171
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gehrmann S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4098
   Geva M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3443
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Hansen N., 2016, CMA EVOLUTION STRATE
   He TY, 2018, ADV NEUR IN, V31
   Hermann KM, 2015, ADV NEUR IN, V28
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang EH, 2012, ACL, V1, P873
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   KHANDELWAL U, 2019, ARXIV PREPRINT ARXIV
   Kim B, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2519
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Lample Guillaume, 2019, NEURIPS
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150
   Liu Y, 2019, ARXIV190407464
   Louviere J, 2015, BEST WORST SCALING T
   Louviere J. J., 1991, BEST WORST SCALING M
   Mikolov T., 2013, ARXIV13013781 CS, DOI DOI 10.48550/ARXIV.1301.3781
   Napoles C, 2012, P JOINT WORKSHOP AUT, P95
   Narayan S, 2018, P 2018 C N AM CHAPT, V1, P1747, DOI DOI 10.18653/V1/N18-1158
   Narayan S., 2017, P 2017 C EMPIRICAL M, P606
   Narayan Shashi, P 2018 C EMP METH NA, P1797
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), P7
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Ramachandran P, 2017, P 2017 C EMP METH NA, P383, DOI DOI 10.18653/V1/D17-1039
   Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shaw Peter, 2018, NAACL, P5, DOI DOI 10.18653/V1/N18-2074
   Song K., 2019, PROC INT C MACHINE L, P5926
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4465
   Wang R., 2019, ABS190705338 CORR
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Xu W., 2016, T ASSOC COMPUT LING, V4, P401, DOI DOI 10.1162/TACL_A_00107
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yinhan Liu, 2019, ARXIV190711692
   Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P93
NR 56
TC 93
Z9 93
U1 6
U2 12
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2020
VL 8
BP 264
EP 280
DI 10.1162/tacl_a_00313
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA XX8IL
UT WOS:000736531900018
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Bingham, E
   Chen, JP
   Jankowiak, M
   Obermeyer, F
   Pradhan, N
   Karaletsos, T
   Singh, R
   Szerlip, P
   Horsfall, P
   Goodman, ND
AF Bingham, Eli
   Chen, Jonathan P.
   Jankowiak, Martin
   Obermeyer, Fritz
   Pradhan, Neeraj
   Karaletsos, Theofanis
   Singh, Rohit
   Szerlip, Paul
   Horsfall, Paul
   Goodman, Noah D.
TI Pyro: Deep Universal Probabilistic Programming
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE Probabilistic programming; graphical models; approximate Bayesian
   inference; generative models; deep learning
AB Pyro is a probabilistic programming language built on Python as a platform for developing advanced probabilistic models in AI research. To scale to large data sets and high-dimensional models, Pyro uses stochastic variational inference algorithms and probability distributions built on top of PyTorch, a modern GPU-accelerated deep learning framework. To accommodate complex or model-specific algorithmic behavior, Pyro leverages Poutine, a library of composable building blocks for modifying the behavior of probabilistic programs.
C1 [Bingham, Eli; Chen, Jonathan P.; Jankowiak, Martin; Obermeyer, Fritz; Pradhan, Neeraj; Karaletsos, Theofanis; Singh, Rohit; Szerlip, Paul] Uber Technol Inc, Uber AI Labs, 555 Market St, San Francisco, CA 94103 USA.
   [Horsfall, Paul; Goodman, Noah D.] Uber AI Labs, 555 Market St, San Francisco, CA 94103 USA.
   [Horsfall, Paul; Goodman, Noah D.] Stanford Univ, Stanford, CA 94305 USA.
C3 Uber Technologies, Inc.; Stanford University
RP Bingham, E (通讯作者)，Uber Technol Inc, Uber AI Labs, 555 Market St, San Francisco, CA 94103 USA.
EM eli.bingham@uber.com; jpchen@uber.com; jankowiak@uber.com;
   fritzo@uber.com; npradhan@uber.com; theofanis@uber.com; rohits@uber.com;
   pas@uber.com; horsfallp@gmail.com; ngoodman@stanford.edu
CR [Anonymous], 2016, NIPS
   Carpenter B., 2017, J STAT SOFTWARE, V76
   Dillon JV, 2017, TENSORFLOW DISTRIBUT
   Ge H., 2018, AISTATS
   Ghahramani Z, 2015, NATURE, V521, P452, DOI 10.1038/nature14541
   Goodman N., 2008, UAI
   Goodman ND, 2014, DESIGN IMPLEMENTATIO
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Kammar Ohad, 2013, ICFP
   Kingma D.P., 2014, ICLR
   Krishnan Rahul G, 2017, AAAI
   Mansinghka Vikash K., 2018, PLDI
   Siddharth N., 2017, NIPS
   Tolpin David, 2016, IFL
   Tran D., 2017, ICLR
   Wingate David, 2011, AISTATS
NR 16
TC 297
Z9 301
U1 5
U2 18
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2019
VL 20
AR 28
PG 6
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA HL4FB
UT WOS:000458670100001
HC Y
HP N
DA 2023-11-10
ER

PT J
AU van der Westhuizen, E
   Niesler, TR
AF van der Westhuizen, Ewald
   Niesler, Thomas R.
TI Synthesised bigrams using word embeddings for code-switched ASR of four
   South African language pairs
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Code-switching; Word embeddings; IsiZulu; IsiXhosa; Setswana; Sesotho
AB Code-switching is the phenomenon whereby multilingual speakers spontaneously alternate between more than one language during discourse and is widespread in multilingual societies. Current state-of-the-art automatic speech recognition (ASR) systems are optimised for monolingual speech, but performance degrades severely when presented with multiple languages. We address ASR of speech containing switches between English and four South African Bantu languages. No comparable study on code-switched speech for these languages has been conducted before and consequently no directly applicable benchmarks exist. A new and unique corpus containing 14.3 hours of spontaneous speech extracted from South African soap operas was used to perform our study. The varied nature of the code-switching in this data presents many challenges to ASR. We focus specifically on how the language model can be improved to better model bilingual language switches for English-isiZulu, English-isiXhosa, English-Setswana and English-Sesotho. Code-switching examples in the corpus transcriptions were extremely sparse, with the majority of code-switched bigrams occurring only once. Furthermore, differences in language typology between English and the Bantu languages and among the Bantu languages themselves contribute further challenges. We propose a new method using word embeddings trained on text data that is both out-of-domain and monolingual for the synthesis of artificial bilingual code-switched bigrams to augment the sparse language modelling training data. This technique has the particular advantage of not requiring any additional training data that includes code-switching. We show that the proposed approach is able to synthesise valid codeswitched bigrams not seen in the training set. We also show that, by augmenting the training set with these bigrams, we are able to achieve notable reductions for all language pairs in the overall perplexity and particularly substantial reductions in the perplexity calculated across a language switch boundary (between 5 and 31%). We demonstrate that the proposed approach is able to reduce the unseen code-switched bigram types in the test sets by up to 20.5%. Finally, we show that the augmented language models achieve reductions in the word error rate for three of the four language pairs considered. The gains were larger for language pairs with disjunctive orthography than for those with conjunctive orthography. We conclude that the augmentation of language model training data with code-switched bigrams synthesised using word embeddings trained on out-of-domain monolingual text is a viable means of improving the performance of ASR for code-switched speech. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [van der Westhuizen, Ewald; Niesler, Thomas R.] Stellenbosch Univ, Dept Elect & Elect Engn, Private Bag X1, ZA-7602 Matieland, South Africa.
C3 Stellenbosch University
RP Niesler, TR (通讯作者)，Stellenbosch Univ, Dept Elect & Elect Engn, Private Bag X1, ZA-7602 Matieland, South Africa.
EM ewaldvdw@sun.ac.za; trn@sun.ac.za
FU Nvidia Corporation; Telkom South Africa; Department of Arts and Culture
   of South Africa
FX We would like to thank e.tv and Yula Quinn at Rhythm City for assistance
   with data compilation. We also gratefully acknowledge the support of
   Nvidia Corporation with the donation of GPU equipment used for this
   research, as well as the support of Telkom South Africa and the
   Department of Arts and Culture of South Africa.
CR Adel H., 2013, P 51 ANN M ASS COMP
   Adel H, 2015, IEEE-ACM T AUDIO SPE, V23, P431, DOI 10.1109/TASLP.2015.2389622
   Adel H, 2013, INT CONF ACOUST SPEE, P8411, DOI 10.1109/ICASSP.2013.6639306
   Ahmed BHA, 2012, INT CONF ASIAN LANG, P137, DOI 10.1109/IALP.2012.28
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 1990, CODESWITCHING WORLDW
   [Anonymous], 2015, T ASSOC COMPUT LING, DOI DOI 10.1162/TACL_A_00134
   Baayen RH, 2003, PROBABILISTIC LINGUISTICS, P229
   Berg A., 2013, P INT LEX FUNCT GRAM
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   de Wet F., 2014, SPOKEN LANGUAGE TECH
   Fung P, 2008, IEEE SIGNAL PROC MAG, V25, P89, DOI 10.1109/MSP.2008.918417
   Gales M. J. F., 2014, P SLTU ST PET RUSS
   Goldhahn D., 2012, P LREC IST TURK
   Gutmann M., 2010, P AISTATS SARD IT
   Houwei Cao, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P246, DOI 10.1109/ISCSLP.2010.5684900
   Jurafsky D., 2017, SPEECH LANGUAGE PROC, V3rd
   Levy O., 2014, ANN C NEUR INF PROC
   Levy Omer., 2014, P COMPUTATIONAL NATU, DOI [DOI 10.3115/V1/W14-1618, 10.3115/v1/W14-1618]
   Li Y., 2013, P INT LYON FRANC
   Li Y., 2014, P EMNLP DOH QAT
   Li Y., 2012, P COLING MUMB IND
   Li Y., 2014, P ICASSP FLOR IT
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T., 2013, P NAACL HLT ATL GEOR
   Modipa T.I., 2013, P 24 ANN S PATT REC
   Muysken P, 1997, IMPACT, V1, P361
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Peters AM, 1997, CROSSLINGUISTIC STUDY OF LANGUAGE ACQUISITION, VOL 5, P135
   POPLACK S, 1988, SOCIOLINGUISTICS INT, V2, P1174
   Povey D., 2011, P ASRU BIG ISL HAW
   Povey D, 2011, COMPUT SPEECH LANG, V25, P404, DOI 10.1016/j.csl.2010.06.003
   Van der Westhuizen E., 2018, P LREC MIYAZ JAP
   van Dulm O., 2007, GRAMMAR ENGLISH AFRI
   Vesely K., 2013, P INT LYON FRANC
   Vu N. T., 2012, IEEE INT C ACOUSTICS, DOI [10.1109/ICASSP.2012.6289015, DOI 10.1109/ICASSP.2012.6289015]
   Winford Donald, 2003, INTRO CONTACT LINGUI
   Xiaohui Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P215, DOI 10.1109/ICASSP.2014.6853589
   Xu HH, 2011, COMPUT SPEECH LANG, V25, P802, DOI 10.1016/j.csl.2011.03.001
   Yilmaz E., 2016, P SLT SAN DIEG CAL, DOI [10.1109/SLT.2016.7846326, DOI 10.1109/SLT.2016.7846326]
   Yilmaz E, 2017, INTERSPEECH, P42, DOI 10.21437/Interspeech.2017-391
   Yilmaz E, 2016, INTERSPEECH, P1536, DOI 10.21437/Interspeech.2016-48
   Yilmaz E, 2016, PROCEDIA COMPUT SCI, V81, P159, DOI 10.1016/j.procs.2016.04.044
NR 44
TC 8
Z9 8
U1 1
U2 21
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR
PY 2019
VL 54
BP 151
EP 175
DI 10.1016/j.csl.2018.10.002
PG 25
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HB4SM
UT WOS:000451046000011
DA 2023-11-10
ER

PT J
AU Priyadarshi, A
   Saha, SK
AF Priyadarshi, Ankur
   Saha, Sujan Kumar
TI The first named entity recognizer in Maithili: Resource creation and
   system development
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Named entity recognition; Maithili language; corpus annotation; LSTM
   model; gazetteer lists
AB In this paper, we present our effort on the development of a Maithili Named Entity Recognition (NER) system. Maithili is one of the official languages of India, with around 50 million native speakers. Although various NER systems have been developed in several Indian languages, we did not find any openly available NER resource or system in Maithili. For the development, we manually annotated a Maithili NER corpus containing around 200K words. We prepared a baseline classifier using Conditional Random Fields (CRF). Then we ran many experiments using various recurrent neural networks (RNN). We collected larger raw corpus to obtain better word embedding and character embedding. In our experiments, we found, neural models are better than CRF; a CRF layer is effective for the prediction of the final output in the RNN models; character embedding is effective in Maithili language. We also investigated the effectiveness of gazetteer lists in neural models. We prepared a few gazetteer lists from various web resources and used those in the neural models. The incorporation of the gazetteer layer caused performance improvement. The final system achieved an f-measure of 91.6% with 94.9% precision and 88.53% recall.
C1 [Priyadarshi, Ankur; Saha, Sujan Kumar] Birla Inst Technol, Comp Sci & Engn Dept, Ranchi 835215, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Priyadarshi, A (通讯作者)，Birla Inst Technol, Comp Sci & Engn Dept, Ranchi 835215, Bihar, India.
EM Priyadarshiankur81@gmail.com
RI Saha, S K/L-9587-2017
OI Saha, S K/0000-0002-7275-7980
FU Science and Engineering Research Board (SERB), India [EEQ/2016/000241]
FX This work was supported by Science and Engineering Research Board
   (SERB), India [Grant No: EEQ/2016/000241].
CR [Anonymous], 2008, P ACL 08, DOI DOI 10.1039/B003067H
   [Anonymous], 2008, P IJCNLP 2008
   Baldwin T., 2015, P WORKSH NOIS US GEN, P126
   Bhattu S.N., 2018, FIRE, P158
   Biswas Sitanath, 2009, 2009 2nd International Conference on Emerging Trends in Engineering and Technology (ICETET 2009), P639, DOI 10.1109/ICETET.2009.10
   Bordes A, 2011, 25 AAAI C ART INT
   Borthwick A., 1999, THESIS NEW YORK U GR
   Chopra D, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P581, DOI 10.1109/CICT.2016.121
   Cucerzan S., 1999, P 1999 JOINT SIGDAT, P90
   Das A, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3015467
   Ekbal A, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P349
   Ekbal A, 2007, LINGUIST INVESTIG, V30, P95
   Ganesh H.B. Barathi, 2018, FIRE, P119
   Gorla S, 2020, INFORMATION, V11, DOI 10.3390/info11020082
   Goyal A, 2018, COMPUT SCI REV, V29, P21, DOI 10.1016/j.cosrev.2018.06.001
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Grishman R, 1996, COLING 1996, DOI [10.3115/992628.992709, DOI 10.3115/992628.992709]
   Grishman Ralph, 1995, 6 MESS UND C MUC 6 P
   Gupta D, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1762
   Gupta V., INT J COMPUTER APPL, V33, P28
   Heinzerling B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2989
   Isozaki H., 2002, P 19 INT C COMP LING, P1, DOI DOI 10.3115/1071884.1071911
   Kumar N., 2006, P TECHN REP
   Lawrie D., 2020, FLOR ART INT RES S
   Leaman Robert, 2008, Pac Symp Biocomput, P652
   Li W., 2004, ACM T ASIAN LANG INF, V2, P290, DOI [10.1145/979872.979879, DOI 10.1145/979872.979879]
   Mccallum A., 2003, P 7 C NATURAL LANGUA, P188, DOI [10.3115/1119176.1119206, 10.3115/1119176, DOI 10.3115/1119176, DOI 10.3115/1119176.1119206]
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Misawa S, 2017, P 1 WORKSH SUBW CHAR, P97, DOI DOI 10.18653/V1/W17-4114
   Mundotiya R.K., 2020, ARXIV PREPRINT ARXIV
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Pandian S.L., 2008, INFOS, pNLP45
   Prasad G, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P16, DOI 10.1109/ICSTM.2015.7225384
   Priyadarshi A, 2020, COMPUT SPEECH LANG, V62, DOI 10.1016/j.csl.2019.101054
   Reimers N., 2017, P C EMPIRICAL METHOD, P338, DOI DOI 10.18653/V1/D17-1035
   Rocktäschel T, 2012, BIOINFORMATICS, V28, P1633, DOI 10.1093/bioinformatics/bts183
   Saha SK, 2012, KNOWL-BASED SYST, V27, P322, DOI 10.1016/j.knosys.2011.09.015
   Saha SK, 2009, J BIOMED INFORM, V42, P905, DOI 10.1016/j.jbi.2008.12.012
   Sharma R, 2022, NAT PROD RES, V36, P2166, DOI 10.1080/14786419.2020.1844696
   Singh A.K., 2008, P IJCNLP 08 WORKSH N, P5
   Singh OM, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2019), P184, DOI 10.1109/CIC48465.2019.00031
   Srikanth P., 2008, P IJCNLP 08 WORKSH N
   Thenmalar S., 2015, INT J NAT LANG COMPU, V4, P01, DOI [10.5121/ijnlc.2015.4501, DOI 10.5121/IJNLC.2015.4501]
   Vijayakrishna R., 2008, P IJCNLP 08 WOKSHOP, P93
   Vinayak A., 2016, ARXIV PREPRINT ARXIV, P154
   Wakao T., 1996, COLING 1996 VOLUME 1
   Yadav V., 2018, P 27 INT C COMP LING, P2145
NR 47
TC 2
Z9 2
U1 1
U2 6
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2021
VL 41
IS 1
BP 1083
EP 1095
DI 10.3233/JIFS-210051
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UB5PA
UT WOS:000685896700064
DA 2023-11-10
ER

PT J
AU Hanzlícek, Z
   Matousek, J
   Vít, J
AF Hanzlicek, Zdenek
   Matousek, Jindrich
   Vit, Jakub
TI Using LSTM neural networks for cross-lingual phonetic speech
   segmentation with an iterative correction procedure
SO COMPUTATIONAL INTELLIGENCE
LA English
DT Article; Early Access
DE LSTM neural networks; multi-lingual and cross-lingual modeling; speech
   segmentation
ID AUTOMATIC SEGMENTATION; ALIGNMENT
AB This article describes experiments on speech segmentation using long short-term memory recurrent neural networks. The main part of the paper deals with multi-lingual and cross-lingual segmentation, that is, it is performed on a language different from the one on which the model was trained. The experimental data involves large Czech, English, German, and Russian speech corpora designated for speech synthesis. For optimal multi-lingual modeling, a compact phonetic alphabet was proposed by sharing and clustering phones of particular languages. Many experiments were performed exploring various experimental conditions and data combinations. We proposed a simple procedure that iteratively adapts the inaccurate default model to the new voice/language. The segmentation accuracy was evaluated by comparison with reference segmentation created by a well-tuned hidden Markov model-based framework with additional manual corrections. The resulting segmentation was also employed in a unit selection text-to-speech system. The generated speech quality was compared with the reference segmentation by a preference listening test.
C1 [Hanzlicek, Zdenek; Matousek, Jindrich; Vit, Jakub] Univ West Bohemia, Fac Appl Sci, NTIS New Technol Informat Soc, Plzen, Czech Republic.
   [Hanzlicek, Zdenek] Univ West Bohemia, Fac Appl Sci, NTIS New Technol Informat Soc, Tech 8, Plzen 30100, Czech Republic.
C3 University of West Bohemia Pilsen; University of West Bohemia Pilsen
RP Hanzlícek, Z (通讯作者)，Univ West Bohemia, Fac Appl Sci, NTIS New Technol Informat Soc, Tech 8, Plzen 30100, Czech Republic.
EM zhanzlic@ntis.zcu.cz
RI Matousek, Jindrich/C-2146-2011
OI Matousek, Jindrich/0000-0002-7408-7730; Hanzlicek,
   Zdenek/0000-0002-4001-9289
FU Grantova Agentura Ceske Republiky
FX Grantova Agentura Ceske Republiky
CR Adell J, 2005, INT CONF ACOUST SPEE, P309
   Adell J., 2004, P 5 ISCA WORKSH SPEE, P139
   Anderson O., 1994, P ICASSP 94 IEEE INT, P121
   Ball MJ, 2018, J INT PHON ASSOC, V48, P155, DOI 10.1017/S0025100317000147
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bhagath P, 2019, TENCON IEEE REGION, P1764, DOI 10.1109/TENCON.2019.8929673
   Brognaux S, 2016, IEEE-ACM T AUDIO SPE, V24, P5, DOI 10.1109/TASLP.2015.2456421
   BRUGNARA F, 1993, SPEECH COMMUN, V12, P357, DOI 10.1016/0167-6393(93)90083-W
   Dong L., 2014, THESIS
   Dusan S, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P645
   Finster H., 1992, IJCNN International Joint Conference on Neural Networks (Cat. No.92CH3114-6), P734, DOI 10.1109/IJCNN.1992.227231
   Franke J., 2016, ITG S, P1
   Garofolo J, 1990, DARPA TIMIT ACOUSTIC
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hanzlicek Z, 2020, LECT NOTES ARTIF INT, V12284, P456, DOI 10.1007/978-3-030-58323-1_49
   Haubold A, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P224
   Hieronymus JL., 1994, ASCII PHONETIC SYMBO
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hoffmann S., 2013, TEXT TO SPEECH ALIGN, P1520, DOI [10.21437/Interspeech.2013-307, DOI 10.21437/INTERSPEECH.2013]
   Hoffmann S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1389
   Horak P., 2001, 33 IMPROVEMENTS SPEE, P328
   Hosom JP, 2009, SPEECH COMMUN, V51, P352, DOI 10.1016/j.specom.2008.11.003
   Hunt MJ., 1984, ICASSP 84 IEEE INT C, P251
   International Phonetic Association, 1999, HDB INT PHON ASS GUI
   Kalinli O., 2012, AUTOMATIC PHONEME SE, P2270
   Karafiát M, 2016, IEEE W SP LANG TECH, P637, DOI 10.1109/SLT.2016.7846330
   Kawai H, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P677
   Kelley MC, 2018, INTERSPEECH, P1205
   Keshet J., 2005, PROC INTERSPEECH 200, P2961, DOI 10.21437/Interspeech.2005-129
   Kingma D. P., 2014, C TRACK P
   Kirshenbaum E., 2011, REPRESENTING IPA PHO
   Kiss G, 2013, INT CONF COGN INFO, P579, DOI 10.1109/CogInfoCom.2013.6719169
   Kominek J., 2003, P 8 EUR C SPEECH COM, P313, DOI [10.21437/Eurospeech.2003-127, DOI 10.21437/EUROSPEECH.2003]
   Kominek J., 2004, P INTERSPEECH 2004 I, P1385, DOI [10.21437/Interspeech.2004-458, DOI 10.21437/INTERSPEECH.2004]
   Kreuk F, 2020, INT CONF ACOUST SPEE, P8089, DOI [10.1109/ICASSP40776.2020.9053053, 10.1109/icassp40776.2020.9053053]
   Lachachi N., 2017, J TELECOMMUN INFORM, V1, P12
   Le VB, 2009, IEEE T AUDIO SPEECH, V17, P1471, DOI 10.1109/TASL.2009.2021723
   LENNIG M, 1983, SPEECH COMMUN, V2, P190, DOI 10.1016/0167-6393(83)90025-0
   Leontiev NA., 2019, INT MULTI C IND ENG, P1, DOI [10.1109/FarEastCon.2019.8934239, DOI 10.1109/FAREASTCON.2019.8934239]
   Leow SJ, 2015, INT CONF ACOUST SPEE, P5813, DOI 10.1109/ICASSP.2015.7179086
   Li M., 2016, 9 ISCA SPEECH SYNTHE, P196, DOI 10.21437/SSW.2016-32
   Liu CJ, 2016, INT CONF ACOUST SPEE, P5020, DOI 10.1109/ICASSP.2016.7472633
   LJOLJE A, 1991, INT CONF ACOUST SPEE, P473, DOI 10.1109/ICASSP.1991.150379
   Lo HY, 2007, INT CONF ACOUST SPEE, P933
   Luo JQ, 2021, INT J ELEC ENG EDUC, DOI 10.1177/0020720920983554
   MacKenzie L, 2020, LINGUIST VANGUARD, V6, DOI 10.1515/lingvan-2018-0061
   Malfrère F, 2003, SPEECH COMMUN, V40, P503, DOI 10.1016/S0167-6393(02)00131-0
   Matouesek J., 2003, P EUROSPEECH 2003, P301
   Matousek J, 2003, LECT NOTES ARTIF INT, V2807, P287
   Matousek J., 2008, P 6 INT C LANG RES E
   Matousek J, 2017, LECT NOTES ARTIF INT, V10415, P138, DOI 10.1007/978-3-319-64206-2_16
   Matousek J, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1626
   Mizera P, 2018, LECT NOTES ARTIF INT, V11096, P419, DOI 10.1007/978-3-319-99579-3_44
   Vu NT, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6855086
   Park SS, 2007, IEEE T AUDIO SPEECH, V15, P2202, DOI 10.1109/TASL.2007.903933
   Park SS, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2066
   Paulo S., 2003, P EUROSPEECH 2003, P309, DOI [10.21437/Eurospeech.2003-126, DOI 10.21437/EUROSPEECH.2003]
   Peng WJ, 2021, 2021 12TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), DOI 10.1109/ISCSLP49672.2021.9362107
   Povey Daniel, 2011, IEEE 2011 WORKSH AUT
   Qiao Y, 2008, INT CONF ACOUST SPEE, P3989
   Ramteke PB, 2019, SPEECH COMMUN, V107, P1, DOI 10.1016/j.specom.2019.01.003
   Räsänen OJ, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1811
   Reddi S.J., 2018, P 6 INT C LEARN REPR
   Reichl W., 1993, P EUR 1993 ISCA, P1771
   Rendel A, 2012, INT CONF ACOUST SPEE, P4533, DOI 10.1109/ICASSP.2012.6288926
   Sangeetha S., 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P864, DOI 10.1109/ICICICT46008.2019.8993408
   Saon G, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P55, DOI 10.1109/ASRU.2013.6707705
   Scharenborg O, 2010, J ACOUST SOC AM, V127, P1084, DOI 10.1121/1.3277194
   Schultz T, 2001, SPEECH COMMUN, V35, P31, DOI 10.1016/S0167-6393(00)00094-7
   Schultz T, 2013, INT CONF ACOUST SPEE, P8126, DOI 10.1109/ICASSP.2013.6639248
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Smirnov VM, 2019, 2019 WAVE ELECTRONICS AND ITS APPLICATION IN INFORMATION AND TELECOMMUNICATION SYSTEMS (WECONF)
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Stolcke Andreas, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5552, DOI 10.1109/ICASSP.2014.6854665
   Tihelka D, 2018, LECT NOTES ARTIF INT, V11107, P369, DOI 10.1007/978-3-030-00794-2_40
   Tihelka D, 2013, LECT NOTES COMPUT SC, V8082, P442, DOI 10.1007/978-3-642-40585-3_56
   Toledano DT, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205355
   Toledano DT, 2000, INT CONF ACOUST SPEE, P3438, DOI 10.1109/ICASSP.2000.860140
   Torre Toledano D., 1998, P 3 ESCA COCOSDA WOR, P207
   Vachhani B., LECT NOTES COMPUTER, V10415, DOI [10.1007/978-3-319-64206-2_44, DOI 10.1007/978]
   Vít J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5684, DOI 10.1109/ICASSP.2018.8461960
   Wagner M., 1981, ICASSP 81. Proceedings of the 1981 IEEE International Conference on Acoustics, Speech and Signal Processing, P1156
   Wells JC., 2016, COMPUTER CODING IPA
   Wells John C., 1997, HDB STANDARDS RESOUR
   Wightman CW., PROGR SPEECH SYNTHES, DOI [10.1007/978-1-4612-1894-4_25, DOI 10.1007/978]
   Wong JHM, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6768, DOI 10.1109/ICASSP39728.2021.9413819
   Yuan JH, 2013, INTERSPEECH, P2305
   Ziolko M., 2010, PERCEPTUAL WAVELET D, P2234
   Zue V. W., 1996, Recent research towards advanced man-machine interface through spoken language, P515, DOI 10.1016/B978-044481607-8/50088-8
NR 92
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0824-7935
EI 1467-8640
J9 COMPUT INTELL-US
JI Comput. Intell.
PD 2023 SEP 19
PY 2023
DI 10.1111/coin.12602
EA SEP 2023
PG 36
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R8GA8
UT WOS:001066674400001
DA 2023-11-10
ER

PT J
AU Kirkwood, CW
AF Kirkwood, CW
TI Recursive calculation of probability distributions for sequential
   decision analysis models
SO IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND
   REVIEWS
LA English
DT Article
DE decision analysis; decision trees; probability distributions; stochastic
   models
AB This paper presents a general-purpose procedure to compactly specify probability information and efficiently calculate probability distributions over the outcome evaluation measure for a sequential decision analysis model. Computer code to implement the calculation procedure is presented in the Pascal programming language. Empirical results are reviewed that show that this approach can quickly determine outcome probability distributions for large sequential decision analysis models using modest computing resources.
C1 Arizona State Univ, Dept Management, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Kirkwood, CW (通讯作者)，Arizona State Univ, Dept Management, Tempe, AZ 85287 USA.
CR *BORL INT INC, 1996, BORL DELPH WIND 95 W
   BUEDE D, 1996, OR MS TODAY, V23, P73
   CALL HJ, 1990, RELIAB ENG SYST SAFE, V30, P115, DOI 10.1016/0951-8320(90)90092-2
   Clemen R.T., 1996, MAKING HARD DECISION
   KIRKWOOD CW, 1994, IEEE T SYST MAN CYB, V24, P1425, DOI 10.1109/21.310526
   KIRKWOOD CW, 1993, MANAGE SCI, V39, P900, DOI 10.1287/mnsc.39.7.900
   McNamee P., 1990, DECISION ANAL SUPERT
   SEDGEWICK R, 1988, ALGORITHMS
NR 8
TC 1
Z9 1
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017-2394 USA
SN 1094-6977
J9 IEEE T SYST MAN CY C
JI IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.
PD FEB
PY 1998
VL 28
IS 1
BP 104
EP 111
DI 10.1109/5326.661093
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZR901
UT WOS:000074026700010
DA 2023-11-10
ER

PT J
AU Dey, D
   Sarkar, S
AF Dey, D
   Sarkar, S
TI PSQL: A query language for probabilistic relational data
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article
DE data uncertainty; probabilistic relational model; probabilistic SQL;
   query language
AB Database systems based on the relational model have become very popular for the storage of large volumes of business-related data. Although the relational model provides a great range of advantages over other data models, it was designed to support deterministic data and, consequently, it lacks a comprehensive way for handling uncertain data. However, in all real-world environments, uncertainty in data values is a common occurrence. Therefore, there is a need to extend the relational model so that data uncertainty can be captured explicitly. In an earlier work, we have proposed a probabilistic relational algebra that is a consistent extension of the conventional relational algebra and is reducible to the latter. The contribution of this work is the development of a non-procedural probabilistic query language-structured around the popular SQL-that can be built on top of that algebra. We formalize the extended syntax, provide examples to illustrate the syntax, and examine query formulation from a decision-theoretic perspective (C) 1998 Elsevier Science B.V.
C1 Univ Washington, Sch Business Adm, Seattle, WA 98195 USA.
   Univ Texas, Sch Management, Richardson, TX 75803 USA.
C3 University of Washington; University of Washington Seattle; University
   of Texas System; University of Texas Dallas
RP Dey, D (通讯作者)，Univ Washington, Sch Business Adm, Seattle, WA 98195 USA.
CR [Anonymous], 1988, FUZZY SETS UNCERTAIN
   BARBARA D, 1992, IEEE T KNOWL DATA EN, V4, P487, DOI 10.1109/69.166990
   Bischoff J., 1997, DATA WAREHOUSE PRACT
   Cavallo R., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB, P71
   Dey D, 1996, ACM T DATABASE SYST, V21, P339, DOI 10.1145/232753.232796
   JAYNES ET, 1968, IEEE T SYST SCI CYB, VSSC4, P227, DOI 10.1109/TSSC.1968.300117
   MENDELSON H, 1986, ACM T DATABASE SYST, V11, P159, DOI 10.1145/5922.5678
   MOTRO A, 1990, DATABASE ENG, V9, P213
   ONEILL P, 1994, DATABASE PRINCIPLES
   PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X
NR 10
TC 13
Z9 14
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0169-023X
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD OCT 30
PY 1998
VL 28
IS 1
BP 107
EP 120
DI 10.1016/S0169-023X(98)00015-9
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 123PH
UT WOS:000076133200006
DA 2023-11-10
ER

PT S
AU Lin, SJ
   Lu, WH
AF Lin, Shu-Jung
   Lu, Wen-Hsiang
BE Ng, HT
   Leong, MK
   Kan, MY
   Ji, D
TI Learning question focus and semantically related features from web
   search results for Chinese question classification
SO INFORMATION RETRIEVAL TECHNOLOGY, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 3rd Asia Information Retrieval Symposium
CY OCT 16-18, 2006
CL Singapore, SINGAPORE
DE question answering; question classification; Web search results;
   language model; question focus; semantically related feature
AB Recently, some machine learning techniques like support vector machines are employed for question classification. However, these techniques heavily depend on the availability of large amounts of training data, and may suffer many difficulties while facing various new questions from the real users on the Web. To mitigate the problem of lacking sufficient training data, in this paper, we present a simple learning method that explores Web search results to collect more training data automatically by a few seed terms (question answers). In addition, we propose a novel semantically related feature model (SRFM), which takes advantage of question focuses and their semantically related features learned from the larger number of collected training data to support the determination of question type. Our experimental results show that the proposed new learning method can obtain better classification performance than the bigram language modeling (LM) approach for the questions with untrained question focuses.
C1 Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Lin, SJ (通讯作者)，Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
EM shu-jung@dns.csie.ncku.edu.tw; whlu@mail.ncku.edu.tw
CR Brill Eric, 2002, P 2002 C EMP METH NA
   DAY MY, 2005, IEEE NLPKE2005
   MOLDOVAN D, 2003, ACM T INFORMATION SY
   MOLDOVAN D, 1999, P 8 TEXT RETR C TREC, P175
   RAVICHANDRAN D, 2001, ASS COMP LING C ACL
   SOLORIO T, 2004, CLING 2004
   SUZUKI J, 2003, ACL 2003 WORKSH MULT
   WEI L, 2002, QUESTION CLASSIFICAT
   XIN L, 2002, LEARNING QUESTION CL
   ZHANG D, 2003, QUESTION CALSSIFICAT
NR 10
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-45780-1
J9 LECT NOTES COMPUT SC
PY 2006
VL 4182
BP 284
EP 296
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFG22
UT WOS:000241690200022
DA 2023-11-10
ER

PT J
AU Schuler, W
   Wu, S
   Schwartz, L
AF Schuler, William
   Wu, Stephen
   Schwartz, Lane
TI A Framework for Fast Incremental Interpretation during Speech Decoding
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID RECOGNITION; SYSTEM
AB This article describes a framework for incorporating referential semantic information from a world model or ontology directly into a probabilistic language model of the sort commonly used in speech recognition, where it can be probabilistically weighted together with phonological and syntactic factors as an integral part of the decoding process. Introducing world model referents into the decoding search greatly increases the search space, but by using a single integrated phonological, syntactic, and referential semantic language model, the decoder is able to incrementally prune this search based on probabilities associated with these combined contexts. The result is a single unified referential semantic probability model which brings several kinds of context to bear in speech decoding, and performs accurate recognition in real time on large domains in the absence of example in-domain training sentences.
C1 [Schuler, William; Wu, Stephen; Schwartz, Lane] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Schuler, W (通讯作者)，Univ Minnesota, Dept Comp Sci & Engn, 200 Union St SE, Minneapolis, MN 55455 USA.
EM schuler@cs.umn.edu; swu@cs.umn.edu; lane@cs.umn.edu
FU National Science Foundation CAREER/PECASE [0447685]; Div Of Information
   & Intelligent Systems; Direct For Computer & Info Scie & Enginr
   [0447685] Funding Source: National Science Foundation
FX The authors would like to thank the anonymous reviewers for their input.
   This research was supported by National Science Foundation CAREER/PECASE
   award 0447685. The views expressed are not necessarily endorsed by the
   sponsors.
CR Aist G, 2007, P 11 WORKSH SEM PRAG, P149
   [Anonymous], COMPUTATIONAL LINGUI
   [Anonymous], P NIPS
   [Anonymous], COMPUTER INTERPRETAT
   BAKER JK, 1975, IEEE T ACOUST SPEECH, VAS23, P24, DOI 10.1109/TASSP.1975.1162650
   Bilmes JA, 2005, IEEE SIGNAL PROC MAG, V22, P89, DOI 10.1109/MSP.2005.1511827
   Blaylock Nate, 2005, IJCAI WORKSH MOD OTH, P79
   Bos Johan, 1996, P 10 AMST C, P133
   BRACHMAN RJ, 1985, COGNITIVE SCI, V9, P171, DOI 10.1207/s15516709cog0902_1
   BROWNSCHMIDT S, 2002, P 24 ANN M COGN SCI, P148
   Church A., 1940, J SYMBOLIC LOGIC, V5, P56, DOI [10.2307/2266170, DOI 10.2307/2266170]
   Dale R., 1991, Computational Intelligence, V7, P252, DOI 10.1111/j.1467-8640.1991.tb00399.x
   DeVault  D., 2003, P WORKSH INF COMP SE, P73
   Ehlen P., 2008, P 13 INT C INT US IN, P276, DOI DOI 10.1145/1378773.1378810
   FISHER WM, 1987, J ACOUST SOC AM, V81, pS92, DOI 10.1121/1.2034854
   Frege G., 1892, Z PHILOS PHILOS KRIT, V100, P25, DOI DOI 10.2307/2181485
   Gorniak P, 2004, J ARTIF INTELL RES, V21, P429, DOI 10.1613/jair.1327
   GROENENDIJK J, 1991, LINGUIST PHILOS, V14, P39, DOI 10.1007/BF00628304
   HADDOCK NJ, 1989, LANG COGNITIVE PROC, V4, P337
   Hobbs J., 1996, FINITE STATE DEVICES, P383
   HOBBS JR, 1993, ARTIF INTELL, V63, P69, DOI 10.1016/0004-3702(93)90015-4
   HOBBS JR, 1985, P 23 ANN M ASS COMP, P61
   JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384
   Lemon O., 2004, ACM Transactions on Computer-Human Interaction, V11, P241, DOI 10.1145/1017494.1017496
   Marcus M., 1980, THEORY SYNTACTIC REC
   Martin C. E., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P257
   Miller G., 1963, HDB MATH PSYCHOL, V2, P419
   Miller T., 2008, P 46 ANN M ASS COMP, P105
   Montague Richard., 1973, PHILOS LANGUAGE ARTI, P141, DOI [10.1007/978-94-009-2727-8_7, DOI 10.1007/978-94-009-2727-8_7, DOI 10.1007/978-94-010-2506-5_10]
   PETERS I, 2000, P LREC ATH
   Pulman S. G., 1986, LANG COGNITIVE PROC, V1, P197, DOI [DOI 10.1080/01690968608407061, 10.1080/01690968608407061]
   ROBINSON T, 1994, IEEE T NEURAL NETWOR, V5, P298
   SCHULER W, 2001, P ACL, P466
   SCHULER W, 2005, P 9 EUR C SPEECH COM, P901
   Schuler William, 2008, P COLING MANCH UK, P785
   SENEFF S, 2004, P ICSLP JEJ ISL, P1457
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tarski A., 1933, PRACE TOWARZYSTWA NA, V34, P152
   Weide R, 1998, CARNEGIE MELLON U PR
   WILENSKY R, 1984, COMMUN ACM, V27, P574, DOI 10.1145/358080.358101
   YOUNG SR, 1989, COMMUN ACM, V32, P183, DOI 10.1145/63342.63344
NR 41
TC 8
Z9 8
U1 0
U2 2
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2009
VL 35
IS 3
BP 313
EP 343
DI 10.1162/coli.08-011-R2-07-021
PG 31
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 527EV
UT WOS:000272350900001
OA hybrid
DA 2023-11-10
ER

PT J
AU van Eck, P
   Engelfriet, J
   Fensel, D
   van Harmelen, F
   Venema, Y
   Willems, M
AF van Eck, P
   Engelfriet, J
   Fensel, D
   van Harmelen, F
   Venema, Y
   Willems, M
TI A survey of languages for specifying dynamics: A knowledge engineering
   perspective
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE specification languages; knowledge-based systems; dynamics; inference
   control; update logics
ID SPECIFICATION; MODELS; DESIRE; TASK
AB During the last years, a number of formal specification languages for knowledge-based systems has been developed. Characteristics for knowledge-based systems are a complex knowledge base and an inference engine which uses this knowledge to solve a given problem. Specification languages for knowledge-based systems have to cover both aspects. They have to provide the means to specify a complex and large amount of knowledge and they have to provide the means to specify the dynamic reasoning behavior of a knowledge-based system. This paper focuses on the second aspect. For this purpose, we survey existing approaches for specifying dynamic behavior in related areas of research. In fact, we have taken approaches for the specification of information systems (Language for Conceptual Modeling and TROLL), approaches for the specification of database updates and logic programming (Transaction Logic and Dynamic Database Logic) and the generic specification framework of Abstract State Machines.
C1 Univ Twente, Fac Comp Sci, NL-7500 AE Enschede, Netherlands.
   Free Univ Amsterdam, Fac Sci, NL-1081 HV Amsterdam, Netherlands.
   Univ Amsterdam, Inst Log Language & Computat, NL-1018 TV Amsterdam, Netherlands.
   Quintiq BV, NL-5231 BW Shertogenbosch, Netherlands.
C3 University of Twente; Vrije Universiteit Amsterdam; University of
   Amsterdam
RP van Eck, P (通讯作者)，Univ Twente, Fac Comp Sci, POB 217, NL-7500 AE Enschede, Netherlands.
EM vaneck@cs.utwente.nl; Joeri_Engelfriet@mckinsey.com; dieter@cs.vu.nl;
   frankh@cs.vu.nl; yde@wins.uva.nl; mark@quintiq.nl
OI van Harmelen, Frank/0000-0002-7913-0048
CR ABEN M, 1995, THESIS U AMSTERDAM
   ANDREWS D, 1991, PRACTICAL FORMAL MET
   [Anonymous], 1990, HDB THEORETICAL COMP
   [Anonymous], 1980, CALCULUS COMMUNICATI, DOI DOI 10.1007/3-540-10235-3
   [Anonymous], 1984, HDB PHILOS LOGIC VOL, DOI DOI 10.1007/978-94-009-6259-010
   [Anonymous], 1997, J UNIVERSAL COMPUTER
   [Anonymous], ALGEBRAIC SYSTEM SPE
   [Anonymous], STUDIES LOGIC COMPUT
   Beckert B, 1996, LECT NOTES COMPUT SC, V1092, P64
   BERGSTRA JA, 1985, THEOR COMPUT SCI, V37, P77, DOI 10.1016/0304-3975(85)90088-X
   BOLOGNESI T, 1987, COMPUT NETWORKS ISDN, V14, P25, DOI 10.1016/0169-7552(87)90085-7
   Bonner A.J., 1995, CSRI323 U TOR
   Bonner AJ, 1998, SPRING INT SER ENG C, P117
   BONNER AJ, 1994, THEOR COMPUT SCI, V133, P205, DOI 10.1016/0304-3975(94)90190-2
   BONNER AJ, 1993, LOGIC PROGRAMM, P257
   BORGER E, 1995, THEORY PRACTICE INFO, P236
   BORGER E, 1998, EATCS B, P105
   BORGER E, 1997, J UNIVERSAL COMPUTER, V3
   Brazier FMT, 1999, DATA KNOWL ENG, V29, P17, DOI 10.1016/S0169-023X(98)00029-9
   Brazier FMT, 1996, INT J HUM-COMPUT ST, V44, P469, DOI 10.1006/ijhc.1996.0022
   Brazier FMT, 1997, INT J COOP INF SYST, V6, P67, DOI 10.1142/S0218843097000069
   CASTILLO G, 1996, CSL 95, P191
   CLAVEL M, 1997, ELECT NOTES THEORETI, V4
   Conrad S, 1998, SPRING INT SER ENG C, P199
   CONRAD S, 1992, 9202 TU BRAUNSCHW
   DAVID JM, 1993, 2 GEN EXPERT SYSTEM
   DENKER G, 1997, P ALG METH SOFTW TEC, P170
   DENKER G, 1998, ELECT NOTES THEORETI, V15
   DILLER AZ, 1992, INTRO FORMAL METHODS
   EHRIG H, 1990, FUNDAMENTALS ALGEBRA, V2
   EHRIG H, 1985, FUNDAMENTALS ALGEBRA, V1
   Fensel D, 1998, IEEE T KNOWL DATA EN, V10, P527, DOI 10.1109/69.706055
   Fensel D, 1996, LECT NOTES ARTIF INT, V1076, P17
   Fensel D, 1995, KNOWL ENG REV, V10, P361, DOI 10.1017/S0269888900007566
   FENSEL D, 1994, KNOWL ENG REV, V9, P105, DOI 10.1017/S0269888900006767
   Fensel D, 1998, INT J HUM-COMPUT ST, V48, P181, DOI 10.1006/ijhc.1997.0168
   FENSEL D, 1996, P ECAI 96, P1123
   FENSEL D, 1995, KNOWLEDGE ACQUISTION
   GROENBOOM R, 1994, P INTL WORKSH SEM SP
   GUREVICH Y, 1994, SPECIFICATION VALIDA
   HARMELEN F, 1992, KNOWL ACQUIS, V4, P127
   INTVELD L, 1993, FORMAL SPECIFICATION, P233
   Jones Cliff, 1990, SYSTEMATIC SOFTWARE
   Jungclaus R, 1996, ACM T INFORM SYST, V14, P175, DOI 10.1145/226163.226166
   JUNGCLAUS R, 1993, MODELING DYNAMIC OBJ
   KAPPEL AM, 1993, P 4 INTL C LOG PROGR, P229
   KROEGER F, 1987, TEMPORAL LOGIC PROGR
   LINSTER M, 1994, INTL J MAN MACHINE S, V40
   MARCUS S, 1988, ARTIF INTELL, V39, P1
   MESEGUER J, 1992, THEOR COMPUT SCI, V96, P73, DOI 10.1016/0304-3975(92)90182-F
   Milner R., 1989, Communication and concurrency
   Nebel B., 1996, PRINCIPLES KNOWLEDGE, P237
   PierretGolbreich C, 1996, KNOWL ENG REV, V11, P253, DOI 10.1017/S0269888900007918
   Poeck K, 1996, INT J HUM-COMPUT ST, V44, P435, DOI 10.1006/ijhc.1996.0021
   SCHREIBER AT, 1996, INTL J HUMAN COMPUTE
   SCHREIBER G, 1994, IEEE EXPERT, V9, P28, DOI 10.1109/64.363263
   Sernadas A, 1995, J LOGIC COMPUT, V5, P603, DOI 10.1093/logcom/5.5.603
   SPEE JW, 1994, KNOWLEDGE ACQUISITIO, V6
   Spivey J. M., 1992, Z NOTATION REFERENCE, Vsecond
   Spruit P., 1995, Journal of Logic and Computation, V5, P27, DOI 10.1093/logcom/5.1.27
   SPRUIT P, 1993, P 4 INTL WORKSH FDN, P102
   SPRUIT P, IN PRESS THEORETICAL
   TREUR J, 1993, FORMAL SPECIFICATION
   van Harmelen F, 1997, DECIS SUPPORT SYST, V21, P271, DOI 10.1016/S0167-9236(97)00045-6
   Wielinga B. J., 1992, Knowledge Acquisition, V4, P5, DOI 10.1016/1042-8143(92)90013-Q
   WIERINGA RJ, 1995, FORMAL DEV REACTIVE, P333
   WIERINGA RJ, 1991, P 2 INTL C DED OBJ O, P431
   Winter K., 1997, J UNIVERS COMPUT SCI, V3, P689, DOI DOI 10.3217/JUCS-003-05-0689
   WORDSWORTH JB, 1992, SOFTWARE DEV Z
   ZIMMERMANN W, 1997, J UNIVERS COMPUT SCI, V3, P504
   [No title captured]
NR 71
TC 11
Z9 11
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD MAY-JUN
PY 2001
VL 13
IS 3
BP 462
EP 496
DI 10.1109/69.929903
PG 35
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 440DT
UT WOS:000169161200011
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Feinerer, I
AF Feinerer, Ingo
TI Efficient large-scale configuration via integer linear programming
SO AI EDAM-ARTIFICIAL INTELLIGENCE FOR ENGINEERING DESIGN ANALYSIS AND
   MANUFACTURING
LA English
DT Article
DE Configuration; Integer Linear Programming; Linux Kernel Configuration;
   Package Management; Unified Modeling Language
ID FRAMEWORK
AB Configuration of large-scale applications in an engineering context requires a modeling environment that allows the design engineer to draft the configuration problem in a natural way and efficient methods that can process the modeled setting and scale with the number of components. Existing configuration methods in artificial intelligence typically perform quite well in certain subareas but are hard to use for general-purpose modeling without mathematical or logics background (the so-called knowledge acquisition bottleneck) and/or have scalability issues. As a remedy to this important issue both in theory and in practical applications, we use a standard modeling environment like the Unified Modeling Language that has been proposed by the configuration community as a suitable object-oriented formalism for configuration problems. We provide a translation of key concepts of class diagrams to inequalities and identify relevant configuration aspects and show how they are treated as an integer linear program. Solving an integer linear program can be done efficiently, and integer linear programming scales well to large configurations consisting of several thousands components and interactions. We conduct an empirical study in the context of package management for operating systems and for the Linux kernel configuration. We evaluate our methodology by a benchmark and obtain convincing results in support for using integer linear programming for configuration applications of realistic size and complexity.
C1 Vienna Univ Technol, Inst Informat Syst, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Feinerer, I (通讯作者)，Vienna Univ Technol, Inst Informat Syst, Favoritenstr 9, A-1040 Vienna, Austria.
EM ingo.feinerer@tuwien.ac.at
OI Feinerer, Ingo/0000-0001-7656-8338
CR Alliance for Telecommunications Industry Solutions, 2000, ATIS TEL GLOSS 2000
   [Anonymous], P 7 IEEE C ART INT A
   [Anonymous], 2012, J SATISFIABILITY BOO
   Balaban M., 2007, P MOD DRIV ARCH FDN
   Falkner Andreas, 2010, International Journal of Mass Customisation, V3, P351, DOI 10.1504/IJMASSC.2010.037650
   Falkner A, 2011, AI EDAM, V25, P115, DOI 10.1017/S0890060410000570
   FEINERER I., 2007, THESIS VIENNA U TECH
   Feinerer I., 2011, P 15 INT SOFTW PROD
   Felfernig A, 2003, AI EDAM, V17, P31, DOI 10.1017/S0890060403171041
   Felfernig A, 2000, INT J SOFTW ENG KNOW, V10, P449, DOI 10.1142/S0218194000000249
   Felfernig A., 2002, P 5 INT C UN MOD LAN
   Felfernig A, 2011, AI EDAM, V25, P175, DOI 10.1017/S0890060410000612
   Felfernig A, 2011, AI EDAM, V25, P113, DOI 10.1017/S0890060410000569
   Fleischanderl G, 1998, IEEE INTELL SYST APP, V13, P59, DOI 10.1109/5254.708434
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Jackson D., 1996, IEEE T COMPUT, V29, P21
   Jhala R., 2007, P 29 ITN C SOFTW ENG
   LENZERINI M, 1990, INFORM SYST, V15, P453, DOI 10.1016/0306-4379(90)90048-T
   Mailharro D, 1998, AI EDAM, V12, P383, DOI 10.1017/S0890060498124101
   Männistö T, 2001, DATA KNOWL ENG, V36, P55, DOI 10.1016/S0169-023X(00)00034-3
   Mayer W, 2011, AI EDAM, V25, P143, DOI 10.1017/S0890060410000594
   Niederbrucker G., 2011, CLEWS
   Object Management Group, 2012, OBJ CONSTR LANG 2 3
   Object Management Group, 2011, UN MOD LANG 2 4 1
   Pin-Shan Chen P., 1976, ACM Transactions on Database Systems, V1, P9, DOI 10.1145/320434.320440
   Salzer G., 2007, P 1 IEEE IFIP INT S
   Sincero J, 2007, PROC SPLC WORKSHOP O
   Soininen T, 1998, AI EDAM, V12, P357, DOI 10.1017/S0890060498124083
   Stumptner M, 1998, AI EDAM, V12, P307, DOI 10.1017/S0890060498124046
   Treinen R., 2011, P 14 INT ACM SIG SOF
   Voronov A., 2011, P IJCAI 2011 WORKSH
   Zengler C., 2010, P ECAI 2010 WORKSH C
NR 32
TC 6
Z9 6
U1 1
U2 13
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0890-0604
EI 1469-1760
J9 AI EDAM
JI AI EDAM-Artif. Intell. Eng. Des. Anal. Manuf.
PD FEB
PY 2013
VL 27
IS 1
BP 37
EP 49
DI 10.1017/S0890060412000376
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Multidisciplinary;
   Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 070NF
UT WOS:000313514200004
DA 2023-11-10
ER

PT J
AU Gross, A
   Murthy, D
AF Gross, Alexander
   Murthy, Dhiraj
TI Modeling virtual organizations with Latent Dirichlet Allocation: A case
   for natural language processing
SO NEURAL NETWORKS
LA English
DT Article
DE Natural language processing; Latent Dirichlet Allocation; Big Data;
   Social media; Virtual organizations
AB This paper explores a variety of methods for applying the Latent Dirichlet Allocation (LDA) automated topic modeling algorithm to the modeling of the structure and behavior of virtual organizations found within modern social media and social networking environments. As the field of Big Data reveals, an increase in the scale of social data available presents new challenges which are not tackled by merely scaling up hardware and software. Rather, they necessitate new methods and, indeed, new areas of expertise. Natural language processing provides one such method. This paper applies LDA to the study of scientific virtual organizations whose members employ social technologies. Because of the vast data footprint in these virtual platforms, we found that natural language processing was needed to 'unlock' and render visible latent, previously unseen conversational connections across large textual corpora (spanning profiles, discussion threads, forums, and other social media incarnations). We introduce variants of LDA and ultimately make the argument that natural language processing is a critical interdisciplinary methodology to make better sense of social 'Big Data' and we were able to successfully model nested discussion topics from forums and blog posts using LDA. Importantly, we found that LDA can move us beyond the state-of-the-art in conventional Social Network Analysis techniques. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Gross, Alexander] Univ Maine, Orono, ME 04469 USA.
   [Murthy, Dhiraj] Univ London, Goldsmiths Coll, London WC1E 7HU, England.
C3 University of Maine System; University of Maine Orono; University of
   London; Goldsmiths University London
RP Murthy, D (通讯作者)，Univ London, Goldsmiths Coll, London WC1E 7HU, England.
EM d.murthy@gold.ac.uk
RI Murthy, Dhiraj/B-7067-2009
OI Murthy, Dhiraj/0000-0001-9734-1124
FU Office of Advanced Cyberinfrastructure (OAC); Direct For Computer & Info
   Scie & Enginr [1025428] Funding Source: National Science Foundation
CR [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 2010, ARXIV
   Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2004, ADV NEUR IN, V16, P17
   Blei DM, 2002, ADV NEUR IN, V14, P601
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2006, INT C MACHINE LEARNI, P113, DOI 10.1145/1143844.1143859
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Brzozowski MJ, 2009, GROUP 2009 PROCEEDINGS, P219
   Buntine WL, 1994, J ARTIF INTELL RES, V2, P159, DOI 10.1613/jair.62
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Fabisch A, 2013, NEURAL NETWORKS, V42, P83, DOI 10.1016/j.neunet.2013.01.020
   Fombrun C.J., 1982, ACAD MANAGE REV, V7, P280, DOI DOI 10.5465/AMR.1982.4285594
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Geyer W, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P59
   Gruber T, 2008, J WEB SEMANT, V6, P4, DOI 10.1016/j.websem.2007.11.011
   Hazen T.J., 2010, 2010 IEEE SPOK LANG
   Kaisler S., 2013, 2013 46 HAW INT C SY
   Kantardzic M, 2011, DATA MINING CONCEPTS
   Kireyev K, 2009, NIPS WORKSH APPL TOP
   Li L. J., 2010, 2010 IEEE C COMP VIS
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   Mann G. S., 2006, P 6 ACM IEEE CS JOIN
   Mierswa I., 2006, P ACM SIGKDD INT C K, P1
   Mowshowitz A, 1997, COMMUN ACM, V40, P30, DOI 10.1145/260750.260759
   Pak A., 2010, LREC
   Pantel P, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P113
   Pritchard JK, 2000, GENETICS, V155, P945
   Scott J., 2011, SAGE HDB SOCIAL NETW
   Sivic J, 2008, IEEE C COMP VIS PATT
   Sujitha S., 2014, INT J ADV RES COMPUT, V3
   Travica B., 1997, AM C INF SYST IND
   Wellman B, 2001, AM BEHAV SCI, V45, P436, DOI 10.1177/00027640121957286
   Xing Wei, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   Zhang H., 2007, 2007 IEEE INT SEC IN
NR 38
TC 38
Z9 39
U1 0
U2 49
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD OCT
PY 2014
VL 58
SI SI
BP 38
EP 49
DI 10.1016/j.neunet.2014.05.008
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA AQ0OS
UT WOS:000342483200005
PM 24930023
OA Green Accepted
DA 2023-11-10
ER

PT J
AU Nareshkumar, MD
   Jaison, B
AF Nareshkumar, M. Daniel
   Jaison, B.
TI A Light-Weight Deep Learning-Based Architecture for Sign Language
   Classification
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Deep learning; machine learning; classification; filters; american sign
   language
ID MODEL
AB With advancements in computing powers and the overall quality of images captured on everyday cameras, a much wider range of possibilities has opened in various scenarios. This fact has several implications for deaf and dumb people as they have a chance to communicate with a greater number of people much easier. More than ever before, there is a plethora of info about sign language usage in the real world. Sign languages, and by extension the datasets available, are of two forms, isolated sign language and continuous sign language. The main difference between the two types is that in isolated sign language, the hand signs cover individual letters of the alphabet. In continuous sign language, entire words' hand signs are used. This paper will explore a novel deep learning architecture that will use recently published large pre-trained image models to quickly and accurately recognize the alphabets in the American Sign Language (ASL). The study will focus on isolated sign language to demonstrate that it is possible to achieve a high level of classification accuracy on the data, thereby showing that interpreters can be implemented in the real world. The newly proposed MobileNetV2 architecture serves as the backbone of this study. It is designed to run on end devices like mobile phones and infer signals (what does it infer) from images in a relatively short amount of time. With the proposed architecture in this paper, the classification accuracy of 98.77% in the Indian Sign Language (ISL) and American Sign Language (ASL) is achieved, outperforming the existing state-of-the-art systems.
C1 [Nareshkumar, M. Daniel] RMK Engn Coll, Dept Elect & Commun Engn, Kavaraipettai 601206, India.
   [Jaison, B.] RMK Engn Coll, Dept Comp Sci & Engn, Kavaraipettai 601206, India.
C3 R.M.K. Engineering College; R.M.K. Engineering College
RP Nareshkumar, MD (通讯作者)，RMK Engn Coll, Dept Elect & Commun Engn, Kavaraipettai 601206, India.
EM mnr.ece@rmkec.ac.in
RI Mohan, Daniel Nareshkumar/ADK-4856-2022
OI Mohan, Daniel Nareshkumar/0000-0002-4764-1900; Bennet,
   Jaison/0000-0001-6886-4321
CR Alashhab S, 2019, ADV INTELL SYST COMP, V800, P45, DOI 10.1007/978-3-319-94649-8_6
   Ameen S, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12197
   Anitha G., 2021, COMPUTER SYSTEMS SCI, V42, P7
   [Anonymous], 2018, AKASH ASL ALPHABET
   Bheda V, 2017, Arxiv, DOI arXiv:1710.06836
   Bousbai K, 2019, 2019 6 INT C IMAGE S, P1, DOI [10.1109/ISPA48434.2019.8966918, DOI 10.1109/ISPA48434.2019.8966918]
   Das A, 2018, P 2018 INT C SMART C, P1, DOI DOI 10.1109/ICSCET.2018.8537248
   Elakkiya R., 2021, ISL CSLTR INDIAN SIG
   Ewald H. M., 2016, REPORTS-BASEL
   Farah Sayeed R., 2015, INT J APPL ENG RES, V10, P8121
   Garcia B., 2016, CONVOLUTIONAL NEURAL, V2, P225
   Gowshika U., 2015, INT J APPL ENG RES, V10, P8125
   Jain DK, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102758
   Jaishankar B, 2022, INTELL AUTOM SOFT CO, V32, P1815, DOI 10.32604/iasc.2022.021822
   Kanagavalli N, 2022, INTELL AUTOM SOFT CO, V33, P191, DOI 10.32604/iasc.2022.022720
   Kompally P., 2021, APPL SCI, V11, P1
   Mohan Prakash, 2013, American Journal of Applied Sciences, V10, P924, DOI 10.3844/ajassp.2013.924.930
   Neelakandan S, 2022, INTELL AUTOM SOFT CO, V32, P1617, DOI 10.32604/iasc.2022.022209
   Neelakandan S., 2022, VIRTUAL AUGMENTED RE, P111, DOI [10.1007/978-3-030-94102-46, DOI 10.1007/978-3-030-94102-46]
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Prakash M., 2012, EUR J SCI RES, V81, P450
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rajaraman PV, 2021, PATTERN RECOGN LETT, V152, P340, DOI 10.1016/j.patrec.2021.10.021
   Safaya K., 2013, IPASJ INT J INFORM T, V1, P1
   Satish Kumar T., 2022, INT J IMAGE GRAPH, V26, P1
   Satpathy S, 2019, J INTELL FUZZY SYST, V37, P7039, DOI 10.3233/JIFS-181577
   Sethuraman SC, 2021, IEEE CONSUM ELECTR M, V10, P17, DOI 10.1109/MCE.2020.3029769
   Singh H, 2022, OPTIK, V257, DOI 10.1016/j.ijleo.2022.168789
   Sunitha G, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104404
   Tripathy JK, 2021, COMPUT SCI REV, V42, DOI 10.1016/j.cosrev.2021.100433
   Venu D, 2022, OPTIK, V252, DOI 10.1016/j.ijleo.2021.168545
   Wathugala D. M., 2002, P 4 INT INF TECHN C, P72
NR 32
TC 0
Z9 0
U1 4
U2 8
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2023
VL 35
IS 3
BP 3501
EP 3515
DI 10.32604/iasc.2023.027848
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA 4Y2MA
UT WOS:000861363100014
OA hybrid
DA 2023-11-10
ER

PT J
AU Rahman, H
   Rahin, RS
   Mahbub, AM
   Islam, A
   Mukta, SH
   Rahman, M
AF Rahman, Habibur
   Rahin, Rezwan Shahrior
   Mahbub, Araf Mohammad
   Islam, Adnanul
   Mukta, Saddam Hossain
   Rahman, Mahbubur
TI Punctuation Prediction in Bangla Text
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Neural networks; punctuation prediction; natural language processing;
   BRNN
ID NETWORK
AB Punctuation prediction is critical as it can enhance the readability of machine-transcribed speeches or texts significantly by adding appropriate punctuation. Furthermore, systems like Automatic Speech Recognizer (ASR) produce texts that are unpunctuated, making the readability difficult for humans and also hampers the performance of various natural language processing (NLP) tasks. Such NLP related tasks have been investigated thoroughly for English; however, very limited work is done for punctuation prediction in the Bangla language. In this study, we train a bidirectional recurrent neural network (BRNN) along with Attention model with a plausibly large Bangla dataset. Afterwards, we apply extensive postprocessing techniques for predicting punctuation more accurately with the employed model. Initially, we perform experimentationwith a relatively imbalanced dataset, and our model shows promising results (F1 = 56.9 for Period) in punctuation prediction. Later, we also investigate the model's performance using a balanced Bangla dataset to achieve higher performance scores (F1 = 62.2 for Question). Thus, the goal of this study is to propose an efficient approach that can predict punctuation in Bangla texts effectively. Our study also includes investigation on how our postprocessing techniques affect the prediction performance. Being an early attempt for the punctuation prediction in Bangla text, our work is expected to significantly contribute in the NLP field for the Bangla language, and will pave the way for future work with the Bangla language in this direction.
C1 [Rahman, Habibur; Rahin, Rezwan Shahrior; Mahbub, Araf Mohammad; Mukta, Saddam Hossain] United Int Univ, Dhaka 1200, Bangladesh.
   [Islam, Adnanul] Monash Univ, Clayton, Vic 3800, Australia.
   [Rahman, Mahbubur] Mil Inst Sci & Technol, Mirpur Cantonment, Dhaka 1216, Bangladesh.
C3 United International University (UIU); Monash University
RP Rahman, H (通讯作者)，United Int Univ, Dhaka 1200, Bangladesh.
EM habiburrahmanshamimm@gmail.com; rezwanshahriorrahin@gmail.com;
   araf@gtaf.org; Adnan.Islam@monash.edu; saddam@cse.uiu.ac.bd;
   mahbub@cse.mist.ac.bd
RI Islam, Md Adnanul/AED-4547-2022
OI Islam, Md Adnanul/0000-0002-0278-7738
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Adiba FI, 2020, INT J AUTOMATION ART, V1, P80
   Al Nazi Zabir., 2020, BANGLA NEWSPAPER DAT, DOI [10.34740/KAGGLE/DSV/1576225, DOI 10.34740/KAGGLE/DSV/1576225]
   Alam Tanvirul, 2020, P 6 WORKSHOP NOISY U, P132, DOI DOI 10.18653/V1/2020.WNUT-1.18
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Ballesteros Miguel, 2016, P 2016 C EMPIRICAL M, P1048
   Beeferman D, 1998, INT CONF ACOUST SPEE, P689, DOI 10.1109/ICASSP.1998.675358
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1409.1259, DOI 10.48550/ARXIV.1409.1259]
   Cho KYHY, 2014, Arxiv, DOI arXiv:1406.1078
   Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, 10.48550/arXiv.1412.3555, DOI 10.48550/ARXIV.1412.3555]
   Fang M., 2019, P INT C LEARN REPR I, P1, DOI DOI 10.1109/ICSIDP47821.2019.9172986
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hasan H. M. Mahmudul, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P1131, DOI 10.1109/ICSSIT48917.2020.9214196
   Islam Adnanul, 2016, P 7 ANN S COMPUTING
   Islam MA, 2021, NEURAL COMPUT APPL, V33, P12141, DOI 10.1007/s00521-021-05895-x
   Islam MA, 2017, PROCEEDINGS OF 2017 4TH INTERNATIONAL CONFERENCE ON NETWORKING, SYSTEMS AND SECURITY (NSYSS), P95
   Islam Md. Adnanul, 2022, P 22 ACMINTERNATIONA, DOI [10.1145/3514197.3549640, DOI 10.1145/3514197.3549640]
   Juin CC, 2017, TENCON IEEE REGION, P1806, DOI 10.1109/TENCON.2017.8228151
   Kim S, 2019, INT CONF ACOUST SPEE, P7280, DOI 10.1109/ICASSP.2019.8682418
   Li XX, 2020, INTERSPEECH, P1067, DOI 10.21437/Interspeech.2020-2052
   Liu X, 2018, INT CONF ASIAN LANG, P74, DOI 10.1109/IALP.2018.8629143
   Makhija K, 2019, ASIAPAC SIGN INFO PR, P268, DOI 10.1109/APSIPAASC47483.2019.9023200
   Makhoul J, 1999, P DARPA BROADCAST NE, V249, P252
   Milkowski M, 2010, SOFTWARE PRACT EXPER, V40, P543, DOI 10.1002/spe.971
   Moró A, 2017, INTERSPEECH, P558, DOI 10.21437/Interspeech.2017-204
   Mukta MSH, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3474363
   Nanchen A, 2019, INT CONF ACOUST SPEE, P7275, DOI 10.1109/ICASSP.2019.8683796
   Oktem Alp, 2017, Statistical Language and Speech Processing. 5th International Conference, SLSP. Proceedings: LNAI 10583, P131, DOI 10.1007/978-3-319-68456-7_11
   Parlar T, 2019, COMPUT SCI-AGH, V20, P123, DOI 10.7494/csci.2019.20.1.3097
   Peitz Stephan., 2011, P 8 INT WORKSHOP SPO
   Pham QH, 2019, SOICT 2019: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY, P322, DOI 10.1145/3368926.3369716
   Rodr¡guez P, 2018, Arxiv, DOI arXiv:1806.10805
   Salloum W., 2017, BIONLP 2017, V2017, P159
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Su YH, 2019, NEUROCOMPUTING, V356, P151, DOI 10.1016/j.neucom.2019.04.044
   Szaszák G, 2019, INTERSPEECH, P2988, DOI 10.21437/Interspeech.2019-2132
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Tilk O, 2016, INTERSPEECH, P3047, DOI 10.21437/Interspeech.2016-1517
   Tündik MA, 2018, INT CONF COGN INFO, P135, DOI 10.1109/CogInfoCom.2018.8639876
   Varavs A, 2018, LECT NOTES ARTIF INT, V11171, P91, DOI 10.1007/978-3-030-00810-9_9
   Wang F, 2018, INT C PATT RECOG, P2803, DOI 10.1109/ICPR.2018.8545470
   Wang T, 2015, Arxiv, DOI arXiv:1511.03729
   Xu K., 2016, 2016 10 INT S CHINES, P1, DOI [10.1109/ISCSLP.2016.7918492, DOI 10.1109/ISCSLP.2016.7918492]
   Yi JY, 2019, INT CONF ACOUST SPEE, P7270, DOI 10.1109/ICASSP.2019.8682260
   Zelasko P, 2018, Arxiv, DOI arXiv:1807.00543
NR 45
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR
PY 2023
VL 22
IS 3
AR 81
DI 10.1145/3575804
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9FA8
UT WOS:000998922200019
DA 2023-11-10
ER

PT S
AU Bohnet, B
AF Bohnet, B
BE Su, KY
   Tsujii, J
   Lee, JH
   Kwong, OY
TI A graph grammar approach to map between dependency trees and topological
   models
SO NATURAL LANGUAGE PROCESSING - IJCNLP 2004
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 1st International Joint Conference on Natural Language Processing
   (IJCNLP 2004)
CY MAR 22-24, 2004
CL Hainan Isl, PEOPLES R CHINA
AB Determining the word order in free word order languages is deemed as a challenge for NLG. In this paper, we propose a simple approach in order to get the appropriate grammatically correct variants of a sentence using a dependency structure as input. We describe a linearization grammar based on a graph grammar that allows to retrieve a topological model using unordered constituent structures and precedence relations. The graph grammar formalism is totally language independent and only the grammar depends on the language. The grammar rules can be automatically acquired from a corpus that is annotated with phrase structures and dependency structures. The dependency structures annotation is retrieved by structure translation from the phrase structure annotation. We conclude with the description of a grammar and the evaluation of the formalism using a large corpus.
C1 Univ Stuttgart, Inst Intelligent Syst, D-70569 Stuttgart, Germany.
C3 University of Stuttgart
RP Bohnet, B (通讯作者)，Univ Stuttgart, Inst Intelligent Syst, Univ Str 38, D-70569 Stuttgart, Germany.
EM Bernd.Bohnet@iis.uni-stuttgart.de
CR [Anonymous], 1937, GRUNDGEDANKEN DTSCH
   BECH G, 1955, STUDIUM DTSCH VERBUM
   Bohnet B., 2001, 8 EUR WORKSH NAT LAN
   BOHNET B, 2003, 1 INT C MEAN TEXT TH
   BROKER N, 1998, COLING ACL 98
   Busatto G., 2002, THESIS U PADERBORN
   DUCHIER D, 2001, P ACL
   GERDES K, 2001, P ACL
   Kathol Andreas, 1995, THESIS OHIO STATE U
   Melcuk I., 1988, DEPENDENCY SYNTAX TH
   Thielen C., 1999, GUIDELINES TAGGING D
   WOJCIECHL S, 1997, P ANLP C
   XIA F, 2001, P HUM LANG TECHN C S
NR 13
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-24475-1
J9 LECT NOTES COMPUT SC
PY 2005
VL 3248
BP 636
EP 645
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BBZ57
UT WOS:000228359800067
DA 2023-11-10
ER

PT S
AU Papakitsos, E
   Gregoriadou, M
   Ralli, A
AF Papakitsos, E
   Gregoriadou, M
   Ralli, A
BE Christodoulakis, DN
TI Functional decomposition and lazy word-parsing in modern Greek
SO NATURAL LANGUAGE PROCESSING-NLP 2000, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 2nd International Conference on Natural Language Processing (NLP 2000)
CY JUN 02-04, 2000
CL PATRAS, GREECE
SP ALTEC Grp, Comp Technol Inst, CompBank Networking SA, Hellen Republic, Gen Secretariat Res & Technol, Hellen Republic, Minist Educ & Religious Affairs, Infoquest SA, INTRASOFT SA, ION Publ Co, Microsoft Hellas, Natl & Kapodistrian Univ Athens, OTEnet SA, Patakis Publicat, Univ Aegean, Univ Patras
AB Word recognition and generation is a fundamental part of the processing of natural language, especially for languages with rich morphology such as Modem Greek, and it requires computationally effective morphological processors. Various models have been proposed for developing computerized systems to accomplish the task of recognition of morphosyntactic features of words. In this paper there is a description of extending and adapting the model of functional decomposition in order to cover a number of morphological phenomena that are encountered in Modem Greek. To achieve a more efficient word recognition modifications on the original model were introduced, the lazy word-parsing approach been adopted. The proposed system was used for processing a large scale corpus and the results are presented and discussed as well.
C1 Univ Athens, Dept Informat Panepistimiopolis, GR-15771 Athens, Greece.
   Univ Patras, Dept Philosophy, Patras, Greece.
C3 National & Kapodistrian University of Athens; University of Patras
RP Papakitsos, E (通讯作者)，Univ Athens, Dept Informat Panepistimiopolis, TYPA Bldg, GR-15771 Athens, Greece.
CR ANANIADOU S, 1990, P SICONLP 90
   [Anonymous], 1987, TEXT SPEECH MITALK S
   [Anonymous], 1992, MORPHOLOGY COMPUTATI, DOI DOI 10.7551/MITPRESS/4775.001.0001
   CHURCH K, 1986, ACL P 24 ANN M
   DERMATAS E, 1994, P LANG ENG INF HIGHW
   DRAGGIOTIS A, 1997, PARSING TECHNIQUE RE
   DURA E, 1994, P LANG ENG INF HIGHW
   KALABOUKIS T, 1994, P LANG ENG INF HIGHW
   MARKOPOULOS G, 1997, 2 LEVEL DESCRIPTION
   PACKARD D, 1977, COMPUTER ASSISTED MO
   RALLI A, 1994, P 8 LING M ENGL GREE
   RALLI A, 1992, COMPOUNDS MODERN GRE
   RALLI A, 1991, P EURISCON 91
   RALLI A, 1983, MORPHOLOGIE VERBALE
   RALLI A, 1987, P 3 EUR ACL M COP
   RALLI A, 1985, MORPHOLOGY, V1, pCH2
   Ralli Angela, 1988, THESIS U MONTREAL
   SGARBAS K, 1995, LITERARY LINGUISTIC, V10
   TOURATZIDIS L, 1992, LANG SPEECH, V35, P435, DOI 10.1177/002383099203500404
NR 19
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-67605-8
J9 LECT NOTES ARTIF INT
PY 2000
VL 1835
BP 27
EP 37
PG 11
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BS52C
UT WOS:000170202300003
DA 2023-11-10
ER

PT S
AU Horling, B
   Lesser, V
AF Horling, B
   Lesser, V
BE Ishida, T
   Gasser, L
   Nakashima, H
TI Quantitative organizational models for large-scale agent systems
SO MASSIVELY MULTI-AGENT SYSTEMS I
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Massively Multi-Agent Systems
CY DEC 10-11, 2004
CL Kyoto, JAPAN
SP Natl Inst Adv Ind Sci & Technol, Kyoto Univ, Ctr Excellence Knowledge Soc, Future Univ, Hakodate
AB As the scale and scope of multi-agent systems grow, it becomes increasingly important to manage the manner in which the participants interact. The potential for bottlenecks, intractably large sets of coordination partners, and shared bounded resources can make individual and high-level goals difficult to achieve. To address these problems, many large systems employ an additional layer of structuring, known as an organizational design, that assigns agents particular and different roles, responsibilities and peers. These additional constraints can allow agents to operate effectively within a large-scale system, In this paper, we will introduce a domain-independent organizational design representation capable of modeling and predicting the quantitative performance characteristics of agent organizations. This representation supports the selection of an appropriate design given a particular operational context. We will demonstrate how the language can be used to represent complex interactions, and show modeling techniques that can address the combinatorics of large-scale agent systems.
C1 Univ Massachusetts, Amherst, MA 01003 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst
RP Horling, B (通讯作者)，Univ Massachusetts, Amherst, MA 01003 USA.
EM bhorling@cs.umass.edu; lesser@cs.umass.edu
CR [Anonymous], CMUCS79155
   [Anonymous], OBJECT MAGAZINE
   [Anonymous], 2003, AAMAS 03
   Decker K. S., 1993, International Journal of Intelligent Systems in Accounting, Finance and Management, V2, P215
   DELOACH S, 2002, P 15 C CAN SOC COMP, P1
   DIGNUM V, 2004, P 3 INT JOINT C AUT
   DURFEE EH, 1991, IEEE T SYST MAN CYB, V21, P1363, DOI 10.1109/21.135682
   Horling B, 2003, MU S ART SOC SIM ORG, V9, P139
   HORLING B, 2004, P INT C INT AG TECHN
   Hübner JF, 2002, LECT NOTES ARTIF INT, V2507, P118
   PATTISON HE, 1987, RES NOTES ARTIFICIAL, V1, P59
   ZHANG H, 2004, P INT C INT AG TECHN
NR 12
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-26974-6
J9 LECT NOTES ARTIF INT
PY 2005
VL 3446
BP 121
EP 135
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BCR10
UT WOS:000230879000009
DA 2023-11-10
ER

PT J
AU Kawai, Y
   Oshima, Y
   Sasamoto, Y
   Nagai, Y
   Asada, M
AF Kawai, Yuji
   Oshima, Yuji
   Sasamoto, Yuki
   Nagai, Yukie
   Asada, Minoru
TI A Computational Model for Child Inferences of Word Meanings via
   Syntactic Categories for Different Ages and Languages
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Syntactics; Hidden Markov models; Computational modeling; Semantics;
   Motion pictures; Neurons; Visualization; Computational model;
   cross-linguistic difference; hidden Markov model (HMM); learning of word
   meanings; syntactic category
ID YOUNG-CHILDREN; MOTHERS SPEECH; ACQUISITION; VERBS; INFANTS; NOUNS;
   CONSTRAINTS; LIMITATIONS; VOCABULARY; EMERGENCE
AB Children exploit their morphosyntactic knowledge in order to infer the meanings of words. A recent behavioral study has reported developmental changes in word learning from three to five years of age, with respect to a child's native language. To understand the computational basis of this phenomenon, we propose a model based on a hidden Markov model (HMM). The HMM acquires syntactic categories of given words as its hidden states, which are associated with observed features. Then, the model infers the syntactic category of a new word, which facilitates the selection of an appropriate visual feature. We hypothesize that using this model with different numbers of categories can replicate the manner in which children of different ages learn words. We perform simulation experiments in three native language environments (English, Japanese, and Chinese), which demonstrate that the model produces similar performances as the children in each environment. Allowing a larger number of categories means that the model can acquire a sufficient number of obvious categories, which results in the successful inference of visual features for novel words. In addition, cross-linguistic differences originating from the acquisition of language-specific syntactic categories are identified, i.e., the syntactic categories learned from English and Chinese corpora are relatively reliant on word orders, whereas the Japanese-trained model exploits morphological cues to infer the syntactic categories.
C1 [Kawai, Yuji; Asada, Minoru] Osaka Univ, Grad Sch Engn, Suita, Osaka 5650871, Japan.
   [Oshima, Yuji; Sasamoto, Yuki] Osaka Univ, Suita, Osaka 5650871, Japan.
   [Oshima, Yuji] NTT Software Innovat Ctr, Tokyo, Japan.
   [Sasamoto, Yuki] Fujitsu Finland Oy, Helsinki, Finland.
   [Nagai, Yukie] Natl Inst Informat & Commun Technol, Osaka 5650871, Japan.
C3 Osaka University; Osaka University; National Institute of Information &
   Communications Technology (NICT) - Japan
RP Kawai, Y (通讯作者)，Osaka Univ, Grad Sch Engn, Suita, Osaka 5650871, Japan.
EM kawai@ams.eng.osaka-u.ac.jp; yukie@nict.go.jp;
   asada@ams.eng.osaka-u.ac.jp
OI Asada, Minoru/0000-0001-9506-6333; Nagai, Yukie/0000-0003-4794-0940
FU JSPS [24000012, 13J00756]; JST CREST, Japan [JPMJCR17A4]; Grants-in-Aid
   for Scientific Research [13J00756] Funding Source: KAKEN
FX This work was supported in part by JSPS Grants-in-Aid for Specially
   Promoted Research under Grant 24000012, in part by Grants-in-Aid for
   JSPS Fellows under Grant 13J00756, and in part by JST CREST, Japan under
   Grant JPMJCR17A4.
CR Alishahi A., 2009, P COGSCI WORKSH PSYC
   Alishahi A, 2010, COGNITION IN FLUX, P2452
   [Anonymous], 2001, CHILDRENS LANGUAGE
   [Anonymous], 2007, P 45 ANN M ASS COMP
   [Anonymous], 2007, ADV NEURAL INFORM PR
   [Anonymous], 1982, WHY NOUNS ARE LEARNE
   [Anonymous], 2000, P 2 WORKSHOP LEARNIN
   [Anonymous], 2009, P 2009 C EMP METH NA
   [Anonymous], 2000, CHILDES PROJECT TOOL
   [Anonymous], 2012, P 2012 JOINT C EMP M
   [Anonymous], 2006, P ANN M COGNITIVE SC
   Asr FT, 2010, COGNITION IN FLUX, P1529
   Attamimi M, 2016, ADV ROBOTICS, V30, P806, DOI 10.1080/01691864.2016.1172507
   Baker CL, 2009, COGNITION, V113, P329, DOI 10.1016/j.cognition.2009.07.005
   Bates E. A., 1989, CROSSLINGUISTIC STUD, P3
   Beal MJ, 2002, ADV NEUR IN, V14, P577
   Bornstein MH, 2004, CHILD DEV, V75, P1115, DOI 10.1111/j.1467-8624.2004.00729.x
   BRAINE MDS, 1976, MONOGR SOC RES CHILD, V41, P1, DOI 10.2307/1165959
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Cameron-Faulkner T, 2003, COGNITIVE SCI, V27, P843, DOI 10.1016/j.cogsci.2003.06.001
   Dittmar M, 2011, J CHILD LANG, V38, P1109, DOI 10.1017/S0305000910000747
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Fazly A, 2010, COGNITIVE SCI, V34, P1017, DOI 10.1111/j.1551-6709.2010.01104.x
   Finch S, 1992, BACKGROUND EXPT MACH, P229
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gentner D., 2001, LANG ACQUIS, P215, DOI DOI 10.1017/CBO9780511620669.010
   Gogate LJ, 2006, INFANCY, V9, P259, DOI 10.1207/s15327078in0903_1
   Golinkoff Roberta M., 2006, ACTION MEETS WORD CH, P364
   Henry A., 2004, ENGLISH BELFAST CORP
   Henry Alison, 1995, BELFAST ENGLISH STAN
   Imai M, 2005, CHILD DEV, V76, P340, DOI 10.1111/j.1467-8624.2005.00849_a.x
   Imai M, 2008, CHILD DEV, V79, P979, DOI 10.1111/j.1467-8624.2008.01171.x
   Inamura T, 2004, INT J ROBOT RES, V23, P363, DOI 10.1177/0278364904042199
   Klein D, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P128
   MacWhinney B., 1987, MECH LANGUAGE ACQUIS
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   MARKMAN EM, 1988, COGNITIVE PSYCHOL, V20, P121, DOI 10.1016/0010-0285(88)90017-5
   Matsuzawa J, 2001, CEREB CORTEX, V11, P335, DOI 10.1093/cercor/11.4.335
   Merialdo B., 1994, Computational Linguistics, V20, P155
   Mintz TH, 2003, COGNITION, V90, P91, DOI 10.1016/S0010-0277(03)00140-9
   Mintz TH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00024
   Miyata S., 2013, MIIPRO NANAMI CORPUS
   Monaghan P, 2007, COGNITIVE PSYCHOL, V55, P259, DOI 10.1016/j.cogpsych.2006.12.001
   Nakamura T, 2011, ADV ROBOTICS, V25, P2189, DOI 10.1163/016918611X595035
   NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1207/s15516709cog1401_2
   Ogura T, 2006, J CHILD LANG, V33, P1, DOI 10.1017/S0305000905007270
   OLGUIN R, 1993, COGNITIVE DEV, V8, P245, DOI 10.1016/S0885-2014(93)80001-A
   Onnis L, 2008, COGNITIVE SCI, V32, P184, DOI 10.1080/03640210701703691
   Oshima-Takane Y., 1995, CHILDES MANUAL JAPAN
   Parisien Christopher., 2008, P 12 C COMP NAT LANG, P89, DOI [https://doi.org/10.3115/1596324.1596340, DOI 10.3115/1596324.1596340]
   PHILLIPS JR, 1973, CHILD DEV, V44, P182
   Redington M, 1998, COGNITIVE SCI, V22, P425, DOI 10.1207/s15516709cog2204_2
   Rohlfing KJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00470
   Sakai KL, 2005, SCIENCE, V310, P815, DOI 10.1126/science.1113530
   Santelmann LM, 1998, COGNITION, V69, P105, DOI 10.1016/S0010-0277(98)00060-2
   Schutze H., 1993, P 31 ANN M ASS COMP, P251
   Seidenberg MS, 1997, SCIENCE, V275, P1599, DOI 10.1126/science.275.5306.1599
   Seidenberg MS, 1999, COGNITIVE SCI, V23, P569, DOI 10.1207/s15516709cog2304_8
   Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   SNOW CE, 1972, CHILD DEV, V43, P549, DOI 10.2307/1127555
   Tardif T, 1996, DEV PSYCHOL, V32, P492, DOI 10.1037/0012-1649.32.3.492
   Tardif T., 2007, CHINESE BEIJING CORP
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Theakston AL, 2001, J CHILD LANG, V28, P127, DOI 10.1017/S0305000900004608
   Thompson PM, 2000, NATURE, V404, P190, DOI 10.1038/35004593
   Tomasello M, 2000, COGNITION, V74, P209, DOI 10.1016/S0010-0277(99)00069-4
   Tomasello M, 2000, TRENDS COGN SCI, V4, P156, DOI 10.1016/S1364-6613(00)01462-5
   Tomasello M, 1998, COGN LINGUIST, V9, P379, DOI 10.1515/cogl.1998.9.4.379
   Tomasello M., 2003, CONSTRUCTING LANGUAG
   Toyomura A, 2005, IEICE T INF SYST, VE88D, P2389, DOI 10.1093/ietisy/e88-d.10.2389
   ZUKOW PG, 1990, DEV PSYCHOBIOL, V23, P705, DOI 10.1002/dev.420230711
NR 73
TC 1
Z9 1
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEPT
PY 2020
VL 12
IS 3
BP 401
EP 416
DI 10.1109/TCDS.2018.2883048
PG 16
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Robotics; Neurosciences & Neurology
GA NN3AB
UT WOS:000568663000003
OA Bronze
DA 2023-11-10
ER

PT J
AU Cederborg, T
   Oudeyer, PY
AF Cederborg, Thomas
   Oudeyer, Pierre-Yves
TI From Language to Motor Gavagai: Unified Imitation Learning of Multiple
   Linguistic and Nonlinguistic Sensorimotor Skills
SO IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT
LA English
DT Article
DE Discovering linguistic channels; imitation learning; language
   acquisition; motor Gavagai problem; robot learning by demonstration;
   sensorimotor learning
ID ROBOT; GENERATION; INFANTS
AB We identify a strong structural similarity between the Gavagai problem in language acquisition and the problem of imitation learning of multiple context-dependent sensorimotor skills from human teachers. In both cases, a learner has to resolve concurrently multiple types of ambiguities while learning how to act in response to particular contexts through the observation of a teacher's demonstrations. We argue that computational models of language acquisition and models of motor skill learning by demonstration have so far only considered distinct subsets of these types of ambiguities, leading to the use of distinct families of techniques across two loosely connected research domains. We present a computational model, mixing concepts and techniques from these two domains, involving a simulated robot learner interacting with a human teacher. Proof-of-concept experiments show that: 1) it is possible to consider simultaneously a larger set of ambiguities than considered so far in either domain; and 2) this allows us to model important aspects of language acquisition and motor learning within a single process that does not initially separate what is "linguistic" from what is "nonlinguistic." Rather, the model shows that a general form of imitation learning can allow a learner to discover channels of communication used by an ambiguous teacher, thus addressing a form of abstract Gavagai problem (ambiguity about which observed behavior is "linguistic", and in that case which modality is communicative).
C1 [Cederborg, Thomas; Oudeyer, Pierre-Yves] French Natl Inst Comp Sci & Control INRIA, F-91762 Palaiseau, France.
   [Cederborg, Thomas; Oudeyer, Pierre-Yves] Ensta ParisTech, F-91762 Palaiseau, France.
C3 Institut Polytechnique de Paris
RP Cederborg, T (通讯作者)，French Natl Inst Comp Sci & Control INRIA, F-91762 Palaiseau, France.
EM thomas.cederborg@inria.fr; pierre-yves.oudeyer@inria.fr
FU ERC [EXPLORERS 240007]; Region Aquitaine
FX This work was supported in part by the ERC Grant EXPLORERS 240007 and
   Region Aquitaine.
CR Abbeel P., 2004, P 21 INT C MACHINE L
   Abbeel P, 2010, INT J ROBOT RES, V29, P1608, DOI 10.1177/0278364910371999
   Allen K, 2010, PSYCHOL SCI, V21, P1518, DOI 10.1177/0956797610383434
   [Anonymous], 2000, INT C MACH LEARN
   [Anonymous], 2008, ARTIFICIAL LIFE
   [Anonymous], 2006, SELF ORG EVOLUTION S
   Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024
   Baranes A, 2013, ROBOT AUTON SYST, V61, P49, DOI 10.1016/j.robot.2012.05.008
   Baranès A, 2009, IEEE T AUTON MENT DE, V1, P155, DOI 10.1109/TAMD.2009.2037513
   Billard A., 2008, HDB ROBOTICS, P1371, DOI 10.1007/978-3-540-30301-5_60
   Cakmak M, 2012, ACMIEEE INT CONF HUM, P17
   Calinon S., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P255
   Calinon Sylvain, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P582, DOI 10.1109/ICHR.2009.5379592
   Calinon S., 2009, ROBOT PROGRAMMING DE
   Calinon S, 2007, IEEE T SYST MAN CY B, V37, P286, DOI 10.1109/TSMCB.2006.886952
   Calinon S, 2010, IEEE ROBOT AUTOM MAG, V17, P44, DOI 10.1109/MRA.2010.936947
   Cangelosi A., 2011, IEEE T AUTONOM MENTA, V3, P17
   CANGELOSI A, 2010, INTEGRATION ACTION L
   Cederborg Thomas, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P650, DOI 10.1109/Humanoids.2011.6100875
   Cederborg T., 2013, THEORETICAL COMPUTAT
   Cederborg T, 2010, IEEE INT C INT ROBOT, P267, DOI 10.1109/IROS.2010.5652040
   Dautenhahn K, 2011, ADV INTERACT STUD, V2, P1
   Demiris Y, 2008, INFANT CHILD DEV, V17, P43, DOI 10.1002/icd.543
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dominey PF, 2007, IEEE INT CONF ROBOT, P2169, DOI 10.1109/ROBOT.2007.363642
   Driesen J., 2009, INTERSPEECH, P1
   Fischer K, 2011, INTERACT STUD, V12, P134, DOI 10.1075/is.12.1.06fis
   Gogate LJ, 2000, CHILD DEV, V71, P878, DOI 10.1111/1467-8624.00197
   Grizou J., 2013, IEEE INT C DEV LEARN
   Guenter F, 2007, ADV ROBOTICS, V21, P1521
   Ito M, 2006, NEURAL NETWORKS, V19, P323, DOI 10.1016/j.neunet.2006.02.007
   Kulic D, 2012, INT J ROBOT RES, V31, P330, DOI 10.1177/0278364911426178
   Laine U., 2009, P INT 09 BRIGHT ENGL, P852
   Lallee S., 2010, ROBOTS STUDIES COMPU, V264
   Lopes M., 2010, FROM MOTOR LEARNING
   Lopes M., 2011, 2011 IEEE INT C DEV, V2, P1
   Lopes M, 2010, STUD COMPUT INTELL, V264, P313
   Mangin Olivier, 2012, Human Behavior Understanding. Proceedings of the Third International Workshop, HBU 2012, P134, DOI 10.1007/978-3-642-34014-7_12
   Mangin O., 2013, IEEE INT C DEV LEARN
   Mangin O., 2010, 10 INT C EP ROB
   Massera G, 2010, IEEE COMPUT INTELL M, V5, P33, DOI 10.1109/MCI.2010.937321
   McGregor KK, 2009, J CHILD LANG, V36, P807, DOI 10.1017/S0305000908009173
   Mohammad Y., 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4119, DOI 10.1109/IROS.2010.5651719
   Mohammad Y, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2537, DOI 10.1109/IROS.2009.5353987
   Nehaniv C. L., 2002, IMITATION ANIMALS AR
   Nguyen SM., 2012, PALADYN, V3, P136, DOI [10.2478/s13230-013-0110-z, DOI 10.2478/S13230-013-0110-Z]
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Oudeyer PY, 2006, CONNECT SCI, V18, P189, DOI 10.1080/09540090600768567
   Park A, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P53
   Pastra K, 2012, PHILOS T R SOC B, V367, P103, DOI 10.1098/rstb.2011.0123
   QUINE WVO, 2013, WORD OBJECT
   Rao RPN, 2007, IMITATION AND SOCIAL LEARNING IN ROBOTS, HUMANS AND ANIMALS: BEHAVIOURAL, SOCIAL AND COMMUNICATIVE DIMENSIONS, P217, DOI 10.1017/CBO9780511489808.016
   Rohlfing K., 2012, IEEE CIS AMD NEWSLET, V9
   Ruvolo P., 2010, PATTERN RECOGNIT LET
   Smith LB, 2010, COGNITIVE SCI, V34, P1287, DOI 10.1111/j.1551-6709.2010.01130.x
   Steels L., 2008, SPATIAL LANGUAGE DIA
   Steels L., 2006, TRENDS COGN SCI
   Steels L., 2008, PREHISTORY LANGUAGE, P18
   Steels L, 2010, EVOLUTION OF COMMUNICATION AND LANGUAGE IN EMBODIED AGENTS, P223, DOI 10.1007/978-3-642-01250-1_13
   Steels L, 2008, CONNECT SCI, V20, P337, DOI 10.1080/09540090802413186
   Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102
   Sugiura K, 2011, ADV ROBOTICS, V25, P825, DOI 10.1163/016918611X563328
   ten Bosch L., 2009, COMPUTATIONAL MODEL
   Whiten A, 2006, DEVELOPMENTAL SCI, V9, P574, DOI 10.1111/j.1467-7687.2006.00535.x
   Wrede B., 2012, P HUM 2012 WORKSH DE
   Xu F., 2005, P 27 ANN C COGN SCI, P288
   Yu C., 2004, ACM T APPL PERCEPT, V1, P57, DOI DOI 10.1145/1008722.1008727
   Yu C, 2007, NEUROCOMPUTING, V70, P2149, DOI 10.1016/j.neucom.2006.01.034
NR 68
TC 4
Z9 6
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1943-0604
EI 1943-0612
J9 IEEE T AUTON MENT DE
JI IEEE Trans. Auton. Ment. Dev.
PD SEP
PY 2013
VL 5
IS 3
SI SI
BP 222
EP 239
DI 10.1109/TAMD.2013.2279277
PG 18
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Robotics; Neurosciences & Neurology
GA 220KZ
UT WOS:000324583800005
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Felfernig, A
   Zanker, M
AF Felfernig, A
   Zanker, M
BE Anderson, M
   Cheng, P
   Haarslev, V
TI Diagrammatic acquisition of functional knowledge for product
   configuration systems with the unified modeling language
SO THEORY AND APPLICATION OF DIAGRAMS, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 1st International Conference on Theory and Application of Diagrams
   (Diagrams 2000)
CY SEP 01-03, 2000
CL UNIV EDINBURGH, EDINBURGH, SCOTLAND
HO UNIV EDINBURGH
AB Shorter product cycles, lower prices of products, and the production of goods that axe tailored to the customers needs made knowledge based product configuration systems a great success of AI technology. However, configuration knowledge bases tend to become large and complex. Therefore, knowledge acquisition and maintenance are crucial phases in the life-cycle of a configuration system. We will show how to meet this challenge by extending a standard design language from the area of Software Engineering with classical description concepts for expressing configuration knowledge. We automatically translate this graphical depiction into logical sentences which can be exploited by a general inference engine to solve the configuration task. In order to cope with usability restrictions of diagrammatic notations for large applications, we introduce the usage of contextual diagrams. This mechanism makes the conceptual model more readable and understandable and supports intuitively the acquisition of functional configuration knowledge.
C1 Univ Klagenfurt, Inst Wirtschaftsinformat & Anwendungssyst, A-9020 Klagenfurt, Austria.
C3 University of Klagenfurt
RP Felfernig, A (通讯作者)，Univ Klagenfurt, Inst Wirtschaftsinformat & Anwendungssyst, A-9020 Klagenfurt, Austria.
RI Zanker, Markus/B-2771-2008
OI Zanker, Markus/0000-0002-4805-5516
CR [Anonymous], 1998, OBJECT TECHNOLOGY SE
   BARKER VE, 1989, COMMUN ACM, V32, P298, DOI 10.1145/62065.62067
   Chandrasekaran B., 1993, APPL ARTIFICIAL INTE, P227
   DELISLE NM, 1987, ACM T INFORM SYST, V5, P168, DOI 10.1145/27636.27639
   FELDKAMP F, 1998, AI EDAM ARTIFICIAL I, V12, P4
   Felfernig A., 1999, Proceedings. SEKE'99. Eleventh International Conference on Software Engineering and Knowledge Engineering, P337
   FLEISCHANDERL G, 1998, IEEE INT SYST CONF G
   FLEISCHANDERL G, 1996, AAAI 96 FALL S CONF
   FRIEDRICH G, 1999, AAAI WORKSH CONF ORL, P35
   GUHA R, 1991, THESIS STANFORD U
   GUHA RV, 1991, STANCS911399 STANF U
   HAAG A, 1998, IEEE INT SYST CONF G
   Heinrich M., 1991, Proceedings. Seventh IEEE Conference on Artificial Intelligence Applications (Cat. No.91CH2967-8), P257, DOI 10.1109/CAIA.1991.120878
   MANOS T, 1998, P 3 INT C COOP INF S, P260
   McCarthy J, 1993, P IJCAI
   McGuinness DL, 1998, AI EDAM, V12, P333, DOI 10.1017/S089006049812406X
   Mittal S., 1989, PROC 11 INT JOINT C, P1395
   *OBJ MAN GROUP OMG, 1999, XMI SPEC
   Peltonen Hannu, 1998, P EUR C PROD DAT TEC, P189
   PINE B, 1993, HARVARD BUSINESS SEP
   RUNKEL JT, 1994, P ART INT DES 94, P183
   SABIN D, 1999, ART INT MAN RES PLAN
   Soininen T, 1998, AI EDAM, V12, P357, DOI 10.1017/S0890060498124083
   Stumptner M, 1997, AI COMMUN, V10, P111
   STUMPTNER M, 1997, P 10 C AI APPL, V10, P373
   Yu B, 1998, IEEE INTELL SYST APP, V13, P34, DOI 10.1109/5254.708431
NR 26
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-67915-4
J9 LECT NOTES ARTIF INT
PY 2000
VL 1889
BP 361
EP 375
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BU08P
UT WOS:000174950500025
DA 2023-11-10
ER

PT J
AU Demir, S
   Oktem, S
AF Demir, Seniz
   Oktem, Seza
TI A benchmark dataset for Turkish data-to-text generation
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Data-to-text generation; Neural Models; Biography domain; Dining venue
   domain; Turkish; Crowdsourcing
ID NATURAL-LANGUAGE GENERATION; OF-THE-ART
AB In the last decades, data-to-text (D2T) systems that directly learn from data have gained a lot of attention in natural language generation. These systems need data with high quality and large volume, but unfortunately some natural languages suffer from the lack of readily available generation datasets. This article describes our efforts to create a new Turkish dataset (Tr-D2T) that consists of meaning representation and reference sentence pairs without fine-grained word alignments. We utilize Turkish web resources and existing datasets in other languages for producing meaning representations and collect reference sentences by crowdsourcing native speakers. We particularly focus on the generation of single-sentence biographies and dining venue descriptions. In order to motivate future Turkish D2T studies, we present detailed benchmarking results of different sequence-to-sequence neural models trained on this dataset. To the best of our knowledge, this work is the first of its kind that provides preliminary findings and lessons learned from the creation of a new Turkish D2T dataset. Moreover, our work is the first extensive study that presents generation performances of transformer and recurrent neural network models from meaning representations in this morphologically-rich language.
C1 [Demir, Seniz] MEF Univ, Dept Comp Engn, Istanbul, Turkiye.
   [Oktem, Seza] MEF Univ, Dept English Language Teaching, Istanbul, Turkiye.
C3 MEF Universitesi; MEF Universitesi
RP Demir, S (通讯作者)，MEF Univ, Dept Comp Engn, Istanbul, Turkiye.
EM demirse@mef.edu.tr; oktemse@mef.edu.tr
RI Demir, Şeniz/AAB-5451-2021
FU TUBITAK-ARDEB, Turkey [117E977]
FX Acknowledgments This work is supported by TUBITAK-ARDEB, Turkey under
   the grant number 117E977. The dataset is available for research purposes
   and non-commercial use. To obtain the dataset, you are required to send
   an email to the corresponding author, and agree to general terms and
   conditions for data usage according to TUBITAK Open Science Policy. The
   authors want to thank Uluc Furkan Vardar and Ilkay Tevfik Devran for
   implementing the XML parser and building input meaning representations,
   and Artun Burak Mecik, Batuhan Bilgin, and Volkan Ozer for
   delexicalizing the collected dataset.
CR Altan A, 2016, DIL EDEB DERG, V13, P1
   [Anonymous], 2010, P 2010 C EMP METH NA
   [Anonymous], 2005, P ACL WORKSHOP INTRI
   [Anonymous], 2002, P 2 INT C HUMAN LANG
   Ayan Burcu Karagol, 2000, P COLING STUDENT SES
   Barzilay R., 2005, P HUM LANG TECHN C C, P331
   Belz A, 2009, PRODIGY METEO PREALP
   Bocklisch T, 2017, Arxiv, DOI arXiv:1712.05181
   Castro Ferreira T., 2018, P 11 INT C NATURAL L, P171, DOI [10.18653/v1/W18-6521, DOI 10.18653/V1/W18-6521]
   Chen D. L., 2008, P 25 INT C MACH LEAR, P128, DOI DOI 10.1145/1390156.1390173
   Chisholm A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P633
   Dusek O, 2020, COMPUT SPEECH LANG, V59, P123, DOI 10.1016/j.csl.2019.06.009
   Ferreira T.C., 2019, P 2019 C EMP METH NA
   Gardent C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P179, DOI 10.18653/v1/P17-1017
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gehrmann S., 2018, P 11 INT C NATURAL L, P46
   Hakkani Dilek Zeynep, 1996, DESIGN IMPLEMENTATIO
   Hakkani-Tür DZ, 2002, COMPUT HUMANITIES, V36, P381, DOI 10.1023/A:1020271707826
   Jagfeld Glorianna, 2018, INLG 2018 11 INT NAT, P221, DOI DOI 10.18653/V1/W18-6529
   Jarvis S, 2013, LANG LEARN, V63, P87, DOI 10.1111/j.1467-9922.2012.00739.x
   Kaffee L.A, 2018, SHORT PAPERS, P640
   Kim M, 2018, MOD LANG J, V102, P120, DOI 10.1111/modl.12447
   Kutlugun M.A, 2018, 2018 26 SIGNAL PROCE
   Lampouras G, 2018, Arxiv, DOI arXiv:1810.13414
   Lebret Remi, 2016, P 2016 C EMP METH NA, P1203, DOI [10.18653/v1/D16-1128, DOI 10.18653/V1/D16-1128]
   Liang P, 2009, P JOINT C 47 ANN M A, P91, DOI DOI 10.1007/978-3-642-02374-3_6
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Liu TY, 2018, AAAI CONF ARTIF INTE, P4881
   Luckman C, 2020, J FLUENCY DISORD, V63, DOI 10.1016/j.jfludis.2020.105747
   Mahapatra J., 2016, P 9 INT NATURAL LANG, P143
   Mairesse F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1552
   Malvern D, 2004, LEXICAL DIVERSITY AND LANGUAGE DEVELOPMENT: QUANTIFICATION AND ASSESSMENT, P121
   Manishina E, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3624
   McCarthy P. M., 2007, LANG TEST, V24, P459, DOI DOI 10.1177/0265532207080767
   Mecik A.B., 2020, P 2020 ECAI WORKSHOP
   Mei Hongyuan, 2016, P 2016 C N AM CHAPTE, P720
   Moryossef A., 2019, P 2019 C N AM CHAPT, V1, P2267
   Nema P., 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-1139
   Novikova J., 2019, P 5 WORKSHOP NOISY U, P431
   Nuzumlali M.Y., 2014, P C EMPIRICAL METHOD, P702
   Ondrej Dusek, 2019, P 12 INT C NATURAL L, P563
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Perez-Beltrachini L., 2017, P 10 INT C NATURAL L, P238
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.1080/1472586x.2015.1113070.
   Portet F, 2009, ARTIF INTELL, V173, P789, DOI 10.1016/j.artint.2008.12.002
   Puduppully R, 2019, AAAI CONF ARTIF INTE, P6908
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Rao Jinfeng, 2019, P 12 INT C NAT LANG, P95
   Reiter E, 2005, ARTIF INTELL, V167, P137, DOI 10.1016/j.artint.2005.06.006
   Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502
   Shahidi H, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3864
   Sharma S, 2017, Arxiv, DOI arXiv:1606.03632
   Shimorina A, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP'2019), P44
   Shimorina Anastasia, 2020, P 3 INT WORKSHOP NAT, P55
   Sutskever I, 2011, ICML
   Taylan Erguvanli, 1984, FUNCTION WORD ORDER
   Torruella J, 2013, PROCD SOC BEHV, V95, P447, DOI 10.1016/j.sbspro.2013.10.668
   van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151
   Vardar U.F, 2019, P 27 SIGNAL PROCESSI, P1
   Varshney D, 2020, LECT NOTES COMPUT SC, V12089, P82, DOI 10.1007/978-3-030-51310-8_8
   Vaswani A., 2017, ARXIV, V30, P5998
   Vougiouklis P, 2018, J WEB SEMANT, V52-53, P1, DOI 10.1016/j.websem.2018.07.002
   Wen TH, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2019.06.008
   Wen Tsung-Hsien, 2015, P 2015 C EMPIRICAL M, P1711, DOI 10.18653/v1/D15-1199
   Wiseman S., 2017, P 2017 C EMPIRICAL M
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483
NR 67
TC 0
Z9 0
U1 2
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2023
VL 77
AR 101433
DI 10.1016/j.csl.2022.101433
EA JUL 2022
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3L2LI
UT WOS:000834597200001
OA Bronze
DA 2023-11-10
ER

PT J
AU Tepper, JA
   Powell, HM
   Palmer-Brown, D
AF Tepper, JA
   Powell, HM
   Palmer-Brown, D
TI A corpus-based connectionist architecture for large-scale natural
   language parsing
SO CONNECTION SCIENCE
LA English
DT Article
DE connectionist networks; hybrid architectures; natural language
   processing; deterministic shift-reduce parsing; corpus linguistics;
   treebank grammar
ID REPRESENTATION
AB We describe a deterministic shift-reduce parsing model that combines the advantages of connectionism with those of traditional symbolic models for parsing realistic sub-domains of natural language. It is a modular system that learns to annotate natural language texts with syntactic structure. The parser acquires its linguistic knowledge directly from pre-parsed sentence examples extracted from an annotated corpus. The connectionist modules enable the automatic learning of linguistic constraints and provide a distributed representation of linguistic information that exhibits tolerance to grammatical variation. The inputs and outputs of the connectionist modules represent symbolic information which can be easily manipulated and interpreted and provide the basis for organizing the parse. Performance is evaluated using labelled precision and recall. (For a test set of 4128 words, precision and recall of 75% and 69%, respectively, were achieved.) The work presented represents a significant step towards demonstrating that broad coverage parsing of natural language can be achieved with simple hybrid connectionist architectures which approximate shift-reduce parsing behaviours. Crucially, the model is adaptable to the grammatical framework of the training corpus used and so is not predisposed to a particular grammatical formalism.
C1 Nottingham Trent Univ, Dept Comp & Math, Nottingham NG1 4BU, England.
   Leeds Metropolitan Univ, Sch Comp, Leeds LS6 3QS, W Yorkshire, England.
C3 Nottingham Trent University; Leeds Beckett University; University of
   Leeds
RP Powell, HM (通讯作者)，Nottingham Trent Univ, Dept Comp & Math, Burton St, Nottingham NG1 4BU, England.
EM Heather.Powell@ntu.ac.uk
OI Tepper, Jonathan/0000-0001-7339-0132
CR Allen J., 1995, NATURAL LANGUAGE UND
   [Anonymous], 1985, LECT CONT SYNTACTIC
   [Anonymous], 2000, HDB NATURAL LANGUAGE
   [Anonymous], BRIT NAT CORP
   BERG G, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P32
   BOD R, 2000, P COLING 2000 SAARBR
   BOD R, 1996, RECENT ADV PARSING T, P255
   BRILL E, 1998, P COLING 98 QUEB CAN
   BRILL E, 1994, P COLING 94 KYOT JAP
   Brill E.D., 1993, THESIS U PENNSYLVANI
   BUO FD, 1994, INT CONF ACOUST SPEE, P365
   BUO FD, 1996, P COLING 96 KOP
   Callan R. E., 1997, Connection Science, V9, P139, DOI 10.1080/095400997116667
   Charniak E, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA132
   Charniak Eugene., 1997, P 14 NAT C ART INT, V2005, P18, DOI DOI 10.5555/1867406.1867499
   CHRISTIANSEN MH, 2001, CONNECTIONIST PSYCHO
   Cleeremans A, 1989, NEURAL COMPUT, V1, P372, DOI 10.1162/neco.1989.1.3.372
   Collins M, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P16
   DYER MG, 1995, COMPUTATIONAL ARCHIT, P389
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844
   FELDMAN JA, 1982, COGNITIVE SCI, V6, P205, DOI 10.1016/S0364-0213(82)80001-3
   FRANCIS WN, 1979, MANUAL INFORMATION A
   FRAZIER L, 1978, COGNITION, V6, P291, DOI 10.1016/0010-0277(78)90002-1
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   GARSIDE R, 1987, MANUAL INFORMATION A
   Ghahramani Z., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), P541, DOI 10.1109/IJCNN.1991.155392
   GIBSON E, 1991, THESIS CARNEGIEMELLO
   Giles C. L., 1990, ADV NEURAL INFORM PR, V2, P380
   HARRISON P, 1991, P WORKSH EV NAT LANG, P71
   HENDERSON J, 1994, J PSYCHOLINGUIST RES, V23, P353, DOI 10.1007/BF02143945
   HENDERSON JB, 1998, P 17 INT C COMP LING, P531
   Hindle D., 1993, Computational Linguistics, V19, P103
   HINDLE D, 1991, P 29 ANN M ASS COMP, P229
   HO EKS, 1997, CONNECT SCI, V9, P269
   JOHANSSON S, 1978, MANUAL INFORMATION A
   Kwasny S. C., 1995, Connection Science, V7, P61, DOI 10.1080/09540099508915657
   Lawrence S, 2000, IEEE T KNOWL DATA EN, V12, P126, DOI 10.1109/69.842255
   Leech G., 1993, Literary & Linguistic Computing, V8, P275, DOI 10.1093/llc/8.4.275
   Magerman D. M., 1995, P 33 ANN M ASS COMPU, P276, DOI [DOI 10.3115/981658.981695, 10.3115/981658.981695]
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Mayberry MR, 2000, LECT NOTES ARTIF INT, V1778, P144
   McMahon J, 1998, ARTIF INTELL REV, V12, P347, DOI 10.1023/A:1006517723917
   MIIKKULAINEN R, 1995, COMPUTATIONAL ARCHIT, P153
   MIIKULAINEN R, 1990, P 13 INT C COMP LING, P201
   PALMERBROWN D, 2002, IN PRESS TRENDS COGN
   PLATE TA, 1995, IEEE T NEURAL NETWOR, V6, P623, DOI 10.1109/72.377968
   POLLACK JB, 1990, ARTIF INTELL, V46, P77, DOI 10.1016/0004-3702(90)90005-K
   REGGIA J, 1987, 1ST P INT C NEUR NET, P131
   REILLY R, 1992, NETWORK-COMP NEURAL, V3, P37, DOI 10.1088/0954-898X/3/1/006
   Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P318
   SHARKEY NE, 1992, TWENT WORKSH LANG TE, V3, P87
   SHASTRI L, 1993, BEHAV BRAIN SCI, V16, P417, DOI 10.1017/S0140525X00030910
   SHIEBER SM, 1983, COMPUTER SPEECH LANG, P297
   SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M
   SMOLENSKY P, 1990, FDN ARTIFICIAL INTEL, V11, P1
   STEVENSON S, 1994, J PSYCHOLINGUIST RES, V23, P295, DOI 10.1007/BF02145044
   Stevenson S, 1997, LANG COGNITIVE PROC, V12, P349, DOI 10.1080/016909697386880
   Sun R., 1992, Connection Science, V4, P93, DOI 10.1080/09540099208946607
   TEPPER JA, 2000, THESIS NOTTINGHAM TR
   TEPPER JA, 1995, P 4 INT C COGN SCI N
   TEPPER JA, 1995, P 3 SNN NEUR NETW S
   TEPPER JA, 2001, P 2 WORKSH NAT LANG, P8
   WERMTER S, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P670
   WERMTER S, 1999, HYBRID NEURAL SYSTEM
   Winograd T., 1983, LANGUAGE COGNITIVE P
NR 66
TC 5
Z9 5
U1 0
U2 2
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0954-0091
EI 1360-0494
J9 CONNECT SCI
JI Connect. Sci.
PD JUN
PY 2002
VL 14
IS 2
BP 93
EP 114
DI 10.1080/09540090210162074
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 617AF
UT WOS:000179336400001
OA Green Submitted
DA 2023-11-10
ER

PT S
AU Kapetanios, E
   Groenewoud, P
AF Kapetanios, E
   Groenewoud, P
BE Andreasen, T
   Motro, A
   Christiansen, H
   Larsen, HL
TI Query construction through meaningful suggestions of terms
SO FLEXIBLE QUERY ANSWERING SYSTEMS, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 5th International Conference on Flexible Query Answering Systems
CY OCT 27-29, 2002
CL COPENHAGEN, DENMARK
SP Roskilde Univ, Dept Comp Sci, George Mason Univ, Dept Informat & Software Engn, Copenhagen Businss Sch
DE query languages; ontologies; semantics; information retrieval
ID LANGUAGE
AB Query formulation by using database specific query languages such as SQL or OQL turns out to be cumbersome or even impossible when end-users need to pose queries to large database schemes. This is due to the difficulties which arise out of the wrong or impossible interpretations of storage models and the lack of mechanisms to embed application domain semantics within query languages. Visual query languages (VQLs) and natural language (NL) based query interfaces in query answering systems alleviate, in some cases, the task of constructing. a query. VQLs, however, are bound to visual formalisms which need further interpretation and still lack the use of semantics other than those provided by well-known conceptual models (EER, OMT, etc.). NL based approaches, on the other side, presuppose a considerable knowledge of the vocabulary terms to, be used by the end-user for a particular application domain and, furthermore, they do not exploit the meaning of words other than that as provided by the syntax, in order to formulate a meaningful query. This turns out to be cumbersome, especially when advanced terminologies and large vocabularies should be used. This is also strengthened by the non-unique name assumption characterizing the application domain vocabulary. In this paper, we present a query construction paradigm which underlies the Meaning Driven Data Query Language MDDQL. It strongly relies on the construction of queries through suggestions of meaningful terms, in a preferred natural language, when requested by the end-user. An inference engine is responsible for the suggestion of a semantically consistent set, not only of application domain terms, but also of operator or operation terms, during the query construction process. All inferences are drawn at a "heuristic level" of representation of the vocabulary, i.e., on the basis of data structures (cyclic graph), and not at an "epistemological level", i.e., based on logic-like representations.
C1 ETHZ, Dept Comp Sci, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Kapetanios, E (通讯作者)，ETHZ, Dept Comp Sci, Postfach 8092, Zurich, Switzerland.
OI Kapetanios, Epaminondas/0000-0002-0617-2183
CR Adam NR, 1997, IEEE T KNOWL DATA EN, V9, P238, DOI 10.1109/69.591449
   Bechhofer S., 1999, Proceedings User Interfaces to Data Intensive Systems, P158, DOI 10.1109/UIDIS.1999.791472
   Cardiff J, 1997, INT J COOP INF SYST, V6, P151, DOI 10.1142/S0218843097000082
   Catarci T, 1997, J VISUAL LANG COMPUT, V8, P215, DOI 10.1006/jvlc.1997.0037
   CATELL RGG, 1997, OBJECT DATABASE STAN
   Chomsky N., 1957, SYNTACTIC STRUCTURES, DOI [10.1515/9783112316009, DOI 10.1515/9783112316009]
   CHU WW, 1994, IEEE T KNOWL DATA EN, V6, P738, DOI 10.1109/69.317704
   CHU WW, 1996, J INTELLIGENT INFORM
   DESAUSSURE F, 1972, COURS LINGISTIQUE GE
   Gil I., 1999, Proceedings User Interfaces to Data Intensive Systems, P54, DOI 10.1109/UIDIS.1999.791462
   GROFF JR, 1999, SQL COMPLETE REFEREN
   GROSZ BJ, 1987, ARTIF INTELL, V32, P173, DOI 10.1016/0004-3702(87)90011-7
   Hendrix G. G., 1978, ACM Transactions on Database Systems, V3, P105, DOI 10.1145/320251.320253
   KAPETANIOS E, 2002, P 14 INT C SCI STAT
   KAPETANIOS E, 2000, 5 IFIP ITN WORK C VI
   KNIGHT K, 1994, P AAAI 94 SEATTL US
   KNIGHT K, 1995, P 14 IJCAI 94 MONTR
   LOPEZ MF, 1999, P IJCAI 99 WORKSH ON
   MAIER D, 1998, P QUER LANG WORKSH C
   McCarthy J., 1969, MACH INTELL, V4
   Paton N. W., 1999, Proceedings. Eleventh International Conference on Scientific and Statistical Database Management, P138, DOI 10.1109/SSDM.1999.787629
   ROBIE J, 1998, P QUER LANG WORKSH C
   Schank R. C., 1973, COMPUTER MODELS THOU, P187
   Stevens R, 2000, BIOINFORMATICS, V16, P184, DOI 10.1093/bioinformatics/16.2.184
   Ullman S, 1962, SEMANTICS INTRO SCI
   WITTGESTEIN L, 1953, PHILOS INVESTIGATION
   WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773
   Zhang G., 1999, Proceedings User Interfaces to Data Intensive Systems, P64, DOI 10.1109/UIDIS.1999.791463
   ZHANG GG, 1998, THESIS U CALIFORNIA
NR 29
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-00074-7
J9 LECT NOTES ARTIF INT
PY 2002
VL 2522
BP 226
EP 239
PG 14
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BW67X
UT WOS:000182803500018
DA 2023-11-10
ER

PT J
AU Theodorakis, S
   Pitsikalis, V
   Maragos, P
AF Theodorakis, Stavros
   Pitsikalis, Vassilis
   Maragos, Petros
TI Dynamic-static unsupervised sequentiality, statistical subunits and
   lexicon for sign language recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic sign language recognition; Data-driven subunits; Sub-sign
   phonetic modeling; Unsupervised; Segmentation; HMM
ID HIDDEN MARKOV-MODELS; ASL RECOGNITION; BASIC UNITS
AB We introduce a new computational phonetic modeling framework for sign language (SL) recognition. This is based on dynamic-static statistical subunits and provides sequentiality in an unsupervised manner, without prior linguistic information. Subunit "sequentiality" refers to the decomposition of signs into two types of parts, varying and non-varying, that are sequentially stacked across time. Our approach is inspired by the Movement-Hold SL linguistic model that refers to such sequences. First, we segment signs into intra-sign primitives, and classify each segment as dynamic or static, i.e., movements and non-movements. These segments are then clustered appropriately to construct a set of dynamic and static subunits. The dynamic/static discrimination allows us employing different visual features for clustering the dynamic or static segments. Sequences of the generated subunits are used as sign pronunciations in a data-driven lexicon. Based on this lexicon and the corresponding segmentation, each subunit is statistically represented and trained on multimodal sign data as a hidden Markov model. In the proposed approach, dynamic/static sequentiality is incorporated in an unsupervised manner. Further, handshape information is integrated in a parallel hidden Markov modeling scheme. The novel sign language modeling scheme is evaluated in recognition experiments on data from three corpora and two sign languages: Boston University American SL which is employed pre-segmented at the sign-level, Greek SL Lemmas, and American SL Large Vocabulary Dictionary, including both signer dependent and unseen signers' testing. Results show consistent improvements when compared with other approaches, demonstrating the importance of dynamic/static structure in sub-sign phonetic modeling. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Theodorakis, Stavros; Pitsikalis, Vassilis; Maragos, Petros] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-10682 Athens, Greece.
C3 National Technical University of Athens
RP Theodorakis, S (通讯作者)，Zografou Campus, Athens 15773, Greece.
EM sth@cs.ntua.gr; vpitsik@cs.ntua.gr; maragos@cs.ntua.gr
FU EU research program Dicta-Sign [FP7-ICT-3-231135]
FX This work was supported by the EU research program Dicta-Sign with grant
   FP7-ICT-3-231135.
CR Ajmera J, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P411, DOI 10.1109/ASRU.2003.1318476
   [Anonymous], 2012, P 2012 IEEE COMPUTER, DOI DOI 10.1109/CVPRW.2012.6239187
   [Anonymous], COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2006.68
   [Anonymous], 2004, P EUR C COMP VIS
   [Anonymous], 2000, SIGN WRITING
   [Anonymous], 2001, AUTOMATIC SIGN LANGU
   Aran O, 2010, PATTERN RECOGN, V43, P1776, DOI 10.1016/j.patcog.2009.12.002
   Athitsos Vassilis, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563181
   Athitsos V., 2010, P WKSP REPR PROC SL
   Awad G, 2009, IEEE IMAGE PROC, P2729, DOI 10.1109/ICIP.2009.5414159
   Brentari D., 2002, MODALITY STRUCTURE S, P35
   Buehler Patrick, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2961, DOI 10.1109/CVPRW.2009.5206523
   Cohen I., 2000, NIPS, V2
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   Cooper Helen, 2011, VISUAL ANAL HUMANS
   Corina D., 2008, PHONOLOGY, V10, P165
   COULTER G, 1982, ANN M LING SOC AM SA
   Derpanis KG, 2008, IMAGE VISION COMPUT, V26, P1650, DOI 10.1016/j.imavis.2008.04.007
   Ding LY, 2009, IMAGE VISION COMPUT, V27, P1826, DOI 10.1016/j.imavis.2009.02.005
   Fang G., 2002, P GEST SIGN LANG HCI, P163
   Fang GL, 2007, IEEE T SYST MAN CY A, V37, P1, DOI 10.1109/TSMCA.2006.886347
   Fang GL, 2004, INT C PATT RECOG, P454, DOI 10.1109/ICPR.2004.1333800
   Guyon I., 2003, J MACH LEARN RES, V3, P1157, DOI 10.1162/153244303322753616
   Han JW, 2009, PATTERN RECOGN LETT, V30, P623, DOI 10.1016/j.patrec.2008.12.010
   KADIR T, 2004, P BRIT MACH VIS C
   Klima E. S., 1979, SIGNS LANGUAGE
   Koller O, 2013, IEEE INT CONF AUTOMA
   Kong WW, 2010, J SIGNAL PROCESS SYS, V59, P211, DOI 10.1007/s11265-008-0292-5
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Liddell SK., 1989, SIGN LANG STUD, V64, P195, DOI DOI 10.1353/SLS.1989.0027
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Myers EW, 1986, ALGORITHMICA, V1, P251, DOI 10.1007/BF01840446
   Nayak S, 2012, J MACH LEARN RES, V13, P2589
   Neidle C., 2012, P 5 WKSP REPR PROC S
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Ong SCW, 2007, LECT NOTES COMPUT SC, V4778, P16
   Pitsikalis V., 2010, P WKSP REPR PROC SL
   Pitsikalis V., 2011, IEEE CVPR WKSP GEST
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Prillwitz S., 1989, INT STUDIES SL COMMU, V7, P225
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Roussos A., 2010, P ECCV WKSP SIGN GES
   Sandler W., 1987, THESIS U TEXAS AUSTI
   Starner Thad, 1997, MOTION BASED RECOGNI, P227
   STOKOE WC, 1980, ANNU REV ANTHROPOL, V9, P365, DOI 10.1146/annurev.an.09.100180.002053
   Theodorakis S., 2012, P INT C IM PROC
   Theodoralds S., 2010, INT C AC SPEECH SIGN
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
   Vogler C, 1997, IEEE SYS MAN CYBERN, P156, DOI 10.1109/ICSMC.1997.625741
   Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895
   Vogler C, 1999, LECT NOTES ARTIF INT, V1739, P211
   von Agris Ulrich, 2008, Universal Access in the Information Society, V6, P323, DOI 10.1007/s10209-007-0104-x
   Wang H., 2010, P ECCV WKSP SIGN GES, V1
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Xie L., 2003, P INT C MULT EXP, V3
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang RD, 2006, INT C PATT RECOG, P108
   Yin P, 2009, INT CONF ACOUST SPEE, P4757, DOI 10.1109/ICASSP.2009.4960694
   Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735
   Zieren J, 2005, PATTERN RECOGN, P333, DOI [10.1007/11492429_63, DOI 10.1007/11492429_63]
NR 62
TC 22
Z9 22
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 533
EP 549
DI 10.1016/j.imavis.2014.04.012
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600008
DA 2023-11-10
ER

PT J
AU Gao, P
   Geng, SJ
   Zhang, RR
   Ma, TL
   Fang, RY
   Zhang, YF
   Li, HS
   Qiao, Y
AF Gao, Peng
   Geng, Shijie
   Zhang, Renrui
   Ma, Teli
   Fang, Rongyao
   Zhang, Yongfeng
   Li, Hongsheng
   Qiao, Yu
TI CLIP-Adapter: Better Vision-Language Models with Feature Adapters
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article; Early Access
DE Feature adapter; Vision-language model; Few-shot learning;
   Open-vocabulary
AB Large-scale contrastive vision-language pretraining has shown significant progress in visual representation learning. Unlike traditional visual systems trained by a fixed set of discrete labels, a new paradigm was introduced in Radford et al. (International conference on machine learning, PMLR, 2021) to directly learn to align images with raw texts in an open-vocabulary setting. On downstream tasks, a carefully chosen text prompt is employed to make zero-shot predictions. To avoid non-trivial prompt engineering, context optimization (Zhou et al. in Int J Comput Vis 130(9):2337-2348, 2022) has been proposed to learn continuous vectors as task-specific prompts with few-shot training examples. In this paper, we show that there is an alternative path to achieve better vision-language models other than prompt tuning. While prompt tuning is for the textual inputs, we propose CLIP-Adapter to conduct fine-tuning with feature adapters on either visual or language branch. Specifically, CLIP-Adapter adopts an additional bottleneck layer to learn new features and performs residual-style feature blending with the original pretrained features. As a consequence, CLIP-Adapter is able to outperform context optimization while maintaining a simple design. Experiments and extensive ablation studies on various visual classification tasks demonstrate the effectiveness of our approach.
C1 [Gao, Peng; Zhang, Renrui; Ma, Teli; Qiao, Yu] Shanghai AI Lab, Shanghai, Peoples R China.
   [Geng, Shijie; Zhang, Yongfeng] Rutgers State Univ, New Brunswick, NJ USA.
   [Fang, Rongyao; Li, Hongsheng] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
C3 Shanghai Artificial Intelligence Laboratory; Rutgers State University
   System; Rutgers New Brunswick; Chinese University of Hong Kong
RP Gao, P (通讯作者)，Shanghai AI Lab, Shanghai, Peoples R China.
EM gaopeng@pjlab.org.cn; sg1309@rutgers.edu; zhangrenrui@pjlab.org.cn;
   hsli@ee.cuhk.edu.hk; qiaoyu@pjlab.org.cn
CR Alayrac Jean-Baptiste, 2022, ADV NEURAL INFORM PR
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Carion Nicolas, 2020, ECCV, DOI DOI 10.1007/978-3-030-58452-813
   Chen Yen-Chun, 2020, ECCV
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong L, 2019, ADV NEUR IN, V32
   Dosovitskiy Alexey, 2021, ICLR
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gao P., 2021, P IEEE CVF INT C COM, P3621
   Gao P., 2021, NEURIPS
   Gao P, 2019, PROC CVPR IEEE, P6632, DOI 10.1109/CVPR.2019.00680
   Gao T., 2021, ACL IJCNLP
   Gu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8410
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Hendrycks Dan, 2021, ARXIV200616241, P8340
   Hendrycks Dan, 2021, CVPR, P3
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Hu SD, 2022, Arxiv, DOI arXiv:2206.07382
   Jia C, 2021, PR MACH LEARN RES, V139
   Jia ML, 2022, LECT NOTES COMPUT SC, V13693, P709, DOI 10.1007/978-3-031-19827-4_41
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim Jin-Hwa, 2018, ADV NEURAL INFORM PR
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045
   Li C., 2022, 36 C NEUR INF PROC S
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li Junnan, 2021, ADV NEURAL INF PROCE, P9694, DOI DOI 10.48550/ARXIV.2107.07651
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Lian D., 2022, ADV NEURAL INFORM PR, V35, P109
   Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815
   Liu X, 2021, Arxiv, DOI [arXiv:2103.10385, DOI 10.48550/ARXIV.2103.10385]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu JS, 2019, ADV NEUR IN, V32
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Mao Mingyuan, 2021, ADV NEURAL INF PROCE, V34, P25346
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford A, 2021, PR MACH LEARN RES, V139
   Recht B, 2019, PR MACH LEARN RES, V97
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sun T., 2022, INT C MACH LEARN PML, p20,841
   Sung YL, 2022, PROC CVPR IEEE, P5217, DOI 10.1109/CVPR52688.2022.00516
   Sung YL., 2022, ADV NEURAL INFORM PR, V35, p12,991
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsimpoukelli Maria, 2021, ADV NEURAL INFORM PR, V34, P200
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A., 2017, ARXIV, V30, P5998
   Wang Haohan, 2019, NEURIPS, V32, P6
   Wang WH, 2022, Arxiv, DOI arXiv:2208.10442
   Wang Zirui, 2022, INT C LEARN REPR
   Wortsman M, 2022, PROC CVPR IEEE, P7949, DOI 10.1109/CVPR52688.2022.00780
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiujun I, 2020, ECCV
   Yao Y., 2022, P 2022 C EMP METH NA, P117
   Yao Y, 2022, Arxiv, DOI arXiv:2109.11797
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhou C., 2022, INT C LEARN REPR
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
NR 70
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD 2023 SEP 15
PY 2023
DI 10.1007/s11263-023-01891
EA SEP 2023
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R8IP5
UT WOS:001066741400001
DA 2023-11-10
ER

PT J
AU Ha, LQ
   Hanna, P
   Ming, J
   Smith, FJ
AF Ha, Le Quan
   Hanna, Philip
   Ming, Ji
   Smith, F. J.
TI Extending Zipf's law to n-grams for large corpora
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Article
DE Zipf Distributions; Zipf's Law; n-grams; Phrases
ID WORD PHRASES; FREQUENCIES; MANDELBROT; MODEL
AB Experiments show that for a large corpus, Zipf's law does not hold for all ranks of words: the frequencies fall below those predicted by Zipf's law for ranks greater than about 5,000 word types in the English language and about 30,000 word types in the inflected languages Irish and Latin. It also does not hold for syllables or words in the syllable-based languages, Chinese or Vietnamese. However, when single words are combined together with word n-grams in one list and put in rank order, the frequency of tokens in the combined list extends Zipf's law with a slope close to -1 on a log-log plot in all five languages. Further experiments have demonstrated the validity of this extension of Zipf's law to n-grams of letters, phonemes or binary bits in English. It is shown theoretically that probability theory alone can predict this behavior in randomly created n-grams of binary bits.
C1 [Hanna, Philip; Ming, Ji; Smith, F. J.] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.
   [Ha, Le Quan] Hochiminh City Univ Ind, Minist Ind & Trade, Comp Sci Branch, Ho Chi Minh City, Vietnam.
C3 Queens University Belfast
RP Smith, FJ (通讯作者)，Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.
EM lequanha@hcmuaf.edu.vn; p.hanna@qub.ac.uk; j.ming@qub.ac.uk;
   fj.smith@qub.ac.uk
CR [Anonymous], P WORKSH SPEECH NAT
   [Anonymous], 2001, WORD FREQUENCY DISTR
   [Anonymous], ARCH CELTIC LATIN LI
   [Anonymous], 2004, P JADT
   BAAYEN H, 1991, P 29 ANN M ASS COMP, P271
   BHERIN UMU, 2004, CORPAS GAELGE 1600 1
   BLAKE C, 2006, P 21 INT C COMP LING, V1, P601
   BOOTH AD, 1967, INFORM CONTROL, V10, P386, DOI 10.1016/S0019-9958(67)90201-X
   Chau M, 2009, INFORM PROCESS MANAG, V45, P115, DOI 10.1016/j.ipm.2008.06.005
   CIERI C, 2000, P LREC 2000 ATH, P49
   Deane Paul., 2005, P 43 ANN M ASS COMPU, P605, DOI DOI 10.3115/1219840.1219915
   Egghe L, 1999, J AM SOC INFORM SCI, V50, P233, DOI 10.1002/(SICI)1097-4571(1999)50:3<233::AID-ASI6>3.0.CO;2-8
   FEDOROWICZ J, 1982, J AM SOC INFORM SCI, V33, P223, DOI 10.1002/asi.4630330406
   Francis W.N, 1964, MANUAL INFORM ACCOMP
   GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344
   GUITER H, 1982, STUDIES ZIPFS LAW
   HA LQ, 2003, J COMPUT LINGUIST CH, V8, P77
   HA LQ, 2005, THESIS QUEENS U BELF
   Hatzigeorgiu N., 2001, J QUANT LINGUIST, V8, P175, DOI [10.1076/jqul.8.3.175.4096, DOI 10.1076/JQUL.8.3.175.4096]
   Jedynak BM, 2005, NEURAL COMPUT, V17, P1508, DOI 10.1162/0899766053723078
   JELINEK F, 1985, IBM TECH DISCL B, V28
   Kornai A., 2002, GLOTTOMETRICS, V4, P61
   LAHERRERE J, 1996, DISTRIBUTIONS TYPE F
   LI WT, 2001, ZIPFS LAW IMPORTANCE
   Mandelbrot B., 1953, COMMUN THEORY, P486, DOI DOI 10.1140/EPJB/E2014-40805-2
   MANDELBROT BB, 1954, T IRE, V3, P124
   Miller G. A., 1958, INFORM CONTR, V1, P370, DOI [DOI 10.1016/S0019-9958(58)90229-8, 10.1016/S0019-9958(58)90229-8]
   Montemurro MA, 2001, PHYSICA A, V300, P567, DOI 10.1016/S0378-4371(01)00355-7
   NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P1414, DOI 10.1109/TASSP.1985.1164728
   NEY H, 1999, COMPUTATIONAL MODELS, P259
   OBOYLE P, 1994, COMPUT SPEECH LANG, V8, P337, DOI 10.1006/csla.1994.1017
   Orlov J., 1983, B ACAD SCI GEORGIA, V110, P269
   SAMUELSON C, 1996, P 4 WORKSH VER LARG
   SICHEL HS, 1975, J AM STAT ASSOC, V70, P542, DOI 10.2307/2285930
   Sichel HS, 1997, S AFR STAT J, V31, P13
   Silagadze Z., 1997, COMPLEX SYST, V11, P487, DOI DOI 13/2018/02/11-6-4.PDF
   Simon H. A., 1960, INFORM CONTROL, V3, P80, DOI [10.1016/S0019-9958(60)90302-8, DOI 10.1016/S0019-9958(60)90302-8]
   SIMON HA, 1955, BIOMETRIKA, V42, P425
   SMITH FJ, 1985, INFORM PROCESS MANAG, V21, P215, DOI 10.1016/0306-4573(85)90106-2
   Sole R. V., 2001, J QUANT LINGUIST, V8, P165, DOI DOI 10.1076/JQUL.8.3.165.4101
   YONEZAWA Y, 1999, P 10 WORKSH GEN INF
   Zipf G.K., 1949, HUMAN BEHAVIOUR PRIN
NR 42
TC 15
Z9 15
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
EI 1573-7462
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD DEC
PY 2009
VL 32
IS 1-4
BP 101
EP 113
DI 10.1007/s10462-009-9135-4
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 533TH
UT WOS:000272847700006
DA 2023-11-10
ER

PT J
AU Watanobe, Y
   Mirenkov, N
AF Watanobe, Yutaka
   Mirenkov, Nikolay
TI Algorithmic Transparency of Large-Scale *AIDA Programs
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE Algorithmic transparency; programming in pictures; large-scale programs
ID ANALYTICS
AB Programming in pictures is an approach where pictures and moving pictures are used as super-characters to represent the features of computational algorithms and data structures, as well as for explaining the models and application methods involved. *AIDA is a computer language that supports programming in pictures. This language and its environment have been developed and promoted as a test-bed for various innovations in information technology (IT) research and implementation, including exploring the compactness of the programs and their adaptive software systems, and obtaining better understanding of information resources. In this paper, new features of the environment and methods of their implementation are presented. They are considered within a case study of a large-scale module of a nuclear safety analysis system to demonstrate that *AIDA language is appropriate for developing efficient codes of serious applications and for providing support, based on folding/unfolding techniques, enhancing the readability, maintainability and algorithmic transparency of programs. Features of this support and the code efficiency are presented through the results of a computational comparison with a FORTRAN equivalent.
C1 [Watanobe, Yutaka] Univ Aizu, Comp Sci & Engn, Aizu Wakamatsu, Fukushima 9658580, Japan.
C3 University of Aizu
RP Watanobe, Y (通讯作者)，Univ Aizu, Comp Sci & Engn, Aizu Wakamatsu, Fukushima 9658580, Japan.
EM yutaka@u-aizu.ac.jp; c15nikmi@u-aizu.ac.jp
CR ARK Information Systems, 2016, TECHNICAL REPORT
   Avola D., 2010, P HC 10 ACM, P159
   Bitter R., 2007, LABVIEW ADV PROGRAMM
   Booch G, 2011, IEEE SOFTWARE, V28, P6, DOI 10.1109/MS.2011.4
   Bottoni P., THEORY ANNOTATIONS
   Bottoni P., 2004, P WORK C ADV VIS INT, P55, DOI DOI 10.1145/989863.989870
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Chien AA, 2019, COMMUN ACM, V62, P5, DOI 10.1145/3162391
   Detienne F., 2002, SOFTWARE DESIGN COGN
   Estelles Enrique, 2010, Interdisciplinary Journal of e-Learning and Learning Objects, V6, P175
   Juhár J, 2017, 2017 IEEE 14TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATICS, P152, DOI 10.1109/INFORMATICS.2017.8327238
   Larkin J. H., 1995, DIAGRAMMATIC REASONI
   Lin CC, 2018, 2018 FIRST INTERNATIONAL COGNITIVE CITIES CONFERENCE (IC3 2018), P135, DOI 10.1109/IC3.2018.00-43
   Nosál M, 2015, ACSIS-ANN COMPUT SCI, V5, P953, DOI 10.15439/2015F173
   Parnas DL, 2011, COMMUN ACM, V54, P31, DOI 10.1145/1953122.1953136
   PETRE M, 1995, COMMUN ACM, V38, P33, DOI 10.1145/203241.203251
   Quatrani T., 2006, VISUAL MODELING IBM
   Rainie L., THEME 7 NEED GROWS A
   Raistrick C., 2004, MODEL DRIVEN ARCHITE
   Roberts JC, 2018, IEEE T VIS COMPUT GR, V24, P791, DOI 10.1109/TVCG.2017.2745878
   Shneiderman B., 2004, DESIGNING USER INTER
   Shneiderman B., 2002, LEONARDOS LAPTOP HUM
   Sloan RH, 2018, IEEE SECUR PRIV, V16, P18, DOI 10.1109/MSP.2018.2701166
   Swift B, 2013, 2013 1ST INTERNATIONAL WORKSHOP ON LIVE PROGRAMMING (LIVE), P27, DOI 10.1109/LIVE.2013.6617345
   Watanobe Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P34, DOI 10.1109/CIT.2016.67
   Watanobe Y, 2014, FRONT ARTIF INTEL AP, V265, P783, DOI 10.3233/978-1-61499-434-3-783
   Watanobe Y, 2014, S VIS LANG HUM CEN C, P137, DOI 10.1109/VLHCC.2014.6883036
   Watanobe Y, 2014, FUTURE GENER COMP SY, V37, P417, DOI 10.1016/j.future.2013.12.031
   Watanobe Y, 2012, FRONT ARTIF INTEL AP, V246, P198, DOI 10.3233/978-1-61499-125-0-198
   Wells P., 8 MYTHS SOFTWARE MOD
NR 30
TC 0
Z9 0
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD SEP
PY 2020
VL 30
IS 9
BP 1263
EP 1288
DI 10.1142/S0218194020500345
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OK1HZ
UT WOS:000584403700004
OA hybrid
DA 2023-11-10
ER

PT J
AU Zhao, DX
   Chang, Z
   Guo, ST
AF Zhao, Dexin
   Chang, Zhi
   Guo, Shutao
TI Cross-scale fusion detection with global attribute for dense captioning
SO NEUROCOMPUTING
LA English
DT Article
DE Dense caption; Deep neural networks; LSTM
AB As a new task of image understanding, the dense caption model needs to locate and describe a salient region in the image simultaneously. It inevitably divides the dense caption model into two parts, one part for detecting the regions of interest and the other part for generating regional language caption. Previous methods are relatively simple to deal with these two parts, using the feature map on the last convolution layer of RPN network to predict object coordinates, and using LSTM for regional language modeling. However, the structure of RPN is insufficient to deal with a large number of objects in the complex dataset, and LSTM also fails to effectively utilize the global information of images in regional language training, which brings opportunity to improve the performance of dense caption. In this paper, we propose a novel Cross-scale Fusion with Global Attribute model (CSGA) that enables the two parts of the dense caption model to perform normal end-to-end training without mutual interference. Furthermore, our model uses a one-stage object detector with feature map fusion operation across multiple detection scales to improve the quality of object detection part, and combines image features with the global high-level attribute to improve regional language training. We design a variety of model architectures and conducted sufficient experiments. Empirical results on Visual Genome dataset show that our model achieves competitive results with mAP 8.33. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zhao, Dexin; Chang, Zhi; Guo, Shutao] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Navel Softwar, 391 West Binshui Rd, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology
RP Chang, Z (通讯作者)，Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Navel Softwar, 391 West Binshui Rd, Tianjin 300384, Peoples R China.
EM zhaodexin@email.tjut.edu.cn; 163128303@stud.tjut.edu.cn;
   alsonsmileshine@hotmail.com
OI Chang, Zhi/0000-0003-4716-7943
FU National Natural Science Foundation of China [61571328]; Tianjin Key
   Natural Science Foundation [18JCZDJC96800]; Training plan of Tianjin
   University Innovation Team [TD12-5016, TD13-5025]; Major projects of
   science and technology for their services in Tianjin [17YFZCGX00360]
FX This research work is supported by National Natural Science Foundation
   of China (Grant No. 61571328), Tianjin Key Natural Science Foundation
   (No.18JCZDJC96800), Training plan of Tianjin University Innovation Team
   (No.TD12-5016, No.TD13-5025), Major projects of science and technology
   for their services in Tianjin (No.17YFZCGX00360).
CR [Anonymous], 2017, CORR
   [Anonymous], 2015, P ICLR
   [Anonymous], 2013, P 51 ANN M ASS COMP
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Elliott D, 2013, P 2013 C EMP METH NA, P1292
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuznetsova P., 2014, J T ASS COMPUT LINGU, V2, P351, DOI [10.1162/tacl_a_00188, DOI 10.1162/TACL_A_00188]
   Li JW, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1106, DOI 10.3115/v1/p15-1107
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Li Z., 2017, FSSD FEATURE FUSION
   Liang XD, 2017, IEEE I CONF COMP VIS, P3382, DOI 10.1109/ICCV.2017.364
   Lin R., 2015, P 2015 C EMPIRICAL M, P899
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luong M.-T., 2015, P 2015 C EMP METH NA, P1412, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mao J, 2015, INT C LEARN REPR
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Socher R, 2013, TACL, P207
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Z, 2016, INT CONF ACOUST SPEE, P3236, DOI 10.1109/ICASSP.2016.7472275
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zhang Y, 2017, INT CONF ACOUST SPEE, P4845, DOI 10.1109/ICASSP.2017.7953077
   Zhao DX, 2019, NEUROCOMPUTING, V329, P476, DOI 10.1016/j.neucom.2018.11.004
   Zhao N, 2016, PROCEEDINGS OF 2016 8TH INTERNATIONAL CONFERENCE ON MODELLING, IDENTIFICATION & CONTROL (ICMIC 2016), P989, DOI 10.1109/ICMIC.2016.7804258
NR 44
TC 1
Z9 1
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 15
PY 2020
VL 373
BP 98
EP 108
DI 10.1016/j.neucom.2019.09.055
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN5YI
UT WOS:000496973200010
DA 2023-11-10
ER

PT J
AU Tran, TT
   Miwa, M
   Ananiadou, S
AF Tran, Thy Thy
   Miwa, Makoto
   Ananiadou, Sophia
TI Syntactically-informed word representations from graph neural network
SO NEUROCOMPUTING
LA English
DT Article
DE Natural language processing; Contextual word representation; Word
   representation; Word embedding; Syntactic word representation
AB Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text. These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information. Therefore, we propose new syntactically-informed word representations (SIWRs), which allow us to enrich the pre-trained word representations with syntactic information without training language models from scratch. To obtain SIWRs, a graph-based neural model is built on top of either static or contextualised word representations such as GloVe, ELMo and BERT. The model is first pre-trained with only a relatively modest amount of task-independent data that are automatically annotated using existing syntactic tools. SIWRs are then obtained by applying the model to downstream task data and extracting the intermediate word representations. We finally replace word representations in downstream models with SIWRs for applications. We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs). The results demonstrate that our SIWRs yield performance gains over the base representations in these NLP tasks with 3-9% relative error reduction. Our SIWRs also perform better than fine-tuning BERT in binary RE. We also conduct extensive experiments to analyse the proposed method. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Tran, Thy Thy; Ananiadou, Sophia] Univ Manchester, Natl Ctr Text Min, Dept Comp Sci, Manchester, Lancs, England.
   [Miwa, Makoto] Toyota Technol Inst, Nagoya, Aichi, Japan.
   [Tran, Thy Thy; Miwa, Makoto; Ananiadou, Sophia] Natl Inst Adv Ind Sci & Technol, Artificial Intelligence Res Ctr, Tokyo, Japan.
   [Ananiadou, Sophia] Alan Turing Inst, London, England.
C3 University of Manchester; Toyota Technological Institute; National
   Institute of Advanced Industrial Science & Technology (AIST)
RP Tran, TT (通讯作者)，Univ Manchester, Natl Ctr Text Min, Dept Comp Sci, Manchester, Lancs, England.
EM thy.tran@manchester.ac.uk; makoto-miwa@toyota-ti.ac.jp;
   sophia.ananiadou@manchester.ac.uk
RI Miwa, Makoto/M-5596-2018
OI Miwa, Makoto/0000-0002-2330-6972; Tran, Thy Thy/0000-0002-0627-9706
FU BBSRC Japan Partnering Award [BB/P025684/1]; Artificial Intelligence
   Research Center, AIST, Japan; University of Manchester; BBSRC
   [BB/P025684/1] Funding Source: UKRI
FX This research was supported by BBSRC Japan Partnering Award [Grant ID:
   BB/P025684/1] and by funding from the Artificial Intelligence Research
   Center, AIST, Japan. TTT thanks the University of Manchester for the
   Research Impact Scholarship Award.
CR Alt C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1388
   [Anonymous], 2016, ABS160502688 ARXIV
   [Anonymous], 2018, LONG PAPERS
   [Anonymous], 2017, ADV NEURAL INFORM PR
   Bansal M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P809
   Chelba C., 2014, ARXIV PREPRINT ARXIV
   Chen YX, 2016, NONLINEAR DYNAM, V85, P2801, DOI 10.1007/s11071-016-2863-5
   Child R, 2019, LANGUAGE MODELS ARE, V1, P8
   Christopoulou F, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P81
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Devlin J., 2018, ARXIV, V1, P4171
   Dozat T, 2016, DEEP BIAFFINE ATTENT
   Eriguchi A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P823
   Faruqui Manaal., 2015, P 2015 C N AM CHAPT, P1606, DOI [10.3115/v1/N15-1184, DOI 10.3115/V1/N15-1184]
   Fisher J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5840
   Hermann Karl Moritz, 2013, ACL, V1, P894
   Iacobacci I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P95
   Ju Meizhi, 2018, P 2018 C N AM CHAPT, P1446, DOI DOI 10.18653/V1/N18-1131
   Kingma D.P., 2014, ICLR
   Kipf T., 2017, ARXIV
   Kuncoro A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1426
   Lauscher A., 2019, ARXIV190902339
   Li J., 2015, P 2015 C EMP METH NA, P1722, DOI [10.18653/v1/D15-1200, DOI 10.18653/V1/D15-1200]
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Marcheggiani D., 2017, ARXIV170304826, DOI DOI 10.18653/V1/D17-1159
   Marcheggiani D., 2018, P 2018 M N AM CHAPTE, V2, P486, DOI 1804.08313
   McDonald R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1849
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Narasimhan, IMPROVING LANGUAGE U
   Neumann M, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P319
   Noreen E, 1989, COMPUTER INTENSIVE M
   Peng H., 2019, ARXIV190902134
   Peng N., 2017, T ASSOC COMPUT LING, V5, P101, DOI DOI 10.1162/TACL_A_00049
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Qiu L., 2016, P 2016 C EMP METH NA, P183, DOI DOI 10.18653/V1/D16-1018
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Socher R., 2012, P 2012 JOINT C EMPIR, P1201, DOI DOI 10.1162/153244303322533223
   Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI [DOI 10.1162/TACL_A_00177, 10.1162/tacl_a_00177]
   Song LF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2226
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5027
   Swayamdipta S., 2019, ARXIV190604341
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tissier J., 2017, EMNLP, P254
   Tokui S, 2015, CHAINER NEXT GENERAT, P1
   Vashishth S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3308
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Vulic I, 2018, REPRESENTATION LEARNING FOR NLP, P137
   Walker C., 2006, ACE 2005 MULTILINGUA, V57
   Wang HY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1371
   Xin X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1853
   Yasunaga M., 2017, ARXIV170606681
   Ye W, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1351
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2205
NR 54
TC 7
Z9 7
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD NOV 6
PY 2020
VL 413
BP 431
EP 443
DI 10.1016/j.neucom.2020.06.070
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD4DT
UT WOS:000579803700035
PM 33162674
OA Green Published, hybrid
DA 2023-11-10
ER

PT J
AU Wang, B
   Ou, ZJ
   Tan, ZQ
AF Wang, Bin
   Ou, Zhijian
   Tan, Zhiqiang
TI Learning Trans-Dimensional Random Fields with Applications to Language
   Modeling
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Language modeling; random field; stochastic approximation;
   trans-dimensional sampling; undirected graphical modeling
ID STOCHASTIC-APPROXIMATION; ALGORITHMS; INFERENCE
AB To describe trans-dimensional observations in sample spaces of different dimensions, we propose a probabilistic model, called the trans-dimensional random field (TRF) by explicitly mixing a collection of random fields. In the framework of stochastic approximation (SA), we develop an effective training algorithm, called augmented SA, which jointly estimates the model parameters and normalizing constants while using trans-dimensional mixture sampling to generate observations of different dimensions. Furthermore, we introduce several statistical and computational techniques to improve the convergence of the training algorithm and reduce computational cost, which together enable us to successfully train TRF models on large datasets. The new model and training algorithm are thoroughly evaluated in a number of experiments. The word morphology experiment provides a benchmark test to study the convergence of the training algorithm and to compare with other algorithms, because log-likelihoods and gradients can be exactly calculated in this experiment. For language modeling, our experiments demonstrate the superiority of the TRF approach in being computationally more efficient in computing data probabilities by avoiding local normalization and being able to flexibly integrate a richer set of features, when compared with n-gram models and neural network models.
C1 [Wang, Bin; Ou, Zhijian] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Tan, Zhiqiang] Rutgers State Univ, Dept Stat, Piscataway, NJ 08854 USA.
C3 Tsinghua University; Rutgers State University System; Rutgers New
   Brunswick
RP Wang, B (通讯作者)，Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM wb.th08@gmail.com; ozj@tsinghua.edu.cn; ztan@stat.rutgers.edu
FU Toshiba Corporation; NSFC [61473168]; Tsinghua Initiative [20121088069]
FX This work is partly supported by NSFC grant 61473168, Tsinghua
   Initiative 20121088069 and Toshiba Corporation.
CR Amaya F, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P10
   [Anonymous], 2016, ABS160904309 CORR
   [Anonymous], 2009, P HUMAN LANGUAGE TEC
   [Anonymous], 2015, 3 INT C LEARNING REP
   [Anonymous], 2012, COURSERA NEURAL NETW
   [Anonymous], 2012, GOOGLE
   Benveniste A., 1990, ADAPTIVE ALGORITHMS, DOI [DOI 10.1007/978-3-642-75894-2, 10.1007/978-3-642-75894-2]
   Chelba C., 2014, ARXIV PREPRINT ARXIV
   Chen H F., 2002, STOCHASTIC APPROXIMA
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.2307/2337340
   Gu MG, 2001, J ROY STAT SOC B, V63, P339, DOI 10.1111/1467-9868.00289
   Khudanpur S, 2000, COMPUT SPEECH LANG, V14, P355, DOI 10.1006/csla.2000.0149
   Koller Daphne, 2009, PROBABILISTIC GRAPHI
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Liang FM, 2007, J AM STAT ASSOC, V102, P305, DOI 10.1198/016214506000001202
   Malouf R., 2002, P 6 C NATURAL LANGUA, V20, P1, DOI [10.3115/1118853.1118871, DOI 10.3115/1118853.1118871]
   Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Minka TP., 2003, COMP NUMERICAL OPTIM, P1
   Mnih A., 2013, NIPS
   Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028
   POLYAK BT, 1992, SIAM J CONTROL OPTIM, V30, P838, DOI 10.1137/0330046
   Roark B., 2004, P ACL, P47
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159
   Ruokolainen T, 2010, FRONT ARTIF INTEL AP, V219, P73, DOI 10.3233/978-1-60750-641-6-73
   Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003
   Shazeer N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1428
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Tan ZQ, 2017, J COMPUT GRAPH STAT, V26, P54, DOI 10.1080/10618600.2015.1113975
   Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI DOI 10.1145/1390156.1390290
   Wang B, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P785
   Wiesler S., 2011, ADV NEURAL INFORM PR, P657
   YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287
   Zaremba W., 2014, PREPRINT
NR 40
TC 11
Z9 11
U1 3
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD APR
PY 2018
VL 40
IS 4
BP 876
EP 890
DI 10.1109/TPAMI.2017.2696536
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY2ZU
UT WOS:000426687100008
PM 28436847
DA 2023-11-10
ER

PT J
AU Cao, FF
   Huang, XM
AF Cao, Feifei
   Huang, Xiaomin
TI Performance analysis of aspect-level sentiment classification task based
   on different deep learning models
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Deep learning; Aspect-based sentiment classification; Comment datasets;
   Perfor-mance analysis; Neural network models; Pre-trained language
   models
AB Aspect-level sentiment classification task (ASCT) is a natural language processing task that aims to correctly identify specific aspects and determine their sentiment polarity from a given target sentence. Deep learning models have been proven to be effective in aspect-based sentiment classification tasks, and the mainstream Aspect level sentiment classification (ASC) models currently constructed generally assume that the training and test datasets are Gaussian distribution (e.g., the same language). Once the data distribution changes, the ASC model must be retrained on the new distribution data to achieve good performance. However, acquiring a large amount of labeled data again typically requires a lot of manpower and money, which seems unlikely, especially for the ASC task, as it requires aspect-level annotation. This article analyzes the performance of sequence-based models, graph-based convolutional neural networks, and pre-training language models on the aspect-level sentiment classification task using two sets of comment datasets in Chinese and English, from four perspectives: classification performance, performance with different aspect numbers, specific case performance, and computational cost. In this article, we design a state-of-the-art ASCbased classification method and conduct a systematic study on eight public standard English and Chinese datasets with various commonly used assessment measures that provide directions for cross-language migration. Finally, we discuss the limitations of the study as well as future research directions.
C1 [Cao, Feifei; Huang, Xiaomin] Guangdong Peizheng Coll, Sch Econ, Guangzhou, Peoples R China.
RP Cao, FF; Huang, XM (通讯作者)，Guangdong Peizheng Coll, Sch Econ, Guangzhou, Peoples R China.
EM caoff16@lzu.edu.cn; hxmzy315@126.com
CR Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549
   Brun C, 2014, PROC SEMEVAL WORKSHO, P838
   Bu JH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2069
   Cai HJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P340
   Chen CH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5596
   Chen Peng, 2017, P 2017 C EMP METH NA, P452, DOI DOI 10.18653/V1/D17-1047
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai JQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1816
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Gu S, 2018, P 27 INT C COMPUTATI, P774
   Jiang L, 2011, PROC 49 ANN M ASS CO, P151
   Jiang QN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6280
   Kim Y, 2014, Arxiv, DOI arXiv:1408.5882
   Kiritchenko S, 2014, PROC 8 INT WORKSHOP, P437, DOI DOI 10.3115/V1/S14-2076
   Li CL, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P180, DOI 10.1109/WI-IAT.2014.96
   Li R., 2021, P 59 ANN M ASS COMP, V1, P6319, DOI [DOI 10.18653/V1/2021.ACL-LONG.494, 10.18653/v1/2021.acl-long.494]
   Li X, 2019, PROC 5 WORKSHOP NOIS, P34
   Li X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P946
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu HY, 2020, IEEE T COMPUT SOC SY, V7, P1358, DOI 10.1109/TCSS.2020.3033302
   Liu J, 2017, PROC IEEE 31 INT C T, V2, P572
   Liu Q, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1023, DOI 10.1145/3178876.3186001
   Liu T, 2016, PROC INT C COMPUT LI
   Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4068
   Ma YK, 2018, AAAI CONF ARTIF INTE, P5876
   Majumdert N, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3402
   Marcheggiani Diego, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P273, DOI 10.1007/978-3-319-06028-6_23
   Nazir A, 2022, IEEE T AFFECT COMPUT, V13, P845, DOI 10.1109/TAFFC.2020.2970399
   Nguyen TH, 2015, P 2016 C EMP METH NA, P2509
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pontiki M., 2014, P 8 INT WORKSHOP SEM, P27, DOI [10.3115/v1/s14-2004, DOI 10.3115/V1/S14-2004]
   Pontiki M., 2016, P 10 INT WORKSH SEM, P19, DOI DOI 10.18653/V1/S16-1002
   Pontiki Maria, 2015, P 9 INT WORKSH SEM E, P486, DOI [10.18653/v1/s15-2082, DOI 10.18653/V1/S15-2082]
   Poria S, 2023, IEEE T AFFECT COMPUT, V14, P108, DOI 10.1109/TAFFC.2020.3038167
   Qiu XP, 2021, Arxiv, DOI arXiv:2003.08271
   Ruder S., 2016, PROC C EMPIRICAL MET, P999
   Sabour S., 2017, ADV NEURAL INFORM PR, V1, P3856, DOI DOI 10.5555/3294996.3295142
   Saeidi M, 2016, P COLING 2016 26 INT, P1546
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Sun C, 2019, Arxiv, DOI arXiv:1903.09588
   Tan SB, 2008, EXPERT SYST APPL, V34, P2622, DOI 10.1016/j.eswa.2007.05.028
   Tang Hao, 2020, P 58 ANN M ASS COMP, P6578, DOI [DOI 10.18653/V1/2020.ACL-MAIN.588, 10.18653/v1/2020.acl-main.588]
   Tay Y, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P107, DOI 10.1145/3132847.3132936
   Tian YH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2910
   Toh Z, 2016, PROC 10 INT WORKSHOP, P282, DOI DOI 10.18653/V1/S16-1045
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Wang JJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3548
   Wang Y, 2016, PROCEEDINGS OF THE 2016 SECOND CONFERENCE ON MOBILE AND SECURE SERVICES (MOBISECSERV)
   WenyaWang Sinno Jialin Pan, 2016, ARXIV160306679
   Wu ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4166
   Xing BW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5313
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   Zagibalov T, 2008, P 3 INT JOINT C NAT
   Zeng JF, 2019, IEEE ACCESS, V7, P20462, DOI 10.1109/ACCESS.2019.2893806
   Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4568
   Zhang M, 2015, PROC C EMPIRICAL MET, P612, DOI [10.18653/v1/d15-1073, DOI 10.18653/V1/D15-1073]
   Zhang MS, 2016, AAAI CONF ARTIF INTE, P3087
   Zhang W, 2022, IEEE T AFFECT COMPUT
   Zhang WX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9209
   Zheng SL, 2018, Arxiv, DOI arXiv:1802.00892
   Zhou J, 2019, IEEE ACCESS, V7, P78454, DOI 10.1109/ACCESS.2019.2920075
NR 62
TC 0
Z9 0
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD OCT 9
PY 2023
VL 9
AR e1578
DI 10.7717/peerj-cs.1578
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U6UB2
UT WOS:001086124900003
PM 37869455
OA gold
DA 2023-11-10
ER

PT J
AU Bengio, Y
   Ducharme, R
   Vincent, P
   Jauvin, C
AF Bengio, Y
   Ducharme, R
   Vincent, P
   Jauvin, C
TI A neural probabilistic language model
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article; Proceedings Paper
CT Workshop on Machine Learning Methods for Text and Images
CY 2001
CL VANCOUVER, CANADA
DE statistical language modeling; artificial neural networks; distributed
   representation; curse of dimensionality
ID NETWORKS
AB A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.
C1 Univ Montreal, Ctr Rech Math, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal
RP Bengio, Y (通讯作者)，Univ Montreal, Ctr Rech Math, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada.
EM BENGIOY@IRO.UMONTREAL.CA; DUCHARME@IRO.UMONTREAL.CA;
   VINCENTP@IRO.UMONTREAL.CA; JAUVINC@IRO.UMONTREAL.CA
CR [Anonymous], 1998, ENCY APPL LING, DOI DOI 10.7551/MITPRESS/7287.001.0001
   [Anonymous], 2000004 GCNU TR U CO
   [Anonymous], 1215 U MONTR DEP IRO
   [Anonymous], 2003, AISTATS
   [Anonymous], PATTERN RECOGNITION
   BAKER D, 1998, SIGIR 98
   Bellegarda J.-R., 1997, P 5 EUR C SPEECH COM, P1451
   Bengio S, 2000, IEEE T NEURAL NETWOR, V11, P550, DOI 10.1109/72.846725
   Bengio Y, 2000, ADV NEUR IN, V12, P400
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BROWN A, 2000, 2000004 GCNU TR U CO
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DONGARRA J, 1995, MESSAGE PASSING INTE
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   GOODMAN J, 2001, MSRTR200172 MICROS R
   Hinton G.E, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI DOI 10.1109/69.917563
   JENSEN KJ, 2000, P ICSLP
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   MIIKKULAINEN R, 1991, COGNITIVE SCI, V15, P343, DOI 10.1207/s15516709cog1503_2
   NEY H, 1993, EUR C SPEECH COMM TE, P973
   Niesler TR, 1998, INT CONF ACOUST SPEE, P177, DOI 10.1109/ICASSP.1998.674396
   PACCANARO A, 2000, P INT JOINT C NEUR N
   PEREIRA F, 1993, 31ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P183
   Riis SK, 1996, J COMPUT BIOL, V3, P163, DOI 10.1089/cmb.1996.3.163
   Schmidhuber J, 1996, IEEE T NEURAL NETWOR, V7, P142, DOI 10.1109/72.478398
   Schutze Hinrich, 1993, ADV NEURAL INFORM PR, P895
   Schwenk H, 2002, INT CONF ACOUST SPEE, P765
   STOLCKE A, 2002, P INT C STAT LEARN P
   Xu W., 2000, INT C STAT LANG PROC, pM1
NR 33
TC 1796
Z9 2092
U1 46
U2 472
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD AUG 15
PY 2003
VL 3
IS 6
BP 1137
EP 1155
DI 10.1162/153244303322533223
PG 19
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science
GA 733LT
UT WOS:000186002400006
DA 2023-11-10
ER

PT S
AU Allison, B
   Guthrie, D
   Guthrie, L
AF Allison, Ben
   Guthrie, David
   Guthrie, Louise
BE Sojka, P
   Kopecek, I
   Pala, K
TI Another look at the data sparsity problem
SO TEXT, SPEECH AND DIALOGUE, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Text, Speech and Dialogue
CY SEP 11-15, 2006
CL Brno, CZECH REPUBLIC
SP Int Speech Commun Assoc, S Moravia Gas Co, Masaryk Univ, Fac Informat, Univ West Bohemia, Fac Appl Sci
AB Performance on a statistical language processing task relies upon accurate information being found in a corpus. However, it is known (and this paper will confirm) that many perfectly valid word sequences do not appear in training corpora. The percentage of n-grams in a test document which are seen in a training corpus is defined as n-gram coverage, and work in the speech processing community [7] has shown that there is a correlation between n-gram coverage and word error rate (WER) on a speech recognition task. Other work (e.g. [1]) has shown that increasing training data consistently improves performance of a language processing task. This paper extends that work by examining n-gram coverage for far larger corpora, considering a range of document types which vary in their similarity to the training corpora, and experimenting with a broader range of pruning techniques. The paper shows that large portions of language will not be represented within even very large corpora. It confirms that more data is always better, but how much better is dependent upon a range of factors: the source of that additional data, the source of the test documents, and how the language model is pruned to account for sampling errors and make computation reasonable.
C1 Univ Sheffield, Sheffield S1 4DP, S Yorkshire, England.
C3 University of Sheffield
RP Allison, B (通讯作者)，Univ Sheffield, Regent Court,211 Portobello St, Sheffield S1 4DP, S Yorkshire, England.
EM b.allison@dcs.shef.ac.uk
CR Brill E., 2001, P C HUM LANG TECHN
   Chen Stanley, 1998, EMPIRICAL STUDY SMOO
   JELINEK F, 1991, P EUR 91
   KLIMT B, 2004, INTRO ENRON EMAIL CO
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   MOORE R, 2001, P IEEE INT WORKSH IN
   POWELL W, 1970, ANARCHISTS COOKBOOK
   ROSENFELD R, 1995, P EUR 95
NR 8
TC 14
Z9 15
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-39090-1
J9 LECT NOTES ARTIF INT
PY 2006
VL 4188
BP 327
EP 334
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFD09
UT WOS:000241103500041
DA 2023-11-10
ER

PT J
AU Zhu, JH
   Huang, XJ
   Song, DW
   Rüger, S
AF Zhu, Jianhan
   Huang, Xiangji
   Song, Dawei
   Rueger, Stefan
TI Integrating multiple document features in language models for expert
   finding
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Expert finding; Language models; Enterprise search
AB We argue that expert finding is sensitive to multiple document features in an organizational intranet. These document features include multiple levels of associations between experts and a query topic from sentence, paragraph, up to document levels, document authority information such as the PageRank, indegree, and URL length of documents, and internal document structures that indicate the experts' relationship with the content of documents. Our assumption is that expert finding can largely benefit from the incorporation of these document features. However, existing language modeling approaches for expert finding have not sufficiently taken into account these document features. We propose a novel language modeling approach, which integrates multiple document features, for expert finding. Our experiments on two large scale TREC Enterprise Track datasets, i.e., the W3C and CSIRO datasets, demonstrate that the natures of the two organizational intranets and two types of expert finding tasks, i.e., key contact finding for CSIRO and knowledgeable person finding for W3C, influence the effectiveness of different document features. Our work provides insights into which document features work for certain types of expert finding tasks, and helps design expert finding strategies that are effective for different scenarios. Our main contribution is to develop an effective formal method for modeling multiple document features in expert finding, and conduct a systematic investigation of their effects. It is worth noting that our novel approach achieves better results in terms of MAP than previous language model based approaches and the best automatic runs in both the TREC2006 and TREC2007 expert search tasks, respectively.
C1 [Zhu, Jianhan] UCL, Dept Comp Sci, London WC1E 6BT, England.
   [Huang, Xiangji] York Univ, Sch Informat Technol, Toronto, ON M3J 1P3, Canada.
   [Song, Dawei] Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland.
   [Rueger, Stefan] Open Univ, Knowledge Media Inst, Milton Keynes MK7 6AA, Bucks, England.
C3 University of London; University College London; York University -
   Canada; Robert Gordon University; Open University - UK
RP Zhu, JH (通讯作者)，UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.
EM jianhan.zhu@ucl.ac.uk; jhuang@yorku.ca; d.song@rgu.ac.uk;
   s.rueger@open.ac.uk
OI Huang, Jimmy Xiangji/0000-0003-1292-1491; Rueger,
   Stefan/0000-0002-6013-9018; Song, Dawei/0000-0002-8660-3608
FU Engineering and Physical Sciences Research Council [EP/F014708/2,
   EP/F035705/1] Funding Source: researchfish; EPSRC [EP/F035705/1,
   EP/F014708/2] Funding Source: UKRI
CR [Anonymous], 2003, P 26 ANN INT ACM SIG, DOI DOI 10.1145/860435.860550
   BAILEY P, 2008, P TREC 2007
   Balog K., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P43, DOI 10.1145/1148170.1148181
   BALOG K, 2007, P 30 ANN INT ACM SIG, P551, DOI DOI 10.1145/1277741.1277836
   Bar-Yossef Z, 2008, KNOWL INF SYST, V14, P101, DOI 10.1007/s10115-007-0096-0
   Baumgartner R., 2007, P 4 EUR SEM WEB C ES, P16
   CAMPBELL CS, 2003, P CIKM 2003
   CAO Y, 2006, P TREC 2005
   CHENG T, 2007, P 33 INT C VER LARG, P387
   Chengxiang Zhai, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P403, DOI 10.1145/502585.502654
   CONRAD JG, 1994, P 17 ANN INT ACM SIG, P260
   Craswell N., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P416, DOI 10.1145/1076034.1076106
   CRASWELL N, 2006, P TREC 2005
   CRASWELL N, 2005, P TREC 2004
   DEVRIES AP, 2008, P INITIATIVE EV XML
   DUAN H, 2008, P TREC 2007
   ENGELSCHALL R, 1999, USERS GUIDE URL REWR
   Fang H, 2007, LECT NOTES COMPUT SC, V4425, P418
   Fu YP, 2006, LECT NOTES COMPUT SC, V4182, P43
   Guimerà R, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.065103
   Haase P, 2008, KNOWL INF SYST, V15, P75, DOI 10.1007/s10115-006-0055-1
   Huang XJ, 2006, IEEE DATA MINING, P295
   Huang XJ, 2006, KNOWL INF SYST, V10, P473, DOI 10.1007/s10115-006-0015-9
   KUSHMERICK N, 1997, P 15 INT JOINT C ART, P729
   Liu P, 2005, KNOWL INF SYST, V8, P103, DOI 10.1007/s10115-004-0152-y
   MACDONALD C, 2007, P CIKM 2007, P344
   Macdonald C, 2008, KNOWL INF SYST, V16, P259, DOI 10.1007/s10115-007-0105-3
   Maybury M, 2001, COMMUN ACM, V44, P55, DOI 10.1145/501317.501343
   METZLER D, 2005, P 28 ANN INT ACM SIG, P472, DOI DOI 10.1145/1076034.1076115
   OHSAWA Y, 2002, P WWW2002, P436
   Petkova D, 2007, P 16 ACM C INF KNOWL, P731, DOI [DOI 10.1145/1321440.1321542, 10.1145/1321440.1321542]
   Petkova D, 2006, PROC INT C TOOLS ART, P599
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   SERDYUKOV P, 2008, P ECIR 2008
   Shen X., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P43, DOI 10.1145/1076034.1076045
   SOBOROFF I, 2007, P TREC 2006
   Tyler JR, 2003, COMMUNITIES AND TECHNOLOGIES, P81
   UPSTILL T, 2003, P AUSTR DOC COMP S A
   Vechtomova O, 2003, INFORM RETRIEVAL, V6, P251, DOI 10.1023/A:1023936321956
   WESTERVELD T, 2007, P TREC2006
   Yimam-Seid D, 2003, J ORG COMP ELECT COM, V13, P1, DOI 10.1207/S15327744JOCE1301_1
   ZHU J, 2008, P 10 ACM WORKSH WEB, P25
   ZHU J, 2007, P TREC 2006
   ZHU J, 2007, WEB INTELLIGENCE AGE, V5, P405
   ZHU J, 2009, J AM SOC IN IN PRESS
   ZHU J, 2008, P ACM INT C INF KNOW, P1421
NR 46
TC 29
Z9 33
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD APR
PY 2010
VL 23
IS 1
BP 29
EP 54
DI 10.1007/s10115-009-0202-6
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 581HF
UT WOS:000276511700002
OA Green Accepted
DA 2023-11-10
ER

PT J
AU Awiszus, M
   Schubert, F
   Rosenhahn, B
AF Awiszus, Maren
   Schubert, Frederik
   Rosenhahn, Bodo
TI Wor(l)d-GAN: Toward Natural-Language-Based PCG in Minecraft
SO IEEE TRANSACTIONS ON GAMES
LA English
DT Article
DE Index Terms-BERT; generation; generative adversarial network (GAN);
   level; Minecraft; natural language processing (NLP); procedural content
   generation (PCG); representation; scales; SinGAN; single example; style
AB This article presents Wor(l)d-GAN, a method to perform data-driven procedural content generation via machine learning in Minecraft from a single example. Based on a 3-D generative adversarial network (GAN) architecture, we are able to create arbitrarily sized world snippets from a given sample. Our method applies dense representations used in natural language processing in two ways. First, we propose block2vec representations based on word2vec. Second, we use the pretrained large language model bidirectional encoder representations from transformers (BERT) to generate representations directly from the token names. These representations make Wor(l)d-GAN independent of the number of different blocks, which can vary a lot in Minecraft, and enable the generation of larger levels. We evaluate our approach on creations from the community as well as structures generated with the Minecraft World Generator under several metrics. Wor(l)d-GAN enables its users to generate Minecraft worlds based on parts of their creations.
C1 [Awiszus, Maren; Schubert, Frederik; Rosenhahn, Bodo] Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany.
C3 Leibniz University Hannover
RP Schubert, F (通讯作者)，Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany.
EM awiszus@tnt.uni-hannover.de; schubert@tnt.uni-hannover.de;
   rosenhahn@tnt.uni-hannover.de
FU Federal Ministry of Education and Research, Germany [01DD20003];
   Deutsche Forschungsgemeinschaft [EXC 2122]
FX This work was supported in part by the Federal Ministry of Education and
   Research, Germany, through the project LeibnizKILabor under Grant
   01DD20003 and in part by the Deutsche Forschungsgemeinschaft under
   Germany's Excellence Strategy within the Cluster of Excellence
   PhoenixDunder Grant EXC 2122.
CR Agrawal A, 2021, FOUND TRENDS MACH LE, V14, P211, DOI 10.1561/2200000090
   [Anonymous], 2020, MIN GAN CIT GEN
   [Anonymous], 2009, MIN VERS 1 16
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Awiszus M, 2020, P 16 ANN AAAI C ART
   Awiszus M, 2021, IEEE CONF COMPU INTE, P71, DOI 10.1109/COG52621.2021.9619133
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Freiknecht J., 2020, PROC INT C FOUND DIG, P1, DOI [10.1145/3402942.3409599, DOI 10.1145/3402942.3409599]
   Giacomello E, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P316, DOI 10.1109/GEM.2018.8516539
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grbic D, 2021, LECT NOTES COMPUT SC, V12694, P325, DOI 10.1007/978-3-030-72699-7_21
   Green M. C., 2019, P 14 INT C FDN DIG G, P1
   Gutierrez J, 2020, IEEE C EVOL COMPUTAT
   Herve J.-B., 2021, P 16 INT C FDN DIG G, P1
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kano A. M., 2020, THESIS U CALIFORNIA
   Karavolos D, 2021, IEEE T GAMES, V13, P11, DOI 10.1109/TG.2019.2931044
   Khalifa A., 2020, P AAAI C ART INT INT, VVolume 16, P95
   Khameneh N. Y., 2020, PROC 2 WORKSHOP EXP
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Levy O, 2014, ADV NEUR IN, V27
   Lucas SM, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P170, DOI 10.1145/3321707.3321781
   Mikolov Tomas, 2013, INT C LEARN REPR
   Patrascu C., 2016, PROC IEEE C COMPUT I, P1
   planetminecraft, DREHM PRIM
   Rabii Y., 2021, P AAAI C ART INT INT, P187
   Radford A, 2021, PR MACH LEARN RES, V139
   Rudolph M, 2022, IEEE WINT CONF APPL, P1829, DOI 10.1109/WACV51458.2022.00189
   Salge C., 2018, PROC 13 INT C FOUND, P1
   Salge C., 2019, PROC 10 INT C COMPUT, P311
   Salge C, 2020, KUNSTL INTELL, V34, P19, DOI 10.1007/s13218-020-00635-0
   Schubert F, 2022, IEEE T GAMES, V14, P284, DOI 10.1109/TG.2021.3069833
   Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467
   Snodgrass S., 2013, PROC 9 ARTIF INTELL, P25
   Soros LB, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCO'17 COMPANION), P95, DOI 10.1145/3067695.3075605
   Sudhakaran S, 2021, Arxiv, DOI arXiv:2103.08737
   Summerville A, 2018, IEEE T GAMES, V10, P257, DOI 10.1109/TG.2018.2846639
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Volz V, 2020, IEEE CONF COMPU INTE, P399, DOI 10.1109/CoG47356.2020.9231944
   Volz V, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P221, DOI 10.1145/3205455.3205517
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Yoon E., 2018, P 14 ART INT INT DIG, P250
NR 43
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2475-1502
EI 2475-1510
J9 IEEE T GAMES
JI IEEE Trans. Gamres
PD JUN
PY 2023
VL 15
IS 2
BP 182
EP 192
DI 10.1109/TG.2022.3153206
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J9LE5
UT WOS:001012760400006
DA 2023-11-10
ER

PT J
AU Ahkouk, K
   Machkour, M
   Majhadi, K
   Mama, R
AF Ahkouk, Karam
   Machkour, Mustapha
   Majhadi, Khadija
   Mama, Rachid
TI SQLSketch: Generating SQL Queries using a sketch-based approach
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Natural language processing; text to SQL translation; database
   interfaces; natural language translation; machine translation
AB In the last decade, many intelligent interfaces and layers have been suggested to allow the use of relational databases and extraction of the content using only the natural language. However most of them struggle when exposed to new databases. In this article, we present SQLSketch, a sketch-based network for generating SQL queries to address the problem of automatically translate Natural Languages questions to SQL using the related databases schemas. We argue that the previous models that use full or partial sequence-to-sequence structure in the decoding phase can, in fact, have counter-effect on the generation operation and came up with more loss of the context or the meaning of the user question. In this regard, we use a full sketch-based structure that decouples the generation process into many small prediction modules. The SQLSketch is evaluated against GreatSQL, a new cross-domain, large-scale and balanced dataset for the Natural Language to SQL translation task. For a long-term aim of making better models and contributing in adding more improvements to the semantic parsing tasks, we propose the GreatSQL dataset as the first balanced cross-domain corpus that includes 45,969 pairs of natural language questions and their corresponding SQL queries in addition to simplified and well structured ground-truth annotations. We establish results for SQLSketch using GreatSQL dataset and compare the performance against two popular types of models that represent the sequential and partial-sketch based approaches. Experimental result shows that SQLSketch outperforms the baseline models by 13% in exact matching accuracy and achieve a score of 23.9% to be the new state-of-the-art model on GreatSQL.
C1 [Ahkouk, Karam; Machkour, Mustapha; Majhadi, Khadija; Mama, Rachid] Ibn Zohr Univ, Fac Sci, Souss Massa Daraa, Morocco.
C3 Ibn Zohr University of Agadir
RP Ahkouk, K (通讯作者)，Ibn Zohr Univ, Fac Sci, Souss Massa Daraa, Morocco.
EM k.ahkouk@uiz.ac.ma
RI Machkour, Mustapha/AAI-1518-2019
OI Machkour, Mustapha/0000-0003-4515-6589
CR Ahkouk Karam, 2020, International Journal of Reasoning-based Intelligent Systems, V12, P264, DOI 10.1504/IJRIS.2020.111786
   [Anonymous], 2017, ABS170900103 CORR
   [Anonymous], 2003, P 8 INT C INT US INT
   [Anonymous], 2019, ARXIV190111504
   Artzi Yoav, 2013, T ASS FORCOMPUTATION
   Banarescu L., 2013, P 7 LING ANN WORKSH
   Berant J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1415, DOI 10.3115/v1/p14-1133
   Bogin B., 2019, ARXIV190506241
   Das Dipanjan, 2010, NAACL
   Devlin Jacob, 2018, ARXIV181004805
   Dong L., 2016, P 54 ANN M ASS COMP, V1
   Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731
   Finegan-Dollak C., 2018, ACL ASS COMPUTATIONA
   He P., 2019, ARXIV190808113
   Hwang Wonseok, 2019, ARXIV190201069
   Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089
   Lee D., 2019, P 2019 C EMP METH NA, P6047
   Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468
   Liang P, 2011, P 49 ANN M ASS COMPU, V1, P590
   Lin Kevin, 2019, ARXIV190513326
   Lin Xi Victoria, 2018, LREC
   Ling Wang, 2016, ACL 1
   Oda Y, 2015, IEEE INT CONF AUTOM, P574, DOI 10.1109/ASE.2015.36
   Price P., 1990, SPEECH NATURAL LANGU, P91, DOI DOI 10.3115/116580.116612
   Reddy S., 2014, TACL, V2, P377, DOI [DOI 10.1162/TACL_A_00190, /10.1162/tacla00190]
   Shi T., 2018, ARXIV180905054
   Tang Lappoon R., 2001, MACHINE LEARNING ECM, P466
   Wang C, 2017, POINTING OUT SQL QUE
   Wong Yuk Wah, 2007, P 45 ANN M ASS COMP
   Xu X., 2017, ARXIV PREPRINT ARXIV
   Yaghmazadeh N., 2017, P ACM PROGRAM LANG, V63
   Yu T., 2018, ARXIV180908887
   Yu T., 2018, ARXIV180409769
   Yu Tao, 2018, P EMNLP, DOI [10.18653/v1/D18-1193, DOI 10.18653/V1/D18-1193]
   Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050
   Zettlemoyer Luke S., 2005, UAI
   Zhao L., 2019, ARXIV190506241
NR 37
TC 0
Z9 0
U1 2
U2 2
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2021
VL 40
IS 6
BP 12253
EP 12263
DI 10.3233/JIFS-210359
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TA8PR
UT WOS:000667508800130
DA 2023-11-10
ER

PT J
AU Schmidtke, HR
AF Schmidtke, H. R.
TI TextMap: A general purpose visualization system
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Language-perception interface; Mental models; Visualization
AB Human language is a versatile tool for communicating mental models between speakers of a language. This paper presents the Text-Map system, a logic-based system for generating visuospatial representations from textual input. TextMap combines a minimalistic parser with a simple model counting mechanism to automatically extract coordinate information from propositional Horn-logic knowledge bases encoding spatial predications. The system is based on a biologically inspired low-level bit vector mechanism, the activation bit vector machine (ABVM). It does not require an ontology apart from a list of which tokens indicate relations. Its minimalism and simplicity make it a general purpose visualization or imagery tool. The paper describes the TextMap application architecture as well as the key algorithms forming the ABVM core. The system is evaluated with respect to a larger case study of a geographic layout of 13 cities demonstrating capabilities as well as current shortcomings for a complex scenario of a human mental map description. (C) 2019 Published by Elsevier B.V.
C1 [Schmidtke, H. R.] Univ Oregon, Eugene, OR 97403 USA.
C3 University of Oregon
RP Schmidtke, HR (通讯作者)，Univ Oregon, Eugene, OR 97403 USA.
EM schmidtke@acm.org
OI Schmidtke, Hedda Rahel/0000-0002-2777-7819
CR [Anonymous], 2012, WORKSH P 8 INT C INT
   [Anonymous], CONSCIOUSNESS EXPLAI
   [Anonymous], 1998, CRITIQUE PURE REASON
   [Anonymous], 1994, UNIFIED THEORIES COG
   Baader F., 2002, DESCRIPTION LOGIC HD
   Benerecetti M, 2000, J EXP THEOR ARTIF IN, V12, P279, DOI 10.1080/09528130050111446
   Casati R., 1999, PARTS PLACES STRUCTU
   Cohn AG, 2001, FUND INFORM, V46, P1
   Dubois D., 1994, HDB LOGIC ARTIFICIAL, V3, P439
   Dylla F, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038927
   Escrig M Teresa, 1998, FR ART INT, V47
   Freksa C, 2015, LECT NOTES COMPUT SC, V9368, P65, DOI 10.1007/978-3-319-23374-1_4
   Gardenfors P., 1995, LANGUAGE EVOLUTION C
   Hajek P., 1998, TR LOG STUD LOG LIB, V4
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Harnad S., 2003, ENCY COGNITIVE SCI
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Levesque H. J., 1987, Computational Intelligence, V3, P78, DOI 10.1111/j.1467-8640.1987.tb00176.x
   Ligozat G, 1998, J VISUAL LANG COMPUT, V9, P23, DOI 10.1006/jvlc.1997.9999
   Passino KM, 1998, FUZZY CONTROL
   Penrose R., 1999, EMPERORS NEW MIND CO
   Quine Willard V., 1982, METHODS LOGIC, Vfourth
   RANDELL DA, 1992, KR 92, P165
   Renz J, 1999, ARTIF INTELL, V108, P69, DOI 10.1016/S0004-3702(99)00002-8
   Schmidtke Hedda R., 2018, Journal of Reliable Intelligent Environments, V4, P211, DOI 10.1007/s40860-018-0070-5
   Schmidtke Hedda R., 2008, Revue d'Intelligence Artificielle, V22, P589, DOI 10.3166/RIA.22.589-608
   Schmidtke HR, 2018, PROCEDIA COMPUT SCI, V145, P805, DOI 10.1016/j.procs.2018.11.027
   Schmidtke HR, 2018, COGN SYST RES, V52, P896, DOI 10.1016/j.cogsys.2018.09.008
   Steels L., 2008, SYMBOLS EMBODIMENT D, P223, DOI [DOI 10.1093/ACPROF:OSO/9780199217274.003.0012, 10.1093/acprof:oso/9780199217274.003.0012]
   Taddeo M, 2005, J EXP THEOR ARTIF IN, V17, P419, DOI 10.1080/09528130500284053
   Vasardani Maria, 2013, Spatial Information Theory. 11th International Conference, COSIT 2013. Proceedings: LNCS 8116, P299, DOI 10.1007/978-3-319-01790-7_17
   Vogt P., 2002, COGNITIVE SYSTEMS RE, V3, P429, DOI DOI 10.1016/S1389-0417(02)00051-7
   ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1
   Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904
   ZADEH LA, 1988, COMPUTER, V21, P83, DOI 10.1109/2.53
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zadeh LA., 1979, ADV FUZZY SET THEORY, V11, P3, DOI DOI 10.1142/9789814261302_0022
NR 37
TC 1
Z9 1
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-4366
EI 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD JAN
PY 2020
VL 59
BP 27
EP 36
DI 10.1016/j.cogsys.2019.08.004
PG 10
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology; Psychology
GA JQ3OW
UT WOS:000498859500003
DA 2023-11-10
ER

PT J
AU Yan, M
   Pan, Y
AF Yan, Ming
   Pan, Yi
TI Meta-learning for compressed language model: A multiple choice question
   answering study
SO NEUROCOMPUTING
LA English
DT Article
DE End-to-end reptile; Compressed pretrained-language-model; Meta-learning;
   Multiple-choice question answering
AB Model compression is a promising approach for reducing the model size of pretrained-language-models (PLMs) on low resource edge devices and applications. Unfortunately, the compression process always accompanies a cost of performance degradation, especially for the low resource downstream tasks, i.e., multiple-choice question answering. To address the degradation issue of model compression on PLMs, we proposed an end-to-end reptile (ETER) meta-learning approach to improving the performance of PLMs on the low resource multiple-choice question answering task. Specifically, our ETER improves the traditional two-stage meta-learning to an end-to-end manner, integrating the target finetuning stage into the meta training stage. To strengthen the generic meta-learning, ETER employs two-level meta-task construction from instance-level and domain-level to enrich its task generalization. What is more, ETER optimizes meta-learning by parameter constraints to reduce its parameter learning space. Experiments demonstrate that ETER significantly improved the performance of compressed PLMs and achieved large superiority over the baselines on different datasets.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Yan, Ming] Agcy Sci Technol & Res, Singapore, Singapore.
   [Pan, Yi] Georgia State Univ, Atlanta, GA 30303 USA.
C3 Agency for Science Technology & Research (A*STAR); University System of
   Georgia; Georgia State University
RP Yan, M (通讯作者)，Agcy Sci Technol & Res, Singapore, Singapore.
EM yan_ming@ihpc.a-star.edu.sg
OI Yan, Ming/0000-0002-5762-395X
FU Agency for Science, Technology and Research (A*STAR) under its AME
   Programmatic Funding Scheme [A18A1b0045]; Science and Technology
   Innovation Program of Sichuan Province [2018RZ0129]
FX Acknowledgement The paper is supported by the Agency for Science,
   Technology and Research (A*STAR) under its AME Programmatic Funding
   Scheme (Project No. A18A1b0045) and the Science and Technology
   Innovation Program of Sichuan Province (Grant No. 2018RZ0129) . Thanks
   JD AI Research for the GPU resource support.
CR Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chen Z., 2018, ARXIV180305655
   Devlin J., 2018, ARXIV, V1, P4171
   Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368
   Finn C, 2017, PR MACH LEARN RES, V70
   Ganesh Prakhar, 2020, ARXIV200211985
   Gordon Mitchell A., 2020, COMPRESSING BERT STU
   Guo DY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P855
   Jiang Z., 2020, ADV NEURAL INFORM PR
   Jiao X., 2020, FINDINGS ASS COMPUTA, P4163, DOI [10.18653/v1/2020.findings-emnlp.372, DOI 10.18653/V1/2020.FINDINGS-EMNLP.372, 10.18653/v1/2020. findings-emnlp.372. URL]
   Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8010
   Jin Di, 2020, ARXIV200913081
   Lai G., 2017, EMNLP, P785, DOI DOI 10.18653/V1/D17-1082
   Lan Zhenzhong, 2019, ARXIV190911942
   Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y
   Liu Y., ARXIV PREPRINT ARXIV
   Liu Z., 2020, ARXIV200511700
   Nichol Alex, 2018, ARXIV180302999
   Ostermann S., 2018, P 12 INT WORKSHOP SE, P747
   Raffel C, 2020, J MACH LEARN RES, V21
   Raganato A., 2020, FINDINGS ASS COMPUTA, P556, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.49
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Richardson M, 2013, P 2013 C EMPIRICAL M, P193
   Sanh V., 2020, ADV NEURAL INFORM PR, V33, P20378
   Sanh Victor, 2020, DISTILBERT DISTILLED
   Santoro A, 2016, PR MACH LEARN RES, V48
   Sennrich R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P211
   Shen DH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1839
   Shen S., 2019, ARXIV190905840
   Shoeybi M, ARXIV190908053
   Si C., 2019, ARXIV191012391
   Snell Jake, 2017, NEURIPS
   Sun K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2633
   Sun K, 2019, T ASSOC COMPUT LING, V7, P217, DOI 10.1162/tacl_a_00264
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158
   Tay Yi, 2020, ARXIV200500743
   Trischler Adam, 2017, P 2 WORKSH REPR LEAR, P191, DOI DOI 10.18653/V1/W17-2623
   Vinyals Oriol, 2016, P NEURIPS
   Wang L., 2018, P 12 INT WORKSHOP SE, P758, DOI [10.18653/v1/S18-1120, DOI 10.18653/V1/S18-1120]
   Wang Z, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6151
   Wolf T., P 2020 C EMPIRICAL M, P38
   Xia JN, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2393, DOI 10.1145/3357384.3358165
   Yan Ming, 2020, P 58 ANN M ASS COMPU, P7331
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zafrir Ofir, 2019, 2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS), P36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zhao Sanqiang, 2019, ARXIV190911687
   Zhu C., 2020, ARXIV190911764
   Zhu P., 2020, ABS200109415 CORR
NR 49
TC 4
Z9 4
U1 4
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAY 28
PY 2022
VL 487
BP 181
EP 189
DI 10.1016/j.neucom.2021.01.148
EA MAR 2022
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1B5WQ
UT WOS:000792507600002
DA 2023-11-10
ER

PT J
AU Ganesh, P
   Chen, Y
   Lou, X
   Khan, MA
   Yang, Y
   Sajjad, H
   Nakov, P
   Chen, DM
   Winslett, M
AF Ganesh, Prakhar
   Chen, Yao
   Lou, Xin
   Khan, Mohammad Ali
   Yang, Yin
   Sajjad, Hassan
   Nakov, Preslav
   Chen, Deming
   Winslett, Marianne
TI Compressing Large-Scale Transformer-Based Models: A Case Study on BERT
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Pre-trained Transformer-based models have achieved state-of-the-art performance for various Natural Language Processing (NLP) tasks. However, these models often have billions of parameters, and thus are too resourcehungry and computation-intensive to suit lowcapability devices or applications with strict latency requirements. One potential remedy for this is model compression, which has attracted considerable research attention. Here, we summarize the research in compressing Transformers, focusing on the especially popular BERT model. In particular, we survey the state of the art in compression for BERT, we clarify the current best practices for compressing large-scale Transformer models, and we provide insights into the workings of various methods. Our categorization and analysis also shed light on promising future research directions for achieving lightweight, accurate, and generic NLP models.
C1 [Ganesh, Prakhar; Chen, Yao; Lou, Xin; Khan, Mohammad Ali] Adv Digital Sci Ctr, Singapore, Singapore.
   [Yang, Yin] Hamad Bin Khalifa Univ, Coll Sci & Engn, Ar Rayyan, Qatar.
   [Sajjad, Hassan; Nakov, Preslav] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Ar Rayyan, Qatar.
   [Chen, Deming; Winslett, Marianne] Univ Illinois, Urbana, IL USA.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar
   Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Computing
   Research Institute; University of Illinois System; University of
   Illinois Urbana-Champaign
RP Ganesh, P (通讯作者)，Adv Digital Sci Ctr, Singapore, Singapore.
EM prakhar.g@adsc-create.edu.sg; yao.chen@adsc-create.edu.sg;
   lou.xin@adsc-create.edu.sg; mohamraad.k@adsc-create.edu.sg;
   yyang@hbku.edu.qa; hsajjad@hbku.edu.qa; pnakov@hbku.edu.qa;
   dchen@illinois.edu; winslett@illinois.edu
RI Chen, Yao/AAW-9689-2021
OI Chen, Yao/0000-0002-5798-2282; Sajjad, Hassan/0000-0002-8584-6595
FU Qatar National Research Fund (Qatar Foundation) [NPRP10-0208-170408];
   National Research Foundation, Prime Minister's Office, Singapore, under
   its Campus for Research Excellence and Technological Enterprise (CREATE)
   program
FX This publication was made possible by NPRP grant NPRP10-0208-170408 from
   the Qatar National Research Fund (a member of Qatar Foundation). This
   work is also partially supported by the National Research Foundation,
   Prime Minister's Office, Singapore, under its Campus for Research
   Excellence and Technological Enterprise (CREATE) program. The findings
   herein reflect the work, and are solely the responsibility of, the
   authors.
CR Ben Noach M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P884
   Boo Y, 2020, INT CONF ACOUST SPEE, P1753, DOI [10.1109/icassp40776.2020.9054724, 10.1109/ICASSP40776.2020.9054724]
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Cao QQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4487
   Chen DY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2463
   Chen Tianlong, 2020, P 34 C NEUR INF PROC, P1753
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Chia Yew Ken, 2018, P COMP DEEP NEUR NET
   Chumachenko Artem, 2020, WEIGHT SQUEEZING REP
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Deb Kalyanmoy, 2014, SEARCH METHODOLOGIES, P403, DOI DOI 10.1007/978-1-4614-6940-7_15
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding LF, 2020, 11TH IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG 2020), P420, DOI 10.1109/ICBK50248.2020.00066
   Fan Angela, 2021, P 10 INT C LEARN REP
   Fan Angela, 2020, P 8 INT C LEARN REPR
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Franco J, 2021, PHYSIOTHER THEOR PR, V37, P1419, DOI 10.1080/09593985.2019.1709234
   Gordon MA, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P143
   Goyal Saurabh, 2020, INT C MACH LEARN PML, P3690
   Guo Fu-Ming, 2019, ARXIV190912486
   HOU L, 2020, ADV NEUR IN, V33, pNI404
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hubara I, 2018, J MACH LEARN RES, V18
   Jiao X., 2020, FINDINGS ASS COMPUTA, P4163, DOI [10.18653/v1/2020.findings-emnlp.372, DOI 10.18653/V1/2020.FINDINGS-EMNLP.372, 10.18653/v1/2020. findings-emnlp.372. URL]
   Kaitao, 2020, ARXIV200412817
   Khetan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2807
   Kitaev Nikita, 2020, ARXIV200104451
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365
   Lan Zhenzhong, 2019, ARXIV190911942
   Li B., 2020, FINDINGS ASS COMPUTA, P3187
   Li JQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3009
   Li Zhuohan, 2020, INT C MACH LEARN, P5958
   Lin Z, 2020, P FIND ASS COMP LING, P719
   Liu L., 2019, ARXIV191103588
   Liu W., 2020, P 58 ANN M ASS COMPU, P6035, DOI DOI 10.18653/V1/2020.ACL-MAIN.537
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Machacek Matous, 2014, P 9 WORKSH STAT MACH, P293, DOI [10.3115/v1/W14-3336, DOI 10.3115/V1/W14-3336]
   Mao Yihuan, 2020, COLING, P3225, DOI [DOI 10.18653/V1/2020.COLING-MAIN.287, 10.18653/v1/2020.coling-main.287]
   Michel Paul, 2019, ADV NEURAL INFORM PR, P14014
   Mukherjee S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2221
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Prakash Prafull, 2020, FIND 2020 C EMP METH, P4711, DOI [10.18653/v1/2020.findings-emnlp.423, DOI 10.18653/V1/2020.FINDINGS-EMNLP.423]
   Prasanna S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3208
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21
   Raganato A., 2020, FINDINGS ASS COMPUTA, P556, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.49
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rosset, 2020, MICROSOFT RES BLOG, V2, P13
   Sajjad Hassan, 2020, ARXIV200403844
   Sanh Victor, 2020, ADV NEURAL INFORM PR, V33
   Sanh Victor, 2019, P 5 WORKSH EN EFF MA, DOI [10.1609/aaai.v34i05.6409, DOI 10.1609/AAAI.V34I05.6409]
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Shoeybi M., 2019, ARXIV
   Sun SQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P498
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4323
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158
   Tambe T., 2021, MICRO
   Tang R., 2019, P 2 WORKSH DEEP LEAR, P202, DOI DOI 10.18653/V1/D19-6122
   Tay Yi, 2020, ARXIV200500743
   Tian James Yi, 2019, ARXIV191206638
   Tsai Henry, 2020, ARXIV200806808
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang SR, 2020, COMPUTING, V102, P717, DOI 10.1007/s00607-019-00768-7
   Wang Sinong, 2020, ARXIV200604768, DOI [10.1007/s00607-019-00768-7, DOI 10.1007/S00607-019-00768-7]
   Wang Wenhui, ADV NEURAL INFORM PR, V33
   Wasserblat Moshe, 2020, P SUSTAINLP WORKSHOP, P35, DOI DOI 10.18653/V1/2020.SUSTAINLP-1.5
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Xin J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2246
   Xu CW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7859
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P811, DOI 10.1109/MICRO50266.2020.00071
   Zafrir O, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zhao Guangxiang, 2019, ARXIV191211637
   Zhao Sanqiang, 2019, ARXIV190911687
   Zhou Denny, P INT C MACH LEARN I, P11546
   Zhou W., 2020, ADV NEURAL INFORM PR
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 82
TC 33
Z9 34
U1 9
U2 21
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 1061
EP 1080
DI 10.1162/tacl_a_00413
PG 20
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200063
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Do, P
   Le, H
   Pham, AB
   Nguyen, CH
AF Phuc Do
   Hung Le
   Pham, An B.
   Nguyen, Cuong H.
TI Using BERT and Knowledge Graph for detecting triples in Vietnamese text
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Natural Language Processing; BERT; Knowledge Graph; Contextual
   understanding; Triple classification
AB One of the challenges in constructing Knowledge Graphs from text is verifying the correctness of the produced results. Each language has its unique characteristics, so a Knowledge Graphs construction system may perform better on certain languages and worse on others. In order to detect the most suitable Knowledge Graph construction systems for Vietnamese, in this paper, we propose a method to classify triples extracted from such systems into two categories: Existent and Non-existent. Vietnamese is a low-resource language with limited natural language processing tools and datasets. By combining BERT with a self-constructed Vietnamese Knowledge Graph, we build a classification model to verify the existence of triples in paragraphs. Our results suggest that BERT can learn contextual relations between words from a large amount of text, even for a low-resource language like Vietnamese. BERT's adaptive capability to detect meaningful triples is also shown and discussed. The outcome of this paper could potentially be used to build more sophisticated systems to solve Knowledge Graph construction and Triple Classification tasks in low resource languages.
C1 [Phuc Do; Hung Le; Pham, An B.; Nguyen, Cuong H.] Vietnam Natl Univ Ho Chi Minh City, Univ Informat Technol, Quarter 6, Ho Chi Minh City, Vietnam.
   [Hung Le] Japan Adv Inst Sci & Technol, Human Informat Sci, 1-1 Asahidai, Nomi, Ishikawa 9231292, Japan.
C3 Vietnam National University Hochiminh City; Japan Advanced Institute of
   Science & Technology (JAIST)
RP Do, P (通讯作者)，Vietnam Natl Univ Ho Chi Minh City, Univ Informat Technol, Quarter 6, Ho Chi Minh City, Vietnam.
EM phucdo@uit.edu.vn; 15520283@gm.uit.edu.vn; 16520016@gm.uit.edu.vn;
   16520148@gm.uit.edu.vn
FU Vietnam National University Ho Chi Minh City (VNU-HCMC) [DS2020-26-01]
FX This research is funded by Vietnam National University Ho Chi Minh City
   (VNU-HCMC) under Grant Number DS2020-26-01.
CR Amazon, 2019, COMPUTATION LANGUAGE
   An Bo, 2018, P 2018 C N AM CHAPT
   Chen DG, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8810366
   Clark Kevin, 2020, ICLR
   Nguyen DQ, 2019, SEMANT WEB, V10, P947, DOI 10.3233/SW-180318
   Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811
   Devlin J., 2018, ARXIV, V1, P4171
   Do P., 2021, COMPUTATIONAL SCI TE, DOI [10.1007/978-981-33-4069-5_1, DOI 10.1007/978-981-33-4069-5_1]
   Do P, 2022, NEURAL COMPUT APPL, V34, P8393, DOI 10.1007/s00521-020-05495-1
   Phuc D, 2019, J INTELL FUZZY SYST, V37, P7555, DOI 10.3233/JIFS-179362
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Ji GL, 2016, AAAI CONF ARTIF INTE, P985
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Nguyen DQ, 2020, PHOBERT PRETRAINED L
   QIN XL, 2017, P IEEE C COMP VIS PA, P1
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rumelhart D., 1986, PARALLEL DISTRIBUTED, V1
   Socher, 2017, ARXIV161101576
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Ho T, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P268, DOI 10.1109/KSE.2015.54
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2020, ARXIV181100147
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang Z., 2016, P 25 INT JOINT C ART, P4
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Xiao H, 2015, TRANSG GENERATIVE MI
   Yao Liang, 2019, ABS190903193 CORR
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
NR 29
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD OCT
PY 2022
VL 34
IS 20
BP 17999
EP 18013
DI 10.1007/s00521-022-07439-3
EA JUN 2022
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2BD
UT WOS:000807908300002
DA 2023-11-10
ER

PT J
AU Jain, A
   Singh, SK
   Singh, KP
AF Jain, Anamika
   Singh, Satish Kumar
   Singh, Krishna Pratap
TI Multi-task learning using GNet features and SVM classifier for signature
   identification
SO IET BIOMETRICS
LA English
DT Article
ID VECTOR
AB Signature biometrics is a widely accepted and used modality to verify the identity of an individual in many legal and financial organisations. A writer and language-independent signature identification method that can distinguish between the genuine and forged sample irrespective of the language of the signature has been proposed. To extract the distinguishing features, a pre-trained model GoogLeNet, which is fine-tuned with the largest signature dataset present till date (GPDS Synthetic), has been used. The proposed method is tested over the BHSig260 (contains images from two regional languages, Bengali and Hindi) dataset. With the help of the above fine-tuned model, knowledge is transferred to the publicly available datasets - BHSig260 and MCYT-75. The features extracted using the fine-tuned model has been fed to the support vector machine (SVM) classifiers. With the proposed method, 96.5% and 95.7% accuracy on Bengali and Hindi datasets, and 93% on MCYT-75 with skilled forged samples have been achieved respectively.
C1 [Jain, Anamika; Singh, Satish Kumar; Singh, Krishna Pratap] Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Jain, A (通讯作者)，Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
EM anamika06jain@gmail.com
RI singh, satish/U-7158-2018; JAIN, ANAMIKA/IAO-0486-2023
OI singh, satish/0000-0002-8536-4991; 
CR Bhunia AK, 2019, NEURAL COMPUT APPL, V31, P8737, DOI 10.1007/s00521-019-04220-x
   Bouamra W, 2018, EXPERT SYST APPL, V107, P182, DOI 10.1016/j.eswa.2018.04.035
   Dey S., 2017, PATTERN RECOGN LETT
   Diaz M, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3274658
   Diaz M, 2016, INT C PATT RECOG, P1147, DOI 10.1109/ICPR.2016.7899791
   Diaz M, 2017, IEEE T PATTERN ANAL, V39, P951, DOI 10.1109/TPAMI.2016.2560810
   Dutta A, 2016, INT C PATT RECOG, P3422, DOI 10.1109/ICPR.2016.7900163
   Eskander GS, 2013, IET BIOMETRICS, V2, P169, DOI 10.1049/iet-bmt.2013.0024
   Ferrer MA, 2013, 6 IAPR INT C BIOM IC, P1, DOI DOI 10.1109/ICB.2013.6612969
   Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981
   Ferrer MA, 2012, IEEE T INF FOREN SEC, V7, P966, DOI 10.1109/TIFS.2012.2190281
   Fierrez-Aguilar J, 2005, LECT NOTES COMPUT SC, V3546, P523
   Hafemann LG, 2018, INT J DOC ANAL RECOG, V21, P219, DOI 10.1007/s10032-018-0301-6
   Hafemann LG, 2016, INT C PATT RECOG, P2989, DOI 10.1109/ICPR.2016.7900092
   Hafemann LG, 2016, IEEE IJCNN, P2576, DOI 10.1109/IJCNN.2016.7727521
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jagtap AB, 2020, MULTIMED TOOLS APPL, V79, P35109, DOI 10.1007/s11042-020-08857-y
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Khan SS, 2010, LECT NOTES ARTIF INT, V6206, P188
   Loka H, 2017, IET BIOMETRICS, V6, P70, DOI 10.1049/iet-bmt.2016.0046
   Okawa M, 2018, PATTERN RECOGN, V79, P480, DOI 10.1016/j.patcog.2018.02.027
   Oliveira L.S., 2017, INT CONF IMAG PROC, P1
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Pal S, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P72, DOI 10.1109/DAS.2016.48
   Pal S, 2013, IET BIOMETRICS, V2, P182, DOI 10.1049/iet-bmt.2013.0016
   Ren JC, 2012, KNOWL-BASED SYST, V26, P144, DOI 10.1016/j.knosys.2011.07.016
   Ruder Sebastian, 2017, OVERVIEW MULTITASK L
   Serdouk Y, 2017, IMAGE VISION COMPUT, V66, P26, DOI 10.1016/j.imavis.2017.08.004
   Shariatmadari S, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420530018
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Soleimani A, 2016, PATTERN RECOGN LETT, V80, P84, DOI 10.1016/j.patrec.2016.05.023
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wan V, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P775, DOI 10.1109/NNSP.2000.890157
   Wei P, 2019, PROC CVPR IEEE, P5757, DOI 10.1109/CVPR.2019.00591
   Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219
   Yilmaz MB, 2018, IEEE COMPUT SOC CONF, P639, DOI 10.1109/CVPRW.2018.00094
NR 36
TC 4
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2047-4938
EI 2047-4946
J9 IET BIOMETRICS
JI IET Biom.
PD MAR
PY 2021
VL 10
IS 2
BP 117
EP 126
DI 10.1049/bme2.12007
EA FEB 2021
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QM6RT
UT WOS:000616971300001
OA gold
DA 2023-11-10
ER

PT J
AU Ivgi, M
   Shaham, U
   Berant, J
AF Ivgi, Maor
   Shaham, Uri
   Berant, Jonathan
TI Efficient Long-Text Understanding with Short-Text Models
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Transformer-based pretrained language models (LMs) are ubiquitous across natural language understanding, but cannot be applied to long sequences such as stories, scientific articles, and long documents due to their quadratic complexity. While a myriad of efficient transformer variants have been proposed, they are typically based on custom implementations that require expensive pretraining from scratch. In this work, we propose SLED: SLiding-Encoder and Decoder, a simple approach for processing long sequences that re-uses and leverages battle-tested short-text pretrained LMs. Specifically, we partition the input into overlapping chunks, encode each with a short-text LM encoder and use the pretrained decoder to fuse information across chunks (fusion-in-decoder). We illustrate through controlled experiments that SLED offers a viable strategy for long text understanding and evaluate our approach on SCROLLS, a benchmark with seven datasets across a wide range of language understanding tasks. We find that SLED is competitive with specialized models that are up to 50x larger and require a dedicated and expensive pretraining step.
C1 [Ivgi, Maor; Shaham, Uri; Berant, Jonathan] Tel Aviv Univ, Blavatnik Sch Comp Sci, Tel Aviv, Israel.
C3 Tel Aviv University
RP Ivgi, M (通讯作者)，Tel Aviv Univ, Blavatnik Sch Comp Sci, Tel Aviv, Israel.
EM maor.ivgi@cs.tau.ac.il; uri.shaham@cs.tau.ac.il; joberant@cs.tau.ac.il
FU Yandex Initiative for Machine Learning; Shashua Fellowship; Blavatnik
   Family Foundation; European Research Council (ERC) under the European
   Union Horizons 2020 research and innovation programme [802800]; European
   Research Council (ERC) [802800] Funding Source: European Research
   Council (ERC)
FX This research was partially supported by The Yandex Initiative for
   Machine Learning, the Shashua Fellowship, the Len Blavatnik and the
   Blavatnik Family Foundation, and the European Research Council (ERC)
   under the European Union Horizons 2020 research and innovation programme
   (grant ERC DELPHI 802800). We would also like to thank our action editor
   and the anonymous reviewers for their insightful suggestions and
   feedback. This work was completed in partial fulfillment for the Ph.D.
   degree of the first author.
CR Ainslie J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P268
   Albert Gu., 2021, ARXIV
   Amouyal Samuel., 2022, ARXIV
   Beltagy I., 2020, ARXIV
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Chen MD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8602
   Choromanski Krzysztof, 2020, ARXIV200914794
   Conneau Alexis, 2020, ASS COMPUT LINGUIST, P8440, DOI [10.18653/v1/2020.acl-main.747, DOI 10.18653/V1/2020.ACL-MAIN, DOI 10.18653/V1/2020.ACL-MAIN.747]
   Cui P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5881
   Dasigi P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4599
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Guo Mandy., 2022, FINDINGS ASS COMPUTA, P724, DOI 10.18653/v1/2022.findings-naacl.55
   Gupta A., 2022, ARXIV
   Gupta A., 2020, ARXIV
   Huang L, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1419
   Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874
   Jiang YC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2726
   Kitaev Nikita, 2020, ARXIV200104451
   Kocisky T., 2018, T ASSOC COMPUT LING, V6, P317, DOI DOI 10.1162/TACL_A_00023
   Koreeda Y., 2021, FINDINGS ASS COMPUTA, P1907, DOI [10.18653/v1/2021.findings-emnlp.164, DOI 10.18653/V1/2021.FINDINGS-EMNLP.164]
   Lewis M., 2020, 58 ANN M ASS COMP LI, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Liu Yinhan, 2019, ARXIV190711692
   Ma X., 2021, ADV NEURAL INFORM PR
   Mehta Harsh., 2022, ARXIV
   Pang RY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5336
   Peng H., 2021, 9 INT C LEARN REPR I
   Quentin Fournier Gaetan, 2021, PRACTICAL SURVEY FAS
   Raffel C, 2020, ARXIV
   Raffel C, 2020, J MACH LEARN RES, V21
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Roy A, 2021, T ASSOC COMPUT LING, V9, P53, DOI 10.1162/tacl_a_00353
   Shaham Uri., 2022, ARXIV
   Sinong Wang, 2020, LINFORMER SELF ATTEN
   Tay Y, 2020, EFFICIENT TRANSFORME
   Tay Yi, 2021, INT C LEARN REPR, V1
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J., 2022, FINDINGS ASS COMPUTA, P1455
   Wang ZG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5878
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Xiong WH, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1975
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369
   Yavuz S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P974
   Yi Tay., 2022, ARXIV
   Zaheer M., 2020, ADV NEUR IN, V33
   Zhong M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5905
NR 46
TC 0
Z9 0
U1 6
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 22
PY 2023
VL 11
BP 284
EP 299
DI 10.1162/tacl_a_00547
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA A3SB5
UT WOS:000954352100002
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU McCoy, RT
   Smolensky, P
   Linzen, T
   Gao, JF
   Celikyilmaz, A
AF McCoy, R. Thomas
   Smolensky, Paul
   Linzen, Tal
   Gao, Jianfeng
   Celikyilmaz, Asli
TI How Much Do Language Models Copy From Their Training Data? Evaluating
   Linguistic Novelty in Text Generation Using RAVEN
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Current language models can generate high-quality text. Are they simply copying text they have seen before, or have they learned generalizable linguistic abstractions? To tease apart these possibilities, we introduce RAVEN, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure. We apply these analyses to four neural language models trained on English (an LSTM, a Transformer, Transformer-XL, and GPT-2). For local structure-e.g., individual dependencies-text generated with a standard sampling scheme is substantially less novel than our baseline of human-generated text from each model's test set. For larger-scale structure-e.g., overall sentence structure-model-generated text is as novel or even more novel than the human-generated baseline, but models still sometimes copy substantially, in some cases duplicating passages over 1,000 words long from the training set. We also perform extensive manual analysis, finding evidence that GPT-2 uses both compositional and analogical generalization mechanisms and showing that GPT-2's novel text is usually well-formed morphologically and syntactically but has reasonably frequent semantic issues (e.g., being self-contradictory).
C1 [McCoy, R. Thomas] Princeton Univ, Princeton, NJ 08544 USA.
   [McCoy, R. Thomas; Smolensky, Paul; Gao, Jianfeng; Celikyilmaz, Asli] Microsoft Res, Redmond, WA 98052 USA.
   [McCoy, R. Thomas; Smolensky, Paul] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Linzen, Tal] NYU, New York, NY USA.
   [Celikyilmaz, Asli] Meta AI, Menlo Pk, CA USA.
C3 Princeton University; Microsoft; Johns Hopkins University; New York
   University
RP McCoy, RT (通讯作者)，Princeton Univ, Princeton, NJ 08544 USA.; McCoy, RT (通讯作者)，Microsoft Res, Redmond, WA 98052 USA.; McCoy, RT (通讯作者)，Johns Hopkins Univ, Baltimore, MD 21218 USA.
EM tom.mccoy@princeton.edu; psmo@microsoft.com; linzen@nyu.edu;
   jfgao@microsoft.com; aslic@meta.com
FU National Science Foundation [1746891]
FX Portions of this research were supported by the National Science
   Foundation Graduate Research Fellowship Program under grant no. 1746891.
   Any opinions, findings, and conclusions or recommendations expressed in
   this material are those of the authors and do not necessarily reflect
   the views of the National Science Foundation.
CR Akyurek Ekin, 2022, FINDINGS ASS COMPUTA, P2429
   Albright A, 2003, COGNITION, V90, P119, DOI 10.1016/S0010-0277(03)00146-X
   Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Bender E. M., 2020, C SESSION P 58 ANN M
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633
   Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267
   Carlini Nicholas., 2023, 11 INT C LEARNING RE
   Celikyilmaz A, 2021, Arxiv, DOI arXiv:2006.14799
   Chen Mark, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.03374
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Dasgupta Ishita., 2022, P 39 INT C MACH LEAR, V162 of Proceedings of Machine Learning Research, P4816
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7250
   Dyer Chris., 2016, P 2016 C N AM CHAPT, P199, DOI [10.18653/v1/N16-1024, DOI 10.18653/V1/N16-1024]
   Elazar Y, 2022, Arxiv, DOI arXiv:2207.14251
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HADLEY RF, 1994, MIND LANG, V9, P431, DOI 10.1111/j.1468-0017.1994.tb00225.x
   Haley Coleman., 2020, P 3 BLACKBOXNLP WORK, P333, DOI [10.18653/v1/2020.blackboxnlp-1.31, DOI 10.18653/V1/2020.BLACKBOXNLP-1.31]
   Han XC, 2022, Arxiv, DOI arXiv:2205.12600
   Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689
   Holtzman Ari, 2020, ICLR
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1725
   Hupkes D, 2020, J ARTIF INTELL RES, V67, P757
   Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4
   Kandpal N, 2022, PR MACH LEARN RES, P10697
   Kaplan J, 2020, Arxiv, DOI arXiv:2001.08361
   Keysers Daniel., 2020, INT C LEARNING REPRE
   Khandelwal Urvashi, 2020, INT C LEARN REPR ICL
   Kim N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9087
   Kitaev N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2676
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9332
   KUCZAJ SA, 1977, J VERB LEARN VERB BE, V16, P589, DOI 10.1016/S0022-5371(77)80021-2
   Lake B, 2018, PR MACH LEARN RES, V80
   LeBrun Benjamin., 2022, INT C LEARN REPR
   Lee J, 2023, Arxiv, DOI arXiv:2203.07618
   Lee K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8424
   Li YF, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4767
   Marcus G, 2020, Arxiv, DOI [arXiv:2002.06177, DOI 10.48550/ARXIV.2002.06177]
   MARCUS GF, 1992, MONOGR SOC RES CHILD, V57, pR5
   McCoy RT, 2020, T ASSOC COMPUT LING, V8, P125, DOI 10.1162/tacl_a_00304
   Meister Clara., 2021, P 59 ANN M ASS COMPU, P5328, DOI [10.18653/v1/2021.acl-long.414, DOI 10.18653/V1/2021.ACL-LONG.414]
   Merity S., 2017, INT C LEARNING REPRE
   MONTAGUE R, 1970, THEORIA, V36, P373
   Mutton A., 2007, P 45 ANN M ASS COMPU, P344
   O'Donnell T. J., 2015, PRODUCTIVITY REUSE L, DOI [10.7551/mitpress/9780262028844.001.0001, DOI 10.7551/MITPRESS/9780262028844.001.0001]
   Pannitto Ludovica., 2020, P 24 C COMPUTATIONAL, P165, DOI DOI 10.18653/V1/2020.CONLL-1.13
   PRASADA S, 1993, LANG COGNITIVE PROC, V8, P1, DOI 10.1080/01690969308406948
   Radford A., 2019, LANGUAGE MODELS ARE
   Rashkin H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4274
   Ravfogel S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3532
   Schlag Imanol., 2019, NEURIPS WORKSHOP CON, DOI [10.48550/arXiv.1910.06611, DOI 10.48550/ARXIV.1910.06611]
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Keskar NS, 2019, Arxiv, DOI [arXiv:1909.05858, DOI 10.48550/ARXIV.1909.05858]
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Vaswani A., 2017, ARXIV, V30, P5998
   Wei J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P932
   Yamakoshi T, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3977
   Yang C, 2016, PRICE OF LINGUISTIC PRODUCTIVITY: HOW CHILDREN LEARN TO BREAK THE RULES OF LANGUAGE, P1, DOI 10.7551/mitpress/9780262035323.001.0001
   Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776
   Zhang SS, 2022, Arxiv, DOI [arXiv:2205.01068, DOI 10.48550/ARXIV.2205.01068]
   Zhang YA, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1112
   Zhang Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3295
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, P1097, DOI 10.1145/3209978.3210080
   Ziegler Albert., 2021, 1 LOOK ROTE LEARNING
NR 68
TC 0
Z9 0
U1 3
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 29
PY 2023
VL 11
BP 652
EP 670
DI 10.1162/tacl_a_00567
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA L6IQ3
UT WOS:001024283700001
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Settles, B
   LaFlair, GT
   Hagiwara, M
AF Settles, Burr
   LaFlair, Geoffrey T.
   Hagiwara, Masato
TI Machine Learning-Driven Language Assessment
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID ENGLISH
AB We describe a method for rapidly creating language proficiency assessments, and provide experimental evidence that such tests can be valid, reliable, and secure. Our approach is the first to use machine learning and natural language processing to induce proficiency scales based on a given standard, and then use linguistic models to estimate item difficulty directly for computer-adaptive testing. This alleviates the need for expensive pilot testing with human subjects. We used these methods to develop an online proficiency exam called the Duolingo English Test, and demonstrate that its scores align significantly with other high-stakes English assessments. Furthermore, our approach produces test scores that are highly reliable, while generating item banks large enough to satisfy security requirements.
C1 [Settles, Burr; LaFlair, Geoffrey T.; Hagiwara, Masato] Duolingo, Pittsburgh, PA 15206 USA.
   [Hagiwara, Masato] Octanove Labs, Seattle, WA USA.
RP Settles, B (通讯作者)，Duolingo, Pittsburgh, PA 15206 USA.
EM burr@duolingo.com; geoff@duolingo.com; masato@octanove.com
OI LaFlair, Geoffrey/0000-0003-0306-6550
CR ABRAHAM RG, 1992, MOD LANG J, V76, P468, DOI 10.2307/330047
   AERA APA & NCME., 2014, STAND ED PSYCH TEST
   Alderson J.C., 1995, LANGUAGE TEST CONSTR
   ANDRICH D, 1978, PSYCHOMETRIKA, V43, P561, DOI 10.1007/BF02293814
   [Anonymous], 1998, ED MEAS ISS PRACT, DOI DOI 10.1111/J.1745-3992.1998.TB00632.X
   [Anonymous], 2011, SCALE DEV THEORY APP
   [Anonymous], COMPUTERIZED ADAPTIV
   [Anonymous], 2006, SMART LANGUAGE READE
   [Anonymous], 2004, PSYCHOL TESTING PRIN
   [Anonymous], 2011, ANNU M AM EDUC RES
   [Anonymous], 1960, PROBABILISTIC MODELS
   Bachman L. F., 2010, LANGUAGE ASSESSMENT
   Beinborn L., 2014, T ASSOC COMPUT LING, V2, P517, DOI DOI 10.1162/TACL_A_00200
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   BROWN JD, 1989, JAPAN ASS LANGUAGE T, V11, P46
   Cambridge English, 2012, PREL WORDL
   Capel A., 2012, ENGLISH PROFILE J, V3, P1
   Capel A., 2010, ENGLISH PROFILE J, V1, DOI DOI 10.1017/S2041536210000048
   Cau S, 2015, GLOBAL TIMES
   Chen SY, 2003, J EDUC MEAS, V40, P129, DOI 10.1111/j.1745-3984.2003.tb01100.x
   Council of Europe, 2001, COMM EUR FRAM REF LA
   Culligan B, 2015, LANG TEST, V32, P503, DOI 10.1177/0265532215572268
   Curto Pedro, 2015, 7th International Conference on Computer-Supported Education (CSEDU 2015). Proceedings, P36
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Dudley Renee, 2016, REUTERS INVESTIGATES
   Elkan C, 2005, LECT NOTES COMPUT SC, V3772, P295
   ETS , 2010, LINK TOEFL IBT SCOR
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Freedle R., 1999, LANG TEST, V16, P2
   Freedle R., 1993, 9313 ETS
   Graves A., 2014, ARXIV14105401, DOI DOI 10.3389/NEUR0.12.006.2007
   Heafield K., 2013, P 51 ANN M ASS COMP, V2, P690
   Hoshino A., 2010, P 11 INT C INTELLIGE, V46, P279
   Isbell DR, 2017, ASSESS WRIT, V34, P37, DOI 10.1016/j.asw.2017.08.004
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jessop L, 2007, CAN MOD LANG REV, V64, P215, DOI 10.3138/cmlr.64.1.215
   Kane MT, 2013, J EDUC MEAS, V50, P1, DOI 10.1111/jedm.12000
   Khodadady E., 2014, J LANGUAGE TEACHING, V5, P1353
   Klein-Braley, 1997, LANG TEST, V14, P47, DOI [10.1177/026553229701400104, DOI 10.1177/026553229701400104]
   Kostin I., 2004, 0411 ETS, DOI [10.1002/j.2333-8504.2004.tb01938.x, DOI 10.1002/J.2333-8504.2004.TB01938.X]
   Lane S., 2016, HDB TEST DEV
   Lin W. Y., 2008, J PAN PACIFIC ASS AP, V12, P61
   Linacre J.M., 2014, RASCH MEASUREMENT T, V27, P1441
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P923
   Lord F., 1980, APPL ITEM RESPONSE T
   Loukina A., 2016, P COLING 2016 26 INT, P3245
   MASTERS GN, 1982, PSYCHOMETRIKA, V47, P149, DOI 10.1007/BF02296272
   Milton J., 2010, 2 LANGUAGE ACQUISITI, P211
   Milton J, 2010, SECOND LANG ACQUIS, V52, P83
   Mostow J., 2012, P 7 WORKSH BUILD ED, P136
   Napoles C, 2010, P NAACL HLT 2010 WOR, P42
   Nissan S., 1995, ANAL FACTORS AFFECTI, P95
   Nitko A. J., 2011, ED ASSESSMENT STUDEN, V6th ed.
   Perez-Beltrachini L, 2012, P 7 WORKSH BUILD ED, P147
   Reichert M., 2010, C TEST CONTRIBUTIONS, P205
   Sculley David, 2010, P 16 ACM SIGKDD INT, P979, DOI DOI 10.1145/1835804.1835928
   Segall D.O., 2005, ENCY SOCIAL MEASUREM
   Settles B., 2012, SYNTHESIS LECT ARTIF, V6, P1, DOI DOI 10.2200/S00429ED1V01Y201207AIM018
   SIRECI SG, 1991, J EDUC MEAS, V28, P237, DOI 10.1111/j.1745-3984.1991.tb00356.x
   Staehr LS, 2008, LANG LEARN J, V36, P139, DOI 10.1080/09571730802389975
   Stocking M. L., 1994, 945 ETS
   Sung YT, 2015, MOD LANG J, V99, P371, DOI 10.1111/modl.12213
   Susanti Y, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION, VOL 1 (CSEDU), P267, DOI 10.5220/0005775502670274
   VAJJALA S, 2018, P 13 WORKSH INN US N, P147
   Vajjala S., 2016, P WORKSHOP COMPUTATI, P38
   Van Moere A, 2012, LANG TEST, V29, P325, DOI 10.1177/0265532211424478
   Vinther T., 2002, INT J APPL LINGUIST, V12, P54, DOI [DOI 10.1111/1473-4192.00024, 10.1111/1473-4192.00024]
   Volodina E., 2016, CALL COMMUNITIES CUL, P456, DOI 10.14705/rpnet.2016.eurocall2016.606
   Wainer, 2000, COMPUTERIZED ADAPTIV
   WEISS DJ, 1984, J EDUC MEAS, V21, P361, DOI 10.1111/j.1745-3984.1984.tb01040.x
   Westhoff G, 2007, MOD LANG J, V91, P676, DOI 10.1111/j.1540-4781.2007.00627_9.x
   Xia M., 2016, P 11 WORKSHOP INNOVA, P12
   Zhu Xiaojin, 2009, SYNTHESIS LECT ARTIF, DOI [10.2200/S00196ED1V01Y200906AIM006, DOI 10.2200/S00196ED1V01Y200906AIM006]
   Zimmerman J., 1977, INTELLIGENCE, V1, P5, DOI DOI 10.1016/0160-2896(77)90025-3
NR 75
TC 23
Z9 24
U1 6
U2 15
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2020
VL 8
BP 247
EP 263
DI 10.1162/tacl_a_00310
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA XX8IL
UT WOS:000736531900017
OA gold
DA 2023-11-10
ER

PT J
AU Özer, H
   Korkmaz, EE
AF Ozer, Hilal
   Korkmaz, Emin Erkan
TI Transmorph: a transformer based morphological disambiguator for Turkish
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
LA English
DT Article
DE Natural language analysis; agglutinative languages; machine learning
   methods; morphological disambiguation; morphological analysis;
   transformer network
AB The agglutinative nature of the Turkish language has a complex morphological structure, and there are generally more than one parse for a given word. Before further processing, morphological disambiguation is required to determine the correct morphological analysis of a word. Morphological disambiguation is one of the first and crucial steps in natural language processing since its success determines later analyses. In our proposed morphological disambiguation method, we used a transformer-based sequence-to-sequence neural network architecture. Transformers are commonly used in various NLP tasks, and they produce state-of-the-art results in machine translation. However, to the best of our knowledge, transformer-based encoder-decoders have not been studied in morphological disambiguation. In this study, in addition to character level tokenization, three input subword representations are evaluated, which are unigram, bytepair, and wordpiece tokenization methods. We have achieved the best accuracy with character input representation which is 96.25%. Although the proposed model is developed for Turkish language, it is not language-dependent, so it can be applied to a larger set of languages.
C1 [Ozer, Hilal; Korkmaz, Emin Erkan] Yeditepe Univ, Dept Comp Engn, Fac Engn, Istanbul, Turkey.
C3 Yeditepe University
RP Özer, H (通讯作者)，Yeditepe Univ, Dept Comp Engn, Fac Engn, Istanbul, Turkey.
EM hilal.ozer@std.yeditepe.edu.tr
RI korkmaz, emin erkan/C-8380-2012
CR Akyürek E, 2019, T ASSOC COMPUT LING, V7, P567, DOI 10.1162/tacl_a_00286
   [Anonymous], 2007, STRUCTURE
   [Anonymous], 2009, P BIENNIAL GSCL C
   Antworth EL, 1990, PC KIMMO 2 LEVEL PRO
   BAYES T, 1958, BIOMETRIKA, V45, P296
   Çöltekin Ç, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1079
   Cunningham J. P., 2007, ADV NEURAL INFORM PR, V20, P329
   Daybelge T, 2007, P REC ADV NAT LANG P, P145
   Defazio A, 2021, ARXIV
   Eryigit G, 2004, Proceedings of the IASTED International Conference on Artificial Intelligence and Applications, Vols 1and 2, P299
   Esref Y., 2019, P 2019 27 SIGNAL PRO, P1
   Geva M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5484
   Görgün O, 2012, COMPUTER AND INFORMATION SCIENCES II, P77, DOI 10.1007/978-1-4471-2155-8_9
   Güngör O, 2019, NAT LANG ENG, V25, P147, DOI 10.1017/S1351324918000281
   Hakkani-Tür DZ, 2002, COMPUT HUMANITIES, V36, P381, DOI 10.1023/A:1020271707826
   Hochreiter S., 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/NECO.1997.9.8.1735
   Kalender M, 2018, IEEE T KNOWL DATA EN, V30, P367, DOI 10.1109/TKDE.2017.2761743
   Kalender M, 2017, TURK J ELECTR ENG CO, V25, P2388, DOI 10.3906/elk-1512-102
   Kayabas A, 2019, TURK J ELECTR ENG CO, V27, P3837, DOI 10.3906/elk-1902-125
   Koskenniemi K, 1983, 2 LEVEL MORPHOLOGY G
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Libovicky J, 2018, P 3 C MACH TRANSL RE, P253, DOI DOI 10.18653/V1/W18-6326
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   Oflazer K., 1994, Literary & Linguistic Computing, V9, P137, DOI 10.1093/llc/9.2.137
   Oflazer K, 1996, P C EMPIRICAL METHOD
   Oflazer K, 1994, P 4 C APPL NAT LANG, P144, DOI [10.3115/974358.974391, DOI 10.3115/974358.974391]
   Orhan U, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3397967
   Ozturel A, 2019, P 14 INT C FIN STAT, P65, DOI DOI 10.18653/V1/W19-3110
   Pan YR, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12060096
   Rumelhart D.E., 1985, TECHNICAL REPORT, DOI 10.1016/b978-1-4832-1446-7.50035-2
   Sak H, 2009, P ACL IJCNLP 2009 C, P273
   Sak H, 2008, LECT NOTES ARTIF INT, V5221, P417
   Sak H, 2007, LECT NOTES COMPUT SC, V4394, P107
   Seker A, 2020, FINDINGS ASS COMPUTA, P4368, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.391
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shaw Peter, 2018, NAACL, P5, DOI DOI 10.18653/V1/N18-2074
   Shen Q, 2016, P COLING 2016 26 INT, P181
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Wu Y, 2016, ARXIV
   Yildiz E, 2019, 16TH SIGMORPHON WORKSHOP ON COMPUTATIONAL RESEARCH IN PHONETICS PHONOLOGY, AND MORPHOLOGY (SIGMORPHON 2019), P25
   Yildiz E, 2016, AAAI CONF ARTIF INTE, P2863
   Yildiz OT, 2019, P INT C RECENT ADV N, P1364
   Yuret D, 2006, P MAIN C HUM LANG TE, P328, DOI DOI 10.3115/1220835.1220877
   Zhu SL, 2018, WIRELESS PERS COMMUN, V102, P2527, DOI 10.1007/s11277-018-5274-8
NR 46
TC 1
Z9 1
U1 2
U2 2
PU Tubitak Scientific & Technological Research Council Turkey
PI ANKARA
PA ATATURK BULVARI NO 221, KAVAKLIDERE, TR-06100 ANKARA, TURKIYE
SN 1300-0632
EI 1303-6203
J9 TURK J ELECTR ENG CO
JI Turk. J. Electr. Eng. Comput. Sci.
PY 2022
VL 30
IS 5
BP 1897
EP 1913
DI 10.55730/1300-0632.3912
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7J6XM
UT WOS:000904725600015
OA Bronze
DA 2023-11-10
ER

PT J
AU Shin, HC
   Lu, L
   Kim, L
   Seff, A
   Yao, JH
   Summers, RM
AF Shin, Hoo-Chang
   Lu, Le
   Kim, Lauren
   Seff, Ari
   Yao, Jainhua
   Summers, Ronald M.
TI Interleaved Text/Image Deep Mining on a Large-Scale Radiology Database
   for Automated Image Interpretation
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE Deep learning; Convolutional Neural Networks; Topic Models; Natural
   Language Processing; Medical Imaging
AB Despite tremendous progress in computer vision, there has not been an attempt to apply machine learning on very large-scale medical image databases. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital's Picture Archiving and Communication System. With natural language processing, we mine a collection of similar to 216K representative two-dimensional images selected by clinicians for diagnostic reference and match the images with their descriptions in an automated manner. We then employ a weakly supervised approach using all of our available data to build models for generating approximate interpretations of patient images. Finally, we demonstrate a more strictly supervised approach to detect the presence and absence of a number of frequent disease types, providing more specific interpretations of patient scans. A relatively small amount of data is used for this part, due to the challenge in gathering quality labels from large raw text data. Our work shows the feasibility of large-scale learning and prediction in electronic patient records available in most modern clinical institutions. It also demonstrates the trade-offs to consider in designing machine learning systems for analyzing large medical data.
C1 [Shin, Hoo-Chang; Lu, Le; Kim, Lauren; Seff, Ari; Yao, Jainhua; Summers, Ronald M.] NIH, Imaging Biomarkers & Comp Aided Diag Lab Radiol &, Ctr Clin, Bldg 10, Bethesda, MD 20892 USA.
C3 National Institutes of Health (NIH) - USA; NIH Clinical Center (CC)
RP Shin, HC (通讯作者)，NIH, Imaging Biomarkers & Comp Aided Diag Lab Radiol &, Ctr Clin, Bldg 10, Bethesda, MD 20892 USA.
EM HOOCHANG.SHIN@NIH.GOV; LE.LU@NIH.GOV; LAUREN.KIM2@NIH.GOV;
   ARI.SEFF@NIH.GOV; JYAO@CC.NIH.GOV; RMS@NIH.GOV
RI Lu, Le/AAD-7619-2020; Summers, Ronald/AAX-6290-2021; Yao,
   Jianhua/GQZ-6627-2022
OI Lu, Le/0000-0002-6799-9416; Yao, Jianhua/0000-0001-9157-9596
FU Intramural Research Program of the National Institutes of Health
   Clinical Center; KRIBB Research Initiative Program (Korean Biomedical
   Scientist Fellowship Program), Korea Research Institute of Bioscience
   and Biotechnology, Republic of Korea
FX This work was supported in part by the Intramural Research Program of
   the National Institutes of Health Clinical Center, and in part by a
   grant from the KRIBB Research Initiative Program (Korean Biomedical
   Scientist Fellowship Program), Korea Research Institute of Bioscience
   and Biotechnology, Republic of Korea. This study utilized the
   high-performance computational capabilities of the Biowulf Linux cluster
   at the National Institutes of Health, Bethesda, MD
   (http://biowulf.nih.gov). We thank NVIDIA for the K40 GPU donation.
CR [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2003, SIGIR
   [Anonymous], 2015, P IEEE C COMPUTER VI
   [Anonymous], 2003, PROC 26 ANN INT ACM, DOI DOI 10.1145/860435.860537
   [Anonymous], OPEN OP ACC BIOM IM
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48
   Bird S., 2009, NATURAL LANGUAGE PRO, Vfirst
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Carrivick Luke, 2005, 2005 COMP SOC C COP, V2, P854
   Chapman WW, 2013, STUD HEALTH TECHNOL, V192, P677, DOI 10.3233/978-1-61499-289-9-677
   Chapman WW, 2001, J BIOMED INFORM, V34, P301, DOI 10.1006/jbin.2001.1029
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deselaers T, 2008, PATTERN RECOGN LETT, V29, P2003, DOI 10.1016/j.patrec.2008.03.013
   Ding C, 2006, PROCEEDING 21 NATL C, V1, P342
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Gaussier E., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P601, DOI 10.1145/1076034.1076148
   Gupta A., 2013, P INT C MACH LEARN
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hodosh M., 2010, P NAACL HLT 2010 WOR
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Humphreys BL, 1998, J AM MED INFORM ASSN, V5, P1
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karpathy A., 2014, ADV NEURAL INFORM PR, V27, P1889
   Kelvin Xu, 2015, P 31 INT C MACH LEAR
   Kiapour MH, 2014, LECT NOTES COMPUT SC, V8689, P472, DOI 10.1007/978-3-319-10590-1_31
   Kim G., 2015, IEEE C COMP VIS PATT
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Krizhevsky A., 2009, HDB SYST AUTOIMMUNE, V1, P3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Langlotz CP, 2006, RADIOGRAPHICS, V26, P1595, DOI 10.1148/rg.266065168
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li S., 2011, P C COMP NAT LANG LE, P220
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281, DOI 10.1055/s-0038-1634945
   Mao J., 2015, P INT C LEARN REPR I
   Mikolov T., 2013, P 2013 C N AM CHAPT, P746
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T., 2013, P WORKSHOP ICLR
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Ordonez V, 2014, LECT NOTES COMPUT SC, V8694, P494, DOI 10.1007/978-3-319-10599-4_32
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021
   Schriml LM, 2012, NUCLEIC ACIDS RES, V40, pD940, DOI 10.1093/nar/gkr972
   SCHUYLER PL, 1993, B MED LIBR ASSOC, V81, P217
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Simonyan K, 2015, 3 INT C LEARN REPR I
   Socher R, 2013, ADV NEURAL INFORM PR, V26
   Stevens K., 2012, P 2012 JOINT C EMP M, P952, DOI DOI 10.1094/PDIS-11-11-0999-PDN
   Szegedy C, 2015, P IEEE C COMP VIS PA
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Vincent P., 2008, P 25 INT C MACH LEAR, P1096
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Young P., 2014, T ASSOC COMPUT LING, V2, P67
NR 59
TC 44
Z9 47
U1 1
U2 23
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2016
VL 17
AR 107
PG 31
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA EH1SD
UT WOS:000391546500001
DA 2023-11-10
ER

PT J
AU Rédey, G
AF Rédey, G
TI iCTRL:: Intensional conformal text representation language
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE intensional logic; Aristotelian term logic; sentence-formula proximity;
   knowledge base validation; natural language syntax conform text
   modelling; computer-aided knowledge acquisition; content relevant
   textual knowledge base query handling; information retrieval systems
AB A new compact and homogeneous symbolism is introduced to achieve a more general and exact representation of natural language texts. Traditional first-order and intensional logic cannot cope with numerous natural language phenomena such as the large variety of modalities, satisfactory interpretation of iterative application of modal operators or certain modelling problems like one-to-one sentence-formula mapping. The CTRL/iCTRL formalism can model them successfully and they are able to control many other different shades of meaning by applying only a minimal number of syntactic tools.
   The most profitable and beneficial Al application of the presented natural language syntax consistent knowledge representation technique is automated knowledge acquisition: computer-aided textual data base generation and logical inference based information retrieval. CTRL/iCTRL applicability is demonstrated by various illustrative examples including a transparent graphical interpretation analogous to Frege's graph language that help clarify new concepts and exemplify partial inappropriateness of traditional logical language.
   The CTRL/iCTRL paradigm is based on a novel and interesting synthesis of the two traditional logic schools, the Stoic and the Peripatetic school, refuting a century long scientific prejudice against the latter stated to be completely outworn. An interesting issue of this analysis points out that expressing subordination unconsciously and simply by co-ordination causes a typical restriction of meaning in classical logic. (C) 1999 Elsevier Science B.V. All rights reserved.
C1 Hungarian Atom Energy Author, Nucl Safety Directorate, H-1539 Budapest 114, Hungary.
RP Rédey, G (通讯作者)，Hungarian Atom Energy Author, Nucl Safety Directorate, POB 676, H-1539 Budapest 114, Hungary.
CR REDEY G, 1993, ENG APPL ARTIF INTEL, V6, P65, DOI 10.1016/0952-1976(93)90042-V
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 6
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0004-3702
J9 ARTIF INTELL
JI Artif. Intell.
PD APR
PY 1999
VL 109
IS 1-2
BP 33
EP 70
DI 10.1016/S0004-3702(99)00016-8
PG 38
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 205BQ
UT WOS:000080801800002
DA 2023-11-10
ER

PT J
AU Graziani, L
   Gori, M
   Melacci, S
AF Graziani, Lisa
   Gori, Marco
   Melacci, Stefano
TI A language modeling-like approach to sketching
SO NEURAL NETWORKS
LA English
DT Article
DE Sketch generation; Recurrent Neural Networks; Language Modeling
AB Sketching is a universal communication tool that, despite its simplicity, is able to efficiently express a large variety of concepts and, in some limited contexts, it can be even more immediate and effective than natural language. In this paper we explore the feasibility of using neural networks to approach sketching in the same way they are commonly used in Language Modeling. We propose a novel approach to what we refer to as "Sketch Modeling", in which a neural network is exploited to learn a probabilistic model that estimates the probability of sketches. We focus on simple sketches and, in particular, on the case in which sketches are represented as sequences of segments. Segments and sequences can be either given - when the sketches are originally drawn in this format - or automatically generated from the input drawing by means of a procedure that we designed to create short sequences, loosely inspired by the human behavior. A Recurrent Neural Network is used to learn the sketch model and, afterward, the network is seeded with an incomplete sketch that it is asked to complete, generating one segment at each time step. We propose a set of measures to evaluate the outcome of a Beam Search-based generation procedure, showing how they can be used to identify the most promising generations. Our experimental analysis assesses the feasibility of this way of modeling sketches, also in the case in which several different categories of sketches are considered. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Graziani, Lisa] Univ Siena, Dept Social Polit & Cognit Sci, Siena, Italy.
   [Graziani, Lisa; Gori, Marco; Melacci, Stefano] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Gori, Marco] Univ Cote dAzur, MAASAI, Nice, France.
   [Graziani, Lisa] Univ Florence, Dept Informat Engn, Florence, Italy.
C3 University of Siena; University of Siena; UDICE-French Research
   Universities; Universite Cote d'Azur; University of Florence
RP Melacci, S (通讯作者)，Univ Siena, Dept Informat Engn & Math, Siena, Italy.
EM lisa.graziani@unifi.it; marco.gori@unisi.it; mela@diism.unisi.it
OI Graziani, Lisa/0000-0002-7384-9633
CR Aksan E., 2020, ADV NEUR IN
   [Anonymous], 2015, P WORKSHOP SKETCH BA
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   Ballester P, 2016, AAAI CONF ARTIF INTE, P1124
   Baran I, 2010, COMPUT GRAPH FORUM, V29, P655, DOI 10.1111/j.1467-8659.2009.01635.x
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao N, 2019, AAAI CONF ARTIF INTE, P2564
   Chen Y., 2017, ARXIV PREPRINT ARXIV
   Creswell Antonia, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P798, DOI 10.1007/978-3-319-46604-0_55
   Dantanarayana L, 2016, CAAI T INTELL TECHNO, V1, P272, DOI 10.1016/j.trit.2016.10.003
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Douglas David H, 1973, CARTOGRAPHICA INT J, DOI [DOI 10.1002/9780470669488.CH2, 10.3138/FM57-6770-U75U-7727, DOI 10.3138/FM57-6770-U75U-7727]
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Forbus KD, 2018, AAAI CONF ARTIF INTE, P7665
   Graves A., 2013, ARXIV PREPRINT ARXIV
   Graziani L, 2018, LECT NOTES ARTIF INT, V11298, P320, DOI 10.1007/978-3-030-03840-3_24
   Ha David, 2017, ARXIV170403477
   Liu F, 2019, PROC CVPR IEEE, P5823, DOI 10.1109/CVPR.2019.00598
   Maggini M, 2020, IEEE T NEUR NET LEAR, V31, P4475, DOI 10.1109/TNNLS.2019.2955597
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Ribeiro Leo Sampaio Ferraz, 2020, P IEEECVF C COMPUTER, P14153
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sarvadevabhatla RK, 2020, IEEE T PATTERN ANAL, V42, P221, DOI 10.1109/TPAMI.2018.2877996
   Sasaki K, 2019, IEEE T COGN DEV SYST, V11, P119, DOI 10.1109/TCDS.2018.2868160
   Song JF, 2018, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2018.00090
   Sun ZB, 2012, LECT NOTES COMPUT SC, V7572, P626, DOI 10.1007/978-3-642-33718-5_45
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tang H, 2019, IEEE INT CONF AUTOMA, P192
   Todorovic D., 2008, SCHOLARPEDIA, V3, P5345
   Vaswani A, 2017, ADV NEUR IN, V30
   Wiseman Sam, 2016, P 2016 C EMPIRICAL M, P1296, DOI [DOI 10.18653/V1/D16-1137, 10.18653/v1/d16]
   Xu P., 2019, TNNLS
   Xu P., 2020, ARXIV PREPRINT ARXIV
   Zhang, 2019, VEGETAT HIST ARCHAEO, P1
NR 38
TC 0
Z9 0
U1 0
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD DEC
PY 2021
VL 144
BP 627
EP 638
DI 10.1016/j.neunet.2021.09.020
EA OCT 2021
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA WH9IW
UT WOS:000707983400013
PM 34653720
DA 2023-11-10
ER

PT J
AU Ihasz, PL
   Kovacs, M
   Piumarta, I
   Kryssanov, VV
AF Ihasz, Peter Lajos
   Kovacs, Mate
   Piumarta, Ian
   Kryssanov, Victor V.
TI A Supplementary Feature Set for Sentiment Analysis in Japanese Dialogues
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Affect-awareness; sentiment recognition; dialogue acts; gaming data;
   Japanese language
ID EMOTIONS
AB Recently, real-time affect-awareness has been applied in several commercial systems, such as dialogue systems and computer games. Real-time recognition of affective states, however, requires the application of costly feature extraction methods and/or labor-intensive annotation of large datasets, especially in the case of Asian languages where large annotated datasets are seldom available. To improve recognition accuracy, we propose the use of cognitive context in the form of "emotion-sensitive" intentions. Intentions are often represented through dialogue acts and, as an emotion-sensitive model of dialogue acts, a tagset of interpersonal-relations-directing interpersonal acts (the IA model) is proposed. The model's adequacy is assessed using a sentiment classification task in comparison with two well-known dialogue act models, the SWBD-DAMSL and the DIT++. For the assessment, five Japanese in-game dialogues were annotated with labels of sentiments and the tags of all three dialogue act models which were used to enhance a baseline sentiment classifier system. The adequacy of the IA tagset is demonstrated by a 9% improvement to the baseline sentiment classifier's recognition accuracy, outperforming the other two models by more than 5%.
C1 [Ihasz, Peter Lajos; Kovacs, Mate; Piumarta, Ian; Kryssanov, Victor V.] Ritsumeikan Univ, 1 Chome 1-1 Nojihigashi, Kusatsu, Shiga 5258577, Japan.
C3 Ritsumeikan University
RP Ihasz, PL (通讯作者)，Ritsumeikan Univ, 1 Chome 1-1 Nojihigashi, Kusatsu, Shiga 5258577, Japan.
EM gr0238re@ed.ritsumei.ac.jp; gr0278ir@ed.ritsumei.ac.jp;
   piumarta@cs.ritsumei.ac.jp; kvvictor@is.ritsumei.ac.jp
OI Kovacs, Mate/0000-0001-5999-8061
CR [Anonymous], 2008, 5 AUSTR C INT ENT IE
   [Anonymous], 2014, P 2014 C EMP METH NA
   [Anonymous], 2005, P 1 AAAI C ART INT I
   [Anonymous], IMAGE PROCESSING COM
   [Anonymous], 2005, INTERSPEECH 2005
   [Anonymous], 1987, POLITENESS SOME UNIV
   [Anonymous], P 14 ANN C INT SPEEC
   [Anonymous], 1997, 9702 U COL I COGN SC
   [Anonymous], 2017, DIALOGUE ACT ANNOTAT, DOI [DOI 10.1007/978-3-319-42816-1, 10.1007/978-3-319-42816-1]
   [Anonymous], P INT C SIT INT INTE
   [Anonymous], 2002, INTERSPEECH
   [Anonymous], 2009, P ACII, DOI DOI 10.1109/ACII.2009.5349350
   [Anonymous], 2012, INFORM SYSTEMS TECHN
   Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1
   Bunt H., 2009, AAMAS 2009 WORKSHOP, P13
   Bunt H, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P430
   Bunt H, 2011, COMPUT SPEECH LANG, V25, P222, DOI 10.1016/j.csl.2010.04.006
   Chung J., 2014, CORR
   English, 2016, FACIAL EMOTION RECOG
   Fayek H. M., 2015, P C SIGNAL PROCESSIN, P1
   Frijda N. H., 1987, COGNITION EMOTION, V1, P115, DOI [DOI 10.1080/02699938708408043, https://doi.org/10.1080/02699938708408043]
   Hyunjin Yoon, 2013, 2013 International Conference on ICT Convergence (ICTC), P783, DOI 10.1109/ICTC.2013.6675478
   Ihasz PL, 2015, 2015 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE COMPUTING), P64, DOI 10.1109/Culture.and.Computing.2015.43
   Kingma D. P., 2014, C TRACK P
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   MATSUMOTO Y, 1988, J PRAGMATICS, V12, P403, DOI 10.1016/0378-2166(88)90003-3
   Opitz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.28.739
   Popescu-Belis A, 2008, LANG RESOUR EVAL, V42, P99, DOI 10.1007/s10579-008-9063-y
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Tian LM, 2015, INT CONF AFFECT, P698, DOI 10.1109/ACII.2015.7344645
   Vogt T, 2008, LECT NOTES ARTIF INT, V5078, P188, DOI 10.1007/978-3-540-69369-7_21
NR 32
TC 2
Z9 2
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG
PY 2019
VL 18
IS 4
AR 39
DI 10.1145/3310283
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JL3KV
UT WOS:000495430700006
DA 2023-11-10
ER

PT J
AU Gao, W
   Ni, MY
   Deng, HT
   Zhu, X
   Zeng, P
   Hu, X
AF Gao, Wang
   Ni, Mingyuan
   Deng, Hongtao
   Zhu, Xun
   Zeng, Peng
   Hu, Xi
TI Few-shot fake news detection via prompt-based tuning
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Fake news detection; few-shot; prompt-based tuning; pre-trained language
   model
AB As people increasingly use social media to read news, fake news has become a major problem for the public and government. One of the main challenges in fake news detection is how to identify them in the early stage of propagation. Another challenge is that detection model training requires large amounts of labeled data, which are often unavailable or expensive to acquire. To address these challenges, we propose a novel Fake News Detection model based on Prompt Tuning (FNDPT). FNDPT first designs a prompt-based template for early fake news detection. This mechanism incorporates contextual information into textual content and extracts relevant knowledge from pre-trained language models. Furthermore, our model utilizes prompt-based tuning to enhance the performance in a few-shot setting. Experimental results on two real-world datasets verify the effectiveness of FNDPT.
C1 [Gao, Wang; Ni, Mingyuan; Deng, Hongtao; Zhu, Xun; Zeng, Peng; Hu, Xi] Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
   Jianghan Univ, Engn Res Ctr Intelligent Decis & Informat, Wuhan, Peoples R China.
C3 Jianghan University; Jianghan University
RP Gao, W (通讯作者)，Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
EM gaow@jhun.edu.cn
RI GAO, WANG/GWU-5411-2022; Zeng, Peng/IQW-9449-2023
OI GAO, WANG/0000-0001-9671-489X; 
FU Industry-University-Research Project of Wuhan Education Bureau
   [CXY202208]; Special Research Fund for Discipline Characteristics of
   Jianghan University [2022XKZK10]
FX This work was supported in part by Industry-University-Research Project
   of Wuhan Education Bureau (No. CXY202208) and Special Research Fund for
   Discipline Characteristics of Jianghan University (NO. 2022XKZK10).
CR Boididou C., 2015, MEDIAEVAL, V3, P7, DOI DOI 10.1145/1235
   Bovet A, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07761-2
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2778, DOI 10.1145/3485447.3511998
   Chen Y., 2022, ADAPROMPT ADAPTIVE M
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gao W, 2020, NEURAL NETW WORLD, V30, P145, DOI 10.14311/NNW.2020.30.011
   Gao W, 2023, WORLD WIDE WEB, V26, P55, DOI 10.1007/s11280-022-01034-1
   Gao W, 2021, LECT NOTES COMPUT SC, V13080, P370, DOI 10.1007/978-3-030-90888-1_28
   Gao W, 2020, IEEE MULTIMEDIA, V27, P28, DOI 10.1109/MMUL.2020.3012675
   Gao W, 2019, KNOWL INF SYST, V61, P1123, DOI 10.1007/s10115-018-1314-7
   Gong J., 2021, PROMPT BASED ZERO SH
   Gu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8410
   Han X., 2022, OPEN, V3, P182, DOI DOI 10.1016/J.AIOPEN.2022.11.003
   Jiang GY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103029
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Karnyoto A, 2022, COMPUT SCI INF SYST, V19, P639, DOI 10.2298/CSIS210501053K
   Liu C, 2019, LECT NOTES ARTIF INT, V11776, P172, DOI 10.1007/978-3-030-29563-9_17
   Liu JS, 2021, J WEB SEMANT, V70, DOI 10.1016/j.websem.2021.100646
   Liu Pengfei, 2021, PRETRAIN PROMPT PRED
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726
   Popat K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P22
   Przybyla P, 2020, AAAI CONF ARTIF INTE, V34, P490
   Raza S, 2022, INT J DATA SCI ANAL, DOI 10.1007/s41060-022-00359-4
   Schucher N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P148
   Seoh R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6311
   Sheng Q, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P1640, DOI 10.1145/3459637.3482440
   Sun AX, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1145, DOI 10.1145/2348283.2348511
   Wanda P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102465
   Wang CY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2792
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2020, AAAI CONF ARTIF INTE, V34, P516
   Yanagi Y, 2020, IEEE INT CONF INTELL, P85, DOI [10.1109/ines49302.2020.9147195, 10.1109/INES49302.2020.9147195]
   Zellers Rowan, 2019, NEURIPS
   Zhou XY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P836, DOI 10.1145/3289600.3291382
   Zhu Q, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1124
NR 39
TC 0
Z9 0
U1 6
U2 6
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2023
VL 44
IS 6
BP 9933
EP 9942
DI 10.3233/JIFS-221647
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I6WU1
UT WOS:001004176300070
DA 2023-11-10
ER

PT S
AU Lee, J
AF Lee, Junsoo
BE Gavrilova, M
   Gervasi, O
   Kumar, V
   Tan, CJK
   Taniar, D
   Lagana, A
   Mun, Y
   Choo, H
TI Simulation of Internet Transport Protocols for high bandwidth-delay
   networks
SO COMPUTATIONAL SCIENCE AND ITS APPLICATIONS - ICCSA 2006, PT 5
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT International Conference on Computational Science and Its Applications
   (ICCSA 2006)
CY MAY 08-AUG 11, 2006
CL Glasgow, SCOTLAND
SP IEE, Univ Perugia, Univ Calgary, Univ Minnesota, Queens Univ, Belfast, ERCIM, OptimaNumerics, INTEL, AMD
AB This paper addresses the simulation of communication networks with high bandwidth-delay products. We use hybrid models to overcome the computational/memory barriers that packet-level simulators encounter due to the large number of packets present in the network at every instant of time. We describe a set of software tools that constructs these hybrid models for general networks. The networks to be simulated and their parameters are specified in a network description script language (NDSL) and an NDSL translator automatically generates the corresponding a model in the hybrid systems specification language modelica. We also extend our previous hybrid modeling work to several variants of TCP that appeared recently to improve TCP's poor performance in high bandwidth-delay product networks. To demonstrate the usefulness of software tools developed and the new TCP hybrid models, we discuss simulation results from Internet-2 Abilene backbone.
C1 Sookmyung Womens Univ, Dept Comp Sci, Seoul 140742, South Korea.
C3 Sookmyung Women's University
RP Lee, J (通讯作者)，Sookmyung Womens Univ, Dept Comp Sci, Seoul 140742, South Korea.
EM jslee@sm.ac.kr
CR [Anonymous], KLUWER INT SERIES EN
   [Anonymous], 2003, RFC3649 HIGHSPEED TC
   BOHACEK S, 2003, ACM SIGMETRICS
   BOHACEK S, 2004, FAIRNESS TCP IP HIGH
   Floyd S., 2004, 3742 RFC
   JIN C, 2004, P IEEE INFOCOM
   Kelly T, 2003, ACM SIGCOMM COMP COM, V33, P83, DOI 10.1145/956981.956989
   Kumaran K, 1998, IEEE INFOCOM SER, P1449, DOI 10.1109/INFCOM.1998.662963
   *VINT PROJ, 2000, COLL RES UC BERK LBL
   YAN A, 1999, IEEE T INFORM THEORY
NR 10
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-34079-3
J9 LECT NOTES COMPUT SC
PY 2006
VL 3984
BP 175
EP 184
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BEL03
UT WOS:000237650900019
DA 2023-11-10
ER

PT S
AU Huang, XJ
   Peng, FC
   An, AJ
   Schuurmans, D
   Cercone, N
AF Huang, XJ
   Peng, FC
   An, AJ
   Schuurmans, D
   Cercone, N
BE Xiang, Y
   ChaibDraa, B
TI Session boundary detection for association rule learning using
   <i>n</i>-gram language models
SO ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 16th Conference of the
   Canadian-Society-for-Computational-Studies-of-Intelligence
CY JUN 11-13, 2003
CL HALIFAX, CANADA
SP Canadian Soc Computat Studies Intelligence, Natl Res Council Canada
AB We present a statistical method using n-gram language models to identify session boundaries in a large collection of Livelink log data. The identified sessions are then used for association rule learning. Unlike the traditional ad hoe timeout method, which uses fixed time thresholds for session identification, our method uses an information theoretic approach that provides a natural technique for performing dynamic session identification. The effectiveness of our approach is evaluated with respect to 4 different interestingness measures. We find that we obtain a, significant improvement in each interestingness measure, ranging from a 26.6% to 39% improvement on average over the best results obtained With standard timeout methods.
C1 Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   Univ York, Dept Comp Sci, Toronto, ON M3J 1P3, Canada.
   Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada.
C3 University of Waterloo; York University - Canada; Dalhousie University
RP Huang, XJ (通讯作者)，Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
EM jhuang@cs.uwaterloo.ca; f3peng@cs.uwaterloo.ca; aan@cs.yorku.ca;
   dale@cs.uwaterloo.ca; nick@cs.dal.ca
CR Agrawal R, 1994, CITESEER, P487
   AN A, 2001, COMPUTATIONAL INGELL, V17
   [Anonymous], 2000, P WORKSH POSTPR MACH
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   BRUHA I, 1996, MACHINE LEARNING STA
   CATLEDGE L, 1995, P 3 INT WORLD WID WE
   Chen Stanley, 1998, EMPIRICAL STUDY SMOO
   HE D, 2000, P 22 ANN C INF RETR
   HEIMSTRA D, 2001, THESIS U TWENTE
   HUANG X, 2002, P IEEE INT C DAT MIN
   LAFFERTY J, 2001, P 24 ACM SIGIR C RES
   PENG F, 2003, P 2K EUR C INF RETR
   Ponte Jay M, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
NR 13
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-40300-0
J9 LECT NOTES ARTIF INT
PY 2003
VL 2671
BP 237
EP 251
PG 15
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BX29V
UT WOS:000184853500017
DA 2023-11-10
ER

PT J
AU Buchheit, P
AF Buchheit, P
TI A neuro-propositional model of language processing
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
ID SENTENCES
AB An implemented model of language processing has been developed that views the propositional components of a sentence as neural units. The propositional sentence units are linked through symbolic, reified representations of subordinate sentence parts. Large numbers of these highly standardized propositional units are encoded in a manner that interconnects propositional data through the declarative knowledge base structures, thus minimizing the importance of the procedural component and the need for backward chaining and inference generation The introduction of new sentence information triggers a connectionist-like flurry of activity in which constantly changing propositional weights and reification strengths effect changes in the belief states encoded within the knowledge base. (C) 1999 John Wiley & Sons, Inc.
C1 Harold Washington Coll, CIS Dept, Chicago, IL 60601 USA.
RP Buchheit, P (通讯作者)，Harold Washington Coll, CIS Dept, Chicago, IL 60601 USA.
CR [Anonymous], 1990, REPRESENTATIONS COMM
   [Anonymous], 1995, SPEAKING MINDS INTER
   BUCHHEIT P, 1992, 4 INT C TOOLS ART IN, P293
   BUCHHEIT P, 1993, 21 ACM COMP SCI C IN, P410
   BUCHHEIT P, 1996, INT J INTELL SYST, P11
   BUCHHEIT P, THESIS U ILLINOIS CH
   Churchland PS., 1992, COMPUTATIONAL BRAIN, DOI 10.7551/mitpress/2010.001.0001
   GOETZ ET, 1981, J VERB LEARN VERB BE, V20, P369, DOI 10.1016/S0022-5371(81)90506-5
   Ng A. M.-H., 1993, Seventh Annual Midwest Computer Conference. Proceedings Manual, P135
   QUILLIAN MR, 1968, SEMANTIC INFORMATION
   RATCLIFF R, 1978, J VERB LEARN VERB BE, V17, P403, DOI 10.1016/S0022-5371(78)90238-4
   Smith G., 1991, COMPUTERS HUMAN LANG
   Van Dijk TA., 1983, STRATEGIES DISCOURSE
   WILKS Y, 1975, COMMUN ACM, V18, P264, DOI 10.1145/360762.360770
   WILKS Y, 1983, PARSING NATURAL LANG
NR 15
TC 2
Z9 2
U1 0
U2 0
PU JOHN WILEY & SONS INC
PI NEW YORK
PA 605 THIRD AVE, NEW YORK, NY 10158-0012 USA
SN 0884-8173
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD JUN
PY 1999
VL 14
IS 6
BP 585
EP 601
DI 10.1002/(SICI)1098-111X(199906)14:6<585::AID-INT3>3.0.CO;2-5
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 198KC
UT WOS:000080421800003
DA 2023-11-10
ER

PT J
AU Singh, I
   Blukis, V
   Mousavian, A
   Goyal, A
   Xu, DF
   Tremblay, J
   Fox, D
   Thomason, J
   Garg, A
AF Singh, Ishika
   Blukis, Valts
   Mousavian, Arsalan
   Goyal, Ankit
   Xu, Danfei
   Tremblay, Jonathan
   Fox, Dieter
   Thomason, Jesse
   Garg, Animesh
TI PROGPROMPT: program generation for situated robot task planning using
   large language models
SO AUTONOMOUS ROBOTS
LA English
DT Article; Early Access
DE Robot task planning; LLM code generation; Planning domain
   generalization; Symbolic planning
AB Task planning can require defining myriad domain knowledge about the world in which a robot needs to act. To ameliorate that effort, large language models (LLMs) can be used to score potential next actions during task planning, and even generate action sequences directly, given an instruction in natural language with no additional domain information. However, such methods either require enumerating all possible next steps for scoring, or generate free-form text that may contain actions not possible on a given robot in its current context. We present a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example programs that can be executed. We make concrete recommendations about prompt structure and generation constraints through ablation experiments, demonstrate state of the art success rates in VirtualHome household tasks, and deploy our method on a physical robot arm for tabletop tasks. Website and code at progprompt.github.io
C1 [Singh, Ishika; Thomason, Jesse] Univ Southern Calif, Comp Sci, Los Angeles, CA 90089 USA.
   [Blukis, Valts; Mousavian, Arsalan; Goyal, Ankit; Xu, Danfei; Tremblay, Jonathan; Fox, Dieter; Garg, Animesh] NVIDIA, Seattle Robot Lab, Seattle, WA 98105 USA.
   [Fox, Dieter] Univ Washington, Comp Sci & Engn, Seattle, WA 98195 USA.
   [Garg, Animesh] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30308 USA.
C3 University of Southern California; University of Washington; University
   of Washington Seattle; University System of Georgia; Georgia Institute
   of Technology
RP Singh, I (通讯作者)，Univ Southern Calif, Comp Sci, Los Angeles, CA 90089 USA.
EM ishikasi@usc.edu; vblukis@nvidia.com; amousavian@nvidia.com;
   angoyal@nvidia.com; danfeix@nvidia.com; jtremblay@nvidia.com;
   dieterf@nvidia.com; jessetho@usc.edu; animeshg@nvidia.com
FU SCELC, Statewide California Electronic Library Consortium; NVIDIA
FX Open access funding provided by SCELC, Statewide California Electronic
   Library Consortium. This project was conducted at and funded by NVIDIA.
CR Ahn M., 2022, ARXIV
   Akakzia A., 2021, INT C LEARNING REPRE
   Baier JA, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1808
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Bryce D, 2007, AI MAG, V28, P47
   Cao Y, 2023, Arxiv, DOI arXiv:2302.12927
   Capitanelli A, 2023, Arxiv, DOI arXiv:2303.00438
   Chen M., 2021, ARXIV
   Danielczuk M, 2021, IEEE INT CONF ROBOT, P6010, DOI 10.1109/ICRA48506.2021.9561516
   Eysenbach Ben, 2019, ADV NEURAL INFORM PR, V32
   FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5
   Garrett Caelan Reed, 2020, P INT C AUTOMATED PL, V30, P440
   Gu Xiuye, 2022, INT C LEARN REPR
   Gupta T., 2022, ARXIV
   Helmert M, 2006, J ARTIF INTELL RES, V26, P191, DOI 10.1613/jair.1705
   Hoffmann J, 2001, AI MAG, V22, P57
   Holtzman Ari, 2020, ICLR
   Huang WL, 2023, Arxiv, DOI arXiv:2303.00855
   Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]
   Huang WL, 2022, Arxiv, DOI arXiv:2201.07207
   Jansen P., 2020, FINDINGS ASS COMPUTA, P4412
   Jiang Y., 2018, ARXIV
   Jiang YD, 2019, ADV NEUR IN, V32
   Kurutach T, 2018, ADV NEUR IN, V31
   Li S., 2022, ARXIV
   Liang J., 2023, CODE POLICIES LANGUA
   Liu P., 2021, ARXIV
   Luong T., 2015, P C EMPIRICAL METHOD, P1412, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mai JJ, 2023, Arxiv, DOI arXiv:2304.09349
   Mirchandani S., 2021, ADV NEURAL INFORM PR, V34, P29529
   Nair S., 2020, INT C LEARNING REPRE
   OpenAI, 2023, ARXIV
   Patel R., 2022, INT C LEARNING REPRE
   Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886
   Shah D., 2022, INT C LEARNING REPRE
   Sharma P, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1713
   Shridhar M., 2020, IEEE C COMPUTER VISI
   Silver T., 2022, MULTIDISCIPLINARY C
   Skreta M, 2023, Arxiv, DOI arXiv:2303.14100
   Srinivas A., 2018, INT C MACHINE LEARNI, V80, P4732
   Sundermeyer M, 2021, IEEE INT CONF ROBOT, P13438, DOI 10.1109/ICRA48506.2021.9561877
   Vemprala S., 2023, CHATGPT ROBOTICS DES
   Wei J. -J., 2022, ARXIV
   Wiseman S., 2017, P 2017 C EMPIRICAL M
   Xie Y., 2023, TRANSLATING NATURAL
   Xie YQ, 2023, Arxiv, DOI arXiv:2302.05128
   Xu D, 2019, ADV NEUR IN, V32
   Xu DF, 2018, IEEE INT CONF ROBOT, P3795
   Zeng A., 2022, ARXIV
   Zhu Y., 2020, ARXIV
NR 50
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0929-5593
EI 1573-7527
J9 AUTON ROBOT
JI Auton. Robot.
PD 2023 AUG 28
PY 2023
DI 10.1007/s10514-023-10135-3
EA AUG 2023
PG 14
WC Computer Science, Artificial Intelligence; Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Robotics
GA R4AF1
UT WOS:001063783800001
OA hybrid
DA 2023-11-10
ER

PT J
AU Ksieniewicz, P
   Zyblewski, P
   Borek-Marciniec, W
   Kozik, R
   Choras, M
   Wozniak, M
AF Ksieniewicz, Pawel
   Zyblewski, Pawel
   Borek-Marciniec, Weronika
   Kozik, Rafal
   Choras, Michal
   Wozniak, Michal
TI <i>Alphabet</i><i> Flatting</i> as a variant of n-gram feature
   extraction method in ensemble classification of fake news
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Natural language processing; Pattern recognition; Fake news; Classifier
   ensemble; n-gram
AB The detection of disinformation becomes a significant challenge in the modern world. Most of our communica-tion media and most of the sources of information about reality are located on the distributed network services, where the published content is usually not a subject to any initial verification. One of the few tools that seem to be able to process such large volumes of data efficiently are pattern recognition methods employing extraction of features obtained through the Natural Language Processing models and procedures. The following paper is proposing an Alphabet Flatting - a modification of the preprocessing method for the feature extraction from large language corpora - allowing the construction of diverse classifier ensembles integrated by the support accumulation, the generalization power of which may compete with quality of the STATE-of-ThE-ART models in environments with strict time constraints. The proposed method has been thoroughly evaluated with the set of computer experiments, the results of which allow us to conclude its potential usefulness in the solutions of the automatic systems for preventing the spread of fake news.
C1 [Ksieniewicz, Pawel; Zyblewski, Pawel; Borek-Marciniec, Weronika; Wozniak, Michal] Wroclaw Univ Sci & Technol, Fac Informat & Commun Technol, Dept Syst & Comp Networks, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
   [Kozik, Rafal; Choras, Michal] Bydgoszcz Univ Sci & Technol, Inst Telecommun & Comp Sci, Bydgoszcz, Poland.
C3 Wroclaw University of Science & Technology; Bydgoszcz University of
   Science & Technology
RP Ksieniewicz, P (通讯作者)，Wroclaw Univ Sci & Technol, Fac Informat & Commun Technol, Dept Syst & Comp Networks, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM pawel.ksieniewicz@pwr.edu.pl; pawel.zyblewski@pwr.edu.pl;
   weronika.borek@pwr.edu.pl; rkozik@pbs.edu.pl; chorasm@pbs.edu.pl;
   michal.wozniak@pwr.edu.pl
RI Wozniak, Michal/A-4806-2008
OI Wozniak, Michal/0000-0003-0146-4205; Zyblewski,
   Pawel/0000-0002-4224-6709; Borek-Marciniec, Weronika/0000-0003-2426-9541
FU Department of Systems and Computer Networks, Faculty of Information and
   Communication Technology, Wroclaw University of Science and Technology;
   Institute of Telecommunications and Computer Science, Bydgoszcz
   University of Science and Technology; National Center for Research and
   Development within INFOSTRATEG program [INFOSTRATEG-I/0019/2021-00]
FX This publication is cofinanced by the statutory funds of the Department
   of Systems and Computer Networks, Faculty of Information and
   Communication Technology, Wroclaw University of Science and Technology,
   the statutory funds of the Institute of Telecommunications and Computer
   Science, Bydgoszcz University of Science and Technology and the National
   Center for Research and Development within INFOSTRATEG program, number
   of application for funding: INFOSTRATEG-I/0019/2021-00.
CR Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   [Anonymous], 2019, ENISA STRENGTHENING
   Atodiresei CS, 2018, PROCEDIA COMPUT SCI, V126, P451, DOI 10.1016/j.procs.2018.07.279
   Barrón-Cedeño A, 2019, INFORM PROCESS MANAG, V56, P1849, DOI 10.1016/j.ipm.2019.03.005
   Bharadwaj P., 2019, INT J NAT LANG COMPU, V8
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Brodersen Kay H., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3121, DOI 10.1109/ICPR.2010.764
   Castillo C., 2011, P 20 INT C WORLD WID, P675
   Choras M, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107050
   Dentith M.R.X, 2016, PROBLEM FAKE NEWS
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, DOI 10.48550/ARXIV.1802.05365]
   Gereme F, 2021, INFORMATION, V12, DOI 10.3390/info12010020
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Giachanou A, 2020, LECT NOTES ARTIF INT, V12284, P30, DOI 10.1007/978-3-030-58323-1_3
   Giachanou A, 2020, LECT NOTES COMPUT SC, V12089, P181, DOI 10.1007/978-3-030-51310-8_17
   Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P877, DOI 10.1145/3331184.3331285
   Gomes HM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054925
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gruppi M, 2021, Arxiv, DOI [arXiv:2102.04567, 10.48550/ARXIV.2102.04567, DOI 10.48550/ARXIV.2102.04567]
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hassan N., 2020, INT J INTELL ENG SYS, V13, P291, DOI DOI 10.22266/IJIES2020.0229.27
   Hesse G, 2015, INT C PAR DISTRIB SY, P797, DOI 10.1109/ICPADS.2015.106
   Horne B. D., 2017, P INT AAAI C WEB SOC, P1
   Joulin A, 2016, Arxiv, DOI [arXiv:1612.03651, DOI 10.48550/ARXIV.1612.03651]
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kaur S, 2020, SOFT COMPUT, V24, P9049, DOI 10.1007/s00500-019-04436-y
   Kong SH, 2020, IEEE 10TH SYMPOSIUM ON COMPUTER APPLICATIONS AND INDUSTRIAL ELECTRONICS (ISCAIE 2020), P102, DOI [10.1109/iscaie47305.2020.9108841, 10.1109/ISCAIE47305.2020.9108841]
   Ksieniewicz P, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207498
   Ksieniewicz P, 2019, LECT NOTES COMPUT SC, V11872, P332, DOI 10.1007/978-3-030-33617-2_34
   Ksieniewicz P, 2019, NEUROCOMPUTING, V353, P74, DOI 10.1016/j.neucom.2018.05.130
   Kula Sebastian, 2021, 13th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2020). Advances in Intelligent Systems and Computing (AISC 1267), P239, DOI 10.1007/978-3-030-57805-3_23
   Kumar S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5047
   Kurup L., 2019, P 2019 3 IEEE INT C, DOI 10.1109/ICECCT. 2019.8869504
   Liu C, 2019, J BIOMED INFORM, V100, DOI 10.1016/j.jbi.2019.103318
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Roy A, 2018, Arxiv, DOI arXiv:1811.04670
   Santafe G, 2015, ARTIF INTELL REV, V44, P467, DOI 10.1007/s10462-015-9433-y
   Saquete E, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112943
   Tai KS, 2015, Arxiv, DOI arXiv:1503.00075
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Silva RM, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113199
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Thelwall M., 2017, CYBEREMOTIONS, P119, DOI [10.1007/978-3-319-43639-5_7, DOI 10.1007/978-3-319-43639-5_7]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wynne HE, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P669, DOI 10.1145/3366030.3366116
   Yang KC, 2019, Arxiv, DOI arXiv:1907.07347
   Zubiaga A., 2016, PHEME DATASET RUMOUR
NR 50
TC 1
Z9 1
U1 3
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD APR
PY 2023
VL 120
AR 105882
DI 10.1016/j.engappai.2023.105882
PG 11
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Engineering
GA 8P1HY
UT WOS:000926281900001
DA 2023-11-10
ER

PT S
AU Harbeck, S
   Ohler, U
   Nöth, E
   Niemann, H
AF Harbeck, S
   Ohler, U
   Nöth, E
   Niemann, H
BE Matousek, V
   Mautner, P
   Ocelikova, J
   Sojka, P
TI Information theoretic based segments for language identification
SO TEXT, SPEECH AND DIALOGUE
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Text, Speech and Dialogue (TSD 99)
CY SEP 13-17, 1999
CL PLZEN, CZECH REPUBLIC
SP Medav GmbH, SpeechWorks, Univ Bohemia, Fac Appl Sci, Masaryk Univ
AB In our paper we present two new approaches for language identification. Both of them are based on the use of so-called multigrams, an information theoretic based observation representation. In the first approach we use multigram models for phonotactic modeling of phoneme or codebook sequences. The multigram model can be used to segment the new observation into larger units (e.g. something like words) and calculates a probability for the best segmentation. In the second approach we build a fenon recognizer using the segments of the best segmentation of the training material as "words" inside the recognition vocabulary. On the OGI test corpus and on the NLST'95 evaluation corpus we got significant improvements with this second approach in comparison to the unsupervised codebook approach when discriminating between English and German utterances.
C1 Univ Erlangen Nurnberg, Chair Pattern Recognit Comp Sci 5, D-91058 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Harbeck, S (通讯作者)，Univ Erlangen Nurnberg, Chair Pattern Recognit Comp Sci 5, Martensstr 3, D-91058 Erlangen, Germany.
EM snharbec@informatik.uni-erlangen.de; niemann@informatik.uni-erlangen.de
RI Noth, Elmar/C-2355-2013
OI Noth, Elmar/0000-0002-3396-555X
CR Deng L, 1993, IEEE T SPEECH AUDI P, V1, P471, DOI 10.1109/89.242494
   Harbeck S., 1998, P WORKSH TEXT SPEECH, P375
   HARBECK S, 1999, P EUR C SPEECH COMM
   HARBECK S, 1997, P 2 SQEL WORKSH MULT, P9
   OHLER U, 1999, P EUR C SPEECH COMM
   RISSANEN J, 1989, STOCHASTIC COMPLEXIT
   Schukat-Talamazzini EG, 1997, P EUR C SPEECH COMM, P2731
   Warnke V, 1999, INT CONF ACOUST SPEE, P525, DOI 10.1109/ICASSP.1999.758178
   Zissman MA, 1996, IEEE T SPEECH AUDI P, V4, P31, DOI 10.1109/TSA.1996.481450
NR 9
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-66494-7
J9 LECT NOTES ARTIF INT
PY 1999
VL 1692
BP 187
EP 192
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BQ71V
UT WOS:000089259200034
DA 2023-11-10
ER

PT S
AU Nenadic, G
   Spasic, I
AF Nenadic, G
   Spasic, I
BE Christodoulakis, DN
TI Recognition and acquisition of compound names from corpora
SO NATURAL LANGUAGE PROCESSING-NLP 2000, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 2nd International Conference on Natural Language Processing (NLP 2000)
CY JUN 02-04, 2000
CL PATRAS, GREECE
SP ALTEC Grp, Comp Technol Inst, CompBank Networking SA, Hellen Republ, Gen Secretariat Res & Technol, Hellen Republ, Minist Educ & Religious Affairs, Infoquest SA, INTRASOFT SA, ION Publ Co, Microsoft Hellas, Natl & Kapodistrian Univ Athens, OTEnet SA, Patakis Publicat, Univ Aegean, Univ Patras
AB In this paper we will present an approach to acquisition of some classes of compound words from large corpora, as well as a method for semi-automatic generation of appropriate linguistic models, that can be further used for compound word recognition and for completion of compound word dictionaries. The approach is intended for a highly inflective language such as Serbo-Croatian. Generated linguistic models axe represented by local grammars.
C1 Univ Belgrade, Fac Math, YU-11001 Belgrade, Yugoslavia.
   Univ Belgrade, Fac Econ, YU-11001 Belgrade, Yugoslavia.
C3 University of Belgrade; University of Belgrade
RP Nenadic, G (通讯作者)，Univ Belgrade, Fac Math, YU-11001 Belgrade, Yugoslavia.
EM goran@matf.bg.ac.yu; irenas@one.ekof.bg.ac.yu
RI Spasic, Irena/D-2259-2010
CR [Anonymous], P 16 C COMP LING
   BURNARD L, 1995, 5 TEI U
   COATESSTEPHANDS S, 1992, THESIS CITY U LONDON
   GROSS M, 1998, MONOGRAPH 125 ANNIVE, P231
   GROSS M, 1989, LECT NOTES COMPUTER
   MAIERMEYER P, 1996, ACT PREM JOURN INTEX
   NENADIC G, 1999, LECT NOTES ARTIFICIA, V1692
   NENADIC G, 1998, P 1 WORKSH TEXT SPEE
   NENADIC G, 1998, 23 BULAG U FRANCH CO
   SILBERZTEIN M, 1993, DICT ELECTRONIQUES A
   SILBERZTEIN M, 1994, P COLING 94 ACL TOKY
   SPASIC I, 1999, P 3 EUR C FORM DESCR
   SPASIC I, 1996, P C TERM STAND SERB
   SPASIC I, 1999, THESIS U BELGRADE
   VITAS D, 1993, THESIS U BELGRADE
   VITAS D, 1996, P COMPLEX 96 BUD HUN
NR 16
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-67605-8
J9 LECT NOTES ARTIF INT
PY 2000
VL 1835
BP 38
EP 48
PG 11
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BS52C
UT WOS:000170202300004
DA 2023-11-10
ER

PT J
AU Demir, S
AF Demir, Seniz
TI Turkish Data-to-Text Generation Using Sequence-to-Sequence Neural
   Networks
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Data-to-text generation; sequence-to-sequence model; Turkish; Wikipedia
ID NATURAL-LANGUAGE GENERATION; OF-THE-ART
AB End-to-end data-driven approaches lead to rapid development of language generation and dialogue systems. Despite the need for large amounts of well-organized data, these approaches jointly learn multiple components of the traditional generation pipeline without requiring costly human intervention. End-to-end approaches also enable the use of loosely aligned parallel datasets in system development by relaxing the degree of semantic correspondences between training data representations and text spans. However, their potential in Turkish language generation has not yet been fully exploited. In this work, we apply sequenceto-sequence (Seq2Seq) neural models to Turkish data-to-text generation where the input data given in the form of a meaning representation is verbalized. We explore encoder-decoder architectures with attention mechanism in unidirectional, bidirectional, and stacked recurrent neural network (RNN) models. Our models generate one-sentence biographies and dining venue descriptions using a crowdsourced dataset where all field value pairs that appear in meaning representations are fully captured in reference sentences. To support this work, we also explore the performances of our models on a more challenging dataset, where the content of a meaning representation is too large to fit into a single sentence, and hence content selection and surface realization need to be learned jointly. This dataset is retrieved by coupling introductory sentences of person-related Turkish Wikipedia articles with their contained infobox tables. Our empirical experiments on both datasets demonstrate that Seq2Seq models are capable of generating coherent and fluent biographies and venue descriptions from field value pairs. We argue that the wealth of knowledge residing in our datasets and the insights obtained fromthis study hold the potential to give rise to the development of new end-to-end generation approaches for Turkish and other morphologically rich languages.
C1 [Demir, Seniz] MEF Univ, Dept Comp Engn, Maslak Ayazaga Caddesi, TR-34396 Istanbul, Turkiye.
C3 MEF Universitesi
RP Demir, S (通讯作者)，MEF Univ, Dept Comp Engn, Maslak Ayazaga Caddesi, TR-34396 Istanbul, Turkiye.
EM demirse@mef.edu.tr
RI Demir, Şeniz/AAB-5451-2021
FU TUBITAK-ARDEB [117E977]
FX This work is supported by TUBITAK-ARDEB under the grant number 117E977.
CR Angeli G., 2010, P 2010 C EMPIRICAL M, P502
   [Anonymous], 2002, P 2 INT C HUMAN LANG
   Ayan Burcu Karagol, 2000, P COLING STUDENT SES
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, P65, DOI DOI 10.3115/1626355.1626389
   Barzilay R., 2005, P C HUM LANG TECHN E, P331, DOI DOI 10.3115/1220575.1220617
   Bateman John A., 1990, P INF SCI I
   Belz Anja, 2005, P 10 EUROPEAN WORKSH, P15
   Birant Cagdas Can, 2016, INT J COMPUTER APPL, V144, P23
   Biswas Russa, 2018, P 1STWORKSHOP DEEP L
   Channarukul S, 2001, INT J UNCERTAIN FUZZ, V9, P649
   Chen D. L., 2008, P 25 INT C MACH LEAR, P128, DOI DOI 10.1145/1390156.1390173
   Chen Shuang, 2018, P E2E NLG CHALL SYST
   Chen ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P183
   Chisholm A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P633
   Cicekli Ilyas, 1998, P JOINT C NEW METHOD, P165
   Colin E., 2016, P 9 INT NAT LANG GEN, P163
   Daza A, 2018, REPRESENTATION LEARNING FOR NLP, P207
   Demir Seniz, 2022, COMPUT SPEECH LANG
   Dogan E, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP)
   Duma Daniel, 2013, P 10 INT C COMPUTATI, P83
   Dusek O, 2020, COMPUT SPEECH LANG, V59, P123, DOI 10.1016/j.csl.2019.06.009
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Ferreira TC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P552
   Fuad TA, 2019, COMPUT SPEECH LANG, V58, P216, DOI 10.1016/j.csl.2019.04.006
   Gao Hanning, 2021, P 29 INT JOINT C ART
   Gardent C., 2017, P 10 INT C NAT LANG
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gehrmann S., 2018, P 11 INT C NATURAL L, P46
   Ghaddar A., 2016, CONLL, P229, DOI DOI 10.18653/V1/K16-1023
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Gong H., 2020, P 28 INT C COMP LING, P1978, DOI DOI 10.18653/V1/2020.COLING-MAIN.179
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Güran A, 2013, TURK J ELECTR ENG CO, V21, P1411, DOI 10.3906/elk-1201-15
   Hakkani Dilek Zeynep, 1996, DESIGN IMPLEMENTATIO
   Harris M, 2008, P 5 INT NAT LANG GEN, P157
   Hewlett D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1535
   Hsu WN, 2016, IEEE W SP LANG TECH, P467, DOI 10.1109/SLT.2016.7846305
   Kawashima T, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P43, DOI 10.1145/3350546.3352499
   Kingma DP, 2015, 3 INT C LEARN REPR I
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Konstas I., 2013, P 2013 C EMPIRICAL M, P1503
   Kutlu M, 2010, COMPUT J, V53, P1315, DOI 10.1093/comjnl/bxp124
   Kutlugun Mehmet Ali, 2018, P 26 SIGNAL PROCESSI, P1
   Kuyu M, 2018, SIG PROCESS COMMUN
   Kuyu Menekse, 2019, SIG PROCESS COMMUN
   Lampouras G, 2018, Arxiv, DOI arXiv:1810.13414
   Lange D., 2010, P 19 ACM INT C INFOR, P1661
   Langkilde-Geary Irene, 2002, P INT C NAT LANG GEN, P17
   Lebret Remi, 2016, P 2016 C EMP METH NA, P1203, DOI [10.18653/v1/D16-1128, DOI 10.18653/V1/D16-1128]
   Li G, 2019, P 3 WORKSH NEUR GEN, P148
   Li J., 2021, P 30 INT JOINT C ART, P4492
   Liang P, 2009, P JOINT C 47 ANN M A, P91, DOI DOI 10.1007/978-3-642-02374-3_6
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Liu TY, 2018, AAAI CONF ARTIF INTE, P4881
   Mahapatra J., 2016, P 9 INT NATURAL LANG, P143
   Mairesse F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1552
   Mairesse F, 2014, COMPUT LINGUIST, V40, P763, DOI [10.1162/coli_a_00199, 10.1162/COLI_a_00199]
   Malouf R, 2017, MORPHOLOGY, V27, P431, DOI 10.1007/s11525-017-9307-x
   Mangrulkar S, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P191
   Manishina E, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3624
   Manishina Elena, 2016, THESIS U AVIGNON FRA
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Mrabet Yassine, 2016, P 2 INT WORKSHOP NAT, P29
   Nokinova J., 2016, P 9 INT NATURAL LANG, P265
   Nuzumlali M.Y., 2014, P C EMPIRICAL METHOD, P702
   O'Donnell M., 2001, Natural Language Engineering, V7, P225
   Oflazer Kemal, 2018, TURKISH NATURAL LANG
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Perez-Beltrachini Laura, 2018, P 2018 C N AM CHAPT, V1, P1516, DOI DOI 10.18653/V1/N18-1137
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.1080/1472586x.2015.1113070.
   Portet F, 2009, ARTIF INTELL, V173, P789, DOI 10.1016/j.artint.2008.12.002
   Prabhavalkar R, 2017, INTERSPEECH, P939, DOI 10.21437/Interspeech.2017-233
   Puduppully R, 2019, AAAI CONF ARTIF INTE, P6908
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Rebuffel Clement, 2020, P ADV INF RETR, P65
   Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502
   Ritter A., 2011, P C EMPIRICAL METHOD, P583
   Sankarasubramaniam Y, 2014, INFORM PROCESS MANAG, V50, P443, DOI 10.1016/j.ipm.2014.02.001
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sha L, 2018, AAAI CONF ARTIF INTE, P5414
   Shimorina A., 2018, PROC 11 INT C NATURA, P360
   Socher R., 2011, P 28 INT C MACHINE L, P129
   Sripada Somayajulu, 2003, P CORPUS LINGUISTICS, P734
   Suadaa LH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1451
   Temizsoy Murat, 1998, P NATURAL LANGUAGE G, P188
   Tran V. K., 2018, P 27 INT C COMPUTATI, P1205
   Trisedya Bayu Distiawan, 2021, IEEE T PATTERN ANAL, P1
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   Tran VK, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P231
   Vardar U.F, 2019, P 27 SIGNAL PROCESSI, P1
   Vaswani A., 2017, P 31 INT C NEUR INF, P6000
   Wang R, 2018, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3203078
   Wen TH, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2019.06.008
   Wen Tsung-Hsien, 2015, P 2015 C EMPIRICAL M, P1711, DOI 10.18653/v1/D15-1199
   Yermakov Ruslan, 2021, INLG, P364
   Yildiz T, 2019, TURK J ELECTR ENG CO, V27, P1052, DOI 10.3906/elk-1806-185
   Yu Seunghak, 2017, P 1 WORKSHOP SUBWORD, P92
   Zhang X, 2014, P 2014 C EMP METH NA, P670, DOI DOI 10.3115/V1/D14-1074
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
   Zhu CG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1261
NR 103
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB
PY 2023
VL 22
IS 2
DI 10.1145/3543826
PG 27
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C7AF6
UT WOS:000963394900006
DA 2023-11-10
ER

PT J
AU Gupta, S
   Tiwari, S
   Ortiz-Rodriguez, F
   Panchal, R
AF Gupta, Shivansh
   Tiwari, Sanju
   Ortiz-Rodriguez, Fernando
   Panchal, Ronak
TI KG4ASTRA: question answering over Indian Missiles Knowledge Graph
SO SOFT COMPUTING
LA English
DT Article
DE Query answering; Knowledge graph; Knowledge extraction; Neo4j; Cypher
AB Natural language, being unstructured, makes the tedious task for building a model to parse it into a query language successfully. An incorrect query for a particular question would lead to an absurd answer. As seen in many semantic parsing approaches, the inaccurate answering of complex questions increases significantly. This leads to many novel effective strategies that can apply to semantic parsing approaches to accurately parse complex natural language questions and generate an appropriate answer over a large knowledge graph. The defense system in a particular country is one of the most crucial components, and the lack of a proper defensive domain interface makes it a significant motivation. Hence, a knowledge graph has been constructed to collect and enquire about all information in one place. In this paper, KG4ASTRA has been designed with a Missile Knowledge Graph consisting of 177 entities linked using 400 relationships. A query-answering model then utilizes this manually created Missile Knowledge Graph, which generates tabular or graph representation for the natural language question. Neo4j platform has been used to prepare the knowledge graph, and Cypher queries are used to execute queries. The modeled knowledge has been evaluated by executing natural language queries on KG4ASTRA query-answering model and compared the search results with other existing knowledge graphs. As of our best knowledge, neither the knowledge graph nor the question-answering model has been designed for Indian Missiles. As a future scope, the proposed knowledge graph will be connected with the existing knowledge graph and extended to automatically extract domain-specific entities.
C1 [Gupta, Shivansh] Jaypee Inst Informat Technol, Noida, India.
   [Tiwari, Sanju; Ortiz-Rodriguez, Fernando] Univ Autonoma Tamaulipas, Ciudad Victoria, Tamaulipas, Mexico.
   [Panchal, Ronak] Vidyabharti Trust Coll BCA, Bardoli, Gujarat, India.
C3 Jaypee Institute of Information Technology (JIIT); Universidad Autonoma
   de Tamaulipas
RP Tiwari, S (通讯作者)，Univ Autonoma Tamaulipas, Ciudad Victoria, Tamaulipas, Mexico.
EM shivanshgupta171999@gmail.com; sanju.tiwari@uat.edu.mx;
   ferortiz@uat.edu.mx; ronak.panchal@vtcbb.edu.in
RI Ortiz-Rodriguez, Fernando/A-5224-2011
OI Ortiz-Rodriguez, Fernando/0000-0003-2084-3462
CR Abdelkawi A, 2019, LECT NOTES COMPUT SC, V11877, P571, DOI 10.1007/978-3-030-33246-4_36
   Abujabal A, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1191, DOI 10.1145/3038912.3052583
   Blomqvist E., 2020, KNOWLEDGE GRAPHS
   Bordes Antoine, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P165, DOI 10.1007/978-3-662-44848-9_11
   Chen YZ, 2019, LECT NOTES COMPUT SC, V11448, P533, DOI 10.1007/978-3-030-18590-9_81
   Dubey M, 2016, LECT NOTES COMPUT SC, V9678, P300, DOI 10.1007/978-3-319-34129-3_19
   Gaurav D, 2021, EMERG TECHNOL DATA M, V3, P11
   Gaurav D, 2020, SOFT COMPUT, V24, P9625, DOI 10.1007/s00500-019-04473-7
   Gharibi M, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.00012
   Goyal A., 2020, KNOWL GRAPH SEM WEB
   Graefe G., 1993, Proceedings. Ninth International Conference on Data Engineering (Cat. No.92CH3258-1), P209, DOI 10.1109/ICDE.1993.344061
   Gubichev A., 2015, THESIS TU MUNCHEN
   Lin ZQ, 2017, J COMPUT SCI TECH-CH, V32, P242, DOI 10.1007/s11390-017-1718-y
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Mishra Sanju, 2019, International Journal of Web-Based Learning and Teaching Technologies, V14, P55, DOI 10.4018/IJWLTT.2019070105
   Moerkotte Guido, 2008, SIGMOD, P539
   Neumann T, 2011, PROC VLDB ENDOW, V4, P539, DOI 10.14778/2002938.2002940
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Powers DM., 2011, EVALUATION PRECISION, V2, P37, DOI 10.48550/arXiv.2010.16061
   Ruan T, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0798-8
   Selinger Patricia, 1979, P 1979 ACM SIGMOD IN, P23, DOI DOI 10.1145/582095.582099
   Sheng Ming, 2020, Web Information Systems and Applications. 17th International Conference, WISA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12432), P215, DOI 10.1007/978-3-030-60029-7_20
   Tiwari S, 2021, SOFT COMPUT, V25, P8337, DOI 10.1007/s00500-021-05756-8
   Unger C., 2012, P 21 INT C WORLD WID, P639, DOI DOI 10.1145/2187836.2187923
   Villazon-Terrazas B, 2020, KNOWLEDGE GRAPHS SEM
   Walter Sebastian, 2012, The Semantic Web. 11th International Semantic Web Conference (ISWC 2012). Proceedings, P362, DOI 10.1007/978-3-642-35173-0_25
   Wang HW, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P417, DOI 10.1145/3269206.3271739
   Xu K, 2015, LECT NOTES COMPUT SC, V9283, P414, DOI 10.1007/978-3-319-24027-5_43
   Yahya M., 2012, P 2012 JOINT C EMPIR, P379
   Yao XC, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P956
   Zou L, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P313, DOI 10.1145/2588555.2610525
NR 31
TC 2
Z9 2
U1 5
U2 33
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD NOV
PY 2021
VL 25
IS 22
BP 13841
EP 13855
DI 10.1007/s00500-021-06233-y
EA SEP 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WL6HB
UT WOS:000702246200002
DA 2023-11-10
ER

PT J
AU Sharghi, H
   Sartipi, K
AF Sharghi, Hassan
   Sartipi, Kamran
TI An expressive event-based language for representing user behavior
   patterns
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
LA English
DT Article
DE Behavior pattern; Sequence of events; Language; Semantics; Constraint
AB In-depth analysis of user interactions with applications in large systems is widely adopted as a means to understand user's behavior for strategic purposes such as fraud detection, system security, weblog analysis, social networking, and customer relationship management. Overall, the user behavior presents characteristics, relationships, structures, and effects of a sequence of actions in a specific application domain. The interaction of users with applications at the business-level generates events that make the elements of the user behavior. Formal modelling and representation of complex patterns of user actions using expressive languages are critical aspects of behavior analysis. We present a model to describe the behavior elements and their relationships. The model also provides a systematic mechanism for describing and presenting events, sequence of events, and complex behavior patterns. A behavior pattern can be defined as a sequence of typed events that occur during specific time intervals. An event consists of a tuple of attributes whose values represent an observation of the behavior. In this paper, first we define a semantic model of the user behavior to address the issues around the user behavior representation, and then we present syntax and semantics of a generic Behavior Pattern Language (BPL), which enables the analysts to define a variety of complex behavior patterns in a declarative manner. We present the feasibility of the approach through several examples of complex behavior patterns expressed using the proposed language.
C1 [Sharghi, Hassan] Univ Ontario, Inst Technol, Dept Elect Comp & Software Engn, 2000 Simcoe St North, Oshawa, ON L1H 7K4, Canada.
   [Sartipi, Kamran] McMaster Univ, DeGroote Sch Business, Informat Syst, 1280 Main St West, Hamilton, ON L8S 4M4, Canada.
C3 Ontario Tech University; McMaster University
RP Sharghi, H (通讯作者)，Univ Ontario, Inst Technol, Dept Elect Comp & Software Engn, 2000 Simcoe St North, Oshawa, ON L1H 7K4, Canada.
EM Mohammadhassan.Sharghigoorabi@uoit.net; sartipi@mcmaster.ca
CR Alvarez M., 2015, RES REPORT
   Angeletou S, 2011, LECT NOTES COMPUT SC, V7031, P35, DOI 10.1007/978-3-642-25073-6_3
   Anicic D., 2011, C WORLD WID WEB HYD
   Anicic D, 2010, LECT NOTES COMPUT SC, V6333, P42, DOI 10.1007/978-3-642-15918-3_5
   [Anonymous], PROGRAMMING LANGUAGE
   Arasu A, 2006, VLDB J, V15, P121, DOI 10.1007/s00778-004-0147-z
   Aztiria A, 2013, IEEE T SYST MAN CY-S, V43, P1265, DOI 10.1109/TSMC.2013.2252892
   Barga R. S., 2007, 3 BIENN C INN DAT SY
   Brenna L., 2007, P 2007 ACM SIGMOD IN, P1100
   Bry F., 2006, IEEE SERV COMP WORKS
   Bui Hai-Lam, 2009, SURVEY COMP EVENT QU
   Cao L., 2014, IEEE INTELL SYST APP, P62
   Cao LB, 2010, INFORM SCIENCES, V180, P3067, DOI 10.1016/j.ins.2010.03.025
   Cugola G, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2187671.2187677
   Fox Armando, 2013, ENG SOFTWARE SERVICE
   Grieskamp W., 2006, SCESM 06
   Kirou A, 2008, LECT NOTES COMPUT SC, V5101, P33, DOI 10.1007/978-3-540-69384-0_8
   Li GL, 2005, LECT NOTES COMPUT SC, V3790, P249
   Luckham D, 2012, EVENT PROCESSING FOR BUSINESS: ORGANIZING THE REAL-TIME ENTERPRISE, P1
   Pietzuch PR, 2004, IEEE NETWORK, V18, P44, DOI 10.1109/MNET.2004.1265833
   Plotkin G. D., 1981, STRUCTURAL APPROACH
   Priya RV, 2012, INT J DATA WAREHOUS, V8, P1, DOI [10.4018/jdwm.2012040101, 10.4018/jdwm.201204010]
   Python, 2015, PYTH PROGR LANG WEBS
   Rieke R., 2013, IEEE INT C AV REL SE, P946
   Rozsnyai S., 2009, IEEE C COMM ENT COMP
   Sandell NF, 2009, SOCIAL COMPUTING AND BEHAVIORAL MODELING, P180, DOI 10.1007/978-1-4419-0056-2_23
   Stolfo S.J., 2008, INSIDER ATTACK CYBER
   Thomas D, 2013, PROGRAMMING RUBY 1 9
   Wang C., 2012, BEHAV COMPUTING, P21
   Wooldridge M., 2000, REASONING RATIONAL A
   Yarmand MH, 2013, J COMPUT SECUR, V21, P1, DOI 10.3233/JCS-2012-0454
   Zarri G. P., 2012, BEHAV COMPUTING, P37
   Zerkouk M., 2013, SPRINGER SCI BUSINES, P291
NR 33
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0925-9902
EI 1573-7675
J9 J INTELL INF SYST
JI J. Intell. Inf. Syst.
PD DEC
PY 2017
VL 49
IS 3
BP 435
EP 459
DI 10.1007/s10844-017-0456-5
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FL8LX
UT WOS:000414502400006
DA 2023-11-10
ER

PT J
AU Wang, EL
   Kumar, PM
   Samuel, RDJ
AF Wang, Erlu
   Kumar, Priyan Malarvizhi
   Samuel, R. Dinesh Jackson
TI Semantic Graphical Dependence Parsing Model in Improving English
   Teaching Abilities
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Dependence Parsing; Semantic Graphical; Mono-parsing Text, and BiParsing
   Text
ID TECHNOLOGY
AB It is a very difficult problem to achieve high-order functionality for graphical dependency parsing without growing decoding difficulties. To solve this problem, this article offers a way for Semantic Graphical Dependence Parsing Model (SGDPM) with a language-dependency model and a beam search to represent high-order functions for computer applications. The first approach is to scan a large amount of unnoticed data using a baseline parser. It will build auto-parsed data to create the Language-dependence Model (LDM). The LDM is based on a set of new features during beam search decoding, where it will incorporate the LDM features into the parsing model and utilize the features in parsing models of bilingual text. Our approach has main benefits, which include rich high-order features that are described given the large size and the additional large crude corpus for increasing the difficulty of decoding. Further, SGDPM has been evaluated using the suggested method for parsing tasks of mono-parsing text and bi-parsing text to carry out experiments on the English and Chinese data in the mono-parsing text function using computer applications. Experimental results show that the most accurate Chinese data is obtained with the best known English data systems and their comparable accuracy. Furthermore, the lab-scale experiments on the Chinese/General bilingual information in the bitext parsing process outperform the best recorded existing solutions.
C1 [Wang, Erlu] Jilin Inst Chem Technol, Sch Foreign Language, Jilin 132022, Jilin, Peoples R China.
   [Kumar, Priyan Malarvizhi] Middlesex Univ, London, England.
   [Samuel, R. Dinesh Jackson] Oxford Brookes Univ, Fac Technol Design & Environm, Visual Artificial Intelligence Lab, Oxford, England.
C3 Jilin Institute of Chemical Technology; Middlesex University; Oxford
   Brookes University
RP Wang, EL (通讯作者)，Jilin Inst Chem Technol, Sch Foreign Language, Jilin 132022, Jilin, Peoples R China.
EM 53182565@qq.com; mkpriyan@khu.ac.kr; rsamuel@brookes.ac.uk
RI KUMAR, PRIYAN MALARVIZHI/GYV-1373-2022; Samuel, Dinesh
   Jackson/AAG-7420-2019
OI Samuel, Dinesh Jackson/0000-0002-1582-7161
FU Social Science Project of the 13th "Five-Year Plan" of Jilin Provincial
   Department of Education-Cultivation of English Majors' Innovative and
   Entrepreneurial Ability in the Information Age [JJKH20190841SK]
FX This research is supported by the Social Science Project of the 13th
   "Five-Year Plan" of Jilin Provincial Department of Education-Cultivation
   of English Majors' Innovative and Entrepreneurial Ability in the
   Information Age (Grant No. JJKH20190841SK).
CR [Anonymous], 2000, ED POLICY ANAL ARCH, DOI DOI 10.14507/EPAA.V8N51.2000
   Bañados E, 2006, CALICO J, V23, P533, DOI 10.1558/cj.v23i3.533-550
   Bhardwaj B. K, 2012, DATA MINING PREDICTI
   Bouhnik D, 2006, J AM SOC INF SCI TEC, V57, P299, DOI 10.1002/asi.20277
   Greenwood CR, 2001, REM SPEC EDUC, V22, P34, DOI 10.1177/074193250102200105
   Hsu H. M. J., 2011, INT J INFORM ED TECH, V1, P365, DOI [10.7763/IJIET.2011.V1.59, DOI 10.7763/IJIET.2011.V1.59]
   Johnson L., 2012, THESIS U LOUISVILLE
   Kern R, 2006, TESOL QUART, V40, P183, DOI 10.2307/40264516
   King J., 2002, Computer Assisted Language Learning, V15, P509, DOI 10.1076/call.15.5.509.13468
   Lau B., 2008, INT J COMPUTING ICT, V2, P19
   Ling Z., 2001, FOREIGN LANG WORLD, V6
   Liu PL, 2010, COMPUT EDUC, V54, P436, DOI 10.1016/j.compedu.2009.08.027
   Liu TY, 2009, J COMPUT ASSIST LEAR, V25, P515, DOI 10.1111/j.1365-2729.2009.00329.x
   Ranalli J, 2008, COMPUT ASSIST LANG L, V21, P441, DOI 10.1080/09588220802447859
   Roschelle JM, 2000, FUTURE CHILD, V10, P76, DOI 10.2307/1602690
   Sadaf A, 2012, COMPUT EDUC, V59, P937, DOI 10.1016/j.compedu.2012.04.001
   Suh S, 2010, J COMPUT ASSIST LEAR, V26, P370, DOI 10.1111/j.1365-2729.2010.00353.x
   Tsai SC, 2011, RECALL, V23, P117, DOI 10.1017/S0958344011000048
   Wiriyachitra, 2002, THAI TESOL FOCUS, V15, P4
   WOZNEY L, 2006, J TECHNOLOGY TEACHER, V14, P173
   Yang SC, 2007, COMPUT HUM BEHAV, V23, P860, DOI 10.1016/j.chb.2006.02.015
   Young C. A., 2004, Contemporary Issues in Technology and Teacher Education, V4
NR 22
TC 0
Z9 0
U1 1
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAY
PY 2021
VL 20
IS 3
SI SI
AR 48
DI 10.1145/3425633
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA UY1JZ
UT WOS:000701288900010
DA 2023-11-10
ER

PT J
AU Tuo, AX
   Bing, L
AF Anxie, Tuo
   Bing, Li
TI Application of deep learning and artificial intelligence in the
   psychological mechanism of language activity
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Deep learning; artificial intelligence; language activities; algorithm
   simulation
ID MODEL
AB The deep learning architecture consists of multiple layers of non-linear computing units, and the output of each lower layer is used as the input of the higher layer, which can learn effective feature representations from a large amount of input data. In this paper, the author analyze the application of deep learning and artificial intelligence in the psychological mechanism of language activity. Language activity is a complex cognitive process that drives the comprehensive response, coordination, and operation of body-related functions. In this activity, there are three information processing links: language input, intermediate processing and language output. Intermediate processing is the core part. Information processing drives systemic language responses, including those of the oral muscles and nervous system. According to the experimental results, we analyze the psychological factors in the processing of language activity information, study the language processing and information processing modes of deep learning and artificial intelligence in the brain, and the psychological mechanism of English-Chinese alternate language activities. the result predicted by SVM regression is 5.35 m/s, and the prediction error is 4.5%. In addition to the speed prediction, we used the same sample data to predict the direction of the next second. The simulation results this system can predict the language activity.
C1 [Anxie, Tuo] Guizhou Med Univ, Coll Med Humanities, Cognit Linguist Psychol, Guiyang 550001, Peoples R China.
   [Bing, Li] Guizhou Univ, Coll Foreign Languages, Psycholinguist, Guiyang, Peoples R China.
C3 Guizhou Medical University; Guizhou University
RP Tuo, AX (通讯作者)，Guizhou Med Univ, Coll Med Humanities, Cognit Linguist Psychol, Guiyang 550001, Peoples R China.
EM tax20191210@163.com
FU Promotion of Ethnic Identity of Ethnic Minorities through `Internet+'
   Chinese Character Source Learning in Southwest China, A Neural Mechanism
   ERP Study of Chinese-English Vocabulary Partial Coding and Conversion
   [2017JJD190003]
FX This research is supported by Promotion of Ethnic Identity of Ethnic
   Minorities through `Internet+' Chinese Character Source Learning in
   Southwest China(Grant No. 2017JJD190003), A Neural Mechanism ERP Study
   of Chinese-English Vocabulary Partial Coding and Conversion.
CR Virgen-Carrillo CA, 2018, ARCH LATINOAM NUTR, V68, P29
   Amani N., 2018, INT J ENERGY SECTOR, V12, P88
   Bergero FM, 2018, BUILD SIMUL-CHINA, V11, P405, DOI 10.1007/s12273-017-0400-1
   CornejoBueno L., 2017, METEOROLOGY, V5, P11
   Ghali R., 2015, J ED TRAINING STUDIE, V4, P42
   Hristopulos DT, 2015, COMPUT GEOSCI-UK, V85, P26, DOI 10.1016/j.cageo.2015.05.018
   Jiang YY, 2018, BIOSCI BIOTECH BIOCH, V82, P1225, DOI 10.1080/09168451.2018.1453293
   Lee H, 2014, TECHNOL FORECAST SOC, V86, P49, DOI 10.1016/j.techfore.2013.08.020
   Lei Z., 2018, EARTHQ ENG ENG VIB, V17, P47
   Lucchino EC, 2019, BUILD SIMUL-CHINA, V12, P3, DOI 10.1007/s12273-019-0511-y
   McClellan SA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185718
   Najeebullah, 2014, COMPUTERS ELECT ENG
   Sámano R, 2018, ARCH LATINOAM NUTR, V68, P41
   Shen PY, 2018, APPL ENERG, V223, P188, DOI 10.1016/j.apenergy.2018.04.039
   Shungo S., 2018, EVOLUTIONARY I EC RE, V11, P12
   Strzalkowski J., 2018, IOP Conference Series: Materials Science and Engineering, V415, DOI 10.1088/1757-899X/415/1/012014
   Taniguchi H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25679-z
   Thomas A, 2017, BUILD SIMUL-CHINA, V10, P1023, DOI 10.1007/s12273-017-0409-5
   Tiejun C., 2017, CHINESE J APPL MECH, P71
   Torregrosa-Jaime B., 2018, ENERGIES, V12, P43
   Usha Rani R., 2015, INT J COMPUTER APPL, V116, P25, DOI [10.5120/20292-2681, DOI 10.5120/20292-2681]
   Wang Mi, 2018, Boletin de Malariologia y Salud Ambiental, V58, P26
   Zhu HuiYu, 2018, Boletin de Malariologia y Salud Ambiental, V58, P20
NR 23
TC 0
Z9 0
U1 3
U2 35
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2020
VL 38
IS 6
SI SI
BP 7315
EP 7327
DI 10.3233/JIFS-179806
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA MY7XE
UT WOS:000558628900056
DA 2023-11-10
ER

PT J
AU Liu, XY
   Tang, HL
   Zhao, J
   Dou, QS
   Lu, MY
AF Liu, Xiaoyan
   Tang, Huanling
   Zhao, Jie
   Dou, Quansheng
   Lu, Mingyu
TI TCAMixer: A lightweight Mixer based on a novel triple concepts attention
   mechanism for NLP
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Textual feature representation; Attention mechanism; Deep learning;
   Modeling lighter
AB Large-scale model sizes and expensive computing costs cause the challenge of deploying and applying large pre-trained models. Hence, this paper presents a novel Triple Concepts Attention Mechanism and a lightweight TCAMixer model for edge devices to classify texts. Furthermore, the TCAMixer abstracts textual concepts in a human way, which is unmatched by other counterparts such as pNLP-Mixer (a projection-based MLP-Mixer model for Nature Language Processing) and HyperMixer (a hyper network using dynamic token-mixing layers). Experimental results on several public datasets demonstrate that the TCAMixer outperforms the counterparts by a significant margin, for example, achieving 3% higher accuracy with a smaller model size of 0.177M. Additionally, the TCAMixer achieves a performance of 85% to 98.7% compared to that of large pre-trained models but only occupies 1/3000 to 1/2000 of their size on most test datasets.
C1 [Liu, Xiaoyan; Tang, Huanling; Dou, Quansheng] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Shandong, Peoples R China.
   [Zhao, Jie] Shandong Technol & Business Univ, Sch Management Sci & Engn, Yantai 264005, Shandong, Peoples R China.
   [Tang, Huanling; Dou, Quansheng] Coinnovat Ctr Shandong Coll & Univ Future Intellig, Yantai 264005, Shandong, Peoples R China.
   [Tang, Huanling; Dou, Quansheng] Shandong Technol & Business Univ, Univ Shandong, Key Lab Intelligent Informat Proc, Yantai 264005, Shandong, Peoples R China.
   [Lu, Mingyu] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116026, Liaoning, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University; Shandong University; Shandong Technology & Business
   University; Dalian Maritime University
RP Tang, HL (通讯作者)，Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Shandong, Peoples R China.
EM lxy15058247683@aliyun.com; thL01@163.com; 17832275101@163.com;
   li_dou@163.com; lumingyu@dlmu.edu.cn
RI 刘, 孝炎/JGE-3976-2023
OI 刘, 孝炎/0000-0002-2793-7587
FU National Natural Science Foundation of China [61976124, 61976125,
   62176140]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61976124, No. 61976125, No. 62176140) .
CR Bailin Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P639, DOI 10.1007/978-3-030-58536-5_38
   Beltagy I, 2020, Arxiv, DOI [arXiv:2004.05150, DOI 10.48550/ARXIV.2004.05150]
   Chen SF, 2022, Arxiv, DOI arXiv:2107.10224
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Devlin J., 2018, ARXIV, V1, P4171
   Fusco F, 2023, Arxiv, DOI arXiv:2202.04350
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Guo MH, 2021, Arxiv, DOI [arXiv:2105.02358, 10.48550/arXiv.2105.02358, DOI 10.1109/TPAMI.2022.3211006]
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]
   Ioannou Y, 2017, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2017.633
   Javed U, 2021, INT J EMERG TECHNOL, V16, P274, DOI 10.3991/ijet.v16i03.18851
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, P1746, DOI DOI 10.3115/V1/D14-1181
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee-Thorp J, 2022, Arxiv, DOI arXiv:2105.03824
   Lian D., 2021, AS MLP AXIAL SHIFTED, DOI DOI 10.48550/ARXIV.2107.08391
   Lin MB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P673
   Liu Hanxiao, 2021, ADV NEURAL INF PROCE, V34, P9204, DOI DOI 10.48550/ARXIV.2105.08050
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Mai FR, 2022, Arxiv, DOI arXiv:2203.03691
   Sabour S., 2017, P 31 INT C NEUR INF, P3856
   Shaukat K, 2020, ENERGIES, V13, DOI 10.3390/en13102509
   Shazeer N., 2017, OUTRAGEOUSLY LARGE N, P1
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158
   Tang W., 2022, IEEE T MULTIMED, P1, DOI [10.1109/TMM.2022.3192661, DOI 10.1109/TMM.2022.3192661]
   Tolstikhin I, 2021, ADV NEURAL INFORM PR
   Touvron Hugo, 2021, P INT C MACH LEARN I, DOI [10.48550/arXiv.2012.12877, DOI 10.48550/ARXIV.2012.12877]
   Vaswani A., 2017, ARXIV, V30, P5998
   Wu MC, 2019, INT CONF ACOUST SPEE, P2202, DOI 10.1109/ICASSP.2019.8682450
   Xie Q., 2020, ADV NEURAL INFORM PR, V33, P6256, DOI DOI 10.5555/3495724.3496249
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Yu T, 2022, IEEE WINT CONF APPL, P3615, DOI 10.1109/WACV51458.2022.00367
   Zhang Ye, 2017, P 8 INT JOINT C NAT, V1, P253
   Zhu JM, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2941, DOI 10.1145/3340531.3412704
   Zhuo HY, 2018, Arxiv, DOI [arXiv:1806.05320, 10.48550/arXiv.1806.05320, DOI 10.48550/ARXIV.1806.05320]
NR 38
TC 0
Z9 0
U1 2
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD AUG
PY 2023
VL 123
AR 106471
DI 10.1016/j.engappai.2023.106471
EA MAY 2023
PN C
PG 8
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Engineering
GA J7QT4
UT WOS:001011537800001
DA 2023-11-10
ER

PT J
AU Wachs-Lopes, GA
   Rodrigues, PS
AF Wachs-Lopes, Guilherme Alberto
   Rodrigues, Paulo Sergio
TI Analyzing natural human language from the point of view of dynamic of a
   complex network
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Complex networks; Physical measures; Clustering coefficient; Textual
   information retrieval
ID APPROACHING HUMAN LANGUAGE; SMALL-WORLD; CONG
AB With increasing amount of information, mainly due to the explosive growth of Internet, the demand for applications of automatic text analysis has also grown. One of the tools that has increased in importance in the understanding of problems related to this area are complex networks. This tool merges graph theory and statistical methods for modeling important problems. In several research fields, complex networks are studied from the various points of view, such as: topology of networks, extraction of physical features and statistics, specific applications, comparison of metrics and study of physical phenomena. Linguistic is one area that has received great attention, particularly due to its close relationship with issues arising from the emergence of large text databases. Thus, many studies have emerged for modeling of complex networks in this area, increasing the demand for efficient algorithms for feature extraction, network dynamic observation and comparison of behavior for different types of languages. Some works for specific languages such as English, Chinese, French, Spanish, Russian and Arabic, have discussed the semantic aspects of these languages. On the other hand, as an important feature of a network we can highlight the computation of average clustering coefficient. This measure has a physical impact on the network topology studies and consequently on the conclusions about the semantics of a language. However its computational time is of O(n(3)), making its computing prohibitive for large current databases. This paper presents as main contribution a modeling of two complex networks: the first one, in English, is constructed from a specific medical database; the second, in Portuguese, from a journalistic manually annotated database. Our paper then presents the study of the dynamics of these two networks. We show their small-world behavior and the influence of hubs, suggesting that these databases have a high degree of Modularity, indicating specific contexts of words. Also, a method for efficient clustering coefficient computation is presented, and can be applied to large current databases. Other features such as fraction of reciprocal connections and average connection density are also calculated and discussed for both networks. (C) 2015 Elsevier Ltd. All rights reserved.
C1 [Wachs-Lopes, Guilherme Alberto; Rodrigues, Paulo Sergio] Ctr Univ FEI, Dept Comp Sci, Sao Paulo, Brazil.
C3 Centro Universitario da FEI
RP Rodrigues, PS (通讯作者)，Ctr Univ FEI, Dept Comp Sci, 3972 Castelo Branco Ave, Sao Paulo, Brazil.
EM gwachs@fei.edu.br; psergio@fei.edu.br
RI Lopes, Guilherme/E-9501-2017; Rodrigues, Paulo/K-6328-2015
OI Lopes, Guilherme/0000-0003-0873-3236; Rodrigues,
   Paulo/0000-0003-3258-0794
FU CNPq [301858/2007-1]; CAPES [094/2007]; FAPESP (Sao Paulo Research
   Foundation); FEI (Ignacian Educational Foundation) a Brazilian Jesuit
   Faculty of Science Computing and Engineering
FX The authors would like to thank the CNPq (Project 301858/2007-1) and
   CAPES (Project 094/2007), the Brazilian agencies for Scientific
   Financing, FAPESP (Sao Paulo Research Foundation), as well as to FEI
   (Ignacian Educational Foundation) a Brazilian Jesuit Faculty of Science
   Computing and Engineering, for the support of this work.
CR Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47
   Albert R, 1999, NATURE, V401, P130, DOI 10.1038/43601
   Allesina S, 2008, THEOR ECOL-NETH, V1, P55, DOI 10.1007/s12080-007-0007-8
   Amancio D. R., 2014, STRUCTURE SEMANTICS
   Amancio DR, 2012, PHYSICA A, V391, P1855, DOI 10.1016/j.physa.2011.10.015
   Amancio DR, 2014, PHYS LIFE REV, V11, P641, DOI 10.1016/j.plrev.2014.07.010
   Baeza-Yates R.A., 1999, MODERN INFORM RETRIE
   Biemann C., 2012, P 24 INT C COMP LING, P263
   Bota A, 2014, P 9 INT C APPL INFOR, V1, P113
   Cancho RFI, 2001, P ROY SOC B-BIOL SCI, V268, P2261, DOI 10.1098/rspb.2001.1800
   Cech R., 2014, COMPLEX NETWORKS THE, P167
   Cech R, 2014, PHYS LIFE REV, V11, P624, DOI 10.1016/j.plrev.2014.07.009
   Chen XY, 2014, PHYS LIFE REV, V11, P628, DOI 10.1016/j.plrev.2014.07.011
   Colman ER, 2012, PHYSICA A, V391, P6626, DOI 10.1016/j.physa.2012.07.034
   Cong J, 2014, PHYS LIFE REV, V11, P598, DOI 10.1016/j.plrev.2014.04.004
   Cong T., 2014, PHYS LIFE REV, V11, P639
   Deng WB, 2011, PHYSICA A, V390, P1481, DOI 10.1016/j.physa.2010.12.029
   Erdos P., 1959, PUBL MATH DEBRECEN, V6, P290, DOI DOI 10.5486/PMD.1959.6.3-4.12
   Ferrer-i Cancho R., 2014, PHYS LIFE REV, V11, P621
   Gao YY, 2014, PHYSICA A, V393, P579, DOI 10.1016/j.physa.2013.08.075
   Hart J., 1981, WIZARD OF ID SERIES
   Hersh W., 1994, SIGIR 94, P192
   Hudson R, 2014, PHYS LIFE REV, V11, P619, DOI 10.1016/j.plrev.2014.06.013
   Köhler R, 2014, PHYS LIFE REV, V11, P630, DOI 10.1016/j.plrev.2014.07.016
   Li JY, 2007, PHYSICA A, V380, P629, DOI 10.1016/j.physa.2007.02.059
   Macutek J, 2014, PHYS LIFE REV, V11, P635, DOI 10.1016/j.plrev.2014.07.015
   Mehri A, 2012, PHYSICA A, V391, P2429, DOI 10.1016/j.physa.2011.12.011
   Mishkovski I, 2011, COMMUN NONLINEAR SCI, V16, P341, DOI 10.1016/j.cnsns.2010.03.018
   Newman M., 2006, STRUCTURE DYNAMICS N
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Pardo T. A. S., 2005, P INT C COMM CIRC SY, P2678
   Pons P, 2005, LECT NOTES COMPUT SC, V3733, P284
   PRICE DJD, 1965, SCIENCE, V149, P510
   Schank T., 2005, J GRAPH ALGORITHMS A, V9, P265, DOI DOI 10.7155/JGAA.00108
   Sheng L, 2009, PHYSICA A, V388, P2561, DOI 10.1016/j.physa.2009.02.043
   SOLOMONOFF RAY, 1951, BULL MATH BIOPHYS, V13, P107, DOI 10.1007/BF02478357
   Sporns O., 2003, NEUROSCIENCE DATABAS, P171, DOI [DOI 10.1007/978-1-4615-1079-6_12, 10.1007/978-1-4615-1079-6_12]
   Wachs-Lopes G. A., 2011, THESIS
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Yu SY, 2014, PHYS LIFE REV, V11, P626, DOI 10.1016/j.plrev.2014.06.003
   Zhao YY, 2014, PHYS LIFE REV, V11, P637, DOI 10.1016/j.plrev.2014.07.012
NR 41
TC 20
Z9 21
U1 2
U2 50
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 1
PY 2016
VL 45
BP 8
EP 22
DI 10.1016/j.eswa.2015.09.020
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA CY2IS
UT WOS:000366232700002
DA 2023-11-10
ER

PT S
AU Jain, S
   Kinber, E
AF Jain, S
   Kinber, E
BE Jain, S
   Simon, HU
   Tomita, E
TI Learning multiple languages in groups
SO ALGORITHMIC LEARNING THEORY
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 16th Annual International Conference on Algorithmic Learning Theory (ALT
   2005)
CY OCT 08-11, 2005
CL Singapore, SINGAPORE
SP Lee Fdn, USAF, Asian Off Aerosp Res & Dev, Natl Univ Singapore, Sch Comp, Ruhr Univ Bochum, Fak Math, Hokkaido Univ, Div Comp Sci, Univ Lubeck, Inst Theoret Comp Sci, MBZ Marketing Buro Zeugmann
ID MACHINE INDUCTIVE INFERENCE; IDENTIFICATION; CRITERIA
AB We consider a variant of Cold's learning paradigm where a learner receives as input n different languages (in form of one text where all input languages are interleaved). Our goal is to explore the situation when a more "coarse" classification of input languages is possible, whereas more refined classification is not. More specifically, we answer the following question: under which conditions, a learner, being fed n different languages, can produce m grammars covering all input languages, but cannot produce k grammars covering input languages for any k > m. We also consider a variant of this task, where each of the output grammars may not cover more than r input languages. Our main results indicate that the major factor affecting classification capabilities is the difference n - m between the number n of input languages and the number m of output grammars. We also explore relationship between classification capabilities for smaller and larger groups of input languages. For the variant of our model with the upper bound on the number of languages allowed to be represented by one output grammar, for classes consisting of disjoint languages, we found complete picture of relationship between classification capabilities for different parameters n (the number of input languages), m (number of output grammars), and r (bound on the number of languages represented by each output grammar). This picture includes a combinatorial characterization of classification capabilities for the parameters n, m, r of certain types.
C1 Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore.
   Sacred Heart Univ, Dept Comp Sci, Fairfield, CT 06432 USA.
C3 National University of Singapore; Sacred Heart University
RP Jain, S (通讯作者)，Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore.
EM sanjay@comp.nus.edu.sg; kinbere@sacredheart.edu
CR [Anonymous], 2014, COMPUTER SCI LIB THE
   [Anonymous], 1987, THEORY RECURSIVE FUN
   Barzdins J., 1974, THEORY ALGORITHMS PR, V210, P82
   BLUM L, 1975, INFORM CONTROL, V28, P125, DOI 10.1016/S0019-9958(75)90261-2
   BLUM M, 1967, J ACM, V14, P322, DOI 10.1145/321386.321395
   CASE J, 1982, LECT NOTES COMPUT SC, V140, P107
   CASE J, 1983, THEOR COMPUT SCI, V25, P193, DOI 10.1016/0304-3975(83)90061-0
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   JAIN S, 2001, ALT
   OSHERSON D, 1986, SYSTEMS THAT LEARN I
   OSHERSON DN, 1982, INFORM CONTROL, V52, P123, DOI 10.1016/S0019-9958(82)80025-9
   PINKER S, 1958, J SYMBOLIC LOGIC, V23, P331
   Wexler K., 1980, FORMAL PRINCIPLES LA
NR 13
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-29242-X
J9 LECT NOTES ARTIF INT
PY 2005
VL 3734
BP 256
EP 268
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematics
GA BDH68
UT WOS:000233583800020
DA 2023-11-10
ER

PT J
AU Fouad, MM
   Mahany, A
   Aljohani, N
   Abbasi, RA
   Saeed-Ul Hassan
AF Fouad, Mohammed M.
   Mahany, Ahmed
   Aljohani, Naif
   Abbasi, Rabeeh Ayaz
   Hassan, Saeed-Ul
TI ArWordVec: efficient word embedding models for Arabic tweets
SO SOFT COMPUTING
LA English
DT Article
DE ArWordVec; Natural language processing; Word embeddings; Deep
   convolution neural networks; Arabic tweets
AB One of the major advances in artificial intelligence nowadays is to understand, process and utilize the humans' natural language. This has been achieved by employing the different natural language processing (NLP) techniques along with the aid of the various deep learning approaches and architectures. Using the distributed word representations to substitute the traditional bag-of-words approach has been utilized very efficiently in the last years for many NLP tasks. In this paper, we present the detailed steps of building a set of efficient word embedding models called ArWordVec that are generated from a huge repository of Arabic tweets. In addition, a new method for measuring Arabic word similarity is introduced that has been used in evaluating the performance of the generated ArWordVec models. The experimental results show that the performance of the ArWordVec models overcomes the recently available models on Arabic Twitter data for the word similarity task. In addition, two of the large Arabic tweets datasets are used to examine the performance of the proposed models in the multi-class sentiment analysis task. The results show that the proposed models are very efficient and help in achieving a classification accuracy ratio exceeding 73.86% with a high average F1 value of 74.15.
C1 [Fouad, Mohammed M.] Fujitsu Technol Solut, Dubai, U Arab Emirates.
   [Mahany, Ahmed] Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
   [Aljohani, Naif] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
   [Abbasi, Rabeeh Ayaz] Quaid I Azam Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Hassan, Saeed-Ul] Informat Technol Univ, Lahore, Pakistan.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University; King Abdulaziz
   University; Quaid I Azam University
RP Fouad, MM (通讯作者)，Fujitsu Technol Solut, Dubai, U Arab Emirates.
EM Mohammed.Fouad@ts.fujitsu.com; ahmedmahany@cis.asu.edu.eg;
   nraljohani@kau.edu.sa; rabbasi@qau.edu.pk; saeed-ul-hassan@itu.edu.pk
RI Abbasi, Rabeeh/B-4495-2011; Aljohani, Naif R/S-1109-2017; Fouad,
   Mohammed/C-4052-2013; Mahany, Ahmed/IXD-8851-2023; Hassan,
   Saeed-Ul/G-1889-2016
OI Abbasi, Rabeeh/0000-0002-3787-7039; Fouad, Mohammed/0000-0002-6369-6178;
   Mahany, Ahmed/0000-0001-5133-6995; Hassan, Saeed-Ul/0000-0002-6509-9190
CR Al-Azani S, 2017, PROCEDIA COMPUT SCI, V109, P359, DOI 10.1016/j.procs.2017.05.365
   Al-Twairesh N, 2016, 54 ANN M ASS COMP LI
   Ananiadou Sophia, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P318, DOI 10.1007/978-3-642-37256-8_27
   [Anonymous], 2016, GLOVE PYTHON
   [Anonymous], 2015, P 2015 C N AM CHAPT
   Batista-Navarro Riza Theresa, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P559, DOI 10.1007/978-3-642-37247-6_45
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   El-Mawass N, 2016, 2016 6 INT C DIG INF
   Fahmi A, 2019, SOFT COMPUT, V23, P5753, DOI 10.1007/s00500-018-3242-6
   Fahmi A, 2019, J INTELL SYST, V28, P699, DOI 10.1515/jisys-2017-0083
   Fahmi A, 2018, INT J SYST SCI, V49, P2385, DOI 10.1080/00207721.2018.1503356
   Howells K, 2017, 9 INT C THEOR APPL S
   Indhuja K., 2014, 2014 1 INT C COMP SY
   Iñiguez L, 2018, IEEE INT CONF FUZZY
   Jahangir M, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P722, DOI 10.1109/IntelliSys.2017.8324209
   Kumar D, 2018, LECT NOTES COMPUTER
   Lu C, 2017, LECT NOTES ARTIF INT, V10234, P524, DOI 10.1007/978-3-319-57454-7_41
   Luong M-T, 2013, SIGNLL C COMP NAT LA
   Mikolov T, 2013, EXPLOITING SIMILARIT, DOI [10.1162/153244303322533223, DOI 10.1162/153244303322533223]
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mohammad SM, 2016, J ARTIF INTELL RES, V55, P95, DOI 10.1613/jair.4787
   Nabil M., 2015, P 2015 C EMP METH NA, P2515, DOI DOI 10.18653/V1/D15-1299
   Nada Almarwani, 2017, P 3 ARABIC NATURAL L, P185, DOI DOI 10.18653/V1/W17-1322
   Nakov P, 2016, P 10 INT WORKSH SEM, P1, DOI DOI 10.18653/V1/S16-1001
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Rehurek R., 2010, P LREC 2010 WORKSHOP, P45
   Sharma M, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-3043-8
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Wang MQ, 2018, LECT NOTES ARTIF INT, V10937, P56, DOI 10.1007/978-3-319-93034-3_5
   Xun G., 2017, P 23 ACM SIGKDD INT
   Zhang Y, 2015, ARXIV151003820, DOI [10.3115/v1/D14-1181, DOI 10.3115/V1/D14-1181]
   Ziani A., 2017, 2 INT C AUT CONTR TE
NR 32
TC 13
Z9 13
U1 1
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD JUN
PY 2020
VL 24
IS 11
SI SI
BP 8061
EP 8068
DI 10.1007/s00500-019-04153-6
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LK0KT
UT WOS:000530547900019
DA 2023-11-10
ER

PT J
AU Bruce, RF
   Wiebe, JM
AF Bruce, RF
   Wiebe, JM
TI Decomposable modeling in natural language processing
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB In this paper, we describe a framework for developing probabilistic classifiers in natural language processing. Our focus is on formulating models that capture the most important interdependencies among features, to avoid overfitting the data while also characterizing the data well. The class of probability models and the associated inference techniques described here were developed in mathematical statistics, and are widely used in artificial intelligence and applied statistics. Our goal is to make this model selection framework accessible to researchers in NLP, and provide pointers to available software and important references. In addition, toe describe how the quality of the three determinants of classifier performance (the features, the form of the model, and the parameter estimates) can be separately evaluated. We also demonstrate the classification performance of these models in a large-scale experiment involving the disambiguation of 34 words taken from the HECTOR word sense corpus (Hanks 1996). In 10-fold cross-validations, the model search procedure performs significantly better than naive Bayes on 6 of the words without being significantly worse on any of them.
C1 Univ N Carolina, Dept Comp Sci, Asheville, NC 28804 USA.
   New Mexico State Univ, Dept Comp Sci, Las Cruces, NM 88003 USA.
C3 University of North Carolina; University of North Carolina - Asheville;
   New Mexico State University
RP Bruce, RF (通讯作者)，Univ N Carolina, Dept Comp Sci, Asheville, NC 28804 USA.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], 1996, P EMNLP 1996
   [Anonymous], 1998, P 1 INT C LANG RES E
   [Anonymous], 1975, DISCRETE MULTIVARIAT
   ATKINS S, 1993, PAPERS COMPUTATIONAL
   BDSBERG JH, 1995, THESIS AALBORG U
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BOUTILIER C, 1996, P 12 C UNC ART INT U
   Breiman L, 1984, CLASSIFICATION ALGOR, V40, P358, DOI 10.1201/9781315139470
   BRUCE R, 1994, P 32 ANN M ASS COMP, P139
   Bruce R., 1996, P C EMP METH NAT LAN, P101
   BUNTINE W, 1996, IEEE T KNOWLEDGE DAT, V8
   BUNTINE W, 1995, 5 INT ART INT STAT W
   Cohen P.R., 1997, EMPIRICAL METHODS AR, p115M
   DARROCH JN, 1980, ANN STAT, V8, P522, DOI 10.1214/aos/1176345006
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Hanks P., 1996, INT J CORPUS LINGUIS, DOI 10.1075/ijcl.1.1.06han
   KAYALLP M, 1997, P COMP NAT LANG LEAR
   Langley P., 1992, P 10 NAT C ART INT, P223
   LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157
   LEACOCK C, 1993, P ARPA WORKSH HUM LA
   Mood A.M., 1974, INTRO THEORY STAT
   Pearl J., 1988, MORGAN KAUFMANN SERI
   PEDERSEN T, 1997, P 14 NAT C ART INT A
   PEDERSEN T, 1997, P 5 C APPL NAT LANG
   Ratnaparkhi Adwait., 1997, P 2 C EMP METH NAT L
   READ TRC, 1988, GOODNESS OF FIT STAT
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   WHITTAKER J, 1990, GRAPHICAL MODELS APP
   WIEBE J, 1997, P 2 INT C REC ADV NL
NR 30
TC 15
Z9 16
U1 0
U2 2
PU M I T PRESS
PI CAMBRIDGE
PA FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA
SN 0891-2017
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 1999
VL 25
IS 2
BP 195
EP 207
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Linguistics
GA 210PN
UT WOS:000081114000002
DA 2023-11-10
ER

PT J
AU Lu, SY
   Liu, Z
   Liu, TL
   Zhou, WCS
AF Lu, Siyu
   Liu, Zheng
   Liu, Tianlin
   Zhou, Wangchunshu
TI Scaling-up medical vision-and-language representation learning with
   federated learning
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Medical vision-and-language; Representation learning; Federated learning
AB Medical Vision-and-Language Pre-training (MedVLP), which learns generic vision-language representations from medical images and texts to benefit various downstream medical tasks, has drawn remarkable attention in both artificial intelligence and clinical medicine. However, existing works ignore the privacy issues and the heavy computation burden in MedVLP. In this study, we propose a FedMedVLP model, which adopts federated learning to unify the datasets from different clients, e.g., centers and hospitals, to form a largescale pre-training dataset. As a result, the unified large-scale pre-training dataset can be used to pre-train the MedVLP to achieve strong performance. Overall, our FedMedVLP can improve the performance of MedVLP while preventing data leakage. Extensive experiments prove that the proposed model sets new state-of-the-art results on five benchmark datasets across three medical mainstream tasks, i.e., medical image-text retrieval, medical text-image retrieval, and medical visual question answering tasks. Besides, we further evaluate our method on our curated well-balanced medical dataset COVID-Fed.
C1 [Lu, Siyu; Liu, Tianlin; Zhou, Wangchunshu] Jinan Univ, Guangzhou, Peoples R China.
   [Liu, Zheng] UCL, London, England.
C3 Jinan University; University of London; University College London
RP Liu, TL; Zhou, WCS (通讯作者)，Jinan Univ, Guangzhou, Peoples R China.
EM tianlinliu95@gmail.com; ericzhou@jun.edu.cn
CR Abacha Asma Ben, 2019, CLEF WORK NOT, V2
   Alberti Chris, 2019, EMPIRICAL METHODS NA
   Alsentzer Emily, 2019, P 2 CLIN NATURAL LAN, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/, DOI 10.18653/V1]
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Chen FL, 2023, MACH INTELL RES, V20, P38, DOI 10.1007/s11633-022-1369-5
   Chen H, 2018, AAAI CONF ARTIF INTE, P6706
   Chen Jun, 2021, ARXIV
   Chen YC, 2020, Arxiv, DOI arXiv:1909.11740
   Cho Jaemin, 2020, EMPIRICAL METHODS NA
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou Zi-Yi, 2022, P IEEE CVF C COMP VI
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   E. W. Johnson Alistair, 2019, Arxiv, DOI [arXiv:1901.07042, DOI 10.48550/ARXIV.1901.07042]
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gan Zhe, 2020, ANN C NEUR INF PROC
   Gao Hongyu, 2022, P 30 ACM INT C MULT
   Gao Peng, P IEEE CVF C COMP VI
   Ging Simon., 2020, ANN C NEUR INF PROC
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodosh M., 2014, P TACL, V7, P67, DOI [10.1162/tacl_a_00166, DOI 10.1162/TACL_A_00166]
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huang SC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3922, DOI 10.1109/ICCV48922.2021.00391
   Huang Ting-Hao, 2016, ANN C N AM CHAPT ASS
   Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Irvin J, 2019, AAAI CONF ARTIF INTE, P590
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Kazemzadeh Sahar, 2014, EMPIRICAL METHODS NA
   Khare Y, 2021, I S BIOMED IMAGING, P1033, DOI 10.1109/ISBI48211.2021.9434063
   Kim JH, 2018, ADV NEUR IN, V31
   Kim Wonjae, 2021, ARXIV
   Kingma D. P., 2014, C TRACK P
   Lau JJ, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.251
   Lei J, 2021, Arxiv, DOI [arXiv:2102.06183, 10.48550/arXiv.2102.06183]
   Li G, 2019, Arxiv, DOI arXiv:1908.06066
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li Junnan., 2021, ANN C NEUR INF PROC
   Li Linjie, 2020, ARXIV
   Li Linjie, 2020, EMPIRICAL METHODS NA
   Li LN, 2021, Arxiv, DOI arXiv:2010.12831
   Li Tian, 2020, PROC MACHINE LEARNIN, V2, P429, DOI [10.48550/arXiv.1812.06127, DOI 10.48550/ARXIV.1812.06127]
   Li W, 2022, Arxiv, DOI arXiv:2012.15409
   Liu B, 2021, LECT NOTES COMPUT SC, V12902, P210, DOI 10.1007/978-3-030-87196-3_20
   Liu B, 2021, I S BIOMED IMAGING, P1650, DOI 10.1109/ISBI48211.2021.9434010
   Lu JS, 2019, ADV NEUR IN, V32
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Miyazawa Kazuki, 2020, ARXIV
   Nguyen BX, 2022, IEEE COMPUT SOC CONF, P4557, DOI 10.1109/CVPRW56347.2022.00502
   Ni MH, 2021, Arxiv, DOI arXiv:2006.02635
   Ordonez Vicente, 2011, ANN C NEUR INF PROC
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Pelka O, 2018, LECT NOTES COMPUT SC, V11043, P180, DOI 10.1007/978-3-030-01364-6_20
   Radford Alec, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.00020
   Rahman W, 2020, Arxiv, DOI arXiv:1908.05787
   Su Weijie, 2020, ICLR
   Subramanian Sanjay, 2020, EMPIRICAL METHODS NA
   Sun C, 2019, Arxiv, DOI arXiv:1906.05743
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Wang BR, 2019, AAAI CONF ARTIF INTE, P8909
   Wang JF, 2021, Arxiv, DOI arXiv:2012.06946
   Wang Zifeng, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2210.10163
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Xiujun I, 2020, ECCV
   Yan B, 2022, AAAI CONF ARTIF INTE, P2982
   Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426
   Yu F, 2021, Arxiv, DOI [arXiv:2006.16934, DOI 10.1609/AAAI.V35I4.16431]
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhan LM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2345, DOI 10.1145/3394171.3413761
   Zhang Cha., 2006, ANN C NEUR INF PROC
   Zhang PC, 2021, Arxiv, DOI arXiv:2101.00529
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zhang YH, 2022, Arxiv, DOI [arXiv:2010.00747, 10.48550/arXiv.2010.00747]
   Zhao GX, 2019, Arxiv, DOI arXiv:1911.09483
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu HY, 2021, NEUROCOMPUTING, V465, P371, DOI 10.1016/j.neucom.2021.07.098
NR 78
TC 0
Z9 0
U1 0
U2 0
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD NOV
PY 2023
VL 126
AR 107037
DI 10.1016/j.engappai.2023.107037
PN D
PG 10
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Engineering
GA W0WG2
UT WOS:001088913200001
DA 2023-11-10
ER

PT J
AU Boubeta-Puig, J
   Ortiz, G
   Medina-Bulo, I
AF Boubeta-Puig, Juan
   Ortiz, Guadalupe
   Medina-Bulo, Inmaculada
TI ModeL4CEP: Graphical domain-specific modeling languages for CEP domains
   and event patterns
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Complex event processing; Model-driven development; Domain-specific
   modeling language; Event processing language
ID ARCHITECTURE; IMPLEMENTATION; MANAGEMENT; SYSTEMS
AB Complex event processing (CEP) is a cutting-edge technology that allows the analysis and correlation of large volumes of data with the aim of detecting complex and meaningful events through the use of event patterns, as well as permitting the inference of valuable knowledge for end users. Despite the great advantages that CEP can bring to expert or intelligent business systems, it poses a substantial challenge to their users, who are business experts but do not have the necessary knowledge and experience using this technology. The main problem these users have to face is precisely hand-writing the code for event pattern definition, which requires them to implement the conditions to be met to detect relevant situations for the domain in question by using a particular event processing language (EPL). In order to respond to this need, in this paper we propose both a graphical domain-specific modeling language (DSML) for facilitating CEP domain definitions by domain experts, and a graphical DSML for event pattern definition by non-technological users. The proposed languages provide high expressiveness and flexibility and are independent of event patterns and actions' implementation code. This way, domain experts can define the relevant event types and patterns within their business domain, without having to be experts on EPL programming, nor on other complicated computer science technological issues, beyond an understandable and intuitive graphical definition. Furthermore, with these DSMLs, users will also be able to define the actions to be automatically taken once a pattern is detected in the system. Further benefits of these DSMLs are evaluated and discussed in depth in this paper. (C) 2015 Elsevier Ltd. All rights reserved.
C1 [Boubeta-Puig, Juan; Ortiz, Guadalupe; Medina-Bulo, Inmaculada] Univ Cadiz, Dept Comp Sci & Engn, Cadiz 11519, Spain.
C3 Universidad de Cadiz
RP Boubeta-Puig, J (通讯作者)，Univ Cadiz, Dept Comp Sci & Engn, Avda Univ Cadiz 10, Cadiz 11519, Spain.
EM juan.boubeta@uca.es; guadalupe.ortiz@uca.es; inmaculada.medina@uca.es
RI Medina-Bulo, Inmaculada/L-5523-2014; Ortiz, Guadalupe/K-8601-2014;
   Boubeta-Puig, Juan/L-9429-2014
OI Medina-Bulo, Inmaculada/0000-0002-7543-2671; Ortiz,
   Guadalupe/0000-0002-5121-6341; Boubeta-Puig, Juan/0000-0002-8989-7509
FU Spanish Ministry of Science and Innovation under the National Program
   for Research, Development and Innovation, project MoD-SOA
   [TIN2011-27242]
FX This work was funded by the Spanish Ministry of Science and Innovation
   under the National Program for Research, Development and Innovation,
   project MoD-SOA (TIN2011-27242).
CR ALERT, 2013, ACT SUPP REAL TIM CO
   [Anonymous], 2014, HDB RES DEMAND DRIVE
   [Anonymous], 2012, P 2 INT WORKSH AD SE
   [Anonymous], 2011, EVENT PROCESSING ACT
   [Anonymous], 2010, EVENT PROCESSING DES
   ATKINSON C, 2001, COMPONENT BASED PROD
   Boubera-Puig J, 2014, EXPERT SYST APPL, V41, P445, DOI 10.1016/j.eswa.2013.07.070
   Boubeta-Puig J., 2012, P 2 INT WORKSH AD SE, P1, DOI [10.1145/2377836.2377838, DOI 10.1145/2377836.2377838]
   Boubeta-Puig J., 2011, SERV COMP 2011 3 INT, P143
   BRA, 2007, EV PROC MARK PULS 20
   Bruns R., 2014, DEBS 2014 P 8 ACM IN, P83, DOI [10.1145/2611286.2611296, DOI 10.1145/2611286.2611296]
   Bruns R, 2015, EXPERT SYST APPL, V42, P1235, DOI 10.1016/j.eswa.2014.09.005
   CHAKRAVARTHY S, 1994, DATA KNOWL ENG, V14, P1, DOI 10.1016/0169-023X(94)90006-X
   Chaudhuri S, 2011, COMMUN ACM, V54, P88, DOI 10.1145/1978542.1978562
   Cugola G., 2010, P 4 ACM INT C DISTR, P50, DOI DOI 10.1145/1827418.1827427
   Cugola G, 2015, COMPUTING, V97, P103, DOI 10.1007/s00607-014-0404-y
   Cugola G, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2187671.2187677
   Decker G, 2007, IEEE INT ENTERP DIST, P27, DOI 10.1109/EDOC.2007.41
   Dunkel J, 2011, EXPERT SYST APPL, V38, P6530, DOI 10.1016/j.eswa.2010.11.087
   Eclipse Foundation, 2012, EMF
   EsperTech, 2015, ESP COMPL EV PROC
   Event Processing Technical Society, 2010, EV PROC GLOSS VERS 2
   Fodor P., 2014, ETALIS EVENT DRIVEN
   Fowler M., 2010, DOMAIN SPECIFIC LANG
   Garcia-Molina J., 2013, DESARROLLO SOFTWARE, P289
   IBM, 2014, OP DEC MAN
   JBoss Community, 2014, DROOLS FUS
   Kleppe A. G., 2003, MDA EXPLAINED MODEL
   Luckham D, 2012, EVENT PROCESSING FOR BUSINESS: ORGANIZING THE REAL-TIME ENTERPRISE, P1
   Luckham D., 2002, POWER EVENTS INTRO C
   Mulo E, 2013, SERV ORIENTED COMPUT, V7, P59, DOI 10.1007/s11761-012-0121-3
   Obweger Hannes, 2011, International Journal of Business Process Integration and Management, V5, P344, DOI 10.1504/IJBPIM.2011.043392
   Obweger H., 2010, 2010 IEEE 7th International Conference on Services Computing (SCC 2010), P329, DOI 10.1109/SCC.2010.51
   Oracle, 2015, OR EV PROC
   Ortiz G., 2007, THESIS
   Paschke Adrian, 2014, Rules on the Web. From Theory to Applications. 8th International Symposium, RuleML 2014 Co-located with the 21st European Conference on Artificial Intelligence, ECAI 2014. Proceedings. LNCS: 8620, P1, DOI 10.1007/978-3-319-09870-8_1
   Paschke Adrian, 2012, Rules on the Web: Research and Applications. Proceedings of the 6th International Symposium, RuleML 2012, P100, DOI 10.1007/978-3-642-32689-9_9
   Paschke A., 2009, P AAAI SPRING S INT, P54
   Romero D, 2013, SOFTWARE PRACT EXPER, V43, P1205, DOI 10.1002/spe.1125
   Sen S., 2010, P 4 ACM INT C DISTR, P196, DOI DOI 10.1145/1827418.1827459
   Sen S, 2010, LECT NOTES COMPUT SC, V6051, P209, DOI 10.1007/978-3-642-13094-6_17
   Software AG, 2014, AP AN DEC PLATF
   Stahl T., 2006, MODEL DRIVEN SOFTWAR
   Steinberg D., 2008, EMF ECLIPSE MODELING
   Stühmer R, 2009, LECT NOTES COMPUT SC, V5823, P893, DOI 10.1007/978-3-642-04930-9_56
   Sybase, 2015, SAP SYB EV STREAM PR
   Terroso-Saenz F, 2015, INFORM SYST, V52, P34, DOI 10.1016/j.is.2015.03.005
   Terroso-Sáenz F, 2015, INFORM FUSION, V21, P187, DOI 10.1016/j.inffus.2012.08.008
   TIBCO, 2015, STREAMBASE STUD
   Uhm Y, 2011, EXPERT SYST APPL, V38, P13291, DOI 10.1016/j.eswa.2011.04.150
   Vincent P., 2010, RETURN EXPERT SYSTEM
   von Halle B., 2013, TECHNOLOGY
   W3C, 2014, OWL WEB ONTOLOGY LAN
   W3C, 2014, RDF SCHEM 1 1
   Yao W, 2011, J NETW COMPUT APPL, V34, P799, DOI 10.1016/j.jnca.2010.04.020
   Yuan ST, 2009, EXPERT SYST APPL, V36, P3671, DOI 10.1016/j.eswa.2008.02.024
   Zang CZ, 2008, INFORM SYST FRONT, V10, P543, DOI 10.1007/s10796-008-9109-0
NR 57
TC 23
Z9 23
U1 0
U2 20
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 30
PY 2015
VL 42
IS 21
BP 8095
EP 8110
DI 10.1016/j.eswa.2015.06.045
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA CQ7HB
UT WOS:000360772500069
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Ponti, EM
   O'Horan, H
   Berzak, Y
   Vulic, I
   Reichart, R
   Poibeau, T
   Shutova, E
   Korhonen, A
AF Ponti, Edoardo Maria
   O'Horan, Helen
   Berzak, Yevgeni
   Vulic, Ivan
   Reichart, Roi
   Poibeau, Thierry
   Shutova, Ekaterina
   Korhonen, Anna
TI Modeling Language Variation and Universals: A Survey on Typological
   Linguistics for Natural Language Processing
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Linguistic typology aims to capture structural and semantic variation across the world's languages. A large-scale typology could provide excellent guidance for multilingual Natural Language Processing (NLP), particularly for languages that suffer from the lack of human labeled resources. We present an extensive literature survey on the use of typological information in the development of NLP techniques. Our survey demonstrates that to date, the use of information in existing typological databases has resulted in consistent but modest improvements in system performance. We show that this is due to both intrinsic limitations of databases (in terms of coverage and feature granularity) and under-utilization of the typological features included in them. We advocate for a new approach that adapts the broad and discrete nature of typological categories to the contextual and continuous nature of machine learning algorithms used in contemporary NLP. In particular, we suggest that such an approach could be facilitated by recent developments in data-driven induction of typological knowledge.
C1 [Ponti, Edoardo Maria; O'Horan, Helen; Vulic, Ivan; Korhonen, Anna] Univ Cambridge, LTL, Cambridge, England.
   [Berzak, Yevgeni] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA.
   [Reichart, Roi] Technion IIT, Fac Ind Engn & Management, Haifa, Israel.
   [Poibeau, Thierry] Univ Sorbonne Nouvelle, CNRS, ENS PSL, LATTICE Lab,UPSC, Paris, France.
   [Shutova, Ekaterina] Univ Amsterdam, ILLC, Amsterdam, Netherlands.
C3 University of Cambridge; Massachusetts Institute of Technology (MIT);
   Technion Israel Institute of Technology; Universite PSL; Ecole Normale
   Superieure (ENS); Universite Sorbonne Nouvelle - Paris 3; Centre
   National de la Recherche Scientifique (CNRS); University of Amsterdam
RP Ponti, EM (通讯作者)，Univ Cambridge, LTL, Cambridge, England.
EM ep490@cam.ac.uk; helen.ohoran@gmail.com; berzak@mit.edu;
   iv250@cam.ac.uk; roiri@ie.technion.ac.il; thierry.poibeau@ens.fr;
   e.shutova@uva.nl; alk23@cam.ac.uk
OI Berzak, Yevgeni/0000-0003-4474-1727
CR Agi eljko, 2016, T ASS COMPUTATIONAL
   Agic eljko., 2014, EMNLP 2014 WORKSHOP, P13, DOI [10.3115/v1/W14-4203, DOI 10.3115/V1/W14-4203]
   Agic Z, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P268
   Almeida MSC, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P408
   Ammar Waleed, 2016, T ASS COMPUTATIONAL, V4, P431, DOI DOI 10.1162/TACL_A_00109
   [Anonymous], 1977, STUD LANG, DOI DOI 10.1075/SL.1.1.04DIX
   [Anonymous], 2013, PERFECTIVE IMPERFECT
   [Anonymous], P 50 ANN M ASS COMP
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2012, P 2012 JOINT C EMPIR
   [Anonymous], 2015, P 2015 C EMPIRICAL M
   [Anonymous], 2013, COMPUTER SCI
   [Anonymous], 2012, P 2012 JOINT C EMPIR
   [Anonymous], 2008, HUMAN LANGUAGE TECHN
   [Anonymous], 2010, OXFORD HDB LINGUISTI
   [Anonymous], 2015, P 1 WORKSH VECT SPAC
   [Anonymous], 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1213
   [Anonymous], 2011, ACL HLT 2011 P 49 AN
   [Anonymous], 2016, P 2016 C EMPIRICAL M, DOI DOI 10.18653/V1/D16-1136
   [Anonymous], 2018, J ARTIFICIAL INTELLI
   [Anonymous], 2012, P 50 ANN M ASS COMPU
   [Anonymous], 2010, P 2010 C EMP METH NA
   [Anonymous], 2007, NIPS
   [Anonymous], 2013, P 51 ANN M ASS COMPU
   [Anonymous], 2016, P 1 C MACHINE TRANSL
   [Anonymous], 2010, P 23 INT C COMPUTATI
   [Anonymous], 1996, INTRO BAYESIAN NETWO
   [Anonymous], 1966, UNIVERSALS LANGUAGE
   [Anonymous], 2013, PROC ANN M ASS COMPU
   [Anonymous], 2008, P 46 ANN M ASS COMPU
   [Anonymous], 1988, EXPLAINING LANGUAGE
   [Anonymous], P 2018 C EMP METH LA
   [Anonymous], 2016, ARXIV160306270
   Artetxe Mikel, 2018, ICLR POSTER
   Asgari Ehsaneddin., 2017, P 2017 C EMP METH NA, V2, P113
   Banea C., 2008, P 2008 C EMPIRICAL M, P127
   Bender E. M., 2009, P EACL 2009 WORKSH I, P26
   Bender E. M., 2011, LING ISSUES LANG TEC, DOI DOI 10.33011/LILT.V6I.1239
   Bender EM, 2016, LINGUIST TYPOL, V20, P645, DOI 10.1515/lingty-2016-0035
   Bender EM, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2447
   Bender Emily M, 2013, P 7 WORKSHOP LANGUAG, P74
   Berlin B., 1969, BASIC COLOR TERMS TH
   Berzak Y., 2015, P 19 C COMP NAT LANG, P94
   Berzak Yevgeni, 2014, P CONLL BALT MD, P21
   Bickel B., 2007, LINGUIST TYPOL, V11, P239, DOI [10.1515/LINGTY.2007.018, DOI 10.1515/LINGTY.2007.018]
   Bickel Balthasar, 2015, OXFORD HDB LINGUISTI, P901, DOI DOI 10.1093/OXFORDHB/9780199677078.013.0046
   Bickel Balthasar, 2017, TECHNICAL REPORT
   BJERVA J, 2018, P 2018 C N AM CHAPT, V1, P907, DOI DOI 10.18653/V1/N18-1083
   Bowerman M., 2001, LANG ACQUIS, P475, DOI DOI 10.1017/CBO9780511620669.018
   Bybee J, 2005, LINGUIST REV, V22, P381, DOI 10.1515/tlir.2005.22.2-4.381
   Chang M-W, 2007, ACL, P280
   Chen X., 2018, T ASSOC COMPUT LING, V6, P557, DOI DOI 10.1162/TACL_A_00039
   Cohen Shay B., 2016, SYNTHESIS LECT HUMAN
   Coke Reed, 2016, ABS160308016 CORR
   Collins Chris, 2009, SYNTACTIC STRUCTURES
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Comrie Bernard., 1989, LANGUAGE UNIVERSALS, V2nd edn
   Conneau Alexis, 2018, EMNLP
   Conneau Alexis, 2017, ARXIV171004087
   Copestake Ann, 2005, RES LANGUAGE COMPUTA, V4, P281
   Corbett Greville G., 2010, OXFORD HDB LINGUISTI, P190
   Cotterell R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1182, DOI 10.18653/v1/P17-1109
   Cotterell Ryan, 2018, P 2018 C N AM CHAPT, V1, P37
   Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951
   Cristofaro S., 1999, INTRO TIPOLOGIA LING
   CROFT W, 1995, LANGUAGE, V71, P490, DOI 10.2307/416218
   Croft W., 2017, P 15 INT WORKSH TREE, P6375
   Croft W, 2008, THEOR LINGUIST, V34, P1, DOI 10.1515/THLI.2008.001
   Croft William., 2000, EXPLAINING LANGUAGE
   Croft William, 2003, TYPOLOGY UNIVERSALS, V2
   D'Andrade RG, 1995, DEV COGNITIVE ANTHR
   Daiber Joachim, 2016, P COLING 2016 26 INT, P3167
   Das Dipanjan, 2011, P 49 ANN M ASS COMP, P600
   Daume III Hal, 2007, P 45 ANN M ASS COMPU, P65
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deri A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P399
   diaeresis>om Oscar Tackstr<spacing, 2013, P 2013 C N AM CHAPT, P1061
   Dixon R. M. W., 1994, ERGATIVITY
   Dryer Matthew S., 1998, 33 REG M CHIC LING S, P1
   Duong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P845
   Durham W. H., 1991, COEVOLUTION GENES CU
   Evans N, 2009, BEHAV BRAIN SCI, V32, P429, DOI 10.1017/S0140525X0999094X
   Fang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P587, DOI 10.18653/v1/P17-2093
   Faruqui Manaal., 2015, P 2015 C N AM CHAPT, P1606, DOI [10.3115/v1/N15-1184, DOI 10.3115/V1/N15-1184]
   Fernández AM, 2016, J ARTIF INTELL RES, V55, P131, DOI 10.1613/jair.4762
   Ganchev K, 2010, J MACH LEARN RES, V11, P2001
   Gerz D., 2018, T ASSOC COMPUT LING, V6, P451, DOI DOI 10.1162/TACL_A_00032
   Gerz D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P316
   Goedemans Rob, 2014, STRESSTYP2
   Gouws S, 2015, PR MACH LEARN RES, V37, P748
   Gouws Stephan, 2015, 2015 ANN C N AM CHAP, P1386
   GREENBERG JH, 1966, LANGUAGE, V42, P508, DOI 10.2307/411706
   Greenberg Joseph H., 1963, UNIVERSALS LANG, P73
   Greenberg JosephH., 1978, UNIVERSALS HUMAN LAN, V1, P61
   Guo J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1234
   Guo Jiang, 2016, P COLING 2016 26 INT, P12
   Ha Thanh Le, 2016, P 2016 INT WORKSH SP
   Hammarstrom Harald., 2021, GLOTTOLOG 4 4
   Haspelmath M., 1999, Z SPRACHWISS, V18, P180, DOI [10.1515/zfsw.1999.18.2.180, DOI 10.1515/ZFSW.1999.18.2.180]
   Haspelmath M., 2009, WOLD
   Haspelmath Martin., 2007, LINGUIST TYPOL, V11, P119, DOI [10.1515/LINGTY.2007.011, DOI 10.1515/LINGTY.2007.011]
   Hermann K. M., 2014, P ICLR
   Hu Z, 2016, P 2016 C EMP METH NA, P1670, DOI DOI 10.18653/V1/D16-1173
   Hu ZT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2410, DOI 10.18653/v1/p16-1228
   Hwa R., 2005, Natural Language Engineering, V11, P311, DOI 10.1017/S1351324905003840
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Key Mary Ritchie, 2015, IDS
   Khapra Mitesh M., 2011, P 49 ANN M ASS COMPU, P561
   Klementiev, 2012, P COLING 2012, P1459
   Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108
   Korhonen A, 2017, P 6 JOINT C LEX COMP, P22
   Lauly S., 2013, DEEP LEARN WORKSH NI
   Lefever E., 2011, P 49 ANN M ASS COMP, P317
   Lewis Paul M., 2016, ETHNOLOGUE LANGUAGES, V19
   Lewis W.D., 2008, INT JOINT C NATURAL, P685
   Littel Patrick, 2016, URIEL TYPOLOGICAL DA
   Littell Patrick, 2017, P 2017 C EMP METH NA, P2529, DOI DOI 10.18653/V1/D17-1268
   Liu HT, 2010, LINGUA, V120, P1567, DOI 10.1016/j.lingua.2009.10.001
   Lu X., 2013, ASS COMPUTATIONAL LI, P150
   Maddieson I, 2013, INTERSPEECH, P3021
   Majid A, 2007, COGN LINGUIST, V18, P133, DOI 10.1515/COG.2007.005
   McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI [10.3115/1219840.1219852, DOI 10.3115/1219840.1219852]
   Michaelis S. M., 2013, ATLAS PIDGIN CREOLE
   Moran S., 2014, PHOIBLE ONLINE
   Mrksic Nikola, 2017, T ASS COMPUTATIONAL, V5, P309
   Mrksic Nikola, 2016, NAACL HLT, P142, DOI DOI 10.18653/V1/N16-1018
   MURAWAKI Y, 2017, P 8 INT JOINT C NAT, V1, P451
   Nichols J, 1992, LANGUAGE DIVERSITY S
   Niehues Jan, 2011, P 6 WORKSH STAT MACH, P198
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   OHoran H., 2016, P COLING 2016 26 INT, P1297
   Osborne D., 2016, T ASSOC COMPUT LING, V4, P417
   OSTLING R, 2017, P 15 C EUR CHAPT ASS, V2, P644, DOI DOI 10.18653/V1/E17-2102
   Östling R, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P205
   Pado S., 2005, P HUM LANG TECHN C C, P859, DOI DOI 10.3115/1220575.1220683
   Padó S, 2009, J ARTIF INTELL RES, V36, P307, DOI 10.1613/jair.2863
   Pappas Nikolaos, 2017, 8 INT JOINT C NAT LA, P1015
   Plank Frans, 1996, UNIVERSALS ARCH
   Ponti EM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1531
   Reichart R., 2012, P 2012 C N AM CHAPTE, P70
   Rosa R, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P243
   Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793
   Rotman G, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P910
   Roy R. S., 2014, P COLING, P1037
   Sapir Edward, 2014, LANGUAGE
   Schaufeli WB, 2010, WORK ENGAGEMENT: A HANDBOOK OF ESSENTIAL THEORY AND RESEARCH, P10
   Schone Patrick, 2001, IJCAI 2001 WORKSH TE
   Silberer C., 2010, P 5 INT WORKSH SEM E, P134
   Snyder Ben, 2010, THESIS
   Sogaard Anders, 2012, P COLING 2012, P1181
   Sogaard Anders, 2011, P 49 ANN M ASS COMP, V49, P682
   Sproat R, 2016, LINGUIST TYPOL, V20, P635, DOI 10.1515/lingty-2016-0034
   Tackstrom O., 2012, P 2012 C N AM CHAPT, P477
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Takamura H, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P69
   Talmy Leonard., 1991, P 17 ANN M BERK LING, P480, DOI DOI 10.3765/BLS.V17I0.1620
   Taskar B, 2004, ADV NEUR IN, V16, P25
   Taylor Bradley, 2013, VALENCY PATTERNS LEI
   Teh Y.W., 2007, ADV NEURAL INFORM PR, P1473
   Tiedemann Jorg, 2015, P 3 INT C DEPENDENCY, P340
   Tsvetkov Yulia, 2016, P NAACL SAN DIEG CA, P1357, DOI DOI 10.18653/V1/N16-1161
   Upadhyay S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1661
   Vulic I, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P56, DOI 10.18653/v1/P17-1006
   Vulic I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P719
   Wälchli B, 2012, LINGUISTICS, V50, P671, DOI 10.1515/ling-2012-0021
   Wang D., 2017, T ASS COMPUTATIONAL, V5, P147
   Wang Dingquan, 2016, T ASSOC COMPUT LING, V4, P491
   Wang H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1891
   Wang M, 2014, T ASSOC COMPUT LING, V2, P55, DOI DOI 10.1162/TACLTACLA00165
   Wicentowski R., 2001, P 1 INT C HUM LANG T
   Wichmann Soren, 2018, ASJP DATABASE VERSIO
   Wisniewski G., 2014, P C EMP METH NAT LAN, P1779
   Xiaoand M, 2014, P 18 C COMPUTATIONAL, P119
   Zeljko Agic, 2017, P NODALIDA 2017 WORK, P1
   Zeman Daniel, 2008, P IJCNLP 08 WORKSH N
   Zennaki Othman, 2016, P 26 INT C COMP LING, P450
   Zhang Yuan, 2016, P 2016 C N AM CHAPTE, DOI DOI 10.18653/V1/N16-1156
   Zhang Yuan., 2012, P 2012 JOINT C EMPIR, P1368
   Zhou GY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1426
   Zhou XJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1403
   Ziser Y., 2018, P EMNLP 2018, P238
NR 181
TC 53
Z9 53
U1 4
U2 22
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2019
VL 45
IS 3
BP 559
EP 601
DI 10.1162/coli_a_00357
PG 43
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA JC1KA
UT WOS:000489035700005
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Maucec, MS
   Brest, J
AF Maucec, Mirjam Sepesy
   Brest, Janez
TI Slavic languages in phrase-based statistical machine translation: a
   survey
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Article
DE Statistical machine translation; Morphology; Slavic language;
   Inflection; Free word order
ID SPEECH RECOGNITION; MODELS; INFORMATION; TRENDS
AB The demand for translations is increasing at a rate far beyond the capacity of professional translators. It is too difficult, time consuming and expensive to translate everything from scratch in each language. Machine translation offers a solution, as it provides translation automatically. Until recently, statistical machine translation has proved to be one of the most successful approaches. However, a new approach to machine translation based on neural networks has emerged with promising results. The present paper concerns phrase-based statistical machine translation, an area that has been extensively studied in the literature. The translation system consists of many components built on the premise of probabilities. Each component is described separately. Although high quality translation systems have been developed for certain language pairs, there is still a large number of languages that cause many translation errors. Languages with a rich morphology pose an especially difficult challenge for research. We address one group of morphologically rich languages: Slavic languages, which constitute a relatively homogeneous family of languages characterized by rich, inflectional morphology. The present paper offers a comprehensive survey of approaches to coping with Slavic languages in different aspects of statistical machine translation. We observe that the interest of the community in research of more difficult languages is increasing and we believe that the translation quality of those languages will reach the level of practical use in the near future.
C1 [Maucec, Mirjam Sepesy; Brest, Janez] Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SLO-2000 Maribor, Slovenia.
C3 University of Maribor
RP Maucec, MS (通讯作者)，Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SLO-2000 Maribor, Slovenia.
EM mirjam.sepesy@um.si; janez.brest@um.si
RI Brest, Janez/B-8013-2008
OI Brest, Janez/0000-0001-5864-3533
FU Javna Agencija za Raziskovalno Dejavnost RS [P2-0069, P2-0041]
FX The authors would like to thank the editor and anonymous reviewers for
   their helpful and constructive comments that greatly contributed to
   improving the paper. Funding was provided by Javna Agencija za
   Raziskovalno Dejavnost RS (Grant Nos. P2-0069, P2-0041).
CR 232-239, 2007, IST034291 EUROMATRIX
   Alumäe T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1820
   [Anonymous], 2012, P NAACL HLT 2012 WOR
   [Anonymous], 2016, P 1 C MACH TRANSL, DOI DOI 10.18653/V1/W16-2301
   [Anonymous], 2014, P 14 C EUROPEAN CHAP
   [Anonymous], 2005, P ACL WORKSHOP INTRI
   [Anonymous], 2011, PROC 49 ACL
   [Anonymous], 2012, P 13 C EUROPEAN CHAP
   [Anonymous], 2008, P JOINT 46 ANN M ASS
   [Anonymous], 2012, PROC 50 ANN M ASS CO
   [Anonymous], 2014, ABS14090473 CORR
   [Anonymous], 2014, EACL
   [Anonymous], 2003, HLT NAACL 2003 HUMAN
   [Anonymous], 2015, P 10 WORKSHOP STAT M
   [Anonymous], 2013, P 2013 C EMP METH NA
   Aran M, 2016, P C LANG TECHN DIG H, P13
   Baerman M., 2015, OXFORD HDB INFLECTIO
   Berovi D., 2013, P 4 WORKSHOP STAT PA, P22
   Bertoldi N, 2010, PRAGUE B MATH LINGUI, V91, P7
   Bhala RVV, 2014, ARTIF INTELL REV, V42, P159, DOI 10.1007/s10462-012-9331-5
   Bilmes J. A., 2003, P C N AM CHAPT ASS C, P4, DOI DOI 10.3115/1073483.1073485
   Bisazza A, 2014, P COLING 2014 25 INT, P1918
   Bohnet B, 2013, T ASS COMPUT LINGUIS, V1, P429
   Bojar Ondrej, 2014, Prague Bulletin of Mathematical Linguistics, P71, DOI 10.2478/pralin-2014-0005
   Bojar Ondrej, 2011, Prague Bulletin of Mathematical Linguistics, P63, DOI 10.2478/v10108-011-0005-2
   Bojar O, 2013, P 8 WORKSH STAT MACH, P92
   Bojar O., 2006, P LREC GEN IT 22 28, P1236
   Bojar O., 2012, P 7 WORKSH STAT MACH, P253
   Bojar O., 2008, P 3 WORKSH STAT MACH, P143
   Bojar O, 2007, P 2 WORKSH STAT MACH, P232
   Bojar O, 2011, RES WORKSH ISR SCI F
   Bojar O, 2012, P 6 WORKSH SYNT SEM, P30
   Bojar Ond .rej, 2010, P ACL ACL UPPS, P86
   Bojar O, 2006, LECT NOTES ARTIF INT, V4139, P214
   Bojar O, 2013, LECT NOTES COMPUT SC, V8082, P465, DOI 10.1007/978-3-642-40585-3_59
   Botha JA, 2014, PR MACH LEARN RES, V32, P1899
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Brychcin T., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P560, DOI 10.1109/IDAACS.2011.6072829
   Brychcín T, 2015, INFORM PROCESS MANAG, V51, P68, DOI 10.1016/j.ipm.2014.08.006
   Burlot F, 2015, P 12 INT WORKSH SPOK, P188
   Cettolo M., 2015, INT WORKSH SPOK LANG
   Chahuneau Victor, 2013, HLT NAACL, P1206
   Chen S. F., 1998, TR1098 HARV U COMP S
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Cholakov K., 2014, P C EMP METH NAT LAN, P196
   Chung J, 2016, P 1 C MACH TRANSL AS, P268
   Costa-jussà MR, 2015, J ASSOC INF SCI TECH, V66, P2160, DOI 10.1002/asi.23517
   Costa-Jussà MR, 2015, COMPUT SPEECH LANG, V32, P3, DOI 10.1016/j.csl.2014.11.001
   Del Gaudio R., 2016, WMT, P435
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348
   Ding Shuoyang, 2016, P 1 C MACH TRANSL BE, P272
   Donaj G, 2016, LANGUAGE MODELING AU
   Dove C., 2012, P 11 C ASS MACH TRAN
   Duc Tam Hoang, 2015, Prague Bulletin of Mathematical Linguistics, P75, DOI 10.1515/pralin-2015-0015
   Dugonik J, 2014, 2014 IEEE SYMPOSIUM ON DIFFERENTIAL EVOLUTION (SDE), P89
   DURRANI N, 2013, P 51 ANN M ASS COMP, P399
   Durrani N, 2015, COMPUT LINGUIST, V41, P185, DOI 10.1162/COLI_a_00218
   Durrani Nadir, 2014, P 25 ANN C COMP LING, P421
   Dusek O., 2012, P 7 ACL WORKSH STAT, P267
   Dyer Chris, 2013, P 2013 C N AM CHAPTE, P644
   Eisele A., 2008, P 3 WORKSH STAT MACH, P179
   Farrús M, 2012, J AM SOC INF SCI TEC, V63, P174, DOI 10.1002/asi.21674
   Felice M, 2013, MACH TRANSL, V27, P193, DOI 10.1007/s10590-013-9137-5
   Fishel M, 2009, P C PAC ASS COMP LIN
   Galuscáková P, 2012, FRONT ARTIF INTEL AP, V247, P58, DOI 10.3233/978-1-61499-133-5-58
   Gao JF, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P699
   Gao Qin, 2008, SOFTWARE ENG TESTING, P49, DOI [DOI 10.3115/1622110.1622119, 10.3115/1622110.1622119]
   Genzel Dmitriy, 2010, P 23 INT C COMPUTATI, P376
   Giménez J, 2010, MACH TRANSL, V24, P209, DOI 10.1007/s10590-011-9088-7
   Gimpel K, 2014, COMPUT LINGUIST, V40, P349, DOI [10.1162/COLI_a_00175, 10.1162/coli_a_00175]
   GOLDWATER S, 2005, P HUM LANG TECHN C C, P676
   Graham Y., 2010, P 7 INT WORKSH SPOK, P275
   Green N., 2011, 49 ANN M ASS COMPUTA, P69
   Hammarström H, 2011, COMPUT LINGUIST, V37, P309, DOI 10.1162/COLI_a_00050
   Hirsimäki T, 2009, IEEE T AUDIO SPEECH, V17, P724, DOI 10.1109/TASL.2008.2012323
   Ho CF, 2014, ARTIF INTELL REV, V42, P851, DOI 10.1007/s10462-012-9357-8
   Hoang C., 2014, P COLING 2014 25 INT, P1928
   Homola P, 2008, P 21 INT FLOR ART IN, P227
   Huet S, 2013, P 8 WORKSH STAT MACH, P154
   Hunsicker S., 2012, P 7 WORKSH STAT MACH, P312
   Ircing P., 2001, P EUR C SPEECH COMM, V1, P487
   Ircing P, 2009, IEEE T AUDIO SPEECH, V17, P840, DOI 10.1109/TASL.2009.2014217
   *ISO, 1995, 91995 ISO
   Jawaid B, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P682
   Jeong Minwoo, 2010, 9 C ASS MACH TRANSL
   Joty Shafiq, 2014, P 9 WORKSH STAT MACH, P402
   Juhar J., 2012, NEW TECHNOLOGIES TRE, P261, DOI DOI 10.5772/32623
   Junczys-Dowmunt M., 2011, INT JOINT C SEC INT, P379
   Junczys-Dowmunt Marcin, 2016, P 1 C MACH TRANSL, P319
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kapociute-Dzikiene J., 2013, P 4 WORKSH STAT PARS, P12
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Kazi M, 2014, P INT WORKSH SPOK LA, P65
   Kipyatkova I, 2014, LECT NOTES ARTIF INT, V8773, P451, DOI 10.1007/978-3-319-11581-8_56
   Kirchhoff K, 2006, P TC STAR WORKSH SPE
   Kneser R, 1993, P 3 EUR C SPEECH COM, P22
   Koehn P, 2012, P 10 C ASS MACH TRAN
   Koehn Philipp, 2007, P 2007 JOINT C EMP M
   Koehn Philipp, 2011, STAT MACHINE TRANSLA
   Kolovratnik D, 2009, ITAT 2009 INFORM TEC, P31
   Kos Kamil, 2009, Prague Bulletin of Mathematical Linguistics, P135, DOI 10.2478/v10108-009-0026-2
   Kos Kamil, 2010, P JOINT 5 WORKSH STA, P60
   Kubon V., 2014, P C LANG TECHN CLOS, P92
   Labaka G, 2014, MACH TRANSL, V28, P91, DOI 10.1007/s10590-014-9153-0
   Lembersky G, 2012, COMPUT LINGUIST, V38, P799, DOI 10.1162/COLI_a_00111
   Lerner U, 2013, P 2014 C EMP METH NA, P513
   Libovicky J, 2015, P 9 WORKSH STAT MACH, P409
   Lo Chi-kiu, 2016, P 1 C MACH TRANSL BE, P326
   Luong T., 2013, P 17 C COMP NAT LANG, P104, DOI DOI 10.1007/BF02579642
   Macherey K, 2011, P 49 ANN M ASS COMP, P1395
   Majewski P, 2008, LECT NOTES ARTIF INT, V5246, P397, DOI 10.1007/978-3-540-87391-4_51
   Marasek K, 2012, P 9 INT WORKSH SPOK, P126
   Marecek David, 2011, P 6 WORKSH STAT MACH, P426
   Mariño JB, 2006, COMPUT LINGUIST, V32, P527, DOI 10.1162/coli.2006.32.4.527
   Maucec MS, 2014, PATTERN RECOGN LETT, V46, P96, DOI 10.1016/j.patrec.2014.05.012
   Maucec MS, 2010, INFORMATICA-LITHUAN, V21, P95
   Mauec MS, 2016, P ART INT NAT LANG C, P99
   McDonald R, 2011, COMPUT LINGUIST, V37, P197, DOI 10.1162/coli_a_00039
   Mikolov T., 2013, P 2013 C N AM CHAPT, P746
   Mikolov T, 2009, INT CONF ACOUST SPEE, P4725, DOI 10.1109/ICASSP.2009.4960686
   Mikowski M, 2012, WHITE PAPER SERIES
   Minkov Einat., 2007, P 45 ANN M ASS COMPU, P128
   Molchanov A, 2016, P 1 C MACH TRANSL AS, P339
   Morchid M, 2014, P 11 INT WORKSH SPOK, P80
   Muller Thomas, 2012, P NAACL HLT, P386
   Munkova D, 2014, I C APPL INF COMM TE, P447
   Munková D, 2015, LECT NOTES ARTIF INT, V9227, P481, DOI 10.1007/978-3-319-22053-6_51
   Niehues Jan, 2011, P 6 WORKSH STAT MACH, P198
   Nivre J., 2007, Natural Language Engineering, V13, P95, DOI 10.1017/S1351324906004505
   Nivre J, 2015, LECT NOTES COMPUT SC, V9041, P3, DOI 10.1007/978-3-319-18111-0_1
   Novak M., 2013, P WORKSH DISC MACH T, P51
   Novák V, 2007, LECT NOTES ARTIF INT, V4629, P92
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Oparin I., 2008, THESIS
   Oparin I, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P189, DOI 10.1109/SLT.2008.4777872
   Papineni K, 2004, RC22176W0109022 IBM
   Popel M, 2011, P 6 WORKSH STAT MACH, P433
   Popel M, 2010, LECT NOTES ARTIF INT, V6233, P293, DOI 10.1007/978-3-642-14770-8_33
   Popovi M, 2015, 18 ANN C EUR ASS MAC, P105
   Popovic Maja, 2011, Prague Bulletin of Mathematical Linguistics, P59, DOI 10.2478/V10108-011-0011-4
   Popovic M., 2004, P 4 INT C LANG RES E, P1585
   Popovic M., 2015, P 18 ANN C EUR ASS M, P97
   Popovic M, 2011, COMPUT LINGUIST, V37, P657, DOI 10.1162/COLI_a_00072
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.1080/1472586x.2015.1113070.
   Popovic Maja, 2014, P C LANG TECHN CLOS, P76
   Prochazka V, 2011, RADIOENGINEERING, V20, P1002
   RishOj C, 2011, P 6 WORKSH STAT MACH, P447
   Rosa R., 2012, P 7 WORKSH STAT MACH, P362
   Rosa R, 2016, P 1 C MACH TRANSL AS, P449
   Rotovnik T, 2007, SPEECH COMMUN, V49, P437, DOI 10.1016/j.specom.2007.02.010
   Ruth J, 2011, P 2 INT WORKSH FREE, P69
   Seeker W, 2013, COMPUT LINGUIST, V39, P23, DOI 10.1162/COLI_a_00134
   Sennrich R., 2015, P T ASS COMP LING, V3, P169
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sennrich Rico, 2016, P 1 C MACHINE TRANSL, V2, P371, DOI DOI 10.18653/V1/W16-2323
   Shaik MAB, 2011, INT CONF ACOUST SPEE, P4680
   Shalonova K, 2009, IEEE T AUDIO SPEECH, V17, P956, DOI 10.1109/TASL.2009.2015694
   Shin E, 2013, P 10 INT WORKSH SPOK, P288
   Simova I., 2013, P MT SUMMIT 14 WORKS
   Slawik I, 2015, 18 ANN C EUR ASS MAC, P105
   Snover  M., 2006, 5 C ASS MACH TRANSL
   Son L. H., 2012, P 2012 C N AM CHAPT, P39
   Stanojevic M., 2014, P 9 WORKSHOP STAT MA, P414, DOI [DOI 10.3115/V1/W14-3354, 10.3115/v1/W14-3354]
   Tamchyna A, 2015, P ACL 2015 4 WORKSH, P11
   Tiedemann Jorg., 2014, 18 C COMPUTATIONAL N, P130, DOI [10.3115/v1/W14-1614, DOI 10.3115/V1/W14-1614]
   Tillmann C, 2013, NAT LANG ENG, V19, P33, DOI 10.1017/S135132491100026X
   Tillmann Christoph, 2004, P HLT NAACL, P101
   Toral A, 2015, COMPUT SPEECH LANG, V32, P11, DOI 10.1016/j.csl.2014.10.002
   Toutanova K, 2008, P C ASS COMP LING HU, P514
   TRAN KM, 2014, P EMNLP 2014, P1676
   Tsvetkov Yulia, 2013, P 8 WORKSH STAT MACH, P271
   Vaswani Ashish, 2012, P 50 ANN M ASS COMP, V1, P311
   Vazhenina D, 2013, 2013 INTERNATIONAL JOINT CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY & UBI-MEDIA COMPUTING (ICAST-UMEDIA), P205, DOI 10.1109/ICAwST.2013.6765434
   Virpioja S, 2010, P JOINT 5 WORKSH STA, P195
   Wang L., 2014, SCI WORLD J, V2014
   Wang R., 2012, P EACL JOINT WORKSH, P119
   Wang R, 2016, ACM T ASIAN LOW-RESO, V15, DOI 10.1145/2843942
   Wang R, 2015, IEEE-ACM T AUDIO SPE, V23, P1209, DOI 10.1109/TASLP.2015.2425220
   Weller M, 2013, P 8 WORKSH STAT MACH, P232
   Williams P, 2016, SYNTHESIS LECT HUMAN, V9, P1, DOI [10.2200/s00716-d1v04y201604hlt033, DOI 10.2200/S00716-D1V04Y201604HLT033]
   Wok K, 2013, P INT WORKSH SPOK LA
   Wok K, 2015, COMPUT MED IMAG GRAP, V46, P249
   Wok K, 2015, P INT WORKSH SPOK LA, P101
   Wolk Krzysztof, 2015, Foundations of Intelligent Systems. 22nd International Symposium, ISMIS 2015. Proceedings: LNCS 9384, P433, DOI 10.1007/978-3-319-25252-0_46
   Wolk Krzysztof, 2014, Lecture Notes on Information Theory, V2, P191, DOI 10.12720/lnit.2.2.191-197
   Wolk K., 2014, P 11 INT WORKSH SPOK, P143, DOI DOI 10.13140/RG.2.1.1128.9204
   Wolk K, 2015, PROCEDIA COMPUT SCI, V64, P2, DOI 10.1016/j.procs.2015.08.456
   Wróblewska A, 2011, STUD COMPUT INTELL, V369, P123
   Wu X, 2014, P 9 WORKSH STAT MACH, P420
   Xiong D, 2015, NAT LANG ENG, V21, P201, DOI 10.1017/S1351324913000168
   Zabokrtsky Z., 2008, P 3 WORKSH STAT MACH, P167
   Zeman Daniel, 2011, Prague Bulletin of Mathematical Linguistics, P79, DOI 10.2478/v10108-011-0013-2
   Zens Richard, 2006, P WORKSH STAT MACH T, P55
   [No title captured]
NR 196
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
EI 1573-7462
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD JAN
PY 2019
VL 51
IS 1
BP 77
EP 117
DI 10.1007/s10462-017-9558-2
PG 41
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HI5VG
UT WOS:000456521600005
DA 2023-11-10
ER

PT J
AU Nihal, RA
   Rahman, S
   Broti, NM
   Deowan, SA
AF Nihal, Ragib Amin
   Rahman, Sejuti
   Broti, Nawara Mahmood
   Deowan, Shamim Ahmed
TI Bangla Sign alphabet recognition with zero-shot and transfer learning
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Bangla sign language; Deep learning; Recognition; Large dataset;
   Convolutional neural network
ID CLASSIFICATION; SCALE
AB Bangla, being the fifth most spoken language in the world has its own distinct sign language with two methods (one-handed and two-handed) of representation. However, a standard automatic recognition system of Bangla sign language (BdSL) is still to be achieved. Though widely studied and explored by researchers in the past years, certain unaddressed issues like identifying unseen signs and both types of BdSL or lack of evaluation of the models in versatile environmental conditions demarcate the real-world implementation of the automatic recognition of BdSL. To find a probable solution to the shortcomings in the existing works, this paper proposes two approaches based on conventional transfer learning and contemporary Zero-shot learning (ZSL) for automatic BdSL alphabet recognition of both seen and unseen data. The performance of the proposed system is evaluated for both types of Bangla sign representations as well as on a large dataset with 35,149 images from over 350 subjects, varying in terms of backgrounds, camera angle, light contrast, skin tone, hand size, and orientation. For the ZSL approach, a new semantic descriptor dedicated to BdSL is created and a split of the dataset into seen and unseen classes is proposed. Our model achieved 68.21%, 91.57%, and 54.34% of harmonic mean accuracy, seen accuracy, and zero-shot accuracy with six unseen classes respectively. For the transfer learning-based approach, we found pre-trained DenseNet201 architecture to be the best performing feature extractor and Linear Discriminant Analysis as the best classifier with an overall accuracy of 93.68% on the large dataset after conducting quantitative experimentation on 18 CNN architectures and 21 classifiers. The satisfactory result from our models supports its very probative potential to serve extensively for the hearing and speaking impaired community. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Nihal, Ragib Amin; Rahman, Sejuti; Broti, Nawara Mahmood; Deowan, Shamim Ahmed] Univ Dhaka, Dept Robot & Mechatron Engn, Dhaka 1000, Bangladesh.
C3 University of Dhaka
RP Rahman, S (通讯作者)，Univ Dhaka, Dept Robot & Mechatron Engn, Dhaka 1000, Bangladesh.
EM sejuti.rahman@du.ac.bd
RI Broti, Nawara Mahmood/IAN-3551-2023
OI Broti, Nawara Mahmood/0000-0002-0917-335X
CR Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Aziz KE, 2017, 2017 6TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION & 2017 7TH INTERNATIONAL SYMPOSIUM IN COMPUTATIONAL MEDICAL AND HEALTH TECHNOLOGY (ICIEV-ISCMHT)
   Bilge Y.C., 2019, ARXIV PREPRINT ARXIV
   Bossard B, 2003, LECT NOTES ARTIF INT, V2915, P90
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Cheraghian A., 2019, P MVA 2019 16 INT C
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Goldberg Y., 2014, CORR
   Hill J, 2020, NAT ELECTRON, V3, P512, DOI 10.1038/s41928-020-0451-7
   Hoque OB, 2018, 2018 INTERNATIONAL CONFERENCE ON INNOVATION IN ENGINEERING AND TECHNOLOGY (ICIET)
   Islam M.S., 2018, P 2018 INT C BANGLA, DOI [10.1109/ICBSLP.2018.8554466, DOI 10.1109/ICBSLP.2018.8554466]
   Islam M, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON MECHATRONICS ENGINEERING (ICOM), P1, DOI [10.1109/icom47790.2019.8952046, 10.1109/3ict.2019.8910301]
   Jarman A.M., 2015, INT J ELECT INFORMAT, V4, P1
   Jiaxi Wu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P456, DOI 10.1007/978-3-030-58517-4_27
   KNUTH DE, 1992, AM MATH MON, V99, P403, DOI 10.2307/2325085
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Madapana Naveen, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P754, DOI 10.1145/3382507.3421161
   Madapana N., 2017, P 19 ACM INT C MULT, P331
   Medar R., 2017, ICCUBEA IEEE, P1
   Nicodemus B, 2017, SIGN LANG STUD, V17, P143, DOI 10.1353/sls.2017.0000
   Nihal R.A., 2021, SN COMPUT SCI, V2, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Rafi A.M., 2019, GHTC, P1
   Rahaman MA, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-018-7253-3
   Rahaman MA, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P192, DOI 10.1109/ICCITechn.2014.7073150
   Rony AJ, 2018, INT CONF ELECTR ENG, P74, DOI 10.1109/CEEICT.2018.8628158
   Sadik F., 2019, 2019 5 IEEE INT WIE, P1
   Uddin J., 2017, EICT IEEE, P1
   Urmee PP, 2019, 2019 5TH IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (WIECON-ECE 2019), DOI 10.1109/wiecon-ece48653.2019.9019934
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wu JT, 2018, LECT NOTES COMPUT SC, V11305, P244, DOI 10.1007/978-3-030-04221-9_22
NR 35
TC 5
Z9 5
U1 4
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD OCT
PY 2021
VL 150
BP 84
EP 93
DI 10.1016/j.patrec.2021.06.020
EA JUL 2021
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UO5CG
UT WOS:000694711500010
DA 2023-11-10
ER

PT J
AU Pan, RH
   García-Díaz, JA
   Garcia-Sanchez, F
   Valencia-García, R
AF Pan, Ronghao
   Garcia-Diaz, Jose Antonio
   Garcia-Sanchez, Francisco
   Valencia-Garcia, Rafael
TI Evaluation of transformer models for financial targeted sentiment
   analysis in Spanish
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Natural language processing; Financial domain;
   Targeted sentiment analysis
ID LANGUAGE
AB Nowadays, financial data from social media plays an important role to predict the stock market. However, the exponential growth of financial information and the different polarities of sentiment that other sectors or stakeholders may have on the same information has led to the need for new technologies that automatically collect and classify large volumes of information quickly and easily for each stakeholder. In this scenario, we conduct a targeted sentiment analysis that can automatically extract the main economic target from financial texts and obtain the polarity of a text towards such main economic target, other companies and society in general. To this end, we have compiled a novel corpus of financial tweets and news headlines in Spanish, constituting a valuable resource for the Spanish-focused research community. In addition, we have carried out a performance comparison of different Spanish-specific large language models, with MarIA and BETO achieving the best results. Our best result has an overall performance of 76.04%, 74.16%, and 68.07% in macro F1-score for the sentiment classification towards the main economic target, society, and other companies, respectively, and an accuracy of 69.74% for target detection. We have also evaluated the performance of multi-label classification models in this context and obtained a performance of 71.13%.
C1 [Pan, Ronghao; Garcia-Diaz, Jose Antonio; Garcia-Sanchez, Francisco; Valencia-Garcia, Rafael] Univ Murcia, Fac Informat, Murcia, Spain.
C3 University of Murcia
RP Valencia-García, R (通讯作者)，Univ Murcia, Fac Informat, Murcia, Spain.
EM valencia@um.es
RI Valencia-Garcia, Rafael/L-4759-2014
OI Valencia-Garcia, Rafael/0000-0003-2457-1791
FU MCIN/AEI [PDC2021-121112-I00, TED2021-131167B-I00]; European Union
   NextGenerationEU/PRTR; Seneca Foundation-the Regional Agency for Science
   and Technology of Murcia (Spain); Banco Santander; University of Murcia;
    [20963/PI/18];  [PID2019-107652RB-I00/AEI]
FX This work is part of the research projects AIInFunds
   (PDC2021-121112-I00) and LT-SWM (TED2021-131167B-I00) funded by
   MCIN/AEI/10.13039/501100011033 and by the European Union
   NextGenerationEU/PRTR. This work is also part of the research project
   LaTe4PSP (PID2019-107652RB-I00/AEI/10.13039/501100011033) funded by
   MCIN/AEI/10.13039/501100011033. Besides, it was supported by the Seneca
   Foundation-the Regional Agency for Science and Technology of Murcia
   (Spain) -through project 20963/PI/18. In addition, Jose Antonio
   Garcia-Diaz is supported by Banco Santander and the University of Murcia
   through the Doctorado Industrial programme. The funders had no role in
   study design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Paredes-Valverde MA, 2017, SCI PROGRAMMING-NETH, V2017, DOI 10.1155/2017/1329281
   García-Díaz JA, 2022, FUTURE GENER COMP SY, V130, P59, DOI 10.1016/j.future.2021.12.011
   García-Díaz JA, 2020, PROCES LENG NAT, P139, DOI 10.26342/2020-65-22
   Arratia-Quesada AA, 2021, PREDICCIONESFINANCIE, P137
   Barnes J., 2022, P 16 INT WORKSHOP SE
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Bozinovski S, 2020, INFORM-INT J COMPUT, V44, P291, DOI 10.31449/inf.v44i3.2828
   Brauwers G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3503044
   Canete J., 2020, PML4DC ICLR
   Cañete J, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4291
   Chiang CH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6813
   Martínez-Seis BC, 2022, COMPUT SIST, V26, P899, DOI [10.13053/CyS-26-2-4258, 10.13053/cys-26-2-4258]
   Conneau Alexis, 2019, ARXIV191102116
   de la Rosa J, 2022, PROCES LENG NAT, P13, DOI 10.26342/2022-68-1
   Salas-Zárate MD, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/5140631
   Salas-Zárate MD, 2017, J INF SCI, V43, P458, DOI 10.1177/0165551516645528
   Salas-Zárate MD, 2014, J INF SCI, V40, P749, DOI 10.1177/0165551514547842
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du N., 2022, INT C MACHINE LEARNI, V162, P5547
   Garcia-Diaz JA, 2023, IEEE ACCESS, V11, P14211, DOI 10.1109/ACCESS.2023.3244065
   Goodell JW, 2023, J BEHAV EXP FINANC, V37, DOI [10.1016/j.jbef.2022.100722, DOI 10.1016/J.JBEF.2022.100722]
   Gutiérrez-Fandiño A, 2022, PROCES LENG NAT, P39, DOI 10.26342/2022-68-3
   Hamborg F, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1663
   Kalyan K. S., 2021, ARXIV
   Kharde V., 2016, INT J COMPUTER APPL, V139, P5, DOI [DOI 10.5120/IJCA2016908625, 10.5120/ijca2016908625]
   Lan Zhenzhong, 2019, ARXIV190911942
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Liaw R, 2018, Arxiv, DOI [arXiv:1807.05118, 10.48550/ARXIV.1807.05118, DOI 10.48550/ARXIV.1807.05118]
   Ligthart A, 2021, ARTIF INTELL REV, V54, P4997, DOI 10.1007/s10462-021-09973-3
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Milne A, 2013, SSRN ELECT J, V1, P9, DOI [10.2139/ssrn.2325362, DOI 10.2139/SSRN.2325362]
   Mutlu MM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): STUDENT RESEARCH WORKSHOP, P467
   Nemes L, 2021, J INFORM TELECOMMUN, V5, P375, DOI 10.1080/24751839.2021.1874252
   Orbach M, 2021, P 2021 C EMP METH NA
   Angel SO, 2021, DATA TECHNOL APPL, V55, P461, DOI 10.1108/DTA-09-2020-0200
   Othan D., 2019, PROC ICIIT, P30
   Paul A, 2016, IEEE WIREL COMMUN, V23, P68, DOI 10.1109/MWC.2016.7721744
   Peñalver-Martinez I, 2014, EXPERT SYST APPL, V41, P5995, DOI 10.1016/j.eswa.2014.03.022
   Pilar GD, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118817
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Sonkiya P., 2021, ARXIV
   Tetlock PC, 2007, J FINANC, V62, P1139, DOI 10.1111/j.1540-6261.2007.01232.x
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Vaswani A, 2017, ADV NEUR IN, V30
   Veres C, 2022, IEEE ACCESS, V10, P61970, DOI 10.1109/ACCESS.2022.3182505
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483
   Yang K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116847
   Yi JY, 2019, INT CONF ACOUST SPEE, P7270, DOI 10.1109/ICASSP.2019.8682260
NR 49
TC 0
Z9 0
U1 3
U2 3
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD MAY 9
PY 2023
VL 9
AR e1377
DI 10.7717/peerj-cs.1377
PG 33
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H5LY1
UT WOS:000996387100005
PM 37346571
OA Green Published, gold
DA 2023-11-10
ER

PT S
AU Yuan, W
   Gao, JF
   Suzuki, H
AF Yuan, W
   Gao, JF
   Suzuki, H
BE Dale, R
   Wong, KF
   Su, J
   Kwong, OY
TI An empirical study on language model adaptation using a metric of domain
   similarity
SO NATURAL LANGUAGE PROCESSING - IJCNLP 2005, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 2nd International Joint Conference on Natural Language Processing
CY OCT 11-13, 2005
CL Cheju Isl, SOUTH KOREA
SP Jeju Provine Local Govt, Korea Adv Inst Sci & Technol, Korea Inst Sci & Technol Informat, Elet & Telecomm Res Inst, Microsoft Korea, Microsoft Japan, Mobico & Sysmeta
AB This paper presents an empirical study on four techniques of language model adaptation, including a maximum a posteriori (MAP) method and three discriminative training models, in the application of Japanese Kana-Kanji conversion. We compare the performance of these methods from various angles by adapting the baseline model to four adaptation domains. In particular, we attempt to interpret the results given in terms of the character error rate (CER) by correlating them with the characteristics of the adaptation domain measured using the information-theoretic notion of cross entropy. We show that such a metric correlates well with the CER performance of the adaptation methods, and also show that the discriminative methods are not only superior to a MAP-based method in terms of achieving larger CER reduction, but are also more robust against the similarity of background and adaptation domains.
C1 Shanghai Jiao Tong Univ, Shanghai 200030, Peoples R China.
   Microsoft Res Asia, Beijing 100080, Peoples R China.
   Microsoft Res, Redmond, WA 98052 USA.
C3 Shanghai Jiao Tong University; Microsoft Research Asia; Microsoft;
   Microsoft
RP Yuan, W (通讯作者)，Shanghai Jiao Tong Univ, 1954 Huashan Rd, Shanghai 200030, Peoples R China.
EM sunnyuanovo@sjtu.edu.cn; jfgao@microsoft.com; hisamis@microsoft.com
CR BACCHIANI M, 2003, ICASSP, P224
   BACCHIANI M, 2004, HLT NAACL, P21
   Bellegarda J. R., 2001, P ISCA WORKSH AD MET, P165
   Collins M., 2002, EMNLP
   COLLINS M, 2002, RANKING ALGORITHMS N
   Dagan I, 1999, MACH LEARN, V34, P43, DOI 10.1023/A:1007537716579
   Gao J., 2002, ACM T ASIAN LANGUAGE, V1, P3
   GAO J, 2005, IN PRESS MINIMUM SAM
   Lee L., 1999, P 37 ANN M ASS COMPU, P25, DOI [DOI 10.3115/1034678.1034693, 10.3115/1034678.1034693]
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   ROARK B, 2004, ICASSP, P749
NR 12
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-29172-5
J9 LECT NOTES ARTIF INT
PY 2005
VL 3651
BP 957
EP 968
PG 12
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BDF92
UT WOS:000233302600083
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Wang, X
   Zhao, Y
   Zeng, GP
   Xiao, P
   Wang, ZL
AF Wang, Xi
   Zhao, Yu
   Zeng, Guangping
   Xiao, Peng
   Wang, Zhiliang
TI Study on the classification problem of the coping stances in the Satir
   model based on machine learning
SO JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE The coping stances; the ICTCLAS; Satir model; psychological counselling
   database
AB This paper applies machine learning technology to the Satir theory model and intelligently classifies the communication stances of the second layer according to the language and behaviour information of the first layer. We arranged a large number of dialogical language materials from a TV interview programme and used the ICTCLAS Chinese word segmentation system to create a 'psychological consultation database'. We construct the word training set by part of making use of speech filtering and text word vectorisation, and construct the semantic training set by annotating the original data with the Satir model. These two sets form the Satir communication posture classification training set. Experimental results show that the success rate of classification of four inconsistent coping stances reached 70.37%, 75.92%, 83.33%, and 77.78%.
C1 [Wang, Xi; Zhao, Yu; Zeng, Guangping; Xiao, Peng; Wang, Zhiliang] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Wang, ZL (通讯作者)，Univ Sci & Technol Beijing, Sch Comp & Commun Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
EM wzl@ustb.edu.cn
RI Zeng, Guangping/GSO-0529-2022; Liu, Junyang/A-9731-2018
OI Liu, Junyang/0000-0002-7252-1900; Xiao, Peng/0000-0001-9774-8629
CR Abdollahi R, 2014, J ELECTR ENG-SLOVAK, V65, P228, DOI 10.2478/jee-2014-0035
   Asano M, 2015, FOUND PHYS, V45, P1362, DOI 10.1007/s10701-015-9929-y
   Endres-Niggemeyer B, 2013, INFORM-WISS PRAX, V64, P311, DOI 10.1515/iwp-2013-0047
   Fitter M. J., 1982, Behaviour and Information Technology, V1, P81, DOI 10.1080/01449298208914438
   Ismail Issham, 2010, International Journal of Interactive Mobile Technologies, V4, P31, DOI 10.3991/ijim.v4i4.1408
   Rajan K, 2015, ANNU REV MATER RES, V45, P153, DOI 10.1146/annurev-matsci-070214-021132
   Riva G, 2007, STUD HEALTH TECHNOL, V125, P394
   Satir V., 1991, SATIR MODEL FAMILY T
   Schiaffonati V, 2003, MIND MACH, V13, P537, DOI 10.1023/A:1026252817929
   Tai K, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-39
   Wang Z.L., 2006, ARTIFICAL PSYCHOL
   Wang Z.L., 2006, CAAI T INTELLIGENT S, V1, P38, DOI https://doi.org/10.3969/j.issn.1673-4785.2006.01.006
   Yanco HA, 2015, J FIELD ROBOT, V32, P420, DOI 10.1002/rob.21568
NR 13
TC 0
Z9 0
U1 1
U2 10
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0952-813X
EI 1362-3079
J9 J EXP THEOR ARTIF IN
JI J. Exp. Theor. Artif. Intell.
PD JAN 2
PY 2023
VL 35
IS 1
BP 129
EP 149
DI 10.1080/0952813X.2021.1960628
EA FEB 2022
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9YG
UT WOS:000754507700001
DA 2023-11-10
ER

PT J
AU Liu, FY
   Emerson, G
   Collier, N
AF Liu, Fangyu
   Emerson, Guy
   Collier, Nigel
TI Visual Spatial Reasoning
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Spatial relations are a basic part of human cognition. However, they are expressed in natural language in a variety of ways, and previous work has suggested that current vision-and-language models (VLMs) struggle to capture relational information. In this paper, we present Visual Spatial Reasoning (VSR), a dataset containing more than 10k natural text-image pairs with 66 types of spatial relations in English (e.g., under, in front of, facing). While using a seemingly simple annotation format, we show how the dataset includes challenging linguistic phenomena, such as varying reference frames. We demonstrate a large gap between human and model performance: The human ceiling is above 95%, while state-of-the-art models only achieve around 70%. We observe that VLMs' by-relation performances have little correlation with the number of training examples and the tested models are in general incapable of recognising relations concerning the orientations of objects.(1)
C1 [Liu, Fangyu; Emerson, Guy; Collier, Nigel] Univ Cambridge, Cambridge, England.
C3 University of Cambridge
RP Liu, FY (通讯作者)，Univ Cambridge, Cambridge, England.
EM fl399@cam.ac.uk; gete2@cam.ac.uk; nhc30@cam.ac.uk
RI Liu, Fangyu/AHA-5291-2022
OI Liu, Fangyu/0000-0001-7038-3623
FU Cambridge Language Sciences Incubator Fund; Grace amp; Thomas C.H. Chan
   Cambridge Scholarship
FX We thank the TACL reviewers and the action editor for their thoughtful
   comments. We thank Qian Wang and Rongtian Ye for helping trial the
   annotation scheme; Zihao Fu for helping set up the annotation server.
   The project is funded by Cambridge Language Sciences Incubator Fund. FL
   is supported by Grace & amp; Thomas C.H. Chan Cambridge Scholarship.
CR Akula Arjun., 2020, P 58 ANN M ASS COMP, P6555, DOI [10.18653/v1/2020.acl-main.586, DOI 10.18653/V1/2020.ACL-MAIN.586]
   Alayrac Jean-Baptiste, 2022, ADV NEURAL INFORM PR
   Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bugliarello E, 2021, T ASSOC COMPUT LING, V9, P978, DOI 10.1162/tacl_a_00408
   Bugliarello Emanuele., 2022, P 39 INT C MACH LEAR, V162 of Proceedings of Machine Learning Research, P2370
   Christie G., 2016, P 2016 C EMPIRICAL M, P1493
   Cirik Volkan, 2018, P C N AM CHAPT ASS C, P781
   Collell G, 2018, AAAI CONF ARTIF INTE, P6765
   Edmonds-Wathen Cris., 2012, 12 INT C MATH ED TOP, P5857
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   Hendricks Lisa Anne., 2021, FINDINGS ASS COMPUTA, P3635, DOI [10.18653/v1/2021.findings-acl.318, DOI 10.18653/V1/2021.FINDINGS-ACL.318]
   Huang SH, 2023, Arxiv, DOI arXiv:2302.14045
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Jia C, 2021, PR MACH LEARN RES, V139
   Joe Booth, 2023, CLIP VISUAL SPATIAL
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Kim W, 2021, PR MACH LEARN RES, V139
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuhnle A, 2019, LECT NOTES COMPUT SC, V11132, P162, DOI 10.1007/978-3-030-11018-5_15
   Kuhnle Alexander., 2018, P WORKSHOP GENERALIZ, P17
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lei J., 2020, P 58 ANN M ASS COMP, P8211, DOI DOI 10.18653/V1/2020.ACL-MAIN.730
   Levinson S., 2003, SPACE LANGUAGE COGNI, DOI [10.1017/CBO9780511613609, DOI 10.1017/CBO9780511613609]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10467
   Liu RT, 2019, PROC CVPR IEEE, P4180, DOI 10.1109/CVPR.2019.00431
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2365
   Liu YH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3976
   Loshchilov Ilya, 7 INT C LEARN REPR I
   Fagundes CKM, 2021, T GIS, V25, P3159, DOI 10.1111/tgis.12815
   Mirzaee R, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4582
   Parcalabescu L, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8253
   Radford A, 2021, PR MACH LEARN RES, V139
   Rosch Philipp J., 2022, FIND ASS COMP LING N, P1031, DOI [10.18653/v1/2022.findings-naacl.77, DOI 10.18653/V1/2022.FINDINGS-NAACL.77]
   Subramanian S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5198
   Suhr A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6418
   Suhr A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P217, DOI 10.18653/v1/P17-2034
   Talmy L., 1983, SPATIAL ORIENTATION, P225, DOI DOI 10.1007/978-1-4615-9325-6_11
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Vaswani A., 2017, ARXIV, V30, P5998
   Vukovic N, 2015, COGNITION, V142, P110, DOI 10.1016/j.cognition.2015.05.017
   Xi Chen., 2023, 11 INT C LEARNING RE
   Xie Ning., 2019, NEURIPS 2018 VIGIL W
   Yatskar Mark, 2016, P 2016 C N AM CHAPT, P193, DOI DOI 10.18653/V1/N16-1023
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zhai XH, 2022, PROC CVPR IEEE, P18102, DOI 10.1109/CVPR52688.2022.01759
NR 49
TC 0
Z9 0
U1 1
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUN 20
PY 2023
VL 11
BP 635
EP 651
DI 10.1162/tacl_a_00566
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA K7VI6
UT WOS:001018475800002
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Chi, YL
   Lee, HM
AF Chi, Yu-Liang
   Lee, Hsun-Ming
TI A formal modeling platform for composing web services
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE formal model; web service; service composition; workflow; Petri Nets
AB Building a robust service composition is increasingly problematic as large scales of Web service operations can now be possibly achieved through the Internet. This article proposes an effective composing platform based on a formal modeling language. In particular, Petri Nets patterns are developed for enhancing service composition modeling, workflow quality measurement and scripting productivity. By providing a visual editing module, this platform allows business application developers to exploit its composing capabilities without much requiring design time or skills. (C) 2007 Published by Elsevier Ltd.
C1 [Lee, Hsun-Ming] Texas State Univ San Marcos, Dept Comp Informat Syst & Quantitat Methods, San Marcos, TX USA.
C3 Texas State University System; Texas State University San Marcos
EM maxchi@cycu.edu.tw; sl20@txstate.edu
RI CHI, YU-LIANG/AAP-9313-2020
OI CHI, YU-LIANG/0000-0002-9979-1134
CR Benatallah B, 2003, IEEE INTERNET COMPUT, V7, P40, DOI 10.1109/MIC.2003.1167338
   Casati F, 2002, INFORM SYST FRONT, V4, P19, DOI 10.1023/A:1015374204227
   Curbera F, 2002, IEEE INTERNET COMPUT, V6, P86, DOI 10.1109/4236.991449
   FLORESCU D, 2001, IEEE DATA ENG B, V24, P48
   Heckel R, 2004, LECT NOTES COMPUT SC, V3098, P559, DOI 10.1007/978-3-540-27755-2_16
   Ko IY, 2003, IEEE INTERNET COMPUT, V7, P52, DOI 10.1109/MIC.2003.1232518
   Kristensen L. M., 1998, International Journal on Software Tools for Technology Transfer, V2, P98, DOI 10.1007/s100090050021
   Medjahed B, 2003, VLDB J, V12, P59, DOI 10.1007/s00778-003-0087-z
   Menascé DA, 2004, IEEE INTERNET COMPUT, V8, P88, DOI 10.1109/MIC.2004.57
   Milanovic N, 2004, IEEE INTERNET COMPUT, V8, P51, DOI 10.1109/MIC.2004.58
   MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143
   van der Aalst W, 2003, IEEE INTELL SYST, V18, P72
   Van der Aalst WMP, 2003, DISTRIB PARALLEL DAT, V14, P5, DOI 10.1023/A:1022883727209
   Weber M, 2003, LECT NOTES COMPUT SC, V2472, P124
   *WFMC, 1999, TC1011 WFMC
NR 15
TC 15
Z9 19
U1 0
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD FEB
PY 2008
VL 34
IS 2
BP 1500
EP 1507
DI 10.1016/j.eswa.2007.01.022
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA 263TH
UT WOS:000253238900071
DA 2023-11-10
ER

PT J
AU Liaqat, MI
   Hassan, MA
   Shoaib, M
   Khurshid, SK
   Shamseldin, MA
AF Liaqat, Muhammad Irzam
   Hassan, Muhammad Awais
   Shoaib, Muhammad
   Khurshid, Syed Khaldoon
   Shamseldin, Mohamed A.
TI Sentiment analysis techniques, challenges, and opportunities: Urdu
   language-based analytical study
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Opinion mining; Poor resource language; Word sense
   disambiguation; Urdu-based language constructs; Digital repositories
AB Sentiment analysis in research involves the processing and analysis of sentiments from textual data. The sentiment analysis for high resource languages such as English and French has been carried out effectively in the past. However, its applications are comparatively few for resource-poor languages due to a lack of textual resources. This systematic literature explores different aspects of Urdu-based sentiment analysis, a classic case of poor resource language. While Urdu is a South Asian language understood by one hundred and sixty-nine million people across the planet. There are various shortcomings in the literature, including limitation of large corpora, language parsers, and lack of pre-trained machine learning models that result in poor performance. This article has analyzed and evaluated studies addressing machine learning-based Urdu sentiment analysis. After searching and filtering, forty articles have been inspected. Research objectives have been proposed that lead to research questions. Our searches were organized in digital repositories after selecting and screening relevant studies. Data was extracted from these studies. Our work on the existing literature reflects that sentiment classification performance can be improved by overcoming the challenges such as word sense disambiguation and massive datasets. Furthermore, Urdu-based language constructs, including language parsers and emoticons, context-level sentiment analysis techniques, pre-processing methods, and lexical resources, can also be improved.
C1 [Liaqat, Muhammad Irzam; Hassan, Muhammad Awais; Shoaib, Muhammad; Khurshid, Syed Khaldoon] Univ Engn & Technol Lahore, Dept Comp Sci, Lahore, Punjab, Pakistan.
   [Shamseldin, Mohamed A.] Future Univ Egypt, Fac Engn Technol, Dept Mech Engn, New Cairo, Egypt.
C3 University of Engineering & Technology Lahore; Egyptian Knowledge Bank
   (EKB); Future University in Egypt
RP Hassan, MA (通讯作者)，Univ Engn & Technol Lahore, Dept Comp Sci, Lahore, Punjab, Pakistan.
EM awais.hassan@uet.edu.pk
RI Shamseldin, Mohamed/AAW-3374-2020
OI Shamseldin, Mohamed/0000-0002-3993-2265
CR Ali MZ, 2021, IEEE ACCESS, V9, P84296, DOI 10.1109/ACCESS.2021.3087827
   Altrabsheh N, 2014, LECT NOTES ARTIF INT, V8779, P40, DOI 10.1007/978-3-319-11298-5_5
   Anwar W, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4489
   Asghar MZ, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12397
   Asghar MZ, 2017, COGN COMPUT, V9, P868, DOI 10.1007/s12559-017-9503-3
   Asif M, 2020, TELEMAT INFORM, V48, DOI 10.1016/j.tele.2020.101345
   Awais DM, 2019, ACM T ASIAN LOW-RESO, V18, P1
   Babu AG, 2017, P 2017 INT C MACH LE
   Badaro G, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3295662
   Basiri ME, 2014, OPEN T INFORM PROCES, p1?14
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Basiri ME, 2020, KNOWL-BASED SYST, V198, DOI 10.1016/j.knosys.2020.105949
   Bibi Raheela, 2019, 2019 IEEE 17th International Conference on Software Engineering Research, Management and Applications (SERA), P66, DOI 10.1109/SERA.2019.8886788
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   Dong XF, 2021, TECHNOL SOC, V67, DOI 10.1016/j.techsoc.2021.101724
   Fernandez A, 2011, INFORM SOFTWARE TECH, V53, P789, DOI 10.1016/j.infsof.2011.02.007
   Ghulam H, 2019, PROCEDIA COMPUT SCI, V147, P131, DOI 10.1016/j.procs.2019.01.202
   Hasan A, 2018, MATH COMPUT APPL, V23, DOI 10.3390/mca23010011
   Hassan S. M., 2019, INDIAN J SCI TECHNOL, V12, P01, DOI [10.17485/ijst/2019/v12i35/146571, DOI 10.17485/ijst/2019/v12i35/146571]
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Idrees F, 2019, P 10 INT C INFORM CO, P1
   Jena RK, 2019, BEHAV INFORM TECHNOL, V38, P986, DOI 10.1080/0144929X.2019.1625440
   Khan IU, 2022, COMPUTERS, V11, DOI 10.3390/computers11010003
   Khan L, 2021, IEEE ACCESS, V9, P97803, DOI 10.1109/ACCESS.2021.3093078
   Khan W, 2019, LANG RESOUR EVAL, V53, P331, DOI 10.1007/s10579-018-9439-6
   Khattak A, 2021, EGYPT INFORM J, V22, P53, DOI 10.1016/j.eij.2020.04.003
   Kitchenham Barbara, 2004, PROCEDURES PERFORMIN, V33, P1, DOI DOI 10.1145/3328905.3332505
   Lin C., 2009, P 18 ACM C INF KNOWL, P375, DOI 10.1145/1645953.1646003
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Lo SL, 2017, ARTIF INTELL REV, V48, P499, DOI 10.1007/s10462-016-9508-4
   Majeed A, 2020, 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING WORKSHOPS (ASEW 2020), P125, DOI 10.1145/3417113.3423375
   Marrese-Taylor E, 2014, EXPERT SYST APPL, V41, P7764, DOI 10.1016/j.eswa.2014.05.045
   Mehmood F, 2020, IEEE ACCESS, V8, P192740, DOI 10.1109/ACCESS.2020.3030885
   Mehmood K, 2019, ADV INTELL SYST COMP, V858, P29, DOI 10.1007/978-3-030-01174-1_3
   Mehmood K, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3329709
   Mehmood K, 2019, IEEE ACCESS, V7, P47991, DOI 10.1109/ACCESS.2019.2908420
   Mehta P, 2020, INT J SCI TECHNOLOGY, V9, p601?609
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mukhtar N, 2020, ARTIF INTELL REV, V53, P2521, DOI 10.1007/s10462-019-09740-5
   Mukhtar N, 2018, TELEMAT INFORM, V35, P2173, DOI 10.1016/j.tele.2018.08.003
   Naqvi RA, 2020, CMC-COMPUT MATER CON, V65, P1221, DOI 10.32604/cmc.2020.011686
   Naqvi U, 2021, IEEE ACCESS, V9, P114085, DOI 10.1109/ACCESS.2021.3104308
   Nazir M, 2020, 2020 5TH IEEE WORKSHOP ON THE ELECTRONIC GRID (EGRID), DOI 10.1109/EGRID48559.2020.9330631
   Ouhbi S, 2015, REQUIR ENG, V20, P119, DOI 10.1007/s00766-013-0192-5
   Portal CC, 2018, CORE C PORT
   Pourpanah F, 2020, ARXIV
   Rank SJC, 2018, SCIMAGO J COUNTRY RA
   Raza H, 2019, INT J ADV COMPUT SC, V10, P157
   Safder I, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12751
   Sattar A, 2021, PAKISTAN J ENG TECH, V4, DOI [10.51846/vol4iss2pp149-152, DOI 10.51846/VOL4ISS2PP149-152]
   Seo S, 2020, IEEE ACCESS, V8, P6861, DOI 10.1109/ACCESS.2019.2963426
   Syed AZ, 2010, LECT NOTES ARTIF INT, V6437, P32, DOI 10.1007/978-3-642-16761-4_4
   Tabassum N, 2021, INTELL AUTOM SOFT CO, V30, P175, DOI 10.32604/iasc.2021.018998
   Wohlin C., 2014, P 18 INT C EVALUATIO, P1, DOI [DOI 10.1145/2601248.2601268, 10.1145/2601248.2601268]
   Zhou XJ, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P533, DOI 10.1145/3106426.3106459
NR 56
TC 2
Z9 2
U1 1
U2 3
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD AUG 31
PY 2022
VL 8
AR e1032
DI 10.7717/peerj-cs.1032
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2SH
UT WOS:000860016600002
PM 36091980
OA gold, Green Published
DA 2023-11-10
ER

PT J
AU Glavas, G
   Franco-Salvador, M
   Ponzetto, SP
   Rosso, P
AF Glavas, Goran
   Franco-Salvador, Marc
   Ponzetto, Simone P.
   Rosso, Paolo
TI A resource-light method for cross-lingual semantic textual similarity
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Semantic textual similarity; Cross-lingual; Word embeddings; Word
   alignment; Parallel sentences alignment; Plagiarism detection
AB Recognizing semantically similar sentences or paragraphs across languages is beneficial for many tasks, ranging from cross-lingual information retrieval and plagiarism detection to machine translation. Recently proposed methods for predicting cross-lingual semantic similarity of short texts, however, make use of tools and resources (e.g., machine translation systems, syntactic parsers or named entity recognition) that for many languages (or language pairs) do not exist. In contrast, we propose an unsupervised and a very resource-light approach for measuring semantic similarity between texts in different languages. To operate in the bilingual (or multilingual) space, we project continuous word vectors (i.e., word embeddings) from one language to the vector space of the other language via the linear translation model. We then align words according to the similarity of their vectors in the bilingual embedding space and investigate different unsupervised measures of semantic similarity exploiting bilingual embeddings and word alignments. Requiring only a limited-size set of word translation pairs between the languages, the proposed approach is applicable to virtually any pair of languages for which there exists a sufficiently large corpus, required to learn monolingual word embeddings. Experimental results on three different datasets for measuring semantic textual similarity show that our simple resource-light approach reaches performance close to that of supervised and resource-intensive methods, displaying stability across different language pairs. Furthermore, we evaluate the proposed method on two extrinsic tasks, namely extraction of parallel sentences from comparable corpora and cross-lingual plagiarism detection, and show that it yields performance comparable to those of complex resource-intensive state-of-the-art models for the respective tasks. (C) 2017 Published by Elsevier B.V.
C1 [Glavas, Goran; Ponzetto, Simone P.] Univ Mannheim, Sch Business Informat & Matemath, Data & Web Sci Grp, B6 26, DE-68159 Mannheim, Germany.
   [Franco-Salvador, Marc] Symanto Res, Pretzfelder Str 15, DE-90425 Nurnberg, Germany.
   [Franco-Salvador, Marc; Rosso, Paolo] Univ Politecn Valencia, Pattern Recognit & Human Language Technol Res Ctr, Camino Vera S-N, ES-46022 Valencia, Spain.
C3 University of Mannheim; Universitat Politecnica de Valencia
RP Glavas, G (通讯作者)，Univ Mannheim, Sch Business Informat & Matemath, Data & Web Sci Grp, B6 26, DE-68159 Mannheim, Germany.
EM goran@informatik.uni-mannheim.de; mfranco@prhlt.upv.es;
   simone@informatik.uni-mannheim.de; prosso@dsic.upv.es
OI Ponzetto, Simone Paolo/0000-0001-7484-2049; Glavas,
   Goran/0000-0002-1301-6314
FU DAAD; SomEMBED project [TIN2015-71147-C2-1-P]; Ministry of Science,
   Research and the Arts of the state of Baden-Wurttemberg
FX Part of the work presented in this article was performed during second
   author's research visit to the University of Mannheim, supported by
   Contact Fellowship awarded by the DAAD scholarship program "STIBET
   Doktoranden". The research of the last author has been carried out in
   the framework of the SomEMBED project (TIN2015-71147-C2-1-P).
   Furthermore, this work was partially funded by the Junior-professor
   funding programme of the Ministry of Science, Research and the Arts of
   the state of Baden-Wurttemberg (project "Deep semantic models for
   high-end NLP application").
CR Agirre E, 2016, P 10 INT WORKSH SEM, P497, DOI DOI 10.18653/V1/S16-1081
   Agirre E., 2012, P 6 INT WORKSHOP SEM, P385
   [Anonymous], P 8 INT WORKSH SEM E
   [Anonymous], 1998, ENCY APPL LING, DOI DOI 10.7551/MITPRESS/7287.001.0001
   [Anonymous], JRC ACQUIS MULTILING
   [Anonymous], 1994, INTRO BOOTSTRAP
   [Anonymous], 2010, P C N AM CHAPTER ASS
   [Anonymous], 2014, P 14 C EUR CHAPT ASS
   [Anonymous], 2015, P 2015 C EMPIRICAL M
   [Anonymous], 2015, P 9 INT WORKSHOP SEM, DOI DOI 10.18653/V1/S15-2046
   [Anonymous], 2012, P 1 JOINT C LEX COMP
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Aziz W., 2011, P 8 BRAZ S INF HUM L, P234
   Brychcin T., 2016, P 10 INT WORKSH SEM, P588, DOI [10.18653/v1/S16-1089, DOI 10.18653/V1/S16-1089]
   Dagan I, 2010, NAT LANG ENG, V16, P105, DOI 10.1017/S1351324909990234
   Dinu G., 2015, P INT C LEARN REPR
   Franco-Salvador M, 2016, KNOWL-BASED SYST, V111, P87, DOI 10.1016/j.knosys.2016.08.004
   Franco-Salvador M, 2016, INFORM PROCESS MANAG, V52, P550, DOI 10.1016/j.ipm.2015.12.004
   Han L., 2013, P 2 JOINT C LEX COMP
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Islam A., 2008, ACM T KNOWL DISCOV D, V2, P10, DOI 10.1145/1376815.1376819
   Castillo JJ, 2011, INT J MACH LEARN CYB, V2, P177, DOI 10.1007/s13042-011-0026-z
   Jimenez S., 2016, SEMEVAL, P749
   King DB, 2015, ACS SYM SER, V1214, P1
   Kuhn Harold W, 1955, NAV RES LOG, V2, P83, DOI [DOI 10.1002/NAV.20053, 10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]
   Ljubesic N, 2011, LECT NOTES ARTIF INT, V6836, P395, DOI 10.1007/978-3-642-23538-2_50
   Lopez-Gazpio I, 2017, KNOWL-BASED SYST, V119, P186, DOI 10.1016/j.knosys.2016.12.013
   Madnani N, 2012, P 2012 C N AM CHAPT, P182
   Mehdad Yashar, 2011, P 49 ANN M ASS COMP, P1336
   Mihalcea Rada, 2015, P 9 INT WORKSH SEM E, DOI DOI 10.18653/V1/S15-2045
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T., 2013, ARXIV13094168 CORR
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Oliva J, 2011, DATA KNOWL ENG, V70, P390, DOI 10.1016/j.datak.2011.01.002
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Potthast M., 2011, OVERVIEW 3 INT COMPE
   Potthast M., 2010, P 23 INT C COMP LING, P997
   Potthast M, 2011, LANG RESOUR EVAL, V45, P45, DOI 10.1007/s10579-009-9114-z
   Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578
   Saric F., 2012, P 1 JOINT C LEXICAL, P441
   Schryver Gilles-Maurice de, 2002, NORDIC J AFRICAN STU, V11, P266
   Socher R., 2011, P 24 INT C NEUR INF
   Sultan Md Arafat, 2014, P 8 INT WORKSHOP SEM, P241, DOI [10.3115/v1/S14-2039, DOI 10.3115/V1/S14-2039]
   Turchi M., 2013, P 7 INT WORKSH SEM E, P128
   Vulic I, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P363, DOI 10.1145/2766462.2767752
   Yih Wen-tau, 2011, P 15 C COMP NAT LANG, P247
   Zesch T., 2012, P 1 JOINT C LEXICAL, P435
NR 48
TC 22
Z9 24
U1 1
U2 34
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD MAR 1
PY 2018
VL 143
BP 1
EP 9
DI 10.1016/j.knosys.2017.11.041
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA FW3II
UT WOS:000425199600001
OA Green Submitted, Green Published
DA 2023-11-10
ER

PT J
AU Pinto, JP
   Viana, P
   Teixeira, I
   Andrade, M
AF Pinto, Jose Pedro
   Viana, Paula
   Teixeira, Ines
   Andrade, Maria
TI Improving word embeddings in Portuguese: increasing accuracy while
   reducing the size of the corpus
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Natural language processing; Machine learning; Multimedia systems;
   Context awareness; Word2Vec
ID MODELS
AB The subjectiveness of multimedia content description has a strong negative impact on tag-based information retrieval. In our work, we propose enhancing available descriptions by adding semantically related tags. To cope with this objective, we use a word embedding technique based on the Word2Vec neural network parameterized and trained using a new dataset built from online newspapers. A large number of news stories was scraped and pre-processed to build a new dataset. Our target language is Portuguese, one of the most spoken languages worldwide. The results achieved significantly outperform similar existing solutions developed in the scope of different languages, including Portuguese. Contributions include also an online application and API available for external use. Although the presented work has been designed to enhance multimedia content annotation, it can be used in several other application areas.
C1 [Pinto, Jose Pedro; Viana, Paula; Teixeira, Ines; Andrade, Maria] INESC TEC, Porto, Portugal.
   [Viana, Paula] Polytech Porto, Sch Engn, Porto, Portugal.
   [Andrade, Maria] Univ Porto, Fac Engn, Porto, Portugal.
C3 INESC TEC; Instituto Politecnico do Porto; Universidade do Porto
RP Viana, P (通讯作者)，INESC TEC, Porto, Portugal.; Viana, P (通讯作者)，Polytech Porto, Sch Engn, Porto, Portugal.
EM paula.viana@inesctec.pt
RI Andrade, Maria/HKN-0074-2023; da Costa Andrade, Maria
   Eduarda/IXN-1199-2023; ANDRADE, MARIA/JGM-7159-2023
OI Viana, Paula/0000-0001-8447-2360; Andrade, Maria
   Teresa/0000-0002-1363-5027
CR Baek JW, 2021, MULTIMED TOOLS APPL, V80, P34499, DOI 10.1007/s11042-019-08607-9
   Bhardwaj A, 2018, DEEP LEARNING ESSENT
   Bojanowski P, 2017, Arxiv, DOI [arXiv:1607.04606, DOI 10.48550/ARXIV.1607.04606]
   Bruni E, 2011, P GEMS 2011 WORKSH G, P22
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Chamberlain Benjamin P., 2020, RecSys '20: Fourteenth ACM Conference on Recommender Systems, P732, DOI 10.1145/3383313.3418486
   Dridi A, 2019, IEEE ACCESS, V7, P176414, DOI 10.1109/ACCESS.2019.2957440
   Dusserre E, 2017, IWCS
   Hartmann N, 2017, Arxiv, DOI arXiv:1708.06025
   Hinton G.E, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI DOI 10.1109/69.917563
   Hofstatter Sebastian, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P810, DOI 10.1007/978-3-030-15712-8_57
   Hu K, 2019, INFORM PROCESS MANAG, V56, P1185, DOI 10.1016/j.ipm.2019.02.014
   Nguyen HT, 2018, INFORM PROCESS MANAG, V54, P451, DOI 10.1016/j.ipm.2018.02.001
   Inc. F, 2020, FASTTEXT
   Joulin A, 2016, Arxiv, DOI arXiv:1607.01759
   Khatua A, 2019, INFORM PROCESS MANAG, V56, P247, DOI 10.1016/j.ipm.2018.10.010
   Lenci A, 2018, ANNU REV LINGUIST, V4, P151, DOI 10.1146/annurev-linguistics-030514-125254
   Liu CR, 2017, INTERSPEECH, P1686, DOI 10.21437/Interspeech.2017-965
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Tien NH, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102090
   NLX-group, 2020, 60 4WANALOGIES
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pinto J.P., 2013, P 2013 ACM INT WORKS, P25, DOI DOI 10.1145/2512142.2512154
   Pinto JP, 2019, ADV INTELL SYST, V833, P131, DOI 10.1007/978-3-319-98678-4_15
   Pinto JP, 2015, CVMP 2015: PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, DOI 10.1145/2824840.2824853
   Rehurek R., 2010, P LREC 2010 WORKSHOP, P45
   Rehurek R., 2019, GENSIM TOPIC MODELLI
   Rida-E-Fatima S, 2019, IEEE ACCESS, V7, P114795, DOI 10.1109/ACCESS.2019.2927281
   Rodrigues J, 2016, LECT NOTES ARTIF INT, V9727, P259, DOI 10.1007/978-3-319-41552-9_27
   Roy D, 2019, INFORM PROCESS MANAG, V56, P1026, DOI 10.1016/j.ipm.2018.10.009
   Santosh Kumar P, 2021, ADV INTELLIGENT SYST, V1165, P525, DOI [10.1007/978-981-15-5113-0_41, DOI 10.1007/978-981-15-5113-0_41]
   Lee LSY, 2015, Arxiv, DOI arXiv:1511.06961
   Subba B, 2022, COMPUT INTELL-US, V38, P530, DOI 10.1111/coin.12478
   Sun F, 2016, Arxiv, DOI arXiv:1603.07603
   Svoboda L, 2016, INT C INTELLIGENT TE, P103
   Svoboda L, 2017, Arxiv, DOI arXiv:1711.01804
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Venekoski V., 2017, P NODALIDA GOTH, V131, P231
   Viana P, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0094-5
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
NR 40
TC 0
Z9 0
U1 1
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 18
PY 2022
VL 8
DI 10.7717/peerj-cs.964
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C9YK0
UT WOS:000965386500001
PM 35875629
OA Green Submitted, gold, Green Published
DA 2023-11-10
ER

PT J
AU Huang, Y
   Wang, YM
   Wang, L
AF Huang, Yan
   Wang, Yuming
   Wang, Liang
TI Efficient Image and Sentence Matching
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Matrix decomposition; Symmetric matrices; Computational modeling;
   Predictive models; Analytical models; Task analysis; Context modeling;
   Efficient image and sentence matching; cross-modal similarity
   distillation; vision and language
AB Recently the accuracy of image and sentence matching has been continuously improved by larger and larger models. However, such large models not only need huge storage space but also slow down inference speed, which are not very suitable for low-cost devices in real-world applications. To our knowledge, this work makes the first attempt to improve the model efficiency in the context of image and sentence matching, and accordingly proposes a simple yet effective Whitened Similarity Distillation (WSD) method, which can distill cross-modal knowledge from a large teacher model to a small student model of both high efficiency and accuracy. The high efficiency is achieved by performing: 1) feature representation based on efficient backbone networks; and 2) similarity measurement in a fast N-to-N manner. However, the accuracy of such a student model is much worse than that of teacher model, because there exists very large variation inconsistency between two cross-modal similarity matrices of teacher and student models, which is hard to reduce during the similarity distillation. By performing two whitening-like transformations in the orthogonal space, the proposed WSD can reduce the large variation inconsistency more isotropically and is able to improve the accuracy of student model. We perform extensive experiments on two benchmark datasets and demonstrate the effectiveness of the proposed WSD. Compared with the teacher model, our distilled student model is 7x smaller (in model size) and 9x faster (in testing speed), only at the cost of < 2% accuracy decrease.
C1 [Huang, Yan; Wang, Yuming; Wang, Liang] Chinese Acad Sci CASIA, Inst Automat, Ctr Excellence Brain Sci & Intelligence Technol CE, Natl Lab Pattern Recognit NLPR,Ctr Res Intelligent, Beijing 100045, Peoples R China.
   [Huang, Yan; Wang, Yuming; Wang, Liang] Univ Chinese Acad Sci UCAS, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Huang, Y (通讯作者)，Chinese Acad Sci CASIA, Inst Automat, Ctr Excellence Brain Sci & Intelligence Technol CE, Natl Lab Pattern Recognit NLPR,Ctr Res Intelligent, Beijing 100045, Peoples R China.; Huang, Y (通讯作者)，Univ Chinese Acad Sci UCAS, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
EM yhuang@nlpr.ia.ac.cn; yuming.wang@cripac.ia.ac.cn;
   wangliang@nlpr.ia.ac.cn
RI Huang, Yan/HCH-6526-2022
OI Huang, Yan/0000-0002-8239-7229
FU National Key Research and Development Program of China [2018AAA0100400];
   Key Research Program of Frontier Sciences CAS [ZDBS-LY-JSC032]; National
   Natural Science Foundation of China [61721004, U1803261, 61976132];
   Beijing Nova Program [Z201100006820079]; CAS-AIR
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018AAA0100400, in part by the
   Key Research Program of Frontier Sciences CAS under Grant
   ZDBS-LY-JSC032, in part by the National Natural Science Foundation of
   China under Grants 61721004, U1803261, and 61976132, in part by Beijing
   Nova Program underGrant Z201100006820079, and CAS-AIR.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Chen D., 2020, ARXIV
   Chen Guobin, 2017, ADV NEUR IN, P742
   Chen JC, 2021, PROC CVPR IEEE, P15784, DOI 10.1109/CVPR46437.2021.01553
   Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, 10.48550/arXiv.1412.3555, DOI 10.48550/ARXIV.1412.3555]
   Croitoru I, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11563, DOI 10.1109/ICCV48922.2021.01138
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Domingos P., 2000, P 17 INT C MACHINE L, P231, DOI DOI 10.5555/645529.657784
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Faghri F, 2018, Arxiv, DOI arXiv:1707.05612
   Feng Y, 2019, PROC CVPR IEEE, P4120, DOI 10.1109/CVPR.2019.00425
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Geigle G, 2022, Arxiv, DOI arXiv:2103.11920
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   Haohan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8681, DOI 10.1109/CVPR42600.2020.00871
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]
   Hodosh M., 2014, P TACL, V7, P67, DOI [10.1162/tacl_a_00166, DOI 10.1162/TACL_A_00166]
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang Y, 2022, IEEE T PATTERN ANAL, V44, P2968, DOI 10.1109/TPAMI.2021.3052490
   Huang Y, 2019, IEEE I CONF COMP VIS, P5773, DOI 10.1109/ICCV.2019.00587
   Huang Y, 2019, AAAI CONF ARTIF INTE, P8489
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Huang Y, 2020, IEEE T PATTERN ANAL, V42, P636, DOI 10.1109/TPAMI.2018.2883466
   Huang Y, 2017, PROC CVPR IEEE, P7254, DOI 10.1109/CVPR.2017.767
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Karpathy A., 2014, ADV NEURAL INFORM PR, V27, P1889
   Kessy A, 2018, AM STAT, V72, P309, DOI 10.1080/00031305.2016.1277159
   Kim Y, 2016, Arxiv, DOI arXiv:1606.07947
   Kingma D. P., 2014, C TRACK P
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kunran Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P664, DOI 10.1007/978-3-030-58595-2_40
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Lev G, 2016, LECT NOTES COMPUT SC, V9910, P833, DOI 10.1007/978-3-319-46466-4_50
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Chunxiao, 2020, P IEEE CVF C COMP VI, P10918, DOI DOI 10.1109/CVPR42600.2020.01093
   Liu HX, 2019, Arxiv, DOI [arXiv:1806.09055, DOI 10.48550/ARXIV.1806.09055]
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Lu J., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1908.02265
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Paszke A, 2019, ADV NEUR IN, V32
   Peng BY, 2019, IEEE I CONF COMP VIS, P5006, DOI 10.1109/ICCV.2019.00511
   Peng H., 2020, PROC INT C NEURAL IN
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Qu LG, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1047, DOI 10.1145/3394171.3413961
   Radford Alec, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.00020
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shi BT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5182
   Shuster K, 2019, PROC CVPR IEEE, P12508, DOI 10.1109/CVPR.2019.01280
   Sukmin Yun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13873, DOI 10.1109/CVPR42600.2020.01389
   Sun ZQ, 2020, Arxiv, DOI arXiv:2004.02984
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang Wenhui, 2020, ARXIV200210957, DOI DOI 10.1145/3308558.3313562
   Wang YX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3792
   Wang ZH, 2019, IEEE I CONF COMP VIS, P5763, DOI 10.1109/ICCV.2019.00586
   Wehrmann J, 2019, IEEE I CONF COMP VIS, P5803, DOI 10.1109/ICCV.2019.00590
   Wehrmann P, 2020, AAAI CONF ARTIF INTE, V34, P12313
   Wen KY, 2021, IEEE T CIRC SYST VID, V31, P2866, DOI 10.1109/TCSVT.2020.3030656
   Wu AC, 2019, PROC CVPR IEEE, P1187, DOI 10.1109/CVPR.2019.00128
   Wu YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2088, DOI 10.1145/3343031.3350940
   Xi Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10938, DOI 10.1109/CVPR42600.2020.01095
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yu L, 2019, PROC CVPR IEEE, P2902, DOI 10.1109/CVPR.2019.00302
   Yufan Liu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7089, DOI 10.1109/CVPR.2019.00726
   Yalniz IZ, 2019, Arxiv, DOI [arXiv:1905.00546, 10.48550/arXiv.1905.00546]
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
NR 85
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD MAR 1
PY 2023
VL 45
IS 3
BP 2970
EP 2983
DI 10.1109/TPAMI.2022.3178485
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA D1BV8
UT WOS:000966154400001
PM 35622793
DA 2023-11-10
ER

PT J
AU Bidgoly, AJ
   Amirkhani, H
   Baradaran, R
AF Bidgoly, Amir Jalaly
   Amirkhani, Hossein
   Baradaran, Razieh
TI Clustering-based Sequence to Sequence Model for GenerativeQuestion
   Answering in a Low-resource Language
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Generative question answering; low-resource language; clustering; deep
   learning; encoder-decoder model
AB Despite the impressive success of sequence to sequence models for generative question answering, they need a vast amount of question-answer pairs during training, which is hard and expensive to obtain, especially for low-resource languages. In this article, we present a framework that exploits the semantic clusters among the question-answer pairs to compensate for the lack of enough training data. In the training phase, the questionanswer pairs are clustered, and a cluster predictor is trained to identify the cluster each question belongs to. Then, a sequence to sequence model is trained, where there is a different generator for each cluster in the decoder component. During the test phase, the cluster of the input question is first identified using the trained cluster predictor, and the appropriate decoder is exploited. Our experiments on a Persian religious dataset show that the proposed method outperforms the standard sequence to sequence model by a large margin in terms of ROUGE and BLEU scores. This is traced back to the lower number of words in each cluster, leading to a reduction in the number of effective parameters each generator needs to learn, which help the model learn from fewer training data with less overfitting.
C1 [Bidgoly, Amir Jalaly; Amirkhani, Hossein; Baradaran, Razieh] Univ Qom, Dept Informat Technol & Comp Engn, PO 3716146611, Qom, Iran.
RP Bidgoly, AJ (通讯作者)，Univ Qom, Dept Informat Technol & Comp Engn, PO 3716146611, Qom, Iran.
EM Ajalaly@qom.ac.ir; amirkhani@qom.ac.ir; R.Baradaran@stu.qom.ac.ir
RI Baradaran, Razieh/GZN-0992-2022
CR Abdi A, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101023
   Amirkhani H, 2021, Arxiv, DOI arXiv:2009.08820
   [Anonymous], 2016, P C EMPIRICAL METHOD
   Baranova-Bolotova V, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2477, DOI 10.1145/3397271.3401449
   Bi B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2521
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boyd A., 2018, P 2018 EMNLP WORKSHO, P79
   Cho KYHY, 2014, Arxiv, DOI arXiv:1406.1078
   Dabre R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1410
   Daniel JE, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P948
   Das R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P358, DOI 10.18653/v1/P17-2057
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhingra Bhuwan, 2018, P 2018 C N AM CHAPT, V2, P582, DOI DOI 10.18653/V1/N18-2092
   Dong X, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6306
   Fajcik Martin, 2021, P 3 WORKSHOP MACHINE
   Fu Y., 2018, P 2018 C N AM CHAPTE, P185
   Gupta D, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3359988
   He SZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P199, DOI 10.18653/v1/P17-1019
   Huang YZ, 2018, MACH VISION APPL, V29, P1009, DOI 10.1007/s00138-018-0908-0
   Karpagam K, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-018-1022-8
   Khalil Talaat, 2019, P C EMPIRICAL METHOD, P6420
   Lang Q, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107858
   Lee K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2840
   Lewis M., 2018, GENERATIVE QUESTION
   Lewis P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4896
   LijunWu Jinhua Zhu, 2019, P C EMPIRICAL METHOD, P4366
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Liu C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4223
   Louvan Samuel, 2018, P 2018 EMNLP WORKSHO, P74
   Mishra A, 2016, J KING SAUD UNIV-COM, V28, P345, DOI 10.1016/j.jksuci.2014.10.007
   Momtazi S., 2009, P 18 ACM C INF KNOWL, P1911, DOI DOI 10.1145/1645953.1646263
   Nakatsuji M, 2020, AAAI CONF ARTIF INTE, V34, P8520
   Otegi A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P436
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parida S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5994
   Perera R, 2012, 2012 IEEE FOURTH INTERNATIONAL CONFERENCE ON TECHNOLOGY FOR EDUCATION (T4E), P245, DOI 10.1109/T4E.2012.48
   Rajpurkar P, 2016, Arxiv, DOI [arXiv:1606.05250, DOI 10.48550/ARXIV.1606.05250]
   Rajpurkar P, 2018, Arxiv, DOI arXiv:1806.03822
   Sondhi P, 2007, EURASIP J BIOINFORM, DOI 10.1155/2007/28576
   Sutskever I, 2014, ADV NEUR IN, V27
   Tan CQ, 2018, AAAI CONF ARTIF INTE, P5940
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Shuohang, 2021, FINDINGS ASS COMPUTA, P3958
   Wang SN, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2209
   Wei MX, 2019, IEEE ACCESS, V7, P61008, DOI 10.1109/ACCESS.2019.2904337
   Xu W, 2003, P 26 SIGIR TOR ON CA, P267
   Yang JY, 2020, LECT NOTES COMPUT SC, V12454, P340, DOI 10.1007/978-3-030-60248-2_23
   Yin Jun, 2016, P INT JOINT C ARTIFI
   Yoon S, 2018, Arxiv, DOI arXiv:1710.03430
   Yoon S, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2093, DOI 10.1145/3357384.3358148
   Zhang MS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P997
   Zuin G., 2018, 2018 INT JOINT C NEU, P1
NR 53
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB
PY 2023
VL 22
IS 2
DI 10.1145/3563036
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C7AF6
UT WOS:000963394900026
DA 2023-11-10
ER

PT J
AU Monteiro, J
   Alam, J
   Falk, TH
AF Monteiro, Joao
   Alam, Jahangir
   Falk, Tiago H.
TI Residual convolutional neural network with attentive feature pooling for
   end-to-end language identification from short-duration speech
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Language recognition; Language modeling; Residual convolutional neural
   networks; Attentive feature pooling
AB The problem of language identification from speech is tackled in this work. Residual convolutional neural networks are employed to this end, aiming at exploiting the ability of such architectures to take into account large contextual segments of input data. Moreover, learnable attention mechanisms are introduced on top of the convolutional stack for data-driven feature pooling across time, enabling the computation of fixed-dimension representations given varying-length speech segments as input. Training is performed using a combination of language identification and metric learning via triplet loss minimization, aimed at enforcing class separability within the embeddings space. Evaluation is performed across different conditions, such as multi-class classification, short-duration test utterances, and confusing languages, for the closed-set case, while open-set performance is evaluated with the introduction of unseen languages. At test time, end-to-end scoring along with cosine similarity and PLDA are employed, outperforming state-of-the-art benchmark methods, such as i-vectors by improving the average cost by 30% to 40% depending on the evaluation condition. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Monteiro, Joao; Alam, Jahangir; Falk, Tiago H.] INRS, EMT, 800 Rue Gauchetiere O,6900, Montreal, PQ, Canada.
   [Monteiro, Joao; Alam, Jahangir] CRIM, 405 Ogilvy Ave,101, Montreal, PQ, Canada.
C3 University of Quebec; Institut national de la recherche scientifique
   (INRS); Universite de Montreal
RP Monteiro, J (通讯作者)，INRS, EMT, 800 Rue Gauchetiere O,6900, Montreal, PQ, Canada.
EM joao.monteiro@emt.inrs.ca
RI Alam, Jahangir/AAW-5565-2021; Falk, Tiago/IQW-2566-2023
FU National Research Council of Canada (NRC) through the Canadian
   Indigenous Languages Technology [909859]; Natural Sciences and
   Engineering Research Council of Canada (NSERC) [RGPIN-2016-4175,
   RGPAS493010-2016]
FX The authors wish to acknowledge funding from the National Research
   Council of Canada (NRC) through the Canadian Indigenous Languages
   Technology project under contract #909859, and from the Natural Sciences
   and Engineering Research Council of Canada (NSERC) through
   contract/grant RGPIN-2016-4175, and RGPAS493010-2016. Any opinions,
   findings, conclusions or recommendations expressed in this material are
   those of the authors and do not necessarily reflect those of the NRC or
   NSERC.
CR Alam MJ, 2016, INTERSPEECH, P420, DOI 10.21437/Interspeech.2016-1465
   [Anonymous], ARXIV180206093
   Bai S, 2018, UNIVERSAL LANGUAGE M
   Bhattacharya G, 2017, INTERSPEECH, P1517, DOI 10.21437/Interspeech.2017-1575
   Cai W., 2018, OD 2018 SPEAK LANG R, P7481
   Cai WC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5209
   Chung J. S., 2018, INTERSPEECH
   Dehak N., 2011, P 12 ANN C INT SPEEC, P1
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Devlin J., 2018, ARXIV, V1, P4171
   Dong Wang Z. Z., 2015, THCHS 30 FREE CHINES
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hardt Moritz, 2016, INT C LEARN REPR
   Hermans Alexander, 2017, DEFENSE TRIPLET LOSS, V4
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L
   Li H. H., 2017, PLANT CELL TISSUE OR, V2017, P1, DOI DOI 10.1016/J.EC0LM0DEL.2017.01.003
   Pascanu R., 2013, P 30 INT C MACHINE L
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Raffel Colin, 2015, ARXIV151208756
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Snyder D., 2015, ARXIV151008484
   Snyder D., 2018, P 2018 IEEE INT C AC
   Snyder D, 2017, INTERSPEECH, P999, DOI 10.21437/Interspeech.2017-620
   Tang ZY, 2018, ASIAPAC SIGN INFO PR, P596, DOI 10.23919/APSIPA.2018.8659714
   Tang ZY, 2017, ASIAPAC SIGN INFO PR, P749, DOI 10.1109/APSIPA.2017.8282134
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A., 2017, ARXIV, V30, P5998
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Zhang Huan, 2018, SELF ATTENTION GENER
NR 32
TC 9
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD NOV
PY 2019
VL 58
BP 364
EP 376
DI 10.1016/j.csl.2019.05.006
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IM0GC
UT WOS:000477663800020
DA 2023-11-10
ER

PT J
AU Akhtar, MS
   Sawant, P
   Sen, S
   Ekbal, A
   Bhattacharyya, P
AF Akhtar, Md Shad
   Sawant, Palaash
   Sen, Sukanta
   Ekbal, Asif
   Bhattacharyya, Pushpak
TI Improving Word Embedding Coverage in Less-Resourced Languages Through
   Multi-Linguality and Cross-Linguality: A Case Study with Aspect-Based
   Sentiment Analysis
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Sentiment analysis; Aspect-Based Sentiment Analysis (ABSA);
   cross-lingual sentiment analysis; deep learning; Long Short Term Memory
   (LSTM); bilingual word embeddings; data sparsity; low-resourced
   languages; Indian languages
AB In the era of deep learning-based systems, efficient input representation is one of the primary requisites in solving various problems related to Natural Language Processing (NLP), data mining, text mining, and the like. Absence of adequate representation for an input introduces the problem of data sparsity, and it poses a great challenge to solve the underlying problem. The problem is more intensified with resource-poor languages due to the absence of a sufficiently large corpus required to train a word embedding model. In this work, we propose an effective method to improve the word embedding coverage in less-resourced languages by leveraging bilingual word embeddings learned from different corpora. We train and evaluate deep Long Short Term Memory (LSTM)-based architecture and show the effectiveness of the proposed approach for two aspect-level sentiment analysis tasks (i.e., aspect term extraction and sentiment classification). The neural network architecture is further assisted by hand-crafted features for prediction. We apply the proposed model in two experimental setups: multi-lingual and cross-lingual. Experimental results show the effectiveness of the proposed approach against the state-of-the-art methods.
C1 [Akhtar, Md Shad; Sen, Sukanta; Ekbal, Asif; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801106, Bihar, India.
   [Sawant, Palaash] Goa Univ, Dept Comp Sci & Technol, Taleigao 403206, Goa, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna; Goa University
RP Akhtar, MS (通讯作者)，Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801106, Bihar, India.
EM shad.pcs15@iitp.ac.in; palaash77@gmail.com; sukanta.pcs15@iitp.ac.in;
   asif@iitp.ac.in; pb@iitp.ac.in
RI Ekbal, Asif/JKI-7638-2023
FU Visvesvaraya PhD scheme for Electronics and IT, Ministry of Electronics
   and Information Technology (MeitY), Government of India
FX Asif Ekbal acknowledges Young Faculty Research Fellowship (YFRF),
   supported by Visvesvaraya PhD scheme for Electronics and IT, Ministry of
   Electronics and Information Technology (MeitY), Government of India,
   being implemented by Digital India Corporation (formerly Media Lab
   Asia).
CR Akhtar MS, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2703
   Akhtar MS, 2017, KNOWL-BASED SYST, V125, P116, DOI 10.1016/j.knosys.2017.03.020
   Akhtar Md Shad, 2016, P COLING 2016 26 INT, P482
   Akhtar Md Shad, 2018, P 2018 C N AM CHAPTE, P572
   [Anonymous], 2003, HLT NAACL 2003 HUMAN
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bahdanau Dzmitry, 2017, ABS170600286 CORR
   Bakliwal A, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1189
   Balamurali A. R., 2012, P 24 INT C COMP LING, P73
   Barnes Jeremy, 2016, P COLING 2016 26 INT, P1613
   Bhattacharyya P, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3785
   Chernyshevich Maryna, 2014, P 8 INT WORKSH SEM E, P309, DOI DOI 10.3115/V1/S14-2051
   Das A, 2010, WOODHEAD PUBL INDIA, P54
   Dhingra Bhuwan, 2017, CORR
   Faruqui Manaal, 2014, P EACL, DOI [10.3115/v1/E14-1049, DOI 10.3115/V1/E14-1049]
   Firth J. R., 1957, SYNOPSIS LINGUISTIC
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gupta DK, 2015, LECT NOTES COMPUT SC, V9103, P220, DOI 10.1007/978-3-319-19581-0_20
   Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P174, DOI 10.3115/976909.979640
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jagtap V., 2013, INT J SCI ENG TECHNO, V2, P164
   Joshi A., 2010, P 8 ICON
   Kaljahi R, 2016, P WORKSHOP COMPUTATI, P60
   Kim S., 2004, P 20 INT C COMP LING, P1367, DOI DOI 10.3115/1220355.1220555
   Kingma D. P., 2014, C TRACK P
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Luong Thang, 2015, P 1 WORKSHOP VECTOR, P151, DOI [DOI 10.3115/V1/W15-1521, 10]
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mohammad SM, 2016, J ARTIF INTELL RES, V55, P95, DOI 10.1613/jair.4787
   Mukherjee A., 2012, P 50 ANN M ASS COMP, V1, P339
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Pang B., 2005, P ACL, P115, DOI DOI 10.3115/1219840.1219855
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pontiki M., 2014, P 8 INT WORKSHOP SEM, P27, DOI [10.3115/v1/s14-2004, DOI 10.3115/V1/S14-2004]
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Radhakrishna V, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P684
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Singhal P., 2016, P COLING 2016 26 INT, P3053
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Toh Z., 2014, P 8 INT WORKSH SEM E, P235
   Tsai HM, 2008, 2008 FIRST IEEE INTERNATIONAL CONFERENCE ON UBI-MEDIA COMPUTING AND WORKSHOPS, PROCEEDINGS, P231, DOI 10.1109/UMEDIA.2008.4570895
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Vulic I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P719
   Wagner A, 2014, J APPL GEOD, V8, P223, DOI 10.1515/jag-2014-0014
   Wiebe J, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P1065
   Zhou XJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1403
   Zhuang L, 2006, P 15 ACM INT C INF K, DOI [DOI 10.1145/1183614.1183625, 10.1145/1183614.1183625]
NR 50
TC 10
Z9 10
U1 1
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD FEB
PY 2019
VL 18
IS 2
AR 15
DI 10.1145/3273931
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KJ8HG
UT WOS:000512296200007
DA 2023-11-10
ER

PT S
AU Cohen, S
   Kanza, Y
   Sagiv, Y
AF Cohen, S
   Kanza, Y
   Sagiv, Y
BE Ghelli, G
   Grahne, G
TI SQL4X: A flexible query language for XML and relational databases
SO DATABASE PROGRAMMING LANGUAGES
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 8th International Workshop on Database Programming Languages
CY SEP 08-10, 2001
CL FRASCATI, ITALY
SP European Space Agcy, European Space Res Inst, Esprit Working Grp AppSem
ID CONJUNCTIVE QUERIES
AB SQL4X, a powerful language for simultaneously querying both relational and XML databases is presented. Using SQL4X, one can create both relations and XML documents as query results. Thus, SQL4X can be thought of as an integration language. In order to allow easy integration of XML documents with varied structures, SQL4X uses flexible semantics when querying XML. SQL4X is also a powerful query language. It can express quantification, negation, aggregation, grouping and path expressions.
   Datalog(4x) and Tree-Datalog(4x), extensions of Datalog, are defined as elegant abstract models for SQL4X queries. Query containment is characterized for many common classes of SQL4X queries. Specifically, for Datalog(4x) queries, a complete characterization of containment of conjunctive queries and of unions of queries is presented. Equivalence of Datalog(4x) queries under bag-set semantics is also characterized. A sufficient condition for containment of Tree-Datalog(4x) queries is presented. This condition is shown to be complete for a large class of common queries..
C1 Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel.
C3 Hebrew University of Jerusalem
RP Cohen, S (通讯作者)，Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel.
RI Cohen, Sara/JHU-9984-2023
CR ABITEBOUL S, 1996, LOREL QUERY LANGUAGE
   Aho A. V., 1979, ACM Transactions on Database Systems, V4, P435, DOI 10.1145/320107.320112
   Calvanese D., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P389, DOI 10.1109/ICDE.2000.839439
   CALVANESE D, 1999, P 18 S PRINC DAT SYS
   CHAMBERLIN D, 2001, XQUERY 1 0 XML QUERY
   Chandra A., 1977, P 9 ANN ACM S THEOR
   CHAUDHURI S, 1995, P 11 INT C DAT ENG T
   CHAUDHURI S, 1993, P 12 S PRINC DAT SYS
   Clark J., 1999, XSL TRANSFORMATIONS
   COHEN S, 1999, P 18 S PRINC DAT SYS
   DEROSE S, 2001, XML POINTER LANGUAGE
   DEUTSCH A, 1999, 8 INT WORLD WID WEB
   Deutsch A., 1998, XML QL QUERY LANGUAG
   FERNANDEZ M, 1999, XML QUERY LANGUAGES
   FERNANDEZ MF, 2000, P 9 INT WORLD WID WE
   Florescu D., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P139, DOI 10.1145/275487.275503
   GOLDMAN R, 1999, P 2 INT WORKSH WEB D
   GRAHNE G, 1999, 8 INT WORKSH DAT PRO
   IOANNIDIS YE, 1995, ACM T DATABASE SYST, V20, P288, DOI 10.1145/211414.211419
   JOHNSON DS, 1983, SIAM J COMPUT, V12, P616, DOI 10.1137/0212042
   KANZA Y, 2001, P 20 S PRINC DAT SYS
   LEVY A, 1993, P 12 ACM SIGACT SIGM, P109
   Nutt W., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P214, DOI 10.1145/275487.275512
   ROBIE J, 1998, XML QUERY LANGUAGE X
NR 24
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-44080-1
J9 LECT NOTES COMPUT SC
PY 2002
VL 2397
BP 263
EP 280
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BW28C
UT WOS:000181438100016
DA 2023-11-10
ER

PT S
AU Meseguer, J
   Rosu, G
AF Meseguer, J
   Rosu, G
BE Basin, D
   Rusinowitch, M
TI Rewriting logic semantics: From language specifications to formal
   analysis tools
SO AUTOMATED REASONING, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 2nd International Joint Conference on Automated Reasoning (IJCAR 2004)
CY JUL 04-08, 2004
CL Cork, IRELAND
SP Sci Fdn Ireland, Cork Constraint Computat Ctr, Univ Coll Cork
ID FRAMEWORK; MODEL
AB Formal semantic definitions of concurrent languages, when specified in a well-suited semantic framework and supported by generic and efficient formal tools, can be the basis of powerful software analysis tools. Such tools can be obtained for free from the semantic definitions; in our experience in just the few weeks required to define a language's semantics even for large languages like Java. By combining, yet distinguishing, both equations and rules, rewriting logic semantic definitions unify both the semantic equations of equational semantics (in their higher-order denotational version or their first-order algebraic counterpart) and the semantic rules of SOS. Several limitations of both SOS and equational semantics are thus overcome within this unified framework. By using a high-performance implementation of rewriting logic such as Maude, a language's formal specification can be automatically transformed into an efficient interpreter. Furthermore, by using Maude's breadth first search command, we also obtain for free a semi-decision procedure for finding failures of safety properties; and by using Maude's LTL model checker, we obtain, also for free, a decision procedure for LTL properties of finite-state programs. These possibilities, and the competitive performance of the analysis tools thus obtained, axe illustrated by means of a concurrent Caml-like language; similar experience with Java (source and JVM) programs is also summarized.
C1 Univ Illinois, Urbana, IL 61801 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign
RP Meseguer, J (通讯作者)，Univ Illinois, Urbana, IL 61801 USA.
CR [Anonymous], 1998, AMAST SERIES
   [Anonymous], 1992, MATH STRUCT COMP SCI, V2, P119, DOI DOI 10.1017/S0960129500001407
   [Anonymous], 2001, MODEL CHECKING
   BAKER H, 1977, P 1977 IFIP C, P987
   BASIN D, 2000, P 3 WRLA
   BERRY G, 1992, THEOR COMPUT SCI, V96, P217, DOI 10.1016/0304-3975(92)90185-I
   BEST E, 1987, THEOR COMPUT SCI, V55, P87, DOI 10.1016/0304-3975(87)90090-9
   Borovansky P, 2002, THEOR COMPUT SCI, V285, P155, DOI 10.1016/S0304-3975(01)00358-9
   Boudol G., 1985, ALGEBRAIC METHODS SE, P169
   BRAGA C, P WRLA 04 ENTCS
   BRAGA C, 2001, THESIS PONTIFICIA U
   BRAGA C, 2002, 12 INT WORKSH LOPSTR, V2664, P262
   BRAT G, 2000, ASE 00, P3
   BROY M, 1987, ACM T PROGR LANG SYS, V9, P54, DOI 10.1145/9758.10501
   Bruni R, 2003, LECT NOTES COMPUT SC, V2719, P252
   BRUNI R, 1999, THESIS U PISA
   CARABETTA G, 1998, P WRLA 98, V15, P253
   Chen F, 2003, LECT NOTES COMPUT SC, V2706, P197
   Clavel M, 2002, THEOR COMPUT SCI, V285, P187, DOI 10.1016/S0304-3975(01)00359-0
   Clavel M., 2003, MAUDE 2 0 MANUAL
   CLAVEL M, 2000, CAFE IND STRENGTH AL
   Clement D., 1986, P FRANC JAP AI CS S, P49
   Degano P, 2002, THEOR COMPUT SCI, V275, P259, DOI 10.1016/S0304-3975(01)00165-7
   DENICOLA R, 1992, THEORETICAL COMPUTER, V96
   EKER S, 2002, P 4 WRLA ENTCS
   FARZAN A, 2004, SPRINGER LNCS
   FARZAN A, JAVAFAN
   Gadducci F, 2000, FOUNDAT COMPUT, P133
   Goguen J., 1996, ALGEBRAIC SEMANTICS, DOI DOI 10.7551/MITPRESS/1188.001.0001
   GOGUEN JA, 1981, LECT NOTES COMPUT SC, V107, P292
   Havelund K, 2001, IEEE T SOFTWARE ENG, V27, P749, DOI 10.1109/32.940728
   Havelund K., 2000, 5 NASA LANGL FORM ME
   HAVELUND K, 2000, INT J SOFTW TOOLS TE, V2, P366, DOI DOI 10.1007/S100090050043
   Hennessy M., 1990, SEMANTICS PROGRAMMIN
   HINTERMEIER C, 1995, LNCS, V968
   JACOBS B, 2000, NIIIR0318 U NIJM COM
   Johnsen E. B., 2004, P 5 INT WORKSH REWR
   Laneve C., 1996, Mathematical Structures in Computer Science, V6, P219, DOI 10.1017/S0960129500000980
   MARTIOLIET N, 1993, HDB PHILOS LOGIC
   Meseguer J, 2003, NATO SC S SS III C S, V191, P133
   MESEGUER J, 1992, THEOR COMPUT SCI, V96, P73, DOI 10.1016/0304-3975(92)90182-F
   Meseguer J, 1999, LECT NOTES COMPUT SC, V1664, P415
   Meseguer J, 1998, LECT NOTES COMPUT SC, V1376, P62
   Meseguer J, 1998, LECT NOTES COMPUT SC, V1376, P18
   MESEGUER J, 2004, SPRINGER LNCS
   MESEGUER J, 2003, LECT NOTES PROGRAM V
   Meseguer J, 1993, RES DIRECTIONS CONCU, P314
   MESEGUER J, 1996, LECT NOTES COMPUTER, V1119, P331
   Meseguer J., 1992, P 1992 INT S NEW MOD, P61
   MOORE J, 2002, P WORKSH FORM TECHN
   MOORE J, 2003, P CHARME 2003, V2860, P289
   MOSSES PD, 1990, HDB THEORETICAL COMP, VB
   MOSSES PD, 1999, LNCS, V1672, P70
   MOSSES PD, 2002, LNCS, V2422, P21
   MOSSES PD, 2003, IN PRESS J LOGIC ALG
   Ölveczky PC, 2002, THEOR COMPUT SCI, V285, P359, DOI 10.1016/S0304-3975(01)00363-2
   OLVECZKY PC, 2000, THESIS U BERGEN NORW
   Park DYW, 2000, FIFTEENTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, PROCEEDINGS, P253, DOI 10.1109/ASE.2000.873671
   Plotkin G. D., 1981, DAIMIFN19 AARH U
   Reynolds J. C., 1993, LISP and Symbolic Computation, V6, P233, DOI 10.1007/BF01019459
   Rosu G, 2003, LECT NOTES COMPUT SC, V2725, P301
   ROSU G, 2002, P INT C AUT SOFTW EN
   ROSU G, 2003, 322 CS U ILL URB CHA
   Scott D, 1970, 4 ANN PRINC C INF SC, P169
   STEGGLES LJ, 2001, LNCS, V2075, P363, DOI DOI 10.1007/3-540-45740-2_21
   Stehr M.-O., 2000, P 3 INT WORKSH REWR
   Stehr MO, 2001, LECT NOTES COMPUT SC, V2128, P250
   STEHR MO, 2004, IN PRESS LNCS, V2635
   STEHR MO, 2001, PETRI NETS SYSTEM EN
   STEHR MO, 2002, THESIS U HAMBURG GER
   STEHR MO, 2002, P 4 WRLA ENTCS ELS
   Strachey C., 2000, Higher-Order and Symbolic Computation, V13, P11, DOI 10.1023/A:1010000313106
   Talcott C. L., 2002, THEORETICAL COMPUTER, V285
   TALCOTT CL, 1997, P IFIP C FORM METH O, P154
   THATI P, 2002, P 4 WRLA ENTCS
   TURI D, 1996, THESIS FREE U AMSTER
   Verdejo A., 2003, THESIS U COMPLUTENSE
   VERDEJO A, 2000, IFIP C P, V183, P351
   VERDEJO A, 2002, P 4 WRLA ENTCS
   VERDEJO A, 2003, UNPUB EXECUTABLE STR
   Verdejo A., 2000, INT 2000 INT SPECIFI, P49
   Viry P, 2002, THEOR COMPUT SCI, V285, P487, DOI 10.1016/S0304-3975(01)00366-8
   Viry P, 1999, J SYMB COMPUT, V28, P381, DOI 10.1006/jsco.1999.0288
   VIRY P, 1996, P WRLA 96 SEPT 3 6, P51
   VISSER W, 2000, P POST CAV WORKSH AD
   WANG M, 1980, ACTA INFORM, V14, P337
   1996, P WRLA 96 SEPT 3 6 1, V4
NR 87
TC 47
Z9 47
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-22345-2
J9 LECT NOTES ARTIF INT
PY 2004
VL 3097
BP 1
EP 44
PG 44
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BAK73
UT WOS:000222645100001
DA 2023-11-10
ER

PT J
AU Chu, CH
   Oliveira, V
   Virgo, FG
   Otani, M
   Garcia, N
   Nakashima, Y
AF Chu, Chenhui
   Oliveira, Vinicius
   Virgo, Felix Giovanni
   Otani, Mayu
   Garcia, Noa
   Nakashima, Yuta
TI The semantic typology of visually grounded paraphrases
SO COMPUTER VISION AND IMAGE UNDERSTANDING
LA English
DT Article
DE Vision and language; Image interpretation; Visual grounded paraphrases;
   Semantic typology; Dataset
AB Visually grounded paraphrases (VGPs) are different phrasal expressions describing the same visual concept in an image. Previous studies treat VGP identification as a binary classification task, which ignores various phenomena behind VGPs (i.e., different linguistic interpretation of the same visual concept) such as linguistic paraphrases and VGPs from different aspects. In this paper, we propose semantic typology for VGPs, aiming to elucidate the VGP phenomena and deepen the understanding about how human beings interpret vision with language. We construct a large VGP dataset that annotates the class to which each VGP pair belongs according to our typology. In addition, we present a classification model that fuses language and visual features for VGP classification on our dataset. Experiments indicate that joint language and vision representation learning is important for VGP classification. We further demonstrate that our VGP typology can boost the performance of visually grounded textual entailment.
C1 [Chu, Chenhui; Virgo, Felix Giovanni] Kyoto Univ, Sakyo Ku, Yoshida Honmachi, Kyoto 6068501, Japan.
   [Oliveira, Vinicius] Ecole Polytech, Route Saclay, F-91120 Palaiseau, France.
   [Otani, Mayu] CyberAgent Inc, Shibuya Ku, 40-1 Abema Towers,Udagawacho, Tokyo 1500042, Japan.
   [Garcia, Noa; Nakashima, Yuta] Osaka Univ, 1-1 Yamadaoka, Suita, Osaka 5650871, Japan.
C3 Kyoto University; Institut Polytechnique de Paris; Osaka University
RP Chu, CH (通讯作者)，Kyoto Univ, Sakyo Ku, Yoshida Honmachi, Kyoto 6068501, Japan.
EM chu@i.kyoto-u.ac.jp
RI Nakashima, Yuta/O-6299-2014
OI Nakashima, Yuta/0000-0001-8000-3567; Otani, Mayu/0000-0001-9923-2669;
   Chu, Chenhui/0000-0001-9848-6384; Virgo, Felix
   Giovanni/0000-0002-9523-2343
FU ACT-I, JST; JSPS KAKENHI [18H03264]; Grants-in-Aid for Scientific
   Research [18H03264] Funding Source: KAKEN
FX This work was supported by ACT-I, JST and JSPS KAKENHI No. 18H03264.
CR Aafaq N, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355390
   Androutsopoulos I, 2010, J ARTIF INTELL RES, V38, P135, DOI 10.1613/jair.2985
   [Anonymous], 2006, P HUMAN LANGUAGE TEC
   [Anonymous], 2013, P EMNLP C
   [Anonymous], 2013, P 2013 C N AM CHAPT
   Baker C.F., 1998, 36 ANN M ASS COMPUTA, P86, DOI DOI 10.3115/980845.980860
   Benikova D., 2017, P RANLP 2017, DOI DOI 10.26615/978-954-452-049-6_014
   Berant J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1415, DOI 10.3115/v1/p14-1133
   Bhagat R, 2013, COMPUT LINGUIST, V39, P463, DOI 10.1162/COLI_a_00166
   Callison-Burch C, 2006, P MAIN C HUMAN LANGU, P17
   Chen K, 2017, IEEE I CONF COMP VIS, P824, DOI 10.1109/ICCV.2017.95
   Chu C., 2018, P 27 INT C COMP LING, P3479
   Chu CH, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P644
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, ARXIV, V1, P4171
   Dolan B., 2004, P 20 INT C COMP LING, DOI DOI 10.3115/1220355.1220406
   Dong WJ, 2021, IEEE ACCESS, V9, P349, DOI 10.1109/ACCESS.2020.3046719
   Faruqui Manaal., 2015, P 2015 C N AM CHAPT, P1606, DOI [10.3115/v1/N15-1184, DOI 10.3115/V1/N15-1184]
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Fukui Akira, 2016, ARXIV160601847, P457, DOI [DOI 10.18653/V1/D16-1044, 10.18653/v1/D16-1044]
   Goodman S., 2016, UNDERSTANDING IMAGE
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodosh M., 2014, P TACL, V7, P67, DOI [10.1162/tacl_a_00166, DOI 10.1162/TACL_A_00166]
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   King DB, 2015, ACS SYM SER, V1214, P1
   Kovatchev V, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1384
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Liu Dacheng, 2019, IEEE T PATTERN ANAL
   Lu JS, 2019, ADV NEUR IN, V32
   MacCartney B., 2009, THESIS STANFORD U ST
   Mikolov T., 2013, ARXIV13013781 CS, DOI DOI 10.48550/ARXIV.1301.3781
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Otani M., 2019, P ICCV 2019 MDALC WO
   Otani M, 2020, NEUROCOMPUTING, V404, P165, DOI 10.1016/j.neucom.2020.04.066
   Pavlick E, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1512
   Plummer BA, 2017, IEEE I CONF COMP VIS, P1946, DOI 10.1109/ICCV.2017.213
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Richang Hong, 2015, IEEE Transactions on Big Data, V1, P152, DOI 10.1109/TBDATA.2016.2515640
   Riezler Stefan, 2007, P 45 ANN M ASS COMPU, P464
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Samaran J, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P81
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vila M., 2014, OPEN J MODERN LINGUI, V4, P205, DOI DOI 10.4236/OJML.2014.41016
   Vila M, 2015, LANG RESOUR EVAL, V49, P77, DOI 10.1007/s10579-014-9272-5
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vu H.T., 2018, P 27 INT C COMPUTATI, P2354
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang MZ, 2016, LECT NOTES COMPUT SC, V9912, P696, DOI 10.1007/978-3-319-46484-8_42
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xiujun I, 2020, ECCV
   Yang Shuai, 2020, ECCV
   Yeh R. A., 2017, ADV NEURAL INFORM PR, P1909
   Yu Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1114
   Zhengyuan Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P387, DOI 10.1007/978-3-030-58568-6_23
NR 56
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1077-3142
EI 1090-235X
J9 COMPUT VIS IMAGE UND
JI Comput. Vis. Image Underst.
PD JAN
PY 2022
VL 215
AR 103333
DI 10.1016/j.cviu.2021.103333
EA DEC 2021
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XX4OD
UT WOS:000736276200001
OA Green Published, hybrid
DA 2023-11-10
ER

PT J
AU Fu, YF
   Ho, CS
AF Fu, Yu-Fen
   Ho, Cheng-Seen
TI A USER-DEPENDENT EASILY-ADJUSTED STATIC FINGER LANGUAGE RECOGNITION
   SYSTEM FOR HANDICAPPED APHASIACS
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
AB Unlike sign language, which usually involves large-scale movements to form a gesture, finger language, suitable for handicapped aphasiacs, is represented by relatively small-scale hand gestures accessible by a mere change of the bending manner of a patient's fingers. Therefore, we need a system that can tackle the specificity of each handicapped aphasiac. We propose a system that fulfills this requirement by employing a programmable data glove to capture tiny movement-related finger gestures, an optical signal value-parameterized function to calculate the finger bending degrees, and an automatic regression module to extract most adequate finger features for a specific patient. The selected features are fed into a neural network, which learns to build a finger language recognition model for the specific patient. Then the system can be available for use by the specific user. At the time of this writing, the achieved average success rate was 100% from unbiased field experiments.
C1 [Fu, Yu-Fen] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   [Fu, Yu-Fen] China Univ Technol, Taipei, Taiwan.
   [Ho, Cheng-Seen] Tuangnan Univ, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Fu, YF (通讯作者)，Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sec 4,Shinglung Rd, Taipei 106, Taiwan.
EM yfen@cute.edu.tw
FU National Science Council, Taiwan, ROC [NSC 93-2622-E-163-001-CC3, NSC
   94-2213-E-163-003]
FX The authors gratefully acknowledge the financial support provided by the
   National Science Council, Taiwan, ROC under grants NSC
   93-2622-E-163-001-CC3 and NSC 94-2213-E-163-003. We would also like to
   thank the generous assistance of Dr. Lih-Horng Shyu, Department of
   Electro-Optics Engineering, National Formosa University with the
   construction of the data glove.
CR FU YF, 2007, P 2 INT C INN COMP I
   FU YF, 2008, SMART MATER STRUCT, V6, P1
   GILDEN DB, 1993, P VIRT REAL C
   JIANGQIN W, 2001, J COMM HITECH, V11, P23
   MEADE AD, 1987, P IEEE INT C ROB AUT, V4, P1192
   WEI Z, 2003, J SYSTEM SIMULATION, V15, P290
   YAXIN Z, 2001, BEIJING J U SCI TECH, V23, P284
NR 7
TC 3
Z9 3
U1 2
U2 4
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PY 2009
VL 23
IS 10
BP 932
EP 944
AR PII 916863703
DI 10.1080/08839510903363487
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 520AV
UT WOS:000271813000003
OA Bronze
DA 2023-11-10
ER

PT J
AU O'Riordan, LJ
   Doyle, M
   Baruffa, F
   Kannan, V
AF O'Riordan, Lee J.
   Doyle, Myles
   Baruffa, Fabio
   Kannan, Venkatesh
TI A hybrid classical-quantum workflow for natural language processing
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE quantum computing; NLP; AI; HPC
AB Natural language processing (NLP) problems are ubiquitous in classical computing, where they often require significant computational resources to infer sentence meanings. With the appearance of quantum computing hardware and simulators, it is worth developing methods to examine such problems on these platforms. In this manuscript we demonstrate the use of quantum computing models to perform NLP tasks, where we represent corpus meanings, and perform comparisons between sentences of a given structure. We develop a hybrid workflow for representing small and large scale corpus data sets to be encoded, processed, and decoded using a quantum circuit model. In addition, we provide our results showing the efficacy of the method, and release our developed toolkit as an open software suite.
C1 [O'Riordan, Lee J.; Doyle, Myles; Kannan, Venkatesh] Irish Ctr High End Comp, Dublin, Ireland.
   [O'Riordan, Lee J.; Doyle, Myles; Kannan, Venkatesh] Natl Univ Ireland, Galway, Ireland.
   [Baruffa, Fabio] Intel Deutschland GmbH, Feldkirchen, Germany.
C3 Ollscoil na Gaillimhe-University of Galway; Intel Corporation
RP O'Riordan, LJ (通讯作者)，Irish Ctr High End Comp, Dublin, Ireland.; O'Riordan, LJ (通讯作者)，Natl Univ Ireland, Galway, Ireland.
EM lee.oriordan@ichec.ie
RI O'Riordan, Lee J/C-3627-2012
OI O'Riordan, Lee J/0000-0002-6758-9433; Doyle, Myles/0000-0001-7889-8357
FU Enterprise Ireland; European Union [IP 2018 0751]; Intel
FX We would like to thank Prof. Bob Coecke and Dr Ross Duncan for
   discussions and suggestions during the early stages of this work. The
   work leading to this publication has received funding from Enterprise
   Ireland and the European Union's Regional Development Fund under grant
   agreement IP 2018 0751. The opinions, findings and conclusions or
   recommendations expressed in this material are those of the authors and
   neither Enterprise Ireland nor the European Union are liable for any use
   that may be made of information contained herein. The authors also
   acknowledge funding and support from Intel during the duration of this
   project.
CR Aerts D, 2014, LECT NOTES COMPUT SC, V8369, P71, DOI 10.1007/978-3-642-54943-4_7
   [Anonymous], 2016, ARXIV160107195
   Arunachalam S, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/12/123010
   BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457
   Bausch J., 2019, ARXIV19090523
   Bird S., 2009, NATURAL LANGUAGE PRO, Vfirst
   Blacoe W, 2015, LECT NOTES COMPUT SC, V8951, P41, DOI 10.1007/978-3-319-15931-7_4
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Coecke B., 2010, ARXIV10034394
   Coecke B., 2020, QUANTUM NATURAL LANG
   Coecke B., 2019, ARXIV190403478
   Coecke B, 2011, NEW J PHYS, V13, DOI 10.1088/1367-2630/13/4/043016
   Cowtan Alexander, 2019, LEIBNIZ INT P INFORM, V135, P1, DOI DOI 10.4230/LIPICS.TQC.2019.5
   de Felice G., 2020, P 3 ANN INT APPL CAT
   Di Matteo O., 2020, IEEE T QUANTUM ENG, V1, P1, DOI [10.1109/TQE.2019.2960170, DOI 10.1109/TQE.2019.2960170]
   Giovannetti V, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.160501
   Guerreschi GG, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab8505
   Hagberg A. A., 2008, P PYTH SCI C
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Harrow A.W., 2020, ARXIV200400026
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jaiswal AK., 2018, P C LERN WISS DAT AN, P159
   Jakob Wenzel, 2017, PYBIND11 SEAMLESS OP
   Lambek J., 2008, Journal of Logic, Language and Information, V17, P141, DOI 10.1007/s10849-007-9053-2
   Levy Omer., 2014, P COMPUTATIONAL NATU, DOI [DOI 10.3115/V1/W14-1618, 10.3115/v1/W14-1618]
   McKinney W., 2010, P 9 PYTH SCI C AUST, P56, DOI 10.25080/majora-92bf1922-00a
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T., 2013, P WORKSHOP ICLR
   Mitarai K, 2019, PHYS REV A, V99, DOI 10.1103/PhysRevA.99.012301
   Nisbet R, 2009, HDB STAT ANAL DATA M, DOI [10.1016/B978-0-12-374765-5.X0001-0, DOI 10.1016/B978-0-12-374765-5.00052-8]
   O'Riordan LJ., 2020, QNLP ICHEC QUANTUM N, DOI [10.5281/zenodo.3743034, DOI 10.5281/ZENODO.3743034]
   Socher R., 2013, LONG PAPERS, V1, P455
   Tiwari P, 2018, ARXIV181004491
   Trugenberger CA, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.067901
   Trugenberger CA, 2002, QUANTUM INF PROCESS, V1, P471, DOI 10.1023/A:1024022632303
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wang B., 2019, QUANTUM LIKE MODELS, P83, DOI [10.1007/978-3-030-25913-6_5, DOI 10.1007/978-3-030-25913-6_5]
   Wang BY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1444, DOI 10.1145/3331184.3331412
   Wiebe N., 2019, ARXIV190205162
   Wiebe N, 2015, QUANTUM INF COMPUT, V15, P316
   Zeng W, 2016, ELECTRON P THEOR COM, P67, DOI 10.4204/EPTCS.221.8
NR 45
TC 7
Z9 7
U1 2
U2 11
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR
PY 2021
VL 2
IS 1
AR 015011
DI 10.1088/2632-2153/abbd2e
PG 24
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SQ6YW
UT WOS:000660500300016
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Body, T
   Tao, XH
   Li, YF
   Li, L
   Zhong, N
AF Body, Thomas
   Tao, Xiaohui
   Li, Yuefeng
   Li, Lin
   Zhong, Ning
TI Using back-and-forth translation to create artificial augmented textual
   data for sentiment analysis models
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Natural language processing; Translation; Sentiment analysis; Data
   augmentation
AB Sentiment analysis classification models trained using neural networks require large amounts of data, but collecting these datasets requires significant time and resources. Although artificial data has been used successfully in computer vision, there are few effective and generalizable methods for creating artificial augmented text data. In this paper, a text based data augmentation method is proposed called back-and-forth translation that can be used to artificially increase the size of any natural language dataset. By creating augmented text data and adding it to the original dataset, it is demonstrated by empirical experiments that back-and-forth translation data augmentation can reduce the error rate in binary sentiment classification models by up to 3.4%. These results are shown to be statistically significant.
C1 [Body, Thomas; Tao, Xiaohui] Univ Southern Queensland, Sch Sci, Darling Hts, Qld, Australia.
   [Li, Yuefeng] Queensland Univ Technol, Sci & Engn Fac, Brisbane, Qld, Australia.
   [Li, Lin] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Zhong, Ning] Maebashi Inst Technol, Dept Life Sci & Informat, Maebashi, Gumma, Japan.
C3 University of Southern Queensland; Queensland University of Technology
   (QUT); Wuhan University of Technology
RP Body, T; Tao, XH (通讯作者)，Univ Southern Queensland, Sch Sci, Darling Hts, Qld, Australia.
EM u1101544@umail.usq.edu.au; xiaohui.tao@usq.edu.au; y2.li@qut.edu.au;
   cathylilin@whut.edu.cn; zhong@maebashi-it.ac.jp
RI li, yueyue/IVH-9846-2023; li, li/HII-4157-2022; LI, Yue/GRS-8071-2022;
   Tao, Xiaohui/JKI-2330-2023; Li, Li/AEM-3636-2022; Li, Yue/B-7669-2016
OI Li, Yue/0000-0001-9562-3136
CR [Anonymous], 2014, ARXIV14021128CSSTAT
   [Anonymous], 2015, NIPSX 15 P 28 INT C
   [Anonymous], ARXIV PREPRINT ARXIV
   Bar D., 2015, TUDCS20150017
   Campos D. F., 2016, ARXIV161109268V3
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Fei Hongliang, 2020, P 58 ANN M ASS COMP, P5759, DOI DOI 10.18653/V1/2020.ACL-MAIN.510
   Galinsky R, 2016, PROCEEDINGS OF THE 2016 IEEE ARTIFICIAL INTELLIGENCE AND NATURAL LANGUAGE CONFERENCE (AINL FRUCT 2016), P45
   Gao F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5539
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Honnibal Matthew, 2015, P 2015 C EMPIRICAL M, P1373, DOI 10.18653/v1/d15-1162
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kim Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1246
   Kobayashi S., 2018, P 2018 C N AM CHAPTE, V2, P452, DOI 10.18653/v1/N18-2072
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A., 2019, P 2019 C N AM ASS CO, V1, P3609
   Li Jiwei, 2015, ARXIV150601066, DOI DOI 10.18653/V1/N16-1082
   Li Y, 2020, INFORMATION, V11, DOI 10.3390/info11050255
   Longadge R., 2013, ARXIV13051707, V2, P83, DOI [DOI 10.48550/ARXIV.1305.1707, DOI 10.1109/SIU.2013.6531574]
   Lun JQ, 2020, AAAI CONF ARTIF INTE, V34, P13446
   Luo GX, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6140153
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   Maynard D, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1142
   McCann Bryan, 2017, ADV NEURAL INFORM PR, P6297
   Mesbah S., 2020, THESIS DELFT U TECHN, DOI [10.4233/uuid:dbbfe1fc-bf63-45f0-8cf2-28ed7dab90eb, DOI 10.4233/UUID:DBBFE1FC-BF63-45F0-8CF2-28ED7DAB90EB]
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Qiu SY, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P249, DOI 10.1145/3366424.3383552
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Shakeel MH, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102204
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sun X, 2017, INT CONF AFFECT, P12, DOI 10.1109/ACIIW.2017.8272616
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   Tran Toan, 2017, ADV NEURAL INFORM PR, P2794, DOI DOI 10.5555/3294996.3295039
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang XK, 2019, INT J INNOV COMPUT I, V15, P227, DOI 10.24507/ijicic.15.01.227
   Wang Yequan, 2016, P 2016 C EMP METH NA, P606, DOI [DOI 10.18653/V1/D16-1058, 10.18653/v1/D16-1058]
   Wieting John, 2017, P 2017 C EMP METH NA, P274, DOI DOI 10.18653/V1/D17-1026
   Wu X, 2019, LECT NOTES COMPUT SC, V11539, P84, DOI 10.1007/978-3-030-22747-0_7
   Yaeger L., 1996, P NIPS, P807
   Yi K, 2019, PROC CVPR IEEE, P7010, DOI 10.1109/CVPR.2019.00718
   Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897
NR 45
TC 6
Z9 6
U1 3
U2 20
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 15
PY 2021
VL 178
AR 115033
DI 10.1016/j.eswa.2021.115033
EA APR 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA UR4HD
UT WOS:000696711100011
DA 2023-11-10
ER

PT J
AU Feng, D
   Chen, HN
AF Feng, Dan
   Chen, Hainan
TI A small samples training framework for deep Learning-based automatic
   information extraction: Case study of construction accident news reports
   analysis
SO ADVANCED ENGINEERING INFORMATICS
LA English
DT Article
DE Automatic information extraction; Small sample training; Cross
   combination-based text augmentation; Construction accident news reports
ID SAFETY PERFORMANCE; MANAGEMENT; KNOWLEDGE; SYSTEM; NLP
AB Knowledge management is crucial for construction safety management. Widely collected and well-organized safety-related documents are recognized to be significant in raising the workers' security awareness and then to prevent hazards and accidents. To improve document processing efficiency, automatic information extraction plays an important role. However, currently, automatic information extraction modeling requires large scale training datasets. It is a big challenge for the engineering industry, especially for the fields which heavily rely on the experts' knowledge. Limited data sources, and high time and labor costs make it not practical to establish a large-scale dataset. This work proposed a natural language data augmentation-based small samples training framework for automatic information extraction modeling. With the designed cross combination-based text data augmentation algorithm, the deep neural network can be employed to build up automatic information extraction models without large-scale raw data and manual annotations. Characters semantic coding is employed to avoid word segmentation and make sure that the framework can be utilized in different writing language systems. The BiLSTM-CRF model is adopted as the detection core to conduct character classification. Through a case study of two independent accident news report datasets analysis, the proposed framework has been validated. A reliable and robust automatic information extraction model can be established, even though with small samples training.
C1 [Feng, Dan] Wuhan Univ, Sch Econ & Management, Wuhan 420106, Peoples R China.
   [Feng, Dan] China Construct Seventh Engn Div Corp LTD, Zhengzhou 450004, Peoples R China.
   [Chen, Hainan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518000, Peoples R China.
C3 Wuhan University; Sun Yat Sen University
RP Chen, HN (通讯作者)，Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518000, Peoples R China.
EM hn.chen@live.com
RI CHEN, Hainan/L-9003-2019
OI CHEN, Hainan/0000-0002-6864-6268
FU China Postdoctoral Science Foundation [2019M663239]; Fundamental
   Research Funds for the Central Universities [19lgpy289]
FX This work was jointly supported by China Postdoctoral Science Foundation
   (2019M663239) and the Fundamental Research Funds for the Central
   Universities (grant no. 19lgpy289). The conclusions herein are those of
   the authors and do not necessarily reflect the views of the sponsoring
   agencies.
CR Auch F, 2010, INT J MANAG PROJ BUS, V3, P443, DOI 10.1108/17538371011056075
   Bamel UK, 2020, ACCIDENT ANAL PREV, V135, DOI 10.1016/j.aap.2019.105387
   Chen HN, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100959
   Chi N.W., 2017, GAZETTEERS INFORM EX, P401
   Dawood H, 2019, J INF TECHNOL CONSTR, V24, P540, DOI 10.36680/j.itcon.2019.030
   Duryan M, 2020, ACCIDENT ANAL PREV, V139, DOI 10.1016/j.aap.2020.105496
   Ghazal MM, 2022, INT J CONSTR MANAG, V22, P1632, DOI 10.1080/15623599.2020.1738205
   Gunduz M, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/2610306
   Hardison D, 2019, SAFETY SCI, V120, P517, DOI 10.1016/j.ssci.2019.08.001
   Hassan FU, 2020, J LEG AFF DISPUTE RE, V12, DOI 10.1061/(ASCE)LA.1943-4170.0000379
   Hassani K, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932710
   Huang YH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11226426
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Kim T, 2019, J CONSTR ENG M, V145, DOI 10.1061/(ASCE)CO.1943-7862.0001625
   Lample G., 2016, P HLTNAACL
   Levy O., 2014, ARXIV PREPRINT ARXIV
   Li J, 2015, SAFETY SCI, V74, P70, DOI 10.1016/j.ssci.2014.12.003
   Li SQ, 2020, J CLEAN PROD, V257, DOI 10.1016/j.jclepro.2020.120581
   Liu QJ, 2020, ENG CONSTR ARCHIT MA, V27, P765, DOI 10.1108/ECAM-03-2019-0136
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Mansouri S, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001759
   Mohammadi A, 2018, SAFETY SCI, V109, P382, DOI 10.1016/j.ssci.2018.06.017
   Nazeer, P 2018 INT C COMP PO, P1072
   Nnaji C, 2020, J TRAFFIC TRANSP ENG, V7, P61, DOI 10.1016/j.jtte.2019.11.001
   Stenetorp P., 2012, P DEM 13 C EUR CHAPT, P102
   Tang LYN, 2017, J MANAGE ENG, V33, DOI 10.1061/(ASCE)ME.1943-5479.0000554
   Tixier AJP, 2016, AUTOMAT CONSTR, V62, P45, DOI 10.1016/j.autcon.2015.11.001
   Toutanova K., ARXIV PREPRINT ARXIV
   Wang WM, 2008, INFORM PROCESS MANAG, V44, P1707, DOI 10.1016/j.ipm.2008.05.002
   Winge S, 2019, J SAFETY RES, V71, P139, DOI 10.1016/j.jsr.2019.09.015
   Xie QP, 2019, IEEE ACCESS, V7, P32672, DOI 10.1109/ACCESS.2019.2903106
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Ye Zhixiu, 2018, P 56 ANN M ASS COMP, V2, P235
   Yu ES, 2019, ENERGIES, V12, DOI 10.3390/en12234425
   Zhang JS, 2017, AUTOMAT CONSTR, V73, P45, DOI 10.1016/j.autcon.2016.08.027
   Zhang JS, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000346
   Zhang JS, 2015, J COMPUT CIVIL ENG, V29, DOI 10.1061/(ASCE)CP.1943-5487.0000427
   Zou Y, 2017, AUTOMAT CONSTR, V80, P66, DOI 10.1016/j.autcon.2017.04.003
NR 38
TC 33
Z9 33
U1 12
U2 60
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1474-0346
EI 1873-5320
J9 ADV ENG INFORM
JI Adv. Eng. Inform.
PD JAN
PY 2021
VL 47
AR 101256
DI 10.1016/j.aei.2021.101256
EA FEB 2021
PG 13
WC Computer Science, Artificial Intelligence; Engineering,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QY9OF
UT WOS:000630364600035
DA 2023-11-10
ER

PT J
AU Sahin, GG
   Vania, C
   Kuznetsov, I
   Gurevych, I
AF Sahin, Goezde Guel
   Vania, Clara
   Kuznetsov, Ilia
   Gurevych, Iryna
TI LINSPECTOR: Multilingual Probing Tasks for Word Representations
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Despite an ever-growing number of word representation models introduced for a large number of languages, there is a lack of a standardized technique to provide insights into what is captured by these models. Such insights would help the community to get an estimate of the downstream task performance, as well as to design more informed neural architectures, while avoiding extensive experimentation that requires substantial computational resources not all researchers have access to. A recent development in NLP is to use simple classification tasks, also called probing tasks, that test for a single linguistic feature such as part-of-speech. Existing studies mostly focus on exploring the linguistic information encoded by the continuous representations of English text. However, from a typological perspective the morphologically poor English is rather an outlier: The information encoded by the word order and function words in English is often stored on a subword, morphological level in other languages. To address this, we introduce 15 type-level probing tasks such as case marking, possession, word length, morphological tag count, and pseudoword identification for 24 languages. We present a reusable methodology for creation and evaluation of such tests in a multilingual setting, which is challenging because of a lack of resources, lower quality of tools, and differences among languages. We then present experiments on several diverse multilingual word embedding models, in which we relate the probing task performance for a diverse set of languages to a range of five classic NLP tasks: POS-tagging, dependency parsing, semantic role labeling, named entity recognition, and natural language inference. We find that a number of probing tests have significantly high positive correlation to the downstream tasks, especially for morphologically rich languages. We show that our tests can be used to explore word embeddings or black-box neural models for linguistic cues in a multilingual setting. We release the probing data sets and the evaluation suite LINSPECTOR with.
C1 [Sahin, Goezde Guel; Kuznetsov, Ilia; Gurevych, Iryna] Tech Univ Darmstadt, AIPHES & UKP Lab, Darmstadt, Germany.
   [Sahin, Goezde Guel] Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.
   [Vania, Clara] NYU, New York, NY 10003 USA.
   [Vania, Clara] Univ Edinburgh, ILCC, Edinburgh, Midlothian, Scotland.
C3 Technical University of Darmstadt; Technical University of Darmstadt;
   New York University; University of Edinburgh
RP Sahin, GG (通讯作者)，Tech Univ Darmstadt, AIPHES & UKP Lab, Darmstadt, Germany.; Sahin, GG (通讯作者)，Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.
EM sahin@ukp.informatik.tu-darmstadt.de; c.vania@nyu.edu;
   Kuznetsov@ukp.informatik.tu-darmstadt.de;
   Gurevych@ukp.informatik.tu-darmstadt.de
OI Sahin, Gozde Gul/0000-0002-0332-1657
FU DFG [GRK 1994/1]; German Federal Ministry of Education and Research
   (BMBF) [01UG1816B, 01IS17050]; Indonesian Endowment Fund for Education
   (LPDP); Centre for Doctoral Training in Data Science - UK EPSRC
   [EP/L016427/1]; University of Edinburgh
FX We first thank the anonymous reviewers who helped us improve the paper.
   We would like to thank Marvin Kaster for his help on contextualizing the
   probing tasks and to Max Eichler for his contribution on acquiring
   experimental results for additional languages in Appendix C. We are
   sincerely grateful to Adam Lopez, Ida Szubert, Ji-Ung Lee, Edwin
   Simpson, and members of AGORA Lab for providing feedback on early drafts
   of this work. This research has been supported by the DFG-funded
   research training group "Adaptive Preparation of Information form
   Heterogeneous Sources" (AIPHES, GRK 1994/1), and also by the German
   Federal Ministry of Education and Research (BMBF) under the promotional
   reference 01UG1816B (CEDIFOR) and as part of the Software Campus program
   under the promotional reference 01IS17050. We gratefully acknowledge the
   support of NVIDIA Corp. with the donation of the Tesla K40 GPU used for
   this research. Clara Vania is supported by the Indonesian Endowment Fund
   for Education (LPDP), the Centre for Doctoral Training in Data Science,
   funded by the UK EPSRC (grant EP/L016427/1), and the University of
   Edinburgh. We finally thank UKP system administrators for their system
   maintenance efforts and Celal Sahin for helping with system
   configuration errors.
CR Adi Yossi, 2017, INT C LEARNING REPRE, P1
   Aggarwal Rakesh, 2016, Perspect Clin Res, V7, P187
   [Anonymous], 2017, PROC 2 WORKSHOP EVAL
   [Anonymous], 2017, SEMEVAL ACL, DOI DOI 10.18653/V1/S17-2002
   Ataman D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P305
   Belinkov Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P861, DOI 10.18653/v1/P17-1080
   Belinkov Yonatan, 2019, T ASS COMPUTATIONAL
   Bengtson E., 2008, EMNLP, P294
   Benikova Darina, 2014, P KONVENS GERMEVAL S, P104
   Bisazza A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2871
   Blake Barry J., 2001, CASE, P119
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Bruni L, 2012, GENESIS AND ETHOS OF THE MARKET, P136
   Che Wanxiang, 2018, P CONLL 2018 SHARED, P55
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Comrie B., 1998, CASE TYPOLOGY GRAMMA, P95
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Conneau Alexis, 2018, EMNLP
   Conneau Alexis, 2018, P ICLR
   Corbett G. G., 2013, WORLD ATLAS LANGUAGE
   Cotterell R, 2019, T ASSOC COMPUT LING, V7, P327, DOI 10.1162/tacl_a_00271/1923163
   Cotterell Ryan, 2018, P 2018 C N AM CHAPT, V2, P536
   Dozat T., 2017, ICLR
   Eichler M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P127
   Erten B, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2106
   Eryigit Gulsen, 2008, Computational Linguistics, V34, P357, DOI 10.1162/coli.2008.07-017-R1-06-83
   Faruqui Manaal., 2015, P 2015 C N AM CHAPT, P1606, DOI [10.3115/v1/N15-1184, DOI 10.3115/V1/N15-1184]
   Finkelstein L., 2001, WWW
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI DOI 10.5555/177910.177914
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P1
   Gerz D., 2018, T ASSOC COMPUT LING, V6, P451, DOI DOI 10.1162/TACL_A_00032
   Ghaddar Abbas, 2017, P 8 INT JOINT C NAT, V1, P413
   Hajic J., 2009, P 13 C COMP NAT LANG, P1, DOI DOI 10.3115/1596409.1596411
   Haverinen K, 2015, LANG RESOUR EVAL, V49, P907, DOI 10.1007/s10579-015-9310-y
   Heinzerling B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2989
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Hohensee Matt, 2012, P 2012 C N AM CHAPT, P315
   Huang EH, 2012, ACL, V1, P873
   Huang Zhiheng, 2015, ARXIV
   Iggesen Oliver A., 2013, WORLD ATLAS LANGUAGE
   Isguder Gozde Gul, 2014, P WORKSH LEX GRAMM R, P46
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   Kirov C, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1868
   Kohn Arne, 2015, P 2015 C EMP METH NA, P2067, DOI [DOI 10.18653/V1/D15-1246, 10.18653/v1/D15-1246]
   Kohn Arne, 2016, P 1 WORKSH EV VECT S, P67
   Kutuzov Andrei, 2017, P 21 NORDIC C COMPUT, P271
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Ling W., 2015, P 2015 C EMP METH NA, P1520, DOI [DOI 10.18653/V1/D15-1176, DOI 10.18653/V1]
   Linzen, 2016, P 1 WORKSH EV VECT S, P13, DOI DOI 10.18653/V1/W16-2503
   Luong T., 2013, P 17 C COMP NAT LANG, P104, DOI DOI 10.1007/BF02579642
   McCarthy Arya D., 2018, P 2 WORKSH UN DEP UD, P91, DOI DOI 10.18653/V1/W18-6011
   McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI [10.3115/1219840.1219852, DOI 10.3115/1219840.1219852]
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T., 2013, EFFICIENT ESTIMATION, P1, DOI [10.1162/153244303322533223, DOI 10.1162/153244303322533223]
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Nayak N, 2016, REPE VAL ACL, P19, DOI 10.18653/v1/W16-2504
   Nivre Joakim, 2018, UNIVERSAL DEPENDENCI
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Pilehvar MT, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1857, DOI 10.18653/v1/P17-1170
   Qian P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1478
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rogers Anna, 2018, P 27 INT C COMP LING, P2690
   Rogers BM, 2017, UNPOPULAR SOVEREIGNTY: MORMONS AND THE FEDERAL MANAGEMENT OF EARLY UTAH TERRITORY, P135
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Sahin GG, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P386
   Sahin GG, 2018, LANG RESOUR EVAL, V52, P673, DOI 10.1007/s10579-017-9390-y
   Sahin H. Bahadir, 2017, AUTOMATICALLY ANNOTA
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Schnabel T., 2015, P 2015 C EMPIRICAL M, P298, DOI 10.18653/v1/D15-1036
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi X., 2016, P 2016 C EMP METH NA, P1526, DOI DOI 10.18653/V1/D16-1159
   Sylak-Glassman J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P674
   Sylak-Glassman John, 2016, TECHNICAL REPORT
   Tal Linzen Tal, 2018, P 4 INT C SCI TECHN, P1, DOI DOI 10.1109/ICSTC.2018.8528591
   Tenney Ian, 2019, INT C LEARN REPR
   Tsvetkov Y., 2015, P 2015 C EMP METH NA, P2049, DOI DOI 10.18653/V1/D15-1243
   Vania C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2573
   Vania C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2016, DOI 10.18653/v1/P17-1184
   Veldhoen Sara, 2016, COCO NIPS, P69
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Xiao RR, 2017, ADVANCES IN ENERGY, ENVIRONMENT AND MATERIALS SCIENCE, P289
NR 84
TC 11
Z9 11
U1 3
U2 12
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 2020
VL 46
IS 2
BP 335
EP 385
DI 10.1162/coli_a_00376
PG 51
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA ME9JR
UT WOS:000544970400004
OA Green Submitted, Green Published, gold
DA 2023-11-10
ER

PT J
AU Singhania, S
   Razniewski, S
   Weikum, G
AF Singhania, Sneha
   Razniewski, Simon
   Weikum, Gerhard
TI Predicting Document Coverage for Relation Extraction
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper presents a new task of predicting the coverage of a text document for relation extraction (RE): Does the document contain many relational tuples for a given entity? Coverage predictions are useful in selecting the best documents for knowledge base construction with large input corpora. To study this problem, we present a dataset of 31,366 diverse documents for 520 entities. We analyze the correlation of document coverage with features like length, entity mention frequency, Alexa rank, language complexity, and information retrieval scores. Each of these features has only moderate predictive power. We employ methods combining features with statistical models like TF-IDF and language models like BERT. The model combining features and BERT, HERB, achieves an F1 score of up to 46%. We demonstrate the utility of coverage predictions on two use cases: KB construction and claim refutation.
C1 [Singhania, Sneha; Razniewski, Simon; Weikum, Gerhard] Max Planck Inst Informat, Saarbrucken, Germany.
C3 Max Planck Society
RP Singhania, S (通讯作者)，Max Planck Inst Informat, Saarbrucken, Germany.
EM ssinghan@mpi-inf.mpg.de; srazniew@mpi-inf.mpg.de; weikum@mpi-inf.mpg.de
FU German Science Foundation (DFG: Deutsche Forschungsgemeinschaft)
   [4530095897]
FX We thank Andrew Yates for his suggestions. Further thanks to the
   anonymous reviewers, action editor, and fellow researchers at MPI, for
   their comments towards improving our paper. This work is supported by
   the German Science Foundation (DFG: Deutsche Forschungsgemeinschaft) by
   grant 4530095897: ``Negative Knowledge at Web Scale''.
CR Arnaout H, 2021, J WEB SEMANT, V71, DOI 10.1016/j.websem.2021.100661
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P542
   Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P985, DOI 10.1145/3331184.3331303
   Darari F, 2013, LECT NOTES COMPUT SC, V8218, P66, DOI 10.1007/978-3-642-41335-3_5
   Devlin J., 2018, ARXIV, V1, P4171
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Flesch R., 1949, ART READABLE READING
   Galárraga L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P375, DOI 10.1145/3018661.3018739
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI [DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]
   Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI [10.1145/3447772, 10.1145/3418294]
   Han X, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P745
   Hopkinson Andrew., 2018, P 2018 C N AM CHAPTE, P200, DOI [10.18653/v1/N18-3025, DOI 10.18653/V1/N18-3025]
   Ipeirotis PG, 2007, ACM T DATABASE SYST, V32, DOI 10.1145/1292609.1292611
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Lipton Zachary C, 2014, Mach Learn Knowl Discov Databases, V8725, P225, DOI 10.1007/978-3-662-44851-9_15
   Luggen M, 2019, LECT NOTES COMPUT SC, V11778, P453, DOI 10.1007/978-3-030-30793-6_26
   Mintz M., 2009, P JOINT C 47 ANN M A, V2, P1003, DOI DOI 10.3115/1690219.1690287
   Mitchell T, 2018, COMMUN ACM, V61, P103, DOI 10.1145/3191513
   Nakashole N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1009
   Nogueira R., 2020, ABS190104085 ARXIV
   Nogueira Rodrigo, 2020, FINDINGS ASS COMPUTA, P708, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.63
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Raffel C, 2020, J MACH LEARN RES, V21
   Rashkin P., 2017, P 2017 C EMP METH NA, P2931, DOI DOI 10.18653/V1/D17-1317
   Razniewski S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5771
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Robertson S. E., 1995, OV 3 TEXT RETR C TRE, V109, P109
   Roy D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2373
   Sandhaus Evan, 2008, NEW YORK TIMES ANNOT
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2895
   Thorne J., 2018, LONG PAPERS, P809, DOI DOI 10.18653/V1/N18-1074
   Wang XL, 2019, PROC INT CONF DATA, P578, DOI 10.1109/ICDE.2019.00058
   Weikum G, 2021, FOUND TRENDS DATABAS, V10, P108, DOI 10.1561/1900000064
   Xu BF, 2021, AAAI CONF ARTIF INTE, V35, P14149
   Yao Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P764
   Zhang Y., 2017, P 2017 C EMPIRICAL M, P35
NR 39
TC 0
Z9 0
U1 0
U2 2
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 18
PY 2022
VL 10
BP 207
EP 223
DI 10.1162/tacl_a_00456
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 8K9LF
UT WOS:000923413700001
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Ning, X
   Yu, ZY
   Li, LS
   Li, WJ
   Tiwari, P
AF Ning, Xin
   Yu, Zaiyang
   Li, Lusi
   Li, Weijun
   Tiwari, Prayag
TI DILF: Differentiable rendering-based multi-view Image-Language Fusion
   for zero-shot 3D shape understanding
SO INFORMATION FUSION
LA English
DT Article
DE Zero-shot 3D shape understanding; Differentiable rendering; Text-image
   fusion; Information fusion
ID CLASSIFICATION
AB Zero-shot 3D shape understanding aims to recognize "unseen"3D categories that are not present in training data. Recently, Contrastive Language-Image Pre-training (CLIP) has shown promising open-world performance in zero-shot 3D shape understanding tasks by information fusion among language and 3D modality. It first renders 3D objects into multiple 2D image views and then learns to understand the semantic relationships between the textual descriptions and images, enabling the model to generalize to new and unseen categories. However, existing studies in zero-shot 3D shape understanding rely on predefined rendering parameters, resulting in repetitive, redundant, and low-quality views. This limitation hinders the model's ability to fully comprehend 3D shapes and adversely impacts the text-image fusion in a shared latent space. To this end, we propose a novel approach called Differentiable rendering-based multi-view Image-Language Fusion (DILF) for zero-shot 3D shape understanding. Specifically, DILF leverages large-scale language models (LLMs) to generate textual prompts enriched with 3D semantics and designs a differentiable renderer with learnable rendering parameters to produce representative multi-view images. These rendering parameters can be iteratively updated using a text-image fusion loss, which aids in parameters' regression, allowing the model to determine the optimal viewpoint positions for each 3D object. Then a group-view mechanism is introduced to model interdependencies across views, enabling efficient information fusion to achieve a more comprehensive 3D shape understanding. Experimental results can demonstrate that DILF outperforms state-of-the-art methods for zero-shot 3D classification while maintaining competitive performance for standard 3D classification. The code is available at https://github.com/yuzaiyang123/DILP.
C1 [Ning, Xin; Yu, Zaiyang; Li, Weijun] Chinese Acad Sci, Inst Semicond, Beijing 100083, Peoples R China.
   [Li, Lusi] Old Dominion Univ, Dept Comp Sci, Norfolk, VA 23529 USA.
   [Yu, Zaiyang] Halmstad Univ, Sch Informat Technol, Halmstad, Sweden.
   [Tiwari, Prayag] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Semiconductors, CAS; Old
   Dominion University; Halmstad University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Li, WJ (通讯作者)，Chinese Acad Sci, Inst Semicond, Beijing 100083, Peoples R China.; Li, LS (通讯作者)，Old Dominion Univ, Dept Comp Sci, Norfolk, VA 23529 USA.; Tiwari, P (通讯作者)，Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM ningxin@semi.ac.cn; yuzaiyang@semi.ac.cn; lusili@cs.odu.edu;
   lusili@cs.odu.edu; prayag.tiwari@ieee.org
FU National Natural Science Foundation of China [6237334]; Beijing Natural
   Science Foundation [L233036]
FX We thank all reviewers and editors for their valuable feedback. This
   work is supported by the National Natural Science Foundation of China
   No. 6237334, Beijing Natural Science Foundation No. L233036.
CR Abdelreheem Ahmed, 2022, P IEEE CVF WINT C AP, P3941
   Bangaru Sai Praveen, 2022, SIGGRAPH AS 2022 C P, P1
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Chang Angel X., 2015, arXiv
   Chen GY, 2023, Arxiv, DOI arXiv:2305.11487
   Chen JJ, 2022, PROC CVPR IEEE, P549, DOI 10.1109/CVPR52688.2022.00064
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Fernandes D, 2021, INFORM FUSION, V68, P161, DOI 10.1016/j.inffus.2020.11.002
   Fu JM, 2022, IEEE IMAGE PROC, P2846, DOI 10.1109/ICIP46576.2022.9897323
   Goel Shashank, 2022, ADV NEURAL INF PROCE, V35, P6704
   Guo SD, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101864
   Hamdi A, 2023, Arxiv, DOI arXiv:2212.09100
   Hamdi A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1, DOI 10.1109/ICCV48922.2021.00007
   Hegde D, 2023, Arxiv, DOI arXiv:2303.11313
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Huang Tianyu, 2022, ARXIV
   Hyung Junha, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P12674, DOI 10.1109/CVPR52729.2023.01219
   Jiang CR, 2023, INFORM FUSION, V91, P316, DOI 10.1016/j.inffus.2022.10.016
   Jun Heewoo, 2023, ARXIV
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Liu AA, 2021, INFORM SCIENCES, V547, P984, DOI 10.1016/j.ins.2020.09.057
   Liu SC, 2019, Arxiv, DOI arXiv:1901.05567
   Liu Yahui, 2023, ABS230304599 CORR
   Ma Q, 2023, INFORM FUSION, V100, DOI 10.1016/j.inffus.2023.101907
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   Ma X, 2022, Arxiv, DOI [arXiv:2202.07123, 10.48550/arXiv.2202.07123]
   Tran MT, 2022, IEEE COMPUT SOC CONF, P3167, DOI 10.1109/CVPRW56347.2022.00357
   Mohammadi SS, 2021, IEEE IMAGE PROC, P3103, DOI 10.1109/ICIP42928.2021.9506426
   Montanaro Antonio, 2022, NEURIPS
   Mosella-Montoro A, 2021, INFORM FUSION, V76, P46, DOI 10.1016/j.inffus.2021.05.002
   Mu N, 2022, LECT NOTES COMPUT SC, V13686, P529, DOI 10.1007/978-3-031-19809-0_30
   Nichol A, 2022, Arxiv, DOI arXiv:2212.08751
   Park Jinyoung, 2023, ABS230316450 CORR
   Paszke A., 2017, NIPS 2017 WORKSHOP A
   Petersen F, 2022, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR52688.2022.00397
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi SH, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102053
   Qi ZK, 2023, Arxiv, DOI arXiv:2302.02318
   Qian Guocheng, 2022, ADV NEURAL INFORM PR, V35, P23192
   Qian Guocheng, 2022, NEURIPS
   Radford A, 2021, PR MACH LEARN RES, V139
   Ran HX, 2022, PROC CVPR IEEE, P18920, DOI 10.1109/CVPR52688.2022.01837
   Ravi Nikhila, 2020, ABS200708501 CORR
   Romaszko L, 2017, IEEE INT CONF COMP V, P940, DOI 10.1109/ICCVW.2017.115
   Seo J, 2023, Arxiv, DOI arXiv:2303.07937
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Thu NP, 2018, ADV NEUR IN, V31
   Tian X, 2022, INFORM FUSION, V77, P19, DOI 10.1016/j.inffus.2021.07.002
   Tulsiani S, 2018, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2018.00039
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   Wang Can, 2022, P IEEECVF C COMPUTER, P3835
   Wang Shuo, 2023, ABS230301686 CORR
   Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192
   Wijaya Kevin Tirta, 2022, ABS220509962 CORR
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xue L, 2023, Arxiv, DOI arXiv:2305.08275
   Xue L, 2022, Arxiv, DOI [arXiv:2212.05171, 10.48550/arXiv.2212.05171]
   Yang JQ, 2020, INFORM FUSION, V61, P24, DOI 10.1016/j.inffus.2020.03.008
   Zeid Karim Abou, 2023, ABS230316570 CORR
   Zhang Qijian, 2023, IEEE T MULTIMED
   Zhang RR, 2022, PROC CVPR IEEE, P8542, DOI 10.1109/CVPR52688.2022.00836
   Zhu X., 2022, ARXIV
NR 63
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD FEB
PY 2024
VL 102
AR 102033
DI 10.1016/j.inffus.2023.102033
EA SEP 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U3UQ7
UT WOS:001084085200001
OA hybrid
DA 2023-11-10
ER

PT J
AU Hu, HX
   Sener, O
   Sha, F
   Koltun, V
AF Hu, Hexiang
   Sener, Ozan
   Sha, Fei
   Koltun, Vladlen
TI Drinking From a Firehose: Continual Learning With Web-Scale Natural
   Language
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Task analysis; Benchmark testing; Learning systems; Multitasking; Social
   networking (online); Neural networks; Data models; Continual learning;
   lifelong learning; personalized language modelling; online multi-task
   learning; web-scale datasets
ID KNOWLEDGE
AB Continual learning systems will interact with humans, with each other, and with the physical world through time - and continue to learn and adapt as they do. An important open problem for continual learning is a large-scale benchmark which enables realistic evaluation of algorithms. In this paper, we study a natural setting for continual learning on a massive scale. We introduce the problem of personalized online language learning (POLL), which involves fitting personalized language models to a population of users that evolves over time. To facilitate research on POLL, we collect massive datasets of Twitter posts. These datasets, Firehose10 M and Firehose100 M, comprise 100 million tweets, posted by one million users over six years. Enabled by the Firehose datasets, we present a rigorous evaluation of continual learning algorithms on an unprecedented scale. Based on this analysis, we develop a simple algorithm for continual gradient descent (ConGraD) that outperforms prior continual learning methods on the Firehose datasets as well as earlier benchmarks. Collectively, the POLL problem setting, the Firehose datasets, and the ConGraD algorithm enable a complete benchmark for reproducible research on web-scale continual learning.
C1 [Hu, Hexiang; Sha, Fei] Univ Southern Calif, Viterbi Sch Engn, Dept Comp Sci, Los Angeles, CA 90007 USA.
   [Sener, Ozan; Koltun, Vladlen] Intel Labs, Santa Clara, CA 95054 USA.
C3 University of Southern California; Intel Corporation
RP Sener, O (通讯作者)，Intel Labs, Santa Clara, CA 95054 USA.
EM hexiang.frank.hu@gmail.com; ozansener@cs.stanford.edu; feisha@usc.edu;
   vkoltun@gmail.com
RI Hu, Hexiang/GNW-4536-2022
CR Ahn Hongjoon, 2019, ADV NEUR IN, P4392
   Ajalloeian A, 2021, Arxiv, DOI arXiv:2008.00051
   Aljundi R., 2019, ARXIV
   Aljundi R., 2013, GRADIENT BASED SAMPL
   Aljundi R, 2019, ADV NEUR IN, V32
   Aljundi R, 2019, PROC CVPR IEEE, P11246, DOI 10.1109/CVPR.2019.01151
   Aljundi R, 2017, PROC CVPR IEEE, P7120, DOI 10.1109/CVPR.2017.753
   [Anonymous], 2017, ADV NEURAL INFORM PR
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Biesialska M., 2020, P 28 INT C COMPUTATI, P6523, DOI DOI 10.18653/V1/2020.COLING-MAIN.574
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616.1376746.URLhttps]
   Buzzega P., 2020, PROC 34 INT C NEURAL
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Changpinyo S., 2018, P 27 INT C COMP LING, P2965
   Chaudhry A., 2019, PROC INT C LEARN REP, P1
   Chaudhry A, 2018, LECT NOTES COMPUT SC, V11215, P556, DOI 10.1007/978-3-030-01252-6_33
   Chaudhry Arslan, 2019, ARXIV
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Chen Y, 2019, Arxiv, DOI arXiv:1904.10644
   Chen Z., 2018, LIFELONG MACHINE LEA
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Dathathri S., 2020, PROC INT C LEARN REP
   De Lange M, 2021, Arxiv, DOI arXiv:1909.08383
   Ficler Jessica, 2017, P WORKSH STYL VAR, P94, DOI DOI 10.18653/V1/W17-4912
   Grossberg S. T, 2012, STUDIES MIND BRAIN
   Hazan E., 2016, FDN TRENDS OPTIM, V2, P157, DOI DOI 10.1561/2400000013
   Hazan E, 2017, PR MACH LEARN RES, V70
   Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Hu Z., 2017, PR MACH LEARN RES
   Isele D, 2018, AAAI CONF ARTIF INTE, P3302
   Jin XS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2018
   Jung HC, 2016, Arxiv, DOI arXiv:1607.00122
   Ke Z., 2020, PROC 34 INT C NEURAL
   Kingma DP., 2015, ABS14126980 CORR, DOI DOI 10.48550/ARXIV.1412.6980
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Lample G., 2019, P INT C LEARN REPR
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Logeswaran L., 2018, ADV NEURAL INFORM PR, P5108
   Lopez-Paz D, 2017, ADV NEUR IN, V30
   Madotto A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7452
   Mallya A, 2018, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2018.00810
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI DOI 10.1016/S0079-7421(08)60536-8
   Nguyen C. V., 2018, PROC INT C LEARN REP, P1
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Prabhu Ameya, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P524, DOI 10.1007/978-3-030-58536-5_31
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Rannen A, 2017, IEEE I CONF COMP VIS, P1329, DOI 10.1109/ICCV.2017.148
   Rebuffi S., 2017, ADV NEURAL INFORM PR, P506
   Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587
   Ritter H, 2018, ADV NEUR IN, V31
   Robins A., 1995, Connection Science, V7, P123, DOI 10.1080/09540099550039318
   Rolnick D., 2019, PROC 33 INT C NEURAL
   Rusu A. A., 2016, PROC INT C NEURAL IN
   Saxena A, 2015, Arxiv, DOI arXiv:1412.0691
   Schmidhuber J, 1997, NEURAL NETWORKS, V10, P857, DOI 10.1016/S0893-6080(96)00127-X
   Schwarz J, 2018, PR MACH LEARN RES, V80
   Sener O., 2020, PROC INT C LEARN REP
   Serrà J, 2018, PR MACH LEARN RES, V80
   Shalev-Shwartz S, 2012, FOUND TRENDS MACH LE, V4, P107, DOI 10.1561/2200000018
   Shin H, 2017, ADV NEUR IN, V30
   Keskar NS, 2019, Arxiv, DOI [arXiv:1909.05858, DOI 10.48550/ARXIV.1909.05858]
   Silver D.L., 2002, ADV ARTIFICIAL INTEL, V15, P90, DOI DOI 10.1007/3-540-47922-8_8
   Socher Richard, 2017, P 2017 C EMP METH NA, P1923, DOI DOI 10.18653/V1/D17-1206
   Suchanek F., 2007, P 16 INT C WORLD WID, DOI DOI 10.1145/1242572.1242667
   Swaroop S, 2019, Arxiv, DOI arXiv:1905.02099
   Thrun S, 1996, ADV NEUR IN, V8, P640
   Vaswani A., 2017, P ADV NEUR INF PROC
   Wang A., 2019, PROC INT C LEARN REP, P1
   Wang A., 2019, PROC 33 INT CONFNEUR
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Yao Y, 2007, CONSTR APPROX, V26, P289, DOI 10.1007/s00365-006-0663-2
   Zenke F, 2017, PR MACH LEARN RES, V70
   Zhang JT, 2020, IEEE WINT CONF APPL, P1120, DOI 10.1109/WACV45572.2020.9093365
NR 79
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD MAY 1
PY 2023
VL 45
IS 5
BP 5684
EP 5696
DI 10.1109/TPAMI.2022.3218265
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C9BQ7
UT WOS:000964792800022
PM 36315549
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Di, DL
   Song, XY
   Zhang, WN
   Zhang, Y
   Wang, FL
AF Di, Donglin
   Song, Xianyang
   Zhang, Weinan
   Zhang, Yue
   Wang, Fanglin
TI Building Dialogue Understanding Models for Low-resource Language
   Indonesian from Scratch
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Dialogue datasets; intent classification; slot-filling; indonesian
AB Using off-the-shelf resources from resource-rich languages to transfer knowledge to low-resource languages has received a lot of attention. The requirements of enabling the model to achieve the reliable performance, including the scale of required annotated data and the effective framework, are not well guided. To address the first question, we empirically investigate the cost-effectiveness of several methods for training intent classification and slot-filling models from scratch in Indonesia (ID) using English data. Confronting the second challenge, we propose a Bi-Confidence-Frequency Cross-Lingual transfer framework (BiCF), which consists of "BiCF Mixing", "Latent Space Refinement" and "Joint Decoder", respectively, to overcome the lack of low-resource language dialogue data. BiCF Mixing based on the word-level alignment strategy generates code-mixed data by utilizing the importance-frequency and translating-confidence. Moreover, Latent Space Refinement trains a new dialogue understanding model using code-mixed data and word embedding models. Joint Decoder based on Bidirectional LSTM (BiLSTM) and Conditional Random Field (CRF) is used to obtain experimental results of intent classification and slot-filling. We also release a large-scale fine-labeled Indonesia dialogue dataset (ID-WOZ(1)) and ID-BERT for experiments. BiCF achieves 93.56% and 85.17% (F1 score) on intent classification and slot filling, respectively. Extensive experiments demonstrate that our framework performs reliably and cost-efficiently on different scales of manually annotated Indonesian data.
C1 [Di, Donglin; Wang, Fanglin] Adv AI, Res & Dev, 80 Robinson Rd, Singapore 068898, Singapore.
   [Song, Xianyang] Northeast Forestry Univ, Harbin 150040, Peoples R China.
   [Zhang, Weinan] Harbin Inst Technol, 92 West Dazhi St, Harbin, Heilongjiang, Peoples R China.
   [Zhang, Yue] Westlake Univ, Hangzhou 310024, Zhejiang, Peoples R China.
C3 Northeast Forestry University - China; Harbin Institute of Technology;
   Westlake University
RP Di, DL (通讯作者)，Adv AI, Res & Dev, 80 Robinson Rd, Singapore 068898, Singapore.
EM donglin.ddl@gmail.com; sxy56713@nefu.edu.cn; wnzhang@ir.hit.edu.cn;
   yue.zhang@wias.org.cn; fanglin.wang@advancegroup.com
RI Lu, Xiaomei/IUQ-2139-2023; zhang, xu/JEO-4879-2023; li,
   wl/JJC-0768-2023; Di, Donglin/AFP-1438-2022; WANG, Bin/JGM-2639-2023;
   wang, xiaoxuan/JMP-6531-2023; zhang, ly/JMB-7214-2023; cheng,
   chen/JHS-9462-2023
OI Zhang, Yue/0000-0002-5214-2268; Di, Donglin/0000-0002-2270-3378
FU Science and Technology Innovation 2030 Major Project of China
   [2021ZD0113302]; National Natural Science Foundation of China [62076081,
   61772153, 61936010]
FX This paper is supported by the Science and Technology Innovation 2030
   Major Project of China (No. 2021ZD0113302) and National Natural Science
   Foundation of China (No. 62076081, No. 61772153 and No. 61936010).
CR Ammar Waleed, 2016, T ASS COMPUTATIONAL, V4, P431, DOI DOI 10.1162/TACL_A_00109
   [Anonymous], 2015, P 2015 C EMPIRICAL M
   [Anonymous], 2013, SIMPLE FAST EFFECTIV
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Budzianowski Pawel, 2018, C EMPIRICAL METHODS
   Chen Hongshen, 2016, P 2016 C EMPIRICAL M, P731
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Cheng Y., 2019, JOINT TRAINING NEURA, P25, DOI DOI 10.1007/978-981-32-9748-7_3
   Chowanda Andry, 2017, INT C COMPUTER SCI C
   Collins Michael, 2011, STAT MACHINE TRANSLA
   de Melo Gerard, 2017, P IJCNLP 2017, P3
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dozat T, 2017, Arxiv, DOI arXiv:1611.01734
   Feng Yue, 2020, ANN M ASS COMPUTATIO
   FLEISS JL, 1969, PSYCHOL BULL, V72, P323, DOI 10.1037/h0028106
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Gunasekara C, 2020, ARXIV
   Guo J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1234
   Guo JY, 2022, Arxiv, DOI arXiv:2205.10059
   Guo Jinyu, 2021, ARXIV
   HongminWang Yue Zhang, 2017, ARXIV
   Joulin A, 2016, Arxiv, DOI [arXiv:1612.03651, DOI 10.48550/ARXIV.1612.03651]
   KELLEY JF, 1984, ACM T OFF INF SYST, V2, P26, DOI 10.1145/357417.357420
   Kim S., 2021, FINDINGS 2022 C EMPI, P352
   Koto F, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P801
   Lin Yen-Ting, 2021, ARXIV
   Liu Hui, 2018, ANN M ASS COMPUTATIO
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Liu ZH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1297
   Liu ZH, 2020, AAAI CONF ARTIF INTE, V34, P8433
   McCann Bryan, 2017, ADV NEURAL INFORM PR, P6297
   Moghe N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1137
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Ramos J., 2003, P 1 INSTR C MACH LEA, VVolume 242, P29
   Salton Gerard, 1982, EXTENDED BOOLEAN INF
   Schuster Sebastian, 2018, N AM CHAPTER ASS COM
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   Sun WW, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1442, DOI 10.1145/3404835.3462883
   Tho Cuk, 2018, Procedia Computer Science, V135, P315, DOI 10.1016/j.procs.2018.08.179
   Tiedemann J, 2016, J ARTIF INTELL RES, V55, P209, DOI 10.1613/jair.4785
   Tiedemann Jorg, 2015, P 20 NORDIC C COMPUT, P191
   Vaswani A., 2018, C ASS MACHINE TRANSL
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu Chien-Sheng, 2019, ANN M ASS COMPUTATIO
   Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046
   Xiang Lu, 2021, P CCF INT C NATURAL, P193
   Yang Z, 2019, NEURAL INFORM PROCES
   Zhang MS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P997
NR 52
TC 0
Z9 0
U1 3
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD APR
PY 2023
VL 22
IS 4
AR 105
DI 10.1145/3575803
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9FI3
UT WOS:000998929700013
DA 2023-11-10
ER

PT J
AU Agerri, R
   Rigau, G
AF Agerri, Rodrigo
   Rigau, German
TI Robust multilingual Named Entity Recognition with shallow
   semi-supervised features
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Named Entity Recognition; Information Extraction; Clustering;
   Semi-supervised learning; Natural Language Processing
AB We present a multilingual Named Entity Recognition approach based on a robust and general set of features across languages and datasets. Our system combines shallow local information with clustering semi-supervised features induced on large amounts of unlabeled text. Understanding via empirical experimentation how to effectively combine various types of clustering features allows us to seamlessly export our system to other datasets and languages. The result is a simple but highly competitive system which obtains state of the art results across five languages and twelve datasets. The results are reported on standard shared task evaluation data such as CoNLL for English, Spanish and Dutch. Furthermore, and despite the lack of linguistically motivated features, we also report best results for languages such as Basque and German. In addition, we demonstrate that our method also obtains very competitive results even when the amount of supervised data is cut by half, alleviating the dependency on manually annotated data. Finally, the results show that our emphasis on clustering features is crucial to develop robust out-of-domain models. The system and models are freely available to facilitate its use and guarantee the reproducibility of results. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Agerri, Rodrigo; Rigau, German] Univ Basque Country UPV EHU, IXA NLP Grp, Donostia San Sebastian, Spain.
C3 University of Basque Country
RP Agerri, R (通讯作者)，Univ Basque Country UPV EHU, IXA NLP Grp, Donostia San Sebastian, Spain.
EM rodrigo.agerri@ehu.eus; german.rigau@ehu.eus
RI Agerri, Rodrigo/ABA-4096-2021; Rigau, German/H-7235-2015
OI Agerri, Rodrigo/0000-0002-7303-7598; Rigau, German/0000-0003-1119-0930;
   Ho Manh Tan, 19020434/0000-0001-8656-3071
FU European project NewsReader [EC/FP7/316404]; European project QTLeap
   [EC/FP7/610516]; Spanish Ministry of Economy and Competitiveness
   (MINECO) SKATER [TIN2012-38584-C06-01]; Spanish Ministry of Economy and
   Competitiveness (MINECO) TUNER [TIN2015-65308-C5-1-R]
FX We would like to thank the anonymous reviewers for their comments to
   improve this paper. We would also like to thank Sebastian Pado for his
   help training the Clark clusters. This work has been supported by the
   European projects NewsReader, EC/FP7/316404 and QTLeap - EC/FP7/610516,
   and by the Spanish Ministry of Economy and Competitiveness (MINECO)
   SKATER, Grant No. TIN2012-38584-C06-01 and TUNER, TIN2015-65308-C5-1-R.
CR Agerri R, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3823
   Ahn D., 2006, P WORKSH ANN REAS TI, P1, DOI DOI 10.3115/1629235.1629236
   Al-Onaizan Y, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P400
   Alegria I, 2006, PROCES LENG NAT, P25
   [Anonymous], 1998, P 7 MESS UND C MUC 7
   [Anonymous], 2008, P ACL 08
   [Anonymous], 2005, P 43 ANN M ASS COMP
   [Anonymous], 2002, COLING 02 6 C NATURA
   [Anonymous], 2010, KONVENS
   [Anonymous], 2009, RES LANGUAGE COMPUTA
   [Anonymous], 2015, P INT C GERM SOC COM
   [Anonymous], 2012, SYNTHESIS LECT HUMAN
   [Anonymous], 2008, P ACL 08 HLT
   [Anonymous], 2005, THESIS MIT
   Babych B., 2003, P 7 INT EAMT WORKSHO
   Baroni M, 2009, LANG RESOUR EVAL, V43, P209, DOI 10.1007/s10579-009-9081-4
   Benikova Darina, 2014, P KONVENS GERMEVAL S, P104
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Ciaramita Massimiliano, 2006, P 2006 C EMP METH NA, P594, DOI DOI 10.3115/1610075.1610158
   Clark A, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P59
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Cucerzan S., 2007, P C EMP METH NAT LAN, V2007, P708, DOI DOI 10.1145/2187836.2187900
   Curran J, 2003, P 7 C NAT LANG LEARN, P164, DOI DOI 10.3115/1119176.1119200
   Cybulska Agata, 2013, P INT C REC ADV NAT, P156
   Desmet B, 2014, LANG RESOUR EVAL, V48, P307, DOI 10.1007/s10579-013-9255-y
   Florian R, 2003, P 7 C NAT LANG LEARN, V4, P168, DOI DOI 10.3115/1119176.1119201
   Hachey B, 2013, ARTIF INTELL, V194, P130, DOI 10.1016/j.artint.2012.04.005
   Han Xianpei, 2011, P 49 ANN M ASS COMP, P945
   Hanig C., 2014, P KONV GERM EV SHAR
   Hoffart J., 2011, P EMNLP, P27
   Hong Y., 2011, P 49 ANN M ASS COMP, P1127
   Ji H., 2008, P ACL 08 HLT, P254
   Ji Heng, 2011, P 49 ANN M ASS COMP, P1148
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Li H., 2013, P 51 ANN M ASS COMP, V1, P604
   Mendes P. N., 2011, P TAC KBP 2011 WORKS, V116, P118
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Miller S, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P337
   Minard A.-L., 2016, P LREC 2016
   Minard Anne-Lyse Myriam, 2015, P 9 INT WORKSHOP SEM, P778
   Mnih A., 2007, P 24 INT C MACHINE L, P641, DOI DOI 10.1145/1273496.1273577
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   NOBATA C, 2000, P WORKSH COMP CORP A, P20
   Nothman J, 2013, ARTIF INTELL, V194, P151, DOI 10.1016/j.artint.2012.03.006
   Padró L, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2473
   Passos Alexandre, 2014, P 18 C COMP NAT LANG, P78
   Pontiki M., 2014, P 8 INT WORKSHOP SEM, P27, DOI [10.3115/v1/s14-2004, DOI 10.3115/V1/S14-2004]
   Pontiki Maria, 2015, P 9 INT WORKSH SEM E, P486, DOI [10.18653/v1/s15-2082, DOI 10.18653/V1/S15-2082]
   Pradhan S., 2012, JOINT C EMNLP CONLL, P1
   Przybocki M. A., 2004, LREC
   Ratinov L., 2009, P 13 C COMPUTATIONAL, DOI DOI 10.3115/1596374.1596399
   Reimers N., 2014, P KONV GERM EV SHAR
   Ritter A, 2011, P C EMP METH NAT LAN, P1524, DOI DOI 10.1075/LI.30.1.03NAD
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   TAULE M, 2008, P 6 INT LANG RES EV, P96
   Tjong Kim Sang E. F., 2002, COLING 02
   Tonelli S., 2014, TECHNICAL REPORT
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Zhang T., 2003, P 7 C NAT LANG LEARN, P204
NR 61
TC 42
Z9 44
U1 0
U2 27
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD SEP
PY 2016
VL 238
BP 63
EP 82
DI 10.1016/j.artint.2016.05.003
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DS2KX
UT WOS:000380599500003
OA Green Submitted, hybrid, Green Accepted
DA 2023-11-10
ER

PT J
AU Callan, D
   Foster, J
AF Callan, Dominic
   Foster, Jennifer
TI How interesting and coherent are the stories generated by a large-scale
   neural language model? Comparing human and automatic evaluations of
   machine-generated text
SO EXPERT SYSTEMS
LA English
DT Article
DE evaluation; machine-generated text; natural language generation;
   transformers
AB Evaluation of the narrative text generated by machines has traditionally been a challenge, particularly when attempting to evaluate subjective elements such as interest or believability. Recent improvements in narrative machine text generation have been largely driven by the emergence of transformer-based language models, trained on massive quantities of data, resulting in higher quality text generation. In this study, a corpus of stories is generated using the pre-trained GPT-Neo transformer model, with human-written prompts as inputs upon which to base the narrative text. The stories generated through this process are subsequently evaluated through both human evaluation and two automated metrics: BERTScore and BERT Next Sentence Prediction, with the aim of determining whether there is a correlation between the automatic scores and the human judgements. The results show variation in human evaluation results in comparison to modern automated metrics, suggesting further work is required to train automated metrics to identify text that is defined as interesting by humans.
C1 [Callan, Dominic; Foster, Jennifer] Dublin City Univ, Sch Comp, Dublin, Ireland.
C3 Dublin City University
RP Callan, D; Foster, J (通讯作者)，Dublin City Univ, Sch Comp, Dublin, Ireland.
EM dominic.callan24@mail.dcu.ie; jennifer.foster@dcu.ie
OI Callan, Dominic/0000-0002-9163-1777
CR Akoury N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6470
   Black Sid, 2021, GPT NEO LARGE SCALE
   Brown T. B., 2020, P ADV NEUR INF PROC, V33, P1877
   Celikyilmaz A., 2020, PREPRINT
   Chaganty A. T., 2018, PREPRINT
   Clark E., 2021, PREPRINT
   Devlin J., 2018, ARXIV, V1, P4171
   Fan A., 2018, PREPRINT
   Gao L., 2020, PREPRINT
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Halliday M.A.K., 1976, COHESION ENGLISH
   Hashimoto T. B., 2019, PREPRINT
   Howcroft D. M., 2020, P 13 INT C NAT LANG
   Ji TB, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6416
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, DOI DOI 10.2307/3105454
   Lowe R., 2017, PREPRINT
   McIntyre N., 2009, P JOINT C 47 ANN M A
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pillutla K., 2021, ADV NEURAL INFORM PR, V34, P4816, DOI 10.48550/arXiv.2102.01454
   Purdy C., 2018, 14 ART INT INT DIG E
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Roemmele M., 2017, SIGKDD 2017 WORKSH M
   Sellam Thibault, 2020, P 58 ANN M ASS COMPU, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704]
   van der Lee C., 2019, BEST PRACTICES HUMAN
   van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151
   Vaswani A., 2017, ARXIV, V30, P5998
   Yao L., 2019, ARXIV ABS181105701
   Zellers Rowan, 2019, NEURIPS
   Zhang T., 2020, RESCALING BERTSCORE
   Zhang Tianyi, 2020, ICLR
   Zhao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P563
NR 31
TC 0
Z9 0
U1 9
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JUL
PY 2023
VL 40
IS 6
DI 10.1111/exsy.13292
EA MAR 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I1QT5
UT WOS:000956803900001
OA hybrid
DA 2023-11-10
ER

PT J
AU Ceusters, W
   Rogers, J
   Consorti, F
   Rossi-Mori, A
AF Ceusters, W
   Rogers, J
   Consorti, F
   Rossi-Mori, A
TI Syntactic-semantic tagging as a mediator between linguistic
   representations and formal models: an exercise in linking SNOMED to
   GALEN
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE concept representation; linguistic semantics; syntactic-semantic
   tagging; natural language understanding; automated knowledge acquisition
AB Natural language understanding applications are good candidates to solve the knowledge acquisition bottleneck when designing large scale concept systems. However, a necessary condition is that systems are built that transform sentences into a meaning representation that is independent of the subtleties of linguistic structure that nevertheless underly the way language works. The Cassandra II syntactic-semantic tagging system fulfills this goal partially. Within the GALEN-IN-USE project, it is used to transform linguistic representations of surgical procedure expressions into conceptual representations. In this paper, the proctology chapter of the SNOMED V3.1 procedure axis was used as a testbed to evaluate the usefulness of this approach. A quantitative and qualitative analysis of the data obtained is presented, showing that the Cassandra system can indeed complement the manual modelling efforts being conducted in the GALEN-IN-USE project. The different requirements related to linguistic modelling versus conceptual modelling can partly be accounted for by using an interface ontology, of which the fine tuning will however remain an important effort. (C) 1999 Elsevier Science B.V. All rights reserved.
C1 L&C NV, B-9520 Zonnegem, Belgium.
   Univ Manchester, Dept Comp Sci, Med Informat Grp, Manchester M13 9PL, Lancs, England.
   Univ Roma La Sapienza, Ist Clin Chirurg 4, I-00161 Rome, Italy.
   CNR, Ist Tecnol Biomed, I-00137 Rome, Italy.
C3 University of Manchester; Sapienza University Rome; Consiglio Nazionale
   delle Ricerche (CNR); Istituto di Tecnologie Biomediche (ITB-CNR)
RP Ceusters, W (通讯作者)，L&C NV, Moorhof,Hazenakkerstr 20, B-9520 Zonnegem, Belgium.
EM werner.ceusters@rug.ac.be
RI RossiMori, Angelo/AAD-4133-2022; Ceusters, Werner M/H-2269-2013
OI Ceusters, Werner M/0000-0002-2676-8689; Consorti,
   Fabrizio/0000-0001-7096-4428
CR ALLEN J, 1987, NATURAL LANGUAGE UND
   [Anonymous], 1990, GEN ORG KNOWLEDGE NA
   [Anonymous], 1992, LINGUISTIC SEMANTICS
   BATEMAN JA, 1995, GEN UPPER MODEL 2 0
   Baud R, 1993, Proc Annu Symp Comput Appl Med Care, P289
   BAUD R, 1997, UNPUB SCAMC FALL S
   *CEN ENV, 1995, 18281995 CEN ENV
   Ceusters W, 1997, ST HEAL T, V43, P396
   CEUSTERS W, 1994, P MIC 94, P311
   CEUSTERS W, 1997, P IMIA WG6 C NAT LAN, P71
   CEUSTERS W, 1997, P MIC 97, P183
   CEUSTERS W, 1996, P ME 96, P154
   Galeazzi E, 1997, ST HEAL T, V43, P280
   *GALEN CONS, VUM0396 GALEN CONS
   *GALEN CONS, VUM0296 GALEN CONS
   KIRBY J, 1996, AMIA FALL S, P709
   Lenat Douglas B, 1989, BUILDING LARGE KNOWL
   Lyon John, 1995, LINGUISTIC SEMANTICS
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   MICHALSKI RS, 1986, MACH LEARN, V2, P3
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   RECTOR A, 1993, 17 ANN S COMP APPL M, P414
   RECTOR A, 1995, 5 C ART INT MED EUR, P17
   ROGERS J, 1996, P ME 96, P174
   Rogers JE, 1997, ST HEAL T, V43, P241
   SWARTOUT W, 1996, KNOWL ACQ WORKSH BAN
   VOSSEN P, 1997, P IJCAI 97 WORKSH MU
   WAGNER J, 1994, P 12 INT C EUR FED M, P218
   WAGNER JC, 1995, P 8 WORLD C MED INF, P100
NR 29
TC 9
Z9 9
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0933-3657
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JAN
PY 1999
VL 15
IS 1
BP 5
EP 23
DI 10.1016/S0933-3657(98)00043-8
PG 19
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 157BW
UT WOS:000078040100002
PM 9930614
DA 2023-11-10
ER

PT J
AU Stefanini, M
   Cornia, M
   Baraldi, L
   Cascianelli, S
   Fiameni, G
   Cucchiara, R
AF Stefanini, Matteo
   Cornia, Marcella
   Baraldi, Lorenzo
   Cascianelli, Silvia
   Fiameni, Giuseppe
   Cucchiara, Rita
TI From Show to Tell: A Survey on Deep Learning-Based Image Captioning
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Image captioning; vision-and-language; deep learning; survey
ID TRANSFORMER; GENERATION; LANGUAGE; MODELS
AB Connecting Vision and Language plays an essential role in Generative Intelligence. For this reason, large research efforts have been devoted to image captioning, i.e. describing images with syntactically and semantically meaningful sentences. Starting from 2015 the task has generally been addressed with pipelines composed of a visual encoder and a language model for text generation. During these years, both components have evolved considerably through the exploitation of object regions, attributes, the introduction of multi-modal connections, fully-attentive approaches, and BERT-like early-fusion strategies. However, regardless of the impressive results, research in image captioning has not reached a conclusive answer yet. This work aims at providing a comprehensive overview of image captioning approaches, from visual encoding and text generation to training strategies, datasets, and evaluation metrics. In this respect, we quantitatively compare many relevant state-of-the-art approaches to identify the most impactful technical innovations in architectures and training strategies. Moreover, many variants of the problem and its open challenges are discussed. The final goal of this work is to serve as a tool for understanding the existing literature and highlighting the future directions for a research area where Computer Vision and Natural Language Processing can find an optimal synergy.
C1 [Stefanini, Matteo; Cornia, Marcella; Baraldi, Lorenzo; Cascianelli, Silvia; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, Italy.
   [Fiameni, Giuseppe] NVIDIA AI Technol Ctr, I-21024 Milan, Italy.
   [Fiameni, Giuseppe] CINECA, HPC specialist, Casalecchio Di Reno, Italy.
C3 Universita di Modena e Reggio Emilia; CINECA, Italy
RP Cornia, M (通讯作者)，Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, Italy.
EM matteo.stefanini@unimore.it; marcella.cornia@unimore.it;
   lorenzo.baraldi@unimore.it; silvia.cascianelli@unimore.it;
   gfiameni@nvidia.com; rita.cucchiara@unimore.it
RI Cornia, Marcella/Y-9903-2019; Cucchiara, Rita/L-3006-2015
OI Cornia, Marcella/0000-0001-9640-9385; Cucchiara,
   Rita/0000-0002-2239-283X; Baraldi, Lorenzo/0000-0001-5125-4957;
   Cascianelli, Silvia/0000-0001-7885-6050
CR Agrawal H, 2019, IEEE I CONF COMP VIS, P8947, DOI 10.1109/ICCV.2019.00904
   Aker A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1250
   Alikhani M., 2020, P 58 ANN M ASS COMP, P6525
   Anderson P., 2017, P 2017 C EMP METH NA, P936, DOI [10.18653/v1/D17-1098, DOI 10.18653/V1/D17-1098]
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2019, IEEE I CONF COMP VIS, P4260, DOI 10.1109/ICCV.2019.00436
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   [Anonymous], 2014, 3 INT C LEARN REPR
   [Anonymous], 2015, SHOW TELL NEURAL IMA
   Ardila A, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/565871
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Bai Z., 2021, P IEEE CVF INT C COM, P5422
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, P65, DOI DOI 10.3115/1626355.1626389
   Ben HX, 2022, IEEE T MULTIMEDIA, V24, P904, DOI 10.1109/TMM.2021.3060948
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Bigazzi Roberto, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P1152, DOI 10.1109/ICPR48806.2021.9412628
   Caglayan O., 2020, P 28 INT C COMPUTATI, P2322
   Changpinyo S, 2021, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR46437.2021.00356
   Chaorui Deng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P712, DOI 10.1007/978-3-030-58601-0_42
   Chatterjee M, 2018, LECT NOTES COMPUT SC, V11206, P747, DOI 10.1007/978-3-030-01216-8_45
   Chen FH, 2019, ADV NEUR IN, V32
   Chen FH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P46, DOI 10.1145/3123266.3123275
   Chen FH, 2018, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2018.00146
   Chen L, 2021, PROC CVPR IEEE, P16841, DOI 10.1109/CVPR46437.2021.01657
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen S, 2018, LECT NOTES COMPUT SC, V11215, P72, DOI 10.1007/978-3-030-01252-6_5
   Chen TH, 2017, IEEE I CONF COMP VIS, P521, DOI 10.1109/ICCV.2017.64
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Chen XP, 2018, PROC CVPR IEEE, P7995, DOI 10.1109/CVPR.2018.00834
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Cornia M., 2022, ARXIV
   Cornia M, 2020, IEEE INT CONF ROBOT, P1128, DOI 10.1109/icra40945.2020.9196653
   Cornia M, 2019, PROC CVPR IEEE, P8299, DOI 10.1109/CVPR.2019.00850
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177745
   Cui Y, 2018, PROC CVPR IEEE, P5804, DOI 10.1109/CVPR.2018.00608
   Dai B., 2018, P EUROPEAN C COMPUTE, P294
   Dai B, 2018, ADV NEUR IN, V31
   Dai B, 2017, ADV NEUR IN, V30
   Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323
   Del Chiaro R., 2020, PROC 34 INT C NEURAL
   Desai K, 2021, PROC CVPR IEEE, P11157, DOI 10.1109/CVPR46437.2021.01101
   Deshpande A, 2019, PROC CVPR IEEE, P10687, DOI 10.1109/CVPR.2019.01095
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R
   Elliott D., 2016, P ACL 2016, P70
   Elliott D., 2015, ARXIV151004709
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fei Zhengcong, 2019, P AAAI C ART INT WOR
   Feng Y, 2019, PROC CVPR IEEE, P4120, DOI 10.1109/CVPR.2019.00425
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Biten AF, 2019, PROC CVPR IEEE, P12458, DOI 10.1109/CVPR.2019.01275
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gao JL, 2019, PROC CVPR IEEE, P6293, DOI 10.1109/CVPR.2019.00646
   Ge HW, 2019, IEEE I CONF COMP VIS, P1754, DOI 10.1109/ICCV.2019.00184
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gu JX, 2018, LECT NOTES COMPUT SC, V11205, P519, DOI 10.1007/978-3-030-01246-5_31
   Gu JX, 2019, IEEE I CONF COMP VIS, P10322, DOI 10.1109/ICCV.2019.01042
   Gu JX, 2018, AAAI CONF ARTIF INTE, P6837
   Gu JX, 2017, IEEE I CONF COMP VIS, P1231, DOI 10.1109/ICCV.2017.138
   Guo D, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P920
   Guo L., 2020, PROC 29 INT JOINT C
   Guo L., 2021, ARXIV
   Guo LT, 2019, PROC CVPR IEEE, P4199, DOI 10.1109/CVPR.2019.00433
   Guo LT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P765, DOI 10.1145/3343031.3350943
   Gupta A., 2012, P 26 AAAI C ARTIFICI, P606
   Gurari Danna, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P417, DOI 10.1007/978-3-030-58520-4_25
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S., 2020, P AS C COMP VIS, P153
   Hendricks LA, 2018, LECT NOTES COMPUT SC, V11206, P269, DOI 10.1007/978-3-030-01216-8_17
   Hendricks LA, 2016, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2016.8
   Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1
   Herdade S, 2019, ADV NEUR IN, V32
   Hessel J., 2021, ARXIV
   Hodosh M., 2016, P 5 WORKSHOP VISION, P19
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hosseinzadeh M, 2021, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR46437.2021.00275
   Hu X., 2021, ARXIV
   Hu XW, 2021, AAAI CONF ARTIF INTE, V35, P1575
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huang L, 2019, ADV NEUR IN, V32
   Huang QB, 2022, IEEE T MULTIMEDIA, V24, P2004, DOI 10.1109/TMM.2021.3074803
   Jhamtani H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4024
   Ji JY, 2021, AAAI CONF ARTIF INTE, V35, P1655
   Jia C, 2021, PR MACH LEARN RES, V139
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang Huaizu, 2020, IEEE CVF C COMP VIS
   Jiang M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1475
   Jiang M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2141
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Jing BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2577
   Jing Wang, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P4337, DOI 10.1145/3394171.3413753
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kasai J., 2021, TRANSPARENT HUMAN EV
   Ke L, 2019, IEEE I CONF COMP VIS, P8887, DOI 10.1109/ICCV.2019.00898
   Kilickaya M, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P199
   Kim DJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2012
   Kim DJ, 2019, PROC CVPR IEEE, P6264, DOI 10.1109/CVPR.2019.00643
   Kim H., 2021, P IEEECVF INT C COMP, P2095
   Kipf T N, 2016, ICLR
   Kiros R., 2014, PROC INT C NEURAL IN
   Koehn Philipp, 2009, STAT MACHINE TRANSLA
   Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Kuznetsova P., 2014, J T ASS COMPUT LINGU, V2, P351, DOI [10.1162/tacl_a_00188, DOI 10.1162/TACL_A_00188]
   Laina I, 2019, IEEE I CONF COMP VIS, P7413, DOI 10.1109/ICCV.2019.00751
   Lan WY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1549, DOI 10.1145/3123266.3123366
   Lee H, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P220
   Lee Hwanhee, 2020, P 1 WORKSH EV COMP N, P34
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li S., 2011, P C COMP NAT LANG LE, P220
   Li XY, 2019, AAAI CONF ARTIF INTE, P8650
   Li XR, 2019, IEEE T MULTIMEDIA, V21, P2347, DOI 10.1109/TMM.2019.2896494
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Li YH, 2019, PROC CVPR IEEE, P12489, DOI 10.1109/CVPR.2019.01278
   Liang XD, 2017, IEEE I CONF COMP VIS, P3382, DOI 10.1109/ICCV.2017.364
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu F., 2020, ADV NEURAL INFORM PR
   Liu FL, 2021, PROC CVPR IEEE, P13748, DOI 10.1109/CVPR46437.2021.01354
   Liu FL, 2019, ADV NEUR IN, V32
   Liu FX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6761
   Liu LX, 2019, IEEE I CONF COMP VIS, P4239, DOI 10.1109/ICCV.2019.00434
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Liu W, 2021, ARXIV, DOI [10.48550/arxiv.2101.10804, DOI 10.48550/ARXIV.2101.10804]
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2019, ADV NEUR IN, V32
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YD, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2341, DOI 10.1145/3343031.3350961
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Mahajan Shweta, 2020, ADV NEURAL INFORM PR, V33, P3613
   Mao J., 2015, PROC INT C LEARN REP
   Mao YZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4258
   Mathews A, 2018, PROC CVPR IEEE, P8591, DOI 10.1109/CVPR.2018.00896
   Meng ZH, 2021, PROC CVPR IEEE, P12674, DOI 10.1109/CVPR46437.2021.01249
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Miyazaki T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1780
   Mokady Ron, 2021, ARXIV
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Pan JY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1987, DOI 10.1109/ICME.2004.1394652
   Papineni K., 2002, BLEU METHOD AUTOMATI, P311
   Park CC, 2019, IEEE T PATTERN ANAL, V41, P999, DOI 10.1109/TPAMI.2018.2824816
   Park CC, 2017, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2017.681
   Park DH, 2019, IEEE I CONF COMP VIS, P4623, DOI 10.1109/ICCV.2019.00472
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Pont-Tuset Jordi, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P647, DOI 10.1007/978-3-030-58558-7_38
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Radford Alec, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.00020
   Ramanishka V, 2017, PROC CVPR IEEE, P3135, DOI 10.1109/CVPR.2017.334
   Ramesh A, 2021, Arxiv, DOI [arXiv:2102.12092, DOI 10.48550/ARXIV.2102.12092]
   Ramisa A, 2018, IEEE T PATTERN ANAL, V40, P1072, DOI 10.1109/TPAMI.2017.2721945
   Ranzato M, 2016, ICLR, P1
   Reed S, 2016, PR MACH LEARN RES, V48
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Rohrbach A., 2018, P C EMP METH NAT LAN, P4035
   Sammani F, 2020, PROC CVPR IEEE, P4807, DOI 10.1109/CVPR42600.2020.00486
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sharif N., 2020, MACHINE LEARNING PAR, P9
   Sharif N, 2018, LECT NOTES COMPUT SC, V11212, P39, DOI 10.1007/978-3-030-01237-3_3
   Sharma Himanshu, 2020, 2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC), P325, DOI 10.1109/PARC49193.2020.236619
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shen S., 2021, ARXIV
   Shetty R, 2017, IEEE I CONF COMP VIS, P4155, DOI 10.1109/ICCV.2017.445
   Shi Zhan, 2020, P 58 ANN M ASS COMP, P7454, DOI DOI 10.18653/V1/2020.ACL-MAIN.664
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Shuster K, 2019, PROC CVPR IEEE, P12508, DOI 10.1109/CVPR.2019.01280
   Sidorov O., 2020, EUR C COMP VIS, P742, DOI DOI 10.1007/978-3-030-58536-5_44
   Simonyan K, 2015, P 3 INT C LEARN REPR
   Song YQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P784, DOI 10.1145/3343031.3350996
   Srinivasan K, 2021, Arxiv, DOI arXiv:2103.01913
   Sugano Y, 2016, Arxiv, DOI arXiv:1608.05203
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Szegedy C., 2015, P IEEE C COMPUTER VI, P1, DOI DOI 10.1109/CVPR.2015.7298594
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tavakoli HR, 2017, IEEE I CONF COMP VIS, P2506, DOI 10.1109/ICCV.2017.272
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tran Alasdair, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13032, DOI 10.1109/CVPR42600.2020.01305
   Unanue IJ, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P915
   Van Miltenburg Emiel, 2018, COLING
   Vaswani A., 2017, P 31 INT C NEUR INF, P6000
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Vijayakumar AK, 2018, AAAI CONF ARTIF INTE, P7371
   Wang J, 2021, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR46437.2021.00136
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang LW, 2017, ADV NEUR IN, V30
   Wang QZ, 2022, IEEE T PATTERN ANAL, V44, P1035, DOI 10.1109/TPAMI.2020.3013834
   Wang QZ, 2019, PROC CVPR IEEE, P4190, DOI 10.1109/CVPR.2019.00432
   Wang SJ, 2021, PROC CVPR IEEE, P14045, DOI 10.1109/CVPR46437.2021.01383
   Wang YF, 2017, PROC CVPR IEEE, P7378, DOI 10.1109/CVPR.2017.780
   Wang ZR, 2022, Arxiv, DOI arXiv:2108.10904
   Welinder Peter, 2010, CALTECH UCSD BIRDS 2
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu SM, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1180, DOI 10.1145/2998181.2998364
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1029, DOI 10.1145/3240508.3240640
   Xia QL, 2020, Arxiv, DOI arXiv:2003.01473
   Xiangxi Shi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P574, DOI 10.1007/978-3-030-58568-6_34
   Xie HY, 2019, Arxiv, DOI arXiv:1912.08960
   Xu GH, 2021, PROC CVPR IEEE, P12632, DOI 10.1109/CVPR46437.2021.01245
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang LJ, 2017, PROC CVPR IEEE, P1978, DOI 10.1109/CVPR.2017.214
   Yang XY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5000
   Yang X, 2019, IEEE I CONF COMP VIS, P4249, DOI 10.1109/ICCV.2019.00435
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yang XW, 2021, Arxiv, DOI arXiv:2109.02865
   Yang Xuewen, 2020, COMPUTER VISION ECCV, P1
   Yang Y., 2011, P C EMP METH NAT LAN, P444, DOI DOI 10.5555/2145432.2145484
   Yang Z., 2016, P 30 INT C NEUR INF, V29, P2369
   Yang ZY, 2021, PROC CVPR IEEE, P8747, DOI 10.1109/CVPR46437.2021.00864
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yi YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P985
   Yin GJ, 2019, PROC CVPR IEEE, P6234, DOI 10.1109/CVPR.2019.00640
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Yiwu Zhong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P211, DOI 10.1007/978-3-030-58568-6_13
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, T ASSOC COMPUT LING, V2, P67
   Zeyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P629, DOI 10.1007/978-3-030-58571-6_37
   Zha ZJ, 2022, IEEE T PATTERN ANAL, V44, P710, DOI 10.1109/TPAMI.2019.2909864
   Zhang L., 2017, PROC INT C NEURAL IN
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang T., 2020, PROC INT C LEARN REP
   Zhang W, 2020, AAAI CONF ARTIF INTE, V34, P9571
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
   Zhao WT, 2020, AAAI CONF ARTIF INTE, V34, P12984
   Zheng Y, 2019, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2019.00859
   Zhengcong Fei, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P3182, DOI 10.1145/3394171.3413901
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu Q, 2021, AAAI CONF ARTIF INTE, V35, P3608
   Zhu XX, 2021, Arxiv, DOI arXiv:2012.09742
NR 254
TC 19
Z9 19
U1 57
U2 81
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JAN 1
PY 2023
VL 45
IS 1
BP 539
EP 559
DI 10.1109/TPAMI.2022.3148210
PG 21
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7B9BG
UT WOS:000899419900033
PM 35130142
OA Green Submitted
HC Y
HP N
DA 2023-11-10
ER

PT J
AU Ackley, DH
   Ackley, ES
AF Ackley, David H.
   Ackley, Elena S.
TI The <i>ulam</i> Programming Language for Artificial Life
SO ARTIFICIAL LIFE
LA English
DT Article; Proceedings Paper
CT 13th European Conference on Artificial Life (ECAL)
CY JUL 20-24, 2015
CL Univ York, York Ctr Complex Syst Anal, York, ENGLAND
SP MIT Press, Artificial Life, Springer, HIERATIC Project Hierarch Anal Complex Dynam Syst, FoCAS Project Fundamentals Collect Adapt Syst, Earth Life Sci Inst Origins Network, SimOmics
HO Univ York, York Ctr Complex Syst Anal
DE Robust first computing; best effort computing; movable feast machine;
   asynchronous cellular automata
AB Traditional digital computing demands perfectly reliable memory and processing, so programs can build structures once then use them foreverbut such deterministic execution is becoming ever more costly in large-scale systems. By contrast, living systems, viewed as computations, naturally tolerate fallible hardware by repairing and rebuilding structures even while in useand suggest ways to compute using massive amounts of unreliable, merely best-effort hardware. However, we currently know little about programming without deterministic execution, in architectures where traditional models of computationand deterministic ALife models such as the Game of Lifeneed not apply. This expanded article presents ulam, a language designed to balance concurrency and programmability upon best-effort hardware, using lifelike strategies to achieve robust and scalable computations. The article reviews challenges for traditional architecture, introduces the active-media computational model for which ulam is designed, and then presents the language itself, touching on its nomenclature and surface appearance as well as some broader aspects of robust software engineering. Several ulam examples are presented; then the article concludes with a brief consideration of the couplings between a computational model and its physical implementation.
C1 [Ackley, David H.] Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA.
   [Ackley, Elena S.] Ackleyshack LLC, POB 993, Placitas, NM 87043 USA.
C3 University of New Mexico
RP Ackley, DH (通讯作者)，Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA.
EM ackley@cs.unm.edu; esa@ackleyshack.com
CR Ackley D. H, 2014, MFM VERSION 2 CODEBA
   Ackley D. H., 1996, ARTIF LIFE, P116
   Ackley D. H., 2011, P HOTOS 13, P8
   Ackley DH, 2014, ALIFE 2014: THE FOURTEENTH INTERNATIONAL CONFERENCE ON THE SYNTHESIS AND SIMULATION OF LIVING SYSTEMS, P606, DOI 10.7551/978-0-262-32621-6-ch098
   Ackley DH, 2016, AAAI CONF ARTIF INTE, P4142
   Ackley DH, 2015, ECAL 2015: THE THIRTEENTH EUROPEAN CONFERENCE ON ARTIFICIAL LIFE, P554, DOI 10.7551/978-0-262-33027-5-ch097
   Ackley DH, 2013, COMPUT J, V56, P1450, DOI 10.1093/comjnl/bxs129
   Ackley DH, 2013, COMMUN ACM, V56, P38, DOI 10.1145/2505340
   Ackley DH, 2013, ARTIF LIFE, V19, P347, DOI 10.1162/ARTL_a_00117
   Ackley E. S, 2014, ULAM COMPILER MFM PR
   Agapie A, 2014, J COMPUT BIOL, V21, P699, DOI 10.1089/cmb.2014.0074
   [Anonymous], THESIS
   [Anonymous], 2012, P ACM WORKSH REL SYN, DOI DOI 10.1145/2414729.2414732
   Bedau MA, 2003, TRENDS COGN SCI, V7, P505, DOI 10.1016/j.tics.2003.09.012
   Beer RD, 2014, ARTIF LIFE, V20, P183, DOI 10.1162/ARTL_a_00125
   Bersini H., 1994, Artificial Life IV. Proceedings of the Fourth International Workshop on the Synthesis and Simulation of Living Systems, P382
   Borkar Shekhar, 1988, P SUP 88
   Budzynowski A., 2013, P 14 USENIX C HOT TO, P25
   Burks A.W., 1966, THEORY SELF REPRODUC
   Canton B, 2008, NAT BIOTECHNOL, V26, P787, DOI 10.1038/nbt1413
   Cappello F, 2009, INT J HIGH PERFORM C, V23, P374, DOI 10.1177/1094342009347767
   Elliott J, 2014, 2014 5TH WORKSHOP ON LATEST ADVANCES IN SCALABLE ALGORITHMS FOR LARGE-SCALE SYSTEMS (SCALA), P9, DOI 10.1109/ScalA.2014.5
   Gershenfeld N, 2010, ACM SIGPLAN NOTICES, V45, P1, DOI 10.1145/1707801.1706301
   GRINSTEIN G, 1985, PHYS REV LETT, V55, P2527, DOI 10.1103/PhysRevLett.55.2527
   Hutton T, 2012, READY CROSS PLATFORM
   IEEE, 2013, 2013 43 ANN IEEE IFI
   IEEE, 1988, 100311988 IEEE
   KARP RM, 1991, DISCRETE APPL MATH, V34, P165, DOI 10.1016/0166-218X(91)90086-C
   Kishinevsky M, 2007, IEEE DES TEST COMPUT, V24, P414, DOI 10.1109/MDT.2007.166
   Madhavan A, 2014, CONF PROC INT SYMP C, P517, DOI 10.1109/ISCA.2014.6853226
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Misailovic S, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465790
   Ray T. S, 1995, TRH133 ATR HUM INF P
   Renganarayana L., 2012, P 2012 ACM WORKSH RE, P41, DOI DOI 10.1145/2414729.2414737
   Reynolds C.W., 1987, SIGGRAPH COMPUTER GR, V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406, 10.1145/37401.37406]
   Stojanovic MN, 2003, NAT BIOTECHNOL, V21, P1069, DOI 10.1038/nbt862
   Toffoli T., 1987, CELLULAR AUTOMATA MA
   Ulam S, 1950, P INT C MATHEMATICIA, P264
NR 38
TC 4
Z9 4
U1 0
U2 4
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 1064-5462
EI 1530-9185
J9 ARTIF LIFE
JI Artif. Life
PD FAL
PY 2016
VL 22
IS 4
BP 431
EP 450
DI 10.1162/ARTL_a_00212
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EF3RC
UT WOS:000390241100002
PM 27824495
DA 2023-11-10
ER

PT J
AU Cong, Y
   Wu, YM
   Liang, XB
   Pei, JY
   Qin, ZS
AF Cong, Yao
   Wu, Yimin
   Liang, Xinbo
   Pei, Jiayan
   Qin, Zishan
TI PH-model: enhancing multi-passage machine reading comprehension with
   passage reranking and hierarchical information
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Multi-passage reading comprehension; Passage reranking; Hierarchical
   neural network; Gumbel-Softmax; Natural language processing
ID NEURAL-NETWORKS
AB Machine reading comprehension(MRC), which employs computers to answer questions from given passages, is a popular research field. In natural language, a natural hierarchical representation can be seen: characters, words, phrases, sentences, paragraphs, and documents. Current studies have demonstrated that hierarchical information can help machines understand natural language. However, prior works focused on the overall performance of MRC tasks without considering hierarchical information. In addition, the noise problem still has not been adequately addressed, even though many researchers have adopted the technique of passage reranking. Thus, in this paper, focusing on noise information processing and the extraction of hierarchical information, we propose a model (PH-Model) with a passage reranking framework (P) and hierarchical neural network (H) for a Chinese multi-passage MRC task. PH-Model produces more precise answers by reducing noise information and extracting hierarchical information. Experimental results on the DuReader 2.0 dataset (a large scale real-world Chinese MRC dataset) show that PH-Model outperforms the ROUGE-L and BLEU-4 baseline by 18.24% and 24.17%, respectively.
C1 [Cong, Yao; Wu, Yimin; Liang, Xinbo; Qin, Zishan] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Pei, Jiayan] South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Wu, YM (通讯作者)，South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM congyao95@hotmail.com; csymwu@scut.edu.cn; xbliang321@hotmail.com;
   scutasensio@gmail.com; qzs_233@foxmail.com
FU National Key R & D Program of China [2016YFB1200402-020]
FX This work is partially supported by the National Key R & D Program of
   China under Grant Number 2016YFB1200402-020. Any opinions, discussions,
   and conclusions in this material are those of the authors and do not
   necessarily reflect the views of the National Key R & D Program of
   China. We also appreciate the reviewers' valuable and profound comments.
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Catelli R, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106779
   Cui F, 2019, CHIN J URBAN ENV STU, V7, DOI 10.1142/S2345748119400062
   Duta IC, 2016, INT WORK CONTENT MUL
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Esposito M, 2020, INFORM SCIENCES, V514, P88, DOI 10.1016/j.ins.2019.12.002
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   He W, 2018, MACHINE READING FOR QUESTION ANSWERING, P37
   Imran SA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1193, DOI 10.1109/ROBIO.2013.6739626
   Jang Eric, 2017, INT C LEARN REPR
   Jiahua L, 2018, J CHINESE INFORM PRO
   Jiang YC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2714
   Lai G., 2017, EMNLP, P785, DOI DOI 10.18653/V1/D17-1082
   Lan Zhenzhong, 2019, ARXIV190911942
   Li Z, 2018, CHIN INT CONF ELECTR, P93, DOI 10.1109/CICED.2018.8592530
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, DOI DOI 10.2307/3105454
   Lin DW, 2019, LECT NOTES COMPUT SC, V11772, P121, DOI 10.1007/978-3-030-31624-2_10
   Liu J, 2018, P 2018 C EMP METH NA, P2109
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mucheng Ren, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P736, DOI 10.1007/978-3-030-32236-6_67
   Nishida K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2335
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pota M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144710
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seo Min Joon, 2017, 5 INT C LEARN REPR I
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vinyals O., 2015, P ADV NEURAL INFORM, P2692, DOI 10.48550/arxiv.1506.03134
   Wang Shuohang, 2017, P 5 INT C LEARN REPR
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Wang YZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1918
   Yan M, 2019, AAAI CONF ARTIF INTE, P7354
   Yang A, 2018, MACHINE READING FOR QUESTION ANSWERING, P98
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
NR 38
TC 5
Z9 5
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD AUG
PY 2021
VL 51
IS 8
BP 5440
EP 5452
DI 10.1007/s10489-020-02168-3
EA JAN 2021
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TG7OE
UT WOS:000606299200003
DA 2023-11-10
ER

PT J
AU Lin, CJ
   Weng, RC
   Keerthi, SS
AF Lin, Chih-Jen
   Weng, Ruby C.
   Keerthi, S. Sathiya
TI Trust region Newton method for large-scale logistic regression
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE logistic regression; newton method; trust region; conjugate gradient;
   support vector machines
ID OPTIMIZATION
AB Large-scale logistic regression arises in many applications such as document classification and natural language processing. In this paper, we apply a trust region Newton method to maximize the log-likelihood of the logistic regression model. The proposed method uses only approximate Newton steps in the beginning, but achieves fast convergence in the end. Experiments show that it is faster than the commonly used quasi Newton approach for logistic regression. We also extend the proposed method to large-scale L2-loss linear support vector machines (SVM).
C1 [Lin, Chih-Jen] Natl Taiwan Univ, Dept Comp Sci, Taipei 106, Taiwan.
   [Weng, Ruby C.] Natl Chengchi Univ, Dept Stat, Taipei 116, Taiwan.
   [Keerthi, S. Sathiya] Yahoo Res, Santa Clara, CA 95054 USA.
C3 National Taiwan University; National Chengchi University; Yahoo! Inc;
   Yahoo! Inc United States
RP Lin, CJ (通讯作者)，Natl Taiwan Univ, Dept Comp Sci, Taipei 106, Taiwan.
EM cjlin@csie.ntu.edu.tw; chweng@nccu.edu.tw; selvarak@yahoo-inc.com
OI Lin, Chih-Jen/0000-0003-4684-8747; WENG, CHIU-HSING/0000-0001-5495-3817
CR [Anonymous], ALGORITHMS SPARSE LI
   [Anonymous], 2007, P 24 INT C MACH LEAR
   [Anonymous], 2006, INTRO STAT RELATIONA
   Asuncion A, 2007, UCI MACHINE LEARNING
   BENSON S, 2001, MCSP9090901 MATH COM
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   BOUARICHA A, 1997, MCSP6350197 ARG NAT
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   DUFF IS, 1989, ACM T MATH SOFTWARE, V15, P1, DOI 10.1145/62038.62043
   GOODMAN J, 2002, ACL, P9
   JIN R, 2003, P 20 INT C MACH LEAR
   Joachims T., 2006, P ACM C KNOWLEDGE DI
   Kao WC, 2004, NEURAL COMPUT, V16, P1689, DOI 10.1162/089976604774201640
   Keerthi SS, 2005, J MACH LEARN RES, V6, P341
   Koh KM, 2007, J MACH LEARN RES, V8, P1519
   KOMAREK P, 2005, TR0527 CARN MELL U R
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Lin C. J., 2007, P 24 INT C MACH LEAR
   Lin CJ, 1999, SIAM J OPTIMIZ, V9, P1100, DOI 10.1137/S1052623498345075
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Malouf R., 2002, P 6 C NAT LANG LEARN, P1, DOI DOI 10.3115/1118853.1118872
   Mangasarian OL, 2002, OPTIM METHOD SOFTW, V17, P913, DOI 10.1080/1055678021000028375
   Minka T., 2003, COMP NUMERICAL OPTIM
   Nash SG, 2000, J COMPUT APPL MATH, V124, P45, DOI 10.1016/S0377-0427(00)00426-X
   Nash SG, 1991, SIAM J OPTIMIZ, V1, P358, DOI 10.1137/0801023
   Platt J., 1998, SUPPORT VECTOR LEARN
   Smola AJ, 2008, ADV NEURAL INFORM PR, V20
   STEIHAUG T, 1983, SIAM J NUMER ANAL, V20, P626, DOI 10.1137/0720042
   Zou X, 1993, SIAM J OPTIMIZ, V3, P582, DOI 10.1137/0803029
NR 30
TC 234
Z9 249
U1 9
U2 26
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD APR
PY 2008
VL 9
BP 627
EP 650
PG 24
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA 312AS
UT WOS:000256642100004
DA 2023-11-10
ER

PT J
AU Terenin, A
   Magnusson, M
   Jonsson, L
   Draper, D
AF Terenin, Alexander
   Magnusson, Mans
   Jonsson, Leif
   Draper, David
TI Polya Urn Latent Dirichlet Allocation: A Doubly Sparse Massively
   Parallel Sampler
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Bayesian inference; big data; computational complexity; gibbs sampling;
   latent dirichlet allocation; markov chain monte carlo; natural language
   processing; parallel and distributed systems; topic models
AB Latent Dirichlet Allocation (LDA) is a topic model widely used in natural language processing and machine learning. Most approaches to training the model rely on iterative algorithms, which makes it difficult to run LDA on big corpora that are best analyzed in parallel and distributed computational environments. Indeed, current approaches to parallel inference either don't converge to the correct posterior or require storage of large dense matrices in memory. We present a novel sampler that overcomes both problems, and we show that this sampler is faster, both empirically and theoretically, than previous Gibbs samplers for LDA. We do so by employing a novel Polya-urn-based approximation in the sparse partially collapsed sampler for LDA. We prove that the approximation error vanishes with data size, making our algorithm asymptotically exact, a property of importance for large-scale topic models. In addition, we show, via an explicit example, that-contrary to popular belief in the topic modeling literature-partially collapsed samplers can be more efficient than fully collapsed samplers. We conclude by comparing the performance of our algorithm with that of other approaches on well-known corpora.
C1 [Terenin, Alexander] Imperial Coll London, Dept Math, Stat Sect, London SW7 2AZ, England.
   [Magnusson, Mans; Jonsson, Leif] Linkoping Univ, S-58183 Linkoping, Sweden.
   [Draper, David] Univ Calif Santa Cruz, Dept Appl Math & Stat, Stat, Santa Cruz, CA 95064 USA.
C3 Imperial College London; Linkoping University; University of California
   System; University of California Santa Cruz
RP Terenin, A (通讯作者)，Imperial Coll London, Dept Math, Stat Sect, London SW7 2AZ, England.
EM a.terenin17@imperial.ac.uk; mons.magnusson@gmail.com;
   leif.jonsson@ericsson.se; draper@ucsc.edu
OI Jonsson, Leif/0000-0002-8989-0251; Terenin,
   Alexander/0000-0001-5292-3104; Draper, David/0000-0002-6367-3101
FU Swedish Foundation for Strategic Research [RIT 15-0097]
FX We are thankful to Graham Neubig, Tamara Broderick, Eric P. Xing, Qirong
   Ho, Wei Dai, Willie Neiswanger, Murat Demirbas, Shawfeng Dong, Thanasis
   Kottas, Kunal Sarkhel, and Mattias Villani for their thoughts, and to
   several referees whose comments substantially improved the paper.
   Membership on this list does not imply agreement with the ideas
   expressed here, nor responsibility for any errors that may be present.
   Mans Magnusson was partially financially supported by the Swedish
   Foundation for Strategic Research (Smart Systems: RIT 15-0097).
CR Airoldi EM, 2008, J MACH LEARN RES, V9, P1981
   Anandkumar  A., 2012, NIPS
   [Anonymous], 2015, ARXIV150803387
   [Anonymous], 2007, P 45 ANN M ASS COMP
   [Anonymous], 1968, PSYCHOBIOLOGY LANGUA
   [Anonymous], 2005, P NEURAL INFORM PROC
   ARAUJO MD, 1997, P 4 S AM WORKSH STRI, V8, P2
   BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chamandy N, 2015, AM STAT, V69, P283, DOI 10.1080/00031305.2015.1089790
   Chen JF, 2016, PROC VLDB ENDOW, V9, P744, DOI 10.14778/2977797.2977801
   Draper D., OPTIMAL BAYESIAN ANA
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Heaps H. S., 1978, INFORM RETRIEVAL COM
   Hoffman MD, 2013, J MACH LEARN RES, V14, P1303
   Ihler A, 2012, IEEE T KNOWL DATA EN, V24, P952, DOI 10.1109/TKDE.2011.29
   Johndrow James E, 2018, J AM STAT ASS
   JOHNDROW JE, 2017, ARXIV170500841
   Kotz S., 2000, WILEY SER PROB STAT, V1
   Li AQ, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P891, DOI 10.1145/2623330.2623756
   Li Q, 2017, IEEE PHOTON CONF, P49, DOI 10.1109/IPCon.2017.8116001
   LIU JS, 1995, J ROY STAT SOC B MET, V57, P157
   Magnusson M, 2018, J COMPUT GRAPH STAT, V27, P449, DOI 10.1080/10618600.2017.1366913
   Marsaglia G, 2000, ACM T MATH SOFTWARE, V26, P363, DOI 10.1145/358407.358414
   McCallum Andrew Kachites, 2002, MALLET MACHINE LEARN
   Mimno David, 2011, EMNLP 11 P C EMPIRIC, P262, DOI DOI 10.5555/2145432.2145462
   Negrea Jeffrey, 2017, ARXIV170207441
   Newman D, 2009, J MACH LEARN RES, V10, P1801
   Oza NC, 2005, IEEE SYS MAN CYBERN, P2340
   Teh Y. W., 2010, ENCY MACHINE LEARNIN, DOI DOI 10.1007/978-0-387-30164-8_219
   Terenin A, 2018, STAT COMPUT, P1
   Terenin A., 2016, ARXIV150908999
   van der Vaart A.W., 2000, CAMBRIDGE SERIES STA
   Walker A. J., 1977, ACM Transactions on Mathematical Software, V3, P253, DOI 10.1145/355744.355749
   Wallach Hanna M., 2009, P 26 ANN INT C MACH, P1105, DOI DOI 10.1145/1553374.1553515
   Yao LM, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P937
   Yuan JH, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1351, DOI 10.1145/2736277.2741115
   Yurochkin M., 2017, ADV NEURAL INFORM PR, P3881
   Yurochkin M., 2016, ADV NEURAL INFORM PR, P2505
NR 39
TC 6
Z9 6
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUL
PY 2019
VL 41
IS 7
BP 1709
EP 1719
DI 10.1109/TPAMI.2018.2832641
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IC4XW
UT WOS:000470972300014
PM 29994329
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Read, T
   Bárcena, E
   Barros, B
   Verdejo, F
AF Read, T
   Bárcena, E
   Barros, B
   Verdejo, F
TI Adaptive modelling of student diagnosis and material selection for
   on-line language learning
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article; Proceedings Paper
CT 8th Ibero-American Conference on Artifical Intelligence (IBERAMIA 02)
CY NOV 12-15, 2002
CL SEVILLE, SPAIN
SP Univ Sevilla, CICYT, FIDETIA
ID BAYESIAN NETWORKS
AB The use of interactive on-line environments in distance learning appears to be promising because they solve some of the difficulties teachers have maintaining control of individual student progress due to the large number of students present in such courses. However, in the case of language learning, work is still required to design a system that is as flexible and effective as an experienced teacher. In this paper I-PETER (Intelligent Personalised English Tutoring EnviRonment) is presented as an advance in this area. It has four domain models that represent linguistic and didactic knowledge. Its student linguistic knowledge model is richer than that typically used in language teaching: a student's command of English is evaluated by interpreting his/her performance on specific linguistic units in terms of three related criteria, rather than by a general linguistic competence ranking. This model enables error diagnosis to be undertaken using a Bayesian network, to reflect how teachers actually undertake the process in the classroom. The results of this diagnosis process enable a finer-grained control of material selection than is normally possible, giving rise to a course structure that is continuously adapted to individual student needs.
C1 Univ Nacl Educ Distancia, Dept Lenguajes & Sistemas Informat, Madrid 28040, Spain.
   Filologias Extranjeras & Linguist, Madrid 28040, Spain.
C3 Universidad Nacional de Educacion a Distancia (UNED)
RP Read, T (通讯作者)，Univ Nacl Educ Distancia, Dept Lenguajes & Sistemas Informat, Edificio Interfacultat,C Juan del Rosal 16, Madrid 28040, Spain.
EM tread@lsi.uned.es; mbarcena@flog.uned.es; bbarros@lsi.uned.es;
   felisa@lsi.uned.es
RI Barros, Beatriz/F-7921-2016; Barros, Beatriz/AGX-0172-2022
OI Barros, Beatriz/0000-0001-6546-3688; Barros, Beatriz/0000-0001-6546-3688
CR [Anonymous], 1988, 2 LANGUAGE ACQUISITI
   [Anonymous], 1998, INT J ARTIFICIAL INT
   Bunt A, 2002, LECT NOTES COMPUT SC, V2363, P698
   CARBONEL.JR, 1970, IEEE T MAN MACHINE, VMM11, P190, DOI 10.1109/TMMS.1970.299942
   Chapelle C. A., 1997, LANGUAGE LEARNING TE, V1, P19
   Clancey W. J., 1983, Journal of Computer-Based Instruction, V10, P8
   CONATI C, 1996, P UM 96 U HAW
   Dimitrova V, 1998, BRIT J EDUC TECHNOL, V29, P47, DOI 10.1111/1467-8535.00045
   Halliday MA., 1994, FUNCTIONAL GRAMMAR
   HARRELL W, 1999, INT J INSTRUCTIONAL, V23, P267
   HEIFT T, 2002, INT J ARTIFICIAL INT, V12, P310
   HOLLAND MV, 1995, INTELLIGENT LANGUAGE
   JOHNSON WL, 1985, IEEE T SOFTWARE ENG, V11, P267, DOI 10.1109/TSE.1985.232210
   KOHN K, 1994, BARRIERS BRIDGES MED, P31
   Levy M., 1997, COMPUT ASSIST LANG L
   MAYO J, 2001, THESIS U CANTERBURY
   Merrill D. C., 1992, J LEARN SCI, V2, P277, DOI [DOI 10.1207/S15327809JLS0203_2, 10.1207/s15327809jls0203_2]
   Millán E, 2000, LECT NOTES COMPUT SC, V1839, P534
   Pearl J., 1988, MORGAN KAUFMANN SERI
   VanLehn K., 1988, FDN INTELLIGENT TUTO, V55, P78
   WEGNER E, 1987, ARTIFICIAL INTELLIGE
NR 21
TC 5
Z9 5
U1 0
U2 2
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2002
VL 12
IS 3-4
BP 135
EP 149
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 687LY
UT WOS:000183379200002
DA 2023-11-10
ER

PT J
AU Fu, NH
   Wei, L
   Song, YQ
   Li, QY
   Xin, R
   Omee, SS
   Dong, RZ
   Siriwardane, EMD
   Hu, JJ
AF Fu, Nihang
   Wei, Lai
   Song, Yuqi
   Li, Qinyang
   Xin, Rui
   Omee, Sadman Sadeed
   Dong, Rongzhi
   Siriwardane, Edirisuriya M. Dilanga
   Hu, Jianjun
TI Material transformers: deep learning language models for generative
   materials design
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE deep learning; language models; generative design; materials discovery;
   transformer
ID TOTAL-ENERGY CALCULATIONS; WAVE
AB Pre-trained transformer language models (LMs) on large unlabeled corpus have produced state-of-the-art results in natural language processing, organic molecule design, and protein sequence generation. However, no such models have been applied to learn the composition patterns for the generative design of material compositions. Here we train a series of seven modern transformer models (GPT, GPT-2, GPT-Neo, GPT-J, BLMM, BART, and RoBERTa) for materials design using the expanded formulas of the ICSD, OQMD, and Materials Projects databases. Six different datasets with/out non-charge-neutral or EB samples are used to benchmark the generative design performances and uncover the biases of modern transformer models for the generative design of materials compositions. Our experiments show that the materials transformers based on causal LMs can generate chemically valid material compositions with as high as 97.61% to be charge neutral and 91.22% to be electronegativity balanced, which has more than six times higher enrichment compared to the baseline pseudo-random sampling algorithm. Our LMs also demonstrate high generation novelty and their potential in new materials discovery is proved by their capability to recover the leave-out materials. We also find that the properties of the generated compositions can be tailored by training the models with selected training sets such as high-bandgap samples. Our experiments also show that different models each have their own preference in terms of the properties of the generated samples and their running time complexity varies a lot. We have applied our materials transformers to discover a set of new materials as validated using density functional theory calculations.
C1 [Fu, Nihang; Wei, Lai; Song, Yuqi; Li, Qinyang; Xin, Rui; Omee, Sadman Sadeed; Dong, Rongzhi; Hu, Jianjun] Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29201 USA.
   [Siriwardane, Edirisuriya M. Dilanga] Univ Colombo, Dept Phys, Colombo 03, Sri Lanka.
C3 University of South Carolina System; University of South Carolina
   Columbia; University of Colombo
RP Hu, JJ (通讯作者)，Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29201 USA.
EM jianjunh@cse.sc.edu
OI Wei, Lai/0000-0003-0344-8540; Dong, Rongzhi/0000-0003-1467-6725;
   Siriwardane, Edirisuriya/0000-0001-8960-5273; Li,
   Qinyang/0009-0000-1544-8754
FU National Science Foundation [1940099, 1905775, 2110033]; Direct For
   Mathematical & Physical Scien; Division Of Materials Research [1905775]
   Funding Source: National Science Foundation; Div Of Electrical, Commun &
   Cyber Sys; Directorate For Engineering [2110033] Funding Source:
   National Science Foundation; Office of Advanced Cyberinfrastructure
   (OAC); Direct For Computer & Info Scie & Enginr [1940099] Funding
   Source: National Science Foundation
FX The research reported in this work was supported in part by National
   Science Foundation under the Grant Nos. 1940099, 1905775 and 2110033.
   The views, perspectives, and content do not necessarily represent the
   official views of the NSF.
CR Bagal V, 2022, J CHEM INF MODEL, V62, P2064, DOI 10.1021/acs.jcim.1c00600
   Black Sid, 2021, Zenodo
   BLOCHL PE, 1994, PHYS REV B, V50, P17953, DOI 10.1103/PhysRevB.50.17953
   Brown T.B., 2020, P 34 INT C NEUR INF
   Dan YB, 2019, Arxiv, DOI arXiv:1911.05020
   Dan YB, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-00352-0
   Davies D W, 2019, J OPEN SOURCE SOFTW, V41361
   De Cao N, 2018, Arxiv, DOI [arXiv:1805.11973, DOI 10.48550/ARXIV.1805.11973]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dollar O, 2021, CHEM SCI, V12, P8362, DOI 10.1039/d1sc01050f
   Dong L, 2019, ADV NEUR IN, V32
   Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7
   Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x
   Gao L, 2020, Arxiv, DOI arXiv:2101.00027
   Goodall REA, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19964-7
   Guimaraes GL, 2018, Arxiv, DOI [arXiv:1705.10843, DOI 10.48550/ARXIV.1705.10843]
   Hautier G, 2011, INORG CHEM, V50, P656, DOI 10.1021/ic102031h
   Hesslow D, 2022, Arxiv, DOI arXiv:2205.05789
   Hu JJ, 2023, Arxiv, DOI arXiv:2102.01620
   Ingraham J, 2019, ADV NEUR IN, V32
   Jain A, 2013, APL MATER, V1, DOI 10.1063/1.4812323
   Jang J, 2020, J AM CHEM SOC, V142, P18836, DOI 10.1021/jacs.0c07384
   Kim H, 2021, J CHEM INF MODEL, V61, P5804, DOI 10.1021/acs.jcim.1c01289
   Kresse G, 1996, PHYS REV B, V54, P11169, DOI 10.1103/PhysRevB.54.11169
   KRESSE G, 1993, PHYS REV B, V47, P558, DOI 10.1103/PhysRevB.47.558
   Kresse G, 1999, PHYS REV B, V59, P1758, DOI 10.1103/PhysRevB.59.1758
   Kresse G, 1996, COMP MATER SCI, V6, P15, DOI 10.1016/0927-0256(96)00008-0
   Kusaba M, 2022, ARXIV
   Lewis M, 2019, Arxiv, DOI [arXiv:1910.13461, DOI 10.48550/ARXIV.1910.13461, 10.48550/arXiv.1910.13461]
   Li J, 2022, ARXIV
   Li JY, 2021, Arxiv, DOI arXiv:2105.10311
   Linder J, 2020, CELL SYST, V11, P49, DOI 10.1016/j.cels.2020.05.007
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Madani A, 2020, Arxiv, DOI [arXiv:2004.03497, 10.48550/arXiv.2004.03497, DOI 10.48550/ARXIV.2004.03497]
   Narasimhan, IMPROVING LANGUAGE U
   Oganov A.R., 2012, CECAM WORKSH LAUS 20, P22
   Omee SS, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100491
   Osadchy M, 2021, J PHYS CHEM B, V125, P6440, DOI 10.1021/acs.jpcb.1c02449
   Perdew JP, 1996, PHYS REV LETT, V77, P3865, DOI 10.1103/PhysRevLett.77.3865
   Polykovskiy D, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.565644
   Radford A., 2019, OPENAI BLOG, V19
   Raffel C, 2020, Arxiv, DOI arXiv:1910.10683
   Rothchild D, 2021, Arxiv, DOI [arXiv:2108.10307, DOI 10.48550/ARXIV.2108.10307]
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI [10.1162/tacl_a_.00313, 10.1162/tacl_a_00313]
   Shao XC, 2022, J CHEM PHYS, V156, DOI 10.1063/5.0074677
   Shen T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5186
   Sun WH, 2019, NAT MATER, V18, P732, DOI 10.1038/s41563-019-0396-2
   Wang Ben, 2021, GPT J 6B 6 BILLION P
   Wei J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P932
   Wei L., 2022, ARXIV
   Wei L, 2022, INORG CHEM, V61, P8431, DOI 10.1021/acs.inorgchem.1c03879
   Wu Z, 2020, ACS SYNTH BIOL, V9, P2154, DOI 10.1021/acssynbio.0c00219
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zagorac D, 2019, J APPL CRYSTALLOGR, V52, P918, DOI 10.1107/S160057671900997X
   Zhao Y, 2021, ADV SCI, V8, DOI 10.1002/advs.202100566
   Zunger A, 2021, CHEM REV, V121, P3031, DOI 10.1021/acs.chemrev.0c00608
NR 56
TC 3
Z9 3
U1 14
U2 47
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR 1
PY 2023
VL 4
IS 1
DI 10.1088/2632-2153/acadcd
PG 16
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA 7P0UQ
UT WOS:000908430900001
OA gold
DA 2023-11-10
ER

PT S
AU Roy, D
   Patel, R
   DeCamp, P
   Kubat, R
   Fleischman, M
   Roy, B
   Mavridis, N
   Tellex, S
   Salata, A
   Guinness, J
   Levit, M
   Gorniak, P
AF Roy, Deb
   Patel, Rupal
   DeCamp, Philip
   Kubat, Rony
   Fleischman, Michael
   Roy, Brandon
   Mavridis, Nikolaos
   Tellex, Stefanie
   Salata, Alexia
   Guinness, Jethran
   Levit, Michael
   Gorniak, Peter
BE Vogt, P
   Sugita, Y
   Tuci, E
   Nehaniv, C
TI The human Speechome Project
SO SYMBOL GROUNDING AND BEYOND, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 3rd Annual International Wokshop on Emergence and Evolution of
   Linguistic Communication
CY SEP 30-OCT 01, 2006
CL Rome, ITALY
AB The Human Speechome Project is an effort to observe and computationally model the longitudinal course of language development for a single child at an unprecedented scale. We are collecting audio and video recordings for the first three years of one child's life, in its near entirety, as it unfolds in the child's home. A network of ceiling-mounted video cameras and microphones are generating approximately 300 giga-bytes of observational data each day from the home. One of the worlds largest single-volume disk arrays is under construction to house approximately 400,000 hours of audio and video recordings that will accumulate over the three year study. To analyze the massive data set, we are developing new data mining technologies to help human analysts rapidly annotate and transcribe recordings using semi-automatic methods, and to detect and visualize salient patterns of behavior and interaction. To make sense of large-scale patterns,that span across months or even years of observations, we are developing computational models of language acquisition that are able to learn from the childs experiential record. By creating and evaluating machine learning systems that step into the shoes of the child and sequentially process long stretches of perceptual experience, we will investigate possible language learning strategies used by children with an emphasis on early word learning.
C1 MIT, Media Lab, Cognit Machines Grp, Cambridge, MA 02139 USA.
   Northeastern Univ, Commun Anal & Design Lab, Boston, MA 02115 USA.
C3 Massachusetts Institute of Technology (MIT); Northeastern University
RP Roy, D (通讯作者)，MIT, Media Lab, Cognit Machines Grp, Cambridge, MA 02139 USA.
EM dkroy@media.mit.edu
RI Galantucci, Bruno/E-5770-2010
CR FLEISCHMAN M, 2005, P 27 ANN M COGN SCI
   Gorniak P.J., 2005, THESIS MIT
   Roy D, 2005, ARTIF INTELL, V167, P170, DOI 10.1016/j.artint.2005.04.007
   Roy D, 2006, P 28 ANN COGN SCI C
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4
   Tomasello M, 2004, J CHILD LANG, V31, P101, DOI 10.1017/S0305000903005944
NR 6
TC 35
Z9 35
U1 1
U2 9
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-45769-0
J9 LECT NOTES ARTIF INT
PY 2006
VL 4211
BP 192
EP 196
PG 5
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFJ24
UT WOS:000242307400015
DA 2023-11-10
ER

PT J
AU Chen, GY
   van Deemter, K
AF Chen, Guanyi
   van Deemter, Kees
TI Computational Modelling of Quantifier Use: Corpus, Models, and
   Evaluation
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
LA English
DT Article
ID NATURAL-LANGUAGE GENERATION; REFERRING EXPRESSIONS; SEMANTICS; SPEAKERS;
   AUDIENCE
AB A prominent strand of work in formal semantics investigates the ways in which human languages quantify the elements of a set, as when we say All A are B, Few A are B, and so on. Building on a growing body of empirical studies that shed light on the meaning and the use of quantifiers, we extend this line of work by computationally modelling how human speakers textually describe complex scenes in which quantitative relations play an important role. To this end, we conduct a series of elicitation experiments in which human speakers were asked to perform a linguistic task that invites the use of quantified expressions. The experiments result in a corpus, called QTUNA, made up of short texts that contain a large variety of quantified expressions. We analyse QTUNA, summarise our findings, and explain how we design computational models of human quantifier use accordingly. Finally, we evaluate these models in accordance with QTUNA.
C1 [Chen, Guanyi; van Deemter, Kees] Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
C3 Utrecht University
RP Chen, GY (通讯作者)，Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
EM g.chen@uu.nl; c.j.vandeemter@uu.nl
CR [Anonymous], 2014, THESIS
   Barr D., 2013, P 14 EUROPEAN WORKSH, P157
   BARWISE J, 1981, LINGUIST PHILOS, V4, P159, DOI 10.1007/BF00350139
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Belz A., 2007, P UCNLG MT LANGUAGE, P75
   Busemeyer JR, 2000, J MATH PSYCHOL, V44, P171, DOI 10.1006/jmps.1999.1282
   Chen G., 2020, P 13 INT C NATURAL L, P263
   Chen G., 2022, FINDINGS ASS COMPUTA, P73
   Chen G., 2022, THESIS UTRECHT U
   Chen G., 2019, P 12 INT C NATURAL L, P529
   Chen G., 2019, P 12 INT C NAT LANG, P124
   Coupland N., 2008, SOCIOLINGUISTICS REA
   Creaney N., 1996, 8 INT NAT LANG GEN W
   DALE R, 1995, COGNITIVE SCI, V19, P233, DOI 10.1207/s15516709cog1902_3
   Dale R., 2009, P 12 EUR WORKSH NAT, P58, DOI DOI 10.3115/1610195.1610204
   Degen J., 2011, P ANN M COGN SCI SOC, V33
   Degen J, 2020, PSYCHOL REV, V127, P591, DOI 10.1037/rev0000186
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Engelhardt PE, 2011, BRAIN COGNITION, V77, P304, DOI 10.1016/j.bandc.2011.07.004
   Engelhardt PE, 2006, J MEM LANG, V54, P554, DOI 10.1016/j.jml.2005.12.009
   Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633
   Franke M., 2014, P ANN M COGN SCI SOC
   Gatt A., 2007, PROCEEDPROCEEDINGS 1, P49
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Geurts B, 2007, LANGUAGE, V83, P533, DOI 10.1353/lan.2007.0115
   Gibbs RW, 2012, TOP COGN SCI, V4, P7, DOI 10.1111/j.1756-8765.2011.01172.x
   Grice P., 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1163/9789004368811_003
   Herbelot A., 2015, P 2015 C EMPIRICAL M, P22
   Holden JG, 2009, PSYCHOL REV, V116, P318, DOI 10.1037/a0014849
   Horton WS, 1996, COGNITION, V59, P91, DOI 10.1016/0010-0277(96)81418-1
   Howcroft D. M., 2017, P 10 INT C NATURAL L, P149
   Kamp H., 1993, DISCOURSE LOGIC INTR
   KAUFMAN EL, 1949, AM J PSYCHOL, V62, P498, DOI 10.2307/1418556
   Kenney R., 1996, VAGUENESS READER
   Koolen R, 2011, J PRAGMATICS, V43, P3231, DOI 10.1016/j.pragma.2011.06.008
   Kotek H, 2015, NAT LANG SEMANT, V23, P119, DOI 10.1007/s11050-015-9113-0
   Krahmer E, 2012, COMPUT LINGUIST, V38, P173, DOI 10.1162/COLI_a_00088
   Kutlak R, 2016, FRONT PSYCHOL, V7, DOI [10.3389/fphyg.2016.01275, 10.3389/fpsyg.2016.01275]
   Lappin S, 2000, LINGUIST PHILOS, V23, P599, DOI 10.1023/A:1005638918877
   Levinson Stephen C., 1983, CAMBRIDGE TXB LINGUI
   Lidz J, 2011, NAT LANG SEMANT, V19, P227, DOI 10.1007/s11050-010-9062-6
   Moxey L. M., 1993, COMMUNICATING QUANTI
   Nouwen R., 2010, LINGUISTIC ENTERPRIS, V150, P235, DOI [10.1075/la.150.10nou, DOI 10.1075/LA.150.10NOU]
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   PECHMANN T, 1989, LINGUISTICS, V27, P89, DOI 10.1515/ling.1989.27.1.89
   Peters Stanley., 2006, QUANTIFIERS LANGUAGE
   Pezzelle S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2865
   Pezzelle S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P114
   Qing C., 2014, THESIS U AMSTERDAM
   Reiter E., 2000, BUILDING NATURAL LAN, P41
   Same F, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5554
   Schmuckler MA, 2001, INFANCY, V2, P419, DOI 10.1207/S15327078IN0204_02
   Solt S, 2016, LANGUAGE, V92, P65, DOI 10.1353/lan.2016.0016
   Sorensen R., 2022, STANFORD ENCY PHILOS
   Sorodoc I., 2016, P 5 WORKSHOP VISION, P75
   Sun R, 2008, CAMB HANDB PSYCHOL, P1, DOI 10.1017/CBO9780511816772
   Testoni A., 2019, P WORKSHOP COGNITIVE, P105
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   van Deemter K., 2016, COMP MOD REF STUD
   van Deemter K., 2017, P 10 INT C NAT LANG, P213
   van Deemter K, 2012, COGNITIVE SCI, V36, P799, DOI 10.1111/j.1551-6709.2011.01205.x
   van Gompel RPG, 2019, PSYCHOL REV, V126, P345, DOI 10.1037/rev0000138
   Viethen J., 2008, P 5 INT NATURAL LANG, P59
   Yildirim I., 2013, P 35 ANN M COGN SCI
   Zajenkowski M, 2013, INTELLIGENCE, V41, P456, DOI 10.1016/j.intell.2013.06.020
NR 65
TC 0
Z9 0
U1 1
U2 1
PU AI ACCESS FOUNDATION
PI MARINA DEL REY
PA USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA
   90292-6695 USA
SN 1076-9757
EI 1943-5037
J9 J ARTIF INTELL RES
JI J. Artif. Intell. Res.
PY 2023
VL 77
BP 167
EP 206
PG 40
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J5IB3
UT WOS:001009942300002
DA 2023-11-10
ER

PT J
AU Wotawa, F
AF Wotawa, F
TI Debugging hardware designs using a value-based model
SO APPLIED INTELLIGENCE
LA English
DT Article
DE model-based reasoning; software debugging; debugging of hardware designs
ID DIAGNOSIS
AB In this paper we describe the use of model-based diagnosis for locating bugs in hardware designs. Nowadays hardware designs are written in a programming language. We restrict our view to hardware designs written in a subset of the commonly used hardware description language VHDL. This subset includes all synthesize-able (register transfer level (RTL)) programs, i.e., programs that can be automatically converted into a gate level representation. Therefore almost all VHDL programs are RTL programs. We show the conversion of VHDL programs into a logical representation. This representation is a model that can be directly used by a model-based diagnosis engine for computing diagnoses. The resulting diagnoses are mapped back to the VHDL code fragments of the original program explaining a misbehavior. In addition, we specify some rules optimizing the obtained results. We further present some arguments showing that the proposed debugging technique scales up to large designs.
C1 Graz Tech Univ, Inst Software Technol, A-8010 Graz, Austria.
C3 Graz University of Technology
RP Wotawa, F (通讯作者)，Graz Tech Univ, Inst Software Technol, Inffeldgasse 166-2, A-8010 Graz, Austria.
OI Wotawa, Franz/0000-0002-0462-2283
CR [Anonymous], VHDL ANAL MODELING D
   [Anonymous], 1994, FDN COMPUTER SCI
   BOND GW, 1994, SCE9415 CARL U DEP S
   BOND GW, 1994, THESIS CARLETON U OT
   BOTTCHER C, 1995, P 14 INT JOINT C ART
   BURNELL L, 1995, COMMUN ACM, V38, P31, DOI 10.1145/203330.203338
   Burnell L J., 1993, P 9 C, P285
   CHENG KT, 1999, IEEE COMPUTER, V32
   CHUNG PY, 1994, IEEE T VERY LARGE SC, V2, P320
   CONSOLE L, 1993, P 13 INT JOINT C ART, P1494
   DEKLEER J, 1987, ARTIF INTELL, V32, P97, DOI 10.1016/0004-3702(87)90063-4
   DEKLEER J, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P324
   FATTAH YE, 1995, P 14 INT JOINT C ART, P1742
   Friedrich G, 1999, ARTIF INTELL, V111, P3, DOI 10.1016/S0004-3702(99)00034-X
   FROHLICH P, 1997, P 15 INT JOINT C ART
   GREIF G, 1989, J GAY LESBIAN PSYCHO, V1, P79
   HAMSCHER WC, 1984, P AAAI 84 AUST TX, P276
   IEEE, 1988, 10761987 IEEE
   *IEEE, 1998, P10766D112 IEEE
   Jackson D., 1995, ACM Transactions on Software Engineering and Methodology, V4, P109, DOI 10.1145/210134.210135
   REITER R, 1987, ARTIF INTELL, V32, P57, DOI 10.1016/0004-3702(87)90062-2
   Shapiro EY., 1983, ALGORITHMIC PROGRAM
   STRUSS P, 1989, P IJCAI 89 DETROIT, P1318
   STUMPTNER M, 1997, P 15 INT JOINT C ART
   Stumptner M., 1999, P 16 INT JOINT C ART
   STUMPTNER M, 1998, P 9 INT WORKSH PRINC
   WEISER M, 1984, IEEE T SOFTWARE ENG, V10, P352, DOI 10.1109/TSE.1984.5010248
   WOTAWA F, 1996, THESIS TU WIEN
NR 28
TC 18
Z9 18
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 0924-669X
J9 APPL INTELL
JI Appl. Intell.
PY 2001
VL 16
IS 1
BP 71
EP 92
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 494HU
UT WOS:000172277000005
DA 2023-11-10
ER

PT J
AU Zhu, ZY
   Li, Y
   Wang, Y
   Wang, YJ
   Tong, HH
AF Zhu, Ziye
   Li, Yun
   Wang, Yu
   Wang, Yaojing
   Tong, Hanghang
TI A deep multimodal model for bug localization
SO DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Article
DE Bug localization; Bug report; Multimodal learning; Attention mechanism;
   Multi-grained features
AB Bug localization utilizes the collected bug reports to locate the buggy source files. The state of the art falls short in handling the following three aspects, including (L1) the subtle difference between natural language and programming language, (L2) the noise in the bug reports and (L3) the multi-grained nature of programming language. To overcome these limitations, we propose a novel deep multimodal model named DeMoB for bug localization. It embraces three key features, each of which is tailored to address each of the three limitations. To be specific, the proposed DeMoB generates the multimodal coordinated representations for both bug reports and source files for addressing L1. It further incorporates the AttL encoder to process bug reports for addressing L2, and the MDCL encoder to process source files for addressing L3. Extensive experiments on four large-scale real-world data sets demonstrate that the proposed DeMoB significantly outperforms existing techniques.
C1 [Zhu, Ziye; Li, Yun; Wang, Yu] Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Big Data Secur & Intelligent Proc, Nanjing, Peoples R China.
   [Li, Yun; Wang, Yaojing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Tong, Hanghang] Univ Illinois, Dept Comp Sci, Urbana, IL USA.
C3 Nanjing University of Posts & Telecommunications; Nanjing University;
   University of Illinois System; University of Illinois Urbana-Champaign
RP Li, Y (通讯作者)，Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Big Data Secur & Intelligent Proc, Nanjing, Peoples R China.; Li, Y (通讯作者)，Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM 2016070251@njupt.edu.cn; liyun@njupt.edu.cn; 2017070114@njupt.edu.cn;
   wyj@smail.nju.edu.cn; htong@illinois.edu
OI Li, Yun/0000-0002-2079-9484; Wang, Yu/0000-0003-1606-6795
FU Natural Science Foundation of China [61772284]; State Key Lab
   [KFKT2020B21]; Postgraduate Research and Practice Innovation Program of
   Jiangsu Province [SJKY19_0763]; NSF [1947135, 2003924]
FX This researchwas supported by Natural Science Foundation of China (No.
   61772284), State Key Lab. for Novel Software Technology (KFKT2020B21),
   and Postgraduate Research and Practice Innovation Program of Jiangsu
   Province (SJKY19_0763). Hanghang Tong is partially supported by NSF
   (1947135 and 2003924).
CR Lam AN, 2017, INT C PROGRAM COMPRE, P218, DOI 10.1109/ICPC.2017.24
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], 2005, P 6 INT S AUTOMATED
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS, DOI DOI 10.48550/ARXIV.1409.0473
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bennin K. E., 2018, P 22 INT C EV ASS SO, P101
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   COSI P, 1994, INT CONF ACOUST SPEE, P553
   Debroy V, 2009, UTDCS459
   DeMillo RA, 1997, P INT COMP SOFTW APP, P515, DOI 10.1109/CMPSAC.1997.625061
   Fidler S, 2015, ARXIV PREPRINT ARXIV
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huo X., 2016, IJCAI, P1606
   Huo X, 2018, IEEE DATA MINING, P1049, DOI 10.1109/ICDM.2018.00133
   Huo X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1909
   Jiang Y, 2015, 2015 INTERNATIONAL SYMPOSIUM ON BIOELECTRONICS AND BIOINFORMATICS (ISBB), P1, DOI 10.1109/ISBB.2015.7344908
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim D, 2013, IEEE T SOFTWARE ENG, V39, P1597, DOI 10.1109/TSE.2013.24
   King DB, 2015, ACS SYM SER, V1214, P1
   Li W, 2012, SCI CHINA INFORM SCI, V55, P133, DOI 10.1007/s11432-011-4530-2
   Liu ZN, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2137, DOI 10.1145/3357384.3358155
   Lukins SK, 2008, WORK CONF REVERSE EN, P155, DOI 10.1109/WCRE.2008.33
   Marcus A, 2004, 11TH WORKING CONFERENCE ON REVERSE ENGINEERING, PROCEEDINGS, P214, DOI 10.1109/WCRE.2004.10
   Mihalcea R, 2006, LECT NOTES COMPUT SC, V3878, P319
   Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347
   Peters M.E., 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-1202
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.0055, 10.1109/ICDM.2016.178]
   Rahman MM, 2018, PROC IEEE ACM INT C, P348, DOI 10.1145/3183440.3195003
   Rajagopalan SS, 2016, LECT NOTES COMPUT SC, V9911, P338, DOI 10.1007/978-3-319-46478-7_21
   Saha RK, 2013, IEEE INT CONF AUTOM, P345, DOI 10.1109/ASE.2013.6693093
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi ZD, 2018, APPL SOFT COMPUT, V62, P636, DOI 10.1016/j.asoc.2017.10.048
   Silberer C, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P721
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sterling CD, 2007, SOFTWARE PRACT EXPER, V37, P1061, DOI 10.1002/spe.798
   Hoang T, 2019, IEEE T SOFTWARE ENG, V45, P1002, DOI 10.1109/TSE.2018.2810892
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Wang YJ, 2018, IEEE DATA MINING, P607, DOI 10.1109/ICDM.2018.00076
   Wong WE, 2006, J SYST SOFTWARE, V79, P891, DOI 10.1016/j.jss.2005.06.045
   Xiao Y, 2017, ASIA PAC SOFWR ENG, P338, DOI 10.1109/APSEC.2017.40
   Xu YB, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2565, DOI 10.1145/3219819.3220051
   Ye X, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P689, DOI 10.1145/2635868.2635874
   Zhang J, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5241-2
   Zhang YD, 2019, AAAI CONF ARTIF INTE, P5845
   Zhou J, 2012, PROC INT CONF SOFTW, P14, DOI 10.1109/ICSE.2012.6227210
NR 47
TC 10
Z9 11
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1384-5810
EI 1573-756X
J9 DATA MIN KNOWL DISC
JI Data Min. Knowl. Discov.
PD JUL
PY 2021
VL 35
IS 4
SI SI
BP 1369
EP 1392
DI 10.1007/s10618-021-00755-7
EA APR 2021
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SX2CO
UT WOS:000645169900001
DA 2023-11-10
ER

PT J
AU Rastgoo, R
   Kiani, K
   Escalera, S
AF Rastgoo, Razieh
   Kiani, Kourosh
   Escalera, Sergio
TI Hand sign language recognition using multi-view hand skeleton
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Multi-view hand skeleton; Hand sign language recognition; 3DCNN; Hand
   pose estimation; RGB video; Hand action recognition
ID 3D HAND; ACCURATE; NETWORK
AB Hand sign language recognition from video is a challenging research area in computer vision, which performance is affected by hand occlusion, fast hand movement, illumination changes, or background complexity, just to mention a few. In recent years, deep learning approaches have achieved state-of-the-art results in the field, though previous challenges are not completely solved. In this work, we propose a novel deep learning-based pipeline architecture for efficient automatic hand sign language recognition using Single Shot Detector (SSD), 2D Convolutional Neural Network (2DCNN), 3D Convolutional Neural Network (3DCNN), and Long Short-Term Memory (LSTM) from RGB input videos. We use a CNN-based model which estimates the 3D hand keypoints from 2D input frames. After that, we connect these estimated keypoints to build the hand skeleton by using midpoint algorithm. In order to obtain a more discriminative representation of hands, we project 3D hand skeleton into three views surface images. We further employ the heatmap image of detected keypoints as input for refinement in a stacked fashion. We apply 3DCNNs on the stacked features of hand, including pixel level, multi-view hand skeleton, and heatmap features, to extract discriminant local spatio-temporal features from these stacked inputs. The outputs of the 3DCNNs are fused and fed to a LSTM to model long-term dynamics of hand sign gestures. Analyzing 2DCNN vs. 3DCNN using different number of stacked inputs into the network, we demonstrate that 3DCNN better capture spatio-temporal dynamics of hands. To the best of our knowledge, this is the first time that this multi-modal and multi-view set of hand skeleton features are applied for hand sign language recognition. Furthermore, we present a new large-scale hand sign language dataset, namely RKS-PERSIANSIGN, including 10'0 00 RGB videos of 100 Persian sign words. Evaluation results of the proposed model on three datasets, NYU, First-Person, and RKS-PERSIANSIGN, indicate that our model outperforms state-of-the-art models in hand sign language recognition, hand pose estimation, and hand action recognition. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Rastgoo, Razieh; Kiani, Kourosh] Semnan Univ, Elect & Comp Engn Dept, Semnan 3513119111, Iran.
   [Escalera, Sergio] Univ Barcelona, Dept Math & Informat, Barcelona, Spain.
   [Escalera, Sergio] Comp Vis Ctr, Barcelona, Spain.
C3 Semnan University; University of Barcelona; Centre de Visio per
   Computador (CVC)
RP Kiani, K (通讯作者)，Semnan Univ, Elect & Comp Engn Dept, Semnan 3513119111, Iran.
EM rrastgoo@semnan.ac.ir; kourosh.kiani@semnan.ac.ir; sergio@maia.ub.es
RI Kiani, Kourosh/T-7468-2019; Escalera, Sergio/L-2998-2015
OI Kiani, Kourosh/0000-0001-6582-8691; Escalera,
   Sergio/0000-0003-0617-8873; Rastgoo, Razieh/0000-0001-7963-9461
FU Spanish project (MINECO/FEDER,UE) [TIN2016-74946-P]; CERCA
   Programme/Generalitat de Catalunya; ICREA under the ICREA Academia
   programme; High Intelligent Solution (HIS) company in Iran
FX This work is partially supported by the Spanish project TIN2016-74946-P
   (MINECO/FEDER,UE), CERCA Programme/Generalitat de Catalunya, ICREA under
   the ICREA Academia programme, and High Intelligent Solution (HIS)
   company in Iran. We gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the Titan XP GPU used for this
   research. Also, we would like to thank two deaf centers of Iran (Semnan
   and Tehran) and the Computer Vision Center (CVC) of Spain for their
   collaborations.
CR [Anonymous], TEXAS MATH SIGN LANG
   [Anonymous], AM SIGN LANGUAGE
   [Anonymous], AM SIGN LANGUAGE
   [Anonymous], REGION ENSEMBLE NETW
   [Anonymous], SIGNING SAVVY
   [Anonymous], OPENPOSE REALTIME MU
   [Anonymous], 2019, CONSTRUCT DYNAMIC GR
   [Anonymous], LEARNING ESTIMATE 3D
   [Anonymous], THESIS
   [Anonymous], HGR NET FUSION NETWO
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Chengde Wan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5147, DOI 10.1109/CVPR.2018.00540
   Devineau G, 2018, IEEE INT CONF AUTOMA, P106, DOI 10.1109/FG.2018.00025
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Ferreira PM, 2019, MULTIMED TOOLS APPL, V78, P10035, DOI 10.1007/s11042-018-6565-5
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Gomez-Donoso F, 2019, EXPERT SYST APPL, V136, P327, DOI 10.1016/j.eswa.2019.06.055
   Goodwyn SW, 2000, J NONVERBAL BEHAV, V24, P81, DOI 10.1023/A:1006653828895
   Hirafuji Neiva Davi, 2018, Expert Systems with Applications, V103, P159, DOI 10.1016/j.eswa.2018.01.051
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Köpüklü O, 2019, IEEE INT CONF AUTOMA, P407
   Köpüklü O, 2018, IEEE COMPUT SOC CONF, P2184, DOI 10.1109/CVPRW.2018.00284
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Lim KM, 2016, EXPERT SYST APPL, V54, P208, DOI 10.1016/j.eswa.2016.01.047
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Yousaf Kanwal, 2018, Wireless Communications and Mobile Computing, V2018, DOI 10.1155/2018/1013234
   Zimmerman T. G., 1987, SIGCHI Bulletin, P189, DOI 10.1145/1165387.275628
NR 30
TC 54
Z9 55
U1 7
U2 87
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JUL 15
PY 2020
VL 150
AR 113336
DI 10.1016/j.eswa.2020.113336
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA LG6FG
UT WOS:000528193700017
DA 2023-11-10
ER

PT J
AU Jiang, JJ
   Liu, ZY
   Zheng, NN
AF Jiang, Jingjing
   Liu, Ziyi
   Zheng, Nanning
TI Correlation Information Bottleneck: Towards Adapting Pretrained
   Multimodal Models for Robust Visual Question Answering
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article
DE Information bottleneck; Robustness; Visual question answering;
   Vision-language model
ID LANGUAGE
AB Benefiting from large-scale pretrained vision language models (VLMs), the performance of visual question answering (VQA) has approached human oracles. However, finetuning such models on limited data often suffers from overfitting and poor generalization issues, leading to a lack of model robustness. In this paper, we aim to improve input robustness from an information bottleneck perspective when adapting pretrained VLMs to the downstream VQA task. Input robustness refers to the ability of models to defend against visual and linguistic input variations, as well as shortcut learning involved in inputs. Generally, the representations obtained by pretrained VLMs inevitably contain irrelevant and redundant information for a specific downstream task, resulting in statistically spurious correlations and insensitivity to input variations. To encourage representations to converge to a minimal sufficient statistic in multimodal learning, we propose Correlation Information Bottleneck (CIB), which seeks a tradeoff between compression and redundancy in representations by minimizing the mutual information (MI) between inputs and representations while maximizing the MI between outputs and representations. Moreover, we derive a tight theoretical upper bound for the mutual information between multimodal inputs and representations, incorporating different internal correlations that guide models to learn more robust representations and facilitate modality alignment. Extensive experiments consistently demonstrate the effectiveness and superiority of the proposed CIB in terms of input robustness and accuracy.
C1 [Jiang, Jingjing; Liu, Ziyi; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Zheng, NN (通讯作者)，Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM jingjingjiang2017@gmail.com; liuziyi@stu.xjtu.edu.cn;
   nnzheng@mail.xjtu.edu.cn
OI Jiang, jingjing/0000-0002-8241-4877
FU This work was supported by the National Science Foundation of China
   (Grant No. 62088102).; National Science Foundation of China;  [62088102]
FX This work was supported by the National Science Foundation of China
   (Grant No. 62088102).
CR Agarwal Vedika, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9687, DOI 10.1109/CVPR42600.2020.00971
   Agrawal A, 2022, Arxiv, DOI arXiv:2205.12191
   Ahuja K., 2021, ADV NEURAL INF PROCE, V34, P3438
   Alayrac J.-B., 2022, ADV NEURAL INFORM PR, V5, P23716
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ban Y., 2022, NEURAL INFORM PROCES, P1196
   Bao F., 2021, INT C ARTIFICIAL INT, P91
   Bao HB, 2022, Arxiv, DOI arXiv:2111.02358
   Barber D, 2004, ADV NEUR IN, V16, P201
   Belghazi MI, 2018, PR MACH LEARN RES, V80
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, P8102
   Bennasar M, 2015, EXPERT SYST APPL, V42, P8520, DOI 10.1016/j.eswa.2015.07.007
   Cadene Remi, 2019, ADV NEUR IN, P841
   Changpinyo S, 2021, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR46437.2021.00356
   Chen Long, 2020, P IEEE CVF C COMP VI, P10797
   Chen XL, 2015, Arxiv, DOI arXiv:1504.00325
   Cheng PY, 2020, PR MACH LEARN RES, V119
   Cho J, 2021, PR MACH LEARN RES, V139
   Clark C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4069
   Dancette C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1554, DOI 10.1109/ICCV48922.2021.00160
   Dong X., 2021, ADV NEURAL INFORM PR, V34, P4356
   Dou Z.Y., 2022, P IEEECVF C COMPUTER, P18166
   Dubois Yann, 2020, ADV NEURAL INFORM PR, V33, P18674
   Federici M., 2020, INT C LEARNING REPRE
   Gan Zhe, 2020, NEURIPS, V2
   Gat Itai, 2020, ADV NEURAL INF PROCE, P3197
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   Hu R., 2020, P IEEE CVF C COMP VI, P9992, DOI DOI 10.1109/CVPR42600.2020.01001
   Hu RH, 2018, LECT NOTES COMPUT SC, V11211, P55, DOI 10.1007/978-3-030-01234-2_4
   Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849
   Huang ZC, 2021, PROC CVPR IEEE, P12971, DOI 10.1109/CVPR46437.2021.01278
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Jeon I, 2021, AAAI CONF ARTIF INTE, V35, P7926
   Jiang Y, 2018, Arxiv, DOI arXiv:1807.09956
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Jingjing Jiang, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P199, DOI 10.1145/3474085.3475350
   Kant Y., 2021, P IEEECVF INT C COMP, P1604
   Kazemi V., 2017, SHOW ASK ATTEND ANSW
   Kervadec C, 2021, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR46437.2021.00280
   Kim JH, 2018, ADV NEUR IN, V31
   Kim W, 2021, PR MACH LEARN RES, V139
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li B, 2022, AAAI CONF ARTIF INTE, P7399
   Li C., 2022, C EMPIRICAL METHODS, P7241
   Li CL, 2021, Arxiv, DOI arXiv:2103.07829
   Li J., 2022, INT C MACHINE LEARNI, P12888
   Li Junnan, 2021, ADV NEURAL INF PROCE, P9694, DOI DOI 10.48550/ARXIV.2107.07651
   Li L., 2021, IEEE C COMP VIS PATT, P2042
   Li Linjie, 2020, ARXIV
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Li YA, 2021, AAAI CONF ARTIF INTE, V35, P8518
   Liu XJ, 2019, IEEE I CONF COMP VIS, P2611, DOI 10.1109/ICCV.2019.00270
   Lu J., 2015, DEEPER ISTM NORMALIZ
   Lu JS, 2019, ADV NEUR IN, V32
   Mahabadi R. K., 2021, INT C LEARN REPR
   Nam Junhyun, 2020, ADV NEURAL INFORM PR, V33, P1
   Nguyen XL, 2010, IEEE T INFORM THEORY, V56, P5847, DOI 10.1109/TIT.2010.2068870
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Pan YH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3487042
   Pan ZQ, 2021, AAAI CONF ARTIF INTE, V35, P9285
   Poole B, 2019, PR MACH LEARN RES, V97
   Shah M, 2019, PROC CVPR IEEE, P6642, DOI 10.1109/CVPR.2019.00681
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Sheng S., 2021, P ADV NEUR INF PROC, V34, P20346
   Shi JX, 2019, PROC CVPR IEEE, P8368, DOI 10.1109/CVPR.2019.00857
   Shi L, 2020, Arxiv, DOI arXiv:2007.13135
   Shrestha R., 2020, NEGATIVE CASE ANAL V, P8172
   Shwartz-Ziv R, 2017, Arxiv, DOI arXiv:1703.00810
   Su Weijie, 2020, INT C LEARNING REPRE
   Sun SQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P982
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Teney Damien, 2020, ARXIV200409034, P407
   Tishby N., 2000, ARXIV, DOI DOI 10.48550/ARXIV.PHYSICS/0004057
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW)
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang B., 2021, INT C LEARNING REPRE
   Wang HQ, 2022, PROC CVPR IEEE, P16020, DOI 10.1109/CVPR52688.2022.01557
   Wang Peng, 2022, INT C MACHINE LEARNI, P23318
   Wang Wenhui, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P19175, DOI 10.1109/CVPR52729.2023.01838
   Wang Z., 2022, INT C LEARNING REPRE
   Whitehead S, 2020, Arxiv, DOI arXiv:2011.13406
   Xu HY, 2023, Arxiv, DOI arXiv:2302.00402
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yingjun Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P200, DOI 10.1007/978-3-030-58607-2_12
   Yu F, 2021, AAAI CONF ARTIF INTE, V35, P3208
   Yu JH, 2022, Arxiv, DOI [arXiv:2205.01917, DOI 10.48550/ARXIV.2205.01917]
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Yuan L., 2021, ARXIV
   Zeng Y., 2022, ICML, P25994
   Zeng Y, 2023, Arxiv, DOI arXiv:2211.12402
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang Z., 2020, ADV NEUR IN, P18123
   Zhong Yiwu, 2022, P IEEECVF C COMPUTER, P16793
   Zhou Daquan, 2022, P 39 INT C MACHINE L, P27378
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 100
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD AUG 28
PY 2023
AR 1858
DI 10.1007/s11263-023-01858-y
PG 23
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q3WR9
UT WOS:001056861100002
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Xu, JJ
AF Xu, Jingjing
TI A natural language processing based technique for sentiment analysis of
   college english corpus
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Natural language; English corpus; Cluster analysis; TF-IDF
ID NETWORKS
AB The college English corpus can help us better master English, but how to obtain the desired information from a large number of English corpus has become the focus of information technology. Based on the natural language processing (NLP) technology, a sentiment analysis model is built in this article. An improved term frequency-inverse document frequency (TF-IDF) algorithm is proposed in this article, where the weighted average method is used to determine the emotional value of each emotional word. The inspirational words are used to obtain the English corpus's emotional tendency and emotional value. The results show that the model has high classification accuracy and operation efficiency when selecting feature words. Compared with the TF-IDF, the improved TF-IDF algorithm added the necessary information weight processing and word density weight processing to two new processing links, which can significantly improve the efficiency of college English learning.
C1 [Xu, Jingjing] Anhui Univ Chinese Med, Sch Humanities & Int Educ & Exchange, Hefei, Peoples R China.
C3 Anhui University of Chinese Medicine
RP Xu, JJ (通讯作者)，Anhui Univ Chinese Med, Sch Humanities & Int Educ & Exchange, Hefei, Peoples R China.
EM jingjingxu@ahtcm.edu.cn
RI Xu, Jingjing/ACJ-3010-2022
OI Xu, Jingjing/0000-0002-0443-547X
CR Abe H, 2010, IEEE INT C DATA MINI, P1743
   Fang Q, 2018, TEXT DETECTION RECOG
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gui Z, 2018, RES TEXT DETECTION R
   Hasan Sadid A., 2019, DATA SCI HEALTHCARE, P147, DOI DOI 10.1007/978-3-030-05249-2_5
   Hu ZT, 2020, Arxiv, DOI arXiv:1603.06318
   Li B, 2018, COMPUTER SCI, V35, P132
   Liu Y, 2014, J COMMUNICATIONS, V7, P78
   Luo BF, 2018, Arxiv, DOI arXiv:1805.05588
   Mikolov T, 2017, Arxiv, DOI [arXiv:1712.09405, 10.48550/arXiv.1712.09405, DOI 10.48550/ARXIV.1712.09405]
   Peng GF, 2019, CONF TECHNOL APPL, DOI 10.1109/taai48200.2019.8959907
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sun X, 2019, RES MULTIDIRECTION T
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   [奚雪峰 Xi Xuefeng], 2016, [自动化学报, Acta Automatica Sinica], V42, P1445
   Xu K, 2020, ELECT DESIGN ENG, V28, P82
   Yang H, 2019, TEXT RECOGNITION NAT
   Yin Bao-cai, 2015, Journal of Beijing University of Technology, V41, P48, DOI 10.11936/bjutxb2014100026
   Zhou P, 2019, RES TEXT DETECTION R
NR 19
TC 0
Z9 0
U1 9
U2 9
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD FEB 17
PY 2023
VL 9
AR e1235
DI 10.7717/peerj-cs.1235
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H2NR9
UT WOS:000994390500002
PM 37346685
OA gold, Green Published
DA 2023-11-10
ER

PT J
AU Ross, BJ
AF Ross, BJ
TI The evolution of concurrent programs
SO APPLIED INTELLIGENCE
LA English
DT Article
DE genetic programming; process algebra; CCS; concurrency
ID SEMANTICS
AB Process algebra are formal languages used for the rigorous specification and analysis of concurrent systems. By using a process algebra as the target language of a genetic programming system, the derivation of concurrent programs satisfying given problem specifications is possible. A genetic programming system based on Koza's model has been implemented. The target language used is Milner's CCS process algebra, and is chosen for its conciseness and simplicity. The genetic programming environment needs a few adaptations to the computational characteristics of concurrent programs. In particular, means for efficiently controlling the exponentially large computation spaces that are common with process algebra must be addressed. Experimental runs of the system successfully evolved a number of non-iterative CCS systems, hence proving the potential of evolutionary approaches to concurrent system development.
C1 Brock Univ, Dept Comp Sci, St Catharines, ON L2S 3A1, Canada.
C3 Brock University
RP Ross, BJ (通讯作者)，Brock Univ, Dept Comp Sci, St Catharines, ON L2S 3A1, Canada.
CR AALBERSBERG IJ, 1988, THEOR COMPUT SCI, V60, P1, DOI 10.1016/0304-3975(88)90051-5
   [Anonymous], 1988, ALGEBRAIC THEORY PRO
   [Anonymous], 1994, ADV GENETIC PROGRAMM
   [Anonymous], 1977, COMPUTING SURVEYS
   [Anonymous], 1993, GENETIC PROGRAMMING
   BRUCE WS, 1995, THESIS NOVA SE U
   HEHNER ECR, 1988, ACTA INFORM, V25, P1, DOI 10.1007/BF00268842
   Maxwell S. R.  III, 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P413, DOI 10.1109/ICEC.1994.349915
   Milner R., 1989, Communication and concurrency
   OLDEROG ER, 1986, ACTA INFORM, V23, P9, DOI 10.1007/BF00268075
   ROSS BJ, 1994, P 11 EUR C ART INT A
   ROSS BJ, PRACTICAL HDB GENETI, V3
   ROSS BJ, 1995, 1995 IJCAI WORKSH MU, P96
   WONG ML, 1995, P 4 C IT ASS AI, P353
NR 14
TC 3
Z9 3
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 0924-669X
J9 APPL INTELL
JI Appl. Intell.
PD JAN
PY 1998
VL 8
IS 1
BP 21
EP 32
DI 10.1023/A:1008264413708
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZF113
UT WOS:000072863900003
DA 2023-11-10
ER

PT J
AU Gong, T
   Shuai, L
AF Gong, Tao
   Shuai, Lan
TI Exploring the Effect of Power Law Social Popularity on Language
   Evolution
SO ARTIFICIAL LIFE
LA English
DT Article
DE Social scaling; mutual understanding; self-organization; computer
   simulation
ID SCALE-INVARIANCE; NONEQUILIBRIUM; SIMULATION; EMERGENCE; DYNAMICS
AB We evaluate the effect of a power-law-distributed social popularity on the origin and change of language, based on three artificial life models meticulously tracing the evolution of linguistic conventions including lexical items, categories, and simple syntax. A cross-model analysis reveals an optimal social popularity, in which the X value of the power law distribution is around 1.0. Under this scaling, linguistic conventions can efficiently emerge and widely diffuse among individuals, thus maintaining a useful level of mutual understandability even in a big population. From an evolutionary perspective, we regard this social optimality as a tradeoff among social scaling, mutual understandability, and population growth. Empirical evidence confirms that such optimal power laws exist in many large-scale social systems that are constructed primarily via language-related interactions. This study contributes to the empirical explorations and theoretical discussions of the evolutionary relations between ubiquitous power laws in social systems and relevant individual behaviors.
C1 [Gong, Tao] Univ Hong Kong, Dept Linguist, Hong Kong, Hong Kong, Peoples R China.
   [Shuai, Lan] Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA.
C3 University of Hong Kong; Johns Hopkins University
RP Gong, T (通讯作者)，Univ Hong Kong, Dept Linguist, Hong Kong, Hong Kong, Peoples R China.
EM gtojty@gmail.com; susan.shuai@gmail.com
RI Tao, Gong/H-9685-2014
FU University of Hong Kong
FX This work was funded by the Seed Fund for Basic Research of the
   University of Hong Kong. The preliminary results of this article were
   reported in the 8th International Conference on the Evolution of
   Language (Evolang8) in Utrecht, the Netherlands. We thank Yicheng Wu
   from Zhejiang University for Valuable comments on this work.
CR Aiello W, 2002, MASSIVE COMP, V4, P97
   Albert R, 1999, NATURE, V401, P130, DOI 10.1038/43601
   [Anonymous], 1997, SCALE INVARIANCE
   [Anonymous], J ARTIFICIAL SOC SOC
   [Anonymous], 2000, ETHNOLOGUE LANGUAGES
   [Anonymous], 2009, COMPUTATIONAL SIMULA
   [Anonymous], EVOLUTIONARY EMERGEN, DOI DOI 10.1017/CBO9780511606441.019
   Bak P., 2013, NATURE WORKS SCI SEL
   Ball P., 2001, SELF MADE TAPESTY PA
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Baronchelli A, 2006, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2006/06/P06014
   Beckner C, 2009, LANG LEARN, V59, P1
   Camazine S., 2001, SELF ORG BIOL SYSTEM
   Cangelosi A, 2002, SIMULATING THE EVOLUTION OF LANGUAGE, P3
   Clauset A, 2009, SIAM REV, V51, P661, DOI 10.1137/070710111
   Coelho R, 2005, PHYSICA A, V353, P515, DOI 10.1016/j.physa.2005.01.037
   Dall'Asta L, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036105
   de Boer B, 2010, ADAPT BEHAV, V18, P141, DOI 10.1177/1059712309345789
   Ebel H, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.035103
   Fitch Tecumseh W., 2010, EVOLUTION LANGUAGE
   Gell-Mann M., 1994, QUARK JAGUAR ADVENTU
   Gisiger T, 2001, BIOL REV, V76, P161, DOI 10.1017/S1464793101005607
   Gong T, 2013, LANG SCI, V40, P12, DOI 10.1016/j.langsci.2013.04.002
   Gong T, 2012, ARTIF LIFE, V18, P107, DOI 10.1162/artl_a_00051
   Gong T, 2011, INTERACT STUD, V12, P63, DOI 10.1075/is.12.1.03gon
   Gong T, 2010, ADAPT BEHAV, V18, P356, DOI 10.1177/1059712310377241
   Holland J. H, 2012, SIGNALS BOUNDARIES B
   Jeong H, 2000, NATURE, V407, P651, DOI 10.1038/35036627
   Kalampokis A, 2007, PHYSICA A, V379, P665, DOI 10.1016/j.physa.2006.12.048
   Ke J, 2008, COMMUN COMPUT PHYS, V3, P935
   Kello CT, 2010, TRENDS COGN SCI, V14, P223, DOI 10.1016/j.tics.2010.02.005
   Livingstone D, 2002, SIMULATING THE EVOLUTION OF LANGUAGE, P99
   MANDELBROT B, 1967, SCIENCE, V156, P636, DOI 10.1126/science.156.3775.636
   Maylor EA, 2001, PSYCHON B REV, V8, P162, DOI 10.3758/BF03196153
   Nettle D., 1999, LINGUISTIC DIVERSITY
   Newman MEJ, 2005, CONTEMP PHYS, V46, P323, DOI 10.1080/00107510500052444
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Puglisi A, 2008, P NATL ACAD SCI USA, V105, P7936, DOI 10.1073/pnas.0802485105
   Ripeanu M, 2002, IEEE INTERNET COMPUT, V6, P50, DOI 10.1109/4236.978369
   Sims DW, 2008, NATURE, V451, P1098, DOI 10.1038/nature06518
   Spence AJ, 2009, CURR BIOL, V19, pR57, DOI 10.1016/j.cub.2008.10.042
   Stauffer D, 2006, PHYSICA A, V371, P719, DOI 10.1016/j.physa.2006.03.045
   Vogt P, 2010, ADAPT BEHAV, V18, P21, DOI 10.1177/1059712309350970
   Warren CP, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.056105
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wichmann S, 2005, J LINGUIST, V41, P117, DOI 10.1017/S002222670400307X
   Xiao Fan Wang, 2003, IEEE Circuits and Systems Magazine, V3, P6, DOI 10.1109/MCAS.2003.1228503
   Zipf G.K., 1949, HUMAN BEHAVIOUR PRIN
NR 48
TC 2
Z9 2
U1 1
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 1064-5462
EI 1530-9185
J9 ARTIF LIFE
JI Artif. Life
PD SUM
PY 2014
VL 20
IS 3
BP 385
EP 408
DI 10.1162/ARTL_a_00138
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA AL0FP
UT WOS:000338803100005
PM 24730762
DA 2023-11-10
ER

PT J
AU Mairesse, F
   Young, S
AF Mairesse, Francois
   Young, Steve
TI Stochastic Language Generation in Dialogue Using Factored Language
   Models
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID STATE
AB Most previous work on trainable language generation has focused on two paradigms: (a) using a statistical model to rank a set of pre-generated utterances, or (b) using statistics to determine the generation decisions of an existing generator. Both approaches rely on the existence of a handcrafted generation component, which is likely to limit their scalability to new domains. The first contribution of this article is to present BAGEL, a fully data-driven generation method that treats the language generation task as a search for the most likely sequence of semantic concepts and realization phrases, according to Factored Language Models (FLMs). As domain utterances are not readily available for most natural language generation tasks, a large creative effort is required to produce the data necessary to represent human linguistic variation for nontrivial domains. This article is based on the assumption that learning to produce paraphrases can be facilitated by collecting data from a large sample of untrained annotators using crowdsourcing-rather than a few domain experts-by relying on a coarse meaning representation. A second contribution of this article is to use crowdsourced data to show how dialogue naturalness can be improved by learning to vary the output utterances generated for a given semantic input. Two data-driven methods for generating paraphrases in dialogue are presented: (a) by sampling from the n-best list of realizations produced by BAGEL's FLM reranker; and (b) by learning a structured perceptron predicting whether candidate realizations are valid paraphrases. We train BAGEL on a set of 1,956 utterances produced by 137 annotators, which covers 10 types of dialogue acts and 128 semantic concepts in a tourist information system for Cambridge. An automated evaluation shows that BAGEL outperforms utterance class LM baselines on this domain. A human evaluation of 600 resynthesized dialogue extracts shows that BAGEL's FLM output produces utterances comparable to a handcrafted baseline, whereas the perceptron classifier performs worse. Interestingly, human judges find the system sampling fromthe n-best list to be more natural than a system always returning the first-best utterance. The judges are also more willing to interact with the n-best system in the future. These results suggest that capturing the variation found in human language using data-driven methods is beneficial for dialogue interaction.
C1 [Mairesse, Francois] Univ Cambridge, Cambridge CB2 1TN, England.
   [Young, Steve] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
C3 University of Cambridge; University of Cambridge
RP Mairesse, F (通讯作者)，Amazon Com, 101 Main St,Suite 900, Cambridge, MA 02142 USA.
EM francois.mairesse@gmail.com; sjy@eng.cam.ac.uk
FU EU [216594]
FX This research was partly funded by the EU FP7 Programme under grant
   agreement 216594 (CLASSiC project: www.classic-project.org).
CR Angeli G., 2010, P 2010 C EMPIRICAL M, P502
   [Anonymous], 2008, P ACL 08 HLT
   [Anonymous], 2005, M ASS COMP LING, DOI [10.3115/1219840.1219914, DOI 10.3115/1219840.1219914]
   [Anonymous], 2008, P ANN M ASS COMPUTAT
   [Anonymous], 2005, P 9 INTERNATIONALWOR
   [Anonymous], 2004, PROC 21 INT C MACHIN, DOI DOI 10.1145/1015330.1015341
   Bangalore Srinivas, 2000, P 18 INT C COMP LING, P42
   Barzilay R, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P50
   Belz Anja, 2008, Natural Language Engineering, V14, P431, DOI 10.1017/S1351324907004664
   Bilmes J. A., 2003, P C N AM CHAPT ASS C, P4, DOI DOI 10.3115/1073483.1073485
   Bulyko I, 2002, COMPUT SPEECH LANG, V16, P533, DOI 10.1016/S0885-2308(02)00023-2
   CAHILL A, 2006, P 21 INT C COMP LING, P1033
   Chambers Nathanael, 2004, P SIGDIAL CAMBR MASS, P9
   Collins M, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P489
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Collins M., 2004, P 42 ANN M ASS COMPU, P111
   Dekang Lin, 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P323
   FOSTER ME, 2005, P IJCAI 2005 WORKSH, P24
   He Y, 2005, COMPUT SPEECH LANG, V19, P85, DOI 10.1016/j.csl.2004.03.001
   Isard Amy, 2006, P 4 INT NAT LANG GEN, P22
   Kondadadi R., 2013, LONG PAPERS, V1, P1406
   Konstas I, 2012, P 50 ANN M ASS COMP, P369
   Langkilde I., 1998, P 36 ANN M ASS COMP, P704, DOI DOI 10.3115/980845.980963
   Langkilde-Geary Irene, 2002, P INT C NAT LANG GEN, P17
   Lavoie Benoit, 1997, P 5 C APPL NAT LANG, P265
   Lefevre F, 2006, IEEE W SP LANG TECH, P78, DOI 10.1109/SLT.2006.326821
   Lu Wei, 2009, P 2009 C EMP METH NA, P400
   Mairesse F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1552
   Mairesse F, 2011, COMPUT LINGUIST, V37, P455, DOI 10.1162/COLI_a_00063
   Mann W. C., 1988, TEXT, V8, P243
   Nakatsu C, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P1113
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Oh AH, 2002, COMPUT SPEECH LANG, V16, P387, DOI 10.1016/S0885-2308(02)00012-8
   Paiva D.S., 2005, P 43 ANN M ASS COMPU, P58, DOI 10.3115/1219840.1219848
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pon-Barry H., 2006, INT J ARTIF INTELL E, V16, P171
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ratnaparkhi A, 2002, COMPUT SPEECH LANG, V16, P435, DOI 10.1016/S0885-2308(02)00025-6
   Reiter E, 2009, COMPUT LINGUIST, V35, P529, DOI 10.1162/coli.2009.35.4.35405
   Rieser V, 2010, LECT NOTES ARTIF INT, V5790, P105, DOI 10.1007/978-3-642-15573-4_6
   Schatzmann J., 2007, HUMAN LANGUAGE TECHN, P149
   STENT A, 2004, P 42 ANN M ASS COMP, P79, DOI DOI 10.3115/1218955.1218966
   Stent Amanda, 2009, P SIGDIAL 2009 C, P290
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Thomson B., 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), P460, DOI 10.1109/SLT.2010.5700896
   Thomson B, 2010, COMPUT SPEECH LANG, V24, P562, DOI 10.1016/j.csl.2009.07.003
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820
   Torrance Nancy, 1992, P ANN M AM ED RES AS, P1
   Varges S, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P1, DOI 10.3115/1073336.1073337
   Walker MA, 2002, COMPUT SPEECH LANG, V16, P409, DOI 10.1016/S0885-2308(02)00027-X
   White Michael, 2007, P WORKSH US CORP NLG, P22
   Wong Y. W., 2007, P HUM LANG TECHN C N, P172
   Young S, 2010, COMPUT SPEECH LANG, V24, P150, DOI 10.1016/j.csl.2009.04.001
NR 53
TC 23
Z9 26
U1 1
U2 16
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD DEC
PY 2014
VL 40
IS 4
BP 763
EP 799
DI 10.1162/COLI_a_00199
PG 37
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA AT7YI
UT WOS:000345150100003
OA Green Published, hybrid
DA 2023-11-10
ER

PT J
AU Chou, CL
   Chang, CH
   Lin, YH
   Chien, KC
AF Chou, Chien-Lung
   Chang, Chia-Hui
   Lin, Yuan-Hao
   Chien, Kuo-Chun
TI On the Construction of Web NER Model Training Tool based on Distant
   Supervision
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Information extraction; named entity recognition; distant supervision;
   locality-sensitive hashing (LSH); scalable automatic labeling
AB Named entity recognition (NER) is an important task in natural language understanding, as it extracts the key entities (person, organization, location, date, number, etc.) and objects (product, song, movie, activity name, etc.) mentioned in texts. However, existing natural language processing (NLP) tools (such as Stanford NER) recognize only general named entities or require annotated training examples and feature engineering for supervised model construction. Since not all languages or entities have public NER support, constructing a tool for NER model training is essential for low-resource language or entity information extraction. In this article, we study the problem of developing a tool to prepare training corpus from the Web with known seed entities for custom NER model training via distant supervision. The major challenge of automatic labeling lies in the long labeling time due to large corpus and seed entities as well as the concern to avoid false positive and false negative examples due to short and long seeds. To solve this problem, we adopt locality-sensitive hashing (LSH) for various length of seed entities. We conduct experiments on five types of entity recognition tasks, including Chinese person names, food names, locations, points of interest (POIs), and activity names to demonstrate the improvements with the proposed Web NER model construction tool. Because the training corpus is obtained by automatic labeling of the seed entity-related sentences, one could use either the entire corpus or the positive only sentences for model training. Based on the experimental results, we found the decision should depend on whether traditional linear chained conditional random fields (CRF) or deep neural network-based CRF is used for model training as well as the completeness of the provided seed list.
C1 [Chou, Chien-Lung; Chang, Chia-Hui; Lin, Yuan-Hao; Chien, Kuo-Chun] Natl Cent Univ, 300 Zhongda Rd, Taoyuan, Taiwan.
C3 National Central University
RP Chou, CL (通讯作者)，Natl Cent Univ, 300 Zhongda Rd, Taoyuan, Taiwan.
EM formatc.chou@gmail.com; chia@csie.ncu.edu.tw; luff543@gmail.com;
   qk0614@gmail.com
RI Chang, Chia-Hui/C-1049-2009
OI Chang, Chia-Hui/0000-0002-1101-6337
FU Ministry of Science and Technology, Taiwan [107-2221-E-008-085-MY2]
FX This work is sponsored by Ministry of Science and Technology, Taiwan,
   under grant 107-2221-E-008-085-MY2.
CR An Joohui, 2003, P 41 ANN M ASS COMP, V2, P165, DOI [10.3115/1075178.1075207, DOI 10.3115/1075178.1075207]]
   [Anonymous], 2008, ADV NEURAL INFORM PR
   [Anonymous], 2014, THESIS
   [Anonymous], 2010, P 14 C COMPUTATIONAL
   Apache Lucene, 1999, AP LUC TEXT AN
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616.1376746.URLhttps]
   Brinza D, 2010, BIOINFORMATICS, V26, P2856, DOI 10.1093/bioinformatics/btq529
   Burger J, 2003, DOCUMENT UNDERSTANDI
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Chiang Chia-Feng, 2017, P TECHN APPL ART INT
   Chien Kuo-Chun, 2019, INT J COMPUT LING CH, V24, P1
   Chou CL, 2016, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/2963100
   Chuang HM, 2016, INT J GEOGR INF SCI, V30, P1405, DOI 10.1080/13658816.2015.1133820
   Chuang HM, 2014, LECT NOTES BUS INF P, V188, P13
   Chung Chih-Yu, 2017, P 29 C COMP LING SPE, P183
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cunningham H, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P168
   DAS Abhinandan, 2007, P 16 INT C WORLD WID, V16, P271, DOI DOI 10.1145/1242572.1242610
   Finkel Jenny Rose, 2005, P 43 ANN M ASS COMP, P363, DOI [10.3115/1219840.1219885, DOI 10.3115/1219840.1219885]
   Hsu Kuo-Hsin, 2017, ROCLING, P53
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Huang Z., 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jia YH, 2018, MULTIMED TOOLS APPL, V77, P29435, DOI 10.1007/s11042-018-5692-3
   Koga H, 2007, KNOWL INF SYST, V12, P25, DOI 10.1007/s10115-006-0027-5
   Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lample G, 2016, P NAACL HLT, DOI DOI 10.18653/V1/N16-1030
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li CL, 2015, IEEE T KNOWL DATA EN, V27, P558, DOI 10.1109/TKDE.2014.2327042
   LIN J, 2002, P 3 INT C LANG RES E
   Lin Yuan-Hao, 2016, P 28 C COMP LING RES
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI DOI 10.1353/LAN.2019.0015
   Liu F., 2017, P INT JOINT C NAT LA, P555
   Luo BF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P430, DOI 10.18653/v1/P17-1040
   Manku Gurmeet Singh, 2007, P 16 INT C WORLD WID, P141
   Mau TN, 2018, J INFORM TELECOMMUN, V2, P265, DOI 10.1080/24751839.2018.1423790
   Mccallum A., 2003, P 7 C NATURAL LANGUA, P188, DOI [10.3115/1119176.1119206, 10.3115/1119176, DOI 10.3115/1119176, DOI 10.3115/1119176.1119206]
   Michelson M, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2076
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mintz M., 2009, P JOINT C 47 ANN M A, V2, P1003, DOI DOI 10.3115/1690219.1690287
   Toan NM, 2016, INT CONF KNOWL SYS, P49, DOI 10.1109/KSE.2016.7758028
   Pawar Sachin, 2017, CORR
   Qiu Xipeng, 2013, P ANN M ASS COMP LIN
   Rae A, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P711, DOI 10.1145/2348283.2348379
   Rajaraman Anand, 2011, MINING MASSIVE DATAS, P3
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   SARAWAGI S, 2007, FOUND TRENDS DATABAS, V1, P261, DOI DOI 10.1561/1900000003
   Silfverberg M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P259
   Snow R., 2004, ADV NEURAL INFORM PR, P1297
   SUTTON C, 2004, ICML WORKSH STAT REL
   Wang C., 2017, CORR
   Wang J., 2014, ARXIV14082927
   Weston Jason, 2014, ARXIV14103916
   Yushi Yao, 2015, CORR
   Zeng Daojian, 2015, P 2015 C EMP METH NA, P1753, DOI DOI 10.18653/V1/D15-1203
   Zhang Q, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P75, DOI 10.1145/2983323.2983809
   Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186
NR 59
TC 2
Z9 2
U1 1
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD NOV
PY 2020
VL 19
IS 6
AR 87
DI 10.1145/3422817
PG 28
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PA3OO
UT WOS:000595547800013
DA 2023-11-10
ER

PT J
AU Zhang, M
   Xiao, XY
   Xiong, DY
   Liu, Q
AF Zhang, Min
   Xiao, Xinyan
   Xiong, Deyi
   Liu, Qun
TI Topic-Based Dissimilarity and Sensitivity Models for Translation Rule
   Selection
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
LA English
DT Article
AB Translation rule selection is a task of selecting appropriate translation rules for an ambiguous source-language segment. As translation ambiguities are pervasive in statistical machine translation, we introduce two topic-based models for translation rule selection which incorporates global topic information into translation disambiguation. We associate each synchronous translation rule with source- and target-side topic distributions. With these topic distributions, we propose a topic dissimilarity model to select desirable (less dissimilar) rules by imposing penalties for rules with a large value of dissimilarity of their topic distributions to those of given documents. In order to encourage the use of non-topic specific translation rules, we also present a topic sensitivity model to balance translation rule selection between generic rules and topic-specific rules. Furthermore, we project target-side topic distributions onto the source- side topic model space so that we can benefit from topic information of both the source and target language. We integrate the proposed topic dissimilarity and sensitivity model into hierarchical phrase-based machine translation for synchronous translation rule selection. Experiments show that our topic-based translation rule selection model can substantially improve translation quality.
C1 [Zhang, Min; Xiong, Deyi] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou, Peoples R China.
   [Xiao, Xinyan; Liu, Qun] Chinese Acad Sci, Inst Comp Technol, IIP Key Lab, Beijing 100864, Peoples R China.
   [Liu, Qun] Dublin City Univ, Sch Comp, CNGL, Dublin 9, Ireland.
C3 Soochow University - China; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Dublin City University
RP Xiong, DY (通讯作者)，Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou, Peoples R China.
EM MINZHANG@SUDA.EDU.CN; XIAOXINYAN@ICT.AC.CN; DYXIONG@SUDA.EDU.CN;
   LIUQUN@ICT.AC.CN
RI zhang, min/IYI-9869-2023; zhang, meng/JMB-0951-2023
FU National Natural Science Foundation of China [61373095, 61333018];
   Science Foundation Ireland, CNGL at Dublin City University [07/CE/I1142]
FX The work was sponsored by the National Natural Science Foundation of
   China under projects 61373095 and 61333018. Qun Liu's work was partially
   supported by Science Foundation Ireland (Grant No. 07/CE/I1142) as part
   of the CNGL at Dublin City University. We would like to thank three
   anonymous reviewers for their insightful comments. The corresponding
   author of this article is Deyi Xiong.
CR [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], 2007, P 2 WORKSH STAT MACH
   [Anonymous], 2011, P 49 ANN M ASS COMPU
   [Anonymous], 2008, P 2008 C EMPIRICAL M
   Barzilay R, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P113
   Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blunsom P, 2009, P JOINT C 47 ANN M A, P782
   Boyd-Graber J., 2009, P 25 C UNC ART INT, P75
   Carpuat M., 2007, P 2007 JOINT C EMP M, P61
   Carpuat Marine, 2007, P TMI, P43
   Chan Y.S., 2007, P 45 ANN M ASS COMP, P33
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Chiang David, 2005, P ACL 2005
   Dorr B. J., 1994, Computational Linguistics, V20, P597
   Gong Z., 2011, P EMNLP 2011
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hardmeier C., 2012, P EMNLP CONLL, P1179
   He Zhongjun, 2008, P INT C COMP LING CO, P321
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Koehn Philipp, 2003, P HLT NAACL 2003
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Liu Q, 2008, EMNLP 2008, P89
   Liu Yang, 2006, P ACL 2006
   Mimno D., 2009, P EMNLP 2009
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och F. J., 2002, P ACL 2002
   Och F. J, 2003, P ACL 2003
   Papineni K., 2002, P ACL 2002
   Ruiz N., 2011, P 6 WORKSH STAT MACH
   Schler Jonathan, 2006, P AAAI SPRING S COMP, V6, P199
   Stolcke Andreas, 2002, P ICSLP 2002
   Tam YC, 2007, MACH TRANSL, V21, P187, DOI 10.1007/s10590-008-9045-2
   Tiedemann J., 2010, P 2010 WORKSH DOM AD, P909
   Ture Ferhan, 2012, P 2012 C N AM CHAPTE, P417
   Xiao T., 2011, MACHINE TRANSLATION, P131
   Xiao X., 2012, P 50 ANN M ASS COMP, P750
   Xiao Xinyan, 2013, P 2013 C EMP METH NA, P255
   Xiong D., 2012, P 50 ANN M ASS COMP, P902
   Zhao B., 2006, P ACL 2006
   Zhao Bin, 2007, P NIPS 2007
NR 41
TC 4
Z9 4
U1 0
U2 6
PU AI ACCESS FOUNDATION
PI MARINA DEL REY
PA USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA
   90292-6695 USA
SN 1076-9757
EI 1943-5037
J9 J ARTIF INTELL RES
JI J. Artif. Intell. Res.
PY 2014
VL 50
BP 1
EP 30
PG 30
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AL7JJ
UT WOS:000339309800001
DA 2023-11-10
ER

PT J
AU Phan, T
   Do, P
AF Phan, Trung
   Do, Phuc
TI Building a Vietnamese question answering system based on knowledge graph
   and distributed CNN
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE QAS; Deep learning; DM-Tree; Knowledge graph; Graph embedding
AB Question answering system (QAS) can be applied everywhere such as in schools, hospitals, banks, e-commerce websites. A smart QAS that can replace people is what people expect. Therefore, there are a lot of studies to build, develop, and improve QAS. However, QAS used for low-resource languages like Vietnamese is still very limited. So, in this paper, we present a method for building Vietnamese QAS. Except for specific Vietnamese language processes, most of our solutions can also be applied to other languages. We build QAS based on knowledge graph (KG) and convolutional neural network (CNN). KG provides knowledge and deducing ability for QAS. CNN is used to classify questions in the natural language to identify the correct answer to a given question. Moreover, we also use distributed architecture to train the CNN model. On the other hands, we also propose a solution to speed up searching for answers in a large KG by partitioning and indexing KG by using the DM-Tree structure. Besides, we also present experimental results and evaluation results of our model using common metrics to prove the effectiveness of our solution.
C1 [Phan, Trung; Do, Phuc] Vietnam Natl Univ, Univ Informat Technol, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Do, P (通讯作者)，Vietnam Natl Univ, Univ Informat Technol, Ho Chi Minh City, Vietnam.
EM trungphansg@gmail.com; phucdo@uit.edu.vn
FU Vietnam National University Ho Chi Minh City (VNU-HCMC) [DS2020-26-01]
FX This research is funded by Vietnam National University Ho Chi Minh City
   (VNU-HCMC) under grant number DS2020-26-01.
CR Albawi S., 2017, P INT C ENG TECHN IC, P1, DOI [DOI 10.1109/ICENGTECHNOL.2017.8308186, 10.1109/ICEngTechnol.2017.8308186]
   Allam AMN, 2016, INT J RES REV INFORM, V2
   Bghiel A, 2020, 3RD INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEM & SECURITY (NISS'20), DOI 10.1145/3386723.3387894
   Bhagat P, 2020, ICTD2020, VICTD2020, DOI [10.1145/3392561.3397581, DOI 10.1145/3392561.3397581]
   Bhandare A., 2016, INT J COMPUTER SCI I, V7, P2206
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI DOI 10.1145/3236669
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Chang DT, 2018, ARXIV180601756V1CSAI, V5
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Cloudera I, 2017, SPARK GUIDE
   Databricks, 2017, GENTL INTR AP SPARK
   Deriu JM, 2018, SWISSALPS SEMEVAL 20, DOI [10.18653/v1/s17-2054, DOI 10.18653/V1/S17-2054]
   Do P, 2022, NEURAL COMPUT APPL, V34, P8393, DOI 10.1007/s00521-020-05495-1
   Drabas T., 2017, LEARNING PYSPARK
   Fadhil A, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P408, DOI 10.1145/3099023.3099112
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferri C, 2009, PATTERN RECOGN LETT, V30, P27, DOI 10.1016/j.patrec.2008.08.010
   Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P105, DOI 10.1145/3289600.3290956
   Iftene A., 2016, ROCHI INT C HUM COMP, P91
   Joeri C. I.-D., 2016, DISTRIBUTED KERAS DI
   Johnson D.Q, 2017, P AUSTR LANG TECHN A, P108
   Kumar M, 2017, APPL WATER SCI, V7, P2103, DOI 10.1007/s13201-016-0406-3
   Lafferty J., 2001, CONDITIONAL RANDOM F, P282
   Langer M, 2020, IEEE T PARALL DISTR, V31, P2802, DOI 10.1109/TPDS.2020.3003307
   Lei Dian, 2018, ARXIV180508355V1CSLG
   Liu L, 2018, LECT NOTES ARTIF INT, V10956, P173, DOI 10.1007/978-3-319-95957-3_19
   Bach NX, 2020, CYBERN INF TECHNOL, V20, P112, DOI 10.2478/cait-2020-0008
   Nguyen DQ, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2582
   Page LC, 2017, AERA OPEN, V3, DOI 10.1177/2332858417749220
   Pham ST, 2016, P AMS 2015 ASIA MOD, DOI [10.1109/AMS.2015.26, DOI 10.1109/AMS.2015.26]
   Do P, 2020, INT J ADV COMPUT SC, V11, P639
   Le-Hong P, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1049, DOI 10.1145/3184558.3191535
   Reddy, 2020, INT J ELECT COMPUT E, V10, P2710, DOI DOI 10.11591/IJECE.V10I3.PP2710-2718
   Salunkhe A., 2020, INT J COMPUTER APPL, V177, P9, DOI [10.5120/ijca2020919817, DOI 10.5120/IJCA2020919817]
   Sandhini S, 2018, EMERGING TRENDS IN ENGINEERING, SCIENCE AND TECHNOLOGY FOR SOCIETY, ENERGY AND ENVIRONMENT, P779
   Shaikh E, 2019, 2019 2ND IEEE MIDDLE EAST AND NORTH AFRICA COMMUNICATIONS CONFERENCE (IEEEMENACOMM'19), P220, DOI 10.1109/menacomm46666.2019.8988541
   Truong Diem, 2017, P SOICT
   Valueva MV, 2020, MATH COMPUT SIMULAT, V177, P232, DOI 10.1016/j.matcom.2020.04.031
   Veith A. d. S., 2019, APACHE SPARK, DOI [10.1007/978-3-319-77525-8_37, DOI 10.1007/978-3-319-77525-8_37]
   Vijoy M., 2016, INT J ADV RES, DOI [10.21474/ijar01/1303, DOI 10.21474/IJAR01/1303]
   Vu T, 2018, P 2018 C N AM CHAPT, P56, DOI [DOI 10.18653/V1/N18-5012, 10.18653/v1/N18-5012]
   Tung VX, 2015, 2015 Seventh International Conference on Knowledge and Systems Engineering (KSE), P332, DOI 10.1109/KSE.2015.42
   Wahyudi, 2018, INT C INF TECH SYST, P536, DOI 10.1109/ICITSI.2018.8696046
   Yue Wang, 2020, ICIAI 2020: Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence, P170, DOI 10.1145/3390557.3394296
   Zhou XQ, 2018, NEUROCOMPUTING, V274, P8, DOI 10.1016/j.neucom.2016.07.082
NR 45
TC 9
Z9 9
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD NOV
PY 2021
VL 33
IS 21
BP 14887
EP 14907
DI 10.1007/s00521-021-06126-z
EA JUN 2021
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WL7FY
UT WOS:000662912100003
DA 2023-11-10
ER

PT S
AU Kurimo, M
   Turunen, V
   Ekman, I
AF Kurimo, M
   Turunen, V
   Ekman, I
BE Bengio, S
   Bourlard, H
TI Speech transcription and spoken document retrieval in Finnish
SO MACHINE LEARNING FOR MULTIMODAL INTERACTION
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Machine Learning for Multimodal
   Interaction
CY JUN 21-23, 2004
CL Martigny, SWITZERLAND
SP Augnebted Multiparty Interact, Pattern Analy Statist Modeling & Computat Learning, Multi- Modal Meeting Manager, Internact Multimodal Informat Management, European Commiss, SwissNatl Sci Fdn, Natl Cent Competence Res
AB This paper presents a baseline spoken document retrieval system in Finnish that is based on unlimited vocabulary continuous speech recognition. Due to its agglutinative structure, Finnish speech can not be adequately transcribed using the standard large vocabulary continuous speech recognition approaches. The definition of a sufficient lexicon and the training of the statistical language models are difficult, because the words appear transformed by many inflections and compounds. In this work we apply the recently developed language model that enables n-gram models of morpheme-like subword units discovered in an unsupervised manner. In addition to word-based indexing, we also propose an indexing based on the subword units provided directly by our speech recognizer, and a combination of the both. In an initial evaluation of newsreading in Finnish, we obtained a fairly low recognition error rate and average document retrieval precisions close to what can be obtained from human reference transcripts.
C1 Helsinki Univ Technol, Neural Networks Res Ctr, FI-02150 Espoo, Finland.
   Univ Tampere, Dept Informat Studies, FIN-33101 Tampere, Finland.
C3 Aalto University; Tampere University
RP Kurimo, M (通讯作者)，Helsinki Univ Technol, Neural Networks Res Ctr, FI-02150 Espoo, Finland.
EM Mikko.Kurimo@hut.fi
RI Kurimo, Mikko/F-6647-2012
CR [Anonymous], SPEECH RECOGNITION H
   [Anonymous], P ACL 02 WORKSH MORP
   [Anonymous], THESIS U HELSINKI
   [Anonymous], P 8 EUR C SPEECH COM
   BYRNE W, 2001, P 7 EUR C SPEECH COM, P487
   EKMAN I, 2003, THESIS U TAMPERE FIN
   GAROFOLO J, 2000, P CONT BAS MULT INF
   HACIOGLU K, 2003, P EUR GEN SWITZ, P1165
   PYLKKONEN J, 2004, P NORD SIGN PROC S N
   Renals S, 2000, SPEECH COMMUN, V32, P5, DOI 10.1016/S0167-6393(00)00020-0
   SORMUNEN E, 2000, THESIS U TAMPERE
   STOLCKE A, 2002, P ICSLP
   Witten I.H., 1999, MANAGING GIGABYTES C
   ZHOU B, 2002, P ICSLP
NR 14
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-24509-X
J9 LECT NOTES COMPUT SC
PY 2005
VL 3361
BP 253
EP 262
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BCC84
UT WOS:000228664600022
DA 2023-11-10
ER

PT J
AU Oliver, DE
   Shahar, Y
   Shortliffe, EH
   Musen, MA
AF Oliver, DE
   Shahar, Y
   Shortliffe, EH
   Musen, MA
TI Representation of change in controlled medical terminologies
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE controlled medical terminology; concept representation; knowledge
   representation; computer-based patient record; terminology maintenance;
   ontology; frame knowledge-representation language; description logic
ID READ-CODES; MAINTENANCE; LANGUAGE; INFORMATION
AB Computer-based systems that support health care require large controlled terminologies to manage names and meanings of data elements. These terminologies are not static, because change in health care is inevitable. To share data and applications in health care, we need standards not only for terminologies and concept representation, but also for representing change. To develop a principled approach to managing change, we analyze the requirements of controlled medical terminologies and consider features that frame knowledge-representation systems have to offer. Based on our analysis, we present a concept model, a set of change operations, and a change-documentation model that may be appropriate for controlled terminologies in health care. We are currently implementing our modeling approach within a computational architecture. (C) 1999 Elsevier Science B.V. All rights reserved.
C1 Stanford Univ, Sch Med, Stanford, CA 94305 USA.
C3 Stanford University
RP Oliver, DE (通讯作者)，Stanford Univ, Sch Med, Stanford, CA 94305 USA.
EM oliver@smi.stanford.edu
RI Shahar, Yuval/P-5185-2019
OI Shahar, Yuval/0000-0003-0328-2333; Musen, Mark/0000-0003-3325-793X;
   Shortliffe, Edward/0000-0001-5201-6176
FU NLM NIH HHS [LM-06245] Funding Source: Medline; PHS HHS [EM-07033]
   Funding Source: Medline
CR [Anonymous], 1991, SIGART B, DOI DOI 10.1145/122296.122309
   Baorto DM, 1997, J AM MED INFORM ASSN, P96
   BECHHOFER S, 1994, C1 U MANCH
   BRACHMAN RJ, 1985, COGNITIVE SCI, V9, P532
   BRACHMAN RJ, 1983, IEEE COMPUTER    OCT, P67
   CHAUDHRI V, 1998, OPEN KNOWLEDGE BASE
   CIMINO JJ, 1994, J AM MED INFORM ASSN, P135
   CIMINO JJ, 1994, J AM MED INFORM ASSN, V1, P35, DOI 10.1136/jamia.1994.95236135
   Cimino JJ, 1996, METHOD INFORM MED, V35, P202
   Elhanan G, 1996, Proc AMIA Annu Fall Symp, P348
   Elhanan G, 1997, J AM MED INFORM ASSN, P719
   EVANS DA, 1994, J AM MED INFORM ASSN, V1, P207, DOI 10.1136/jamia.1994.95236153
   FIRST MB, 1994, DIAGNOSTIC STAT MANU, P773
   Forrey AW, 1996, CLIN CHEM, V42, P81
   GIUSE DA, 1995, J AM MED INFORM ASSN, V2, P297, DOI 10.1136/jamia.1995.96073832
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   HORROCKS I, 1996, GRAIL SEMANTICS
   HUMPHREYS BL, 1993, B MED LIBR ASSOC, V81, P170
   MCCRAY AT, 1995, METHOD INFORM MED, V34, P193
   MUSEN MA, 1995, METHOD INFORM MED, V34, P85
   Musen MA, 1996, J AM MED INFORM ASSN, V3, P367, DOI 10.1136/jamia.1996.97084511
   *NAT LIB MED, 1998, UMLS MET FACT SHEET
   *NAT LIB MED, 1997, MED SUBJ HEAD ANN AL
   *NAT LIB MED, 1996, UMLS KNOWL SOURC
   Nowlan W A, 1991, Proc Annu Symp Comput Appl Med Care, P855
   OHNOMACHADO L, 1998, IN PRESS J AM MED IN
   OLSON NE, 1996, P 18 S COMP APPL MED, P902
   ONEIL M, 1995, METHOD INFORM MED, V34, P187
   PATIL RS, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P777
   PATY D, 1994, ANN NEUROL, V36, pS134, DOI 10.1002/ana.410360732
   PELTASON C, 1991, SIGART B, V2, P108
   *PRACT MAN INF COR, 1994, ICD 9 CM INT CLASS
   RECTOR AL, 1995, METHOD INFORM MED, V34, P147
   Rector AL, 1997, ARTIF INTELL MED, V9, P139, DOI 10.1016/S0933-3657(96)00369-7
   RESNICK LA, 1993, CLASSIC DESCRIPTION
   Robinson D, 1997, J AM MED INFORM ASSN, V4, P465, DOI 10.1136/jamia.1997.0040465
   SHAHAR Y, 1998, IN PRESS ARTIF INTEL
   SITTIG DF, 1994, J AM MED INFORM ASSN, V1, P412, DOI 10.1136/jamia.1994.95153429
   Spackman KA, 1997, J AM MED INFORM ASSN, P640
   Thurin A, 1995, Medinfo, V8 Pt 1, P110
   Tuttle MS, 1996, METHOD INFORM MED, V35, P211
   WILLIAMS JBW, 1987, DIAGNOSTIC STAT MANU, P414
NR 42
TC 46
Z9 47
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JAN
PY 1999
VL 15
IS 1
BP 53
EP 76
DI 10.1016/S0933-3657(98)00045-1
PG 24
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Medical Informatics
GA 157BW
UT WOS:000078040100004
PM 9930616
DA 2023-11-10
ER

PT J
AU Can, B
AF Can, Burcu
TI Unsupervised learning of allomorphs in Turkish
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
LA English
DT Article
DE Natural language processing; morphology; allomorphs; clustering;
   unsupervised learning; nonparametric Bayesian learning
AB One morpheme may have several surface forms that correspond to allomorphs. In English, ed and d are surface forms of the past tense morpheme, and s, es, and ies are surface forms of the plural or present tense morpheme. Turkish has a large number of allomorphs due to its morphophonemic processes. One morpheme can have tens of different surface forms in Turkish. This leads to a sparsity problem in natural language processing tasks in Turkish. Detection of allomorphs has not been studied much because of its difficulty. For example, tu and di are Turkish allomorphs (i.e. past tense morpheme), but all of their letters are different. This paper presents an unsupervised model to extract the allomorphs in Turkish. We are able to obtain an F-measure of 73.71% in the detection of allomorphs, and our model outperforms previous unsupervised models on morpheme clustering.
C1 [Can, Burcu] Hacettepe Univ, Fac Engn, Dept Comp Engn, Ankara, Turkey.
C3 Hacettepe University
RP Can, B (通讯作者)，Hacettepe Univ, Fac Engn, Dept Comp Engn, Ankara, Turkey.
EM burcucan@cs.hacettepe.edu.tr
RI Can, Burcu BC/M-8346-2018
OI Can, Burcu BC/0000-0002-1700-0395
CR [Anonymous], 2007, STRUCTURE
   Can B, 2012, P 13 C EUR CHAPT ASS, P654
   Can B, 2013, RECENT ADV NATURAL L, P129
   Coltekin C, 2010, P 7 INT C LANG RES E, P820
   Cotterell R, 2015, P 19 C COMP NAT LANG, P164, DOI DOI 10.18653/V1/K15
   Creutz M, 2002, P ACL 2002 WORKSH MO, P21, DOI DOI 10.3115/1118647.1118650
   Eryigit G, 2004, Proceedings of the IASTED International Conference on Artificial Intelligence and Applications, Vols 1and 2, P299
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   Hankamer J., 1989, LEXICAL REPRESENTATI, P392
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940
   Kurimo M, MORPHO CHALLENGE 200
   Poon H, 2009, P HUM LANG TECHN 200, P209
   Spiegler S., 2011, MACHINE LEARNING ANA
   Virpioja S, 2010, LECT NOTES COMPUT SC, V6241, P609, DOI 10.1007/978-3-642-15754-7_73
NR 14
TC 4
Z9 4
U1 0
U2 0
PU Tubitak Scientific & Technological Research Council Turkey
PI ANKARA
PA ATATURK BULVARI NO 221, KAVAKLIDERE, TR-06100 ANKARA, TURKIYE
SN 1300-0632
EI 1303-6203
J9 TURK J ELECTR ENG CO
JI Turk. J. Electr. Eng. Comput. Sci.
PY 2017
VL 25
IS 4
BP 3253
EP 3260
DI 10.3906/elk-1605-216
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FC7AR
UT WOS:000406993300057
OA Bronze, Green Submitted
DA 2023-11-10
ER

PT J
AU Hahn, U
   Romacker, M
   Schulz, S
AF Hahn, U
   Romacker, M
   Schulz, S
TI How knowledge drives understanding - matching medical ontologies with
   the needs of medical language processing
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE natural language processing; text understanding; description logics;
   pathology domain
ID INFORMATION-SYSTEMS; TERMINOLOGY SERVER; REPRESENTATION; TAXONOMY; UMLS
AB In this article, we introduce a knowledge-based approach to medical text understanding. From an in-depth consideration of deep sentence and text understanding we distill basic requirements for an adequate knowledge representation framework. These requirements are then matched with currently available medical ontologies (thesauri, terminologies, etc.). A fundamental trade-off is recognized between large-scale conceptual coverage on the one hand, and formal mechanisms for integrity preservation and conceptual expressiveness on the ether hand. We discuss various shortcomings of the most wide-spread ontologies to capture medical knowledge in-the-large. As a result, we argue for the need of a formally sound and expressive model along the lines of KL-ONE-style terminological representation systems in the format of description logics. These provide an adequate methodology for designing more sophisticated, flexible medical ontologies serving the needs of 'deep' knowledge applications which are by no means restricted to medical language processing. (C) 1999 Elsevier Science B.V. All rights reserved.
C1 Univ Freiburg, Text Knowledge Engn Lab, Computat Linguist Div, D-79085 Freiburg, Germany.
   Freiburg Univ Hosp, Dept Med Informat, D-79104 Freiburg, Germany.
C3 University of Freiburg; University of Freiburg
RP Hahn, U (通讯作者)，Univ Freiburg, Text Knowledge Engn Lab, Computat Linguist Div, Werthmannpl 1, D-79085 Freiburg, Germany.
EM hahn@coling.uni-freiburg.de
CR [Anonymous], COMPUTATIONAL LEXICO
   [Anonymous], 1991, LEXICAL ACQUISITION
   BAUD RH, 1995, METHOD INFORM MED, V34, P176
   Biebow B., 1993, Conceptual Graphs for Knowledge Representation. First International Conference on Conceptual Structures, ICCS '93 Proceeding, P75
   BRAZDIL PB, 1990, FR ART INT, P90
   BROKER N, 1997, NEW METHODS LANGUAGE, P301
   Burgun A, 1997, J AM MED INFORM ASSN, V4, P356, DOI 10.1136/jamia.1997.0040356
   Campbell JR, 1997, J AM MED INFORM ASSN, V4, P238, DOI 10.1136/jamia.1997.0040238
   Carenini G., 1994, Seventeenth Annual Symposium on Computer Applications in Medical Care. Patient-Centered Computing, P725
   Chandrasekaran B., 1989, Artificial Intelligence in Medicine, V1, P29, DOI 10.1016/0933-3657(89)90014-6
   CIMINO JJ, 1995, IMIA YB MED INFORMAT, P71
   COTE RA, 1993, SNOMED INT
   EVANS D, 1996, AMIA 96 P 18 AMIA FA, P388
   EVANS DA, 1994, J AM MED INFORM ASSN, V1, P207, DOI 10.1136/jamia.1994.95236153
   Falasconi S, 1997, METHOD INFORM MED, V36, P30
   FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161, DOI 10.1136/jamia.1994.95236146
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   HAHN U, 1994, INT J HUM-COMPUT ST, V41, P179, DOI 10.1006/ijhc.1994.1056
   Hahn U., 1996, ECAI 96. 12th European Conference on Artificial Intelligence, P572
   HAHN U, 1997, AMIA 97 P 19 AMIA FA, P819
   HAHN U, 1996, AMIA 96, P383
   HAHN U, 1997, P RIAO 97 C COMPUTER, V1, P578
   HAIMOWITZ IJ, 1988, SCAMC 88 P 12 ANN S, P101
   HAUG P, 1994, SCAMC 94 P 18 ANN S, P247
   HEINSOHN J, 1994, ARTIF INTELL, V68, P367, DOI 10.1016/0004-3702(94)90071-X
   HORROCKS I, 1996, KRDB 96 P 3 WORKSH K, P24
   INGENERF J, 1997, KUNSTL INTELL, V11, P6
   INGENERF J, 1996, P 19 ANN C GES KLASS, P355
   Keravnou ET, 1996, ARTIF INTELL MED, V8, P235, DOI 10.1016/0933-3657(95)00035-6
   KLAR R, 1996, P 19 ANN C GES KLASS, P380
   LIN R, 1992, SCAMC 91 P 15 ANN S, P843
   MCCRAY AT, 1995, METHOD INFORM MED, V34, P193
   MCCRAY AT, 1995, MEDINFO 95, P144
   *NLM, 1998, UN MED LANG SYST
   *NLM, 1997, MED SUBJ HEAD
   NOWLAN W, 1991, ARTIF INTELL, P105
   PORTER BW, 1990, ARTIF INTELL, V45, P229, DOI 10.1016/0004-3702(90)90041-W
   RASSINOUX AM, 1995, SCAMC 95, P27
   RECTOR AL, 1995, METHOD INFORM MED, V34, P147
   Rector AL, 1997, ARTIF INTELL MED, V9, P139, DOI 10.1016/S0933-3657(96)00369-7
   REIMER U, 1988, CAIA 88 P 4 IEEE AAA, P338
   Rosse C, 1998, J AM MED INFORM ASSN, V5, P17, DOI 10.1136/jamia.1998.0050017
   Sager N., 1987, MED LANGUAGE PROCESS
   SCHULZ S, 1998, P 8 WORKSH KNOWL ENG
   Senyk O., 1989, Applied Artificial Intelligence, V3, P249, DOI 10.1080/08839518908949927
   Smart JF, 1995, LECT NOTES ARTIF INT, V934, P53
   STAAB S, 1997, IJCAI 97, V2, P996
   STRUBE M, 1996, ACL 96, P270
   SZOLOVITS P, 1984, READINGS MED ARTIFIC, P210
   Volot F., 1994, Seventeenth Annual Symposium on Computer Applications in Medical Care. Patient-Centered Computing, P710
   WINSTON ME, 1987, COGNITIVE SCI, V11, P417, DOI 10.1207/s15516709cog1104_2
   WOODS WA, 1992, COMPUT MATH APPL, V23, P133, DOI 10.1016/0898-1221(92)90139-9
   ZWEIGENBAUM P, 1991, P RIAO 91 C INT TEXT, V2, P695
NR 53
TC 33
Z9 35
U1 1
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0933-3657
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JAN
PY 1999
VL 15
IS 1
BP 25
EP 51
DI 10.1016/S0933-3657(98)00044-X
PG 27
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Medical Informatics
GA 157BW
UT WOS:000078040100003
PM 9930615
DA 2023-11-10
ER

PT J
AU Rotman, G
   Reichart, R
AF Rotman, Guy
   Reichart, Roi
TI Deep Contextualized Self-training for Low Resource Dependency Parsing
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Neural dependency parsing has proven very effective, achieving state-of-the-art results on numerous domains and languages. Unfortunately, it requires large amounts of labeled data, which is costly and laborious to create. In this paper we propose a self-training algorithm that alleviates this annotation bottleneck by training a parser on its own output. Our Deep Contextualized Self-training (DCST) algorithm utilizes representation models trained on sequence labeling tasks that are derived from the parser's output when applied to unlabeled data, and integrates these models with the base parser through a gating mechanism. We conduct experiments across multiple languages, both in low resource in-domain and in cross-domain setups, and demonstrate that DCST substantially outperforms traditional self-training as well as recent semi-supervised training methods.(1)
C1 [Rotman, Guy; Reichart, Roi] Technion ITT, Fac Ind Engn & Management, Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Rotman, G (通讯作者)，Technion ITT, Fac Ind Engn & Management, Haifa, Israel.
EM grotman@campus.technion.ac.il; roiri@ie.technion.ac.il
FU ISF [1625/18]
FX We would like to thank the action editor and the reviewers, as well as
   the members of the IE@Technion NLP group for their valuable feedback and
   advice. This research was partially funded by an ISF personal grant no.
   1625/18.
CR Abney S, 2004, COMPUT LINGUIST, V30, P364
   Angeli Gabor, 2015, P 53 ANN M ASS COMP
   [Anonymous], 2012, P 2012 JOINT C EMPIR
   [Anonymous], 2018, P 56 ANN M ASS COMP, DOI DOI 10.18653/V1/P18-1128
   Artetxe M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P789
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Che Wanxiang, 2018, P CONLL 2018 SHARED, P55
   Chen W., 2008, P 22 INT C COMP LING, V1, P113
   Chen WL, 2014, P COLING 2014 25 INT, P816
   Clark K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1914
   Clevert D.-A., 2015, FAST ACCURATE DEEP N
   Devlin J., 2018, ARXIV, V1, P4171
   Dozat T., 2017, ICLR
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Goldwasser D, 2011, P 49 ANN M ASS COMPU, P1486
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Hadiwinoto C, 2017, AAAI CONF ARTIF INTE, P109
   He YL, 2011, INFORM PROCESS MANAG, V47, P606, DOI 10.1016/j.ipm.2010.11.003
   Hershcovich D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1127, DOI 10.18653/v1/P17-1104
   Hovy Eduard, 2006, P HUM LANG TECHN C N, P57, DOI DOI 10.3115/1614049.1614064
   Imamura K, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P110
   Kingma D. P., 2014, C TRACK P
   Kiperwasser E., 2016, T ASS COMPUTATIONAL, V4, P313, DOI [DOI 10.1162/TACL_A_00101, 10.1162/tacl_a_00101]
   Kiperwasser E., 2018, T ASSOC COMPUT LING, V6, P225, DOI DOI 10.1162/tacl_a_00017
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Ma XZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1403
   McCann Bryan, 2017, ADV NEURAL INFORM PR, P6297
   McClosky D., 2006, P MAIN C HUM LANG TE, P152, DOI DOI 10.3115/1220835.1220855
   McClosky D, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P337
   McClosky David., 2010, HUMAN LANGUAGE TECHN, P28
   McDonald Ryan, 2013, P 51 ANN M ASS COMP, V2, P92
   Mihalcea R., 2004, P CONLL 2004, P33
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   Nivre Joakim, 2018, UNIVERSAL DEPENDENCI
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Plank B., 2011, P 49 ANN M ASS COMP, V1, P1566
   Plank B, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P614
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Reichart Roi, 2007, P 45 ANN M ASS COMP, P616
   Ruder S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1044
   Rybak Piotr, 2018, P CONLL 2018 SHARED, P45
   Sato M., 2017, P CONLL 2017 SHARED, P71
   Shareghi E, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3509
   Sogaard A., 2010, P ACL 2010 C SHORT P, P205
   Spoustova Drahomira, 2010, Prague Bulletin of Mathematical Linguistics, P7, DOI 10.2478/v10108-010-0017-3
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Steedman M, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P331
   Strzyz M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P717
   Tenney Ian, 2019, P INT C LEARN REPR
   Toutanova K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1434
   Vaswani A., 2017, ARXIV, V30, P5998
   Vinyals O., 2015, ADV NEURAL INFORM PR, V28
   Wang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4465
   Wieting John, 2019, 7 INT C LEARN REPR I
   Yadav V., 2018, P 27 INT C COMP LING, P2145
   Yarowsky D, 1995, P ACL, P189, DOI [10.3115/981658.981684, DOI 10.3115/981658.981684]
   Zhang Kelly, 2018, P 2018 EMNLP WORKSH, P359, DOI [DOI 10.18653/V1/W18-5448, 10.18653/v1/W18-5448]
   Zhang Xiang, 2015, NEURIPS, DOI DOI 10.5555/2969239.2969312
   Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186
   Ziser Y., 2018, 2018 C N AM CHAPT AS, P1241
NR 60
TC 18
Z9 18
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2019
VL 7
BP 695
EP 713
DI 10.1162/tacl_a_00294
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA VK5UX
UT WOS:000736523200044
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Gabani, K
   Solorio, T
   Liu, Y
   Hassanali, KN
   Dollaghan, CA
AF Gabani, Keyur
   Solorio, Thamar
   Liu, Yang
   Hassanali, Khairun-nisa
   Dollaghan, Christine A.
TI Exploring a corpus-based approach for detecting language impairment in
   monolingual English-speaking children
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Natural language processing; Machine learning; Analysis of orthographic
   transcriptions; Language impairment; Monolingual English-speaking
   children
ID DEVELOPMENTAL OUTCOMES; GRAMMATICAL MORPHOLOGY; NONWORD REPETITION;
   DELAYED INSERTION; WORKING-MEMORY; OTITIS-MEDIA; AGE-CHILDREN; SPEECH;
   PREVALENCE; BIAS
AB Objectives: This paper explores the use of an automated method for analyzing narratives of monolingual English speaking children to accurately predict the presence or absence of a language impairment. The goal is to exploit corpus-based approaches inspired by the fields of natural language processing and machine learning.
   Methods and materials: We extract a large variety of features from language samples and use them to train language models and well known machine learning algorithms as the underlying predictors. The methods are evaluated on two different datasets and three language tasks. One dataset contains samples of two spontaneous narrative tasks performed by 118 children with an average age of 13 years and a second dataset contains play sessions from over 600 younger children with an average age of 6 years.
   Results: We compare results against a cut off baseline method and show that our results are far superior, reaching F-measures of over 85% in two of the three language tasks, and 48% in the third one.
   Conclusions: The different experiments we present here show that corpus based approaches can yield good prediction results in the problem of language impairment detection. These findings warrant further exploration of natural language processing techniques in the field of communication disorders. Moreover, the proposed framework can be easily adapted to analyze samples in languages other than English since most of the features are language independent or can be customized with little effort. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Solorio, Thamar] Univ Alabama Birmingham, Dept Comp & Informat Sci, Birmingham, AL 35294 USA.
   [Gabani, Keyur; Liu, Yang; Hassanali, Khairun-nisa] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75080 USA.
   [Dollaghan, Christine A.] Univ Texas Dallas, Dept Commun Sci & Disorders, Richardson, TX 75080 USA.
C3 University of Alabama System; University of Alabama Birmingham;
   University of Texas System; University of Texas Dallas; University of
   Texas System; University of Texas Dallas
RP Solorio, T (通讯作者)，Univ Alabama Birmingham, Dept Comp & Informat Sci, 1300 Univ Blvd, Birmingham, AL 35294 USA.
EM solorio@cis.uab.edu
OI Solorio, Thamar/0000-0002-3541-9405
FU National Science Foundation [1017190, 1018124]; National Institute of
   Child Health and Human Development; Agency for Healthcare Research and
   Quality; National Institutes of Health General Clinical Research Center;
   Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [1018124, 1017190] Funding Source: National Science
   Foundation
FX This research was supported by the National Science Foundation under
   grants 1017190 and 1018124. We would like to thank the reviewers for
   their thoughtful comments. The Paradise dataset used for these analyses
   were obtained originally in the course of a research project led by Jack
   L. Paradise, MD, and supported by grants from the National Institute of
   Child Health and Human Development, the Agency for Healthcare Research
   and Quality, and the National Institutes of Health General Clinical
   Research Center, in addition to gifts from SmithKline Beecham
   Laboratories and Pfizer. We also thank the children and families who
   participated and the research team who designed and implemented the
   study from which these data were obtained, including J. L Paradise, T.
   F., Campbell, H. M. Feldman, D. L Pitcairn, D. K. Colborn, B. S.
   Bernard, C. G. Smith, H. E. Rockette, J. E. Janosky, M. Kurs-Lasky, and
   many student research assistants.
CR [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 1998, THESIS U WAIKATO HAM
   Bedore LM, 2005, APPL PSYCHOLINGUIST, V26, P195, DOI 10.1017/S0142716405050149
   Bedore LM, 1998, J SPEECH LANG HEAR R, V41, P1185, DOI 10.1044/jslhr.4105.1185
   Bishop DVM, 1996, J CHILD PSYCHOL PSYC, V37, P391, DOI 10.1111/j.1469-7610.1996.tb01420.x
   Brants T, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P224
   Campbell T, 1997, J SPEECH LANG HEAR R, V40, P519, DOI 10.1044/jslhr.4003.519
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Conti-Ramsden G, 2001, J CHILD PSYCHOL PSYC, V42, P741, DOI 10.1111/1469-7610.00770
   Conti-Ramsden G, 1999, J SPEECH LANG HEAR R, V42, P1195, DOI 10.1044/jslhr.4205.1195
   Conti-Ramsden G, 1999, INT J LANG COMM DIS, V34, P359
   ContiRamsden G, 1997, J SPEECH LANG HEAR R, V40, P765, DOI 10.1044/jslhr.4004.765
   Deevy P, 2010, LANG SPEECH HEAR SER, V41, P277, DOI 10.1044/0161-1461(2009/08-0096)
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Dunn L. M., 1997, PPVT 3 PEABODY PICTU
   FLETCHER P, 1984, LANG TEST, P33
   Friedman J, 1998, ADDITIVE LOGISTIC RE
   Gabani K., 2009, P HUMAN LANGUAGE TEC, P46, DOI 10.3115/1620754.1620762
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   GAULIN CA, 1994, PERCEPT MOTOR SKILL, V79, P55, DOI 10.2466/pms.1994.79.1.55
   Gillam RB, 2004, CLASSIFICATION OF DEVELOPMENTAL LANGUAGE DISORDERS: THEORETICAL ISSUES AND CLINICAL IMPLICATIONS, P137
   Greenslade KJ, 2009, LANG SPEECH HEAR SER, V40, P150, DOI 10.1044/0161-1461(2008/07-0049)
   HANSSON K, 1995, J SPEECH HEAR RES, V38, P589, DOI 10.1044/jshr.3803.589
   Jacobson PF, 2002, APPL PSYCHOLINGUIST, V23, P23, DOI 10.1017/S0142716402000024
   Johnson CJ, 1999, J SPEECH LANG HEAR R, V42, P744, DOI 10.1044/jslhr.4203.744
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC
   KINCAID JP, 1975, 875 USN AIR STAT
   KLEE T, 1992, TOP LANG DISORD, V12, P28, DOI 10.1097/00011363-199202000-00005
   Law J, 2004, J SPEECH LANG HEAR R, V47, P924, DOI 10.1044/1092-4388(2004/069)
   Law J, 2000, INT J LANG COMM DIS, V35, P165, DOI 10.1080/136828200247133
   Law J, 2009, J SPEECH LANG HEAR R, V52, P1401, DOI 10.1044/1092-4388(2009/08-0142)
   Leonard LB, 2007, J SPEECH LANG HEAR R, V50, P408, DOI 10.1044/1092-4388(2007/029)
   LIDZ CS, 1994, LANG SPEECH HEAR SER, V27, P367
   MacWhinney B., 2000, CHILDES PROJECT TOOL
   Marchman VA, 1999, J SPEECH LANG HEAR R, V42, P206, DOI 10.1044/jslhr.4201.206
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Mayer Mercer, 1969, FROG ARE YOU
   MILLER J, 1983, SYSTEMATIC ANAL LANG
   Paradise JL, 2005, NEW ENGL J MED, V353, P576, DOI 10.1056/NEJMoa050406
   Paradise JL, 2003, PEDIATRICS, V112, P265, DOI 10.1542/peds.112.2.265
   Paradise JL, 2001, NEW ENGL J MED, V344, P1179, DOI 10.1056/NEJM200104193441601
   Parisse C, 2000, BEHAV RES METH INS C, V32, P468, DOI 10.3758/BF03200818
   Peña E, 2001, AM J SPEECH-LANG PAT, V10, P138, DOI 10.1044/1058-0360(2001/014)
   PENA E, 1992, J SPEC EDUC, V26, P269, DOI 10.1177/002246699202600304
   Rescorla L, 2009, J SPEECH LANG HEAR R, V52, P16, DOI 10.1044/1092-4388(2008/07-0171)
   Restrepo MA, 2001, J CHILD LANG, V28, P433, DOI 10.1017/S0305000901004706
   RICE ML, 1995, J SPEECH HEAR RES, V38, P850, DOI 10.1044/jshr.3804.850
   Roark B., 2007, P 2 INT C TECHN AG I
   Sackett DL, 1991, CLIN EPIDEMIOLOGY BA
   Semel E., 2003, CLIN EVALUATION LANG
   Simkin Z, 2001, INT J LANG COMM DIS, V36, P395
   Solorio T., 2008, P WORKSH CURR TRENDS, P116
   SOLORIO T, 2011, NATURAL LANGUAGE ENG, V17
   Spaulding TJ, 2006, LANG SPEECH HEAR SER, V37, P61, DOI 10.1044/0161-1461(2006/007)
   Tilstra J., 2007, COMMUN DISORD Q, V29, P43, DOI 10.1177/1525740108314866
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Tomblin JB, 1996, J SPEECH HEAR RES, V39, P1284, DOI 10.1044/jshr.3906.1284
   Vance R., 1994, LANG SPEECH HEAR SER, V25, P15, DOI DOI 10.1044/0161-1461.2501.15
   Wechsler D., 1991, MANUAL WECHSLER INTE
   WETHERELL D, 2007, CHILD LANGUAGE TEACH, V0023
   Wetherell D, 2007, INT J LANG COMM DIS, V42, P583, DOI 10.1080/13682820601056228
   Williams KT., 2007, EXPRESSIVE VOCABULAR
   Witten I H, 2000, DATA MINING PRACTICA
NR 63
TC 7
Z9 7
U1 4
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD NOV
PY 2011
VL 53
IS 3
BP 161
EP 170
DI 10.1016/j.artmed.2011.08.001
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Medical Informatics
GA 843OD
UT WOS:000296680600002
PM 21937203
DA 2023-11-10
ER

PT J
AU Yu, ZT
   Zhao, J
   Guo, CL
   Yang, Y
AF Yu, Zhengtao
   Zhao, Jia
   Guo, Chenliang
   Yang, Ying
TI StableNet: Distinguishing the hard samples to overcome language priors
   in visual question answering
SO IET COMPUTER VISION
LA English
DT Article; Early Access
DE computer vision; multimedia systems
AB With the booming fields of computer vision and natural language processing, cross-modal intersections such as visual question answering (VQA) have become very popular. However, several studies have shown that many VQA models suffer from severe language prior problems. After a series of experiments, the authors found that previous VQA models are in an unstable state, that is, when training is repeated several times on the same dataset, there are significant differences between the distributions of the predicted answers given by the models each time, and these models also perform unsatisfactorily in terms of accuracy. The reason for model instability is that some of the difficult samples bring serious interference to model training, so we design a method to measure model stability quantitatively and further propose a method that can alleviate both model imbalance and instability phenomena. Precisely, the question types are classified into simple and difficult ones different weighting measures are applied. By imposing constraints on the training process for both types of questions, the stability and accuracy of the model improve. Experimental results demonstrate the effectiveness of our method, which achieves 63.11% on VQA-CP v2 and 75.49% with the addition of the pre-trained model.
   The authors found that some more complex questions cause instability in the visual question answering model. For this reason, metrics are designed to measure the questions' complexity and the model's stability, and incorporated the weights into the loss function. A large number of experiments demonstrated the superiority of our method.image
C1 [Yu, Zhengtao; Zhao, Jia; Guo, Chenliang; Yang, Ying] Fuyang Normal Univ, Sch Comp & Informat Engn, Fuyang, Anhui, Peoples R China.
C3 Fuyang Normal University
RP Zhao, J (通讯作者)，Fuyang Normal Univ, Sch Comp & Informat Engn, Fuyang, Anhui, Peoples R China.
EM zhaojia11b@mails.ucas.ac.cn
FU This work is supported in part by the National Natural Science
   Foundation of China under Grant 61906044, in part by the China
   Postdoctoral Science Foundation under Grant 2020M681984, and in part by
   the key projects of natural science research in Anhui coll [61906044];
   National Natural Science Foundation of China [2020M681984]; China
   Postdoctoral Science Foundation [2023AH050406, 2023AH050418, KJ2020ZD48,
   gxgwfx2021034]; key projects of natural science research in Anhui
   colleges and universities
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant 61906044, in part by the China
   Postdoctoral Science Foundation under Grant 2020M681984, and in part by
   the key projects of natural science research in Anhui colleges and
   universities under Grant 2023AH050406, 2023AH050418, KJ2020ZD48 and
   gxgwfx2021034.
CR Agrawal A., 2016, EMNLP, P1955
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bao H., 2021, 2021 NEURAL INFORM P
   Cadene Remi, 2019, ADV NEUR IN, P841
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Clark C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4069
   Gokhale T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P878
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Grzyb J, 2021, J COMPUT SCI-NETH, V51, DOI 10.1016/j.jocs.2021.101314
   Guo YY, 2022, IEEE T IMAGE PROCESS, V31, P227, DOI 10.1109/TIP.2021.3128322
   Han YD, 2022, Arxiv, DOI arXiv:2207.11850
   Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44
   Kim JH, 2018, ADV NEUR IN, V31
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Liang ZJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3285
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu YB, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3498340
   Long Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10797, DOI 10.1109/CVPR42600.2020.01081
   Luo Z., 2023, ARXIV
   Niu Y., 2021, ADV NEURAL INFORM PR
   Niu YL, 2021, PROC CVPR IEEE, P12695, DOI 10.1109/CVPR46437.2021.01251
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Selvaraju RR, 2019, IEEE I CONF COMP VIS, P2591, DOI 10.1109/ICCV.2019.00268
   Shu XY, 2023, Arxiv, DOI arXiv:2304.01647
   Si Q., 2022, C EMP METH NAT LANG
   Si QY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4101
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Tan H.H., 2019, C EMP METH NAT LANG
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Techapanurak Engkarat, 2021, Computer Vision - ACCV 2020. 15th Asian Conference on Computer Vision. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12625), P53, DOI 10.1007/978-3-030-69538-5_4
   Vaishnav M, 2022, NEURAL COMPUT, V34, P1075, DOI 10.1162/neco_a_01485
   Wu Y., 2022, INT C COMP LING, P5721
   Xue H., 2021, ADV NEURAL INFORM PR, V34, P4514
   Yang ZY, 2021, Arxiv, DOI arXiv:2109.05014
   Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542
   Zhao J, 2022, NEURAL COMPUT APPL, V34, P9015, DOI 10.1007/s00521-022-06923-0
   Zhu X., 2021, P 20 9 INT JOINT C A
NR 40
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9632
EI 1751-9640
J9 IET COMPUT VIS
JI IET Comput. Vis.
PD 2023 OCT 28
PY 2023
DI 10.1049/cvi2.12249
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9YV2
UT WOS:001088300100001
DA 2023-11-10
ER

PT J
AU Veres, C
   Sampson, J
AF Veres, Csaba
   Sampson, Jennifer
TI Self supervised learning and the poverty of the stimulus
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article
DE Classification; Learnability; Text mining; Machine Learning; NLP;
   Language
ID NATURAL-LANGUAGE
AB Diathesis alternations are the possible expressions of the arguments of verbs in different, systematically related subcategorization frames. Semantically similar verbs such as spill and spray can behave differently with respect to the alternations they can participate in. For example one can "spill/spray water on the plant", but while one can "spray the plant with water", it is odd to say "spill the plant with water". "Spray"is a verb which can alternate between syntactic frames while "spill"is not alternating. How human speakers learn the difference between such verbs is not clearly understood, because the primary linguistic data (PLD) they receive does not appear sufficient to infer the knowledge required for adult competence. More generally the poverty of the stimulus (POS) hypothesis states that the PLD is not sufficient for a learner to infer full adult competence of language. That is, learning relies on prior constraints introduced by the language faculty. We tested state-of-the-art machine learning models trained by self supervision, and found some evidence that they could in fact learn the correct pattern of acceptability judgement in the locative alternation. However, we argued that this was partially a result of fine-tuning which introduced negative evidence into the learning data, which facilitated shortcut learning. Large language models (LLMs) cannot learn some linguistic facts from normal language data, but they can compensate to some extent by learning spurious correlated features when negative feedback is introduced during the training cycle.
C1 [Veres, Csaba] Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway.
   [Sampson, Jennifer] Equinor UK Ltd, London, England.
C3 University of Bergen; Equinor
RP Veres, C (通讯作者)，Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway.
EM csaba.veres@uib.no
CR Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   BAKER CL, 1979, LINGUIST INQ, V10, P533
   Bender EM, 2020, P 58 ANN M ASS COMPU, P5185, DOI [DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1]
   Berwick RC, 2011, COGNITIVE SCI, V35, P1207, DOI 10.1111/j.1551-6709.2011.01189.x
   Bley-Vroman Robert, 2001, STUD SECOND LANG ACQ, V23, P207
   Brooks PJ, 1999, LANGUAGE, V75, P720, DOI 10.2307/417731
   Bross Fabian, ACCEPTABILITY RATING
   Chen LJ, 2023, Arxiv, DOI arXiv:2307.09009
   CHOI S, 1991, COGNITION, V41, P83, DOI 10.1016/0010-0277(91)90033-Z
   Chomsky N., 1965, ASPECTS THEORY SYNTA
   Chomsky Noam, 1980, COLUMBIA CLASSICS PH
   Cowie Fiona, 2017, STANFORD ENCY PHILOS
   Devlin J., 2018, ARXIV, V1, P4171
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Grechishnikova D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79682-4
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Jackendoff Ray, 1983, SEMANTICS COGNITION, P283
   Jackendoff Ray, 1990, SEMANTIC STRUCTURES, P322
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kann Katharina, 2019, P SOC COMPUTATION LI, P287
   Kassner N., 2020, PROC 58 ANN M ASS CO, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]
   Levin Beth, 1993, ENGLISH VERB CLASSES
   Li Yujia, 2022, ARXIV, DOI 10.48550/ARXIV.2203.07814
   Liu P., 2021, ARXIV
   Liu YH, 2023, Arxiv, DOI arXiv:2304.01852
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Merriman W.E., 1995, NAMES THINGS YOUNG C, P353
   Mitchell Melanie, 2023, Science, V381, padj5957, DOI 10.1126/science.adj5957
   Perfors A, 2010, J CHILD LANG, V37, P607, DOI 10.1017/S0305000910000012
   PINKER S, 1990, BEHAV BRAIN SCI, V13, P707, DOI 10.1017/S0140525X00081061
   Pinker S., 2007, STUFF THOUGHT LANGUA
   Pinker Steven, 1989, LEARNABILITY COGNITI
   Quinn T, 2018, TLS-TIMES LIT SUPPL, P31
   Ruis Laura, 2022, ARXIV
   Sahlgren M, 2008, ITAL J LINGUIST, V20, P33
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Scholkopf B., 2021, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Veres C, 2022, IEEE ACCESS, V10, P61970, DOI 10.1109/ACCESS.2022.3182505
   Veres C, 2019, LECT NOTES ARTIF INT, V11919, P369, DOI 10.1007/978-3-030-35288-2_30
   Wang A., 2019, INT C LEARNING REPRE
   Wang A, 2019, ADV NEUR IN, V32
   Wang W, 2019, Arxiv, DOI arXiv:1908.04577
   Warstadt A., 2018, NEURAL NETWORK ACCEP
   Wikipedia contributors, 2023, INSTR CAS WIK FREE E
   Yang ZL, 2020, Arxiv, DOI [arXiv:1906.08237, DOI 10.48550/ARXIV.1906.08237]
NR 48
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-023X
EI 1872-6933
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD SEP
PY 2023
VL 147
AR 102208
DI 10.1016/j.datak.2023.102208
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q7YO7
UT WOS:001059645300001
OA hybrid
DA 2023-11-10
ER

PT J
AU Cadoli, M
   Eiter, T
   Gottlob, G
AF Cadoli, M
   Eiter, T
   Gottlob, G
TI Default logic as a query language
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Principles of Knowledge Representation
   and Reasoning
CY MAY 24-27, 1994
CL BONN, GERMANY
SP Gesell Informat, Austrian SOc Artificial Intelligence, Canadian Soc Computat Studies Intelligence, European Coordinating Comm Artificial Intelligence, Amer Assoc Artificial Intelligence, Int Joint Conf Artificial Intelligence
DE nonmonotonic reasoning; default logic; query languages; relational
   databases; expressive power
ID COMPLEXITY; NEGATION; PROGRAMS
AB Research in nonmonotonic reasoning has focused largely on the idea of representing knowledge about the world via rules that are generally true but can be defeated. Even if relational databases are nowadays the main tool for storing very large sets of data, the approach of using nonmonotonic Al formalisms as relational database query languages has been investigated to a much smaller extent. In this work, we propose a novel application of Reiter's default logic by introducing a default query language (DQL) for finite relational databases, which is based on default rules. The main result of this paper is that DQL is as expressive as SO There Exists For All, the existential-universal fragment of second-order logic. This result is not only of theoretical importance: We exhibit queries-which are useful in practice--that can be expressed with DQL and cannot with other query languages based on nonmonotonic logics such as DATALOG with negation under the stable model semantics. In particular, we show that DQL is well-suited for diagnostic reasoning.
C1 VIENNA TECH UNIV,DEPT INFORMAT SYST,A-1040 VIENNA,AUSTRIA.
C3 Technische Universitat Wien
RP Cadoli, M (通讯作者)，UNIV ROMA LA SAPIENZA,DIPARTIMENTO INFORMAT & SISTEMIST,VIA SALARIA 113,I-00198 ROME,ITALY.
RI Eiter, Thomas/ABE-9263-2021
OI Gottlob, Georg/0000-0002-2353-5230
CR Abiteboul S., 1991, Annals of Mathematics and Artificial Intelligence, V3, P151, DOI 10.1007/BF01530924
   ABITEBOUL S, 1992, THEORETICAL STUDIES
   Abiteboul S, 1995, FDN DATABASES
   Aho A., 1979, P ACM S PRINCIPLES P, P110
   BELL C, 1995, J ACM, V42
   BIDOIT N, 1991, THEOR COMPUT SCI, V78, P85, DOI 10.1016/0304-3975(51)90004-7
   Bidoit N., 1987, Proceedings of the Symposium on Logic in Computer Science (Cat. No.87CH2464-6), P89
   BIDOIT N, 1991, INFORMATION COMPUTAT, V19, P15
   CADOLI M, 1993, J LOGIC PROGRAM, V17, P127, DOI 10.1016/0743-1066(93)90029-G
   CADOLI M, 1994, P 4 INT C PRINC KNOW
   CADOLI M, 1994, J COMPUT SYST SCI, V43, P165
   CHANDRA AK, 1988, P PODS 88
   Console L., 1991, Journal of Logic and Computation, V1, P661, DOI 10.1093/logcom/1.5.661
   CORCIULO L, 1993, P INT C DED OBJ OR D
   Eiter T., 1994, Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1994, P267, DOI 10.1145/182591.182639
   EITER T, 1995, J ACM, V42, P3, DOI 10.1145/200836.200838
   EITER T, 1993, 12TH P ACM SIGACT SI, P158
   FAGIN R, 1974, COMPLEXITY COMPUTATI, P43
   Gelfond Michael, 1988, STABLE MODEL SEMANTI, P1070
   Gottlob G., 1992, Journal of Logic and Computation, V2, P397, DOI 10.1093/logcom/2.3.397
   GOTTLOB G, 1990, LECT NOTES AI, V462
   GUREVICH Y, 1988, TRENDS THEORETICAL C, pCH1
   Hamscher W., 1992, READINGS MODEL BASED
   IMMERMAN N, 1987, SIAM J COMPUT, V16, P760, DOI 10.1137/0216051
   Johnson D. S., 1990, HDB THEORETICAL COMP
   KANELLAKIS PC, 1990, HDB THEORETICAL COMP, VB, pCH17
   KAUTZ HA, 1991, ARTIF INTELL, V49, P243, DOI 10.1016/0004-3702(91)90011-8
   KOLAITIS PG, 1991, J COMPUT SYST SCI, V43, P125, DOI 10.1016/0022-0000(91)90033-2
   KRISHNAMURTHY R, 1988, 3RD P INT C DAT KNOW, P416
   LUKASIEWICZ W, 1990, NONMONOTONIC REASONI
   LYNCH JF, 1982, MATH SYST THEORY, V15, P127
   MAREK W, 1991, J ACM, V38, P588, DOI 10.1145/116825.116836
   Marek W., 1993, NONMONOTONIC LOGICS
   Papadimitriou C., 1994, COMPUT COMPLEX
   PAPADIMITRIOU CH, 1985, B EATCS, V26, P21
   POOLE D, 1989, P 11 INT JOINT C ART, P1304
   Reggia J, 1990, ABDUCTIVE INFERENCE
   REITER R, 1980, ARTIF INTELL, V13, P81, DOI 10.1016/0004-3702(80)90014-4
   REITER R, 1984, CONCEPTUAL MODELLING, P163
   SACCA D, 1990, PROCEEDINGS OF THE NINTH ACM SIGACT-SIGMOD-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P205, DOI 10.1145/298514.298572
   SACCA D, 1995, J COMPUTER SYSTEM SC
   SACCA D, 1993, INF P 2 COMP NET M K
   Sakama Chiaki, 1993, P 2 INT WORKSH LOG P, P266
   SCHLIPF JS, IN PRESS J COMPUTER
   Stewart I. A., 1991, Journal of Logic and Computation, V1, P305, DOI 10.1093/logcom/1.3.305
   STILLMAN J, 1992, P AAAI 92 SAN JOSE, P794
   Stockmeyer Larry, 1977, THEORET COMPUT SCI, V3, P1
   Ullman J.D., 1989, PRINCIPLES DATABASE, VI
   Van Gelder A., 1989, Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, P1, DOI 10.1145/73721.73722
   VANGELDER A, 1991, J ACM, V38, P620, DOI 10.1145/116825.116838
   WAGNER KW, 1990, SIAM J COMPUT, V19, P833, DOI 10.1137/0219058
NR 51
TC 43
Z9 43
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314
SN 1041-4347
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD MAY-JUN
PY 1997
VL 9
IS 3
BP 448
EP 463
DI 10.1109/69.599933
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XG593
UT WOS:A1997XG59300008
DA 2023-11-10
ER

PT J
AU Rozovskaya, A
   Roth, D
AF Rozovskaya, Alla
   Roth, Dan
TI Grammar Error Correction in Morphologically Rich Languages: The Case of
   Russian
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Until now, most of the research in grammar error correction focused on English, and the problem has hardly been explored for other languages. We address the task of correcting writing mistakes in morphologically rich languages, with a focus on Russian. We present a corrected and error-tagged corpus of Russian learner writing and develop models that make use of existing state-of-the-art methods that have been well studied for English. Although impressive results have recently been achieved for grammar error correction of non-native English writing, these results are limited to domains where plentiful training data are available. Because annotation is extremely costly, these approaches are not suitable for the majority of domains and languages. We thus focus on methods that use "minimal supervision''; that is, those that do not rely on large amounts of annotated training data, and show how existing minimal-supervision approaches extend to a highly inflectional language such as Russian. The results demonstrate that these methods are particularly useful for correcting mistakes in grammatical phenomena that involve rich morphology.
C1 [Rozovskaya, Alla] CUNY, Queens Coll, Queens, NY 11367 USA.
   [Roth, Dan] Univ Penn, Philadelphia, PA 19104 USA.
C3 City University of New York (CUNY) System; University of Pennsylvania
RP Rozovskaya, A (通讯作者)，CUNY, Queens Coll, Queens, NY 11367 USA.
EM arozovskaya@qc.cuny.edu; danroth@seas.upenn.edu
FU US Defense Advanced Research Projects Agency (DARPA) [HR0011-152-0025]
FX The authors thank Olesya Kisselev for her help with obtaining the RULEC
   corpus, and Elmira Mustakimova for sharing the error categories
   developed at the Russian National Corpus. The authors thank Mark Sammons
   and the anony-mous reviewers for their comments. This work was partially
   supported by contract HR0011-152-0025 with the US Defense Advanced
   Research Projects Agency (DARPA). The views expressed are those of the
   authors and do not reflect the official policy or position of the
   Department of Defense or the US Government.
CR Abel A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2414
   Alexey Sorokin, 2016, COMPUT LINGUIST
   [Anonymous], 2014, P EMNLP 2014 WORKSHO
   [Anonymous], 2010, HUMAN LANGUAGE TECHN
   [Anonymous], 2008, P 3 INT JOINT C NAT
   [Anonymous], 2008, P COLING
   Banko M, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P26, DOI 10.3115/1073012.1073017
   Borisov Alexey, 2014, P 9 WORKSH STAT MACH, P66
   Briscoe T, 2016, P C N AM ASS COMP LI, P380
   Bryant C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P697
   Cahill A., 2013, P 2013 C N AM CHAPT, P507
   Chollampatt S., 2017, P 12 WORKSH INN US N, P327
   Chollampatt S, 2018, AAAI CONF ARTIF INTE, P5755
   Chollampatt Shamil, 2016, P 25 INT JOINT C ART, P2768
   Choshen L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1372
   Choshen Leshem, P ACL
   Choshen Leshem, 2018, P 2018 C N AM CHAPTE, V2, P124
   Dahlmeier D., 2011, P 49 ANN M ASS COMP, P915
   Dahlmeier Daniel, 2012, P 2012 C N AM CHAPT, P568
   Dale R., 2012, P 7 WORKSHOP BUILDIN, P54
   Dale Robert, 2011, P 13 EUROPEAN WORKSH, P242
   de Ilarraza Arantza Diaz, 2008, P COLING, P31
   Dickinson M, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   Felice M., 2015, P 2015 C N AM CHAPT, P578
   Felice M., 2014, P STUD RES WORKSH 14, P116
   Golding Andrew R., 1996, P ICML
   Golding AR, 1999, MACH LEARN, V34, P107, DOI 10.1023/A:1007545901558
   Grundkiewicz R., 2018, P 2018 C N AM CHAPT, V2, P284, DOI DOI 10.18653/V1/N18-2046
   Hana J., 2010, P 4 LING ANN WORKSH, P11, DOI DOI 10.5555/1868720.1868722
   Heafield K., 2013, P 51 ANN M ASS COMP, V2, P690
   Imamura K., 2012, P 50 ANN M ASS COMP, P388
   Ionin T, 2008, LINGUA, V118, P554, DOI 10.1016/j.lingua.2006.11.012
   Israel R., 2013, 59 ANN M ASS COMPUTA, P1419
   IZUMI E., 2003, P 41 ANN M ASS COMP, V2, P145
   Ji JS, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P753, DOI 10.18653/v1/P17-1070
   Junczys-Dowmunt M, 2016, P 2016 C EMPIRICAL M, P1546, DOI DOI 10.18653/V1/D16-1161
   Junczys-Dowmunt Marcin, 2018, P 2018 C N AM CHAPT, V1, P595, DOI DOI 10.18653/V1/N18-1055
   Klyachko Elena, 2013, P 1 WORKSH CORP AN N
   Koehn P., 2017, WMT, P28
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Leacock Claudia, 2010, AUTOMATED GRAMMATICA
   Lee J, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P89, DOI 10.1109/SLT.2008.4777847
   Lung-Hao Lee, 2016, P 3 WORKSH NAT LANG, P1
   Mizumoto T., 2011, 5 INT JOINT C NAT LA, P147
   MONTRUL S, 2002, ACQUISITION SPANISH, P113
   Na-Rae Han, 2006, Natural Language Engineering, V12, P115, DOI 10.1017/S1351324906004190
   Napoles C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P588
   Napoles Courtney, 2017, P 15 C EUR CHAPT ASS, V2, P229
   Ng Hwee Tou, 2014, P 18 C COMP NAT LANG, P1, DOI DOI 10.3115/V1/W14-1701
   Ng Hwee Tou, 2013, P 17 C COMPUTATIONAL, P1
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Rakhilina Ekaterina, 2016, P JOINT WORKSH NLP C, P66
   Ramasamy Loganathan, 2015, P SLOV NLP WORKSH
   Rao GQ, 2018, NATURAL LANGUAGE PROCESSING TECHNIQUES FOR EDUCATIONAL APPLICATIONS, P42
   Rao Gaoqi, 2017, P IJCNLP 2017 SHAR T, P1, DOI DOI 10.1115/GTINDIA2017-4776
   Rizzolo N., 2011, THESIS U ILLINOIS UR
   Rosen A, 2014, LANG RESOUR EVAL, V48, P65, DOI 10.1007/s10579-013-9226-3
   Rozovskaya A., 2010, HUMAN LANGUAGE TECHN, P154
   Rozovskaya A., 2015, P 2 WORKSHOP ARABIC, P26
   Rozovskaya A., 2014, T ACL, V2, P419
   Rozovskaya A., 2011, P 49 ANN M ASS COMP, P924
   Rozovskaya A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2205
   Rozovskaya A, 2017, COMPUT LINGUIST, V43, P723, DOI 10.1162/COLI_a_00299
   Rozovskaya Alla, 2010, P 2010 C EMP METH NA, P961
   Rozovskaya Alla, 2010, P NAACL HLT 2010 5 W, P28
   Sakaguchi Keisuke, 2016, T ASS COMPUTATIONAL, V4, P169, DOI DOI 10.1162/TACL_A_00091
   Schmid H., 1995, P ACL SIGDAT WORKSH, P47, DOI DOI 10.1007/978-94-017-2390-9_2
   Segalovich I, 2003, MLMTA'03: INTERNATIONAL CONFERENCE ON MACHINE LEARNING; MODELS, TECHNOLOGIES AND APPLICATIONS, P273
   Sorokin A., 2017, 6 WORKSH BALT SLAV N, P45, DOI [10.18653/v1/W17, DOI 10.18653/V1/W17]
   Susanto Raymond Hendy, 2014, P 2014 C EMPIRICAL M, P951, DOI DOI 10.3115/V1/D14-1102
   Tajiri T., 2012, P 50 ANN M ASS COMPU, P198
   Tetreault J., 2010, P 48 ANN M ASS COMP, P353
   Tetreault Joel, 2008, P WORKSH HUM JUDG CO, P24
   Vincze V, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3958
   Yannakoudakis H., 2011, P 49 ANN M ASS COMPU
   Yatsenko A. A. A., 2012, RUSSIAN LANGUAGE J, V62, P79
   Yu L. C., 2014, P 1 WORKSH NAT LANG, P42
   Zaghouani W, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2362
NR 79
TC 14
Z9 14
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2019
VL 7
BP 1
EP 17
DI 10.1162/tacl_a_00251
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA VK5UX
UT WOS:000736523200001
OA gold
DA 2023-11-10
ER

PT J
AU Bird, JJ
   Ekárt, A
   Faria, DR
AF Bird, Jordan J.
   Ekart, Aniko
   Faria, Diego R.
TI Chatbot Interaction with Artificial Intelligence: human data
   augmentation with T5 and language transformer ensemble for text
   classification
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article; Early Access
DE Chatbot; Human-machine interaction; Data augmentation; Transformers;
   Language transformation; Natural Language Processing
AB In this work we present the Chatbot Interaction with Artificial Intelligence (CI-AI) framework as an approach to the training of a transformer based chatbot-like architecture for task classification with a focus on natural human interaction with a machine as opposed to interfaces, code, or formal commands. The intelligent system augments human-sourced data via artificial paraphrasing in order to generate a large set of training data for further classical, attention, and language transformation-based learning approaches for Natural Language Processing (NLP). Human beings are asked to paraphrase commands and questions for task identification for further execution of algorithms as skills. The commands and questions are split into training and validation sets. A total of 483 responses were recorded. Secondly, the training set is paraphrased by the T5 model in order to augment it with further data. Seven state-of-the-art transformer-based text classification algorithms (BERT, DistilBERT, RoBERTa, DistilRoBERTa, XLM, XLM-RoBERTa, and XLNet) are benchmarked for both sets after fine-tuning on the training data for two epochs. We find that all models are improved when training data is augmented by the T5 model, with an average increase of classification accuracy by 4.01%. The best result was the RoBERTa model trained on T5 augmented data which achieved 98.96% classification accuracy. Finally, we found that an ensemble of the five best-performing transformer models via Logistic Regression of output label predictions led to an accuracy of 99.59% on the dataset of human responses. A highly-performing model allows the intelligent system to interpret human commands at the social-interaction level through a chatbot-like interface (e.g. "Robot, can we have a conversation?") and allows for better accessibility to AI by non-technical users.
C1 [Bird, Jordan J.; Faria, Diego R.] Aston Univ, Aston Robot Vis & Intelligent Syst Lab ARVIS Lab, Birmingham, W Midlands, England.
   [Ekart, Aniko] Aston Univ, Sch Engn & Appl Sci, Birmingham, W Midlands, England.
C3 Aston University; Aston University
RP Bird, JJ (通讯作者)，Aston Univ, Aston Robot Vis & Intelligent Syst Lab ARVIS Lab, Birmingham, W Midlands, England.
EM birdj1@aston.ac.uk; a.ekart@aston.ac.uk; d.faria@aston.ac.uk
RI Faria, Diego R/B-4056-2011
OI Faria, Diego R/0000-0002-2771-1713; Ekart, Aniko/0000-0001-6967-5397;
   Bird, Jordan J./0000-0002-9858-1231
CR Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC
   [Anonymous], 2005, M ASS COMP LING, DOI [10.3115/1219840.1219914, DOI 10.3115/1219840.1219914]
   [Anonymous], 2013, P UBICOMP 13 ADJ
   Biedert Ralf, 2012, P S EYE TRACK RES AP, P123, DOI DOI 10.1145/2168556.2168575
   Bird, INTELLIGENT COMPUTIN, P593
   Bird J, 2019, MENTAL EMOTIONAL SEN, DOI 10.1109/IS.2018.8710576
   Bird JJ, 2020, IEEE INT C INT ROBOT, P10380, DOI 10.1109/IROS45743.2020.9341557
   Bird JJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185151
   Bird JJ, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P795, DOI 10.1109/IS.2018.8710576
   Bird JJ, 2019, ADV INTELL SYST COMP, V840, P179, DOI 10.1007/978-3-319-97982-3_15
   Bollweg L, 2018, EDMEDIA INNOVATE LEA, P1455
   Candello, 2018, 2018 CHI C HUM FACT, P1
   Chada, 2020, ARXIV PREPRINT ARXIV
   Chang, 2020, ELLACHANG T5 PARAPHR
   Chang W.-C., 2019, ARXIV PREPRINT ARXIV
   Chollet F., 2015, KERAS
   Ciechanowski L, 2019, FUTURE GENER COMP SY, V92, P539, DOI 10.1016/j.future.2018.01.055
   Conneau Alexis, 2019, ARXIV191102116
   Devlin J., 2018, ARXIV, V1, P4171
   Devlin J, 2018, OPEN SOURCING BERT S
   Di Gangi MA, 2019, INTERSPEECH, P1133, DOI 10.21437/Interspeech.2019-3045
   DIMOVSKI M, 2018, ARXIV PREPRINT ARXIV
   Eckstein G., 2019, TESL EJ, V23, pN1
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Haller E, 2013, I C CONTR SYS COMP S, P582, DOI 10.1109/CSCS.2013.85
   Hou, 2018, ARXIV PREPRINT ARXIV
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   JIN L, 2018, P 13 WORKSH INN US N, P13
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kruger JL, 2014, READ RES QUART, V49, P105, DOI 10.1002/rrq.59
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Leonhardt MD, 2007, 7TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P845, DOI 10.1109/ICALT.2007.275
   Lewis Martha, 2020, IFCOLOG J LOGICS THE, V7
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Lukovnikov D, 2019, LECT NOTES COMPUT SC, V11778, P470, DOI 10.1007/978-3-030-30793-6_27
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Maiya, 2020, ARXIV200410703CSLG
   Manurung R, 2008, APPL ARTIF INTELL, V22, P841, DOI 10.1080/08839510802295962
   Marquis A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00452
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Paszke Adam, 2019, NEURIPS
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petrovic S., 2013, ACL 2, P228
   Qi Di, 2020, ARXIV200107966
   Quora, 2017, QUOR QUEST PAIRS KAG
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C., 2019, ABS191010683 ARXIV
   Resnik P., 2009, 2009 C EMPIRICAL MET, P381
   Roller S., 2020, ARXIV PREPRINT ARXIV
   Sanh Victor, 2019, ARXIV191001108
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234
   SHAGASS C, 1976, ARCH GEN PSYCHIAT, V33, P121
   SHANGIPOURATAEI T, 2020, P 2 WORKSH FIG LANG, P67, DOI DOI 10.18653/V1/2020.FIGLANG-1.9
   Shao TH, 2019, IEEE ACCESS, V7, P26146, DOI 10.1109/ACCESS.2019.2900753
   Shleifer, 2019, ARXIV PREPRINT ARXIV
   Stephens, 2002, WHAT HAS LOEBNER CON
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Sun L., 2020, ARXIV200715789
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Virkar M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P891, DOI [10.1109/ICCS45141.2019.9065723, 10.1109/iccs45141.2019.9065723]
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Wang CC, 2019, MULTIMED TOOLS APPL, V78, P4813, DOI 10.1007/s11042-018-5754-6
   Wang Quan, 2019, ARXIV191102168
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang, 2018, ARXIV PREPRINT ARXIV
NR 70
TC 3
Z9 3
U1 5
U2 30
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD 2021 AUG 23
PY 2021
DI 10.1007/s12652-021-03439-8
EA AUG 2021
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UD9TX
UT WOS:000687544000004
OA hybrid, Green Accepted, Green Submitted
DA 2023-11-10
ER

PT J
AU Vázquez, R
   Raganato, A
   Creutz, M
   Tiedemann, J
AF Vazquez, Raul
   Raganato, Alessandro
   Creutz, Mathias
   Tiedemann, Jorg
TI A Systematic Study of Inner-Attention-Based Sentence Representations in
   Multilingual Neural Machine Translation
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Neural machine translation has considerably improved the quality of automatic translations by learning good representations of input sentences. In this article, we explore a multilingual translation model capable of producing fixed-size sentence representations by incorporating an intermediate crosslingual shared layer, which we refer to as attention bridge. This layer exploits the semantics from each language and develops into a language-agnostic meaning representation that can be efficiently used for transfer learning. We systematically study the impact of the size of the attention bridge and the effect of including additional languages in the model. In contrast to related previous work, we demonstrate that there is no conflict between translation performance and the use of sentence representations in downstream tasks. In particular, we show that larger intermediate layers not only improve translation quality, especially for long sentences, but also push the accuracy of trainable classification tasks. Nevertheless, shorter representations lead to increased compression that is beneficial in non-trainable similarity tasks. Similarly, we show that trainable downstream tasks benefit from multilingual models, whereas additional language signals do not improve performance in non-trainable benchmarks. This is an important insight that helps to properly design models for specific applications. Finally, we also include an in-depth analysis of the proposed attention bridge and its ability to encode linguistic properties. We carefully analyze the information that is captured by individual attention heads and identify interesting patterns that explain the performance of specific settings in linguistic probing tasks.
C1 [Vazquez, Raul; Raganato, Alessandro; Creutz, Mathias; Tiedemann, Jorg] Univ Helsinki, Dept Digital Humanities, Helsinki, Finland.
C3 University of Helsinki
RP Vázquez, R (通讯作者)，Univ Helsinki, Dept Digital Humanities, Helsinki, Finland.
EM raul.vazquez@helsinki.fi; alessandro.raganato@helsinki.fi;
   mathias.creutz@helsinki.fi; jorg.tiedemann@helsinki.fi
RI Creutz, Mathias/GXM-7723-2022; Raganato, Alessandro/AAQ-4197-2021
OI Raganato, Alessandro/0000-0002-7018-7515; Tiedemann,
   Jorg/0000-0003-3065-7989; Creutz, Mathias Johan
   Philip/0000-0003-1862-4172
FU European Research Council (ERC) under the European Union's Horizon 2020
   research and innovation programme [771113]; Academy of Finland [314062,
   270354, 273457]; NVIDIA and their GPU grant; Academy of Finland (AKA)
   [270354, 270354, 314062, 314062] Funding Source: Academy of Finland
   (AKA)
FX This work is part of the FoTran project, funded by the European Research
   Council (ERC) under the European Union's Horizon 2020 research and
   innovation programme (grant agreement no 771113). The authors gratefully
   acknowledge the support of the Academy of Finland through project 314062
   from the ICT 2023 call on Computation, Machine Learning and Artificial
   Intelligence and projects 270354 and 273457. Finally, we would also like
   to acknowledge CSC - IT Center for Science, Finland, for computational
   resources, as well as NVIDIA and their GPU grant.
CR Agirre E, 2016, P 10 INT WORKSH SEM, P497, DOI DOI 10.18653/V1/S16-1081
   Agirre E., 2013, P 2 JOINT C LEX COMP, V1, P32
   Agirre E., 2012, P 6 INT WORKSHOP SEM, P385
   Al-Onaizan Yaser, 2016, P 2016 C EMP METH NA, P268, DOI DOI 10.18653/V1/D16-1026
   [Anonymous], 2015, 3 INT C LEARN REPR I
   [Anonymous], 2017, P ACL 2017 SYST DEM
   [Anonymous], 2016, 4 INT C LEARN REPR I
   [Anonymous], 2017, P 2017 C EMP METH NA
   [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], 2018, P 3 C MACH TRANSL RE
   [Anonymous], 2017, 5 INT C LEARN REPR I
   [Anonymous], 2018, P 2018 C EMPIRICAL M
   Arora S., 2017, 5 INT C LEARN REPR I
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bau Anthony, 2019, 7 INT C LEARN REPR I
   Belinkov Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P861, DOI 10.18653/v1/P17-1080
   Bengio Y., 2017, 5 INT C LEARN REPR I
   Blackwood G, 2018, P 27 INT C COMP LING, P3112
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Bojar Ondej, 2018, P 3 C MACH TRANSL RE
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Britz D., 2017, P 2017 C EMP METH NA, P392, DOI [10.18653/v1/D17-1040, DOI 10.18653/V1/D17-1040]
   Callison-Burch Chris, 2007, P 2 WORKSH STAT MACH
   Cer D., 2017, P 11 INT WORKSHOP SE, P1, DOI [DOI 10.18653/V1/S17-2001, 10.1865/3v1/S17-2001]
   Chen Q., 2018, P 27 INT C COMP LING, P1815
   Chen Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1925, DOI 10.18653/v1/P17-1176
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Cifka O, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1362
   Conneau A., 2018, 6 INT C LEARN REPR I
   Conneau A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1699
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Conneau Alexis, 2018, EMNLP
   Dalvi F., 2017, P 8 INT JOINT C NATU, V1, P142
   Devlin J., 2018, ARXIV, V1, P4171
   Dolan B., 2004, P 20 INT C COMP LING, DOI DOI 10.3115/1220355.1220406
   Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723
   Dou ZY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4253
   Elliott D., 2016, P ACL 2016, P70
   Firat O., 2016, P 2016 C N AM CHAPT, P866
   Gehring J, 2017, PR MACH LEARN RES, V70
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI [10.18653/v1/n18, DOI 10.18653/V1/N18]
   Ha T.-L., 2016, P INT WORKSH SPOK LA
   Hill Felix, 2016, P NAACL HLT, P1367, DOI DOI 10.18653/V1/N16-1162
   Hu M., 2004, PROC 10 ACM SIGKDD I, P168, DOI DOI 10.1145/1014052.1014073
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Kingma D. P., 2014, C TRACK P
   Knight Kevin, 2016, ARXIV PREPRINT ARXIV, P30, DOI DOI 10.18653/V1/N16-1004
   Koehn P., 2005, MT SUMMIT, P79
   Koehn P., 2007, ANN M ASS COMP LING
   Lakew S.M., 2018, P 27 INT C COMP LING, P641, DOI DOI 10.48550/ARXIV.1806.06957
   Lee Jason, 2017, T ASSOC COMPUT LING, V5, P365, DOI 10.1162/tacl_a_00067
   Lee L., 2004, ASS COMPUTATIONAL LI, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Lu Y., 2018, P 3 C MACH TRANSL RE, P84, DOI DOI 10.18653/V1/W18-6309
   Luong M.-T., 2015, P 2015 C EMP METH NA, P1412, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Marelli M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Mihalcea Rada, 2015, P 9 INT WORKSH SEM E, DOI DOI 10.18653/V1/S15-2045
   Mikolov T., 2017, SHORT PAPERS, P427, DOI 10.18653/v1/e17
   Pham NT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P971
   Pang B., 2005, P ACL, P115, DOI DOI 10.3115/1219840.1219855
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Poliak A, 2018, P 2018 C N AM CHAPT, DOI [10.18653/v1/n18-2082, DOI 10.18653/V1/N18-2082]
   Reimers Nils, 2019, P 2019 C EMP METH NA, P3973
   Schwenk H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P228
   Schwenk Holger, 2017, P 2 WORKSH REPR LEAR, P157, DOI DOI 10.18653/V1/W17-2619
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shi X., 2016, P 2016 C EMP METH NA, P1526, DOI DOI 10.18653/V1/D16-1159
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Subramanian Sandeep, 2018, 6 INT C LEARN REPR I
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tao Chongyang, 2018, IJCAI, P4418
   Tu Z., 2017, T ASSOC COMPUT LING, Vvol. 5, P87
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Voorhees E. M., 2000, SIGIR Forum, V34, P200
   Wang YN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2955
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Wiebe J, 2014, P 8 INT WORKSH SEM E, P81, DOI [10.3115/v1/S14-2010, DOI 10.3115/V1/S14-2010]
NR 79
TC 5
Z9 5
U1 1
U2 13
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 2020
VL 46
IS 2
BP 387
EP 424
DI 10.1162/coli_a_00377
PG 38
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA ME9JR
UT WOS:000544970400005
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Peer, D
   Stabinger, S
   Engl, S
   Rodríguez-Sánchez, A
AF Peer, David
   Stabinger, Sebastian
   Engl, Stefan
   Rodriguez-Sanchez, Antonio
TI Greedy-layer pruning: Speeding up transformer models for natural
   language processing
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Natural language processing; Transformer models; Pruning; Knwoledge
   distillation
AB Fine-tuning transformer models after unsupervised pre-training reaches a very high performance on many different natural language processing tasks. Unfortunately, transformers suffer from long inference times which greatly increases costs in production. One possible solution is to use knowledge distilla-tion, which solves this problem by transferring information from large teacher models to smaller student models. Knowledge distillation maintains high performance and reaches high compression rates, never-theless, the size of the student model is fixed after pre-training and can not be changed individually for a given downstream task and use-case to reach a desired performance/speedup ratio. Another solution to reduce the size of models in a much more fine-grained and computationally cheaper fashion is to prune layers after the pre-training. The price to pay is that the performance of layer-wise pruning algorithms is not on par with state-of-the-art knowledge distillation methods. In this paper, Greedy-layer pruning is introduced to (1) outperform current state-of-the-art for layer-wise pruning, (2) close the performance gap when compared to knowledge distillation, while (3) providing a method to adapt the model size dy-namically to reach a desired performance/speedup tradeoff without the need of additional pre-training phases. Our source code is available on https://github.com/deepopinion/greedy- layer-pruning .(c) 2022 Elsevier B.V. All rights reserved.
C1 [Peer, David; Stabinger, Sebastian; Engl, Stefan] DeepOpinion, Bozner Pl 1-9, A-6020 Innsbruck, Austria.
   [Peer, David; Stabinger, Sebastian; Rodriguez-Sanchez, Antonio] Univ Innsbruck, Technikerstr 21a, A-6020 Innsbruck, Austria.
C3 University of Innsbruck
RP Peer, D (通讯作者)，DeepOpinion, Bozner Pl 1-9, A-6020 Innsbruck, Austria.; Peer, D (通讯作者)，Univ Innsbruck, Technikerstr 21a, A-6020 Innsbruck, Austria.
EM david.peer@deepopinion.ai
RI Engblom, Stefan/O-8246-2019
OI Engblom, Stefan/0000-0002-3614-1732; Peer, David/0000-0001-9028-0920
CR Bentivogli Luisa, 2009, 5 PASCAL RECOGNIZING
   Cer D., 2017, P 11 INT WORKSHOP SE, P1, DOI [DOI 10.18653/V1/S17-2001, 10.1865/3v1/S17-2001]
   Devlin J., NAACL HLT, P4171, DOI 10.18653/v1/N19-1423
   Dolan B., 2005, 3 INT WORKSHOP PARAP
   Fan Angela, 2020, INT C LEARN REPR
   Fang Y., 2020, P 2020 C EMP METH NA, P498
   Ganesh P, 2021, T ASSOC COMPUT LING, V9, P1061, DOI 10.1162/tacl_a_00413
   Goceri E, 2020, IET IMAGE PROCESS, V14, P882, DOI 10.1049/iet-ipr.2019.0312
   Goceri E, 2019, INT J NUMER METH BIO, V35, DOI 10.1002/cnm.3225
   Izsak P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10644
   Jiao X., 2020, FINDINGS ASS COMPUTA, P4163, DOI [10.18653/v1/2020.findings-emnlp.372, DOI 10.18653/V1/2020.FINDINGS-EMNLP.372, 10.18653/v1/2020. findings-emnlp.372. URL]
   Kervadec H., 2019, ARXIV PREPRINT ARXIV
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Loshchilov I, 2018, DECOUPLED WEIGHT DEC
   Michel Paul, 2019, ADV NEURAL INFORM PR, P14014
   Peer D, 2021, IEEE WINT CONF APPL, P256, DOI 10.1109/WACV48630.2021.00030
   Peer D, 2021, PATTERN RECOGN LETT, V144, P68, DOI 10.1016/j.patrec.2021.01.017
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Rouhou A.C., PATTERN RECOGN LETT
   Sajjad Hassan, 2020, ARXIV200403844
   Sanh Victor, 2019, ARXIV191001108
   Shi Y, 2021, PATTERN RECOGN LETT, V149, P150, DOI 10.1016/j.patrec.2021.06.012
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4323
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]
   Warstadt A., 2018, ARXIV PREPRINT ARXIV
   Williams A, 2018, P 2018 C N AM CHAPTE, P1112, DOI 10.18653/v1/N18-1101
   Worsham J, 2020, PATTERN RECOGN LETT, V136, P120, DOI 10.1016/j.patrec.2020.05.031
   Zhang Z., 2021, OPEN, V2, P36
NR 31
TC 2
Z9 2
U1 4
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD MAY
PY 2022
VL 157
BP 76
EP 82
DI 10.1016/j.patrec.2022.03.023
EA APR 2022
PG 7
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QR
UT WOS:000783928500001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Li, LX
   Li, J
   Xu, YH
   Zhu, H
   Zhang, XF
AF Li, Lixuan
   Li, Jie
   Xu, Yihui
   Zhu, Hao
   Zhang, Xiaofang
TI Enhancing Code Summarization with Graph Embedding and Pre-trained Model
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article; Early Access
DE Code summarization; pre-trained model; code structure; deep learning
AB Code summarization is a task that aims at automatically producing descriptions of source code. Recently many deep-learning-based approaches have been proposed to generate accurate code summaries, among which pre-trained models (PTMs) for programming languages have achieved promising results. It is well known that source code written in programming languages is highly structured and unambiguous. Though previous work pre-trained the model with well-design tasks to learn universal representation from a large scale of data, they have not considered structure information during the fine-tuning stage. To make full use of both the pre-trained programming language model and the structure information of source code, we utilize Flow-Augmented Abstract Syntax Tree (FA-AST) of source code for structure information and propose GraphPLBART - Graph-augmented Programming Language and Bi-directional Auto-Regressive Transformer, which can effectively introduce structure information to a well PTM through a cross attention layer. Compared with the best-performing baselines, GraphPLBART still improves by 3.2%, 7.1%, and 1.2% in terms of BLEU, METEOR, and ROUGE-L, respectively, on Java dataset, and also improves by 4.0%, 6.3%, and 2.1% on Python dataset. Further experiment shows that the structure information from FA-AST has significant benefits for the performance of GraphPLBART. In addition, our meticulous manual evaluation experiment further reinforces the superiority of our proposed approach. This demonstrates its remarkable abstract quality and solidifies its position as a promising solution in the field of code summarization.
C1 [Li, Lixuan; Li, Jie; Xu, Yihui; Zhu, Hao; Zhang, Xiaofang] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
C3 Soochow University - China
RP Zhang, XF (通讯作者)，Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
EM li_lixuan@outlook.com; 2027407061@stu.suda.edu.cn;
   20234227080@stu.suda.edu.cn; 2027406032@stu.suda.edu.cn;
   xfzhang@suda.edu.cn
FU National Natural Science Foundation of China [62172202]; Collaborative
   Innovation Center of Novel Software Technology and Industrialization;
   Major Program of the Natural Science Foundation of Jiangsu Higher
   Education Institutions of China [22KJA520008]; Priority Academic Program
   Development of Jiangsu Higher Education Institutions; Undergraduate
   Training Program for Innovation and Entrepreneurship, Soochow University
   [202210285197H]
FX This work is partially supported by the National Natural Science
   Foundation of China (62172202), Collaborative Innovation Center of Novel
   Software Technology and Industrialization, the Major Program of the
   Natural Science Foundation of Jiangsu Higher Education Institutions of
   China under Grant No. 22KJA520008, the Priority Academic Program
   Development of Jiangsu Higher Education Institutions, and the
   Undergraduate Training Program for Innovation and Entrepreneurship,
   Soochow University (202210285197H).
CR Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655
   Ahmad Wasi Uddin, 2020, P 58 ANN M ASS COMP, P4998
   Alon U, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3290353
   An B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P236
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, P65, DOI DOI 10.3115/1626355.1626389
   Choi Y., 2021, FINDINGS ASS COMPUTA, P2842
   Chunrong Fang, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P516, DOI 10.1145/3395363.3397362
   Clark K, 2020, Arxiv, DOI arXiv:2003.10555
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Feng Zhangyin, 2020, FIND ASS COMP LING E, P1536, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.139
   Gao SZ, 2023, ACM T SOFTW ENG METH, V32, DOI 10.1145/3522674
   Gao YX, 2022, INT C PROGRAM COMPRE, P24, DOI 10.1145/3524610.3527907
   Guo DY, 2021, Arxiv, DOI arXiv:2009.08366
   Guo QP, 2020, AAAI CONF ARTIF INTE, V34, P7847
   Hu X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2269
   Hu X, 2018, INT C PROGRAM COMPRE, P200, DOI 10.1145/3196321.3196334
   Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073
   Kudo T, 2018, Arxiv, DOI arXiv:1808.06226
   Li YJ, 2017, Arxiv, DOI arXiv:1511.05493
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Raffel C, 2020, J MACH LEARN RES, V21
   See A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1704.04368
   Sun ZY, 2020, AAAI CONF ARTIF INTE, V34, P8984
   Taud H., 2018, GEOMATIC APPROACHES, P451
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan Y, 2018, IEEE INT CONF AUTOM, P397, DOI 10.1145/3238147.3238206
   Wang WH, 2020, PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER '20), P261, DOI [10.1109/SANER48275.2020.9054857, 10.1109/saner48275.2020.9054857]
   Wang Y, 2022, INT C PROGRAM COMPRE, P12, DOI 10.1145/3524610.3527903
   Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696
   Wei BL, 2019, ADV NEUR IN, V32
   Wu H., 2021, FINDINGS ASS COMPUTA, P1078, DOI 10.18653/v1/2021.findings-acl.93
NR 33
TC 0
Z9 0
U1 0
U2 0
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD 2023 OCT 12
PY 2023
DI 10.1142/S0218194023410024
EA OCT 2023
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4NU5
UT WOS:001084591200002
DA 2023-11-10
ER

PT J
AU Flor, M
AF Flor, Michael
TI A fast and flexible architecture for very large word n-gram datasets
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
AB This paper presents TrendStream, a versatile architecture for very large word n-gram datasets. Designed for speed, flexibility, and portability, TrendStream uses a novel trie-based architecture, features lossless compression, and provides optimization for both speed and memory use. In addition to literal queries, it also supports fast pattern matching searches (with wildcards or regular expressions), on the same data structure, without any additional indexing. Language models are updateable directly in the compiled binary format, allowing rapid encoding of existing tabulated collections, incremental generation of n-gram models from streaming text, and merging of encoded compiled files. This architecture offers flexible choices for loading and memory utilization: fast memory-mapping of a multi-gigabyte model, or on-demand partial data loading with very modest memory requirements. The implemented system runs successfully on several different platforms, under different operating systems, even when the n-gram model file is much larger than available memory. Experimental evaluation results are presented with the Google Web1T collection and the Gigaword corpus.
C1 Educ Testing Serv, NLP & Speech Grp, Princeton, NJ 08541 USA.
C3 Educational Testing Service (ETS)
RP Flor, M (通讯作者)，Educ Testing Serv, NLP & Speech Grp, Princeton, NJ 08541 USA.
EM mflor@ets.org
RI Flor, Michael/HME-2980-2023
OI Flor, Michael/0000-0002-3320-5729
CR [Anonymous], P NAACL HLT WORKSH S
   [Anonymous], 2004, P 15 ANN ACM SIAM S
   [Anonymous], 2007, EMNLP CONLL 2007 P 2
   [Anonymous], 2002, P INT C SPOKEN LANGU
   [Anonymous], 2007, P 2007 JOINT C EMPIR
   [Anonymous], 2006, WEB IT 5 GRAM VERSIO
   [Anonymous], 2003, ENGLISH GIGAWORD
   [Anonymous], 2015, PROC 18 ACM C INF KN
   [Anonymous], HUMAN LANGUAGE TECHN
   BENTLEY J, 1998, DOBBS J
   Bentley JL, 1997, PROCEEDINGS OF THE EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P360
   Bergsma S, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1507
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Carlson A, 2007, ICMLA 2007: SIXTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/ICMLA.2007.50
   Ceylan H., 2011, ACL SYSTEM DEMONSTRA, P103
   Church K., 2007, P 2007 JOINT C EMP M, P199
   Emami A, 2007, INT CONF ACOUST SPEE, P37
   Evert S., 2010, P NAACL HLT 2010 6 W, P32
   FEDERICO M, 2007, P 2 WORKSH STAT MACH, P88
   FREDKIN E, 1960, COMMUN ACM, V3, P490, DOI 10.1145/367390.367400
   Futagi Yoko, 2010, P 4 WORKSH AN NOIS U, P27
   Giuliano C., 2007, JWEBIT LIB SEARCHING
   Guthrie D., 2010, P 2010 C EMP METH NA, P262
   Guthrie D., 2010, P SIGIR 2010 WEB N G, P21
   Harb B., 2009, P 10 ANN C INT SPEEC, P325
   Hawker T., 2007, P AUSTR LANG TECHN W, P40
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Islam A., 2009, SEMICONDUCTOR DEVICE, P1, DOI 10.1109/NLPKE.2009.5313823
   Lapata M., 2005, ACM T SPEECH LANG PR, V2, P3
   Levenberg A., 2009, P 2009 C EMP METH NA, P756
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   Pauls A, 2011, P 49 ANN M ASS COMPU, P258
   Raj Bhiksha, 2003, ICASSP, P388
   RAVISHANKAR MK, 1996, CMUCS96143
   Sekine S., 2008, P 22 INT C COMP LING, P181
   Sekine S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2682
   Talbot D., 2008, P ACL 08 HLT COL OH, P505
   Talbot D, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1243
   Talbot David, 2007, P 45 ANN M ASS COMP, P512
   Van Durme B, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1574
   Wang KS, 2009, INT CONF ACOUST SPEE, P4733, DOI 10.1109/ICASSP.2009.4960688
   Watanabe Taro, 2009, IJCNLP, P341
   Whittaker E. W. D., 2001, P 7 EUR C SPEECH COM, P33
   YURET D, 2008, P 46 ANN M ASS COMP, P141
NR 44
TC 1
Z9 2
U1 0
U2 1
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JAN
PY 2013
VL 19
IS 1
BP 61
EP 93
DI 10.1017/S1351324911000349
PG 33
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 045HP
UT WOS:000311686300003
DA 2023-11-10
ER

PT S
AU Hahn, U
   Wermter, J
AF Hahn, U
   Wermter, J
BE Zhang, C
   Guesgen, HW
   Yeap, WK
TI Tagging medical documents with high accuracy
SO PRICAI 2004: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 8th Pacific Rim International Conference on Artificial Intelligence
   (PRICAI 2004)
CY AUG 09-13, 2004
CL Auckland, NEW ZEALAND
SP Univ Auckland, Inst Informat Technol Res, USAF Off Sci Res, Asian Off Aerosp Res & Dev, Auckland Univ Technol, Franz Inc
AB We ran both Brill's rule-based tagger and TNT, a statistical tagger, with a default German newspaper-language model on a medical text corpus. Supplied with limited lexicon resources, TNT outperforms the Brill tagger with state-of-the-art performance figures (close to 97% accuracy). We then trained TNT on a large annotated medical text corpus, with a slightly extended tagset that captures certain medical language particularities, and achieved 98% tagging accuracy. Hence, statistical off-the-shelf POS taggers cannot only be immediately reused for medical NLP, but they also achieve - when trained on medical corpora - a higher performance level than for the newspaper genre.
C1 Univ Jena, Text Knowledge Engn Lab, D-07743 Jena, Germany.
C3 Friedrich Schiller University of Jena
RP Hahn, U (通讯作者)，Univ Jena, Text Knowledge Engn Lab, Furstengraben 30, D-07743 Jena, Germany.
EM hahn@coling.uni-freiburg.de
CR Brants T, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P224
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Campbell DA, 2001, J AM MED INFORM ASSN, P90
   Friedman C, 1999, ACAD MED, V74, P890, DOI 10.1097/00001888-199908000-00012
   GIMENEZ J, 2003, P INT C REC ADV NAT
   Kilgarriff A., 2001, INT J CORPUS LINGUIS, V6, P97, DOI [DOI 10.1075/IJCL.6.1.05KIL, 10.1075/ijcl.6.1.05kil]
   Marcus MP., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Ratnaparkhi A., 1996, P C EMP METH NAT LAN, V1, P133
   SAMUELSSON C, 1997, P 35 ANN M ASS COMP, P246
   Skut W, 2002, P 5 C APPL NAT LANG, DOI 10.3115/974557.974571
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   WERMTER J, 2004, P 4 INT LREC C LISB
NR 12
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-22817-9
J9 LECT NOTES ARTIF INT
PY 2004
VL 3157
BP 852
EP 861
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BAU59
UT WOS:000223633300090
DA 2023-11-10
ER

PT J
AU Xu, F
   Dan, YJ
   Yan, KY
   Ma, Y
   Wang, MW
AF Xu, Fan
   Dan, Yangjie
   Yan, Keyu
   Ma, Yong
   Wang, Mingwen
TI Low-Resource Language Discrimination toward Chinese Dialects with
   Transfer Learning and Data Augmentation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Low-resource; chinese dialects; dialects discrimination; transfer
   learning; data augmentation
AB Chinese dialects discrimination is a challenging natural language processing task due to scarce annotation resource. In this article, we develop a novel Chinese dialects discrimination framework with transfer learning and data augmentation (CDDTLDA) in order to overcome the shortage of resources. To be more specific, we first use a relatively larger Chinese dialects corpus to train a source-side automatic speech recognition (ASR) model. Then, we adopt a simple but effective data augmentation method (i.e., speed, pitch, and noise disturbance) to augment the target-side low-resource Chinese dialects, and fine-tune another target ASR model based on the previous source-side ASR model. Meanwhile, the potential common semantic features between source-side and target-side ASR models can be captured by using self-attention mechanism. Finally, we extract the hidden semantic representation in the target ASR model to conduct Chinese dialects discrimination. Our extensive experimental results demonstrate that our model significantly outperforms state-of-the-art methods on two benchmark Chinese dialects corpora.
C1 [Xu, Fan; Dan, Yangjie; Yan, Keyu; Ma, Yong; Wang, Mingwen] Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
C3 Jiangxi Normal University
RP Wang, MW (通讯作者)，Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
EM xufan@jxnu.edu.cn; 2314872656@qq.com; 156183394@qq.com;
   1259993675@qq.com; mwwang@jxnu.edu.cn
RI Yan, Keyu/IXX-0343-2023; yan, keyu/GXW-2126-2022
FU National Natural Science Foundation of China (NSFC) [61772246, 62162031,
   62066020, 61876074]; Natural Science Foundation of Jiangxi Province
   [20192ACBL21030, 20192AE191005]
FX This research was supported by the National Natural Science Foundation
   of China (NSFC) under Grant 61772246, 62162031, 62066020, and 61876074,
   Natural Science Foundation of Jiangxi Province under Grant
   20192ACBL21030 and 20192AE191005.
CR [Anonymous], 2006, J QUANT LINGUIST, DOI DOI 10.1080/09296170500500694
   [Anonymous], 2013, P 51 ANN M ASS COMPU
   [Anonymous], 2016, P 3 WORKSH NLP SIM L
   [Anonymous], 2014, P 1 WORKSH APPL NLP, DOI DOI 10.3115/V1/W14-5316
   Dai W, 2007, P 24 INT C MACH LEAR, P193, DOI [DOI 10.1145/1273496.1273521, 10.1145/1273496.1273521]
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dehak N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P864
   Dras M, 2015, P PAC ASS COMP LING, P53
   Etienne Caroline, 2018, P WORKSH SPEECH MUS
   Gomez-Adorno H., 2017, P 4 WORKSH NLP SIM L, P137
   GREFENSTETTE G, 1995, P 3 INT C STAT AN TE
   IFLYTEK, 2018, RANK LIST IFLYTEK WO
   IFLYTEK, 2018, IFLYTEK WORLD WID CO
   Jauhiainen T, 2019, J ARTIF INTELL RES, V65, P675
   Jia Y, 2018, ADV NEUR IN, V31
   Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3
   Ljubesic N, 2015, INFORM-J COMPUT INFO, V39, P1
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Ren Yi, 2019, P 36 INT C MACH LEAR
   Sgouropoulos Dimitris, 2019, P C INT SPEECH COMM
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simoes A., 2014, P 3 S LANG APPL TECH, P251, DOI DOI 10.4230/OASICS.SLATE.2014.251
   Snyder David, 2018, P OD 2018 SPEAK LANG
   Su JS, 2021, IEEE T PATTERN ANAL, V43, P1530, DOI 10.1109/TPAMI.2019.2954406
   Tiedemann Jorg, 2012, P INT C COMP LING
   Wang Y., 2018, P INT C MACH LEARN, P5123
   Wu N., 2019, P 6 WORKSH NLP SIM L, P54, DOI DOI 10.18653/V1/W19-1406
   Xu F, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3389021
   Xu Fan, 2015, P JOINT WORKSH LANG, P85
   Xu Fan, 2018, P 11 INT C LANG RES
   Zampieri M., 2017, VARDIAL, V2017, P1, DOI DOI 10.18653/v1/W17-1201
   Zampieri M., 2019, P 6 WORKSH NLP SIM L, P1, DOI DOI 10.18653/V1/W19-1401
   Zeng JL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P447
   Zeng JL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P845
   Zhang B, 2019, IEEE-ACM T AUDIO SPE, V27, P2278, DOI 10.1109/TASLP.2019.2946480
NR 37
TC 0
Z9 0
U1 3
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR
PY 2022
VL 21
IS 2
AR 27
DI 10.1145/3473499
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0C7CH
UT WOS:000775466500006
DA 2023-11-10
ER

PT J
AU Cui, LC
   Li, YM
AF Cui, Licong
   Li, Yongming
TI Linguistic quantifiers based on Choquet integrals
SO INTERNATIONAL JOURNAL OF APPROXIMATE REASONING
LA English
DT Article
DE knowledge representation and reasoning; fuzzy logic; fuzzy
   quantification; quantifier; fuzzy measure; Choquet integral
ID FUZZY QUANTIFIERS; AGGREGATION OPERATORS; CARDINALITY; PROPOSITIONS;
   LANGUAGE
AB The introduction of linguistic quantifiers has provided an important tool to model a large number of issues in intelligent systems. Ying [M.S. Ying, Linguistic quantifiers modeled by Sugeno integrals, Artificial Intelligence 170 (2006) 581-606] recently introduced a new framework for modeling quantifiers in natural languages in which each linguistic quantifier is represented by a family of fuzzy measures, and the truth value of a quantified proposition is evaluated by using Sugeno's integral. Representing linguistic quantifiers by fuzzy measures, this paper evaluates linguistic quantified propositions by the Choquet integral. Some elegant logical properties of linguistic quantifiers are derived within this approach, including a prenex normal form theorem stronger than that in Ying's model. In addition, our Choquet integral approach to the evaluation of quantified statements is compared with others, in particular with Ying's Sugeno integral approach. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Cui, Licong; Li, Yongming] Shaanxi Normal Univ, Coll Math & Informat Sci, Xian 710062, Peoples R China.
   [Li, Yongming] Shaanxi Normal Univ, Coll Comp Sci, Xian 710062, Peoples R China.
C3 Shaanxi Normal University; Shaanxi Normal University
RP Cui, LC (通讯作者)，Shaanxi Normal Univ, Coll Math & Informat Sci, Xian 710062, Peoples R China.
EM cuilicong@stu.snnu.edu.cn; liyongm@snuu.edu.cn
RI li, yongming/F-8379-2016
OI li, yongming/0000-0001-8038-008X; Cui, Licong/0000-0001-5549-8780
CR Barrat A, 2003, EUR PHYS J E, V11, P99, DOI 10.1140/epje/i2002-10149-2
   BARWISE J, 1981, LINGUIST PHILOS, V4, P159, DOI 10.1007/BF00350139
   BOSC P, 1994, P NAFIPS IFIS NASA C, P8
   CARMONA MJB, 1989, FUZZY SET SYST, V33, P201, DOI 10.1016/0165-0114(89)90241-8
   Delgado M, 2000, INT J APPROX REASON, V23, P23, DOI 10.1016/S0888-613X(99)00031-6
   DUBOIS D, 1985, FUZZY SET SYST, V16, P199, DOI 10.1016/0165-0114(85)90025-9
   Glöckner I, 2004, INT J APPROX REASON, V37, P93, DOI 10.1016/j.ijar.2003.09.005
   GLOCKNER I, 1999, TR9903 U BIEL
   GLOCKNER I, 2006, STUDIES FUZZINESS SO, V193
   Glockner I, 1997, TR9706 U BIEL
   IBANEZ LMD, 1989, FUZZY SET SYST, V31, P23, DOI 10.1016/0165-0114(89)90064-X
   Iourinski D, 2003, NAFIPS'2003: 22ND INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS PROCEEDINGS, P444
   KACPRZYK J, 1986, IEEE T SYST MAN CYB, V16, P474, DOI 10.1109/TSMC.1986.4308982
   Keenan EL, 2002, LINGUIST PHILOS, V25, P627, DOI 10.1023/A:1020803514176
   Klement E.P., 2000, TRIANGULAR NORMS
   Lawry J, 2004, ARTIF INTELL, V155, P1, DOI 10.1016/j.artint.2003.10.001
   Lawry J, 2001, INT J APPROX REASON, V28, P51, DOI 10.1016/S0888-613X(01)00042-1
   LINDSTROM P, 1966, THEORIA, V32, P186
   Liu YX, 1998, FUZZY SET SYST, V95, P1, DOI 10.1016/S0165-0114(97)00254-6
   Liu YX, 1998, FUZZY SET SYST, V95, P135, DOI 10.1016/S0165-0114(97)00255-8
   Modave F, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P1068, DOI 10.1109/FUZZ.2001.1008838
   Mostowski Andrzej., 1957, FUND MATH, V44, P12, DOI [10.4064/fm-44-1-12-36, DOI 10.4064/FM-44-1-12-36]
   MUROFUSHI T, 1993, FUZZY SET SYST, V56, P229, DOI 10.1016/0165-0114(93)90148-B
   MUROFUSHI T, 1989, FUZZY SET SYST, V29, P201, DOI 10.1016/0165-0114(89)90194-2
   PEI LW, 1993, TYPICAL PROBLEMS MET
   RALESCU D, 1995, FUZZY SET SYST, V69, P355, DOI 10.1016/0165-0114(94)00177-9
   Schwartz DG, 1997, ARTIF INTELL, V93, P103, DOI 10.1016/S0004-3702(97)00020-9
   Smolíková R, 2002, FUZZY SET SYST, V131, P23, DOI 10.1016/S0165-0114(01)00252-4
   Sugeno M., 1974, THESIS TOKYO I TECHN
   Van Eijck J, 1985, GEN QUANTIFIERS THEO
   VANBENTHEM J, 1984, J SYMBOLIC LOGIC, V49, P443, DOI 10.2307/2274176
   YAGER RR, 1983, INT J MAN MACH STUD, V19, P195, DOI 10.1016/S0020-7373(83)80056-X
   YAGER RR, 1991, FUZZY SET SYST, V40, P39, DOI 10.1016/0165-0114(91)90046-S
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M
   YAGER RR, 1994, INT J INTELL SYST, V9, P541, DOI 10.1002/int.4550090604
   YAGER RR, 1984, INT J MAN MACH STUD, V21, P389, DOI 10.1016/S0020-7373(84)80066-8
   Ying M. S., 1986, Proceedings of the Sixteenth International Symposium on Multiple-Valued Logic (Cat. No.86CH2289-7), P242
   Ying MS, 2006, ARTIF INTELL, V170, P581, DOI 10.1016/j.artint.2006.02.001
   ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5
   ZADEH LA, 1978, INT J MAN MACH STUD, V10, P395, DOI 10.1016/S0020-7373(78)80003-0
   [No title captured]
NR 42
TC 12
Z9 12
U1 0
U2 2
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0888-613X
EI 1873-4731
J9 INT J APPROX REASON
JI Int. J. Approx. Reasoning
PD JUN
PY 2008
VL 48
IS 2
BP 559
EP 582
DI 10.1016/j.ijar.2007.11.001
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 311NK
UT WOS:000256606700013
OA hybrid
DA 2023-11-10
ER

PT J
AU Liu, J
   Zhang, XX
AF Liu, Jian
   Zhang, X. X.
TI Modeling fuzzy relational database in HBase
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE HBase; fuzzy relational data; modeling; mapping
ID UNCERTAIN-INFORMATION
AB With the increase of massive data, a large number of business applications began to seek effective and scalable frameworks for data storages and processing. Under this background, emerging technologies for big data, such as Hadoop-based systems that use scalable distributed storage system HBase, become available. Since most of business data nowadays are stored in relational databases, and information imprecision and uncertainty widely exist in real-world applications, there is an increasing willingness to manage large-scale fuzzy relational data in the Hadoop-based platform. This paper concentrates on fuzzy information modeling in HBase. In particular, we investigate the formal transformation from the fuzzy relational data model to the HBase model and develop a set of mapping rules to assist in the transformation process. In addition, we present a generic approach to transform the fuzzy relational algebra into the fuzzy HBase manipulation language.
C1 [Liu, Jian] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Zhang, X. X.] Northeastern Univ, Shenyang, Peoples R China.
C3 Harbin Institute of Technology; Northeastern University - China
RP Liu, J (通讯作者)，Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM jianliu@hit.edu.cn
FU China Postdoctoral Science Foundation [2015M581449, 2016T90294];
   Heilongjiang Postdoctoral Fund [LBH-Z14089]; Natural Science Foundation
   of Heilongjiang Province of China [QC2015067]; Fundamental Research
   Funds for the Central Universities [HIT.NSRIF.2017036]
FX The authors would also like to express their gratitude to the anonymous
   reviewers for providing very helpful suggestions. The work was partially
   supported by the China Postdoctoral Science Foundation funded project
   (2015M581449 and 2016T90294), Heilongjiang Postdoctoral Fund
   (LBH-Z14089), Natural Science Foundation of Heilongjiang Province of
   China (QC2015067), and Fundamental Research Funds for the Central
   Universities (HIT.NSRIF.2017036).
CR [Anonymous], 1997, UNCERTAINTY MANAGEME, DOI DOI 10.1007/978-1-4615-6245-0_8
   [Anonymous], 2011, P 20 ACM INT C INFOR, DOI DOI 10.1145/2063576.2063973
   BARBARA D, 1992, IEEE T KNOWL DATA EN, V4, P487, DOI 10.1109/69.166990
   Cattell R, 2010, SIGMOD REC, V39, P12, DOI 10.1145/1978915.1978919
   Cavallo R., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB, P71
   Chang F, 2006, USENIX ASSOCIATION 7TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P205
   Chattopadhyay B, 2011, PROC VLDB ENDOW, V4, P1318
   CODD EF, 1970, COMMUN ACM, V13, P377, DOI 10.1145/357980.358007
   DeCandia Giuseppe, 2007, Operating Systems Review, V41, P205, DOI 10.1145/1323293.1294281
   Galindo J., 1998, INT C FLEX QUER ANSW, P164
   Gao Xiaoming, 2011, P 1 ANN 11 ACM WORKS, P25, DOI [10.1145/2125636.2125646, DOI 10.1145/2125636.2125646]
   Hsieh NC, 2005, INT J INTELL SYST, V20, P647, DOI 10.1002/int.20088
   Huang C.-C., 2012, P INT C INF APPL, P480
   Kaltman R, 2008, PROC VLDB ENDOW, V1, P1496, DOI 10.14778/1454159.1454211
   LI Jing-min, 2010, 2 INT C INF SCI ENG, P1417
   Li Y., 2014, STUDIES FUZZINESS SO, V311, P1
   Liu J, 2013, APPL INTELL, V39, P386, DOI 10.1007/s10489-012-0419-z
   Liu J, 2013, APPL INTELL, V38, P541, DOI 10.1007/s10489-012-0386-4
   Lo A, 2010, J INTELL INF SYST, V35, P21, DOI 10.1007/s10844-009-0087-6
   Pei J., 2007, PROC 33TH INT C VERY, P15
   Pin-Shan Chen P., 1976, ACM Transactions on Database Systems, V1, P9, DOI 10.1145/320434.320440
   PRADE H, 1984, INFORM SCIENCES, V34, P115, DOI 10.1016/0020-0255(84)90020-3
   Rabl T, 2012, PROC VLDB ENDOW, V5, P1724, DOI 10.14778/2367502.2367512
   RAJU KVSVN, 1988, ACM T DATABASE SYST, V13, P129, DOI 10.1145/42338.42344
   Vila RR, 2013, PIXEL-BIT, P155, DOI [10.1007/978-3-642-38541-4_12, 10.12795/pixelbit.2013.i43.11]
   Suk Kyoon Lee, 1992, Very Large Data Bases. VLDB '92. Proceedings of the 18th International Conference on Very Large Data Bases, P211
   Vora M. N., 2011, Proceedings of the 2011 International Conference on Computer Science and Network Technology (ICCSNT), P601, DOI 10.1109/ICCSNT.2011.6182030
   Wang L., 2013, IEEE VEH TECHN C, P1, DOI DOI 10.1109/VTCFALL.2013.6692247
   Yazici A, 1999, IEEE T FUZZY SYST, V7, P659, DOI 10.1109/91.811232
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 30
TC 3
Z9 4
U1 1
U2 14
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2016
VL 31
IS 3
BP 1845
EP 1857
DI 10.3233/JIFS-15899
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DU9LY
UT WOS:000382540000062
DA 2023-11-10
ER

PT J
AU Kovács, L
   Vassilakis, C
AF Kovács, L
   Vassilakis, C
TI Function oriented history representation in databases
SO COMPUTERS AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE temporal databases; calendars; history; history algebra
ID QUERY LANGUAGE; MODELS
AB In the past years the management of temporal data has attracted numerous researchers resulting to a large number of temporal data extensions to the relational and object oriented data models. In this paper, the proposed temporal data model focuses on the functional characteristics of the histories. The paper introduces a set oriented description of the calendars together with a function oriented history concept with a history-algebra. The completeness of the proposed model with respect to the reduced temporal algebra TA is also proven. The expressive power of the proposed model is demonstrated in. the end of the paper by a hospital example.
C1 Univ Miskolc, Dept Informat Technol, H-3515 Miskolc Egyetemvaros, Hungary.
   Univ Athens, Dept Informat, GR-15771 Athens, Greece.
C3 University of Miskolc; National & Kapodistrian University of Athens
RP Kovács, L (通讯作者)，Univ Miskolc, Dept Informat Technol, H-3515 Miskolc Egyetemvaros, Hungary.
RI Costas, Vassilakis/AAH-5948-2019
OI Costas, Vassilakis/0000-0001-9940-1821
CR Bertino E., 1997, Theory and Practice of Object Systems, V3, P103, DOI 10.1002/(SICI)1096-9942(1997)3:2<103::AID-TAPO3>3.0.CO;2-W
   CATTELL RG, ODMG93
   Chiu JS, 1996, IEEE T KNOWL DATA EN, V8, P189, DOI 10.1109/69.485648
   CLIFFORD J, 1994, ACM T DATABASE SYST, V19, P64, DOI 10.1145/174638.174642
   ELMASRI R, 1990, PROCEEDINGS : 6TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING, P76
   GADIA SK, 1988, P ACM SIGMOD INT C M, P251
   Goh CH, 1996, DATA KNOWL ENG, V18, P147, DOI 10.1016/0169-023X(95)00034-P
   Gregersen H, 1999, IEEE T KNOWL DATA EN, V11, P464, DOI 10.1109/69.774104
   JENSEN C, 1993, 932034 R AALB U I EL
   KALUA P, 1993, 379 IND U COMP SCI D
   KURT A, 6 INT C WORKSH DAT E, P124
   Lee CK, 1998, MOD CHINA, V24, P3
   NAVATHE SB, 1989, INFORM SCIENCES, V49, P147, DOI 10.1016/0020-0255(89)90026-1
   ROSE E, 1993, 12 INT C ENT REL APP, P122
   SCHMIDT D, 1995, P INT WORKSH TEMP DA, P214
   SNODGRASS R, 1987, ACM T DATABASE SYST, V12, P247, DOI 10.1145/22952.22956
   SOTIROPOULOU A, 1998, P 3 BIENN WORLD C IN, V2, P304
   *TSQL2 LANG DES CO, 1995, TSQL2 TEMP QUER LANG
   Vassilakis C., 1996, Proceedings. Seventh International Workshop on Database and Expert Systems Applications, P153, DOI 10.1109/DEXA.1996.558289
   Vassilakis C, 1998, INFORM SYST, V23, P335, DOI 10.1016/S0306-4379(98)00015-5
NR 20
TC 0
Z9 0
U1 0
U2 0
PU SLOVAK ACADEMIC PRESS LTD
PI BRATISLAVA
PA PO BOX 57 NAM SLOBODY 6, 810 05 BRATISLAVA, SLOVAKIA
SN 0232-0274
J9 COMPUT ARTIF INTELL
JI Comput. Artif. Intell.
PY 2000
VL 19
IS 5
BP 417
EP 444
PG 28
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 394XC
UT WOS:000166548800002
DA 2023-11-10
ER

PT J
AU Mi, JP
   Liang, HZ
   Katsakis, N
   Tang, S
   Li, QD
   Zhang, CS
   Zhang, JW
AF Mi, Jinpeng
   Liang, Hongzhuo
   Katsakis, Nikolaos
   Tang, Song
   Li, Qingdu
   Zhang, Changshui
   Zhang, Jianwei
TI Intention-Related Natural Language Grounding via Object Affordance
   Detection and Intention Semantic Extraction
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE intention-related natural language grounding; object affordance
   detection; intention semantic extraction; multi-visual features;
   attention-based dynamic fusion
AB Similar to specific natural language instructions, intention-related natural language queries also play an essential role in our daily life communication. Inspired by the psychology term "affordance" and its applications in Human-Robot interaction, we propose an object affordance-based natural language visual grounding architecture to ground intention-related natural language queries. Formally, we first present an attention-based multi-visual features fusion network to detect object affordances from RGB images. While fusing deep visual features extracted from a pre-trained CNN model with deep texture features encoded by a deep texture encoding network, the presented object affordance detection network takes into account the interaction of the multi-visual features, and reserves the complementary nature of the different features by integrating attention weights learned from sparse representations of the multi-visual features. We train and validate the attention-based object affordance recognition network on a self-built dataset in which a large number of images originate from MSCOCO and ImageNet. Moreover, we introduce an intention semantic extraction module to extract intention semantics from intention-related natural language queries. Finally, we ground intention-related natural language queries by integrating the detected object affordances with the extracted intention semantics. We conduct extensive experiments to validate the performance of the object affordance detection network and the intention-related natural language queries grounding architecture.
C1 [Mi, Jinpeng; Tang, Song; Li, Qingdu] Univ Shanghai Sci & Technol, Inst Machine Intelligence IMI, Shanghai, Peoples R China.
   [Mi, Jinpeng; Liang, Hongzhuo; Tang, Song; Zhang, Jianwei] Univ Hamburg, Dept Informat, Tech Aspects Multimodal Syst, Hamburg, Germany.
   [Katsakis, Nikolaos] Univ Hamburg, Dept Informat, Human Comp Interact, Hamburg, Germany.
   [Zhang, Changshui] Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Hamburg;
   University of Hamburg; Tsinghua University
RP Tang, S (通讯作者)，Univ Shanghai Sci & Technol, Inst Machine Intelligence IMI, Shanghai, Peoples R China.; Tang, S (通讯作者)，Univ Hamburg, Dept Informat, Tech Aspects Multimodal Syst, Hamburg, Germany.
EM tang@informatik.uni-hamburg.de
RI Li, Qingdu/E-9396-2011; jin, li/IWU-4648-2023; zhan, y/ISA-2807-2023;
   zhang, jian/HPD-1712-2023
OI Li, Qingdu/0000-0001-9928-7272; Mi, Jinpeng/0000-0002-0506-9707
FU German Research Foundation (DFG); National Science Foundation (NSFC) in
   project Crossmodal Learning [Sonderforschungsbereich Transregio 169];
   DAAD German Academic Exchange Service under CASY project; National
   Natural Science Foundation of China [61773083]
FX This work was partly funded by the German Research Foundation (DFG) and
   National Science Foundation (NSFC) in project Crossmodal Learning under
   contract Sonderforschungsbereich Transregio 169, the DAAD German
   Academic Exchange Service under CASY project, and the National Natural
   Science Foundation of China (61773083).
CR Ahn H, 2018, IEEE ROBOT AUTOM LET, V3, P3308, DOI 10.1109/LRA.2018.2852786
   Alomari Muhannad, 2017, P 1 WORKSH LANG GROU, P35, DOI DOI 10.18653/V1/W17-2805
   Nguyen A, 2017, IEEE INT C INT ROBOT, P5908, DOI 10.1109/IROS.2017.8206484
   Nguyen A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2765, DOI 10.1109/IROS.2016.7759429
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bastianelli E, 2016, P 25 INT JOINT C ART, P2747
   Bell S, 2015, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR.2015.7298970
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Çelikkanat H, 2015, IEEE T AUTON MENT DE, V7, P92, DOI 10.1109/TAMD.2015.2418678
   Chen K, 2017, IEEE I CONF COMP VIS, P824, DOI 10.1109/ICCV.2017.95
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Conneau A, 2017, P C EMP METH NAT LAN, P670, DOI [10.18653/v1/d17-1070, DOI 10.18653/V1/D17-1070]
   Dehban A, 2016, IEEE INT CONF ROBOT, P4866, DOI 10.1109/ICRA.2016.7487691
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kim DI, 2014, IEEE INT CONF ROBOT, P5578, DOI 10.1109/ICRA.2014.6907679
   Liang HZ, 2019, IEEE INT CONF ROBOT, P3629, DOI [10.1109/icra.2019.8794435, 10.1109/ICRA.2019.8794435]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mi JP, 2019, COGN SYST RES, V54, P128, DOI 10.1016/j.cogsys.2018.12.010
   Myers A, 2015, IEEE INT CONF ROBOT, P1374, DOI 10.1109/ICRA.2015.7139369
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Norman Donald A., 1988, DESIGN EVERYDAY THIN
   Paul R, 2018, INT J ROBOT RES, V37, P1269, DOI 10.1177/0278364918777627
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Perkins J, 2010, COVERING DISASTER: LESSONS FROM MEDIA COVERAGE OF KATRINA AND RITA, P1
   Povey D., 2011, IEEE 2011 WORKSHOP A
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Roesler O, 2019, ACMIEEE INT CONF HUM, P307, DOI [10.1109/HRI.2019.8673121, 10.1109/hri.2019.8673121]
   Roy A, 2016, LECT NOTES COMPUT SC, V9908, P186, DOI 10.1007/978-3-319-46493-0_12
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sawatzky J, 2017, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2017.552
   Shridhar M, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HO, 2016, IEEE T AUTOM SCI ENG, V13, P798, DOI 10.1109/TASE.2015.2396014
   Sun Y, 2014, ROBOT AUTON SYST, V62, P487, DOI 10.1016/j.robot.2013.12.005
   Thermos S, 2017, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2017.13
   Thomason Jesse, 2019, 2019 International Conference on Robotics and Automation (ICRA), P6934, DOI 10.1109/ICRA.2019.8794287
   Thomason J, 2017, C ROBOT LEARNING, V78, P67
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Yu Z, 2015, IEEE IJCNN
   Zhang H, 2017, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR.2017.309
   Zhu YK, 2014, LECT NOTES COMPUT SC, V8690, P408, DOI 10.1007/978-3-319-10605-2_27
NR 43
TC 2
Z9 2
U1 4
U2 23
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD MAY 13
PY 2020
VL 14
AR 26
DI 10.3389/fnbot.2020.00026
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Robotics; Neurosciences & Neurology
GA MW0JD
UT WOS:000556732800001
PM 32477091
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Mardiris, V
   Sirakoulis, GC
   Mizas, C
   Karafyllidis, L
   Thanailakis, A
AF Mardiris, Vasilios
   Sirakoulis, Georgios Ch.
   Mizas, Charilaos
   Karafyllidis, Loannis
   Thanailakis, Adonios
TI A CAD system for modeling and simulation of computer networks using
   cellular automata
SO IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND
   REVIEWS
LA English
DT Article
DE cellular automata (CAs); computer networks; design automation; hardware
   design languages; modeling; very large scale integration
ID VLSI IMPLEMENTATION; ALGORITHMS; VHDL
AB The increasing complexity of computer networks calls for the development of new models for their simulation. Cellular automata (CAs) are a well-known and successful model for complex systems. This paper presents a system for modeling and simulation of computer networks based on CAs. More specifically, a 2-D NaSch CA computer network model has been developed, and several networks were simulated. Algorithms for connectivity evaluation, system reliability evaluation, and shortest path computation in a computer network have also been implemented. Our system, called Net_CA system, was designed and developed as an interactive too] that offers automated modeling with the assistance of a dynamic and user-friendly graphical environment. The proposed system also produces automatically synthesizable very high speed integrated circuits hardware description language code leading to the parallel hardware implementation of the aformentioned CA algorithms. In terms of circuit design and layout, ease of mask generation, silicon area utilization, and maximization of achievable clock speed, CAs are perhaps the computational structures best suited for a fully parallel very large scale integrated realization. The simulation algorithms developed in the present paper offer high flexibility. Furthermore, connection reliability and other important parameters are inputs to the algorithms, rendering Net_CA a very reliable and fast simulator for wireless networks, ad hoc networks, and generally, for low connection reliability networks.
C1 [Mardiris, Vasilios; Mizas, Charilaos] Technol Educ Inst Kavala, GR-65404 Kavala, Greece.
   [Sirakoulis, Georgios Ch.; Karafyllidis, Loannis; Thanailakis, Adonios] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace
RP Mardiris, V (通讯作者)，Technol Educ Inst Kavala, GR-65404 Kavala, Greece.
EM mardiris@teikav.edu.gr; gsirak@ee.duth.gr; mizas@teikav.edu.gr;
   ykar@ee.duth.gr; athanail@ee.duth.gr
RI Sirakoulis, Georgios/AAE-9654-2020; Karafyllidis, Ioannis
   G./AAC-4721-2019; Mizas, Charilaos/AAO-1239-2021; Mardiris,
   Vassilios/AAB-3645-2021
OI Sirakoulis, Georgios/0000-0001-8240-484X; Mardiris,
   Vassilios/0000-0003-4818-8666
CR [Anonymous], 1997, ADDITIVE CELLULAR AU
   Bao F, 2004, IEEE T COMPUT, V53, P1493, DOI 10.1109/TC.2004.94
   Billinton R., 1992, RELIABILITY EVALUATI, Vsecond
   Cagnoni S, 2005, IEEE T SYST MAN CY B, V35, P548, DOI 10.1109/TSMCB.2005.846671
   Chattopadhyay S, 2000, IEEE T VLSI SYST, V8, P724, DOI 10.1109/92.902267
   Chopard B, 1998, CELLULAR AUTOMATA MO, V01
   Cickovski TM, 2005, IEEE ACM T COMPUT BI, V2, P273, DOI 10.1109/TCBB.2005.46
   FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179
   FISHMAN GS, 1986, IEEE T RELIAB, V35, P145, DOI 10.1109/TR.1986.4335388
   Gábor S, 2002, PHYSICA A, V307, P516, DOI 10.1016/S0378-4371(02)00603-9
   Gralewitz M, 2004, SIMUL MODEL PRACT TH, V12, P383, DOI 10.1016/j.simpat.2004.05.001
   Huisinga T, 2001, PHYSICA A, V294, P249, DOI 10.1016/S0378-4371(01)00107-8
   Karafyllidis I, 2000, IEEE T SEMICONDUCT M, V13, P61, DOI 10.1109/66.827346
   Liu F, 2003, PHYSICA A, V328, P341, DOI 10.1016/S0378-4371(03)00614-9
   Maji P, 2003, IEEE T SYST MAN CY A, V33, P466, DOI 10.1109/TSMCA.2003.817035
   Malamud BD, 2000, COMPUT SCI ENG, V2, P42, DOI 10.1109/5992.841795
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   Ren ZL, 2002, COMPUT PHYS COMMUN, V144, P243, DOI 10.1016/S0010-4655(01)00468-4
   Rocco CM, 2002, RELIAB ENG SYST SAFE, V78, P289, DOI 10.1016/S0951-8320(02)00174-6
   Seredynski F, 2002, IEEE T PARALL DISTR, V13, P1009, DOI 10.1109/TPDS.2002.1041877
   Shuai DX, 2004, COMPUT NETW, V45, P399, DOI 10.1016/j.comnet.2004.02.001
   Sirakoulis GC, 2004, INTEGRATION, V37, P63, DOI 10.1016/j.vlsi.2003.11.001
   Sirakoulis GC, 2003, MICROPROCESS MICROSY, V27, P381, DOI 10.1016/S0141-9331(03)00100-5
   Sirakoulis GC, 2001, ADV ENG SOFTW, V32, P189, DOI 10.1016/S0965-9978(00)00085-5
   TANENBAUM AS, 1988, COMPUTER NETWORKS
   Tsaoussidis V, 2002, COMPUT NETW, V40, P477, DOI 10.1016/S1389-1286(02)00291-8
   *U SO CAL I SCI I, 2006, NETW SIM NS 2
   Von Neumann J., 1996, THEORY SELF REPRODUC
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Welch B.B., 2003, PRACTICAL PROGRAMMIN
   Wolfram S., 1986, THEORY APPL CELLULAR
   Worsch T, 1999, FUTURE GENER COMP SY, V16, P157, DOI 10.1016/S0167-739X(99)00044-8
   Yang YX, 2000, IEEE T SYST MAN CY B, V30, P573, DOI 10.1109/3477.865174
   Zhao Y, 2006, IEEE T SYST MAN CY B, V36, P473, DOI 10.1109/TSMCB.2005.859079
NR 34
TC 30
Z9 32
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1094-6977
EI 1558-2442
J9 IEEE T SYST MAN CY C
JI IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.
PD MAR
PY 2008
VL 38
IS 2
BP 253
EP 264
DI 10.1109/TSMCC.2007.913907
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 266XS
UT WOS:000253471800010
DA 2023-11-10
ER

PT J
AU AL-Rousan, M
   Assaleh, K
   Tala'a, A
AF AL-Rousan, M.
   Assaleh, K.
   Tala'a, A.
TI Video-based signer-independent Arabic sign language recognition using
   hidden Markov models
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Arabic sign language (ArSL); Hand gestures; HMM; Deaf people; Feature
   extraction; DCT
ID SYSTEM; GESTURES
AB Sign language in Arab World has been recently recognized and documented. There have been no serious attempts to develop a recognition system that can be used as a communication means between hearing-impaired and other people. This paper introduces the first automatic Arabic sign language (ArSL) recognition system based on hidden Markov models (HMMs). A large set of samples has been used to recognize 30 isolated words from the Standard Arabic sign language. The system operates in different modes including offline, online, signer-dependent, and signer-independent modes. Experimental results on using real ArSL data collected from deaf people demonstrate that the proposed system has high recognition rate for all modes. For signer-dependent case, the system obtains a word recognition rate of 98.13%, 96.74%, and 93.8%, on the training data in offline mode, on the test data in offline mode, and on the test data in online mode respectively. On the other hand, for signer-independent case the system obtains a word recognition rate of 94.2% and 90.6% for offline and online modes respectively. The system does not rely on the use of data gloves or other means as input devices, and it allows the deaf signers to perform gestures freely and naturally. (C) 2009 Elsevier B.V. All rights reserved.
C1 [AL-Rousan, M.] Jordan Univ Sci & Technol, Dept Comp Engn, Irbid 22110, Jordan.
   [Assaleh, K.] Amer Univ Sharjah, Dept Elect Engn, Sharjah, U Arab Emirates.
   [Tala'a, A.] Minist Educ, Private Educ Sector, Irbid, Jordan.
C3 Jordan University of Science & Technology; American University of
   Sharjah
RP AL-Rousan, M (通讯作者)，Jordan Univ Sci & Technol, Dept Comp Engn, POB 3030, Irbid 22110, Jordan.
EM alrousan@just.edu.jo; kassaleh@au.edu; dr.adnan2007@yahoo.com
OI Assaleh, Khaled/0000-0002-0942-0453
CR Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   Al-Rousan M., 2001, International Journal of Computers and Their Applications, V8, P80
   Alotaibi YA, 2005, INFORM SCIENCES, V173, P115, DOI 10.1016/j.ins.2004.07.008
   [Anonymous], 2001, AUTOMATIC SIGN LANGU
   Assaleh K, 2005, EURASIP J APPL SIG P, V2005, P2136, DOI 10.1155/ASP.2005.2136
   Campbell WM, 2002, IEEE T SPEECH AUDI P, V10, P205, DOI 10.1109/TSA.2002.1011533
   Fang GL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P312, DOI 10.1109/AFGR.2002.1004172
   Fang GL, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P90, DOI 10.1109/RATFG.2001.938915
   Gao W, 2004, PATTERN RECOGN, V37, P2389, DOI 10.1016/j.patcog.2004.04.008
   Gao W, 2000, INT J PATTERN RECOGN, V14, P587, DOI 10.1142/S0218001400000386
   Grobel K, 1997, IEEE SYS MAN CYBERN, P162, DOI 10.1109/ICSMC.1997.625742
   HALAWANI M, 2008, IJCSNS INT J COMPUTE, V8, P251
   HIENZ H, 1999, LNAI, V1739
   Kadous M. W., 1996, PROC WORKSHOP INTEGR, P165
   Kim JS, 1996, IEEE T SYST MAN CY B, V26, P354, DOI 10.1109/3477.485888
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   Mohandes M., 2004, Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications (IEEE Cat. No.04EX852), P479, DOI 10.1109/ICTTA.2004.1307840
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   Vamplew P., 1998, Australian Journal of Intelligent Information Processing Systems, V5, P94
   Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895
   Wu Y, 1999, LECT NOTES ARTIF INT, V1739, P103
   YOEFFLER C, 1989, P INT C AC SPEECH SI, P988
   2001, ARAB SIGN LANGUAGE D
NR 25
TC 64
Z9 65
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUN
PY 2009
VL 9
IS 3
BP 990
EP 999
DI 10.1016/j.asoc.2009.01.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 443KQ
UT WOS:000265909000015
DA 2023-11-10
ER

PT J
AU Awal, AM
   Mouchère, H
   Viard-Gaudin, C
AF Awal, Ahmad-Montaser
   Mouchere, Harold
   Viard-Gaudin, Christian
TI A global learning approach for an online handwritten mathematical
   expression recognition system
SO PATTERN RECOGNITION LETTERS
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Frontiers in Handwriting Recognition
   (ICFHR)
CY 2010
CL Kolkata, INDIA
DE Handwriting recognition; Bidimensional languages; Math recognition;
   Structural pattern recognition; Syntactic pattern recognition
ID STRUCTURAL-ANALYSIS; SYNTACTIC APPROACH
AB Despite the recent advances in handwriting recognition, handwritten two-dimensional (2D) languages are still a challenge. Electrical schemas, chemical equations and mathematical expressions (MEs) are examples of such 20 languages. In this case, the recognition problem is particularly difficult due to the two dimensional layout of the language. This paper presents an online handwritten mathematical expression recognition system that handles mathematical expression recognition as a simultaneous optimization of expression segmentation, symbol recognition, and 2D structure recognition under the restriction of a mathematical expression grammar. The originality of the approach is a global strategy allowing learning mathematical symbols and spatial relations directly from complete expressions. A new contextual modeling is proposed for combining syntactic and structural information. Those models are used to find the most likely combination of segmentation/recognition hypotheses proposed by a 2D segmentation scheme. Thus, models are based on structural information concerning the symbol layout. The system is tested with a new public database of mathematical expressions which was used in the CHROME competition. We have also produced a large base of semi-synthetic expressions which are used to train and test the global learning approach. We obtain very promising results on both synthetic and real expressions databases, as well as in the recent CHROME competition. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Awal, Ahmad-Montaser] Univ Lyon 2, Lab Etud Mecanismes Cognitifs, Lyon, France.
   [Mouchere, Harold; Viard-Gaudin, Christian] Univ Nantes, LUNAM Univ, IRCCyN IVC, Nantes, France.
C3 Universite Lyon 2; Nantes Universite
RP Awal, AM (通讯作者)，Univ Lyon 2, Lab Etud Mecanismes Cognitifs, Lyon, France.
EM ahmad-montaser.awal@univ-lyon2.fr; harold.mouchere@univ-nantes.fr;
   christian.viard-gaudin@univ-nantes.fr
RI Mouchère, Harold/U-9179-2017
OI Mouchere, Harold/0000-0001-6220-7216
CR Aly Walaa, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1350, DOI 10.1109/ICDAR.2009.90
   Anderson R.H., 1968, APPL MATH, P436
   Awal Ahmad-Montaser, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P646, DOI 10.1109/ICFHR.2010.106
   Awal Ahmad-Montaser, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1046, DOI 10.1109/ICDAR.2009.71
   Awal A.-M., 2010, INT C FRONT HANDWR R, P427
   Awal A.-M., 2010, DOCUMENT RECOGNITION, P1
   Awal A.-M., 2010, THESIS U NANTES
   Awal AM, 2011, PROC SPIE, V7874, DOI 10.1117/12.876624
   BELAID A, 1984, IEEE T PATTERN ANAL, V6, P105, DOI 10.1109/TPAMI.1984.4767483
   Chan K.-F., 2001, 6 INT C DOC AN REC S, P775
   Chan KF, 2000, PATTERN RECOGN, V33, P375, DOI 10.1016/S0031-3203(99)00067-9
   CHANG SK, 1970, INFORM SCIENCES, V2, P253, DOI 10.1016/S0020-0255(70)80052-4
   Couasnon B, 2001, PROC INT CONF DOC, P215, DOI 10.1109/ICDAR.2001.953786
   Delaye Adrien, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1121, DOI 10.1109/ICDAR.2009.141
   Dimitriadis Y.A., 1991, 1 INT C DOC AN REC S, P885
   DIMITRIADIS YA, 1995, PATTERN RECOGN, V28, P807, DOI 10.1016/0031-3203(94)00160-N
   Eto Y, 2001, PROC INT CONF DOC, P762, DOI 10.1109/ICDAR.2001.953891
   Feng GH, 2009, PATTERN RECOGN, V42, P3215, DOI 10.1016/j.patcog.2009.01.031
   Fitzgerald JA, 2007, PROC INT CONF DOC, P694
   Fitzgerald JA, 2006, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER SCIENCE AND TECHNOLOGY, P151
   Fukuda R., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P131, DOI 10.1109/ICDAR.1999.791742
   Garain U, 2004, IEEE T SYST MAN CY B, V34, P2366, DOI 10.1109/TSMCB.2004.836817
   Geneo R., 2006, INT WORKSH FRONT HAN, P255
   Grbavec A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P417, DOI 10.1109/ICDAR.1995.599026
   Jaekyu Ha, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P956, DOI 10.1109/ICDAR.1995.602060
   Kam-Fai Chan, 2000, International Journal on Document Analysis and Recognition, V3, P3, DOI 10.1007/PL00013549
   Keshari B, 2007, PROC INT CONF DOC, P859
   Kosmala A., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P107, DOI 10.1109/ICDAR.1999.791736
   Lapointe Adrien, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1355, DOI 10.1109/ICDAR.2009.247
   Lavirotte S, 1998, P SOC PHOTO-OPT INS, V3305, P44, DOI 10.1117/12.304644
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lehmberg S, 1996, INT CONF ACOUST SPEE, P3434, DOI 10.1109/ICASSP.1996.550766
   Macé S, 2009, PATTERN RECOGN, V42, P3202, DOI 10.1016/j.patcog.2008.10.018
   Miller EG, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P784
   Mitra J, 2003, PROC INT CONF DOC, P540
   Mouchere H., 2012, 13 INT C FR IN PRESS
   Mouchére H, 2011, PROC INT CONF DOC, P1497, DOI 10.1109/ICDAR.2011.297
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Prusa D, 2007, PROC INT CONF DOC, P849
   Quiniou S, 2011, PROC INT CONF DOC, P452, DOI 10.1109/ICDAR.2011.97
   Raman T. V, 1994, THESIS
   Rhee TH, 2009, PATTERN RECOGN, V42, P3192, DOI 10.1016/j.patcog.2008.10.036
   Scott M., 2010, TECHNICAL REPORT
   Szwoch M, 2007, PROC INT CONF DOC, P809, DOI 10.1109/ICDAR.2007.4377027
   Tapia E, 2005, PROC INT CONF DOC, P1206, DOI 10.1109/ICDAR.2005.197
   Tapia E, 2003, PROC INT CONF DOC, P980
   Tokuyasuy T.A., 1999, IAPR WORKSH DOC LAYO
   Viard-Gaudin C., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P455, DOI 10.1109/ICDAR.1999.791823
   WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088
   Xin Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1056, DOI 10.1109/ICDAR.2009.70
   Yamamoto R., 2006, P 10 INT WORKSH FRON, P249
   Shi Y, 2007, PROC INT CONF DOC, P854
   Yuan ZM, 2008, LECT NOTES COMPUT SC, V5328, P55
   Zanibbi R, 2002, IEEE T PATTERN ANAL, V24, P1455, DOI 10.1109/TPAMI.2002.1046157
   Zanibbi R, 2011, PROC INT CONF DOC, P334, DOI 10.1109/ICDAR.2011.75
   Zhang L, 2005, PROC INT CONF DOC, P972
   Zhu H, 2006, INT J DOC ANAL RECOG, V8, P27, DOI 10.1007/s10032-005-0143-x
NR 57
TC 54
Z9 55
U1 2
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD JAN 1
PY 2014
VL 35
SI SI
BP 68
EP 77
DI 10.1016/j.patrec.2012.10.024
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 259YA
UT WOS:000327561000008
DA 2023-11-10
ER

PT J
AU Nguyen, TD
   Ranganath, S
AF Tan Dat Nguyen
   Ranganath, Surendra
TI Facial expressions in American sign language: Tracking and recognition
SO PATTERN RECOGNITION
LA English
DT Article
DE Probabilistic Principal Component Analysis (PPCA); Facial feature
   tracking; Facial expression recognition; American sign language (ASL);
   Hidden Markov Models (HMM); Bayesian tracking; KLT tracker; Support
   Vector Machine (SVM)
ID SEQUENCES; MODELS
AB This paper presents work towards recognizing facial expressions that are used in sign language communication. Facial features are tracked to effectively capture temporal visual cues on the signers' face during signing. Face shape constraints are used for robust tracking within a Bayesian framework. The constraints are specified through a set of face shape subspaces learned by Probabilistic Principal Component Analysis (PPCA). An update scheme is also used to adapt to persons with different face shapes. Two tracking algorithms are presented, which differ in the way the face shape constraints are enforced. The results show that the proposed trackers can track facial features with large head motions, substantial facial deformations, and temporary facial occlusions by hand. The tracked results are input to a recognition system comprising Hidden Markov Models (HMM) and a support vector machine (SVM) to recognize six isolated facial expressions representing grammatical markers in American sign language (ASL). Tracking error of less than four pixels (on 640 X 480 videos) was obtained with probability greater than 90%; in comparison the KLT tracker yielded this accuracy with 76% probability. Recognition accuracy obtained for ASL facial expressions was 91.76% in person dependent tests and 87.71% in person independent tests. (C) 2011 Elsevier Ltd. All rights reserved.
C1 [Ranganath, Surendra] Indian Inst Technol Gandhinagar, Ahmadabad 382424, Gujarat, India.
   [Tan Dat Nguyen] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Gandhinagar; National University of Singapore
RP Ranganath, S (通讯作者)，Indian Inst Technol Gandhinagar, VGEC Campus, Ahmadabad 382424, Gujarat, India.
EM ntdat@nus.edu.sg; surendra@iitgn.ac.in
FU National Research Foundation-Interactive and Digital Media (NRF-IDM)
   [NRF2007IDM-IDM002-069]
FX We are grateful for the reviewers' comments which has helped us to
   improve the paper. Some of the videos used in our work were from the
   National Center for Sign Language and Gesture Resources (NCSLGR) corpus,
   collected at Boston University as part of the American Sign Language
   Linguistic Research Project (ASLLRP) under the supervision of Carol
   Neidle and Stan Sclaroff. The data can be accessed at:
   http://www.bu.edu/asllrp/. This work was partially supported by the
   National Research Foundation-Interactive and Digital Media (NRF-IDM)
   project grant NRF2007IDM-IDM002-069 on "Live Spaces: Place Oriented
   Embodied Media (POEM)".
CR [Anonymous], HIDDEN MARKOV MODEL
   Baker C, 1980, AM SIGN LANGUAGE TEA
   Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664
   Bienvenu M., FACE AM SIGN LANGUAG
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bridges B., 1996, DEAF TEND YOUR
   Canzler U., 2002, P IAPR WORKSH MACH V, P318
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cristinacce D., 2006, BRIT MACH VIS C ED U, P838
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28
   Ekman P., 2002, FACIAL ACTION CODING
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Hamerly G, 2004, ADV NEUR IN, V16, P281
   Ili T. J. Caste, 2006, 6 INT WORKSH PATT RE, P81
   Kanade T, 2000, P 4 IEEE INT C AUT F
   Kanaujia A, 2007, IEEE IMAGE PROC, P265
   Kanaujia A, 2006, LECT NOTES COMPUT SC, V4338, P492
   Loeding BL, 2004, LECT NOTES COMPUT SC, V3118, P1079
   Lucas Bruce D, 1981, ITERATIVE IMAGE REGI, V81, DOI DOI 10.5555/1623264.1623280
   Mayer C, 2010, IMAGE VISION COMPUT, V28, P762, DOI 10.1016/j.imavis.2009.07.012
   Metaxas D, 2007, LECT NOTES COMPUT SC, V4487, P1114
   Neidle C, 2001, BEHAV RES METH INS C, V33, P311, DOI 10.3758/BF03195384
   Neidle C., 2002, J SIGN LANGUAGE LING, V4, P203
   Neidle C., 2009, LANG LOG WORKSH FORM
   Nguyen HT, 2007, IEEE T PATTERN ANAL, V29, P52, DOI 10.1109/TPAMI.2007.250599
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Patras I, 2010, IEEE T PATTERN ANAL, V32, P1553, DOI 10.1109/TPAMI.2009.175
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH
   Romdhani S., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P483
   Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998
   Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780
   STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Tong Y, 2006, INT C PATT RECOG, P307
   Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Vogler Christian, 2008, Universal Access in the Information Society, V6, P363, DOI 10.1007/s10209-007-0096-6
   von Agris Ulrich, 2008, Universal Access in the Information Society, V6, P323, DOI 10.1007/s10209-007-0104-x
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhou F, 2010, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2010.5539966
NR 52
TC 22
Z9 22
U1 1
U2 28
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD MAY
PY 2012
VL 45
IS 5
BP 1877
EP 1891
DI 10.1016/j.patcog.2011.10.026
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 902DB
UT WOS:000301017700006
DA 2023-11-10
ER

PT J
AU Huang, YX
   Liang, Y
   Wu, ZY
   Zhu, EC
   Yu, ZT
AF Huang, Yuxin
   Liang, Yin
   Wu, Zhaoyuan
   Zhu, Enchang
   Yu, Zhengtao
TI Cross-lingual Sentence Embedding for Low-resource Chinese-Vietnamese
   Based on Contrastive Learning
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Chinese-Vietnamese; low-resource language; cross-lingual sentence
   embedding; siamese network; mBERT
AB Cross-lingual sentence embedding's goal is mapping sentences with similar semantics but in different languages close together and dissimilar sentences farther apart in the representation space. It is the basis of many downstream tasks such as cross-lingual document matching and cross-lingual summary extraction. At present, the works of cross-lingual sentence embedding tasks mainly focus on languages with large-scale corpus. But low-resource languages such as Chinese-Vietnamese are short of sentence-level parallel corpora and clear cross-lingual monitoring signals, and these works on low-resource languages have poor performances. Therefore, we propose a cross-lingual sentence embedding method based on contrastive learning and effectively fine-tune powerful pretraining mode by constructing sentence-level positive and negative samples to avoid the catastrophic forgetting problem of the traditional fine-tuning pre-trained model based only on small-scale aligned positive samples. First, we construct positive and negative examples by taking parallel Chinese Vietnamese sentences as positive examples and non-parallel sentences as negative examples. Second, we construct a siamese network to get contrastive loss by inputting positive and negative samples and fine-tuning our model. The experimental results show that our method can effectively improve the semantic alignment accuracy of cross-lingual sentence embedding in Chinese and Vietnamese contexts.
C1 [Huang, Yuxin; Liang, Yin; Wu, Zhaoyuan; Zhu, Enchang; Yu, Zhengtao] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Yunnan Key Lab Artificial Intelligence, 727 Jingming South Rd, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology
RP Yu, ZT (通讯作者)，Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Yunnan Key Lab Artificial Intelligence, 727 Jingming South Rd, Kunming 650500, Yunnan, Peoples R China.
EM huangyuxin2004@163.com; 2712653816@qq.com; 978105863@qq.com;
   ztyu@hotmail.com
OI Zhu, Enchang/0000-0002-1340-4368
FU National Natural Science Foundation of China [U21B2027, 61972186,
   62266028, 62266027]; Yunnan Provincial Major Science and Technology
   Special Plan Projects [202103AA080015, 202202AD080003]; General Projects
   of Basic Research in Yunnan Province [202201AS070179, 202201AT070915];
   Kunming University of Science and Technology "double first-class" joint
   project [202201BE070001-021]
FX This work was supported by the National Natural Science Foundation of
   China (grant nos. U21B2027, 61972186, 62266028, 62266027); Yunnan
   Provincial Major Science and Technology Special Plan Projects (grant
   nos. 202103AA080015, 202202AD080003); General Projects of Basic Research
   in Yunnan Province (grant nos. 202201AS070179, 202201AT070915]; Kunming
   University of Science and Technology "double first-class" joint project
   (grant no. 202201BE070001-021).
CR Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bai Y., 2021, LONG PAPERS, V1, P6910, DOI DOI 10.18653/V1/2021.ACL-LONG.538
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen T, 2020, PR MACH LEARN RES, V119
   Chuang YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4207
   Conneau A, 2020, Arxiv, DOI [arXiv:1911.02116, 10.48550/arXiv.1911.02116]
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Constant N., 2020, ARXIV
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   E. Hinton Geoffrey, 2012, Arxiv, DOI [arXiv:1207.0580, 10.48550/arXiv.1207.0580, DOI 10.48550/ARXIV.1207.0580]
   El-Kishky A, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P616
   Gao J., 2019, P 7 INT C LEARNING R
   Gao Tianyu, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.08821
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, P8
   Lample G, 2019, Arxiv, DOI arXiv:1901.07291
   Libovicky Jindrich, 2020, FINDINGS ASS COMPUTA, P1663, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.150
   Lin Huan, 2021, ARXIV
   Liu X, 2021, Arxiv, DOI arXiv:2106.06125
   Mulcaire P, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3912
   Pagliardini M, 2018, Arxiv, DOI arXiv:1703.02507
   Papadimitriou I, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2522
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Raffel C, 2020, Arxiv, DOI arXiv:1910.10683
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Ruckl‚ A, 2018, Arxiv, DOI arXiv:1803.01400
   Le QV, 2014, Arxiv, DOI [arXiv:1405.4053, DOI 10.48550/ARXIV.1405.4053]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2021, Arxiv, DOI arXiv:2104.08787
NR 29
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUN
PY 2023
VL 22
IS 6
AR 176
DI 10.1145/3589341
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7YR0
UT WOS:001018562700022
DA 2023-11-10
ER

PT J
AU Buyuk, O
   Arslan, LM
AF Buyuk, Osman
   Arslan, Levent M.
TI Learning from mistakes: Improving spelling correction performance with
   automatic generation of realistic misspellings
SO EXPERT SYSTEMS
LA English
DT Article
DE deep learning; machine learning; natural language processing; neural
   network
AB Sequence to sequence models (seq2seq) require a large amount of labelled training data to learn the mapping between the input and output. A large set of misspelled words together with their corrections is needed to train a seq2seq spelling correction system. Low-resource languages such as Turkish usually lack such large annotated datasets. Although misspelling-reference pairs can be synthesized with a random procedure, the generated dataset may not well match to genuine human-made misspellings. This might degrade the performance in realistic test scenarios. In this paper, we propose a novel procedure to automatically introduce human-like misspellings to legitimate words in Turkish language. Generated human-like misspellings are used to improve the performance of a seq2seq spelling correction system. The proposed system consists of two separate models; a misspelling generator and a spelling corrector. The generator is trained using a relatively small number of human-made misspellings and their manual corrections. Reference words and their misspellings are used as inputs and outputs of the generator, respectively. As a result, it is trained to add realistic spelling errors to the valid words. Training data of the spelling corrector is augmented by the generator's human-like misspellings. In the experiments, we observe that the data augmentation significantly improves the spelling correction performance. Our proposed method yields 5% absolute improvement over the state-of-the-art Turkish spelling correction systems in a test set which contains human-made misspellings from Twitter messages.
C1 [Buyuk, Osman] Izmir Demokrasi Univ, Dept Elect & Elect Engn, Izmir, Turkey.
   [Arslan, Levent M.] Bogazici Univ, Dept Elect & Elect Engn, Istanbul, Turkey.
   [Arslan, Levent M.] Sestek Speech Enabled Software Technol Inc, Sestek Res & Dev Ctr, Istanbul, Turkey.
C3 Izmir Democracy University; Bogazici University
RP Buyuk, O (通讯作者)，Izmir Demokrasi Univ, Dept Elect & Elect Engn, Izmir, Turkey.
EM osman.buyuk@idu.edu.tr
RI Büyük, Osman/HOH-4573-2023
OI Büyük, Osman/0000-0003-1039-3234
FU Turkiye Bilimsel ve Teknolojik Arastirma Kurumu; America Online
FX Turkiye Bilimsel ve Teknolojik Arastirma Kurumu; America Online
CR AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855
   [Anonymous], 2007, STRUCTURE
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bi XJ, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2297, DOI 10.1145/2556288.2557414
   Bolucu N, 2019, IEEE SCI M EL EL BIO, P1, DOI [10.1109/EBBT.2019.8742067, DOI 10.1109/EBBT.2019.8742067]
   Buyuk, 2005, THESIS SABANCI U TUR
   Buyuk O, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12692
   Büyük O, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3383200
   Büyük O, 2019, SIG PROCESS COMMUN, DOI 10.1109/siu.2019.8806476
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105
   Church K.W., 1991, STAT COMP, V1, P93, DOI [DOI 10.1007/BF01889984, 10.1007/BF01889984]
   CNTK, 2020, MICROSOFT COGNITIVE
   Çöltekin Ç, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1079
   Erdogan H, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P98, DOI 10.1109/ASRU.2005.1566516
   Etoori Pravallika, 2018, P ACL 2018 STUDENT R, P146
   Fivez P., 2017, BIOM NAT LANG PROC W, P143, DOI DOI 10.18653/V1/W17-2317
   Flor M, 2019, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P76
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hagen M, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1261, DOI 10.1145/3077136.3080749
   Hassan H., 2008, INT JOINT C NAT LANG, VII
   Hassan Hany., 2013, P 51 INT C, P1577
   Ince E. Yilmaz, 2017, International Journal of Information and Electronics Engineering, V7, P68, DOI 10.18178/ijiee.2017.7.2.663
   Kasewa S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4977
   Koskenniemi, 1983, 2 LEVEL MORPHOLOGY G, V11, P12
   Kristensson, 2017, NEURAL NETWORKS TEXT, V1, P1
   Kristensson Per Ola, 2005, P 10 INT C INT US IN, P151, DOI [10.1145/1040830.1040867, DOI 10.1145/1040830.1040867]
   Manning, 2015, EFFECTIVE APPROACHES, V1, P1
   MAYS E, 1991, INFORM PROCESS MANAG, V27, P517, DOI 10.1016/0306-4573(91)90066-U
   Mikolov, 2016, ENRICHING WORD VECTO, V1, P1
   Oflazer K, 1996, COMPUT LINGUIST, V22, P73
   Oflazer K., 1994, Literary & Linguistic Computing, V9, P137, DOI 10.1093/llc/9.2.137
   Rios A., 2011, LANGUAGE TECHNOLOGY, P51
   Saraclar, 2008, ADV NAT LANG PROC 6
   Sutskever Ilya, 2014, NEURIPS, DOI DOI 10.5555/2969033.2969173
   Torunoglu S.D., 2016, P 1 INT C TURK COMP, V1, P7
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Xiang, 2016, ABSTRACTIVE TEXT SUM, V1, P1
NR 38
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD AUG
PY 2021
VL 38
IS 5
AR e12692
DI 10.1111/exsy.12692
EA MAR 2021
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TI7FY
UT WOS:000629739600001
DA 2023-11-10
ER

PT J
AU Wang, Y
   Wu, LJ
   Li, JT
   Liang, XB
   Zhang, M
AF Wang, Yue
   Wu, Lijun
   Li, Juntao
   Liang, Xiaobo
   Zhang, Min
TI Are the BERT family zero-shot learners? A study on their potential and
   limitations
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Pre-trained language model; Zero-shot text classification; Prompt-based
   learning
AB Starting from the resurgence of deep learning, language models (LMs) have never been so popular. Through simply increasing model scale and data size, large LMs pre-trained with self-supervision objectives demonstrate awe-inspiring results on both task performance and generalization. At the early stage, supervised fine-tuning is indispensable in adapting pre-trained language models (PLMs) to downstream tasks. Later on, the sustained growth of model capacity and data size, as well as newly presented pre-training techniques, make the PLMs perform well under the few-shot setting, especially in the recent paradigm of prompt-based learning. After witnessing the success of PLMs for few-shot tasks, we propose to further study the potential and limitations of PLMs for the zero-shot setting. We utilize 3 models from the most popular BERT family to launch the empirical study on 20 different datasets. We are surprised to find that some simple strategies (without the need of human efforts or unsupervised data) can yield very promising results on a few widely-used datasets, e.g., 88.34%(& PLUSMN;0.60) accuracy on the IMDB dataset, and 84.88%(& PLUSMN;2.83) accuracy on the Amazon dataset, which outperforms manually created prompts without engineering in achieving much better and stable performance with the accuracy of 74.06%(& PLUSMN;13.04), 75.54%(& PLUSMN;11.77) for comparison. However, we also observe some limitations of PLMs under the zero-shot setting, particularly for the language understanding tasks (e.g., GLUE, SuperGLUE).2 & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Wang, Yue; Li, Juntao; Liang, Xiaobo; Zhang, Min] Soochow Univ, Suzhou, Peoples R China.
   [Wu, Lijun] Microsoft Res Asia, Beijing, Peoples R China.
   [Zhang, Min] Harbin Inst Technol, Shenzhen, Peoples R China.
C3 Soochow University - China; Microsoft; Microsoft Research Asia; Harbin
   Institute of Technology
RP Li, JT (通讯作者)，Soochow Univ, Suzhou, Peoples R China.
EM ywangnlp@stu.suda.edu.cn; lijuwu@microsoft.com; ljt@suda.edu.cn;
   xbliang3@stu.suda.edu.cn; minzhang@suda.edu.cn
FU National Science Foundation of China (NSFC) [62206194]; Natural Science
   Foundation of Jiangsu Province, China [BK20220488, JSSCBS20210661];
   Beijing Academy of Artificial Intelligence (BAAI)
FX We would like to thank the efforts of anonymous reviewers for improving
   this paper. This work is supported by the National Science Foundation of
   China (NSFC No. 62206194) , the Natural Science Foundation of Jiangsu
   Province, China (Grant No. BK20220488) , and JSSCBS20210661. This work
   is also supported by Beijing Academy of Artificial Intelligence (BAAI) .
CR [Anonymous], 2008, P 31 ANN INT ACM SIG, DOI DOI 10.1145/1390334.1390436
   Bai Y., ARXIV
   Bao H., ARXIV
   Brown T.B., ARXIV
   Chan Ying-Hong, 2019, P 2 WORKSH MACH READ, P154, DOI DOI 10.18653/V1/D19-5821
   Chang Ming-Wei, 2008, P NAT C ART INT, P830
   Chen XY, 2015, AAAI CONF ARTIF INTE, P2224
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong H., ARXIV
   Feldman J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1173
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Gu JT, 2018, Arxiv, DOI arXiv:1711.02281
   Hambardzumyan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4921
   Haviv A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3618
   Hu S., ARXIV
   Huang F., ARXIV
   Huang J., 2021, FINDINGS ASS COMPUTA, P238, DOI [DOI 10.18653/V1/2021.FINDINGS-EMNLP.23, DOI 10.18653/V1/2021.FINDINGS]
   Huang X.S., 2021, INT C LEARNING REPRE
   Jiang T., ARXIV
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Jin YP, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P112
   Khashabi Daniel, 2020, FINDINGS ASS COMPUTA, P1896, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.171
   Korbak T., ARXIV
   Lan Z., 2020, ARXIV
   Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2627
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Lester B., 2021 C EMP METH NAT
   Lewis M., 2020, P 58 ANN M ASS COMP
   Lhoest Quentin, 2021, Zenodo, DOI 10.5281/ZENODO.5148649
   Li CL, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3238250
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Liu H., ARXIV
   Liu H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4799
   Liu P., 2021, ARXIV
   Liu X., ARXIV
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Logan R.L., ARXIV
   Lu X., 2021, ARXIV
   Ma TT, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P786
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   McAuley J., 2013, P 7 ACM C RECOMMENDE, P165
   Mekala D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P323
   Meng Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9006
   Meng Y, 2019, AAAI CONF ARTIF INTE, P6826
   Mishra S., 2022, P 60 ANN M ASS COMPU, V1, P3470
   Nam J, 2016, AAAI CONF ARTIF INTE, P1948
   Ouyang L., ARXIV
   Perez E, 2021, ADV NEUR IN
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Qin GH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5203
   Radford A., 2019, LANGUAGE MODELS ARE
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Sanh V., ARXIV
   Schick T., 2020, P 28 INT C COMP LING, P5569
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222
   Song YQ, 2014, AAAI CONF ARTIF INTE, P1579
   Su YX, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P234
   Sun Y., ARXIV
   Thoppilan R., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.08239
   Wang T.C., ARXIV
   Wang Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3043
   Wei J., ARXIV
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Xiao Y., ARXIV
   Xu H., 2022, ARXIV
   Yan GF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1050
   Ye J., ARXIV
   Ye ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3014
   Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914
   Yuan Z, ARXIV
   Zhang J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1031
   Zhang N., ARXIV
   Zhang Xiang, 2015, NEURIPS, DOI DOI 10.5555/2969239.2969312
   Zhao XD, 2022, Arxiv, DOI arXiv:2212.06950
   Zhong RQ, 2021, Arxiv, DOI arXiv:2104.04670
   Zhong Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5017
   2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 81
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD SEP
PY 2023
VL 322
AR 103953
DI 10.1016/j.artint.2023.103953
EA JUN 2023
PG 23
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O0TL1
UT WOS:001041031600001
DA 2023-11-10
ER

PT J
AU Ma, CX
   Zhang, C
AF Ma, Changxia
   Zhang, Chen
TI Joint Pre-Trained Chinese Named Entity Recognition Based on
   Bi-Directional Language Model
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Bi-directional encoder representations-from-transformers;
   context-sensitive language; multi-head attention; named entity
   recognition; natural language processing
AB The current named entity recognition (NER) is mainly based on joint convolution or recurrent neural network. In order to achieve high performance, these networks need to provide a large amount of training data in the form of feature engineering corpus and lexicons. Chinese NER is very challenging because of the high contextual relevance of Chinese characters, that is, Chinese characters and phrases may have many possible meanings in different contexts. To this end, we propose a model that leverages a pre-trained and bi-directional encoder representations-from-transformers language model and a joint bi-directional long short-term memory (Bi-LSTM) and conditional random fields (CRF) model for Chinese NER. The underlying network layer embeds Chinese characters and outputs character-level representations. The output is then fed into a bidirectional long short-term memory to capture contextual sequence information. The top layer of the proposed model is CRF, which is used to take into account the dependencies of adjacent tags and jointly decode the optimal chain of tags. A series of extensive experiments were conducted to research the useful improvements of the proposed neural network architecture on different datasets without relying heavily on handcrafted features and domain-specific knowledge. Experimental results show that the proposed model is effective, and character-level representation is of great significance for Chinese NER tasks. In addition, through this work, we have composed a new informal conversation message corpus called the autonomous bus information inquiry dataset, and compared to the advanced baseline, our method has been significantly improved.
C1 [Ma, Changxia] Jiangsu Ocean Univ, Sch Comp Engn, Lianyungang 222005, Peoples R China.
   [Zhang, Chen] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
C3 Jiangsu Ocean University; National University of Singapore
RP Ma, CX (通讯作者)，Jiangsu Ocean Univ, Sch Comp Engn, Lianyungang 222005, Peoples R China.
EM 1997000062@jou.edu.cn; e0397123@u.nus.edu
RI Chen, Zhang/AEG-7326-2022
FU Jiangsu Ocean University Research Foundation [KH18245]; National
   Research Foundation, Prime Minister's Office, Singapore under its LTA
   Urban Mobility Grand Challenge Program [UM01/002]; ST Kinetics
   Autonomous Bus Trial
FX This work was supported by the Jiangsu Ocean University Research
   Foundation under Grant KH18245, the National Research Foundation, Prime
   Minister's Office, Singapore under its LTA Urban Mobility Grand
   Challenge Program, Project Code UM01/002, ST Kinetics Autonomous Bus
   Trial.
CR [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2002, P 6 C NATURAL LANGUA
   Chiu JPC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI DOI 10.1162/TACL_A_00104
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Devlin J., 2018, ARXIV, V1, P4171
   Dong C, 2016, LECT NOTES COMPUT SC, V10102, P239, DOI 10.1007/978-3-319-50496-4_20
   Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260
   Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Han XP, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P765
   He H., 2017, EACL, V15, P713, DOI DOI 10.18653/V1/E17-2113
   Hu ZT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2410, DOI 10.18653/v1/p16-1228
   Huang Z., 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, DOI DOI 10.18653/V1/N16-1030
   Levow G, 2006, P 5 SIGHAN WORKSH CH, P108
   Li HB, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2532
   Li JZ, 2020, SSPS 2020: 2020 2ND SYMPOSIUM ON SIGNAL PROCESSING SYSTEMS, P96, DOI 10.1145/3421515.3421534
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Liu JX, 2019, NEUROCOMPUTING, V338, P46, DOI 10.1016/j.neucom.2019.01.085
   Liu LY, 2018, AAAI CONF ARTIF INTE, P5253
   Liu ZX, 2010, LECT NOTES ARTIF INT, V6216, P634
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Mccallum A., 2003, P 7 C NATURAL LANGUA, P188, DOI [10.3115/1119176.1119206, 10.3115/1119176, DOI 10.3115/1119176, DOI 10.3115/1119176.1119206]
   McCallum A., 2000, ICML
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Peng N., 2015, P 2015 C EMP METH NA, P548, DOI DOI 10.18653/V1/D15-1064
   Peng N., 2017, ARXIV160300786V2CSCL
   Peng NY, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P149
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Peters M. E., 2018, ARXIV180205365
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Ratinov L., 2009, P 13 C COMPUTATIONAL, DOI DOI 10.3115/1596374.1596399
   Sang EFTK, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS, P173
   Shi XL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P594
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Wu F., 2019, WEB C 2019 P WORLD, P3342, DOI DOI 10.1145/3308558.3313743
   Yang J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2720
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zhou JS, 2013, CHINESE J ELECTRON, V22, P225
NR 45
TC 1
Z9 1
U1 1
U2 22
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD JUL
PY 2021
VL 35
IS 09
AR 2153003
DI 10.1142/S0218001421530037
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF4SF
UT WOS:000688564900018
DA 2023-11-10
ER

PT J
AU Davani, AM
   Atari, M
   Kennedy, B
   Dehghani, M
AF Davani, Aida Mostafazadeh
   Atari, Mohammad
   Kennedy, Brendan
   Dehghani, Morteza
TI Hate Speech Classifiers Learn Normative Social Stereotypes
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID MODEL; BIAS; COMPETENCE; WARMTH; RACISM
AB Social stereotypes negatively impact individuals' judgments about different groups and may have a critical role in understanding language directed toward marginalized groups. Here, we assess the role of social stereotypes in the automated detection of hate speech in the English language by examining the impact of social stereotypes on annotation behaviors, annotated datasets, and hate speech classifiers. Specifically, we first investigate the impact of novice annotators' stereotypes on their hate-speech-annotation behavior. Then, we examine the effect of normative stereotypes in language on the aggregated annotators' judgments in a large annotated corpus. Finally, we demonstrate how normative stereotypes embedded in language resources are associated with systematic prediction errors in a hate-speech classifier. The results demonstrate that hate-speech classifiers reflect social stereotypes against marginalized groups, which can perpetuate social inequalities when propagated at scale. This framework, combining social-psychological and computational-linguistic methods, provides insights into sources of bias in hate-speech moderation, informing ongoing debates regarding machine learning fairness.
C1 [Davani, Aida Mostafazadeh; Atari, Mohammad; Kennedy, Brendan; Dehghani, Morteza] Univ Southern Calif, Los Angeles, CA 90007 USA.
C3 University of Southern California
RP Davani, AM (通讯作者)，Univ Southern Calif, Los Angeles, CA 90007 USA.
EM mostafaz@usc.edu; atari@usc.edu; btkenned@usc.edu; mdehghan@usc.edu
OI Kennedy, Brendan/0000-0001-7252-7475
CR Ahmed Z, 2022, EPJ DATA SCI, V11, DOI 10.1140/epjds/s13688-022-00319-9
   Akhtar Sohail., 2021, ARXIV PREPRINT ARXIV
   [Anonymous], 1960, PROBABILISTIC MODELS
   Arhin Kofi., 2021, ARXIV
   Aroyo L, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P1100, DOI 10.1145/3308560.3317083
   Badjatiya P, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P49, DOI 10.1145/3308558.3313504
   Ben Hutchinson, 2020, ACL, P5491, DOI DOI 10.18653/V1/2020.ACL-MAIN.487
   Bender Emily M., 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P610, DOI 10.1145/3442188.3445922
   Blodgett Su Lin, 2020, P 58 ANN M ASS COMPU, DOI [DOI 10.18653/V1/2020.ACL-MAIN.485, 10.18653/v1/2020.aclmain.485, 10.18653/v1]
   Blodgett Su Lin, 2017, ARXIV170700061
   Bolukbasi T, 2016, NEURAL INFORM PROCES, P4349, DOI DOI 10.5555/3157382
   Borkan D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P491, DOI 10.1145/3308560.3317593
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230
   Carter ER, 2015, SOC PERSONAL PSYCHOL, V9, P269, DOI 10.1111/spc3.12181
   Chang Ming-Wei, 2019, NAACL HLT
   Charlesworth TES, 2021, PSYCHOL SCI, V32, P218, DOI 10.1177/0956797620963619
   Chuang YS, 2021, WOAH 2021: THE 5TH WORKSHOP ON ONLINE ABUSE AND HARMS, P114
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cowan G, 2002, J SOC ISSUES, V58, P247, DOI 10.1111/1540-4560.00259
   Crawford Kate., 2017, C NEURAL INFORM PROC
   Cuddy AJC, 2008, ADV EXP SOC PSYCHOL, V40, P61, DOI 10.1016/S0065-2601(07)00002-0
   Cuddy AJC, 2007, J PERS SOC PSYCHOL, V92, P631, DOI 10.1037/0022-3514.92.4.631
   Czarnowska P, 2021, T ASSOC COMPUT LING, V9, P1249, DOI 10.1162/tacl_a_00425
   Davani AM, 2022, T ASSOC COMPUT LING, V10, P92, DOI 10.1162/tacl_a_00449
   Davani AM, 2021, WOAH 2021: THE 5TH WORKSHOP ON ONLINE ABUSE AND HARMS, P92
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   Davidson T, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P25
   Diaz Mark, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2342, DOI 10.1145/3531146.3534647
   Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729
   Feldman M, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P259, DOI 10.1145/2783258.2783311
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115
   Garg S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P219, DOI 10.1145/3306618.3317950
   Gavin Gaffney, 2018, PUSHSHIFT GAB CORPUS
   Geva M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1161
   Gong L, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P937, DOI 10.1145/3038912.3052693
   Gultchin L., 2019, PMLR, V97, P2474
   Hardt Moritz, 2016, NEURIPS
   Hofmann W, 2005, PERS SOC PSYCHOL B, V31, P1369, DOI 10.1177/0146167205275613
   Hovy D., 2013, P 2013 C N AM CHAPT, P1120, DOI DOI 10.1145/1148170.1148215
   Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432
   Huesmann LR, 2012, J RES ADOLESCENCE, V22, P556, DOI 10.1111/j.1532-7795.2012.00785.x
   Ji Ho Park., 2018, P 2018 C EMP METH NA
   Jiang JA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256762
   Kennedy B., 2018, PSYARXIV
   Kennedy B, 2022, LANG RESOUR EVAL, V56, P79, DOI 10.1007/s10579-021-09569-x
   Kennedy Brendan, 2020, P 58 ANN M ASS COMP, P5435, DOI DOI 10.18653/V1/2020.ACL-MAIN.483
   Kiritchenko Svetlana, 2021, Journal of Artificial Intelligence Research, V71, P431
   Koch A, 2016, J PERS SOC PSYCHOL, V110, P675, DOI 10.1037/pspa0000046
   Kocon J, 2021, IEEE DATA MINING, P1168, DOI 10.1109/ICDM51629.2021.00140
   Kwok Irene, 2013, TWENTYSEVENTH AAAI C, P1621, DOI DOI 10.5555/2891460.2891697
   Lalor John P, 2016, Proc Conf Empir Methods Nat Lang Process, V2016, P648
   Manzinit T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P615
   McCradden MD, 2020, J AM MED INFORM ASSN, V27, P2024, DOI 10.1093/jamia/ocaa085
   Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
   Mozafari M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237861
   Norton MI, 2011, PERSPECT PSYCHOL SCI, V6, P215, DOI 10.1177/1745691611406922
   Nozza D, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P149, DOI 10.1145/3350546.3352512
   Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342
   Patton Desmond., 2019, P 52 HAWAII INT C SY, DOI [10.24251/HICSS.2019.260, DOI 10.24251/HICSS.2019.260]
   Pavlick E, 2019, T ASSOC COMPUT LING, V7, P677, DOI 10.1162/tacl_a_00293
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pietraszkiewicz A, 2019, EUR J SOC PSYCHOL, V49, P871, DOI 10.1002/ejsp.2561
   Posch Lisa., 2018, 11 INT AAAI C WEB SO
   Prabhakaran V, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5740
   Prabhakaran Vinodkumar, 2021, P JOINT 15 LINGUISTI, P133, DOI [10.18653/v1/2021.law-1.14, DOI 10.18653/V1/2021.LAW-1.14]
   Rajadesingan A, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P97, DOI 10.1145/2684822.2685316
   Ross Bjorn, 2016, P NLP4CMC 3 3 WORKSH, V17, DOI [10.17185/duepublico/42132, DOI 10.17185/DUEPUBLICO/42132]
   Rottger Paul, 2022, P 2022 C N AM CHAPTE, P175, DOI 10.18653/v1/2022.naacl-main.13
   Sap M, 2022, P 2022 C N AM CHAPT, P5884
   Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668
   Stemler S.E., 2021, PRACTICAL ASSESS RES, V26, P1, DOI [10.7275/v2gd-4441, DOI 10.7275/V2GD-4441]
   Swinger N, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P305, DOI 10.1145/3306618.3314270
   Uma AN, 2021, J ARTIF INTELL RES, V72, P1385
   Vaidya Ameya, 2020, P INT AAAI C WEB SOC, V14, P683
   Vidgen B, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1667
   Wagner C, 2021, NATURE, V595, P197, DOI 10.1038/s41586-021-03666-1
   Waseem Z., 2016, WORKSH NLP COMP SOC, P138
   Wich Maximilian, 2020, P 4 WORKSHOP ONLINE, P191
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Xia Mengzhou, 2020, P 8 INT WORKSH NAT L, P7, DOI DOI 10.18653/V1/2020.SOCIALNLP-1.2
   Zeerak Talat, 2021, DISEMBODIED MACHINE
   Zhuang L., 2021, P 20 CHINESE NATL C, P1218
   Zou LX, 2017, J PERS SOC PSYCHOL, V112, P696, DOI 10.1037/pspa0000080
NR 86
TC 0
Z9 0
U1 9
U2 12
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 22
PY 2023
VL 11
BP 300
EP 319
DI 10.1162/tacl_a_00550
PG 20
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA A3SB5
UT WOS:000954352100003
OA gold
DA 2023-11-10
ER

PT J
AU Takano, W
AF Takano, Wataru
TI Annotation Generation From IMU-Based Human Whole-Body Motions in Daily
   Life Behavior
SO IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS
LA English
DT Article
DE Human motion; language; probabilistic modeling
ID LANGUAGE; PRIMITIVES
AB This article describes a stochastic framework for integrating human whole-body motions with natural language. Human whole-body motions in daily life are measured by inertial measurement units (IMU) and subsequently encoded into motion primitives. Sentences are manually attached to the human motion primitives for their descriptions. Two aspects of semantics and syntactics are represented by stochastic modules. One stochastic module trains the linking of motion primitives to words, and the other module represents word order in the sentence structure. These two modules are helpful toward converting human whole-body motions into descriptions, where multiple words are generated from the human motions by the first module, and the second module searches for syntactically consistent sentences consisting of the generated words. The proposed framework is tested on a large dataset of human whole-body motions and their descriptive sentences. The linking of human motions to natural language enables robots to understand observations of human behavior as sentences.
C1 [Takano, Wataru] Ctr Math Modeling & Data Sci, Toyonaka, Osaka 5608531, Japan.
RP Takano, W (通讯作者)，Ctr Math Modeling & Data Sci, Toyonaka, Osaka 5608531, Japan.
EM takano@sigmath.es.osaka-u.ac.jp
FU Japan Society for the Promotion of Science [17K20000]; Grants-in-Aid for
   Scientific Research [17K20000] Funding Source: KAKEN
FX This work was supported by a Grant-in-Aid for Challenging Research
   (Exploratory) from the Japan Society for the Promotion of Science under
   Grant 17K20000. This article was recommended by Associate Editor X. Hu.
CR Ahn H, 2018, IEEE INT CONF ROBOT, P5915
   [Anonymous], P IEEE S SER COMP IN
   [Anonymous], P 20 INT C ART NEUR
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Asfour T, 2006, IEEE-RAS INT C HUMAN, P40, DOI 10.1109/ICHR.2006.321361
   Billard AG, 2006, ROBOT AUTON SYST, V54, P370, DOI 10.1016/j.robot.2006.01.007
   Cheng Y, 2017, IEEE ANN INT CONF CY, P1072, DOI 10.1109/CYBER.2017.8446270
   Ijspeert A. J., 2003, NEURAL INF PROCESS S, V15, P1547
   Inamura T, 2004, INT J ROBOT RES, V23, P363, DOI 10.1177/0278364904042199
   KADABA MP, 1990, J ORTHOP RES, V8, P383, DOI 10.1002/jor.1100080310
   Kadone H, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2900, DOI 10.1109/IROS.2005.1545416
   Kanda H, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1852
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kulic Dana, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P1210, DOI 10.1109/ROMAN.2009.5326307
   Levine S, 2016, J MACH LEARN RES, V17
   Nakamura Tomoaki, 2011, IEEE International Conference on Robotics and Automation, P6233
   Nakamura T, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P2421
   Okada M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1410, DOI 10.1109/ROBOT.2002.1014741
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Plappert M, 2018, ROBOT AUTON SYST, V109, P13, DOI 10.1016/j.robot.2018.07.006
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shixiang Gu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3389, DOI 10.1109/ICRA.2017.7989385
   Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102
   Sugiura K, 2010, IEEE INT C INT ROBOT, P1774, DOI 10.1109/IROS.2010.5649754
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Takano Wataru, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P708, DOI 10.1109/ICHR.2008.4755976
   Takano W, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1422
   Takano W, 2007, IEEE INT CONF ROBOT, P3092, DOI 10.1109/ROBOT.2007.363942
   Takano W, 2019, AUTON ROBOT, V43, P913, DOI 10.1007/s10514-018-9762-1
   Takano W, 2017, ROBOT AUTON SYST, V91, P247, DOI 10.1016/j.robot.2017.02.003
   Takano W, 2015, INT J ROBOT RES, V34, P1314, DOI 10.1177/0278364915587923
   Takano W, 2009, IEEE INT CONF ROBOT, P2490
   Tani J, 2003, IEEE T SYST MAN CY A, V33, P481, DOI 10.1109/TSMCA.2003.809171
   Yamada T, 2018, IEEE ROBOT AUTOM LET, V3, P3441, DOI 10.1109/LRA.2018.2852838
   Yu Cheng, 2018, 2018 IEEE International Conference on Information and Automation (ICIA). Proceedings, P1503, DOI 10.1109/ICInfA.2018.8812425
NR 36
TC 8
Z9 8
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2291
EI 2168-2305
J9 IEEE T HUM-MACH SYST
JI IEEE T. Hum.-Mach. Syst.
PD FEB
PY 2020
VL 50
IS 1
BP 13
EP 21
DI 10.1109/THMS.2019.2960630
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KE2IA
UT WOS:000508380700002
OA hybrid
DA 2023-11-10
ER

PT J
AU Brown, KN
   Cagan, J
AF Brown, KN
   Cagan, J
TI Optimized process planning by generative simulated annealing
SO AI EDAM-ARTIFICIAL INTELLIGENCE FOR ENGINEERING DESIGN ANALYSIS AND
   MANUFACTURING
LA English
DT Article
DE process planning; simulated annealing; shape grammar; semantics;
   optimization
ID SHAPE; FEATURES; GRAMMAR; MODEL
AB Manufacturing process planning is a difficult problem with a prohibitively large search space. It is normally tackled by decomposing goal objects into features, and then sequencing features to obtain a plan. This paper investigates an alternative approach. The capabilities of a manufacturing process are represented by a formal language of shape, in which sentences correspond to manufacturable objects. The language is interpreted to describe process plans corresponding to the shape generation, complete with cost estimates. A macro layer that describes single operations of the machine is implemented on top of the formal language. The space it describes is searched by the generative simulated annealing algorithm, a stochastic search technique based on simulated annealing. Plans that are close to the optimum are generated in reasonable time.
C1 UNIV ABERDEEN, DEPT COMP SCI, ABERDEEN AB24 3UE, SCOTLAND.
   CARNEGIE MELLON UNIV, DEPT MECH ENGN, PITTSBURGH, PA 15213 USA.
C3 University of Aberdeen; Carnegie Mellon University
RI Brown, Kenneth N/G-6752-2012
OI Brown, Kenneth N/0000-0003-1853-0723; Cagan,
   Jonathan/0000-0002-3935-9219
CR [Anonymous], 1985, INTRO AUTOMATED PROC
   [Anonymous], P INT C COMP AID DES
   [Anonymous], 1991, PROC 4 INT C GENETIC
   BROWN KN, 1994, IFIP TRANS B, V18, P135
   Brown KN, 1996, ARTIF INTELL ENG, V10, P153, DOI 10.1016/0954-1810(95)00025-9
   BROWN KN, 1995, RES ENG DES, V7, P151, DOI 10.1007/BF01638097
   BROWN KN, 1992, ARTIFICIAL INTELLIGENCE IN DESIGN 92, P287
   BROWN KN, 1996, ADV FORMAL DESIGN ME, P59
   CAGAN J, 1993, ENVIRON PLANN B, V20, P5, DOI 10.1068/b200005
   CAGAN J, 1997, IN PRESS COMPUTATION
   Chuang S.-H., 1991, Research in Engineering Design, V2, P147, DOI 10.1007/BF01578996
   FINGER S, 1990, P 1 INT WORKSH FORM, P133
   FINGER S, 1990, 2 INT C DES THEOR ME
   Fitzhorn P. A., 1990, (AI EDAM) Artificial Intelligence for Engineering Design, Analysis and Manufacturing, V4, P151, DOI 10.1017/S0890060400002353
   FLEMMING U, 1987, ENVIRON PLANN B, V14, P323, DOI 10.1068/b140323
   FU Z, 1991, 1991 ASME DES AUT C
   GASCHNIG J, 1979, CMUCS79124
   Green R.E., 1992, MACHINERYS HDB
   HARVEY WD, 1995, THESIS U STANFORD ST
   HAYES C, 1989, J MANUF SYST, V8, P1, DOI 10.1016/0278-6125(89)90015-0
   JOSHI S, 1988, COMPUT AIDED DESIGN, V20, P58, DOI 10.1016/0010-4485(88)90050-4
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Knuth D. E., 1968, Mathematical Systems Theory, V2, P127, DOI 10.1007/BF01692511
   MAREFAT M, 1996, P 1996 ASME DES ENG
   Nau D. S., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1670
   Opitz H, 1970, CLASSIFICATION SYSTE
   PENJAM J, 1990, THEOR COMPUT SCI, V71, P241, DOI 10.1016/0304-3975(90)90200-2
   REDDY G, 1995, J MECH DESIGN, V117, P315, DOI 10.1115/1.2826141
   Rinderle J. R., 1991, Research in Engineering Design, V2, P137, DOI 10.1007/BF01578995
   SCHMIDT LC, 1995, RES ENG DES, V7, P102, DOI 10.1007/BF01606905
   SELMAN B, 1992, P 10 NAT C ART INT A, P440
   SHAH J, 1989, MANUFACTURING REV, V2, P204
   Shah J. J., 1991, Research in Engineering Design, V2, P93, DOI 10.1007/BF01579254
   SRIKANTAPPA AB, 1992, P ASME COMP ENG C, P245
   STINY G, 1978, ENVIRON PLANN B, V5, P5, DOI 10.1068/b050005
   Stiny G., 1991, Research in Engineering Design, V2, P171, DOI 10.1007/BF01578998
   STINY G, 1980, ENVIRON PLANN B, V7, P343, DOI 10.1068/b070343
   STINY G, 1981, ENVIRON PLANN B, V8, P257, DOI 10.1068/b080257
   SZYKMAN S, 1995, J MECH DESIGN, V117, P308, DOI 10.1115/1.2826140
   SZYKMAN S, 1993, ADV DESIGN AUTOMATIO, P527
NR 40
TC 36
Z9 36
U1 1
U2 3
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0890-0604
EI 1469-1760
J9 AI EDAM
JI AI EDAM-Artif. Intell. Eng. Des. Anal. Manuf.
PD JUN
PY 1997
VL 11
IS 3
BP 219
EP 235
DI 10.1017/S0890060400003140
PG 17
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Multidisciplinary;
   Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XQ043
UT WOS:A1997XQ04300005
DA 2023-11-10
ER

PT J
AU de Castro, GZ
   Guerra, RR
   Guimaraes, FG
AF de Castro, Giulia Zanon
   Guerra, Rubia Reis
   Guimaraes, Frederico Gadelha
TI Automatic translation of sign language with multi-stream 3D CNN and
   generation of artificial depth maps
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Sign language recognition; Gesture recognition; Deep learning; 3D
   convolutional neural networks; Computer vision; Generative adversarial
   networks
AB Sign languages play an essential role in the cognitive and social development of the deaf, consisting of a natural form of communication and being a symbol of identity and culture. However, hearing loss has a severe social impact due to an existing communication barrier, preventing access to essential services such as education and health. A bi-directional sign language translation may be the solution to bridging the communication gap between the deaf and the listener, completing a two-way communication cycle. Virtual personal assistants can benefit from this technology by extending how users interact with the intelligent system. With this idea, in this work we develop a multi-stream deep learning model to recognize signs of Brazilian (BSL), Indian (ISL), and Korean (KSL) Sign Languages. We combine different types of information for the classification task, using single-stream and multi-stream 3D Convolutional Neural Networks. In addition, considering the largest source of sign data globally - the internet - we propose a depth sensor-free classification method, with depth maps artificially generated through Generative Adversarial Networks. In order to consider the main parameters that encode sign languages, the final architecture is composed of a multi-stream network that receives the segmented hands, the faces, the distances and speeds of the points of articulation, and the RGB frames associated with artificial depth maps. Finally, we provide a visual explanation to understand which regions were important for model decision-making. The best models were obtained using the multi-stream network, presenting an accuracy of 0.91 +/- 0.07, and f1-score of 0.90 +/- 0.08 on publicly available BSL data set. The results suggest that the multi-stream network with artificially generated depth maps is suitable for the task of sign recognition in different languages.
C1 [de Castro, Giulia Zanon; Guerra, Rubia Reis; Guimaraes, Frederico Gadelha] Univ Fed Minas Gerais, Dept Elect Engn, Machine Intelligence & Data Sci Lab MINDS, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
   [de Castro, Giulia Zanon] Univ Fed Minas Gerais, Grad Program Elect Engn, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais; Universidade Federal de Minas
   Gerais
RP Guimaraes, FG (通讯作者)，Univ Fed Minas Gerais, Dept Elect Engn, Machine Intelligence & Data Sci Lab MINDS, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
EM giuliaz@ufmg.br; rubiarg@cs.ubc.ca; fredericoguimaraes@ufmg.br
RI Guimaraes, Frederico G/F-3937-2010
OI Guimaraes, Frederico G/0000-0001-9238-8839
FU Coordination for the Im-provement of Higher Education Personnel (CAPES,
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior); Foundation
   for Re-search of the State of Minas Gerais (FAPEMIG, Fundacao de Amparo
   a Pesquisa do Estado de Minas Gerais); National Council for Scientific
   and Technological Development (CNPq), Brazil [306850/2016-8,
   312991/2020-7]
FX This work has been supported by the Coordination for the Im-provement of
   Higher Education Personnel (CAPES, Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior), the Foundation for Re-search of the State of
   Minas Gerais (FAPEMIG, Fundacao de Amparo a Pesquisa do Estado de Minas
   Gerais) and by the National Council for Scientific and Technological
   Development (CNPq), Brazil, Grants no. 306850/2016-8 and 312991/2020-7.
   We thank Dr. Silvia Grasiella from the Federal Institute of Minas Gerais
   (IFMG), https://www.ifmg. edu.br/ouropreto, in the city of Ouro Preto,
   Brazil, and the MINDS (Machine Intelligence and Data Science) Laboratory
   at UFMG, https://minds.eng.ufmg.br/, for the database acquisition and
   curating. The authors would like to thank the anonymous reviewers for
   their earnest efforts and thorough review of our manuscript.
CR Almeida Silvia GM, 2019, Zenodo, DOI 10.5281/ZENODO.2667329
   Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   Amrutha K, 2021, 2021 INT C INNOVATIV, P1
   Bai Y., 2000, COLUMBIA SOCIAL WORK, V18, P37, DOI [10.7916/CSWR.V18I1.5928, DOI 10.7916/CSWR.V18I1.5928]
   Barnett S, 2011, AM J PUBLIC HEALTH, V101, P2235, DOI 10.2105/AJPH.2011.300247
   Bilge Y. C., 2022, IEEE T PATTERN ANAL
   Bragg D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P16, DOI 10.1145/3308561.3353774
   Brito L. F., 2010, GRAMATICA LINGUAS SI
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cerna LR, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114179
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chong TW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103554
   Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175
   Zeiler MD, 2013, Arxiv, DOI arXiv:1301.3557
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008
   Dhanjal AS, 2022, MULTIMED TOOLS APPL, V81, P4283, DOI 10.1007/s11042-021-11706-1
   Du Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030458
   Escalera S., 2017, GESTURE RECOGNITION
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Forshay Lance, 2016, SIGNALOUD OPEN LETT
   Fuhl W, 2019, IEEE INT CONF COMP V, P4406, DOI 10.1109/ICCVW.2019.00541
   Geng WD, 2016, SCI REP-UK, V6, DOI 10.1038/srep36571
   Goodfellow I., 2014, ADV NEURAL INFORM PR, V27
   Guzsvinecz T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051072
   Hosain A, 2019, PR INT CONF DATA SC, P203, DOI 10.1109/DSAA.2019.00035
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391
   Huang J., 2018, 32 AAAI C ART INT
   Isola Phillip, 2017, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2017.632
   Jadon S., 2020, VIDEO SUMMARIZATION
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Katilmis Z, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115213
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Kushalnagar P, 2018, PUBLIC HEALTH NUTR, V21, P912, DOI 10.1017/S1368980017002865
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lee CKM, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114403
   Li HS, 2020, MULTIMED TOOLS APPL, V79, P27583, DOI 10.1007/s11042-020-09299-2
   Liang ZJ, 2018, COMPUT J, V61, P1724, DOI 10.1093/comjnl/bxy049
   Lupinetti K, 2020, LECT NOTES COMPUT SC, V12242, P420, DOI 10.1007/978-3-030-58465-8_31
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/SmartCity.2015.38, 10.1109/NEBEC.2015.7117114]
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Masood Sarfaraz, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P623, DOI 10.1007/978-981-10-7566-7_63
   Meulder M., 2019, LEGAL RECOGNITION SI
   Passos WL, 2021, IEEE T CIRCUITS-I, V68, P4761, DOI 10.1109/TCSI.2021.3091001
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Raghuveera T, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-019-1250-6
   Rastgoo R, 2021, IEEE COMPUT SOC CONF, P3446, DOI 10.1109/CVPRW53098.2021.00384
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2021, MULTIMED TOOLS APPL, V80, P127, DOI 10.1007/s11042-020-09700-0
   Rezende T., 2016, 29 SIBGRAPI WORKSH F, P1
   Rezende TM, 2021, NEURAL COMPUT APPL, V33, P10449, DOI 10.1007/s00521-021-05802-4
   Santos AS, 2019, REV LAT-AM ENFERM, V27, DOI 10.1590/1518-8345.2612.3127
   Seredin OS, 2019, INT ARCH PHOTOGRAMM, V42-2, P189, DOI 10.5194/isprs-archives-XLII-2-W12-189-2019
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Sridhar A, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1366, DOI 10.1145/3394171.3413528
   Stergiou A, 2019, IEEE IMAGE PROC, P1830, DOI [10.1109/icip.2019.8803153, 10.1109/ICIP.2019.8803153]
   Tahir Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P823, DOI 10.1109/ICDSP.2015.7251991
   Tyrone ME, 2010, J PHONETICS, V38, P317, DOI 10.1016/j.wocn.2010.02.003
   Vahdani E., 2022, RECOGNIZING AM SIGN
   Venugopalan A, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115601
   Vogler C., 2003, THESIS CITESEER
   Wadhawan A, 2021, ARCH COMPUT METHOD E, V28, P785, DOI 10.1007/s11831-019-09384-2
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang HG, 2006, J INF SCI ENG, V22, P1109
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Yan JL, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422550035
   Yang S, 2020, LECT NOTES COMPUT SC, V11961, P532, DOI 10.1007/978-3-030-37731-1_43
   Yongsen Ma, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191755
   Zhang L, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3377553
NR 71
TC 1
Z9 1
U1 5
U2 26
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD APR 1
PY 2023
VL 215
AR 119394
DI 10.1016/j.eswa.2022.119394
EA DEC 2022
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA 6V8QC
UT WOS:000895304000003
DA 2023-11-10
ER

PT S
AU Terasawa, K
   Nagasaki, T
   Kawashima, T
AF Terasawa, K
   Nagasaki, T
   Kawashima, T
BE Bunke, H
   Spitz, AL
TI Automatic keyword extraction from historical document images
SO DOCUMENT ANALYSIS SYSTEMS VII, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 7th International Workshop on Document Analysis Systems
CY FEB 13-15, 2006
CL Nelson, NEW ZEALAND
SP Int Assoc Pattern Recognit, Siemens AG, Human Ware Grp, Hitachi Cent Res Lab, DocRec Ltd, Univ Bern
AB This paper presents an automatic keyword extraction method from historical document images. The proposed method is language independent because it is purely appearance based, where neither lexical information nor any other statistical language models are required. Moreover, since it does not need word segmentation, it can be applied to Eastern languages where they do not put clear spacing between words. The first half of the paper describes the algorithm to retrieve document image regions which have similar appearance to the given query image. The algorithm was evaluated in recall-precision manner, and showed its performance of over 80-90% average precision. The second half of the paper describes the keyword extraction method which works even if no query word is explicitly specified. Since the computational cost was reduced by the efficient pruning techniques, the system could extract keywords successfully from relatively large documents.
C1 Future Univ Hakodate, Sch Syst Informat Sci, Hakodate, Hokkaido 0418655, Japan.
C3 Future University Hakodate
RP Terasawa, K (通讯作者)，Future Univ Hakodate, Sch Syst Informat Sci, 116-2 Kamedanakano Cho, Hakodate, Hokkaido 0418655, Japan.
EM g3103004@fun.ac.jp; nagasaki@fun.ac.jp; kawasima@fun.ac.jp
CR Fink GA, 2005, PROC INT CONF DOC, P1070, DOI 10.1109/ICDAR.2005.172
   Gatos B, 2005, PROC INT CONF DOC, P54, DOI 10.1109/ICDAR.2005.30
   Lu Y, 2002, INT C PATT RECOG, P57, DOI 10.1109/ICPR.2002.1047794
   Manmatha R, 1996, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.1996.517139
   Marinai S, 2003, PROC INT CONF DOC, P223
   Oka R, 1998, COMPUT J, V41, P559, DOI 10.1093/comjnl/41.8.559
   Rath TM, 2003, PROC CVPR IEEE, P521
   Rath TM, 2003, PROC INT CONF DOC, P218
   Terasawa K, 2005, PROC INT CONF DOC, P437
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
NR 11
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-32140-3
J9 LECT NOTES COMPUT SC
PY 2006
VL 3872
BP 413
EP 424
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA BDW09
UT WOS:000235773400037
DA 2023-11-10
ER

PT J
AU DellaPietra, S
   DellaPietra, V
   Lafferty, J
AF DellaPietra, S
   DellaPietra, V
   Lafferty, J
TI Inducing features of random fields
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE random field; Kullback-Leibler divergence; iterative scaling; maximum
   entropy; EM algorithm; statistical learning; clustering; word
   morphology; natural language processing
ID MAXIMUM-LIKELIHOOD; IMAGES; DISTRIBUTIONS
AB We present a technique for constructing random fields from a see of training samples. The learning paradigm builds increasingly complex fields by allowing potential functions, or features, that are supported by increasingly large subgraphs. Each feature has a weight that is trained by minimizing the Kuliback-Leibler divergence between the model and the empirical distribution of the training data. A greedy algorithm determines how features are incrementally added to the field and an iterative scaling algorithm is used to estimate the optimal values of the weights. The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated. Relations to other learning approaches, including decision trees, are given. As a demonstration of the method, we describe its application to the problem of automatic word classification in natural language processing.
C1 CARNEGIE MELLON UNIV,SCH COMP SCI,DEPT COMP SCI,PITTSBURGH,PA 15213.
C3 Carnegie Mellon University
RP DellaPietra, S (通讯作者)，RENAISSANCE TECHNOL,STONY BROOK,NY 11790, USA.
CR ALMEIDA MP, 1993, ANN APPL PROBAB, V3, P103
   [Anonymous], 1992, ANN APPL PROBAB
   BALRAM N, 1993, IEEE T INFORM THEORY, V39, P1333, DOI 10.1109/18.243450
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BREIAMN L, 1984, CLASSIFICATION REGRE
   Brown D. T., 1959, INFORM CONTROL, V2, P386, DOI DOI 10.1016/S0019-9958(59)80016-4
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Brown P. F., 1990, Computational Linguistics, V16, P79
   CHALMOND B, 1989, PATTERN RECOGN, V22, P747, DOI 10.1016/0031-3203(89)90011-3
   CSISZAR I, 1989, ANN STAT, V17, P1409, DOI 10.1214/aos/1176347279
   CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454
   Csiszar I., 1984, STAT DECISIONS DEDEW, V1, P205
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DIACONIS P, 1979, ANN STAT, V7, P269, DOI 10.1214/aos/1176344611
   FERRARI P, 1993, ANN APPL PROBAB, V3, P137
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GEYER CJ, 1992, J R STAT SOC B, V54, P657
   JAYNES E. T., 1983, PAPERS PROBABILITY S
   LAFFERTY J, 1993, P 9 ANN C U WAT CTR
   POTAMIANOS GG, 1993, IEEE T INFORM THEORY, V39, P1322, DOI 10.1109/18.243449
   YOUNES L, 1988, ANN I H POINCARE-PR, V24, P269
NR 22
TC 466
Z9 484
U1 0
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314
SN 0162-8828
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD APR
PY 1997
VL 19
IS 4
BP 380
EP 393
DI 10.1109/34.588021
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW122
UT WOS:A1997WW12200008
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Monshi, MMA
   Poon, J
   Chung, V
AF Monshi, Maram Mahmoud A.
   Poon, Josiah
   Chung, Vera
TI Deep learning in generating radiology reports: A survey
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Convolutional neural network; Deep learning; Natural language
   processing; Radiology; Recurrent neural network
ID SEGMENTATION
AB Substantial progress has been made towards implementing automated radiology reporting models based on deep learning (DL). This is due to the introduction of large medical text/image datasets. Generating radiology coherent paragraphs that do more than traditional medical image annotation, or single sentence-based description, has been the subject of recent academic attention. This presents a more practical and challenging application and moves towards bridging visual medical features and radiologist text. So far, the most common approach has been to utilize publicly available datasets and develop DL models that integrate convolutional neural networks (CNN) for image analysis alongside recurrent neural networks (RNN) for natural language processing (NLP) and natural language generation (NLG). This is an area of research that we anticipate will grow in the near future. We focus our investigation on the following critical challenges: understanding radiology text/image structures and datasets, applying DL algorithms (mainly CNN and RNN), generating radiology text, and improving existing DL based models and evaluation metrics. Lastly, we include a critical discussion and future research recommendations. This survey will be useful for researchers interested in DL, particularly those interested in applying DL to radiology reporting.
C1 [Monshi, Maram Mahmoud A.; Poon, Josiah; Chung, Vera] Univ Sydney, Sch Comp Sci, Sydney, NSW, Australia.
   [Monshi, Maram Mahmoud A.] Taif Univ, Dept Informat Technol, At Taif, Saudi Arabia.
C3 University of Sydney; Taif University
RP Monshi, MMA (通讯作者)，Univ Sydney, Sch Comp Sci, Sydney, NSW, Australia.
EM mmon4544@uni.sydney.edu.au
RI Poon, Josiah/IUP-0510-2023
OI Monshi, Maram/0000-0001-5622-1601
CR Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC
   Akay A, 2019, IEEE J BIOMED HLTH I
   Alom M.Z., 2018, P IEEE C COMP VIS PA, DOI DOI 10.48550/ARXIV.1803.01164
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2018, IMAGING RADIOLOGY ME
   [Anonymous], 2020, ACR RECOMMENDATIONS
   [Anonymous], 2016, P SAI INTELLIGENT SY, DOI DOI 10.1007/978-3-319-56991-8_32
   Bertrand H., 2019, ARXIV PREPRINT ARXIV
   Biswas M, 2019, FRONT BIOSCI-LANDMRK, V24, P392, DOI 10.2741/4725
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bustos A, 2020, MED IMAGE ANAL, V66, DOI 10.1016/j.media.2020.101797
   Chaudhari AS, 2018, MAGN RESON MED, V80, P2139, DOI 10.1002/mrm.27178
   Cheng JZ, 2016, SCI REP-UK, V6, DOI [10.1038/srep21808, 10.1038/srep24454]
   Cho K, 2014, ARXIV14061078, DOI [10.3115/v1/d14, DOI 10.3115/V1/D14-1179]
   Clevert D.-A., 2015, FAST ACCURATE DEEP N
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2018, DEEP LEARNING NATURA
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348
   Dong YX, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P51, DOI 10.1109/CHASE.2017.59
   Erickson BJ, 2018, J AM COLL RADIOL, V15, P521, DOI 10.1016/j.jacr.2017.12.027
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249
   Glorot Xavier, 2011, P 14 INT C ART INT S, P315, DOI DOI 10.1002/ECS2.1832
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Guo J, 2018, ARTIF INTELL MED, V90, P25, DOI 10.1016/j.artmed.2018.06.006
   Hassanpour S, 2016, J DIGIT IMAGING, V29, P59, DOI 10.1007/s10278-015-9823-3
   He X, 2018, DEEP LEARNING NATURA, P289, DOI DOI 10.1007/978-981-10-5209-5_10
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Hicks SA, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P490, DOI 10.1145/3204949.3208113
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Huang Gao, 2017, PROC CVPR IEEE, P4700, DOI DOI 10.1109/CVPR.2017.243
   Irvin J, 2019, ARXIV190107031, V33, P590, DOI DOI 10.1609/AAAI.V33I01.3301590
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jing B, 2017, ACL
   Johnson A.E., 2019, MIMIC CXR JPG LARGE
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kilickaya M., 2016, ARXIV161207600
   Kisilev P, 2016, LECT NOTES COMPUT SC, V10008, P121, DOI 10.1007/978-3-319-46976-8_13
   Kohli M, 2017, AM J ROENTGENOL, V208, P754, DOI 10.2214/AJR.16.17224
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lakhani P, 2018, J AM COLL RADIOL, V15, P350, DOI 10.1016/j.jacr.2017.09.044
   Lam C, 2018, INVEST OPHTH VIS SCI, V59, P590, DOI 10.1167/iovs.17-22721
   Langlotz CP, 2006, RADLEX NEW METHOD IN
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SM, 2019, J THORAC IMAG, V34, P75, DOI 10.1097/RTI.0000000000000387
   Li Y., 2018, P 32 INT C NEUR INF, P1537
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, DOI DOI 10.2307/3105454
   Lin Chin-Yew, 2004, P 42 ANN M ASS COMP, P5, DOI DOI 10.3115/1218955.1219032
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   McBee MP, 2018, ACAD RADIOL
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Monshi MMA, 2019, NEUR INF PROC ICONIP, P1
   Nwankpa C., 2018, ACTIVATION FUNCTIONS
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Peng Yifan, 2018, AMIA Jt Summits Transl Sci Proc, V2017, P188
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Rubin J., 2018, ARXIV180407839
   Sahu B. K., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P256, DOI 10.1109/ICECTECH.2011.5942093
   SCHUYLER PL, 1993, B MED LIBR ASSOC, V81, P217
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Shin HC, 2017, ELS MIC SOC BOOK SER, P405, DOI 10.1016/B978-0-12-810408-8.00023-7
   Shin HC, 2016, J MACH LEARN RES, V17
   Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274
   Shin HC, 2015, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2015.7298712
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Six O., 2019, ARTIFICIAL INTELLIGE
   Statistics, 2020, STAT DIAGN IM DAT
   Stock P, 2018, LECT NOTES COMPUT SC, V11210, P504, DOI 10.1007/978-3-030-01231-1_31
   Szegedy  C., 2017, AAAI, V4, P1
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thanki R. M., 2019, HYBRID ADV COMPRESSI, P1
   van Ginneken B, 2011, RADIOLOGY, V261, P719, DOI 10.1148/radiol.11091710
   VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087
   Wang F, 2018, JAMA INT MED
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang H, 2018, CORR
   Wang J, 2016, SCI REP-UK, V6, P1, DOI [10.1038/srep19883, DOI 10.1038/SREP27327, DOI 10.1038/S41598-016-0001-8]
   Wang X, 2016, ARXIV160307965
   Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943
   Wang Xiaosong, 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wong H. Y. F., 2020, RADIOLOGY, DOI [10.1148/radiol.2020201160, DOI 10.1148/RADIOL.2020201160]
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue Y, 2018, LECT NOTES COMPUT SC, V11070, P457, DOI 10.1007/978-3-030-00928-1_52
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang SH, 2017, PROC CVPR IEEE, P4264, DOI 10.1109/CVPR.2017.454
   ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
NR 103
TC 52
Z9 53
U1 4
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JUN
PY 2020
VL 106
AR 101878
DI 10.1016/j.artmed.2020.101878
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA MC8XK
UT WOS:000543562200004
PM 32425358
OA Bronze, Green Published
DA 2023-11-10
ER

PT J
AU Abdelaziz, I
   Abdou, S
   Al-Barhamtoshy, H
AF Abdelaziz, Ibrahim
   Abdou, Sherif
   Al-Barhamtoshy, Hassanin
TI A large vocabulary system for Arabic online handwriting recognition
SO PATTERN ANALYSIS AND APPLICATIONS
LA English
DT Article
DE Online handwriting recognition; Arabic; Large vocabulary; Adaptive
   training; Hidden Markov models; Advanced modeling
AB The success of using Hidden Markov Models (HMMs) for speech recognition application has motivated the adoption of these models for handwriting recognition especially the online handwriting that has large similarity with the speech signal as a sequential process. Some languages such as Arabic, Farsi and Urdo include large number of delayed strokes that are written above or below most letters and usually written delayed in time. These delayed strokes represent a modeling challenge for the conventional left-right HMM that is commonly used for Automatic Speech Recognition (ASR) systems. In this paper, we introduce a new approach for handling delayed strokes in Arabic online handwriting recognition using HMMs. We also show that several modeling approaches such as context based tri-grapheme models, speaker adaptive training and discriminative training that are currently used in most state-of-the-art ASR systems can provide similar performance improvement for Hand Writing Recognition (HWR) systems. Finally, we show that using a multi-pass decoder that use the computationally less expensive models in the early passes can provide an Arabic large vocabulary HWR system with practical decoding time. We evaluated the performance of our proposed Arabic HWR system using two databases of small and large lexicons. For the small lexicon data set, our system achieved competing results compared to the best reported state-of-the-art Arabic HWR systems. For the large lexicon, our system achieved promising results (accuracy and time) for a vocabulary size of 64k words with the possibility of adapting the models for specific writers to get even better results.
C1 [Abdelaziz, Ibrahim; Abdou, Sherif] Cairo Univ, Fac Comp & Informat, 5 Dr Ahmed Zewail St, Giza, Egypt.
   [Al-Barhamtoshy, Hassanin] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Cairo University; King Abdulaziz
   University
RP Abdelaziz, I (通讯作者)，Cairo Univ, Fac Comp & Informat, 5 Dr Ahmed Zewail St, Giza, Egypt.
EM i.hosny@fci-cu.edu.eg; s.abdou@fci-cu.edu.eg
RI Abdelaziz, Ibrahim/AAE-2152-2021; Al-Barhamtoshy, Hassanin/I-7125-2013
OI Abdelaziz, Ibrahim/0000-0003-1449-5115; Al-Barhamtoshy,
   Hassanin/0000-0003-3915-9513
FU National Plan for Science, Technology and Innovation (MAARIFAH), King
   Abdulaziz City for Science and Technology, Kingdom of Saudi Arabia
   [11-INF-1997-03]; Science and Technology Unit, King Abdulaziz University
FX Dr. Hassanin likes to acknowledge the National Plan for Science,
   Technology and Innovation (MAARIFAH), King Abdulaziz City for Science
   and Technology, Kingdom of Saudi Arabia-award number (11-INF-1997-03).
   He also acknowledges and thank the Science and Technology Unit, King
   Abdulaziz University for their support.
CR Abdelazeem S, 2011, PROC INT CONF DOC, P1304, DOI 10.1109/ICDAR.2011.262
   Abdelaziz I, 2014, UNPUB
   Al-Taani A. T., 2005, INT J COMPUTATIONAL, V2, P107
   ALMUALLIM H, 1987, IEEE T PATTERN ANAL, V9, P715, DOI 10.1109/TPAMI.1987.4767970
   Anastasakos T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1137, DOI 10.1109/ICSLP.1996.607807
   Biadsy F., 2006, P INT WORKSH FRONT H
   Daifallah Khaled, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P886, DOI 10.1109/ICDAR.2009.169
   El Abed H, 2011, INT J DOC ANAL RECOG, V14, P15, DOI 10.1007/s10032-010-0124-6
   Elanwar RI, 2007, PROC WRLD ACAD SCI E, V23, P288
   ELWAKIL MS, 1989, PATTERN RECOGN, V22, P97, DOI 10.1016/0031-3203(89)90058-7
   Gales MJF, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P15, DOI 10.1109/ASRU.2001.1034578
   Ghods V, 2011, P 3 INT C COMP ENG T
   Ghods V, 2013, PATTERN RECOGN LETT, V34, P486, DOI 10.1016/j.patrec.2012.12.005
   Ha J, 1993, 3 INT WORKSH FRONT H
   Hu JY, 2000, PATTERN RECOGN, V33, P133, DOI 10.1016/S0031-3203(99)00043-6
   Huang BQ, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P793, DOI 10.1109/ISDA.2007.31
   Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559
   Julian F, 2008, ADV BIOMETRICS
   Kharma NN, 2001, PATTERN RECOGN, V34, P2115, DOI 10.1016/S0031-3203(00)00140-0
   Khorsheed MS, 2003, PATTERN RECOGN LETT, V24, P2235, DOI 10.1016/S0167-8655(03)00050-3
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Razavi S. M., 2006, J ELECT COMPUTER ENG, V2, P63
   Starner T, 1994, AC SPEECH SIGN PROC
   Wulandhari L. A., 2008, GRAPHICS VISION IMAG, V8, P17
   Young S., 1997, HTK BOOK, V2
   Zhou DY, 2009, IEEE T KNOWL DATA EN, V21, P66, DOI 10.1109/TKDE.2008.95
NR 26
TC 11
Z9 11
U1 1
U2 13
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1433-7541
EI 1433-755X
J9 PATTERN ANAL APPL
JI Pattern Anal. Appl.
PD NOV
PY 2016
VL 19
IS 4
BP 1129
EP 1141
DI 10.1007/s10044-015-0526-7
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EE7ME
UT WOS:000389801200016
DA 2023-11-10
ER

PT J
AU Pavlopoulos, J
   Romell, A
   Curman, J
   Steinert, O
   Lindgren, T
   Borg, M
   Randl, K
AF Pavlopoulos, John
   Romell, Alv
   Curman, Jacob
   Steinert, Olof
   Lindgren, Tony
   Borg, Markus
   Randl, Korbinian
TI Automotive fault nowcasting with machine learning and natural language
   processing
SO MACHINE LEARNING
LA English
DT Article; Early Access
DE Automotive fault nowcasting; Natural language processing; Multilingual
   text classification
AB Automated fault diagnosis can facilitate diagnostics assistance, speedier troubleshooting, and better-organised logistics. Currently, most AI-based prognostics and health management in the automotive industry ignore textual descriptions of the experienced problems or symptoms. With this study, however, we propose an ML-assisted workflow for automotive fault nowcasting that improves on current industry standards. We show that a multilingual pre-trained Transformer model can effectively classify the textual symptom claims from a large company with vehicle fleets, despite the task's challenging nature due to the 38 languages and 1357 classes involved. Overall, we report an accuracy of more than 80% for high-frequency classes and above 60% for classes with reasonable minimum support, bringing novel evidence that automotive troubleshooting management can benefit from multilingual symptom text classification.
C1 [Pavlopoulos, John; Lindgren, Tony; Randl, Korbinian] Stockholm Univ, Dept Comp & Syst Sci, Stockholm, Sweden.
   [Steinert, Olof; Lindgren, Tony] Scania CV, Strateg Prod Planning & Adv Analyt, Sodertalje, Sweden.
   [Romell, Alv; Curman, Jacob; Borg, Markus] Lund Univ, Dept Comp Sci, Lund, Sweden.
C3 Stockholm University; Scania; Lund University
RP Pavlopoulos, J (通讯作者)，Stockholm Univ, Dept Comp & Syst Sci, Stockholm, Sweden.
EM ioannis@dsv.su.se; alvromell@gmail.com; curmanjacob@gmail.com;
   olof.steinert@scania.com; tony@dsv.su.se; markus.borg@cs.lth.se;
   korbinian.randl@dsv.su.se
RI Borg, Markus/F-3609-2010
OI Borg, Markus/0000-0001-7879-4371
FU Stockholm University; European Union [101093026]
FX Open access funding provided by Stockholm University. Funding for this
   research has been provided by the European Union's Horizon Europe
   research and innovation programme EFRA (Grant Agreement Number
   101093026). Funded by the European Union. Views and opinions expressed
   are however those of the author(s) only and do not necessarily reflect
   those of the European Union or European Commission-EU. Neither the
   European Union nor the granting authority can be held responsible for
   them.
CR Adamopoulou E., 2020, OVERVIEW CHATBOT TEC, P373, DOI [10.1007/978-3-030-49186-4_31, DOI 10.1007/978-3-030-49186-4_31]
   Aktas EU, 2020, EMPIR SOFTW ENG, V25, P3544, DOI 10.1007/s10664-020-09846-3
   Biteus J, 2017, SAE INT J MATER MANU, V10, P306, DOI 10.4271/2017-01-0237
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borg M., 2014, RECOMMENDATION SYSTE, P477
   Borsci Simone, 2022, Personal and Ubiquitous Computing, V26, P95, DOI 10.1007/s00779-021-01582-9
   Carvalho TP, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106024
   Conneau A, 2020, Arxiv, DOI [arXiv:1911.02116, 10.48550/arXiv.1911.02116]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Fink O, 2020, ENG APPL ARTIF INTEL, V92, DOI 10.1016/j.engappai.2020.103678
   Irving J, 2021, SCHIZOPHRENIA BULL, V47, P405, DOI 10.1093/schbul/sbaa126
   Jonsson L, 2016, EMPIR SOFTW ENG, V21, P1533, DOI 10.1007/s10664-015-9401-9
   Joulin A, 2016, Arxiv, DOI arXiv:1607.01759
   Izquierdo JL, 2020, J MED INTERNET RES, V22, DOI 10.2196/21801
   Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726
   Nath AG, 2021, ARTIF INTELL REV, V54, P2609, DOI 10.1007/s10462-020-09910-w
   Qian CH, 2022, NEURAL PROCESS LETT, V54, P2509, DOI 10.1007/s11063-021-10719-z
   Safaeipour H, 2021, J PROCESS CONTR, V97, P1, DOI 10.1016/j.jprocont.2020.11.005
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Shaheen Z, 2020, Arxiv, DOI [arXiv:2010.12871, 10.48550/arXiv.2010.12871]
   Theissler A, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107864
   Thorne C, 2017, LANG LINGUIST COMPAS, V11, DOI 10.1111/lnc3.12253
   Vaish R, 2021, ENG APPL ARTIF INTEL, V106, DOI 10.1016/j.engappai.2021.104504
   Wang W, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER AIDED EDUCATION (ICISCAE 2018), P64, DOI 10.1109/ICISCAE.2018.8666928
   Zhang TC, 2022, ISA T, V119, P152, DOI 10.1016/j.isatra.2021.02.042
   Zhao ZB, 2021, CHIN J MECH ENG-EN, V34, DOI 10.1186/s10033-021-00570-7
NR 26
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD 2023 OCT 2
PY 2023
DI 10.1007/s10994-023-06398-7
EA OCT 2023
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T1WZ1
UT WOS:001075969400001
OA hybrid
DA 2023-11-10
ER

PT J
AU Zeng, ZH
   Bhat, S
AF Zeng, Ziheng
   Bhat, Suma
TI Idiomatic Expression Identification using Semantic Compatibility
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Idiomatic expressions are an integral part of natural language and constantly being added to a language. Owing to their non-compositionality and their ability to take on a figurative or literal meaning depending on the sentential context, they have been a classical challenge for NLP systems. To address this challenge, we study the task of detecting whether a sentence has an idiomatic expression and localizing it when it occurs in a figurative sense. Prior research for this task has studied specific classes of idiomatic expressions offering limited views of their generalizability to new idioms. We propose a multi-stage neural architecture with attention flow as a solution. The network effectively fuses contextual and lexical information at different levels using word and sub-word representations. Empirical evaluations on three of the largest benchmark datasets with idiomatic expressions of varied syntactic patterns and degrees of non-compositionality show that our proposed model achieves new state-of-the-art results. A salient feature of the model is its ability to identify idioms unseen during training with gains from 1.4% to 30.8% over competitive baselines on the largest dataset.
C1 [Zeng, Ziheng; Bhat, Suma] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign
RP Zeng, ZH (通讯作者)，Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
EM zzeng13@illinois.edu; spbhat2@illinois.edu
OI Bhat, Suma/0000-0003-0324-5890
FU IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR)-a
   research collaboration as part of the IBM AI Horizons Network
FX We thank the anonymous reviewers for their comments on earlier drafts
   that significantly helped improve this manuscript. This work was
   supported by the IBM-ILLINOIS Center for Cognitive Computing Systems
   Research (C3SR)-a research collaboration as part of the IBM AI Horizons
   Network.
CR [Anonymous], 2010, P 23 INT C COMPUTATI
   [Anonymous], 1999, NATURE IDIOMS SYSTEM
   [Anonymous], 2006, P WORKSH MULT EXPR I
   Baldwin T, 2005, COMPUT SPEECH LANG, V19, P398, DOI 10.1016/j.csl.2005.02.004
   Baldwin T, 2010, CH CRC MACH LEARN PA, P267
   Baroni M, 2009, LANG RESOUR EVAL, V43, P209, DOI 10.1007/s10579-009-9081-4
   Biddle R, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1217, DOI 10.1145/3366423.3380198
   Bird S, 2004, P ACL INTERACTIVE PO, P214
   Blunsom P., 2007, THESIS U MELBOURNE M
   BNC Consortium, 2007, BRIT NATL CORPUS
   BOBROW SA, 1973, MEM COGNITION, V1, P343, DOI 10.3758/BF03198118
   Constant M, 2017, COMPUT LINGUIST, V43, P837, DOI 10.1162/COLI_a_00302
   Cook P., 2008, P LREC WORKSH SHAR T, P19
   Cordeiro S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1986
   Devlin J., 2018, ARXIV, V1, P4171
   Dong Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3393
   Evert S, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P188
   Fadaee M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P925
   Fazly A, 2009, COMPUT LINGUIST, V35, P61, DOI 10.1162/coli.08-010-R1-07-048
   Fazly Afsaneh, 2006, 11 C EUR CHAPT ASS C
   Feldman Anna, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P435, DOI 10.1007/978-3-642-37247-6_35
   Filippova K., 2015, P 2015 C EMPIRICAL M, P360
   Flor M., 2018, P 2018 C N AM CHAPT, P86
   Fothergill Richard, 2012, P 1 JOINT C LEX COMP, P100
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, P758
   Gong HY, 2020, FIGURATIVE LANGUAGE PROCESSING, P146
   Gong Hongyu, 2017, P AAAI C ART INT, V31
   Green S, 2013, COMPUT LINGUIST, V39, P195, DOI 10.1162/COLI_a_00139
   Haagsma H, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P279
   Hashimoto Chikara, 2006, COLINGACL 2006 21 IN, P353
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Jang H., 2015, P 16 ANN M SPEC INT, P384
   KATZ JJ, 1963, LANGUAGE, V39, P170, DOI 10.2307/411200
   Korkontzelos I, 2013, 2 JOINT C LEX COMP S, P39
   Korkontzelos loannis, 2010, HLT NAACL, P636
   Kumar T, 2020, FIGURATIVE LANGUAGE PROCESSING, P116
   Kurfali Murathan, 2020, P JOINT WORKSH MULT, P85
   Liu CS, 2019, AAAI CONF ARTIF INTE, P6738
   Liu CS, 2017, AAAI CONF ARTIF INTE, P3230
   Liu Changsheng., 2019, THESIS U PITTSBURGH
   Liu Pengfei., 2017, P 2017 C EMPIRICAL M, P1204
   Malmi E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5054
   Mao R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3888
   McCarthy Diana, 2007, P 2007 JOINT C EMP M, P369
   Moon R., 1998, FIXED EXPRESSIONS ID
   Nasr A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1116
   Nivre Joakim, 2004, P METH EV MULT UN RE
   PEARCE DARREN, 2001, P WORKSHOP WORDNET O, P41
   Peng J., 2014, P 2014 C EMPIRICAL M, P2019
   Peng Jing, 2016, COMMUN COMPUT PHYS, V656, P17, DOI [10.1007/978-3-319-55209, DOI 10.1007/978-3-319-55209]
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Reddy Siva, 2011, P 5 INT JOINT C NATU, P210
   Sag I. A., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P1
   Salton Giancarlo., 2014, P 3 WORKSHOP HYBRID, P36, DOI [10.3115/v1/W14-1007, DOI 10.3115/V1/W14-1007]
   Salton GD, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P194
   Savary A., 2017, P 13 WORKSH MULT EXP, P31
   Schneider Nathan, 2015, P 2015 C N AM CHAPT, P1537, DOI DOI 10.3115/V1/N15-1177
   Schone P, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P100
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Scott D., 2020, P 28 INT C COMPUTATI, P627
   Seo Min Joon, 2017, 5 INT C LEARN REPR I
   Shutova E, 2013, COMPUT LINGUIST, V39, P301, DOI 10.1162/COLI_a_00124
   Sporleder Caroline, 2009, P 12 C EUR ACL, P754
   Srivastava R. K., 2015, SEV SAV STAT CAST
   Steen GJ, 2010, METHOD LINGUISTIC ME, DOI 10.1075/celcr.14
   Stevenson M, 2001, COMPUT LINGUIST, V27, P321, DOI 10.1162/089120101317066104
   Su CD, 2020, FIGURATIVE LANGUAGE PROCESSING, P30
   Tabossi P, 2008, J EXP PSYCHOL LEARN, V34, P313, DOI 10.1037/0278-7393.34.2.313
   Tabossi P, 2009, MEM COGNITION, V37, P529, DOI 10.3758/MC.37.4.529
   Taslimipoor Shiva, 2018, MULTIWORD EXPRESSION, P299
   Westerstahl Dag, 2002, P LLC8 CSLI PUBL
   WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8
   Wolf T., P 2020 C EMPIRICAL M, P38
NR 73
TC 2
Z9 2
U1 1
U2 4
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2021
VL 9
BP 1546
EP 1562
DI 10.1162/tacl_a_00442
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA YU3MT
UT WOS:000751952200092
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Balkus, SV
   Yan, DH
AF Balkus, Salvador V.
   Yan, Donghui
TI Improving short text classification with augmented data using GPT-3
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE GPT-3; Data augmentation; Text classification; Machine learning
ID ENSEMBLE
AB GPT-3 is a large-scale natural language model developed by OpenAI that can perform many different tasks, including topic classification. Although researchers claim that it requires only a small number of in-context examples to learn a task, in practice GPT-3 requires these training examples to be either of exceptional quality or a higher quantity than easily created by hand. To address this issue, this study teaches GPT-3 to classify whether a question is related to data science by augmenting a small training set with additional examples generated by GPT-3 itself. This study compares two augmented classifiers: the Classification Endpoint with an increased training set size and the Completion Endpoint with an augmented prompt optimized using a genetic algorithm. We find that data augmentation significantly increases the accuracy of both classifiers, and that the embedding-based Classification Endpoint achieves the best accuracy of about 76%, compared to human accuracy of 85%. In this way, giving large language models like GPT-3 the ability to propose their own training examples can improve short text classification performance.
C1 [Balkus, Salvador V.] Univ Massachusetts, Program Data Sci, Dartmouth, MA 20452 USA.
   [Yan, Donghui] Univ Massachusetts, Dept Math, Dartmouth, MA USA.
C3 University of Massachusetts System; University Massachusetts Dartmouth;
   University of Massachusetts System; University Massachusetts Dartmouth
RP Balkus, SV (通讯作者)，Univ Massachusetts, Program Data Sci, Dartmouth, MA 20452 USA.
EM sbalkus@g.harvard.edu
FU First, we must thank the Program in Data Science at the University of
   Massachusetts Dartmouth for financially supporting this project. In
   addition, we would also like to thank members of the University of
   Massachusetts Dartmouth Big Data Club for contribut; Program in Data
   Science at the University of Massachusetts Dartmouth
FX First, we must thank the Program in Data Science at the University of
   Massachusetts Dartmouth for financially supporting this project. In
   addition, we would also like to thank members of the University of
   Massachusetts Dartmouth Big Data Club for contributing questions to our
   training, validation, and test data. Finally, we especially thank
   Benjamin Pfeffer, McCord Murray, and John Willy for generously
   volunteering to perform post hoc annotations of the questions used in
   this study.
CR Adhikari A, 2019, Arxiv, DOI arXiv:1904.08398
   Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Bajaj P., 2022, ARXIV
   Bischl B, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1484
   Chen WL, 2022, Arxiv, DOI arXiv:2105.02365
   Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Du J., 2020, N AM CHAPTER ASS COM
   Feng S. Y., 2021, FINDINGS ASS COMPUTA, P968, DOI [DOI 10.18653/V1/2021.FINDINGS-ACL.84, 10.18653/v1/2021.findingsacl.84, 10.18653/v1/2021.findings-acl.84]
   Gerz D., 2018, T ASSOC COMPUT LING, V6, P451, DOI DOI 10.1162/TACL_A_00032
   GPT-3, 2020, GUARDIAN
   Guo X., 2022, ARXIV
   Hestness J, 2017, Arxiv, DOI arXiv:1712.00409
   Jiang Z., 2022, INT C COMP LING
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Kobayashi S., 2018, P 2018 C N AM CHAPTE, V2, P452, DOI 10.18653/v1/N18-2072
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Kumar V., 2020, P 2 WORKSH LIF LONG
   Li Q., 2020, ACM T INTEL SYST TEC, V13, P1
   Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100
   Liu RB, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9031
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Dai AM, 2015, Arxiv, DOI arXiv:1511.01432
   Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726
   Onan A, 2019, IEEE ACCESS, V7, P145614, DOI 10.1109/ACCESS.2019.2945911
   Onan A, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/5901087
   Onan A, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2497471
   Onan A, 2017, INFORM PROCESS MANAG, V53, P814, DOI 10.1016/j.ipm.2017.02.008
   Onan A, 2017, J INF SCI, V43, P25, DOI 10.1177/0165551515613226
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   OpenAI, 2021, CLASS OPENAI DOC
   OpenAI, 2022, EMB OPENAI DOC
   OpenAI, 2021, COMPL OPENAI DOC
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pilipiszyn A., 2021, GPT 3 POWERS NEXT GE
   Qu YR, 2020, Arxiv, DOI arXiv:2010.08670
   Quteineh H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7400
   Radford Alec, 2018, OPENAI BLOG
   Raffel C., 2022, J MACH LEARN RES, V21, P5
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Song G., 2014, J MULTIMED, V9, P1
   SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849
   Sun Y, 2021, Arxiv, DOI arXiv:2107.02137
   Thiergart J., 2021, ARXIV
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Wang A, 2019, ADV NEUR IN, V32
   Wen Xian Yang, 2004, Intelligent Data Analysis, V8, P385
   Yoo K. M., 2021, FINDINGS ASS COMPUTA
   Zhang H., 2018, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1710.09412
   Zhao T., 2021, ARXIV
   Zoph B., 2022, 2022 IEEE INT PAR DI, P1044
   Zulqarnain M., 2020, INDONESIAN J ELECT E, V19, P325, DOI DOI 10.11591/IJEECS.V19.I1.PP325-335
NR 56
TC 0
Z9 0
U1 4
U2 4
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD 2023 AUG 25
PY 2023
DI 10.1017/S1351324923000438
EA AUG 2023
PG 30
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA T3MO0
UT WOS:001077062200001
OA Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Dai, LR
   Cooper, K
   Wong, WE
AF Dai, Lirong
   Cooper, Kendra
   Wong, W. Eric
TI Modeling and analysis of performance aspects for software architecture:
   A UML-based approach
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE aspect-oriented software development; software architecture; unified
   modeling language; Rapide architectural description language; formal
   methods
ID TROPOS
AB Much attention has been focused on the problem of effectively designing software architecture to meet non-functional requirements (NFRs). The significant benefits of such work include detecting and removing defects earlier, which reduces development time and cost while improving the quality of the design; in turn the improved quality of the design makes it easier to maintain as the system evolves. The Formal Design Analysis Framework (FDAF) is an aspect-oriented approach proposed to support the design and analysis of multiple NFRs for distributed, concurrent, and real-time systems. In FDAF, non-functional requirements are realized and represented as reusable aspects in the repository; designs are captured in an extended version of the Unified Modeling Language (UML). FDAF supports the automated translation of extended UML designs into existing formal notations. Subsequently, the analysis of an aspect design is achieved using existing formal analysis tools, which leverages a large body of work in the research community. This paper focuses on the modeling and analysis of the response time performance aspect. The algorithms for translating extended UML diagrams into Rapide, the proofs of correctness for the algorithms, and an illustration of the FDAF approach using the Domain Name System are presented.
C1 Seattle Univ, Dept Comp Sci & Software Engn, Seattle, WA 98122 USA.
   Univ Texas, Dept Comp Sci, Richardson, TX USA.
C3 Seattle University; University of Texas System; University of Texas
   Dallas
RP Dai, LR (通讯作者)，Seattle Univ, Dept Comp Sci & Software Engn, PO 222000, Seattle, WA 98122 USA.
EM daia@seattleu.edu; kcooper@utdallas.edu; ewong@utdallas.edu
CR Allen R. J., 1997, CMUCS97144
   [Anonymous], 1998, OBJECT CONSTRAINT LA
   [Anonymous], 2004, UNIFIED MODELING LAN
   [Anonymous], 2003, EVAPORATIVE COOLING
   BALSAMO S, 2004, P 4 INT WORKSH SOFTW, P115
   Bass L., 2003, SOFTWARE ARCHITECTUR
   BERTRAND P, 1998, P 20 IEEE ACM INT C
   Bresciani P, 2004, AUTON AGENT MULTI-AG, V8, P203, DOI 10.1023/B:AGNT.0000018806.20944.ef
   BRODLIE KW, 1992, SCI VISUALIZATION TE
   CHENG BHC, 2003, P IEEE WORKSH REQ HI, P13
   Chung L., 2000, NONFUNCTIONAL REQUIR
   CLARK T, 1997, P 2 NO FORM METH WOR
   Clarke S., 2004, ASPECT ORIENTED SOFT, P425
   Cooper K, 2005, SCI COMPUT PROGRAM, V57, P89, DOI 10.1016/j.scico.2004.10.007
   DARDENNE A, 1993, SCI COMPUT PROGRAM, V20, P3, DOI 10.1016/0167-6423(93)90021-G
   Filman R., 2004, ASPECT ORIENTED SOFT
   Giorgini P, 2005, ENG APPL ARTIF INTEL, V18, P159, DOI 10.1016/j.engappai.2004.11.017
   GOBEL S, 2004, P 3 INT C ASP OR SOF, P74
   Holzmann G, 2003, SPIN MODEL CHECKER P
   Jain R., 1991, ART COMPUTER SYSTEMS
   Jani D, 2005, LECT NOTES COMPUT SC, V3527, P185
   Jürjens J, 2005, PROC INT CONF SOFTW, P322
   Kazman R, 1998, IEEE INT C ENG COMP, P68, DOI 10.1109/ICECCS.1998.706657
   KELLER S, 1990, TUTORIAL SYSTEM SOFT, P145
   LANO K, 2000, P RIG OBJ OR METH YO
   LOPEZGRAO JP, 2004, P 4 INT WORKSH SOFTW, P25, DOI DOI 10.1145/974044.974048
   LUCKHAM DC, 1995, IEEE T SOFTWARE ENG, V21, P336, DOI 10.1109/32.385971
   Medvidovic N, 2002, ACM T SOFTW ENG METH, V11, P2, DOI 10.1145/504087.504088
   MEYER B, 1990, INTRO THEORY PROGRAM
   MOCKAPETRIS PV, 1987, STD0013 IETF
   MONROE RT, 1998, CMUCS98163 SCH COMP
   Ober L, 2003, LECT NOTES COMPUT SC, V2589, P356
   *OBJ MAN GROUP, 2003, PTC20030302 OMG
   Shaw Mary, 1996, SOFTWARE ARCHITECTUR
   Simon H. A., 1996, SCI ARTIFICIAL, V3rd
   *SOFTW DES GROUP, 2002, ALL AN
   Spivey J Michael, 1988, UNDERSTANDING Z SPEC
   ter Hofstede AHM, 1998, INFORM SOFTWARE TECH, V40, P519, DOI 10.1016/S0950-5849(98)00078-0
   van Lamsweerde A, 2001, FIFTH IEEE INTERNATIONAL SYMPOSIUM ON REQUIREMENTS ENGINEERING, PROCEEDINGS, P249
   WIN B, 2004, ASPECT ORIENTED SOFT, P633
   Yu E, 2001, WIRTSCHAFTSINF, V43, P123, DOI 10.1007/BF03250789
NR 41
TC 2
Z9 2
U1 0
U2 2
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD JUN
PY 2006
VL 16
IS 3
BP 347
EP 378
DI 10.1142/S0218194006002835
PG 32
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 066IN
UT WOS:000239223000003
DA 2023-11-10
ER

PT S
AU Shastri, L
AF Shastri, L
BE Wermter, S
   Sun, R
TI Types and quantifiers in SHRUTI - A connectionist model of rapid
   reasoning and relational processing
SO HYBRID NEURAL SYSTEMS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT International Workshop on Hybrid Neural Systems
CY DEC 04-05, 1998
CL DENVER, COLORADO
ID TEMPORAL SYNCHRONY; REPRESENTATION; MEMORY
AB In order to understand language, a hearer must draw inferences to establish referential and causal coherence. Hence our ability to understand language suggests that we are capable of performing a wide range of inferences rapidly and spontaneously. This poses a challenge for cognitive science: How can a system of slow neuron-like elements encode a large body of knowledge and perform inferences with such speed? SHRUTI attempts to answer this question by demonstrating how a neurally plausible network can encode a large body of semantic and episodic facts, and systematic rule-like knowledge, and yet perform a range of inferences,within a few hundred milliseconds. This paper describes a novel representation of types and instances in SHRUTI that supports the encoding of rules and facts involving types and quantifiers, enables SHRUTI to distinguish between hypothesized and asserted entities, and facilitates the dynamic instantiation and unification of entities during inference.
C1 Int Comp Sci Inst, Berkeley, CA 94704 USA.
RP Shastri, L (通讯作者)，Int Comp Sci Inst, Berkeley, CA 94704 USA.
CR AJJANAGADDE V, 1990, PROGRAM OF THE TWELFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P285
   AJJANAGADDE V, 1991, 916 U TUB WILH SCHIC
   AJJANAGADDE V, 1989, P 11 C COGN SCI SOC, P396
   Bailey D, 1998, PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P84
   Barnden J., 1991, Connection Science, V3, P269, DOI 10.1080/09540099108946588
   BLISS TVP, 1993, NATURE, V361, P31, DOI 10.1038/361031a0
   GASSER M, 1998, 221 IND U COGN SCI P
   HOBBS JR, 1993, ARTIF INTELL, V63, P69, DOI 10.1016/0004-3702(93)90015-4
   Hummel JE, 1997, PSYCHOL REV, V104, P427, DOI 10.1037/0033-295X.104.3.427
   Lakoff G., 1987, WOMEN FIRE DANGEROUS, DOI 10.7208/chicago/9780226471013.001.0001
   Lange T. E., 1989, Connection Science, V1, P181, DOI 10.1080/09540098908915635
   LISMAN JE, 1995, SCIENCE, V267, P1512, DOI 10.1126/science.7878473
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Mani D. R., 1993, Connection Science, V5, P205, DOI 10.1080/09540099308915700
   Park NS, 1995, KNOWL-BASED SYST, V8, P345, DOI 10.1016/0950-7051(96)81918-6
   Regier T., 1996, HUMAN SEMANTIC POTEN
   SHASTRI L, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P159
   SHASTRI L, 1993, BEHAV BRAIN SCI, V16, P417, DOI 10.1017/S0140525X00030910
   Shastri L., 1999, Proceedings of the Second International Conference on Information Fusion. FUSION '99, P1262
   Shastri L, 1999, APPL INTELL, V11, P79, DOI 10.1023/A:1008380614985
   Shastri L, 1999, NEUROCOMPUTING, V26-7, P865, DOI 10.1016/S0925-2312(98)00131-3
   Shastri L, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P680
   SHASTRI L, 1997, TR97003 INT COMP SCI
   SHASTRI L, IN PRESS LECT NOTES
   SHASTRI L, 1996, P 18 C COGN SCI SOC
   SINGER W, 1993, ANNU REV PHYSIOL, V55, P349, DOI 10.1146/annurev.physiol.55.1.349
   Sun R., 1992, Connection Science, V4, P93, DOI 10.1080/09540099208946607
   Von der Malsburg C., 1986, BRAIN THEORY
NR 28
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-67305-9
J9 LECT NOTES ARTIF INT
PY 2000
VL 1778
BP 28
EP 45
PG 18
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BS61R
UT WOS:000170570700003
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Mujahid, M
   Kanwal, K
   Rustam, F
   Aljadani, W
   Ashraf, I
AF mujahid, Muhammad
   Kanwal, Khadija
   Rustam, Furqan
   Aljadani, Wajdi
   Ashraf, Imran
TI Arabic ChatGPT Tweets Classification Using RoBERTa and BERT Ensemble
   Model
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Arabic tweets; low-resource language; ChatGPT; OpenAI; transformer
   models; BERT; sentiment analysis
ID SENTIMENT ANALYSIS; IMPACT
AB ChatGPT OpenAI, a large-language chatbot model, has gained a lot of attention due to its popularity and impressive performance in many natural language processing tasks. ChatGPT produces superior answers to a wide range of real-world human questions and generates human-like text. The new OpenAI ChatGPT technology may have some strengths and weaknesses at this early stage. Users have reported early opinions about the ChatGPT features, and their feedback is essential to recognize and fix its shortcomings and issues. This study uses the ChatGPT tweets Arabic dataset to automatically find user opinions and sentiments about ChatGPT technology. The dataset is preprocessed and labeled using the TextBlob Arabic Python library into positive, negative, and neutral tweets. Despite extensive works for the English language, languages like Arabic are less studied regarding tweet analysis. Existing literature about Arabic tweet sentiment analysis has mainly focused on machine learning and deep learning models. We collected a total of 27,780 unstructured tweets from Twitter using the Tweepy SNscrape Python library using various hash-tags such as # Chat-GPT, #OpenAI, #Chatbot, Chat-GPT3, and so on. To enhance the model's performance and reduce computational complexity, unstructured tweets are converted into structured and normalized forms. Tweets contain missing values, URL and HTML tags, stop words, punctuation, diacritics, elongations, and numeric values that have no impact on the model performance; hence, these increase the computational cost. So, these steps are removed with the help of Python preprocessing libraries to enhance text quality and consistency. This study adopts Transformer-based models such as RoBERTa, XLNet, and DistilBERT that automatically classify the tweets. Additionally, a hybrid transformer-based model is proposed to obtain better results. The proposed hybrid model is developed by combining the hidden outputs of the RoBERTA and BERT models using a concatenation layer, then adding dense layers with "Relu" activation employed as a hidden layer to create non-linearity and a "softmax" activation function for multiclass classification. They differ from existing state-of-the-art models due to the enhanced capabilities of both models in text classification. Hybrid models combine the different models to make accurate predictions and reduce bias and enhanced the overall results, while state-of-the-art models are incapable of making accurate predictions. Experiments show that the proposed hybrid model achieves 96.02% accuracy, 100% precision on negative tweets, and 99% recall for neutral tweets. The performance of the proposed model is far better than existing state-of-the-art models.
C1 [mujahid, Muhammad] Khwaja Fareed Univ Engn & Information Technol, Dept Comp Sci, Rahim Yar Khan, Pakistan.
   [Kanwal, Khadija] Women Univ Multan, Inst CS & IT, Multan 6600, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin D04 V1W8, Ireland.
   [Aljadani, Wajdi] Univ North Texas, Dept Comp Sci & Engn, Denton, TX USA.
   [Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 University College Dublin; University of North Texas System; University
   of North Texas Denton; Yeungnam University
RP Ashraf, I (通讯作者)，Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM mujahidws890@gmail.com; khadijakanwal.6022@wum.edu.pk;
   furqan.rustam1@gmail.com; wajdi.j1@gmail.com; imranashraf@ynu.ac.kr
RI Rustam, Furqan/ABE-4772-2020; Mujahid, Muhammad/HZH-8780-2023
OI Rustam, Furqan/0000-0001-8403-1047; Ashraf, Imran/0000-0002-8271-6496;
   Mujahid, Muhammad/0009-0005-5751-5528; Aljedaani,
   Wajdi/0000-0002-6700-719X
CR Abu Farha Ibrahim, 2022, P 7 ARABIC NATURAL L, P399
   Al Shamsi Arwa A., 2021, ADV SCI TECHNOL ENG, V6, P1012
   Al-Hassan A, 2022, MULTIMEDIA SYST, V28, P1963, DOI 10.1007/s00530-020-00742-w
   Aldayel HK, 2016, J INF SCI, V42, P782, DOI 10.1177/0165551515610513
   Alduailaj AM, 2023, MACH LEARN KNOW EXTR, V5, P29, DOI 10.3390/make5010003
   Alqarni A, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010016
   AlSalman Hussain, 2020, P 3 INT C COMP APPL, P1
   Anjaria K, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113497
   Antoun W, 2021, Arxiv, DOI arXiv:2012.15520
   Biau G, 2016, TEST-SPAIN, V25, P264, DOI 10.1007/s11749-016-0488-0
   Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312
   Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7
   Carrasco XA, 2021, PROCEDIA COMPUT SCI, V189, P92, DOI 10.1016/j.procs.2021.05.072
   Celik B, 2023, RED-REV EDUC DISTANC, V23, DOI 10.6018/red.491551
   Cheng LC, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P1001, DOI 10.1145/3341161.3344821
   Chouikhi H, 2021, COMM COM INF SC, V1463, P621, DOI 10.1007/978-3-030-88113-9_50
   Chowdhary K, 2020, FUNDAMENTALS ARTIFIC, P603, DOI DOI 10.1007/978-81-322-3972-7_19
   Cui JF, 2023, ARTIF INTELL REV, V56, P8469, DOI 10.1007/s10462-022-10386-z
   Dahou Abdelhalim Hafedh, 2023, 12th International Conference on Information Systems and Advanced Technologies "ICISAT 2022": Intelligent Information, Data Science and Decision Support System. Lecture Notes in Networks and Systems (624), P135, DOI 10.1007/978-3-031-25344-7_13
   Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601
   Dang CN, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/9986920
   Das B, 2018, Arxiv, DOI arXiv:1806.06407
   Fawzy Mohamed, 2022, 2022 20th International Conference on Language Engineering (ESOLEC), P24, DOI 10.1109/ESOLEC54569.2022.10009633
   Fsih Emna, 2022, P 7 ARABIC NATURAL L, P431
   Gao CA., 2022, BIORXIV
   Guzman E, 2014, INT REQUIR ENG CONF, P153, DOI 10.1109/RE.2014.6912257
   Hadhood Haret, 2022, THESIS ITA SUOMEN YL
   Hadwan M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115547
   Haider Ahmad S., 2022, J INTERCULT COMMUN R, V51, P628
   Haque M. U., 2022, ARXIV, DOI [DOI 10.48550/ARXIV.2212.05856, 10.48550/arXiv.2212.05856]
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Hong X, 2019, IEEE ACCESS, V7, P80893, DOI 10.1109/ACCESS.2019.2919385
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Khered Abdullah Salem, 2022, P 7 ARABIC NATURAL L, P479
   Kumar V., 2014, INT J DATABASE THEOR, V7, P61, DOI [DOI 10.14257/IJDTA.2014.7.1.06, DOI 10.14257/IJDTA.2014.7.1.0]
   Li MY, 2017, BIOMED SIGNAL PROCES, V34, P114, DOI 10.1016/j.bspc.2017.01.010
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Lock S., 2022, WHAT IS AI CHATBOT P
   Mayfield A., 2008, WHAT IS SOCIAL MEDIA
   Mujahid M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188438
   Nassr Z, 2019, 4TH INTERNATIONAL CONFERENCE ON SMART CITY APPLICATIONS (SCA' 19), DOI 10.1145/3368756.3369078
   Pascanu R, 2014, Arxiv, DOI [arXiv:1312.6026, 10.48550/ARXIV.1312.6026]
   QusayAl-Bayati Abdulhakeem, 2020, J ENG-NY, V26, P85, DOI DOI 10.31026/J.ENG.2020.06.07
   Rahman W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2359, DOI 10.18653/v1/2020.acl-main.214
   Sajjad H, 2022, COMPUT SPEECH LANG, V77, DOI 10.1016/j.csl.2022.101429
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Wenzlaff Karsten, 2022, SMARTER HUMANS VALID, DOI [10.2139/ssrn.4302443, DOI 10.2139/SSRN.4302443]
   Zainuddin N, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS, AND CONTROL TECHNOLOGY (I4CT), P333, DOI 10.1109/I4CT.2014.6914200
   Zheng WY, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 3, PROCEEDINGS, P335, DOI 10.1109/IITA.2009.457
   Zhou XJ, 2013, INT C COMP SUPP COOP, P557, DOI 10.1109/CSCWD.2013.6581022
NR 51
TC 1
Z9 1
U1 10
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD AUG
PY 2023
VL 22
IS 8
AR 204
DI 10.1145/3605889
PG 23
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q7NS7
UT WOS:001059361200002
DA 2023-11-10
ER

PT J
AU Mehmood, F
   Shahzadi, R
   Ghafoor, H
   Asim, MN
   Ghani, MU
   Mahmood, W
   Dengel, A
AF Mehmood, Faiza
   Shahzadi, Rehab
   Ghafoor, Hina
   Asim, Muhammad Nabeel
   Ghani, Muhammad Usman
   Mahmood, Waqar
   Dengel, Andreas
TI EnML: Multi-label Ensemble Learning for Urdu Text Classification
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Multi-label Urdu text classification; multi-label Urdu news dataset;
   traditional machine learning; deep learning; language models;
   multi-label ensemble learning; data transformation methods
ID RANKING; ALGORITHM
AB Exponential growth of electronic data requires advanced multi-label classification approaches for the development of natural language processing (NLP) applications such as recommendation systems, drug reaction detection, hate speech detection, and opinion recognition/mining. To date, several machine and deep learning-based multi-label classification methodologies have been proposed for English, French, German, Chinese, Arabic, and other developed languages. Urdu is the 11th largest language in the world and has no computer-aided multi-label textual news classification approach. Unlike other languages, Urdu is lacking multi-label text classification datasets that can be used to benchmark the performance of existing machine and deep learning methodologies. With an aim to accelerate and expedite research for the development of Urdu multi-label text classification-based applications, this article provides multiple contributions as follows: First, it provides a manually annotated multi-label textual news classification dataset for the Urdu language. Second, it benchmarks the performance of traditional machine learning approaches particularly by adapting three data transformation approaches along with three top-performing machine learning classifiers and four algorithm adaptation-based approaches. Third, it benchmarks performance of 16 existing deep learning approaches and the four most widely used language models. Finally, it provides an ensemble approach that reaps the benefits of three different deep learning architectures to precisely predict different classes associated with a particular Urdu textual document. Experimental results reveal that proposed ensemble approach performance values (87% accuracy, 92% F1-score, and 8% hamming loss) are significantly higher than adapted machine and deep learning-based approaches.
C1 [Mehmood, Faiza; Shahzadi, Rehab; Ghafoor, Hina; Mahmood, Waqar] Univ Engn & Technol, Al Khawarizmi Inst Comp Sci KICS, Lahore, Pakistan.
   [Mehmood, Faiza; Ghani, Muhammad Usman] Univ Engn & Technol, Dept Comp Sci, Faisalabad Campus, Lahore, Pakistan.
   [Ghafoor, Hina; Asim, Muhammad Nabeel; Dengel, Andreas] German Res Ctr Artificial Intelligence DFKI, D-67663 Kaiserslautern, Germany.
   [Ghafoor, Hina; Dengel, Andreas] Rheinland Pfalz Tech Univ, Dept Comp Sci, D-67663 Kaiserslautern, Germany.
C3 University of Engineering & Technology Lahore; University of Engineering
   & Technology Lahore; German Research Center for Artificial Intelligence
   (DFKI)
RP Asim, MN (通讯作者)，German Res Ctr Artificial Intelligence DFKI, D-67663 Kaiserslautern, Germany.
EM faiza.mehmood@kics.edu.pk; rehab.shahzadi@kics.edu.pk;
   hina.ghafoor@kics.edu.pk; nabeel.asim@dfki.de; usman.ghani@kics.edu.pk;
   director@kics.edu.pk; andreas.dengel@dfki.de
FU Higher Education Commission Pakistan [NRPU-20-16560]
FX This work was supported by the Higher Education Commission Pakistan
   under Grant NRPU-20-16560.
CR Abbasi A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-22523-3
   Ahmed Kashif, 2016, J APPL COMPUT SCI MA, V21, P17
   Akbik A., 2018, P 27 INT C COMPUTATI, P1638
   Al-Salemi B, 2019, INFORM PROCESS MANAG, V56, P212, DOI 10.1016/j.ipm.2018.09.008
   Al-Salemi B, 2016, KNOWL-BASED SYST, V103, P104, DOI 10.1016/j.knosys.2016.03.029
   Albawi S, 2017, I C ENG TECHNOL
   Ali Abbas Raza, 2009, P 7 INT C FRONT INF, P21
   Aljedani N, 2021, EGYPT INFORM J, V22, P225, DOI 10.1016/j.eij.2020.08.004
   Almeida AMG, 2018, NEUROCOMPUTING, V320, P35, DOI 10.1016/j.neucom.2018.08.053
   Ameer I, 2022, IEEE ACCESS, V10, P8779, DOI 10.1109/ACCESS.2022.3143819
   Amin Saadullah, 2019, CLEF WORKING NOTES
   Ashraf N, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.896
   Asim MN, 2020, GENES-BASEL, V11, DOI 10.3390/genes11121475
   Asim MN, 2021, NEURAL COMPUT APPL, V33, P5437, DOI 10.1007/s00521-020-05321-8
   Asim MN, 2017, INT J COMPUT SCI NET, V17, P135
   Asim MN, 2017, INT J ADV COMPUT SC, V8, P369, DOI 10.14569/IJACSA.2017.081048
   Benites F, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P847, DOI 10.1109/ICDMW.2015.14
   Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   Bogaert M, 2019, EUR J OPER RES, V279, P620, DOI 10.1016/j.ejor.2019.05.037
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]
   Boros Martin, 2012, INT J COMPUT COMMUN, V1, P62, DOI DOI 10.7763/IJCCE.2012.V1.18
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brown I, 2012, EXPERT SYST APPL, V39, P3446, DOI 10.1016/j.eswa.2011.09.033
   Cave Andrew, 2017, WHAT WILL WE DO WORL
   Chang WC, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3163, DOI 10.1145/3394486.3403368
   Chen WJ, 2016, PATTERN RECOGN, V52, P61, DOI 10.1016/j.patcog.2015.10.008
   Chen Y, 2018, IEEE I C NETW INFRAS, P409, DOI 10.1109/ICNIDC.2018.8525817
   Cheng WW, 2009, MACH LEARN, V76, P211, DOI 10.1007/s10994-009-5127-5
   Chitrakar R, 2012, ASIAN HIMAL INT CONF
   Christopher John Cornish HellabyWatkins, 1989, LEARNING DELAYED REW
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1606.01781
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Curi Z, 2018, Arxiv, DOI arXiv:1809.02811
   Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dilawari A, 2023, IEEE ACCESS, V11, P23557, DOI 10.1109/ACCESS.2023.3249783
   Du CX, 2019, AAAI CONF ARTIF INTE, P6359
   Du JC, 2019, J AM MED INFORM ASSN, V26, P1279, DOI 10.1093/jamia/ocz085
   El Kafrawy Passent, 2015, INT J COMPUT APPL, V114, P1, DOI [10.5120/20083-1666, DOI 10.5120/20083-1666]
   Elghazel H, 2016, EXPERT SYST APPL, V57, P1, DOI 10.1016/j.eswa.2016.03.041
   Esuli A, 2006, LECT NOTES COMPUT SC, V4209, P1
   Fiallos A, 2019, INT CONF EDEMOC EGOV, P324, DOI [10.1109/icedeg.2019.8734365, 10.1109/ICEDEG.2019.8734365]
   Fitriawan A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS, AND ITS APPLICATIONS (IC3INA) - RECENT PROGRESS IN COMPUTER, CONTROL, AND INFORMATICS FOR DATA SCIENCE, P102, DOI 10.1109/IC3INA.2016.7863032
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fürnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8
   Gargiulo Francesco, 2018, P 11 INT JOINT C BIO, P641, DOI DOI 10.5220/0006730506410650
   Guo Q., 2019, STAR TRANSFORMER
   Halawi B, 2018, IEEE ACCESS, V6, P63890, DOI 10.1109/ACCESS.2018.2877685
   He Jiahui, 2019, J NEW MEDIA, V1, P51
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hüllermeier E, 2008, ARTIF INTELL, V172, P1897, DOI 10.1016/j.artint.2008.08.002
   Hussain S., 2016, P C LANG TECHN CLT 1
   Ibrahim MA, 2021, J BIOMED INFORM, V116, DOI 10.1016/j.jbi.2021.103699
   Jabreel M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061123
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Joulin A, 2016, Arxiv, DOI arXiv:1607.01759
   Kalchbrenner N, 2014, Arxiv, DOI [arXiv:1404.2188, DOI 10.48550/ARXIV.1404.2188]
   Kashif M, 2021, Arxiv, DOI arXiv:2103.05105
   Kim Y, 2014, Arxiv, DOI arXiv:1408.5882
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, P1746, DOI DOI 10.3115/V1/D14-1181
   Kurata Gakuto, 2016, P C N AM CHAPT ASS C, P521, DOI [10.18653/v1/N16-1063, DOI 10.18653/V1/N16-1063]
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Li ML, 2017, IEEE T AFFECT COMPUT, V8, P443, DOI 10.1109/TAFFC.2017.2723012
   Li SJ, 2002, J COMPUT SCI TECHNOL, V17, P933, DOI 10.1007/BF02960786
   Liu JZ, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P115, DOI 10.1145/3077136.3080834
   Liu PF, 2016, Arxiv, DOI arXiv:1605.05101
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Marr Bernard, 2015, BIG DATA 20 MIND BOG
   Matthijs J, 2015, J PSYCHOL PSYCHOTHER, V5, P1, DOI DOI 10.4172/2161-0487.1000197
   Mehmood F, 2022, APPL ENERG, V324, DOI 10.1016/j.apenergy.2022.119754
   Mehmood F, 2021, RENEW SUST ENERG REV, V151, DOI 10.1016/j.rser.2021.111559
   Mehmood F, 2020, IEEE ACCESS, V8, P192740, DOI 10.1109/ACCESS.2020.3030885
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Moyano JM, 2018, INFORM FUSION, V44, P33, DOI 10.1016/j.inffus.2017.12.001
   Mulcahy Mark, 2017, BIG DATA STAT FACTS
   Muñoz E, 2019, BRIEF BIOINFORM, V20, P190, DOI 10.1093/bib/bbx099
   Pappas N, 2019, T ASSOC COMPUT LING, V7, P139, DOI 10.1162/tacl_a_00259
   Peng H, 2019, Arxiv, DOI arXiv:1906.04898
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1063, DOI 10.1145/3178876.3186005
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Pinter Y, 2017, Arxiv, DOI arXiv:1707.06961
   Prabhu Y, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P441, DOI 10.1145/3159652.3159660
   Qiao Chao, 2018, ICLR
   Quan Chanqin, 2016, BIOMED RES INT-UK
   Raghavan A. K., 2019, P 15 C NAT LANG PROC
   Read J, 2014, Arxiv, DOI arXiv:1502.05988
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Rish I., 2001, IN IJCAI 2001 WORKSH, V3, P41, DOI DOI 10.1214/088342306000000060
   Rojarath A, 2016, INT CONF SOFTW ENG, P107, DOI 10.1109/ICSESS.2016.7883026
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Roxas Rachel Edita O., 2011, P 9 WORKSH AS LANG R
   Rusland NF, 2017, IOP CONF SER-MAT SCI, V226, DOI 10.1088/1757-899X/226/1/012091
   Saleem S, 2022, CMC-COMPUT MATER CON, V70, P505, DOI 10.32604/cmc.2022.018871
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Sattar Sohail Abdul, 2017, IND J SCI TECHNOL, V10, P29
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Shehab MA, 2016, INT CONF COMP SCI
   Shen YL, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P373, DOI 10.1145/2567948.2577348
   Shimura K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P811
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spyromitros E, 2008, LECT NOTES ARTIF INT, V5138, P401, DOI 10.1007/978-3-540-87881-0_40
   Summra S, 2021, 2021 18TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE 2021), DOI 10.1109/CCE53527.2021.9632882
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P1602, DOI 10.1109/TKDE.2016.2522427
   Tang BZ, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/2379208
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Tripathy A, 2016, EXPERT SYST APPL, V57, P117, DOI 10.1016/j.eswa.2016.03.028
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Usman M, 2016, INT J ADV COMPUT SC, V7, P265
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang BX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2311
   Wang YQ, 2016, LECT NOTES COMPUT SC, V9931, P567, DOI 10.1007/978-3-319-45814-4_46
   Wasim M, 2019, IEEE ACCESS, V7, P3882, DOI 10.1109/ACCESS.2018.2887165
   Wei LW, 2019, LECT NOTES COMPUT SC, V11536, P548, DOI 10.1007/978-3-030-22734-0_40
   Wu QY, 2014, KNOWL-BASED SYST, V67, P105, DOI 10.1016/j.knosys.2014.06.004
   Xu G, 2017, INT CONF BIG DATA, P126, DOI 10.1109/BIGCOMP.2017.7881727
   Yang PC, 2018, Arxiv, DOI arXiv:1806.04822
   Yang Z., 2016, P 2016 C N AM CHAPTE, P1480, DOI [10.18653/v1/N16-1174, DOI 10.18653/V1/N16-1174]
   Yang ZL, 2020, Arxiv, DOI [arXiv:1906.08237, DOI 10.48550/ARXIV.1906.08237]
   Yih WT, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P643
   Yin WP, 2017, Arxiv, DOI arXiv:1702.01923
   Yin Wenpeng, 2018, T ASS COMPUT LING, V6, P687, DOI DOI 10.1162/TACL_A_00249
   You RH, 2019, Arxiv, DOI arXiv:1811.01727
   You Ronghui, 2019, NEURIPS, P5812
   Zahid R, 2020, 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING WORKSHOPS (ASEW 2020), P138, DOI 10.1145/3417113.3423377
   Zenobi Gabriele, 2001, MACHINE LEARNING ECM, P576, DOI DOI 10.1007/3-540-44795-4_
   Zhang LJ, 2018, IOP CONF SER-MAT SCI, V322, DOI 10.1088/1757-899X/322/6/062007
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang W, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0774-y
   Zhang WJ, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P100, DOI 10.1145/3206025.3206030
   Zia Tehseen, 2015, International Journal of Intelligent Systems and Applications, V7, P33, DOI 10.5815/ijisa.2015.06.03
NR 134
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP
PY 2023
VL 22
IS 9
AR 227
DI 10.1145/3616111
PG 31
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T7EN7
UT WOS:001079577300007
DA 2023-11-10
ER

PT J
AU Liu, S
   Zhou, G
   Xia, Y
   Wu, H
   Li, ZF
AF Liu, Shuo
   Zhou, Gang
   Xia, Yi
   Wu, Hao
   Li, Zhufeng
TI A data-centric way to improve entity linking in knowledge-based question
   answering
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Entity linking; Negative sampling; Natural language processing;
   Knowledge-based question answering
AB Entity linking in knowledge-based question answering (KBQA) is intended to construct a mapping relation between a mention in a natural language question and an entity in the knowledge base. Most research in entity linking focuses on long text, but entity linking in open domain KBQA is more concerned with short text. Many recent models have tried to extract the features of raw data by adjusting the neural network structure. However, the models only perform well with several datasets. We therefore concentrate on the data rather than the model itself and created a model DME (Domain information Mining and Explicit expressing) to extract domain information from short text and append it to the data. The entity linking model will be enhanced by training with DME-processed data. Besides, we also developed a novel negative sampling approach to make the model more robust. We conducted experiments using the large Chinese open source benchmark KgCLUE to assess model performance with DME-processed data. The experiments showed that our approach can improve entity linking in the baseline models without the need to change their structure and our approach is demonstrably transferable to other datasets.
C1 [Liu, Shuo; Zhou, Gang; Xia, Yi; Wu, Hao; Li, Zhufeng] Informat Engn Univ, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Li, ZF (通讯作者)，Informat Engn Univ, Zhengzhou, Henan, Peoples R China.
EM 20086538@qq.com
FU Science and Technology Research Program of the Department of Science and
   Technology of Henan Province [222102210081]
FX Funding This research is supported by the Science and Technology
   Research Program of the Department of Science and Technology of Henan
   Province (approval No.: 222102210081) . The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR [Anonymous], 2016, HLT NAACL, DOI DOI 10.18653/V1/N16-1150
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Besancon R, 2017, ACTES 24 ME C RENCE, V1, P182
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616.1376746.URLhttps]
   Chen S, 2020, AAAI CONF ARTIF INTE, V34, P7529
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Peters ME, 2019, Arxiv, DOI arXiv:1909.04164
   Fang Z, 2019, Arxiv, DOI arXiv:1902.00330
   Huang XF, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.667
   Lample G, 2016, P NAACL HLT, DOI DOI 10.18653/V1/N16-1030
   Le P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4081
   Levy Omer, 2017, P 21 C COMPUTATIONAL, P58
   Logeswaran L, 2019, Arxiv, DOI arXiv:1906.07348
   Lu X, 2022, APPL INTELL, V52, P1878, DOI 10.1007/s10489-021-02306-5
   McIlwaine IC, 1997, J AM SOC INFORM SCI, V48, P331, DOI 10.1002/(SICI)1097-4571(199704)48:4<331::AID-ASI6>3.3.CO;2-B
   Mikolov Tomas, 2013, INT C LEARN REPR
   Mulang IO, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2157, DOI 10.1145/3340531.3412159
   Ng A, 2021, CHAT ANDREW MLOPS MO
   Nie F, 2018, AAAI CONF ARTIF INTE, P5908
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Rao JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1913, DOI 10.1145/2983323.2983872
   Schindler D, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.835
   Sevgili Ö, 2022, SEMANT WEB, V13, P527, DOI 10.3233/SW-222986
   Shen W, 2015, IEEE T KNOWL DATA EN, V27, P443, DOI 10.1109/TKDE.2014.2327028
   Sil A, 2018, AAAI CONF ARTIF INTE, P5464
   Cai TT, 2020, Arxiv, DOI arXiv:2010.06682
   Vaswani A., 2017, PROC ADV NEURAL INF, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Wang JP, 2020, INFORMATION, V11, DOI 10.3390/info11090421
   Wu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6397
   Xu Liang, 2020, CLUE CHINESE LANGUAG
   Yamada I, 2022, Arxiv, DOI arXiv:1909.00426
   Zhang YQ, 2019, PROC INT CONF DATA, P614, DOI 10.1109/ICDE.2019.00061
   Zwicklbauer S, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P425, DOI 10.1145/2911451.2911535
NR 33
TC 1
Z9 1
U1 2
U2 2
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD FEB 9
PY 2023
VL 9
AR e1233
DI 10.7717/peerj-cs.1233
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C8DK0
UT WOS:000964157000003
PM 37346650
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Saldhana, JA
   Shatz, SM
   Hu, ZX
AF Saldhana, JA
   Shatz, SM
   Hu, ZX
TI Formalization of object behavior and interactions from UML models
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
AB UML, being the industry standard as a common OO modeling language, needs a well-defined semantic base for its notation. Formalization of the graphical notation enables automated processing and analysis tasks. This paper describes a methodology for synthesis of a Petri net model from UML diagrams. The approach is based on deriving Object Net Models from UML statechart diagrams and connecting these object models based on UML collaboration diagram information. The resulting system-level Petri net model can be used as a foundation for formal Petri net analysis and simulation techniques. The methodology is illustrated on some small examples and a larger case study. The case study reveals some unexpected invalid system-state situations.
C1 Univ Illinois, Dept Comp Sci, Concurrent Software Syst Lab, Chicago, IL 60607 USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital
EM jsaldhan@cs.uic.ed; shatz@cs.uic.ed; zhu@cs.uic.ed
CR [Anonymous], 1992, OBJECT LIFE CYCLES M
   [Anonymous], 1999, DOING HARD TIME DEV
   Black C, 1998, COMPUT SYST SCI ENG, V13, P83
   BOOCH G, 1999, UNIFIED MODELING LAN
   CHENG B, 1997, P 19 INT C SOFTW ENG
   DENG Y, 1993, LECT NOTES COMPUTER
   Duri S., 1994, ACM Transactions on Software Engineering and Methodology, V3, P340, DOI 10.1145/201024.201038
   ELKLUTBI M, 1998, P C HIGH PERF COMP B
   FRANCE R, 1997, P 21 ANN INT COMP SO
   GOGOLLA M, 1998, P ICSE 98 WORKSH PRE, P55
   HAREL D, 1987, SCI COMPUT PROGRAM, V8, P231, DOI 10.1016/0167-6423(87)90035-9
   HE X, 2000, P WORKSH DEF PREC UM
   HE X, 2000, P 24 INT COMP SOFTW
   HE X, 2000, P IFIP 16 WORLD COMP, P484
   Jensen K., 1992, ANAL METHODS PRACTIC, V1, DOI [10.1007/978-3-662-06289-0, DOI 10.1007/978-3-662-06289-0]
   LAKOS C, 1994, TR943 U TASM COMP SC
   LILIUS J, 1999, 272 TUCS
   MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143
   POOLEY R, 1999, P 15 ANN UK PERF ENG, P45
   SHATZ S, 1998, P C HIGH PERF COMP
NR 20
TC 35
Z9 39
U1 1
U2 3
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD DEC
PY 2001
VL 11
IS 6
BP 643
EP 673
DI 10.1142/S021819400100075X
PG 31
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 528RW
UT WOS:000174257600001
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Almuzaini, HA
   Azmi, AM
AF Almuzaini, Huda A.
   Azmi, Aqil M.
TI An unsupervised annotation of Arabic texts using multi-label topic
   modeling and genetic algorithm
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Arabic corpus; Topic modeling; Multi-label annotation; Genetic
   algorithm; Latent Dirichlet allocation; Crowdsourcing
ID LDA
AB Every day the world produces an enormous amount of textual data. This unstructured text is of little use unless it is labeled using a combination of categories, keywords, tags. Humans can never annotate such massive data, and with a growing divide between the daily produced data and those annotated, the only alternative is to mechanize it. Automatic annotation process helps in saving resources in terms of time and cost. The process of multi-label annotation involves associating a document with multiple relevant labels. This paper proposes an unsupervised model to annotate corpus using multi-labels automatically. The model is based on multi-label topic modeling and genetic algorithm (GA). Topic modeling is a technique to extract the hidden topics from text, and the GA is used to find the optimal number of topics. We hyper-tuned the parameters of the topic modeling using two different training methods: variational Bayes and Gibbs sampling. The class imbalance in a corpus can affect the result of topic modeling, where the majority class dominates the minority class. We overcome this problem using the partitioning method. Though the proposed model was developed for the Arabic dataset, it is language neutral. We tested our model on three large Arabic corpora and three large English social media datasets. For the Arabic language, our work being the first work that tackles multi-label annotation, we needed a reference to compare our model. For the Arabic corpus, we compared the result of automatic annotation against humans using crowdsourcing (whose labeling was checked for quality). The analysis of the annotation shows an agreement among models (machine vs. human) of 79.30%. Moreover, for the English dataset, the results are quite competitive.
C1 [Almuzaini, Huda A.; Azmi, Aqil M.] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11543, Saudi Arabia.
C3 King Saud University
RP Azmi, AM (通讯作者)，King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11543, Saudi Arabia.
EM hamozeani@imamu.edu.sa; aqil@ksu.edu.sa
RI Azmi, Aqil M/L-3780-2019; Azmi, Aqil M/AAR-2299-2020
OI Azmi, Aqil M/0000-0002-0983-2861; Azmi, Aqil M/0000-0002-0983-2861;
   Almuzaini, Huda/0000-0002-4496-4317
CR Alhawarat M, 2018, IEEE ACCESS, V6, P42740, DOI 10.1109/ACCESS.2018.2852648
   Almuzaini HA, 2020, IEEE ACCESS, V8, P127913, DOI 10.1109/ACCESS.2020.3009217
   Alzanin SM, 2019, KNOWL-BASED SYST, V185, DOI 10.1016/j.knosys.2019.104945
   [Anonymous], 2010, P NIPS US
   [Anonymous], 2021, 10 MOST SPOKEN LANGU
   [Anonymous], 2017, ERGODICTHEORY DYNAMI
   Asuncion A., 2012, ARXIV PREPRINT ARXIV
   Awasare V. K., 2017, 2 INT C EL COMP COMM, P1
   Ayadi R, 2015, COMM COM INF SC, V538, P491, DOI 10.1007/978-3-319-24770-0_42
   Ayadi R, 2014, INT J INF RETR RES, V4, P57, DOI 10.4018/ijirr.2014040104
   Basu Sugato, 2002, ICML, P3
   Benz D, 2010, VLDB J, V19, P849, DOI 10.1007/s00778-010-0208-4
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brahmi A, 2012, INFORM RETRIEVAL, V15, P33, DOI 10.1007/s10791-011-9171-y
   Burkhardt Sophie, 2019, ACM SIGKDD Explorations Newsletter, V21, P61, DOI 10.1145/3373464.3373474
   Cai LK, 2020, IEEE ACCESS, V8, P152183, DOI 10.1109/ACCESS.2020.3017382
   Canini KR, 2009, P INT C ART INT STAT, V5, P65
   Chouigui A, 2017, I C COMP SYST APPLIC, P135, DOI 10.1109/AICCSA.2017.22
   Chu Z., 2021, 3 C AUTOMATED KNOWLE
   Dietz L., 2007, P 24 INT C MACHINE L, P233, DOI DOI 10.1145/1273496.1273526
   Dong H, 2021, IEEE T NEUR NET LEAR, V32, P2224, DOI 10.1109/TNNLS.2020.3002798
   El Bazi I., 2018, INT J INTELLIGENT EN, V11, P229
   El-Alami FZ, 2020, J INF COMMUN TECHNOL, V19, P381
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121
   Fujino A., 2005, PROC NATL CONF ARTIF, P764
   Gao X, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104034
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Guellil I, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00688-x
   Guellil I, 2018, LECT NOTES ARTIF INT, V10989, P557, DOI 10.1007/978-3-030-00563-4_54
   He DB, 2019, IEEE ACCESS, V7, P131593, DOI 10.1109/ACCESS.2019.2940516
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Imane G, 2019, INT J WEB INF SYST, V15, P594, DOI 10.1108/IJWIS-03-2019-0008
   Jelodar H., 2019, ARXIV PREPRINT ARXIV
   Jiang HQ, 2022, PSYCHOL HEALTH MED, V27, P1977, DOI 10.1080/13548506.2021.1990367
   Jo T., 2006, THESIS
   Johnsen JW, 2019, IEEE INT CONF BIG DA, P4248, DOI 10.1109/BigData47090.2019.9006006
   Kelaiaia A, 2016, INT ARAB J INF TECHN, V13, P332
   Khoja S., 1999, STEMMING ARABIC TEXT
   Kulkarni A., 2021, ARXIV PREPRINT ARXIV
   Kwaik K.A., 2020, P 4 WORKSHOP OPEN SO, P1
   Mifrah S., 2020, INT J ADV TRENDS COM, P5756, DOI DOI 10.30534/IJATCSE/2020/231942020
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Mimno David, 2011, EMNLP 11 P C EMPIRIC, P262, DOI DOI 10.5555/2145432.2145462
   Mimno David, 2009, P 2009 C EMPIRICAL M, V2, P880, DOI DOI 10.3115/1699571.1699627
   Molavi Mohammadreza, 2020, Addressing Global Challenges and Quality Education. 15th European Conference on Technology Enhanced Learning, EC-TEL 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12315), P455, DOI 10.1007/978-3-030-57717-9_44
   Moscato P, 2003, INT SER OPER RES MAN, V57, P105, DOI 10.1007/0-306-48056-5_5
   Naili M., 2017, ARABIC TOPIC IDENTIF
   Papadimitriou CH, 2000, J COMPUT SYST SCI, V61, P217, DOI 10.1006/jcss.2000.1711
   Papanikolaou Y, 2017, J MACH LEARN RES, V18, P1
   Patibandla R. S. M. Lakshmi, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P421, DOI 10.1007/978-981-10-7566-7_41
   Pavlinek M, 2017, EXPERT SYST APPL, V80, P83, DOI 10.1016/j.eswa.2017.03.020
   Perez F., 2018, ARXIV PREPRINT ARXIV
   Radford A., 2019, OPENAI BLOG
   Raff Edward, 2020, EXPLORATORY ANAL COV
   Röder M, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P399, DOI 10.1145/2684822.2685324
   Rosen-Zvi Michal, 2004, P 20 C UNCERTAINTY A, P487, DOI DOI 10.5555/1036843.1036902
   Saad M. K., 2010, 6 INT S ELECT ELECT, P1
   Schofeld Alexandra, 2017, P 15 C EUR CHAPT ASS, V2, P432, DOI DOI 10.18653/V1/E17-2069
   Settles Burr, 2009, COMPUTER SCI TECHNIC
   Smola A, 2010, PROC VLDB ENDOW, V3, P703, DOI 10.14778/1920841.1920931
   Stevens K., 2012, P 2012 JOINT C EMP M, P952
   Taghva K, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P152, DOI 10.1109/ITCC.2005.90
   Taware R., 2021, INT C MACH LEARN OPT
   Wan XJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2297
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang H., 2013, P 23 INT JOINT C ART, P2719
   Wang MZ, 2021, PROC VLDB ENDOW, V14, P1964, DOI 10.14778/3476249.3476255
   Xiao YQ, 2021, KNOWL-BASED SYST, V224, DOI 10.1016/j.knosys.2021.107094
   Xing YY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2882
   Yao LM, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P937
   Zha DC, 2019, KNOWL INF SYST, V61, P137, DOI 10.1007/s10115-018-1280-0
   Zhan W, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1305, DOI 10.1145/3097983.3098141
   Zhang H, 2020, LECT NOTES COMPUT SC, V12113, P227, DOI 10.1007/978-3-030-59416-9_14
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhu Y, 2009, LECT NOTES ARTIF INT, V5914, P134
   Zrigui Mounir, 2012, CIT. Journal of Computing and Information Technology, V20, P125, DOI 10.2498/cit.1001770
NR 76
TC 3
Z9 3
U1 3
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD OCT 1
PY 2022
VL 203
AR 117384
DI 10.1016/j.eswa.2022.117384
EA MAY 2022
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA 1S0FK
UT WOS:000803735400001
DA 2023-11-10
ER

PT J
AU Hoffmann, J
   Weber, I
   Kraft, FM
AF Hoffmann, Joerg
   Weber, Ingo
   Kraft, Frank Michael
TI SAP Speaks PDDL: Exploiting a Software-Engineering Model for Planning in
   Business Process Management
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
LA English
DT Article
ID COMPLEXITY
AB Planning is concerned with the automated solution of action sequencing problems described in declarative languages giving the action preconditions and effects. One important application area for such technology is the creation of new processes in Business Process Management (BPM), which is essential in an ever more dynamic business environment. A major obstacle for the application of Planning in this area lies in the modeling. Obtaining a suitable model to plan with - ideally a description in PDDL, the most commonly used planning language - is often prohibitively complicated and/or costly. Our core observation in this work is that this problem can be ameliorated by leveraging synergies with model-based software development. Our application at SAP, one of the leading vendors of enterprise software, demonstrates that even one-to-one model re-use is possible.
   The model in question is called Status and Action Management (SAM). It describes the behavior of Business Objects (BO), i.e., large-scale data structures, at a level of abstraction corresponding to the language of business experts. SAM covers more than 400 kinds of BOs, each of which is described in terms of a set of status variables and how their values are required for, and affected by, processing steps (actions) that are atomic from a business perspective. SAM was developed by SAP as part of a major model-based software engineering effort. We show herein that one can use this same model for planning, thus obtaining a BPM planning application that incurs no modeling overhead at all.
   We compile SAM into a variant of PDDL, and adapt an off-the-shelf planner to solve this kind of problem. Thanks to the resulting technology, business experts may create new processes simply by specifying the desired behavior in terms of status variable value changes: effectively, by describing the process in their own language.
C1 [Hoffmann, Joerg] Univ Saarland, D-6600 Saarbrucken, Germany.
   [Weber, Ingo] NICTA, Sydney, NSW, Australia.
C3 Saarland University; Australian National University
RP Hoffmann, J (通讯作者)，Univ Saarland, D-6600 Saarbrucken, Germany.
EM HOFFMANN@CS.UNI-SAARLAND.DE; INO.WEBER@NICTA.COM.AU;
   FRANK.MICHAEL.KRAFT@BPMNFORUM.NET
RI Weber, Ingo/C-9166-2011
OI Weber, Ingo/0000-0002-4833-5921
FU Australian Government; Australian Research Council through the ICT
   Centre of Excellence program
FX NICTA is funded by the Australian Government as represented by the
   Department of Broadband, Communications and the Digital Economy and the
   Australian Research Council through the ICT Centre of Excellence
   program.
CR Aalst W., 1997, APPL THEORY PETRI NE
   Agarwal V., 2005, J WEB SEMANTICS, V3
   Aler R, 2002, KNOWL-BASED SYST, V15, P473, DOI 10.1016/S0950-7051(02)00032-1
   [Anonymous], 2001, P 17 INT JOINT C ART
   [Anonymous], 1971, PROBLEM SOLVING METH
   [Anonymous], 2001, LONELYLAND
   BACCHUS F, 2000, SUBSET PDDL AIPS2000
   BACKSTROM C, 1995, COMPUT INTELL, V11, P625, DOI 10.1111/j.1467-8640.1995.tb00052.x
   Bell M., 2008, SERVICE ORIENTED MOD
   Berardi D, 2005, INT J COOP INF SYST, V14, P333, DOI 10.1142/S0218843005001201
   Berardi D, 2003, LECT NOTES COMPUT SC, V2910, P43
   Bertoli P., 2006, P 16 INT C AUT PLANN
   Bertoli P, 2010, ARTIF INTELL, V174, P316, DOI 10.1016/j.artint.2009.12.002
   Biundo S., 2003, PLANET TECHNOLOGICAL
   Bonet B, 2001, ARTIF INTELL, V129, P5, DOI 10.1016/S0004-3702(01)00108-4
   Bonet B., 2000, Proceedings of the Fifth International Conference on Artificial Intelligence Planning and Scheduling, P52
   Bonet B., 2006, P 5 INT PLANN COMP I
   Born M, 2008, LECT NOTES COMPUT SC, V5021, P772
   Born M, 2009, LECT NOTES COMPUT SC, V5463, P759, DOI 10.1007/978-3-642-00887-0_67
   Bryce D., 2008, P 6 INT PLANN COMP I
   Bryce D., 2004, P 14 INT C AUT PLANN, P365
   Bryce D, 2006, J ARTIF INTELL RES, V26, P35, DOI 10.1613/jair.1869
   BYLANDER T, 1994, ARTIF INTELL, V69, P165, DOI 10.1016/0004-3702(94)90081-7
   Calvanese D., 2008, IEEE DATA ENG B, V31, P18
   Cimatti A, 2003, ARTIF INTELL, V147, P35, DOI 10.1016/S0004-3702(02)00374-0
   Cimatti A., 1997, Recent Advances in AI Planning. 4th European Conference on Planning, ECP'97 Proceedings, P130, DOI 10.1007/3-540-63912-8_81
   Cimatti A., 1998, Proceedings Fourth International Conference on Artificial Intelligence Planning Systems, P36
   Cimatti A, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P875
   Cohn D., 2009, B IEEE COMPUTER SOC, V32, P3
   Constantinescu I, 2004, IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P506, DOI 10.1109/ICWS.2004.1314776
   Cresswell S., 2010, KNOWLEDGE ENG REV
   De Giacomo G, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1866
   Dumas M, 2005, PROCESS-AWARE INFORMATION SYSTEMS: BRIDGING PEOPLE AND SOFTWARE THROUGH PROCESS TECHNOLOGY, P1, DOI 10.1002/0471741442
   Fox M, 2003, J ARTIF INTELL RES, V20, P61, DOI 10.1613/jair.1129
   Gazen B. Cenk, 1997, LNCS, P221
   Gerevini AE, 2009, ARTIF INTELL, V173, P619, DOI 10.1016/j.artint.2008.10.012
   Gonzalez-Ferrer A., 2009, P 3 INT COMP KNOWL E
   Helmert M, 2006, J ARTIF INTELL RES, V26, P191, DOI 10.1613/jair.1705
   Helmert M, 2009, ARTIF INTELL, V173, P503, DOI 10.1016/j.artint.2008.10.013
   Hoffmann J, 2005, J ARTIF INTELL RES, V24, P519, DOI 10.1613/jair.1677
   Hoffmann J, 2001, J ARTIF INTELL RES, V14, P253, DOI 10.1613/jair.855
   Hoffmann Jorg, 2005, PROC INT C AUTOMATED, P71
   Jonathan P. J., 1999, P AAAI 99 WORKSH AG
   Kambhampati S., 2007, P 22 NAT C AM ASS AR
   Kitchin D. E., 2005, P ICAPS 05 WORKSH VE
   Krafzig D., 2005, ENTERPRISE SOA SERVI
   Kuester JM, 2007, LECT NOTES COMPUT SC, V4714, P165
   Lago UD, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P447
   Liu Z., 2007, P 22 NAT C AM ASS AR
   May N, 2008, LECT NOTES BUS INF P, V10, P46
   McDermott D, 1999, ARTIF INTELL, V109, P111, DOI 10.1016/S0004-3702(99)00010-7
   McDermott D., 1998, TR98003 CVC YAL CTR
   Mediratta A., 2006, RI06002 IBM
   Meyer H, 2006, LECT NOTES COMPUT SC, V4102, P81
   NARAYANAN S, 2002, P 11 INT WORLD WID W
   Nilsson N. J., 1969, INFORMATION PROCESSI, V2, P1556
   Object Management Group, 2008, BUS PROC MOD NOT V1
   Object Management Group, 2006, OBJ CONSTR LANG SPEC
   Palacios H, 2009, J ARTIF INTELL RES, V35, P623, DOI 10.1613/jair.2708
   Pearl J., 1984, HEURISTICS
   PEDNAULT EPD, 1989, S REPR REAS, P324
   Pesic M, 2007, LECT NOTES COMPUT SC, V4803, P77
   Pistore M., 2005, P 19 INT JOINT C ART
   PONNEKANTI SR, 2002, P 11 INT WORLD WID W
   R-Moreno MD, 2007, EXPERT SYST APPL, V33, P389, DOI 10.1016/j.eswa.2006.05.027
   Richter S., 2009, P 19 INT C AUT PLANN
   SAP, 2010, SAP NETWEAVER
   Sardina S., 2008, P PRINC KNOWL REPR R, P640
   Shaparau D., 2006, P 21 NAT C AM ASS AR
   SIRIN E, 2004, J WEB SEMANTICS, V1
   Sirin E., 2006, AAAI FALL S AG SEARC
   Smith DE, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P326
   Srivastava B., 2002, P KBCS MUMB, P467
   Traverso P., 2005, AUTOMATED PLANNING T
   Turner J., 1994, CONSTRUCTION FORMAL
   van der Aalst W., 2003, ADV COURSE PETRI NET, P1
   van der Aalst WMP, 2006, LECT NOTES COMPUT SC, V4184, P1
   Wainer J, 2003, LECT NOTES COMPUT SC, V2806, P151
   Weld DS, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P897
   Weske M., 2007, BUSINESS PROCESS MAN
   West M, 2009, 19 INT C AUT PLANN S
   Yoon S. W., 2007, P 17 INT C AUT PLANN
   Younes HLS, 2005, J ARTIF INTELL RES, V24, P851, DOI 10.1613/jair.1880
NR 83
TC 15
Z9 15
U1 0
U2 7
PU AI ACCESS FOUNDATION
PI MARINA DEL REY
PA USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA
   90292-6695 USA
SN 1076-9757
EI 1943-5037
J9 J ARTIF INTELL RES
JI J. Artif. Intell. Res.
PY 2012
VL 44
BP 587
EP 632
DI 10.1613/jair.3636
PG 46
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 981FC
UT WOS:000306951300001
OA Green Published, gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Wang, YW
   Zeng, Y
   Tang, JB
   Xu, B
AF Wang, Yuwei
   Zeng, Yi
   Tang, Jianbo
   Xu, Bo
TI Biological Neuron Coding Inspired Binary Word Embeddings
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Word embeddings; Neuron coding; Spiking neural networks
ID NETWORKS; CELLS; INFORMATION; MODEL
AB Word embeddings are the semantic representations of the words. They are derived from large corpus and work well on many natural language tasks, with one downside of costing large memory space. In this paper, we propose binary word embedding models based on inspirations from biological neuron coding mechanisms, converting the spike timing of neurons during specific time intervals into binary codes, reducing the space and speeding up computation. We build three types of models to post-process the original dense word embeddings, namely, the homogeneous Poission processing-based rate coding model, the leaky integrate-and-fire neuron-based model, and the Izhikevich's neuron-based model. We test our binary embedding models on word similarity and text classification tasks of five public datasets. The experimental results show that the brain-inspired binary word embeddings (which reduce approximately 68.75% of the space) get similar results to original embeddings for word similarity task while better performance than traditional binary embeddings on text classification task.
C1 [Wang, Yuwei; Zeng, Yi; Tang, Jianbo; Xu, Bo] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Wang, Yuwei; Zeng, Yi; Tang, Jianbo; Xu, Bo] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Zeng, Yi; Xu, Bo] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Shanghai, Peoples R China.
   [Zeng, Yi] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Zeng, Y (通讯作者)，Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.; Zeng, Y (通讯作者)，Univ Chinese Acad Sci, Beijing, Peoples R China.; Zeng, Y (通讯作者)，Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Shanghai, Peoples R China.; Zeng, Y (通讯作者)，Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
EM yuwei.wang@ia.ac.cn; yi.zeng@ia.ac.cn
OI Zeng, Yi/0000-0002-9595-9091
FU Strategic Priority Research Program of Chinese Academy of Sciences
   [XDB32070100]; Beijing Municipality of Science and Technology
   [Z181100001518006]; CETC Joint Fund [6141B08010103]; Major Research
   Program of Shandong Province [2018CXGC1503]
FX This study is supported by the Strategic Priority Research Program of
   Chinese Academy of Sciences (Grant No. XDB32070100), the Beijing
   Municipality of Science and Technology (Grant No. Z181100001518006), the
   CETC Joint Fund (Grant No. 6141B08010103), and the Major Research
   Program of Shandong Province 2018CXGC1503.
CR Adrian ED, 1926, J PHYSIOL-LONDON, V61, P49, DOI 10.1113/jphysiol.1926.sp002273
   Agirre E., 2009, HUMAN LANGUAGE TECHN
   [Anonymous], 2014, C EMPIRICAL METHODS
   [Anonymous], 2010, DYNAMICAL SYSTEMS NE
   [Anonymous], 2016, ARXIV161103000
   Azhar H, 2005, IEEE INT JOINT C NEU
   BAIR W, 1994, J NEUROSCI, V14, P2870
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Brown EN, 2004, NAT NEUROSCI, V7, P456, DOI 10.1038/nn1228
   Burkitt AN, 2006, BIOL CYBERN, V95, P1, DOI 10.1007/s00422-006-0068-6
   Cao YQ, 2015, INT J COMPUT VISION, V113, P54, DOI 10.1007/s11263-014-0788-3
   Crawford E, 2016, COGNITIVE SCI, V40, P782, DOI 10.1111/cogs.12261
   Faisal AA, 2008, NAT REV NEUROSCI, V9, P292, DOI 10.1038/nrn2258
   Faruqui M, 2015, P 53 ANN M ASS COMP
   Floreano D, 2006, INT J INTELL SYST, V21, P1005, DOI 10.1002/int.20173
   Gupta A, 2007, IEEE IJCNN, P53, DOI 10.1109/IJCNN.2007.4370930
   Hill F., 2016, COMPUTATIONAL LINGUI
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   HOPFIELD JJ, 1995, NATURE, V376, P33, DOI 10.1038/376033a0
   Hu J, 2013, NEURAL COMPUT, V25, P450, DOI 10.1162/NECO_a_00395
   Hunsberger E., 2015, COMPUTER SCI
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Johansson RS, 2004, NAT NEUROSCI, V7, P170, DOI 10.1038/nn1177
   Kistler W.M., 2002, SPIKING NEURON MODEL
   Laurent G, 1996, TRENDS NEUROSCI, V19, P489, DOI 10.1016/S0166-2236(96)10054-0
   Lestienne R, 1996, BIOL CYBERN, V74, P55, DOI 10.1007/BF00199137
   Ling SS, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P387
   Loiselle S, 2005, IEEE IJCNN, P2076
   Luong T., 2013, P 17 C COMP NAT LANG, P104, DOI DOI 10.1007/BF02579642
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Murphy B., 2012, P COLING 2012
   O'Keefe L. P., 1997, Society for Neuroscience Abstracts, V23, P1125
   Pennington J., 2014, P 2014 C EMP METH NA
   Phan X.-H., 2008, P 17 INT C WORLD WID, P91
   Ponulak F, 2011, ACTA NEUROBIOL EXP, V71, P409
   Quiroga RQ, 2013, PRINCIPLES OF NEURAL CODING, P1, DOI 10.1201/b14756
   Rieke F., 1999, SPIKES EXPLORING NEU
   Rolls ET, 2017, LANG COGN NEUROSCI, V32, P316, DOI 10.1080/23273798.2016.1203443
   Saal HP, 2009, J NEUROSCI, V29, P8022, DOI 10.1523/JNEUROSCI.0665-09.2009
   Socher R., 2013, LONG PAPERS, V1, P455
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   SOFTKY WR, 1992, NEURAL COMPUT, V4, P643, DOI 10.1162/neco.1992.4.5.643
   Stewart TC, 2010, M COGN SCI SOC
   Sun F., 2016, P 25 INT JOINT C ART, P2915
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Thorpe SJ, 1990, PARALLEL PROCESSING
   Tiesinga P, 2008, NAT REV NEUROSCI, V9, P97, DOI 10.1038/nrn2315
   Van Rullen R, 2001, NEURAL COMPUT, V13, P1255, DOI 10.1162/08997660152002852
NR 50
TC 8
Z9 8
U1 1
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD OCT
PY 2019
VL 11
IS 5
BP 676
EP 684
DI 10.1007/s12559-019-09643-1
PG 9
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA JL0SG
UT WOS:000495244800006
OA hybrid
DA 2023-11-10
ER

PT J
AU Nair, M
   Kannimoola, JM
   Jayaraman, B
   Nair, B
   Diwakar, S
AF Nair, Manjusha
   Kannimoola, Jinesh Manchan
   Jayaraman, Bharat
   Nair, Bipin
   Diwakar, Shyam
TI Temporal constrained objects for modelling neuronal dynamics
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Temporal constrained objects; Constraint programming; Object-oriented
   languages; Declarative modelling; Neuron models
ID GRANULAR LAYER; FIRE MODEL; SIMULATION; LANGUAGE; CIRCUITS
AB Background: Several new programming languages and technologies have emerged in the past few decades in order to ease the task of modelling complex systems. Modelling the dynamics of complex systems requires various levels of abstractions and reductive measures in representing the underlying behaviour. This also often requires making a trade-off between how realistic a model should be in order to address the scientific questions of interest and the computational tractability of the model.
   Methods: In this paper, we propose a novel programming paradigm, called temporal constrained objects, which facilitates a principled approach to modelling complex dynamical systems. Temporal constrained objects are an extension of constrained objects with a focus on the analysis and prediction of the dynamic behaviour of a system. The structural aspects of a neuronal system are represented using objects, as in object-oriented languages, while the dynamic behaviour of neurons and synapses are modelled using declarative temporal constraints. Computation in this paradigm is a process of constraint satisfaction within a time-based simulation.
   Results: We identified the feasibility and practicality in automatically mapping different kinds of neuron and synapse models to the constraints of temporal constrained objects. Simple neuronal networks were modelled by composing circuit components, implicitly satisfying the internal constraints of each component and interface constraints of the composition. Simulations show that temporal constrained objects provide significant conciseness in the formulation of these models. The underlying computational engine employed here automatically finds the solutions to the problems stated, reducing the code for modelling and simulation control. All examples reported in this paper have been programmed and successfully tested using the prototype language called TCOB. The code along with the programming environment are available at http://github.com/compneuro/TCOB_Neuron.
   Discussion: Temporal constrained objects provide powerful capabilities for modelling the structural and dynamic aspects of neural systems. Capabilities of the constraint programming paradigm, such as declarative specification, the ability to express partial information and non-directionality, and capabilities of the object-oriented paradigm especially aggregation and inheritance, make this paradigm the right candidate for complex systems and computational modelling studies. With the advent of multi-core parallel computer architectures and techniques or parallel constraint-solving, the paradigm of temporal constrained objects lends itself to highly efficient execution which is necessary for modelling and simulation of large brain circuits.
C1 [Nair, Manjusha; Nair, Bipin; Diwakar, Shyam] Amrita Vishwa Vidyapeetham, Amrita Sch Biotechnol, Kollam, Kerala, India.
   [Nair, Manjusha] Amrita Vishwa Vidyapeetham, Dept Comp Sci & Applicat, Amritapuri Campus, Kollam, Kerala, India.
   [Kannimoola, Jinesh Manchan] Amrita Vishwa Vidyapeetham, Ctr Cybersecur Syst & Networks, Amritapuri Campus, Kollam, Kerala, India.
   [Jayaraman, Bharat] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY USA.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri;
   Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri;
   Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo
RP Diwakar, S (通讯作者)，Amrita Vishwa Vidyapeetham, Amrita Sch Biotechnol, Kollam, Kerala, India.
EM shyam@amrita.edu
RI Kannimoola, Jinesh Manchan/ABF-1318-2020; M, Manjusha
   Nair/ABE-9781-2020; Diwakar, Shyam/C-2455-2015
OI Kannimoola, Jinesh Manchan/0000-0001-5392-0570; M, Manjusha
   Nair/0000-0002-1573-1936; Diwakar, Shyam/0000-0003-1546-0184; nair,
   bipin/0000-0002-4944-8805
FU Department of Science and Technology, Young Faculty Research
   Fellowship-Sir Visvesvaraya PhD Scheme, MeitY, Government of India
   [SR/CSRI/60/2013]; Embracing The World
FX This work was partially supported by Grants SR/CSRI/60/2013 from
   Department of Science and Technology, Young Faculty Research
   Fellowship-Sir Visvesvaraya PhD Scheme, MeitY, Government of India and
   by Embracing The World. There was no additional external funding
   received for this study. The funders had no role in study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript.
CR [Anonymous], 1999, P WEEK DOCTORAL STUD
   [Anonymous], 1994, JOINT C DECLARATIVE
   [Anonymous], 2004, PRINCIPLES OBJECT OR
   Benhamou F, 2007, TRENDS IN CONSTRAINT PROGRAMMING, P17
   Bezzi M, 2004, NEUROCOMPUTING, V58, P593, DOI 10.1016/j.neucom.2004.01.100
   BORNING A, 1981, ACM T PROGR LANG SYS, V3, P353, DOI 10.1145/357146.357147
   Brette R, 2005, J NEUROPHYSIOL, V94, P3637, DOI 10.1152/jn.00686.2005
   Campeotto Federico, 2014, Practical Aspects of Declarative Languages. 16th International Symposium, PADL 2014. Proceedings: LNCS 8324, P152, DOI 10.1007/978-3-319-04132-2_11
   Cannon RC, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00079
   Covert MW, 2003, BIOTECHNOL BIOENG, V84, P763, DOI 10.1002/bit.10849
   D'Angelo E, 2011, J INTEGR NEUROSCI, V10, P317, DOI 10.1142/S0219635211002762
   DANGELO E, 1995, J PHYSIOL-LONDON, V484, P397, DOI 10.1113/jphysiol.1995.sp020673
   Darlington J., 1990, Concurrency: Practice and Experience, V2, P149, DOI 10.1002/cpe.4330020302
   Davison Andrew P, 2008, Front Neuroinform, V2, P11, DOI 10.3389/neuro.11.011.2008
   Destexhe A., 1998, METHODS NEURONAL MOD, P1
   Diesmann M, 2001, FORSCHUNG WISSCHENSC, V58, P43
   Diwakar S, 2009, J NEUROPHYSIOL, V101, P519, DOI 10.1152/jn.90382.2008
   Felgentreff T, 2015, ACM SIGPLAN NOTICES, V50, P767, DOI [10.1145/2814270.2814311, 10.1145/2858965.2814311]
   FREEMANBENSON BN, 1990, COMMUN ACM, V33, P54, DOI 10.1145/76372.77531
   Gleeson P, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000815
   Goddard N. H., 1998, THE BOOK OF GENESIS, P349
   Goodman Dan, 2008, Front Neuroinform, V2, P5, DOI 10.3389/neuro.11.005.2008
   Govindarajan K., 1996, Conference Record of POPL '96: The 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, P91, DOI 10.1145/237721.237735
   Gupta V, 1995, LECT NOTES COMPUT SC, V999, P226
   Gutkin B, 2003, J PHYSIOLOGY-PARIS, V97, P209, DOI 10.1016/j.jphysparis.2003.09.005
   Hines ML, 1997, NEURAL COMPUT, V9, P1179, DOI 10.1162/neco.1997.9.6.1179
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V116, P449, DOI 10.1113/jphysiol.1952.sp004717
   Horn B, 1991, SIRI CONSTRAINED OBJ
   Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Jayaraman B., 2002, Practical Aspects of Declarative Languages. 4th International Symposium, PADL 2002. Proceedings (Lecture Notes in Computer Science Vol.2257), P28
   Kandel ER., 2021, PRINCIPLES NEURAL SC, V6
   Kannimoola JM, 2017, COMPUT LANG SYST STR, V49, P82, DOI 10.1016/j.cl.2017.03.002
   Koch C., 1998, METHODS NEURONAL MOD
   Lago JM, 2001, THEOR COMPUT SCI, V269, P363, DOI 10.1016/S0304-3975(01)00013-5
   Markram H, 2006, NAT REV NEUROSCI, V7, P153, DOI 10.1038/nrn1848
   MCCORMICK DA, 1993, CEREB CORTEX, V3, P387, DOI 10.1093/cercor/3.5.387
   Medini C., 2014, P INTERDISCIPLINARY, P1, DOI [10.1145/2660859.2660961, DOI 10.1145/2660859.2660961]
   Nair M., 2014, 2014 INT C HIGH PERF, P1
   Naud R, 2008, BIOL CYBERN, V99, P335, DOI 10.1007/s00422-008-0264-7
   Pushpendran M., 2006, THESIS
   Raikov I., 2010, BMC NEUROSCI, V11, P2202, DOI [10.1186/1471-2202-11-s1-p66, DOI 10.1186/1471-2202-11-S1-P66]
   Ray Subhasis, 2008, Front Neuroinform, V2, P6, DOI 10.3389/neuro.11.006.2008
   Reiner MJ, 2017, MATH COMP MODEL DYN, V23, P319, DOI 10.1080/13873954.2017.1298627
   Richmond P, 2014, NEUROINFORMATICS, V12, P307, DOI 10.1007/s12021-013-9208-z
   Roggeri L, 2008, J NEUROSCI, V28, P6354, DOI 10.1523/JNEUROSCI.5709-07.2008
   Rolf C, 2011, THESIS
   Roth A, 2009, COMPUT NEUROSCI-MIT, P139
   Solinas S, 2010, FRONT CELL NEUROSCI, V4, DOI 10.3389/fncel.2010.00012
   Tambay PY., 2003, THESIS
   Zaytsev YV, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00023
NR 58
TC 1
Z9 1
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 23
PY 2018
AR e159
DI 10.7717/peerj-cs.159
PG 31
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HG1AG
UT WOS:000454680600003
PM 33816812
OA gold, Green Published, Green Submitted
DA 2023-11-10
ER

PT J
AU Pérez, A
   Gojenola, K
   Casillas, A
   Oronoz, M
   de Ilarraza, AD
AF Perez, Alicia
   Gojenola, Koldo
   Casillas, Arantza
   Oronoz, Maite
   de Ilarraza, Arantza Diaz
TI Computer aided classification of diagnostic terms in spanish
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Classification of Medical Records; Natural language processing;
   Finite-State Transducers; Applications in medicine
ID ICD-9-CM
AB The goal of this paper is to classify Medical Records (MRs) by their diagnostic terms (DTs) according to the International Classification of Diseases Clinical Modification (ICD-9-CM). The challenge we face is twofold: (i) to treat the natural and non-standard language in which doctors express their diagnostics and (ii) to perform a large-scale classification problem.
   We propose the use of Finite-State Transducers (FSTs) that, for their underlying topology, constrain the allowed input DT string while synchronously produce the output ICD-9-CM class. It is outstanding their versatility to efficiently implement soft-matching operations between terms expressed in natural language to standard terms and, hence, to the final ICD-9-CM code. The FSTs were built up from a corpora and standard resources such as the ICD-9-CM and SNOMED CT amongst others. Our corpora count on a big-data comprising more than 20,000 DTs from MRs from the Basque Hospital System so as to model natural language in this domain. An F1-measure of 91.2 was achieved on a test-set of 2850 randomly selected DTs, and a random 5-fold cross validation on a training set served to double-check the stability of the provided results. Real MRs were of much help to adapt the system to natural language. Misspellings, colloquial and specific language and abbreviations made the classification process difficult. The FSTs were proven efficient in this large-scale classification task. Moreover, the composition operation for FSTs made it easy the addition of new features to the system. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Perez, Alicia; Gojenola, Koldo] Univ Basque Country, Tech Sch Engn Bilbao, Dept Languages & Comp Syst, Leioa 48940, Bizkaia, Spain.
   [Casillas, Arantza] Univ Basque Country, Fac Sci & Technol, Dept Elect & Elect, Leioa 48940, Bizkaia, Spain.
   [Oronoz, Maite; de Ilarraza, Arantza Diaz] Univ Basque Country, Fac Comp Sci, Dept Languages & Comp Syst, Leioa 48940, Bizkaia, Spain.
C3 University of Basque Country; University of Basque Country; University
   of Basque Country
RP Casillas, A (通讯作者)，Univ Basque Country, Fac Sci & Technol, Dept Elect & Elect, Barrio Sarriena S-N, Leioa 48940, Bizkaia, Spain.
EM alicia.perez@ehu.es; koldo.gojenola@ehu.es; arantza.casillas@ehu.es;
   maite.oronoz@ehu.es; a.diazdeilarraza@ehu.es
RI Gojenola, Koldo/Z-5616-2019; Casillas, Arantza/B-8954-2018; Oronoz,
   Maite/AAA-4858-2019; Pérez, Alicia/AAF-7338-2019; Pérez,
   Alicia/S-8562-2016
OI Gojenola, Koldo/0000-0002-2116-6611; Casillas,
   Arantza/0000-0003-4248-8182; Pérez, Alicia/0000-0003-2638-9598; Pérez,
   Alicia/0000-0003-2638-9598; DIAZ DE ILARRAZA SANCHEZ, MARIA
   ARANZAZU/0000-0003-3317-8561; ORONOZ ANCHORDOQUI,
   MAITE/0000-0001-9097-6047
FU Spanish Ministry of Science and Innovation (EXTRECM)
   [TIN2013-46616-C2-1-R]; Basque Government [IT344-10, IE12-333];
   Galdakao-Usansolo Hospital; Spanish Ministry of Science and Innovation
   (SKATER) [TIN2012-38584-C06-02]
FX Authors would like to thank the Galdakao-Usansolo Hospital for their
   contributions and support, in particular to Javier Yetano, responsible
   of the Clinical Documentation Service.; This work was partially funded
   by the Spanish Ministry of Science and Innovation (EXTRECM:
   TIN2013-46616-C2-1-R, SKATER: TIN2012-38584-C06-02) and the Basque
   Government (IT344-10, IE12-333).
CR [Anonymous], 2009, SIGKDD EXPLOR NEWSL, V11, P10, DOI DOI 10.1145/1656274.1656278
   [Anonymous], 2001, INTRO AUTOMATA THEOR
   Argaw A. A., 2007, GEN PURPOSE TEXT CAT
   Aronson A. R., 2007, P WORKSH BIONLP 2007, P105
   Beesley K. R., 2003, CSLI STUDIES COMPUTA
   Benesch C, 1997, NEUROLOGY, V49, P660, DOI 10.1212/WNL.49.3.660
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cheng O., 2007, IEEE INT C AC SPEECH, V4, P342
   Chomsky N., 1959, INFORM CONTR, V2, P137, DOI [10.1016/S0019-9958(59)90362-6, DOI 10.1016/S0019-9958(59)90362-6]
   Crammer K., 2007, P WORKSHOP BIONLP 20, P129
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Farkas R, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-69
   Farkas R, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S3-S10
   Goldstein Ira, 2007, AMIA Annu Symp Proc, P279
   Hassan A., 2008, IJCNLP, P913
   Holmes AB, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021132
   HULDEN M., 2009, P 12 C EUR CHAPT ASS, V12, P29, DOI DOI 10.3115/1609049.1609057
   Hulden M., 2009, THESIS TUCSON
   John GH., 1995, P 11 C UNC ART INT, P338, DOI DOI 10.1109/TGRS.2004.834800
   Karttunen Lauri, 1996, NAT LANG ENG, V2, P305
   Levenshtein V. I., 1966, BINARY CODES CAPABLE, DOI DOI 10.1109/TVCG.2012.323
   Linden K., 2009, WORKSH SYST FRAM COM
   Lita L. V., 2008, P INT JOINT C NAT LA, P877
   Lojo D, 2009, LECT NOTES COMPUT SC, V5602, P499, DOI 10.1007/978-3-642-02267-8_53
   Medori J., 2010, P NAACL HLT 2010 2 L, P84
   Metais E., 2007, P 5 WSEAS INT C TEL, P354
   Mohri M, 1997, COMPUT LINGUIST, V23, P269
   Mohri M., 2003, AT T
   Patrick J., 2007, P 10 C PAC ASS COMP, P218
   Pereira L., 2013, PROCEDIA TECHNOLOGY, V9, P1351, DOI DOI 10.1016/J.PR0TCY.2013.12.152
   Perotte A, 2014, J AM MED INFORM ASSN, V21, P231, DOI 10.1136/amiajnl-2013-002159
   Pestian J. P., 2007, P WORKSH BIONLP 2007, P97, DOI DOI 10.3115/1572392.1572411
   Pradhan S., 2014, J AM MED INFORM ASS
   Riley Michael, 2009, P NAACL TUTORIALS, P9
   SNOMED-CT, 2012, SNOMED CT US GUID IN
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Stanfill MH, 2010, J AM MED INFORM ASSN, V17, P646, DOI 10.1136/jamia.2009.001024
   Toselli AH, 2011, MULTIMODAL INTERACTIVE PATTERN RECOGNITON AND APPLICATIONS, P1, DOI 10.1007/978-0-85729-479-1
   Witten IH, 2011, MOR KAUF D, P1
   Yli-Jyra A., 2006, P INT WORKSH RES INF, P32
NR 40
TC 14
Z9 14
U1 0
U2 708
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD APR 15
PY 2015
VL 42
IS 6
BP 2949
EP 2958
DI 10.1016/j.eswa.2014.11.035
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Operations Research & Management Science
GA CA9UY
UT WOS:000349271500009
DA 2023-11-10
ER

PT J
AU Bhunia, AK
   Roy, PP
   Mohta, A
   Pal, U
AF Bhunia, Ayan Kumar
   Roy, Partha Pratim
   Mohta, Akash
   Pal, Umapada
TI Cross-language framework for word recognition and spotting of Indic
   scripts
SO PATTERN RECOGNITION
LA English
DT Article
DE Indic script recognition; Handwritten word recognition; Word spotting;
   Cross language recognition; Script similarity; Hidden Markov model
ID HANDWRITTEN; SEGMENTATION
AB Handwritten word recognition and spotting of low-resource scripts are difficult as sufficient training data is not available and it is often expensive for collecting data of such scripts. This paper presents a novel cross language platform for handwritten word recognition and spotting for such low-resource scripts where training is performed with a sufficiently large dataset of an available script (considered as source script) and testing is done on other scripts (considered as target script). Training with one source script and testing with another script to have a reasonable result is not easy in handwriting domain due to the complex nature of handwriting variability among scripts. Also it is difficult in mapping between source and target characters when they appear in cursive word images. The proposed Indic cross language framework exploits a large resource of dataset for training and uses it for recognizing and spotting text of other target scripts where sufficient amount of training data is not available. Since, Indic scripts are mostly written in 3 zones, namely, upper, middle and lower, we employ zone-wise character (or component) mapping for efficient learning purpose. The performance of our cross-language framework depends on the extent of similarity between the source and target scripts. Hence, we devise an entropy based script similarity score using source to target character mapping that will provide a feasibility of cross language transcription. We have tested our approach in three Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the corresponding results are reported. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Bhunia, Ayan Kumar; Mohta, Akash] Inst Engn & Management, Dept ECE, Kolkata, India.
   [Roy, Partha Pratim] Indian Inst Technol, Dept CSE, Roorkee, Uttar Pradesh, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
C3 Institute of Engineering & Management (IEM), Kolkata; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Roorkee; Indian Statistical Institute; Indian Statistical Institute
   Kolkata
RP Roy, PP (通讯作者)，Indian Inst Technol, Dept CSE, Roorkee, Uttar Pradesh, India.
EM proy.fcs@iitr.ac.in
RI Pal, Umapada/AAC-4930-2022; Roy, Partha Pratim/AAW-2994-2020; Roy,
   Partha Pratim/AAV-9061-2020; Roy, Partha Pratim/GPF-4253-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; 
CR [Anonymous], P ICFHR AUG 5 8 NIAG
   Bhattacharya U, 2009, IEEE T PATTERN ANAL, V31, P444, DOI 10.1109/TPAMI.2008.88
   Bhoi S, 2015, NAT CONF COMPUT VIS
   Bhowmik T. K., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P195, DOI 10.1109/DAS.2012.50
   Bhunia AK, 2015, PROC INT CONF DOC, P636, DOI 10.1109/ICDAR.2015.7333839
   Bianne-Bernard AL, 2011, IEEE T PATTERN ANAL, V33, P2066, DOI 10.1109/TPAMI.2011.22
   Bunke H, 2003, PROC INT CONF DOC, P448
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   DILLENCOURT MB, 1992, J ACM, V39, P253, DOI 10.1145/128749.128750
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Gaur S, 2015, PROC INT CONF DOC, P491, DOI 10.1109/ICDAR.2015.7333810
   Ghosh D, 2010, IEEE T PATTERN ANAL, V32, P2142, DOI 10.1109/TPAMI.2010.30
   Gray RM, 2011, ENTROPY AND INFORMATION THEORY , SECOND EDITION, P395, DOI 10.1007/978-1-4419-7970-4
   Keserwani R, 2017, INT C ADV PATT REC I
   Knill KM, 2014, INTERSPEECH, P16
   Koerich AL, 2005, IEEE T PATTERN ANAL, V27, P1509, DOI 10.1109/TPAMI.2005.207
   Levenshtein V. I., 1966, BINARY CODES CAPABLE, DOI DOI 10.1109/TVCG.2012.323
   Leydier Y, 2009, PATTERN RECOGN, V42, P2089, DOI 10.1016/j.patcog.2009.01.026
   Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151
   Loof J., 2009, INTERSPEECH, P88
   Märgner V, 2007, PROC INT CONF DOC, P1274
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   Nie F., 2017, P AAAI C ART INT
   Nie F., 2014, P INT C MACH LEARN I, V32
   Pal U, 2004, PATTERN RECOGN, V37, P1887, DOI 10.1016/j.patcog.2004.02.003
   Pal U, 2012, INT CONF FRONT HAND, P169, DOI 10.1109/ICFHR.2012.238
   Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8
   Roy PP, 2016, PATTERN RECOGN, V60, P1057, DOI 10.1016/j.patcog.2016.04.012
   Rusiñol M, 2015, PATTERN RECOGN, V48, P545, DOI 10.1016/j.patcog.2014.08.021
   Stolcke A., 2006, P INT C AC SPEECH SI
   Su T., 2013, CHINESE HANDWRITING
   Toth L., 2008, INTERSPEECH
   Vapnik Vladimir, 1999, NATURE STAT LEARNING, V2
   Wshah S, 2014, PATTERN RECOGN, V47, P1039, DOI 10.1016/j.patcog.2013.09.019
NR 37
TC 20
Z9 20
U1 0
U2 14
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD JUL
PY 2018
VL 79
BP 12
EP 31
DI 10.1016/j.patcog.2018.01.034
PG 20
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GE0KP
UT WOS:000430903000002
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Padó, S
   Lapata, M
AF Pado, Sebastian
   Lapata, Mirella
TI Dependency-based construction of semantic space models
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID ACQUISITION
AB Traditionally, vector-based semantic space models use word co-occurrence counts from large corpora to represent lexical meaning. In this article we present a novel flamework for constructing semantic spaces that takes syntactic relations into account. We introduce a formalization for this class of models, which allows linguistic knowledge to guide the construction process. We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing: semantic priming, synonymy detection, and word sense disambiguation. In all cases, our framework obtains results that are comparable or superior to the state of the art.
C1 Computat Linguist, D-66041 Saarbrucken, Germany.
   Univ Edinburgh, Sch Informats, Edinburgh EH8 9LW, Midlothian, Scotland.
   Univ Saarland, D-6600 Saarbrucken, Germany.
C3 University of Edinburgh; Saarland University
RP Padó, S (通讯作者)，Computat Linguist, POB 151150, D-66041 Saarbrucken, Germany.
EM pado@coli.uni-sb.de; mlap@inf.ed.ac.uk
RI Pado, Sebastian/F-4883-2016
OI Pado, Sebastian/0000-0002-7529-6825
FU Engineering and Physical Sciences Research Council [EP/C538447/1]
   Funding Source: researchfish
CR AGIRRE E, 1996, P 16 INT C COMP LING, P16
   [Anonymous], NATURAL LANGUAGE INF
   [Anonymous], 1968, MATH STRUCTURES LANG
   [Anonymous], LANGUAGE INVITATION
   Banerjee S., 2003, P 18 INT JOINT C ART, V3, P805
   BANNARD C, 2003, P ACL 2003 WORKSH MU, P65
   BARZILAY R, 2003, THESIS COLUMBIA U NE
   Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127
   BRISCOE E, 2002, P 3 INT C LANG RES E, P1499
   BUDANITSKY A, 2001, P WORKSH WORDNET OTH, P29
   Burnard L., 1995, USERS GUIDE BRIT NAT
   Choi FYY, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P109
   Curran J., 2004, THESIS U EDINBURGH
   Curran JR, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P231
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Dunning T., 1993, Computational Linguistics, V19, P61
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fillmore C, 1965, INDIRECT OBJECT CONS
   Foltz PW, 1998, DISCOURSE PROCESS, V25, P285, DOI 10.1080/01638539809545029
   Goldberg Adele E, 1995, CONSTRUCTIONS
   GOLUB G. H., 1996, MATRIX COMPUTATIONS, DOI DOI 10.56021/9781421407944
   Green Georgia, 1974, SEMANTICS SYNTACTIC
   Grefenstette G, 1994, EXPLORATIONS AUTOMAT
   GROPEN J, 1989, LANGUAGE, V65, P203, DOI 10.2307/415332
   HENDERSON JM, 2002, P 19 INT C COMP LING, P335
   HIGGINS D, 2004, P INT C LING EV, P265
   Hirst G, 1998, LANG SPEECH & COMMUN, P305
   HODGSON JM, 1991, LANG COGNITIVE PROC, V6, P169, DOI 10.1080/01690969108406942
   Hoste V., 2002, Natural Language Engineering, V8, P311, DOI 10.1017/S1351324902003005
   Howell D.C., 2002, STAT METHODS PSYCHOL
   Jackendoff R., 1983, SEMANTIC COGNITION
   Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, 1997 DIGEST OF TECHNICAL PAPERS, P94
   Jones Michael P., 1997, 5 C APPL NAT LANG PR, P166, DOI [10.3115/974557.974582, DOI 10.3115/974557.974582]
   KANEJIYA D, 2003, P HLT NAACL 2003 WOR, P53
   KEENAN EL, 1977, LINGUIST INQ, V8, P63
   Kilgarriff Adam., 2001, INT J CORPUS LINGUIS, V6, P97, DOI [10.1075/ijcl.6.1.05kil, DOI 10.1075/IJCL.6.1.05KIL]
   Koeling R., 2005, P HUM LANG TECHN C C, P419
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Leacock C, 1998, LANG SPEECH & COMMUN, P265
   Lee L., 1999, P 37 ANN M ASS COMPU, P25, DOI [DOI 10.3115/1034678.1034693, 10.3115/1034678.1034693]
   Lesk M., 1986, P 5 ANN INT C SYSTEM, P24, DOI DOI 10.1145/318723.318728
   Levin Beth, 1993, ENGLISH VERB CLASSES
   Levy JP, 2000, PERSP NEURAL COMP, P273
   Lin D., 2001, Natural Language Engineering, V7, P343, DOI 10.1017/S1351324901002765
   Lin D., 1998, P 17 INT C COMPUTATI, V2, P768, DOI [DOI 10.3115/980432.980696, 10.3115/980691.980696]
   LIN D, 2001, P 1 HUM LANG TECHN C, P222
   LIN D, 1999, P 37 ANN M ASS COMP, P317
   LIN D, 1998, P LREC WORKSH EV PAR, P234
   Lowe R, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P806
   Lowe W., 2001, P 23 ANN C COGN SCI, P576
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   MANBER U, 1994, PROCEEDINGS OF THE WINTER 1994 USENIX CONFERENCE, P23
   Manning Christopher, 1999, FDN STAT NATURAL LAN, P3
   MCCARTHY D, 2003, P ACL 2003 WORKSH MU, P73, DOI DOI 10.3115/1119282.1119292
   MCCARTHY D, 2004, P 42 ANN M ASS COMP, P280
   MCDONALD S, 2004, P 42 ANN M ASS COMP, P17, DOI DOI 10.1017/S1351324910000124
   McDonald S., 2000, THESIS U EDINBURGH
   MIHALCEA R, 2004, P SENS 3 3 INT WORKS
   Miltsakaki Eleni., 2003, THESIS U PENNSYLVANI
   MORRIS RK, 1994, J EXP PSYCHOL LEARN, V20, P92, DOI 10.1037/0278-7393.20.1.92
   NEVILLE H, 1991, J COGNITIVE NEUROSCI, V3, P151, DOI 10.1162/jocn.1991.3.2.151
   PATEL M, 1998, P 4 NEUR COMP PSYCH, P199
   Pedersen T., 2004, DEMONSTRATION PAPERS
   Pinker Steven, 1989, LEARNABILITY COGNITI
   RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Sahlgren M, 2006, WORD SPACE MODEL USI
   SALTON G, 1989, SIGIR FORUM, V23, P137, DOI 10.1145/75335.75479
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SAMPSON GR, 1995, ENGLISH COMPUTER
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Talmy Leonard, 1985, LANGUAGE TYPOLOGY SY, V3, P57, DOI DOI 10.1017/CB09780511618437
   Tesniere L., 1959, ELEMENTS SYNTAXE STR
   Turney P, 2001, P 12 EUR C MACH LEAR, P491, DOI DOI 10.1007/3-540-44795-4_42
   VOORHEES EM, 1999, 2 SCH INF EXTR SCIE9, P32
   WEEDS J, 2003, THESIS U SUSSEX UK
   WEST RF, 1986, MEM COGNITION, V14, P104, DOI 10.3758/BF03198370
   WIDDOWS D, 2003, P HLT NAACL, P197
   WIEMERHASTINGS P, 2001, P 23 ANN C COGN SCI, P1140
   Yarowsky D., 2002, Natural Language Engineering, V8, P293, DOI 10.1017/S135132490200298X
NR 81
TC 217
Z9 223
U1 0
U2 26
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN
PY 2007
VL 33
IS 2
BP 161
EP 199
DI 10.1162/coli.2007.33.2.161
PG 39
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 181YF
UT WOS:000247471600002
OA Green Published, Bronze
DA 2023-11-10
ER

PT J
AU Antonucci, A
   Zaffalon, M
AF Antonucci, Alessandro
   Zaffalon, Marco
TI Decision-theoretic specification of credal networks: A unified language
   for uncertain modeling with sets of Bayesian networks
SO INTERNATIONAL JOURNAL OF APPROXIMATE REASONING
LA English
DT Article; Proceedings Paper
CT 3rd European Workshop on Probabilistic Graphical Models
CY SEP 12-15, 2006
CL Prague, CZECH REPUBLIC
DE Probabilistic graphical models; Bayesian networks; Credal networks;
   Credal sets; Imprecise probabilities; Conservative updating;
   Conservative inference rule
AB Credal networks are models that extend Bayesian nets to deal with imprecision in probability, and can actually be regarded as sets of Bayesian nets. Credal nets appear to be powerful means to represent and deal with many important and challenging problems in uncertain reasoning. We give examples to show that some of these problems can only be modeled by credal nets called non-separately specified. These, however, are still missing a graphical representation language and updating algorithms. The situation is quite the opposite with separately specified credal nets, which have been the subject of much study and algorithmic development. This paper gives two major contributions. First, it delivers a new graphical language to formulate any type of credal network, both separately and non-separately specified. Second, it shows that any non-separately specified net represented with the new language can be easily transformed into an equivalent separately specified net, defined over a larger domain. This result opens up a number of new outlooks and concrete outcomes: first of all, it immediately enables the existing algorithms for separately specified credal nets to be applied to non-separately specified ones. We explore this possibility for the 2U algorithm: an algorithm for exact updating of singly connected credal nets, which is extended by our results to a class of non-separately specified models. We also consider the problem of inference on Bayesian networks, when the reason that prevents some of the variables from being observed is unknown. The problem is first reformulated in the new graphical language, and then mapped into an equivalent problem on a separately specified net. This provides a first algorithmic approach to this kind of inference, which is also proved to be NP-hard by similar transformations based on our formalism. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Antonucci, Alessandro; Zaffalon, Marco] Ist Dalle Molle Studie Intelligenza Artificiale I, CH-6928 Lugano, Switzerland.
C3 Universita della Svizzera Italiana
RP Antonucci, A (通讯作者)，Ist Dalle Molle Studie Intelligenza Artificiale I, Galleria 2, CH-6928 Lugano, Switzerland.
EM alessandro@idsia.ch; zaffalon@idsia.ch
RI Zaffalon, Marco/M-7035-2017
OI Zaffalon, Marco/0000-0001-8908-1502; Antonucci,
   Alessandro/0000-0001-7915-2768
CR [Anonymous], 1979, COMPUTERS INTRACTABI
   [Anonymous], 1990, PROC 6 C UNCERTAINTY
   [Anonymous], 2002, P 18 C UNCERTAINTY A
   ANTONUCCI A, 2006, P 3 EUR START AI RES, P120
   ANTONUCCI A, 2006, P 3 EUR WORKSH PROB, P25
   Antonucci A, 2007, INT J APPROX REASON, V44, P200, DOI 10.1016/j.ijar.2006.07.011
   Antonucci A, 2006, ADV SOFT COMP, P223
   Cano A, 2002, INT J APPROX REASON, V29, P1, DOI 10.1016/S0888-613X(01)00046-9
   Cano A., 1994, P INT C INF PROC MAN, P4
   CANO A, 2007, P 5 INT S IMPR PROB, P57
   Cozman F., 2004, P 20 C UNC ART INT, p[104, 223, 224]
   Cozman FG, 2005, INT J APPROX REASON, V39, P167, DOI 10.1016/j.ijar.2004.10.003
   Cozman FG, 2000, ARTIF INTELL, V120, P199, DOI 10.1016/S0004-3702(00)00029-1
   de Campos CP, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1313
   de Cooman G, 2004, ARTIF INTELL, V159, P75, DOI 10.1016/j.artint.2004.05.006
   Fagiuoli E, 1998, ARTIF INTELL, V106, P77, DOI 10.1016/S0004-3702(98)00089-7
   Levi I., 1980, ENTERPRISE KNOWLEDGE
   Little R. J. A., 1987, STAT ANAL MISSING DA
   Moral S, 2002, ANN MATH ARTIF INTEL, V35, P295, DOI 10.1023/A:1014555822314
   Pearl J., 1988, MORGAN KAUFMANN SERI
   Walley P, 1996, J ROY STAT SOC B MET, V58, P3
   Walley P., 1991, STAT REASONING IMPRE
   WELLMAN MP, 1990, ARTIF INTELL, V44, P257, DOI 10.1016/0004-3702(90)90026-V
   Zaffalon M, 2001, ISIPTA, V1, P384
   Zaffalon M, 2005, ISIPTA 05-PROCEEDINGS OF THE FOURTH INTERNATIONAL SYMPOSIUM ON IMPRECISE PROBABILITIES AND THEIR APPLICATIONS, P406
   ZHANG N, 1993, INT J APPROX REASON, V11, P83
NR 26
TC 28
Z9 28
U1 1
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0888-613X
EI 1873-4731
J9 INT J APPROX REASON
JI Int. J. Approx. Reasoning
PD OCT
PY 2008
VL 49
IS 2
BP 345
EP 361
DI 10.1016/j.ijar.2008.02.005
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 370IC
UT WOS:000260754900009
OA Green Submitted, hybrid
DA 2023-11-10
ER

PT J
AU Zalaket, J
   Camilleri, G
AF Zalaket, J
   Camilleri, G
TI OAP: An Object-oriented Approach for Planning modeling
SO INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED
   SYSTEMS
LA English
DT Article
DE artificial intelligence; planning; object-oriented; STRIPS;
   functional-strips
ID SEARCH
AB This article describes a planning approach based on the object representation. A planning domain in OAP (Object-oriented Approach for Planning) consists of a dynamic set of objects. OAP provides a language for planning problems modeling and implementation. This approach can evolve a domain model from a literal (predicative) representation to an object based representation, as well as enhancing the development of planning problems. The goal of OAP is to offer the possibility to design and develop planning problems as any other software engineering problem, and to allow the application of planning to a larger class of domains by using methods (functions) that can be implemented within the world objects. Planning systems using OAP as language can be integrated into any existing object-oriented software with a slight additional effort to transform the system to a planning domain model, which allows the use of planning to solve generic tasks in existing software applications (Business, web,...). Therefore planning in real world systems will be easier to model and to implement using all the software engineering facilities offered by the object-oriented tools.
C1 Univ Toulouse 3, IRIT, CSC, F-31062 Toulouse, France.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier
RP Zalaket, J (通讯作者)，Univ Toulouse 3, IRIT, CSC, 118 Route Narbonne, F-31062 Toulouse, France.
EM zalaket@irit.fr; camiller@irit.fr
CR [Anonymous], ARTIFICAL INTELLIGEN
   AVRIM LB, 1995, P 14 INT JOINT C AI, P1636
   Bacchus F, 2000, ARTIF INTELL, V116, P123, DOI 10.1016/S0004-3702(99)00071-5
   BACCHUS F, 2001, P 17 INT JOINT C ART
   Bonet B, 2001, ARTIF INTELL, V129, P5, DOI 10.1016/S0004-3702(01)00108-4
   BONET B, 2000, AI MAGAZINE, V21
   FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5
   FOX M, 2002, P 7 INT C ART INT PL
   FOX M, 2002, P 7 INT C ART INT MO
   GEFFNER H, 1999, FUNCTIONAL STRIPS MO
   HASLUM P, 2002, P WORK PLANN RES 200
   Hoffmann J, 2001, AI MAG, V22, P57
   HOFFMANN J, 2002, P 15 EUR C ART INT
   KVARNSTROM J, 1999, 6 INT WORKSH TEMP RE
   LOERINCS G, 1997, P AAA197, P714
   Long D, 1999, J ARTIF INTELL RES, V10, P87, DOI 10.1613/jair.570
   MINH B, 2001, P EUR C PLANN
   MULLER M, 2000, UNPUB INTERGRATING F
   Pednault E. P. D., 1994, Journal of Logic and Computation, V4, P467, DOI 10.1093/logcom/4.5.467
   RICHARDSON NE, 2002, P 7 INT C ART I PLAN
NR 20
TC 1
Z9 1
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-4885
J9 INT J UNCERTAIN FUZZ
JI Int. J. Uncertainty Fuzziness Knowl.-Based Syst.
PD OCT
PY 2004
VL 12
SU S
BP 63
EP 82
DI 10.1142/S0218488504003041
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 869YE
UT WOS:000225020000006
DA 2023-11-10
ER

PT J
AU Hurley, B
   O'Sullivan, B
   Allouche, D
   Katsirelos, G
   Schiex, T
   Zytnicki, M
   de Givry, S
AF Hurley, Barry
   O'Sullivan, Barry
   Allouche, David
   Katsirelos, George
   Schiex, Thomas
   Zytnicki, Matthias
   de Givry, Simon
TI Multi-language evaluation of exact solvers in graphical model discrete
   optimization
SO CONSTRAINTS
LA English
DT Article
DE Graphical model; Markov random field; Weighted constraint satisfaction
   problem; Integer linear programming; MaxSAT
ID ELIMINATION; SEARCH
AB By representing the constraints and objective function in factorized form, graphical models can concisely define various NP-hard optimization problems. They are therefore extensively used in several areas of computer science and artificial intelligence. Graphical models can be deterministic or stochastic, optimize a sum or product of local functions, defining a joint cost or probability distribution. Simple transformations exist between these two types of models, but also with MaxSAT or linear programming. In this paper, we report on a large comparison of exact solvers which are all state-of-the-art for their own target language. These solvers are all evaluated on deterministic and probabilistic graphical models coming from the Probabilistic Inference Challenge 2011, the Computer Vision and Pattern Recognition OpenGM2 benchmark, the Weighted Partial MaxSAT Evaluation 2013, the MaxCSP 2008 Competition, the MiniZinc Challenge 2012 & 2013, and the CFLib (a library of Cost Function Networks). All 3026 instances are made publicly available in five different formats and seven formulations. To our knowledge, this is the first evaluation that encompasses such a large set of related NP-complete optimization frameworks, despite their tight connections. The results show that a small number of evaluated solvers are able to perform well on multiple areas. By exploiting the variability and complementarity of solver performances, we show that a simple portfolio approach can be very effective. This portfolio won the last UAI Evaluation 2014 (MAP task).
C1 [Hurley, Barry; O'Sullivan, Barry] Natl Univ Ireland Univ Coll Cork, Insight Ctr Data Analyt, Cork, Ireland.
   [Allouche, David; Katsirelos, George; Schiex, Thomas; Zytnicki, Matthias; de Givry, Simon] INRA, MIAT, UR 875, F-31320 Castanet Tolosan, France.
C3 University College Cork; INRAE
RP de Givry, S (通讯作者)，INRA, MIAT, UR 875, F-31320 Castanet Tolosan, France.
EM barry.hurley@insight-centre.org; barry.osullivan@insight-centre.org;
   david.allouche@toulouse.inra.fr; george.katsirelos@toulouse.inra.fr;
   thomas.schiex@toulouse.inra.fr; matthias.zytnicki@toulouse.inra.fr;
   degivry@toulouse.inra.fr
OI O'Sullivan, Barry/0000-0002-0090-2085
FU Science Foundation Ireland (SFI) [10/IN.1/I3032]; SFI [SFI/12/RC/2289];
   Science Foundation Ireland (SFI) [10/IN.1/I3032] Funding Source: Science
   Foundation Ireland (SFI)
FX We are grateful to the GenoToul (Toulouse) Bioinformatic platform for
   providing us computational support for this work. This work is supported
   by Science Foundation Ireland (SFI) Grant 10/IN.1/I3032. The Insight
   Centre for Data Analytics is supported by SFI Grant SFI/12/RC/2289.
CR Allouche David, 2012, Principles and Practice of Constraint Programming. Proceedings 18th International Conference, CP 2012, P840, DOI 10.1007/978-3-642-33558-7_60
   Allouche D., 2012, P AAAI
   Allouche D, 2015, LECT NOTES COMPUT SC, V9255, P12, DOI 10.1007/978-3-319-23219-5_2
   Amadini R, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P232
   [Anonymous], 2009, PROC 25THCONF UNCERT
   [Anonymous], 2007, NIPS
   [Anonymous], 1999, THESIS MAASTRICHT U
   Ansótegui C, 2014, AAAI CONF ARTIF INTE, P2594
   Argelich J, 2008, INT SYM MVL, P106, DOI 10.1109/ISMVL.2008.22
   Bacchus F, 2007, LECT NOTES COMPUT SC, V4741, P133
   Bensana E., 1999, Constraints, V4, P293, DOI 10.1023/A:1026488509554
   Breiman L, 1984, CLASSIFICATION ALGOR, V40, P358, DOI 10.1201/9781315139470
   Cabon B., 1999, Constraints, V4, P79, DOI 10.1023/A:1009812409930
   Cooper M, 2004, ARTIF INTELL, V154, P199, DOI 10.1016/j.artint.2003.09.002
   Cooper MC, 2010, ARTIF INTELL, V174, P449, DOI 10.1016/j.artint.2010.02.001
   Cooper MC, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P68
   Davies Jessica, 2013, Theory and Applications of Satisfiability Testing - SAT 2013. 16th International Conference. Proceedings. LNCS 7962, P166
   Davies Jessica, 2011, Principles and Practice of Constraint Programming - CP 2011. Proceedings of the 17th International Conference (CP 2011), P225, DOI 10.1007/978-3-642-23786-7_19
   de Givry S, 2013, LECT NOTES COMPUT SC, V8124, P263, DOI 10.1007/978-3-642-40627-0_22
   de Givry S, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P84
   Dechter R, 1999, ARTIF INTELL, V113, P41, DOI 10.1016/S0004-3702(99)00059-4
   Fargier H., 1995, P 11 INT C UNC ART I
   Favier A, 2011, IJCAI, P2126
   Gomes CP, 2001, ARTIF INTELL, V126, P43, DOI 10.1016/S0004-3702(00)00081-3
   Hebrard E, 2010, LECT NOTES COMPUT SC, V6140, P181, DOI 10.1007/978-3-642-13520-0_22
   Huberman BA, 1997, SCIENCE, V275, P51, DOI 10.1126/science.275.5296.51
   Hurley Barry, 2014, Integration of AI and OR Techniques in Constraint Programming. 11th International Conference, CPAIOR 2014. Proceedings: LNCS 8451, P301, DOI 10.1007/978-3-319-07046-9_22
   Junger M, 2010, 50 YEARS INTEGER PRO
   Kadioglu S., 2010, ECAI, V2010, P751
   Kappes JH, 2015, INT J COMPUT VISION, V115, P155, DOI 10.1007/s11263-015-0809-x
   Kishimoto A., 2013, P CP WORKSH CONSTR B
   Koller Daphne, 2009, PROBABILISTIC GRAPHI
   Kotthoff L., 2013, ARXIV13061031
   Kotthoff L, 2014, AI MAG, V35, P48, DOI 10.1609/aimag.v35i3.2460
   Kratica J, 2001, RAIRO-RECH OPER, V35, P127, DOI 10.1051/ro:2001107
   Larrosa J, 2008, ARTIF INTELL, V172, P204, DOI 10.1016/j.artint.2007.05.006
   Li C. M., 2009, HDB SATISFIABILITY
   Meseguer P., 2006, HDB CONSTRAINT PROGR
   Nethercote N., 2007, MINIZINC STANDARD CP, P529
   Neveu B, 2004, LECT NOTES COMPUT SC, V3258, P423
   OMahony E., 2008, AICS 2008
   Otten L., 2012, NIPS DISCML WORKSH
   Petit T, 2000, PROC INT C TOOLS ART, P358, DOI 10.1109/TAI.2000.889894
   Prusa D, 2015, IEEE T PATTERN ANAL, V37, P898, DOI 10.1109/TPAMI.2014.2353626
   Rossi F, 2006, FOUND ARTIF INTELL, P1
   Sanchez M, 2008, CONSTRAINTS, V13, P130, DOI 10.1007/s10601-007-9029-5
   Schlesinger M., 1976, KIBERNETIKA, V4, P2
   Sontag D., 2008, P 24 C UNCERTAINTY A, P503
   Sontag D, 2012, UAI, P795
   Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036
   Xu L, 2008, J ARTIF INTELL RES, V32, P565, DOI 10.1613/jair.2490
NR 51
TC 28
Z9 28
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1383-7133
EI 1572-9354
J9 CONSTRAINTS
JI Constraints
PD JUL
PY 2016
VL 21
IS 3
BP 413
EP 434
DI 10.1007/s10601-016-9245-y
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM4BU
UT WOS:000376291400005
DA 2023-11-10
ER

PT J
AU Ruiz-Dolz, R
   Alemany, J
   Barberá, SMH
   Garcia-Fornes, A
AF Ruiz-Dolz, Ramon
   Alemany, Jose
   Heras Barbera, Stella M.
   Garcia-Fornes, Ana
TI Transformer-Based Models for Automatic Identification of Argument
   Relations: A Cross-Domain Evaluation
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Article
DE Task analysis; Ethics; Natural language processing; Data mining;
   Standards; Intelligent systems; Computational modeling
AB Argument mining is defined as the task of automatically identifying and extracting argumentative components (e.g., premises, claims, etc.) and detecting the existing relations among them (i.e., support, attack, rephrase, no relation). One of the main issues when approaching this problem is the lack of data, and the size of the publicly available corpora. In this work, we use the recently annotated US2016 debate corpus. US2016 is the largest existing argument annotated corpus, which allows exploring the benefits of the most recent advances in natural language processing in a complex domain like argument (relation) mining. We present an exhaustive analysis of the behavior of transformer-based models (i.e., BERT, XLNET, RoBERTa, DistilBERT, and ALBERT) when predicting argument relations. Finally, we evaluate the models in five different domains, with the objective of finding the less domain-dependent model. We obtain a macro F1-score of 0.70 with the US2016 evaluation corpus, and a macro F1-score of 0.61 with the Moral Maze cross-domain corpus.
C1 [Ruiz-Dolz, Ramon; Alemany, Jose; Heras Barbera, Stella M.; Garcia-Fornes, Ana] Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia
RP Ruiz-Dolz, R (通讯作者)，Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Valencia 46022, Spain.
EM raruidol@dsic.upv.es; jalemany1@dsic.upv.es; stehebar@upv.es;
   agarcia@dsic.upv.es
RI Ruiz-Dolz, Ramon/AHI-7798-2022
OI Ruiz-Dolz, Ramon/0000-0002-3059-8520; Alemany, Jose/0000-0002-5116-5935
FU Spanish Government [TIN2017-89,156-R]; FPI [BES-2015-074, 498];
   Valencian Government [PROMETEO/2018/002]; NVIDIA Corporation
FX This work was supported in part by the Spanish Government project under
   Grant TIN2017-89,156-R, in part by the FPI under grant BES-2015-074,498,
   and in part by the Valencian Government project under Grant
   PROMETEO/2018/002. The authors gratefully acknowledge the support of
   NVIDIA Corporation with the donation of the Titan V GPUs used for this
   research.
CR Cocarascu O., 2017, P 2017 C EMPIRICAL M, P1374
   Devlin J., 2018, ARXIV, V1, P4171
   Jha R, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P940, DOI 10.1145/3341105.3373907
   Kotonya N, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), P156
   Lan Zhenzhong, 2019, ARXIV190911942
   Lawrence J, 2019, COMPUT LINGUIST, V45, P765, DOI [10.1162/COLI_a_00364, 10.1162/COLIa00364]
   Lawrence J, 2014, FRONT ARTIF INTEL AP, V266, P465, DOI 10.3233/978-1-61499-436-7-465
   Liu Yinhan, 2019, ARXIV190711692
   Menini S, 2018, AAAI CONF ARTIF INTE, P4889
   Naderi Nona, 2015, PRINCIPLES PRACTICE, P16
   Niculae V, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P985, DOI 10.18653/v1/P17-1091
   Palau RM, 2009, P 12 INT C ART INT L, P98
   Rago A, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1949
   Sanh Victor, 2019, ARXIV191001108
   Stab C, 2017, COMPUT LINGUIST, V43, P619, DOI 10.1162/COLI_a_00295
   Toni, 2020, DATASET INDEPENDENT
   Vaswani A, 2017, ADV NEUR IN, V30
   Visser J, 2020, LANG RESOUR EVAL, V54, P123, DOI 10.1007/s10579-019-09446-8
   Walton D, 2008, ARGUMENTATION SCHEMES, P1, DOI 10.1017/CBO9780511802034
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
NR 20
TC 3
Z9 3
U1 5
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
EI 1941-1294
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD NOV 1
PY 2021
VL 36
IS 6
BP 62
EP 70
DI 10.1109/MIS.2021.3073993
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XT1FC
UT WOS:000733340300014
OA Green Published, Green Submitted
DA 2023-11-10
ER

PT J
AU Gómez, RS
   Augusto, JC
AF Gomez, Rodolfo Sabas
   Augusto, Juan Carlos
TI Expressiveness of temporal query languages:: on the modelling of
   intervals, interval relationships and states
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Article
DE temporal deductive databases; temporal relational databases; knowledge
   representation; temporal logic
ID EVENT CALCULUS; SEMANTICS; TIME; DATABASES
AB Storing and retrieving time-related information are important, or even critical, tasks on many areas of computer science (CS) and in particular for artificial intelligence (AI). The expressive power of temporal databases/query languages has been studied from different perspectives, but the kind of temporal information they are able to store and retrieve is not always conveniently addressed. Here we assess a number of temporal query languages with respect to the modelling of time intervals, interval relationships and states, which can be thought of as the building blocks to represent and reason about a large and important class of historic information. To survey the facilities and issues which are particular to certain temporal query languages not only gives an idea about how useful they can be in particular contexts, but also gives an interesting insight in how these issues are, in many cases, ultimately inherent to the database paradigm. While in the area of AI declarative languages are usually the preferred choice, other areas of CS heavily rely on the extended relational paradigm. This paper, then, will be concerned with the representation of historic information in two well known temporal query languages: Templog in the context of temporal deductive databases, and TSQL2 in the context of temporal relational databases. We hope the results highlighted here will increase cross-fertilisation between different communities. This article can be related to recent publications drawing the attention towards the different approaches followed by the Databases and AI communities when using time-related concepts.
C1 [Gomez, Rodolfo Sabas] Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England.
   [Augusto, Juan Carlos] Univ Ulster, Sch Comp & Math, Newtownabbey BT37 0QB, Antrim, North Ireland.
C3 University of Kent; Ulster University
RP Gómez, RS (通讯作者)，Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England.
EM R.S.Gomez@kent.ac.uk; jc.augusto@ulster.ac.uk
RI Augusto, Juan Carlos/AAJ-2288-2020
CR ABADI M, 1989, J SYMB COMPUT, V8, P277, DOI 10.1016/S0747-7171(89)80070-7
   ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0
   ALLEN JF, 1983, COMMUN ACM, V26, P11
   ARTALE A, 2002, TIME 02
   BAUDINET M, 1995, INFORM COMPUT, V117, P157, DOI 10.1006/inco.1995.1036
   Baudinet M., 1991, Proceedings of the Tenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, P280, DOI 10.1145/113413.113439
   BAUDINET M, 1992, INTENSIONAL LOGICS P, P50
   BAUDINET M, 1989, P ACM SIGACT SIGPLAN, P267
   BAUDINET M, 1993, TEMPORAL DATA BASES
   BETTINI C, 1998, IEEE T KNOWL DATA EN, V10
   BETTINI C, 2001, TIME 01
   BETTINI C, 1998, TEMPORAL DATABASE RE
   BOHLEN M, 1996, LECT NOTES COMPUTER, V1057, P325
   Cervesato I, 2000, COMPUT INTELL-US, V16, P307, DOI 10.1111/0824-7935.00115
   Chittaro L, 1996, COMPUT INTELL, V12, P359, DOI 10.1111/j.1467-8640.1996.tb00267.x
   CHOMICKI J, 1990, PROCEEDINGS OF THE NINTH ACM SIGACT-SIGMOD-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P379, DOI 10.1145/298514.298589
   CHOMICKI J, 1990, THESIS RUTGERS U NEW
   CHOMICKI J, 1994, LECT NOTES ARTIF INT, V827, P506
   Clifford J, 1997, ACM T DATABASE SYST, V22, P171, DOI 10.1145/249978.249980
   COBO ML, 1999, SCCC 99, P170
   DOWTY DR, 1986, LINGUIST PHILOS, V9, P37
   Dyreson C., 1994, SIGMOD REC, V23, P52
   Dyreson CE, 1998, ACM T DATABASE SYST, V23, P1, DOI 10.1145/288086.288087
   ETZIONI O, 1998, TEMPORAL DATABASE RE
   FREKSA C, 1992, ARTIF INTELL, V54, P199, DOI 10.1016/0004-3702(92)90090-K
   Galton A., 2002, Database and Expert Systems Applications. 13th International Conference, DEXA 2002. Proceedings (Lecture Notes in Computer Science Vol.2453), P547
   Galton A., 2005, HDB TEMPORAL REASONI
   GOMEZ RS, 2004, ICEIS 04, V1, P306
   GOMEZ RS, 2000, P 6 C ARG CIENC COMP, P111
   GOODWIN S, 2000, TIME 00
   GRANOVETTER M, 1992, ACTA SOCIOL, V35, P3, DOI 10.1177/000169939203500101
   Hamblin C. L., 1972, STUDY TIME, P324, DOI [10.1007/978-3-642-65387-2_23, DOI 10.1007/978-3-642-65387-2_23]
   Jensen CS, 1996, INFORM SYST, V21, P311, DOI 10.1016/0306-4379(96)00017-8
   KOWALSKI R, 1992, J LOGIC PROGRAM, V12, P121, DOI 10.1016/0743-1066(92)90041-Z
   KOWALSKI R, 1986, NEW GENERAT COMPUT, V4, P67, DOI 10.1007/BF03037383
   Lloyd JW., 2012, FDN LOGIC PROGRAMMIN
   MORRIS R, 1999, TIME 99
   REVESZ PZ, 1993, THEOR COMPUT SCI, V116, P117, DOI 10.1016/0304-3975(93)90222-F
   REYNOLDS M, 2003, TIME 03
   SNODGRASS R, 1987, ACM T DATABASE SYST, V12, P247, DOI 10.1145/22952.22956
   SNODGRASS R, 1986, COMPUTER, V19, P35, DOI 10.1109/MC.1986.1663327
   Snodgrass R. T., 1995, TSQL2 TEMPORAL QUERY
   Stonebraker M., 1976, ACM Transactions on Database Systems, V1, P189, DOI 10.1145/320473.320476
   TANSEL A, 1998, TEMPORAL DATABASE RE
   TANSEL A, 1993, TEMPORAL DATA BASES
   TERENZIANI P, 2000, TIME 00, P191
   Toman D., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, P58, DOI 10.1145/237661.237676
   TOMAN D, 1996, EDBT 96, P307
   TOMAN D, 1994, P INT LOG PROGR S, P189
   [No title captured]
   [No title captured]
NR 51
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD DEC
PY 2006
VL 26
IS 4
BP 269
EP 289
DI 10.1007/s10462-007-9051-4
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 249IY
UT WOS:000252222700002
OA Green Submitted
DA 2023-11-10
ER

PT S
AU van der Mark, P
   van Engelen, R
   Gallivan, K
   Dewar, W
AF van der Mark, P
   van Engelen, R
   Gallivan, K
   Dewar, W
BE Sloot, P
   Tan, CJK
   Dongarra, JJ
   Hoekstra, AG
TI A case study for automatic code generation on a coupled ocean-atmosphere
   model
SO COMPUTATIONAL SCIENCE-ICCS 2002, PT I, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT International Conference on Computational Science
CY APR 21-24, 2002
CL AMSTERDAM, NETHERLANDS
SP Univ Amsterdam, Sect Computat Sci, SHARCNET, Canada, Univ Tennessee, Dept Comp Sci, Power Comp & Commun BV, Elsevier Sci Publ, Springer Verlag, HPCN Fdn, Natl Supercomp Facilities, Sun Microsyst Inc, Queens Univ, Sch Comp Sci
ID EDDIES
AB Traditional design and implementation of large atmospheric models is a difficult, tedious and erroneous task. With the CTADEL project we propose a new method of code generation, where the designer describes the model in an abstract high-level specification language which is translated into highly optimized Fortran code. In this paper we show the abilities of this method on a coupled ocean-atmosphere model, in which we have to deal with multi-resolution domains and different time-steps. We, briefly, describe a new concept in compiler design, the use of templates for code generation, to elevate the burden of choosing architecture optimized numerical routines.
C1 Leiden Univ, Leiden Inst Advanced Comp Sci, NL-2300 RA Leiden, Netherlands.
   Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA.
   Florida State Univ, Dept Oceanog, Tallahassee, FL 32306 USA.
C3 Leiden University; Leiden University - Excl LUMC; State University
   System of Florida; Florida State University; State University System of
   Florida; Florida State University
RP van der Mark, P (通讯作者)，Leiden Univ, Leiden Inst Advanced Comp Sci, POB 9512, NL-2300 RA Leiden, Netherlands.
EM pmark@liacs.nl; engelen@cs.fsu.edu; gallivan@cs.fsu.edu;
   dewar@ocean.fsu.edu
CR [Anonymous], 1992, ART SCI COMPUTING
   DEROSE L, 1995, 8 INT WORKSH LCPC 95, P269
   DEWAR WK, UNPUB J MARINE RES
   HOLLAND WR, 1978, J PHYS OCEANOGR, V8, P363, DOI 10.1175/1520-0485(1978)008<0363:TROMEI>2.0.CO;2
   HOUSTIS E, 1987, P 1 INT C SUP NEW YO, P255
   Roberts R, 1996, J PSYCHOPHYSIOL, V10, P86
   Smith KS, 2001, J PHYS OCEANOGR, V31, P554, DOI 10.1175/1520-0485(2001)031<0554:TSAEOM>2.0.CO;2
   Sterling T, 1995, INT C PARALLEL PROCE, P11
   VANDERMARK P, 2001, P 15 INT C SUP SORR, P252
   vanEngelen R, 1997, IEEE COMPUT SCI ENG, V4, P22, DOI 10.1109/99.615428
   VANENGELEN RA, 2001, J COMPUTING INFORMAT
   VANENGELEN RA, 1998, CTADEL GENERATOR EFF
NR 12
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-43591-3
J9 LECT NOTES COMPUT SC
PY 2002
VL 2329
BP 419
EP 428
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BW26B
UT WOS:000181350500042
OA Bronze
DA 2023-11-10
ER

PT J
AU Kim, K
   Park, EJ
   Shin, JH
   Kwon, OW
   Kim, YK
AF Kim, Kangil
   Park, Eun-Jin
   Shin, Jong-Hun
   Kwon, Oh-Woog
   Kim, Young-Kil
TI Divergence-based fine pruning of phrase-based statistical translation
   model
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Statistical machine translation; Model revision; Phrase table;
   Entropy-based pruning; Relative entropy
AB A widely used automatic translation approach, phrase-based statistical machine translation, learns a probabilistic translation model composed of phrases from a large parallel corpus with a large language model. The translation model is often enormous because of many combinations of source and target phrases, which leads to the restriction of applications to limited computing environments. Entropy-based pruning resolves this issue by reducing the model size while retaining the translation quality. To safely reduce the size, this method detects redundant components by evaluating a relative entropy of models before and after pruning the components. In the literature, this method is effective, but we have observed that it can be improved more by adjusting the divergence distribution determined by the relative entropy. In the results of preliminary experiments, we derive two factors responsible for limiting pruning efficiency of entropy-based pruning. The first factor is proportion of pairs composing translation models with respect to their translation probability and its estimate. The second factor is the exponential increase of the divergence for pairs with low translation probability and estimate. To control the factors, we propose a divergence-based fine pruning using a divergence metric to adapt the curvature change of the boundary conditions for pruning and Laplace smoothing. In practical translation tasks for English-Spanish and English-French language pairs, this method shows statistically significant improvement on the efficiency up to 50% and average 12% more pruning compared to entropy-based pruning to show the same translation quality. (C) 2016 Elsevier Ltd. All rights reserved.
C1 [Kim, Kangil] Konkuk Univ, 120 Neungdong Ro, Seoul 05029, South Korea.
   [Park, Eun-Jin; Shin, Jong-Hun; Kwon, Oh-Woog; Kim, Young-Kil] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 34129, South Korea.
C3 Konkuk University; Electronics & Telecommunications Research Institute -
   Korea (ETRI)
RP Kim, K (通讯作者)，Konkuk Univ, 120 Neungdong Ro, Seoul 05029, South Korea.
EM kangil.kim.01@gmail.com
FU ICT R&D program of MSIP/IITP [10041807]
FX This work was supported by the ICT R&D program of MSIP/IITP. [10041807,
   Development of Original Software Technology for Automatic Speech
   Translation with Performance 90% for Tour/International Event Focused on
   Multilingual Expansibility and Based on Knowledge Learning].
CR [Anonymous], 2007, P 2007 JOINT C EMPIR
   [Anonymous], 2008, INTRO INFORM RETRIEV, DOI DOI 10.1017/CBO9780511809071
   [Anonymous], 2002, P 2 INT C HUMAN LANG
   [Anonymous], 2003, HLT NAACL 2003 HUMAN
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Chiang D, 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Cover T.M., 2012, ELEMENTS INFORM THEO
   Eck M., 2007, P MT SUMM 11, P159
   Foster G., 2006, P 2006 C EMP METH NA, P53
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Isahara, 2007, HUMAN LANGUAGE TECHN, P484
   Johnson J.H., 2012, P 10 C ASS MACH TRAN
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Koehn P, 2004, LECT NOTES COMPUT SC, V3265, P115
   Koehn P., 2005, P AAMT 10 MACH TRANS, P79, DOI DOI 10.3115/1626355.1626380
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn Philipp, 2009, STAT MACHINE TRANSLA
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Ling Wang, 2012, P 2012 JOINT C EMP M, P962
   Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586
   Nirenburg S, 1994, MACHINE TRANSLATION
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 1999, P JOINT SIGDAT C EMP, P20
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park EJ, 2015, ETRI J, V37, P541, DOI 10.4218/etrij.15.0114.1017
   Stolcke Andreas, 1998, P DARPA BROADC NEWS, P270
   Vogel S, 1996, P 16 C COMP LING ASS, P836, DOI DOI 10.3115/993268.993313
   Zens R, 2002, LECT NOTES ARTIF INT, V2479, P18
   Zens R., 2005, IWSLT, P145
   Zens Richard, 2012, P EMNLP CONLL JEJ IS, P972
NR 30
TC 3
Z9 3
U1 1
U2 26
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2017
VL 41
BP 146
EP 160
DI 10.1016/j.csl.2016.06.006
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DY1OI
UT WOS:000384863900008
DA 2023-11-10
ER

PT J
AU Zhang, ZS
   Chen, KH
   Wang, R
   Utiyama, M
   Sumita, E
   Li, ZC
   Zhao, H
AF Zhang, Zhuosheng
   Chen, Kehai
   Wang, Rui
   Utiyama, Masao
   Sumita, Eiichiro
   Li, Zuchao
   Zhao, Hai
TI Universal Multimodal Representation for Language Understanding
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Task analysis; Visualization; Machine translation; Feature extraction;
   Annotations; Transformers; Standards; Artificial intelligence; natural
   language understanding; vision-language modeling; multimodal machine
   translation
AB Representation learning is the foundation of natural language processing (NLP). This work presents new methods to employ visual information as assistant signals to general NLP tasks. For each sentence, we first retrieve a flexible number of images either from a light topic-image lookup table extracted over the existing sentence-image pairs or a shared cross-modal embedding space that is pre-trained on out-of-shelf text-image pairs. Then, the text and images are encoded by a Transformer encoder and convolutional neural network, respectively. The two sequences of representations are further fused by an attention layer for the interaction of the two modalities. In this study, the retrieval process is controllable and flexible. The universal visual representation overcomes the lack of large-scale bilingual sentence-image pairs. Our method can be easily applied to text-only tasks without manually annotated multimodal parallel corpora. We apply the proposed method to a wide range of natural language generation and understanding tasks, including neural machine translation, natural language inference, and semantic similarity. Experimental results show that our method is generally effective for different tasks and languages. Analysis indicates that the visual signals enrich textual representations of content words, provide fine-grained grounding information about the relationship between concepts and events, and potentially conduce to disambiguation.
C1 [Zhang, Zhuosheng; Wang, Rui; Li, Zuchao; Zhao, Hai] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Zhang, Zhuosheng; Wang, Rui; Li, Zuchao; Zhao, Hai] Shanghai Jiao Tong Univ, Key Lab, Shanghai Educ Commiss Intelligent Interact & Cogn, Shanghai 200240, Peoples R China.
   [Chen, Kehai] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen 518055, Peoples R China.
   [Utiyama, Masao; Sumita, Eiichiro] NICT, Koganei, Tokyo 1848795, Japan.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Harbin
   Institute of Technology; National Institute of Information &
   Communications Technology (NICT) - Japan
RP Zhao, H (通讯作者)，Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM zhangzs@sjtu.edu.cn; chenkehai@hit.edu.cn; wangrui.nlp@gmail.com;
   mutiyama@nict.go.jp; eiichiro.sumita@nict.go.jp; charlee@sjtu.edu.cn;
   zhaohai@cs.sjtu.edu.cn
RI Zhang, Zhuosheng/AAF-4919-2020
OI Li, Zuchao/0000-0003-0436-8446; zhao, hai/0000-0001-7290-0487; Sumita,
   Eiichiro/0000-0002-1028-4399; Zhang, Zhuosheng/0000-0002-4183-3645
FU Key Projects of National Natural Science Foundation of China [U1836222,
   61733011]; National Natural Science Foundation of China [62276077,
   6217020129]; Shanghai Pujiang Program [21PJ1406800]; Shanghai Municipal
   Science and Technology Major Project [2021SHZDZX0102]; Beijing Academy
   of Artificial Intelligence (BAAI) [4]; CCF-Baidu Open Fund [CCFBAIDU
   OF2022018]; Shenzhen College Stability Support Plan
   [GXWD20220811170358002, GXWD20220817123150002]
FX The work of Hai Zhao was supported by the Key Projects of National
   Natural Science Foundation of China under Grants U1836222 and 61733011.
   The work of Rui Wang was supported by the National Natural Science
   Foundation of China under Grant 6217020129, in part by Shanghai Pujiang
   Program under Grant 21PJ1406800, in part by Shanghai Municipal Science
   and Technology Major Project under Grant 2021SHZDZX0102, in part by the
   Beijing Academy of Artificial Intelligence (BAAI) (No. 4), in part by
   CCF-Baidu Open Fund under Grant CCFBAIDU OF2022018. The work of Kehai
   Chen was supported by the National Natural Science Foundation of China
   under Grant 62276077, and in part by Shenzhen College Stability Support
   Plan under Grants GXWD20220811170358002 and GXWD20220817123150002
CR Abnar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4190
   [Anonymous], 2017, PROC 2 WORKSHOP EVAL
   [Anonymous], 2017, P 4 WORKSHOP ASIAN T
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bentivogli L., 2009, P TAC, P1
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Brown WM., 2003, NAT RESOUR RES, V12, P141, DOI [DOI 10.1023/A:1024218913435, 10.1023/A:1024218913435]
   Brownlee J., 2019, MACHINE LEARNING MAS
   Caglayan O, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4159
   Cer D., 2017, P 11 INT WORKSHOP SE, P1, DOI [DOI 10.18653/V1/S17-2001, 10.1865/3v1/S17-2001]
   Chen KH, 2019, IEEE-ACM T AUDIO SPE, V27, P1970, DOI 10.1109/TASLP.2019.2937190
   Clark K., 2020, PROC 8 INT C LEARN R, P1
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dolan B., 2005, 3 INT WORKSH PAR IWP, P1
   Durand T, 2016, PROC CVPR IEEE, P4743, DOI 10.1109/CVPR.2016.513
   Elliott D., 2016, P ACL 2016, P70
   Engilberge M, 2018, PROC CVPR IEEE, P3984, DOI 10.1109/CVPR.2018.00419
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Gao Chenyu, 2022, IEEE Transactions on Pattern Analysis and Machine Intelligence, V44, P9603, DOI 10.1109/TPAMI.2021.3132034
   Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Gronroos S., 2018, P 3 C MACHINE TRANSL, P603
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hewitt J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2566
   Hill F., 2019, PROC 7 INT C LEARN R
   Hong RC, 2022, IEEE T PATTERN ANAL, V44, P684, DOI 10.1109/TPAMI.2019.2911066
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu RH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1419, DOI 10.1109/ICCV48922.2021.00147
   Ive J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6525
   Iyer Shankar, 2017, 1 QUORA DATASET RELE
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2017, PROC 3 INT C LEARN R, DOI DOI 10.48550/ARXIV.1412.6980
   Kocmi T, 2017, P 14 INT C NATURAL L, P56
   Koehn Philipp, 2004, P 2004 C EMPIRICAL M, P388
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li XR, 2019, IEEE T MULTIMEDIA, V21, P2347, DOI 10.1109/TMM.2019.2896494
   Li Xiujun, 2020, P 16 EUR C COMP VIS, V12375, P121, DOI DOI 10.1007/978-3-030-58577-8_8/TABLES/4
   Lin H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1320, DOI 10.1145/3394171.3413715
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Lu JS, 2019, ADV NEUR IN, V32
   Ma XZ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4282
   MCDANIEL MA, 1986, J EXP PSYCHOL LEARN, V12, P54, DOI 10.1037/0278-7393.12.1.54
   Meier D., 2000, ACCELERATED LEARNING
   Meng YX, 2019, ADV NEURAL INFORM PR, P2742
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Miyazaki T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1780
   Mukherjee T., 2016, P 2016 C EMPIRICAL M, P912
   Narasimhan, IMPROVING LANGUAGE U
   Noh H, 2017, ADV NEUR IN, V30
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48
   Parida S, 2019, Arxiv, DOI arXiv:1907.08948
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Plummer BA, 2022, IEEE T PATTERN ANAL, V44, P2155, DOI 10.1109/TPAMI.2020.3029008
   Portaz M, 2019, Arxiv, DOI arXiv:1903.11299
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [DOI 10.18653/V1/D16-1264, 10.18653/v1/D16-1264]
   Ren Z., 2016, P 2016 ACM MULTIMEDI, DOI 10.1145/2964284.2967212
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shi HY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1842
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Su W, 2020, PROC 8 INT C LEARN R
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tan H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2066
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang X, 2021, IEEE T PATTERN ANAL, V43, P4205, DOI 10.1109/TPAMI.2020.2972281
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   Wu Zhiyong, 2021, P 59 ANN M ASS COMP, V1, P6153, DOI DOI 10.18653/V1/2021.ACL-LONG
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yin YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3025
   Yoshikawa Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P417, DOI 10.18653/v1/P17-2066
   Zablocki É, 2018, AAAI CONF ARTIF INTE, P5626
   Zhang J, 2017, P 2 C MACH TRANSL, P477
   Zhang K, 2018, IEEE DATA MINING, P747, DOI 10.1109/ICDM.2018.00090
   Zhang Z, 2020, PROC 8 INT C LEARN R
   Zhang Zhuosheng, 2020, AAAI CONF ARTIF INTE, P9628
   Zhou CT, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1388
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
NR 91
TC 2
Z9 2
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUL 1
PY 2023
VL 45
IS 7
BP 9169
EP 9185
DI 10.1109/TPAMI.2023.3234170
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I7PI8
UT WOS:001004665900080
PM 37018264
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Mao, R
   He, K
   Zhang, XL
   Chen, GY
   Ni, JJ
   Yang, ZL
   Cambria, E
AF Mao, Rui
   He, Kai
   Zhang, Xulang
   Chen, Guanyi
   Ni, Jinjie
   Yang, Zonglin
   Cambria, Erik
TI A survey on semantic processing techniques
SO INFORMATION FUSION
LA English
DT Article
DE Semantic processing; Word sense disambiguation; Anaphora resolution;
   Named entity recognition; Concept extraction; Subjectivity detection
ID NAMED ENTITY RECOGNITION; COREFERENCE RESOLUTION; SENTIMENT ANALYSIS;
   ANAPHORA RESOLUTION; REFERRING EXPRESSIONS; EXTRACTION; SYSTEM; WEB;
   SUBJECTIVITY; CORPUS
AB Semantic processing is a fundamental research domain in computational linguistics. In the era of powerful pre-trained language models and large language models, the advancement of research in this domain appears to be decelerating. However, the study of semantics is multi-dimensional in linguistics. The research depth and breadth of computational semantic processing can be largely improved with new technologies. In this survey, we analyzed five semantic processing tasks, e.g., word sense disambiguation, anaphora resolution, named entity recognition, concept extraction, and subjectivity detection. We study relevant theoretical research in these fields, advanced methods, and downstream applications. We connect the surveyed tasks with downstream applications because this may inspire future scholars to fuse these low-level semantic processing tasks with high-level natural language processing tasks. The review of theoretical research may also inspire new tasks and technologies in the semantic processing domain. Finally, we compare the different semantic processing techniques and summarize their technical trends, application trends, and future directions.
C1 [Mao, Rui; Yang, Zonglin; Cambria, Erik] Nanyang Technol Univ, Continental NTU Corp Lab, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Zhang, Xulang] Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
   [He, Kai] Natl Univ Singapore, Saw Swee Hock Sch Publ Hlth, Singapore 117549, Singapore.
   [Chen, Guanyi] Cent China Normal Univ, Hubei Prov Key Lab Artificial Intelligence & Smart, 382 Xiongchu Ave, Wuhan 430079, Peoples R China.
   [Chen, Guanyi] Cent China Normal Univ, Sch Comp Sci, 382 Xiongchu Ave, Wuhan 430079, Peoples R China.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University; Nanyang Technological
   University & National Institute of Education (NIE) Singapore; Nanyang
   Technological University; National University of Singapore; Central
   China Normal University; Central China Normal University
RP Cambria, E (通讯作者)，Nanyang Technol Univ, Continental NTU Corp Lab, 50 Nanyang Ave, Singapore 639798, Singapore.
EM rui.mao@ntu.edu.sg; kai_he@nus.edu.sg; xulang001@e.ntu.edu.sg;
   g.chen@ccnu.edu.cn; jinjie001@e.ntu.edu.sg; zonglin001@e.ntu.edu.sg;
   cambria@ntu.edu.sg
RI Cambria, Erik/C-2103-2013; Mao, Rui/ABM-7006-2022
OI Cambria, Erik/0000-0002-3030-1280; Mao, Rui/0000-0002-1082-8755
FU RIE2020 Industry Alignment Fund-Industry Collaboration Projects
   (IAF-ICP) Funding Initiative
FX <B>Acknowledgments</B> This study is supported under the RIE2020
   Industry Alignment Fund-Industry Collaboration Projects (IAF-ICP)
   Funding Initiative, as well as cash and in-kind contribution from the
   industry partner (s) .
CR Abro WA, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108318
   Adams R., 2007, P ACL PASCAL WORKSHO, P119
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Agichtein E., 2008, TAC, P1
   Agirre E., 2009, P 12 C EUROPEAN CHAP, P33, DOI DOI 10.3115/1609067.1609070
   Agirre E, 2014, COMPUT LINGUIST, V40, P57, DOI 10.1162/COLI_a_00164
   Ahlers D., 2013, P 7 WORKSHOP GEOGRAP, P74, DOI [DOI 10.1145/2533888.2533938, 10.1145/2533888.2533938]
   Aloraini A, 2021, P 4 WORKSHOP COMPUTA, P82
   Aloraini A, 2022, ARXIV
   Aloraini A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P90
   Alvaro Nestor, 2017, JMIR Public Health Surveill, V3, pe24, DOI 10.2196/publichealth.6396
   Aone C, AAAI, P1
   Aralikatte R, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P810
   Aralikatte R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1229
   Arnold J.E., 1998, THESIS STANFORD U
   Atkins B.T, 1992, ACTA LINGUIST HUNGAR, V41, P5
   Attree S, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P134
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bagga Amit, 1998, P 1 INT C LANG RES E, P563
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Baldwin B, 1997, P ACL97EACL97 WORKSH, P38
   Bamman D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P44
   Banerjee S., 2003, P 18 INT JOINT C ART, V3, P805
   Bar-Haim R., 2008, TAC, P1
   Barba E., 2021, IJCAI, P3779
   Barba E, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4661
   BARWISE J, 1981, J PHILOS, V78, P668, DOI 10.2307/2026578
   Basile P, 2014, P 25 INT C COMP LING, P1591, DOI DOI 10.1024/1012-5302/A000007
   Batmaz Z, 2019, ARTIF INTELL REV, V52, P1, DOI 10.1007/s10462-018-9654-y
   Beaver DI, 2004, LINGUIST PHILOS, V27, P3, DOI 10.1023/B:LING.0000010796.76522.7a
   Bekoulis G, 2018, EXPERT SYST APPL, V114, P34, DOI 10.1016/j.eswa.2018.07.032
   Bengtson E., 2008, EMNLP, P294
   Bentivogli L., 2005, Natural Language Engineering, V11, P247, DOI 10.1017/S1351324905003839
   Bentivogli L., 2009, P TAC, P1
   Berend G, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8498
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Bergler S., 2003, WORKSHOP TEXT SUMMAR, P1
   Bevilacqua M., 2019, P INT C REC ADV NAT, P122
   Bevilacqua M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2854
   Bevilacqua Michele, 2021, P 30 INT JOINT C ART, P4330, DOI DOI 10.24963/IJCAI.2021/593
   Black W., 2006, INTRO ARABIC WORDNET, P295
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blevins T, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1006
   Blloshmi R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1030
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616.1376746.URLhttps]
   Bond F., 2012, P 6 GLOB WORDNET C, P56
   Bontcheva K, 2013, LANG RESOUR EVAL, V47, P1007, DOI 10.1007/s10579-013-9215-6
   Bornstein A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P205
   Boroditsky L, 2011, SCI AM, V304, P62, DOI 10.1038/scientificamerican0211-62
   Borrega O, 2007, P CORPUS LINGUISTICS, P1
   Bos J, 2003, COMPUT LINGUIST, V29, P179, DOI 10.1162/089120103322145306
   Branahl S, 1998, EDGAR ELECT DATA GAT
   Brennan S. E., 1987, 25th Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference, P155
   BRENNAN SE, 1995, LANG COGNITIVE PROC, V10, P137, DOI 10.1080/01690969508407091
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Bruce RF, 1999, COMPUT LINGUIST, V25, P195
   Buring D, 2005, BINDING THEORY
   Byron D.K., 2006, TRAITEMENT AUTOM LAN, V46, P91
   Cambria E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3829
   Campolungo N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4331
   Cardie C., 1999, P 1999 JOINT SIGDAT, P82
   Carter D., 1987, INTERPRETING ANAPHOR
   Chafe W., 1976, SUBJECT TOPIC, P25
   Chai HX, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2996
   Chambers CG, 1998, J MEM LANG, V39, P593, DOI 10.1006/jmla.1998.2575
   Chambers N., 2007, P ACL PASCAL WORKSHO, P165
   Chen C., 2014, P 2014 C EMPIRICAL M, P763
   Chen C., 2013, P 2013 C EMP METH NA, P1360
   Chen C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P778
   Chen C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P320
   Chen G., 2018, P 11 INT C NAT LANG, P57
   Chen G., 2022, FINDINGS ASS COMPUTA, P73
   Chen G., 2022, THESIS UTRECHT U
   Chen GY, 2023, COMPUT SPEECH LANG, V79, DOI 10.1016/j.csl.2022.101466
   Chen H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P172
   Chen S., 2021, P 25 C COMPUTATIONAL, P518
   Chinchor N., 1993, COMPUT LINGUIST, V19, P409
   Chinchor N. A., 1995, Empirical Methods in Discourse Interpretation and Generation. Papers from the 1995 AAAI Symposium (TR SS-95-06), P21
   Chinchor N.A, 1998, 7 MESS UND C MUC 7, P1
   Chklovski T., 2004, P C EMPIRICAL METHOD, P33
   Church K. W., 1988, Second Conference on Applied Natural Language Processing, P136
   Clark H.H., 1975, P WORKSHOP THEORETIC, P169
   Clark K., 2016, P 2016 C EMPIRICAL M, P2256, DOI DOI 10.18653/V1/D16-1245
   Clark K, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1405
   Clark K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P643
   Cohen KB, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1775-9
   Cohn T, 2003, P AUSTR LANG TECHN W, P86
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conia S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3269
   Croft W., 2007, COGN LINGUIST
   Cui Leyang., 2021, FINDINGS ASS COMPUTA, P1835, DOI [10.18653/v1/2021.findings-acl.161, DOI 10.18653/V1/2021.FINDINGS-ACL.161]
   Cybulska A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4545
   Daelemans W., 2004, TIMBL TILBURG MEMORY
   Das SSS, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6338
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Davis E, 2017, AI MAG, V38, P97, DOI 10.1609/aimag.v38i4.2734
   De Lange M, 2022, IEEE T PATTERN ANAL, V44, P3366, DOI 10.1109/TPAMI.2021.3057446
   Demner-Fushman D, 2019, TAC, P1
   Deng YF, 2020, BIOINFORMATICS, V36, P4316, DOI 10.1093/bioinformatics/btaa501
   Denis P., 2008, P 2008 C EMP METH NA, P660
   Denis P, 2009, PROCES LENG NAT, P87
   Derczynski L., 2017, P 3 WORKSHOP NOISY U, P140, DOI DOI 10.18653/V1/W17-4418
   Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811
   Devitt A, 2007, P 45 ANN M ASS COMP, P984
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dictionary C.E., 1982, COLLINS
   Dictionary O, 2010, OXFORD DICT ENGLISH, Vthird
   Dimitrakis E, 2020, J INTELL INF SYST, V55, P233, DOI 10.1007/s10844-019-00584-7
   Ding X., 2010, P 23 INT C COMPUTATI, P268
   Doddington G.R., 2004, P 4 INT C LANG RES E, P837
   Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279
   Edmonds P, 2001, P SENSEVAL 2 2 INT W, P1
   Ehrmann M., 2022, P WORKING NOTES CLEF, V3180, P1038
   Emami A., 2018, P 2018 C N AM CHAPT, P25
   Farooq U, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON SOFTWARE, KNOWLEDGE, INFORMATION MANAGEMENT AND APPLICATIONS (SKIMA)
   Fauconnier G, 2008, WAY WE THINK CONCEPT
   Fei H, 2021, AAAI CONF ARTIF INTE, V35, P12785
   Feng YF, 2019, AAAI CONF ARTIF INTE, P3558
   Ferrucci D., 2004, Natural Language Engineering, V10, P327, DOI 10.1017/S1351324904003523
   Fillmore CJ, 2006, COGN LINGUIST RES, V34, P373, DOI 10.1515/9783110199901.373
   Finkel J. R., 2009, P EMNLP, P141
   Finkel Jenny Rose, 2005, P 43 ANN M ASS COMP, P363, DOI DOI 10.3115/1219840.1219885
   Firth JR, 1957, STUDIES LINGUISTIC A, P10
   Fligelstone S., 1992, NEW DIRECTIONS ENGLI, P153
   Fritzler A, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P993, DOI 10.1145/3297280.3297378
   Fu SY, 2020, J BIOMED INFORM, V109, DOI 10.1016/j.jbi.2020.103526
   Gao C, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1623, DOI 10.1145/3488560.3501396
   Garnham A., 2001, MENTAL MODELS INTERP
   Ge N., 1998, P 6 WORKSHOP VERY LA, P161
   Ghaddar A, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P136
   Girardi C, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3204
   Givon T, 1983, SWITCH REF UNIVERS G, V51, P82
   Goldberg A, 2010, WIRES COGN SCI, V1, P468, DOI 10.1002/wcs.22
   Gonzalo J., 1999, 1999 JOINT SIGDAT C, P195
   Gonzalo J., 1998, USAGE WORDNET NATURA, P38
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Grishman R, 1996, P 16 C COMPUTATIONAL, P466, DOI DOI 10.3115/992628.992709
   Grosz B. J., 1983, 21st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, P44
   Grosz B.J, 1977, REPRESENTATION USE F
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   Guillou L, 2012, P STUDENT RES WORKSH, P1
   GUNDEL JK, 1993, LANGUAGE, V69, P274, DOI 10.2307/416535
   Gupta P., 2016, P COLING 2016 26 INT, P2537
   Gurulingappa H, 2012, J BIOMED INFORM, V45, P885, DOI 10.1016/j.jbi.2012.04.008
   Hadiwinoto C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5297
   Haghighi A., 2009, P 2009 C EMPIRICAL M, P1152
   Han N.-R, 2006, KOREAN ZERO PRONOUNS
   Harabagiu S.M, 1999, P ACL 99 WORKSHOP RE, P29
   Harabagiu SM, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P55
   Hardmeier C., 2010, IWSLT INT WORKSHOP S, P283
   Hasler L., 2006, P 5 EDITION INT C LA, P1167
   Havasi C., 2007, RECENT ADV NATURAL L, P27
   Haveliwala Taher H, 2002, P 11 INT C WORLD WID, DOI [10.1145/511446.511513, DOI 10.1145/511446.511513]
   He K, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-05096-w
   He K, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118927
   He K, 2021, J MED INTERNET RES, V23, DOI 10.2196/25670
   He K, 2019, SOCIAL MEDIA MINING FOR HEALTH APPLICATIONS (#SMM4H) WORKSHOP & SHARED TASK, P1
   He K, 2019, EPILEPSY BEHAV, V94, P65, DOI 10.1016/j.yebeh.2019.02.002
   Heim I., 1982, SEMANTICS DEFINITE I
   Hendrickx I, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P144
   Herrero-Zazo M, 2013, J BIOMED INFORM, V46, P914, DOI 10.1016/j.jbi.2013.07.011
   Hirsch JA, 2016, AM J NEURORADIOL, V37, P596, DOI 10.3174/ajnr.A4696
   Hirschman L, 1997, P AAAI SPRING S APPL, P118
   Hirschman L, 1998, 7 MESS UND C MUC 7, P1
   Hitzeman J., 1998, 5 INT C SPOK LANG PR, P2763
   Hobbs J. R., 1988, 26th Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference, P95
   HOBBS JR, 1978, LINGUA, V44, P311, DOI 10.1016/0024-3841(78)90006-2
   Hohenecker P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8554
   Hongwei Wang, 2019, ACM Transactions on Information Systems, V37, DOI 10.1145/3312738
   Hornby AlbertSydney., 1995, OXFORD ADV LEARNERS
   Hou YF, 2018, COMPUT LINGUIST, V44, P237, DOI 10.1162/COLI_a_00315
   Hovy Eduard, 2006, P HUM LANG TECHN C N, P57, DOI DOI 10.3115/1614049.1614064
   Hu JW, 2016, PROCEEDINGS 2016 FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2016), P83, DOI 10.1109/ICMIP.2016.10
   HUANG CTJ, 1984, LINGUIST INQ, V15, P531
   Huang LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3509
   Huang Y., 2022, P 29 INT C COMP LING, P2515
   Hung CL, 2016, KNOWL-BASED SYST, V110, P224, DOI 10.1016/j.knosys.2016.07.030
   Hung CL, 2013, IEEE INTELL SYST, V28, P47, DOI 10.1109/MIS.2013.1
   Iacobacci I, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P897
   Iida R., 2007, P LINGUISTIC ANNOTAT, P132
   Iida R., 2011, P 49 ANN M ASS COMPU, P804
   Iida R., 2007, ACM T ASIAN LANG INF, V6, P1
   Iovine A, 2020, DECIS SUPPORT SYST, V131, DOI 10.1016/j.dss.2020.113250
   Isozaki H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P184
   JACKENDOFF R, 1976, LINGUIST INQ, V7, P89
   Jakob N, 2010, P ACL 2010 C SHORT P, P263
   Jiang TW, 2021, IEEE ACM T COMPUT BI, V18, P823, DOI 10.1109/TCBB.2020.2979959
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Joshi A., 2006, ENCY LANGUAGE LINGUI, V1, P223, DOI DOI 10.1016/B0-08-044854-2/04366-2
   Joshi Aravind K., 1979, P 6 INT JOINT C ART, P435, DOI [10.5555/1624861.1624958, DOI 10.5555/1624861.1624958]
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Joshi M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5803
   Kageback M., 2016, P 5 WORKSHOP COGNITI, P51
   Kai He, 2022, 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P2287, DOI 10.1109/BIBM55620.2022.9995551
   Kameyama M, 1997, OPERATIONAL FACTORS, P46
   Kameyama M, 1985, ZERO ANAPHORA CASE J
   Kamp H., 1993, DISCOURSE LOGIC INTR
   Katiyar A., 2018, P 2018 C N AM CHAPT, V1, P861, DOI DOI 10.18653/V1/N18-1079
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066
   Kehler A, 1997, COMPUT LINGUIST, V23, P467
   Kim A, 2018, COMPUT INTEL NEUROSC, V2018, P1
   Kim JD, 2003, BIOINFORMATICS, V19, pi180, DOI 10.1093/bioinformatics/btg1023
   Kim JD, 2012, INT J DISTRIB SENS N, DOI 10.1155/2012/247346
   Kirstain Y, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P14
   Klie Jan-Christoph, 2018, P 27 INT C COMP LING, P5, DOI DOI 10.18653/V1/D18-2022
   Kocijan V, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4303
   Kolluru K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3748
   Kong F., 2010, P 2010 C EMPIRICAL M, P882
   Krallinger M, 2017, CHEM REV, V117, P7673, DOI 10.1021/acs.chemrev.6b00851
   Kripke Saul A., 1972, SEMANTICS NATURAL LA, P253
   KROVETZ R, 1992, ACM T INFORM SYST, V10, P115, DOI 10.1145/146802.146810
   Kubler S., 2011, P INT C REC ADV NAT, P261
   Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019
   Kumar S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5670
   LaPorte J, 2006, PHILOS STUD, V130, P321, DOI 10.1007/s11098-004-4676-5
   Lappin S., 1994, Computational Linguistics, V20, P535
   Lata K, 2022, APPL INTELL, V52, P9816, DOI 10.1007/s10489-021-02878-2
   Le M., 2018, P 27 INT C COMP LING, P354
   Le Nagard R., 2010, P JOINT 5 WORKSHOP S, P252
   Leacock C., 1993, P WORKSHOP HUMAN LAN, P260
   Lee H, 2017, NAT LANG ENG, V23, P733, DOI 10.1017/S1351324917000109
   Lee H, 2013, COMPUT LINGUIST, V39, P885, DOI 10.1162/COLI_a_00152
   Lee Kenton, 2018, P 2018 C NAACL HUM L, P687, DOI [10.18653/v1/N18-2108, DOI 10.18653/V1/N18-2108]
   Lee Kenton, 2017, P 2017 C EMP METH NA, P188, DOI DOI 10.18653/V1/D17-1018
   Lenzi VB, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P333
   Lesk M., 1986, P 5 ANN INT C SYSTEM, P24, DOI DOI 10.1145/318723.318728
   Levesque H. J., 2012, P INT WORKSHOP TEMPO, P552
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Li C, 2019, JMIR MED INF, V7, DOI 10.2196/12238
   Li C, 2010, BMC SYST BIOL, V4, DOI [10.1186/1752-0509-4-39, 10.1186/1752-0509-4-92]
   Li F, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1609-9
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Li LF, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101817
   Li X., 2020, P 58 ANN M ASS COMPU, P5849, DOI DOI 10.18653/V1/2020.ACL-MAIN.519
   Li X., 2017, P 8 INT JOINT C NAT, V1, P733
   Li YF, 2021, BIOINFORMATICS, V37, P2699, DOI 10.1093/bioinformatics/btab153
   Liang T, 2003, P RES COMP LING C, P111
   Lipscomb CE, 2000, B MED LIBR ASSOC, V88, P265
   Liu F., 2018, P 2018 C N AM CHAPT, V1, P1336
   Liu P, 2022, NEUROCOMPUTING, V473, P37, DOI 10.1016/j.neucom.2021.10.101
   Liu Q, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103145
   Liu RC, 2023, IEEE IJCNN, DOI 10.1109/IJCNN54540.2023.10191719
   Liu RC, 2023, ARTIF INTELL REV, DOI 10.1007/s10462-023-10506-3
   Liu T, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P102, DOI 10.18653/v1/P17-1010
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61
   Liu X, 2021, Arxiv, DOI [arXiv:2103.10385, DOI 10.48550/ARXIV.2103.10385]
   Liu Yinhan, 2019, ARXIV190711692
   Liu ZY, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P509
   Loureiro D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5682
   Luo HY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4829
   Luo X., 2005, P HUM LANG TECHN C C, P25
   Luo XQ, 2016, THEOR APPL NAT LANG, P141, DOI 10.1007/978-3-662-47909-4_5
   Ma RT, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5721
   Ma Y., 2022, J NATURAL LANGUAGE P, V29, P187
   Mao Bing, 2022, 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P2318, DOI 10.1109/BIBM55620.2022.9995416
   Mao R, 2023, IEEE T AFFECT COMPUT, V14, P1743, DOI 10.1109/TAFFC.2022.3204972
   Mao R, 2022, INFORM FUSION, V86-87, P30, DOI 10.1016/j.inffus.2022.06.002
   Mao R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1222
   Marrero M, 2013, COMPUT STAND INTER, V35, P482, DOI 10.1016/j.csi.2012.09.004
   Martin S, 2015, ESSLLI 27 WORKSH LOG
   Martschat S., 2014, P 2014 C EMPIRICAL M, P2070
   Maru M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3534
   Marvin R., 2018, P 13 C ASS MACH TRAN, V1, P125
   Mayor M., 2009, LONGMAN DICT CONT EN
   McCallum A., 2004, ADV NEURAL INFORM PR, V17, P1
   McCallum A, 2003, KDD WORKSH DAT CLEAN, P1
   McCarthy J. F., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1050
   McCoy K.E, 1999, RELAT DISCOURSE DIAL
   Merrouni ZA, 2020, J INTELL INF SYST, V54, P391, DOI 10.1007/s10844-019-00558-9
   Miculicich L.M., 2017, P 2 WORKSHOP COREFER, P30
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Miller G. A., 1998, WORDNET ELECT LEXICA
   Miller George A., 1993, P WORKSH HUM LANG TE, P303
   Miner G, 2012, PRACTICAL TEXT MINING AND STATISTICAL ANALYSIS FOR NON-STRUCTURED TEXT DATA APPLICATIONS, P1
   Mirkin S, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1209
   Mitkov R., 2014, ANAPHORA RESOLUTION
   Mitkov R, 2022, OXFORD HDB COMPUTATI
   Mitkov R, 2007, LECT NOTES COMPUT SC, V4410, P179
   Miwa M., 2014, PROC C EMPIRICAL MET, P1858, DOI DOI 10.3115/V1/D14-1200
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Monaikul N, 2021, AAAI CONF ARTIF INTE, V35, P13570
   Montgomery C., 1982, American Journal of Computational Linguistics, V8, P70
   Montoyo A, 2012, DECIS SUPPORT SYST, V53, P675, DOI 10.1016/j.dss.2012.05.022
   Moosavi NS, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P632
   Moro A., 2014, T ASSOC COMPUT LING, V2, P231, DOI DOI 10.1162/TACL_A_00179
   Moro Andrea, 2015, P 9 INT WORKSH SEM E, P288, DOI [DOI 10.18653/V1/S15-2049, 10.18653/v1/S15-2049]
   Muis A.O., 2017, P 2017 C EMPIRICAL M, P2608, DOI DOI 10.18653/V1/D17-1276
   Muzerelle J., 2013, P TALN 2013, V2, P555
   Nakaiwa H., 1995, Empirical Methods in Discourse Interpretation and Generation. Papers from the 1995 AAAI Symposium (TR SS-95-06), P99
   NAKAIWA H, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P201
   Nakaiwa H., 1996, 16 INT C COMPUTATION, P812
   Nasar Z, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3445965
   Nassirtoussi AK, 2015, EXPERT SYST APPL, V42, P306, DOI 10.1016/j.eswa.2014.08.004
   Nastase V, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Navigli R., 2013, P SEMEVAL, P222, DOI DOI 10.1016/S0044-328X(82)80082-2
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Navigli R, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1683
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Neale S, 2015, P 11 JOINT ACL ISO W, P1
   Nedoluzhko A., 2014, 201457 UFAL MFF UK
   Nedoluzhko A, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4859
   Neves M, 2021, BRIEF BIOINFORM, V22, P146, DOI 10.1093/bib/bbz130
   Ng H.T., 1996, P 16 ANN M ASS COMPU, P40, DOI DOI 10.3115/981863.981869
   Ng H.T, 1997, P ACL SIGLEX WORKSHO, P1
   Ng V, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P55
   Ng V, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P104
   Ng V, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1396
   Ni JJ, 2022, AAAI CONF ARTIF INTE, P11112
   Ni JJ, 2023, ARTIF INTELL REV, V56, P3055, DOI 10.1007/s10462-022-10248-8
   Nicolae C., 2006, P 2006 C EMP METH NA, P275
   Nicolov N, 2008, AISB 2008 CONVENTION, V1, P37
   Noyes G.E., 1943, MOD LANG NOTES, V58, P600
   Oberle B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P389
   Ogrodniczuk M., 2013, LANGUAGE TECHNOLOGY, P215
   Ohana B, 2009, P ITT, V8
   OHara T, 2004, P SENSEVAL 3 3 INT W, P199
   Okumura M., 1996, COLING 1996, P871
   Orasan C, 2007, RECENT ADV NAT LANG, P291
   Orita N, 2014, P 5 WORKSH COGN MOD, P63
   Orita N, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1639
   Palmer F.R., 1981, SEMANTICS
   Pan L., 2017, P 8 INT JOINT C NATU, V1, P875
   Pasini T., 2017, P 2017 C EMP METH NA, P78
   Pasini T, 2020, ARTIF INTELL, V279, DOI 10.1016/j.artint.2019.103215
   Pasini T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1694
   Passonneau R., 1997, INSTRUCTIONS APPL DI, P46
   Pearson J, 2001, P 1 WORKSH COGN PLAU, P1472
   Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Petruck M.R., 1996, HDB PRAGMAT, V2
   Pianta E, 2002, P 1 INT WORDNET C, P293
   Poesio M, 2000, P 2 INT C LANG RES E, P1
   Poesio M., 2004, P 5 SIGDIAL WORKSH D, P154
   Poesio M, 2004, P LANG RES EV C, P653
   Poesio M., 2003, P 2003 EACL WORKSH C, P31
   Poesio M, 2008, TECHNICAL REPORT
   Poesio M, 1999, TECHNICAL REPORT, P1
   Poesio M., 1999, ACL 99 WORKSH STAND, P65
   Poesio M, 2023, ANNU REV LINGUIST, V9, P561, DOI 10.1146/annurev-linguistics-031120-111653
   Poesio M, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1170
   Ponzetto S.P., 2006, P HLT C NAACL, P192
   Popov A., 2017, P STUD RES WORKSH AS, P25
   Postma M., 2016, P 8 GLOB WORDNET C, P302
   Pradhan S., 2012, JOINT C EMNLP CONLL, P1
   Pradhan Sameer, 2007, P 4 INT WORKSH SEM E, P87
   Raganato A, 2017, P 2017 C EMP METH NA, P1156, DOI DOI 10.18653/V1/D17-1120
   Raganato A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P470
   Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99
   Raghunathan K., 2010, P 2010 C EMP METH NA, P492
   Rahimi A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P151
   Rahman A., 2012, P 2012 JOINT C EMPIR, P777
   Rahman A, 2011, J ARTIF INTELL RES, V40, P469, DOI 10.1613/jair.3120
   Ransing R., 2022, ICT ANAL APPL P ICT4, P435
   Recasens M, 2011, NAT LANG ENG, V17, P485, DOI 10.1017/S135132491000029X
   REINHART T, 1983, LINGUIST PHILOS, V6, P47, DOI 10.1007/BF00868090
   Reiter N., 2018, ABSTRACTS EADH DATA, P1
   Ren FL, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2646
   Resnik P., 1999, Natural Language Engineering, V5, P113, DOI 10.1017/S1351324999002211
   Rim K, 2016, PROC 12 JOINT ACL IS, P75
   Ringland N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5176
   Rios Gonzales A., 2017, P 2 C MACH TRANSL, P11
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9
   ROSCH EH, 1973, COGNITIVE PSYCHOL, V4, P328, DOI 10.1016/0010-0285(73)90017-0
   Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793
   Rudinger Rachel, 2018, P 2018 C N AM CHAPT, V2, DOI [10.18653/v1/n18- 2002, DOI 10.18653/V1/N18-2002]
   Ruppenhofer J., 2016, TECHNICAL REPORT
   Saggion H., 2010, P 7 C INT LANG RES E, P1129
   Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381
   Salgado D, 2012, BIOINFORMATICS, V28, P2285, DOI 10.1093/bioinformatics/bts435
   Salloum Said A., 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P61, DOI 10.1007/978-3-030-44289-7_6
   Same F, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5554
   Sanderson M., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P142
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Sang-Bum Kim, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P258
   Sasano R., 2008, P 22 INT C COMPUTATI, P769
   Sasano R., 2011, IJCNLP, P758
   Saunders D., 2020, P 2 WORKSHOP GENDER, P35
   Scarlini B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3528
   Scarlini B, 2020, AAAI CONF ARTIF INTE, V34, P8758
   Scarlini B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P699
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339
   Scozzafava F, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P37
   Seki K., 2001, P 6 NATURAL LANGUAGE, P403
   Seki K, 2002, P 19 INT C COMPUTATI, P1
   Shafqat S., 2022, J ARTIF INTELL TECHN, V2, P152
   Shibuya T, 2020, T ASSOC COMPUT LING, V8, P605, DOI 10.1162/tacl_a_00334
   Sidner C.L, 1979, TECHNICAL REPORT
   Silvestri S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12125775
   Singh P, 2002, KURZWEILAINET, V143, P1
   Singh R.L., 2014, ADV COMPUT INT J, V5, P17, DOI DOI 10.5121/ACIJ.2014.5403
   Skylaki S, 2020, Arxiv, DOI arXiv:2012.09936
   Snell Jake, 2017, NEURIPS
   Snow R, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P801
   Snyder Benjamin, 2004, SENSEVAL 3, P41
   Sonawane S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P351, DOI 10.1109/CAST.2016.7914993
   Song BS, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab282
   Song L., 2020, P 58 ANN M ASS COMPU, P5429
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Steinberger J, 2007, INFORM PROCESS MANAG, V43, P1663, DOI 10.1016/j.ipm.2007.01.010
   Stenetorp P., 2012, P DEMONSTRATIONS 13, P102
   STEVENSON RJ, 1994, LANG COGNITIVE PROC, V9, P519, DOI 10.1080/01690969408402130
   Stojanovski D., 2018, P 3 C MACHINE TRANSL, P49
   Stokoe C., 2003, P 26 ANN INT ACM SIG, P159
   Stoyanov V., 2009, P JOINT C 47 ANN M A, P656
   Straková J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5326
   Strube N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P312
   Stubbs A, 2015, J BIOMED INFORM, V58, pS20, DOI 10.1016/j.jbi.2015.07.020
   Su JL, 2022, Arxiv, DOI arXiv:2208.03054
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Sukthanker R, 2020, INFORM FUSION, V59, P139, DOI 10.1016/j.inffus.2020.01.010
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Taghipour K., 2015, P 19 C COMP NAT LANG, P338, DOI DOI 10.18653/V1/K15-1037
   Talukdar PP, 2009, LECT NOTES ARTIF INT, V5782, P442, DOI 10.1007/978-3-642-04174-7_29
   Tan X, 2019, LECT NOTES ARTIF INT, V11838, P343, DOI 10.1007/978-3-030-32233-5_27
   Tang GB, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1429
   Taule M, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P96
   Tedeschi S., 2021, FINDINGS ASS COMPUTA, P2584
   Tedeschi S., 2021, FINDINGS ASS COMPUTA, P2521
   Tedeschi S, 2022, FINDINGS ASS COMPUTA, P801
   Telljohann H., 2004, P 4 INT C LANG RES E, P2229
   Tetreault JR, 2001, COMPUT LINGUIST, V27, P507, DOI 10.1162/089120101753342644
   Le TT, 2016, LECT NOTES COMPUT SC, V10053, P297, DOI 10.1007/978-3-319-49397-8_26
   Tong HH, 2006, IEEE DATA MINING, P613
   Tripodi R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P88
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Uma A, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.818451
   Uma AN, 2021, J ARTIF INTELL RES, V72, P1385
   Upadhyay C, 2021, IEEE SYS MAN CYBERN, P3291, DOI 10.1109/SMC52423.2021.9658757
   Uryupina O, 2020, NAT LANG ENG, V26, P95, DOI 10.1017/S1351324919000056
   Uzuner O, 2012, J AM MED INFORM ASSN, V19, P786, DOI 10.1136/amiajnl-2011-000784
   van Deemter K, 2000, COMPUT LINGUIST, V26, P629, DOI 10.1162/089120100750105966
   van Miltenburg E., 2020, P 13 INT C NATURAL L, P398
   Vaswani A, 2017, ADV NEUR IN, V30
   Vial L, 2019, P 10 GLOB WORDNET C, P108
   Vieira R, 2000, COMPUT LINGUIST, V26, P539, DOI 10.1162/089120100750105948
   Vijay S, 2022, ARXIV
   Vilain M., 1995, P 6 MESSAGE UNDERSTA, P45, DOI DOI 10.3115/1072399.1072405
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Walker C., 2006, LINGUISTIC DATA CONS, V57, P45
   Wan Q, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107298
   Wang BL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P204
   Wang LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P921
   Wang M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6229
   Wang S., 2013, P 11 WORKSHOP ASIAN, P10
   Wang YX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3019
   Wang Y, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3522593
   Webber B. L., 1988, 26th Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference, P113
   Webber B.L, 2016, FORMAL APPROACH DISC
   Webster Kellie, 2018, T ASS COMPUT LINGUIS, V6, P605, DOI DOI 10.1162/TACL_A_00240
   Wei ZP, 2020, Arxiv, DOI arXiv:1909.03227
   Weiner, 1989, OXFORD ENGLISH DICT
   Weischedel R., 2013, ONTONOTES RELEASE 50, V23
   Wheeler DL, 2008, NUCLEIC ACIDS RES, V36, pD13, DOI 10.1093/nar/gkm1000
   Wilks Y., 1973, PREFERENCE SEMANTICS
   WINOGRAD T, 1972, COGNITIVE PSYCHOL, V3, P1, DOI 10.1016/0010-0285(72)90002-3
   Wiseman S., 2016, P 2016 C N AM CHAPTE, P994, DOI DOI 10.18653/V1/N16-1114
   Wiseman S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5363
   Wiseman S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1416
   Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD1074, DOI 10.1093/nar/gkx1037
   Witte R., 2003, P 2003 INT S REFEREN, P43
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P917
   Wu J., 2023, INFORM FUSION, V100
   Wu W., 2020, P 58 ANN M ASS COMPU, P6953
   Xia Y, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2291
   Yadav V., 2018, P 27 INT C COMP LING, P2145
   Yan Hang, 2021, LONG PAPERS, V1, P5808
   Yan YK, 2022, Arxiv, DOI arXiv:2204.11467
   Yan ZH, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P185
   Yang CL, 1999, LANG COGNITIVE PROC, V14, P715, DOI 10.1080/016909699386248
   Yang SL, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2403
   Yang XF, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P176
   Yang Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6365
   Yao Y, 2022, P 29 INT C COMPUTATI, P2494
   Ye DM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7170
   Yin Q., 2018, P 27 INT C COMPUTATI, P13
   Yin Q., 2019, ACM T ASIAN LOW-RESO, V19, P1
   Yin Q., 2017, P 2017 C EMPIRICAL M, P1309
   Yin QY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P569
   Yin QY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3322
   Yu BW, 2020, FRONT ARTIF INTEL AP, V325, P2282, DOI 10.3233/FAIA200356
   Yuan D., 2016, PROC COLING, P1374
   Zeldes A, 2017, LANG RESOUR EVAL, V51, P581, DOI 10.1007/s10579-016-9343-x
   Zhang HM, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P867
   Zhang J., 2021, FINDINGS ASS COMPUTA, P1092
   Zhang M., 2017, P 2017 C EMP METH NA, P1730, DOI DOI 10.18653/V1/D17-1182
   Zhang R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P102
   Zhang XL, 2023, ARTIF INTELL REV, V56, P5645, DOI 10.1007/s10462-022-10300-7
   Zhang Y., 2017, P 2017 C EMPIRICAL M, P35
   Zhao Jieyu, 2018, P 2018 C N AM CHAPT, V2, DOI DOI 10.18653/V1/N18-2003
   Zhao S., 2007, P 2007 JOINT C EMPIR, P541
   Zheng SC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1227, DOI 10.18653/v1/P17-1113
   Zhong Z., 2010, P ACL 2010 SYST DEM, P78
   Zhong ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P50
   Zhou K, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1006, DOI 10.1145/3394486.3403143
   Aikawa Naoyoshi, 2011, IPSJ Online Transactions, V4, P160, DOI 10.2197/ipsjtrans.4.160
   Akkaya C., 2009, P 2009 C EMPIRICAL M, P190
   Al Hamoud A, 2022, J KING SAUD U COMPUT, P7975
   Al-Zaidy RA, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2551, DOI 10.1145/3308558.3313642
   Aleksandrova D., 2019, P INT C RECENT ADV N, P42
   Amini I., 2019, P 10 WORKSHOP COMPUT, P81
   Anaya-Sanchez H, 2006, LECT NOTES COMPUT SC, V4140, P472
   [Anonymous], 1995, NEURAL FUZZY SYSTEMS
   [Anonymous], 2014, GENETIC ALGORITHMS B, DOI [DOI 10.1007/0-387-28356-0_4, DOI 10.1007/978-1-4614-6940-7_4]
   Asher N., 2003, LOGICS CONVERSATION
   Aue A., 2005, P RECENT ADV NATURAL, V1, P1, DOI DOI 10.1111/J.1745-3992.1984.TB00758.X
   Austin J.L., 1975, DO THINGS WORDS
   Banea C, 2011, MULTILING NAT LANG P, V6, P1
   Banea C., 2008, P 2008 C EMPIRICAL M, P127
   Banea C., 2010, P 23 INT C COMPUTATI, P1
   Banfield A, 2014, UNSPEAKABLE SENTENCE
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bao H., 2021, NATURAL LANGUAGE PRO, P235
   Barbosa L, 2010, COL 2010 23 INT C CO, V2, P36
   Belinkov Y., 2017, P 8 INT JOINT C NATU, V1, P1
   Benamara F., 2011, P 5 INT JOINT C NATU, P1180
   Bethard S, 2016, P 10 INT WORKSH SEM, DOI DOI 10.18653/V1/S16-1165
   Biyani P, 2014, KNOWL-BASED SYST, V69, P170, DOI 10.1016/j.knosys.2014.04.048
   Bonzanini M, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1121, DOI 10.1145/2348283.2348499
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]
   Cabrera A., 2023, ZENO CHATBOT REPORT
   Cambria E, 2016, COLING 2016 26 INT C, P2666, DOI 10.1109/ssci.2018.8628796
   Cambria E., 2023, ARXIV
   Cambria E, 2022, INT CONF DAT MIN WOR, P403, DOI 10.1109/ICDMW58026.2022.00060
   Cambria E, 2014, AAAI CONF ARTIF INTE, P1515
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Chaturvedi I, 2018, J FRANKLIN I, V355, P1780, DOI 10.1016/j.jfranklin.2017.06.007
   Chaturvedi I, 2016, INT CONF DAT MIN WOR, P916, DOI [10.1109/ICDMW.2016.107, 10.1109/ICDMW.2016.0134]
   Chaturvedi I, 2016, IEEE IJCNN, P4474, DOI 10.1109/IJCNN.2016.7727785
   Chen J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4057
   Chen W, 2019, AAAI CONF ARTIF INTE, P6268
   Chesley P., 2006, P AAAI CAAW 06 SPRIN, V580, P233
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Clark Kevin, 2020, ICLR
   Cohen-Almagor R, 2011, POLICY INTERNET, V3, DOI 10.2202/1944-2866.1059
   Cotelo J.M, 2015, PROCESAMIENTO LENGUA, P75
   Crawshaw Michael, 2020, ARXIV200909796
   Das A, 2010, COMPUT APPROACH SUBJ, P14
   Das A, 2009, 2009 3 INT C AFFECTI, P1
   Das Nilanjana, 2020, Machine Learning and Information Processing. Proceedings of ICMLIP 2019. Advances in Intelligent Systems and Computing (AISC 1101), P149, DOI 10.1007/978-981-15-1884-3_14
   E. Hinton Geoffrey, 2012, Arxiv, DOI [arXiv:1207.0580, 10.48550/arXiv.1207.0580, DOI 10.48550/ARXIV.1207.0580]
   FANG IE, 1967, J BROADCASTING, V11, P63
   Fang S., 2021, P 30 INT JOINT C ART, P1449
   Fang Y., 2022, FINDINGS ASS COMPUTA, P5883
   Frénay B, 2016, IEEE T CYBERNETICS, V46, P3351, DOI 10.1109/TCYB.2015.2504404
   Friedman N., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P139
   Galley M., 2004, ACL 04 P 42 ANN M AS, P669, DOI [10.3115/1218955.1219040, DOI 10.3115/1218955.1219040]
   Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025
   Gardenfors P., 2004, CONCEPTUAL SPACES GE
   Ge MS, 2023, ARTIF INTELL REV, DOI 10.1007/s10462-023-10564-7
   Ge MS, 2022, AAAI CONF ARTIF INTE, P10681
   Gehrmann S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192360
   Gitari ND, 2015, INT J MULTIMEDIA UBI, V10, P215, DOI DOI 10.14257/IJMUE.2015.10.4.21
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Hairong Huo, 2020, Web and Big Data. 4th International Joint Conference, APWeb-WAIM 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12318), P270, DOI 10.1007/978-3-030-60290-1_21
   Han S., 2022, P 29 INT C COMPUTATI, P94
   He K., 2022, IEEE T AFFECT COMPUT
   He Y, 2010, TECHNICAL REPORT
   Helmi M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P1897, DOI 10.1109/FUZZY.2009.5277329
   Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166
   Hillard D., 2003, COMPANION VOLUME P H, V2, P34, DOI 10.3115/1073483.1073495
   Holland JH, 1975, ADAPTATION NATURAL A
   Hosmer D. W., 2000, APPL LOGISTIC REGRES
   Huang LS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9230
   Huang XQ, 2019, IEEE DATA MINING, P1108, DOI 10.1109/ICDM.2019.00132
   Huang ZH, 2015, Arxiv, DOI arXiv:1508.01991
   Hube C, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P195, DOI 10.1145/3289600.3291018
   Hube C, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1779, DOI 10.1145/3184558.3191640
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Xuan HNT, 2012, INT CONF ASIAN LANG, P17, DOI 10.1109/IALP.2012.47
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kamal A, 2013, INT J COMPUT SCI, V10, P191
   Kamil AZ, 2018, STUD FUZZ SOFT COMP, V361, P63, DOI 10.1007/978-3-319-75408-6_6
   Karimi S, 2017, J INF SCI, V43, P356, DOI 10.1177/0165551516641818
   Kartik Detroja C, 2023, INTELL SYST APPL
   Keshavarz H., 2018, J AI DATA MINING, V6, P341
   Khatua A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206903
   Kilgarriff A, 2000, COMPUT HUMANITIES, V34, P1, DOI 10.1023/A:1002619001915
   Kim S.-M., 2006, P MAIN C HUMAN LANGU, P200
   Kim S.-M, 2005, COMPANION VOLUME P C, P61
   Kim S.N.O., 2010, P 5 INT WORKSH SEM E, P21, DOI DOI 10.1007/S10579-012-9210-3
   Kim Y., 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1181
   Krapivin M, 2009, TECHNICAL REPORT, P1
   Lafferty J., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Lakoff George., 1980, METAPHORS WE LIVE
   Lan Zhenzhong, 2019, ARXIV190911942
   Lange L., 2020, P 58 ANN M ASS COMPU, P6945
   Largeron C., 2011, P 2011 ACM S APPL CO, P924
   Lee L., 2004, ASS COMPUTATIONAL LI, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Li B., 2008, P 31 ANN INT ACM SIG, P735
   Li B., 2008, P 2008 C EMPIRICAL M, P937
   Li KQ, 2018, IEEE DATA MINING, P267, DOI 10.1109/ICDM.2018.00042
   Li P., 2016, P 10 INT WORKSHOP SE, P1268
   Li W, 2023, P AAAI C ARTIFICIAL, P13121
   Lin C, 2011, P 5 INT JOINT C NATU, P1153
   Litkowski K., 2004, P SENSEVAL 3 3 INT W, P13
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Liu Chia-Wei, 2016, P C EMP METH NAT LAN, P2122, DOI 10.18653/v1/D16-1230
   Liu Q, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1821, DOI 10.1145/3219819.3219960
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Liu Y, 2020, IEEE DATA MINING, P1142, DOI 10.1109/ICDM50108.2020.00139
   Liu ZJ, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0468-7
   Löhr G, 2022, REV PHILOS PSYCHOL, V13, P549, DOI 10.1007/s13164-021-00542-9
   Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586
   Maas Andrew, 2011, ACL, V1, P7, DOI DOI 10.5555/2002472.2002491
   Mao R., 2023, P 61 ANN M ASS COMPU, V3, P127
   Mao R, 2021, AAAI CONF ARTIF INTE, V35, P13534
   Mao R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3888
   McCowan I., 2005, P 5 INT C METHODS TE
   MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037/0033-295X.85.3.207
   Meng R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P582, DOI 10.18653/v1/P17-1054
   Mihalcea R., 2007, P 45 ANN M ASS COMPU, P976
   Mikolov T., 2017, SHORT PAPERS, P427, DOI 10.18653/v1/e17
   Mogadala A., 2012, P 26 PACIFIC ASIA C, P171
   Morency L-P, 2011, P 13 INT C MULT INT, P169, DOI [DOI 10.1145/2070481.2070509, 10.1145/2070481.2070509]
   Moro A., 2014, P 2014 INT C POSTERS, V1272, P25
   Murray G., 2009, P 2009 C EMPIRICAL M, P1348
   Murray G, 2011, NAT LANG ENG, V17, P397, DOI 10.1017/S1351324910000264
   Nakov P., 2013, 2 JOINT C LEXICAL CO, P312
   Neiberg D., 2006, P FONETIK, P101
   Nguyen TD, 2007, LECT NOTES COMPUT SC, V4822, P317
   Ortega R, 2013, PROCES LENG NAT, P179
   PAIVIO A, 1965, J VERB LEARN VERB BE, V4, P32, DOI 10.1016/S0022-5371(65)80064-0
   Paltoglou Georgios, 2014, Professional Search in the Modern World. COST Action IC1002 on Multilingual and Multifaceted Interactive Information Access: LNCS 8830, P193, DOI 10.1007/978-3-319-12511-4_10
   Pant K, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P75, DOI 10.1145/3366424.3382704
   Pennebaker JW, 2001, LINGUISTIC INQUIRY W, DOI DOI 10.4018/978-1-60960-741-8.CH012
   Polanyi L, 2006, INFORM RETRIEVAL SER, V20, P1
   Preiss J, 2001, P SENSEVAL 2 2 INT W, P1
   Pryzant R, 2020, AAAI CONF ARTIF INTE, V34, P480
   Raaijmakers S, 2007, P 1 INT WORKSHOP DAT, P34
   Raaijmakers S, 2008, P 2008 C EMPIRICAL M, P466
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Recasens M., 2013, P 51 ANN M ASS COMPU, P1650
   Remus R, 2011, P 18 NORDIC C COMPUT, P168
   Riloff E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1044
   Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105
   Rustamov S., 2013, P 4 WORKSHOP COMPUTA, P108
   Rustamov S, 2018, ADV FUZZY SYST, V2018, DOI 10.1155/2018/2371621
   Sagnika S, 2021, NEURAL COMPUT APPL, V33, P17425, DOI 10.1007/s00521-021-06328-5
   Sagnika S, 2020, MULTIMED TOOLS APPL, V79, P32389, DOI 10.1007/s11042-020-09632-9
   Satapathy R, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14070191
   Satapathy R, 2017, COMPUT SIST, V21, P657, DOI [10.13053/cys-21-4-2783, 10.13053/CyS-21-4-2783]
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Seel NM., 2011, ENCY SCI LEARNING, DOI DOI 10.1007/978-1-4419-1428-6
   Serrano-Guerrero J, 2015, INFORM SCIENCES, V311, P18, DOI 10.1016/j.ins.2015.03.040
   Sixto J, 2016, LECT NOTES ARTIF INT, V9875, P121, DOI 10.1007/978-3-319-45243-2_11
   SMITH EA, 1961, J EDUC RES, V54, P298, DOI 10.1080/00220671.1961.10882728
   Socher R, 2013, ADV NEURAL INFORM PR, V26
   Somasundaran S., 2007, P 8 SIGDIAL WORKSHOP, P26
   Somasundaran S., 2010, P NAACL HLT 2010 WOR, P116
   Soong HC, 2019, 2019 IEEE 9TH SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), P272, DOI 10.1109/ISCAIE.2019.8743799
   Soria-Olivas E, 2011, IEEE T NEURAL NETWOR, V22, P505, DOI 10.1109/TNN.2010.2103956
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Stone P.J., 1966, GEN INQUIRER COMPUTE
   Stoyanov V, 2005, P C HUMAN LANGUAGE T, P923
   Strapparava C., 2004, P 4 INT C LANGUAGE R
   Subrahmanya N, 2010, IEEE T PATTERN ANAL, V32, P788, DOI 10.1109/TPAMI.2009.98
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Toutanova K, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P63, DOI 10.3115/1117794.1117802
   Traugott E.C., 2010, SUBJECTIF INTERSUBJE, V29, P71, DOI DOI 10.1515/9783110226102.1.29
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Ulrich J, 2008, AAAI08 EMAIL WORKSHO, P1
   Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203
   Villena J., 2015, P TASS 2015 WORKSHOP, P13
   Wan M, 2016, IEEE DATA MINING, P489, DOI [10.1109/ICDM.2016.0060, 10.1109/ICDM.2016.121]
   Wan X., 2009, P JOINT C 47 ANN M A, V1, P235
   Wang S., 2012, P 50 ANN M ASS COMP, V2, P90, DOI DOI 10.5555/2390665.2390688
   Wang S, 2013, P 30 INT C MACH LEAR, V28, P118
   Wang W, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106576
   Wang YN, 2018, IEEE DATA MINING, P597, DOI 10.1109/ICDM.2018.00075
   Wei J., 2022, ADV NEURAL INFORM PR, V35, P24824
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Wiebe J, 2005, LECT NOTES COMPUT SC, V3406, P486
   Wiebe J. M., 1994, Computational Linguistics, V20, P233
   Wiebe J.M., 1990, RECOGNIZING SUBJECTI
   Wiebe J, 2011, IEEE T AFFECT COMPUT, V2, P175, DOI 10.1109/T-AFFC.2011.19
   Wiebe JM, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P735
   Wierzbicka A., 1972, SEMANTIC PRIMITIVES
   WilliamWarner Julia, 2012, P 2 WORKSHOP LANGUAG, P19
   Wilson T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P761
   Wilson T, 2005, P C HUM LANG TECHN E, P347, DOI DOI 10.3115/1220575.1220619
   Wilson T, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P2738
   Wöllmer M, 2013, IEEE INTELL SYST, V28, P46, DOI 10.1109/MIS.2013.34
   Wrede B, 2003, P EUROSPEECH, P2805
   Xiaochen Wang, 2018, 2018 IEEE Third International Conference on Data Science in Cyberspace (DSC). Proceedings, P339, DOI 10.1109/DSC.2018.00055
   Xiong CY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1271, DOI 10.1145/3038912.3052558
   Xiong S., 2021, P MACHINE LEARNING R, V139, P11470
   Yang X, 2020, J AM MED INFORM ASSN, V27, P1935, DOI 10.1093/jamia/ocaa189
   Yang Z., 2016, P 2016 C N AM CHAPTE, P1480, DOI [10.18653/v1/N16-1174, DOI 10.18653/V1/N16-1174]
   Ye H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4142
   Young T, 2018, AAAI CONF ARTIF INTE, P4970
   Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P129
   Zhang J., 2021, OPEN, V2, P14, DOI [10.1016/j.aiopen.2021.03.001, DOI 10.1016/J.AIOPEN.2021.03.001]
   Zhang Q., 2016, P 2016 C EMPIRICAL M, P836, DOI DOI 10.18653/V1/D16-1080
   Zhang WS, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL CONFERENCE ON AGRICULTURE ENGINEERING, P831, DOI 10.1145/1321440.1321555
   Zhao H, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4069
   Ziming Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2126, DOI 10.1109/ICPR.2010.521
   Zobel Justin, 2001, P 24 ANN INT ACM SIG, P111, DOI DOI 10.1145/383952.383970
NR 708
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD JAN
PY 2024
VL 101
AR 101988
DI 10.1016/j.inffus.2023.101988
PG 60
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T5MA4
UT WOS:001078414700001
DA 2023-11-10
ER

PT J
AU Badaro, G
   Hajj, H
   Habash, N
AF Badaro, Gilbert
   Hajj, Hazem
   Habash, Nizar
TI A Link Prediction Approach for Accurately Mapping a Large-scale Arabic
   Lexical Resource to English WordNet
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Link prediction; arabic wordnet expansion; arabic natural language
   processing; lexical resources; arabic sentiment lexicon; wordnet
AB Success of Natural Language Processing (NLP) models, just like all advanced machine learning models, rely heavily on large -scale lexical resources. For English, English WordNet (EWN) is a leading example of a large-scale resource that has enabled advances in Natural Language Understanding (NLU) tasks such as word sense disambiguation, question answering, sentiment analysis, and emotion recognition. EWN includes sets of cognitive synonyms called synsets, which are interlinked by means of conceptual-semantic and lexical relations and where each synset expresses a distinct concept. However, other languages are still lagging behind in having large-scale and rich lexical resources similar to EWN. In this article, we focus on enabling the development of such resources for Arabic. While there have been efforts in developing an Arabic WordNet (AWN), the current version of AWN has its limitations in size and in lacking transliteration standards, which are important for compatibility with Arabic NLP tools. Previous efforts for extending AWN resulted in a lexicon, called ArSenL, that overcame the size and the transliteration standard limitation but was limited in accuracy due to the heuristic approach that only considered surface matching between the English definitions from the Standard Arabic Morphological Analyzer (SAMA) and EWN synset terms, and that resulted in inaccurate mapping of Arabic lemmas to EWN's synsets. Furthermore, there has been limited exploration of other expansion methods due to expensive manual validation needed. To address these limitations of simultaneously having large-scale size with high accuracy and standard representations, the mapping problem is formulated as a link prediction problem between a large-scale Arabic lexicon and EWN, where a word in one lexicon is linked to a word in another lexicon if the two words are semantically related. We use a semi-supervised approach to create a training dataset by finding common terms in the large-scale Arabic resource and AWN. This set of data becomes implicitly linked to EWN and can be used for training and evaluating prediction models. We propose the use of a two-step Boosting method, where the first step aims at linking English translations of SAMA's terms to EWN's synsets. The second step uses surface similarity between SAMA's glosses and EWN's synsets. The method results in a new large-scale Arabic lexicon that we call ArSenL 2.0 as a sequel to the previously developed sentiment lexicon ArSenL. A comprehensive study covering both intrinsic and extrinsic evaluations shows the superiority of the method compared to several baseline and state-of-the-art link prediction methods. Compared to previously developed ArSenL, ArSenL 2.0 included a larger set of sentimentally charged adjectives and verbs. It also showed higher linking accuracy on the ground truth data compared to previous ArSenL. For extrinsic evaluation, ArSenL 2.0 was used for sentiment analysis and showed, here, too, higher accuracy compared to previous ArSenL.
C1 [Badaro, Gilbert; Hajj, Hazem] Amer Univ Beirut, Elect & Comp Engn Dept, POB 11-0236, Riad E Solh Beirut 11072020, Lebanon.
   [Habash, Nizar] New York Univ Abu Dhabi, Comp Sci Dept, POB 129188, Abu Dhabi, U Arab Emirates.
C3 American University of Beirut
RP Badaro, G (通讯作者)，Amer Univ Beirut, Elect & Comp Engn Dept, POB 11-0236, Riad E Solh Beirut 11072020, Lebanon.
EM ggb05@aub.edu.lb; hh63@aub.edu.lb; nizar.habash@nyu.edu
OI Habash, Nizar/0000-0002-1831-3457
FU Qatar National Research Fund (Qatar Foundation) [NPRP 6-716-1-138]
FX This work was made possible by NPRP 6-716-1-138 grant from the Qatar
   National Research Fund (a member of Qatar Foundation).
CR Abdul-Mageed M., 2011, P 49 ANN M ASS COMP, P587
   Abdul-Mageed M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1162
   Abouenour L, 2013, LANG RESOUR EVAL, V47, P891, DOI 10.1007/s10579-013-9237-0
   Abu-Jbara A., 2012, P 50 ANN M ASS COMP, V1, P399
   Al Sallab Ahmad A., 2015, P AR NAT LANG PROC W, V9
   Al-Ayyoub M., 2015, INT J SOC NETW MIN, V2, P101, DOI [DOI 10.1504/IJSNM.2015.072280, 10.1504/IJSNM.2015.072280]
   Al-Kabi Mohammed, 2013, 4 INT C INF COMM SYS, P23
   Al-Moslmi T, 2018, J INF SCI, V44, P345, DOI 10.1177/0165551516683908
   Al-Rowaily K, 2015, DIGIT INVEST, V14, P53, DOI 10.1016/j.diin.2015.07.006
   Al-Sallab A, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3086575
   Al-Twairesh N, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P697
   Alkhalifa M, 2010, INT J INFORM COMMUNI, V3, P20
   Alkhalifa Musa, 2009, P 3 INT C AR LANG PR
   Alnawas A, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3278605
   Aminian Maryam, 2016, P 3 WORKSH NLP SIM L, P73
   [Anonymous], 2014, P 8 WORKSH SOC NETW
   [Anonymous], 2015, 2 WORKSHOP ARABIC NA
   [Anonymous], 2015, ARXIV150601906
   [Anonymous], 2016, P INT C LANG RES EV
   [Anonymous], 2013, INT J COMPUTATIONAL
   [Anonymous], 2017, P 11 INT WORKSH SEM
   [Anonymous], 2002, ARABIC MORPHOLOGICAL
   [Anonymous], 2013, ARABIC SENTIMENT ANA
   [Anonymous], 2012, P 6 INT GLOBAL WORD
   Baccianella S, 2010, LREC, V10, P2200, DOI DOI citeulike-article-id:9238846
   Badaro G, 2014, LARGE SCALE ARABIC S, P165
   Badaro G., 2018, P 7 JOINT C LEXICAL, P86, DOI [DOI 10.18653/V1/S18-2009, 10.18653/v1/S18-2009]
   Badaro G, 2018, P 12 INT WORKSH SEM, P236, DOI DOI 10.18653/V1/S18-1036
   Badaro G., 2018, OSACT, V3, P26
   Badaro G, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3295662
   Badaro G, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1004, DOI 10.1109/ICDMW.2014.28
   Badaro G, 2013, INT WIREL COMMUN, P349, DOI 10.1109/IWCMC.2013.6583584
   Badaro Gilbert, 2014, P QAT FDN RES C
   Baly Ramy, 2017, P AR NAT LANG PROC W
   Baly Ramy Georges, 2014, P QAT FDN RES C ITPP
   Banerjee S., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P136
   Beseiso M, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3360016
   Black W., 2006, INTRO ARABIC WORDNET, P295
   Bond F., 2013, P 51 ANN M ASS COMPU, P1352
   Buckwalter Tim, 2004, LDC2004102 LING DAT
   Chen YQ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383
   Chu-Carroll Jennifer, 2001, TREC2001
   Constantine Layale, 2016, P 22 ACM SIGKDD C KN
   Dasigi P., 2012, P 50 ANN M ASS COMP, V2, P65
   Diab M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3782
   El Kholy A, 2012, MACH TRANSL, V26, P25, DOI 10.1007/s10590-011-9110-0
   El-Beltagy S. R., 2013, 9 INT C INN INF TECH, P215
   El-Beltagy Samhaa R., 2018, COMPUT LINGUIST, P169
   Elayeb B, 2016, ACM T ASIAN LOW-RESO, V15, DOI 10.1145/2789210
   Elnagar Ashraf, 2016, 2016 IEEEACS 13 INT, P1, DOI DOI 10.1109/AICCSA.2016.7945800
   Eskander Ramy, 2015, P 2015 C EMPIRICAL M, P2545
   Esuli A., 2007, EVALUATION 02232, V17, P26
   Farghaly A., 2009, ACM T ASIAN LANGUAGE, V8, P1, DOI DOI 10.1145/1644879.1644881
   Feldman R, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2436256.2436274
   Guo W., 2012, P 50 ANN M ASS COMPU, V2, P140
   Guo W, 2012, P 50 ANN M ASS COMP, P864
   Guo Weiwei, 2013, P C N AM CHAPT ASS C, P739
   Habash N, 2007, TEXT SPEECH LANG TEC, V38, P15
   Habash Nizar, 2004, P SESS TRAIT AUT LAR
   Hamdi A, 2018, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3209885
   Hanoka Valerie, 2012, P 8 INT C LANG RES E, P6
   He YL, 2012, AGEING RES REV, V11, P1, DOI 10.1016/j.arr.2011.11.004
   Joshi NC, 2012, CHEMISTRY OF PHYTOPOTENTIALS: HEALTH, ENERGY AND ENVIRONMENTAL PERSPECTIVES, P239, DOI 10.1007/978-3-642-23394-4_50
   Kaity M, 2019, J SUPERCOMPUT, V75, P2243, DOI 10.1007/s11227-019-02755-3
   Mikolov T., 2013, P 26 INT C NEUR INF, V2, P3111
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Moldovan DI, 2000, IEEE INTERNET COMPUT, V4, P34, DOI 10.1109/4236.815847
   Navigli R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P216
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Patel Kevin, 2018, P 9 GLOB WORDNET C G, P269
   Patwardhan Siddharth, 2006, P WORKSH MAK SENS SE
   Rodriguez Horacio, 2008, 4 GLOB WORDNET C SZE
   Rodriguez Horacio, 2008, P INT C LANG RES EV
   Sabra KS, 2017, 2017 SENSORS NETWORKS SMART AND EMERGING TECHNOLOGIES (SENSET)
   Sagot Benoit, 2011, P 5 LANG TECHN C LTC
   Salloum Wael Sameer, 2012, MODERN STANDARD ARAB
   Shen Dan, 2007, P JOINT C EMP METH N
   Soudi A, 2007, TEXT SPEECH LANG TEC, V38, P1
   Zitouni Imed, 2009, ACM T ASIAN LANG INF, V8, P1
NR 79
TC 5
Z9 5
U1 1
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD NOV
PY 2020
VL 19
IS 6
AR 80
DI 10.1145/3404854
PG 38
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PA3OO
UT WOS:000595547800006
DA 2023-11-10
ER

PT J
AU Liu, YH
   Gu, JT
   Goyal, N
   Li, X
   Edunov, S
   Ghazvininejad, M
   Lewis, M
   Zettlemoyer, L
AF Liu, Yinhan
   Gu, Jiatao
   Goyal, Naman
   Li, Xian
   Edunov, Sergey
   Ghazvininejad, Marjan
   Lewis, Mike
   Zettlemoyer, Luke
TI Multilingual Denoising Pre-training for Neural Machine Translation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper demonstrates that multilingual denoising pre-training produces significant performance gains across a wide variety of machine translation (MT) tasks. We present mBART-a sequence-to-sequence denoising auto-encoder pre-trained on large-scale monolingual corpora in many languages using the BART objective (Lewis et al., 2019). mBART is the first method for pre-training a complete sequence-to-sequencemodel by denoising full texts in multiple languages, whereas previous approaches have focused only on the encoder, decoder, or reconstructing parts of the text. Pre-training a complete model allows it to be directly fine-tuned for supervised (both sentence-level and document-level) and unsupervised machine translation, with no task-specific modifications. We demonstrate that adding mBART initialization produces performance gains in all but the highest-resource settings, including up to 12 BLEU points for low resource MT and over 5 BLEU points for many document-level and unsupervised models. We also show that it enables transfer to language pairs with no bi-text or that were not in the pre-training corpus, and present extensive analysis of which factors contribute the most to effective pre-training.
C1 [Gu, Jiatao; Goyal, Naman; Li, Xian; Edunov, Sergey; Ghazvininejad, Marjan; Lewis, Mike] Facebook AI, Menlo Pk, CA USA.
   [Liu, Yinhan; Zettlemoyer, Luke] Birch Technol, New Taipei, Taiwan.
C3 Facebook Inc
RP Liu, YH (通讯作者)，Birch Technol, New Taipei, Taiwan.
EM yinhan@birch.ai; jgu@fb.com; naman@fb.com; xianl@fb.com; edunov@fb.com;
   ghazvini@fb.com; mikelewis@fb.com; lsz@fb.com
CR Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   [Anonymous], 2012, P 16 ANN C EUR ASS M
   Arivazhagan N., 2019, ARXIV190705019
   Artetxe Mikel, 2017, 6 INT C LEARN REPR I
   Artetxe Mikel, 2019, ARXIV PREPRINT ARXIV
   Cettolo M., 2015, INT WORKSH SPOK LANG
   Chen XL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P261
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2475
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Devlin J., 2018, ARXIV, V1, P4171
   Ding CC, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3325885
   Ding CC, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3276773
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Edunov S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4052
   Firat O., 2016, P 2016 C N AM CHAPT, P866
   Gu Jiatao, 2018, P 2018 C N AM CHAPT, V1, P344, DOI [10.18653/v1/n18, DOI 10.18653/V1/N18]
   Gu Jiatao., 2019, ARXIV PREPRINT ARXIV
   Guillaume Wenzek, 2019, ARXIV PREPRINT ARXIV
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6098
   Jean Sebastien, 2017, ARXIV170405135
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66
   Kunchukuttan A., 2017, ARXIV171002855
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G., 2018, INT C LEARNING REPRE
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039
   Lample Guillaume, INT C LEARN REPR
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Li L., 2019, ARXIV191103110
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   LongyueWang Zhaopeng Tu, 2017, EMNLP, DOI 10.18653/v1/d17-1301
   Miculicich L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2947
   Mikolov T., 2013, EFFICIENT ESTIMATION
   Nitish Shirish Keskar, 2019, ARXIV PREPRINT ARXIV
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48
   PIRES T, 2019, P 57 ANN M ASS COMP
   Pourdamghani N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3057
   Qi Ye, 2018, ARXIV180406323, DOI 10.18653/
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Ramachandran P, 2017, P 2017 C EMP METH NA, P383, DOI DOI 10.18653/V1/D17-1039
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Song KT, 2019, PR MACH LEARN RES, V97
   Tiedemann J., 2017, ARXIV PREPRINT ARXIV
   Tu Zhaopeng, 2018, T ASSOC COMPUT LING, V6, P407
   Vaswani A, 2017, ADV NEUR IN, V30
   Wada Takashi, 2018, ABS180902306 CORR, DOI [10.18653/v1/P19-1300, DOI 10.18653/V1/P19-1300]
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Yang Jiacheng, 2019, ARXIV190805672
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang Yizhe, 2019, ARXIV191100536
   Zhu J, 2020, ICLR
   Zhu Jinhua, 2019, MACH TRANSL
NR 55
TC 306
Z9 311
U1 11
U2 36
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PY 2020
VL 8
BP 726
EP 742
DI 10.1162/tacl_a_00343
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA XX8IL
UT WOS:000736531900047
OA gold, Green Submitted
DA 2023-11-10
ER

PT J
AU Barceló-Coblijn, L
   Corominas-Murtra, B
   Gomila, A
AF Barcelo-Coblijn, Lluis
   Corominas-Murtra, Bernat
   Gomila, Antoni
TI Syntactic trees and small-world networks: syntactic development as a
   dynamical process
SO ADAPTIVE BEHAVIOR
LA English
DT Article
DE Language acquisition; small-world networks; complex systems; syntactic
   development
ID LANGUAGE; MODELS
AB Language has been argued to exhibit a complex system behavior. In our approach, the syntactic relations of dependency between words have been represented as networks. In a previous study, two English infants' corpora of utterances were analyzed longitudinally, offering a view of the ontogeny of syntax. Abrupt changes were detected in the growth pattern of the Giant Connected Component - the largest connected set of nodes in a graph. In the present study, we have further analyzed and compared three more infants, from the CHILDES database, learning three different languages: Dutch, German and Spanish. Our results show, along with previous work with English-speaking infants, that all three infants' syntactic networks change their topology in a similar way, from tree-like networks to small-world networks. This change happens at a similar period in all three infants (between 700 and 800 days), regardless of the language they acquire. Our study also shows that the hubs - the most connected nodes in these small-world networks - are always the so-called functional words, which, according to linguistic theory, just contribute to the syntactic structure of human language. The emergence of these hubs happens abruptly, following a logarithmic growth pattern. This developmental pattern challenges usage-based theories of language acquisition and suggests that syntactic development is driven by the growth of the lexicon.
C1 [Barcelo-Coblijn, Lluis; Gomila, Antoni] Univ Balearic Isl, Systemat Lab, Human Cognit & Evolut Grp, Dept Philosophy & Social Work, Palma De Mallorca 07100, Illes Balears, Spain.
   [Corominas-Murtra, Bernat] Univ Pompeu Fabra GRIB, ICREA Complex Syst Lab, Barcelona, Spain.
C3 Universitat de les Illes Balears; Pompeu Fabra University; ICREA
RP Gomila, A (通讯作者)，Univ Balearic Isl, Systemat Lab, Human Cognit & Evolut Grp, Dept Philosophy & Social Work, Campus Valldemossa, Palma De Mallorca 07100, Illes Balears, Spain.
EM antonigomila@gmail.com
RI Barceló-Coblijn, Lluís/L-1054-2019; Gomila, Antoni/I-1342-2012
OI Barceló-Coblijn, Lluís/0000-0002-8765-6314; Corominas-Murtra,
   Bernat/0000-0001-9806-5643
FU Ministerio de Ciencia e Innovacion (Spain) [BES2007-64086,
   FFI2010-20759, FFI2009-13416-C02]; IST-FET ECAGENTS EU [011940]; ICREA
   Funding Source: Custom
FX This study has been supported by the grant BES2007-64086, the projects
   FFI2010-20759 and FFI2009-13416-C02 from the Ministerio de Ciencia e
   Innovacion (Spain) and IST-FET ECAGENTS EU 011940.
CR [Anonymous], 1990, SYNTACTIC THEORY ACQ
   [Anonymous], 1936, PSYCHOBIOLOGY LANGUA
   [Anonymous], 1992, 1 VERBS CASE STUDY E
   Calvo P., 2008, HDB COGNITIVE SCI EM
   Cancho RFI, 2001, P ROY SOC B-BIOL SCI, V268, P2261, DOI 10.1098/rspb.2001.1800
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Chomsky Noam., 1963, HDB MATH PSYCHOL, V2, P269
   Chomsky Noam., 2000, STEP STEP ESSAYS MIN, P89
   Corominas-Murtra B., 2011, THESIS U POMPEU
   Corominas-Murtra B., 2007, ARXIV07043708V2
   Corominas-Murtra B, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.036115
   Corominas-Murtra B, 2009, ADV COMPLEX SYST, V12, P371, DOI 10.1142/S0219525909002192
   de Jong E. D., 1998, P 10 NETH BELG C ART, P27
   Guardiano C., 2011, BIOLINGUISTIC ENTERP
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Hudson R., 1990, ENGLISH WORD GRAMMAR
   Ke JY, 2008, J QUANT LINGUIST, V15, P70, DOI 10.1080/09296170701794286
   Melcuk I., 1988, DEPENDENCY SYNTAX TH
   Ninio A., 2006, LANGUAGE LEANING CUR
   Ninio A., 2003, PSYCHOL LANGUAGE COM, V7, P3
   Ninio A., 1996, PROPOSAL ADOPTION DE, P85
   Pinker Steven, 1989, LEARNABILITY COGNITI
   Popescu M., 2003, BUILDING AWARENESS L, P17
   Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303
   Solé RV, 2010, COMPLEXITY, V15, P20, DOI 10.1002/cplx.20305
   Steels L., 2000, P PPSN 6 LECT NOT CO
   Tomasello M., 2003, CONSTRUCTING LANGUAG
   Vogt P, 2010, ADAPT BEHAV, V18, P21, DOI 10.1177/1059712309350970
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
NR 29
TC 14
Z9 14
U1 0
U2 17
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1059-7123
EI 1741-2633
J9 ADAPT BEHAV
JI Adapt. Behav.
PD DEC
PY 2012
VL 20
IS 6
BP 427
EP 442
DI 10.1177/1059712312455439
PG 16
WC Computer Science, Artificial Intelligence; Psychology, Experimental;
   Social Sciences, Interdisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Psychology; Social Sciences - Other Topics
GA 048JM
UT WOS:000311907400002
DA 2023-11-10
ER

PT J
AU Alsubhi, K
   Jamal, A
   Alhothali, A
AF Alsubhi, Kholoud
   Jamal, Amani
   Alhothali, Areej
TI Deep learning-based approach for Arabic open domain question answering
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Arabic open domain question answering; Transformer-based models for
   question answering; Dense information retrieval approach
AB Open-domain question answering (OpenQA) is one of the most challenging yet widely investigated problems in natural language processing. It aims at building a system that can answer any given question from large-scale unstructured text or structured knowledge-base. To solve this problem, researchers traditionally use information retrieval methods to retrieve the most relevant documents and then use answer extractions techniques to extract the answer or passage from the candidate documents. In recent years, deep learning techniques have shown great success in OpenQA by using dense representation for document retrieval and reading comprehension for answer extraction. However, despite the advancement in the English language OpenQA, other languages such as Arabic have received less attention and are often addressed using traditional methods. In this paper, we use deep learning methods for Arabic OpenQA. The model consists of document retrieval to retrieve passages relevant to a question from large-scale free text resources such as Wikipedia and an answer reader to extract the precise answer to the given question. The model implements dense passage retriever for the passage retrieval task and the AraELECTRA for the reading comprehension task. The result was compared to traditional Arabic OpenQA approaches and deep learning methods in the English OpenQA. The results show that the dense passage retriever outperforms the traditional Term Frequency-Inverse Document Frequency (TF-IDF) information retriever in terms of the top-20 passage retrieval accuracy and improves our end-to-end question answering system in two Arabic question-answering benchmark datasets.
C1 [Alsubhi, Kholoud; Jamal, Amani; Alhothali, Areej] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.
C3 King Abdulaziz University
RP Alsubhi, K (通讯作者)，King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.
EM kalsobhi0013@stu.kau.edu.sa
RI Alhothali, Areej/AAF-8271-2021
OI Alhothali, Areej/0000-0001-9727-0178
CR Ahmed W, 2017, INT J ADV RES COMPUT, V8, P2849, DOI [10.26483/ijarcs.v8i1.2849, DOI 10.26483/IJARCS.V8I1.2849]
   Ahmed Waheeb, 2017, INT J ENG RES, V6, P142
   Ahmed Waheeb, 2016, INT J COMPUTATIONAL, V12, P18
   Almiman A, 2020, ALEX ENG J, V59, P4427, DOI 10.1016/j.aej.2020.07.048
   [Anonymous], 2009, ENCY DATABASE SYST, DOI DOI 10.1007/978-0-387-39940-9_561
   Antoun W, P 6 AR NAT LANG PROC, P191
   Antoun W., 2020, P 4 WORKSHOP OPEN SO, P9
   Attardi W, 2015, WIKIEXTRACTOR
   Bird S., 2008, P 3 WORKSH ISS TEACH, V13, P62, DOI DOI 10.3115/1627306.1627317
   Briggs J., DENSE PASSAGE RETRIE
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Clark JH, 2020, T ASSOC COMPUT LING, V8, P454, DOI 10.1162/tacl_a_00317
   Clark K., 2020, ARXIV PREPRINT
   Cui Yiming, 2020, P 28 INT C COMPUTATI, P6717, DOI DOI 10.18653/V1/2020.COLING-MAIN.589
   Devlin J., 2018, ARXIV, V1, P4171
   elastic, 2021, FREE OPEN SEARCH CRE
   Guu K, 2020, ARXIV PREPRINT
   Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2545
   Huang Z, 2020, IEEE ACCESS, V8, P94341, DOI 10.1109/ACCESS.2020.2988903
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086
   Lewis P, 2020, P 58 ANN M ASS COMPU, P7315, DOI [DOI 10.18653/V1/2020.ACL-MAIN.653, 10.18653/v1/2020.acl-main.653]
   Mozannar H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P108
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Rajpurkar Pranav, 2016, ARXIV, P2383
   Rusic M, 2021, NLP SOLUTIONS STREAM
   Sammut C., 2017, ENCY MACHINE LEARNIN, V2nd, DOI DOI 10.1007/978-1-4899-7687-1_68
   Teufel S, 2007, TEXT SPEECH LANG TEC, V37, P163
   Voidful, 2021, VOIDFULDPR CTX ENCOD
   Wikimedia Foundation, 2021, ARW DUMP PROGR 20210
   Wu Y., 2016, PREPRINT, DOI [10.48550/ARXIV.1609.08144, DOI 10.48550/ARXIV.1609.08144]
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P72
   Zhang Zhirui, 2018, CONLL 2018 22 C COMP, P190, DOI DOI 10.18653/V1/K18-1019
   Zhu F, 2021, ARXIV PREPRINT, DOI [10.48550/arXiv.2101.00774, DOI 10.48550/ARXIV.2101.00774]
NR 37
TC 5
Z9 5
U1 1
U2 6
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD MAY 4
PY 2022
VL 8
AR e952
DI 10.7717/peerj-cs.952
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1I4NZ
UT WOS:000797207800001
PM 35634104
OA Green Published, gold
DA 2023-11-10
ER

PT J
AU Kühn, S
   Cruse, H
AF Kühn, S
   Cruse, H
TI Static mental representations in recurrent neural networks for the
   control of dynamic behavioural sequences
SO CONNECTION SCIENCE
LA English
DT Article
DE mental representations; recurrent neural networks; learning;
   action-based model; simple language
ID PREMOTOR CORTEX; WORKING-MEMORY; PASSIVE VOICE; LANGUAGE; SYNTAX;
   MECHANISMS; COMPREHENSION; AVAILABILITY; RECOGNITION; INFORMATION
AB What enables an organism to perform behaviour we would call cognitive and adaptive, like language? Here, it is argued that an essential prerequisite is the ability to build up mental representations of external situations to uncouple the behaviour from direct environmental control. Such representations can be realized by building up cell assemblies. The recurrent neural network presented to cope with this task has been used for generation of action but can also be utilized as a basis for mental representations due to its attractor characteristics. In this context, a new learning algorithm (Dynamic Delta Rule) is proposed, which leads to a self-organized weight distribution yielding stable states on the one hand and which, on the other hand, only activates subpopulations of larger networks that code for the respective situation. In a second step, ways are shown of how the static information of these internal models can be transformed into time-dependent behavioural sequences.
C1 Univ Bielefeld, Fac Biol, Dept Biol Cybernet & Theoret Biol, D-4800 Bielefeld, Germany.
C3 University of Bielefeld
RP Kühn, S (通讯作者)，Univ Bielefeld, Fac Biol, Dept Biol Cybernet & Theoret Biol, D-4800 Bielefeld, Germany.
EM simone.kuehn@uni-bielefeld.de
CR [Anonymous], BLS
   [Anonymous], 1995, CONSTRUCTIONS CONSTR
   [Anonymous], NATO ASI SERIES
   [Anonymous], STRATEGIES TEXT COMP
   [Anonymous], 1992, 1 VERBS CASE STUDY E
   Baddeley A., 1986, WORKING MEMORY
   BERRIDGE KC, 1987, BEHAV BRAIN RES, V23, P59, DOI 10.1016/0166-4328(87)90242-7
   BOCK JK, 1982, PSYCHOL REV, V89, P1, DOI 10.1037/0033-295X.89.1.1
   BOCK JK, 1974, J EXP PSYCHOL, V103, P837, DOI 10.1037/h0037391
   Buccino G, 2001, EUR J NEUROSCI, V13, P400, DOI 10.1111/j.1460-9568.2001.01385.x
   Calvin W. H., 1996, BRAINS THINK
   Cangelosi A, 2001, IEEE T EVOLUT COMPUT, V5, P93, DOI 10.1109/4235.918429
   Cangelosi A, 1998, CONNECT SCI, V10, P83, DOI 10.1080/095400998116512
   CANGELOSI A, 2004, P 8 INT C SIM AD BEH, P487
   Clark HH., 1977, PSYCHOL LANGUAGE
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Cruse H, 2003, BIOL CYBERN, V88, P425, DOI 10.1007/s00422-003-0395-9
   Cruse H, 2003, COGNITIVE SCI, V27, P135, DOI 10.1207/s15516709cog2701_5
   CRUSE H, 1993, BIOL CYBERN, V69, P345, DOI 10.1007/BF00203131
   CRUSE H, 1998, P 5 INT C SIM AD BEH, P381
   De Saussure, 1967, GRUNDFRAGEN ALLGEMEI
   Decety J, 2003, TRENDS COGN SCI, V7, P527, DOI 10.1016/j.tics.2003.10.004
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   FISHER C, 1994, LANG COGNITIVE PROC, V9, P473, DOI 10.1080/01690969408402129
   Fuster JM., 1995, MEMORY CEREBRAL CORT
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   GERNSBACHER MA, 1988, J MEM LANG, V27, P699, DOI 10.1016/0749-596X(88)90016-2
   GERNSBACHER MA, 1989, COGNITION, V32, P99, DOI 10.1016/0010-0277(89)90001-2
   Gibson J.J., 1966, ECOLOGICAL APPROACH
   Gibson James J., 1979, ECOLOGICAL APPROACH
   Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313
   Glenberg AM, 1999, DISCOURSE PROCESS, V28, P1, DOI 10.1080/01638539909545067
   Grafton ST, 1997, NEUROIMAGE, V6, P231, DOI 10.1006/nimg.1997.0293
   Grèzes J, 2001, NEUROIMAGE, V13, P775, DOI 10.1006/nimg.2000.0740
   HARRIS M, 1978, Q J EXP PSYCHOL, V30, P495, DOI 10.1080/00335557843000089
   HASCHKE R, 2001, P INT C ART NEUR NET, P1109
   Hebb D. O., 1949, ORG BEHAV NEUROPSYCH
   Heidelberger M, 1998, BOST STUD PHILOS SCI, V198, P9
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hörnig R, 2005, MEM COGNITION, V33, P131, DOI 10.3758/BF03195303
   Iacoboni M, 1999, SCIENCE, V286, P2526, DOI 10.1126/science.286.5449.2526
   Jeannerod M, 1999, Q J EXP PSYCHOL-A, V52, P1, DOI 10.1080/027249899391205
   Jensen O, 2005, TRENDS NEUROSCI, V28, P67, DOI 10.1016/j.tins.2004.12.001
   Johnson-Laird P. N., 1983, MENTAL MODELS COGNIT
   JOHNSONLAIRD PN, 1968, Q J EXP PSYCHOL, V20, P69, DOI 10.1080/14640746808400129
   Jordan M., 1986, P 8 ANN C COGN SCI S, P531
   Kaschak MP, 2000, J MEM LANG, V43, P508, DOI 10.1006/jmla.2000.2705
   Kindermann T, 2002, MECH MACH THEORY, V37, P375, DOI 10.1016/S0094-114X(01)00080-5
   KINDERMANN T, 2003, THESIS U BIELEFELD
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Lashley K., 1951, CEREBRAL MECH BEHAV, pP112, DOI DOI 10.1016/J.HUMOV.2007.04.001
   LEVELT W, 1989, SPEAKING INTENTION A
   Levelt W.J.M., 1999, NEUROCOGNITION LANGU, P83, DOI DOI 10.1093/ACPROF:OSO/9780198507932.003.0004
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Naigles LR, 1998, PSYCHOL SCI, V9, P363, DOI 10.1111/1467-9280.00069
   OSGOOD CE, 1981, J CHILD LANG, V8, P367, DOI 10.1017/S030500090000324X
   Pinker Steven, 1989, LEARNABILITY COGNITI
   Porr B, 2003, PHILOS T R SOC A, V361, P2225, DOI 10.1098/rsta.2003.1273
   Rizzolatti G, 2001, NAT REV NEUROSCI, V2, P661, DOI 10.1038/35090060
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Roskies AL, 1999, NEURON, V24, P7, DOI 10.1016/S0896-6273(00)80817-X
   Slobin DanI., 1985, CROSSLINGUISTIC STUD, V1, P141
   Smith CS, 1971, J LINGUIST, V7, P213, DOI 10.1017/S0022226700002929
   Steil Jochen J, 1999, INPUT OUTPUT STABILI
   Steinkühler U, 1998, BIOL CYBERN, V79, P457, DOI 10.1007/s004220050495
   STEINKUHLER U, 2000, PRERATIONAL INTELLIG, P121
   Tani J, 1999, NEURAL NETWORKS, V12, P1131, DOI 10.1016/S0893-6080(99)00060-X
   Tomasello M., 2003, CULTURAL ORIGINS HUM
   TULVING E, 1966, J VERB LEARN VERB BE, V5, P381, DOI 10.1016/S0022-5371(66)80048-8
   Von Eckardt B., 1993, WHAT IS COGNITIVE SC
   Wittgenstein Ludwig, 1972, PHILOS INVESTIGATION
   WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931
   Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5
   Zwaan RA, 2000, MEM COGNITION, V28, P1022, DOI 10.3758/BF03209350
   Zwaan RA, 1998, PSYCHOL BULL, V123, P162, DOI 10.1037/0033-2909.123.2.162
NR 80
TC 7
Z9 7
U1 0
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0954-0091
J9 CONNECT SCI
JI Connect. Sci.
PD SEP-DEC
PY 2005
VL 17
IS 3-4
BP 343
EP 360
DI 10.1080/09540090500177638
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 979JJ
UT WOS:000232937900010
OA Bronze
DA 2023-11-10
ER

PT J
AU Gamallo, P
   Sotelo, S
   Pichel, JR
   Artetxe, M
AF Gamallo, Pablo
   Sotelo, Susana
   Pichel, Jose Ramom
   Artetxe, Mikel
TI Contextualized Translations of Phrasal Verbs with Distributional
   Compositional Semantics and Monolingual Corpora
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID MODELS
AB This article describes a compositional distributional method to generate contextualized senses of words and identify their appropriate translations in the target language using monolingual corpora. Word translation is modeled in the same way as contextualization of word meaning, but in a bilingual vector space. The contextualization of meaning is carried out by means of distributional composition within a structured vector space with syntactic dependencies, and the bilingual space is created by means of transfer rules and a bilingual dictionary. A phrase in the source language, consisting of a head and a dependent, is translated into the target language by selecting both the nearest neighbor of the head given the dependent, and the nearest neighbor of the dependent given the head. This process is expanded to larger phrases by means of incremental composition. Experiments were performed on English and Spanish monolingual corpora in order to translate phrasal verbs in context. A new bilingual data set to evaluate strategies aimed at translating phrasal verbs in restricted syntactic domains has been created and released.
C1 [Gamallo, Pablo] Univ Santiago de Compostela, CiTIUS, Ctr Invest Tecnol Intelixentes, Santiago De Compostela, Spain.
   [Sotelo, Susana] Univ Santiago de Compostela, CiTIUS, Santiago De Compostela, Spain.
   [Pichel, Jose Ramom] Imaxin Software, Santiago De Compostela, Spain.
   [Artetxe, Mikel] Univ Basque Country, IXA Grp, Euskal Herriko Unibersitatea, Bilbao, Spain.
C3 Universidade de Santiago de Compostela; Universidade de Santiago de
   Compostela; University of Basque Country
RP Gamallo, P (通讯作者)，Univ Santiago de Compostela, CiTIUS, Ctr Invest Tecnol Intelixentes, Santiago De Compostela, Spain.
EM pablo.gamallo@usc.es; susana.sotelo.docio@usc.es;
   jramompichel@imaxin.com; mikel.artetxe@ehu.eus
RI gamallo, pablo/A-6985-2009
OI gamallo, pablo/0000-0002-5819-2469; Sotelo, Susana/0000-0002-0067-7957
CR Agirre E, 2016, P 10 INT WORKSH SEM, P497, DOI DOI 10.18653/V1/S16-1081
   Aker Ahmet, 2013, P 51 ANN M ASS COMP, P4
   Andrade D., 2011, P 4 WORKSH BUILD US, P10
   [Anonymous], P MT SUMMIT
   [Anonymous], 1991, P 29 ANN M ASS COMP, DOI DOI 10.3115/981344.981378
   [Anonymous], 2012, P 2012 JOINT C EMP M
   [Anonymous], P 23 INT C COMP LING
   [Anonymous], 2012, P 24 INT C COMP LING
   [Anonymous], 2011, P 9 INT C COMP SEM O
   [Anonymous], 2017, ABS171011041 CORR
   [Anonymous], NAACL SHORT 09 P HUM
   [Anonymous], P 36 ANN M ASS COMP
   [Anonymous], 2015, P 3 WORKSHOP CONTINU
   Ansari Ebrahim, 2014, INDIAN J SCI TECHNOL, V7, P1279
   Artetxe M., 2016, P 2016 C EMPIRICAL M, P2289, DOI [DOI 10.18653/V1/D16-1250, 10.18653/v1/d16-1250]
   Artetxe M, 2018, AAAI CONF ARTIF INTE, P5012
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Baroni M., 2010, ASS COMPUTATIONAL LI, P1183
   Baroni M., 2014, LINGUIST ISSUES LANG, V9, P241
   Baroni M, 2013, LANG LINGUIST COMPAS, V7, P511, DOI 10.1111/lnc3.12050
   Boas HC, 2010, CONSTR APPROACH LANG, V10, P1
   Brychcin T., 2016, P 10 INT WORKSH SEM, P588, DOI [10.18653/v1/S16-1089, DOI 10.18653/V1/S16-1089]
   Cheng Jianpeng, 2015, P 2015 C EMP METH NA, P1531, DOI DOI 10.18653/V1/D15-1177
   Chiang Y.-S., 2002, P 19 INT C COMP LING, P1, DOI DOI 10.3115/1071884.1071904
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Coecke B., 2010, ARXIV10034394
   Dagan Ido, 1991, P 29 ANN M ASS COMP, P341
   Delpech Estelle, 2012, COLING, P745
   Devlin Jacob, 2019, P NAACL
   Erk K, 2010, COMPUT LINGUIST, V36, P723, DOI 10.1162/coli_a_00017
   Erk Katrin, 2008, P C EMPIRICAL METHOD, P897
   Fung Pascale, 1997, 5 ANN WORKSH VER LAR, P192
   Gamallo P, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P239, DOI 10.1109/SNAMS.2018.8554689
   Gamallo P, 2018, INFORM PROCESS MANAG, V54, P1244, DOI 10.1016/j.ipm.2018.05.003
   Gamallo P, 2017, LANG RESOUR EVAL, V51, P727, DOI 10.1007/s10579-016-9357-4
   Gamallo P, 2011, LANG RESOUR EVAL, V45, P95, DOI 10.1007/s10579-010-9129-5
   Gamallo Pablo, 2017, CORPUS LINGUISTICS L
   Gamallo Pablo, 2017, P 11 INT WORKSH SEM, P226
   Gamallo Pablo, 2008, INT C INT TEXT PROC, V4919, P423
   Grefenstette Edward, 2011, P C EMPIRICAL METHOD, P1394
   Grefenstette Gregory, 1999, TRANSLATING COMPUTER
   Guevara E., 2010, P 2010 WORKSH GEOMET, P33
   Hazem A, 2014, LECT NOTES COMPUT SC, V8404, P310, DOI 10.1007/978-3-642-54903-8_26
   Hudson R.A., 2003, P 1 INT C MEAN TEXT, P181
   Irsoy O., 2014, ADV NEURAL INFORM PR, P2096, DOI DOI 10.5555/2969033.2969061
   Kahane Sylvain, 2003, DEPENDENCY VALENCY I
   Kartsaklis Dimitri, 2014, P LEARN SEM WORKSH N
   Kober T, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P433, DOI 10.18653/v1/P17-2069
   Krishnamurthy Jayant, 2013, ACL 2013, P1
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039
   McCann Bryan, 2017, ABS170800107 CORR
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, P51, DOI DOI 10.18653/V1/K16-1006
   Mikolov T., 2013, P 2013 C N AM CHAPT, P746
   Mikolov Tomas, 2013, ABS13094168 CORR
   Mitchell J, P ACL 08 HLT, P236, DOI DOI 10.1039/9781847558633-00236
   Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x
   Mitchell Jeff, 2009, P 2009 C EMP METH NA, V1, P430
   MONTAGUE R, 1970, THEORIA, V36, P373
   Pham NT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P971
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Rapp Reinhard, 1999, ACL, DOI DOI 10.3115/1034678.1034756
   Resnik P, 1996, COGNITION, V61, P127, DOI 10.1016/S0010-0277(96)00722-6
   Rubino R, 2011, LECT NOTES COMPUT SC, V6609, P29, DOI 10.1007/978-3-642-19437-5_3
   Saralegi X., 2008, LREC 2008 WORKSH BUI, P27
   Shao L., 2004, P 20 INT C COMP LING, DOI DOI 10.3115/1220355.1220444
   Socher R., 2012, P 2012 JOINT C EMPIR, P1201, DOI DOI 10.1162/153244303322533223
   Tanaka Takaaki, 2003, P ACL 2003 WORKSH MU, P17, DOI DOI 10.3115/1119282.1119285
   Thater S, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P948
   Tsujii Junichi, 2009, MACHINE TRANSLATION
   Turney PD, 2012, J ARTIF INTELL RES, V44, P533, DOI 10.1613/jair.3640
   Upadhyay Shyam, 2018, P C N AM CHAPTER ASS, P607
   Weir D, 2016, COMPUT LINGUIST, V42, P727, DOI 10.1162/COLI_a_00265
   Wijaya Derry Tanti, 2017, P 2017 C EMPIRICAL M, P1452
   Zanzotto F.M., 2010, P 23 INT C COMPUTATI, P1263
NR 75
TC 4
Z9 4
U1 3
U2 21
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2019
VL 45
IS 3
BP 395
EP 421
DI 10.1162/coli_a_00353
PG 27
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA JC1KA
UT WOS:000489035700001
OA gold
DA 2023-11-10
ER

PT J
AU Luo, G
   Zhou, YY
   Sun, XS
   Wang, Y
   Cao, LJ
   Wu, YJ
   Huang, FY
   Ji, RR
AF Luo, Gen
   Zhou, Yiyi
   Sun, Xiaoshuai
   Wang, Yan
   Cao, Liujuan
   Wu, Yongjian
   Huang, Feiyue
   Ji, Rongrong
TI Towards Lightweight Transformer Via Group-Wise Transformation for
   Vision-and-Language Tasks
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Transformers; Task analysis; Computational modeling; Benchmark testing;
   Visualization; Convolution; Head; Lightweight transformer; visual
   question answering; image captioning; reference expression comprehension
AB Despite the exciting performance, Transformer is criticized for its excessive parameters and computation cost. However, compressing Transformer remains as an open problem due to its internal complexity of the layer designs, i.e., Multi-Head Attention (MHA) and Feed-Forward Network (FFN). To address this issue, we introduce Group-wise Transformation towards a universal yet lightweight Transformer for vision-and-language tasks, termed as LW-Transformer. LW-Transformer applies Group-wise Transformation to reduce both the parameters and computations of Transformer, while also preserving its two main properties, i.e., the efficient attention modeling on diverse subspaces of MHA, and the expanding-scaling feature transformation of FFN. We apply LW-Transformer to a set of Transformer-based networks, and quantitatively measure them on three vision-and-language tasks and six benchmark datasets. Experimental results show that while saving a large number of parameters and computations, LW-Transformer achieves very competitive performance against the original Transformer networks for vision-and-language tasks. To examine the generalization ability, we apply LW-Transformer to the task of image classification, and build its network based on a recently proposed image Transformer called Swin-Transformer, where the effectiveness can be also confirmed.
C1 [Luo, Gen; Zhou, Yiyi; Sun, Xiaoshuai; Cao, Liujuan; Ji, Rongrong] Xiamen Univ, Dept Artificial Intelligence, Media Analyt & Comp Lab, Xiamen 361005, Peoples R China.
   [Wang, Yan] Microsoft, Beijing 100080, Peoples R China.
   [Wu, Yongjian; Huang, Feiyue] Tencent Technol Shanghai Co Ltd, Shenzhen 518000, Peoples R China.
C3 Xiamen University
RP Zhou, YY (通讯作者)，Xiamen Univ, Dept Artificial Intelligence, Media Analyt & Comp Lab, Xiamen 361005, Peoples R China.
EM luogen@stu.xmu.edu.cn; zhouyiyi@xmu.edu.cn; xssun@xmu.edu.cn;
   yanwang@ee.columbia.edu; caoliujuan@xmu.edu.cn; littlekenwu@tencent.com;
   garyhuang@tencent.com; rrji@xmu.edu.cn
OI Luo, Gen/0000-0001-5334-1843; Cao, Liujuan/0000-0002-7645-9606
FU National Science Fund for Distinguished Young Scholars [62025603];
   National Natural Science Foundation of China [U21B2037, 62176222,
   62176223, 62176226, 62072386, 62072387, 62072389, 62002305]; China
   Postdoctoral Science Foundation [2021T40397]; Guangdong Basic and
   Applied Basic Research Foundation [2019B1515120049]; Natural Science
   Foundation of Fujian Province of China [2021J01002]
FX This work was supported in part by the National Science Fund for
   Distinguished Young Scholars under Grant 62025603; in part by the
   National Natural Science Foundation of China under Grant U21B2037, Grant
   62176222, Grant 62176223, Grant 62176226, Grant 62072386, Grant
   62072387, Grant 62072389, and Grant 62002305; in part by the China
   Postdoctoral Science Foundation under Grant 2021T40397; in part by the
   Guangdong Basic and Applied Basic Research Foundation under Grant
   2019B1515120049; and in part by the Natural Science Foundation of Fujian
   Province of China under Grant 2021J01002. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Zhu Li.
CR Alberti C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2131
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2005, P ACL WORKSHOP INTRI
   [Anonymous], 2018, INT C MACH LEARN STO
   [Anonymous], 2018, PROC INT C LEARN REP
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, P8102
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Carion Nicolas, 2020, ARXIV200512872
   Chelba C., 2013, ARXIV PREPRINT ARXIV
   Chen Xinlei, 2015, ARXIV150400325
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Choromanski K. M, 2020, PROC INT C LEARN REP
   Chu X., 2021, ADV NEURAL INF PROCE, V34, P9355, DOI DOI 10.48550/ARXIV.2104.13840
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Cornia M., 2019, ARXIV191002974
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Dai Zihang, 2019, ARXIV190102860
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, ARXIV, V1, P4171
   El-Nouby A, ARXIV210609681, V2021
   Fan A, 2019, ARXIV, V103, P1
   Fukui Akira, 2016, ARXIV160601847, P457, DOI [DOI 10.18653/V1/D16-1044, 10.18653/v1/D16-1044]
   Gao P, 2019, IEEE I CONF COMP VIS, P5824, DOI 10.1109/ICCV.2019.00592
   Gao P, 2019, PROC CVPR IEEE, P6632, DOI 10.1109/CVPR.2019.00680
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Guo QP, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1315
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herdade S, 2019, ADV NEUR IN, V32
   Howard Andrew G, 2017, ARXIV170404861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Hu RH, 2019, IEEE I CONF COMP VIS, P10293, DOI 10.1109/ICCV.2019.01039
   Hu RH, 2017, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2017.470
   Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Jiao X., 2020, FINDINGS ASS COMPUTA, P4163, DOI [10.18653/v1/2020.findings-emnlp.372, DOI 10.18653/V1/2020.FINDINGS-EMNLP.372, 10.18653/v1/2020. findings-emnlp.372. URL]
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086
   Kim JH, 2018, ADV NEUR IN, V31
   Kim Jin-Hwa, 2016, ARXIV161004325, DOI 10.48550/arXiv.1610.04325
   Kingma D. P., 2014, C TRACK P
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Li Gen, 2019, ARXIV190806066, P2
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li Liunian Harold, 2019, ARXIV190803557
   Li Y., 2021, ARXIV210712292
   Li YA, 2021, AAAI CONF ARTIF INTE, V35, P8518
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Liu DQ, 2019, IEEE I CONF COMP VIS, P4672, DOI 10.1109/ICCV.2019.00477
   Liu JY, 2017, IEEE I CONF COMP VIS, P4866, DOI 10.1109/ICCV.2017.520
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Liu XH, 2018, LECT NOTES COMPUT SC, V11219, P353, DOI 10.1007/978-3-030-01267-0_21
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu J., 2019, ARXIV191202315
   Lu JS, 2019, ADV NEUR IN, V32
   Ma Ningning, 2018, P EUR C COMP VIS ECC, P116, DOI [DOI 10.1007/978-3-030-01264-9_8, 10.1007/978-3-030-01264-9_8]
   Ma XD, 2019, ADV NEUR IN, V32
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Perez E., 2018, PROC AAAI C ARTIF IN, V32
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sanh Victor, 2019, ARXIV191001108
   Santoro A., 2017, P ADV NEUR INF PROC, P4967
   Shen S., 2019, ARXIV190905840
   So DR, 2019, PR MACH LEARN RES, V97
   Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710
   Sukhbaatar Sainbayar, 2019, ARXIV190507799
   Szegedy C., 2017, PROC 31 AAAI C ARTIF, V31
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tao D., 2020, ARXIV200412070
   Tian James Yi, 2019, ARXIV191206638
   Vaswani A., 2017, ARXIV, V30, P5998
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wang Sinong, 2020, ARXIV200604768
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2017, PROC CVPR IEEE, P3521, DOI 10.1109/CVPR.2017.375
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1114
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Yu Zhou, 2019, ARXIV190804107
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zafrir Ofir, 2019, 2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS), P36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zhang Hongyi, 2017, ABS171009412 CORR
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou L., 2019, ARXIV190911059
NR 99
TC 8
Z9 8
U1 27
U2 90
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PY 2022
VL 31
BP 3386
EP 3398
DI 10.1109/TIP.2021.3139234
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1D4ZT
UT WOS:000793811000006
PM 35471883
OA Green Submitted
DA 2023-11-10
ER

PT J
AU Yang, S
   Feng, DW
   Liu, Y
   Li, DS
AF Yang, Sen
   Feng, Dawei
   Liu, Yang
   Li, Dongsheng
TI Distant context aware text generation from abstract meaning
   representation
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Text generation; Abstract meaning representation; Graph encoder;
   Receptive field
AB Text generation from abstract meaning representation is a fundamental task in natural language generation. An interesting challenge is that distant context could influence the surface realization for each node. In the previous encoder-decoder based approaches, graph neural networks have been commonly used to encode abstract meaning representation graphs and exhibited superior performance over the sequence and tree encoders. However, most of them cannot stack numerous layers, thus being too shallow to capture distant context. In this paper, we propose solutions from three aspects. Firstly, we introduce a Transformer based graph encoder to embed abstract meaning representation graphs. This encoder can stack more layers to encode larger context, while without performance degrading. Secondly, we expand the receptive field of each node, i.e. building direct connections between node pairs, to capture the information of its distant neighbors. We also exploit relative position embedding to make the model aware of the original hierarchy of graphs. Thirdly, we encode the linearized version of abstract meaning representation with the pre-trained language model to get the sequence encoding and incorporate it into graph encoding to enrich features. We conduct experiments on LDC2015E86 and LDC2017T10. Experimental results demonstrate that our method outperforms previous strong baselines. Especially, we investigate the performance of our model on large graphs, finding a larger performance gain. Our best model achieves 31.99 of BLEU and 37.02 of METEOR on LDC2015E86, 34.21 of BLEU, and 39.26 of METEOR on LDC2017T10, which are new states of the art.
C1 [Yang, Sen; Feng, Dawei; Liu, Yang; Li, Dongsheng] Natl Univ Def Technol, Coll Comp Sci, Changsha, Peoples R China.
   [Yang, Sen; Feng, Dawei; Li, Dongsheng] Natl Univ Def Technol, Natl Lab Parallel & Distributed Proc, Changsha, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Yang, S (通讯作者)，Natl Univ Def Technol, Coll Comp Sci, Changsha, Peoples R China.; Yang, S (通讯作者)，Natl Univ Def Technol, Natl Lab Parallel & Distributed Proc, Changsha, Peoples R China.
EM yangsen.nudt@hotmail.com
OI Yang, Sen/0000-0003-3222-2268
CR Abu-El-Haifa S, 2019, PR MACH LEARN RES, V97
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Banarescu Laura, 2013, P 7 LING ANN WORKSH
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, P65, DOI DOI 10.3115/1626355.1626389
   Beck D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P273
   Cai D, 2020, AAAI CONF ARTIF INTE, V34, P7464
   Cao K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2157
   Chen Benson, 2019, ARXIV190512712
   Chen Y, 2020, 8 INT C LEARN REPR I
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1, 10.3115]
   Choi E, 2020, AAAI CONF ARTIF INTE, V34, P606
   Damonte M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3649
   Devlin J., 2018, ARXIV, V1, P4171
   Dyer C., 2016, P 2016 M N AM CHAPTE, P731, DOI 10.18653/v1/N16-1087
   Gao H, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954523
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Guo ZJ, 2019, T ASSOC COMPUT LING, V7, P297, DOI 10.1162/tacl_a_00269
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu ZN, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2704, DOI 10.1145/3366423.3380027
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kasper R. T., 1989, Speech and Natural Language. Proceedings of a Workshop, P153
   Kipf T N, 2016, ICLR
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Konstas I, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P146, DOI 10.18653/v1/P17-1014
   Li Qimai, 2018, ARXIV180107606, DOI DOI 10.1109/IFETC.2018.8583886
   Liao K, 2018, P 27 INT C COMP LING, P1178
   Manuel M, 2020, P 58 ANN M ASS COMP
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Petar V., 2018, ICLR
   Radford A., 2019, OPENAI BLOG
   Rao S, 2017, BIONLP, V2017, P126, DOI DOI 10.18653/V1/W17-2315
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Song LF, 2019, T ASSOC COMPUT LING, V7, P19, DOI 10.1162/tacl_a_00252
   Song LF, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1616
   Song LF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P7, DOI 10.18653/v1/P17-2002
   Takase Sho, 2016, P 2016 C EMP METH NA, P1054, DOI [10.18653/v1/D16-1112, DOI 10.18653/V1/D16-1112]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang TM, 2020, T ASSOC COMPUT LING, V8, P19, DOI 10.1162/tacl_a_00297
   Xu K., 2018, ARXIV180400823
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Yao S., 2020, P 58 ANN M ASS COMPU, P7145, DOI [10.18653/v1/2020.acl-main.640, DOI 10.18653/V1/2020.ACL-MAIN.640]
   Yun S, 2019, ADV NEUR IN, V32
   Zhao YB, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P732
   Zhu J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5459
NR 45
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JAN
PY 2022
VL 52
IS 2
BP 1672
EP 1685
DI 10.1007/s10489-021-02431-1
EA MAY 2021
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YL6SX
UT WOS:000654848300001
DA 2023-11-10
ER

PT J
AU Rossmanith, P
   Zeugmann, T
AF Rossmanith, P
   Zeugmann, T
TI Stochastic finite learning of the pattern languages
SO MACHINE LEARNING
LA English
DT Article
DE inductive learning; pattern languages; average-case analysis; learning
   in the limit; stochastic finite learning
ID IDENTIFICATION; AVERAGE; SET
AB The present paper proposes a new learning model-called stochastic finite learning-and shows the whole class of pattern languages to be learnable within this model.
   This main result is achieved by providing a new and improved average-case analysis of the Lange-Wiehagen (New Generation Computing, 8, 361-370) algorithm learning the class of all pattern languages in the limit from positive data. The complexity measure chosen is the total learning time, i.e., the overall time taken by the algorithm until convergence. The expectation of the total learning time is carefully analyzed and exponentially shrinking tail bounds for it are established for a large class of probability distributions. For every pattern pi containing k different variables it is shown that Lange and Wiehagen's algorithm possesses an expected total learning time of O(<(<alpha>) over cap>alpha (k) E[Lambda ]log(1/beta)(k)), where <(<alpha>) over cap> and beta are two easily computable parameters arising naturally from the underlying probability distributions, and E[Lambda] is the expected example string length.
   Finally, assuming a bit of domain knowledge concerning the underlying class of probability distributions, it is shown how to convert learning in the limit into stochastic finite learning.
C1 Tech Univ Munich, Inst Informat, D-80290 Munich, Germany.
   Med Univ Lubeck, Inst Theoret Informat, D-23560 Lubeck, Germany.
C3 Technical University of Munich; University of Lubeck
RP Rossmanith, P (通讯作者)，Tech Univ Munich, Inst Informat, D-80290 Munich, Germany.
EM rossmani@in.tum.de; thomas@tcs.mu-luebeck.de
OI Rossmanith, Peter/0000-0003-0177-8028
CR ANGLUIN D, 1980, J COMPUT SYST SCI, V21, P46, DOI 10.1016/0022-0000(80)90041-0
   ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5
   BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371
   DALEY RP, 1986, INFORM CONTROL, V69, P12, DOI 10.1016/S0019-9958(86)80042-0
   Erlebach T, 1997, LECT NOTES ARTIF INT, V1316, P260
   FULK MA, 1990, INFORM COMPUT, V85, P1, DOI 10.1016/0890-5401(90)90042-G
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   GOLDMAN SA, 1993, SIAM J COMPUT, V22, P705, DOI 10.1137/0222047
   HAGERUP T, 1990, INFORM PROCESS LETT, V33, P305, DOI 10.1016/0020-0190(90)90214-I
   HAUSSLER D, 1991, INFORM COMPUT, V95, P129, DOI 10.1016/0890-5401(91)90042-Z
   Hopcroft J.E., 1969, FORMAL LANGUAGES THE
   Kearns M., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory, P57
   Lange S, 1996, MATH SYST THEORY, V29, P599
   LANGE S, 1990, NEW GENERAT COMPUT, V8, P361
   LANGE S, 1993, LECTURE NOTES ARTIFI, V659, P254
   Mitchell A, 1999, LECT NOTES ARTIF INT, V1720, P93
   MUGGLETON S, 1994, P 11 INT C MACH LEAR, P371
   PITT L, 1989, LECT NOTES ARTIF INT, V397, P18
   Reischuk R., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P198, DOI 10.1145/279943.279984
   Reischuk R, 1999, LECT NOTES COMPUT SC, V1563, P414
   ROSSMANITH P, 1998, EATCS B, V54, P46
   SALOMAA A, 1994, EATCS B, V55, P144
   Schapire R. E., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory, P122
   Shinohara T., 1995, LECT NOTES ARTIF INT, V961, P259
   VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972
   Zeugmann T, 1998, ANN MATH ARTIF INTEL, V23, P117, DOI 10.1023/A:1018964207937
   ZEUGMANN T, 1995, LECT NOTES ARTIF INT, V961, P190
NR 27
TC 18
Z9 18
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PY 2001
VL 44
IS 1-2
BP 67
EP 91
DI 10.1023/A:1010875913047
PG 25
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 428MR
UT WOS:000168465900004
OA Bronze
DA 2023-11-10
ER

PT J
AU Shi, TT
   Huang, SH
   Chen, LX
   Heng, Y
   Kuang, ZY
   Xu, L
   Mei, H
AF Shi, Tingting
   Huang, Shuheng
   Chen, Linxin
   Heng, Yu
   Kuang, Zuyin
   Xu, Lei
   Mei, Hu
TI A molecular generative model of ADAM10 inhibitors by using GRU-based
   deep neural network and transfer learning
SO CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS
LA English
DT Article; Proceedings Paper
CT 10th Colloquium on Chemiometricum Mediterraneum (CCM)
CY JUN 12-14, 2019
CL Minorca, SPAIN
SP Chemometr Soc France
DE Deep learning; Recurrent neural network; Molecular design; Virtual
   screening; ADAM10; Inhibitor
ID DISCOVERY; CLEAVAGE; DESIGN
AB Recurrent neural network (RNN) is one of the most representative architectures in deep learning and widely adopted in many research fields especially in natural language processing. In this work, a gated-recurrent-unit (GRU)-based deep neural network combined with transfer learning was successfully employed to establish a molecular generative model of ADAM10 inhibitors. The results showed that the GRU-based generative model can learn accurately the SMILES grammars of the molecules and be capable of generating novel potential ADAM10 inhibitors. In comparison with traditional ligand-based methods, the GRU-based generative model requires only the SMILES information of the chemical ligands and can generate efficiently a large set of potential novel structures. These unique advantages make it extremely useful in de novo drug design and large-scale virtual screening researches.
C1 [Shi, Tingting; Mei, Hu] Chongqing Univ, Key Lab Biorheol Sci & Technol Minist Educ, Chongqing 400044, Peoples R China.
   [Shi, Tingting; Huang, Shuheng; Chen, Linxin; Heng, Yu; Kuang, Zuyin; Xu, Lei; Mei, Hu] Chongqing Univ, Coll Bioengn, Chongqing 400044, Peoples R China.
C3 Chongqing University; Chongqing University
RP Mei, H (通讯作者)，Chongqing Univ, Minist Educ, Key Lab Biorheol Sci & Technol, Chongqing 400044, Peoples R China.
EM shitingting@cqu.edu.cn; shhuang@cqu.edu.cn; chenlinxin@cqu.edu.cn;
   201819021102@cqu.edu.cn; 201819021101@cqu.edu.cn; 364504974@qq.com;
   meihu@cqu.edu.cn
FU Fundamental Research Funds for the Central Universities
   [106112017CDJQJ238816]
FX The authors acknowledge the support of the Fundamental Research Funds
   for the Central Universities (Project No. 106112017CDJQJ238816).
CR Altmeppen HC, 2015, ELIFE, V4, DOI 10.7554/eLife.04260
   [Anonymous], 2016, GOOGLES NEURAL MACHI
   [Anonymous], 2014, ADAM METHOD STOCHAST
   BOHM HJ, 1992, J COMPUT AID MOL DES, V6, P61, DOI 10.1007/bf00124387
   Camodeca C, 2016, EUR J MED CHEM, V111, P193, DOI 10.1016/j.ejmech.2016.01.053
   Chen CK, 2018, INTERDISCIP SCI, V10, P823, DOI 10.1007/s12539-017-0254-3
   Chu YY, 2021, BRIEF BIOINFORM, V22, P451, DOI 10.1093/bib/bbz152
   Ciresan DC, 2012, IEEE IJCNN
   Eck D, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P747, DOI 10.1109/NNSP.2002.1030094
   Gupta A, 2018, MOL INFORM, V37, DOI 10.1002/minf.201700111
   Hartenfeller M, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002380
   Healy EF, 2010, J MOL GRAPH MODEL, V29, P436, DOI 10.1016/j.jmgm.2010.08.006
   Jozefowicz R., 2016, INT C MACH LEARN
   Kohutek ZA, 2009, J NEUROSCI, V29, P4605, DOI 10.1523/JNEUROSCI.5126-08.2009
   Madoux F, 2016, SCI REP-UK, V6, DOI 10.1038/s41598-016-0013-4
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Olivecrona M, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0235-x
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   RDkit, OP SOURC CHEM SOFTW
   Schneider G, 2005, NAT REV DRUG DISCOV, V4, P649, DOI 10.1038/nrd1799
   Segler MHS, 2018, ACS CENTRAL SCI, V4, P120, DOI 10.1021/acscentsci.7b00512
   Tippmann F, 2009, FASEB J, V23, P1643, DOI 10.1096/fj.08-121392
   Wang YL, 2017, NUCLEIC ACIDS RES, V45, pD955, DOI 10.1093/nar/gkw1118
   Wong WWL, 2009, J CHEMINFORMATICS, V1, DOI 10.1186/1758-2946-1-4
   Woods N, 2015, ONCOTARGET, V6, P35931, DOI 10.18632/oncotarget.5933
   Xue DY, 2019, WIRES COMPUT MOL SCI, V9, DOI 10.1002/wcms.1395
   Zhang YF, 2020, FRONT CHEM, V7, DOI 10.3389/fchem.2019.00895
   Zhou BBS, 2006, CANCER CELL, V10, P39, DOI 10.1016/j.ccr.2006.05.024
NR 28
TC 9
Z9 9
U1 6
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-7439
EI 1873-3239
J9 CHEMOMETR INTELL LAB
JI Chemometrics Intell. Lab. Syst.
PD OCT 15
PY 2020
VL 205
AR 104122
DI 10.1016/j.chemolab.2020.104122
PG 7
WC Automation & Control Systems; Chemistry, Analytical; Computer Science,
   Artificial Intelligence; Instruments & Instrumentation; Mathematics,
   Interdisciplinary Applications; Statistics & Probability
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Chemistry; Computer Science; Instruments &
   Instrumentation; Mathematics
GA NR3RL
UT WOS:000571480800001
DA 2023-11-10
ER

PT J
AU Sen, S
   Hasanuzzaman, M
   Ekbal, A
   Bhattacharyya, P
   Way, A
AF Sen, Sukanta
   Hasanuzzaman, Mohammed
   Ekbal, Asif
   Bhattacharyya, Pushpak
   Way, Andy
TI Neural machine translation of low-resource languages using SMT phrase
   pair injection
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Machine translation; Translation technology
AB Neural machine translation (NMT) has recently shown promising results on publicly available benchmark datasets and is being rapidly adopted in various production systems. However, it requires high-quality large-scale parallel corpus, and it is not always possible to have sufficiently large corpus as it requires time, money, and professionals. Hence, many existing large-scale parallel corpus are limited to the specific languages and domains. In this paper, we propose an effective approach to improve an NMT system in low-resource scenario without using any additional data. Our approach aims at augmenting the original training data by means of parallel phrases extracted from the original training data itself using a statistical machine translation (SMT) system. Our proposed approach is based on the gated recurrent unit (GRU) and transformer networks. We choose the Hindi-English, Hindi-Bengali datasets for Health, Tourism, and Judicial (only for Hindi-English) domains. We train our NMT models for 10 translation directions, each using only 5-23k parallel sentences. Experiments show the improvements in the range of 1.38-15.36 BiLingual Evaluation Understudy points over the baseline systems. Experiments show that transformer models perform better than GRU models in low-resource scenarios. In addition to that, we also find that our proposed method outperforms SMT-which is known to work better than the neural models in low-resource scenarios-for some translation directions. In order to further show the effectiveness of our proposed model, we also employ our approach to another interesting NMT task, for example, old-to-modern English translation, using a tiny parallel corpus of only 2.7K sentences. For this task, we use publicly available old-modern English text which is approximately 1000 years old. Evaluation for this task shows significant improvement over the baseline NMT.
C1 [Sen, Sukanta; Ekbal, Asif; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Patna, Bihar, India.
   [Hasanuzzaman, Mohammed; Way, Andy] Dublin City Univ, ADAPT Ctr, Dublin, Ireland.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System); Dublin City University
RP Sen, S (通讯作者)，Indian Inst Technol Patna, Patna, Bihar, India.
EM sukanta.pcs15@iitp.ac.in
RI Ekbal, Asif/JKI-7638-2023
FU Visvesvaraya PhD scheme for Electronics and IT, Ministry of Electronics
   and Information Technology (MeitY), Government of India
FX Asif Ekbal gratefully acknowledges Young Faculty Research Fellowship,
   supported by Visvesvaraya PhD scheme for Electronics and IT, Ministry of
   Electronics and Information Technology (MeitY), Government of India,
   being implemented by Digital India Corporation (formerly Media Lab
   Asia).
CR [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   Artetxe M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3632
   Arthur P., 2016, P 2016 C EMP METH NA, P1557, DOI DOI 10.18653/V1/D16-1162
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bojar O, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3550
   Chatterjee Rajen, 2016, P WMT, V2, P131, DOI DOI 10.18653/V1/W16-2301
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Crego JM, 2016, ARXIV161005540 CORR
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   Feng Y., 2017, P 2017 C EMP METH NA, P1390, DOI DOI 10.18653/V1/D17-1146
   Forcada ML, 1997, LECT NOTES COMPUT SC, V1240, P453, DOI 10.1007/BFb0032504
   Gulcehre C, 2017, COMPUT SPEECH LANG, V45, P137, DOI 10.1016/j.csl.2017.01.014
   Guzman Francisco, 2019, ARXIV190201382
   He W, 2016, AAAI CONF ARTIF INTE, P151
   Heafield K., 2011, P 6 WORKSH STAT MACH, P187
   Hieber Felix, 2017, ABS171205690 CORR
   Jha GN, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   JunczysDowmunt M., 2016, P 9 INT WORKSH SPOK
   Kalchbrenner N., 2013, P 2013 C EMPIRICAL M, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Kingma D. P., 2014, C TRACK P
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Knight Kevin, 2016, ABS160402201 CORR
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   Koehn P., 2017, WMT, P28
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Kunchukuttan A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3473
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039
   Niehues Jan, 2016, P COLING 2016 26 INT, P1828
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Paszke Adam, 2017, PROC 31 C NEURAL INF, P6
   Ramachandran P, 2017, P 2017 C EMP METH NA, P383, DOI DOI 10.18653/V1/D17-1039
   Ren S, 2019, AAAI CONF ARTIF INTE, P241
   Sennrich R, 2017, P SOFTW DEM 15 C EUR, P65, DOI DOI 10.18653/V1/E17-3017
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Song K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P449
   Sutskever I., 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tang Yaohua, 2016, NEURAL MACHINE TRANS
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang X, 2017, AAAI CONF ARTIF INTE, P3330
   Wang X, 2018, IEEE-ACM T AUDIO SPE, V26, P2255, DOI 10.1109/TASLP.2018.2860287
   Wang XY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P856
   Way A., P INT C COMP LING IN
   Wu Y, 2016, ARXIV
   Zhang ZR, 2018, AAAI CONF ARTIF INTE, P555
   Zhao Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4609
   Zong, 2016, P 2016 C EMP METH NA, P1535, DOI DOI 10.18653/V1/D16-1160
NR 49
TC 10
Z9 10
U1 1
U2 21
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD MAY
PY 2021
VL 27
IS 3
BP 271
EP 292
AR PII S1351324920000303
DI 10.1017/S1351324920000303
PG 22
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA SK5CD
UT WOS:000656232400001
DA 2023-11-10
ER

PT J
AU Malakar, M
   Keskar, RB
   Zadgaonkar, A
AF Malakar, Mousumi
   Keskar, Ravindra B.
   Zadgaonkar, Ajit
TI A hierarchical automatic phoneme recognition model for Hindi-Devanagari
   consonants using machine learning technique
SO EXPERT SYSTEMS
LA English
DT Article
DE automatic phoneme recognition; hierarchical model; machine learning;
   mutual information; speech recognition
ID CLASSIFICATION; FEATURES
AB A phoneme is perceptually the smallest distinct sound unit distinguished among words in a particular language. Every language has its own set of phonemes, and all the words are ordered sequences of phonemes. Therefore, phoneme recognition is essential to automatic speech recognition (ASR) systems. Phonemes of a language can be classified together using a single machine learning (ML) model through the direct classification (also known as the baseline or flat classification) approach. However, it is observed that the performance of such phoneme recognition degrades with the increase in the number of phoneme classes. The challenge is pronounced in languages with a larger number of phoneme classes, like Hindi, which has 48 phonemes. In this paper, we propose a speaker-independent hierarchical classification approach for 33 Hindi-Devanagari consonants/phonemes using cepstral features with ML techniques like support vector machine (SVM), random forest (RF) and fully connected deep neural network (DNN). In this hierarchical approach, a given phoneme is classified into successive subgroups until the particular phoneme class is identified. To perform the classification task, a binary or multi-class classifier is invoked for each internal (non-leaf) node in the hierarchy tree. Our model identified pairs of Optimal Feature Sets (based on mutual information) and the best suitable ML classifier for each internal decision node in the hierarchy using 10-fold cross-validation to help in efficient classification. Our proposed hierarchical model leads to better accuracy and 57% improved performance for phoneme recognition compared with the non-hierarchical, that is, the direct classification approach.
C1 [Malakar, Mousumi; Keskar, Ravindra B.] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Technol, Nagpur, India.
   [Zadgaonkar, Ajit] Speech Markers Pvt Ltd, Pune, India.
   [Malakar, Mousumi] Visvesvaraya Natl Inst Technol, Nagpur, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur; National Institute of Technology (NIT
   System); Visvesvaraya National Institute of Technology, Nagpur
RP Malakar, M (通讯作者)，Visvesvaraya Natl Inst Technol, Nagpur, India.
EM mala.mou@gmail.com
RI Keskar, Ravindra/AAC-9494-2021
OI Keskar, Ravindra/0000-0002-3674-6539; , Mousumi/0000-0003-4410-6715
CR Ali AMA, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, P118, DOI 10.1109/ISCAS.1999.778799
   Anjos I, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12620
   [Anonymous], 2022, PLAC ART
   [Anonymous], 2022, PHON
   [Anonymous], 2022, HINDI
   [Anonymous], 2022, DEV
   [Anonymous], 2011, INT J SIGNAL PROCESS
   [Anonymous], 2022, FEAT SEL
   [Anonymous], 2022, STUDYSMARTER
   ARIKI Y, 1989, ELECTRON LETT, V25, P918, DOI 10.1049/el:19890615
   Azim Mona A., 2021, 2021 Tenth International Conference on Intelligent Computing and Information Systems (ICICIS), P99, DOI 10.1109/ICICIS52592.2021.9694108
   Bhatt S., 2018, HINDI SPEECH VOWEL R, P201
   Bhatt S, 2021, WIRELESS PERS COMMUN, V118, P3303, DOI 10.1007/s11277-021-08181-0
   Bhatt S, 2020, J AMB INTEL HUM COMP, V11, P4213, DOI 10.1007/s12652-020-01703-x
   Clarkson P, 1999, INT CONF ACOUST SPEE, P585, DOI 10.1109/ICASSP.1999.759734
   Defiyanti S., 2019, 2019 5 INT C SCI TEC, P1
   Driaunys K., 2005, Information Technology and Control, V34, P257
   Esposito A., 1999, TRAINING, V2050, P1156
   Fredj I. B., 2014, ENERGY ELECT ENG CEE, V1, P57
   FRY DB, 1958, LANG SPEECH, V1, P35, DOI 10.1177/002383095800100104
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Juneja A, 2003, IEEE IJCNN, P675
   Kaewtip Kantapon, 2019, 2019 23rd International Computer Science and Engineering Conference (ICSEC), P18, DOI 10.1109/ICSEC47112.2019.8974726
   Kaur S., 2014, INT J COMPUTER SCI E, V4, P285
   Koizumi T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P326, DOI 10.1109/ICSLP.1996.607119
   Kuldeep K., 2011, INT J COMPUTING BUSI, V1, P2229
   Kumar M, 2004, IBM J RES DEV, V48, P703, DOI 10.1147/rd.485.0703
   LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546
   Li XJ, 2021, INTERSPEECH, P2461, DOI 10.21437/Interspeech.2021-1803
   Lopes Carla, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1760
   Malakar M., 2021, SPEECH COMMUN
   Malviya Shrikant, 2016, 2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA), P188, DOI 10.1109/ICSDA.2016.7919009
   Meenakshi GN, 2017, INTERSPEECH, P503, DOI 10.21437/Interspeech.2017-1388
   Mori R. D., 1980, SPOKEN LANGUAGE GENE, P191
   Mukherjee Himadri, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P61, DOI 10.1007/978-981-10-7566-7_7
   Myrvoll T. A., 1999, NORSIG 99, P614
   Oh D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010428
   Patil VV, 2016, J PHONETICS, V54, P202, DOI 10.1016/j.wocn.2015.11.001
   Rabiner L., 2007, INTRO DIGITAL SPEECH
   Rao KS, 2015, LANGUAGE IDENTIFICAT
   Samudravijaya K, 1998, SADHANA-ACAD P ENG S, V23, P313, DOI 10.1007/BF02745745
   Scanlon P, 2007, IEEE T AUDIO SPEECH, V15, P803, DOI 10.1109/TASL.2006.885907
   SCHMIDBAUER O, 1993, LANG SPEECH, V36, P331, DOI 10.1177/002383099303600311
   Singhvi A, 2008, INT CONF SIGN PROCES, P571, DOI 10.1109/ICOSP.2008.4697197
   Sinha S, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1953, DOI 10.1109/ICACCI.2013.6637481
   Waibel A., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P107, DOI 10.1109/ICASSP.1988.196523
   Waterhouse S, 1997, ADV NEUR IN, V9, P800
   Yang HH, 2000, SPEECH COMMUN, V31, P35, DOI 10.1016/S0167-6393(00)00007-8
   Zahorian SA, 1997, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.1997.596111
NR 49
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD AUG
PY 2023
VL 40
IS 7
DI 10.1111/exsy.13288
EA MAR 2023
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L1ZA1
UT WOS:000950307900001
OA Bronze
DA 2023-11-10
ER

PT J
AU Zhang, JH
   Huang, B
   Fujita, H
   Zeng, GH
   Liu, J
AF Zhang, Jiahao
   Huang, Bo
   Fujita, Hamido
   Zeng, Guohui
   Liu, Jin
TI FeQA: Fusion and enhancement of multi-source knowledge on question
   answering
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Question answering system; Semantic enhancement; Knowledge graph;
   Knowledge interaction
AB In the question answering task, we usually need to reason the answer according to the question. Question answering tasks mostly use the pretrained language model to obtain the semantic embedding of questions and choices to predict answers, while the pretrained language model cannot accurately represent the potential relationship between entities in the question. Therefore, researchers introduce knowledge graph to realize the reasoning from question entity to answer entity. However, the limitation of knowledge graph lies in the lack of background information of entities, which may lead to wrong reasoning. To solve the above problems, a new question answering system model FeQA is proposed, which adopts large-scale pretrained language model and knowledge graph. The former uses dual-attention mechanism to enhance the semantics of questions by using Wiktionary and other question answering datasets, while the latter uses graph neural network to infer entities. During the interaction of two modal knowledge, the former provides the basis for the reasoning of nodes in the latter, and the latter provides structured knowledge for the former. After several reasoning iterations, the final answer is obtained by using the knowledge of the two modes. The experimental results on the CommonsenseQA and OpenBookQA datasets show that the performance of this model is better than that of the baseline models. Ablation experiments show that the components and knowledge sources included in this model play an important role in the effect of question and answering task. Extended experiments show the model has good application capability.
C1 [Zhang, Jiahao; Huang, Bo; Zeng, Guohui; Liu, Jin] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201600, Peoples R China.
   [Fujita, Hamido] HUTECH Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Fujita, Hamido] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Kuala Lumpur, Malaysia.
   [Fujita, Hamido] Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Granada, Spain.
   [Fujita, Hamido] Iwate Prefectural Univ, Iwate, Japan.
C3 Shanghai University of Engineering Science; Ho Chi Minh City University
   of Technology (HUTECH); Vietnam National University Hochiminh City;
   Universiti Teknologi Malaysia; University of Granada; Iwate Prefectural
   University
RP Fujita, H (通讯作者)，Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Kuala Lumpur, Malaysia.
EM TracyQAQ@126.com; huangbosues@sues.edu.cn; h.fujita@hutech.edu.vn;
   zenggh@sues.edu.cn; liujin@sues.edu.cn
RI Fujita, Hamido/D-6249-2012
OI Fujita, Hamido/0000-0001-5256-210X; Huang, Bo/0000-0002-5476-620X
FU Scientific and Technological Innovation 2030 - Major Project of New
   Generation Artificial Intelligence [2020AAA0109300]; Shanghai Science
   and Technology Young Talents Sailing Program [19YF1418400]; National
   Natural Science Foundation of China [62006150]; Shanghai Science and
   Technology Innovation Action Plan [22S31903700, 21S31904200]; Songjiang
   District Science and Technology Research Project [19SJKJGG83]; Shanghai
   Local Capacity Enhancement Project [21010501500]
FX This work is sponsored by the Scientific and Technological Innovation
   2030 - Major Project of New Generation Artificial Intelligence (No.
   2020AAA0109300), Shanghai Science and Technology Young Talents Sailing
   Program (No. 19YF1418400), National Natural Science Foundation of China
   (No. 62006150), Shanghai Science and Technology Innovation Action Plan
   (22S31903700, 21S31904200), Songjiang District Science and Technology
   Research Project (No. 19SJKJGG83), and Shanghai Local Capacity
   Enhancement Project (No. 21010501500).
CR Alon T., 2019, ABS181100937
   Cao X, 2023, APPL INTELL, V53, P12032, DOI 10.1007/s10489-022-04123-w
   Chen QL, 2020, Arxiv, DOI arXiv:2011.02705
   Fang YW, 2020, Arxiv, DOI arXiv:1911.03631
   Feng YL, 2020, Arxiv, DOI arXiv:2005.00646
   Huang Z., 2022, ARXIV
   Jiao J, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107270
   Jiao S., 2022, APPL INTELL, P1
   Kim E, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117405
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Lv SW, 2020, AAAI CONF ARTIF INTE, V34, P8449
   Macdonald C., 2021, CIKM 21 30 ACM INT C, P4526, DOI [10.1145/3459637.3482013, DOI 10.1145/3459637.3482013]
   Mao YN, 2021, Arxiv, DOI arXiv:2009.08553
   Mihaylov T, 2018, Arxiv, DOI arXiv:1809.02789
   Nassiri K, 2023, APPL INTELL, V53, P10602, DOI 10.1007/s10489-022-04052-8
   Rodriguez-Torrealba R, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118258
   Santoro A, 2017, ADV NEUR IN, V30
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Sun HT, 2019, Arxiv, DOI arXiv:1904.09537
   Sun HT, 2018, Arxiv, DOI arXiv:1809.00782
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic P, 2018, P 6 INT C LEARN REPR
   Wang XY, 2019, AAAI CONF ARTIF INTE, P7208
   Wu WQ, 2021, APPL INTELL, V51, P4515, DOI 10.1007/s10489-020-02111-6
   Xiong HB, 2021, KNOWL-BASED SYST, V221, DOI 10.1016/j.knosys.2021.106954
   Xu Y., 2021, HUMAN PARITY COMMONS
   Xu YC, 2021, Arxiv, DOI arXiv:2012.04808
   Yamada I., 2021, ARXIV
   Yao YZ, 2022, LECT NOTES ARTIF INT, V13551, P131, DOI 10.1007/978-3-031-17120-8_11
   Yasunaga M, 2021, Arxiv, DOI arXiv:2104.06378
   Lin BY, 2019, Arxiv, DOI arXiv:1909.02151
   Zhang X., 2022, INT C LEARNING REPRE
NR 33
TC 0
Z9 0
U1 16
U2 16
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD OCT 1
PY 2023
VL 227
AR 120286
DI 10.1016/j.eswa.2023.120286
EA MAY 2023
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA I2TC0
UT WOS:001001348500001
DA 2023-11-10
ER

PT J
AU Deng, HL
   Zhang, L
   Shu, X
AF Deng, Hongli
   Zhang, Lei
   Shu, Xin
TI Feature memory-based deep recurrent neural network for language modeling
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Memory and attention; Recurrent neural network; Deep learning; Language
   modeling
AB Recently, deep recurrent neural networks (DRNNs) have been widely proposed for language modeling. DRNNs can learn higher-level features of input data by stacking multiple recurrent layers, making them achieve better performance than single-layer models. However, due to their simple linear stacking patterns, the gradient information vanishes when it is backward propagated through too many layers. As a result, DRNNs become hard to train and their performance degrades rapidly with the number of recurrent layers increasing. To address this problem, the feature memory-based deep recurrent neural network (FMDRNN) is proposed in this paper. FMDRNN presents a new stacking pattern by introducing a special feature memory module (FM), which makes the hidden units of each layer can see and reuse all the features generated by preceding stacked layers, not just the feature from previous layer as in DRNNs. FM is like a traffic hub to provide direct connections between each two layers, and the attention network in FM controls the switch of these connections. These direct connections enable FMDRNN can alleviate the vanishing of gradient in the process of backward propagation and also make the learned features do not wash away when they reach the end of the network. FMDRNN is evaluated by performing extensive experiments on the widely used English Penn Treebank dataset and five more complex non-English language corpora. The experimental results show that FMDRNN can be effectively trained even if a larger number of layers are stacked, so that it benefits from deeper networks instead of degrading performance, and consistently achieves markedly better results than other models through deeper but thinner network. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Deng, Hongli; Zhang, Lei; Shu, Xin] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Sichuan, Peoples R China.
   [Deng, Hongli] China West Normal Univ, Educ & Informat Technol Ctr, Nanchong 637002, Peoples R China.
C3 Sichuan University; China West Normal University
RP Zhang, L (通讯作者)，Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Sichuan, Peoples R China.
EM hongli_deng@foxmail.com; leizhang@scu.edu.cn; shuxin@stu.scu.edu.cn
FU National Key R&D Program of China [2016YFC0801800]; National Natural
   Science Foundation of China [61332002, 61772353]; Fok Ying Tung
   Education Foundation [151068]
FX This work was supported by National Key R&D Program of China (grant
   2016YFC0801800); National Natural Science Foundation of China (grants
   61332002, 61772353); Fok Ying Tung Education Foundation (grant 151068).
CR [Anonymous], 2013, COMPUT SCI
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Brown PF., 1997, COMPUT LINGUIST, V18, P467
   Deng H., 2017, NEURAL COMPUT APPL
   Doetseh P, 2014, INT CONF FRONT HAND, P279, DOI 10.1109/ICFHR.2014.54
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Fan H., 2016, ARXIV161106878
   Federico M, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P240, DOI 10.1109/ICSLP.1996.607087
   Gal Y., 2016, ADV NEURAL INFORM PR, V29, P1019, DOI [DOI 10.48550/ARXIV.1512.05287, 10.48550/arXiv.1512.05287]
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Graves A., 2010, NEURAL NETWORKS, V18, P867
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hermans M., 2013, ADV NEURAL INFORM PR
   Irsoy O., 2014, P C EMP METH NAT LAN, P720, DOI DOI 10.3115/V1/D14-1080
   Jaeger H., 2016, 148 GMD GERM NAT RES, V34
   Jordan M., 1986, TECHNICAL REPORT
   Kim Y., 2015, ARXIV150806615
   Kneser R, 1995, IMPROVED BACKING OFF
   LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L
   Liu X, 2015, INT CONF ACOUST SPEE, P5406, DOI 10.1109/ICASSP.2015.7179004
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Niesler TR, 1996, INT CONF ACOUST SPEE, P164, DOI 10.1109/ICASSP.1996.540316
   PINEDA FJ, 1987, PHYS REV LETT, V59, P2229, DOI 10.1103/PhysRevLett.59.2229
   Press O., 2016, ARXIV160805859
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sak H, 2014, INTERSPEECH, P338
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Wang LT, 2017, IEEE T CYBERNETICS, V47, P3172, DOI 10.1109/TCYB.2017.2705345
   Williams R.J., 1995, BACK PROPAGATION THE, V433, P17
   Yamamoto H., 2003, Systems and Computers in Japan, V34, P108, DOI 10.1002/scj.1210
   Zaremba Wojciech, 2014, ARXIV14092329
   Zhang L, 2008, IEEE T NEURAL NETWOR, V19, P158, DOI 10.1109/TNN.2007.904015
   Zhang L, 2011, IEEE T NEURAL NETWOR, V22, P1021, DOI 10.1109/TNN.2011.2132762
   Zhang L, 2009, IEEE T AUTOMAT CONTR, V54, P1341, DOI 10.1109/TAC.2009.2015552
NR 42
TC 21
Z9 22
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUL
PY 2018
VL 68
BP 432
EP 446
DI 10.1016/j.asoc.2018.03.040
PG 15
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GH1HZ
UT WOS:000433155300030
DA 2023-11-10
ER

PT J
AU Mairesse, F
   Walker, MA
AF Mairesse, Francois
   Walker, Marilyn A.
TI Controlling User Perceptions of Linguistic Style: Trainable Generation
   of Personality Traits
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID LANGUAGE; ADAPTATION; SELF
AB Recent work in natural language generation has begun to take linguistic variation into account, developing algorithms that are capable of modifying the system's linguistic style based either on the user's linguistic style or other factors, such as personality or politeness. While stylistic control has traditionally relied on handcrafted rules, statistical methods are likely to be needed for generation systems to scale to the production of the large range of variation observed in human dialogues. Previous work on statistical natural language generation (SNLG) has shown that the grammaticality and naturalness of generated utterances can be optimized from data; however these data-driven methods have not been shown to produce stylistic variation that is perceived by humans in the way that the system intended. This paper describes PERSONAGE, a highly parameterizable language generator whose parameters are based on psychological findings about the linguistic reflexes of personality. We present a novel SNLG method which uses parameter estimation models trained on personality-annotated data to predict the generation decisions required to convey any combination of scalar values along the five main dimensions of personality. A human evaluation shows that parameter estimation models produce recognizable stylistic variation along multiple dimensions, on a continuous scale, and without the computational cost incurred by overgeneration techniques.
C1 [Mairesse, Francois] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
   [Walker, Marilyn A.] Univ Calif Santa Cruz, Baskin Sch Engn, Santa Cruz, CA 95064 USA.
   [Mairesse, Francois] Univ Sheffield, Sheffield S10 2TN, S Yorkshire, England.
C3 University of Cambridge; University of California System; University of
   California Santa Cruz; University of Sheffield
RP Mairesse, F (通讯作者)，Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.
EM f.mairesse@eng.cam.ac.uk; maw@soe.ucsc.edu
FU Royal Society; Vice Chancellor's studentship
FX This work was funded by a Royal Society Wolfson Research Merit
   Fellowship to Marilyn Walker and a Vice Chancellor's studentship to
   Francois Mairesse. Thanks to Chris Mellish, Donia Scott, Rob Gaizauskas,
   and Roger Moore for detailed comments on earlier versions of this work.
CR André E, 2000, EMBODIED CONVERSATIONAL AGENTS, P220
   [Anonymous], 2004, ACM ASS COMPUTATIONA
   [Anonymous], HDB LANGUAGE SOCIAL
   [Anonymous], P 9 INT WORKSH NAT L
   [Anonymous], P EMNLP 2004
   [Anonymous], INT J ARTIFICIAL INT
   Bangalore Srinivas, 2000, P 18 INT C COMP LING, P42
   Barzilay R, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P164
   Belz Anja, 2008, Natural Language Engineering, V14, P431, DOI 10.1017/S1351324907004664
   BELZ A, 2005, P 3 CORP LING C BIRM
   Biber Douglas., 1988, VARIATION SPEECH WRI
   Bouayad-Agha N, 2000, INFORM DESIGN J, V9, P161
   Brennan SE, 1996, J EXP PSYCHOL LEARN, V22, P1482, DOI 10.1037/0278-7393.22.6.1482
   Cassell J, 2003, USER MODEL USER-ADAP, V13, P89, DOI 10.1023/A:1024026532471
   Chambers Nathanael, 2004, P SIGDIAL CAMBR MASS, P9
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Costa P. T., 1992, REVISED NEO PERSONAL
   Daume III Hal, 2007, P 45 ANN M ASS COMP, P256, DOI DOI 10.48550/ARXIV.0907.1815
   Dunbar R. I. M., 1996, GROOMING GOSSIP EVOL
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Funder D.C., 1997, PERSONALITY PUZZLE
   Goffman E., 1970, STRATEGIC INTERACTIO
   GOLDBERG LR, 1990, J PERS SOC PSYCHOL, V59, P1216, DOI 10.1037/0022-3514.59.6.1216
   Gosling S. D., 2007, P INT C WEBL SOC MED
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   GREEN SJ, 1996, LECT NOTES ARTIF INT, V1036, P125
   HIGASHINAKA R, 2007, ACM T SPEECH LANG PR, V4
   Hovy E. H., 1988, GENERATING NATURAL L
   INKPEN DZ, 2004, RECENT ADV NATURAL L, V3, P141
   Isard Amy, 2006, P 4 INT NAT LANG GEN, P22
   John O. P., 1991, BIG 5 INVENTORY VERS, DOI [DOI 10.1037/T07550-000, 10.1037/t07550-000]
   Jordan P. W., 2000, THESIS U PITTSBURGH
   Kittredge R., 1991, Computational Intelligence, V7, P305, DOI 10.1111/j.1467-8640.1991.tb00403.x
   Labov W., 2006, SOCIAL STRATIFICATIO
   LANGKILDE I, 1998, P 36 ANN M ASS COMP, P704
   Langkilde-Geary Irene, 2002, P INT C NAT LANG GEN, P17
   Lavoie Benoit, 1997, P 5 C APPL NAT LANG, P265
   Lester JC, 1999, USER MODEL USER-ADAP, V9, P1, DOI 10.1023/A:1008374607830
   LEVELT WJM, 1982, COGNITIVE PSYCHOL, V14, P78, DOI 10.1016/0010-0285(82)90005-6
   Litman DJ, 2006, SPEECH COMMUN, V48, P559, DOI 10.1016/j.specom.2005.09.008
   MAIRESSE F, 2008, THESIS U SHEFFIELD
   Mairesse F, 2007, P 45 ANN M ASS COMP, P496
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Mairesse F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1552
   Mairesse F, 2010, USER MODEL USER-ADAP, V20, P227, DOI 10.1007/s11257-010-9076-2
   Marcus DK, 2006, PSYCHOL MED, V36, P1571, DOI 10.1017/S0033291706008245
   McQuiggan SW, 2008, USER MODEL USER-ADAP, V18, P81, DOI 10.1007/s11257-007-9040-y
   Mehl MR, 2006, J PERS SOC PSYCHOL, V90, P862, DOI 10.1037/0022-3514.90.5.862
   Nakatsu C, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P1113
   Narayanan Shrikanth, 1998, P 36 ANN M ASS COMP, P1345
   NORMAN WT, 1963, J ABNORM PSYCHOL, V66, P574, DOI 10.1037/h0040291
   Paiva D.S., 2005, P 43 ANN M ASS COMPU, P58, DOI 10.3115/1219840.1219848
   PAIVA DS, 2004, P INT C NAT LANG GEN, P120
   PARIS C, 1994, P 7 INT WORKSH NAT L, P45
   Pennebaker J. W., 2001, INQUIRY WORD COUNT L
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   PIWEK P, 2003, P ANN M EUR CHAPT AS, P151
   POLLACK ME, 1991, NOUS, V25, P513, DOI 10.2307/2216076
   PORAYSKAPOMSTA K, 2004, P INT C NAT LANG GEN, P141
   POWER R, 2003, P 4 INT C INT TEXT P, P444
   Rambow O, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P426
   Reiter E., 2000, BUILDING NATURAL LAN, P41
   Scherer KR., 1979, SOCIAL MARKERS SPEEC, P147
   Scott D. R., 1990, Current Research in Natural Language Generation, P47
   Singh S, 2002, J ARTIF INTELL RES, V16, P105, DOI 10.1613/jair.859
   Snyder B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1713
   Srivastava S, 2010, J PERS SOC PSYCHOL, V98, P520, DOI 10.1037/a0017057
   STENT A, 2005, P EUROIMSA GRIND
   STENT A, 2004, P 42 ANN M ASS COMP, P79, DOI DOI 10.3115/1218955.1218966
   Tapus A., 2008, P AAAI SPRING S STAN, P133
   VOGEL K, 1986, IRAL-INT REV APPL LI, V24, P48
   Walker M. A., 1997, Proceedings of the First International Conference on Autonomous Agents, P96, DOI 10.1145/267658.267680
   Walker M.A., 1993, THESIS U PENNSYLVANI
   Walker MA, 2002, COMPUT SPEECH LANG, V16, P409, DOI 10.1016/S0885-2308(02)00027-X
   Walker MA, 2002, COMPUT SPEECH LANG, V16, P273, DOI 10.1016/S0885-2308(02)00029-3
   Walker M, 2007, J ARTIF INTELL RES, V30, P413, DOI 10.1613/jair.2329
   Wang N, 2005, FRONT ARTIF INTEL AP, V125, P686
   White Michael, 2007, P WORKSH US CORP NLG, P22
   Witten I. H., 2005, DATA MINING PRACTICA, V2nd
NR 81
TC 59
Z9 59
U1 2
U2 19
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD SEP
PY 2011
VL 37
IS 3
BP 455
EP 488
DI 10.1162/COLI_a_00063
PG 34
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA 812LO
UT WOS:000294295200002
OA hybrid
DA 2023-11-10
ER

PT J
AU Shi, SM
   Wu, X
   Su, RH
   Huang, HY
AF Shi, Shumin
   Wu, Xing
   Su, Rihai
   Huang, Heyan
TI Low-resource Neural Machine Translation: Methods and Trends
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Low-resource; neural machine translation; semi-supervised; unsupervised;
   transfer learning; pivot-based methods; data augmentation
ID NETWORK; ZERO
AB Neural Machine Translation (NMT) brings promising improvements in translation quality, but until recently, these models rely on large-scale parallel corpora. As such corpora only exist on a handful of language pairs, the translation performance is far from the desired effect in the majority of low-resource languages. Thus, developing low-resource language translation techniques is crucial and it has become a popular research field in neural machine translation. In this article, we make an overall review of existing deep learning techniques in low-resource NMT. We first show the research status as well as some widely used low-resource datasets. Then, we categorize the existing methods and show some representative works detailedly. Finally, we summarize the common characters among them and outline the future directions in this field.
C1 [Shi, Shumin; Wu, Xing; Su, Rihai; Huang, Heyan] Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing 100089, Peoples R China.
C3 Beijing Institute of Technology
RP Shi, SM (通讯作者)，Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing 100089, Peoples R China.
EM bjssm@bit.edu.cn; wuxing@bit.edu.cn; surihai@bit.edu.cn;
   hhy63@bit.edu.cn
OI Shi, Shumin/0000-0003-3436-7575
FU National Natural Science Foundation of China [61671064, 61732005]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61671064, 61732005).
CR Artetxe M, 2020, Arxiv, DOI arXiv:2004.04721
   Artetxe M, 2018, Arxiv, DOI arXiv:1710.11041
   Artetxe M, 2019, Arxiv, DOI arXiv:1902.01313
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, P65, DOI DOI 10.3115/1626355.1626389
   Bertoldi N., 2009, P 4 WORKSHOP STAT MA, P182
   Bojar O., 2011, P 6 WORKSHOP STAT MA, P330
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Bugliarello E, 2020, Arxiv, DOI arXiv:1909.03149
   Carbonell J., 2006, P 7 C ASS MACH TRANS, P19
   Caswell I, 2019, Arxiv, DOI arXiv:1906.06442
   Chen Y, 2017, Arxiv, DOI arXiv:1705.00753
   Chen Y, 2018, AAAI CONF ARTIF INTE, P5086
   Cheng Y., 2019, JOINT TRAINING NEURA, P25, DOI DOI 10.1007/978-981-32-9748-7_3
   Cheng Y, 2019, JOINT TRAINING NEURA, P41, DOI DOI 10.1007/978-981-32-9748-7_4
   Chiang D, 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chimalamarri S, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3390298
   Chronopoulou A, 2020, Arxiv, DOI arXiv:2009.07610
   Collins M., 2005, P 43 ANN M ASS COMP, V43, P531, DOI DOI 10.3115/1219840.1219906
   Cotterell R, 2018, Arxiv, DOI arXiv:1806.04402
   Currey A, 2017, P 2 C MACH TRANSL, P148, DOI DOI 10.18653/V1/W17-4715
   Currey A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P24
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dou Qing, 2012, P 2012 JOINT C EMP M, P266
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, DOI 10.48550/ARXIV.1802.05365]
   Edunov S, 2018, Arxiv, DOI arXiv:1808.09381
   El Kholy Ahmed, 2013, P 51 ANN M ASS COMPU, V2, P412
   Fadaee M, 2018, Arxiv, DOI arXiv:1808.09006
   Fadaee M, 2017, Arxiv, DOI arXiv:1705.00440
   Farajian M. A., 2017, P 2 C MACHINE TRANSL, P127
   Firat O, 2016, Arxiv, DOI arXiv:1606.04164
   Fujita A., 2020, P 58 ANN M ASS COMP, P5990, DOI DOI 10.18653/V1/2020.ACL-MAIN.532
   Gal Y, 2016, ADV NEUR IN, V29
   Ganin Y, 2017, ADV COMPUT VIS PATT, P189, DOI 10.1007/978-3-319-58347-1_10
   Gao F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5539
   Gibadullin Ilshat, 2019, ARXIV
   Gu JT, 2018, Arxiv, DOI arXiv:1802.05368
   Gu Jiatao, 2018, Arxiv, DOI arXiv:1808.08437
   Gulcehre C, 2015, Arxiv, DOI arXiv:1503.03535
   Guo JL, 2019, AAAI CONF ARTIF INTE, P3723
   Guzman F, 2019, Arxiv, DOI arXiv:1902.01382
   He D, 2016, ADV NEUR IN, V29
   Imankulova A, 2019, Arxiv, DOI arXiv:1907.03060
   Imankulova A, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3341726
   Irvine A., 2014, P 18 C COMPUTATIONAL, P160
   Irvine A, 2016, NAT LANG ENG, V22, P517, DOI 10.1017/S1351324916000127
   Irvine Ann, 2013, P 8 WORKSHOP STAT MA, P262
   Isozaki Hideki, 2010, P JOINT 5 WORKSHOP S, P244
   Ji BJ, 2020, AAAI CONF ARTIF INTE, V34, P115
   Johnson Melvin, 2017, T ASSOC COMPUT LING, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Karakanta A, 2018, MACH TRANSL, V32, P167, DOI 10.1007/s10590-017-9203-5
   Khayrallah H, 2020, Arxiv, DOI arXiv:2004.14524
   Kim Y, 2019, Arxiv, DOI arXiv:1905.05475
   Kim Y, 2019, Arxiv, DOI arXiv:1909.09524
   Kim Y, 2019, Arxiv, DOI arXiv:1901.01590
   Klementiev A., 2012, P 13 C EUR CHAPT ASS, P130
   Kocmi T., 2018, ARXIV
   Koehn P., 2003, STAT PHRASE BASED TR
   Lample G, 2018, Arxiv, DOI arXiv:1711.00043
   Lample G, 2018, Arxiv, DOI arXiv:1804.07755
   Lee Jason, 2017, T ASSOC COMPUT LING, V5, P365, DOI 10.1162/tacl_a_00067
   Leng YC, 2019, Arxiv, DOI arXiv:1906.02461
   Li GL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5689
   Li RM, 2020, AAAI CONF ARTIF INTE, V34, P8245, DOI 10.1609/aaai.v34i05.6339
   Li Xiaoqing, 2016, ARXIV
   Liu D, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2019), P39, DOI 10.1109/ICMCCE48743.2019.00017
   Liu ZH, 2021, Arxiv, DOI arXiv:2105.03953
   Luo GX, 2019, IEEE ACCESS, V7, P154157, DOI 10.1109/ACCESS.2019.2936002
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Lakew SM, 2018, Arxiv, DOI arXiv:1811.01137
   Maimaiti M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3464427
   Maimaiti M, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3314945
   Nakayama H, 2017, MACH TRANSL, V31, P49, DOI 10.1007/s10590-017-9197-z
   Nguyen XP, 2020, Arxiv, DOI arXiv:1911.01986
   Pan BY, 2019, Arxiv, DOI arXiv:1908.01816
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Paul Michael, 2013, ACM Transactions on Asian Language Information Processing, V12, DOI 10.1145/2505126
   Pham H, 2021, Arxiv, DOI arXiv:2102.07847
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.1080/1472586x.2015.1113070.
   Pourdamghani N, 2019, Arxiv, DOI arXiv:1906.05683
   Pourdamghani Nima, 2017, P 2017 C EMP METH NA, P2513, DOI DOI 10.18653/V1/D17-1266
   Nguyen TQ, 2017, Arxiv, DOI arXiv:1708.09803
   Radford A, 2019, LANGUAGE MODELS ARE, DOI DOI 10.1109/CVPRW.2017.228
   Ravi Sujith, 2011, P 49 ANN M ASS COMP, P12
   Ren S, 2018, Arxiv, DOI arXiv:1805.04813
   Ren S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3498
   Ren Shuo, 2019, ARXIV
   Shavarani HS, 2021, Arxiv, DOI arXiv:2104.02831
   Sen S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3083
   Sennrich R, 2019, Arxiv, DOI arXiv:1905.11901
   Sennrich R, 2016, Arxiv, DOI arXiv:1606.02891
   Sennrich R, 2016, Arxiv, DOI arXiv:1511.06709
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, P223
   Sun HP, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1235
   Sutskever I, 2014, Arxiv, DOI arXiv:1409.3215
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Hoang VCD, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P18
   Wang Rui, 2021, ARXIV
   Wang XY, 2018, Arxiv, DOI arXiv:1808.07512
   Wei HR, 2020, Arxiv, DOI arXiv:2010.02473
   Weng RX, 2019, Arxiv, DOI arXiv:1908.07688
   Weng RX, 2020, AAAI CONF ARTIF INTE, V34, P9266
   Wu JW, 2019, Arxiv, DOI arXiv:1904.02331
   Xia YC, 2016, Arxiv, DOI arXiv:1611.00179
   Xie Z, 2017, Arxiv, DOI arXiv:1703.02573
   Xu JT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1580
   Yang Z, 2018, Arxiv, DOI arXiv:1804.09057
   Zahabi S. T., 2013, P 51 ANN M ASS COMPU, P318
   Zhang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1959, DOI 10.18653/v1/P17-1179
   Zheng H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4251
   Zheng Zaixiang, 2019, P INT C LEARNING REP
   Zhou CT, 2019, Arxiv, DOI arXiv:1909.00040
   Zong, 2016, P 2016 C EMP METH NA, P1535, DOI DOI 10.18653/V1/D16-1160
   Zoph B, 2016, Arxiv, DOI arXiv:1604.02201
NR 116
TC 0
Z9 0
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP
PY 2022
VL 21
IS 5
AR 103
DI 10.1145/3524300
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9Z2DN
UT WOS:000950956700019
DA 2023-11-10
ER

PT J
AU Costa, F
   Frasconi, P
   Lombardo, V
   Sturt, P
   Soda, G
AF Costa, F
   Frasconi, P
   Lombardo, V
   Sturt, P
   Soda, G
TI Ambiguity resolution analysis in incremental parsing of natural language
SO IEEE TRANSACTIONS ON NEURAL NETWORKS
LA English
DT Article
DE first-pass attachment; incremental parsing; learning preferences;
   recursive neural networks (RNNs); structured data
ID ATTACHMENT; MODEL
AB Incremental parsing gains its importance in natural language processing and psycholinguistics because of its cognitive plausibility. Modeling the associated cognitive data structures, and their dynamics, can lead to a better understanding of the human parser. In earlier work, we have introduced a recursive neural network (RNN) capable of performing syntactic ambiguity resolution in incremental parsing. In this paper, we report a systematic analysis of the behavior of the network that allows us to gain important insights about the kind of information that is exploited to resolve different forms of ambiguity. In attachment ambiguities, in which a new phrase can be attached at more than one point in the syntactic left context, we found that learning from examples allows us to predict the location of the attachment point with high accuracy, while the discrimination amongst alternative syntactic structures with the same attachment point is slightly better than making a decision purely based on frequencies. We also introduce several new ideas to enhance the architectural design, obtaining significant improvements of prediction accuracy, up to 25% error reduction on the same dataset used in previous work. Finally, we report large scale experiments on the entire Wall Street Journal section of the Penn Treebank. The best prediction accuracy of the model on this large dataset is 87.6%, a relative error reduction larger than 50% compared to previous results.
C1 Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy.
   Univ Turin, Dipartimento Informat, I-10149 Turin, Italy.
   Univ Glasgow, Human Commun Res Ctr, Glasgow G12 8QB, Lanark, Scotland.
C3 University of Florence; University of Turin; University of Glasgow
RP Costa, F (通讯作者)，Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy.
EM costa@dsi.unifi.it; paolo@dsi.unifi.it; vincenzo@di.unito.it;
   patrick@psy.gla.ac.uk; giovanni@dsi.unifi.it
RI Lombardo, Vincenzo/ABE-2078-2021; Costa, Fabrizio/AAW-5379-2020;
   Frasconi, Paolo/G-2944-2010; Costa, Fabrizio/J-5014-2012; Sturt,
   Patrick/E-8496-2010
OI Costa, Fabrizio/0000-0002-4900-995X; Costa,
   Fabrizio/0000-0002-4900-995X; Sturt, Patrick/0000-0002-2055-6933;
   Lombardo, Vincenzo/0000-0002-8166-9827
CR ALTMANN G, 1988, COGNITION, V30, P191, DOI 10.1016/0010-0277(88)90020-0
   [Anonymous], 1999, P 37 ANN M ASS COMP
   Bader M., 1994, PERSPECTIVES SENTENC
   BRILL E, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P152, DOI 10.3115/974499.974526
   CHARNIAK E, 1996, CS9637 BROWN U DEPT
   Chomsky N, 1977, ESSAYS FORM INTERPRE
   COHEN WW, 1998, ADV NEURAL INFORMATI, V10
   Collins M, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P16
   COLLINS M, 2002, ADV NEURAL INFORMATI, V14
   COLLINS M, 1996, P 34 ANN M ASS COMP, P184, DOI DOI 10.3115/981863.981888
   Costa F, 2003, APPL INTELL, V19, P9, DOI 10.1023/A:1023860521975
   CUETOS F, 1988, COGNITION, V30, P73, DOI 10.1016/0010-0277(88)90004-2
   Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151
   Frazier L., 1978, THESIS U CONNECTICUT
   Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916
   HEAPS J, 1978, INFORMATION RETRIEVA
   Henderson J, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P131
   Jain AN, 1991, NEURAL COMPUT, V3, P110, DOI 10.1162/neco.1991.3.1.110
   Kamide Y, 1999, LANG COGNITIVE PROC, V14, P631, DOI 10.1080/016909699386211
   KEMKE C, 2002, P 15 C CAN SOC COMP, V2338, P310
   Lane PCR, 2001, IEEE T KNOWL DATA EN, V13, P219, DOI 10.1109/69.917562
   Lombardo V, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P448
   LOMBARDO V, 1999, LEXICAL REPRESENTION
   LOMBARDO V, 2002, P 6 INT WORKSH TREE, P101
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   MIIKULAINEN R, 1993, SUBSYMBOLIC NATURAL
   MILWARD D, 1994, LING PHILOS, V17
   MITCHELL DC, 1995, J PSYCHOLING RES, V24
   Pickering MJ, 1998, J EXP PSYCHOL LEARN, V24, P940, DOI 10.1037/0278-7393.24.4.940
   Sharkey A., 1996, COMBINING ARTIFICIAL
   SPERDUTI A, 1997, IEEE T NEURAL NETW, V8
   STABLER EP, 1994, UNPUB PARSING INCREM
   STEVENSON S, 1994, J PSYCHOLINGUIST RES, V23, P295, DOI 10.1007/BF02145044
   Sturt P, 2003, COGNITION, V88, P133, DOI 10.1016/S0010-0277(03)00026-X
   THOMPSON H, 1991, P 29 M ASS COMP LING, P87
   Vosse T, 2000, COGNITION, V75, P105, DOI 10.1016/S0010-0277(00)00063-9
   Wermter S, 1997, J ARTIF INTELL RES, V6, P35, DOI 10.1613/jair.282
   WILSON WM, 1973, NATURE, V244, P522, DOI 10.1038/244522a0
   ZHOU D, 2004, ADV NEURAL INFORMATI, V16
NR 39
TC 5
Z9 5
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1045-9227
EI 1941-0093
J9 IEEE T NEURAL NETWOR
JI IEEE Trans. Neural Netw.
PD JUL
PY 2005
VL 16
IS 4
BP 959
EP 971
DI 10.1109/TNN.2005.849837
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA 945MC
UT WOS:000230505600016
PM 16121736
DA 2023-11-10
ER

PT J
AU Zheng, BY
   Xia, P
   Yarmohammadi, M
   Van Durme, B
AF Zheng, Boyuan
   Xia, Patrick
   Yarmohammadi, Mahsa
   Van Durme, Benjamin
TI Multilingual Coreference Resolution in Multiparty Dialogue
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Existing multiparty dialogue datasets for entity coreference resolution are nascent, and many challenges are still unaddressed. We create a large-scale dataset, Multilingual Multiparty Coref (MMC), for this task based on TV transcripts. Due to the availability of gold-quality subtitles in multiple languages, we propose reusing the annotations to create silver coreference resolution data in other languages (Chinese and Farsi) via annotation projection. On the gold (English) data, off-the-shelf models perform relatively poorly on MMC, suggesting that MMC has broader coverage of multiparty coreference than prior datasets. On the silver data, we find success both using it for data augmentation and training from scratch, which effectively simulates the zero-shot cross-lingual setting.
C1 [Zheng, Boyuan; Yarmohammadi, Mahsa; Van Durme, Benjamin] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Xia, Patrick] Microsoft Semant Machines, Berkeley, CA USA.
   [Xia, Patrick] JHU HLTCOE, Baltimore, MD USA.
C3 Johns Hopkins University
RP Zheng, BY (通讯作者)，Johns Hopkins Univ, Baltimore, MD 21218 USA.
EM bzheng12@jhu.edu; mahsa@jhu.edu; vandurme@jhu.edu
FU JHU + Amazon Initiative for Interactive AI(AI2AI); DARPAAIDA
   [FA8750-18-2-0015]; IARPA BETTER [201919051600005]
FX We thank Michelle Fashandi and other linguistsat HLTCOE, along with
   Chenyu Zhang andKate Sanders, for their annotation efforts. Wethank
   Elias Stengel-Eskin, Kate Sanders, andShabnam Behzad for helpful
   comments and feed-back and Chandler May for help in buildingthe
   annotation interface. The third author acknowledges support through a
   fellowship fromJHU + Amazon Initiative for Interactive AI(AI2AI). This
   work was supported by DARPAAIDA (FA8750-18-2-0015) and IARPA
   BETTER(201919051600005). The views and conclusionscontained in this work
   are those of the authorsand should not be interpreted as necessarily
   rep-resenting the official policies, either expressed orimplied, or
   endorsements of DARPA or the U.S.Government. The U.S. Government is
   authorizedto reproduce and distribute reprints for govern-mental
   purposes notwithstanding any copyrightannotation therein.
CR Abadji Julien., 2022, CLEANER DOCUMENT ORI, parXiv:2201.06642
   Akbik A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P397
   Aminian Maryam., 2019, P 13 INT C COMPUTATI, P200, DOI [10.18653/v1/W19-0417, DOI 10.18653/V1/W19-0417]
   [Anonymous], 2006, 11 C EUROPEAN CHAPTE
   [Anonymous], 2015, P 2015 C EMPIRICAL M
   Asher N, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2721
   Bagga Amit, 1998, P 1 INT C LANG RES E, P563
   Bamman D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P44
   Bernd Bohnet, 2022, C RES SEQ2SEQ TRANS
   Chen H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P172
   Chen Y-H, 2016, P 17 ANN M SPEC INT, P90
   Choi J. D., 2018, P 12 INT WORKSH SEM, P57
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Creutz Mathias., 2018, P 11 INT C LANGUAGE
   Cui YM, 2020, Arxiv, DOI arXiv:2004.13922
   Dazat A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3904
   Donna K., 1998, RESOLVING DEMONSTRAT
   Dou ZY, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2112
   Etezadi Romina., 2022, P 2022 C N AM CHAPT, DOI [10.18653/v1/2022.naacl-demo.13, DOI 10.18653/V1/2022.NAACL-DEMO.13]
   Fei H., 2020, P 58 ANN M ASS COMP, P7014
   Frampton Matthew., 2009, EACL, DOI [10.3115/1609067.1609097, DOI 10.3115/1609067.1609097]
   Gabi Rolih, 2018, APPL C RES US DIAL S
   Ghaddar A, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P136
   Iain McCowan Jean, 2005, AM M CORPUS
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Jovanovic N, 2006, LANG RESOUR EVAL, V40, P5, DOI 10.1007/s10579-006-9006-4
   Khosla S, 2021, P CODI CRAC 2021 SHA, P1
   Kim Hongjin., 2021, P CODI CRAC 2021 SHA, P43
   Kitaev N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3499
   Kitaev N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2676
   Kobayashi Hideo., 2021, P CODI CRAC 2021 SHA, P16
   Lee Kenton, 2018, P 2018 C NAACL HUM L, P687, DOI [10.18653/v1/N18-2108, DOI 10.18653/V1/N18-2108]
   Lee Kenton, 2017, P 2017 C EMP METH NA, P188, DOI DOI 10.18653/V1/D17-1018
   Li J., 2020, CORR, P2642, DOI DOI 10.18653/V1/2020.COLING-MAIN.238
   Li ML, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P77
   Li XS, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P906
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P923
   Liu Yinhan, 2019, ARXIV190711692
   Liu Z., 2021, PROC 2 WORKSHOP COMP, P122, DOI DOI 10.18653/V1/2021.CODIMAIN.11
   Liu ZY, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P509
   Liyan Xu., 2021, P CODI CRAC 2021 SHA, P55
   Luo X., 2005, P HUM LANG TECHN C C, P25
   Manuvinakurike R, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P530
   Marilyn A., 1997, STANDARDS DIALOGUE C
   Muzerelle J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P843
   Ozaki H, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2586
   Pradhan S., 2012, JOINT C EMNLP CONLL, P1
   Raffel C, 2020, J MACH LEARN RES, V21
   Rameshkumar R, 2020, P 58 ANN M ASS COMP, P5121, DOI [10.18653/v1/2020.acl-main.459, DOI 10.18653/V1/2020.ACL-MAIN.459]
   Recasens M, 2010, P 5 INT WORKSH SEM E, P1
   Riloff Ellen., 2002, COLING 2002 19 INT C, DOI [10.3115/1072228.1072298, DOI 10.3115/1072228.1072298]
   Roesiger I., 2018, P 1 WORKSHOP COMPUTA, P11
   Roy A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P418
   Sang Yisi., 2022, P 2022 C N AM CHAPT, P4267, DOI [10.18653/v1/2022.naacl-main.317, DOI 10.18653/V1/2022.NAACL-MAIN.317]
   Schwenk Holger, 2017, P 2 WORKSH REPR LEAR, P157, DOI DOI 10.18653/V1/W17-2619
   Shwartz V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6850
   Stengel-Estrin E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P910
   Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737
   Tavakoli Leila., 2014, INT J INFORM COMMUNI, V6, P63
   Thompson B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P90
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Toshniwal S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8519
   Toshniwal Shubham., 2021, P 4 WORKSH COMP MOD, P111, DOI DOI 10.18653/V1/2021.CRAC-1.12
   Urbanek J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P673
   Vilain M., 1995, P 6 MESS UND C MUC 6
   Wang XW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5635
   Weischedel Ralph, 2013, ONTONOTES RELEASE 50
   Wu W., 2020, P 58 ANN M ASS COMPU, P6953
   Xia P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5241
   Xia P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8617
   Xu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8527
   Xuansong Li Stephen, 2015, GALE CHINESE ENGLISH
   Yarmohammadi M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1950
   Yarowsky D, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P200
   Yuan M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7533
   Zhou Ethan., 2018, P 27 INT C COMPUTATI, P24
NR 76
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD AUG 7
PY 2023
VL 11
BP 922
EP 940
DI 10.1162/tacl_a_00581
PG 19
WC Computer Science, Artificial Intelligence; Linguistics; Language &
   Linguistics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Linguistics
GA O6QL7
UT WOS:001045029700002
OA Green Submitted, gold
DA 2023-11-10
ER

PT J
AU Gao, W
   Ma, JY
   Wu, JQ
   Wang, CL
AF Gao, W
   Ma, JY
   Wu, JQ
   Wang, CL
TI Sign language recognition based on HMM/ANN/DP
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 2nd International Conference on Multimodal Interface (ICMI 99)
CY JAN, 1999
CL HONG KONG, HONG KONG
DE hand gesture recognition; sign language recognition; artificial neural
   network; dynamic programming; multimodal user interface; virtual reality
ID SPEECH
AB In this paper, a system designed for helping the deaf to communicate with others is presented. Some useful new ideas are proposed in design and implementation. An algorithm based on geometrical analysis for the purpose of extracting invariant feature to signer position is presented. Rn ANN-DP combined approach is employed for segmenting subwords automatically from the data stream of sign signals. To tackle the epenthesis movement problem, a DP-based method has been used to obtain the context-dependent models. Some techniques for system implementation are also given, including fast matching, frame prediction and search algorithms. The implemented system is able to recognize continuous large vocabulary Chinese Sign Language. Experiments show that proposed techniques in this paper are efficient on either recognition speed or recognition performance.
C1 Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
   Harbin Inst Technol, Dept Comp Sci, Harbin, Peoples R China.
   Dalian Univ Technol, Dept Comp Sci, Dalian, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Harbin Institute of Technology; Dalian University of Technology
RP Gao, W (通讯作者)，Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
EM wgao@ict.ac.cn; jyma@ict.ac.cn; jqwu@ict.ac.cn; clwang@ict.ac.cn
CR [Anonymous], P INT C SYST MAN CYB
   Bellman R., 1962, APPL DYNAMIC PROGRAM, DOI DOI 10.1515/9781400874651
   BOURLARD H, 1997, P INT C ART NEUR NET, P201
   CHARAYAPHAN C, 1992, J BIOMED ENG, V14, P419, DOI 10.1016/0141-5425(92)90088-3
   FELS SS, 1993, IEEE T NEURAL NETWOR, V4, P2, DOI 10.1109/72.182690
   FELS SS, 1994, THESISU TORONTO
   Kadous M. W., 1996, PROC WORKSHOP INTEGR, P165
   KANG SB, 1994, P IM UND WORKSH, P303
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KRAMER J, 1990, 19900312 CDR STANDF
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   MURAKAMI K, 1991, CHI 91 C P, P237, DOI DOI 10.1145/108844.108900
   RABINER L, 1996, IEEE ICASSP MAGAZINE, P4
   STARNER T, 1995, THEIS MIT
   Takahashi T., 1991, SIGCHI Bulletin, V23, P67, DOI 10.1145/122488.122499
   TUNG CP, 1985, P IEEE RSJ C INT ROB, P1
   Vogler C, 1997, IEEE SYS MAN CYBERN, P156, DOI 10.1109/ICSMC.1997.625741
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
   VOGLER C, 1999, P INT C COMP VIS KER, P224
   Vogler Christian, 1999, P GEST WORKSH GIF SU, P400
   WEXELBLAT AD, 1993, THESIS MIT
NR 21
TC 56
Z9 65
U1 0
U2 15
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD AUG
PY 2000
VL 14
IS 5
BP 587
EP 602
DI 10.1142/S0218001400000386
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 351XQ
UT WOS:000089185400004
DA 2023-11-10
ER

PT J
AU Husain, F
   Uzuner, O
AF Husain, Fatemah
   Uzuner, Ozlem
TI Investigating the Effect of Preprocessing Arabic Text on Offensive
   Language and Hate Speech Detection
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
LA English
DT Article
DE Artificial neural networks; offensive language detection; natural
   language processing; Arabic language; machine learning
AB Preprocessing of input text can play a key role in text classification by reducing dimensionality and removing unnecessary content. This study aims to investigate the impact of preprocessing on Arabic offensive language classification. We explore six preprocessing techniques: conversion of emojis to Arabic textual labels, normalization of different forms of Arabic letters, normalization of selected nouns from dialectal Arabic to Modern Standard Arabic, conversion of selected hyponyms to hypernyms, hashtag segmentation, and basic cleaning such as removing numbers, kashidas, diacritics, and HTML tags. We also experiment with raw text and a combination of all six preprocessing techniques. We apply different types of classifiers in our experiments including traditional machine learning, ensemble machine learning, Artificial Neural Networks, and Bidirectional Encoder Representations from Transformers (BERT)-based models to analyze the impact of preprocessing. Our results demonstrate significant variations in the effects of preprocessing on each classifier type and on each dataset. Classifiers that are based on BERT do not benefit from preprocessing, while traditional machine learning classifiers do. However, these results can benefit from validation on larger datasets that cover broader domains and dialects.
C1 [Husain, Fatemah] Kuwait Univ, Sabah AlSalem Univ City Alshadadiya, POB 5969, Safat 13060, Kuwait.
   [Uzuner, Ozlem] George Mason Univ, 4400 Univ Dr,5359 Nguyen Engn Bldg,MSN 1G8, Fairfax, VA 22030 USA.
C3 Kuwait University; George Mason University
RP Husain, F (通讯作者)，Kuwait Univ, Sabah AlSalem Univ City Alshadadiya, POB 5969, Safat 13060, Kuwait.
EM f.husain@ku.edu.kw; ouzuner@gmu.edu
RI Husain, Fatemah/IQW-0461-2023
OI Husain, Fatemah/0000-0003-3470-229X
CR Alharbi A. I., 2020, P 4 WORKSH OP SOURC, P91
   [Anonymous], 2010, SYNTHESIS LECT HUMAN, DOI DOI 10.2200/S00274ED1V01Y201006HLT007
   [Anonymous], 2015, INT SCI INDEX
   Antoun W., 2020, P 4 WORKSHOP OPEN SO, P9
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Darwish K., 2014, P EMNLP 2014 WORKSHO, P217
   Duwairi R, 2014, J INF SCI, V40, P501, DOI 10.1177/0165551514534143
   El Gayar Neamat, 2018, SERIES LANGUAGE PROC, V4, P1, DOI [10.1142/10693, DOI 10.1142/10693]
   HaCohen-Kerner Y, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232525
   Haddad H, 2019, COMM COM INF SC, V1108, P251, DOI 10.1007/978-3-030-32959-4_18
   HamdyMubarak Kareem Darwish, 2020, P 4 WORKSHOP OPEN SO, V4
   Husain F., 2020, P 4 WORKSHOP OPEN SO, P53
   Husain F., 2020, P 14 INT WORKSHOP SE
   Husain F, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3421504
   Husain Fatemah., P 4 WORKSHOP OPEN SO
   Husain Fatemah, 2020, ARABIC OFFENSIVE LAN
   Kamiran F., 2020, P 4 WORKSH OP SOURC, P71
   Mulki H, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P111
   Orsan C., 2018, P 1 WORKSHOP TROLLIN, P113
   Saad MK, 2010, IMPACT TEXT PREPROCE
   Safaya A., 2020, P 14 WORKSH SEM EV, P2054
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Woo H, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1958149
NR 23
TC 4
Z9 4
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL
PY 2022
VL 21
IS 4
AR 73
DI 10.1145/3501398
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L2VC
UT WOS:000799149600010
DA 2023-11-10
ER

PT J
AU Foster, S
   Struth, G
AF Foster, Simon
   Struth, Georg
TI On the Fine-Structure of Regular Algebra
SO JOURNAL OF AUTOMATED REASONING
LA English
DT Article
DE Regular algebra; Kleene algebra; Regular languages; Interactive theorem
   proving; Automated theorem proving; Formalised mathematics
ID SYSTEMS; THEOREM
AB Regular algebra is the algebra of regular expressions as induced by regular language identity. We use Isabelle/HOL for a detailed systematic study of the regular algebra axioms given by Boffa, Conway, Kozen and Salomaa. We investigate the relationships between these systems, formalise a soundness proof for the smallest class (Salomaa's) and obtain completeness for the largest one (Boffa's) relative to a deep result by Krob. As a case study in formalised mathematics, our investigations also shed some light on the power of theorem proving technology for reasoning with algebras and their models, including proof automation and counterexample generation.
C1 [Foster, Simon] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
   [Struth, Georg] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.
C3 University of York - UK; University of Sheffield
RP Struth, G (通讯作者)，Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.
EM simon.foster@york.ac.uk; g.struth@sheffield.ac.uk
RI Foster, Simon/AAP-7392-2021
OI Foster, Simon/0000-0002-9889-9514
CR [Anonymous], 2019, LCP ISABELLE 2019
   Armstrong A., 2013, ARCH FORMAL PROOFS, V2013
   Benzmuller C., 2013, PXTP 2013 EPIC SERIE, V14, P2
   Blanchette JC, 2011, LECT NOTES ARTIF INT, V6989, P12, DOI 10.1007/978-3-642-24364-6_2
   Blanchette JC, 2010, LECT NOTES COMPUT SC, V6172, P131, DOI 10.1007/978-3-642-14052-5_11
   Bloom S., 1993, MATH STRUCT COMPUT S, V3, P1
   Boffa M., 1990, Informatique Theorique et Applications, V24, P419
   Boffa M, 1995, RAIRO-INF THEOR APPL, V29, P515, DOI 10.1051/ita/1995290605151
   Braibant T, 2010, LECT NOTES COMPUT SC, V6172, P163, DOI 10.1007/978-3-642-14052-5_13
   Conway J. H., 1971, 2 BRIT COMB C ROYAL
   Eilenberg S., 1976, AUTOMATA LANGUAGES M
   Ésik Z, 1999, INFORM COMPUT, V148, P131, DOI 10.1006/inco.1998.2746
   Foster S., 2014, ARCH FORMAL PROOFS 2
   Ginzburg A, 1968, ALGEBRAIC THEORY AUT
   Gordon M.J.C., 2006, INTEGRATION HOL ACL2, P153
   Höfner P, 2010, J LOGIC ALGEBR PROGR, V79, P794, DOI 10.1016/j.jlap.2010.07.016
   Huffman B, 2013, LECT NOTES COMPUT SC, V8307, P131, DOI 10.1007/978-3-319-03545-1_9
   Iancu M, 2011, MATH STRUCT COMP SCI, V21, P883, DOI 10.1017/S0960129511000144
   Kleene S.C., 1956, AUTOMATA STUDIES, P3
   KOZEN D, 1994, INFORM COMPUT, V110, P366, DOI 10.1006/inco.1994.1037
   Kozen Dexter, 2012, Relational and Algebraic Methods in Computer Science. Proceedings 13th International Conference, RAMiCS 2012, P162, DOI 10.1007/978-3-642-33314-9_11
   Kozen Dexter, 1990, P MATH FDN COMP SCI, V452, P26
   KROB D, 1991, THEOR COMPUT SCI, V89, P207, DOI 10.1016/0304-3975(91)90395-I
   Miller D., 2012, LNCS, V7679, P92, DOI DOI 10.1007/978-3-642-35308-6_
   Nipkow Tobias, 2014, Interactive Theorem Proving. 5th International Conference, ITP 2014, Held as Part of the Vienna Summer of Logic, VSL 2014. Proceedings: LNCS 8558, P450, DOI 10.1007/978-3-319-08970-6_29
   Pratt V., 1990, STANCS901343 STANF U
   REDKO VN, 1964, UKR MAT ZH, V16, P120
   SALOMAA A, 1966, J ACM, V13, P158, DOI 10.1145/321312.321326
   Wu CH, 2014, J AUTOM REASONING, V52, P451, DOI 10.1007/s10817-013-9297-2
NR 29
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0168-7433
EI 1573-0670
J9 J AUTOM REASONING
JI J. Autom. Reasoning
PD FEB
PY 2015
VL 54
IS 2
BP 165
EP 197
DI 10.1007/s10817-014-9318-9
PG 33
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AY0IT
UT WOS:000347281200003
OA Green Accepted
DA 2023-11-10
ER

PT J
AU Baral, C
   Gelfond, G
   Pontelli, E
   Son, TC
AF Baral, Chitta
   Gelfond, Gregory
   Pontelli, Enrico
   Tran Cao Son
TI An action language for multi-agent domains
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Action languages; Epistemic planning; Reasoning about knowledge
ID DECENTRALIZED CONTROL; REPRESENTING ACTION; LOGIC; COMPLEXITY; SYSTEMS;
   BELIEF
AB The goal of this paper is to investigate an action language, called mA*, for representing and reasoning about actions and change in multi-agent domains. The language, as designed, can also serve as a specification language for epistemic planning, thereby addressing an important issue in the development of multi-agent epistemic planning systems. The mA* action language is a generalization of the single-agent action languages, extensively studied in the literature, to the case of multi-agent domains. The language allows the representation of different types of actions that an agent can perform in a domain where many other agents might be present-such as world-altering actions, sensing actions, and communication actions. The action language also allows the specification of agents' dynamic awareness of action occurrences-which has implications on what agents' know about the world and other agents' knowledge about the world. These features are embedded in a language that is simple, yet powerful enough to address a large variety of knowledge manipulation scenarios in multi-agent domains.
   The semantics of mA* relies on the notion of state, which is described by a pointed Kripke model and is used to encode the agents' knowledge(1) and the real state of the world. The semantics is defined by a transition function that maps pairs of actions and states into sets of states. The paper presents a number of properties of the action theories and relates mA* to other relevant formalisms in the area of reasoning about actions in multi-agent domains. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Baral, Chitta] Arizona State Univ, Sch Comp & AI, Tempe, AZ 85287 USA.
   [Gelfond, Gregory] Univ Nebraska Omaha, Dept Comp Sci, Omaha, NE USA.
   [Pontelli, Enrico; Tran Cao Son] New Mexico State Univ, Dept Comp Sci, Las Cruces, NM 88003 USA.
C3 Arizona State University; Arizona State University-Tempe; University of
   Nebraska System; University of Nebraska Omaha; New Mexico State
   University
RP Son, TC (通讯作者)，New Mexico State Univ, Dept Comp Sci, Las Cruces, NM 88003 USA.
EM chitta@asu.edu; ggelfond@unomaha.edu; epontell@cs.nmsu.edu;
   tson@cs.nmsu.edu
RI Pontelli, Enrico/AAJ-5161-2021
OI Pontelli, Enrico/0000-0002-7753-1737
FU DARPA [W911NF-19-2-0006]; NSF [1914635, 1833630, 1757207, 1812628];
   Division Of Undergraduate Education; Direct For Education and Human
   Resources [1833630] Funding Source: National Science Foundation
FX The first author has been partially supported by DARPA grant
   W911NF-19-2-0006. The last two authors have been partially supported by
   NSF grants 1914635, 1833630, 1757207, and 1812628.
CR Agotnes T., 2014, PLANNING EPISTEMIC G
   Allen M., 2009, ADV NEURAL INFORM PR, V22, P19
   [Anonymous], 2005, P 4 INT JOINT C AUTO
   [Anonymous], 2006, AAMAS
   Aucher G., 2013, P 23 IJCAI, P27
   Baltag A, 2004, SYNTHESE, V139, P165, DOI 10.1023/B:SYNT.0000024912.56773.5e
   Baral C, 2010, THEOR PRACT LOG PROG, V10, P675, DOI 10.1017/S1471068410000359
   Baral C., 2012, P NMR
   Baral C., 2010, P S CONSTR MECH
   Baral C., 2010, P INT JOINT C AUTONO, V1, P259
   Baral C., 2017, DAGSTUHL REPORTS, V7, P1
   Baral C, 2013, LECT NOTES ARTIF INT, V8143, P290, DOI 10.1007/978-3-642-40624-9_18
   Baral C, 2010, LECT NOTES ARTIF INT, V6214, P46
   Bernstein DS, 2002, MATH OPER RES, V27, P819, DOI 10.1287/moor.27.4.819.297
   Boella G., 2005, P 4 INT JOINT C AUT, P682
   Bolander Thomas, 2011, Journal of Applied Non-Classical Logic, V21, P9, DOI 10.3166/jancl.21.9-34
   Bolander T, 2018, OUTST CONTRIB LOGIC, V12, P207, DOI 10.1007/978-3-319-62864-6_8
   Bolander T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2791
   Brafman R. I., 2008, P 18 INT C AUT PLANN, P28
   Castellini C., 2001, P 6 EUR C PLANN ECP
   de Weerdt M, 2003, ANN MATH ARTIF INTEL, V37, P93, DOI 10.1023/A:1020236119243
   de Weerdt M, 2009, MULTIAGENT GRID SYST, V5, P345, DOI 10.3233/MGS-2009-0133
   Del Val A., 1994, Journal of Logic and Computation, V4, P797, DOI 10.1093/logcom/4.5.797
   Durfee EH, 1999, MULTIAGENT SYSTEMS, P121
   Engesser T, 2017, ELECTRON P THEOR COM, P75, DOI 10.4204/EPTCS.243.6
   Engesser T, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1795
   Fabiano F., 2020, INT C AUT PLANN SCHE
   Fagin R., 2003, REASONING KNOWLEDGE, DOI DOI 10.7551/MITPRESS/5803.001.0001
   FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5
   Friedman N, 1999, J ARTIF INTELL RES, V10, P117, DOI 10.1613/jair.506
   GELFOND M, 1993, J LOGIC PROGRAM, V17, P301, DOI 10.1016/0743-1066(93)90035-F
   Gelfond M., 1998, T ARTIF INTELL, V3
   Gerbrandy Jelle, 2006, P 5 INT JOINT C AUT, DOI DOI 10.1145/1160633.1160664
   Ghallab M., 1998, TR98003DCTR1165 CVC
   Giunchiglia E, 1997, ARTIF INTELL, V95, P409, DOI 10.1016/S0004-3702(97)00037-4
   Goldman CV, 2004, J ARTIF INTELL RES, V22, P143, DOI 10.1613/jair.1427
   Guestrin C, 2002, ADV NEUR IN, V14, P1523
   Herzig A, 2005, 6 WORKSH NONM REAS A
   Herzig Andreas, 2006, P 5 INT JOINT C AUTO, P209, DOI 10.1145/1160633.1160666
   KATSUNO H, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P387
   Kominis F, 2015, P I C AUTOMAT PLAN S, P147
   Levesque HJ, 1997, J LOGIC PROGRAM, V31, P59, DOI 10.1016/S0743-1066(96)00121-5
   Lifschitz V., 1987, REASONING ACTIONS PL, P1
   Liu Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1912
   Löwe B, 2011, LECT NOTES ARTIF INT, V6953, P179, DOI 10.1007/978-3-642-24130-7_13
   McCarthy J., 1959, P TEDD C MECH THOUGH, P75
   Muise C, 2015, AAAI CONF ARTIF INTE, P3327
   Nair R., 2003, P 18 INT JOINT C ART, P705
   PEDNAULT EPD, 1989, S REPR REAS, P324
   Peshkin L, 2002, IEEE IJCNN, P1825, DOI 10.1109/IJCNN.2002.1007796
   Phan HT, 2011, ARTIF INTELL, V175, P79, DOI 10.1016/j.artint.2010.04.007
   Sauro L., 2006, AAMAS 06 P 5 INT JOI, P185
   Shanahan M, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P140
   Son TC, 2001, ARTIF INTELL, V125, P19, DOI 10.1016/S0004-3702(00)00080-1
   Son Tran C., 2005, P 20 NATL C ART INT, P1211
   Son TC, 2015, AAAI CONF ARTIF INTE, P1604
   Son TC, 2010, LECT NOTES ARTIF INT, V5948, P208
   Son TC, 2009, LECT NOTES COMPUT SC, V5649, P99, DOI 10.1007/978-3-642-02846-5_13
   Thiebaux S., 2003, P 18 INT JOINT C ART
   Thielscher M, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1276
   Le T, 2018, P I C AUTOMAT PLAN S, P161
   Son TC, 2014, LECT NOTES ARTIF INT, V8761, P239, DOI 10.1007/978-3-319-11558-0_17
   van Benthem J., 2007, J APPL NONCLASSICAL, V17, P129, DOI DOI 10.3166/JANCL.17.129-155
   van Benthem J, 2006, INFORM COMPUT, V204, P1620, DOI 10.1016/j.ic.2006.04.006
   van Eijck J, 2017, LYING WORKSH
   van Eijck Jan, 2004, DYNAMIC EPISTEMIC MO
   VanDitmarsch H, 2007, SYNTH LIBR, V337, P1, DOI 10.1007/978-1-4020-5839-4
   Wan H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1093
   Wan H, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3257
NR 69
TC 6
Z9 6
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD JAN
PY 2022
VL 302
AR 103601
DI 10.1016/j.artint.2021.103601
EA OCT 2021
PG 32
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WH1DA
UT WOS:000707426600003
OA hybrid
DA 2023-11-10
ER

PT J
AU Zhao, B
   Jin, WQ
   Del Ser, J
   Yang, G
AF Zhao, Biao
   Jin, Weiqiang
   Del Ser, Javier
   Yang, Guang
TI ChatAgri: Exploring potentials of ChatGPT on cross-linguistic
   agricultural text classification
SO NEUROCOMPUTING
LA English
DT Article
DE Agricultural text classification; Very large pre-trained language model;
   Generative Pre-trained Transformer (GPT); ChatGPT; GPT-4
AB In the era of sustainable smart agriculture, a vast amount of agricultural news text is posted online, accu-mulating significant agricultural knowledge. To efficiently access this knowledge, effective text classification techniques are urgently needed. Deep learning approaches, such as fine-tuning strategies on pre-trained language models (PLMs), have shown remarkable performance gains. Nonetheless, these methods face several complex challenges, including limited agricultural training data, poor domain transferability (especially across languages), and complex and expensive deployment of large models. Inspired by the success of recent ChatGPT models (e.g., GPT-3.5, GPT-4), this work explores the potential of applying ChatGPT in the field of agricultural informatization. Various crucial factors, such as prompt construction, answer parsing, and different ChatGPT variants, are thoroughly investigated to maximize its capabilities. A preliminary comparative study is conducted, comparing ChatGPT with PLMs-based fine-tuning methods and PLMs-based prompt-tuning methods. Empirical results demonstrate that ChatGPT effectively addresses the mentioned research challenges and bottlenecks, making it an ideal solution for agricultural text classification. Moreover, ChatGPT achieves comparable performance to existing PLM-based fine-tuning methods, even without fine-tuning on agricultural data samples. We hope this preliminary study could inspire the emergence of a general-purpose AI paradigm for agricultural text processing.
C1 [Zhao, Biao; Jin, Weiqiang] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Innovat Harbour, Xian 710049, Shaanxi, Peoples R China.
   [Del Ser, Javier] Basque Res & Technol Alliance BRTA, TECNALIA, Derio 48160, Spain.
   [Yang, Guang] Imperial Coll London, Bioengn, London SW7 2BX, England.
   [Yang, Guang] Imperial Coll London, Imperial X, W12, London W12 7SL, England.
   [Yang, Guang] Imperial Coll London, Natl Heart & Lung Inst, London SW3 6LY, England.
C3 Xi'an Jiaotong University; Imperial College London; Imperial College
   London; Imperial College London
RP Yang, G (通讯作者)，Imperial Coll London, Bioengn, London SW7 2BX, England.; Yang, G (通讯作者)，Imperial Coll London, Imperial X, W12, London W12 7SL, England.; Yang, G (通讯作者)，Imperial Coll London, Natl Heart & Lung Inst, London SW3 6LY, England.
EM biaozhao@xjtu.edu.cn; weiqiangjin@stu.xjtu.edu.cn;
   javier.delser@tecnalia.com; g.yang@imperial.ac.uk
RI Yang, Guang/S-5032-2016; Del Ser, Javier/J-2187-2014
OI Yang, Guang/0000-0001-7344-7733; jin, weiqiang/0000-0002-6656-6061; Del
   Ser, Javier/0000-0002-1260-9775
FU ERC IMI, UK [101005122]; H2020 [952172]; MRC, UK [MC/PC/21013]; Royal
   Society, UK [IEC\NSFC\211235]; NVIDIA Academic Hardware Grant Program,
   UK; SABER project supported by Boehringer Ingelheim Ltd, UK; UKRI Future
   Leaders Fellowship, UK [MR/V023799/1]; Spanish Centro para el Desarrollo
   Tecnologico Industrial (CDTI) , Spain through the AI4ES project;
   Department of Education of the Basque Government (Eusko Jaurlaritza) ,
   Spain via the Consolidated Research Group MATHMODE [IT1456-22]; Natural
   Science Basis Research Plan in Shaanxi Province of China [2021JQ-061]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments, corrections, and recommendations, which significantly
   improved the quality of the paper. G.Y. was supported in part by the ERC
   IMI, UK (101005122) , the H2020 (952172) , the MRC, UK (MC/PC/21013) ,
   the Royal Society, UK (IEC\NSFC\211235) , the NVIDIA Academic Hardware
   Grant Program, UK, the SABER project supported by Boehringer Ingelheim
   Ltd, UK, and the UKRI Future Leaders Fellowship, UK (MR/V023799/1) .
   J.D.S. also acknowledged support from the Spanish Centro para el
   Desarrollo Tecnologico Industrial (CDTI) , Spain through the AI4ES
   project, and the Department of Education of the Basque Government (Eusko
   Jaurlaritza) , Spain via the Consolidated Research Group MATHMODE
   (IT1456-22) . B.Z. and W.J. were supported in part by the Natural
   Science Basis Research Plan in Shaanxi Province of China (Project Code:
   2021JQ-061) . Both the first two authors, B.Z. and W.J., made equal
   contributions to this work.
CR Alec R., 2019, OPENAI BLOG
   Azeez N, 2018, COMPUT SCI ELECTR, P131, DOI 10.1109/CEEC.2018.8674193
   Bang Y, 2023, Arxiv, DOI arXiv:2302.04023
   Brown T.B., 2020, P 34 INT C NEUR INF, P182
   Cao Y, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14081604
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P105
   Dunnmon J, 2019, Arxiv, DOI arXiv:1902.07087
   Edio da C., 2020, INT J ELECT COMPUT E, V8, P1671, DOI [10.11591/ijece.v8i3.pp1671-1683, DOI 10.11591/IJECE.V8I3.PP1671-1683]
   Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, 10.48550/arXiv.2303.10130, DOI 10.48550/ARXIV.2303.10130]
   Fang JZ, 2022, IEEE T AUTOM SCI ENG, DOI 10.1109/TASE.2022.3230080
   Gao JQ, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109935
   Gao J, 2023, Arxiv, DOI arXiv:2303.03836
   Haque M. U., 2022, ARXIV, DOI [DOI 10.48550/ARXIV.2212.05856, 10.48550/arXiv.2212.05856]
   Hu SD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2225
   Jiang S., 2021, ARXIV
   Jiao WX, 2023, Arxiv, DOI arXiv:2301.08745
   Jin Weiqiang, 2023, Database Systems for Advanced Applications: 28th International Conference, DASFAA 2023, Proceedings. Lecture Notes in Computer Science (13945), P425, DOI 10.1007/978-3-031-30675-4_31
   Jin WQ, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103260
   Jin WQ, 2023, DATA MIN KNOWL DISC, V37, P255, DOI 10.1007/s10618-022-00891-8
   Jin WQ, 2021, PROC INT C TOOLS ART, P736, DOI 10.1109/ICTAI52525.2021.00117
   Kim Y., 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1181
   Leong FH, 2022, COMM COM INF SC, V1653, P223, DOI 10.1007/978-3-031-16210-7_18
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Li YC, 2023, IEEE ACCESS, V11, P27034, DOI 10.1109/ACCESS.2023.3253386
   Liu HZ, 2022, IEICE T INF SYST, VE105D, P1472, DOI 10.1587/transinf.2021EDP7261
   Liu P, 2016, ARXIV160505101, P2873, DOI DOI 10.5555/3060832.3061023
   Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815
   Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61
   Liu X, 2021, Arxiv, DOI [arXiv:2103.10385, DOI 10.48550/ARXIV.2103.10385]
   Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5
   Meng LY, 2020, Arxiv, DOI arXiv:2004.14456
   OpenAI, 2023, GPT4 OPENAI
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U
   Raffel C, 2020, J MACH LEARN RES, V21
   Shen YL, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P947
   Shen YL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2782
   Susnjak T., 2023, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JA, 2023, Arxiv, DOI arXiv:2303.04048
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wei X, 2023, Arxiv, DOI arXiv:2302.10205
   Wu PS, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106457
   Xia N, 2023, MACH LEARN, V112, P1011, DOI 10.1007/s10994-022-06198-5
   Xiao YQ, 2023, Arxiv, DOI arXiv:2303.11153
   Xu JL, 2022, J SUPERCOMPUT, V78, P10876, DOI 10.1007/s11227-021-04238-w
   Yunlai S., 2022, J LIBR INF SCI AGR, V34, P19, DOI [10.13998/j.cnki.issn1002-1248.22-0172, DOI 10.13998/J.CNKI.ISSN1002-1248.22-0172]
   Zhang YQ, 2023, NEUROCOMPUTING, V523, P182, DOI 10.1016/j.neucom.2022.12.034
   Zhong QH, 2023, Arxiv, DOI arXiv:2302.10198
   Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]
   Zhu NY, 2018, INT J AGR BIOL ENG, V11, P32, DOI 10.25165/j.ijabe.20181104.4475
NR 52
TC 0
Z9 0
U1 19
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD NOV 7
PY 2023
VL 557
AR 126708
DI 10.1016/j.neucom.2023.126708
EA SEP 2023
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S9ND6
UT WOS:001074351000001
OA Green Submitted, hybrid
DA 2023-11-10
ER

PT S
AU Baba, Y
   Suzuki, M
AF Baba, Y
   Suzuki, M
BE Asperti, A
   Buchberger, B
   Davenport, JH
TI An annotated corpus and a grammar model of theorem description
SO MATHEMATICAL KNOWLEDGE MANAGEMENT, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 2nd International Conference on Mathematical Knowledge Management
CY FEB 16-MAY 18, 2003
CL BERTINORO, ITALY
AB Digitizing documents is becoming increasingly popular in various fields, and training computers to understand the contents of digitized documents is of growing interest. Since the early 90's, research of natural language processing using large annotated corpora such as the Penn TreeBank has developed. Applying the methods of corpus-based research, we built a syntactically annotated corpus of theorem descriptions, using a book of set theory, and extracted a grammar model of theorems from the obtained corpus, as the first step to understanding mathematical documents by computer.
C1 Kyushu Univ, Grad Sch Math, Higashi Ku, Fukuoka 8128581, Japan.
   Kyushu Univ, Fac Math, Higashi Ku, Fukuoka 8128581, Japan.
C3 Kyushu University; Kyushu University
RP Baba, Y (通讯作者)，Kyushu Univ, Grad Sch Math, Higashi Ku, 6-10-1 Hakozaki, Fukuoka 8128581, Japan.
CR CAMERON J, 1999, P SETS LOGIC CATEGOR
   ETO Y, 2001, P 6 INT C DOC AN REC, P430
   Hodges W., 1997, SHORTER MODEL THEORY
   Inoue K., 1998, P 3 AS TECHN C MATH, P280
   Marcus M., BUILDING LARGE ANNOT
   Michler G, 1999, LECT NOTES CONTR INF, V249, P219
   Michler GO, 2001, ARCH MATH, V77, P116
   Rotman J., 1998, GALOIS THEORY
   SEKINE S, 1995, 4 INT WORKSH PARS TE
   2000, IPSJ MAGAZINE, V41
   PROTEUS PROJECT PARS
NR 11
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-00568-4
J9 LECT NOTES COMPUT SC
PY 2003
VL 2594
BP 93
EP 104
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematics
GA BW61D
UT WOS:000182563200008
DA 2023-11-10
ER

EF