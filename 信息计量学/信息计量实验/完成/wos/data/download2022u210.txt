PT J
AU Singh, SM
   Singh, TD
AF Singh, Salam Michael
   Singh, Thoudam Doren
TI An empirical study of low-resource neural machine translation of manipuri in multilingual settings
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Neural machine translation; Multilingual neural machine translation for low resource; Cross-lingual embedding; Manipuri
AB Machine translation requires a large amount of parallel data for a production level of translation quality. This is one of the significant factors behind the lack of machine translation systems for most spoken/written languages. Likewise, Manipuri is a low resource Indian language, and there is very little digital textual available data for the same. In this work, we attempt to address the low resource neural machine translation for Manipuri and English using other Indian languages in a multilingual setup. We train an LSTM based many-to-many multilingual neural machine translation system that is infused with cross-lingual features. Experimental results show that our method improves over the vanilla many-to-many multilingual and bilingual baselines for both Manipuri to/from English translation tasks. Furthermore, our method also improves over the vanilla many-to-many multilingual system for the translation task of all the other Indian languages to/from English. We also examine the generalizability of our multilingual model by evaluating the translation among the language pairs which do not have a direct link via the zero-shot translation and compare it against the pivot-based translation.
C1 [Singh, Salam Michael; Singh, Thoudam Doren] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Silchar
RP Singh, SM (通讯作者)，Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar 788010, Assam, India.
EM salam_rs@cse.nits.ac.in; doren@cse.nits.ac.in
CR Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   [Anonymous], 2014, INT J EC MANAGEMENT, V0, P0
   Arivazhagan N, 2019, MASSIVELY MULTILINGU, V0, P0
   Artetxe M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P789
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Artetxe Mikel, 2018, P 6 INT C LEARNING R, V0, P0, DOI DOI 10.18653/V1/D18-1399
   Bahdanau D, 2016, ARXIV, V0, P0
   Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1538
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Cheng Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1965
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   Dabre R, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3406095
   Dabre Raj, 2015, P 29 PACIFIC ASIA C, V0, P289
   Doren Singh T, 2011, P 5 INT JOINT C NATU, V0, P1304
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P489
   Fathi MR, 2019, IND MANAG J, V11, P621, DOI 10.22059/IMJ.2019.280393.1007588
   Fathi MR, 2021, ANDISHEH AMAD, V20, P175
   Firat O, 2016, P 2016 C N AM CHAPT, V0, P866
   Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012
   Ha TL, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Haddow Barry, 2020, ARXIV200109907, V0, P0
   He Di, 2016, ADV NEURAL INFORM PR, V0, PP820, DOI 10.5555/3157096.3157188
   He J, 2020, P ICLR, V0, P0
   Isahara, 2007, HUMAN LANGUAGE TECHN, V0, P484
   Ji BJ, 2020, AAAI CONF ARTIF INTE, V34, P115
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Joulin A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2979
   Kim Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1246
   Kingma DP, 2014, C TRACK P, V0, P0
   Klein G, 2017, P ACL 2017 SYSTEM DE, V0, P6772
   Knight Kevin, 2016, ABS160402201 CORR, V0, P0
   Kocmi T, 2018, P 3 C MACH TRANSL RE, V0, PP244, DOI 10.18653/V1/W18-6325
   Koehn P, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311
   Koehn P, 2003, P 2003 HUMAN LANGUAG, V0, P0
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Laitonjam L, 2021, P 4 WORKSHOP TECHNOL, V0, P78
   Lample G, 2018, INT C LEARNING REPRE, V0, P0
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5039
   Li Zuchao, 2020, P 5 C MACHINE TRANSL, V0, PP218, DOI 10.18653/v1/2020.findings-emnlp.371
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Meetei LS, 2020, P 17 INT C NATURAL L, V0, P50
   More Rohit, 2015, P 12 INT C NATURAL L, V0, P303
   Nguyen TQ, 2017, P 8 INT JOINT C NAT, V2, P296
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Philip J, 2021, CODS-COMAD 2021: PROCEEDINGS OF THE 3RD ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA (8TH ACM IKDD CODS & 26TH COMAD), V0, PP178, DOI 10.1145/3430984.3431026
   Post Matt, 2018, P 3 C MACH TRANSL RE, V0, PP186, DOI 10.18653/v1/W18-6319
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Sen S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3083
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Singh Shubham, 2020, PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE ON COMPUTING, V0, P0
   Singh Salam Michael, 2021, SOFT COMPUTING AND SIGNAL PROCESSING. PROCEEDINGS OF 3RD ICSCSP 2020. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1325), V0, PP203, DOI 10.1007/978-981-33-6912-2_19
   Singh SM, 2021, P 1 WORKSHOP MULTIMO, V0, P2
   Singh Salam Michael, 2020, P 5 C MACHINE TRANSL, V0, P1139
   Singh TD, 2010, P 4 WORKSH SYNT STRU, V0, P83
   Singh TD, 2010, P 1 WORKSHOP S SE AS, V0, P35
   Singh TD, 2013, P 7 WORKSHOP SYNTAX, V0, P11
   Singh TD, 2018, LECT NOTES COMPUT SC, V10762, P457, DOI 10.1007/978-3-319-77116-8_34
   Song K, 2019, INT C MACHINE LEARNI, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Vaswani A, 2017, ARXIV, V30, P5998
   Yang Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P46
NR 63
TC 7
Z9 7
U1 4
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD SEP 15
PY 2022
VL 34
IS 17
BP 14823
EP 14844
DI 10.1007/s00521-022-07337-8
EA MAY 2022
PG 22
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3T5RN
UT WOS:000795509700003
DA 2023-11-10
ER

PT J
AU Fatima, G
   Nawab, RMA
   Khan, MS
   Saeed, A
AF Fatima, Ghazeefa
   Nawab, Rao Muhammad Adeel
   Khan, Muhammad Salman
   Saeed, Ali
TI Developing a Cross-lingual Semantic Word Similarity Corpus for English-Urdu Language Pair
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Cross-lingual semantic word similarity; Urdu; natural language processing; WordNet
AB Semantic word similarity is a quantitative measure of how much two words are contextually similar. Evaluation of semantic word similarity models requires a benchmark corpus. However, despite the millions of speakers and the large digital text of the Urdu language on the Internet, there is a lack of benchmark corpus for the Cross-lingual Semantic Word Similarity task for the Urdu language. This article reports our efforts in developing such a corpus. The newly developed corpus is based on the SemEval-2017 task 2 English dataset, and it contains 1,945 cross-lingual English-Urdu word pairs. For each of these pairs of words, semantic similarity scores were assigned by 11 native Urdu speakers. In addition to corpus generation, this article also reports the evaluation results of a baseline approach, namely "Translation Plus Monolingual Analysis" for automated identification of semantic similarity between English-Urdu word pairs. The results showed that the path length similarity measure performs better for the Google and Bing translated words. The newly created corpus and evaluation results are freely available online for further research and development.
C1 [Fatima, Ghazeefa; Nawab, Rao Muhammad Adeel; Khan, Muhammad Salman] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus,1-5KM Def Rd Off Raiwand Rd, Lahore, Punjab, Pakistan.
   [Saeed, Ali] Univ Lahore, Dept Software Engn, 1 Km Def Rd, Lahore, Punjab, Pakistan.
C3 COMSATS University Islamabad (CUI); University of Lahore
RP Fatima, G (通讯作者)，COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus,1-5KM Def Rd Off Raiwand Rd, Lahore, Punjab, Pakistan.
EM ghazeefafatimacs@gmail.com; adeelnawab@cuilahore.edu.pk; mskhan@cuilahore.edu.pk; ali.saeed@se.uol.edu.pk
CR Almarsoomi FA, 2013, IEEE SYS MAN CYBERN, V0, PP504, DOI 10.1109/SMC.2013.92
   [Anonymous], 2002, P 19 INT C COMP LING, V0, P0
   [Anonymous], 2013, NAACL, V0, P0
   [Anonymous], 2014, P 8 INT WORKSHOP SEM, V0, P0, DOI DOI 10.3115/V1/S14-2003
   [Anonymous], 2017, SEMEVAL ACL, V0, P0, DOI DOI 10.18653/V1/S17-2002
   [Anonymous], 2008, 2 ACM WORKSHOP IMPRO, V0, P0
   [Anonymous], 2000, P COLING 00 18 INT C, V0, P0
   Badenes-Olmedo C, 2019, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE (K-CAP 19), V0, PP147, DOI 10.1145/3360901.3364444
   Bangalore S, 2007, P 45 ANN M ASS COMP, V0, P152
   Brychcín T, 2019, EXPERT SYST APPL, V135, P287, DOI 10.1016/j.eswa.2019.06.021
   Brychcin Tomas, 2018, KNOWLEDGE BASED SYST, V0, P0
   Camacho-Collados J, 2017, PROC 15 C EUR CHAPTE, V0, P223
   Camacho-Collados J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P1
   Cao Xiaojun, 2021, J PHYS C SERIES, V1744, P0
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2475
   Elavarasi SA, 2014, INT J RES ADVENT TEC, V2, P389, DOI 10.1109/ICAC347590.2019.9036843
   Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110
   Francis W, 1982, FREQUENCY ANAL ENGLI, V0, P0
   Franco-Salvador M, 2016, INFORM PROCESS MANAG, V52, P550, DOI 10.1016/j.ipm.2015.12.004
   Glavas G, 2018, KNOWL-BASED SYST, V143, P1, DOI 10.1016/j.knosys.2017.11.041
   Gliozzo Alfio, 2006, P 21 INT C COMP LING, V0, P0
   Grimes Barbara F, 2000, ETHNOLOGUE LANGUAGES, V14th, P588
   Haneef I, 2019, SCI PROGRAMMING-NETH, V2019, P0, DOI 10.1155/2019/2962040
   Hassan S, 2009, P 2009 C EMP METH NA, V3, P1192
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Hwa R, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P392
   Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, V0, P94
   Kennedy Alistair, 2012, TECHNOLOGIES WORKSHO, V0, P1
   Latif S, 2018, INT CONF FRONT INFO, V0, PP88, DOI 10.1109/FIT.2018.00023
   Leacock C, 1998, LANG SPEECH & COMMUN, V0, P265
   Lin D, 1998, 15 INT C MACHINE LEA, V0, PP296, DOI 10.5555/645527.657297
   Liu Qianchu, 2019, P CONLL, V0, PP33, DOI 10.18653/v1/K19-1004
   Lo C-k, 2019, P 23 C COMP NAT LANG, V0, P206
   Meng L, 2013, INT J HYBRID INF TEC, V6, P1
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Miller George A, 1993, P WORKSH HUM LANG TE, V0, P303
   Mohammad S, 2007, P 2007 JOINT C EMP M, V0, P571
   Monz C, 2005, SIGIR 2005. PROCEEDINGS OF THE TWENTY-EIGHTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP520, DOI 10.1145/1076034.1076123
   Navigli R, 2019, NAT LANG ENG, V25, P693, DOI 10.1017/S1351324919000305
   Nie JY, 1999, SIGIR99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P74
   Resnik P, 1995, INT JOINT CONF ARTIF, V0, P448
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Sabet Ali, 2019, ARXIV191212481, V0, P0
   Saeed A, 2019, LANG RESOUR EVAL, V53, P397, DOI 10.1007/s10579-018-9438-7
   Vulic I, 2020, COMPUT LINGUIST, V46, P0, DOI 10.1162/coli_a_00391
   Vulic I, 2016, J ARTIF INTELL RES, V55, P953, DOI 10.1613/jair.4986
   Warschauer Mark, 2002, J COMPUT-MEDIAT COMM, V7, P0, DOI 10.1111/J.1083-6101.2002.TB00157.X
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P133
   Xiao M, 2014, AAAI CONF ARTIF INTE, V0, P1607
NR 49
TC 1
Z9 1
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2022
VL 21
IS 2
BP 
EP 
DI 10.1145/3472618
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0C7CH
UT WOS:000775466500004
DA 2023-11-10
ER

PT J
AU Wu, ZD
   Kang, J
   Jiang, Q
AF Wu, Zhendong
   Kang, Jie
   Jiang, Qian
TI Semantic key generation based on natural language
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE BERT; deep learning; key generation; semantic extraction; semantic key
AB In recent years, the public has become more aware of security concerns, and the demand for convenient and efficient encryption technology has increased. Biological data is used in identity authentication and key generation as the innate characteristic information of people. Biological key have the advantage of convenience and fast application without carrying any document; however, they also have the disadvantage of biological characteristic leaks and the inability to change. Based on the advantages and disadvantages of biological key, we propose the concept of semantic key. Language, a medium that fills the lives of people, has similar characteristics of convenience and fast application as biological key; however, semantic key will not reveal biological information. As the amount of semantic information is large, it can be changed at any time. Compared with biological key, it provides better security and flexibility. Therefore, we propose a semantic key generation framework of semantic extraction + feature stabilization + fuzzy extraction that improves the existing semantic extraction model and feature stabilization model and design the semantic key extraction model. In terms of artificial sentence formation, semantic key can be extracted with an accuracy of more than 99%, and an error rate of less than 0.5%.
C1 [Wu, Zhendong; Kang, Jie; Jiang, Qian] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Kang, J (通讯作者)，Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Peoples R China.
EM kangjie0004@hdu.edu.cn
FU National Natural Science Foundation of China [61772162]; National Key R&D Program of China [2018YFB0804102]; Key Projects of NSFC Joint Fund of China [U1866209]
CR Agirre E, 2012, P 6 INT WORKSHOP SEM, V0, P385
   Anees A, 2018, PATTERN RECOGN, V77, P289, DOI 10.1016/j.patcog.2017.11.018
   Balamurugan G, 2015, ADV NAT APPL SCI, V9, P525
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Devlin J, 2018, BERT PRETRAINING DEE, V0, P0, DOI DOI 10.18653/V1/N19-PROCEEDINGSOFNAACLHLT1423
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P55
   Geetika KM, 2014, 4 INT C COMP, V0, P1
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kelkboom EJC, 2011, IEEE T INF FOREN SEC, V6, P107, DOI 10.1109/TIFS.2010.2091637
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Li BH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9119
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Marelli Marco, 2014, P LREC, V0, P0
   Moi SH, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, V0, P418, DOI 10.1109/ICCAR.2017.7942730
   Orhan AE, 2018, INT C LEARN REPR, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy ND, 2020, MULTIMED TOOLS APPL, V79, P6823, DOI 10.1007/s11042-019-08507-y
   Scarlini B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3528
   Srivastava RK, 2015, ADV NEUR IN, V28, P0
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wang S, 2014, PATTERN RECOGN, V47, P1321, DOI 10.1016/j.patcog.2013.10.003
   Wieting J, 2016, 4 INT C LEARN REPR I, V0, P1
   Wu ZD, 2018, SECUR COMMUN NETW, V0, P0, DOI DOI 10.1155/2018/5783976
   Wu ZD, 2018, INFORM SCIENCES, V433, P431, DOI 10.1016/j.ins.2016.12.048
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
NR 36
TC 3
Z9 3
U1 3
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD JUL 15
PY 2022
VL 37
IS 7
BP 4041
EP 4064
DI 10.1002/int.22711
EA OCT 2021
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1M9SB
UT WOS:000708943300001
DA 2023-11-10
ER

PT J
AU Ling, HD
   Zhang, AP
   Yin, CC
   Li, DF
   Chang, MY
AF Ling, Huading
   Zhang, Aiping
   Yin, Changchun
   Li, Dafang
   Chang, Mengyu
TI Improve Representation for Cross-Language Clone Detection by Pretrain Using Tree Autoencoder
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Code clone detection; autoencoder; abstract syntax tree
ID digital continuity; blockchain; code
AB With the rise of deep learning in recent years, many code clone detection (CCD) methods use deep learning techniques and achieve promising results, so is cross-language CCD. However, deep learning techniques require a dataset to train the models. The dataset is typically small and has a gap between real-world clones due to the difficulty of collecting datasets for cross-language CCD. This creates a data bottleneck problem: data scale and quality issues will cause that model with a better design can still not reach its full potential. To mitigate this, we propose a tree autoencoder (TAE) architecture. It uses unsupervised learning to pretrain with abstract syntax trees (ASTs) of a large-scale dataset, then finetunes the trained encoder in the downstream CCD task. Our proposed TAE contains a tree Long Short-Term Memory (LSTM) encoder and a tree LSTM decoder. We design a novel embedding method for AST nodes, including type embedding and value embedding. In the training of TAE, we present an "encode and decode by layers" strategy and a node-level batch size design. For the CCD dataset, we propose a negative sampling method based on probability distribution. The experimental results on two datasets verify the effeteness of our embedding method, as well as that TAE and its pretrain enhance the performance of the CCD model. The node context information is well captured, and the reconstruction accuracy of the node-value reaches 95.45%. TAE pretrain improves the performance of CCD with a 4% increase in F1 score, which alleviates the data bottleneck problem.
C1 [Ling, Huading; Zhang, Aiping; Yin, Changchun] Nanjing Univ Aeronaut & Astronaut, Nanjing 210008, Peoples R China.
   [Li, Dafang] Nanjing Univ Finance & Econ, Sch Management Sci & Engn, Nanjing 210000, Peoples R China.
   [Chang, Mengyu] Mcgill Univ, Montreal, PQ H3G 1Y2, Canada.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of Finance & Economics; McGill University
RP Li, DF (通讯作者)，Nanjing Univ Finance & Econ, Sch Management Sci & Engn, Nanjing 210000, Peoples R China.
EM hdlingnuaa@163.com
FU National Key R&D Program of China [2021YFB3100700]; National Natural Science Foundation of China [62032025, 62076125, U20B2049, U20B2050, 61702236]; Natural Science Foundation of Jiangsu Province [BE2020106]; Guangdong Basic and Applied Basic Research Foundation [2021A1515012650]; Shenzhen Science and Technology Program [JCYJ20210324134810028]
CR Bengio S, 2015, ADV NEUR IN, V28, P0
   Bromley J, 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Büch L, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P95, DOI 10.1109/saner.2019.8668039
   Cheng X, 2017, IEICE T INF SYST, VE100D, P273, DOI 10.1587/transinf.2016EDP7334
   Cheng X, 2016, IEEE INT CONF AUTOM, V0, PP696, DOI 10.1145/2970276.2970363
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Ducasse S, 1999, PROCEEDINGS IEEE INTERNATIONAL CONFERENCE ON SOFTWARE MAINTENANCE - 1999 (ICSM99). `SOFTWARE MAINTENANCE FOR BUSINESS CHANGE (CAT. NO.99CB36360), V0, PP109, DOI 10.1109/ICSM.1999.792593
   Fang L, 2021, IEEE T DEPEND SECURE, V21, P1
   Gao Y, 2019, PROC IEEE INT CONF S, V0, PP145, DOI 10.1109/ICSME.2019.00025
   Ge CP, 2022, IEEE T DEPEND SECURE, V19, P2864, DOI 10.1109/TDSC.2021.3065999
   Ge CP, 2022, IEEE T DEPEND SECURE, V19, P2907, DOI 10.1109/TDSC.2021.3076580
   Ge CP, 2021, IEEE T DEPEND SECURE, V18, P2787, DOI 10.1109/TDSC.2020.2963978
   Ge CP, 2021, IEEE T DEPEND SECURE, V18, P1214, DOI 10.1109/TDSC.2019.2899300
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Jiang LX, 2007, PROC INT CONF SOFTW, V0, P96
   Kamiya T, 2002, IEEE T SOFTWARE ENG, V28, P654, DOI 10.1109/TSE.2002.1019480
   King DB, 2015, ACS SYM SER, V1214, P1
   Kraft Nicholas A, 2008, SEKE 2008. THE 20TH INTERNATIONAL CONFERENCE PROCEEDINGS ON SOFTWARE ENGINEERING & KNOWLEDGE ENGINEERING, V0, P54
   Li T, 2021, INTELL AUTOM SOFT CO, V29, P741, DOI 10.32604/iasc.2021.018496
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nafi KW, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), V0, PP1026, DOI 10.1109/ASE.2019.00099
   Nafi KW, 2018, IEEE INT WORK C SO, V0, PP139, DOI 10.1109/SCAM.2018.00023
   Peng H, 2015, LECT NOTES ARTIF INT, V9403, P547, DOI 10.1007/978-3-319-25159-2_49
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Perez Daniel, 2019, 2019 IEEE/ACM 16TH INTERNATIONAL CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR), V0, PP518, DOI 10.1109/MSR.2019.00078
   Ren YJ, 2022, IEEE T INTELL TRANSP, V23, P1639, DOI 10.1109/TITS.2021.3100103
   Ren YJ, 2021, CMC-COMPUT MATER CON, V66, P3271, DOI 10.32604/cmc.2021.011153
   Ren YJ, 2021, FUTURE GENER COMP SY, V115, P304, DOI 10.1016/j.future.2020.09.019
   Ren YJ, 2021, ACM T INTERNET TECHN, V21, P0, DOI 10.1145/3380749
   Ren YJ, 2020, CMC-COMPUT MATER CON, V63, P1471, DOI 10.32604/cmc.2020.06745
   Ren YJ, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20010207
   Ren YJ, 2019, MATH BIOSCI ENG, V16, P1874, DOI 10.3934/mbe.2019091
   Sajnani H, 2016, PROC INT CONF SOFTW, V0, PP1157, DOI 10.1145/2884781.2884877
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wei HH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3034
   Yu H, 2019, INT C PROGRAM COMPRE, V0, PP70, DOI 10.1109/ICPC.2019.00021
   Zhang J, 2019, PROC INT CONF SOFTW, V0, PP783, DOI 10.1109/ICSE.2019.00086
   Zhang XR, 2022, INTELL AUTOM SOFT CO, V32, P1041, DOI 10.32604/iasc.2022.016543
   Zhang XR, 2022, COMPUT SYST SCI ENG, V41, P1043, DOI 10.32604/csse.2022.022305
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 41
TC 0
Z9 0
U1 4
U2 9
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD JUN 15
PY 2022
VL 33
IS 3
BP 1561
EP 1577
DI 10.32604/iasc.2022.027349
PG 17
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA 0G2SZ
UT WOS:000777901500003
DA 2023-11-10
ER

PT J
AU Castro, E
   Godavarthi, A
   Rubinfien, J
   Givechian, K
   Bhaskar, D
   Krishnaswamy, S
AF Castro, Egbert
   Godavarthi, Abhinav
   Rubinfien, Julian
   Givechian, Kevin
   Bhaskar, Dhananjay
   Krishnaswamy, Smita
TI Transformer-based protein generation with regularized latent space optimization
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID landscape; design
AB The space of possible proteins is vast, and optimizing proteins for specific target properties computationally is an ongoing challenge, even with large amounts of data. Castro and colleagues combine a transformer-based model with regularized prediction heads to form a smooth and pseudoconvex latent space that allows for easier navigation and more efficient optimization of proteins. The development of powerful natural language models has improved the ability to learn meaningful representations of protein sequences. In addition, advances in high-throughput mutagenesis, directed evolution and next-generation sequencing have allowed for the accumulation of large amounts of labelled fitness data. Leveraging these two trends, we introduce Regularized Latent Space Optimization (ReLSO), a deep transformer-based autoencoder, which features a highly structured latent space that is trained to jointly generate sequences as well as predict fitness. Through regularized prediction heads, ReLSO introduces a powerful protein sequence encoder and a novel approach for efficient fitness landscape traversal. Using ReLSO, we explicitly model the sequence-function landscape of large labelled datasets and generate new molecules by optimizing within the latent space using gradient-based methods. We evaluate this approach on several publicly available protein datasets, including variant sets of anti-ranibizumab and green fluorescent protein. We observe a greater sequence optimization efficiency (increase in fitness per optimization step) using ReLSO compared with other approaches, where ReLSO more robustly generates high-fitness sequences. Furthermore, the attention-based relationships learned by the jointly trained ReLSO models provide a potential avenue towards sequence-level fitness attribution information.
C1 [Castro, Egbert; Krishnaswamy, Smita] Yale Univ, Computat Biol & Bioinformat Program, New Haven, CT 06520 USA.
   [Godavarthi, Abhinav; Krishnaswamy, Smita] Yale Univ, Dept Appl Math, New Haven, CT 06520 USA.
   [Rubinfien, Julian] Yale Univ, Dept Math, New Haven, CT 06520 USA.
   [Givechian, Kevin; Bhaskar, Dhananjay; Krishnaswamy, Smita] Yale Univ, Dept Genet, New Haven, CT 06520 USA.
   [Krishnaswamy, Smita] Yale Univ, Dept Comp Sci, POB 2158, New Haven, CT 06520 USA.
C3 Yale University; Yale University; Yale University; Yale University; Yale University
RP Krishnaswamy, S (通讯作者)，Yale Univ, Computat Biol & Bioinformat Program, New Haven, CT 06520 USA.; Krishnaswamy, S (通讯作者)，Yale Univ, Dept Appl Math, New Haven, CT 06520 USA.; Krishnaswamy, S (通讯作者)，Yale Univ, Dept Genet, New Haven, CT 06520 USA.; Krishnaswamy, S (通讯作者)，Yale Univ, Dept Comp Sci, POB 2158, New Haven, CT 06520 USA.
EM smita.krishnaswamy@yale.edu
FU National Library of Medicine training grant [LM007056]; Yale-Boehringer Ingelheim Biomedical Data Science Fellowship; NIGMS [R01GM135929, R01GM130847]; NSF Career Grant [2047856]; Chan-Zuckerberg Initiative Grants [CZF2019-182702, CZF2019-002440]; Sloan Fellowship [FG-2021-15883]; Direct For Computer & Info Scie & Enginr; Div Of Information & Intelligent Systems [2047856] Funding Source: National Science Foundation
CR Alley EC, 2019, NAT METHODS, V16, P1315, DOI 10.1038/s41592-019-0598-1
   Angermueller C, 2019, P INT C LEARN REPR A, V0, P0
   Arnold FH, 1998, ACCOUNTS CHEM RES, V31, P125, DOI 10.1021/ar960017f
   Biswas S, 2021, NAT METHODS, V18, P389, DOI 10.1038/s41592-021-01100-y
   Brookes DH, 2018, PREPRINT, V0, P0
   Brookes DH, 2019, PR MACH LEARN RES, V97, P0
   Castro E, 2020, IEEE INT CONF BIG DA, V0, PP4519, DOI 10.1109/BigData50022.2020.9378305
   Chen K, 2020, NAT CATAL, V3, P203, DOI 10.1038/s41929-019-0385-5
   Detlefsen NS, 2022, NAT COMMUN, V13, P0, DOI 10.1038/s41467-022-29443-w
   Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Linder J, 2020, PREPRINT, V0, P0
   Liu G, 2020, BIOINFORMATICS, V36, P2126, DOI 10.1093/bioinformatics/btz895
   Mistry J, 2021, NUCLEIC ACIDS RES, V49, PD412, DOI 10.1093/nar/gkaa913
   Norn C, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2017228118
   Rao R, 2020, BIORXIV, V0, P0, DOI DOI 10.1101/2020.12.15.422761v1
   Rao RS, 2019, ADV NEUR IN, V32, P0
   Rives A, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2016239118
   Rodrigues CHM, 2021, PROTEIN SCI, V30, P60, DOI 10.1002/pro.3942
   Rohl CA, 2004, METHOD ENZYMOL, V383, P66
   Romero PA, 2009, NAT REV MOL CELL BIO, V10, P866, DOI 10.1038/nrm2805
   Sarkisyan KS, 2016, NATURE, V533, P397, DOI 10.1038/nature17995
   Starr TN, 2016, PROTEIN SCI, V25, P1204, DOI 10.1002/pro.2897
   Tiessen Axel, 2012, BMC RES NOTES, V5, P85, DOI 10.1186/1756-0500-5-85
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vig J, 2020, PREPRINT, V0, P0
   Wu NC, 2016, ELIFE, V5, P0, DOI 10.7554/eLife.16965
   Yang KK, 2019, NAT METHODS, V16, P687, DOI 10.1038/s41592-019-0496-6
   Yoshida Y, 2017, PREPRINT, V0, P0
NR 30
TC 10
Z9 11
U1 8
U2 25
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD OCT 15
PY 2022
VL 4
IS 10
BP 840
EP 851
DI 10.1038/s42256-022-00532-1
EA SEP 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 5M4UW
UT WOS:000859605000001
DA 2023-11-10
ER

PT J
AU Gong, N
   Yao, NM
   Guo, S
AF Gong, Ning
   Yao, Nianmin
   Guo, Shun
TI Seeds: Sampling-Enhanced Embeddings
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Task analysis; Training; Estimation; Semantics; Standards; Learning systems; Heuristic algorithms; Natural language processing; negative sampling (NS); word embedding; word representation
AB Finding a desirable sampling estimator has a profound impact on the development of static word embedding models, such as continue-bag-of-words (CBOW) and skip gram (SG), which have been generally accepted as popular low-resource algorithms to generate task-agnostic word representations. Due to the prevalence of large-scale pretrained models, less attention has been paid to these static models in the recent years. However, compared with the dynamic embedding models (e.g., BERT), these static models are straightforward to interpret, cost effective to train, and out-of-box to deploy, thus are still widely used in various downstream models until now. Therefore, it is still of considerable significance to study and improve them, especially the crucial components shared by these static models. In this article, we focus on negative sampling (NS), a key component shared by the sampling-based static models, by investigating and mitigating some critical problems of the sampling core. Concretely, we propose Seeds, a sampling enhanced embedding framework, to learn static word embeddings by a new algorithmic innovation for replacing the NS estimator, in which multifactor global priors are considered dynamically for different training pairs. Then, we implement this framework by four concrete models. For the first two implementations, namely CBOW-GP and SG-GP, both negative words and positive auxiliaries are sampled. And for the other two implementations, CBOW-GN and SG-GN, estimations are simplified by sampling only the negative instances. Extensive experimental results across a variety of standard intrinsic and extrinsic tasks demonstrate that embeddings learned by the proposed models outperform their NS-based counterparts, such as CBOW-NS and SG-NS, as well as other strong baselines.
C1 [Gong, Ning; Yao, Nianmin; Guo, Shun] Dalian Univ Technol, Sch Comp Sci, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Yao, NM (通讯作者)，Dalian Univ Technol, Sch Comp Sci, Dalian 116024, Peoples R China.
EM ginoailab@gmail.com; lucos@dlut.edu.cn; guoshun@mail.dlut.edu.cn
FU National Key Research and Development Program of China [2018AAA0100300]; Innovation Foundation of Science and Technology of Dalian via the project of Study on the Key Management and Privacy Preservation in VANET [2018J12GX045]
CR [Anonymous], 2015, T ASSOC COMPUT LING, V0, P0, DOI DOI 10.1162/TACL_A_00134
   Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   CHURCH KW, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P76
   Dash S, 2019, ARAB J SCI ENG, V0, P1
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dyer C, 2014, ABS14108251, V0, P1
   Fonarev A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2028, DOI 10.18653/v1/P17-1185
   Fu RJ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1199
   Ghahramani, 2014, NEURAL WORD EMBEDDIN, V0, P0
   Gnewuch NHMichael, 2019, ABS190410796, V0, P1
   Guo G, 2018, PROCEEDINGS OF THE INTERNATIONAL SILAGE CONFERENCE (XVIII ISC 2018), V0, P0
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jameel S, 2016, COLING 2016 26 INT C, V0, P1849
   Jameel S, 2019, AAAI CONF ARTIF INTE, V0, PP6562, DOI 10.1609/aaai.v33i01.33016562
   Kotnis B, 2017, ABS170806816, V0, P1
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Landgraf, 2017, ABS170509755, V0, P1
   Ma Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3698
   Mariet Z, 2019, P TWENTYSECOND INT C, V89, P2251
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mu C, 2018, ABS180400306, V0, P1
   Peng HR, 2019, ADV ENERGY MATER, V9, P0, DOI 10.1002/aenm.201803665
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Schlechtweg D, 2019, ABS190602479, V0, P1
   Shi B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2494
   Soleimani BH, 2018, AAAI CONF ARTIF INTE, V0, P5481
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Ustalov D, 2017, P 15 C EUR CHAPT ASS, V2, P543, DOI 10.18653/v1/e17-2087
   Tran VA, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1201, DOI 10.1145/3331184.3331337
   Yang Z, 2020, P 26 ACM SIGKDD INT, V0, P2005
   Zhang YQ, 2019, PROC INT CONF DATA, V0, PP614, DOI 10.1109/ICDE.2019.00061
   Zhu LY, 2021, IEEE T NEUR NET LEAR, V32, P2561, DOI 10.1109/TNNLS.2020.3006531
NR 34
TC 1
Z9 1
U1 3
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD FEB 15
PY 2022
VL 33
IS 2
BP 577
EP 586
DI 10.1109/TNNLS.2020.3028099
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA YU4LL
UT WOS:000752016400013
PM 33079679
DA 2023-11-10
ER

PT J
AU Lee, MC
   Chang, JW
   Yeh, SC
   Chia, TL
   Liao, JS
   Chen, XM
AF Lee, Ming-Che
   Chang, Jia-Wei
   Yeh, Sheng-Cheng
   Chia, Tsorng-Lin
   Liao, Jie-Shan
   Chen, Xu-Ming
TI Applying attention-based BiLSTM and technical indicators in the design and performance analysis of stock trading strategies
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Attention mechanism; Long short-term memory; Stock price trend forecast; Trading strategies
ID big data; deep; news
AB With the development of the Internet, information on the stock market has gradually become transparent, and stock information is easy to obtain. For investors, investment performance depends on the amount of capital and effective trading strategies. The analysis tool commonly used by investors and securities analysts is technical analysis (TA). Technical analysis is the study of past and current financial market information, and a large amount of statistical data is used to predict price trends and determine trading strategies. Technical indicators (TIs) are a type of technical analysis that summarizes possible future trends of stock prices based on historical statistical data to assist investors in making decisions. The stock price trend is a typical time series data with special characteristics such as trend, seasonality, and periodicity. In recent years, time series deep neural networks (DNNs) have demonstrated their powerful performance in machine translation, speech processing, and natural language processing fields. This research proposes the concept of attention-based BiLSTM (AttBiLSTM) applied to trading strategy design and verified the effectiveness of a variety of TIs, including stochastic oscillator, RSI, BIAS, W%R, and MACD. This research also proposes two trading strategies that suitable for DNN, combining with TIs and verifying their effectiveness. The main contributions of this research are as follows: (1) As our best knowledge, this is the first research to propose the concept of applying TIs to the LSTM-attention time series model for stock price prediction. (2) This study introduces five well-known TIs, which reached a maximum of 68.83% in the accuracy of stock trend prediction. (3) This research introduces the concept of exporting the probability of the deep model to the trading strategy. On the backtest of TPE0050, the experimental results reached the highest return on investment of 42.74%. (4) This research concludes from an empirical point of view that technical analysis combined with time series deep neural network has significant effects in stock price prediction and return on investment.
C1 [Lee, Ming-Che; Yeh, Sheng-Cheng; Chia, Tsorng-Lin; Liao, Jie-Shan; Chen, Xu-Ming] Ming Chuan Univ, Dept Comp & Commun Engn, Taoyuan, Taiwan.
   [Chang, Jia-Wei] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Ming Chuan University; National Taichung University of Science & Technology
RP Chang, JW (通讯作者)，Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM jwchang@nutc.edu.tw
FU Ministry of Science and Technology (MOST) [MOST 110-2221-E-130-008]
CR Abarbanell JS, 1997, J ACCOUNTING RES, V35, P1, DOI 10.2307/2491464
   Abdulali A, 2006, BIAS RATIO MEASURING, V2006, P0
   ACM, 2018, FATH DEEP LEARN REV, V0, P0
   Alahi A, 2016, PROC CVPR IEEE, V0, PP961, DOI 10.1109/CVPR.2016.110
   Alshemali B, 2020, KNOWL-BASED SYST, V191, P0, DOI 10.1016/j.knosys.2019.105210
   Amanullah MA, 2020, COMPUT COMMUN, V151, P495, DOI 10.1016/j.comcom.2020.01.016
   [Anonymous], 2012, UFLDL TUTORIAL, V0, P0
   [Anonymous], 1964, RANDOM CHARACTER STO, V0, P0
   Appel G, 2005, TECHNICAL ANAL POWER, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bishop CM, 2006, MACH LEARN, V128, P66
   Brealey RA, 2012, PRINCIPLES CORPORATE, V0, P0
   Cakra YE, 2015, INT C ADV COMP SCI I, V0, PP147, DOI 10.1109/ICACSIS.2015.7415179
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), V0, PP1, DOI 10.1109/SPW.2018.00009
   Chen WL, 2018, DATA KNOWL ENG, V118, P14, DOI 10.1016/j.datak.2018.08.003
   Cheng Y, 2019, JOINT TRAINING NEURA, V0, PP25, DOI 10.1007/978-981-32-9748-7_3
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, P0, DOI 10.1016/j.chaos.2020.109864
   Chiu PS, 2020, IEEE ACCESS, V8, P62032, DOI 10.1109/ACCESS.2020.2984383
   Choi E, 2016, ADV NEUR IN, V29, P0
   DELONG JB, 1990, J FINANC, V45, P379, DOI 10.2307/2328662
   Deng JK, 2022, IEEE T PATTERN ANAL, V44, P5962, DOI 10.1109/TPAMI.2021.3087709
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Gamboa JCB, 2017, ARXIV170101887, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Habibzadeh H, 2018, IEEE COMMUN MAG, V56, P78, DOI 10.1109/MCOM.2018.1700304
   Hu ZD, 2021, OIL GAS SCI TECHNOL, V76, P0, DOI 10.2516/ogst/2021010
   Lee MC, 2017, INFORM PROCESS LETT, V128, P14, DOI 10.1016/j.ipl.2017.07.010
   Lee MC, 2021, COMPUT SCI INF SYST, V18, P401, DOI 10.2298/CSIS200301002L
   Lee MC, 2020, MULTIMED TOOLS APPL, V79, P19629, DOI 10.1007/s11042-020-08841-6
   Lee S, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20072157
   Li C, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1141, DOI 10.1145/3292500.3330983
   Li H, 2018, P MACHINE LEARNING R, V95, P454
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Livieris IE, 2020, NEURAL COMPUT APPL, V32, P17351, DOI 10.1007/s00521-020-04867-x
   Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, V0, PP293, DOI 10.1016/B978-0-12-815480-9.00015-3
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mnih V, 2014, ADV NEUR IN, V27, P0
   Mohammadi M, 2018, IEEE COMMUN MAG, V56, P94, DOI 10.1109/MCOM.2018.1700298
   Murphy JJ, 1999, TECHNICAL ANAL FINAN, V0, P0
   Nelson DMQ, 2017, IEEE IJCNN, V0, PP1419, DOI 10.1109/IJCNN.2017.7966019
   Özkaya U, 2021, AUTOMAT CONSTR, V123, P0, DOI 10.1016/j.autcon.2020.103525
   Öztürk S, 2021, BIOMED SIGNAL PROCES, V68, P0, DOI 10.1016/j.bspc.2021.102601
   Öztürk S, 2021, PROCEDIA COMPUT SCI, V183, P624, DOI 10.1016/j.procs.2021.02.106
   Peng J, 2019, IEEE ACCESS, V7, P7555, DOI 10.1109/ACCESS.2018.2890091
   Qi Y, 2018, COMMUN ACM, V61, P65, DOI 10.1145/3239550
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russell, 2010, ARTIF INTELL, V0, P0
   Schubert, 2019, METATAXIS CONTRASTIV, V2, P0
   Sezer OB, 2020, APPL SOFT COMPUT, V90, P0, DOI 10.1016/j.asoc.2020.106181
   Shi QF, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-18471-z
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Skrobek D, 2020, ENERGIES, V13, P0, DOI 10.3390/en13246601
   Stilgoe J, 2018, SOC STUD SCI, V48, P25, DOI 10.1177/0306312717741687
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tian ZH, 2018, IEEE ACCESS, V6, P35355, DOI 10.1109/ACCESS.2018.2846590
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Werbos P, 1974, REGRESSION NEW TOOLS, V0, P0
   Widrow B, 1960, ADAPTIVE SWITCHING C, V0, P0, DOI DOI 10.21236/AD0241531
   Wilder JW, 1978, TREND RES, V0, P0
   Williams LR, 1979, I MADE 1000000 DOLL, V0, P0
   Xiong W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5934, DOI 10.1109/ICASSP.2018.8461870
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhao R, 2019, MECH SYST SIGNAL PR, V115, P213, DOI 10.1016/j.ymssp.2018.05.050
NR 65
TC 5
Z9 5
U1 6
U2 42
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD AUG 15
PY 2022
VL 34
IS 16
BP 13267
EP 13279
DI 10.1007/s00521-021-06828-4
EA JAN 2022
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3D6KJ
UT WOS:000747641400001
PM 35106029
DA 2023-11-10
ER

PT J
AU Jiang, WC
   Lu, JR
   Liang, TC
   Hong, X
   Lu, JF
   Wu, T
AF Jiang, Wenchao
   Lu, Jiarong
   Liang, Tiancai
   Hong, Xiao
   Lu, Jianfeng
   Wu, Tao
TI BERTBooster: A knowledge enhancement method jointing incremental training and gradient optimization
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE gradient optimization; incremental training; knowledge enhanced; natural language processing; pretraining models
AB The knowledge-enhanced BERT model solves the problem of lacking knowledge in downstream tasks by injecting external expertize, and achieves higher accuracy compared with BERT model. However, owning to large-scale external knowledge is utilized into knowledge-enhanced BERT, some shortcomings comes such as information noise, lower accuracy and weak generalization ability, and so on. To solve this problem, a knowledge enhancement method BERTBooster which combines incremental learning and gradient optimization is proposed. BERTBooster disassembles the input text corpus into entity noun sets through entity noun recognition, and uses the incremental learning task denoising entity auto-encoder to create an incremental task set of entity nouns and external knowledge triples. Furthermore, BERTBooster introduces a new gradient optimization algorithm ChildTuningF into BERT model to improve the generalization ability. BERTBooster can effectively improve the factual knowledge cognition ability of CAGBERT model and improve the accuracy of the model in downstream tasks. Experiments are carried out on six public data sets such as Book_Review, LCQMC, XNLI, Law_QA, Insureace_QA, and NLPCC-DBQA. The experimental results show that the accuracy rate in downstream tasks is increased by 0.65% on average after using BERTBooster on CAGBERT.
C1 [Jiang, Wenchao; Lu, Jiarong; Hong, Xiao] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou, Peoples R China.
   [Jiang, Wenchao; Liang, Tiancai] Guangzhou Univ, Inst Artificial Intelligence & Blockchain, Guangzhou, Peoples R China.
   [Lu, Jianfeng] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Wu, Tao] Chinese Peoples Armed Police Force, Guangdong Prov Corps Hosp, Guangzhou, Peoples R China.
C3 Guangdong University of Technology; Guangzhou University; Wuhan University of Science & Technology
RP Hong, X (通讯作者)，Guangdong Univ Technol, Sch Comp, Guangzhou 510006, Peoples R China.
EM wh_red@163.com
FU Science and Technology Planning Project of Guangdong Province [2019B010139001]
CR Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   [陈德光 Chen Deguang], 2021, 计算机科学与探索 JOURNAL OF FRONTIERS OF COMPUTER SCIENCE & TECHNOLOGY, V15, P1359
   Devlin J, 2018, ARXIV, V1, P4171
   Duan N, 2018, LECT NOTES ARTIF INT, V10619, P954, DOI 10.1007/978-3-319-73618-1_86
   Foret Pierre, 2020, INT C LEARN REPR, V0, P0
   Gan WB, 2022, INT J INTELL SYST, V37, P2012, DOI 10.1002/int.22763
   HINTON GE, 2012, RESEARCHGATE, V3, P212, DOI 10.9774/GLEAF.978-1-909493-38-4_2
   Jiang N, 2023, IEEE T KNOWL DATA EN, V35, P5865, DOI 10.1109/TKDE.2022.3174044
   Keskar NS, 2017, ICLR, V0, P0
   Li Y, 2023, CURR PSYCHOL, V42, P10629, DOI 10.1007/s12144-021-02334-x
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P43
   Sun X, 2021, AAAI CONF ARTIF INTE, V35, P11648
   Sun Y, 2019, ARXIV, V0, P0
   [孙毅 Sun Yi], 2021, 中文信息学报 JOURNAL OF CHINESE INFORMATION PROCESSING, V35, P10
   Tseng H-Y, 2020, P ASIAN C COMPUTER V, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vincent Pascal, 2008, P 25 INT C MACH LEAR, V0, P1096
   Xu B, 2017, LECT NOTES ARTIF INT, V10351, P428, DOI 10.1007/978-3-319-60045-1_44
   Xu RX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P9514
   Yun W, 2021, INT J INTELL SYST, V36, P1686, DOI 10.1002/int.22357
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
NR 23
TC 0
Z9 0
U1 4
U2 11
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD NOV 15
PY 2022
VL 37
IS 11
BP 9390
EP 9403
DI 10.1002/int.22998
EA AUG 2022
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4V0ZM
UT WOS:000842565200001
DA 2023-11-10
ER

PT J
AU Mi, CG
   Xie, L
   Zhang, YN
AF Mi, Chenggang
   Xie, Lei
   Zhang, Yanning
TI Improving data augmentation for low resource speech-to-text translation with diverse paraphrasing
SO NEURAL NETWORKS
LA English
DT Article
DE Data augmentation; Speech translation; Paraphrasing
AB High quality end-to-end speech translation model relies on a large scale of speech-to-text training data, which is usually scarce or even unavailable for some low-resource language pairs. To overcome this, we propose a target-side data augmentation method for low-resource language speech translation. In particular, we first generate large-scale target-side paraphrases based on a paraphrase generation model which incorporates several statistical machine translation (SMT) features and the commonly used recurrent neural network (RNN) feature. Then, a filtering model which consists of semantic similarity and speech-word pair co-occurrence was proposed to select the highest scoring source speech-target paraphrase pairs from candidates. Experimental results on English, Arabic, German, Latvian, Estonian, Slovenian and Swedish paraphrase generation show that the proposed method achieves significant and consistent improvements over several strong baseline models on PPDB datasets (http://paraphrase. org/). To introduce the results of paraphrase generation into the low-resource speech translation, we propose two strategies: audio-text pairs recombination and multiple references training. Experimental results show that the speech translation models trained on new audio-text datasets which combines the paraphrase generation results lead to substantial improvements over baselines, especially on low-resource languages. (C)& nbsp;2022 Elsevier Ltd. All rights reserved.
C1 [Mi, Chenggang] Xian Int Studies Univ, Foreign Language & Literature Inst, Xian, Peoples R China.
   [Xie, Lei; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated AeroSp Ground Ocean Big, Xian, Peoples R China.
C3 Xi'an International Studies University; Northwestern Polytechnical University
RP Mi, CG (通讯作者)，Xian Int Studies Univ, Foreign Language & Literature Inst, Xian, Peoples R China.
EM michenggang@nwpu.edu.cn; lxie@nwpu.edu.cn; zhangyanning@nwpu.edu.cn
FU National Natural Science Foundation of China [61906158]
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Agarap AF, 2018, ARXIV PREPRINT ARXIV, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Bahar P, 2019, ABS191108876 ARXIV, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bhagat R, 2013, COMPUT LINGUIST, V39, P463, DOI 10.1162/COLI_a_00166
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chung YA, 2019, INT CONF ACOUST SPEE, V0, PP7170, DOI 10.1109/ICASSP.2019.8683550
   Chung YA, 2018, INTERSPEECH, V0, PP811, DOI 10.21437/Interspeech.2018-2341
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   Dahlmann L, 2017, P 2017 C EMP METH NA, V0, PP1411, DOI 10.18653/V1/D17-1148
   Denkowski M, 2011, P 6 WORKSHOP STAT MA, V0, P0
   Di Gangi M, 2019, DATA AUGMENTATION EN, V0, P0, DOI DOI 10.5281/zenodo.3525492
   Dong L, 2017, P 2017 C EMP METH NA, V0, PP875, DOI 10.18653/ v1/D17-1091
   Feng Y, 2020, AAAI CONF ARTIF INTE, V34, P59
   Ganitkevitch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P4276
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Gao SL, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P639
   Guo YN, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P501
   Gupta A, 2018, AAAI CONF ARTIF INTE, V0, P5149
   Hartmann W, 2016, INTERSPEECH, V0, PP2378, DOI 10.21437/Interspeech.2016-1386
   Hayashi T, 2018, IEEE W SP LANG TECH, V0, PP426, DOI 10.1109/SLT.2018.8639619
   He W, 2016, AAAI CONF ARTIF INTE, V0, P151
   Jia Y, 2019, INT CONF ACOUST SPEE, V0, PP7180, DOI 10.1109/ICASSP.2019.8683343
   Kamper H, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP719, DOI 10.1109/ASRU.2017.8269008
   KNESER R, 1995, INT CONF ACOUST SPEE, V0, PP181, DOI 10.1109/ICASSP.1995.479394
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kumar A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3609
   Lample Guillaume, 2017, ARXIV171100043, V0, P0
   Liu L, 2012, P 2012 JOINT C EMP M, V0, P402
   Liu Yang, 2005, P 43 ANN M ASS COMP, V0, PP459, DOI 10.3115/1219840.1219897
   Lopez A, 2008, ACM COMPUT SURV, V40, P0, DOI 10.1145/1380584.1380586
   Mallinson J, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P881
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Park DS, 2019, INTERSPEECH, V0, PP2613, DOI 10.21437/Interspeech.2019-2680
   Post Matt, 2018, P 3 C MACH TRANSL RE, V0, PP186, DOI 10.18653/v1/W18-6319
   Prasad NV, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), V0, PP156, DOI 10.1109/ASRU.2013.6707722
   Qian LH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3173
   Renduchintala A, 2018, INTERSPEECH, V0, PP2394, DOI 10.21437/Interspeech.2018-2456
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Snover M, 2006, STUDY TRANSLATION ED, V0, P0
   Sperber Matthias, 2020, P 58 ANN M ASS COMPU, V0, PP7409, DOI 10.18653/v1/2020.acl-main. 661
   Taylor P, 2009, TEXT TO SPEECH SYNTH, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang C, 2020, ABS200710310 ARXIV, V0, P0
   Wang S, 2019, ABS181100119 ARXIV, V0, P0
   Wang X, 2017, AAAI CONF ARTIF INTE, V0, P3330
   Witteveen Sam, 2019, P 3 WORKSH NEUR GEN, V0, PP215, DOI 10.18653/V1/D19-5623
   Zens R, 2008, IWSLT, V0, P0
   Zheng RJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3188
   Zhou Z, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P113
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1097, DOI 10.1145/3209978.3210080
NR 53
TC 2
Z9 2
U1 3
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD APR 15
PY 2022
VL 148
IS 
BP 194
EP 205
DI 10.1016/j.neunet.2022.01.016
EA FEB 2022
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA 0U8HX
UT WOS:000787889400017
PM 35151006
DA 2023-11-10
ER

PT J
AU Tan, JH
   Tan, YH
   Chan, CS
   Chuah, JH
AF Tan, Jia Huei
   Tan, Ying Hua
   Chan, Chee Seng
   Chuah, Joon Huang
TI ACORT: A compact object relation transformer for parameter efficient image captioning
SO NEUROCOMPUTING
LA English
DT Article
DE Image captioning; Deep network compression; Deep learning
ID neural machine translation
AB Recent research that applies Transformer-based architectures to image captioning has resulted in stateof-the-art image captioning performance, capitalising on the success of Transformers on natural language tasks. Unfortunately, though these models work well, one major flaw is their large model sizes. To this end, we present three parameter reduction methods for image captioning Transformers: Radix Encoding, cross-layer parameter sharing, and attention parameter sharing. By combining these methods, our proposed ACORT models have 3.7x to 21.6x fewer parameters than the baseline model without compromising test performance. Results on the MS-COCO dataset demonstrate that our ACORT models are competitive against baselines and SOTA approaches, with CIDEr score P126. Finally, we present qualitative results and ablation studies to demonstrate the efficacy of the proposed changes further. Code and pre-trained models are publicly available at https://github.com/jiahuei/sparse-image-captioning. (c) 2022 Published by Elsevier B.V.
C1 [Tan, Jia Huei; Tan, Ying Hua; Chan, Chee Seng] Univ Malaya, Fac Comp Sci & Informat Technol, CISiP, Kuala Lumpur 50603, Malaysia.
   [Chuah, Joon Huang] Univ Malaya, Fac Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Universiti Malaya
RP Chan, CS (通讯作者)，Univ Malaya, Fac Comp Sci & Informat Technol, CISiP, Kuala Lumpur 50603, Malaysia.
EM tanjiahuei@siswa.um.edu.my; tanyinghua@siswa.um.edu.my; cs.chan@um.edu.my; jhchuah@um.edu.my
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Bai S, 2019, ADV NEURAL INFORM PR, V0, P690
   Chen H, 2018, AAAI CONF ARTIF INTE, V0, P6706
   Chen WL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1975
   Cornia Marcella, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10575, DOI 10.1109/CVPR42600.2020.01059
   Dabre R, 2019, AAAI CONF ARTIF INTE, V0, P6292
   Dai XL, 2019, IEEE T COMPUT, V68, P1487, DOI 10.1109/TC.2019.2914438
   Dai XL, 2020, IEEE T COMPUT, V69, P441, DOI 10.1109/TC.2019.2954495
   Dong X, 2019, ADV NEUR IN, V0, P759
   Dong XY, 2019, PROC CVPR IEEE, V0, PP1761, DOI 10.1109/CVPR.2019.00186
   Fang H, 2015, PROC CVPR IEEE, V0, PP1473, DOI 10.1109/CVPR.2015.7298754
   Gu Jiatao, 2019, ADV NEURAL INFORM PR, V32, P11179
   Guo TZ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P751
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Herdade S, 2019, ADV NEUR IN, V32, P0
   Hossain MZ, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3295748
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Iandola FN, 2016, SQUEEZENET ALEXNET L, V0, P0
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kingma DP, 2014, C TRACK P, V0, P0
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Li RF, 2020, NEUROCOMPUTING, V396, P92, DOI 10.1016/j.neucom.2020.02.041
   Li X, 2016, ADV NEUR IN, V29, P0
   Lin MB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P673
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Lorraine J, 2020, PR MACH LEARN RES, V108, P1540
   Parameswaran SN, 2017, NCVPRIPG, V0, P338
   Pham H, 2018, PR MACH LEARN RES, V80, P0
   Prato Gabriele, 2020, FINDINGS ASS COMPUTA, V0, PP1, DOI 10.18653/V1/2020.FINDINGS-EMNLP.1
   Press O, 2017, P 15 C EUROPEAN CHAP, V2, P157, DOI 10.18653/V1/E17-2025
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Sachan DS, 2018, P 3 C MACH TRANSL RE, V0, PP261, DOI 10.18653/v1/W18-6327
   Sharif N, 1900, P3540, V0, P0
   Shi KY, 2018, INTERSPEECH, V0, P1254
   Tan JH, 2019, IEEE T MULTIMEDIA, V21, P2686, DOI 10.1109/TMM.2019.2904878
   Tan YH, 2019, NEUROCOMPUTING, V333, P86, DOI 10.1016/j.neucom.2018.12.026
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5797
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xia YC, 2019, AAAI CONF ARTIF INTE, V0, P5466
   Xiao T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5292
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yingwei Pan, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10968, DOI 10.1109/CVPR42600.2020.01098
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu Z, 2021, NEUROCOMPUTING, V445, P72, DOI 10.1016/j.neucom.2021.03.026
   Zhou LW, 2018, PROC CVPR IEEE, V0, PP8739, DOI 10.1109/CVPR.2018.00911
   Zoph B, 2018, PROC CVPR IEEE, V0, PP8697, DOI 10.1109/CVPR.2018.00907
NR 64
TC 3
Z9 3
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD APR 14
PY 2022
VL 482
IS 
BP 60
EP 72
DI 10.1016/j.neucom.2022.01.081
EA FEB 2022
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA ZI7EZ
UT WOS:000761781400006
DA 2023-11-10
ER

PT J
AU Eshkevari, M
   Rezaee, MJ
   Saberi, M
   Hussain, OK
AF Eshkevari, Milad
   Rezaee, Mustafa Jahangoshai
   Saberi, Morteza
   Hussain, Omar K.
TI An end-to-end ranking system based on customers reviews: Integrating semantic mining and MCDM techniques
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE End-to-end ranking; Aspect-based sentiment analysis; Dawid-skene algorithm; Best-worst method; Customer reviews; Sydney hotels ranking
ID support
AB Considering customer reviews is one of the challenges of real-world decision models. These reviews can be on different platforms and include a large amount of information and may also include incomprehensible and unrelated phrases. The main advantage of customer reviews is the realistic view that it provides a realistic view of the product or service. Therefore, converting unstructured and incoherent customer-based reviews into machine learning language and ultimately turning it into a decision model is very important. In this paper, we propose an end-to-end ranking method for integrating mechanisms such as text processing, sentiment analysis and the multi-criteria decision-making technique. The proposed ranking method relies on the integration of three methods, namely, the aspect-based sentiment analysis (ABSA) method, the Dawid-Skene algorithm and the Best Worst Method (BWM). In other words, the proposed work encompasses four major steps: i) crawling customer reviews, ii) preprocessing, iii) aspect term extraction, aspect category detection and polarity detection, and iv) designing a decision-making model. The main contribution of this study is to consider ABSA at three levels simultaneously and integrate ABSA and BWM in designing an end-to-end ranking method for ranking the quality of hotel services, facilities and amenities based on customer reviews. The ability of the proposed end-to-end ranking framework is evaluated using a real data set of user reviews of Sydney hotels.
C1 [Eshkevari, Milad; Rezaee, Mustafa Jahangoshai] Urmia Univ Technol, Fac Ind Engn, Orumiyeh, Iran.
   [Saberi, Morteza] Univ Technol Sydney, Sch Informat Syst & Modelling, Sydney, NSW, Australia.
   [Hussain, Omar K.] Univ New South Wales, Sch Business, Canberra, ACT, Australia.
C3 Urmia University of Technology; University of Technology Sydney; University of New South Wales Sydney
RP Rezaee, MJ (通讯作者)，Urmia Univ Technol, Fac Ind Engn, Orumiyeh, Iran.
EM m.eshkevari@ine.uut.ac.ir; m.jahangoshai@uut.ac.ir; Morteza.Saberi@uts.edu.au; O.hussain@adfa.edu.au
CR Aboutorab H, 2018, EXPERT SYST APPL, V107, P115, DOI 10.1016/j.eswa.2018.04.015
   Agarwal A, 2020, ACM T ECON COMPUT, V8, P0, DOI 10.1145/3381519
   Al-Smadi M, 2019, INT J MACH LEARN CYB, V10, P2163, DOI 10.1007/s13042-018-0799-4
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Alamoudi ES, 2021, J DECIS SYST, V30, P259, DOI 10.1080/12460125.2020.1864106
   Ali T, 2021, TOUR MANAG PERSPECT, V40, P0, DOI 10.1016/j.tmp.2021.100892
   Chen X, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3667
   Chiu DKW, 2005, DECIS SUPPORT SYST, V40, P51, DOI 10.1016/j.dss.2004.04.004
   Devlin J, 2019, ARXIV, V0, P0
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, V0, PP3057, DOI 10.1109/ICCV.2017.330
   García-Pablos A, 2018, EXPERT SYST APPL, V91, P127, DOI 10.1016/j.eswa.2017.08.049
   Huang J, 2020, ARXIV, V0, P0
   Huang YH, 2018, INFORM MANAGE-AMSTER, V55, P430, DOI 10.1016/j.im.2017.10.003
   Iqbal M, 2019, ARXIV, V0, P0
   Arenas-Márquez FJ, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102645
   Karimi A, 2021, ARXIV, V0, P0
   Kim J, 2021, ADV ENG INFORM, V49, P0, DOI 10.1016/j.aei.2021.101304
   Kumar A, 2021, J EXP THEOR ARTIF IN, V33, P487, DOI 10.1080/0952813X.2020.1764632
   Laddha A, 2018, NAT LANG ENG, V24, P611, DOI 10.1017/S135132491800013X
   Li X, 2019, ARXIV, V0, P0
   Li YC, 2021, ARXIV, V0, P0
   Li ZC, 2021, NEUROCOMPUTING, V459, P1, DOI 10.1016/j.neucom.2021.06.045
   Liu N, 2020, KNOWL-BASED SYST, V188, P0, DOI 10.1016/j.knosys.2019.105010
   Liu XB, 2018, PROC CVPR IEEE, V0, PP5676, DOI 10.1109/CVPR.2018.00595
   Movahedi S, 2019, ARXIV, V0, P0
   Papadimitriou G, 2021, FUTURE GENER COMP SY, V117, P387, DOI 10.1016/j.future.2020.11.024
   Pontiki M, 2016, P 10 INT WORKSH SEM, V0, PP19, DOI 10.18653/V1/S16-1002
   Rezaei J, 2015, OMEGA-INT J MANAGE S, V53, P49, DOI 10.1016/j.omega.2014.11.009
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Shirouyehzad H, 2016, J APPL RES INDUST EN, V3, P49
   Singh KK, 2016, LECT NOTES COMPUT SC, V9910, P753, DOI 10.1007/978-3-319-46466-4_45
   Skene AM, 1979, APPL STAT, V28, P20, DOI 10.2307/2346806
   Tang H, 2020, P 58 ANN M ASS COMPU, V0, P0
   Thang Tran, 2019, INTEGRATED UNCERTAINTY IN KNOWLEDGE MODELLING AND DECISION MAKING. 7TH INTERNATIONAL SYMPOSIUM, V0, P393, DOI 10.1007/978-3-030-14815-7_33
   Trusca MM, 2020, LECT NOTES COMPUT SC, V12128, P365, DOI 10.1007/978-3-030-50578-3_25
   Valipour M, 2022, STOCH ENV RES RISK A, V36, P919, DOI 10.1007/s00477-021-02045-6
   Wallaart O, 2019, LECT NOTES COMPUT SC, V11503, P363, DOI 10.1007/978-3-030-21348-0_24
   Wang XD, 2021, KNOWL-BASED SYST, V227, P0, DOI 10.1016/j.knosys.2021.107196
   Wang XR, 2019, EUR J OPER RES, V277, P454, DOI 10.1016/j.ejor.2019.02.033
   Wu WJ, 2018, ARXIV, V0, P0
   Xu KQ, 2011, DECIS SUPPORT SYST, V50, P743, DOI 10.1016/j.dss.2010.08.021
   Xu X, 2020, IEEE T CYBERNETICS, V50, P2400, DOI 10.1109/TCYB.2019.2928180
   Xu X, 2021, DECIS SUPPORT SYST, V145, P0, DOI 10.1016/j.dss.2021.113525
   Yu HY, 2021, PATTERN RECOGN, V113, P0, DOI 10.1016/j.patcog.2020.107791
   Yu T, 2007, ACM T WEB, V1, P0, DOI 10.1145/1232722.1232728
   Zhang C, 2019, ARXIV, V0, P0
   Zhang M, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102389
   Zhang YJ, 2020, IEEE-CAA J AUTOMATIC, V7, P1038, DOI 10.1109/JAS.2020.1003243
NR 48
TC 4
Z9 5
U1 13
U2 15
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2022
VL 209
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118294
PG 20
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 6M3UI
UT WOS:000888796100011
DA 2023-11-10
ER

PT J
AU Li, JA
   Xu, HCA
   Xu, XF
   Wang, ZJ
AF Li, Jianan
   Xu, Hanchuan
   Xu, Xiaofei
   Wang, Zhongjie
TI A Novel Method for Identifying Microservices by Considering Quality Expectations and Deployment Constraints
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE Microservice identification; coupling criteria; quality expectations; deployment constraints; clustering
AB Nowadays, microservice architecture has become a dominant software development and deployment paradigm. Decomposing a system into loosely coupled, highly cohesive, and fine-grained microservices while meeting various technical constraints and implementing business capabilities is particularly important for microservice system (MS) designers. When an MS has a large number of functionalities and complex interconnections, it is a big challenge to identify microservices solely based on the experience of MS designers. We propose a structured and automated microservice identification method to decompose a system into appropriate microservices for this challenge. We model a system as unified modeling language (UML) class and sequence diagrams. In the identification phase, we take into account not only the traditional coupling-related criteria but also the quality expectation and deployment constraints, both of which have not yet been fully concerned in previous studies. Based on the criteria, a microservice identification algorithm using the clustering technique is designed. A case study of elderly care services illustrates the identification process. Experiments are conducted to evaluate and compare the proposed method against state-of-the-art methods. Results indicate that the proposed method significantly outperforms those compared from the literature.
C1 [Li, Jianan; Xu, Hanchuan; Xu, Xiaofei; Wang, Zhongjie] Harbin Inst Technol, Fac Comp, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, ZJ (通讯作者)，Harbin Inst Technol, Fac Comp, Harbin, Heilongjiang, Peoples R China.
EM 20S003088@stu.hit.edu.cn; xhc@hit.edu.cn; xiaofei@hit.edu.cn; rainy@hit.edu.cn
FU National Key Research and Development Program of China [2018YFB1402500]; National Natural Science Foundation of China [61832014, 61832004]
CR Abdullah M, 2019, J SYST SOFTWARE, V151, P243, DOI 10.1016/j.jss.2019.02.031
   Alshuqayran N, 2016, IEEE INT CONF SERV, V0, PP44, DOI 10.1109/SOCA.2016.15
   Amiri MJ, 2018, P IEEE I C SERV COMP, V0, PP253, DOI 10.1109/SCC.2018.00042
   Baresi L, 2017, LECT NOTES COMPUT SC, V10465, P19, DOI 10.1007/978-3-319-67262-5_2
   Bentlemsan Khadidja, 2020, INTERNATIONAL JOURNAL OF COMPUTERS AND APPLICATIONS, V42, P449, DOI 10.1080/1206212X.2018.1482820
   Chen R, 2017, ASIA PAC SOFWR ENG, V0, PP466, DOI 10.1109/APSEC.2017.53
   Daoud M, 2020, SMART APPL DATA ANAL, V0, P299
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Di Francesco P, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA 2017), V0, PP21, DOI 10.1109/ICSA.2017.24
   Gysel M, 2016, LECT NOTES COMPUT SC, V9846, P185, DOI 10.1007/978-3-319-44482-6_12
   He X, 2021, FUTURE GENER COMP SY, V118, P263, DOI 10.1016/j.future.2021.01.008
   He X, 2020, LECT NOTES COMPUT SC, V12571, P3, DOI 10.1007/978-3-030-65310-1_1
   Jin WX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (IEEE ICWS 2018), V0, PP211, DOI 10.1109/ICWS.2018.00034
   Josélyne MI, 2018, 2018 IEEE/ACM SYMPOSIUM ON SOFTWARE ENGINEERING IN AFRICA (SEIA), V0, PP43, DOI 10.1145/3195528.3195535
   Kwan A, 2016, P 26 ANN INT C COMPU, V0, P297
   Liu L, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, V0, P751, DOI 10.1109/ICWS53863.2021.00103
   Mazlami G, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), V0, PP524, DOI 10.1109/ICWS.2017.61
   Newman MEJ, 2004, PHYS REV E, V69, P0, DOI 10.1103/PhysRevE.69.026113
   Newman S, 2015, BUILDING MICROSERVIC, V0, P0
   Stojanovic TD, 2020, 2020 24 INT C INFORM, V0, PP1, DOI 10.1109/IT48810.2020.9070652
   Tyszberowicz Shmuel, 2018, DEPENDABLE SOFTWARE ENGINEERING. THEORIES, V0, P0
   Vural H, 2021, IEEE ACCESS, V9, P32721, DOI 10.1109/ACCESS.2021.3060895
   Wang ZJ, 2020, P IEEE I C SERV COMP, V0, PP186, DOI 10.1109/SCC49832.2020.00032
NR 24
TC 1
Z9 1
U1 0
U2 12
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD MAR 15
PY 2022
VL 32
IS 03
BP 417
EP 437
DI 10.1142/S021819402250019X
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1C6CS
UT WOS:000793205300004
DA 2023-11-10
ER

PT J
AU Zhou, B
   Chen, JY
   Cai, QH
   Xue, Y
   Yang, C
   He, J
AF Zhou, Bo
   Chen, Jianying
   Cai, Qianhua
   Xue, Yun
   Yang, Chi
   He, Jing
TI Cross-domain sequence labelling using language modelling and parameter generating
SO CAAI TRANSACTIONS ON INTELLIGENCE TECHNOLOGY
LA English
DT Article
AB Sequence labelling (SL) tasks are currently widely studied in the field of natural language processing. Most sequence labelling methods are developed on a large amount of labelled training data via supervised learning, which is time-consuming and expensive. As an alternative, domain adaptation is proposed to train a deep-learning model for sequence labelling in a target domain by exploiting existing labelled training data in related source domains. To this end, the authors propose a Bi-LSTM model to extract more-related knowledge from multi-source domains and learn specific context from the target domain. Further, the language modelling training is also applied to cross-domain adaptability facilitating. The proposed model is extensively evaluated with the named entity recognition and part-of-speech tagging tasks. The empirical results demonstrate the effectiveness of the cross-domain adaption. Our model outperforms the state-of-the-art methods used in both cross-domain tasks and crowd annotation tasks.
C1 [Zhou, Bo; Chen, Jianying; Cai, Qianhua; Xue, Yun; Yang, Chi] South China Normal Univ, Sch Elect & Informat Engn, Foshan 528225, Peoples R China.
   [He, Jing] Univ Oxford, Dept Nerosci, Oxford, Oxon, England.
C3 South China Normal University; University of Oxford
RP Cai, QH (通讯作者)，South China Normal Univ, Sch Elect & Informat Engn, Foshan 528225, Peoples R China.
EM caiqianhua@m.scnu.edu.cn
FU National Statistical Science Research Project of China [2016LY98]; Science and Technology Department of Guangdong Province in China [2016A010101020, 2016A010101021, 2016A010101022]; Characteristic Innovation Projects of Guangdong Colleges and Universities [2018KTSCX049]; Science and Technology Plan Project of Guangzhou [202102080258, 201903010013]
CR Ammar Waleed, 2016, T ASS COMPUTATIONAL, V4, P431, DOI 10.1162/TACL_A_00109
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P845
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Hovy Eduard, 2006, P HUM LANG TECHN C N, V0, PP57, DOI 10.3115/1614049.1614064
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jia C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2464
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Liu LJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, V0, P0
   Liu LY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1215
   Liu ZH, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), V0, P1
   Low Jin Kiat, 2005, P 4 SIGHAN WORKSH CH, V0, P0
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   McCallum Andrew, 2000, P 17 INT C MACH LEAR, V0, P591
   Nguyen AT, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P299, DOI 10.18653/v1/P17-1028
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Platanios EA, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P425
   Rahimi A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P151
   Rei M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2121, DOI 10.18653/v1/P17-1194
   Rodrigues F, 2018, AAAI CONF ARTIF INTE, V0, P1611
   Rodrigues F, 2014, MACH LEARN, V95, P165, DOI 10.1007/s10994-013-5411-2
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Shin Y, 2020, IEEE-ACM T AUDIO SPE, V28, P105, DOI 10.1109/TASLP.2019.2948773
   Wang X, 2019, BIOINFORMATICS, V35, P1745, DOI 10.1093/bioinformatics/bty869
   Yang J, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P74
   Yang Zhilin, 2017, ICLR, V0, P0
   Zeldes A, 2017, LANG RESOUR EVAL, V51, P581, DOI 10.1007/s10579-016-9343-x
   Zhao LJ, 2019, IEEE-ACM T AUDIO SPE, V27, P2326, DOI 10.1109/TASLP.2019.2944563
   Zhou JT, 2020, IEEE T NEUR NET LEAR, V31, P2304, DOI 10.1109/TNNLS.2019.2911236
NR 33
TC 2
Z9 2
U1 4
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2468-6557
EI 2468-2322
J9 CAAI T INTELL TECHNO
JI CAAI T. Intell. Technol.
PD DEC 15
PY 2022
VL 7
IS 4
BP 710
EP 720
DI 10.1049/cit2.12107
EA JUN 2022
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6L5GI
UT WOS:000806960800001
DA 2023-11-10
ER

PT J
AU Gomez, AN
   Key, O
   Perlin, K
   Gou, S
   Frosst, N
   Dean, J
   Gal, Y
AF Gomez, Aidan N.
   Key, Oscar
   Perlin, Kuba
   Gou, Stephen
   Frosst, Nick
   Dean, Jeff
   Gal, Yarin
TI Interlocking Backpropagation: Improving depthwise model-parallelism
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE Model Parallelism; Distributed Optimisation; Large-scale Modelling; Parallel Distributed Processing; Efficient Training
AB The number of parameters in state of the art neural networks has drastically increased in recent years. This surge of interest in large scale neural networks has motivated the development of new distributed training strategies enabling such models. One such strategy is model-parallel distributed training. Unfortunately, model-parallelism can suffer from poor resource utilisation, which leads to wasted resources. In this work, we improve upon recent developments in an idealised model-parallel optimisation setting: local learning. Motivated by poor resource utilisation in the global setting and poor task performance in the local setting, we introduce a class of intermediary strategies between local and global learning referred to as interlocking backpropagation. These strategies preserve many of the compute-efficiency advantages of local optimisation, while recovering much of the task performance achieved by global optimisation. We assess our strategies on both image classification ResNets and Transformer language models, finding that our strategy consistently out-performs local learning in terms of task performance, and out-performs global learning in training efficiency.
C1 [Gomez, Aidan N.; Key, Oscar; Gal, Yarin] Univ Oxford, Oxford, England.
   [Gomez, Aidan N.; Perlin, Kuba; Gou, Stephen; Frosst, Nick] Cohere, Toronto, ON, Canada.
   [Dean, Jeff] Google, Mountain View, CA 94043 USA.
C3 University of Oxford; Google Incorporated
RP Gomez, AN (通讯作者)，Univ Oxford, Oxford, England.; Gomez, AN (通讯作者)，Cohere, Toronto, ON, Canada.
EM AIDAN.GOMEZ@CS.OX.AC.UK; OSCAR.KEY.20@UCL.AC.UK; KUBA@COHERE.AI; STEPHEN@COHERE.AI; NICK@COHERE.AI; JEFF@GOOGLE.COM; YARIN@CS.OX.AC.UK
FU Engineering and Physical Sciences Research Council (EPSRC) [EP/S021566/1]
CR Belilovsky E, 2020, ICML, V0, P736
   Chelba C, 2014, ARXIV, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831
   Huang YP, 2019, ADV NEUR IN, V32, P0
   Jaderberg M, 2017, PR MACH LEARN RES, V70, P0
   Krizhevsky A, 2009, TECH REP T 2009, V0, P0
   Laskin M, 2021, ARXIV, V0, P0
   Lowe S, 2019, ADV NEURAL INFORM PR, V0, P3033
   Mostafa H, 2018, FRONT NEUROSCI-SWITZ, V12, P0, DOI 10.3389/fnins.2018.00608
   Narayanan Deepak, 2021, ARXIV, V0, P0
   Nokland A, 2019, PR MACH LEARN RES, V97, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Recht B, 2011, ADV NEURAL INFORM PR, V0, P693
   Shoeybi M, 2019, ARXIV, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Xiong Yuwen, 2020, ADV NEURAL INFORM PR, V33, P11142, DOI 10.5555/3495724.3496659
   Xu YZ, 2021, ARXIV, V0, P0
NR 19
TC 0
Z9 0
U1 0
U2 0
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
EI 
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD JUN 15
PY 2022
VL 23
IS 
BP 
EP 
DI 
PG 28
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA I5OA8
UT WOS:001003261000001
DA 2023-11-10
ER

PT J
AU Zhou, XH
   Chai, CL
   Li, GL
   Sun, J
AF Zhou, Xuanhe
   Chai, Chengliang
   Li, Guoliang
   Sun, Ji
TI Database Meets Artificial Intelligence: A Survey
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Tuning; Indexes; Acceleration; Training; Machine learning; Database; artificial intelligence; DB4AI; AI4DB
ID access-control; selectivity estimation; model selection; tuning system; management; materialize; prediction; knowledge; query; lineage
AB Database and Artificial Intelligence (AI) can benefit from each other. On one hand, AI can make database more intelligent (AI4DB). For example, traditional empirical database optimization techniques (e.g., cost estimation, join order selection, knob tuning, index and view selection) cannot meet the high-performance requirement for large-scale database instances, various applications and diversified users, especially on the cloud. Fortunately, learning-based techniques can alleviate this problem. On the other hand, database techniques can optimize AI models (DB4AI). For example, AI is hard to deploy in real applications, because it requires developers to write complex codes and train complicated models. Database techniques can be used to reduce the complexity of using AI models, accelerate AI algorithms and provide AI capability inside databases. Thus both DB4AI and AI4DB have been extensively studied recently. In this article, we review existing studies on AI4DB and DB4AI. For AI4DB, we review the techniques on learning-based configuration tuning, optimizer, index/view advisor, and security. For DB4AI, we review AI-oriented declarative language, AI-oriented data governance, training acceleration, and inference acceleration. Finally, we provide research challenges and future directions.
C1 [Zhou, Xuanhe; Chai, Chengliang; Li, Guoliang; Sun, Ji] Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Chai, CL; Li, GL (通讯作者)，Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.
EM zhouxuan19@mails.tsinghua.edu.cn; chaicl15@mails.tsinghua.edu.cn; liguoliang@tsinghua.edu.cn; sun-j16@mails.tsinghua.edu.cn
FU NSF of China [61925205, 61632016]; Huawei; TAL education
CR Aggarwal CC, 2014, CH CRC DATA MIN KNOW, V0, P457
   Agrawal D, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP2069, DOI 10.1145/2882903.2899414
   Agrawal P, 2006, VLDB, V0, P0
   Anderson MR, 2016, PROC INT CONF DATA, V0, PP577, DOI 10.1109/ICDE.2016.7498272
   [Anonymous], 2010, PROC ACM SIGMOD INT, V0, P0
   [Anonymous], 2011, PROC 5 BIENNIAL C IN, V0, P0
   Avnur R, 2000, SIGMOD REC, V29, P261, DOI 10.1145/335191.335420
   Babu Shivnath, 2020, P 2020 ACM SIGMOD IN, V0, PP1667, DOI 10.1145/3318464.3380591
   Baik C, 2019, PROC INT CONF DATA, V0, PP374, DOI 10.1109/ICDE.2019.00041
   Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812
   Batista LO, 2019, ABS190102868, V0, P0
   Bavoil L, 2005, IEEE VISUALIZATION 2005, V0, P135, DOI 10.1109/visual.2005.1532788
   Bennett Kristin P, 1991, P 4 INT C GEN ALG IC, V0, P400
   Bhaskar R, 2010, P 16 ACM SIGKDD INT, V0, PP503, DOI 10.1145/1835804.1835869
   Bischl B, 2016, J MACH LEARN RES, V17, P0
   Boehm M, 2016, PROC VLDB ENDOW, V9, P1425, DOI 10.14778/3007263.3007279
   Byun JW, 2008, VLDB J, V17, P603, DOI 10.1007/s00778-006-0023-0
   Callahan Steven P, 2006, P 2006 ACM SIGMOD IN, V0, PP745, DOI 10.1145/1142473.1142574
   Chaudhuri S, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, V0, P146
   Chavan M, 2011, PROC INT CONF DATA, V0, PP1284, DOI 10.1109/ICDE.2011.5767949
   Chen JJ, 2019, PROC INT CONF DATA, V0, PP13, DOI 10.1109/ICDE.2019.00009
   Cheney J, 2007, FOUND TRENDS DATABAS, V1, P379, DOI 10.1561/1900000006
   Colombo P, 2016, PROC INT CONF DATA, V0, PP1516, DOI 10.1109/ICDE.2016.7498402
   Cui YW, 2000, ACM T DATABASE SYST, V25, P179, DOI 10.1145/357775.357777
   Curino Carlo, 2011, P ACM SIGMOD INT C M, V0, PP313, DOI 10.1145/1989323.1989357
   Dageville B, 2004, VLDB 04 P 30 INT C V, V30, P1098, DOI 10.1016/B978-012088469-8.50096-6
   Das S, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1923, DOI 10.1145/2882903.2903733
   Ding JL, 2020, SIGMOD20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP969, DOI 10.1145/3318464.3389711
   Dokeroglu T, 2015, APPL SOFT COMPUT, V30, P72, DOI 10.1016/j.asoc.2015.01.026
   Dong Y, 2019, ABS190108544, V0, P0
   Dong Z, 2019, ABS190200655, V0, P0
   Duggan Jennie, 2011, SIGMOD, V0, PP337, DOI 10.1145/1989323.1989359
   Dutt A, 2019, PROC VLDB ENDOW, V12, P1044, DOI 10.14778/3329772.3329780
   Fegaras L, 1998, DATABASE AND EXPERT SYSTEMS APPLICATIONS. 9TH INTERNATIONAL CONFERENCE, V0, P726, DOI 10.1007/BFb0054528
   Fernandes S, 2015, IDEAS 15, V0, PP202, DOI 10.1145/2790755.2790797
   Fernandez RC, 2018, PROC INT CONF DATA, V0, PP1001, DOI 10.1109/ICDE.2018.00094
   Galakatos A, 2019, INT CONF MANAGE DATA, V0, PP1189, DOI 10.1145/3299869.3319860
   Gallinucci E, 2019, EDBT, V0, P546
   Gharibshah Z, 2020, DATA SCI ENG, V5, P12, DOI 10.1007/s41019-019-00115-y
   Gounaris A, 2017, IEEE T PARALL DISTR, V28, P1891, DOI 10.1109/TPDS.2017.2647939
   Goyal ML, 1991, COMPUTERS & SECURITY, V10, P661, DOI 10.1016/0167-4048(91)90124-V
   Grushka-Cohen H, 2019, ABS191010777, Vabs, P10777
   Gu J, 2018, IEEE ICC, V0, P0
   Gupta H, 1999, LECT NOTES COMPUT SC, V1540, P453
   Haas LM, 1999, ACM SIGMODDIGITAL RE, V1, P0
   Halevy A, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP795, DOI 10.1145/2882903.2903730
   Han JW, 2000, SIGMOD RECORD, V29, P1
   Hasan S, 2019, ABS190309999, V0, P0
   Hayek R, 2020, ABS200407009, V0, P0
   He X, 2021, KNOWL-BASED SYST, V212, P0, DOI 10.1016/j.knosys.2020.106622
   Heimel M, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1477, DOI 10.1145/2723372.2749438
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Herodotou Herodotos, 2011, CIDR, V11, P261
   Heule S, 2013, P 16 INT C EXTENDING, V0, PP683, DOI 10.1145/2452376.2452456
   Hutter F, 2019, SPRING SER CHALLENGE, V0, PP1, DOI 10.1007/978-3-030-05318-5
   Idreos S, 2019, CIDR, V0, P0
   Idreos S, 2019, LEARNING KEY VALUE S, V0, P0
   Idreos S, 2019, INT CONF MANAGE DATA, V0, PP2054, DOI 10.1145/3299869.3314034
   Ilyas IF, 2019, DATA CLEANING, V0, P0
   Ioannidis YE, 1991, SIGMOD RECORD, V20, P168, DOI 10.1145/119995.115813
   Jindal A, 2018, INT CONF MANAGE DATA, V0, PP191, DOI 10.1145/3183713.3190656
   Jindal A, 2018, PROC VLDB ENDOW, V11, P800, DOI 10.14778/3192965.3192971
   Kadirvel S, 2012, IEEE IC COMP COM NET, V0, P0
   Kaneko H, 2014, LECT NOTES COMPUT SC, V8481, P410, DOI 10.1007/978-3-319-07455-9_43
   Kara K, 2018, PROC VLDB ENDOW, V12, P348, DOI 10.14778/3297753.3297756
   Kipf Andreas, 2019, CIDR, V0, P0
   Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282, DOI 10.1007/11871842_29
   Kraska T, 2013, CIDR, V1, P1
   Kraska T, 2018, INT CONF MANAGE DATA, V0, PP489, DOI 10.1145/3183713.3196909
   Krishnan S, 2016, PROC VLDB ENDOW, V9, P948
   Krishnanet S, 2018, CORR VOL ABS18080319, V0, P0
   Kumar A, 2017, SIGMOD17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1717, DOI 10.1145/3035918.3054775
   Kumar A, 2015, SIGMOD REC, V44, P17, DOI 10.1145/2935694.2935698
   Kunjir M, 2017, PROC VLDB ENDOW, V10, P1917, DOI 10.14778/3137765.3137808
   Leis V, 2015, PROC VLDB ENDOW, V9, P204
   Leis Viktor, 2017, CIDR, V0, P0
   Li G, 2019, IEEE DATA ENG B, V42, P70
   Li GL, 2019, PROC VLDB ENDOW, V12, P2118, DOI 10.14778/3352063.3352129
   Li GL, 2016, IEEE T KNOWL DATA EN, V28, P2296, DOI 10.1109/TKDE.2016.2535242
   Li L, 2018, ABS181004915, V0, P0
   Li Mu, 2014, 11 USENIX S OPERATIN, V0, PP583, DOI 10.1145/2640087.2644155
   Li XP, 2017, PROC VLDB ENDOW, V10, P1933, DOI 10.14778/3137765.3137812
   Liang X, 2019, ABS190301363, V0, P0
   Lillicrap T, 2016, ABS150902971 CORR, V0, P0
   Lin ZC, 2017, INT SYM COMPUT INTEL, V0, PP108, DOI 10.1109/ISCID.2017.24
   LIPTON RJ, 1990, SIGMOD REC, V19, P1, DOI 10.1145/93605.93611
   Lodeiro-Santiago M, 2017, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND MACHINE LEARNING (IML17), V0, P0, DOI DOI 10.1145/3109761.3158395
   Lu JH, 2019, PROC VLDB ENDOW, V12, P1970, DOI 10.14778/3352063.3352112
   Lu X, 2009, COMPUT MATH APPL, V57, P1037, DOI 10.1016/j.camwa.2008.10.056
   Lühring M, 2007, I C DATA ENGIN WORKS, V0, PP450, DOI 10.1109/ICDEW.2007.4401028
   Luo YY, 2022, IEEE T KNOWL DATA EN, V34, P475, DOI 10.1109/TKDE.2020.2981464
   Luo YY, 2018, PROC INT CONF DATA, V0, PP101, DOI 10.1109/ICDE.2018.00019
   Ma L, 2018, INT CONF MANAGE DATA, V0, PP631, DOI 10.1145/3183713.3196908
   Ma MH, 2020, PROC VLDB ENDOW, V13, P1176, DOI 10.14778/3389133.3389136
   Macke S, 2018, WORKSH ML SYST NEURI, V0, P1
   Mahajan D, 2018, PROC VLDB ENDOW, V11, P1317, DOI 10.14778/3236187.3236188
   Mahajan D, 2016, INT S HIGH PERF COMP, V0, PP14, DOI 10.1109/HPCA.2016.7446050
   Makrynioti N, 2019, ABS190201304, V0, P0
   Marco R, 2018, P 1 INT WORKSHOP EXP, V0, P1
   Marcus R, 2019, PROC VLDB ENDOW, V12, P1705, DOI 10.14778/3342263.3342644
   Marcus R, 2019, PROC VLDB ENDOW, V12, P1733, DOI 10.14778/3342263.3342646
   Mintz M, 2009, P JOINT C 47 ANN M A, V0, PP1003, DOI 10.3115/1690219.1690287
   Mitzenmacher M, 2018, ADV NEUR IN, V31, P0
   Moritz P, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P561
   Müller M, 2018, PROC VLDB ENDOW, V11, P1016, DOI 10.14778/3213880.3213882
   Nagpal B, 2017, J INF PROCESS SYST, V13, P689, DOI 10.3745/JIPS.03.0024
   Nakandala Supun, 2019, PROC 3 INT WORKSHOP, V0, P0, DOI DOI 10.1145/3329486.3329496
   Nguyen N, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), V0, PP417, DOI 10.1109/CLOUD.2018.00059
   Olma M, 2020, VLDB J, V29, P569, DOI 10.1007/s00778-019-00580-x
   Ortiz J, 2019, ARXIV, V0, P0
   Ortiz J, 2018, PROCEEDINGS OF THE SECOND WORKSHOP ON DATA MANAGEMENT FOR END-TO-END MACHINE LEARNING, V0, P0, DOI DOI 10.1145/3209889.3209890
   Park Y, 2020, SIGMOD20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1017, DOI 10.1145/3318464.3389727
   Pedrozo WG, 2018, LECT NOTES ARTIF INT, V10870, P716, DOI 10.1007/978-3-319-92639-1_60
   Poosala V, 1996, ACM SIGMOD RECORD, V0, P294
   Psallidas F, 2018, PROC VLDB ENDOW, V11, P719, DOI 10.14778/3184470.3184475
   Putnam A, 2014, CONF PROC INT SYMP C, V0, PP13, DOI 10.1109/ISCA.2014.6853195
   Rae J, 2019, INT C MACH LEARN PML, V0, P0
   Rzeszotarski JM, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), V0, PP897, DOI 10.1145/2556288.2557231
   Sablayrolles A, 2019, P ICLR, V0, P1
   Sadri Z, 2020, I C DATA ENGIN WORKS, V0, PP158, DOI 10.1109/ICDEW49219.2020.00035
   Schindler JT, 2016, ABS160807981, V0, P0
   Schlemper J, 2019, ABS190203876, V0, P0
   Schnaitter K, 2007, I C DATA ENGIN WORKS, V0, PP459, DOI 10.1109/ICDEW.2007.4401029
   Schnaitter K, 2012, PROC VLDB ENDOW, V5, P478, DOI 10.14778/2140436.2140444
   Schulman J, 2017, ABS190203876, V0, P0
   Shalev-Shwartz S, 2011, J MACH LEARN RES, V12, P1865
   Sheng Y, 2019, ABS190302990, V0, P0
   Sheykhkanloo NM, 2017, INT J CYBER WARF TER, V7, P16, DOI 10.4018/IJCWT.2017040102
   Sohr K, 2008, IEEE T KNOWL DATA EN, V20, P924, DOI 10.1109/TKDE.2008.28
   Stillger M, 2001, PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, V0, P19
   Stoica Ion, 2019, ABS190504278, V0, P0
   Sun J, 2019, PROC VLDB ENDOW, V13, P307, DOI 10.14778/3368289.3368296
   Taft R, 2018, INT CONF MANAGE DATA, V0, PP205, DOI 10.1145/3183713.3190650
   Tan J, 2019, PROC VLDB ENDOW, V12, P1221, DOI 10.14778/3339490.3339503
   Tang P, 2018, LECT NOTES ARTIF INT, V11323, P445, DOI 10.1007/978-3-030-05090-0_38
   Tian S, 2020, DATA SCI ENG, V5, P1, DOI 10.1007/s41019-020-00117-1
   Trummer I, 2019, INT CONF MANAGE DATA, V0, PP1153, DOI 10.1145/3299869.3300088
   Tzoumas K, 2008, HISTORY, V0, P1
   Valens G, 2000, POSITIF, V0, PP101, DOI 10.1109/ICDE.2000.839397
   Van Aken D, 2017, SIGMOD17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP1009, DOI 10.1145/3035918.3064029
   Vartak M, 2016, P WORKSH HUM IN THE, V0, P0
   Venkataraman S, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI 16), V0, P363
   Waas F, 2017, PROC BRIT NAT C DATA, V0, P51
   Wang HX, 2019, IEEE INT CONF MOB DA, V0, PP569, DOI 10.1109/MDM.2019.00121
   Wang W, 2016, SIGMOD REC, V45, P17, DOI 10.1145/3003665.3003669
   Wang YJ, 2019, BIG DATA MIN ANAL, V2, P35, DOI 10.26599/BDMA.2018.9020029
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Weiss GM, 1998, PROCEEDINGS FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P359
   Wu CG, 2018, PROC VLDB ENDOW, V12, P210, DOI 10.14778/3291264.3291267
   Wu YJ, 2019, INT CONF MANAGE DATA, V0, PP1223, DOI 10.1145/3299869.3319861
   Xu C, 2018, INT CONF MANAGE DATA, V0, PP147, DOI 10.1145/3183713.3183741
   Yakout Mohamed, 2012, SIGMOD C, V0, PP97, DOI 10.1145/2213836.2213848
   Yu X, 2019, ICDE 2020, V0, P196
   Yuan HT, 2020, PROC INT CONF DATA, V0, PP1501, DOI 10.1109/ICDE48307.2020.00133
   Zhang C, 2014, SIGMOD14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP265, DOI 10.1145/2588555.2593678
   Zhang HF, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2019), V0, P0, DOI DOI 10.1145/3331453.3361280
   Zhang J, 2019, INT CONF MANAGE DATA, V0, PP415, DOI 10.1145/3299869.3300085
   Zhang Z, 2017, HPDC17: PROCEEDINGS OF THE 26TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, V0, PP143, DOI 10.1145/3078597.3078603
   Zhou XH, 2020, PROC VLDB ENDOW, V13, P1416, DOI 10.14778/3397230.3397238
   Zhu YQ, 2017, PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC 17), V0, PP338, DOI 10.1145/3127479.3128605
   Zilio DC, 2004, VLDB, V0, P1087
   Zilio DC, 2004, INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING, V0, P180
NR 162
TC 33
Z9 33
U1 11
U2 45
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD MAR 1
PY 2022
VL 34
IS 3
BP 1096
EP 1116
DI 10.1109/TKDE.2020.2994641
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA YU4KL
UT WOS:000752013800007
DA 2023-11-10
ER

PT J
AU Yang, W
   Liu, Y
   Xiao, CJ
AF Yang, Wei
   Liu, Yang
   Xiao, Chunjing
TI Deep metric learning for accurate protein secondary structure prediction
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Protein secondary structure prediction; Deep metric learning; Protein language model; Profile feature; Embedding feature
ID networks; angles
AB Predicting the secondary structure of a protein from its amino acid sequence alone is a challenging prediction task for each residue in bioinformatics. Recent work has mainly used deep models based on the profile feature derived from multiple sequence alignments to make predictions. However, the existing state-of-the-art predictors usually have higher computational costs due to their large model sizes and complex network architectures. Here, we propose a simple yet effective deep centroid model for sequence-to-sequence secondary structure prediction based on deep metric learning. The proposed model adopts a lightweight embedding network with multibranch topology to map each residue in a protein chain into an embedding space. The goal of embedding learning is to maximize the similarity of each residue to its target centroid while minimizing its similarity to nontarget centroids. By assigning secondary structure types based on the learned centroids, we bypass the need for a time-consuming k-nearest neighbor search. Experimental results on six test sets demonstrate that our method achieves state-of-the-art performance with a simple architecture and smaller model size than existing models. Moreover, we also experimentally show that the embedding feature from the pretrained protein language model ProtT5-XL-U50 is superior to the profile feature in terms of prediction accuracy and feature generation speed. Code and datasets are available at https://github.com/fengtuan/DML_SS.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yang, Wei; Liu, Yang; Xiao, Chunjing] Henan Univ, Sch Comp & Informat Engn, Henan Key Lab Big Data Anal & Proc, Henan Engn Lab Spatial Informat Proc, Kaifeng 475004, Peoples R China.
C3 Henan University
RP Xiao, CJ (通讯作者)，Henan Univ, Sch Comp & Informat Engn, Henan Key Lab Big Data Anal & Proc, Henan Engn Lab Spatial Informat Proc, Kaifeng 475004, Peoples R China.
EM chunjingxiao@gmail.com
FU National Science Foundation of China [61806074, 62176087]
CR Abdar M, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Abdar M, 2021, INFORM SCIENCES, V577, P353, DOI 10.1016/j.ins.2021.07.024
   Abdar M, 2021, COMPUT BIOL MED, V135, P0, DOI 10.1016/j.compbiomed.2021.104418
   Abdar M, 2021, INFORM FUSION, V76, P243, DOI 10.1016/j.inffus.2021.05.008
   ASAI K, 1993, COMPUT APPL BIOSCI, V9, P141
   Aydin Z, 2006, BMC BIOINFORMATICS, V7, P0, DOI 10.1186/1471-2105-7-178
   Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937
   Buchan DWA, 2010, NUCLEIC ACIDS RES, V38, PW563, DOI 10.1093/nar/gkq427
   Busia A, 2017, ARXIV170203865, V0, P0
   Chopra S, 2005, PROC CVPR IEEE, V0, PP539, DOI 10.1109/cvpr.2005.202
   Devlin J, 2018, ARXIV, V1, P4171
   Drozdetskiy A, 2015, NUCLEIC ACIDS RES, V43, PW389, DOI 10.1093/nar/gkv332
   Elnaggar A, 2021, IEEE T PATTERN ANAL, V14, P0
   Fang C, 2018, PROTEINS, V86, P592, DOI 10.1002/prot.25487
   Ge W, 1900, P269, V0, P0
   Guo J, 2004, PROTEINS, V54, P738, DOI 10.1002/prot.10634
   Hanson J, 2019, BIOINFORMATICS, V35, P2403, DOI 10.1093/bioinformatics/bty1006
   Heffernan R, 2018, J COMPUT CHEM, V39, P2210, DOI 10.1002/jcc.25534
   Heffernan R, 2017, BIOINFORMATICS, V33, P2842, DOI 10.1093/bioinformatics/btx218
   Heinzinger M, 2019, BMC BIOINFORMATICS, V20, P0, DOI 10.1186/s12859-019-3220-8
   Hermans Alexander, 2017, DEFENSE TRIPLET LOSS, V4, P0
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Howard A, 2019, IEEE I CONF COMP VIS, V0, PP1314, DOI 10.1109/ICCV.2019.00140
   Intergovernmental Panel Climate Change Working Grp III, 2014, CLIMATE CHANGE 2014: MITIGATION OF CLIMATE CHANGE, V0, P1
   Jiang Q, 2017, J MOL GRAPH MODEL, V76, P379, DOI 10.1016/j.jmgm.2017.07.015
   Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091
   KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211
   Klausen MS, 2019, PROTEINS, V87, P520, DOI 10.1002/prot.25674
   Li Z, 1900, P2560, V0, P0
   Meiler J, 2001, J MOL MODEL, V7, P360, DOI 10.1007/s008940100038
   Moffat L, 2021, BIOINFORMATICS, V0, P0
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, V0, PP360, DOI 10.1109/ICCV.2017.47
   Ovchinnikov S, 2017, SCIENCE, V355, P294, DOI 10.1126/science.aah4043
   Pearce R, 2021, CURR OPIN STRUC BIOL, V68, P194, DOI 10.1016/j.sbi.2021.01.007
   Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5
   Qin Y, 2021, MED IMAGE ANAL, V67, P0, DOI 10.1016/j.media.2020.101885
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rao RS, 2019, ADV NEUR IN, V32, P0
   Rives A, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2016239118
   SALZBERG S, 1992, J MOL BIOL, V227, P371, DOI 10.1016/0022-2836(92)90892-N
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Selbig J, 1999, BIOINFORMATICS, V15, P1039, DOI 10.1093/bioinformatics/15.12.1039
   Seuss D, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Shi Q, 2019, BIOINFORMATICS, V35, P5128, DOI 10.1093/bioinformatics/btz464
   Shrestha P, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Singh J, 2021, BIOINFORMATICS, V0, P0
   Sohn K, 2016, ADV NEUR IN, V29, P0
   Song HO, 2017, PROC CVPR IEEE, V0, PP2206, DOI 10.1109/CVPR.2017.237
   Sun YF, 2020, PROC CVPR IEEE, V0, PP6397, DOI 10.1109/CVPR42600.2020.00643
   Teh EW, 1900, P448, V0, P0
   Uddin, 2020, BIOINFORMATICS, V0, P0
   Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224
   Wang J, 2017, IEEE I CONF COMP VIS, V0, PP2612, DOI 10.1109/ICCV.2017.283
   Wang S, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep18962
   Wang X, 1900, P5022, V0, P0
   Wang X, 1900, P5207, V0, P0
   Wang YX, 2017, KNOWL-BASED SYST, V118, P115, DOI 10.1016/j.knosys.2016.11.015
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu CY, 2017, IEEE I CONF COMP VIS, V0, PP2859, DOI 10.1109/ICCV.2017.309
   Xu G, 2020, BIOINFORMATICS, V36, P5021, DOI 10.1093/bioinformatics/btaa629
   Yang BR, 2011, KNOWL-BASED SYST, V24, P304, DOI 10.1016/j.knosys.2010.10.002
   Yang Wei, 2013, INT J BIOINFORM RES APPL, V9, P207, DOI 10.1504/IJBRA.2013.052445
   Yang YD, 2018, BRIEF BIOINFORM, V19, P482, DOI 10.1093/bib/bbw129
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi D, 2014, INT C PATT RECOG, V0, PP34, DOI 10.1109/ICPR.2014.16
   Yoo PD, 2008, CURR BIOINFORM, V3, P74, DOI 10.2174/157489308784340676
   Yu B, 1900, P6490, V0, P0
   Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K
   Zhang LC, 2016, J THEOR BIOL, V400, P1, DOI 10.1016/j.jtbi.2016.04.011
   Zheng W, 2020, BIOINFORMATICS, V36, P3749, DOI 10.1093/bioinformatics/btaa217
NR 70
TC 4
Z9 4
U1 7
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD APR 22
PY 2022
VL 242
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.108356
EA FEB 2022
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0V1XS
UT WOS:000788138900002
DA 2023-11-10
ER

PT J
AU Peer, D
   Stabinger, S
   Engl, S
   Rodríguez-Sánchez, A
AF Peer, David
   Stabinger, Sebastian
   Engl, Stefan
   Rodriguez-Sanchez, Antonio
TI Greedy-layer pruning: Speeding up transformer models for natural language processing
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Natural language processing; Transformer models; Pruning; Knwoledge distillation
AB Fine-tuning transformer models after unsupervised pre-training reaches a very high performance on many different natural language processing tasks. Unfortunately, transformers suffer from long inference times which greatly increases costs in production. One possible solution is to use knowledge distilla-tion, which solves this problem by transferring information from large teacher models to smaller student models. Knowledge distillation maintains high performance and reaches high compression rates, never-theless, the size of the student model is fixed after pre-training and can not be changed individually for a given downstream task and use-case to reach a desired performance/speedup ratio. Another solution to reduce the size of models in a much more fine-grained and computationally cheaper fashion is to prune layers after the pre-training. The price to pay is that the performance of layer-wise pruning algorithms is not on par with state-of-the-art knowledge distillation methods. In this paper, Greedy-layer pruning is introduced to (1) outperform current state-of-the-art for layer-wise pruning, (2) close the performance gap when compared to knowledge distillation, while (3) providing a method to adapt the model size dy-namically to reach a desired performance/speedup tradeoff without the need of additional pre-training phases. Our source code is available on https://github.com/deepopinion/greedy- layer-pruning .(c) 2022 Elsevier B.V. All rights reserved.
C1 [Peer, David; Stabinger, Sebastian; Engl, Stefan] DeepOpinion, Bozner Pl 1-9, A-6020 Innsbruck, Austria.
   [Peer, David; Stabinger, Sebastian; Rodriguez-Sanchez, Antonio] Univ Innsbruck, Technikerstr 21a, A-6020 Innsbruck, Austria.
C3 University of Innsbruck
RP Peer, D (通讯作者)，DeepOpinion, Bozner Pl 1-9, A-6020 Innsbruck, Austria.; Peer, D (通讯作者)，Univ Innsbruck, Technikerstr 21a, A-6020 Innsbruck, Austria.
EM david.peer@deepopinion.ai
CR Bentivogli Luisa, 2009, 5 PASCAL RECOGNIZING, V0, P0
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Devlin J, 1900, P4171, V0, P0, DOI DOI 10.18653/v1/N19-1423
   Dolan B, 2005, 3 INT WORKSHOP PARAP, V0, P0
   Fan Angela, 2020, INT C LEARN REPR, V0, P0
   Fang Y, 2020, P 2020 C EMP METH NA, V0, P498
   Ganesh P, 2021, T ASSOC COMPUT LING, V9, P1061, DOI 10.1162/tacl_a_00413
   Goceri E, 2020, IET IMAGE PROCESS, V14, P882, DOI 10.1049/iet-ipr.2019.0312
   Goceri E, 2019, INT J NUMER METH BIO, V35, P0, DOI 10.1002/cnm.3225
   Izsak P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P10644
   Jiao X, 2020, FINDINGS ASS COMPUTA, V0, PP4163, DOI 10.18653/v1/2020.findings-emnlp.372
   Kervadec H, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Loshchilov I, 2018, DECOUPLED WEIGHT DEC, V0, P0
   Michel Paul, 2019, ADV NEURAL INFORM PR, V0, P14014
   Peer D, 2021, IEEE WINT CONF APPL, V0, PP256, DOI 10.1109/WACV48630.2021.00030
   Peer D, 2021, PATTERN RECOGN LETT, V144, P68, DOI 10.1016/j.patrec.2021.01.017
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Sajjad Hassan, 2020, ARXIV200403844, V0, P0
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Shi Y, 2021, PATTERN RECOGN LETT, V149, P150, DOI 10.1016/j.patrec.2021.06.012
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4323
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2158
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5797
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Warstadt A, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Worsham J, 2020, PATTERN RECOGN LETT, V136, P120, DOI 10.1016/j.patrec.2020.05.031
   Zhang Z, 2021, OPEN, V2, P36
NR 31
TC 2
Z9 2
U1 4
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD MAY 15
PY 2022
VL 157
IS 
BP 76
EP 82
DI 10.1016/j.patrec.2022.03.023
EA APR 2022
PG 7
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0P0QR
UT WOS:000783928500001
DA 2023-11-10
ER

PT J
AU Baral, C
   Gelfond, G
   Pontelli, E
   Son, TC
AF Baral, Chitta
   Gelfond, Gregory
   Pontelli, Enrico
   Tran Cao Son
TI An action language for multi-agent domains
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Action languages; Epistemic planning; Reasoning about knowledge
ID decentralized control; representing action; logic; complexity; systems; belief
AB The goal of this paper is to investigate an action language, called mA*, for representing and reasoning about actions and change in multi-agent domains. The language, as designed, can also serve as a specification language for epistemic planning, thereby addressing an important issue in the development of multi-agent epistemic planning systems. The mA* action language is a generalization of the single-agent action languages, extensively studied in the literature, to the case of multi-agent domains. The language allows the representation of different types of actions that an agent can perform in a domain where many other agents might be present-such as world-altering actions, sensing actions, and communication actions. The action language also allows the specification of agents' dynamic awareness of action occurrences-which has implications on what agents' know about the world and other agents' knowledge about the world. These features are embedded in a language that is simple, yet powerful enough to address a large variety of knowledge manipulation scenarios in multi-agent domains. The semantics of mA* relies on the notion of state, which is described by a pointed Kripke model and is used to encode the agents' knowledge(1) and the real state of the world. The semantics is defined by a transition function that maps pairs of actions and states into sets of states. The paper presents a number of properties of the action theories and relates mA* to other relevant formalisms in the area of reasoning about actions in multi-agent domains. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Baral, Chitta] Arizona State Univ, Sch Comp & AI, Tempe, AZ 85287 USA.
   [Gelfond, Gregory] Univ Nebraska Omaha, Dept Comp Sci, Omaha, NE USA.
   [Pontelli, Enrico; Tran Cao Son] New Mexico State Univ, Dept Comp Sci, Las Cruces, NM 88003 USA.
C3 Arizona State University; Arizona State University-Tempe; University of Nebraska System; University of Nebraska Omaha; New Mexico State University
RP Son, TC (通讯作者)，New Mexico State Univ, Dept Comp Sci, Las Cruces, NM 88003 USA.
EM chitta@asu.edu; ggelfond@unomaha.edu; epontell@cs.nmsu.edu; tson@cs.nmsu.edu
FU DARPA [W911NF-19-2-0006]; NSF [1914635, 1833630, 1757207, 1812628]; Division Of Undergraduate Education; Direct For Education and Human Resources [1833630] Funding Source: National Science Foundation
CR Agotnes T, 2014, PLANNING EPISTEMIC G, V0, P0
   Allen M, 2009, ADV NEURAL INFORM PR, V22, P19
   [Anonymous], 2005, P 4 INT JOINT C AUTO, V0, P0
   [Anonymous], 2006, AAMAS, V0, P0
   Aucher G, 2013, P 23 IJCAI, V0, P27
   Baltag A, 2004, SYNTHESE, V139, P165, DOI 10.1023/B:SYNT.0000024912.56773.5e
   Baral C, 2010, THEOR PRACT LOG PROG, V10, P675, DOI 10.1017/S1471068410000359
   Baral C, 2012, P NMR, V0, P0
   Baral C, 2010, P S CONSTR MECH, V0, P0
   Baral C, 2010, P INT JOINT C AUTONO, V1, P259
   Baral C, 2017, DAGSTUHL REPORTS, V7, P1
   Baral C, 2013, LECT NOTES ARTIF INT, V8143, P290, DOI 10.1007/978-3-642-40624-9_18
   Baral C, 2010, LECT NOTES ARTIF INT, V6214, P46
   Bernstein DS, 2002, MATH OPER RES, V27, P819, DOI 10.1287/moor.27.4.819.297
   Boella G, 2005, P 4 INT JOINT C AUT, V0, P682
   Bolander Thomas, 2011, JOURNAL OF APPLIED NON-CLASSICAL LOGIC, V21, P9, DOI 10.3166/jancl.21.9-34
   Bolander T, 2018, OUTST CONTRIB LOGIC, V12, P207, DOI 10.1007/978-3-319-62864-6_8
   Bolander T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P2791
   Brafman RI, 2008, P 18 INT C AUT PLANN, V0, P28
   Castellini C, 2001, P 6 EUR C PLANN ECP, V0, P0
   de Weerdt M, 2003, ANN MATH ARTIF INTEL, V37, P93, DOI 10.1023/A:1020236119243
   de Weerdt M, 2009, MULTIAGENT GRID SYST, V5, P345, DOI 10.3233/MGS-2009-0133
   Del Val A, 1994, JOURNAL OF LOGIC AND COMPUTATION, V4, P797, DOI 10.1093/logcom/4.5.797
   Durfee EH, 1999, MULTIAGENT SYSTEMS, V0, P121
   Engesser T, 2017, ELECTRON P THEOR COM, V0, PP75, DOI 10.4204/EPTCS.243.6
   Engesser T, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1795
   Fabiano F, 2020, INT C AUT PLANN SCHE, V0, P0
   Fagin R, 2003, REASONING KNOWLEDGE, V0, P0, DOI DOI 10.7551/MITPRESS/5803.001.0001
   FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5
   Friedman N, 1999, J ARTIF INTELL RES, V10, P117, DOI 10.1613/jair.506
   GELFOND M, 1993, J LOGIC PROGRAM, V17, P301, DOI 10.1016/0743-1066(93)90035-F
   Gelfond M, 1998, T ARTIF INTELL, V3, P0
   Gerbrandy Jelle, 2006, P 5 INT JOINT C AUT, V0, P0, DOI DOI 10.1145/1160633.1160664
   Ghallab M, 1998, TR98003DCTR1165 CVC, V0, P0
   Giunchiglia E, 1997, ARTIF INTELL, V95, P409, DOI 10.1016/S0004-3702(97)00037-4
   Goldman CV, 2004, J ARTIF INTELL RES, V22, P143, DOI 10.1613/jair.1427
   Guestrin C, 2002, ADV NEUR IN, V14, P1523
   Herzig A, 2005, 6 WORKSH NONM REAS A, V0, P0
   Herzig Andreas, 2006, P 5 INT JOINT C AUTO, V0, PP209, DOI 10.1145/1160633.1160666
   KATSUNO H, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, V0, P387
   Kominis F, 2015, P I C AUTOMAT PLAN S, V0, P147
   Levesque HJ, 1997, J LOGIC PROGRAM, V31, P59, DOI 10.1016/S0743-1066(96)00121-5
   Lifschitz V, 1987, REASONING ACTIONS PL, V0, P1
   Liu Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1912
   Löwe B, 2011, LECT NOTES ARTIF INT, V6953, P179, DOI 10.1007/978-3-642-24130-7_13
   McCarthy J, 1959, P TEDD C MECH THOUGH, V0, P75
   Muise C, 2015, AAAI CONF ARTIF INTE, V0, P3327
   Nair R, 2003, P 18 INT JOINT C ART, V0, P705
   PEDNAULT EPD, 1989, S REPR REAS, V0, P324
   Peshkin L, 2002, IEEE IJCNN, V0, PP1825, DOI 10.1109/IJCNN.2002.1007796
   Phan HT, 2011, ARTIF INTELL, V175, P79, DOI 10.1016/j.artint.2010.04.007
   Sauro L, 2006, AAMAS 06 P 5 INT JOI, V0, P185
   Shanahan M, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P140
   Son TC, 2001, ARTIF INTELL, V125, P19, DOI 10.1016/S0004-3702(00)00080-1
   Son Tran C, 2005, P 20 NATL C ART INT, V0, P1211
   Son TC, 2015, AAAI CONF ARTIF INTE, V0, P1604
   Son TC, 2010, LECT NOTES ARTIF INT, V5948, P208
   Son TC, 2009, LECT NOTES COMPUT SC, V5649, P99, DOI 10.1007/978-3-642-02846-5_13
   Thiebaux S, 2003, P 18 INT JOINT C ART, V0, P0
   Thielscher M, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1276
   Le T, 2018, P I C AUTOMAT PLAN S, V0, P161
   Son TC, 2014, LECT NOTES ARTIF INT, V8761, P239, DOI 10.1007/978-3-319-11558-0_17
   van Benthem J, 2007, J APPL NONCLASSICAL, V17, P129, DOI 10.3166/JANCL.17.129-155
   van Benthem J, 2006, INFORM COMPUT, V204, P1620, DOI 10.1016/j.ic.2006.04.006
   van Eijck J, 2017, LYING WORKSH, V0, P0
   van Eijck Jan, 2004, DYNAMIC EPISTEMIC MO, V0, P0
   VanDitmarsch H, 2007, SYNTH LIBR, V337, P1, DOI 10.1007/978-1-4020-5839-4
   Wan H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1093
   Wan H, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P3257
NR 69
TC 6
Z9 6
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD JAN 15
PY 2022
VL 302
IS 
BP 
EP 
DI 10.1016/j.artint.2021.103601
EA OCT 2021
PG 32
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WH1DA
UT WOS:000707426600003
DA 2023-11-10
ER

PT J
AU Ankner, Z
   Balaji, P
   Zhu, Y
   Hiew, CK
   Wang, P
   Gupta, A
AF Ankner, Zachary
   Balaji, Purvaja
   Zhu, Ye
   Hiew, Chun Keat
   Wang, Patrick
   Gupta, Amar
TI EntailSum: An Entailment-Based Approach to Aspect-Based Text Summarization with Automated Aspect Adaptation
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Aspect-based summarization; entailment; zero-shot; natural language processing
AB Aspect-based summarization differs from generic text-summarization in which the generated summary must be conditioned on a given topic. A fundamental challenge to the aspect-based summarization approach is the lack of labeled data for training models, which limits the usage of supervised methods. One approach to address this issue is to introduce human intervention to generate unique datasets per aspect. However, there is a large number of possible aspects to summarize which makes this option impossible to scale. This limits the use of typical modeling techniques, and requires methods which excel in few-shot, or ideally zero-shot regimes. Hence, in this research, we propose a modular, two-step approach that does not need any aspect-based supervision. This research combines recent advances in zero-shot text classification and generic summarization in a novel way. The backbone of the proposed approach is a transformer network trained for the task of textual entailment, which is used to reduce a document to the set of on topic sentences. In the experiments, our model achieves a new state of the art compared to other unsupervised models on the MA-News dataset (ROUGE-1 35.70 and ROUGE-2 15.52), and even outperforms fine-tuned models without any supervision of its own.
C1 [Ankner, Zachary; Balaji, Purvaja; Gupta, Amar] MIT, Comp Sci & Artificial Intelligence Labs, Cambridge, MA 02139 USA.
   [Zhu, Ye] MIT, Sch Engn, Cambridge, MA 02139 USA.
   [Zhu, Ye] MIT, Sloan Sch Management, Cambridge, MA 02142 USA.
   [Hiew, Chun Keat] Bank Negara Malaysia, Digital & Technol Sect, Kuala Lumpur 05480, Selangor, Malaysia.
   [Wang, Patrick] Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.
C3 Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Northeastern University
RP Ankner, Z (通讯作者)，MIT, Comp Sci & Artificial Intelligence Labs, Cambridge, MA 02139 USA.
EM ankner@mit.edu
FU MIT CSAIL Fintech alliance
CR Angelidis S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3675
   [Anonymous], 2006, COLING ACL, V0, P0
   Bafna K, 2013, PROCEDIA COMPUT SCI, V22, P142, DOI 10.1016/j.procs.2013.09.090
   Baumel T, 2018, ARXIV, V0, P0
   Berthet Q, 2020, ARXIV, V0, P0
   Chang Ming-Wei, 2008, AAAI, V0, P830
   Dang Hoa Trang, 2005, P DOCUMENT UNDERSTAN, V2005, P1
   Daumé H, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Ficler Jessica, 2017, P WORKSH STYL VAR, V0, PP94, DOI 10.18653/V1/W17-4912
   Frermann L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6263
   Hayashi H, 2021, T ASSOC COMPUT LING, V9, P211, DOI 10.1162/tacl_a_00362
   He P, 2020, ARXIV, V0, P0
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Hu Z, 2017, P MACHINE LEARNING R, V70, P1587
   Keskar NS, 2019, ARXIV, V0, P0
   Krishna K, 2018, P 2018 C N AM CHAPTE, V1, P1697
   Kumar A, 2022, COGN COMPUT, V14, P130, DOI 10.1007/s12559-021-09835-8
   Levy Omer, 2017, P 21 C COMPUTATIONAL, V0, PP333, DOI 10.18653/v1/K17-1034
   Lewis M, 2019, ARXIV, V0, P0
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Lin C-Y, 2000, P 18 C COMP LING ASS, V1, P495, DOI 10.3115/990820.990892
   Ling W, 2016, P 2016 C N AM CHAPTE, V0, PP47, DOI 10.18653/V1/N16-1007
   Liu Y, 2021, PROC AAAI C ARTIF IN, V26, P1699
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Liu ZY, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP814, DOI 10.1109/ASRU46091.2019.9003764
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Ozyurt B, 2021, EXPERT SYST APPL, V168, P0, DOI 10.1016/j.eswa.2020.114231
   Popescu A-M, 2005, P HUMAN LANGUAGE TEC, V0, PP339, DOI 10.3115/1220575.1220618
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P255
   Song YQ, 2014, AAAI CONF ARTIF INTE, V0, P1579
   Tan B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6301
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang L, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4453
   Xie Yi, 2020, ARXIV, V0, P0
   Xing C, 2017, AAAI CONF ARTIF INTE, V0, P3351
   Yin Wenpeng, 2019, 2019 C EMPIRICAL MET, V0, P0
   Yogatama D, 2017, ARXIV, V0, P0
   Zheng C, 2020, ARXIV, V0, P0
NR 39
TC 1
Z9 1
U1 1
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD OCT 15
PY 2022
VL 36
IS 13
BP 
EP 
DI 10.1142/S0218001422590170
EA SEP 2022
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6N2FO
UT WOS:000857952400001
DA 2023-11-10
ER

PT J
AU Singhania, S
   Razniewski, S
   Weikum, G
AF Singhania, Sneha
   Razniewski, Simon
   Weikum, Gerhard
TI Predicting Document Coverage for Relation Extraction
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper presents a new task of predicting the coverage of a text document for relation extraction (RE): Does the document contain many relational tuples for a given entity? Coverage predictions are useful in selecting the best documents for knowledge base construction with large input corpora. To study this problem, we present a dataset of 31,366 diverse documents for 520 entities. We analyze the correlation of document coverage with features like length, entity mention frequency, Alexa rank, language complexity, and information retrieval scores. Each of these features has only moderate predictive power. We employ methods combining features with statistical models like TF-IDF and language models like BERT. The model combining features and BERT, HERB, achieves an F1 score of up to 46%. We demonstrate the utility of coverage predictions on two use cases: KB construction and claim refutation.
C1 [Singhania, Sneha; Razniewski, Simon; Weikum, Gerhard] Max Planck Inst Informat, Saarbrucken, Germany.
C3 Max Planck Society
RP Singhania, S (通讯作者)，Max Planck Inst Informat, Saarbrucken, Germany.
EM ssinghan@mpi-inf.mpg.de; srazniew@mpi-inf.mpg.de; weikum@mpi-inf.mpg.de
FU German Science Foundation (DFG: Deutsche Forschungsgemeinschaft) [4530095897]
CR Arnaout H, 2021, J WEB SEMANT, V71, P0, DOI 10.1016/j.websem.2021.100661
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P542
   Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP985, DOI 10.1145/3331184.3331303
   Darari F, 2013, LECT NOTES COMPUT SC, V8218, P66, DOI 10.1007/978-3-642-41335-3_5
   Devlin J, 2018, ARXIV, V1, P4171
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Flesch R, 1949, ART READABLE READING, V0, P0
   Galárraga L, 2017, WSDM17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP375, DOI 10.1145/3018661.3018739
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI 10.18653/V1/N18-1065
   Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI 10.1145/3447772
   Han X, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P745
   Hopkinson Andrew, 2018, P 2018 C N AM CHAPTE, V0, PP200, DOI 10.18653/v1/N18-3025
   Ipeirotis PG, 2007, ACM T DATABASE SYST, V32, P0, DOI 10.1145/1292609.1292611
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Lipton Zachary C, 2014, MACH LEARN KNOWL DISCOV DATABASES, V8725, P225, DOI 10.1007/978-3-662-44851-9_15
   Luggen M, 2019, LECT NOTES COMPUT SC, V11778, P453, DOI 10.1007/978-3-030-30793-6_26
   Mintz M, 2009, P JOINT C 47 ANN M A, V2, P1003, DOI 10.3115/1690219.1690287
   Mitchell T, 2018, COMMUN ACM, V61, P103, DOI 10.1145/3191513
   Nakashole N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1009
   Nogueira R, 2020, ABS190104085 ARXIV, V0, P0
   Nogueira Rodrigo, 2020, FINDINGS ASS COMPUTA, V0, PP708, DOI 10.18653/V1/2020.FINDINGS-EMNLP.63
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rashkin P, 2017, P 2017 C EMP METH NA, V0, PP2931, DOI 10.18653/V1/D17-1317
   Razniewski S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5771
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Robertson SE, 1995, OV 3 TEXT RETR C TRE, V109, P109
   Roy D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P2373
   Sandhaus Evan, 2008, NEW YORK TIMES ANNOT, V0, P0
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2895
   Thorne J, 2018, LONG PAPERS, V0, PP809, DOI 10.18653/V1/N18-1074
   Wang XL, 2019, PROC INT CONF DATA, V0, PP578, DOI 10.1109/ICDE.2019.00058
   Weikum G, 2021, FOUND TRENDS DATABAS, V10, P108, DOI 10.1561/1900000064
   Xu BF, 2021, AAAI CONF ARTIF INTE, V35, P14149
   Yao Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P764
   Zhang Y, 2017, P 2017 C EMPIRICAL M, V0, P35
NR 39
TC 0
Z9 0
U1 0
U2 2
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAR 18
PY 2022
VL 10
IS 
BP 207
EP 223
DI 10.1162/tacl_a_00456
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9LF
UT WOS:000923413700001
DA 2023-11-10
ER

PT J
AU Pandelea, V
   Ragusa, E
   Young, T
   Gastaldo, P
   Cambria, E
AF Pandelea, Vlad
   Ragusa, Edoardo
   Young, Tom
   Gastaldo, Paolo
   Cambria, Erik
TI Toward hardware-aware deep-learning-based dialogue systems
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Dialogue systems; Natural language processing; Artificial intelligence
AB In the past few years, the use of transformer-based models has experienced increasing popularity as new state-of-the-art performance was achieved in several natural language processing tasks. As these models are often extremely large, however, their use for applications within embedded devices may not be feasible. In this work, we look at one such specific application, retrieval-based dialogue systems, that poses additional difficulties when deployed in environments characterized by limited resources. Research on building dialogue systems able to engage in natural sounding conversation with humans has attracted increasing attention in recent years. This has led to the rise of commercial conversational agents, such as Google Home, Alexa and Siri situated on embedded devices, that enable users to interface with a wide range of underlying functionalities in a natural and seamless manner. In part due to memory and computational power constraints, these agents necessitate frequent communication with a server in order to process the users' queries. This communication may act as a bottleneck, resulting in delays as well as in the halt of the system should the network connection be lost or unavailable. We propose a new framework for hardware-aware retrieval-based dialogue systems based on the Dual-Encoder architecture, coupled with a clustering method to group candidates pertaining to a same conversation, that reduces storage capacity and computational power requirements.
C1 [Pandelea, Vlad; Young, Tom; Cambria, Erik] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Ragusa, Edoardo; Gastaldo, Paolo] Univ Genoa, DITEN, Dept Elect Elect Telecommun Engn & Naval Architec, Genoa, Italy.
C3 Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Genoa
RP Cambria, E (通讯作者)，Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
EM vlad.pandelea@ntu.edu.sg; edoardo.ragusa@edu.unige.it; tom@sentic.net; paolo.gastaldo@unige.it; cambria@ntu.edu.sg
FU Agency for Science, Technology and Research (A*STAR) under its AME Programmatic Funding Scheme [A18A2b0046]
CR [Anonymous], 2014, ARXIV14105518, V0, P0
   Arora Suket, 2013, ARXIV13064134, V0, P0
   Bachrach Y, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS14), V0, PP257, DOI 10.1145/2645710.2645741
   Boussaha BEA, 2019, ARXIV190712878, V0, P0
   Cambria E, 2020, SEMEVAL 2020, V0, P9
   Cambria E, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP105, DOI 10.1145/3340531.3412003
   Chen PH, 2018, ARXIV181012406, V0, P0
   Chen Qian, 2019, ARXIV190102609, V0, P0
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Guo RQ, 2016, JMLR WORKSH CONF PRO, V51, P482
   Han S, 2016, DEEP COMPRESSION COM, V0, P0
   Hesamifard E, 2017, CCSW 2017 PROC 2017, V0, PP39, DOI 10.1145/3140649.3140655.
   Hinton Geoffrey, 2015, ARXIV150302531, V0, P0
   Humeau Samuel, 2019, ARXIV190501969, V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Li W, 2020, ARXIV200600492, V0, P0
   Li Yanran, 2017, IJCNLP, V0, P0
   Duong L, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, P49
   Lowe Ryan, 2015, P 16 ANN M SPECIAL I, V0, PP285, DOI 10.18653/v1/W15-4640
   Ma YK, 2020, INFORM FUSION, V64, P50, DOI 10.1016/j.inffus.2020.06.011
   Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473
   Malkov Y, 2014, INFORM SYST, V45, P61, DOI 10.1016/j.is.2013.10.006
   Mazaré PE, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2775
   McDanel B, 2017, EWSN, V0, P168
   Mehta Y, 2020, ARTIF INTELL REV, V53, P2313, DOI 10.1007/s10462-019-09770-z
   Minaee S, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3439726
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ragusa E, 2020, IEEE INTELL SYST, V35, P50, DOI 10.1109/MIS.2020.3011586
   RITTER A, 2010, HUMAN LANGUAGE TECHN, V0, P172
   Ruder Sebastian, 2017, ARXIV170605098, V0, P0
   Shaham Uri, 2018, ARXIV180101587, V0, P0
   Shrivastava Anshumali, 2014, ADV NEURAL INFORM PR, V0, P2321
   Song YY, 2018, INT CONF AGRO-GEOINF, V0, P308
   Tang Raphael, 2019, DISTILLING TASK SPEC, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vig J, 2019, WORKSH DSTC7, V0, P0
   Wu X, 2017, ADV NEURAL INFORM PR, V30, P5745
   Xu HT, 2020, WORLD WIDE WEB, V23, P1989, DOI 10.1007/s11280-019-00688-8
   Yang L, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP245, DOI 10.1145/3209978.3210011
   Young T, 2020, NEUROCOMPUTING, V388, P102, DOI 10.1016/j.neucom.2019.12.126
   Young T, 2018, AAAI CONF ARTIF INTE, V0, P4970
   Yu HF, 2017, ADV NEUR IN, V30, P0
   Zhou X, 2016, P 2016 C EMP METH NA, V0, PP372, DOI 10.18653/v1/D16-1036
NR 45
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUL 15
PY 2022
VL 34
IS 13
BP 10397
EP 10408
DI 10.1007/s00521-020-05530-1
EA JAN 2021
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 2J4QQ
UT WOS:000605918300002
DA 2023-11-10
ER

PT J
AU Peng, L
   Yang, Y
   Zhang, XP
   Ji, YL
   Lu, HM
   Shen, HT
AF Peng, Liang
   Yang, Yang
   Zhang, Xiaopeng
   Ji, Yanli
   Lu, Huimin
   Shen, Heng Tao
TI Answer Again: Improving VQA With Cascaded-Answering Model
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Feature extraction; Visualization; Predictive models; Semantics; Task analysis; Fuses; Natural languages; Visual question answering; co-attention; image understanding
AB Visual Question Answering (VQA) is a very challenging task, which requires to understand visual images and natural language questions simultaneously. In the open-ended VQA task, most previous solutions focus on understanding the question and image contents, as well as their correlations. However, they mostly reason the answers in a one-stage way, which results in that the generated answers are significantly ignored. In this paper, we propose a novel approach, termed Cascaded-Answering Model (CAM), which extends the conventional one-stage VQA model to a two-stage model. Hence, the proposed model can fully explore the semantics embedded in the predicted answers. Specifically, CAM is composed of two cascaded answering modules: Candidate Answer Generation (CAG) module and Final Answer Prediction (FAP) module. In CAG module, we select multiple relevant candidates from the generated answers using a typical VQA approach with Co-Attention. While in FAP module, we integrate the information of question and image, together with the semantics explored from the selected candidate answers to predict the final answer. Experimental results demonstrate that the proposed model produces high-quality candidate answers and achieves the state-of-the-art performance on five large benchmark datasets, VQA-1.0, VQA-2.0, VQA-CP v2, TDIUC and COCO-QA.
C1 [Peng, Liang; Yang, Yang; Zhang, Xiaopeng; Ji, Yanli; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Peoples R China.
   [Peng, Liang; Yang, Yang; Zhang, Xiaopeng; Ji, Yanli; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Yang, Yang] Univ Elect Sci & Technol China UESTC, Inst Elect & Informat Engn, Dongguan 523808, Guangdong, Peoples R China.
   [Lu, Huimin] Kyushu Inst Technol, Dept Mech & Control Engn, Kitakyushu, Fukuoka 8048550, Japan.
C3 University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; Kyushu Institute of Technology
RP Yang, Y (通讯作者)，Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Peoples R China.
EM pliang951125@outlook.com; dlyyang@gmail.com; zxphistory@gmail.com; yanliji@uestc.edu.cn; dr.huimin.lu@ieee.org; shenhengtao@hotmail.com
FU National Key Research and Development Program of China [2018AAA0102200]; Sichuan Science and Technology Program, China [2018GZDZX0032, 2020YFS0057]; Fundamental Research Funds for the Central Universities [ZYGX2019Z015]; National Natural Science Foundation of China [61632007]; Dongguan Songshan Lake Introduction Programof Leading Innovative and Entrepreneurial Talents
CR Agrawal A, 2018, PROC CVPR IEEE, V0, PP4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2019, EMPIRICAL METHODS NA, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Bai YL, 2018, LECT NOTES COMPUT SC, V11216, P21, DOI 10.1007/978-3-030-01258-8_2
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, V0, P8102
   Ben-younes H, 2017, IEEE I CONF COMP VIS, V0, PP2631, DOI 10.1109/ICCV.2017.285
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Bin Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1345, DOI 10.1145/3123266.3123391
   Biten AF, 2019, IEEE I CONF COMP VIS, V0, PP4290, DOI 10.1109/ICCV.2019.00439
   Cadene R, 2019, PROC CVPR IEEE, V0, PP1989, DOI 10.1109/CVPR.2019.00209
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Nguyen DK, 2018, PROC CVPR IEEE, V0, PP6087, DOI 10.1109/CVPR.2018.00637
   Fukui Akira, 2016, ARXIV160601847, V0, PP457, DOI 10.18653/V1/D16-1044
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ilievski I, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS17), V0, PP415, DOI 10.1145/3126686.3126695
   Jiang Yu, 2018, ARXIV180709956, V0, P0
   Johnson J, 2017, PROC CVPR IEEE, V0, PP1988, DOI 10.1109/CVPR.2017.215
   Jun SH, 2017, ICEC17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, V0, P0, DOI DOI 10.1145/3154943.3154947
   Kafle K, 2017, IEEE I CONF COMP VIS, V0, PP1983, DOI 10.1109/ICCV.2017.217
   Kafle K, 2016, PROC CVPR IEEE, V0, PP4976, DOI 10.1109/CVPR.2016.538
   Kazemi V, 2017, ARXIV170403162, V0, P0
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li Q, 2018, LECT NOTES COMPUT SC, V11211, P570, DOI 10.1007/978-3-030-01234-2_34
   Li R, 2016, ADV NEURAL INFORM PR, V0, P4655
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2016, ADV NEUR IN, V29, P0
   Lu P, 2018, AAAI CONF ARTIF INTE, V0, P7218
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Nam H, 2017, PROC CVPR IEEE, V0, PP2156, DOI 10.1109/CVPR.2017.232
   Peng L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1202, DOI 10.1145/3343031.3350925
   Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3
   Ren M, 2015, P 28 INT C NEUR INF, V2, P2953
   Schwartz I, 2017, ADV NEUR IN, V30, P0
   Shi Y, 2018, LECT NOTES COMPUT SC, V11208, P158, DOI 10.1007/978-3-030-01225-0_10
   Shih KJ, 2016, PROC CVPR IEEE, V0, PP4613, DOI 10.1109/CVPR.2016.499
   Shrestha R, 2019, PROC CVPR IEEE, V0, PP10464, DOI 10.1109/CVPR.2019.01072
   Simonyan K, 2015, INT C LEARN REPRESEN, V0, P0
   Singh A, 2019, PROC CVPR IEEE, V0, PP8309, DOI 10.1109/CVPR.2019.00851
   Song JK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P906
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Teney D, 2018, PROC CVPR IEEE, V0, PP4223, DOI 10.1109/CVPR.2018.00444
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP154, DOI 10.1145/3123266.3123326
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP519, DOI 10.1145/3240508.3240513
   Wu CF, 2018, ADV NEUR IN, V31, P0
   Wu Q, 2016, PROC CVPR IEEE, V0, PP4622, DOI 10.1109/CVPR.2016.500
   Yang C, 2019, IEEE ACCESS, V7, P26652, DOI 10.1109/ACCESS.2019.2900530
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2017, PROC CVPR IEEE, V0, PP4187, DOI 10.1109/CVPR.2017.446
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, V0, PP1839, DOI 10.1109/ICCV.2017.202
   Yu Zhou, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Zhang MX, 2017, LECT NOTES COMPUT SC, V10538, P261, DOI 10.1007/978-3-319-68155-9_20
   Zhang MX, 2019, IEEE T IMAGE PROCESS, V28, P32, DOI 10.1109/TIP.2018.2855415
   Zhang Y, 2018, ARXIV180205766, V0, P0
NR 62
TC 13
Z9 13
U1 6
U2 51
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD APR 1
PY 2022
VL 34
IS 4
BP 1644
EP 1655
DI 10.1109/TKDE.2020.2998805
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA ZP7TV
UT WOS:000766623600010
DA 2023-11-10
ER

PT J
AU Liu, T
   Yu, K
   Wang, L
   Zhang, XY
   Zhou, H
   Wu, XF
AF Liu, Tong
   Yu, Ke
   Wang, Lu
   Zhang, Xuanyu
   Zhou, Hao
   Wu, Xiaofei
TI Clickbait detection on WeChat: A deep model integrating semantic and syntactic information
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Clickbait detection; Natural language processing; Graph attention network; Attention mechanism; Syntactic structure
AB In online social media, there is a large amount of clickbait using various tricks such as curious words and well-designed sentence structures, to attract users to click on hyperlinks for unknown benefits. Clickbait detection aims to detect these hyperlinks through automated algorithms. Previous researches usually focus on the semantic information of the English clickbait corpus. In our paper, we construct a Chinese WeChat clickbait dataset, and propose an effective deep method, i.e., multiple features for WeChat clickbait detection (MFWCD), by integrating semantic, syntactic and auxiliary information. Based on the MFWCD framework, we propose two models with different parameter scales, namely MFWCD-BERT and MFWCD-BiLSTM, which respectively use Bidirectional Encoder Representation from Transformers (BERT) and lightweight Bidirectional Long Short-Term Memory (Bi-LSTM) network with attention mechanism to encode title semantics. In addition, we propose an improved Graph Attention Network (GAT) to aggregate local syntactic structures of titles and use attention mechanism to capture valuable structures. Finally, an auxiliary feature related to user reading behavior is introduced to obtain a richer title representation. Sufficient experiments prove the effectiveness and interpretability of our MFWCD for clickbait detection, and the performance is better than compared baseline methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Liu, Tong; Yu, Ke; Wang, Lu; Zhang, Xuanyu; Zhou, Hao; Wu, Xiaofei] Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Yu, K (通讯作者)，Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China.
EM liutt@bupt.edu.cn; yuke@bupt.edu.cn; wangl@bupt.edu.cn; Xuanyu_Zhang@bupt.edu.cn; zhouh@bupt.edu.cn; wuxf@bupt.edu.cn
FU National Natural Science Foundation of China [61601046, 61171098]; 111 Project of China [B08004]; EU FP7 IRSES Mobile Cloud Project [12212]
CR Agrawal A, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), V0, PP268, DOI 10.1109/NGCT.2016.7877426
   Biyani P, 2016, AAAI CONF ARTIF INTE, V0, P94
   Blom JN, 2015, J PRAGMATICS, V76, P87, DOI 10.1016/j.pragma.2014.11.010
   Bruna J, 2013, ABS13126203 CORR, V0, P0, DOI DOI 10.48550/ARXIV.1312.6203
   Chakraborty A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, V0, PP9, DOI 10.1109/ASONAM.2016.7752207
   Chen Y, 2015, P 2015 ACM WORKSH MU, V0, PP15, DOI 10.1145/2823465.2823467
   Devlin J, 2018, ARXIV, V1, P4171
   Dong MQ, 2019, LECT NOTES ARTIF INT, V11440, P56, DOI 10.1007/978-3-030-16145-3_5
   Glenski M, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Gori M, 2005, IEEE IJCNN, V0, P729
   Grbovic M, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP311, DOI 10.1145/3219819.3219885
   Grover A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP855, DOI 10.1145/2939672.2939754
   Hamilton William L, 2017, ADV NEURAL INFORM PR, V0, P1025
   Hu GM, 2021, KNOWL-BASED SYST, V212, P0, DOI 10.1016/j.knosys.2020.106584
   Hu LM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4821
   Kingma DP, 2014, C TRACK P, V0, P0
   Kipf TN, 2016, P INT C LEARNING REP, V0, P0
   Kumar V, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1225, DOI 10.1145/3209978.3210144
   Li QM, 2018, AAAI CONF ARTIF INTE, V0, P3538
   Liao LZ, 2018, IEEE T KNOWL DATA EN, V30, P2257, DOI 10.1109/TKDE.2018.2819980
   Liu Z, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Luckner M, 2014, COMPUT SECUR, V46, P79, DOI 10.1016/j.cose.2014.07.006
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Potthast Martin, 2016, ADVANCES IN INFORMATION RETRIEVAL. 38TH EUROPEAN CONFERENCE ON IR RESEARCH, V0, P810, DOI 10.1007/978-3-319-30671-1_72
   Shang C, 2018, ARXIV E PRINTS ARXIV, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5679
   VELIKOVI P, 2017, ARXIV171010903, V0, P0
   Wang JZ, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP839, DOI 10.1145/3219819.3219869
   Wang K, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Xie FF, 2021, KNOWL-BASED SYST, V211, P0, DOI 10.1016/j.knosys.2020.106524
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   Xu Z, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Yang ZX, 2020, KNOWL-BASED SYST, V204, P0, DOI 10.1016/j.knosys.2020.106194
   Zheng JM, 2021, KNOWL-BASED SYST, V214, P0, DOI 10.1016/j.knosys.2020.106714
   Zhou Yiren, 2017, CORR, V0, P0
NR 36
TC 1
Z9 1
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JUN 7
PY 2022
VL 245
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.108605
EA APR 2022
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1Q9CM
UT WOS:000802978200004
DA 2023-11-10
ER

PT J
AU Alkhawaldeh, RS
   Alawida, M
   Alshdaifat, NFF
   Alma'aitah, WZ
   Almasri, A
AF Alkhawaldeh, Rami S.
   Alawida, Moatsum
   Alshdaifat, Nawaf Farhan Funkur
   Alma'aitah, Wafa' Za'al
   Almasri, Ammar
TI Ensemble deep transfer learning model for Arabic (Indian) handwritten digit recognition
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Ensemble transfer learning; Arabic (Indian) handwritten recognition; Deep supervised learning; Transfer learning; MobileNetV2; ResNet-50
ID convolutional neural-networks; prediction; features
AB Recognising handwritten digits or characters is a challenging task due to noisy data that results from different writing styles. Numerous applications essentially motivate to build an effective recognising model for such purposes by utilizing recent intelligent techniques. However, the difficulty emerges when using the Arabic language that suffers from diverse noises; because of the way of writing inherent in connecting characters and digits. Therefore, this work focuses on the Arabic (Indian) digits and propose an ensemble deep transfer learning (EDTL) model that efficaciously detect and recognise these digits. The EDTL model is a combination of two effective pre-trained transfer learning models that consume time and cost complexity in the training phase. The EDTL is trained on large datasets to extract relevant features as input to a fully-connected Artificial Neural Network classifier. The experimental results, using popular datasets, show significant performance obtained by the EDTL model with accuracy reached up to 99.83% in comparison to baseline methods include deep transfer learning models, ensemble deep transfer learning models and state-of-the-art techniques.
C1 [Alkhawaldeh, Rami S.] Univ Jordan, Dept Comp Informat Syst, Aqaba 77110, Jordan.
   [Alawida, Moatsum] Univ Sains Malaysia USM, Sch Comp Sci, Gelugor 11800, Penang, Malaysia.
   [Alawida, Moatsum] Abu Dhabi Univ, Dept Comp Sci, Abu Dhabi, U Arab Emirates.
   [Alshdaifat, Nawaf Farhan Funkur] Al Al Bayt Univ, Prince Hussein Bin Abdullah, Dept Comp Sci, Fac Informat Technol, Mafraq 25113, Jordan.
   [Alma'aitah, Wafa' Za'al] Hashemite Univ, Fac Sci, Dept Basic Sci, Zarqa, Jordan.
   [Almasri, Ammar] Balqa Appl Univ, Dept Management Informat Syst, Salt 19117, Jordan.
C3 University of Jordan; Universiti Sains Malaysia; Abu Dhabi University; Al al-Bayt University; Hashemite University; Al-Balqa Applied University
RP Alkhawaldeh, RS (通讯作者)，Univ Jordan, Dept Comp Informat Syst, Aqaba 77110, Jordan.
EM r.alkhawaldeh@ju.edu.jo; matsm88@yahoo.com; nawaf@aabu.edu.jo; wafaa_maitah@hu.edu.jo; Ammar.almasri@bau.edu.jo
CR Abdleazeem S, 2008, INT J DOC ANAL RECOG, V11, P127, DOI 10.1007/s10032-008-0073-5
   Abuowaida SFA, 2021, JORDAN J COMPUT INFO, V7, P74, DOI 10.5455/jjcit.71-1603701313
   Al-wajih E, 2021, MULTIMED TOOLS APPL, V80, P24399, DOI 10.1007/s11042-021-10762-x
   Alani AA, 2017, INFORMATION, V8, P0, DOI 10.3390/info8040142
   Alkhateeb JH, 2020, INT J COMMUN NETW IN, V12, P411
   Alkhawaldeh RS, 2021, SOFT COMPUT, V25, P3131, DOI 10.1007/s00500-020-05368-8
   Alkhawaldeh RS, 2019, SCI PROGRAMMING-NETH, V2019, P0, DOI 10.1155/2019/7213717
   Alkhawaldeh RS, 2019, IET COMMUN, V13, P2609, DOI 10.1049/iet-com.2018.5430
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8030292
   Alshdaifat NFF, 2020, ECOL INFORM, V59, P0, DOI 10.1016/j.ecoinf.2020.101121
   Altaf F, 2021, NEURAL COMPUT APPL, V33, P14037, DOI 10.1007/s00521-021-06044-0
   Ashiquzzaman Akm, 2019, DATA MANAGEMENT, V0, P299, DOI 10.1007/978-981-13-1402-5_23
   Ashiquzzaman A, 2017, 2017 IEEE INT C IM V, V0, P1
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Can YS, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10165430
   Chollet F, 2018, DEEP LEARNING PYTHON, V0, P0, DOI DOI 10.1007/978-1-4842-2766-4
   de Sousa IP, 2018, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.167
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dua M, 2021, NEURAL COMPUT APPL, V33, P3155, DOI 10.1007/s00521-020-05209-7
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   Giovannetti A, 2021, NEURAL COMPUT APPL, V33, P14651, DOI 10.1007/s00521-021-06105-4
   Gupta D, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.113784
   Howard Andrew G, 2017, ARXIV170404861, V0, P0
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8010027
   Latif G, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP90, DOI 10.1109/ASAR.2018.8480289
   Loey M, 2017, DEEP LEARNING AUTOEN, V0, P1
   Lumini A, 2019, ECOL INFORM, V51, P33, DOI 10.1016/j.ecoinf.2019.02.007
   Maheshwari M, 2018, INT J APPL ENG RES, V13, P8090
   Mahmoud S, 2008, SIGNAL PROCESS, V88, P844, DOI 10.1016/j.sigpro.2007.10.002
   Minetto R, 2019, IEEE T GEOSCI REMOTE, V57, P6530, DOI 10.1109/TGRS.2019.2906883
   Mudhsh M, 2017, INFORMATION, V8, P0, DOI 10.3390/info8030105
   Owusu E, 2021, NEURAL COMPUT APPL, V33, P11661, DOI 10.1007/s00521-021-05881-3
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI 10.1162/neco_a_00990
   Rehman A, 2019, IEEE ACCESS, V7, P17149, DOI 10.1109/ACCESS.2018.2890810
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Shahabi MS, 2021, BIOCYBERN BIOMED ENG, V41, P946, DOI 10.1016/j.bbe.2021.06.006
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/7068349
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
NR 40
TC 12
Z9 12
U1 2
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JAN 15
PY 2022
VL 34
IS 1
BP 705
EP 719
DI 10.1007/s00521-021-06423-7
EA AUG 2021
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YE3WM
UT WOS:000689599100001
DA 2023-11-10
ER

PT J
AU Gao, ZP
   Yan, JC
   Zhai, GT
   Zhang, JY
   Yang, XK
AF Gao, Zhongpai
   Yan, Junchi
   Zhai, Guangtao
   Zhang, Juyong
   Yang, Xiaokang
TI Robust Mesh Representation Learning via Efficient Local Structure-Aware Anisotropic Convolution
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Shape; Solid modeling; Topology; Convolution; Faces; Spirals; Representation learning; 3-D mesh; 3-D morpable model; graph convolutional network (GCN); representation learning
AB Mesh is a type of data structure commonly used for 3-D shapes. Representation learning for 3-D meshes is essential in many computer vision and graphics applications. The recent success of convolutional neural networks (CNNs) for structured data (e.g., images) suggests the value of adapting insights from CNN for 3-D shapes. However, 3-D shape data are irregular since each node's neighbors are unordered. Various graph neural networks for 3-D shapes have been developed with isotropic filters or predefined local coordinate systems to overcome the node inconsistency on graphs. However, isotropic filters or predefined local coordinate systems limit the representation power. In this article, we propose a local structure-aware anisotropic convolutional operation (LSA-Conv) that learns adaptive weighting matrices for each template's node according to its neighboring structure and performs shared anisotropic filters. In fact, the learnable weighting matrix is similar to the attention matrix in the random synthesizer--a new Transformer model for natural language processing (NLP). Since the learnable weighting matrices require large amounts of parameters for high-resolution 3-D shapes, we introduce a matrix factorization technique to notably reduce the parameter size, denoted as LSA-small. Furthermore, a residual connection with a linear transformation is introduced to improve the performance of our LSA-Conv. Comprehensive experiments demonstrate that our model produces significant improvement in 3-D shape reconstruction compared to state-of-the-art methods.
C1 [Gao, Zhongpai; Zhai, Guangtao; Yang, Xiaokang] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.
   [Yan, Junchi] Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.
   [Zhang, Juyong] Univ Sci & Technol China, Hefei 230026, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Chinese Academy of Sciences; University of Science & Technology of China, CAS
RP Gao, ZP (通讯作者)，Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.; Yan, JC (通讯作者)，Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.
EM gaozhongpai6@gmail.com; yanjunchi@sjtu.edu.cn; zhaiguangtao@sjtu.edu.cn; juyong@ustc.edu.cn; xkyang@sjtu.edu.cn
FU Shanghai Municipal Science and Technology Major Project [2021SHZDZX0102]; National Natural Science Foundation of China [U19B2035, 61831105, 61901259, 61972250]; China Postdoctoral Science Foundation [BX2019208]
CR [Anonymous], 2016, P 11 INT JOINT C COM, V0, P0
   Atwood J, 2016, P 30 INT C NEURAL IN, V0, P0, DOI DOI 10.5555/3157096.3157320
   Blanz V, 1999, COMP GRAPH, V0, PP187, DOI 10.1145/311535.311556
   Bogo F, 2017, PROC CVPR IEEE, V0, PP5573, DOI 10.1109/CVPR.2017.591
   Bogo F, 2014, PROC CVPR IEEE, V0, PP3794, DOI 10.1109/CVPR.2014.491
   Boscaini D, 2016, ABS160506437 CORR, V0, P0
   Bouritsas G, 2019, IEEE I CONF COMP VIS, V0, PP7212, DOI 10.1109/ICCV.2019.00731
   Bruna Joan, 2014, ICLR 2014, V0, P0
   Cao C, 2014, ACM T GRAPHIC, V33, P0, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen Zhixiang, 2021, P IEEE CVF C COMP VI, V0, P13164
   Clevert D-A, 2016, P 4 INT C LEARNING R, V0, P0
   Cucurull Guillem, 2018, INT C LEARN REPR, V0, P1
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Defferrard Michael, 2016, ADV NEURAL INFORM PR, V0, P3837
   Ding XH, 2021, PROC CVPR IEEE, V0, PP13728, DOI 10.1109/CVPR46437.2021.01352
   Donlic M, 2017, 8TH INTERNATIONAL SCIENTIFIC CONFERENCE ON KINESIOLOGY, V0, P694
   Gao Z, 2020, ARXIV200513135, V0, P0
   Gao Z, 1900, V2021, V0, P1
   Genova K, 2018, PROC CVPR IEEE, V0, PP8377, DOI 10.1109/CVPR.2018.00874
   Gong SX, 2019, INT CONF BIOMETR, V0, P0
   Groueix T, 2018, LECT NOTES COMPUT SC, V11206, P235, DOI 10.1007/978-3-030-01216-8_15
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu Qingyong, 2020, P IEEE CVF C COMP VI, V0, PP11108, DOI 10.1109/CVPR42600.2020.01112
   Jiang ZH, 2019, PROC CVPR IEEE, V0, PP11949, DOI 10.1109/CVPR.2019.01223
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, P0, DOI 10.1145/1778765.1778839
   Kingma DP, 2014, C TRACK P, V0, P0
   Kipf TN, 2017, P INT C LEARN REPR, V0, PP1, DOI 10.1109/ICDM.2019.00070
   Li RY, 2018, AAAI CONF ARTIF INTE, V0, P3546
   Li YY, 2018, ADV NEUR IN, V31, P0
   Lim I, 2018, P EUR C COMP VIS WOR, V0, P1
   Liu F, 2018, PROC CVPR IEEE, V0, PP5216, DOI 10.1109/CVPR.2018.00547
   Liu ZW, 2015, IEEE I CONF COMP VIS, V0, PP3730, DOI 10.1109/ICCV.2015.425
   Loper M, 2015, ACM T GRAPHIC, V34, P0, DOI 10.1145/2816795.2818013
   Tran L, 2018, PROC CVPR IEEE, V0, PP7346, DOI 10.1109/CVPR.2018.00767
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), V0, PP832, DOI 10.1109/ICCVW.2015.112
   Monti F, 2017, PROC CVPR IEEE, V0, PP5425, DOI 10.1109/CVPR.2017.576
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, V0, PP296, DOI 10.1109/AVSS.2009.58
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Romero J, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3130800.3130883
   Tay Y, 1900, V2021, V0, P10183
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Verma N, 2018, PROC CVPR IEEE, V0, PP2598, DOI 10.1109/CVPR.2018.00275
   Xie JW, 2018, PROC CVPR IEEE, V0, PP8629, DOI 10.1109/CVPR.2018.00900
   Yang X, 2020, IEEE COMPUT SOC CONF, V0, P348
   Zhu XY, 2016, PROC CVPR IEEE, V0, PP146, DOI 10.1109/CVPR.2016.23
   Zhu XY, 2015, PROC CVPR IEEE, V0, PP787, DOI 10.1109/CVPR.2015.7298679
NR 49
TC 1
Z9 1
U1 3
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2022.3151609
EA FEB 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA ZN2OF
UT WOS:000764879200001
PM 35226610
DA 2023-11-10
ER

PT J
AU Koloski, B
   Perdih, TS
   Robnik-Sikonja, M
   Pollak, S
   Skrlj, B
AF Koloski, Boshko
   Perdih, Timen Stepisnik
   Robnik-Sikonja, Marko
   Pollak, Senja
   Skrlj, Blaz
TI Knowledge graph informed fake news classification via heterogeneous representation ensembles
SO NEUROCOMPUTING
LA English
DT Article
DE Fake news detection; Knowledge graphs; Text representation; Representation learning; Neuro-symbolic learning
AB Increasing amounts of freely available data both in textual and relational form offers exploration of richer document representations, potentially improving the model performance and robustness. An emerging problem in the modern era is fake news detection-many easily available pieces of information are not necessarily factually correct, and can lead to wrong conclusions or are used for manipulation. In this work we explore how different document representations, ranging from simple symbolic bag-of-words, to contextual, neural language model-based ones can be used for efficient fake news identification. One of the key contributions is a set of novel document representation learning methods based solely on knowledge graphs, i.e., extensive collections of (grounded) subject-predicate-object triplets. We demonstrate that knowledge graph-based representations already achieve competitive performance to conventionally accepted representation learners. Furthermore, when combined with existing, contextual representations, knowledge graph-based document representations can achieve state-of-the-art performance. To our knowledge this is the first larger-scale evaluation of how knowledge graph-based representations can be systematically incorporated into the process of fake news classification. (c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Koloski, Boshko; Skrlj, Blaz] Jozef Stefan Int Postgrad Sch, Ljubljana, Slovenia.
   [Koloski, Boshko; Perdih, Timen Stepisnik; Pollak, Senja; Skrlj, Blaz] Jozef Stefan Inst, Ljubljana 1000, Slovenia.
   [Robnik-Sikonja, Marko] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute; Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute; University of Ljubljana
RP Skrlj, B (通讯作者)，Jozef Stefan Int Postgrad Sch, Ljubljana, Slovenia.; Skrlj, B (通讯作者)，Jozef Stefan Inst, Ljubljana 1000, Slovenia.
CR Alhindi Tariq, 2018, P 1 WORKSHOP FACT EX, V0, PP85, DOI 10.18653/V1/W18-5513
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Amirkhani FSAJBH, 2020, FNID FAKE NEWS INFER, V0, P0, DOI DOI 10.21227/FBZD-SW81
   Bordes A, 2013, ADV NEURAL INFORM PR, V26, P0, DOI 10.5555/2999792.2999923
   Buda J, 2020, CLEF, V0, P0
   Gilda S, 2017, IEEE ST CONF RES DEV, V0, PP110, DOI 10.1109/SCORED.2017.8305411
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Kadam AB, 2020, J TRAVEL MED, V27, P0, DOI 10.1093/jtm/taaa057
   Kai Shu, 2017, ACM SIGKDD EXPLORATIONS NEWSLETTER, V19, P22, DOI 10.1145/3137597.3137600
   Kazemi SM, 2018, ADV NEUR IN, V31, P0
   Koloski B, 2020, CLEF, V2696, P0
   Kraskov A, 2004, PHYS REV E, V69, P0, DOI 10.1103/PhysRevE.69.066138
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Loper E, 2002, P ACL 02 WORKSHOP EF, V1, P63, DOI 10.3115/1118108.1118117
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P505
   Martinc M, 2018, CEUR WORKSHOP PROC, V2125, P0
   Ostendorff M, 2019, ARXIV190908402V1, V0, P0
   Patwa P, 2021, P CONSTRAINT WORSKH, V0, P0
   Patwa P, 2021, INT WORKSH COMB ONL, V0, P0
   Perdih TS, 2021, 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2021), V0, PP105, DOI 10.1109/SAMI50585.2021.9378668
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Pulido CM, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17072430
   Rangel Francisco, 2020, CLEF, V2696, P1
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Schuster T, 2020, COMPUT LINGUIST, V46, P499, DOI 10.1162/COLI_a_00380
   Shu K, 2020, ARXIV PREPRINT ARXIV, V0, P1
   Sun Zhiqing, 2019, 7 INT C LEARNING REP, V0, P0
   Trouillon T, 2016, PR MACH LEARN RES, V48, P0
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang Z, 2014, KNOWLEDGE GRAPH TEXT, V0, PP1591, DOI 10.3115/v1/D14-1167
   Yang B, 2015, P INT C LEARNING REP, V0, P0
   Zhang JW, 2020, PROC INT CONF DATA, V0, PP1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang S, 2019, ADV NEUR IN, V32, P0
   Zhu ZC, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2494, DOI 10.1145/3308558.3313508
NR 47
TC 11
Z9 11
U1 1
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUL 28
PY 2022
VL 496
IS 
BP 208
EP 226
DI 10.1016/j.neucom.2022.01.096
EA MAY 2022
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 2B3WG
UT WOS:000810121200005
DA 2023-11-10
ER

PT J
AU Wolk, K
   Wolk, A
   Wnuk, D
   Grzes, T
   Skubis, I
AF Wolk, Krzysztof
   Wolk, Agnieszka
   Wnuk, Dominika
   Grzes, Tomasz
   Skubis, Ida
TI Survey on dialogue systems including slavic languages
SO NEUROCOMPUTING
LA English
DT Article
DE Slavic languages; Task-oriented dialogue systems; Non-task-oriented dialogue systems; Chatbots; Machine learning; Artificial intelligence
ID neural-network; speech recognition; communication; generation; models
AB Slavic languages pose a challenge to the researchers in the domain of dialogue technology. A relatively free word order with a large degree of inflection, such as conjugation of verbs, and declension of adjectives, pronouns, and nouns are exhibited by the Slavic languages, which has a significant impact on the size of lexical inventories that significantly complicate the design of dialogue systems. This article conducts an empirical study on the state-of-the-art dialogue systems within Slavic languages. Moreover, we review the existing models in recent dialogue systems, pinpoint the current main challenges and identify potential research directions of practical and intelligent systems within low-resourced languages. (C) 2021 Published by Elsevier B.V.
C1 [Wolk, Krzysztof; Wolk, Agnieszka; Wnuk, Dominika; Grzes, Tomasz; Skubis, Ida] Polish Japanese Acad Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.
   [Wolk, Agnieszka; Grzes, Tomasz] Bialystok Tech Univ, Fac Comp Sci, Wiejska 45A, PL-15351 Bialystok, Poland.
   [Wnuk, Dominika; Skubis, Ida] Jan Dlugosz Univ Czestochowa, Waszyngtona 4-8, PL-42200 Czestochowa, Poland.
C3 Polsko-Japonska Akademia Technik Komputerowych; Bialystok University of Technology; Jan Dlugosz University
RP Wolk, K (通讯作者)，Polish Japanese Acad Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.
EM kwolk@pja.edu.pl; awolk@pja.edu.pl; dwnuk@pja.edu.pl; t.grzes@pb.edu.pl
CR Adamopoulou E, 2020, MACHINE LEARNING APP, V2, P0, DOI 10.1016/j.mlwa.2020.100006
   AGic ZELJKo, 2013, P 4 BIENNIAL INT WOR, V0, P48
   AISB, 2018, LOEBN PRIZ RES 2018, V0, P0
   Almansor EH, 2020, ADV INTELL SYST COMP, V993, P534, DOI 10.1007/978-3-030-22354-0_47
   Alperen MS, 2010, P LREC WORKSHOP EXPL, V0, P49
   Androutsopoulou A, 2019, GOV INFORM Q, V36, P358, DOI 10.1016/j.giq.2018.10.001
   [Anonymous], 1998, NULL SUBJECT PROPERT, V0, P0
   [Anonymous], 2019, YANDEX CO NEWS YANDE, V0, P0
   Anstatt T, 2016, TUBINGER BEITRAGE LI, V554, P0
   Arkhipov M, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP2019), V0, P89
   Artemova E, 1900, V2021, V0, P465
   AZBot, 2018, ONLINE CHATBOT, V0, P0
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P85
   Bhagwat VA, 2018, DEEP LEARNING CHATBO, V0, P0
   Bhowmik K, 2021, DIGITAL, V3, P0, DOI 10.3390/digital1030011
   Bordes A, 2016, ABS160507683 C0RR, V0, P0
   Boyd A, 2020, ABS200506114 CORR, V0, P0
   Browne W, 2020, SLAVIC LANGUAGES W S, V0, P0
   Bystrov Y, 2018, STUDIES LANGUAGES, V33, P17
   Chatbotsorg, 2021, CHATB ANN IKEA VIRT, V0, P0
   Chatbotsorg, 2021, CHATB ORG SLOV VIRT, V0, P0
   Chatbotsorg, 2020, CHATB ORG SLOV VIRT, V0, P0
   Chatbotsorg, 2020, CHATB ORG VIRT ASS V, V0, P0
   Chatbotsorg, 2020, CHATB ORG POL POL VI, V0, P0
   Chatbotsorg, 2020, CHATB ORG CZECH REP, V0, P0
   Chatbotsorg, 2013, CHATBOT SINK ITC VIR, V0, P0
   Chatbotsorg, 2020, CHATB TEPSON TEL POL, V0, P0
   Chatbotsorg, 2020, CHATB ORG RUSS VIRT, V0, P0
   Chen C-Y, 2018, 2 AL PRIZ P AL PRIC, V0, P0
   Chen Y, 2017, P 55 ANN M ASS COMP, V0, P8
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Cinque G, 2005, OXFORD HDB COMP SYNT, V0, P0
   Clutch, 2020, TOP CHATBOT CO POLAN, V0, P0
   Clutch, 2020, TOP ARTIFICIAL INTEL, V0, P0
   Csaky R, 2019, ABS190808835 CORR, V0, P0
   Dadas S, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Deriu J, 2021, ARTIF INTELL REV, V54, P755, DOI 10.1007/s10462-020-09866-x
   Devlin J, 2018, ARXIV, V1, P4171
   DHaro LF, 2019, 9 INT WORKSH SPOK DI, V0, P0
   Dinan E, 2018, ARXIV181101241, V0, P0
   Dropuljic B, 2011, INT SYMP IMAGE SIG, V0, P95
   Dyer Chris, 2013, P 2013 C N AM CHAPTE, V0, P644
   Engelbrecht K-P, 2008, P ESSV, V0, P86
   Eric M, 2017, ABS170104024 CORR, V0, P0
   Ezquerra AN, 2018, THESIS UPC, V0, P0
   Fang H, 2017, P ALEXA PRIZE ALEXA, V0, P0
   Galley M, 2015, ABS150606863 CORR, V0, P0
   Ghazvininejad M, 2018, AAAI CONF ARTIF INTE, V0, P5110
   Goddeau D, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, V0, P0
   Goo C-W, 2018, P 2018 C N AM CHAPT, V2, P0
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ham D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P583
   Hancock B, 2019, ABS190105415 CORR, V0, P0
   Henderson M, 2019, ABS190901296 CORR, V0, P0
   Hongshen Chen, 2017, ACM SIGKDD EXPLORATIONS NEWSLETTER, V19, P25, DOI 10.1145/3166054.3166058
   Hu BT, 2014, ADV NEUR IN, V27, P0
   Huang ML, 2020, ACM T INFORM SYST, V38, P0, DOI 10.1145/3383123
   Igras Magdalena, 2013, STUDIA INFORMATICA, V34, P67
   Ji Z, 2014, INFORM RETRIEVAL APP, Vabs/1408.6988, P0
   Jung S, 2019, COMPUT SPEECH LANG, V56, P130, DOI 10.1016/j.csl.2018.12.008
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC, V0, P0
   Jurdzinski G, 2016, SCHEDAE INFORM, V25, P0
   Just AI, 2019, SMART SPEAKERS VOICE, V0, P0
   Justin T, 2015, LECT NOTES ARTIF INT, V9302, P351, DOI 10.1007/978-3-319-24033-6_40
   Kaleta R, 2013, ACTA POLONO RUTHENIC, V0, P185
   Kandasamy K, 2017, ABS170203334 CORR, V0, P0
   Kapoc J, 2020, APPL SCI, V10, P0
   Khoury RE, 2019, GOOGLE ASSISTANT IS, V0, P0
   Kim D, 2014, INTERSPEECH, V0, P328
   Kinsella B, 2018, GOOGLE ASSISTANT ROL, V0, P0
   Kipyatkova IS, 2017, AUTOMAT REM CONTR+, V78, P858, DOI 10.1134/S0005117917050083
   Klosowski P, 2019, SIG P ALGO ARCH ARR, V0, PP223, DOI 10.23919/spa.2019.8936782
   Koehn P, 2017, WMT, V0, P28
   Koidan K, 2020, EVALUATION METRICS D, V0, P0
   Kosta P, 2009, THESIS, V0, P0
   Kuligowska K, 2018, ANN U M CURIESKLODOW, V52, P71
   Kuligowska K, 2015, PCBR, V0, P0, DOI DOI 10.18483/PCBR.22
   Kumar R, 2020, INT J ENG TECHNOLOGY, V7, P2791
   Kuratov Y, 2019, ABS190507213 CORR, V0, P0
   Laurisz M, 2020, RAPORT CHATBOTY POLS, V0, P0
   Lenc L, 2017, LECT NOTES COMPUT SC, V10614, P368, DOI 10.1007/978-3-319-68612-7_42
   Leuski A, 2011, AI MAG, V32, P42, DOI 10.1609/aimag.v32i2.2347
   Li J, 2015, ABS151003055, V0, P0
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Li Jiwei, 2017, EMNLP, V0, P0
   Li Jiwei, 2016, EMNLP, V0, P0
   Li X, 2020, AAAI CONF ARTIF INTE, V34, P8253
   Li Z, 2019, ABS190708854 CORR, V0, P0
   Li Z, 2020, ABS200909781 CORR, V0, P0
   Li Z, 2020, SYMMETRY-BASEL, V12, P0, DOI 10.3390/sym12111756
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Lison P, 2017, ABS170408966 CORR, V0, P0
   Liu B, 2018, ABS180406512 CORR, V0, P0
   Liu B, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1237, DOI 10.1145/3178876.3186022
   Liu SM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1489
   Ljubesic N, 2011, LECT NOTES ARTIF INT, V6836, P395, DOI 10.1007/978-3-642-23538-2_50
   Ljubesic Nikola, 2014, P 9 WEB CORPUS WORKS, V0, PP29, DOI 10.3115/v1/W14-0405
   de Lacalle ML, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P2796
   Lowe R, 2017, ABS170807149 CORR, V0, P0
   Lowe Ryan, 2015, P 16 ANN M SPECIAL I, V0, PP285, DOI 10.18653/v1/W15-4640
   Luong T, 2013, P 17 C COMP NAT LANG, V0, PP104, DOI 10.1007/BF02579642
   Lyda A, 2013, OCCUPYING NICHES INT, V0, P0
   Ma YK, 2020, INFORM FUSION, V64, P50, DOI 10.1016/j.inffus.2020.06.011
   Magyar J, 2019, IEEE SYS MAN CYBERN, V0, PP3416, DOI 10.1109/SMC.2019.8914248
   Makarova V, 2002, 7 INT C SPOK LANG PR, V0, P2041
   Maliszewski M, 2018, RAPORT POLSKIE CHATB, V0, P0
   Mateju L, 2018, INTERSPEECH, V0, PP1803, DOI 10.21437/Interspeech.2018-1165
   Mei H, 2015, ABS150900838 CORR, V0, P0
   Migdalski K, 2018, HANDB SPRACH KOMMUN, V41, P1557, DOI 10.1515/9783110542431-004
   Ministry of Health of the Czech Republic, 2020, CZECH MIN HLTH LAUNC, V0, P0
   Mnasri M, 2019, CHATBOTS APPROACHES, V0, P0
   Mrksic N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1777, DOI 10.18653/v1/P17-1163
   Neagu C, 2020, 2 WAYS CHANGE LANGUA, V0, P0
   Nedeljkovic Z, 2020, ARCH ACOUST, V45, P129, DOI 10.24425/aoa.2020.132489
   Nouza J, 2010, LECT NOTES COMPUT SC, V5967, P225
   Nugmanova A, 2019, INT CONF PERVAS COMP, V0, PP844, DOI 10.1109/PERCOMW.2019.8730665
   Oklesinski D, 2019, IMPLEMENTATION CURRE, V0, P0
   Olabiyi O, 2018, ABS180511752 CORR, V0, P0
   Olbert MB, 2019, GOOGLE COMMUNISM ARE, V0, P0
   Papernot N, 2016, ABS161005755 CORR, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paul A, 2019, J INFORM TELECOMMUN, V3, P248, DOI 10.1080/24751839.2018.1558378
   Pearson JC, 1989, INTRO HUMAN COMMUNIC, V0, P0
   Qian Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4279
   Qiu MH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P498, DOI 10.18653/v1/P17-2079
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Rai Siddhant, 2018, 2018 SECOND INTERNATIONAL CONFERENCE ON ELECTRONICS, V0, P1367, DOI 10.1109/ICECA.2018.8474861
   Ranoliya BR, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P1525, DOI 10.1109/ICACCI.2017.8126057
   Rao S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2737
   Rejestr TERYT, 2018, GLOWNY URZD STATYSTY, V0, P0
   Rogalski M, 2016, LECT NOTES ARTIF INT, V9692, P126, DOI 10.1007/978-3-319-39378-0_12
   Rudnicky Alexander, 2016, P 17 ANN M SPEC INT, V0, P404
   Rychalska B, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, V0, P256, DOI 10.1109/SNAMS.2018.8554770
   Safarik R, 2015, P IEEE WORKSH ECMSM, V0, P1
   Schwartz EH, 2019, MEET ONLY VOICE ASSI, V0, P0
   Schwartz EH, 2020, APPLE IS HIRING SIRI, V0, P0
   See A, 2019, ABS190208654 CORR, V0, P0
   Serban IV, 2017, ABS170902349 CORR, V0, P0
   Serban IV, 2015, ABS150704808 CORR, V0, P0
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Serban IV, 2018, DIALOGUE DISCOURSE, V9, P0
   Shaheen Z, 2020, ABS200502470 CORR, V0, P0
   Shaikh A, 2019, INT RES J ENG TECHNO, V6, P1786
   Shang L, 2016, P 12 NTCIR C EV INF, V0, P0
   Shang LF, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1577
   Sharad S, 2017, UNPACKING NOVELTY AN, V0, PP1, DOI 10.2139/SSRN.2388254
   Shaw D, 1996, WELCOME WALRUS, V0, P0
   Siewierska Anna, 2010, CONSTITUENT ORDER LA, V0, P105
   Simeonova L, 2019, ABS190810261 CORR, V0, P0
   Sojasingarayar A, 2020, ABS200602767 CORR, V0, P0
   Song Y, 2016, ABS161007149 CORR, V0, P0
   Stachowicz-Stanusch A, 2018, ORGANIZACJA ZARZDZAN, V2, P63
   Staroniewicz P, 2009, LECT NOTES COMPUT SC, V5641, P42, DOI 10.1007/978-3-642-03320-9_5
   Stent A, 2005, LECT NOTES COMPUT SC, V3406, P341
   Su S, 2018, ABS180809442 CORR, V0, P0
   Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968
   Sun Yu, 2019, ARXIV190409223, V0, P0
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tarasov DS, 2017, P INT C DIAL 2017 CO, V0, P0
   Templeton G, 2020, LANGUAGE SUPPORT VOI, V0, P0
   The Columbia Electronic Encyclopedia, 2012, THE SLAVIC LANGUAGES, V0, P0
   Tian ZL, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P231, DOI 10.18653/v1/P17-2036
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Tur G, 2011, SPOKEN LANGUAGE UNDE, V0, P0
   Vanjani M, 2019, J MANAG SCI BUS INTE, V4, P19
   Vasic D, 2018, 2018 26TH INTERNATIONAL CONFERENCE ON SOFTWARE, V0, P327
   Vaswani A, 2017, ARXIV, V30, P5998
   Vatian A, 2019, LECT NOTES COMPUT SC, V11871, P175, DOI 10.1007/978-3-030-33607-3_20
   Venkatesh A, 2019, GOOGLE ASSISTANTS IN, V0, P0
   Vinyals O, 2015, COMPUTER SCI, V0, P0, DOI DOI 10.48550/ARXIV.1506.03134
   Walker MA, 1997, CMPLG9704004 CORR, V0, P0
   Wallace R, 2003, ELEMENTS AIML STYLE, V0, P0, DOI DOI 10.1.1.693.3664.
   Wang Hao, 2013, P 2013 C EMPIRICAL M, V0, P935
   Wang M, 2015, ABS150302427 CORR, V0, P0
   Wang WJ, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP255, DOI 10.1145/3209978.3210061
   Ward NG, 2016, AI MAG, V37, P7
   Watanabe S, 2014, 15 ANN C INT SPEECH, V0, P0
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wen T, 2015, ABS150801745 CORR, V0, P0
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   Werner R, 2020, THESIS DEP APPL MATH, V0, P0
   Wielka OS, 2020, POMOCY CHATBOT LOG S, V0, P0
   Williams JD, 2016, ARXIV160601269, V0, P0
   Wolk A, 2021, MULTILINGUAL CHATBOT, V0, P0
   Wu Y, 2018, NEUROCOMPUTING, V316, P251, DOI 10.1016/j.neucom.2018.07.073
   Wu YX, 2019, AAAI CONF ARTIF INTE, V0, P7289
   Xing C, 2017, AAAI CONF ARTIF INTE, V0, P3351
   Xu Z, 2017, P 2017 C EMPIRICAL M, V0, PP617, DOI 10.18653/V1/D17-1065
   Yan R, 2016, SIGIR16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP55, DOI 10.1145/2911451.2911542
   Yan Z, 2017, AAAI CONF ARTIF INTE, V0, P4618
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
   Yue G, 2020, DOUBLE NEGATION CONS, V0, P0
   Zhang H, 2019, ABS190705339 CORR, V0, P0
   Zhang WN, 2019, WORLD WIDE WEB, V22, P1427, DOI 10.1007/s11280-018-0598-6
   Zhang Z, 2019, ABS190600499 CORR, V0, P0
   Zhang Z, 2020, SCI CHINA TECHNOL SC, V63, P2011, DOI 10.1007/s11431-020-1692-3
   Zhao T, 2017, ABS170608476 CORR, V0, P0
   Zhao T, 2016, ABS160602560 CORR, V0, P0
   Zheng Yinhe, 2019, ARXIV190109672, V0, P0
   Zhou H, 2017, ABS170401074 CORR, V0, P0
   Zhou H, 1900, P4623, V0, P0
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI 10.1162/COLI_a_00368
NR 207
TC 4
Z9 4
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAR 7
PY 2022
VL 477
IS 
BP 62
EP 84
DI 10.1016/j.neucom.2021.11.076
EA JAN 2022
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA ZI5VK
UT WOS:000761688500007
DA 2023-11-10
ER

PT J
AU Yang, DQ
   Yin, YQ
AF Yang, Dongqiang
   Yin, Yanqin
TI Evaluation of taxonomic and neural embedding methods for calculating semantic similarity
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Semantic Similarity; Lexical Semantics; Distributional Semantics; Neural Embeddings
ID information-content; relatedness; construction; activation; wordnet; models
AB Modelling semantic similarity plays a fundamental role in lexical semantic applications. A natural way of calculating semantic similarity is to access handcrafted semantic networks, but similarity prediction can also be anticipated in a distributional vector space. Similarity calculation continues to be a challenging task, even with the latest breakthroughs in deep neural language models. We first examined popular methodologies in measuring taxonomic similarity, including edge-counting that solely employs semantic relations in a taxonomy, as well as the complex methods that estimate concept specificity. We further extrapolated three weighting factors in modelling taxonomic similarity. To study the distinct mechanisms between taxonomic and distributional similarity measures, we ran head-to-head comparisons of each measure with human similarity judgements from the perspectives of word frequency, polysemy degree and similarity intensity. Our findings suggest that without fine-tuning the uniform distance, taxonomic similarity measures can depend on the shortest path length as a prime factor to predict semantic similarity; in contrast to distributional semantics, edge-counting is free from sense distribution bias in use and can measure word similarity both literally and metaphorically; the synergy of retrofitting neural embeddings with concept relations in similarity prediction may indicate a new trend to leverage knowledge bases on transfer learning. It appears that a large gap still exists on computing semantic similarity among different ranges of word frequency, polysemous degree and similarity intensity.
C1 [Yang, Dongqiang; Yin, Yanqin] Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan, Peoples R China.
C3 Shandong Jianzhu University
RP Yang, DQ (通讯作者)，Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM ydq@sdjzu.edu.cn
FU National Social Science Foundation (China) [17BYY119]
CR Agirre E, 2009, HUMAN LANGUAGE TECHN, V0, P0
   Agirre E, 1994, WORKSH COMP LING SPE, V0, P0
   [Anonymous], 2012, 26 AAAI C ART INT TO, V0, P0
   [Anonymous], 2000, P 2 INT C LANGUAGE R, V0, P0
   [Anonymous], 2006, 3 INT WORDNET C GWC, V0, P0
   [Anonymous], 2016, P 1 WORKSHOP REPRESE, V0, P0
   [Anonymous], 2015, T ASSOC COMPUT LING, V0, P0, DOI DOI 10.1162/TACL_A_00134
   Baker CF, 1998, 36 ANN M ASS COMPUTA, V0, PP86, DOI 10.3115/980845.980860
   Banjade R, 2015, LECT NOTES COMPUT SC, V9041, P335, DOI 10.1007/978-3-319-18111-0_25
   Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bommasani Rishi, 2020, P 58 ANN M ASS COMP, V0, PP4758, DOI 10.18653/V1/2020.ACL-MAIN.431
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407
   COLLINS AM, 1969, J VERB LEARN VERB BE, V8, P240, DOI 10.1016/S0022-5371(69)80069-1
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Curran JR, 2003, DISTRIBUTIONAL SEMAN, V0, P0
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dinu, 2012, THESIS SAARLAN U, V0, P0
   Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P55
   Faruqui Manaal, 2015, P 2015 C N AM CHAPT, V0, PP1606, DOI 10.3115/v1/N15-1184
   Fellbaum C, 1998, LANG SPEECH & COMMUN, V0, P1
   Feng Y, 2017, KNOWL ENG REV, V32, P0, DOI 10.1017/S0269888917000029
   Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110
   Firth JR, 1957, SYNOPSIS LINGUISTIC, V0, P0
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1606
   Ganitkevitch Juri, 2013, P 2013 C N AM CHAPTE, V0, P758
   Gerz Daniela, 2016, P OF THE 2016 C ON E, V0, P2173
   Goldberg Yoav, 2019, ABS190105287 ARXIV, V0, P0
   GOLDSTONE RL, 1994, J EXP PSYCHOL LEARN, V20, P3, DOI 10.1037/0278-7393.20.1.3
   Guzzi PH, 2012, BRIEF BIOINFORM, V13, P569, DOI 10.1093/bib/bbr066
   Harispe S, 2015, SEMANTIC SIMILARITY, V0, P0, DOI DOI 10.2200/S00639ED1V01Y201504HLT027
   Harris Z, 1985, PHILOS LINGUISTICS, V0, P26
   Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237
   Hirst G, 1997, WORDNET ELECT LEXICA, V0, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang EH, 2012, P 50 ANN M ASS COMPU, V0, P873
   Jarmasz M, 2003, P RANLP 2003, V0, P212
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, V0, P94
   Kilgarriff A, 2004, LECT NOTES COMPUT SC, V3206, P103
   Kilgarriff A, 1997, COMPUT HUMANITIES, V31, P91, DOI 10.1023/A:1000583911091
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lastra-Díaz JJ, 2015, ENG APPL ARTIF INTEL, V46, P140, DOI 10.1016/j.engappai.2015.09.006
   Le M, 2015, INT C REC ADV NLP 20, V0, P346
   Leacock C, 1998, LANG SPEECH & COMMUN, V0, P265
   Leacock C, 1994, FILLING SPARSE TRAIN, V0, P0
   Levy O, 2014, ADV NEUR IN, V27, P0
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Lin DK, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P64
   Lipton ZC, 2018, QUEUE, V17, P1
   Luong T, 2013, P 17 C COMP NAT LANG, V0, PP104, DOI 10.1007/BF02579642
   McCann Bryan, 2017, ADV NEURAL INFORM PR, V0, P6297
   McCarthy D, 2004, RANKING WORDNET SENS, V0, P0
   McCarthy D, 2004, 42 ANN M ASS COMP LI, V0, P267
   McHale M, 1998, P COLING ACL WORKSH, V0, P115
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Miller G, 1990, INT J LEXICOGR, V3, P235, DOI 10.1093/IJL/3.4.235
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Mohammad SM, 2012, ABS12031889 ARXIV, V0, P0
   Morris J, 1991, COMPUTATIONAL LINGUISTICS, V17, P21
   Mrksic Nikola, 2017, T ASS COMPUTATIONAL, V5, P309
   Mrksic Nikola, 2016, NAACL HLT, V0, PP142, DOI 10.18653/V1/N16-1018
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Padó S, 2007, COMPUT LINGUIST, V33, P161, DOI 10.1162/coli.2007.33.2.161
   Panchenko, 2013, SIMILARITY MEASURES, V0, P0
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, V0, P1024
   Pedersen T, 2005, 200525 UMSI, V0, P0
   Pedersen T, 2007, J BIOMED INFORM, V40, P288, DOI 10.1016/j.jbi.2006.06.004
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pilehvar MT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1391
   Ponti EM, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P282
   Quillian MRoss, 1968, SEMANTIC INFORM PROC, V0, P227
   QUILLIAN MR, 1967, BEHAV SCI, V12, P410, DOI 10.1002/bs.3830120511
   RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Raunak V, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), V0, P235
   Resnik P, 1995, INT JOINT CONF ARTIF, V0, P448
   Resnik P, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, V0, P399
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahlgren M, 2006, WORD SPACE MODEL USI, V0, P0
   Sánchez D, 2011, KNOWL-BASED SYST, V24, P297, DOI 10.1016/j.knosys.2010.10.001
   Seco N, 2004, FRONT ARTIF INTEL AP, V110, P1089
   Shi WJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1198
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3679
   Speer Robert, 2016, ARXIV160401692, V0, P0
   Strube M, 2006, 21 NAT C ART INT BOS, V0, P1219
   Sussna M, 1993, CIKM 93. PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP67, DOI 10.1145/170088.170106
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Tenney Ian, 2019, INT C LEARN REPR, V0, P0
   TORGERSON WS, 1965, PSYCHOMETRIKA, V30, P379, DOI 10.1007/BF02289530
   Turney P, 2001, P 12 EUR C MACH LEAR, V0, PP491, DOI 10.1007/3-540-44795-4_42
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang T, 2011, P C EMP METH NAT LAN, V0, P1003
   Weeds, 2003, THEISS U SUSSEX, V0, P0
   Wieting J, 2015, T ASS COMPUTATIONAL, V3, P345, DOI 10.1162/TACL_A_00143
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P133
   Yang D, 2005, P 28 AUSTR C COMP SC, V0, P315
   Yang DQ, 2010, J RES PRACT INF TECH, V42, P129
   Yin Z, 2018, ADV NEUR IN, V31, P0
   Yosinski J, 2014, ADV NEUR IN, V27, P0
   Yu M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P545, DOI 10.3115/v1/p14-2089
   Zesch T, 2010, NAT LANG ENG, V16, P25, DOI 10.1017/S1351324909990167
   Zhang ZQ, 2013, NAT LANG ENG, V19, P411, DOI 10.1017/S1351324912000125
   Zipf George Kingsley, 1965, HUMAN BEHAV PRINCIPL, V0, P0
NR 116
TC 0
Z9 0
U1 4
U2 18
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD NOV 15
PY 2022
VL 28
IS 6
BP 733
EP 761
DI 10.1017/S1351324921000279
EA SEP 2021
PG 29
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 6N9YF
UT WOS:000776678400001
DA 2023-11-10
ER

PT J
AU Ma, PC
   Petridis, S
   Pantic, M
AF Ma, Pingchuan
   Petridis, Stavros
   Pantic, Maja
TI Visual speech recognition for multiple languages in the wild
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID automatic recognition; lips
AB Visual speech recognition (VSR) aims to recognize the content of speech based on lip movements, without relying on the audio stream. Advances in deep learning and the availability of large audio-visual datasets have led to the development of much more accurate and robust VSR models than ever before. However, these advances are usually due to the larger training sets rather than the model design. Here we demonstrate that designing better models is equally as important as using larger training sets. We propose the addition of prediction-based auxiliary tasks to a VSR model, and highlight the importance of hyperparameter optimization and appropriate data augmentations. We show that such a model works for different languages and outperforms all previous methods trained on publicly available datasets by a large margin. It even outperforms models that were trained on non-publicly available datasets containing up to to 21 times more data. We show, furthermore, that using additional training data, even in other languages or with automatically generated transcriptions, results in further improvement. Recognition of speech from lip movements is still a challenging problem and much effort is concentrated on the English language. Ma et al. have used auxiliary tasks to train a model such that it works for a range of different languages, including Mandarin, Spanish, Italian, French and Portuguese.
C1 [Ma, Pingchuan; Petridis, Stavros; Pantic, Maja] Imperial Coll London, London, England.
   [Petridis, Stavros; Pantic, Maja] Meta AI, London, England.
C3 Imperial College London
RP Ma, PC (通讯作者)，Imperial Coll London, London, England.
EM pingchuan.ma16@imperial.ac.uk
CR Afouras T, 2018, PREPRINT, V0, P0
   Afouras T, 2020, INT CONF ACOUST SPEE, V0, PP2143, DOI 10.1109/ICASSP40776.2020.9054253
   Afouras T, 2018, INTERSPEECH, V0, P3244
   Afouras T, 2022, IEEE T PATTERN ANAL, V44, P8717, DOI 10.1109/TPAMI.2018.2889052
   [Anonymous], 2018, NEW YORK TIMES 1022, V0, P0
   [Anonymous], 2021, FACEBOOK, V0, P0
   Assael Y, 2016, PREPRINT, V0, P0
   Bear HL, 2014, IEEE IMAGE PROC, V0, PP1371, DOI 10.1109/ICIP.2014.7025274
   Bicevskis Katie, 2016, CAN ACOUST, V44, P17
   Bulat A, 2017, IEEE I CONF COMP VIS, V0, PP1021, DOI 10.1109/ICCV.2017.116
   Cheng SY, 2020, INT CONF ACOUST SPEE, V0, PP4357, DOI 10.1109/icassp40776.2020.9054384
   Chung JS, 2020, INTERSPEECH, V0, PP299, DOI 10.21437/Interspeech.2020-2337
   Chung JS, 2017, PROC CVPR IEEE, V0, PP3444, DOI 10.1109/CVPR.2017.367
   Crawford S, 2019, WIRED 1216, V0, P0
   Denby B, 2010, SPEECH COMMUN, V52, P270, DOI 10.1016/j.specom.2009.08.002
   Deng JK, 2020, PROC CVPR IEEE, V0, PP5202, DOI 10.1109/CVPR42600.2020.00525
   Dungan L, 2018, IEEE IMAGE PROC, V0, PP2560, DOI 10.1109/ICIP.2018.8451754
   Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479
   Ephrat A, 2018, ACM T GRAPHIC, V37, P0, DOI 10.1145/3197517.3201357
   Feathers, 2021, TECH CO ARE TRAINING, V0, P0
   Flynn S, 2020, INNOVATION TECH 1118, V0, P0
   Geirhos R, 2019, PROC 7 INT C LEARNIN, V0, P0
   Greene J, 2020, WASHINGTON POST 0611, V0, P0
   Gulati A, 2020, INTERSPEECH, V0, PP5036, DOI 10.21437/Interspeech.2020-3015
   Haliassos A, 2021, PROC CVPR IEEE, V0, PP5037, DOI 10.1109/CVPR46437.2021.00500
   Heracleous P, 2013, COMPUT SPEECH LANG, V27, P288, DOI 10.1016/j.csl.2012.06.003
   Kim YJ, 2021, INTERSPEECH, V0, PP3675, DOI 10.21437/Interspeech.2021-2041
   Kingma DP, 2014, C TRACK P, V0, P0
   Lee J, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6224, DOI 10.1109/ICASSP39728.2021.9414594
   Liu CX, 2021, IEEE W SP LANG TECH, V0, PP172, DOI 10.1109/SLT48900.2021.9383548
   Ma P, 2022, MPC001 VISUAL SPEECH, V0, P0, DOI DOI 10.5281/zenodo.7065080
   Ma PC, 2021, INTERSPEECH, V0, PP3011, DOI 10.21437/Interspeech.2021-1360
   Ma PC, 2019, INTERSPEECH, V0, PP4090, DOI 10.21437/Interspeech.2019-2726
   Ma PC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7608, DOI 10.1109/ICASSP39728.2021.9415063
   Ma PC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7613, DOI 10.1109/ICASSP39728.2021.9414567
   Makino T, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP905, DOI 10.1109/asru46091.2019.9004036
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Metz R, 2021, CNN 0518, V0, P0
   Mira R, 2023, IEEE T CYBERNETICS, V53, P3454, DOI 10.1109/TCYB.2022.3162495
   Park DS, 2019, INTERSPEECH, V0, PP2613, DOI 10.21437/Interspeech.2019-2680
   Pascual S, 2019, INTERSPEECH, V0, PP161, DOI 10.21437/Interspeech.2019-2605
   Petridis S, 2017, PROC 28 BRIT MACHINE, V0, P0, DOI DOI 10.5244/C.31.161
   Petridis S, 2018, IEEE W SP LANG TECH, V0, PP513, DOI 10.1109/SLT.2018.8639643
   Petridis S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P6219, DOI 10.1109/ICASSP.2018.8461596
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Prajwal KR, 2020, P IEEE CVF C COMP VI, V0, P13796
   Ren SC, 2021, PROC CVPR IEEE, V0, PP13320, DOI 10.1109/CVPR46437.2021.01312
   Salesky E, 2021, INTERSPEECH, V0, PP3655, DOI 10.21437/Interspeech.2021-11
   Serdyuk D, 2022, INTERSPEECH, V0, PP2833, DOI 10.21437/Interspeech.2022-10920
   Serdyuk D, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), V0, PP796, DOI 10.1109/ASRU51503.2021.9688191
   Shihui Ma, 2020, 2020 IEEE FIFTH INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC). PROCEEDINGS, V0, PP78, DOI 10.1109/DSC50466.2020.00020
   Shillingford B, 2019, INTERSPEECH, V0, PP4135, DOI 10.21437/Interspeech.2019-1669
   Shukla A, 2020, PROC WORKSHOP SELF S, V0, P0
   Simko J, 2016, J ACOUST SOC AM, V139, P151, DOI 10.1121/1.4939495
   Simonyan K, 2015, ARXIV, V0, P0
   Sterpu G, 2020, IEEE-ACM T AUDIO SPE, V28, P1052, DOI 10.1109/TASLP.2020.2980436
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Toshniwal S, 2017, INTERSPEECH, V0, PP3532, DOI 10.21437/Interspeech.2017-1118
   Valk J, 2021, IEEE W SP LANG TECH, V0, PP652, DOI 10.1109/SLT48900.2021.9383459
   Wand M, 2017, INTERSPEECH, V0, PP3662, DOI 10.21437/Interspeech.2017-421
   Watanabe S, 2018, INTERSPEECH, V0, PP2207, DOI 10.21437/Interspeech.2018-1456
   Yoshimura T, 2020, INT CONF ACOUST SPEE, V0, PP6999, DOI 10.1109/ICASSP40776.2020.9054358
   Yu JW, 2020, INT CONF ACOUST SPEE, V0, PP6984, DOI 10.1109/ICASSP40776.2020.9054127
   Yu WT, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P3430, DOI 10.1109/ICASSP39728.2021.9414553
   Zadeh A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, PP1801, DOI 10.18653/v1/2020.emnlp-main.141
   Zhang XB, 2019, AAAI CONF ARTIF INTE, V0, P9211
   Zhao Y, 2020, AAAI CONF ARTIF INTE, V34, P6917
   Zhao Ya, 2019, P ACM MULTIMEDIA ASI, V0, P0
NR 69
TC 6
Z9 7
U1 4
U2 9
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD NOV 15
PY 2022
VL 4
IS 11
BP 930
EP 939
DI 10.1038/s42256-022-00550-z
EA OCT 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 6H3DZ
UT WOS:000871286200001
DA 2023-11-10
ER

PT J
AU Nguyen, HT
   Phi, MK
   Ngo, XB
   Tran, V
   Nguyen, LM
   Tu, MP
AF Nguyen, Ha-Thanh
   Phi, Manh-Kien
   Ngo, Xuan-Bach
   Tran, Vu
   Nguyen, Le-Minh
   Tu, Minh-Phuong
TI Attentive deep neural networks for legal document retrieval
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article; Early Access
DE Legal text retrieval; Deep neural networks; Hierarchical representation; Global attention
AB Legal text retrieval serves as a key component in a wide range of legal text processing tasks such as legal question answering, legal case entailment, and statute law retrieval. The performance of legal text retrieval depends, to a large extent, on the representation of text, both query and legal documents. Based on good representations, a legal text retrieval model can effectively match the query to its relevant documents. Because legal documents often contain long articles and only some parts are relevant to queries, it is quite a challenge for existing models to represent such documents. In this paper, we study the use of attentive neural network-based text representation for statute law document retrieval. We propose a general approach using deep neural networks with attention mechanisms. Based on it, we develop two hierarchical architectures with sparse attention to represent long sentences and articles, and we name them Attentive CNN and Paraformer. The methods are evaluated on datasets of different sizes and characteristics in English, Japanese, and Vietnamese. Experimental results show that: (i) Attentive neural methods substantially outperform non-neural methods in terms of retrieval performance across datasets and languages; (ii) Pretrained transformer-based models achieve better accuracy on small datasets at the cost of high computational complexity while lighter weight Attentive CNN achieves better accuracy on large datasets; and (iii) Our proposed Paraformer outperforms state-of-the-art methods on COLIEE dataset, achieving the highest recall and F2 scores in the top-N retrieval task.
C1 [Nguyen, Ha-Thanh; Tran, Vu; Nguyen, Le-Minh] Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa, Japan.
   [Phi, Manh-Kien; Ngo, Xuan-Bach; Tu, Minh-Phuong] Posts & Telecommun Inst Technol, Dept Comp Sci, Hanoi, Vietnam.
C3 Japan Advanced Institute of Science & Technology (JAIST)
RP Nguyen, HT (通讯作者)，Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa, Japan.
EM nguyenhathanh@jaist.ac.jp; kienpm2205@gmail.com; bachnx@ptit.edu.vn; vu.tran@jaist.ac.jp; nguyenml@jaist.ac.jp; phuongtm@ptit.edu.vn
FU JSPS Kakenhi [20K20406]; Asian Office of Aerospace R &D(AOARD), AirForce Office of Scientific Research [FA2386-19-1-4041]
CR Brown TB, 2020, ARXIV, V0, P0
   Chalkidis I, 2019, ARTIF INTELL LAW, V27, P171, DOI 10.1007/s10506-018-9238-9
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Conneau A, 2020, ARXIV, V0, P0
   COOPER WS, 1971, INFORM STORAGE RET, V7, P19, DOI 10.1016/0020-0271(71)90024-6
   Devlin J, 1900, P4171, V0, P0, DOI DOI 10.18653/v1/N19-1423
   Frank S, 2021, COLIEE WORKSHOP ICAI, V0, P78
   Nguyen HT, 2017, INT CONF KNOWL SYS, V0, PP30, DOI 10.1109/KSE.2017.8119430
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, P2333
   Husa VJM, 2016, OXFORD HDB ONLINE SC, V0, P0
   Ito S, 2008, LECT SERIES ULTIMATE, V0, P0
   Kien PM, 2020, P 28 INT C COMP LING, V0, P988
   Kim MY, 2022, REV SOCIONETWORK STR, V16, P157, DOI 10.1007/s12626-022-00103-1
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Kowalski R, 2022, ARTIF INTELL LAW, V30, P163, DOI 10.1007/s10506-021-09295-3
   Lewis M, 2019, ARXIV, V0, P0
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   Martins AFT, 2016, PR MACH LEARN RES, V48, P0
   Masaharu Y, 2021, COLIEE WORKSHOP ICAI, V0, P78
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P52
   Mikolov T, 2011, INT CONF ACOUST SPEE, V0, P5528
   Mueller J, 2016, AAAI CONF ARTIF INTE, V0, P2786
   Bach NX, 2019, SOICT 2019: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY, V0, PP486, DOI 10.1145/3368926.3369731
   Bach NX, 2019, LECT NOTES ARTIF INT, V11672, P206, DOI 10.1007/978-3-030-29894-4_16
   Nguyen Ha Thanh, 2021, 2021 13TH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), V0, PP1, DOI 10.1109/KSE53942.2021.9648724
   Nguyen H, 2021, ARXIV, V0, P0
   Nguyen H, 2020, ARXIV, V0, P0
   Nguyen H, 2021, ARXIV, V0, P0
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Rabelo J, 2020, LECT NOTES ARTIF INT, V12331, P34, DOI 10.1007/978-3-030-58790-1_3
   Radford A, 2018, U BRIT COLUMBIA REPO, V0, P0
   Reimers N, 2019, ARXIV, V0, P0
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Satoh Ken, 2010, JSAI INT S ART INT, V0, P153
   Savelka J, 2022, ARTIF INTELL LAW, V30, P245, DOI 10.1007/s10506-021-09293-5
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP373, DOI 10.1145/2766462.2767738
   Shao YQ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3501
   Shen Yelong, 2014, P 23 ACM INT C C INF, V0, P0, DOI DOI 10.1145/2661829.2661935
   Sugathadasa K, 2019, ADV INTELL SYST COMP, V857, P160, DOI 10.1007/978-3-030-01177-2_12
   Tang D, 2015, EMNLP, V0, P0, DOI DOI 10.18653/v1/D15-1167
   Tran V, 2020, ARTIF INTELL LAW, V28, P441, DOI 10.1007/s10506-020-09262-4
   Nguyen TS, 2018, ARTIF INTELL LAW, V26, P169, DOI 10.1007/s10506-018-9225-1
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Yequan, 2016, P 2016 C EMP METH NA, V0, PP606, DOI 10.18653/V1/D16-1058
   Wehnert Sabine, 2021, ICAIL 21: PROCEEDINGS OF THE EIGHTEENTH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, V0, PP285, DOI 10.1145/3462757.3466104
   Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P19
   Yoshioka Masaharu, 2021, ICAIL 21: PROCEEDINGS OF THE EIGHTEENTH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, V0, PP278, DOI 10.1145/3462757.3466105
   Yoshioka M, 2018, 12 INT WORKSHOP JURI, V0, P0
NR 51
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1007/s10506-022-09341-8
EA DEC 2022
PG 30
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law
SC Computer Science; Government & Law
GA 7K0ZS
UT WOS:000905015800002
DA 2023-11-10
ER

PT J
AU Wang, Q
   Huang, W
   Zhang, XT
   Li, XL
AF Wang, Qi
   Huang, Wei
   Zhang, Xueting
   Li, Xuelong
TI GLCM: Global-Local Captioning Model for Remote Sensing Image Captioning
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article; Early Access
DE Feature extraction; Visualization; Remote sensing; Decoding; Sensors; Natural language processing; Convolutional neural networks; Deep learning; global-local captioning model (GLCM); image captioning; remote sensing
ID attention
AB Remote sensing image captioning (RSIC), which describes a remote sensing image with a semantically related sentence, has been a cross-modal challenge between computer vision and natural language processing. For visual features extracted from remote sensing images, global features provide the complete and comprehensive visual relevance of all the words of a sentence simultaneously, while local features can emphasize the discrimination of these words individually. Therefore, not only global features are important for caption generation but also local features are meaningful for making the words more discriminative. In order to make full use of the advantages of both global and local features, in this article, we propose an attention-based global-local captioning model (GLCM) to obtain global-local visual feature representation for RSIC. Based on the proposed GLCM, the correlation of all the generated words and the relation of each separate word and the most related local visual features can be visualized in a similarity-based manner, which provides more interpretability for RSIC. In the extensive experiments, our method achieves comparable results in UCM-captions and superior results in Sydney-captions and RSICD which is the largest RSIC dataset.
C1 [Wang, Qi; Huang, Wei; Zhang, Xueting; Li, Xuelong] Northwestern Polytech Univ, Sch Artificial Intelligence, Opt & Elect, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Li, XL (通讯作者)，Northwestern Polytech Univ, Sch Artificial Intelligence, Opt & Elect, Xian 710072, Peoples R China.
EM crabwq@gmail.com; hw2hwei@gmail.com; zxt@mail.nwpu.edu.cn; li@nwpu.edu.cn
FU National Natural Science Foundation of China [U21B2041, U1864204]; National Natural Science Foundation of China [U21B2041, U1864204]
CR Ba JMY, 2015, ARXIV, V0, P0
   Banerjee Satanjeev, 2005, PROC ASS COMPUT LING, V0, PP65, DOI 10.3115/1626355.1626389
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Chen L, 2017, IEEE INT CONF COMP V, V0, PP328, DOI 10.1109/ICCVW.2017.47
   Chen L, 2017, PROC CVPR IEEE, V0, PP6298, DOI 10.1109/CVPR.2017.667
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cho KYHY, 2014, ARXIV, V0, P0
   Cornia M, 2019, PROC CVPR IEEE, V0, PP8299, DOI 10.1109/CVPR.2019.00850
   Cui YM, 2017, ARXIV, V0, P0
   Gehring J, 2017, PR MACH LEARN RES, V70, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hoxha G, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3105004
   Hu J, 2018, P IEEE C COMP VIS PA, V0, P7132
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Huang W, 2019, INT GEOSCI REMOTE SE, V0, PP3017, DOI 10.1109/igarss.2019.8898875
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jiang WH, 2018, AAAI CONF ARTIF INTE, V0, P6959
   Johnson J, 2016, PROC CVPR IEEE, V0, PP4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Li LH, 2017, AAAI CONF ARTIF INTE, V0, P4133
   Li P, 2020, IEEE T GEOSCI REMOTE, V58, P7331, DOI 10.1109/TGRS.2020.2981997
   Li XL, 2021, IEEE T GEOSCI REMOTE, V59, P5246, DOI 10.1109/TGRS.2020.3010106
   Li XL, 2021, IEEE T CYBERNETICS, V51, P913, DOI 10.1109/TCYB.2019.2914351
   Li XL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030258
   Li YS, 2021, IEEE T CYBERNETICS, V51, P1756, DOI 10.1109/TCYB.2020.2989241
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin M, 2014, ARXIV, V0, P0
   Lin ZH, 2017, ARXIV, V0, P0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JS, 2016, ADV NEUR IN, V29, P0
   Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P1985, DOI 10.1109/TGRS.2019.2951636
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Luong MT, 2015, ARXIV, V0, P0
   Mao JH, 2015, ARXIV, V0, P0
   Mikolov T, 2013, ARXIV, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Perronnin F, 2010, PROC CVPR IEEE, V0, PP3384, DOI 10.1109/CVPR.2010.5540009
   Qu B, 2016, INT CONF COMP INFO, V0, P124
   Shi ZW, 2017, IEEE T GEOSCI REMOTE, V55, P3623, DOI 10.1109/TGRS.2017.2677464
   Simonyan K, 2015, ARXIV, V0, P0
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Szegedy C, 2015, P IEEE C COMPUTER VI, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Vaswani Ashish, 2017, NEURUIPS, V0, P0
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wang BQ, 2020, IEEE J-STARS, V13, P256, DOI 10.1109/JSTARS.2019.2959208
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P10532, DOI 10.1109/TGRS.2020.3044054
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu FX, 2022, IEEE T CYBERNETICS, V52, P568, DOI 10.1109/TCYB.2020.2979258
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y, 2010, P 18 SIGSPATIAL INT, V0, P270
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yao T, 2017, IEEE I CONF COMP VIS, V0, PP4904, DOI 10.1109/ICCV.2017.524
   You QZ, 2016, PROC CVPR IEEE, V0, PP4651, DOI 10.1109/CVPR.2016.503
   Yuan ZH, 2020, IEEE ACCESS, V8, P2608, DOI 10.1109/ACCESS.2019.2962195
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang TY, 2022, IEEE T CYBERNETICS, V52, P10999, DOI 10.1109/TCYB.2021.3096185
   Zhang W, 2020, AAAI CONF ARTIF INTE, V34, P9571
   Zhang XR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060612
   Zhang XT, 2019, INT GEOSCI REMOTE SE, V0, PP10039, DOI 10.1109/IGARSS.2019.8900503
   Zhang YL, 2019, IEEE T GEOSCI REMOTE, V57, P5535, DOI 10.1109/TGRS.2019.2900302
   Zhang ZY, 2019, IEEE ACCESS, V7, P137355, DOI 10.1109/ACCESS.2019.2942154
   Zhou LW, 2018, PROC CVPR IEEE, V0, PP8739, DOI 10.1109/CVPR.2018.00911
   Zhou XF, 2023, IEEE T CYBERNETICS, V53, P539, DOI 10.1109/TCYB.2022.3163152
NR 70
TC 2
Z9 2
U1 6
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1109/TCYB.2022.3222606
EA NOV 2022
PG 13
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Automation & Control Systems; Computer Science
GA 7V4LL
UT WOS:000912787000001
PM 36446004
DA 2023-11-10
ER

PT J
AU Smetanin, S
AF Smetanin, Sergey
TI How weather impacts expressed sentiment in Russia: evidence from Odnoklassniki
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Natural language processing; Weather; Sentiment; Russia
ID mood; suicide
AB Prior research suggests that weather conditions may substantively impact people's emotional state and mood. In Russia, the relationship between weather and mood has been studied for certain regions-usually with severe or extreme climatic and weather conditions-but with quite limited samples of up to 1,000 people. Over the past decade, partly due to the proliferation of online social networks and the development of natural language processing techniques, the relationship between weather and mood has become possible to study based on the sentiment expressed by individuals. One of the key advantages of such studies based on digital traces is that it is possible to analyze much larger samples of people in comparison with traditional survey-based studies. In this article, we investigate the relationship between historical weather conditions and sentiment expressed in seven Russian cities based on the data of one of the largest Russian social networks, Odnoklassniki. We constructed a daily city-level expressed positive sentiment metric based on 2.76 million posts published by 1.31 million unique users from Odnoklassniki and studied its dynamics relative to daily weather conditions via regression modelling. It was found that a maximum daily temperature between +20 degrees C and +25 degrees C, light breeze (between 5 and 11 km/h) and an increase in the average daily temperature by 20-25 degrees C compared to the previous day are all associated with higher numbers of expressions of positive sentiment, whereas the difference between the maximum and minimum daily temperatures of 15-20 degrees C is associated with lower numbers of expressions of positive sentiment.
C1 [Smetanin, Sergey] Natl Res Univ Higher Sch Econ, Moscow, Russia.
C3 HSE University (National Research University Higher School of Economics)
RP Smetanin, S (通讯作者)，Natl Res Univ Higher Sch Econ, Moscow, Russia.
EM sismetanin@gmail.com
CR [Anonymous], 2014, P 23 ACM INT C INFOR, V0, P0
   Escobar FB, 2021, PLOS ONE, V16, P0, DOI 10.1371/journal.pone.0252408
   Baylis P, 2020, J PUBLIC ECON, V184, P0, DOI 10.1016/j.jpubeco.2020.104161
   Baylis P, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0195750
   Baymurzina D, 2019, PROC INT C DIALOGUE, V18, P53
   Blinova M, 2013, HDB SOCIAL MEDIA MAN, V0, PP405, DOI 10.1007/978-3-642-28897-5_23
   [Бродовская ЕВBrodovskaya EV], 2016, МОНИТОРИНГ ОБЩЕСТВЕННОГО МНЕНИЯ: ЭКОНОМИЧЕСКИЕ И СОЦИАЛЬНЫЕ ПЕРЕМЕНЫ THE MONITORING OF PUBLIC OPINION: ECONOMIC & SOCIAL CHANGES MONITORING OBSHCHESTVENNOGO MNENIYA: EKONOMICHESKIE I SOTSIALNYE PEREMENY, V0, PP283, DOI 10.14515/monitoring.2016.1.13
   Buck S, 2015, INTRO APPL ECONOMETR, V11, P14
   Burke M, 2018, NAT CLIM CHANGE, V8, P723, DOI 10.1038/s41558-018-0222-x
   COHN EG, 1990, BRIT J CRIMINOL, V30, P51, DOI 10.1093/oxfordjournals.bjc.a047980
   Connolly M, 2008, J LABOR ECON, V26, P73, DOI 10.1086/522067
   Cooke LJ, 2000, NEUROLOGY, V54, P302, DOI 10.1212/WNL.54.2.302
   Deisenhammer EA, 2003, ACTA PSYCHIAT SCAND, V108, P402, DOI 10.1046/j.0001-690X.2003.00209.x
   Denissen JJA, 2008, EMOTION, V8, P662, DOI 10.1037/a0013497
   Dunn, 2021, P 8 WORKSHOP NLP SIM, V21, P28
   Dzogang F, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0197002
   Feddersen J, 2016, J R STAT SOC A STAT, V179, P203, DOI 10.1111/rssa.12118
   Garcia GR III, 2021, THESIS BRIGHAM YOUNG, V0, P0
   Hasnulin VI, 2012, EKOLOGIYA CHELOVEKA / HUMAN ECOLOGY, V0, P3
   HOWARTH E, 1984, BRIT J PSYCHOL, V75, P15, DOI 10.1111/j.2044-8295.1984.tb02785.x
   Kalabikhina IE, 2021, MATHEMATICS-BASEL, V9, P0, DOI 10.3390/math9090987
   Keller MC, 2005, PSYCHOL SCI, V16, P724, DOI 10.1111/j.1467-9280.2005.01602.x
   Kööts L, 2011, J INDIVID DIFFER, V32, P74, DOI 10.1027/1614-0001/a000037
   Kostenetskiy PS, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1740, P0, DOI 10.1088/1742-6596/1740/1/012050
   Kotelnikova A, 2021, ARXIV, V0, P0
   Kuratov Y, 2019, ABS190507213 CORR, V0, P0
   [Лебедева-Несевря НАLebedeva-Nesevria NA], 2020, ЗДОРОВЬЕ НАСЕЛЕНИЯ И СРЕДА ОБИТАНИЯ POPULATION HEALTH AND LIFE ENVIRONMENT ZDOROVE NASELENIYA I SREDA OBITANIYA, V0, PP8, DOI 10.35627/2219-5238/2020-328-7-8-13
   Nemeth R, 2021, PATHWAYS SOCIAL SCI, V0, PP49, DOI 10.1007/978-3-030-54936-73
   Odnoklassniki, 2021, OK MED 2022, V0, P0
   Panchenko A, 2014, COMPUT LINGUIST, V2, P506
   Parker PM, 2000, INT J RES MARK, V17, P33, DOI 10.1016/S0167-8116(00)00006-9
   Parsons AG, 2001, AUSTR MARKET J, V9, P78, DOI 10.1016/S1441-3582(01)70177-2
   Rogers Anna, 2018, P 27 INT C COMP LING, V0, P755
   Royal Meteorological Society, 2015, BEAUF SCAL, V0, P0
   Sberbank, 2021, 2 ONL HUM SBERDEVICE, V0, P0
   Settanni M, 2015, FRONT PSYCHOL, V6, P0, DOI 10.3389/fpsyg.2015.01045
   Shan SQ, 2021, INT J ENV RES PUB HE, V18, P0, DOI 10.3390/ijerph18105422
   [Щекотин ЕВSHCHEKOTIN EV], 2020, МОНИТОРИНГ ОБЩЕСТВЕННОГО МНЕНИЯ: ЭКОНОМИЧЕСКИЕ И СОЦИАЛЬНЫЕ ПЕРЕМЕНЫ THE MONITORING OF PUBLIC OPINION: ECONOMIC & SOCIAL CHANGES MONITORING OBSHCHESTVENNOGO MNENIYA: EKONOMICHESKIE I SOTSIALNYE PEREMENY, V0, P78
   Shiryaeva O, 2015, P 5 INT SCI PRACTICA, V5, P419
   Smetanin S, 2022, MATHEMATICS-BASEL, V10, P0, DOI 10.3390/math10162947
   Smetanin S, 2022, IEEE ACCESS, V10, P18886, DOI 10.1109/ACCESS.2022.3149897
   Smetanin S, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102484
   Van de Vliert E, 2004, J ENVIRON PSYCHOL, V24, P17, DOI 10.1016/S0272-4944(03)00021-5
   VCIOM, 2018, EACH AG HAS ITS OWN, V0, P0
   VCIOM, 2021, CYB SCAL PROBL RUSS, V0, P0
   VCIOM, 2021, MED CONS ACT INT, V0, P0
   VCIOM, 2022, HAPP IND, V0, P0
   Vesna E, 2009, SERIYA GUMANITARNYE, V2, P31
   von Mackensen S, 2005, INT J BIOMETEOROL, V49, P156, DOI 10.1007/s00484-004-0226-2
   Wang JH, 2020, ONE EARTH, V2, P568, DOI 10.1016/j.oneear.2020.05.016
   Zheng SQ, 2019, NAT HUM BEHAV, V3, P237, DOI 10.1038/s41562-018-0521-2
NR 51
TC 0
Z9 0
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD NOV 18
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1164
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA C9LT5
UT WOS:000965057200002
PM 36426259
DA 2023-11-10
ER

PT J
AU Stoica, LF
   Stoica, F
AF Stoica, Laura F.
   Stoica, Florin
TI ATLDesigner: ATL Model Checking Using An Attribute Grammar
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE ATL; model checking; web services; attribute grammar
AB In this paper, we use attribute grammars as a formal approach for model checkers development. Our aim is to design an Alternating-Time Temporal Logic (ATL) model checker from a context-free grammar which generates the language of the ATL formulae. An attribute grammar may be informally defined as a context-free grammar which is extended with a set of attributes and a collection of semantic rules. We provide a formal definition for an attribute grammar used as input for Another Tool for Language Recognition (ANTLR) to generate an ATL model checker. The original implementation of the model-checking algorithm is based on Relational Databases and Web Services. Several database systems and Web Services technologies were used for evaluating the system performance in verification of large ATL models.
C1 [Stoica, Laura F.; Stoica, Florin] Lucian Blaga Univ Sibiu, Fac Sci, Dept Math & Informat, Str Dr Ion Ratiu 5-7, Sibiu 550012, Romania.
C3 Lucian Blaga University of Sibiu
RP Stoica, LF (通讯作者)，Lucian Blaga Univ Sibiu, Fac Sci, Dept Math & Informat, Str Dr Ion Ratiu 5-7, Sibiu 550012, Romania.
EM laura.cacovean@ulbsibiu.ro; florin.stoica@ulbsibiu.ro
FU Lucian Blaga University of Sibiu & Hasso Plattner Foundation [LBUS-RRC-2020-01]
CR Alechina N, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1069
   Alur R, 2002, J ACM, V49, P672, DOI 10.1145/585265.585270
   Alur R, 1998, LECT NOTES COMPUT SC, V1427, P521, DOI 10.1007/BFb0028774
   Bingham B, 2010, 2010 9 INT WORKSH HI, V0, P28
   BRYANT RE, 1986, IEEE T COMPUT, V35, P677, DOI 10.1109/TC.1986.1676819
   Busard S, 2019, INT J SOFTW TOOLS TE, V21, P449, DOI 10.1007/s10009-018-0505-6
   Cermák P, 2014, LECT NOTES COMPUT SC, V8559, P525
   Eisner C, 2002, LECT NOTES COMPUT SC, V2318, P230
   Ferrando A, 2021, AAMAS21, V0, P1764
   Holzmann GJ, 1997, IEEE T SOFTWARE ENG, V23, P279, DOI 10.1109/32.588521
   Hu AJ, 1995, THESIS STANFORD U, V0, P0
   Jamroga W, 2011, P 22 INT JOINT C ART, VOne, P252, DOI 10.1023/A:1026171312755
   Kacprzak M, 2020, KR2020: PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, V0, P539
   Kurpiewski D, 2021, P AAMAS, V0, P1770
   Kurpiewski D, 2019, AAMAS 19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, V0, P2372
   Lerda F, 2003, ELECTRONIC NOTES IN THEORETICAL COMPUTER SCIENCE, V89, P0, DOI 10.1016/S1571-0661(05)80008-8
   Lomuscio A, 2006, LECT NOTES COMPUT SC, V3920, P450
   Lomuscio A, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS15), V0, P1713
   Lomuscio A, 2017, INT J SOFTW TOOLS TE, V19, P9, DOI 10.1007/s10009-015-0378-x
   Nam W, 2020, INT J SOFTW ENG KNOW, V30, P555, DOI 10.1142/S0218194020500199
   Niewiadomski A, 2020, P 19 INT C AUT AG MU, V0, P2111
   Rozier KY, 2011, COMPUT SCI REV, V5, P163, DOI 10.1016/j.cosrev.2010.06.002
   Ruan J, 2008, THESIS U LIVERPOOL, V0, P0
   Rus T, 2002, FORM METHOD SYST DES, V20, P249, DOI 10.1023/A:1014742013173
   Slonneger K, 1995, FORMAL SYNTAX SEMANT, V0, P0
   Stoica Florin, 2014, 2014 22ND INTERNATIONAL CONFERENCE ON SOFTWARE, V0, P361, DOI 10.1109/SOFTCOM.2014.7039096
   Stoica F, 2021, PROC 7 INT C MODELLI, V0, P149
   Thirunarayan, 2009, ENCY INFORM SCI TECH, V0, P0
NR 29
TC 0
Z9 0
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD AUG 15
PY 2022
VL 32
IS 08
BP 1125
EP 1154
DI 10.1142/S0218194022500450
EA AUG 2022
PG 30
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 4Q0LA
UT WOS:000848725100001
DA 2023-11-10
ER

PT J
AU Malysiak-Mrozek, B
   Wieszok, J
   Pedrycz, W
   Ding, WP
   Mrozek, D
AF Malysiak-Mrozek, Bozena
   Wieszok, Jadwiga
   Pedrycz, Witold
   Ding, Weiping
   Mrozek, Dariusz
TI High-Efficient Fuzzy Querying With HiveQL for Big Data Warehousing
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Big Data; Warehousing; Data warehouses; Linguistics; Distributed databases; Relational databases; Fuzzy sets; Big data; data warehousing; fuzzy sets; Hadoop; Hive; querying
ID nosql graph databases; implementation; algorithm; framework; query; model
AB Querying and reporting from large volumes of structured, semistructured, and unstructured data often requires some flexibility. This flexibility provided by fuzzy sets allows for categorization of the surrounding world in a flexible, human-mind-like manner. Apache Hive is a data warehousing framework working on top of the Hadoop platform for big data processing. Hive allows executing queries and aggregating and analyzing data stored in Hadoop distributed file system and other repositories. Hive responds to the current needs for efficient big data warehousing, which is impossible with traditional data warehouses due to their rigid nature. This article presents the FuzzyHive library that extends the Hive framework with fuzzy sets based techniques for querying, analyzing, and reporting on big data warehouses. We formalize the fuzzy techniques used while operating on Hive-based data warehouses (including fuzzy filtering on dimensional attributes, projection with fuzzy transformation, fuzzy grouping, and joining). We also show how we embedded these operations in Hive query language, which was not studied so far. Such extensions make big data warehousing more flexible and contribute to the portfolio of tools used by the community of people working with fuzzy sets and data analysis. The FuzzyHive library complements the spectrum of available solutions for fuzzy data processing and querying in large datasets. We investigate Hive fuzzy querying performance, effectiveness, and scalability for various data storage formats (text, Avro, and Parquet). Our experiments demonstrate that the proposed extensions introduce more elasticity and are also efficient for big data warehousing, which is the first such kind of solution for this environment.
C1 [Malysiak-Mrozek, Bozena] Silesian Tech Univ, Dept Graph Comp Vis & Digital Syst, PL-44100 Gliwice, Poland.
   [Wieszok, Jadwiga; Mrozek, Dariusz] Silesian Tech Univ, Dept Appl Informat, PL-44100 Gliwice, Poland.
   [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
   [Pedrycz, Witold] King Abdulaziz Univ, Fac Engn, Dept Elect & Comp Engn, Jeddah 21589, Saudi Arabia.
   [Pedrycz, Witold] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland.
   [Ding, Weiping] Nantong Univ, Sch Informat Sci & Technol, Nantong 226019, Peoples R China.
C3 Silesian University of Technology; Silesian University of Technology; University of Alberta; King Abdulaziz University; Polish Academy of Sciences; Systems Research Institute of the Polish Academy of Sciences; Nantong University
RP Mrozek, D (通讯作者)，Silesian Tech Univ, Dept Appl Informat, PL-44100 Gliwice, Poland.
EM bozena.malysiak-mrozek@polsl.pl; jadwiga.wieszok@gmail.com; wpedrycz@ualberta.ca; dwp9988@163.com; dariusz.mrozek@polsl.pl
FU Amazon Web Services [02/100/RGJ21/0009, 02/020/RGP19/0184]; Statutory Research funds of Department of Applied Informatics, Silesian University of Technology [02/100/BK_21/0008, BK-221/RAU7/2021]; National Natural Science Foundation of China [61300167, 61976120]; Natural Science Foundation of Jiangsu Province [BK20191445]; Qing Lan Project of Jiangsu Province, China
CR [Anonymous], 2016, HADOOPWITH I FUZZY C, V0, P0
   [Anonymous], 2014, FUZZY DATA WAREHOUSI, V0, P0
   [Anonymous], 2014, INT J COMPUT SCI APP, V0, P0
   [Anonymous], 2010, P INEER INT C ENG ED, V0, P0
   [Anonymous], 2013, FUZZY MULTIDIMENSION, V0, P0
   Azar AT, 2015, SOFT COMPUT, V19, P1115, DOI 10.1007/s00500-014-1327-4
   Bakry Malak El, 2015, INT J COMPUTERS APPL, V0, P0
   BenAli-Sougui Ines, 2016, INTERNATIONAL JOURNAL OF FUZZY SYSTEMS APPLICATIONS, V5, P54, DOI 10.4018/IJFSA.2016040104
   Bharill N, 2016, PROCEEDINGS 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2016), V0, PP95, DOI 10.1109/BigDataService.2016.34
   Bordogna G, 2008, HDB RES FUZZY INFORM, V0, P191
   Bosc P, 2000, STUD FUZZ SOFT COMP, V39, P171
   Capriolo Edward, 2012, PROGRAMMING HIVE, V0, P0
   Castelltort A, 2018, FUZZY SET SYST, V348, P21, DOI 10.1016/j.fss.2017.08.002
   Castelltort A, 2017, INT J UNCERTAIN FUZZ, V25, P81, DOI 10.1142/S0218488517500040
   Castelltort A, 2016, ADV INTELL SYST, V400, P189, DOI 10.1007/978-3-319-26154-6_15
   Castelltort A, 2014, COMM COM INF SC, V444, P384
   Castillo-Ortega R, 2011, INT J INTELL SYST, V26, P1002, DOI 10.1002/int.20510
   Choi Y, 2018, ANN OPER RES, V270, P75, DOI 10.1007/s10479-016-2281-6
   CODD EF, 1970, COMMUN ACM, V13, P377, DOI 10.1145/357980.358007
   DOnofrio S, 2017, IEEE INT CONF FUZZY, V0, P0
   del Río S, 2015, INT J COMPUT INT SYS, V8, P422, DOI 10.1080/18756891.2015.1017377
   Delgado M, 2004, IEEE INT CONF FUZZY, V0, P1331
   Ducange P, 2015, P 2015 IEEE INT C FU, V0, P1
   El Bakry M, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), V0, PP118, DOI 10.1109/SAI.2016.7555971
   Elkano M, 2018, FUZZY SET SYST, V348, P75, DOI 10.1016/j.fss.2017.07.003
   Fayek A, 2018, FLEXIBLE MANAGEMENT, V0, P357
   Ford ES, 2002, JAMA-J AM MED ASSOC, V287, P356, DOI 10.1001/jama.287.3.356
   Hai RH, 2016, SIGMOD16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP2097, DOI 10.1145/2882903.2899389
   Havens TC, 2012, IEEE T FUZZY SYST, V20, P1130, DOI 10.1109/TFUZZ.2012.2201485
   Hudec M, 2009, COMPUT SCI INF SYST, V6, P127, DOI 10.2298/csis0902127H
   Kacprzyk J, 2000, STUD FUZZ SOFT COMP, V39, P211
   Khorasani ES, 2018, SOFT COMPUT, V22, P3061, DOI 10.1007/s00500-017-2561-3
   Laux, 2015, P 7 INT C ADV DAT KN, V0, P153
   Li YJ, 2015, J INTELL FUZZY SYST, V28, P2391, DOI 10.3233/IFS-141520
   Liu J, 2016, IEEE T FUZZY SYST, V24, P419, DOI 10.1109/TFUZZ.2015.2459756
   López V, 2015, FUZZY SET SYST, V258, P5, DOI 10.1016/j.fss.2014.01.015
   Ludwig SA, 2015, INT J MACH LEARN CYB, V6, P923, DOI 10.1007/s13042-015-0367-0
   Malysiak B, 2005, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, V0, P36
   Malysiak-Mrozek B, 2018, IEEE ACCESS, V6, P69545, DOI 10.1109/ACCESS.2018.2879829
   Malysiak-Mrozek B, 2018, IEEE T FUZZY SYST, V26, P2732, DOI 10.1109/TFUZZ.2018.2812157
   Malysiak-Mrozek B, 2010, LECT NOTES ARTIF INT, V6098, P616, DOI 10.1007/978-3-642-13033-5_63
   Malysiak-Mrozek B, 2009, ADV INTEL SOFT COMPU, V59, P247
   Martinez-Rojas M, 2015, PROC IEEE INT C FUZZ, V0, PP1, DOI 10.1007/8623_2015_104
   Miloslavskaya N, 2016, PROCEDIA COMPUT SCI, V88, P300, DOI 10.1016/j.procs.2016.07.439
   Molina C, 2006, IEEE T FUZZY SYST, V14, P897, DOI 10.1109/TFUZZ.2006.879984
   Papakostas GA, 2015, 2015 IEEE INT C FUZZ, V0, P1
   Peters G, 2016, GRANULAR COMPUT, V1, P1, DOI 10.1007/s41066-015-0012-z
   Portinale L, 2008, PROC INT C TOOLS ART, V0, PP241, DOI 10.1109/ICTAI.2008.88
   Prabha S, 2014, INT J ADV RES COMPUT, V3, P2235
   Prasad M, 2015, NEUROCOMPUTING, V167, P558, DOI 10.1016/j.neucom.2015.04.034
   Sassi Hidri M, 2018, FUZZY SET SYST, V348, P50, DOI 10.1016/j.fss.2017.11.003
   Segatori A, 2018, IEEE T FUZZY SYST, V26, P174, DOI 10.1109/TFUZZ.2016.2646746
   Smith JW, 1988, PROCEEDINGS. THE TWELFTH ANNUAL SYMPOSIUM ON COMPUTER APPLICATIONS IN MEDICAL CARE (IEEE CAT. NO.88CH2616-1), V0, P261
   Smits G, 2018, FUZZY SET SYST, V348, P4, DOI 10.1016/j.fss.2018.02.017
   Su P, 2015, J INTELL FUZZY SYST, V28, P2409, DOI 10.3233/IFS-141518
   Terrizzano Ignacio, 2015, 7 BIENN C INN DAT SY, V0, P0
   ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5
   Zhang BJ, 2016, SIGNAL PROCESS, V126, P111, DOI 10.1016/j.sigpro.2015.10.014
   Ziólko B, 2015, FUZZY SET SYST, V279, P101, DOI 10.1016/j.fss.2015.03.006
NR 59
TC 3
Z9 3
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD JUN 15
PY 2022
VL 30
IS 6
BP 1823
EP 1837
DI 10.1109/TFUZZ.2021.3069332
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1T4KB
UT WOS:000804698500031
DA 2023-11-10
ER

PT J
AU Ryu, M
   Lee, G
   Lee, K
AF Ryu, Minho
   Lee, Geonseok
   Lee, Kichun
TI Knowledge distillation for BERT unsupervised domain adaptation
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Language model; Knowledge distillation; Domain adaptation
AB A pre-trained language model, BERT, has brought significant performance improvements across a range of natural language processing tasks. Since the model is trained on a large corpus of diverse topics, it shows robust performance for domain shift problems in which data distributions at training (source data) and testing (target data) differ while sharing similarities. Despite its great improvements compared to previous models, it still suffers from performance degradation due to domain shifts. To mitigate such problems, we propose a simple but effective unsupervised domain adaptation method, adversarial adaptation with distillation (AAD), which combines the adversarial discriminative domain adaptation (ADDA) framework with knowledge distillation. We evaluate our approach in the task of cross-domain sentiment classification on 30 domain pairs, advancing the state-of-the-art performance for unsupervised domain adaptation in text sentiment classification.
C1 [Ryu, Minho] SK Telecom, Seoul, South Korea.
   [Lee, Geonseok; Lee, Kichun] Hanyang Univ, Dept Ind Engn, Seoul, South Korea.
C3 SK Group; SK Telecom; Hanyang University
RP Lee, K (通讯作者)，Hanyang Univ, Dept Ind Engn, Seoul, South Korea.
EM ryumin93@sktbrain.com; lgs5228@hanyang.ac.kr; skylee@hanyang.ac.kr
FU Ministry of Education of the Republic of Korea; National Research Foundation of Korea [NRF-2020R1F1A1076278]; "Human Resources Program in Energy Technology" of the Korea Institute of Energy Technology Evaluation and Planning (KETEP); Ministry of Trade, Industry & Energy, Republic of Korea [20204010600090]
CR Blitzer J, 2006, P 2006 C EMPIRICAL M, V0, P120
   Chadha A, 2018, ARXIV180903625, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dredze Mark, 2007, P 45 ANN M ASS COMPU, V0, P440
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Hoffman J, 2018, PR MACH LEARN RES, V80, P0
   Joshi M, 2019, ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Kirkpatrick J, 2016, ARXIV, V0, P0
   Kumar A, 2017, ARXIV, V0, P0
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Nguyen Quang, 2015, AIRLINE REV DATASET, V0, P0
   Paszke Adam, 2017, NIPS W, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Sanh Victor, 2019, NEURIPS EMC2 WORKSHO, V0, P0
   Sun B, 2016, ARXIV, V0, P0
   Sun BC, 2016, AAAI CONF ARTIF INTE, V0, P2058
   Tuzel O, 2016, ADV NEURAL INFORM PR, V0, PP469, DOI 10.5555/3157096.3157149
   Tzeng E, 2017, PROC CVPR IEEE, V0, PP2962, DOI 10.1109/CVPR.2017.316
   Tzeng Eric, 2014, ARXIV14123474, V0, P0, DOI DOI 10.48550/ARXIV.1412.3474
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P3048, DOI 10.1109/TPAMI.2021.3055564
   Weng RX, 2020, AAAI CONF ARTIF INTE, V34, P9266
   Wolf T, 2019, ARXIV, V0, P0
   Yang Z, 2019, ARXIV, V0, P0
   Ziser Y, 2018, 2018 C N AM CHAPT AS, V0, P1241
   Ziser Yftah, 2017, P INT C COMPUTATIONA, V0, PP400, DOI 10.18653/V1/K17-1040
NR 31
TC 3
Z9 3
U1 7
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD NOV 15
PY 2022
VL 64
IS 11
BP 3113
EP 3128
DI 10.1007/s10115-022-01736-y
EA AUG 2022
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 4N6YE
UT WOS:000842758700003
DA 2023-11-10
ER

PT J
AU Verma, K
   Popovi, M
   Poulis, A
   Cherkasova, Y
   HObáin, CO
   Mazzone, A
   Milosevic, T
   Davis, B
AF Verma, Kanishk
   Popovi, Maja
   Poulis, Alexandros
   Cherkasova, Yelena
   HObain, Cathal O.
   Mazzone, Angela
   Milosevic, Tijana
   Davis, Brian
TI Leveraging machine translation for cross-lingual fine-grained cyberbullying classification amongst pre-adolescents
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Corpus linguistics; Text classification; Machine translation; Cyberbullying; Language resources
ID reliability
AB Cyberbullying is the wilful and repeated infliction of harm on an individual using the Internet and digital technologies. Similar to face-to-face bullying, cyberbullying can be captured formally using the Routine Activities Model (RAM) whereby the potential victim and bully are brought into proximity of one another via the interaction on online social networking (OSN) platforms. Although the impact of the COVID-19 (SARS-CoV-2) restrictions on the online presence of minors has yet to be fully grasped, studies have reported that 44% of pre-adolescents have encountered more cyberbullying incidents during the COVID-19 lockdown. Transparency reports shared by OSN companies indicate an increased take-downs of cyberbullying-related comments, posts or content by artificially intelligen moderation tools. However, in order to efficiently and effectively detect or identify whether a social media post or comment qualifies as cyberbullying, there are a number factors based on the RAM, which must be taken into account, which includes the identification of cyberbullying roles and forms. This demands the acquisition of large amounts of fine-grained annotated data which is costly and ethically challenging to produce. In addition where fine-grained datasets do exist they may be unavailable in the target language. Manual translation is costly and expensive, however, state-of-the-art neural machine translation offers a workaround. This study presents a first of its kind experiment in leveraging machine translation to automatically translate a unique pre-adolescent cyberbullying gold standard dataset in Italian with fine-grained annotations into English for training and testing a native binary classifier for pre-adolescent cyberbullying. In addition to contributing high-quality English reference translation of the source gold standard, our experiments indicate that the performance of our target binary classifier when trained on machine-translated English output is on par with the source (Italian) classifier.
C1 [Verma, Kanishk; Popovi, Maja; HObain, Cathal O.; Davis, Brian] Dublin City Univ, ADAPT SFI Res Ctr, Dublin, Ireland.
   [Verma, Kanishk; Mazzone, Angela; Milosevic, Tijana] Dublin City Univ, DCU Antibullying Ctr, Dublin, Ireland.
   [Poulis, Alexandros] TransPerfect DataForce, Luxembourg, Luxembourg.
   [Cherkasova, Yelena] G3 Translate, Strateg Partner Transperfect, New York, NY USA.
C3 Dublin City University; Dublin City University
RP Verma, K (通讯作者)，Dublin City Univ, ADAPT SFI Res Ctr, Dublin, Ireland.; Verma, K (通讯作者)，Dublin City Univ, DCU Antibullying Ctr, Dublin, Ireland.
EM kanishk.verma@adaptcentre.ie
FU Irish Research Council; Google, Ireland [EPSPG/2021/161]; European Union [801522]; Science Foundation Ireland; European Regional Development Fund through the ADAPT Centre for Digital Content Technology [13/RC/2106_P2]
CR Al-garadr MA, 2016, COMPUT HUM BEHAV, V63, P433, DOI 10.1016/j.chb.2016.05.051
   Al-Hashedi M, 2019, PROC 2 INT C COMPUT, V0, P17
   [Anonymous], 2020, DISC TRANSP REP JUL, V0, P0
   Armitage R, 2021, BRIT J GEN PRACT, V71, P122, DOI 10.3399/bjgp21X715073
   Asai R, 2020, SOC CHALLENGES SMART, V0, P459
   Bailey JO, 2021, FRONT ARTIF INTELL, V4, P0, DOI 10.3389/frai.2021.637532
   Balahur A, 2012, ASS COMPUTATIONAL LI, V0, P52
   Balahur A, 2014, COMPUT SPEECH LANG, V28, P56, DOI 10.1016/j.csl.2013.03.004
   Banerjee P, 2012, P 16 ANN M EUR ASS M, V0, P169
   Bauman S, 2015, CYBERBULLYING, V0, P0, DOI DOI 10.1002/9781119221685.ch4
   Bayari R, 2021, ADV SCI TECHNOLOGY E, V6, P783
   Bayari R, 2021, TEXT MINING TECHNIQU, V0, P0
   Bayzick Jennifer, 2011, DETECTING PRESENCE C, V0, P0
   Bermingham A, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP784, DOI 10.1145/1571941.1572127
   Bohra A, 2018, P 2 WORKSH COMP MOD, V0, PP36, DOI 10.18653/v1/W18-1105
   Bretschneider U, 2016, DETECTING CYBERBULLY, V0, P0
   Byrd Jonathon, 2019, PR MACH LEARN RES, V0, PP872, DOI 10.48550/ARXIV.1812.03372
   Chen HY, 2020, ARXIV, V0, P0
   Cheng L, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM19), V0, PP339, DOI 10.1145/3289600.3291037
   Cho KYHY, 2014, ARXIV, V0, P0
   Corazza M, 2019, CLIC IT 2019 6 ANN C, V0, P0
   Dadvar M, 2018, ARXIV, V0, P0
   DeSmet A, 2018, COMPUT HUM BEHAV, V83, P254, DOI 10.1016/j.chb.2018.02.010
   Devlin J, 2019, ARXIV, V0, P0
   DfE, 2019, UNCRC 2019, V0, P0
   Dinakar K, 2011, P INT C WEBL SOC MED, V0, P0
   Emmery C, 2019, ABS191011922 CORR, V0, P0
   Emmery C, 2021, LANG RESOUR EVAL, V55, P597, DOI 10.1007/s10579-020-09509-1
   Facebook Transparency Report, 2021, COMMUNITY STANDARDS, V0, P0
   Gada M, 2021, P 2021 INT C COMPUTE, V0, P1
   GYSELS M, 1992, J MULTILING MULTICUL, V13, P41, DOI 10.1080/01434632.1992.9994482
   Haidar B, 2019, 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, V0, P323, DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00074
   Hayes AF, 2007, COMMUN METHODS MEAS, V1, P77, DOI 10.1080/19312450709336664
   Hieber F, 2018, AMTA, V0, P200
   Hosseinmardi H, 2015, LECT NOTES COMPUT SC, V9471, P49, DOI 10.1007/978-3-319-27433-1_4
   Ibn Rafiq R, 2016, SOC NETW ANAL MIN, V6, P0, DOI 10.1007/s13278-016-0398-x
   Ibn Rafiq R, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), V0, PP617, DOI 10.1145/2808797.2809381
   Ibrahim M, 2020, P 14 WORKSHOP SEMANT, V0, P1881
   Imankulova A, 2019, P MACHINE TRANSLATIO, V0, P128
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Jehl L, 2012, P 7 WORKSH STAT MACH, V0, P410
   Kingma DP, 2014, C TRACK P, V0, P0
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Klonick K, 2020, YALE LAW J, V129, P2418
   Koehn P, 2017, WMT, V0, P28
   Kumar A, 2022, MULTIMEDIA SYST, V28, P2027, DOI 10.1007/s00530-020-00672-7
   Lee C, 2017, COMPUT HUM BEHAV, V68, P352, DOI 10.1016/j.chb.2016.11.047
   Leung ANM, 2018, FRONT PSYCHOL, V9, P0, DOI 10.3389/fpsyg.2018.00365
   Lin Huan, 2021, ARXIV, V0, P0
   Ling W, 2013, P 51 ANN M ASS COMPU, V0, P176
   Lohar Pintu, 2017, PRAGUE BULLETIN OF MATHEMATICAL LINGUISTICS, V0, PP73, DOI 10.1515/pralin-2017-0010
   Lohar P, 2018, P 13 C ASS MACH TRAN, V1, P81
   Lohar P, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP2019), V0, P105
   Luong M-T, 2015, P 2015 C EMP METH NA, V0, PP1412, DOI 10.18653/V1/D15-1166
   Martinez Mateo R, 2014, MISCEL NEA, V49, P73
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Medsker LR, 2001, APPL, V5, P64
   Miethe TD, 1994, CRIME ITS SOCIAL CON, V0, P0
   Pham M, 2021, T ASSOC COMPUT LING, V9, P17, DOI 10.1162/tacl_a_00351
   Moriya S, 2018, P INT COMP SOFTW APP, V0, PP153, DOI 10.1109/COMPSAC.2018.10220
   MYERSSCOTTON C, 1993, LANG SOC, V22, P475, DOI 10.1017/S0047404500017449
   Nadali S, 2013, INT CONF INTELL SYST, V0, PP325, DOI 10.1109/ISDA.2013.6920758
   Nakov P, 2021, ABS210300153 CORR, V0, P0
   Opitz J, 2021, ARXIV, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Patchin JW, 2015, AGGRESS VIOLENT BEH, V23, P69, DOI 10.1016/j.avb.2015.05.013
   Patchin JW, 2006, YOUTH VIOLENCE JUV J, V4, P148, DOI 10.1177/1541204006286288
   Paul S, 2022, MULTIMEDIA SYST, V28, P1897, DOI 10.1007/s00530-020-00710-4
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pennebaker JW, 2001, LINGUISTIC INQUIRY W, V0, P0, DOI DOI 10.4018/978-1-60960-741-8.CH012
   PEW Research Center, 2015, TEENS TECHNOLOGY FRI, V0, P0
   Poplack S, 2003, J LINGUIST, V39, P678, DOI 10.1017/S0022226703272297
   Popovic M, 2021, P C RECENT ADV NATUR, V0, P0
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, V0, PP392, DOI 10.1080/1472586x.2015.1113070.
   Ranathunga S, 2021, ABS210615115 CORR, V0, P0
   Reynolds K, 2011, PROCEEDINGS OF THE 2011 TENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2011), V0, PP241, DOI 10.1109/ICMLA.2011.152
   Rosa H, 2019, COMPUT HUM BEHAV, V93, P333, DOI 10.1016/j.chb.2018.12.021
   Rubino R, 2013, 6 INT JOINT C NAT LA, V0, P1167
   Salawu S, 2020, IEEE T AFFECT COMPUT, V11, P3, DOI 10.1109/TAFFC.2017.2761757
   San Vicente I, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2936
   Sanchez H, 2011, NSDI, V12, P15
   Sasaki Y, 2007, TEACH TUTOR MAT, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Silk MR, 2021, COMMUNICATION, V0, P0
   Slonje R, 2013, COMPUT HUM BEHAV, V29, P26, DOI 10.1016/j.chb.2012.05.024
   Song J, 2018, COMPUT HUM BEHAV, V78, P273, DOI 10.1016/j.chb.2017.10.008
   Sprugnoli R, 2018, P 2 WORKSHOP ABUSIVE, V0, P51
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Thomas Kurt, 2021, 2021 IEEE SYMPOSIUM ON SECURITY AND PRIVACY (SP), V0, PP247, DOI 10.1109/SP40001.2021.00028
   Van Hee C, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0203794
   Van Royen K, 2017, COMPUT HUM BEHAV, V66, P345, DOI 10.1016/j.chb.2016.09.040
   Vaswani A, 2013, P 2013 C EMPIRICAL M, V0, P1387
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Verheijen L, 2017, P 5 C CMC SOCIAL MED, V101, P6
   Vidgen B, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0243300
   Wang H, 2021, ENGINEERING, V14, P15
   Warrens MJ, 2010, ADV DATA ANAL CLASSI, V4, P271, DOI 10.1007/s11634-010-0073-4
   Whoint, 2021, WHO DIRECTOR GEN OPE, V0, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xu JM, 2012, HLT NAACL, V0, P656
   Yin D, 2009, P CONTENT ANAL WEB, V2, P1
   Zhang Yun-tao, 2005, JOURNAL OF ZHEJIANG UNIVERSITY (SCIENCE), V6A, P49, DOI 10.1631/jzus.2005.A0049
   Zhou P, 2016, ARXIV, V0, P0
   Zhou Y, 2019, KDIR: PROCEEDINGS OF THE 11TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, V0, P55, DOI 10.5220/0008064500550064
NR 105
TC 0
Z9 0
U1 5
U2 13
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324922000341
EA SEP 2022
PG 23
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 4I6UY
UT WOS:000850712400001
DA 2023-11-10
ER

PT J
AU Wan, BY
   Jiang, WH
   Fang, YM
   Zhu, MW
   Li, Q
   Liu, Y
AF Wan, Boyang
   Jiang, Wenhui
   Fang, Yu-Ming
   Zhu, Minwei
   Li, Qin
   Liu, Yang
TI Revisiting image captioning via maximum discrepancy competition
SO PATTERN RECOGNITION
LA English
DT Article
DE Image captioning; Model comparison; Attention mechanism
AB Image captioning is a hot research topic bridging computer vision and natural language processing during the past several decades. It has achieved great progress with the help of large-scale datasets and deep learning techniques. Though the variety of image captioning models (ICMs), the performance of ICMs have got stuck in a bottleneck judging from the publicly published results. Considering the marginal performance gains brought by recent ICMs, we raise the following question: "what about the performances of the recent ICMs achieve on in-the-wild images? To clarify this question, we compare existing ICMs by evaluating their generalization ability. Specifically, we propose a novel method based on maximum discrepancy competition to diagnose existing ICMs. Firstly, we establish a new test set containing only informative images selected by adopting maximum discrepancy competition on the existing ICMs, from an arbitrary large-scale raw image set. Secondly, a small-scale and low-cost subjective annotation experiment is conducted on the new test set. Thirdly, we rank the generalization ability of the existing ICMs by comparing their performances on the new test set. Finally, the keys of different ICMs are demonstrated based on a detailed analysis of experimental results. Our analysis yields several interesting findings, including that 1) Using simultaneously low-and high-level object features may be an effective tool to boost the generalization ability for the Transformer based ICMs. 2) Self-attention mechanism may provide better modelling ability for inter-and intra-modal data than other attention-based mechanisms. 3) Constructing an ICM with a multistage language decoder may be a promising way to improve its performance. (c) 2021 Elsevier Ltd. All rights reserved.
C1 [Wan, Boyang; Jiang, Wenhui; Fang, Yu-Ming; Zhu, Minwei; Li, Qin] Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
   [Liu, Yang] SANY Heavy Ind Co Ltd, Beijing, Peoples R China.
C3 Jiangxi University of Finance & Economics; SANY
RP Fang, YM (通讯作者)，Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
EM 2201810057@stu.jxufe.edu.cn; jiang1st@bupt.edu.cn; fa0001ng@e.ntu.edu.sg; 413740229@qq.com; liqin4948@163.com
CR Agrawal H, 2019, IEEE I CONF COMP VIS, V0, PP8947, DOI 10.1109/ICCV.2019.00904
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Bahdanau D, 2016, ARXIV, V0, P0
   Chen J, 2020, P IEEE CVF C COMP VI, V0, P10890
   Chen S, 2020, P IEEECVF C COMPUTER, V0, P9962
   Chen Xinlei, 2015, ARXIV150400325, V0, P0
   Cornia Marcella, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10575, DOI 10.1109/CVPR42600.2020.01059
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   Devlin J, 2018, ARXIV, V1, P4171
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R, V0, P0
   Elsken T, 2019, J MACH LEARN RES, V20, P0
   Fang YM, 2020, PATTERN RECOGN, V103, P0, DOI 10.1016/j.patcog.2020.107294
   Fang YM, 2019, PATTERN RECOGN, V96, P0, DOI 10.1016/j.patcog.2019.106987
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   Gu JX, 2018, AAAI CONF ARTIF INTE, V0, P6837
   Gupta A, 2012, P AAAI C ART INT, V0, P0
   Herdade S, 2019, ADV NEUR IN, V32, P0
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/TPAMI.2019.2913372
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kilickaya M, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P199
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova P, 2014, J T ASS COMPUT LINGU, V2, P351, DOI 10.1162/tacl_a_00188
   Li LH, 2017, AAAI CONF ARTIF INTE, V0, P4133
   Li S, 2011, P C COMP NAT LANG LE, V0, P220
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Longteng Guo, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10324, DOI 10.1109/CVPR42600.2020.01034
   Luo RT, 2018, PROC CVPR IEEE, V0, PP6964, DOI 10.1109/CVPR.2018.00728
   Ma KD, 2020, IEEE T PATTERN ANAL, V42, P851, DOI 10.1109/TPAMI.2018.2889948
   Mao J, 2015, P ICLR 15 MAY, V0, P0
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SAATY TL, 1984, J MATH PSYCHOL, V28, P205, DOI 10.1016/0022-2496(84)90027-0
   Simonyan K, 2015, ARXIV, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang Hongyi, 2020, ARXIV200206440, V0, P0
   Wang JB, 2020, PATTERN RECOGN, V98, P0, DOI 10.1016/j.patcog.2019.107075
   Wang Z, 2008, J VISION, V8, P0, DOI 10.1167/8.12.8
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao XY, 2019, PATTERN RECOGN, V90, P285, DOI 10.1016/j.patcog.2019.01.028
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, V0, PP10677, DOI 10.1109/CVPR.2019.01094
   Yingwei Pan, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10968, DOI 10.1109/CVPR42600.2020.01098
   Young P, 2014, T ASSOC COMPUT LING, V2, P67
NR 55
TC 8
Z9 9
U1 3
U2 22
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD FEB 15
PY 2022
VL 122
IS 
BP 
EP 
DI 10.1016/j.patcog.2021.108358
EA OCT 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WN5VE
UT WOS:000711834500015
DA 2023-11-10
ER

PT J
AU Naik, A
   Lehman, J
   Rose, C
AF Naik, Aakanksha
   Lehman, Jill
   Rose, Carolyn
TI Adapting to the Long Tail: A Meta-Analysis of Transfer Learning Research for Language Understanding Tasks
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Natural language understanding (NLU) has made massive progress driven by large benchmarks, but benchmarks often leave a long tail of infrequent phenomena underrepresented. We reflect on the question: Have transfer learning methods sufficiently addressed the poor performance of benchmark-trained models on the long tail? We conceptualize the long tail using macro-level dimensions (underrepresented genres, topics, etc.), and perform a qualitative meta-analysis of 100 representative papers on transfer learning research for NLU. Our analysis asks three questions: (i) Which long tail dimensions do transfer learning studies target? (ii) Which properties of adaptation methods help improve performance on the long tail? (iii) Which methodological gaps have greatest negative impact on long tail performance? Our answers highlight major avenues for future research in transfer learning for the long tail. Lastly, using our meta-analysis framework, we perform a case study comparing the performance of various adaptation methods on clinical narratives, which provides interesting insights that may enable us to make progress along these future avenues.
C1 [Naik, Aakanksha; Rose, Carolyn] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
   [Lehman, Jill] Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA USA.
   [Naik, Aakanksha] NIH, Clin Ctr, Rehabil Med Dept, Bethesda, MD USA.
C3 Carnegie Mellon University; Carnegie Mellon University; National Institutes of Health (NIH) - USA; NIH Clinical Center (CC)
RP Naik, A (通讯作者)，Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
EM anaik@andrew.cmu.edu; jfl@andrew.cmu.edu; cp3a@andrew.cmu.edu
FU Intramural Research Program of the National Institutes of Health; Clinical Research Center
CR Al Boni M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P769
   Alam F, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1077
   [Anonymous], 2009, ACTIVE LEARNING LIT, V0, P0
   [Anonymous], 2010, COLING 2010 POSTERS, V0, P0
   Arnold Andrew, 2008, P ACL 08 HLT, V0, P245
   Bender EM, 2011, LING ISSUES LANG TEC, V0, P0, DOI DOI 10.33011/LILT.V6I.1239
   Blitzer J, 2006, P 2006 C EMPIRICAL M, V0, P120
   Blodgett Su Lin, 2020, P 58 ANN M ASS COMPU, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.485
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, PD267, DOI 10.1093/nar/gkh061
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Braud Chloe, 2014, P COLING 2014 25 INT, V0, P1694
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P169
   Chan YS, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Chan Yee Seng, 2007, P 45 ANN M ASS COMP, V0, P49
   Chang Ming-Wei, 2010, P 2010 C EMPIRICAL M, V0, P767
   Charniak Eugene, 1997, P 14 NAT C ART INT, V2005, P18, DOI 10.5555/1867406.1867499
   Chen MJ, 2012, P AS C SIGN SYST COM, V0, PP1, DOI 10.1109/ISGT-ASIA.2012.6303206
   Chen SY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7870
   Chiticariu L, 2010, P 2010 C EMP METH NA, V0, P1002
   Cohan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2270
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   Daume III Hal, 2007, P 45 ANN M ASS COMP, V0, PP256, DOI 10.48550/ARXIV.0907.1815
   Dereli N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P331
   Devlin J, 2018, ARXIV, V1, P4171
   Dredze Mark, 2007, P 45 ANN M ASS COMPU, V0, P440
   Faruqui Manaal, 2015, P 2015 C N AM CHAPT, V0, PP1606, DOI 10.3115/v1/N15-1184
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gao Jianfeng, 2015, P 2015 C N AM CHAPT, V0, PP912, DOI 10.3115/V1/N15-1092
   Glorot Xavier, 2011, ICML, V0, P0, DOI DOI 10.1177/1753193411430810
   Gong L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P855
   Gururangan Suchin, 2020, ACL, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.740
   Gururangan Suchin, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Hangya V, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P810
   Hedderich MA, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu JJ, 2020, PR MACH LEARN RES, V119, P0
   Huang YJ, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P785
   Jeong Minwoo, 2009, P 2009 C EMP METH NA, V0, PP1250, DOI 10.3115/1699648.1699671
   Ji Yangfeng, 2015, P 2015 C EMP METH NA, V0, PP2219, DOI 10.18653/V1/D15-1264
   Jiang Jing, 2007, ANN M ASS COMP LING, V0, PP264, DOI 10.1145/1273496.1273558
   Jochim C, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P42
   Joshi Pratik, 2020, P 58 ANN M ASS COMP, V0, PP6282, DOI 10.18653/V1/2020.ACL-MAIN.560
   Kashyap Abhinav Ramesh, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Khanuja S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3575
   Kim Joo-Kyung, 2017, P 2017 C EMP METH NA, V0, PP2832, DOI 10.18653/V1/D17-1302
   Lee Young-Suk, 2020, FINDINGS ASS COMPUTA, V0, P3208
   Li F, 2012, P 50 ANN M ASS COMP, V0, P410
   Liang Jian, 2020, ICML, V0, P0
   Liberati A, 2009, ANN INTERN MED, V151, PW65, DOI 10.7326/0003-4819-151-4-200908180-00136
   Lin BY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2012
   Lison P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1518
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   Lo K, 2020, P 58 ANN M ASS COMP, V0, PP4969, DOI 10.18653/V1/2020.ACL-MAIN.447
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   McCann Bryan, 2018, ABS180608730 CORR, V0, P0
   McClosky David, 2010, HUMAN LANGUAGE TECHN, V0, P28
   McClosky David, 2006, P MAIN C HUM LANG TE, V0, PP152, DOI 10.3115/1220835.1220855
   Nguyen ML, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P807
   Mohit B, 2012, P 13 C EUROPEAN CHAP, V0, P162
   Naik A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2963
   Newman-Griffis D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P4125
   Ning Yu, 2011, P 15 C COMP NAT LANG, V0, P200
   Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), V0, P58
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pilan Ildiko, 2016, P COLING 2016 26 INT, V0, P2101
   Plank B, 2016, BOCHUMER LINGUISTISC, V16, P0
   Plank Barbara, 2014, P 2014 C EMP METH NA, V0, PP968, DOI 10.3115/V1/D14-1104
   Pustejovsky James, 2003, CORPUS LINGUISTICS, V0, P0
   Rai Piyush, 2010, P NAACL HLT 2010 WOR, V0, PP27, DOI 10.5555/1860625.1860629
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Ramponi Alan, 2020, P 28 INT C COMPUTATI, V0, PP6838, DOI 10.18653/V1/2020.COLING-MAIN.603
   Romanov A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1586
   Ruder Sebastian, 2019, P 2019 C N AM CHAPT, V0, PP15, DOI 10.18653/V1/N19-5004
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Scheible C, 2013, P 51 ANN M ASS COMP, V1, P954
   Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P255
   Steedman M, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P331
   Stubbs A, 2015, J BIOMED INFORM, V58, PS20, DOI 10.1016/j.jbi.2015.07.020
   Sun WY, 2013, J AM MED INFORM ASSN, V20, P806, DOI 10.1136/amiajnl-2013-001628
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Tan Songbo, 2009, P HUM LANG TECHN 200, V0, P181
   Tourille Julien, 2017, P 11 INT WORKSH SEM, V0, PP597, DOI 10.18653/v1/S17-2098
   Uzuner Ö, 2007, J AM MED INFORM ASSN, V14, P550, DOI 10.1197/jamia.M2444
   Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang Zhenghui, 2018, ARXIV180409021, V0, PP1, DOI 10.18653/V1/N18-1001
   Wang Zijie J, 2021, P 1 WORKSHOP BRIDGIN, V0, P47
   Wright D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7963
   Wu FZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1701, DOI 10.18653/v1/P17-1156
   Xing Junjie, 2018, P 27 INT C COMP LING, V0, P3619
   Yan Ming, 2020, P 58 ANN M ASS COMPU, V0, P7331
   Yang Haitong, 2015, T ASS COMPUTATIONAL, V3, P271, DOI 10.1162/tacl_a_00138
   Yang Y, 2015, P 2015 C N AM CHAPT, V0, P672
   Yang ZL, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1040, DOI 10.18653/v1/P17-1096
   Yin Wenpeng, 2015, P EMNLP, V0, P1329
   Yu Gu, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Zarrella G, 2016, PROC INT WORKSHOP SE, V0, P0
   Zhang Yuan, 2017, T ASSOC COMPUT LING, V5, P515, DOI 10.1162/TACL_A_00077
NR 100
TC 0
Z9 0
U1 0
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD SEP 7
PY 2022
VL 10
IS 
BP 956
EP 980
DI 10.1162/tacl_a_00500
PG 25
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9IZ
UT WOS:000923407900005
PM 36303892
DA 2023-11-10
ER

PT J
AU Almalki, J
AF Almalki, Jameel
TI A machine learning-based approach for sentiment analysis on distance learning from Arabic Tweets
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Social media; -Learning; Twitter; Apache Spark; Arabic language
ID social media
AB Social media platforms such as Twitter, YouTube, Instagram and Facebook are leading sources of large datasets nowadays. Twitter's data is one of the most reliable due to its privacy policy. Tweets have been used for sentiment analysis and to identify meaningful information within the dataset. Our study focused on the distance learning domain in Saudi Arabia by analyzing Arabic tweets about distance learning. This work proposes a model for analyzing people's feedback using a Twitter dataset in the distance learning domain. The proposed model is based on the Apache Spark product to manage the large dataset. The proposed model uses the Twitter API to get the tweets as raw data. These tweets were stored in the Apache Spark server. A regex-based technique for preprocessing removed retweets, links, hashtags, English words and numbers, usernames, and emojis from the dataset. After that, a Logistic-based Regression model was trained on the pre-processed data. This Logistic Regression model, from the field of machine learning, was used to predict the sentiment inside the tweets. Finally, a Flask application was built for sentiment analysis of the Arabic tweets. The proposed model gives better results when compared to various applied techniques. The proposed model is evaluated on test data to calculate Accuracy, F1 Score, Precision, and Recall, obtaining scores of 91%, 90%, 90%, and 89%, respectively.
C1 [Almalki, Jameel] Umm Al Qura Univ, Coll Comp Al Leith, Dept Comp Sci, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Almalki, J (通讯作者)，Umm Al Qura Univ, Coll Comp Al Leith, Dept Comp Sci, Mecca, Saudi Arabia.
EM jamalki@uqu.edu.sa
FU Deanship of Scientific Research at Umm Al-Qura University [22UQU4331100DSR01]
CR Adwan OY, 2020, INT J EMERG TECHNOL, V15, P79, DOI 10.3991/ijet.v15i15.14467
   Aljabri M, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21165431
   Aljameel SS, 2021, INT J ENV RES PUB HE, V18, P0, DOI 10.3390/ijerph18010218
   Althagafi A, 2021, INT J ADV COMPUT SC, V12, P620
   [Anonymous], 2016, 2016 7 INT C INF INT, V0, P0
   Appel G, 2020, J ACAD MARKET SCI, V48, P79, DOI 10.1007/s11747-019-00695-1
   Arambepola N, 2020, PROC INT C ADV COMPU, V0, P169
   Bhaumik Ujjayanta, 2021, COMPUTATIONAL INTELLIGENCE AND MACHINE LEARNING. PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, V0, P0
   Elzayady H, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), V0, PP171, DOI 10.1109/ICCES.2018.8639195
   Georgescu MR, 2019, IMPORTANCE OPPORTUNI, V4, P83
   Hasan RA, 2019, TELKOMNIKA, V17, P3086
   Kapoor KK, 2018, INFORM SYST FRONT, V20, P531, DOI 10.1007/s10796-017-9810-y
   Khalil R, 2020, BMC MED EDUC, V20, P0, DOI 10.1186/s12909-020-02208-z
   Khan ZF, 2020, INT J EMERG TECHNOL, V15, P4, DOI 10.3991/ijet.v15i09.12387
   Kharde Vishal A, 2016, INT J COMPUTER APPL, V139, P0
   Matar N, 2017, INT J EMERG TECHNOL, V12, P142, DOI 10.3991/ijet.v12i03.6497
   Nassif AB, 2021, APPL SOFT COMPUT, V98, P0, DOI 10.1016/j.asoc.2020.106836
   Osmanoglu UO, 2020, J ED TECHNOL ONLINE, V3, P31, DOI 10.31681/JETOL.663733
   Schneider SL, 2021, ARCH DERMATOL RES, V313, P389, DOI 10.1007/s00403-020-02088-9
   Yu YA, 2018, INT J EMERG TECHNOL, V13, P165, DOI 10.3991/ijet.v13i05.8440
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
NR 21
TC 1
Z9 1
U1 1
U2 4
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 26
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1047
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 3N6VW
UT WOS:000836285200001
PM 36092011
DA 2023-11-10
ER

PT J
AU Alhumoud, SO
   Al Wazrah, AA
AF Alhumoud, Sarah Omar
   Al Wazrah, Asma Ali
TI Arabic sentiment analysis using recurrent neural networks: a review
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Article
DE Sentiment analysis; Deep learning; Opinion mining; Sentiment classification; Arabic language; Recurrent neural network
AB Over the last decade, the amount of Arabic content created on websites and social media has grown significantly. Opinions are shared openly and freely on social media and thus provide a rich source for trend analyses, which are accomplished by conventional methods of language interpretation, such as sentiment analysis. Due to its accuracy in studying unstructured data, deep learning has been increasingly used to test opinions. Recurrent neural networks (RNNs) are a promising approach in textual analysis and exhibit large morphological variations. In total, 193 studies used RNNs in English-language sentiment analysis, and 24 studies used RNNs in Arabic-language sentiment analysis. Those studies varied in the areas they address, the functionality and weaknesses of the models, and the number and scale of the available datasets for different dialects. Such variations are worthy of attention and monitoring; thus, this paper presents a systematic examination of the literature to label, evaluate, and identify state-of-the-art studies using RNNs for Arabic sentiment analysis.
C1 [Alhumoud, Sarah Omar; Al Wazrah, Asma Ali] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU)
RP Al Wazrah, AA (通讯作者)，Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM sohumoud@imamu.edu.sa; aanalwazrah@sm.imamu.edu.sa
FU Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic University
CR Abbes M, 2017, LECT NOTES COMPUT SC, V10638, P667, DOI 10.1007/978-3-319-70139-4_68
   Abdulla NA, 2013, 2013 IEEE JORDAN CONFERENCE ON APPLIED ELECTRICAL ENGINEERING AND COMPUTING TECHNOLOGIES (AEECT), V0, P0
   Abdullah M, 2018, P 12 INT WORKSH SEM, V0, PP350, DOI 10.18653/V1/S18-1053
   Abdullah M, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP835, DOI 10.1109/ICMLA.2018.00134
   Ain QT, 2017, INT J ADV COMPUT SC, V8, P424
   Al-Azani S, 2018, PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON COMPUTING SCIENCES AND ENGINEERING (ICCSE), V0, P0
   Al-Azani S, 2017, LECT NOTES COMPUT SC, V10635, P491, DOI 10.1007/978-3-319-70096-0_51
   Al-Rfou R, 2013, P CONLL 2013 17 C CO, V0, P183
   Al-Smadi M, 2019, INT J MACH LEARN CYB, V10, P2163, DOI 10.1007/s13042-018-0799-4
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Al-Smadi M, 2016, INT CONF INTERNET, V0, PP98, DOI 10.1109/ICITST.2016.7856675
   Al-Twairesh N, 2017, PROCEDIA COMPUT SCI, V117, P63, DOI 10.1016/j.procs.2017.10.094
   Alayba AM, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP13, DOI 10.1109/ASAR.2018.8480191
   Alayba AM, 2018, LECT NOTES COMPUT SC, V11015, P179, DOI 10.1007/978-3-319-99740-7_12
   Alayba AM, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP114, DOI 10.1109/ASAR.2017.8067771
   Albadi N, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), V0, PP69, DOI 10.1109/ASONAM.2018.8508247
   Alhumoud S, 2015, 2015 7TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, V0, P402
   Alsayat A, 2020, EGYPT INFORM J, V21, P7, DOI 10.1016/j.eij.2019.06.001
   Altowayan AA, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), V0, PP3820, DOI 10.1109/BigData.2016.7841054
   Alwehaibi A, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP1471, DOI 10.1109/ICMLA.2018.00239
   Aly M, 2013, LABR LARGE SCALE AR, V0, P0, DOI DOI 10.13140/2.1.3960.5761
   [Anonymous], 2016, 10 INT WORKSHOP SEMA, V0, P0
   [Anonymous], 2018, P 2 WORKSHOP COMPUTA, V0, P0, DOI DOI 10.18653/V1/W18-1104
   [Anonymous], 2017, P 11 INT WORKSHOP SE, V0, P0
   Ayyadevara VK, 2018, PROMACHINE LEARNING, V0, P217
   Baccouche A, 2018, IEEE INT SYMP SIGNAL, V0, PP382, DOI 10.1109/ISSPIT.2018.8642685
   Badaro G, 2018, P 12 INT WORKSH SEM, V0, PP236, DOI 10.18653/V1/S18-1036
   Badaro G, 2014, P EMNLP 2014 WORKSHO, V0, P165
   Baly R, 2017, P 3 AR NAT LANG PROC, V0, P110
   Baly R, 2017, PROCEDIA COMPUT SCI, V117, P266, DOI 10.1016/j.procs.2017.10.118
   Banea C, 2010, P 23 INT C COMPUTATI, V0, P1
   Baniata LH, 2016, C P, V43, P470
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Brun C, 2016, P 10 INT WORKSH SEM, V0, P277
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Chung J, 2014, CORR, V0, P0
   Cliche M, 2017, P SEMEVAL, V0, PP573, DOI 10.18653/V1/S17-2094
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dahou A, 2016, P COLING 2016 26 INT, V0, P2418
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   DuaaAbu Elhija MD, 2016, 2 WORKSHOP ARABIC CO, V0, P29
   El-Khair IA, 2016, ARXIV, V0, P0
   El-Kilany A, 2018, INTELLIGENT NATURAL, V0, P3
   Elmadany AA, 2018, P 11 INT C LANG RES, V0, P0
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Elnagar A, 2018, PROCEDIA COMPUT SCI, V142, P182, DOI 10.1016/j.procs.2018.10.474
   Gines i Ametlle J, 1900, P210, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Habash NY, 2010, SYNTH LECT HUM LANG, V3, P1
   Heckman S, 2011, INFORM SOFTWARE TECH, V53, P363, DOI 10.1016/j.infsof.2010.12.007
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Hemmatian F, 2017, ARTIF INTELL REV, V0, P1
   Hermans M, 2013, P 26 INT C NEUR INF, V26, P190
   Irsoy O, 2014, P C EMP METH NAT LAN, V0, PP720, DOI 10.3115/V1/D14-1080
   Karpathy Andrej, 2015, UNREASONABLE EFFECTI, V21, P23
   Kemp S, 2018, DIGITAL 2018 ESSENTI, V0, P0
   Kim Y, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Kiritchenko S, 2016, P 10 INT WORKSHOP SE, V0, PP42, DOI 10.18653/v1/S16-1004
   Kitchenham Barbara, 2004, KEELE UK KEELE U, V0, P0, DOI DOI 10.5144/0256-4947.2017.79
   Korhonen A, 2017, P 6 JOINT C LEX COMP, V0, P22
   Kumar A, 2016, P 10 INT WORKSHOP SE, V0, P1129
   Kurva, 2018, COMPUTER SCI INFORM, V0, PP31, DOI 10.5121/CSIT.2018.81004
   Liu B, 2011, DATA CENTRIC SYST AP, V0, PP459, DOI 10.1007/978-3-642-19460-3_11
   MacAvaney S, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0221152
   Madhoushi Z, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), V0, PP288, DOI 10.1109/SAI.2015.7237157
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mohammad S, 2018, P 12 INT WORKSH SEM, V0, PP1, DOI 10.18653/V1/S18-1001
   Mohammad SM, 2016, J ARTIF INTELL RES, V55, P95, DOI 10.1613/jair.4787
   Mourad Ahmed, 2013, WASSA 2013, V0, P55
   Nabil M, 2015, P 2015 C EMP METH NA, V0, PP2515, DOI 10.18653/V1/D15-1299
   Najafabadi MM, 2015, J BIG DATA-GER, V2, P1, DOI 10.1186/s40537-014-0007-7
   Nakamura S, 2010, RECURRENT NEURAL NET, V0, P1045
   Oueslati O, 2020, FUTURE GENER COMP SY, V112, P408, DOI 10.1016/j.future.2020.05.034
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Pang B, 2008, FDN TRENDS R INFORM, V2, P1135, DOI 10.1561/9781601981516
   Pascanu R, 2013, P 30 INT C MACHINE L, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pontiki M, 2016, SEMEVAL 2016 TASK 5, V0, P0
   Pontiki M, 2016, P 10 INT WORKSH SEM, V0, PP19, DOI 10.18653/V1/S16-1002
   Rani S, 2019, ARTIF INTELL REV, V52, P1415, DOI 10.1007/s10462-018-9670-y
   Refaee E, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2268
   Reinsel D, 2018, 13 IDC, V0, P13
   Rohith, 2018, INT J PURE APPL MATH, V118, P365
   Rosenthal S, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/v1/S17-2088
   Ruder S, 2016, PROC C EMPIRICAL MET, V0, P999
   Ruder Sebastian, 2016, SEMEVAL 2016 10 INT, V0, PP330, DOI 10.18653/V1/S16-1053
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saleh IM, 2009, P MT SUMM OTT CAN, V0, P0
   Samy AE, 2018, PROCEDIA COMPUT SCI, V142, P61, DOI 10.1016/j.procs.2018.10.461
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shoukry A, 2012, 2012 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), V0, PP546, DOI 10.1109/CTS.2012.6261103
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Souri A, 2018, COMM COM INF SC, V872, P523, DOI 10.1007/978-3-319-96292-4_41
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tang D, 2015, EMNLP, V0, P0, DOI DOI 10.18653/v1/D15-1167
   Teraiya, 2013, J INF KNOWL RES COMP, V12, P313
   Turki Khemakhem I, 2010, P 4 WORKSH SYNT STRU, V0, P61
   Wang BL, 2018, AAAI CONF ARTIF INTE, V0, P5537
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yin W, 2017, COMP STUDY CNN RNN N, V0, P0
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 109
TC 16
Z9 16
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
EI 1573-7462
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD JAN 15
PY 2022
VL 55
IS 1
BP 707
EP 748
DI 10.1007/s10462-021-09989-9
EA APR 2021
PG 42
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YQ4FM
UT WOS:000641632200002
DA 2023-11-10
ER

PT J
AU Laban, P
   Schnabel, T
   Bennett, PN
   Hearst, MA
AF Laban, Philippe
   Schnabel, Tobias
   Bennett, Paul N. N.
   Hearst, Marti A. A.
TI SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB In the summarization domain, a key requirement for summaries is to be factually consistent with the input document. Previous work has found that natural language inference (NLI) models do not perform competitively when applied to inconsistency detection. In this work, we revisit the use of NLI for inconsistency detection, finding that past work suffered from a mismatch in input granularity between NLI datasets (sentence-level), and inconsistency detection (document level). We provide a highly effective and light-weight method called SummaC(Conv) that enables NLI models to be successfully used for this task by segmenting documents into sentence units and aggregating scores between pairs of sentences. We furthermore introduce a new benchmark called SummaC (Summary Consistency) which consists of six large inconsistency detection datasets. On this dataset, SummaC(Conv) obtains state-of-the-art results with a balanced accuracy of 74.4%, a 5% improvement compared with prior work.
C1 [Laban, Philippe; Hearst, Marti A. A.] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Schnabel, Tobias; Bennett, Paul N. N.] Microsoft, Redmond, WA USA.
C3 University of California System; University of California Berkeley; Microsoft
RP Laban, P (通讯作者)，Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM phillab@berkeley.edu; Tobias.Schnabel@microsoft.com; Paul.N.Bennett@microsoft.com; hearst@berkeley.edu
FU Microsoft BAIR Commons; Microsoft Azure Sponsorship
CR [Anonymous], 2010, P 2010 WORKSHOP CREA, V0, P0
   Arumae K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2566
   Bonferroni C, 1935, STUDI ONORE PROFESSO, V0, P13
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Brodersen Kay H, 2010, PROCEEDINGS OF THE 2010 20TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR 2010), V0, PP3121, DOI 10.1109/ICPR.2010.764
   Cachola I, 2020, EMNLP, V0, P4766
   Cao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6251
   Dong Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9320
   Durmus Esin, 2020, P 58 ANN M ASS COMP, V0, PP5055, DOI 10.18653/v1/2020.acl-main.454
   Efron B, 1982, JACKKNIFE BOOTSTRAP, V0, P0
   Etzioni O, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1409360.1409378
   Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373
   Falke T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2214
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Goodrich B, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP166, DOI 10.1145/3292500.3330955
   Goyal T, 2020, ARXIV, V0, P0
   Huang DD, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P446
   Kornilova A, 2019, P 2 WORKSH NEW FRONT, V0, PP48, DOI 10.18653/V1/D19-5406
   Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9332
   Laban Philippe, 2021, P 59 ANN M ASS COMP, V1, P6365
   Liu YH, 2019, ARXIV, V0, P0
   Mariana Valerie R, 2014, MULTIDIMENSIONAL QUA, V0, P0
   Matthew Honnibal, 2020, SPACY IND STRENGTH N, V0, P0, DOI DOI 10.18653/v1/2020.findings-emnlp.322
   Maynez J, 2020, ARXIV, V0, P0
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Nan F, 2021, ARXIV, V0, P0
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Nie YX, 2020, ARXIV, V0, P0
   Pagnoni Artidoro, 2021, NAACL, V0, P0
   Parikh A, 2016, PROC C EMPIR METHODS, V0, PP2249, DOI 10.18653/v1/D16-1244
   Pasunuru R, 2018, P C N AM CHAPT ASS C, V2, P646
   Schuster T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P624
   Scialom T, 2021, ARXIV, V0, P0
   Scialom T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3246
   Thorne J, 2018, LONG PAPERS, V0, PP809, DOI 10.18653/V1/N18-1074
   Vig J, 2021, ARXIV, V0, P0
   Williams A, 2018, P C N AM CHAPT ASS C, V1, P1112, DOI 10.18653/V1/N18-1101
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Zhang Jingqing, 2020, P INT C MACH LEARN, V0, PP11328, DOI 10.1038/S41746-021-00437-0
   Zhang Y, 2020, ACL, V0, PP5108, DOI 10.18653/V1/2020.ACL-MAIN.458
   Zhao Chen, 2019, INT C LEARNING REPRE, V0, P0
NR 42
TC 6
Z9 6
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD FEB 9
PY 2022
VL 10
IS 
BP 163
EP 177
DI 10.1162/tacl_a_00453
PG 15
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9NR
UT WOS:000923420100004
DA 2023-11-10
ER

PT J
AU Abadía-Heredia, R
   López-Martín, M
   Carro, B
   Arribas, JI
   Pérez, JM
   Le Clainche, S
AF Abadia-Heredia, R.
   Lopez-Martin, M.
   Carro, B.
   Arribas, J., I
   Perez, J. M.
   Le Clainche, S.
TI A predictive hybrid reduced order model based on proper orthogonal decomposition combined with deep learning architectures
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Reduced order models; Deep learning architectures; POD; Modal decompositions; Neural networks; Fluid dynamics
ID recurrent neural-networks; flow
AB Solving computational fluid dynamics problems requires using large computational resources. The computational time and memory requirements to solve realistic problems vary from a few hours to several weeks with several processors working in parallel. Motivated by the need of reducing such large amount of resources (improving the industrial applications in which fluid dynamics plays a key role), this article introduces a new predictive Reduced Order Model (ROM) applied to solve fluid dynamics problems. The model is based on physical principles and combines modal decompositions with deep learning architectures. The hybrid ROM, reduces the dimensionality of a database via proper orthogonal decomposition (POD), extracting the dominant features leading the flow dynamics of the problem studied. The number of degrees of freedom are reduced from hundred thousands spatial points describing the database to a few (20-100) POD modes. Firstly, POD divides the spatio-temporal data into spatial modes and temporal coefficients (or temporal modes). Next, the temporal coefficients are integrated in time using convolutional or recurrent neural networks. The temporal evolution of the flow is approximated after combining the spatial modes with the new temporal coefficients computed. The model is tested in two complex problems of fluid dynamics, the three-dimensional wake of a circular cylinder and a synthetic jet. The hybrid ROM uses data from the initial transient stage of numerical simulations to predict the temporally converged solution of the flow with high accuracy. The speed-up factor comparing the time necessary to obtain the predicted solution using the hybrid ROM and the numerical solver is similar to 140-348 in the synthetic jet and similar to 2897-3818 in the three dimensional cylinder wake. The robustness shown in the results presented and the data-driven nature of this ROM, make it possible to extend its application to other fields (i.e. video and language processing, robotics, finances).
C1 [Abadia-Heredia, R.; Perez, J. M.; Le Clainche, S.] Univ Politecn Madrid, ETSI Aeronaut & Espacio, Plaza Cardenal Cisneros 3, Madrid 28040, Spain.
   [Lopez-Martin, M.; Carro, B.; Arribas, J., I] Univ Valladolid, ETSIT, Paseo Belen 15, Valladolid 47011, Spain.
C3 Universidad Politecnica de Madrid; Universidad de Valladolid
RP Le Clainche, S (通讯作者)，Univ Politecn Madrid, ETSI Aeronaut & Espacio, Plaza Cardenal Cisneros 3, Madrid 28040, Spain.
EM sr.abadia@upm.es; manuel.lopezm@uva.es; belcar@tel.uva.es; jarribas@tel.uva.es; josemiguel.perez@upm.es; soledad.leclainche@upm.es
CR Abadia S, 2021, CODE PAPER PREDICTIV, V0, P0
   Abadia S, 2021, RES ING, V0, P0
   [Anonymous], 2016, UNITEXT, V0, P0
   Barkley D, 1996, J FLUID MECH, V322, P215, DOI 10.1017/S0022112096002777
   Blackburn HM, 1999, J FLUID MECH, V385, P255, DOI 10.1017/S0022112099004309
   Brandt L, 2021, J FLUID MECH, V0, P0
   Brunton SL, 2020, ANNU REV FLUID MECH, V52, P477, DOI 10.1146/annurev-fluid-010719-060214
   Brunton SL, 2015, APPL MECH REV, V67, P0, DOI 10.1115/1.4031175
   Cao WP, 2020, NEURAL COMPUT APPL, V32, P12685, DOI 10.1007/s00521-020-04719-8
   Cao WP, 2018, NEUROCOMPUTING, V275, P278, DOI 10.1016/j.neucom.2017.08.040
   Cater JE, 2002, J FLUID MECH, V472, P167, DOI 10.1017/S0022112002002264
   Cattafesta LN, 2011, ANNU REV FLUID MECH, V43, P247, DOI 10.1146/annurev-fluid-122109-160634
   Corrochano A, 2021, FLUIDS, V6, P0, DOI 10.3390/fluids6010004
   DEMONT ME, 1988, J EXP BIOL, V134, P347
   Discetti S, 2018, EXP THERM FLUID SCI, V93, P119, DOI 10.1016/j.expthermflusci.2017.12.011
   Ferrari Markus, 2006, CARDIOVASC ULTRASOUND, V4, P14, DOI 10.1186/1476-7120-4-14
   Fischer PF, 2008, NEK5000 WEB PAGE, V0, P0
   Freitag S, 2018, COMPUT STRUCT, V207, P258, DOI 10.1016/j.compstruc.2017.03.020
   Glezer A, 2002, ANNU REV FLUID MECH, V34, P503, DOI 10.1146/annurev.fluid.34.090501.094913
   Guastoni L, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Güemes A, 2019, PHYS FLUIDS, V31, P0, DOI 10.1063/1.5128053
   Guo MW, 2019, COMPUT METHOD APPL M, V345, P75, DOI 10.1016/j.cma.2018.10.029
   Iuliano E, 2013, COMPUT FLUIDS, V84, P327, DOI 10.1016/j.compfluid.2013.06.007
   JACKSON CP, 1987, J FLUID MECH, V182, P23, DOI 10.1017/S0022112087002234
   Jones BL, 2015, J FLUID MECH, V769, P687, DOI 10.1017/jfm.2015.84
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, P0, DOI 10.1016/j.ymssp.2020.107398
   Lassila T, 2014, MS A MOD SIMUL, V9, P235, DOI 10.1007/978-3-319-02090-7_9
   Le Clainche S, 2013, PRINCIPAL COMPONENT, V0, P239
   Le Clainche S, 2020, AEROSP SCI TECHNOL, V105, P0, DOI 10.1016/j.ast.2020.105920
   Le Clainche S, 2019, ENERGIES, V12, P0, DOI 10.3390/en12091635
   Le Clainche S, 2018, FLUID DYN RES, V50, P0, DOI 10.1088/1873-7005/aab2f1
   Le Clainche S, 2018, ENERGIES, V11, P0, DOI 10.3390/en11030566
   Le Clainche S, 2018, ENERGIES, V11, P0, DOI 10.3390/en11030543
   Le Clainche S, 2017, EXP THERM FLUID SCI, V88, P336, DOI 10.1016/j.expthermflusci.2017.06.011
   Lopez-Martin M, 2021, EXPERT SYST APPL, V177, P0, DOI 10.1016/j.eswa.2021.114924
   Luchtenburg D, 2009, 01 BERL I TECHN, V0, P0
   Lumley JL, 1967, ATMOSPHERIC TURBULEN, V0, P166
   Marusic I, 2003, SEMANTIC SCHOLAR, V0, P0
   Mendez MA, 2019, J FLUID MECH, V870, P988, DOI 10.1017/jfm.2019.212
   Muijres F, 2005, P PSFVIP 5, V0, P0
   Noack BR, 2011, CISM COURSES LECT, V528, P1, DOI 10.1007/978-3-7091-0758-4
   Omata N, 2019, AIP ADV, V9, P0, DOI 10.1063/1.5067313
   Pavlova A, 2006, J HEAT TRANS-T ASME, V128, P897, DOI 10.1115/1.2241889
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmid PJ, 2010, J FLUID MECH, V656, P5, DOI 10.1017/S0022112010001217
   Sharma A, 2011, INT J BIFURCAT CHAOS, V19, P1267
   SIROVICH L, 1987, Q APPL MATH, V45, P561, DOI 10.1090/qam/910462
   Wang H, 2001, AIAA J, V39, P2308, DOI 10.2514/2.1236
   Wang XZ, 2018, SOFT COMPUT, V22, P3473, DOI 10.1007/s00500-018-3203-0
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
NR 51
TC 19
Z9 19
U1 6
U2 15
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JAN 15
PY 2022
VL 187
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115910
EA OCT 2021
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA WK7OI
UT WOS:000709912400007
DA 2023-11-10
ER

PT J
AU Faris, H
   Habib, M
   Faris, M
   Alomari, A
   Castillo, PA
   Alomari, M
AF Faris, Hossam
   Habib, Maria
   Faris, Mohammad
   Alomari, Alaa
   Castillo, Pedro A.
   Alomari, Manal
TI Classification of Arabic healthcare questions based on word embeddings learned from massive consultations: a deep learning approach
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Altibbi; BiLSTM; Deep learning; Long short-term memory; LSTM; Medical question classification; Word2Vec
ID models
AB Automated question classification is a fundamental component of automated question-answering systems, which plays a critical role in promoting medical and healthcare services. Developing an automated question classification system depends heavily on natural language processing and data mining techniques. Question classification methods based on classical machine learning techniques face limitations in capturing the hidden relationships of features, as well as, handling complex languages and very large-scale datasets. Therefore, this paper proposes a deep learning approach for question classification, since deep learning methods have the powerful capability to extract implicit, hidden relationships and automatically generate dense representations of features. The proposed question classification model depends on unidirectional and bidirectional long short-term memory networks (LSTM and BiLSTM), which essentially developed to handle the Arabic language in the field of healthcare. The features are represented and created using a domain-specific word embedding model (Word2Vec) that is constructed by training around 1.5 million medical consultations from Altibbi company. Altibbi is a telemedicine company that is used as a case study and a source for curating and collecting the data. The proposed deep learning approach is a multi-class classification algorithm that automatically labels and maps the questions into 15 categories of medical specialities. The proposed deep learning model is evaluated using several evaluation metrics, including accuracy, precision, recall, and F1-score. Markedly, the proposed model achieved a superb classification capacity in terms of classification accuracy rate, which gained 87.2%.
C1 [Faris, Hossam] Univ Jordan, King Abdullah II Sch Informat Technol, Amman, Jordan.
   [Habib, Maria; Faris, Mohammad; Alomari, Alaa; Alomari, Manal] Altibbi, Amman, Jordan.
   [Castillo, Pedro A.] Univ Granada, CITIC, ETSIIT, Granada, Spain.
C3 University of Jordan; University of Granada
RP Castillo, PA (通讯作者)，Univ Granada, CITIC, ETSIIT, Granada, Spain.
EM hossam.faris@ju.edu.jo; maria.habib@altibbi.com; mohammad.faris@altibbi.com; alaa.alomari@altibbi.com; pacv@ugr.es; manal@altibbi.com
FU Ministerio espanol de Economia y Competitividad [TIN2017-85727-C4-2-P]
CR Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC, V0, P0
   Abdallah A, 2020, ARXIV200510416, V0, P0
   Agrawal S, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS FOR COMPUTING RESEARCH (ICAICR 19), V0, P0, DOI DOI 10.1145/3339311.3339341
   Ahmed W, 2017, INT J ADV RES COMPUT, V8, P1
   Akselrod-Ballin A, 2019, RADIOLOGY, V292, P331, DOI 10.1148/radiol.2019182622
   Aydogan M, 2020, PHYSICA A, V541, P0, DOI 10.1016/j.physa.2019.123288
   Banerjee I, 2019, ARTIF INTELL MED, V97, P79, DOI 10.1016/j.artmed.2018.11.004
   Chollet F, 2015, KERAS, V0, P0
   Dash S, 2020, DEEP LEARNING TECHNI, V0, P0
   Edara Deepak Chowdary, 2023, JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING, V0, PP5309, DOI 10.1007/s12652-019-01399-8
   Estrada S, 2020, MAGN RESON MED, V83, P1471, DOI 10.1002/mrm.28022
   FAES L, 2019, LANCET DIGIT HEALTH, V1, P0
   Faris H, 2020, J BIOMED INFORM, V109, P0, DOI 10.1016/j.jbi.2020.103525
   Gong JW, 2020, BR J GENER PRACT, V2020, P5
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hasan AM, 2018, INT C RELIABLE INFOR, V0, P278
   Huey-Ing Liu, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC), V0, PP341, DOI 10.1109/ICAIIC48513.2020.9065209
   Jain DK, 2020, NEURAL COMPUT APPL, V32, P1839, DOI 10.1007/s00521-019-04620-z
   Jun Liu, 2018, 2018 IEEE/ACIS 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS). PROCEEDINGS, V0, PP820, DOI 10.1109/ICIS.2018.8466463
   Kim J, 2020, NEUROCOMPUTING, V376, P214, DOI 10.1016/j.neucom.2019.10.033
   Kumar A, 2020, DEEP LEARNING TECHNI, V0, PP211, DOI 10.1007/978-3-030-33966-1_11
   Kwak GHJ, 2019, ARXIV190900384, V0, P0
   Lauritsen SM, 2020, ARTIF INTELL MED, V104, P0, DOI 10.1016/j.artmed.2020.101820
   Li Y, 2018, STUD BIG DATA, V26, P83, DOI 10.1007/978-3-319-53817-4_4
   Liu F, 2019, CLIN RES INFORM, V0, P357
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu J, 2019, J AMB INTEL HUM COMP, V0, PP1, DOI 10.1007/S12652-019-01344-9
   Longuenesse, 2012, PUBLIC HLTH ARAB WOR, V0, P0
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   Mairittha T, 2020, UBICOMP/ISWC 20 ADJUNCT: PROCEEDINGS OF THE 2020 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2020 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, V0, PP688, DOI 10.1145/3410530.3414436
   Mikolov T, 2013, P WORKSHOP ICLR, V0, P0
   Mulani J, 2020, DEEP LEARNING TECHNI, V0, P231
   Naili M, 2017, PROCEDIA COMPUT SCI, V112, P340, DOI 10.1016/j.procs.2017.08.009
   Nakua EK, 2015, BMC MUSCULOSKEL DIS, V16, P0, DOI 10.1186/s12891-015-0666-3
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Rawat BPS, 2020, ARXIV200506587, V0, P0
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Ren JT, 2020, INT J MED INFORM, V141, P0, DOI 10.1016/j.ijmedinf.2020.104225
   Romeo S, 2019, INFORM PROCESS MANAG, V56, P274, DOI 10.1016/j.ipm.2017.07.003
   Ryu JY, 2018, P NATL ACAD SCI USA, V115, PE4304, DOI 10.1073/pnas.1803294115
   Sammut C, 2010, TF IDF, V0, PP986, DOI 10.1007/978-0-387-30164-8_832
   Schmidt L, 2020, ARXIV200111268, V0, P0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shahzad A, 2019, J NANOMATER, V2019, P0, DOI 10.1155/2019/5168698
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Soltanolkotabi M, 2019, IEEE T INFORM THEORY, V65, P742, DOI 10.1109/TIT.2018.2854560
   Sparck-Jones K, 2004, J DOC, V60, P493, DOI 10.1108/00220410410560573
   Statista, 2020, WORLDS MOST SPOKEN L, V0, P0
   Vidhya K, 2020, J AMB INTEL HUM COMP, V2020, P1
   Vu MH, 2020, IEEE T MED IMAGING, V39, P2856, DOI 10.1109/TMI.2020.2978284
   Wang YS, 2019, BMC MED INFORM DECIS, V19, P0, DOI 10.1186/s12911-018-0723-6
   Worell, 2001, PUBLIC HLTH ARAB WOR, V0, P0
   Yegnanarayana B, 2009, ARTIFICIAL NEURAL NE, V0, P0
   Yilmaz S, 2020, NEURAL COMPUT APPL, V32, P2909, DOI 10.1007/s00521-020-04725-w
   Zhang LW, 2019, IEEE ACCESS, V7, P162415, DOI 10.1109/ACCESS.2019.2950985
   Zhang Q, 2018, LECT NOTES ARTIF INT, V11173, P519, DOI 10.1007/978-3-030-04015-4_44
   Zhou Z, 2019, IEEE ACCESS, V7, P108818, DOI 10.1109/ACCESS.2019.2933228
   Zhu Y, 2020, J BIOMED INFORM, V106, P0, DOI 10.1016/j.jbl.2020.103451
NR 58
TC 5
Z9 5
U1 1
U2 9
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD APR 15
PY 2022
VL 13
IS 4
BP 1811
EP 1827
DI 10.1007/s12652-021-02948-w
EA MAR 2021
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA ZZ5SG
UT WOS:000626421700001
DA 2023-11-10
ER

PT J
AU Chen, S
   Liao, H
AF Chen, Song
   Liao, Hai
TI BERT-Log: Anomaly Detection for System Logs Based on Pre-trained Language Model
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
AB Logs are primary information resource for fault diagnosis and anomaly detection in large-scale computer systems, but it is hard to classify anomalies from system logs. Recent studies focus on extracting semantic information from unstructured log messages and converting it into word vectors. Therefore, LSTM approach is more suitable for time series data. Word2Vec is the up-to-date encoding method, but the order of words in sequences is not taken into account. In this article, we propose BERT-Log, which regards the log sequence as a natural language sequence, use pre-trained language model to learn the semantic representation of normal and anomalous logs, and a fully connected neural network is utilized to fine-tune the BERT model to detect abnormal. It can capture all the semantic information from log sequence including context and position. It has achieved the highest performance among all the methods on HDFS dataset, with an F1-score of 99.3%. We propose a new log feature extractor on BGL dataset to obtain log sequence by sliding window including node ID, window size and step size. BERT-Log approach detects anomalies on BGL dataset with an F1-score of 99.4%. It gives 19% performance improvement compared to LogRobust and 7% performance improvement compared to HitAnomaly.
C1 [Chen, Song] Chengdu Technol Univ, Sch Comp Engn, Chengdu, Peoples R China.
   [Liao, Hai] Sichuan Vocat Coll Informat Technol, Sch Software, Guangyuan, Peoples R China.
C3 Chengdu Technological University
RP Liao, H (通讯作者)，Sichuan Vocat Coll Informat Technol, Sch Software, Guangyuan, Peoples R China.
EM iliaohai@qq.com
FU CDTU PHD FUND [2020RC002]
CR Aussel N, 2018, I S MOD ANAL SIM COM, V0, PP237, DOI 10.1109/MASCOTS.2018.00031
   Bretan P, 2017, PETROL GEOSCI, V23, P56, DOI 10.1144/petgeo2016-022
   Chen LJ, 2022, APPL INTELL, V52, P15193, DOI 10.1007/s10489-021-03075-x
   Cherkasova L, 2009, ACM T COMPUT SYST, V27, P0, DOI 10.1145/1629087.1629089
   Dai HT, 2022, IEEE T SOFTWARE ENG, V48, P879, DOI 10.1109/TSE.2020.3007554
   Devlin J, 2019, ARXIV, V0, P0
   Du M, 2017, CCS17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, V0, PP1285, DOI 10.1145/3133956.3134015
   Du M, 2016, IEEE DATA MINING, V0, PP859, DOI 10.1109/ICDM.2016.160
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo HX, 2021, IEEE IJCNN, V0, P0, DOI DOI 10.1109/IJCNN52387.2021.9534113
   He PJ, 2018, IEEE T DEPEND SECURE, V15, P931, DOI 10.1109/TDSC.2017.2762673
   He PJ, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), V0, PP33, DOI 10.1109/ICWS.2017.13
   He SL, 2016, PROC INT SYMP SOFTW, V0, PP207, DOI 10.1109/ISSRE.2016.21
   Hooshmand MK, 2022, CAAI T INTELL TECHNO, V7, P228, DOI 10.1049/cit2.12078
   Hu J, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3130908
   Huang SH, 2020, IEEE T NETW SERV MAN, V17, P2064, DOI 10.1109/TNSM.2020.3034647
   Ito K, 2018, LECT NOTES COMPUT SC, V11049, P143, DOI 10.1007/978-3-319-97916-8_10
   Jukic O, 2019, 2019 42ND INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, V0, P431, DOI 10.23919/MIPRO.2019.8757056
   Lee Y, 2021, ARXIV, V0, P0
   Liu CB, 2020, WIREL COMMUN MOB COM, V2020, P0, DOI 10.1155/2020/8827185
   Lou J, 2010, PROTEIN ENG DES SEL, V23, P311, DOI 10.1093/protein/gzq001
   Lv D, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21186125
   Maeyens J, 2020, ANN TELECOMMUN, V75, P563, DOI 10.1007/s12243-020-00809-9
   Makanju A, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P1255
   Mi HB, 2013, IEEE T PARALL DISTR, V24, P1245, DOI 10.1109/TPDS.2013.21
   Mi HB, 2012, SCI CHINA INFORM SCI, V55, P2757, DOI 10.1007/s11432-012-4747-8
   Oliner A, 2007, I C DEPEND SYS NETWO, V0, PP575, DOI 10.1109/DSN.2007.103
   Peng YQ, 2022, APPL INTELL, V52, P5867, DOI 10.1007/s10489-021-02724-5
   Do P, 2022, APPL INTELL, V52, P636, DOI 10.1007/s10489-021-02460-w
   Setia S, 2020, SCI PROGRAMMING-NETH, V2020, P0, DOI 10.1155/2020/8897244
   Studiawan H, 2021, IEEE T DEPEND SECURE, V18, P2136, DOI 10.1109/TDSC.2020.3037903
   Tang L, 2011, P 20 ACM INT C INF K, V0, PP785, DOI 10.1145/2063576.2063690
   Tufek A, 2023, CONCURR COMP-PRACT E, V35, P0, DOI 10.1002/cpe.6559
   Le VH, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, V0, PP492, DOI 10.1109/ASE51524.2021.9678773
   Vaswani A, 2017, NIPS 17, V0, P0
   Wang J, 2022, COMPUT SYST SCI ENG, V41, P1207, DOI 10.32604/csse.2022.022365
   Wittkopp T, 2021, ARXIV, V0, P0
   Xu W, 2009, SOSP09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, V0, P117
   Yen Ting-Fang, 2013, P 29 ANN COMP SEC AP, V0, P199
   Zhang L, 2019, LECT NOTES COMPUT SC, V11719, P123, DOI 10.1007/978-3-030-29611-7_10
   Zhang X, 2019, ESEC/FSE2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP807, DOI 10.1145/3338906.3338931
   Zhang YY, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P2525
   Zhao ZF, 2022, APPL INTELL, V52, P8810, DOI 10.1007/s10489-021-02863-9
   Zhong Y, 2018, ELECTRON LETT, V54, P1334, DOI 10.1049/el.2018.6079
   Zhu JM, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), V0, PP121, DOI 10.1109/ICSE-SEIP.2019.00021
   Zhu Y, 2021, ARXIV, V0, P0
NR 46
TC 3
Z9 3
U1 4
U2 19
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD DEC 31
PY 2022
VL 36
IS 1
BP 
EP 
DI 10.1080/08839514.2022.2145642
PG 23
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 6M9EY
UT WOS:000889166300001
DA 2023-11-10
ER

PT J
AU Kumari, S
   Singh, M
   Singh, R
   Tewari, H
AF Kumari, Swati
   Singh, Maninder
   Singh, Raman
   Tewari, Hitesh
TI Signature based Merkle Hash Multiplication algorithm to secure the communication in IoT devices
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE IoT devices; 6G wireless network; Hash based PQC; Karatsuba multiplication; Side channel attack; Mirai botnet attack
ID authentication scheme; networks; privacy; 6g; encryption; internet; edge
AB Great extent of modernization in intelligent device automation and wireless sensor network have encouraged the augmentation of IoTs to interconnect millions of actual devices to the Internet with the help of sensors, actuators and communication technologies. IoT devices with the potential of pervasive sensing and quantifying ability, it becomes an essential segment of the future Internet. The sixth generation (6G) enabled IoT networks are predicted to transform the data sharing and communication for a future of thorough brilliant and sovereign systems. However, secure communication in a sensor network is very difficult and is more amplified by the use of latest 6G IoT technology which is vulnerable to different kinds of attacks due to their limited security features. Existing security systems like RSA and Elliptic curve cryptography which is based on large integer factors and the discrete logarithmic problem is vulnerable to the attack which emerges from quantum computers. The computing capacity of a quantum computer is higher than classical computers. A 30-qubit quantum computer has the equivalent computing capacity as a traditional silicon-based computer computes at 10 teraflops per second. To secure the communication in the present and future IoT network, an enhanced Hash-based Post-Quantum Cryptography (PQC) architecture named Signature-based Merkle Hash Multiplication (SMHM) algorithm is proposed. In the proposed scheme, the Hash-based Merkle signature algorithm is enhanced using the Bernoulli Karatsuba Multiplication algorithm to secure the data storage and communication in IoT devices. The FPGA based proposed model is implemented in the Xilinx ISE14.5 simulator, both Hardware Descriptive Language (HDL) and High-Level Synthesis (HLS) approach is used to calculate the performance metrics which improved 33% frequency, 22% area, power consumption up to 13%, 10% error and 15% delay.(C) 2022 Elsevier B.V. All rights reserved.
C1 [Kumari, Swati; Singh, Maninder] Thapar Inst Engn & Technol, Patiala 147004, Punjab, India.
   [Singh, Raman] Univ West Scotland, Glasgow G72 0LH, Scotland.
   [Tewari, Hitesh] Trinity Coll Dublin, Dublin, Ireland.
C3 Thapar Institute of Engineering & Technology; Trinity College Dublin
RP Kumari, S (通讯作者)，Thapar Inst Engn & Technol, Patiala 147004, Punjab, India.
EM swati.kumari@thapar.edu; msingh@thapar.edu; raman.singh@uws.ac.uk; htewari@cs.tcd.ie
CR Ahmed Z, 2019, IEEE INT WORKSH COMP, V0, P0, DOI DOI 10.1109/SCCS.2019.8852596
   [Anonymous], 2016, 2016 IEEE ASIAN HARD, V0, P0, DOI DOI 10.1109/ASIANHOST.2016.7835555
   Arshak Khalil, 2007, 2007 IEEE DES DIAGN, V0, P1
   Becker G, 2008, 12 RUHR U BOCH, V0, P19
   Bernstein DJ, 2016, IACR CRYPTOL EPRINT, V2016, P461
   Buchmann J, 2009, POSTQUANTUM CRYPTOGR, V0, PP35, DOI 10.1007/978-3-540-88702-7_3
   Buchmann J, 2011, LECT NOTES COMPUT SC, V7071, P117, DOI 10.1007/978-3-642-25405-5_8
   Cao J, 2019, IEEE INTERNET THINGS, V6, P9794, DOI 10.1109/JIOT.2019.2931724
   Casanova Antoine, 2017, THESIS UPMC INRIA RE, V0, P0
   Chowdhury S, 2021, ARXIV, V0, P0
   Ducas L, 2019, CRYSTALS DILITHIUM A, V0, P0
   Ebrahimi S, 2019, IEEE INTERNET THINGS, V6, P5500, DOI 10.1109/JIOT.2019.2903082
   Göpfert F, 2017, LECT NOTES COMPUT SC, V10346, P184, DOI 10.1007/978-3-319-59879-6_11
   Gui G, 2020, IEEE WIREL COMMUN, V27, P126, DOI 10.1109/MWC.001.1900516
   Imran M, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9111953
   Jiang Q, 2016, J NETW COMPUT APPL, V76, P37, DOI 10.1016/j.jnca.2016.10.001
   Jin BW, 2019, WIRELESS PERS COMMUN, V105, P599, DOI 10.1007/s11277-018-6083-9
   Karthikeyan S, 2019, RECENT TRENDS IN COMMUNICATION, V0, P0
   Kocher PC, 1996, ADVANCES IN CRYPTOLOGY - CRYPTO96. 16TH ANNUAL INTERNATIONAL CRYPTOLOGY CONFERENCE. PROCEEDINGS, V0, P104
   Kumar S, 2021, WIRELESS PERSON COMM, V0, P1
   Kumar S, 2022, ADV MATER PROCESS TE, V8, P2329, DOI 10.1080/2374068X.2021.1912527
   Kumari Prity, 2019, INNOVATIONS SOFT COM, V0, P69
   Lee J, 2019, IEEE ACCESS, V7, P2080, DOI 10.1109/ACCESS.2018.2884084
   Li X, 2018, J NETW COMPUT APPL, V103, P194, DOI 10.1016/j.jnca.2017.07.001
   Li ZP, 2020, J AMB INTEL HUM COMP, V11, P3337, DOI 10.1007/s12652-019-01529-2
   Lieman D, 2001, IEEE P1363, V1, P0
   Liu Z, 2018, IEEE COMMUN MAG, V56, P158, DOI 10.1109/MCOM.2018.1700330
   Mabodi K, 2020, J SUPERCOMPUT, V76, P7081, DOI 10.1007/s11227-019-03137-5
   Malina L, 2021, IEEE ACCESS, V9, P36038, DOI 10.1109/ACCESS.2021.3062201
   Merkle RC, 2019, SECURE COMMUNICATION, V0, P73
   MERKLE RC, 1990, LECT NOTES COMPUT SC, V435, P218, DOI 10.1007/0-387-34805-0_21
   Mousavi SK, 2021, J AMB INTEL HUM COMP, V12, P2033, DOI 10.1007/s12652-020-02303-5
   Mujtaba G, 2019, WIRELESS PERS COMMUN, V106, P2023, DOI 10.1007/s11277-018-5920-1
   Nesa Nashreen, 2020, ADVANCED COMPUTING AND SYSTEMS FOR SECURITY. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 996), V0, PP3, DOI 10.1007/978-981-13-8969-6_1
   Peikert C, 2019, LECT NOTES COMPUT SC, V11891, P1, DOI 10.1007/978-3-030-36030-6_1
   Ren X, 2021, IEEE INTERNET THINGS, V0, P0, DOI DOI 10.1109/JIOT.2021.3064468
   Rogaway P, 2004, LECT NOTES COMPUT SC, V3017, P371
   Salarifard R, 2018, IEEE T CIRCUITS-I, V65, P2869, DOI 10.1109/TCSI.2018.2801118
   Sattiraju R, 2019, ARXIV, V0, P0
   Shor PW, 1999, SIAM REV, V41, P303, DOI 10.1137/S0036144598347011
   Soleymani SA, 2022, IEEE T IND INFORM, V18, P4902, DOI 10.1109/TII.2021.3121505
   Suárez-Albela M, 2018, 2018 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS), V0, P246
   Nguyen VL, 2021, IEEE COMMUN SURV TUT, V23, P2384, DOI 10.1109/COMST.2021.3108618
   Vignesh RS, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON ENVIRONMENTAL AND COMPUTER SCIENCE, V0, PP333, DOI 10.1109/ICECS.2009.21
   Wang MH, 2020, DIGIT COMMUN NETW, V6, P281, DOI 10.1016/j.dcan.2020.07.003
   Zhang ZQ, 2019, IEEE VEH TECHNOL MAG, V14, P28, DOI 10.1109/MVT.2019.2921208
NR 46
TC 2
Z9 2
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD OCT 11
PY 2022
VL 253
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.109543
EA AUG 2022
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4Y0EQ
UT WOS:000861208200009
DA 2023-11-10
ER

PT J
AU Song, R
   Giunchiglia, F
   Zhao, K
   Tian, MJ
   Xu, H
AF Song, Rui
   Giunchiglia, Fausto
   Zhao, Ke
   Tian, Mingjie
   Xu, Hao
TI Graph topology enhancement for text classification
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Text classification; Graph neural networks; Topological features; Feature enhancement
AB Graph neural networks (GNNs) can deal with complex network structures and model complex syntax structures in natural languages, which makes GNN outstanding in text classification tasks. However, most graph neural network approaches don't seem to take full advantage of the topological gains from document graphs. In this paper, we propose a topologically enhanced text classification method to make full use of the structural features of corpus graph and sentence graph. Specifically, we construct two different graphs based on contextual information, called sentence graphs and corpus graphs, respectively. We extract the topological features of words from the corpus graph and inject them into the graph neural network model based on sentence graph classification. To better integrate the topological features, we propose an asynchronous weighted propagation scheme, which selectively fuses the topological features with the original features of the word nodes, and integrate document features to predict final results. A large number of experiments on eight datasets demonstrate the effectiveness of our method.
C1 [Song, Rui; Giunchiglia, Fausto; Tian, Mingjie] Jilin Univ, Sch Artificial Intelligence, Changchun 130012, Peoples R China.
   [Giunchiglia, Fausto] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
   [Zhao, Ke] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
   [Xu, Hao] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Xu, Hao] Jilin Univ, Minist Educ, Key Lab Symbol Comp & Knowledge Engn, Changchun 130012, Peoples R China.
C3 Jilin University; University of Trento; Jilin University; Jilin University; Jilin University
RP Xu, H (通讯作者)，Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Xu, H (通讯作者)，Jilin Univ, Minist Educ, Key Lab Symbol Comp & Knowledge Engn, Changchun 130012, Peoples R China.
EM songrui20@mails.jlu.edu.cn; fausto@disi.unitn.it; zhaoke19@mails.jlu.edu.cn; mjtian19@mails.jlu.edu.cn; xuhao@jlu.edu.cn
FU National Natural Science Foundation of China [62077027]; Ministry of Science and Technology of the People's Republic of China [2018YFC2002500]; Jilin Province Development and Reform Commission, China [2019C053-1]; Education Department of Jilin Province, China [JJKH20200993K]; Department of Science and Technology of Jilin Province, China [20200801002GH]; European Union [823783]
CR Aggarwal Charu C, 2012, MINING TEXT DATA, V0, P0, DOI DOI 10.1007/978-1-4614-3223-4_6
   [Anonymous], 2017, P 2017 C EMPIRICAL M, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/tacl_a_00104
   Dyer C, 2015, INT WORKSH ACL2 THEO, V0, P0
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Garg S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6174
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Grover A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP855, DOI 10.1145/2939672.2939754
   Hu LM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4821
   Huang LZ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3444
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Kingma DP, 2014, C TRACK P, V0, P0
   Kipf NT, 2016, VARIATIONAL GRAPH AU, V0, P0
   Kipf TN, 2016, P INT C LEARNING REP, V0, P0
   Li WY, 2014, EXPERT SYST APPL, V41, P1742, DOI 10.1016/j.eswa.2013.08.073
   Li Y, 2015, 4 INT C LEARNING REP, V0, P0
   Liu X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1247
   Liu XE, 2020, AAAI CONF ARTIF INTE, V34, P8409
   Marcheggiani D, 2018, P 2018 M N AM CHAPTE, V2, P486, DOI 1804.08313
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Niepert M, 2012, ICML, V0, P2014
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1063, DOI 10.1145/3178876.3186005
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Phan X-H, 2008, P 17 INT C WORLD WID, V0, P91
   Ribeiro LFR, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP385, DOI 10.1145/3097983.3098061
   Rios Anthony, 2015, ACM BCB, V2015, P258, DOI 10.1145/2808719.2808746
   Roy A, 2019, TOPOLOGICAL BASED CL, V0, P0
   Ryabinin M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7317
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shen DH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P440
   Shuheng L, 2019, RECURSIVE GRAPHICAL, V0, P0
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Tang J, 2015, ACM KNOWLEDGE DISCOV, V0, P0
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), V0, PP1067, DOI 10.1145/2736277.2741093
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ARXIV, V30, P5998
   Velickovic Petar, 2018, ICLR, V0, P0
   Wallach HM, 2006, P 23 INT C MACH LEAR, V23, P977, DOI 10.1145/1143844.1143967
   Wang S, 2012, P 50 ANN M ASS COMP, V2, P90, DOI 10.5555/2390665.2390688
   Wei P, 2020, SHORT TEXT CLASSIFIC, V0, P0
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yao L, 2019, AAAI CONF ARTIF INTE, V0, P7370
   Zhang Xiang, 2015, NEURIPS, V0, P0, DOI DOI 10.5555/2969239.2969312
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P317
   Zhang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P334
   Zhibin Lu, 2020, ADVANCES IN INFORMATION RETRIEVAL, V0, P0
   Zhou HF, 2021, APPL INTELL, V51, P3255, DOI 10.1007/s10489-020-01937-4
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 53
TC 1
Z9 1
U1 7
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD OCT 15
PY 2022
VL 52
IS 13
BP 15091
EP 15104
DI 10.1007/s10489-021-03113-8
EA MAR 2022
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5C1NG
UT WOS:000767741700008
DA 2023-11-10
ER

PT J
AU Lyu, SF
   Cheng, J
   Wu, XY
   Cui, LZ
   Chen, HH
   Miao, CY
AF Lyu, Shengfei
   Cheng, Jin
   Wu, Xingyu
   Cui, Lizhen
   Chen, Huanhuan
   Miao, Chunyan
TI Auxiliary Learning for Relation Extraction
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
LA English
DT Article
DE Auxiliary learning; dependency-based; neural networks; pretrained language models; relation extraction; sequence-based
ID classification
AB Relation extraction aims to predict a semantic relation between entities in a sentence, which is usually regarded as a classification problem. However, due to the limited relation set, many semantic relations are labeled as a special artificial relation type, termed no_relation, if they are beyond the predefined relation set. Existing methods treat this artificial relation type no_ relation as a common semantic relation without taking its rich semantics into account. In this paper, a novel auxiliary learning method is proposed to excavate the semantic information of no_relation, resulting in the improvement of generalization performance. The auxiliary learning method focuses on the model learning phase and introduces a binary classification task that treats the artificial relation type no_relation as negative class and the rest semantic types as positive class. The binary classification task, named auxiliary learning task, pays more attention to no_relation with a cost-sensitive loss by assigning higher cost on the misclassification of negative samples than positive ones. An additional reward is provided to the main prediction task by the auxiliary learning task, which leads to a better representation for relation extraction. Significant improvements are consistently achieved when state-of-the-art models are equipped with the auxiliary learning task on SemEval-2010 Task 8 and the large-scale TACRED. Especially, new state-of-the-art performance is achieved on SemEval-2010 Task 8 by the proposed method. Meanwhile, the motivation for introducing the auxiliary learning method is further reinforced by extensive experiments.
C1 [Lyu, Shengfei; Cheng, Jin; Wu, Xingyu; Chen, Huanhuan] Univ Sci & Technol China USTC, Sch Comp Sci & Technol, Hefei 230027, Peoples R China.
   [Cui, Lizhen] Shandong Univ SDU, Sch Software, Jinan 250101, Shandong, Peoples R China.
   [Miao, Chunyan] Nanyang Technol Univ NTU, Sch Comp Sci & Engn, Nanyang Ave, Singapore 639798, Singapore.
C3 Chinese Academy of Sciences; University of Science & Technology of China, CAS; Shandong University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Chen, HH (通讯作者)，Univ Sci & Technol China USTC, Sch Comp Sci & Technol, Hefei 230027, Peoples R China.
EM saintfe@mail.ustc.edu.cn; shura@mail.ustc.edu.cn; xingyuwu@mail.ustc.edu.cn; clz@sdu.edu.cn; hchen@ustc.edu.cn; ascymiao@ntu.edu.sg
FU National Key Research and Development Program of China [2016YFB1000905]; National Natural Science Foundation of China [91746209, 91846205]; Innovation Method Fund of China [2018IM020200]; Shandong Key RD Program [2018YFJH0506, 2019JZZY011007]; SDNFSC [ZR2019LZH008]
CR [Anonymous], 2010, 5 INT WORKSH SEM EV, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Bunescu RC, 2005, PROC ADV NEURAL INF, V0, P171
   Bunescu RC, 2005, P C HUM LANG TECHN E, V0, PP724, DOI 10.3115/1220575.1220666
   Chen HH, 2009, IEEE T NEURAL NETWOR, V20, P901, DOI 10.1109/TNN.2009.2014161
   Daojian Zeng, 2014, P COLING 25 INT C CO, V0, P2335
   Devlin J, 2018, ARXIV, V1, P4171
   dos Santos CN, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P626
   Guo ZJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P241
   Jaderberg M, 2017, ICLR, V0, P0
   Jiang BB, 2018, IEEE T NEUR NET LEAR, V29, P5643, DOI 10.1109/TNNLS.2018.2808332
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kipf T N, 2016, ICLR, V0, P0
   Li SH, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P666
   Liu DYH, 2019, IEEE TETCI, V3, P313, DOI 10.1109/TETCI.2018.2870125
   Lyu SF, 2020, 11TH IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG 2020), V0, PP313, DOI 10.1109/ICBK50248.2020.00052
   Lyu SF, 2020, IEEE T NEUR NET LEAR, V31, P3906, DOI 10.1109/TNNLS.2019.2947309
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mintz M, 2009, P JOINT C 47 ANN M A, V0, PP1003, DOI 10.3115/1690219.1690287
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Nakov Preslav, 2010, P 5 INT WORKSH SEM E, V0, P33
   Nguyen TH, 2015, P 1 WORKSH VECT SPAC, V0, PP39, DOI 10.3115/V1/W15-1506
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P43
   Qian Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4293
   Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2895
   Socher R, 2011, P 28 INT C MACHINE L, V0, P129
   Su J, 2015, EMNLP, V0, P536
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Valada A, 2018, IEEE INT CONF ROBOT, V0, PP6939, DOI 10.1109/ICRA.2018.8462979
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang HY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1371
   Wang LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1298
   Wu SC, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2361, DOI 10.1145/3357384.3358119
   Wu XD, 2017, IEEE ACCESS, V5, P12696, DOI 10.1109/ACCESS.2017.2710298
   Wu XD, 2015, IEEE INTELL SYST, V30, P46, DOI 10.1109/MIS.2015.56
   Xu Y, 2015, P 2015 C EMP METH NA, V0, PP1785, DOI 10.18653/V1/D15-1206
   Yao YQ, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1408, DOI 10.1145/3292500.3330904
   Yu BW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5401
   Zelenko D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, P71
   Zhang C, 2018, MACH LEARN, V107, P727, DOI 10.1007/s10994-017-5676-y
   Zhang Y, 2017, P 2017 C EMPIRICAL M, V0, P35
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2205
   Zhao XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2377, DOI 10.1145/3366423.3380301
NR 44
TC 7
Z9 7
U1 3
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2471-285X
EI 
J9 IEEE TETCI
JI IEEE Trans. Emerg. Top. Comput. Intell.
PD FEB 15
PY 2022
VL 6
IS 1
BP 182
EP 191
DI 10.1109/TETCI.2020.3040444
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YK9GM
UT WOS:000745512200021
DA 2023-11-10
ER

PT J
AU Ramesh, G
   Doddapaneni, S
   Bheemaraj, A
   Jobanputra, M
   Raghavan, AK
   Sharma, A
   Sahoo, S
   Diddee, H
   Mahalakshmi, J
   Kakwani, D
   Kumar, N
   Pradeep, A
   Nagaraj, S
   Deepak, K
   Raghavan, V
   Kunchukuttan, A
   Kumar, P
   Khapra, MS
AF Ramesh, Gowtham
   Doddapaneni, Sumanth
   Bheemaraj, Aravinth
   Jobanputra, Mayank
   Raghavan, A. K.
   Sharma, Ajitesh
   Sahoo, Sujit
   Diddee, Harshita
   Mahalakshmi, J.
   Kakwani, Divyanshu
   Kumar, Navneet
   Pradeep, Aswin
   Nagaraj, Srihari
   Deepak, Kumar
   Raghavan, Vivek
   Kunchukuttan, Anoop
   Kumar, Pratyush
   Khapra, Mitesh Shantadevi
TI <i>Samanantar</i>: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB We present Samanantar, the largest publicly available parallel corpora collection for Indic languages. The collection contains a total of 49.7 million sentence pairs between English and 11 Indic languages (from two language families). Specifically, we compile 12.4 million sentence pairs from existing, publicly available parallel corpora, and additionally mine 37.4 million sentence pairs from the Web, resulting in a 4x increase. We mine the parallel sentences from the Web by combining many corpora, tools, and methods: (a) Web-crawled monolingual corpora, (b) document OCR for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. Human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages. Further, we extract 83.4 million sentence pairs between all 55 Indic language pairs from the English-centric parallel corpus using English as the pivot language. We trained multilingual NMT models spanning all these languages on Samanantar which outperform existing models and baselines on publicly available benchmarks, such as FLORES, establishing the utility of Samanantar. Our data and models are available publicly at and we hope they will help advance research in NMT and multilingual NLP for Indic languages.
C1 [Ramesh, Gowtham; Doddapaneni, Sumanth; Kumar, Pratyush; Khapra, Mitesh Shantadevi] RBCDSAI, Chennai, India.
   [Bheemaraj, Aravinth; Sharma, Ajitesh; Sahoo, Sujit; Kumar, Navneet; Pradeep, Aswin; Nagaraj, Srihari; Deepak, Kumar] Tarento Technol, Bengaluru, India.
   [Jobanputra, Mayank; Kakwani, Divyanshu; Kumar, Pratyush; Khapra, Mitesh Shantadevi] IIT Madras, Chennai, India.
   [Raghavan, A. K.; Diddee, Harshita; Mahalakshmi, J.; Kakwani, Divyanshu; Kunchukuttan, Anoop; Kumar, Pratyush; Khapra, Mitesh Shantadevi] AI4Bharat, Chennai, India.
   [Bheemaraj, Aravinth; Sharma, Ajitesh; Sahoo, Sujit; Kumar, Navneet; Pradeep, Aswin; Nagaraj, Srihari; Deepak, Kumar; Raghavan, Vivek] EkStep Fdn, Bengaluru, India.
   [Kunchukuttan, Anoop] Microsoft, New Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras
RP Khapra, MS (通讯作者)，RBCDSAI, Chennai, India.; Khapra, MS (通讯作者)，IIT Madras, Chennai, India.; Khapra, MS (通讯作者)，AI4Bharat, Chennai, India.
EM miteshk@cse.iitm.ac.in
FU Robert Bosch Center for Data Science and Artificial Intelligence; Google
CR Agic E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3204
   Agirre E, 2016, P 10 INT WORKSH SEM, V0, PP497, DOI 10.18653/V1/S16-1081
   Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874
   [Anonymous], 2016, P C N AM CHAPT ASS C, V0, P0
   Anoop, 2020, INDICNLP LIB, V0, P0
   Anoop, 2018, IIT BOMBAY ENGLISH H, V0, P0
   Antonios, 2020, TICO 19 TRANSLATION, V0, P0
   Anvita Abbi, 2012, LANGUAGES INDIA INDI, V0, P0
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Bahdanau D, 2015, P 3 INT C LEARN REPR, V0, P0
   Barrault L, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P1
   Barro L, 2021, PLATELETS, V32, P153, DOI 10.1080/09537104.2020.1849602
   Barry, 2020, PMINDIA COLLECTION P, V0, P0
   Bengio Yoshua, 2009, P INT C MACH LEARN, V0, P0, DOI DOI 10.1145/1553374.1553380
   Bojar Ondrej, 2014, P 9 WORKSH STAT MACH, V0, PP12, DOI 10.3115/V1/W14-3302
   Christodouloupoulos C, 2015, LANG RESOUR EVAL, V49, P375, DOI 10.1007/s10579-014-9287-y
   Dabre Raj, 2017, P 31 PAC AS C LANG I, V0, P282
   El-Kishky A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5960
   EMENEAU MB, 1956, LANGUAGE, V32, P3, DOI 10.2307/410649
   Fangxiaoyu Feng, 2020, LANGUAGE AGNOSTIC BE, V0, P0
   Freitag M, 2020, P 5 C MACH TRANSL, V0, P550
   Gonzales AR, 2020, P 5 C MACHINE TRANSL, V0, P528
   Goyal N, 2021, ARXIV, V0, P0
   Goyal Vikrant, 2020, P 5 C MACHINE TRANSL, V0, P202
   Guo RQ, 2020, PR MACH LEARN RES, V119, P0
   Guzmán F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6098
   Holger, 2019, WIKIMATRIX MINING 13, V0, P0
   Holger, 2020, CCMATRIX MINING BILL, V0, P0, DOI DOI 10.18653/v1/2021.acl-long.507
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Johnson J, 2017, ARXIV, V0, P0
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Junczys-Dowmunt M, 2018, P 3 C MACHINE TRANSL, V0, P888
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, V0, P4948
   Kocmi T, 2018, P 3 C MACH TRANSL RE, V0, PP244, DOI 10.18653/V1/W18-6325
   Koehn P, 2017, WMT, V0, P28
   Kreutzer J, 2022, ARXIV, V0, P0
   Linting, 2021, MT5 MASSIVELY MULTIL, V0, P0
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P923
   Loganathan, 2012, P WORKSHOP MACHINE T, V0, P113
   Nakaike T, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (IEEE ICBC), V0, P0, DOI DOI 10.1109/icbc48266.2020.9169454
   Nakazawa T, 2021, WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION, V0, P1
   Naveen Arivazhagan, 2019, MASSIVELY MULTILINGU, V0, P0
   Nguyen Toan Q, 2017, INT JOINT C NATURAL, V0, P0
   Ortiz Suarez PJ, 2019, P WORKSHOP CHALLENGE, V0, P0, DOI DOI 10.14618/IDS-PUB-9021
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Parida Shantipriya, 2020, P WILDRE5 5 WORKSHOP, V0, P14
   Philip J, 2021, CODS-COMAD 2021: PROCEEDINGS OF THE 3RD ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA (8TH ACM IKDD CODS & 26TH COMAD), V0, PP178, DOI 10.1145/3430984.3431026
   Post M, 2012, P 7 WORKSHOP STAT MA, V0, P401
   Reimers N, 2020, ARXIV, V0, P0
   Riza Hammam, 2016, 2016 CONFERENCE OF THE ORIENTAL CHAPTER OF INTERNATIONAL COMMITTEE FOR COORDINATION AND STANDARDIZATION OF SPEECH DATABASES AND ASSESSMENT TECHNIQUES (O-COCOSDA), V0, PP1, DOI 10.1109/ICSDA.2016.7918974
   Schwenk H, 2020, ARXIV, V0, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Sennrich Rico, 2011, P 18 NORDIC C COMPUT, V0, P175
   Shah P, 2019, 2 INT C ADV COMP COM, V0, P1
   Subbarao Karumuri V, 2012, S ASIAN LANGUAGES SY, V0, P263
   Subramanya SJ, 2019, ADV NEUR IN, V32, P0
   Tahmid, 2020, NOT LOW RESOURCE ANY, V0, P0, DOI DOI 10.18653/v1/2020.emnlp-main.207
   Tan X, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P963
   Thompson B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1342
   Tiedemann J, 2020, P 22 ANN CONFERENEC, V0, P0
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2214
   Vaswani A, 2017, ARXIV, V30, P5998
   Wu YH, 2016, ARXIV, V0, P0
   Yuqing, 2020, MULTILINGUAL TRANSLA, V0, P0
NR 65
TC 15
Z9 15
U1 1
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD FEB 9
PY 2022
VL 10
IS 
BP 145
EP 162
DI 10.1162/tacl_a_00452
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9NR
UT WOS:000923420100003
DA 2023-11-10
ER

PT J
AU Guo, Q
   Cao, S
   Yi, Z
AF Guo, Quan
   Cao, Shuai
   Yi, Zhang
TI A medical question answering system using large language models and knowledge graphs
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE knowledge graph; medical question answering; named entity recognition; pretrained language model; Siamese network
ID extraction; ontology
AB Question answering systems have become prominent in all areas, while in the medical domain it has been challenging because of the abundant domain knowledge. Retrieval based approach has become promising as large pretrained language models come forth. This study focuses on building a retrieval-based medical question answering system, tackling the challenge with large language models and knowledge extensions via graphs. We first retrieve an extensive but coarse set of answers via Elasticsearch efficiently. Then, we utilize semantic matching with pretrained language models to achieve a fine-grained ranking enhanced with named entity recognition and knowledge graphs to exploit the relation of the entities in question and answer. A new architecture based on siamese structures for answer selection is proposed. To evaluate the approach, we train and test the model on two Chinese data sets, NLPCC2017 and cMedQA. We also conduct experiments on two English data sets, TREC-QA and WikiQA. Our model achieves consistent improvement as compared to strong baselines on all data sets. Qualification studies with cMedQA and our in-house data set show that our system gains highly competitive performance. The proposed medical question answering system outperforms baseline models and systems in quantification and qualification evaluations.
C1 [Guo, Quan; Cao, Shuai; Yi, Zhang] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Yi, Z (通讯作者)，Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Sichuan, Peoples R China.
EM zhangyi@scu.edu.cn
FU National Key Research and Development Program of China [2018AAA0100201]
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bekoulis G, 2018, EXPERT SYST APPL, V114, P34, DOI 10.1016/j.eswa.2018.07.032
   Ben Abacha A, 2015, INFORM PROCESS MANAG, V51, P570, DOI 10.1016/j.ipm.2015.04.006
   Bian WJ, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP1987, DOI 10.1145/3132847.3133089
   Buscaldi D, 2010, J INTELL INF SYST, V34, P113, DOI 10.1007/s10844-009-0082-y
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chopra S, 2005, PROC CVPR IEEE, V0, PP539, DOI 10.1109/cvpr.2005.202
   Dai Z, 2019, 2019 12 INT C IM SIG, V0, PP1, DOI 10.1109/CISP-BMEI48845.2019.8965823
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gribova V, 2021, INT J INTELL SYST, V36, P291, DOI 10.1002/int.22300
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo QL, 2010, INT J INTELL SYST, V25, P655, DOI 10.1002/int.20417
   He H, 2015, P 2015 C EMP METH NA, V0, PP1576, DOI 10.18653/V1/D15-1181
   He T, 2020, INT J INTELL SYST, V35, P1375, DOI 10.1002/int.22257
   Huang Z, 2015, BIDIRECTIONAL LSTM C, V34, P01991
   Khalid MA, 2008, LECT NOTES COMPUT SC, V4956, P705
   Kolomiyets O, 2011, INFORM SCIENCES, V181, P5412, DOI 10.1016/j.ins.2011.07.047
   Laskar MTR, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5505
   Lee Minsuk, 2006, AMIA ANNU SYMP PROC, V0, P469
   Li D, 2019, ABS190507588 CORR, V0, P0
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Lloret E, 2011, INT J INTELL SYST, V26, P1125, DOI 10.1002/int.20502
   Nogueira Rodrigo, 2019, ABS190104085 CORR, V0, P0
   Padigela H, 2019, ABS190501758 CORR, V0, P0
   Pulman Stephen, 2014, ABS14121632 CORR, V0, P0
   Qiao Yifan, 2019, ARXIV190407531, V0, P0
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P567
   Rodrigo A, 2017, KNOWL-BASED SYST, V137, P83, DOI 10.1016/j.knosys.2017.09.015
   Segler MHS, 2018, NATURE, V555, P604, DOI 10.1038/nature25978
   Shen Gehui, 2017, P 2017 C EMP METH NA, V0, PP1179, DOI 10.18653/V1/D17-1122
   Tay Y, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP583, DOI 10.1145/3159652.3159664
   Wang D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P707
   Wang H, 2020, INT J INTELL SYST, V35, P1987, DOI 10.1002/int.22280
   Wimalasuriya DC, 2010, J INF SCI, V36, P306, DOI 10.1177/0165551509360123
   Xu P, 2019, ABS190505910 CORR, V0, P0
   Yang L, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP287, DOI 10.1145/2983323.2983818
   Yang Wei, 2019, ABS190310972 CORR, V0, P0
   Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P19
   Yun W, 2021, INT J INTELL SYST, V36, P1686, DOI 10.1002/int.22357
   Zaidi SSA, 2022, INT J INTELL SYST, V37, P3654, DOI 10.1002/int.22701
   Zhang S, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7080767
   Zou XH, 2020, J PHYS CONF SER, V1487, P0, DOI 10.1088/1742-6596/1487/1/012016
NR 42
TC 3
Z9 3
U1 51
U2 93
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD NOV 15
PY 2022
VL 37
IS 11
BP 8548
EP 8564
DI 10.1002/int.22955
EA JUL 2022
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4V0ZM
UT WOS:000822761000001
DA 2023-11-10
ER

PT J
AU Yang, S
   Feng, DW
   Liu, Y
   Li, DS
AF Yang, Sen
   Feng, Dawei
   Liu, Yang
   Li, Dongsheng
TI Distant context aware text generation from abstract meaning representation
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Text generation; Abstract meaning representation; Graph encoder; Receptive field
AB Text generation from abstract meaning representation is a fundamental task in natural language generation. An interesting challenge is that distant context could influence the surface realization for each node. In the previous encoder-decoder based approaches, graph neural networks have been commonly used to encode abstract meaning representation graphs and exhibited superior performance over the sequence and tree encoders. However, most of them cannot stack numerous layers, thus being too shallow to capture distant context. In this paper, we propose solutions from three aspects. Firstly, we introduce a Transformer based graph encoder to embed abstract meaning representation graphs. This encoder can stack more layers to encode larger context, while without performance degrading. Secondly, we expand the receptive field of each node, i.e. building direct connections between node pairs, to capture the information of its distant neighbors. We also exploit relative position embedding to make the model aware of the original hierarchy of graphs. Thirdly, we encode the linearized version of abstract meaning representation with the pre-trained language model to get the sequence encoding and incorporate it into graph encoding to enrich features. We conduct experiments on LDC2015E86 and LDC2017T10. Experimental results demonstrate that our method outperforms previous strong baselines. Especially, we investigate the performance of our model on large graphs, finding a larger performance gain. Our best model achieves 31.99 of BLEU and 37.02 of METEOR on LDC2015E86, 34.21 of BLEU, and 39.26 of METEOR on LDC2017T10, which are new states of the art.
C1 [Yang, Sen; Feng, Dawei; Liu, Yang; Li, Dongsheng] Natl Univ Def Technol, Coll Comp Sci, Changsha, Peoples R China.
   [Yang, Sen; Feng, Dawei; Li, Dongsheng] Natl Univ Def Technol, Natl Lab Parallel & Distributed Proc, Changsha, Peoples R China.
C3 National University of Defense Technology - China; National University of Defense Technology - China
RP Yang, S (通讯作者)，Natl Univ Def Technol, Coll Comp Sci, Changsha, Peoples R China.; Yang, S (通讯作者)，Natl Univ Def Technol, Natl Lab Parallel & Distributed Proc, Changsha, Peoples R China.
EM yangsen.nudt@hotmail.com
CR Abu-El-Haifa S, 2019, PR MACH LEARN RES, V97, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Bahdanau D, 2016, ARXIV, V0, P0
   Banarescu Laura, 2013, P 7 LING ANN WORKSH, V0, P0
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, V0, PP65, DOI 10.3115/1626355.1626389
   Beck D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P273
   Cai D, 2020, AAAI CONF ARTIF INTE, V34, P7464
   Cao K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2157
   Chen Benson, 2019, ARXIV190512712, V0, P0
   Chen Y, 2020, 8 INT C LEARN REPR I, V0, P0
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Choi E, 2020, AAAI CONF ARTIF INTE, V34, P606
   Damonte M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3649
   Devlin J, 2018, ARXIV, V1, P4171
   Dyer C, 2016, P 2016 M N AM CHAPTE, V0, PP731, DOI 10.18653/v1/N16-1087
   Gao H, 2019, PICT COD SYMP, V0, P0, DOI DOI 10.1109/pcs48520.2019.8954523
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Guo ZJ, 2019, T ASSOC COMPUT LING, V7, P297, DOI 10.1162/tacl_a_00269
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu ZN, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2704, DOI 10.1145/3366423.3380027
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Kasper RT, 1989, SPEECH AND NATURAL LANGUAGE. PROCEEDINGS OF A WORKSHOP, V0, P153
   Kipf T N, 2016, ICLR, V0, P0
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Konstas I, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P146, DOI 10.18653/v1/P17-1014
   Li Qimai, 2018, ARXIV180107606, V0, P0, DOI DOI 10.1109/IFETC.2018.8583886
   Liao K, 2018, P 27 INT C COMP LING, V0, P1178
   Manuel M, 2020, P 58 ANN M ASS COMP, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Petar V, 2018, ICLR, V0, P0
   Radford A, 2019, OPENAI BLOG, V0, P0
   Rao S, 2017, BIONLP, V2017, P126, DOI 10.18653/V1/W17-2315
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Song LF, 2019, T ASSOC COMPUT LING, V7, P19, DOI 10.1162/tacl_a_00252
   Song LF, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1616
   Song LF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P7, DOI 10.18653/v1/P17-2002
   Takase Sho, 2016, P 2016 C EMP METH NA, V0, PP1054, DOI 10.18653/v1/D16-1112
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang TM, 2020, T ASSOC COMPUT LING, V8, P19, DOI 10.1162/tacl_a_00297
   Xu K, 2018, ARXIV180400823, V0, P0
   Xu KYL, 2018, PR MACH LEARN RES, V80, P0
   Yao S, 2020, P 58 ANN M ASS COMPU, V0, PP7145, DOI 10.18653/v1/2020.acl-main.640
   Yun S, 2019, ADV NEUR IN, V32, P0
   Zhao YB, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P732
   Zhu J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5459
NR 45
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JAN 15
PY 2022
VL 52
IS 2
BP 1672
EP 1685
DI 10.1007/s10489-021-02431-1
EA MAY 2021
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YL6SX
UT WOS:000654848300001
DA 2023-11-10
ER

PT J
AU Gibert, D
   Planes, J
   Mateu, C
   Le, Q
AF Gibert, Daniel
   Planes, Jordi
   Mateu, Carles
   Le, Quan
TI Fusing feature engineering and deep learning: A case study for malware classification
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Malware classification; Machine learning; Deep learning; Feature extraction; Feature fusion
ID entropy
AB Machine learning has become an appealing signature-less approach to detect and classify malware because of its ability to generalize to never-before-seen samples and to handle large volumes of data. While traditional feature-based approaches rely on the manual design of hand-crafted features based on experts' knowledge of the domain, deep learning approaches replace the manual feature engineering process by an underlying system, typically consisting of a neural network with multiple layers, that perform both feature learning and classification altogether. However, the combination of both approaches could substantially enhance detection systems. In this paper we present an hybrid approach to address the task of malware classification by fusing multiple types of features defined by experts and features learned through deep learning from raw data. In particular, our approach relies on deep learning to extract N-gram like features from the assembly language instructions and the bytes of malware, and texture patterns and shapelet-based features from malware's grayscale image representation and structural entropy, respectively. These deep features are later passed as input to a gradient boosting model that combines the deep features and the hand-crafted features using an early-fusion mechanism. The suitability of our approach has been evaluated on the Microsoft Malware Classification Challenge benchmark and results show that the proposed solution achieves state-of-the-art performance and outperforms gradient boosting and deep learning methods in the literature.
C1 [Gibert, Daniel; Le, Quan] Univ Coll Dublin, CeADAR, Belfield Off Pk, Dublin, Ireland.
   [Planes, Jordi; Mateu, Carles] Univ Lleida, Jaume 2,69, Lleida, Spain.
C3 University College Dublin; Universitat de Lleida
RP Gibert, D (通讯作者)，Univ Coll Dublin, CeADAR, Belfield Off Pk, Dublin, Ireland.
EM daniel.gibert@ucd.ie
FU Enterprise Ireland; European Union [847402]; Spanish Science and Innovation Ministry [PID2019-111544GB-C22]
CR Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC, V0, P0
   Ahmadi M, 2016, CODASPY16: PROCEEDINGS OF THE SIXTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, V0, PP183, DOI 10.1145/2857705.2857713
   Anderson HS, 2018, CORR ABS180404637ARX, V0, P0
   [Anonymous], 2015, STAT-US, V0, P0
   Baysa D, 2013, J COMPUT VIROL HACKI, V9, P179, DOI 10.1007/s11416-013-0185-4
   Bilar D, 2006, BLACKHAT, V0, P0
   BXNET, 2016, TOP MAL US AP, V0, P0
   Çayir A, 2021, COMPUT SECUR, V102, P0, DOI 10.1016/j.cose.2020.102133
   Chen T, 2016, CORR ABS160302754 AR, V0, P0
   Davuluru VSP, 2019, PROC NAECON IEEE NAT, V0, PP273, DOI 10.1109/NAECON46414.2019.9058025
   Demetrio L, 2021, ACM T PRIV SECUR, V24, P0, DOI 10.1145/3473039
   Demetrio L, 2021, IEEE T INF FOREN SEC, V16, P3469, DOI 10.1109/TIFS.2021.3082330
   Drew J, 2017, EURASIP J INF SECUR, V0, P0, DOI DOI 10.1186/s13635-017-0055-6
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao XW, 2020, J INF SECUR APPL, V55, P0, DOI 10.1016/j.jisa.2020.102661
   Gibert D, 2020, IEEE IJCNN, V0, P0, DOI DOI 10.1109/ijcnn48605.2020.9206671
   Gibert D, 2021, COMPUT SECUR, V102, P0, DOI 10.1016/j.cose.2020.102159
   Gibert D, 2019, IEEE IJCNN, V0, P0
   Gibert D, 2020, COMPUT SECUR, V95, P0, DOI 10.1016/j.cose.2020.101873
   Gibert D, 2020, J NETW COMPUT APPL, V153, P0, DOI 10.1016/j.jnca.2019.102526
   Gibert D, 2018, AAAI CONF ARTIF INTE, V0, P7759
   Gibert D, 2019, J COMPUT VIROL HACKI, V15, P15, DOI 10.1007/s11416-018-0323-0
   Gibert D, 2017, FRONT ARTIF INTEL AP, V300, P221, DOI 10.3233/978-1-61499-806-8-221
   Gibert D, 2018, LECT NOTES COMPUT SC, V11141, P383, DOI 10.1007/978-3-030-01424-7_38
   Grabocka J, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP392, DOI 10.1145/2623330.2623613
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu W, 2017, CORR ABS170205983 AR, V0, P0
   Hu X, 2016, IBM J RES DEV, V60, P0, DOI 10.1147/JRD.2016.2559378
   Jiang YK, 2019, LECT NOTES COMPUT SC, V11954, P150, DOI 10.1007/978-3-030-36711-4_14
   Jordaney R, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY 17), V0, P625
   Kalash M, 2018, INT CONF NEW TECHNOL, V0, P0
   Kebede TM, 2017, PROC NAECON IEEE NAT, V0, PP70, DOI 10.1109/NAECON.2017.8268747
   Khan RU, 2019, J COMPUT VIROL HACKI, V15, P29, DOI 10.1007/s11416-018-0324-z
   Kim JY, 2022, COMPUT SECUR, V112, P0, DOI 10.1016/j.cose.2021.102501
   Kim JY, 2018, INFORM SCIENCES, V460, P83, DOI 10.1016/j.ins.2018.04.092
   Krcal M, 2018, DEEP CONVOLUTIONAL M, V0, P0
   Langevin J, 2010, HUM CAP CRIS CYB TEC, V0, P0
   Le Q, 2018, DIGIT INVEST, V26, PS118, DOI 10.1016/j.diin.2018.04.024
   Lin WC, 2022, MATHEMATICS-BASEL, V10, P0, DOI 10.3390/math10040608
   Liu YS, 2019, IEEE ACCESS, V7, P13015, DOI 10.1109/ACCESS.2019.2892500
   Lo WW, 2019, INT CONF NEW TECHNOL, V0, P0, DOI DOI 10.1109/ntms.2019.8763852
   Lyda R, 2007, IEEE SECUR PRIV, V5, P40, DOI 10.1109/MSP.2007.48
   Mays M, 2017, PROC MAICS, V0, P165
   McLaughlin N, 2017, PROCEEDINGS OF THE SEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY17), V0, PP301, DOI 10.1145/3029806.3029823
   Messay-Kebede T, 2018, PROC NAECON IEEE NAT, V0, PP73, DOI 10.1109/NAECON.2018.8556722
   Narayanan BN, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9050721
   Narayanan BN, 2016, PROC NAECON IEEE NAT, V0, PP338, DOI 10.1109/NAECON.2016.7856826
   Nataraj L, 2011, P 8 INT S VIS CYB SE, V4, P4, DOI 10.1145/2016904.2016908
   Nataraj Lakshmanan, 2011, INT S VISUALIZATION, V0, P0
   OJALA T, 1994, INT C PATT RECOG, V0, PP582, DOI 10.1109/ICPR.1994.576366
   Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897
   Pendlebury F, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, V0, P729
   Qiao YC, 2019, IEEE TRUST BIG, V0, PP757, DOI 10.1109/TrustCom/BigDataSE.2019.00109
   Raff E, 2018, 32 AAAI C ART INT NE, V0, P0
   Raff E, 2018, J COMPUT VIROL HACKI, V14, P1, DOI 10.1007/s11416-016-0283-1
   Ronen R, 2018, CORR ABS180210135 AR, V0, P0
   Santos I, 2009, ICEIS 2009 : PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL AIDSS, P317
   STAHLE L, 1989, CHEMOMETR INTELL LAB, V6, P259, DOI 10.1016/0169-7439(89)80095-4
   Steuer R, 2002, BIOINFORMATICS, V18, PS231, DOI 10.1093/bioinformatics/18.suppl_2.S231
   Suciu Octavian, 2019, 2019 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW). PROCEEDINGS, V0, PP8, DOI 10.1109/SPW.2019.00015
   Sudhakar, 2021, FUTURE GENER COMP SY, V125, P334, DOI 10.1016/j.future.2021.06.029
   Ucci D, 2019, COMPUT SECUR, V81, P123, DOI 10.1016/j.cose.2018.11.001
   Vinayakumar R, 2019, IEEE ACCESS, V7, P46717, DOI 10.1109/ACCESS.2019.2906934
   Xiao GQ, 2020, J PARALLEL DISTR COM, V141, P49, DOI 10.1016/j.jpdc.2020.03.012
   Xiao M, 2021, COMPUT SECUR, V110, P0, DOI 10.1016/j.cose.2021.102420
   Yan JQ, 2019, I C DEPEND SYS NETWO, V0, PP52, DOI 10.1109/DSN.2019.00020
   Yousefi-Azar M, 2017, IEEE IJCNN, V0, PP3854, DOI 10.1109/IJCNN.2017.7966342
   Yuan BG, 2020, COMPUT SECUR, V92, P0, DOI 10.1016/j.cose.2020.101740
   Zhang XL, 2021, PROCESSES, V9, P0, DOI 10.3390/pr9060929
   Zhang YN, 2016, IEEE TRUST BIG, V0, PP965, DOI 10.1109/TrustCom.2016.0163
NR 70
TC 7
Z9 7
U1 6
U2 17
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 30
PY 2022
VL 207
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.117957
EA JUN 2022
PG 18
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 3A8TO
UT WOS:000827527100011
DA 2023-11-10
ER

PT J
AU Dimitriadis, D
   Tsoumakas, G
AF Dimitriadis, Dimitris
   Tsoumakas, Grigorios
TI Artificial fine-tuning tasks for yes/no question answering
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Question answering; Machine learning; Yes; no question answering; Transfer learning
AB Current research in yes/no question answering (QA) focuses on transfer learning techniques and transformer-based models. Models trained on large corpora are fine-tuned on tasks similar to yes/no QA, and then the captured knowledge is transferred for solving the yes/no QA task. Most previous studies use existing similar tasks, such as natural language inference or extractive QA, for the fine-tuning step. This paper follows a different perspective, hypothesizing that an artificial yes/no task can transfer useful knowledge for improving the performance of yes/no QA. We introduce three such tasks for this purpose, by adapting three corresponding existing tasks: candidate answer validation, sentiment classification, and lexical simplification. Furthermore, we experimented with three different variations of the BERT model (BERT base, RoBERTa, and ALBERT). The results show that our hypothesis holds true for all artificial tasks, despite the small size of the corresponding datasets that are used for the fine-tuning process, the differences between these tasks, the decisions that we made to adapt the original ones, and the tasks' simplicity. This gives an alternative perspective on how to deal with the yes/no QA problem, that is more creative, and at the same time more flexible, as it can exploit multiple other existing tasks and corresponding datasets to improve yes/no QA models.
C1 [Dimitriadis, Dimitris; Tsoumakas, Grigorios] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Dimitriadis, D (通讯作者)，Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM dndimitri@csd.auth.gr
FU National Infrastructures for Research and Technology S.A. [pa181002-NEBULA]
CR Aghajanyan A, 2021, P EMNLP, V0, P5799
   Alberti C, 2019, ARXIV, V0, P0
   [Anonymous], 2013, INT J ARTIFICIAL INT, V0, P0
   [Anonymous], 2012, IBM J RES DEV, V0, P0, DOI DOI 10.1147/jrd.2012.2184637
   [Anonymous], 2011, P MACHINE LEARNING R, V0, P0
   Athenikos SJ, 2010, COMPUT METH PROG BIO, V99, P1, DOI 10.1016/j.cmpb.2009.10.003
   Baradaran R, 2020, NAT LANGUAGE ENG, V0, P0
   Bouziane A, 2015, PROCEDIA COMPUT SCI, V73, P366, DOI 10.1016/j.procs.2015.12.005
   Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, PP276, DOI 10.18653/v1/w19-4828
   Devlin Jacob, 2019, BERT PRE TRAINING DE, V0, P4171
   Dimitriadis D, 2019, JOINT EUROPEAN C MAC, V0, P661
   Dimitriadis D, 2019, J BIOMED INFORM, V92, P0, DOI 10.1016/j.jbi.2019.103118
   Dzendzik D, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P1
   Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594
   Glushkova Taisia, 2021, ANALYSIS OF IMAGES, V0, P0
   Gupta Poonam, 2012, INT J COMPUTER APPL, V53, P1
   JURAFSKY Daniel, 2018, SPEECH LANGUAGE PROC, V0, P0
   Kajiwara T, 2016, P COLING 2016 26 INT, V0, P1147
   Kanayama H, 2012, P COLING 2012, V0, P1377
   Kano Y, 2017, EPIC SERIES COMPUTIN, V0, P57
   Kano Y, 2016, P OPEN KNOWLEDGE BAS, V0, P91
   Kauchak D, 2013, LONG PAPERS, V1, P1537
   Kim MY, 2014, LECT NOTES ARTIF INT, V8417, P199, DOI 10.1007/978-3-319-10061-6_14
   Kolomiyets O, 2011, INFORM SCIENCES, V181, P5412, DOI 10.1016/j.ins.2011.07.047
   Kotzias D, 2015, KDD15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP597, DOI 10.1145/2783258.2783380
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Magnini B, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P425
   McCloskey M, 1989, PSYCHOL LEARNING MOT, V24, P165
   Munikar M, 2019, P INT C ART INT TRAN, V0, P2
   Pakray P, 2011, CLEF NOT PAP LABS WO, V0, P0
   Pasca MA, 2001, SIGIR FORUM, V0, P366
   Peng S, 2015, CEUR WORKSHOP PROC, V0, P0
   Pundge AM, 2016, INT J COMPUTER APPL, V141, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rondeau MA, 2018, MACHINE READING FOR QUESTION ANSWERING, V0, P12
   Sarrouti M, 2017, INT J HEALTHC INF SY, V12, P62, DOI 10.4018/IJHISI.2017070104
   Sharma V, 2018, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2018), V0, P109
   Shen CL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3654
   Silpa KS, 2018, EMERGING TRENDS IN ENGINEERING, V0, P0
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Tsatsaronis G, 2015, BMC BIOINFORMATICS, V16, P0, DOI 10.1186/s12859-015-0564-6
   Vaswani A, 2017, NIPS, V30, P0
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, P37
   Weissenborn D, 2017, P 21 C COMP NAT LANG, V0, PP271, DOI 10.18653/V1/K17-1028
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xiong C, 2017, P INT C LEARNING REP, V0, P1
   Yang Z, 2016, ACL 2016, V0, P23
   Yin H, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE-RCAR 2020), V0, PP1, DOI 10.1109/rcar49640.2020.9303291
   Yu Lei, 2014, ARXIV14121632, V0, P0
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 54
TC 0
Z9 0
U1 5
U2 7
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324922000286
EA JUN 2022
PG 23
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 2N7KY
UT WOS:000818555300001
DA 2023-11-10
ER

PT J
AU Al-Amin, ST
   Ordonez, C
AF Al-Amin, Sikder Tahsin
   Ordonez, Carlos
TI Incremental and accurate computation of machine learning models with smart data summarization
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
LA English
DT Article
DE Data mining; Incremental computation; Summarization; Machine learning
ID algorithm
AB Nowadays, data scientists prefer "easy" high-level languages like R and Python, which accomplish complex mathematical tasks with a few lines of code, but they present memory and speed limitations. Data summarization has been a fundamental technique in data mining that has promise with more demanding data science applications. Unfortunately, most summarization approaches require reading the entire data set before computing any machine learning (ML) model, the old-fashioned way. Also, it is hard to learn models if there is an addition or removal of data samples. Keeping these motivations in mind, we present incremental algorithms to smartly compute summarization matrix, previously used in parallel DBMSs, to compute ML models incrementally in data science languages. Compared to the previous approaches, our new smart algorithms interleave model computation periodically, as the data set is being summarized. A salient feature is scalability to large data sets, provided the summarization matrix fits in RAM, a reasonable assumption in most cases. We show our incremental approach is intelligent and works for a wide spectrum of ML models. Our experimental evaluation shows models get increasingly accurate, reaching total accuracy when the data set is fully scanned. On the other hand, we show our incremental algorithms are as fast as Python ML library, and much faster than R built-in routines.
C1 [Al-Amin, Sikder Tahsin; Ordonez, Carlos] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 University of Houston System; University of Houston
RP Al-Amin, ST (通讯作者)，Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
EM stahsin.cse@gmail.com
CR Ahmed M, 2019, KNOWL INF SYST, V58, P249, DOI 10.1007/s10115-018-1183-0
   Al-Amin ST, 2020, IEEE INT CONF BIG DA, V0, PP399, DOI 10.1109/BigData50022.2020.9378399
   Altiparmak F, 2008, IEEE T KNOWL DATA EN, V20, P216, DOI 10.1109/TKDE.2007.190693
   Beazley DM, 1996, PROCEEDINGS OF THE FOURTH ANNUAL TCL/TK WORKSHOP, V0, P129
   Bradley PS, 1998, PROCEEDINGS FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P9
   Cauwenberghs G, 2001, ADV NEUR IN, V13, P409
   Chebolu SUS, 2019, LECT NOTES COMPUT SC, V11707, P247, DOI 10.1007/978-3-030-27618-8_19
   Chen YT, 2019, CLUSTER COMPUT, V22, PS7435, DOI 10.1007/s10586-018-1772-4
   Das S, 2010, P 2010 ACM SIGMOD IN, V0, PP987, DOI 10.1145/1807167.1807275
   David J, 2020, J INTELL INF SYST, V54, P483, DOI 10.1007/s10844-019-00570-z
   Dua D, 2017, UCI MACHINE LEARNING, V0, P0
   Eddelbuettel D, 2013, SEAMLESS R C INTEGRA, V0, P0, DOI DOI 10.1007/978-1-4614-6868-4
   Gepperth A, 2016, EUR S ART NEUR NETW, V0, P0
   Hastie T, 2001, ELEMENTS STAT LEARNI, V0, P0, DOI DOI 10.1007/978-0-387-21606-5
   He HB, 2011, IEEE T NEURAL NETWOR, V22, P1901, DOI 10.1109/TNN.2011.2171713
   James G, 2013, SPRINGER TEXTS STAT, V103, P303, DOI 10.1007/978-1-4614-7138-7_8
   Karasuyama M, 2010, IEEE T NEURAL NETWOR, V21, P1048, DOI 10.1109/TNN.2010.2048039
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Levatic J, 2017, J INTELL INF SYST, V49, P461, DOI 10.1007/s10844-017-0457-4
   Ordonez C, 2019, DISTRIB PARALLEL DAT, V37, P329, DOI 10.1007/s10619-018-7229-1
   Ordonez C, 2016, IEEE T KNOWL DATA EN, V28, P1905, DOI 10.1109/TKDE.2016.2545664
   Osojnik A, 2018, J INTELL INF SYST, V50, P315, DOI 10.1007/s10844-017-0462-7
   Patra BK, 2015, KNOWL INF SYST, V42, P1, DOI 10.1007/s10115-013-0709-8
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rumsey D, 2011, STAT DUMMIES DUMMIES, V0, P0
   Spokoiny A, 2008, J INTELLIGENT INFORM, V0, P1
   Tari L, 2012, IEEE T KNOWL DATA EN, V24, P86, DOI 10.1109/TKDE.2010.214
   Totad SG, 2012, KNOWL INF SYST, V33, P475, DOI 10.1007/s10115-012-0514-9
   Zakai A, 2011, P ACM INT C COMP OBJ, V0, PP301, DOI 10.1145/2048147.2048224
   Zhang T, 1996, PROC 1996 ACM INT C, V25, P103, DOI 10.1145/235968.233324
   Zhang Y, 2010, P ICDE, V0, P0
NR 33
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0925-9902
EI 1573-7675
J9 J INTELL INF SYST
JI J. Intell. Inf. Syst.
PD AUG 15
PY 2022
VL 59
IS 1
BP 149
EP 172
DI 10.1007/s10844-021-00690-5
EA JAN 2022
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 3F5MF
UT WOS:000744389900001
DA 2023-11-10
ER

PT J
AU Liaqat, MI
   Hassan, MA
   Shoaib, M
   Khurshid, SK
   Shamseldin, MA
AF Liaqat, Muhammad Irzam
   Hassan, Muhammad Awais
   Shoaib, Muhammad
   Khurshid, Syed Khaldoon
   Shamseldin, Mohamed A.
TI Sentiment analysis techniques, challenges, and opportunities: Urdu language-based analytical study
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Opinion mining; Poor resource language; Word sense disambiguation; Urdu-based language constructs; Digital repositories
AB Sentiment analysis in research involves the processing and analysis of sentiments from textual data. The sentiment analysis for high resource languages such as English and French has been carried out effectively in the past. However, its applications are comparatively few for resource-poor languages due to a lack of textual resources. This systematic literature explores different aspects of Urdu-based sentiment analysis, a classic case of poor resource language. While Urdu is a South Asian language understood by one hundred and sixty-nine million people across the planet. There are various shortcomings in the literature, including limitation of large corpora, language parsers, and lack of pre-trained machine learning models that result in poor performance. This article has analyzed and evaluated studies addressing machine learning-based Urdu sentiment analysis. After searching and filtering, forty articles have been inspected. Research objectives have been proposed that lead to research questions. Our searches were organized in digital repositories after selecting and screening relevant studies. Data was extracted from these studies. Our work on the existing literature reflects that sentiment classification performance can be improved by overcoming the challenges such as word sense disambiguation and massive datasets. Furthermore, Urdu-based language constructs, including language parsers and emoticons, context-level sentiment analysis techniques, pre-processing methods, and lexical resources, can also be improved.
C1 [Liaqat, Muhammad Irzam; Hassan, Muhammad Awais; Shoaib, Muhammad; Khurshid, Syed Khaldoon] Univ Engn & Technol Lahore, Dept Comp Sci, Lahore, Punjab, Pakistan.
   [Shamseldin, Mohamed A.] Future Univ Egypt, Fac Engn Technol, Dept Mech Engn, New Cairo, Egypt.
C3 University of Engineering & Technology Lahore; Egyptian Knowledge Bank (EKB); Future University in Egypt
RP Hassan, MA (通讯作者)，Univ Engn & Technol Lahore, Dept Comp Sci, Lahore, Punjab, Pakistan.
EM awais.hassan@uet.edu.pk
CR Ali MZ, 2021, IEEE ACCESS, V9, P84296, DOI 10.1109/ACCESS.2021.3087827
   Altrabsheh N, 2014, LECT NOTES ARTIF INT, V8779, P40, DOI 10.1007/978-3-319-11298-5_5
   Anwar W, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4489
   Asghar MZ, 2019, EXPERT SYST, V36, P0, DOI 10.1111/exsy.12397
   Asghar MZ, 2017, COGN COMPUT, V9, P868, DOI 10.1007/s12559-017-9503-3
   Asif M, 2020, TELEMAT INFORM, V48, P0, DOI 10.1016/j.tele.2020.101345
   Awais DM, 2019, ACM T ASIAN LOW-RESO, V18, P1
   Babu AG, 2017, P 2017 INT C MACH LE, V0, P0
   Badaro G, 2019, ACM T ASIAN LOW-RESO, V18, P0, DOI 10.1145/3295662
   Basiri ME, 2014, OPEN T INFORM PROCES, V0, P1?14
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Basiri ME, 2020, KNOWL-BASED SYST, V198, P0, DOI 10.1016/j.knosys.2020.105949
   Bibi Raheela, 2019, 2019 IEEE 17TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, V0, P66, DOI 10.1109/SERA.2019.8886788
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   Dong XF, 2021, TECHNOL SOC, V67, P0, DOI 10.1016/j.techsoc.2021.101724
   Fernandez A, 2011, INFORM SOFTWARE TECH, V53, P789, DOI 10.1016/j.infsof.2011.02.007
   Ghulam H, 2019, PROCEDIA COMPUT SCI, V147, P131, DOI 10.1016/j.procs.2019.01.202
   Hasan A, 2018, MATH COMPUT APPL, V23, P0, DOI 10.3390/mca23010011
   Hassan SM, 2019, INDIAN J SCI TECHNOL, V12, P01, DOI 10.17485/ijst/2019/v12i35/146571
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Idrees F, 2019, P 10 INT C INFORM CO, V0, P1
   Jena RK, 2019, BEHAV INFORM TECHNOL, V38, P986, DOI 10.1080/0144929X.2019.1625440
   Khan IU, 2022, COMPUTERS, V11, P0, DOI 10.3390/computers11010003
   Khan L, 2021, IEEE ACCESS, V9, P97803, DOI 10.1109/ACCESS.2021.3093078
   Khan W, 2019, LANG RESOUR EVAL, V53, P331, DOI 10.1007/s10579-018-9439-6
   Khattak A, 2021, EGYPT INFORM J, V22, P53, DOI 10.1016/j.eij.2020.04.003
   Kitchenham Barbara, 2004, PROCEDURES PERFORMIN, V33, P1, DOI 10.1145/3328905.3332505
   Lin C, 2009, P 18 ACM C INF KNOWL, V0, PP375, DOI 10.1145/1645953.1646003
   Liu B, 2011, DATA CENTRIC SYST AP, V0, PP459, DOI 10.1007/978-3-642-19460-3_11
   Lo SL, 2017, ARTIF INTELL REV, V48, P499, DOI 10.1007/s10462-016-9508-4
   Majeed A, 2020, 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING WORKSHOPS (ASEW 2020), V0, PP125, DOI 10.1145/3417113.3423375
   Marrese-Taylor E, 2014, EXPERT SYST APPL, V41, P7764, DOI 10.1016/j.eswa.2014.05.045
   Mehmood F, 2020, IEEE ACCESS, V8, P192740, DOI 10.1109/ACCESS.2020.3030885
   Mehmood K, 2019, ADV INTELL SYST COMP, V858, P29, DOI 10.1007/978-3-030-01174-1_3
   Mehmood K, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3329709
   Mehmood K, 2019, IEEE ACCESS, V7, P47991, DOI 10.1109/ACCESS.2019.2908420
   Mehta P, 2020, INT J SCI TECHNOLOGY, V9, P0
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mukhtar N, 2020, ARTIF INTELL REV, V53, P2521, DOI 10.1007/s10462-019-09740-5
   Mukhtar N, 2018, TELEMAT INFORM, V35, P2173, DOI 10.1016/j.tele.2018.08.003
   Naqvi RA, 2020, CMC-COMPUT MATER CON, V65, P1221, DOI 10.32604/cmc.2020.011686
   Naqvi U, 2021, IEEE ACCESS, V9, P114085, DOI 10.1109/ACCESS.2021.3104308
   Nazir M, 2020, 2020 5TH IEEE WORKSHOP ON THE ELECTRONIC GRID (EGRID), V0, P0, DOI DOI 10.1109/EGRID48559.2020.9330631
   Ouhbi S, 2015, REQUIR ENG, V20, P119, DOI 10.1007/s00766-013-0192-5
   Portal CC, 2018, CORE C PORT, V0, P0
   Pourpanah F, 2020, ARXIV, V0, P0
   Rank SJC, 2018, SCIMAGO J COUNTRY RA, V0, P0
   Raza H, 2019, INT J ADV COMPUT SC, V10, P157
   Safder I, 2021, EXPERT SYST, V38, P0, DOI 10.1111/exsy.12751
   Sattar A, 2021, PAKISTAN J ENG TECH, V4, P0, DOI 10.51846/vol4iss2pp149-152
   Seo S, 2020, IEEE ACCESS, V8, P6861, DOI 10.1109/ACCESS.2019.2963426
   Syed AZ, 2010, LECT NOTES ARTIF INT, V6437, P32, DOI 10.1007/978-3-642-16761-4_4
   Tabassum N, 2021, INTELL AUTOM SOFT CO, V30, P175, DOI 10.32604/iasc.2021.018998
   Wohlin C, 2014, P 18 INT C EVALUATIO, V0, PP1, DOI 10.1145/2601248.2601268
   Zhou XJ, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), V0, PP533, DOI 10.1145/3106426.3106459
NR 56
TC 2
Z9 2
U1 1
U2 3
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD AUG 31
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1032
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 4W2SH
UT WOS:000860016600002
PM 36091980
DA 2023-11-10
ER

PT J
AU Changrampadi, MH
   Shahina, A
   Narayanan, MB
   Khan, AN
AF Changrampadi, Mohamed Hashim
   Shahina, A.
   Narayanan, M. Badri
   Khan, A. Nayeemulla
TI End-to-End Speech Recognition of Tamil Language
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE End to end speech recognition; deep learning; under-resourced language; semi-supervised speech corpus development
ID system; asr
AB Research in speech recognition is progressing with numerous state-ofthe-art results in recent times. However, relatively fewer research is being carried out in Automatic Speech Recognition (ASR) for languages with low resources. We present a method to develop speech recognition model with minimal resources using Mozilla DeepSpeech architecture. We have utilized freely available online computational resources for training, enabling similar approaches to be carried out for research in a low-resourced languages in a financially constrained environments. We also present novel ways to build an efficient language model from publicly available web resources to improve accuracy in ASR. The proposed ASR model gives the best result of 24.7% Word Error Rate (WER), compared to 55% WER by Google speech-to-text. We have also demonstrated a semi-supervised development of speech corpus using our trained ASR model, indicating a cost effective approach of building large vocabulary corpus for low resource language. The trained Tamil ASR model and the training sets are released in public domain and are available on GitHub.
C1 [Changrampadi, Mohamed Hashim] C Abdul Hakeem Coll Engn & Technol, Dept Elect & Commun Engn, Melvisharam 632509, India.
   [Shahina, A.; Narayanan, M. Badri] Sri Sivasubramaniya Nadar Coll Engn, Dept Informat Technol, Kalavakkam 603110, India.
   [Khan, A. Nayeemulla] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
C3 C. Abdul Hakeem College of Engineering & Technology; SSN College of Engineering; Vellore Institute of Technology (VIT); VIT Chennai
RP Changrampadi, MH (通讯作者)，C Abdul Hakeem Coll Engn & Technol, Dept Elect & Commun Engn, Melvisharam 632509, India.
EM hashim@alumni.chalmers.se
CR Amodei D, 2016, PR MACH LEARN RES, V48, P0
   [Anonymous], 2021, CENTR I IND LANG, V0, P0
   Ardila Rosana, 2019, ARXIV191206670, V0, P0
   Arora G, 2020, P 2 WORKSHOP NLP OPE, V0, PP66, DOI 10.18653/v1/2020.nlposs-1.10
   Bandanau D, 2016, INT CONF ACOUST SPEE, V0, PP4945, DOI 10.1109/ICASSP.2016.7472618
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Billa J, 2018, INTERSPEECH, V0, PP3207, DOI 10.21437/Interspeech.2018-2473
   Chan W, 2021, WORKSH MACH LEARN SP, V0, P0
   Chen YC, 2020, INTERSPEECH, V0, PP1803, DOI 10.21437/Interspeech.2020-1315
   Fathima N, 2018, INTERSPEECH, V0, PP3197, DOI 10.21437/Interspeech.2018-2117
   Hannun A, 2017, DISTILL, V2, P8
   Hannun Awni, 2014, ARXIV14125567, V0, P0
   He F, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6494
   Heafield K, 2011, P 6 WORKSH STAT MACH, V0, P187
   Inaguma H, 2019, INT CONF ACOUST SPEE, V0, PP6096, DOI 10.1109/ICASSP.2019.8682918
   Karunanayake Y, 2019, INT CONF ASIAN LANG, V0, PP234, DOI 10.1109/IALP48816.2019.9037702
   Liu C, 2020, P 1 JOINT WORKSHOP S, V0, P46
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Madhavaraj A, 2018, INTERSPEECH, V0, P1966
   Madhavaraj A, 2017, 2017 14 IEEE IND COU, V0, P1
   Mahar SA, 2021, INTELL AUTOM SOFT CO, V29, P183, DOI 10.32604/iasc.2021.015755
   Mohan Krishna Doss, 2018, WORKSHOP SPOKEN LANG, V0, P11
   Mustageem, 2020, MATHEMATICS-BASEL, V8, P0, DOI 10.3390/math8122133
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, P0, DOI 10.1016/j.asoc.2021.107101
   Mustaqeem, 2021, CMC-COMPUT MATER CON, V67, P4039, DOI 10.32604/cmc.2021.015070
   Mustaqeem, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20010183
   ONeill PK, 2021, INTERSPEECH, V0, P0
   Panayotov V, 2015, INT CONF ACOUST SPEE, V0, PP5206, DOI 10.1109/ICASSP.2015.7178964
   Pulugundla B, 2018, INTERSPEECH, V0, PP3182, DOI 10.21437/Interspeech.2018-1302
   Raza AA, 2018, INTERSPEECH, V0, P1021
   Shi XJ, 2015, ADV NEUR IN, V28, P0
   Wang C, 2020, ARXIV200710310, V0, P0
   Zhang Y, 2020, J AMB INTEL HUM COMP, V0, P0
NR 33
TC 7
Z9 7
U1 0
U2 19
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD JUN 15
PY 2022
VL 32
IS 2
BP 1309
EP 1323
DI 10.32604/iasc.2022.022021
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA XA7TM
UT WOS:000720844200017
DA 2023-11-10
ER

PT J
AU Jiang, WH
   Zhu, MW
   Fang, YM
   Shi, GM
   Zhao, XW
   Liu, Y
AF Jiang, Wenhui
   Zhu, Minwei
   Fang, Yuming
   Shi, Guangming
   Zhao, Xiaowei
   Liu, Yang
TI Visual Cluster Grounding for Image Captioning
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Grounding; Visualization; Proposals; Annotations; Transformers; Task analysis; Decoding; Image captioning; attention evaluation; grounding supervision
ID attention
AB Attention mechanisms have been extensively adopted in vision and language tasks such as image captioning. It encourages a captioning model to dynamically ground appropriate image regions when generating words or phrases, and it is critical to alleviate the problems of object hallucinations and language bias. However, current studies show that the grounding accuracy of existing captioners is still far from satisfactory. Recently, much effort is devoted to improving the grounding accuracy by linking the words to the full content of objects in images. However, due to the noisy grounding annotations and large variations of object appearance, such strict word-object alignment regularization may not be optimal for improving captioning performance. In this paper, to improve the performance of both grounding and captioning, we propose a novel grounding model which implicitly links the words to the evidence in the image. The proposed model encourages the captioner to dynamically focus on informative regions of the objects, which could be either discriminative parts or full object content. With slacked constraints, the proposed captioning model can capture correct linguistic characteristics and visual relevance, and then generate more grounded image captions. In addition, we propose a novel quantitative metric for evaluating the correctness of the soft attention mechanism by considering the overall contribution of all object proposals when generating certain words. The proposed grounding model can be seamlessly plugged into most attention-based architectures without introducing inference complexity. We conduct extensive experiments on Flickr30k (Young et al., 2014) and MS COCO datasets (Lin et al., 2014), demonstrating that the proposed method consistently improves image captioning in both grounding and captioning. Besides, the proposed attention evaluation metric shows better consistency with the captioning performance.
C1 [Jiang, Wenhui; Zhu, Minwei; Fang, Yuming] Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang 330032, Jiangxi, Peoples R China.
   [Shi, Guangming] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
   [Zhao, Xiaowei; Liu, Yang] Sany Heavy Ind Co Ltd, Beijing 102206, Peoples R China.
C3 Jiangxi University of Finance & Economics; Xidian University; SANY
RP Fang, YM (通讯作者)，Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang 330032, Jiangxi, Peoples R China.
EM jiang1st@bupt.cn; 918553459@qq.com; fa0001ng@e.ntu.edu.sg; gmshi@xidian.edu.cn; zhaoxw8@sany.com.cn; liuy2655@sany.com.cn
FU National Key Research and Development Program of China [2020AAA0109301]; National Natural Science Foundation of China [62132006, 62161013]; Natural Science Foundation of Jiangxi Province [20202ACB202007, 20203BBE53033]
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Arbelle Assaf, 2021, PROC IEEECVF INT C C, V0, P1801
   Chen K, 2018, PROC CVPR IEEE, V0, PP4042, DOI 10.1109/CVPR.2018.00425
   Chen L, 2017, PROC CVPR IEEE, V0, PP6298, DOI 10.1109/CVPR.2017.667
   Chih-Yao Ma, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12363), V0, PP353, DOI 10.1007/978-3-030-58523-5_21
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Cornia Marcella, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10575, DOI 10.1109/CVPR42600.2020.01059
   Cornia M, 2019, PROC CVPR IEEE, V0, PP8299, DOI 10.1109/CVPR.2019.00850
   Das A, 2017, COMPUT VIS IMAGE UND, V163, P90, DOI 10.1016/j.cviu.2017.10.001
   Datta S, 2019, IEEE I CONF COMP VIS, V0, PP2601, DOI 10.1109/ICCV.2019.00269
   Deng Jiajun, 2021, PROC IEEE INT C COMP, V0, P1769
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   Dogan P, 2019, PROC CVPR IEEE, V0, PP4170, DOI 10.1109/CVPR.2019.00430
   Dognin P, 2019, PROC CVPR IEEE, V0, PP10455, DOI 10.1109/CVPR.2019.01071
   Fei Zhengcong, 2021, PROC AAAI C ARTIF IN, V0, P2
   Gao JL, 2019, PROC CVPR IEEE, V0, PP6293, DOI 10.1109/CVPR.2019.00646
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z
   Guo LT, 2020, IEEE T MULTIMEDIA, V22, P2149, DOI 10.1109/TMM.2019.2951226
   Gupta Tanmay, 2020, ECCV, V0, PP752, DOI 10.1007/978-3-030-58580-844
   Hendricks LA, 2018, LECT NOTES COMPUT SC, V11207, P793, DOI 10.1007/978-3-030-01219-9_47
   Huang BB, 2021, PROC CVPR IEEE, V0, PP16883, DOI 10.1109/CVPR46437.2021.01661
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Ji JZ, 2020, IEEE T IMAGE PROCESS, V29, P7615, DOI 10.1109/TIP.2020.3004729
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li G, 2019, IEEE I CONF COMP VIS, V0, PP8927, DOI 10.1109/ICCV.2019.00902
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CX, 2017, AAAI CONF ARTIF INTE, V0, P4176
   Liu F, 2020, ADV NEURAL INFORM PR, V0, P0
   Liu H, 2021, IEEE T IMAGE PROCESS, V30, P2450, DOI 10.1109/TIP.2021.3051476
   Liu Y, 2021, P IEEECVF C COMPUTER, V0, P5612
   Liu YF, 2020, AAAI CONF ARTIF INTE, V34, P11645
   Longteng Guo, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2017, PROC CVPR IEEE, V0, PP3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Luowei Zhou, 2019, 2019 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP6571, DOI 10.1109/CVPR.2019.00674
   Nenglun Chen, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1966, DOI 10.1145/3474085.3475354
   Pan PB, 2016, PROC CVPR IEEE, V0, PP1029, DOI 10.1109/CVPR.2016.117
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Plummer BA, 2018, LECT NOTES COMPUT SC, V11216, P258, DOI 10.1007/978-3-030-01258-8_16
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Rohrbach A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4035
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shrivastava A, 2016, PROC CVPR IEEE, V0, PP761, DOI 10.1109/CVPR.2016.89
   Song ZL, 2021, AAAI CONF ARTIF INTE, V35, P2584
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wang L, 2021, P IEEECVF C COMPUTER, V0, P14090
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang ZT, 2022, PARTICUOLOGY, V67, P1, DOI 10.1016/j.partic.2021.09.008
   Xiujun I, 2020, ECCV, V0, P0
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Xu, 2023, IEEE TRANS PATTERN ANAL MACH INTELL, V45, P12996, DOI 10.1109/TPAMI.2021.3121705
   Yang ZY, 2019, IEEE I CONF COMP VIS, V0, PP4682, DOI 10.1109/ICCV.2019.00478
   Yingwei Pan, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10968, DOI 10.1109/CVPR42600.2020.01098
   Young P, 2014, T ASSOC COMPUT LING, V2, P67
   Yu LT, 2022, IEEE T MULTIMEDIA, V24, P1775, DOI 10.1109/TMM.2021.3072479
   Zhang HW, 2018, PROC CVPR IEEE, V0, PP4158, DOI 10.1109/CVPR.2018.00437
   Zhang PC, 2021, PROC CVPR IEEE, V0, PP5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang WQ, 2021, AAAI CONF ARTIF INTE, V35, P3394
   Zhang XY, 2021, PROC CVPR IEEE, V0, PP15460, DOI 10.1109/CVPR46437.2021.01521
   Zhou L, 2020, IEEE T IMAGE PROCESS, V29, P694, DOI 10.1109/TIP.2019.2928144
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhou YAN, 2020, PROC CVPR IEEE, V0, PP4776, DOI 10.1109/CVPR42600.2020.00483
NR 73
TC 6
Z9 6
U1 4
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PD JUN 15
PY 2022
VL 31
IS 
BP 3920
EP 3934
DI 10.1109/TIP.2022.3177318
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 2A3KQ
UT WOS:000809404700004
PM 35635813
DA 2023-11-10
ER

PT J
AU Schramowski, P
   Turan, C
   Andersen, N
   Rothkopf, CA
   Kersting, K
AF Schramowski, Patrick
   Turan, Cigdem
   Andersen, Nico
   Rothkopf, Constantin A.
   Kersting, Kristian
TI Large pre-trained language models contain human-like biases of what is right and wrong to do
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
AB Large language models identify patterns in the relations between words and capture their relations in an embedding space. Schramowski and colleagues show that a direction in this space can be identified that separates 'right' and 'wrong' actions as judged by human survey participants. Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a 'moral direction' which can be computed, for example, by a PCA, in the embedding space. The computed 'moral direction' can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the 'moral direction' can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed.
C1 [Schramowski, Patrick; Turan, Cigdem; Kersting, Kristian] Tech Univ Darmstadt, Comp Sci Dept, Artificial Intelligence & Machine Learning Lab, Darmstadt, Germany.
   [Turan, Cigdem; Rothkopf, Constantin A.; Kersting, Kristian] Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany.
   [Andersen, Nico] Leibniz Inst Res & Informat Educ, Frankfurt, Germany.
   [Rothkopf, Constantin A.] Tech Univ Darmstadt, Inst Psychol, Darmstadt, Germany.
   [Rothkopf, Constantin A.; Kersting, Kristian] Hessian Ctr Artificial Intelligence Hessian Ai, Darmstadt, Germany.
C3 Technical University of Darmstadt; Technical University of Darmstadt; Technical University of Darmstadt
RP Schramowski, P; Turan, C (通讯作者)，Tech Univ Darmstadt, Comp Sci Dept, Artificial Intelligence & Machine Learning Lab, Darmstadt, Germany.; Turan, C (通讯作者)，Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany.
EM schramowski@cs.tu-darmstadt.de; cigdem.turan@cs.tu-darmstadt.de
FU ICT-48 Network of AI Research Excellence Center 'TAILOR' (EU Horizon 2020) [952215]; Hessian research priority programme LOEWE within the project WhiteBox; Hessian Ministry of Higher Education, Research and the Arts (HMWK)
CR Abid A, 2021, PERSISTENT ANTIMUSLI, V0, PP298, DOI 10.1145/3461702.3462624
   Alexander L, 2021, STANFORD ENCY PHILOS, V0, P0
   [Anonymous], 2020, NAT MACH INTELL, V2, P419, DOI 10.1038/s42256-020-0223-0
   [Anonymous], 2019, IEEE SPECTRUM, V0, P0
   Bender Emily M, 2021, FACCT 21: PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, V0, P0
   Berreby F, 2015, LECT NOTES COMPUT SC, V9450, P532, DOI 10.1007/978-3-662-48899-7_37
   Bicchieri C, 2018, STANFORD ENCY PHILOS, V0, P0
   Bolukbasi T, 2016, ADV NEUR IN, V29, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Caliskan A, 2017, SCIENCE, V356, P0, DOI 10.1126/science.aal4230
   Cer D, 2018, P EMNLP, V0, P169
   Chami I, 2021, PR MACH LEARN RES, V139, P0
   Chen B, 2021, 9 INT C LEARN REPR, V0, P0
   Chen MX, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2287, DOI 10.1145/3292500.3330723
   Christakis NA, 2019, NATURE, V569, P627, DOI 10.1038/d41586-019-01658-w
   Churchland PS, 2019, CONSCIENCE ORIGINS M, V0, P0
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   Dathathri S, 2020, ICLR, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Fassin Didier, 2012, COMPANION MORAL ANTH, V0, PP1, DOI 10.1002/9781118290620.CH
   Gehman Samuel, 2020, FINDINGS ASS COMPUTA, V0, P3356
   Gert B, 2020, STANFORD ENCY PHILOS, VFall 2020, P0
   Goldberg Yoav, 2019, ABS190105287 ARXIV, V0, P0
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, V0, PP8342, DOI 10.18653/V1/2020.ACL-MAIN.740
   Hendrycks D, 2021, P INT C LEARN REPR, V0, P1
   Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0
   Jentzsch S, 2019, AIES 19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, V0, P0
   Katzenstein Peter J, 1996, CULTURE NATL SECURIT, V0, P0, DOI DOI 10.1057/EJDR.2009.24
   Keskar Nitish Shirish, 2019, CTRL CONDITIONAL TRA, V0, P0
   Kurita K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), V0, P166
   Levine S, 2020, P NATL ACAD SCI USA, V117, P26158, DOI 10.1073/pnas.2014505117
   Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, P241
   Lindström B, 2018, J EXP PSYCHOL GEN, V147, P228, DOI 10.1037/xge0000365
   Maxwell F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P653
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Peng X, 2020, P 13 INT C NATURAL L, V0, P374
   Pereira Luis Moniz, 2009, INTERNATIONAL JOURNAL OF REASONING-BASED INTELLIGENT SYSTEMS, V1, P209, DOI 10.1504/IJRIS.2009.028020
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Reif E, 2019, NEURIPS, V0, P0
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5418
   Ross AS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2662
   Schramowski P, 2020, NAT MACH INTELL, V2, P476, DOI 10.1038/s42256-020-0212-3
   Schramowski P, 2020, FRONT ARTIF INTELL, V3, P0, DOI 10.3389/frai.2020.00036
   Shafer-Landau R, 2012, ETHICAL THEORY ANTHO, V13, P0
   Shwartz V, 2019, T ASSOC COMPUT LING, V7, P403, DOI 10.1162/tacl_a_00277/1923583
   SUMNER LW, 1967, ETHICS, V77, P95, DOI 10.1086/291620
   Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342
   Tan YC, 2019, ADV NEURAL INFORM PR, V0, P13209
   Tenney Ian, 2019, INT C LEARN REPR, V0, P0
   Teso S, 2019, AIES 19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, V0, P0
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang Zhuosheng, 2020, AAAI CONF ARTIF INTE, V0, P9628
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 58
TC 15
Z9 15
U1 9
U2 26
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD MAR 15
PY 2022
VL 4
IS 3
BP 258
EP +
DI 10.1038/s42256-022-00458-8
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA ZY2TX
UT WOS:000772442700005
DA 2023-11-10
ER

PT J
AU Feng, JZ
   Cui, JM
   Wei, QK
   Zhou, ZJ
   Wang, YX
AF Feng, Jianzhou
   Cui, Jinman
   Wei, Qikai
   Zhou, Zhengji
   Wang, Yuxiong
TI A Classification Model of Legal Consulting Questions Based on Multi-Attention Prototypical Networks
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS
LA English
DT Article
DE Legal consulting questions classification; Few-shot learning; Prototypical networks; Instance-dimension level attention
AB Text classification is a research hotspot in the field of natural language processing. Existing text classification models based on supervised learning, especially deep learning models, have made great progress on public datasets. But most of these methods rely on a large amount of training data, and these datasets coverage is limited. In the legal intelligent question-answering system, accurate classification of legal consulting questions is a necessary prerequisite for the realization of intelligent question answering. However, due to lack of sufficient annotation data and the cost of labeling is high, which lead to the poor effect of traditional supervised learning methods under sparse labeling. In response to the above problems, we construct a few-shot legal consulting questions dataset, and propose a prototypical networks model based on multi-attention. For the same category of instances, this model first highlights the key features in the instances as much as possible through instance-dimension level attention. Then it realizes the classification of legal consulting questions by prototypical networks. Experimental results show that our model achieves state-of-the-art results compared with baseline models. The code and dataset are released on https://github.com/cjm0824/MAPN.
C1 [Feng, Jianzhou; Cui, Jinman; Wei, Qikai] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Zhou, Zhengji] Shengming Jizhi Beijing Technol Co Ltd, Beijing 100000, Peoples R China.
   [Wang, Yuxiong] Chongqing NewGo AI Co Ltd, Chongqing 401121, Peoples R China.
C3 Yanshan University
RP Cui, JM (通讯作者)，Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM fjzwxh@ysu.edu.cn; cuijinman@163.com; mrweiqk@163.com
FU National Key Research and Development Program [2020YFC0833404]; Scientific and technological research projects of colleges and universities in Hebei Province [QN2018074]; Nature Scientist Foundation of Hebei Province [F2019203157]
CR Bao Y, 2020, P ICLR, V0, P1
   Du C, 2018, INT J COMPUT COMMUN, V13, P50, DOI 10.15837/ijccc.2018.1.3142
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Gao TY, 2019, AAAI CONF ARTIF INTE, V0, P6407
   Geng RY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1087
   Geng Ruiying, 2019, P 2019 C EMPIRICAL M, V0, P3904
   Han X, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Huang LZ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3444
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Koch G, 2015, ICML, V2, P1
   Mishra Nikhil, 2018, ICLR, V0, P0
   Misra R, 2018, NEWS CATEGORY DATASE, V0, P0
   Satorras Victor Garcia, 2018, INT C LEARN REPR, V0, P0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Snell Jake, 2017, NEURIPS, V0, P0
   Sun SL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P476
   Sung F, 2018, PROC CVPR IEEE, V0, PP1199, DOI 10.1109/CVPR.2018.00131
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vinyals Oriol, 2016, P NEURIPS, V0, P0
   Wang YQ, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3386252
   Zhou Chunting, 2015, ARXIV, V0, P0
NR 21
TC 1
Z9 1
U1 7
U2 23
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1875-6891
EI 1875-6883
J9 INT J COMPUT INT SYS
JI Int. J. Comput. Intell. Syst.
PD JAN 1
PY 2022
VL 14
IS 1
BP 
EP 
DI 10.1007/s44196-021-00053-6
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 0H0ER
UT WOS:000778414000001
DA 2023-11-10
ER

PT J
AU Gumaei, A
   Al-Rakhami, MS
   Hassan, MM
   De Albuquerque, VHC
   Camacho, D
AF Gumaei, Abdu
   Al-Rakhami, Mabrook S.
   Hassan, Mohammad Mehedi
   De Albuquerque, Victor Hugo C.
   Camacho, David
TI An Effective Approach for Rumor Detection of Arabic Tweets Using eXtreme Gradient Boosting Method
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Rumor detection; Arabic; Twitter; machine learning; XGBoost method
ID social media; credibility; users
AB Twitter is currently one of the most popularmicroblogging platforms allowing people to post short messages, news, thoughts, and so on. The Twitter user community is growing very fast. It has an average of 328 million active accounts today, making it one of the most common media for getting information during any influential or important event. Because it is freely used by the public, some credibility checking is required, especially when it comes to events of high importance. Automatic rumor detection in Arabic tweets is a challenging task due to the changes in the structural and morphological nature of the Arabic language, which makes the detection of rumors more difficult than in other languages. In this article, we proposed an effective approach for rumor detection of Arabic tweets using an eXtreme gradient boosting (XGBoost) classifier. We conducted a set of experiments on a public dataset that contained a large number of rumor and non-rumor tweets. The model uses a comprehensive set of features, including content-based, user-based, and topic-based features, allowing one to look at credibility from different angles. The experimental results demonstrated that the proposed XGBoost-based approach achieves 97.18% accuracy on 60% of the dataset as a training set, which is the highest accuracy rate compared with the other methods used in recent related work.
C1 [Gumaei, Abdu; Al-Rakhami, Mabrook S.; Hassan, Mohammad Mehedi] King Saud Univ, Coll Comp & Informat Sci, Riyadh 11362, Saudi Arabia.
   [De Albuquerque, Victor Hugo C.] Fed Inst Educ Sci & Technol Ceara, Fortaleza, Ceara, Brazil.
   [De Albuquerque, Victor Hugo C.] ARMTEC Robot Technol, Fortaleza, Ceara, Brazil.
   [Camacho, David] Univ Politecn Madrid, Comp Syst Engn Dept, Madrid, Spain.
C3 King Saud University; Instituto Federal do Ceara (IFCE); Universidad Politecnica de Madrid
RP Gumaei, A (通讯作者)，King Saud Univ, Coll Comp & Informat Sci, Riyadh 11362, Saudi Arabia.
EM agumaei.c@ksu.edu.sa; malrakhami@ksu.edu.sa; mmhassan@ksu.edu.sa; victor.albuquerque@fe.up.pt; david.camacho@upm.es
FU King Saud University, Riyadh, Saudi Arabia [RSP-2021/18]; CIVIC project (BBVA Foundation Grants for Scientific Research Team SARS-CoV-2); CIVIC project (BBVA Foundation Grants for Scientific Research Team COVID-19); IBERIFIER [CEF-TC-2020-2, 2020-EU-IA-0252, 29374659]; FightDIS [PID2020-117263GB-100]; CHIST-ERA 2017 BDSI PACMEL Project (UPM-Spain) [PCI2019-103623]
CR Al-Khalifa HS, 2011, INT J WEB INF SYST, V7, P130, DOI 10.1108/17440081111141772
   Al-Rakhami MS, 2020, IEEE ACCESS, V8, P155961, DOI 10.1109/ACCESS.2020.3019600
   Alkhair M, 2019, COMM COM INF SC, V1108, P292, DOI 10.1007/978-3-030-32959-4_21
   Alrubaian M, 2019, IEEE ACCESS, V7, P2828, DOI 10.1109/ACCESS.2018.2886314
   Alrubaian M, 2017, CONCURR COMP-PRACT E, V29, P0, DOI 10.1002/cpe.3873
   Alzanin SM, 2019, KNOWL-BASED SYST, V185, P0, DOI 10.1016/j.knosys.2019.104945
   Alzanin SM, 2018, PROCEDIA COMPUT SCI, V142, P294, DOI 10.1016/j.procs.2018.10.495
   [Anonymous], 2009, SIGKDD EXPLOR NEWSL, V11, P10, DOI 10.1145/1656274.1656278
   Bello G, 2013, LECT NOTES ARTIF INT, V8083, P622
   Camacho D, 2020, INFORM FUSION, V63, P88, DOI 10.1016/j.inffus.2020.05.009
   Castillo C, 2011, P 20 INT C WORLD WID, V0, P675
   Chen WL, 2018, PATTERN RECOGN LETT, V105, P226, DOI 10.1016/j.patrec.2017.10.014
   Dayani R, 2015, IEEE I C ADV NETW TE, V0, P0
   Escabias CBort, 2017, TREE BOOSTING DATA C, V0, P0
   Floos AYM, 2020, MEDIA CONTROVERSY BR, V0, P236
   García S, 2009, SOFT COMPUT, V13, P959, DOI 10.1007/s00500-008-0392-y
   Hamidian S, 2019, ARXIV191208926, V0, P0
   Kim JW, 2018, NEW MEDIA SOC, V20, P4807, DOI 10.1177/1461444818784945
   Kwon S, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0168344
   Li C, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (PRAI 2019), V0, PP46, DOI 10.1145/3357777.3357792
   Liang Wu, 2019, ACM SIGKDD EXPLORATIONS NEWSLETTER, V21, P80, DOI 10.1145/3373464.3373475
   Loria S, 2014, TEXTBLOB SIMPLIFIED, V0, P0
   Papadopoulos S, 2016, ACM T INFORM SYST, V34, P0, DOI 10.1145/2870630
   Qazvinian V, 2011, P C EMP METH NAT LAN, V0, PP1589, DOI 10.5555/2145432.2145602
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Sabbeh Sahar F, 2018, JOURNAL OF THEORETICAL AND APPLIED INFORMATION TECHNOLOGY, V96, P2327
   Sahana VP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING AND NETWORK COMMUNICATIONS (COCONET), V0, PP607, DOI 10.1109/CoCoNet.2015.7411251
   Santia GC, 2018, 12 INT AAAI C WEB SO, V0, P0
   Thakur HK, 2018, INT J INF RETR RES, V8, P1, DOI 10.4018/IJIRR.2018070101
   Tian Y, 2020, IEEE ACCESS, V8, P87121, DOI 10.1109/ACCESS.2020.2989180
   Torregrosa J, 2020, BEHAV SCI TERROR POL, V12, P171, DOI 10.1080/19434472.2019.1651751
   Witten IH, 2005, DESIGN USABILITY DIG, V0, PP129, DOI 10.4018/978-1-59140-441-5.CH008
   Wu L, 2017, P 2017 SIAM INT C DA, V0, PP99, DOI 10.1137/1.9781611974973.12
   Xiao YP, 2022, IEEE T EMERG TOP COM, V10, P690, DOI 10.1109/TETC.2020.3034188
   Yang F, 2012, P ACM SIGKDD WORKSH, V0, PP1, DOI 10.1145/2350190.2350203
   Zhang L, 2017, INT GEOPH C QINGD CH, V0, PP1371, DOI 10.1190/IGC2017-351
   Zubiaga A, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3161603
   Zubiaga A, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0150989
NR 38
TC 7
Z9 7
U1 2
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JAN 15
PY 2022
VL 21
IS 1
BP 
EP 
DI 10.1145/3461697
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YU8KX
UT WOS:000752286700008
DA 2023-11-10
ER

PT J
AU Rana, TA
   Shahzadi, K
   Rana, T
   Arshad, A
   Tubishat, M
AF Rana, Toqir A.
   Shahzadi, Kiran
   Rana, Tauseef
   Arshad, Ahsan
   Tubishat, Mohammad
TI An Unsupervised Approach for Sentiment Analysis on Social Media Short Text Classification in Roman Urdu Sentiment analysis on short text classification in Roman Urdu
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Sentiment analysis; roman urdu; opinion extraction; text normalization; roman urdu text classification
ID opinion; extraction; language; pattern; rules
AB During the last two decades, sentiment analysis, also known as opinion mining, has become one of the most explored research areas in Natural Language Processing (NIP) and data mining. Sentiment analysis focuses on the sentiments or opinions of consumers expressed over social media or different web sites. Due to exposure on the Internet, sentiment analysis has attracted vast numbers of researchers over the globe. A large amount of research has been conducted in English, Chinese, and other languages used worldwide. However, Roman Urdu has been neglected despite being the third most used language for communication in the world, covering millions of users around the globe. Although some techniques have been proposed for sentiment analysis in Roman Urdu, these techniques are limited to a specific domain or developed incorrectly due to the unavailability of language resources available for Roman Urdu. Therefore, in this article, we are proposing an unsupervised approach for sentiment analysis in Roman Urdu. First, the proposed model normalizes the text to overcome spelling variations of different words. After normalizing text, we have used Roman Urdu and English opinion lexicons to correctly identify users' opinions from the text. We have also incorporated negation terms and stemming to assign polarities to each extracted opinion. Furthermore, our model assigns a score to each sentence on the basis of the polarities of extracted opinions and classifies each sentence as positive, negative, or neutral. In order to verify our approach, we have conducted experiments on two publicly available datasets for Roman Urdu and compared our approach with the existing model. Results have demonstrated that our approach outperforms existing models for sentiment analysis tasks in Roman Urdu. Furthermore, our approach does not suffer from domain dependency.
C1 [Rana, Toqir A.; Arshad, Ahsan] Univ Lahore, Dept Comp Sci & IT, Lahore 54000, Pakistan.
   [Rana, Toqir A.] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Shahzadi, Kiran] Univ Lahore, Dept Software Engn, Lahore 54000, Pakistan.
   [Rana, Tauseef] Natl Univ Sci & Technol NUST, Dept Comp Software Engn, MCS, Islamabad 44000, Pakistan.
   [Tubishat, Mohammad] Zayed Univ, Coll Technol Innovat, Abu Dhabi 144534, U Arab Emirates.
C3 University of Lahore; Universiti Sains Malaysia; University of Lahore; National University of Sciences & Technology - Pakistan; Zayed University
RP Rana, TA (通讯作者)，Univ Lahore, Dept Comp Sci & IT, Lahore 54000, Pakistan.; Rana, TA (通讯作者)，Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
EM toqirr@gmail.com; shahzadi@se.uol.edu.pk; tauseefrana@mcs.edu.pk; ahsan.arshad@cs.uol.edu.pk; mohammad.tubishat@zu.ac.ae
CR Afzal H, 2013, ESSEM AI IA CIT, V1096, P164
   Akhter MP, 2020, IEEE ACCESS, V8, P91213, DOI 10.1109/ACCESS.2020.2994950
   Al-Ayyoub M, 2019, INFORM PROCESS MANAG, V56, P320, DOI 10.1016/j.ipm.2018.07.006
   Ali AR, 2009, P 7 INT C FRONT INF, V0, P1
   Ali M, 2018, IEEE ACCESS, V6, P7374, DOI 10.1109/ACCESS.2017.2787798
   Amin A, 2020, IEEE ACCESS, V8, P212675, DOI 10.1109/ACCESS.2020.3039548
   Asghar MZ, 2019, EXPERT SYST, V36, P0, DOI 10.1111/exsy.12397
   Awais M, 2019, ACM T ASIAN LOW-RESO, V18, P0, DOI 10.1145/3300050
   Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   Cheah, 2016, 2016 INT C ADV INFOR, V0, P1
   Dargan S, 2020, SOFT COMPUT, V24, P10111, DOI 10.1007/s00500-019-04525-y
   Daud M, 2014, COMPUTER SCI ENG INT, V4, P1
   Ghulam H, 2019, PROCEDIA COMPUT SCI, V147, P131, DOI 10.1016/j.procs.2019.01.202
   Gupta S, 2020, SOFT COMPUT, V24, P5409, DOI 10.1007/s00500-019-04297-5
   Hassan M, 2018, INT ARAB J INF TECHN, V15, P21
   Irvine A, 2012, P 2 WORKSH LANG SOC, V0, P75
   Jabbar Abdul, 2016, P 6 INT C LANG TECHN, V0, P1
   Kaur RP, 2021, VISUAL COMPUT, V37, P1637, DOI 10.1007/s00371-020-01927-0
   Khan K, 2018, INT J ADV COMPUT SC, V9, P646
   Khan K, 2016, KUWAIT J SCI, V43, P129
   Khan M, 2018, P FUT INF COMM C, V0, P630
   Khanna A, 2022, NUTR NEUROSCI, V25, P1240, DOI 10.1080/1028415X.2020.1853410
   Korayem M, 2016, SOC NETW ANAL MIN, V6, P0, DOI 10.1007/s13278-016-0381-6
   Kumar A, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102141
   Kumar MD, 2018, 2018 INT JOINT C NEU, V0, PP1, DOI 10.1109/RAETCS.2018.8443893
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2020, ARCH COMPUT METHOD E, V27, P577, DOI 10.1007/s11831-019-09332-0
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Mahmood Z, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102233
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mehmood K, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3329709
   Meskele D, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102211
   Mukhtar N, 2018, TELEMAT INFORM, V35, P2173, DOI 10.1016/j.tele.2018.08.003
   Mukhtar N, 2018, EXPERT SYST, V35, P0, DOI 10.1111/exsy.12317
   Mukhtar N, 2018, INT J PATTERN RECOGN, V32, P0, DOI 10.1142/S0218001418510011
   Mukund S, 2012, P 2 WORKSHOP LANGUAG, V0, P1
   Mukund S, 2010, ACM TRANS ASIAN LANG, V9, P0, DOI 10.1145/1838751.1838754
   Narang S, 2019, SADHANA-ACAD P ENG S, V44, P0, DOI 10.1007/s12046-019-1126-9
   Narang SR, 2020, SOFT COMPUT, V24, P17279, DOI 10.1007/s00500-020-05018-z
   Narang SR, 2019, SOFT COMPUT, V23, P13603, DOI 10.1007/s00500-019-03897-5
   Nargis GZ, 2016, INT J COMPUTATIONAL, V7, P83
   Noor Faiza, 2019, EMERGING TECHNOLOGIES IN COMPUTING. SECOND INTERNATIONAL CONFERENCE, V0, P0
   Peng HY, 2017, COGN COMPUT, V9, P423, DOI 10.1007/s12559-017-9470-8
   Pergola G, 2019, INFORM PROCESS MANAG, V56, P0, DOI 10.1016/j.ipm.2019.102084
   Rana TA, 2015, PROC 9 INT C IT ASIA, V0, P1
   Rana TA, 2017, INT C COMPUTING INFO, V0, P317
   Rana TA, 2021, INTELL AUTOM SOFT CO, V29, P839, DOI 10.32604/iasc.2021.018572
   Rana TA, 2020, APPL INTELL, V50, P4616, DOI 10.1007/s10489-020-01817-x
   Rana TA, 2019, J INF SCI, V45, P643, DOI 10.1177/0165551518808195
   Rana TA, 2018, ADV SCI LETT, V24, P1370, DOI 10.1166/asl.2018.10752
   Rana TA, 2017, EXPERT SYST APPL, V89, P273, DOI 10.1016/j.eswa.2017.07.047
   Rana TA, 2016, J ICT RES APPL, V10, P76, DOI 10.5614/itbj.ict.res.appl.2016.10.1.6
   Rana TA, 2016, ARTIF INTELL REV, V46, P459, DOI 10.1007/s10462-016-9472-z
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Sharf Z, 2017, INT J COMPUT SCI NET, V17, P213
   Snae C, 2007, PROC WRLD ACAD SCI E, V19, P252
   Sohail O, 2018, P 22 PAC AS C INF SY, V0, P96
   Song C, 2020, KNOWL-BASED SYST, V194, P0, DOI 10.1016/j.knosys.2020.105572
   Syed AZ, 2010, LECT NOTES ARTIF INT, V6437, P32, DOI 10.1007/978-3-642-16761-4_4
   Syed AZ, 2011, LECT NOTES ARTIF INT, V7094, P382, DOI 10.1007/978-3-642-25324-9_33
   Ul Rehman Z, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), V0, PP497, DOI 10.1109/INTECH.2016.7845095
   Vashishtha S, 2019, EXPERT SYST APPL, V138, P0, DOI 10.1016/j.eswa.2019.112834
   Xu GX, 2019, IEEE ACCESS, V7, P51522, DOI 10.1109/ACCESS.2019.2909919
   Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
NR 68
TC 2
Z9 2
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2022
VL 21
IS 2
BP 
EP 
DI 10.1145/3474119
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0C7CH
UT WOS:000775466500007
DA 2023-11-10
ER

PT J
AU Zhang, ZX
   Schomaker, L
AF Zhang, Zhenxing
   Schomaker, Lambert
TI DiverGAN: An Efficient and Effective Single-Stage Framework for Diverse Text-to-Image Generation
SO NEUROCOMPUTING
LA English
DT Article
DE text-to-image generation; lack-of-diversity issue; single-stage framework; generative adversarial network; attention mechanism
ID attention; segmentation; networks
AB In this paper, we concentrate on the text-to-image synthesis task that aims at automatically producing perceptually realistic pictures from text descriptions. Recently, several single-stage methods have been proposed to deal with the problems of a more complicated multi-stage modular architecture. However, they often suffer from the lack-of-diversity issue, yielding similar outputs given a single textual sequence. To this end, we present an efficient and effective single-stage framework (DiverGAN) to generate diverse, plausible and semantically consistent images according to a natural-language description. DiverGAN adopts two novel word-level attention modules, i.e., a channel-attention module (CAM) and a pixel-attention module (PAM), which model the importance of each word in the given sentence while allowing the network to assign larger weights to the significant channels and pixels semantically aligning with the salient words. After that, Conditional Adaptive Instance-Layer Normalization (CAdaILN) is introduced to enable the linguistic cues from the sentence embedding to flexibly manipulate the amount of change in shape and texture, further improving visual-semantic representation and helping stabilize the training. Also, a dual-residual structure is developed to preserve more original visual features while allowing for deeper networks, resulting in faster convergence speed and more vivid details. Furthermore, we propose to plug a fully-connected layer into the pipeline to address the lack-of-diversity problem, since we observe that a dense layer will remarkably enhance the generative capability of the network, balancing the trade-off between a low-dimensional random latent code contributing to variants and modulation modules that use high-dimensional and textual contexts to strength feature maps. Inserting a linear layer after the second residual block achieves the best variety and quality. Both qualitative and quantitative results on benchmark data sets demonstrate the superiority of our DiverGAN for realizing diversity, without harming quality and semantic consistency. (C) 2021 The Authors. Published by Elsevier B.V.
C1 [Zhang, Zhenxing; Schomaker, Lambert] Univ Groningen, Fac Sci & Engn, Bernoulli Inst, NL-9747 Groningen, Netherlands.
C3 University of Groningen
RP Zhang, ZX (通讯作者)，Univ Groningen, Fac Sci & Engn, Bernoulli Inst, NL-9747 Groningen, Netherlands.
EM z.zhang@rug.nl; l.r.b.schomaker@rug.nl
FU Center for Information Technology of the University of Groningen
CR Abernethy J, 2017, CONVERGENCE STABILIT, V0, P0
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Bang D, 2021, IEEE INT CONF COMP V, V0, PP2347, DOI 10.1109/ICCVW54120.2021.00266
   Bi Q, 2021, NEUROCOMPUTING, V436, P147, DOI 10.1016/j.neucom.2021.01.038
   Broer H, 2011, APPL MATH SCI, V172, P1, DOI 10.1007/978-1-4419-6870-8
   Che T, 2016, ARXIV161202136, V0, P0
   Cong XF, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP1828, DOI 10.1145/3394171.3413876
   Fang AQ, 2020, NEUROCOMPUTING, V414, P333, DOI 10.1016/j.neucom.2020.07.014
   Ghosh A, 2018, PROC CVPR IEEE, V0, PP8513, DOI 10.1109/CVPR.2018.00888
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gou Y, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Heusel Martin, 2017, NEURIPS, V6, P7
   Hua X, 2020, NEUROCOMPUTING, V414, P101, DOI 10.1016/j.neucom.2020.06.037
   Kingma DP, 2014, C TRACK P, V0, P0
   Larsen ABL, 2016, PR MACH LEARN RES, V48, P0
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li B, 2021, J NEUROL, V268, P2042, DOI 10.1007/s00415-019-09596-3
   Li PQ, 2021, NEUROCOMPUTING, V429, P199, DOI 10.1016/j.neucom.2020.10.083
   Li W, 2021, PATTERN RECOGN, V110, P0, DOI 10.1016/j.patcog.2020.107646
   Li WH, 2019, PROC CVPR IEEE, V0, PP4998, DOI 10.1109/CVPR.2019.00514
   Lian X, 2019, P MACHINE LEARNING R, V0, P3254
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin ZA, 2018, ADV NEUR IN, V31, P0
   Liu KL, 2019, IEEE I CONF COMP VIS, V0, PP6391, DOI 10.1109/ICCV.2019.00648
   Mao Q, 2019, PROC CVPR IEEE, V0, PP1429, DOI 10.1109/CVPR.2019.00152
   Mei HC, 2021, NEUROCOMPUTING, V438, P211, DOI 10.1016/j.neucom.2020.06.146
   Metz Luke, 2016, ARXIV161102163, V0, P0
   Mirza M, 2014, CONDITIONAL GENERATI, V0, P0
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Qiao TT, 2019, PROC CVPR IEEE, V0, PP1505, DOI 10.1109/CVPR.2019.00160
   Radford Alec, 2015, UNSUPERVISED REPRESE, V0, P0, DOI DOI 10.1007/978-3-319-71589-6_9
   Reed S, 2016, ADV NEUR IN, V29, P0
   Reed S, 2016, PR MACH LEARN RES, V48, P0
   Salimans T, 2016, ADV NEUR IN, V29, P0
   Santurkar S, 2018, ADV NEUR IN, V31, P0
   Schumm T, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Srivastava A, 2017, 5 INT C LEARN REPR I, V0, P0
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tang P, 2021, NEUROCOMPUTING, V435, P103, DOI 10.1016/j.neucom.2020.12.085
   Tao Ming, 2020, ARXIV200805865, V0, P0
   Wah C, 2011, CNSTR2011001 CALTECH, V0, P0
   Wang Z, 2020, NEUROCOMPUTING, V406, P117, DOI 10.1016/j.neucom.2020.03.083
   Xu T, 2018, PROC CVPR IEEE, V0, PP1316, DOI 10.1109/CVPR.2018.00143
   Yin GJ, 2019, PROC CVPR IEEE, V0, PP2322, DOI 10.1109/CVPR.2019.00243
   Zhang DW, 2021, NEUROCOMPUTING, V436, P260, DOI 10.1016/j.neucom.2020.11.046
   Zhang H, 2019, PR MACH LEARN RES, V97, P0
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, V0, PP5908, DOI 10.1109/ICCV.2017.629
   Zhang R, 2018, PROC CVPR IEEE, V0, PP586, DOI 10.1109/CVPR.2018.00068
   Zhang XQ, 2021, NEUROCOMPUTING, V453, P865, DOI 10.1016/j.neucom.2020.04.147
   Zhang Z, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Zhao J, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Zheng YP, 2020, NEUROCOMPUTING, V413, P383, DOI 10.1016/j.neucom.2020.07.016
   Zhu MF, 2019, PROC CVPR IEEE, V0, PP5795, DOI 10.1109/CVPR.2019.00595
NR 56
TC 6
Z9 6
U1 3
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD FEB 7
PY 2022
VL 473
IS 
BP 182
EP 198
DI 10.1016/j.neucom.2021.12.005
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA ZI6WV
UT WOS:000761760200015
DA 2023-11-10
ER

PT J
AU Yang, K
   Yu, HQ
   Fan, GS
   Huang, ZJ
   Zhou, ZY
AF Yang, Kang
   Yu, Huiqun
   Fan, Guisheng
   Huang, Zijie
   Zhou, Ziyi
TI Code Generation with Hybrid of Structural and Semantic Features Retrieval
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE Code generation; deep learning; program comprehension
AB Due to the growing need for faster software delivery, code generation has attracted more and more attention, since it could improve code maintainability by providing suggestions for coding. In the model of generating program source code from natural language (NL), the most effective method is to generate an intermediate architecture (such as Abstract Syntax Tree) combined with a deep learning model. However, these models have the following drawbacks: (1) The data structural information is underutilized and the correlation between samples is not considered. (2) Lack of the ability to memorize large and complex structures, so that complex codes cannot be generated correctly. To address these issues, we propose HRCODE model, a code generation architecture based on Hybrid of structural and semantic features Retrieval CODE model. We transform the NL description into an intermediate structure with structural features. Then, the NL and the intermediate structure are embedded into a vector through weight mixing, and we calculate the similarity score between each vector to retrieve the most relevant samples. Finally, the new input is brought into the PLBART model to generate code. Experiments show that HRCODE is at least 4.7% higher than the state-of-the-art models in the ACC metric and at least 10.3% higher in the BLEU-4 score. We have released our code at https://github.com/jesokang/HRCODE.
C1 [Yang, Kang; Yu, Huiqun; Fan, Guisheng; Huang, Zijie; Zhou, Ziyi] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.
   [Yang, Kang] Shanghai Key Lab Comp Software Evaluating & Testi, Shanghai 201112, Peoples R China.
   [Yu, Huiqun] Shanghai Engn Res Ctr Smart Energy, Shanghai, Peoples R China.
C3 East China University of Science & Technology
RP Yu, HQ (通讯作者)，East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.; Yu, HQ (通讯作者)，Shanghai Engn Res Ctr Smart Energy, Shanghai, Peoples R China.
EM 15921709583@163.com; yhq@ecust.edu.cn; gsfan@ecust.edu.cn; hzj@mail.ecust.edu.cn; zhouziyi96@qq.com
FU National Natural Science Foundation of China [61772200]; Shanghai Natural Science Foundation [21ZR1416300]
CR Ahmad Wasi, 2021, P 2021 C N AM CHAPT, V0, P2655
   [Anonymous], 1969, PROCEESINGS IJCAI 69, V0, P0
   Bowman Samuel R, 2015, ARXIV151106349, V0, P0
   Chen QY, 2018, IEEE INT CONF AUTOM, V0, PP826, DOI 10.1145/3238147.3240471
   Chen XY, 2016, ADV NEUR IN, V29, P0
   Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731
   Gu JT, 2018, AAAI CONF ARTIF INTE, V0, P5133
   Gu XD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), V0, PP933, DOI 10.1145/3180155.3180167
   Haiduc S, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), V0, PP842, DOI 10.1109/ICSE.2013.6606630
   Hayati SA, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P925
   Hill E, 2014, 2014 SOFTWARE EVOLUTION WEEK - IEEE CONFERENCE ON SOFTWARE MAINTENANCE, V0, P0
   Hindle A, 2012, PROC INT CONF SOFTW, V0, PP837, DOI 10.1109/ICSE.2012.6227135
   Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073
   Jia R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P12
   Jiang H, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5076
   Keivanloo I, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), V0, PP664, DOI 10.1145/2568225.2568292
   Kraemer FA, 2011, LECT NOTES COMPUT SC, V6981, P183, DOI 10.1007/978-3-642-24485-8_14
   Li XQ, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P910
   Ling W, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P599
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Locascio N, 2016, P 2016 C EMP METH NA, V0, PP1918, DOI 10.18653/V1/D16-1197
   Lu ML, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Malhotra P, 2015, P ESANN, V89, P0
   MANNA Z, 1971, COMMUN ACM, V14, P151, DOI 10.1145/362566.362568
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Oda Y, 2015, IEEE INT CONF AUTOM, V0, PP574, DOI 10.1109/ASE.2015.36
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Quirk C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P878
   Rabinovich M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1139, DOI 10.18653/v1/P17-1105
   Sunyé G, 2002, INFORM SYST, V27, P445, DOI 10.1016/S0306-4379(02)00014-5
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Vinayakarao V, 2017, WSDM17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP211, DOI 10.1145/3018661.3018691
   Waldinger RJ, 1969, P 1 INT JOINT C ARTI, V0, P241
   Xia X, 2018, IEEE T SOFTWARE ENG, V44, P951, DOI 10.1109/TSE.2017.2734091
   Yin PC, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P7
   Yin PC, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P754
   Yin PC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4553
   Yin PC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P440, DOI 10.18653/v1/P17-1041
   Zhang J, 2018, P 2018 C N AM CHAPT, V0, PP1325, DOI 10.18653/V1/N18-1120
NR 40
TC 0
Z9 0
U1 0
U2 6
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD MAR 15
PY 2022
VL 32
IS 03
BP 457
EP 478
DI 10.1142/S0218194022500267
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1C6CS
UT WOS:000793205300006
DA 2023-11-10
ER

PT J
AU Peng, L
   Yang, Y
   Wang, Z
   Huang, Z
   Shen, HT
AF Peng, Liang
   Yang, Yang
   Wang, Zheng
   Huang, Zi
   Shen, Heng Tao
TI MRA-Net: Improving VQA Via Multi-Modal Relation Attention Network
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Visual question answering; visual relation; attention mechanism; relation attention
AB Visual Question Answering (VQA) is a task to answer natural language questions tied to the content of visual images. Most recent VQA approaches usually apply attention mechanism to focus on the relevant visual objects and/or consider the relations between objects via off-the-shelf methods in visual relation reasoning. However, they still suffer from several drawbacks. First, they mostly model the simple relations between objects, which results in many complicated questions cannot be answered correctly, because of failing to provide sufficient knowledge. Second, they seldom leverage the harmony cooperation of visual appearance feature and relation feature. To solve these problems, we propose a novel end-to-end VQA model, termed Multi-modal Relation Attention Network (MRA-Net). The proposed model explores both textual and visual relations to improve performance and interpretability. In specific, we devise 1) a self-guided word relation attention scheme, which explore the latent semantic relations between words; 2) two question-adaptive visual relation attention modules that can extract not only the fine-grained and precise binary relations between objects but also the more sophisticated trinary relations. Both kinds of question-related visual relations provide more and deeper visual semantics, thereby improving the visual reasoning ability of question answering. Furthermore, the proposed model also combines appearance feature with relation feature to reconcile the two types of features effectively. Extensive experiments on five large benchmark datasets, VQA-1.0, VQA-2.0, COCO-QA, VQA-CP v2, and TDIUC, demonstrate that our proposed model outperforms state-of-the-art approaches.
C1 [Peng, Liang; Yang, Yang; Wang, Zheng; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Peoples R China.
   [Peng, Liang; Yang, Yang; Wang, Zheng; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Yang, Yang] Univ Elect Sci & Technol China UESTC, Inst Elect & Informat Engn, Dongguan 523808, Guangdong, Peoples R China.
   [Huang, Zi] Univ Queensland, St Lucia, Qld 4072, Australia.
C3 University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; University of Queensland
RP Yang, Y (通讯作者)，Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Peoples R China.
EM pliang951125@outlook.com; dlyyang@gmail.com; zh_wang@hotmail.com; huang@itee.uq.edu.au; shenhengtao@hotmail.com
FU National Key Research and Development Program of China [2018AAA0102200]; Sichuan Science and Technology Program, China [2018GZDZX0032, 2020YFS0057]; Fundamental Research Funds for the Central Universities [ZYGX2019Z015]; National Natural Science Foundation of China [61632007]; Dongguan Songshan Lake Introduction Programof Leading Innovative and Entrepreneurial Talents
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2014, P 8 WORKSH SYNT SEM, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, V0, P8102
   Bin Y, 2019, AAAI CONF ARTIF INTE, V0, P8110
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Bin Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1345, DOI 10.1145/3123266.3123391
   Bin Y, 2016, MM16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, V0, PP436, DOI 10.1145/2964284.2967258
   Cadene R, 2019, PROC CVPR IEEE, V0, PP1989, DOI 10.1109/CVPR.2019.00209
   Nguyen DK, 2018, PROC CVPR IEEE, V0, PP6087, DOI 10.1109/CVPR.2018.00637
   Fukui Akira, 2016, ARXIV160601847, V0, PP457, DOI 10.18653/V1/D16-1044
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Han CJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP510, DOI 10.1145/3240508.3240611
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ilievski I, 2017, ADV NEUR IN, V30, P0
   Jun SH, 2017, ICEC17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, V0, P0, DOI DOI 10.1145/3154943.3154947
   Kafle K, 2017, IEEE I CONF COMP VIS, V0, PP1983, DOI 10.1109/ICCV.2017.217
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   LI L, 2019, P INT C COMP VIS, V0, P322
   Li R, 2016, ADV NEURAL INFORM PR, V0, P4655
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4216
   Lu JS, 2016, ADV NEUR IN, V29, P0
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Nam H, 2017, PROC CVPR IEEE, V0, PP2156, DOI 10.1109/CVPR.2017.232
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31, P0
   Peng L, 2022, IEEE T KNOWL DATA EN, V34, P1644, DOI 10.1109/TKDE.2020.2998805
   Peng L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1202, DOI 10.1145/3343031.3350925
   Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3
   Salimans T, 2016, ADV NEUR IN, V29, P0
   Santra A, 2017, ADV GEOSPAT TECH, V0, PP1, DOI 10.4018/978-1-5225-1814-3
   Shen HT, 2021, IEEE T KNOWL DATA EN, V33, P3351, DOI 10.1109/TKDE.2020.2970050
   Shi Y, 2018, LECT NOTES COMPUT SC, V11208, P158, DOI 10.1007/978-3-030-01225-0_10
   Simonyan K, 2015, INT C LEARN REPRESEN, V0, P0
   Singh A, 2019, PROC CVPR IEEE, V0, PP8309, DOI 10.1109/CVPR.2019.00851
   Song JK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P906
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP154, DOI 10.1145/3123266.3123326
   Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP519, DOI 10.1145/3240508.3240513
   Wu CF, 2018, ADV NEUR IN, V31, P0
   Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2017, PROC CVPR IEEE, V0, PP4187, DOI 10.1109/CVPR.2017.446
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, V0, PP1839, DOI 10.1109/ICCV.2017.202
   Zhang MX, 2017, LECT NOTES COMPUT SC, V10538, P261, DOI 10.1007/978-3-319-68155-9_20
   Zhang MX, 2019, IEEE T IMAGE PROCESS, V28, P32, DOI 10.1109/TIP.2018.2855415
   Zhang Y, 2018, P ICLR, V0, P1
   Zhuang BH, 2017, IEEE I CONF COMP VIS, V0, PP589, DOI 10.1109/ICCV.2017.71
NR 56
TC 33
Z9 34
U1 13
U2 92
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JAN 1
PY 2022
VL 44
IS 1
BP 318
EP 329
DI 10.1109/TPAMI.2020.3004830
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA XM0XY
UT WOS:000728561300023
PM 32750794
DA 2023-11-10
ER

PT J
AU Kim, S
   Yoon, B
AF Kim, Sunhye
   Yoon, Byungun
TI Multi-document summarization for patent documents based on generative adversarial network
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Patentsummarization; Generativeadversarialnetwork(GAN); Patentanalysis; Naturallanguageprocessing(NLP); Textmining
ID information
AB Given the exponential growth of patent documents, automatic patent summarization methods to facilitate the patent analysis process are in strong demand. Recently, the development of natural language processing (NLP), text-mining, and deep learning has greatly improved the performance of text summarization models for general documents. However, existing models cannot be successfully applied to patent documents, because patent documents describing an inventive technology and using domain-specific words have many differences from general documents. To address this challenge, we propose in this study a multi-patent summarization approach based on deep learning to generate an abstractive summarization considering the characteristics of a patent. Single patent summarization and multi-patent summarization were performed through a patent-specific feature extraction process, a summarization model based on generative adversarial network (GAN), and an inference process using topic modeling. The proposed model was verified by applying it to a patent in the drone technology field. In consequence, the proposed model performed better than existing deep learning summarization models. The proposed approach enables high-quality information summary for a large number of patent documents, which can be used by R&D researchers and decision-makers. In addition, it can provide a guideline for deep learning research using patent data.
C1 [Kim, Sunhye; Yoon, Byungun] Dongguk Univ, Sch Engn, Dept Ind & Syst Engn, 3-26,Pil Dong 3Ga, Seoul 100715, South Korea.
C3 Dongguk University
RP Yoon, B (通讯作者)，Dongguk Univ, Sch Engn, Dept Ind & Syst Engn, 3-26,Pil Dong 3Ga, Seoul 100715, South Korea.
EM postman3@dongguk.edu
FU National Research Foundation of Korea [NRF-2021R1I1A2045721]
CR Altshuller G, 1996, SUDDENLY INVENTOR AP, V0, P0
   [Anonymous], 2003, P ACL 2003 WORKSH PA, V0, P0
   Arun R, 2010, LECT NOTES ARTIF INT, V6118, P391
   Berduygina Daria, 2020, INTELLIGENT COMPUTING. PROCEEDINGS OF THE 2020 COMPUTING CONFERENCE. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1229), V0, PP625, DOI 10.1007/978-3-030-52246-9_46
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bouayad-Agha N, 2009, 22 INT FLAIRS C, V0, P0
   Brügmann S, 2015, WORLD PAT INF, V40, P30, DOI 10.1016/j.wpi.2014.10.003
   Chiang WC, 2019, APPL ENERG, V242, P1164, DOI 10.1016/j.apenergy.2019.03.117
   Choi SC, 2017, INT CONF UBIQ FUTUR, V0, P18
   Clarke R, 2014, COMPUT LAW SECUR REV, V30, P230, DOI 10.1016/j.clsr.2014.03.002
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.113679
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fedus W, 2018, ICLR, V0, P1
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Giones F, 2017, BUS HORIZONS, V60, P875, DOI 10.1016/j.bushor.2017.08.001
   Girthana K, 2020, SOFT COMPUTING: THEORIES AND APPLICATIONS. PROCEEDINGS OF SOCTA 2018. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1053), V0, PP237, DOI 10.1007/978-981-15-0751-9_22
   Goldstein J, 2000, NAACL ANLP 2000 WORK, V0, P0
   Goodfellow I, 2014, ADV NEURAL INFORM PR, V27, P0
   Grayson M, 1983, INFORM RETRIEVAL CHE, V0, P144
   Guarino G, 2020, 19 IEEE INT C MACH L, V0, P0
   Guo JX, 2018, AAAI CONF ARTIF INTE, V0, P5141
   Guo JF, 2016, TECHNOL FORECAST SOC, V105, P27, DOI 10.1016/j.techfore.2016.01.028
   Haidar MA, 2019, LECT NOTES ARTIF INT, V11489, P107, DOI 10.1007/978-3-030-18305-9_9
   Hovy, 2000, P 18 INT C COMP LING, V0, P0
   Kando N, 2000, P ACM SIGIR 2000 WOR, V0, P0
   Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P423, DOI 10.3115/1075096.1075150
   Ko Y, 2008, PATTERN RECOGN LETT, V29, P1366, DOI 10.1016/j.patrec.2008.02.008
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu LQ, 2018, AAAI CONF ARTIF INTE, V0, P8109
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Magdum PG, 2021, ADV ARTIFICIAL INTEL, V0, P377
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, P0
   Miller DL, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Moehrle MG, 2005, R&D MANAGE, V35, P513, DOI 10.1111/j.1467-9310.2005.00408.x
   Ou S, 2008, J INF SCI, V34, P308, DOI 10.1177/0165551507084630
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Radford Alec, 2016, ICLR, V0, P0, DOI DOI 10.48550/ARXIV.1511.06434
   Rekabdar B, 2019, IEEE INT C SEMANT CO, V0, PP204, DOI 10.1109/ICSC.2019.00047
   Roh T, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9112117
   Sheremetyeva S, 2013, P 5 WORKSH PAT TRANS, V0, P0
   Sheremetyeva S, 2014, P WORKSHOP AUTOMATIC, V0, P0, DOI DOI 10.3115/V1/W14-5605
   Sinha A, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Souza CM, 2019, LECT NOTES ARTIF INT, V11805, P508, DOI 10.1007/978-3-030-30244-3_42
   Straus J, 1997, PRESENT STATE PATENT, V0, PIX
   Thakkar KS, 2010, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ENGINEERING AND TECHNOLOGY (ICETET 2010), V0, PP516, DOI 10.1109/ICETET.2010.104
   Trappey AJC, 2020, ADV ENG INFORM, V43, P0, DOI 10.1016/j.aei.2019.101027
   Trappey AJC, 2009, J SYST SCI SYST ENG, V18, P71, DOI 10.1007/s11518-009-5100-7
   Victoria M, 2004, B AM SOC INFORM SCI, V30, P0, DOI 10.1002/BULT.319
   Vo T, 2021, SGAN4ABSUM SEMANTIC, V0, P0
   Xu J, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Yang M, 2020, INFORM SCIENCES, V521, P46, DOI 10.1016/j.ins.2020.02.040
   Yoon B, 2004, J HIGH TECHNOLOGY MA, V15, P37, DOI 10.1016/J.HITECH.2003.09.003
   Yoon B, 2016, SOUTH KOREA PATENT, V0, Patent No. [20160050729A, 20160050729]
   Yoon B, 2018, TECHNOL FORECAST SOC, V132, P105, DOI 10.1016/j.techfore.2018.01.019
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
   Zhang Y, 2016, P C NEUR INF PROC SY, V0, P1
   Zhang Y, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9081665
   Zhuang HJ, 2019, IEEE ACCESS, V7, P169426, DOI 10.1109/ACCESS.2019.2955087
NR 59
TC 1
Z9 1
U1 9
U2 32
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 30
PY 2022
VL 207
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.117983
EA JUL 2022
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 3B5YV
UT WOS:000828016900004
DA 2023-11-10
ER

PT J
AU Shivakumar, PG
   Narayanan, S
AF Shivakumar, Prashanth Gurunath
   Narayanan, Shrikanth
TI End-to-end neural systems for automatic children speech recognition: An empirical study
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Children speech recognition; End-to-end speech recognition; Residual network; Time depth separable convolutional network; Transformer
AB A key desiderata for inclusive and accessible speech recognition technology is ensuring its robust performance to children's speech. Notably, this includes the rapidly advancing neural network based end-to-end speech recognition systems. Children speech recognition is more challenging due to the larger intra-inter speaker variability in terms of acoustic and linguistic characteristics compared to adult speech. Furthermore, the lack of adequate and appropriate children speech resources adds to the challenge of designing robust end-to-end neural architectures. This study provides a critical assessment of automatic children speech recognition through an empirical study of contemporary state-of-the-art end-to-end speech recognition systems. Insights are provided on the aspects of training data requirements, adaptation on children data, and the effect of children age, utterance lengths, different architectures and loss functions for end-to-end systems and role of language models on the speech recognition performance.
C1 [Shivakumar, Prashanth Gurunath; Narayanan, Shrikanth] Univ Southern Calif, Dept Elect & Comp Engn, Signal Anal & Interpretat Lab, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Shivakumar, PG (通讯作者)，Univ Southern Calif, Dept Elect & Comp Engn, Signal Anal & Interpretat Lab, Los Angeles, CA 90089 USA.
EM pgurunat@usc.edu; shri@sipi.usc.edu
FU Simons Foundation [627148]
CR Amodei D, 2016, PR MACH LEARN RES, V48, P0
   Ba Jimmy Lei, 2016, ARXIV160706450, V0, P0
   Baevski Alexei, 2020, P ADV NEUR INF PROC, V33, P12449
   Bone Daniel, 2017, IEEE SIGNAL PROCESSING MAGAZINE, V34, P196
   Bone D, 2017, AUTISM IMAGING DEVIC, V0, P335
   Chan W, 2016, INT CONF ACOUST SPEE, V0, PP4960, DOI 10.1109/ICASSP.2016.7472621
   Chen, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4774, DOI 10.1109/ICASSP.2018.8462105
   Chorowski J, 2015, ADV NEUR IN, V28, P0
   Cole RA, 2000, 6 INT C SPOK LANG PR, V4, P369
   Collobert R, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Collobert R, 2019, FULLY CONVOLUTIONAL, V0, P0
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Das S, 1998, INT CONF ACOUST SPEE, V0, PP433, DOI 10.1109/ICASSP.1998.674460
   Dauphin YN, 2017, PR MACH LEARN RES, V70, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dong LH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5884, DOI 10.1109/ICASSP.2018.8462506
   Fan Angela, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043
   GALLAGHER TM, 1977, J SPEECH HEAR RES, V20, P303, DOI 10.1044/jshr.2002.303
   Gerosa M, 2006, 9 INT C SPOK LANG PR, V0, P0
   Gerosa M, 2007, SPEECH COMMUN, V49, P847, DOI 10.1016/j.specom.2007.01.002
   GHAI S, 2009, 10 ANN C INT SPEECH, V0, P369
   Giuliani D, 2006, COMPUT SPEECH LANG, V20, P107, DOI 10.1016/j.csl.2005.05.002
   Giuliani D, 2003, INT CONF ACOUST SPEE, V0, P137
   Gong P, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Grangier David, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Graves Alex, 2006, ICML, V0, PP369, DOI 10.1145/1143844.1143891
   Heafield K, 2011, P 6 WORKSH STAT MACH, V0, P369
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Karita S, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP449, DOI 10.1109/ASRU46091.2019.9003750
   Kim J, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Kim S, 2017, INT CONF ACOUST SPEE, V0, PP4835, DOI 10.1109/ICASSP.2017.7953075
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686
   Lee S, 1997, 5 EUR C SPEECH COMM, V0, P369
   Lee S-I, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Lee S, 2014, J ACOUST SOC AM, V136, P1880, DOI 10.1121/1.4894799
   Liao H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1611
   Likhomanenko T, 2019, INTERSPEECH, V0, PP3915, DOI 10.21437/Interspeech.2019-3107
   Narayanan S, 2002, IEEE T SPEECH AUDI P, V10, P65, DOI 10.1109/89.985544
   Panayotov V, 2015, INT CONF ACOUST SPEE, V0, PP5206, DOI 10.1109/ICASSP.2015.7178964
   Park DS, 2019, INTERSPEECH, V0, PP2613, DOI 10.21437/Interspeech.2019-2680
   PARMAR N, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Potamianos A, 2003, IEEE T SPEECH AUDI P, V11, P603, DOI 10.1109/TSA.2003.818026
   Povey D, 2011, IEEE 2011 WORKSHOP A, V0, P0
   Povey D, 2018, INTERSPEECH, V0, PP3743, DOI 10.21437/Interspeech.2018-1417
   Povey D, 2016, INTERSPEECH, V0, PP2751, DOI 10.21437/Interspeech.2016-595
   Pratap Vineel, 2018, ARXIV181207625, V0, P0
   Pundak G, 2017, INTERSPEECH, V0, PP1303, DOI 10.21437/Interspeech.2017-429
   Russell MJ, 2002, 7 INT C SPOK LANG PR, V0, P369
   Saon G, 2017, INTERSPEECH, V0, PP132, DOI 10.21437/Interspeech.2017-405
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Serizel R, 2017, NAT LANG ENG, V23, P325, DOI 10.1017/S135132491600005X
   Shivakumar PG, 2020, COMPUT SPEECH LANG, V63, P0, DOI 10.1016/j.csl.2020.101077
   Shivakumar Prashanth Gurunath, 2014, WOCCI, V5, P15
   Sinha R, 2018, COMPUT SPEECH LANG, V48, P103, DOI 10.1016/j.csl.2017.10.007
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Swietojanski P, 2014, IEEE W SP LANG TECH, V0, PP171, DOI 10.1109/SLT.2014.7078569
   Synnaeve Gabriel, 2019, ARXIV191108460, V0, P0
   Tong R, 2017, INT CONF ASIAN LANG, V0, PP36, DOI 10.1109/IALP.2017.8300540
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang YX, 2017, INTERSPEECH, V0, PP4006, DOI 10.21437/Interspeech.2017-1452
   Ward W, 2019, MY SCI TUTOR MYST CO, V0, P0
   Ward W, 2011, ACM T SPEECH LANGUAG, V7, P1
   Watanabe S, 2017, IEEE J-STSP, V11, P1240, DOI 10.1109/JSTSP.2017.2763455
   Wu F, 2019, INTERSPEECH, V0, PP1, DOI 10.1159/000503583
   Xie XR, 2019, INT CONF ACOUST SPEE, V0, PP5711, DOI 10.1109/ICASSP.2019.8682667
   Xiong W, 2017, IEEE-ACM T AUDIO SPE, V25, P2410, DOI 10.1109/TASLP.2017.2756440
   Xue SF, 2014, IEEE-ACM T AUDIO SPE, V22, P1713, DOI 10.1109/TASLP.2014.2346313
   Zeghidour N, 2018, INTERSPEECH, V0, PP781, DOI 10.21437/Interspeech.2018-2414
   Zhang C, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3224
   Zhang Y, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Zhang Y, 2017, INT CONF ACOUST SPEE, V0, PP4845, DOI 10.1109/ICASSP.2017.7953077
NR 74
TC 5
Z9 5
U1 1
U2 18
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR 15
PY 2022
VL 72
IS 
BP 
EP 
DI 10.1016/j.csl.2021.101289
EA SEP 2021
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA XM4TI
UT WOS:000728821200004
DA 2023-11-10
ER

PT J
AU Nikolaidou, K
   Seuret, M
   Mokayed, H
   Liwicki, M
AF Nikolaidou, Konstantina
   Seuret, Mathias
   Mokayed, Hamam
   Liwicki, Marcus
TI A survey of historical document image datasets
SO INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION
LA English
DT Article
DE Historical documents; Image datasets; Document image analysis; Machine learning
ID handwritten text recognition; icfhr 2018 competition; hidden markov-models; writer identification; segmentation; line; system; binarization; features; extraction
AB This paper presents a systematic literature review of image datasets for document image analysis, focusing on historical documents, such as handwritten manuscripts and early prints. Finding appropriate datasets for historical document analysis is a crucial prerequisite to facilitate research using different machine learning algorithms. However, because of the very large variety of the actual data (e.g., scripts, tasks, dates, support systems, and amount of deterioration), the different formats for data and label representation, and the different evaluation processes and benchmarks, finding appropriate datasets is a difficult task. This work fills this gap, presenting a meta-study on existing datasets. After a systematic selection process (according to PRISMA guidelines), we select 65 studies that are chosen based on different factors, such as the year of publication, number of methods implemented in the article, reliability of the chosen algorithms, dataset size, and journal outlet. We summarize each study by assigning it to one of three pre-defined tasks: document classification, layout structure, or content analysis. We present the statistics, document type, language, tasks, input visual aspects, and ground truth information for every dataset. In addition, we provide the benchmark tasks and results from these papers or recent competitions. We further discuss gaps and challenges in this domain. We advocate for providing conversion tools to common formats (e.g., COCO format for computer vision tasks) and always providing a set of evaluation metrics, instead of just one, to make results comparable across studies.
C1 [Nikolaidou, Konstantina; Mokayed, Hamam; Liwicki, Marcus] Lulea Univ Technol, EISLAB Machine Learning Grp, Aurorum 1, S-97187 Lulea, Norrbotten, Sweden.
   [Seuret, Mathias] Friedrich Alexander Univ, Pattern Recognit Lab Comp Vis Grp, Martensstr 3, D-91058 Erlangen, Bavaria, Germany.
C3 Lulea University of Technology; University of Erlangen Nuremberg
RP Nikolaidou, K (通讯作者)，Lulea Univ Technol, EISLAB Machine Learning Grp, Aurorum 1, S-97187 Lulea, Norrbotten, Sweden.
EM konstantina.nikolaidou@ltu.se; mathias.seuret@fau.de; hamam.mokayed@ltu.se; marcus.liwicki@ltu.se
FU Lulea University of Technology
CR Adam K, 2018, INT J DOC ANAL RECOG, V21, P283, DOI 10.1007/s10032-018-0312-3
   Alaei, 2011, 2011 7 IRANIAN C MAC, V0, PP1, DOI 10.1109/IranianMVIP.2011.6121553
   Alaei A, 2012, INT J PATTERN RECOGN, V26, P0, DOI 10.1142/S0218001412530011
   Alaei A, 2011, PATTERN ANAL APPL, V14, P381, DOI 10.1007/s10044-011-0226-x
   Alaei A, 2011, PATTERN RECOGN, V44, P917, DOI 10.1016/j.patcog.2010.10.014
   Almazán J, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, V0, P0, DOI DOI 10.5244/C.26.67
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Sanchez JA, 2019, PATTERN RECOGN, V94, P122, DOI 10.1016/j.patcog.2019.05.025
   Sánchez JA, 2017, PROC INT CONF DOC, V0, PP1383, DOI 10.1109/ICDAR.2017.226
   Sanchez JA, 2016, INT CONF FRONT HAND, V0, PP630, DOI 10.1109/ICFHR.2016.0120
   Sánchez JA, 2014, INT CONF FRONT HAND, V0, PP785, DOI 10.1109/ICFHR.2014.137
   Sánchez JA, 2015, PROC INT CONF DOC, V0, PP1166, DOI 10.1109/ICDAR.2015.7333944
   Anna Scius-Bertrand, 2021, HIP 21: THE 6TH INTERNATIONAL WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING, V0, PP37, DOI 10.1145/3476887.3476913
   Arora Ashish, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP663, DOI 10.1109/ICDAR.2019.00111
   Arvanitopoulos N, 2017, P 4 INT WORKSHOP HIS, V0, P0
   Arvanitopoulos N, 2014, INT CONF FRONT HAND, V0, PP726, DOI 10.1109/ICFHR.2014.127
   Belay Birhanu, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1268, DOI 10.1109/ICDAR.2019.00205
   Binmakhashen GM, 2020, ACM COMPUT SURV, V52, P0, DOI 10.1145/3355610
   Bishop Christopher M, 1994, TECHNICAL REPORT, V0, P0
   Boillet M, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING (HIP 19), V0, PP7, DOI 10.1145/3352631.3352633
   Breuel TM, 2008, PROC SPIE, V6815, P0, DOI 10.1117/12.783598
   Brink AA, 2012, PATTERN RECOGN, V45, P162, DOI 10.1016/j.patcog.2011.07.005
   Bromley J, 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   Burie JC, 2016, INT CONF FRONT HAND, V0, PP596, DOI 10.1109/ICFHR.2016.0114
   Causer T, 2012, DIGIT HUMANITIES Q, V6, P0
   Chen YK, 2000, IEEE T PATTERN ANAL, V22, P1304, DOI 10.1109/34.888715
   CHOLLET F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Christlein Vincent, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1505, DOI 10.1109/ICDAR.2019.00242
   Christlein V, 2017, PROC INT CONF DOC, V0, PP991, DOI 10.1109/ICDAR.2017.165
   Christlein V, 2017, PATTERN RECOGN, V63, P258, DOI 10.1016/j.patcog.2016.10.005
   Christiein V, 2015, PROC INT CONF DOC, V0, PP906, DOI 10.1109/ICDAR.2015.7333893
   Cilia Nicole Dalia, 2021, PATTERN RECOGNITION. ICPR INTERNATIONAL WORKSHOPS AND CHALLENGES. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12667), V0, PP223, DOI 10.1007/978-3-030-68787-8_16
   Clanuwat T, 2018, ARXIV, V0, P0
   Clausner Christian, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1527, DOI 10.1109/ICDAR.2019.00246
   Clausner C, 2017, PROC INT CONF DOC, V0, PP1411, DOI 10.1109/ICDAR.2017.230
   Clausner C, 2011, PROC INT CONF DOC, V0, PP48, DOI 10.1109/ICDAR.2011.19
   Clausner C, 2018, INT CONF FRONT HAND, V0, PP471, DOI 10.1109/ICFHR-2018.2018.00088
   Clausner C, 2015, PROC INT CONF DOC, V0, PP931, DOI 10.1109/ICDAR.2015.7333898
   Clinchant S, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), V0, PP133, DOI 10.1109/DAS.2018.44
   Cloppet F, 2017, PROC INT CONF DOC, V0, PP1371, DOI 10.1109/ICDAR.2017.224
   Cloppet F, 2016, INT CONF FRONT HAND, V0, PP590, DOI 10.1109/ICFHR.2016.106
   Constum T, 2022, LECT NOTES COMPUT SC, V13237, P143, DOI 10.1007/978-3-031-06555-2_10
   Coquenet D, 2022, IEEE T PATTERN ANAL, V0, P1
   Dalal N, 2005, PROC CVPR IEEE, V0, PP886, DOI 10.1109/cvpr.2005.177
   Dehak N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P864
   Diem M, 2017, PROC INT CONF DOC, V0, PP1355, DOI 10.1109/ICDAR.2017.222
   Djeddi C, 2013, PATTERN RECOGN LETT, V34, P1196, DOI 10.1016/j.patrec.2013.03.020
   Dolfing HJGA, 2020, INT CONF FRONT HAND, V0, PP67, DOI 10.1109/ICFHR2020.2020.00023
   Dulla A, 2018, IET C P, V0, PP10, DOI 10.1049/cp.2018.1286
   En S, 2017, J ELECTRON IMAGING, V26, P0, DOI 10.1117/1.JEI.26.1.011010
   En S, 2016, PATTERN RECOGN, V54, P149, DOI 10.1016/j.patcog.2016.01.014
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fernández-Mota D, 2014, INT C PATT RECOG, V0, PP256, DOI 10.1109/ICPR.2014.53
   Fernández-Mota D, 2014, INT J DOC ANAL RECOG, V17, P293, DOI 10.1007/s10032-014-0220-0
   Fiel S, 2017, PROC INT CONF DOC, V0, PP1377, DOI 10.1109/ICDAR.2017.225
   Fischer A, 2010, P 9 IAPR INT WORKSH, V0, PP3, DOI 10.1145/1815330.1815331
   Fischer A, 2011, P 2011 WORKSH HIST D, V0, PP29, DOI 10.1145/2037342.2037348
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Fischer A, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), V0, PP137, DOI 10.1109/VSMM.2009.26
   Fornés A, 2017, PROC INT CONF DOC, V0, PP1389, DOI 10.1109/ICDAR.2017.227
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Gatos B, 2011, PROC INT CONF DOC, V0, PP1160, DOI 10.1109/ICDAR.2011.234
   Gatos Basilis, 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP1375, DOI 10.1109/ICDAR.2009.246
   Gatos B, 2015, PROC INT CONF DOC, V0, PP646, DOI 10.1109/ICDAR.2015.7333841
   Gattal A, 2017, PATTERN ANAL APPL, V20, P307, DOI 10.1007/s10044-017-0607-x
   Gattal A, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, V0, P305, DOI 10.1109/DAS.2016.10
   Giotis AP, 2017, PATTERN RECOGN, V68, P310, DOI 10.1016/j.patcog.2017.02.023
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Graves Alex, 2006, ICML, V0, PP369, DOI 10.1145/1143844.1143891
   Grüning T, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), V0, PP351, DOI 10.1109/DAS.2018.38
   Ha D, 2018, ARXIV, V0, P0
   Hajic J, 2017, PROC INT CONF DOC, V0, PP39, DOI 10.1109/ICDAR.2017.16
   Harley AW, 2015, PROC INT CONF DOC, V0, PP991, DOI 10.1109/ICDAR.2015.7333910
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/ICCV.2017.322
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Hussain R, 2015, EURASIP J IMAGE VIDE, V0, P0, DOI DOI 10.1186/s13640-015-0102-5
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Karatzas D, 2015, PROC INT CONF DOC, V0, PP1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, V0, PP1484, DOI 10.1109/ICDAR.2013.221
   Kassis M, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP11, DOI 10.1109/ASAR.2017.8067751
   Kassis M, 2016, INT CONF FRONT HAND, V0, PP31, DOI 10.1109/ICFHR.2016.0019
   Kassis M, 2014, INT CONF FRONT HAND, V0, PP387, DOI 10.1109/ICFHR.2014.71
   Kesiman MWA, 2018, INT CONF FRONT HAND, V0, PP483, DOI 10.1109/ICFHR-2018.2018.00090
   Kesiman MWA, 2016, INT CONF FRONT HAND, V0, PP168, DOI 10.1109/ICFHR.2016.0042
   Kiessling B, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING (HIP 19), V0, PP13, DOI 10.1145/3352631.3352648
   Kim SH, 2001, PROCEEDINGS OF SIXTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, V0, PP189, DOI 10.1109/ICDAR.2001.953781
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiss M, 2022, LECT NOTES COMPUT SC, V13237, P158, DOI 10.1007/978-3-031-06555-2_11
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kurar Barakat Berat, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP732, DOI 10.1109/ICDAR.2019.00122
   Kusetogullari H, 2021, BIG DATA RES, V23, P0, DOI 10.1016/j.bdr.2020.100182
   Kusetogullari H, 2020, NEURAL COMPUT APPL, V32, P16505, DOI 10.1007/s00521-019-04163-3
   Lang E, 2018, INT CONF FRONT HAND, V0, PP44, DOI 10.1109/ICFHR-2018.2018.00017
   LeCun Yann, 1998, MNIST DATABASE HANDW, V0, P0, DOI DOI 10.1561/2400000035
   Lee BCG, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP3055, DOI 10.1145/3340531.3412767
   Leydier Y, 2007, PATTERN RECOGN, V40, P3552, DOI 10.1016/j.patcog.2007.04.024
   Leydier Y, 2009, PATTERN RECOGN, V42, P2089, DOI 10.1016/j.patcog.2009.01.026
   Liangcai Gao, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1510, DOI 10.1109/ICDAR.2019.00243
   Likforman-Sulem L, 2007, INT J DOC ANAL RECOG, V9, P123, DOI 10.1007/s10032-006-0023-z
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lombardi F, 2020, J IMAGING, V6, P0, DOI 10.3390/jimaging6100110
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maarand M, 2022, LECT NOTES COMPUT SC, V13237, P399, DOI 10.1007/978-3-031-06555-2_27
   Marinai S, 2005, IEEE T PATTERN ANAL, V27, P23, DOI 10.1109/TPAMI.2005.4
   Mark P, 2021, DIGITAL PETER NEW DA, V0, PP43, DOI 10.1145/3476887.3476892
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   Mehri Maroua, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1488, DOI 10.1109/ICDAR.2019.00239
   Mehri M, 2017, PATTERN ANAL APPL, V20, P325, DOI 10.1007/s10044-015-0451-9
   Mehri Maroua, 2017, WORKSH HIST DOC IM P, V0, P0
   Merabti H, 2018, INFORM-J COMPUT INFO, V42, P95
   Mohammed Hussein, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP726, DOI 10.1109/ICDAR.2019.00121
   Mohammed H, 2017, PROC INT CONF DOC, V0, PP1013, DOI 10.1109/ICDAR.2017.168
   Monnier T, 2020, INT CONF FRONT HAND, V0, PP91, DOI 10.1109/ICFHR2020.2020.00027
   Namboodiri AM, 2007, ADV PATTERN RECOGNIT, V0, PP29, DOI 10.1007/978-1-84628-726-8_2
   Neudecker Clemens, 2021, HIP 21: THE 6TH INTERNATIONAL WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING, V0, PP13, DOI 10.1145/3476887.3476888
   Newell AJ, 2014, PATTERN RECOGN, V47, P2255, DOI 10.1016/j.patcog.2013.11.029
   Nicolaou Anguelos, 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP626, DOI 10.1109/ICDAR.2009.243
   Nikolaou N, 2010, IMAGE VISION COMPUT, V28, P590, DOI 10.1016/j.imavis.2009.09.013
   Nina, 2018, NEPHI OPEN SOURCE PY, V0, P0
   Oliveira SA, 2018, INT CONF FRONT HAND, V0, PP7, DOI 10.1109/ICFHR-2018.2018.00011
   Pantke W, 2014, INT CONF FRONT HAND, V0, PP15, DOI 10.1109/ICFHR.2014.11
   Pantke W, 2013, PROC INT CONF DOC, V0, PP1300, DOI 10.1109/ICDAR.2013.263
   Papadopoulos C, 2013, P 2 INT WORKSHOP HIS, V0, PP123, DOI 10.1145/2501115.2501130
   Perez Daniel, 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP301, DOI 10.1109/ICDAR.2009.10
   Perronnin Florent, 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP106, DOI 10.1109/ICDAR.2009.16
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Pletschacher S, 2010, PROCEEDINGS OF THE 2010 20TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR 2010), V0, PP257, DOI 10.1109/ICPR.2010.72
   Prasad Animesh, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP287, DOI 10.1109/ICDAR.2019.00054
   Prasad D, 2020, IEEE COMPUT SOC CONF, V0, PP2439, DOI 10.1109/CVPRW50498.2020.00294
   Pratikakis Ioannis, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1547, DOI 10.1109/ICDAR.2019.00249
   Pratikakis I, 2018, INT CONF FRONT HAND, V0, PP489, DOI 10.1109/ICFHR-2018.2018.00091
   Pratikakis I, 2017, PROC INT CONF DOC, V0, PP1395, DOI 10.1109/ICDAR.2017.228
   Pratikakis I, 2013, PROC INT CONF DOC, V0, PP1471, DOI 10.1109/ICDAR.2013.219
   Pratikakis I, 2011, PROC INT CONF DOC, V0, PP1506, DOI 10.1109/ICDAR.2011.299
   Puigcerver J, 2018, PYLAIA, V0, P0
   Quiros, 2021, VORAU ABBEY LIB COD, V0, P0
   Quiros, 2020, FINNISH COURT RECORD, V0, P0
   Quiros L, 2018, ARXIV, V0, P0
   Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8
   Redmon J, 2018, ARXIV, V0, P0
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Rodríguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005
   ROMERO V, 1900, P10141, V0, P0
   Romero V, 2013, PATTERN RECOGN, V46, P1658, DOI 10.1016/j.patcog.2012.11.024
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusiñol M, 2011, PROC INT CONF DOC, V0, PP63, DOI 10.1109/ICDAR.2011.22
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saini Rajkumar, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1499, DOI 10.1109/ICDAR.2019.00241
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Schubert E, 2017, ACM T DATABASE SYST, V42, P0, DOI 10.1145/3068335
   Serrano N, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P2709
   Seuret M, 2021, LECT NOTES COMPUT SC, V12824, P618, DOI 10.1007/978-3-030-86337-1_41
   Seuret M, 2020, INT CONF FRONT HAND, V0, PP216, DOI 10.1109/ICFHR2020.2020.00048
   Seuret M, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING (HIP 19), V0, PP1, DOI 10.1145/3352631.3352640
   Seuret M, 2016, INT CONF FRONT HAND, V0, PP459, DOI 10.1109/ICFHR.2016.85
   Shahkolaei A, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP156, DOI 10.1109/ASAR.2018.8480372
   Shao YX, 2013, INT J DOC ANAL RECOG, V16, P413, DOI 10.1007/s10032-012-0194-8
   Shen Zejiang, 2020, IEEE C COMP VIS PATT, V0, P548
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shuangping Huang, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP681, DOI 10.1109/ICDAR.2019.00114
   Simistira F, 2017, PROC INT CONF DOC, V0, PP1361, DOI 10.1109/ICDAR.2017.223
   Simistira F, 2016, INT CONF FRONT HAND, V0, PP471, DOI 10.1109/ICFHR.2016.0093
   Simonyan K, 2015, ARXIV, V0, P0
   Songxuan Lai, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1137, DOI 10.1109/ICDAR.2019.00184
   Stoekl Ben Ezra Daniel, 2021, HIP 21: THE 6TH INTERNATIONAL WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING, V0, PP61, DOI 10.1145/3476887.3476896
   Sudholt S, 2016, INT CONF FRONT HAND, V0, PP277, DOI 10.1109/ICFHR.2016.0060
   Suryani M, 2017, PROC INT CONF DOC, V0, PP796, DOI 10.1109/ICDAR.2017.135
   Szegedy C, 2014, ARXIV, V0, P0
   Tang YY, 1996, PATTERN RECOGN, V29, P1931, DOI 10.1016/S0031-3203(96)00044-1
   Toselli AH, 2004, INT J PATTERN RECOGN, V18, P519, DOI 10.1142/S0218001404003344
   Toselli AH, 2007, PROC INT CONF DOC, V0, P944
   Valy D, 2017, P 4 INT WORKSH HIST, V0, PP1, DOI 10.1145/3151509.3151510
   Verma V, 2019, PR MACH LEARN RES, V97, P0
   Vinciarelli A, 2002, INT C PATT RECOG, V0, PP81, DOI 10.1109/ICPR.2002.1047800
   Voigtlaender P, 2016, INT CONF FRONT HAND, V0, PP228, DOI 10.1109/ICFHR.2016.48
   Wolf C, 2002, INT C PATT RECOG, V0, PP1037, DOI 10.1109/ICPR.2002.1048482
   Wu Yuxin, 2019, DETECTRON2, V0, P0
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Xu Zhong, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1015, DOI 10.1109/ICDAR.2019.00166
   Yang HL, 2018, IEEE ACCESS, V6, P30174, DOI 10.1109/ACCESS.2018.2840218
   Yang HM, 2018, PROC CVPR IEEE, V0, PP3474, DOI 10.1109/CVPR.2018.00366
   Yue Xu, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP793, DOI 10.1109/ICDAR.2019.00132
   Zhang H, 2018, ARXIV, V0, P0
   Zhang XY, 2017, PATTERN RECOGN, V61, P348, DOI 10.1016/j.patcog.2016.08.005
   Zhaowei Cai, 2018, 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION. PROCEEDINGS, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Zhuang Juntang, 2018, ARXIV, V0, P0
   Ziomek, 2021, GLOSAT HIST MEASUREM, V0, PP49, DOI 10.1145/3476887.3476890
NR 194
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1433-2833
EI 1433-2825
J9 INT J DOC ANAL RECOG
JI Int. J. Doc. Anal. Recognit.
PD DEC 15
PY 2022
VL 25
IS 4
BP 305
EP 338
DI 10.1007/s10032-022-00405-8
EA JUL 2022
PG 34
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6M4CX
UT WOS:000833450300001
DA 2023-11-10
ER

PT J
AU Sobieszek, A
   Price, T
AF Sobieszek, Adam
   Price, Tadeusz
TI Playing Games with Ais: The Limits of GPT-3 and Similar Large Language Models
SO MINDS AND MACHINES
LA English
DT Article
DE GPT-3; Artificial Intelligence; Psychometrics; Language Games; Turing test
AB This article contributes to the debate around the abilities of large language models such as GPT-3, dealing with: firstly, evaluating how well GPT does in the Turing Test, secondly the limits of such models, especially their tendency to generate falsehoods, and thirdly the social consequences of the problems these models have with truth-telling. We start by formalising the recently proposed notion of reversible questions, which Floridi & Chiriatti (2020) propose allow one to 'identify the nature of the source of their answers', as a probabilistic measure based on Item Response Theory from psychometrics. Following a critical assessment of the methodology which led previous scholars to dismiss GPT's abilities, we argue against claims that GPT-3 completely lacks semantic ability. Using ideas of compression, priming, distributional semantics and semantic webs we offer our own theory of the limits of large language models like GPT-3, and argue that GPT can competently engage in various semantic tasks. The real reason GPT's answers seem senseless being that truth-telling is not amongst them. We claim that these kinds of models cannot be forced into producing only true continuation, but rather to maximise their objective function they strategize to be plausible instead of truthful. This, we moreover claim, can hijack our intuitive capacity to evaluate the accuracy of its outputs. Finally, we show how this analysis predicts that a widespread adoption of language generators as tools for writing could result in permanent pollution of our informational ecosystem with massive amounts of very plausible but often untrue texts.
C1 [Sobieszek, Adam] Univ Warsaw, Dept Psychol, Warsaw, Poland.
   [Price, Tadeusz] Univ Nottingham, Dept Philosophy, Nottingham, England.
C3 University of Warsaw; University of Nottingham
RP Price, T (通讯作者)，Univ Nottingham, Dept Philosophy, Nottingham, England.
EM apytp2@nottingham.ac.uk
CR Almeida F, 2019, WORD EMBEDDINGS SURV, V0, P0, DOI DOI 10.48550/ARXIV.1901.09069
   [Anonymous], 1994, POSSIBLE WORLDS LIT, V0, P0
   [Anonymous], 1666, DISSERTATIO ARTE COM, V0, P0
   Bartolucci F, 2007, PSYCHOMETRIKA, V72, P141, DOI 10.1007/s11336-005-1376-9
   Bernstein J, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen Mark, 2021, EVALUATING LARGE LAN, V0, P0
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407
   COLLINS AM, 1969, J VERB LEARN VERB BE, V8, P240, DOI 10.1016/S0022-5371(69)80069-1
   CONNEAU A, 2018, ACL, V0, P2126
   DAMASSINO N, 2020, MIND MACH, V30, P0
   Embretson SE, 2000, ITEM RESPONSE THEORY, V0, P0
   ERICKSON TD, 1981, J VERB LEARN VERB BE, V20, P540, DOI 10.1016/S0022-5371(81)90165-1
   Finnie-Ansley J, 2022, AUSTR COMP ED C, V0, P1019
   Firth JR, 1957, SYNOPSIS LINGUISTIC, V0, P0
   Floridi L, 2017, PHILOS TECHNOLOGY, V30, P123, DOI 10.1007/s13347-017-0259-1
   Floridi L, 2019, PHILOS TECHNOLOGY, V0, P0, DOI DOI 10.1007/s13347-019-00345-y
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Floridi L, 2011, METAPHILOSOPHY, V42, P282, DOI 10.1111/j.1467-9973.2011.01693.x
   Floridi L, 2011, ERKENNTNIS, V74, P147, DOI 10.1007/s10670-010-9249-8
   GILBERT DT, 1991, AM PSYCHOL, V46, P107, DOI 10.1037/0003-066X.46.2.107
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gwern Branwen, 2020, GPT 3 CREATIVE FICTI, V0, P0
   Heller F, 1957, WHATS MY LINE, V0, P0
   Hendrycks D, 2021, ARXIV, V0, P0
   Hutson M, 2021, ROBO WRITERS RISE RI, V0, P0
   Justyna B, 2016, FOLIA OECONOMICA STE, V16, P163, DOI 10.1515/FOLI-2016-0032
   Kaminska, 2020, GPT 3 LANGUAGE TOOL, V0, P0
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Lample G, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Lewis DK, 1986, PLURALITY WORLDS, V0, P0
   Mahoney, 2006, RATIONALE LARGE TEXT, V0, P0
   Marcus G, 2020, TECHNOL REV, V0, P0
   Mercier H, 2021, ROYAL I PHILOS S, V89, P257, DOI 10.1017/S1358246121000096
   Mercier H, 2020, NOT BORN YESTERDAY, V0, P0
   Mercier H, 2017, THE ENIGMA OF REASON, V0, P0
   Montemayor C, 2021, MIND MACH, V31, P471, DOI 10.1007/s11023-021-09568-5
   Mulder J, 2009, PSYCHOMETRIKA, V74, P273, DOI 10.1007/s11336-008-9097-5
   Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592
   OpenAI, 2021, EXAMPLES, V0, P0
   Pal D, 2021, GENERATES CODE USING, V0, P0
   Pearl J, 2002, AI MAG, V23, P95
   Pearl J, 2019, THE BOOK OF WHY, V0, P0
   Pennycook G, 2021, NATURE, V592, P590, DOI 10.1038/s41586-021-03344-2
   Peregrin J, 2021, MIND MACH, V31, P305, DOI 10.1007/s11023-021-09564-9
   Prenner, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reynolds L, 2021, 2021 CHI C HUM FACT, V0, P0
   Russell S, 2019, HUMAN COMPATIBLE ART, V0, P0
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038
   Shannon CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shin Taylor, 2020, P EMNLP 2020, V0, P0
   Shmilovici A, 2009, COMPUT ECON, V33, P131, DOI 10.1007/s10614-008-9153-3
   Sperber D, 2010, MIND LANG, V25, P359, DOI 10.1111/j.1468-0017.2010.01394.x
   Umanath S, 2014, PERSPECT PSYCHOL SCI, V9, P408, DOI 10.1177/1745691614535933
   Wang Chaoqi, 2020, INT C LEARNING REPRE, V0, P0
   Zhao TZ, 2021, PR MACH LEARN RES, V139, P0
   Zimmerman A, 2020, DAILY NOUS 0730, V0, P0
NR 59
TC 12
Z9 12
U1 9
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-6495
EI 1572-8641
J9 MIND MACH
JI Minds Mach.
PD JUN 15
PY 2022
VL 32
IS 2
BP 341
EP 364
DI 10.1007/s11023-022-09602-0
EA MAY 2022
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1U7HG
UT WOS:000790126500001
DA 2023-11-10
ER

PT J
AU Heidari, N
   Moradi, P
   Koochari, A
AF Heidari, Narges
   Moradi, Parham
   Koochari, Abbas
TI An attention-based deep learning method for solving the cold-start and sparsity issues of recommender systems
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Recommender systems; Matrix factorization; Deep learning; Attention mechanism
ID matrix factorization; information; network; model
AB Matrix Factorization is a successful approach for generating an effective recommender system. However, most existing matrix factorization methods suffer from the sparsity and cold-start issues of the user-item matrix as the primary information source of recommender systems. Besides, they are not much scalable to apply to large real-world applications. A main idea to overcome the cold-start and sparsity issues is to use additional information sources such as user/item profiles or user reviews on items. In this paper, a novel Attention-based Deep Learning Recommender System, so-called ADLRS, is proposed to employ the information sources in the matrix factorization method framework. The proposed method uses a language model to represent contextual information such that important features are effectively embedded. Moreover, a deep autoencoder reduces the dimensionality of item vectors embedded by the language model. Then, these vectors are used as regularization terms in the matrix factorization framework to form an objective function. Then, an iterative algorithm is designed to solve the objective function and provide a method prediction of unknown rating values. Experimental results show that the proposed method achieves superior performance compared to other state-of-the-art ones in most cases. Moreover, the improvement rate for sparse datasets and cold items proves that the proposed method effectively deals with sparsity, cold start and scalability problems. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Heidari, Narges; Koochari, Abbas] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Moradi, Parham] Univ Kurdistan, Dept Comp Engn, Sanandaj, Iran.
C3 Islamic Azad University; University of Kurdistan
RP Moradi, P (通讯作者)，Univ Kurdistan, Dept Comp Engn, Sanandaj, Iran.
EM haidari78@gmail.com; p.moradi@uok.ac.ir; koochari@srbiau.ac.ir
CR Aditya PH, 2016, INT C ADV COMP SCI I, V0, PP303, DOI 10.1109/ICACSIS.2016.7872755
   Ahmadian S, 2020, KNOWL-BASED SYST, V192, P0, DOI 10.1016/j.knosys.2019.105371
   Ahmadian S, 2014, 2014 6TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), V0, PP98, DOI 10.1109/IKT.2014.7030341
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   Alharthi H, 2018, J INTELL INF SYST, V51, P139, DOI 10.1007/s10844-017-0489-9
   Aljunid MF, 2022, EXPERT SYST APPL, V207, P0, DOI 10.1016/j.eswa.2022.117933
   Aljunid MF, 2021, CAAI T INTELL TECHNO, V6, P480, DOI 10.1049/cit2.12048
   Aljunid MF, 2020, CAAI T INTELL TECHNO, V5, P268, DOI 10.1049/trit.2020.0031
   Ayata D, 2018, IEEE T CONSUM ELECTR, V64, P196, DOI 10.1109/TCE.2018.2844736
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Bathla G, 2020, MULTIMED TOOLS APPL, V79, P20845, DOI 10.1007/s11042-020-08932-4
   Ben-Lhachemi N, 2019, 2019 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES (ICDS 2019), V0, P0, DOI DOI 10.1109/icds47004.2019.8942380
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Chen SL, 2018, KNOWL-BASED SYST, V158, P109, DOI 10.1016/j.knosys.2018.05.040
   Chen ZX, 2020, NEUROCOMPUTING, V385, P269, DOI 10.1016/j.neucom.2019.12.088
   Chou YC, 2020, IEEE ACCESS, V8, P190934, DOI 10.1109/ACCESS.2020.3031621
   Darban ZZ, 2022, EXPERT SYST APPL, V200, P0, DOI 10.1016/j.eswa.2022.116850
   Devlin J, 2019, ARXIV, V0, P0
   Ekstrand Michael D, 2010, FOUNDATIONS AND TRENDS IN HUMAN-COMPUTER INTERACTION, V4, P81, DOI 10.1561/1100000009
   Feng FXY, 2022, ARXIV, V0, P0
   Fu YYZ, 2020, WORKSHOP ON E-COMMERCE AND NLP (ECNLP 3), V0, P54
   Goldberg Y, 2014, ARXIV, V0, P0
   Hernando A, 2016, KNOWL-BASED SYST, V97, P188, DOI 10.1016/j.knosys.2015.12.018
   Hidasi B, 2016, ARXIV, V0, P0
   Hidasi B, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS16), V0, PP241, DOI 10.1145/2959100.2959167
   Hwang WS, 2018, COMPUT SCI INF SYST, V15, P347, DOI 10.2298/CSIS170820003H
   Jamali MEster, 2010, P 4 ACM C REC SYST, V0, P0, DOI DOI 10.1145/1864708.186473617.W.
   Jannach D, 2015, USER MODEL USER-ADAP, V25, P427, DOI 10.1007/s11257-015-9165-3
   Kang WC, 2018, IEEE DATA MINING, V0, PP197, DOI 10.1109/ICDM.2018.00035
   Kaviani M, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), V0, PP113, DOI 10.1109/icwr49608.2020.9122275
   Kiran R, 2020, EXPERT SYST APPL, V144, P0, DOI 10.1016/j.eswa.2019.113054
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Liu D, 2020, KNOWL-BASED SYST, V191, P0, DOI 10.1016/j.knosys.2019.105243
   Liu J, 2022, SURVEY HETEROGENEOUS, V0, P0
   Liu Y, 2018, BIG DATA MIN ANAL, V1, P211, DOI 10.26599/BDMA.2018.9020019
   Logeswaran L, 2018, ARXIV, V0, P0
   Malkiel I, 2020, ARXIV, V0, P0
   Mao MS, 2017, IEEE T CYBERNETICS, V47, P4049, DOI 10.1109/TCYB.2016.2595620
   Moradi P, 2016, INT CONF ADV ICT, V0, PP162, DOI 10.1109/ICTER.2016.7829914
   Pang GY, 2019, KNOWL-BASED SYST, V181, P0, DOI 10.1016/j.knosys.2019.05.029
   Parvin H, 2019, KNOWL-BASED SYST, V166, P92, DOI 10.1016/j.knosys.2018.12.016
   Parvin H, 2019, EXPERT SYST APPL, V118, P152, DOI 10.1016/j.eswa.2018.09.045
   Pradhan T, 2020, KNOWL-BASED SYST, V204, P0, DOI 10.1016/j.knosys.2020.106181
   Qiu L, 2016, KNOWL-BASED SYST, V110, P233, DOI 10.1016/j.knosys.2016.07.033
   Ranjbar M, 2015, ENG APPL ARTIF INTEL, V46, P58, DOI 10.1016/j.engappai.2015.08.010
   Sarwar B, 2000, APPL DIMENSIONALITY, V0, P0
   Sedhain S, 2015, WWW15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP111, DOI 10.1145/2740908.2742726
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Song XY, 2022, ARXIV, V0, P0
   Srifi M, 2020, INFORMATION, V11, P0, DOI 10.3390/info11060317
   Stitini O, 2022, ELECTRONICS-SWITZ, V11, P0, DOI 10.3390/electronics11020242
   Strub F, 2016, P 1 WORKSHOP DEEP LE, V0, PP11, DOI 10.1145/2988450
   Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP1441, DOI 10.1145/3357384.3357895
   Symeonidis P, 2019, EXPERT SYST APPL, V118, P261, DOI 10.1016/j.eswa.2018.09.053
   Tahmasbi H, 2021, J INTELL INF SYST, V56, P169, DOI 10.1007/s10844-020-00613-w
   Tang JX, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP565, DOI 10.1145/3159652.3159656
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang S, 2017, IEEE INT CON MULTI, V0, PP283, DOI 10.1109/ICME.2017.8019347
   Wang W, 2019, J AMB INTEL HUM COMP, V10, P3035, DOI 10.1007/s12652-018-0803-6
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Wu CH, 2016, KNOWL-BASED SYST, V109, P90, DOI 10.1016/j.knosys.2016.06.028
   Wu H, 2018, KNOWL-BASED SYST, V145, P46, DOI 10.1016/j.knosys.2018.01.003
   Xia HB, 2021, COMPLEX INTELL SYST, V7, P1367, DOI 10.1007/s40747-021-00274-4
   Xu CF, 2021, NEUROCOMPUTING, V423, P580, DOI 10.1016/j.neucom.2020.10.066
   Xue GT, 2022, NEUROCOMPUTING, V472, P212, DOI 10.1016/j.neucom.2021.03.138
   Yang Shuiqiao, 2021, ARXIV, V0, P0
   Yang YM, 2023, IEEE T KNOWL DATA EN, V35, P1637, DOI 10.1109/TKDE.2021.3101356
   Yang Z, 2016, P 2016 C N AM CHAPTE, V0, PP1480, DOI 10.18653/v1/N16-1174
   Yi BL, 2019, IEEE T IND INFORM, V15, P4591, DOI 10.1109/TII.2019.2893714
   Yin H, 2021, WORLD WIDE WEB, V24, P1027, DOI 10.1007/s11280-020-00850-7
   Yin RP, 2019, KNOWL-BASED SYST, V185, P0, DOI 10.1016/j.knosys.2019.105020
   Zhang S, 2018, ARXIV, V0, P0
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhao JL, 2020, KNOWL-BASED SYST, V209, P0, DOI 10.1016/j.knosys.2020.106434
   Zheng L, 2017, WSDM17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP425, DOI 10.1145/3018661.3018665
   Zhu Y, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2585, DOI 10.1145/3357384.3357805
   Zhuang YY, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su13148039
NR 77
TC 3
Z9 3
U1 4
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 28
PY 2022
VL 256
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.109835
EA SEP 2022
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4X0UD
UT WOS:000860566400003
DA 2023-11-10
ER

PT J
AU Li, W
   Du, YJ
   Li, XY
   Chen, XL
   Xie, CZ
   Li, H
   Li, XL
AF Li, Wei
   Du, Yajun
   Li, Xianyong
   Chen, Xiaoliang
   Xie, Chunzhi
   Li, Hui
   Li, Xiaolei
TI UD_BBC: Named entity recognition in social network combined BERT-BiLSTM-CRF with active learning
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Named entity recognition; Deep learning models; Natural language processing; Education public opinion
ID community structure; performance
AB With the rapid growth of Internet penetration, more and more people choose the Internet to express their views on topics of interest. In recent years, named entity recognition (NER) is becoming a popular task for the public to obtain structured information from public opinion text. At present, NER models with good results, such as deep learning model, need a lot of labeled data for training. However, this will give rise to a problem: labeling a large amount of data requires a lot of human resources, which is thankless in some areas. Therefore, in this paper, we propose a NER model combining active learning and deep learning methods. Firstly, the active learning method can solve the above problem. The strategy combines uncertainty-based sampling and diversity -based sampling to estimate the information of data. We use highly informative data as the initial training dataset. Secondly, this paper uses a deep learning model combining bidirectional encoder representations from Transformers, bidirectional long-short-term memory and conditional random field (BERT-BiLSTM-CRF). BERT extracts the semantic features of data, and BiLSTM predicts the probability distribution of entity labels. We use the CRF for decoding the probability distribution into corresponding entity labels. Finally, we use the initial training dataset for training BERT-BiLSTM-CRF. This model predicts the entity labels of the unlabeled data. Then, we judge if the machine-labeled data is highly reliable and expand the highly reliable data to the initial training dataset. The updated dataset retrains the NER model, so that the trained model has higher precision than the previous model. The results show that our model performs well without a large number of labeled datasets. The model achieves a precision value of 70.31%, recall rate of 74.93% and F1 score of 72.55% in the named entity recognition task, which proves the effectiveness of our model. Besides, the F1 score of BERT-BiLSTM-CRF with uncertainty-based sampling and diversity-based sampling (UD_BBC) is higher than the BiLSTM-CRF based on maximum normalized log-probability (MNLP_BiLSTM-CRF) by 9.00%, when recognizing overall entity categories. It provides a solution to the problem of named entity recognition in educational public opinion.
C1 [Li, Wei; Du, Yajun; Li, Xianyong; Chen, Xiaoliang; Xie, Chunzhi; Li, Xiaolei] Xihua Univ, Coll Comp Sci & Software Engn, Chengdu 610039, Peoples R China.
   [Li, Hui] Lib Xihua Univ, Chengdu 610039, Peoples R China.
C3 Xihua University
RP Du, YJ (通讯作者)，Xihua Univ, Coll Comp Sci & Software Engn, Chengdu 610039, Peoples R China.
EM lxllixiaolei1987@163.com; lw@stu.xhu.edu.cn; lxllixiaolei1987@163.com; chenxl@mail.xhu.edu.cn; xcz_xihua@mail.xhu.edu.cn; lxllixiaolei1987@163.com; lxllixiaolei1987@163.com
FU National Natural Science Foun-dation, China; Sichuan Regional Innovation Cooperation, China Project; Innovation Fundation of Xihua University, China;  [61872298];  [61802316];  [61902324];  [2021YFQ0008];  [YCJJ2021027]
CR [Anonymous], 2013, INTERSPEECH, V0, P0
   Banan A, 2020, AQUACULT ENG, V89, P0, DOI 10.1016/j.aquaeng.2020.102053
   Ben Veyseh AP, 2021, LECT NOTES ARTIF INT, V12977, P644, DOI 10.1007/978-3-030-86523-8_39
   Chang HS, 2020, MACH LEARN, V109, P1749, DOI 10.1007/s10994-020-05897-1
   Chen CC, 2022, ENG APPL COMP FLUID, V16, P248, DOI 10.1080/19942060.2021.2009374
   Chen HY, 2021, IEEE J-STARS, V14, P2781, DOI 10.1109/JSTARS.2021.3059451
   Chen Y, 2019, J BIOMED INFORM, V96, P0, DOI 10.1016/j.jbi.2019.103252
   Chen YK, 2015, J BIOMED INFORM, V58, P11, DOI 10.1016/j.jbi.2015.09.010
   Cho M, 2020, J BIOMED INFORM, V103, P0, DOI 10.1016/j.jbi.2020.103381
   Claveau V, 2018, LECT NOTES COMPUT SC, V10761, P30, DOI 10.1007/978-3-319-77113-7_3
   Dai Z, 2019, 2019 12 INT C IM SIG, V0, PP1, DOI 10.1109/CISP-BMEI48845.2019.8965823
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du YJ, 2022, INFORM FUSION, V88, P100, DOI 10.1016/j.inffus.2022.07.010
   Du YJ, 2021, INFORM SCIENCES, V570, P722, DOI 10.1016/j.ins.2021.04.081
   Fan YJ, 2020, IEEE ACCESS, V8, P25111, DOI 10.1109/ACCESS.2020.2970836
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Jia C, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6384
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Lai J, 2010, 14 INT C COMPUTER SU, V0, P234
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Li JQ, 2020, J SUPERCOMPUT, V76, P1450, DOI 10.1007/s11227-017-2229-x
   Li Q, 2021, ENG APPL ARTIF INTEL, V100, P0, DOI 10.1016/j.engappai.2021.104192
   Li X, 2013, PROC CVPR IEEE, V0, PP859, DOI 10.1109/CVPR.2013.116
   Liu S, 2021, INT J COMPUT INT SYS, V14, P0, DOI 10.1007/s44196-021-00019-8
   Luo JX, 2020, NEUROCOMPUTING, V410, P138, DOI 10.1016/j.neucom.2020.05.039
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Oudah M, 2017, NAT LANG ENG, V23, P441, DOI 10.1017/S1351324916000097
   Peters ME, 2018, ARXIV180205365, V0, P0
   Pirovani Juliana PC, 2019, P IBERIAN LANGUAGES, V0, P421
   Ren PZ, 2022, ACM COMPUT SURV, V54, P0, DOI 10.1145/3472291
   Ronran C, 2020, INT CONF BIG DATA, V0, PP613, DOI 10.1109/BigComp48618.2020.00132
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Settles B, 2008, P 2008 C EMPIRICAL M, V0, P1070
   Shen Y, 2018, PROC INT C LEARN REP, V0, P252
   Siencnik SK, 2015, P 20 NORD C COMP LIN, V0, P239
   Sinha S, 2019, IEEE I CONF COMP VIS, V0, PP5971, DOI 10.1109/ICCV.2019.00607
   Tedeschi S, 2021, FINDINGS ASS COMPUTA, V0, P2521
   Upadhyay PK, 2020, ROM J INF SCI TECH, V23, P292
   Tran VC, 2017, KNOWL-BASED SYST, V132, P179, DOI 10.1016/j.knosys.2017.06.023
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wintaka DC, 2019, PROCEDIA COMPUT SCI, V157, P221, DOI 10.1016/j.procs.2019.08.161
   Yao R, 2022, ISA T, V126, P691, DOI 10.1016/j.isatra.2021.07.017
   Yin CC, 2017, IEEE DATA MINING, V0, PP575, DOI 10.1109/ICDM.2017.67
   Yoo D, 2019, PROC CVPR IEEE, V0, PP93, DOI 10.1109/CVPR.2019.00018
NR 46
TC 3
Z9 3
U1 30
U2 81
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD NOV 15
PY 2022
VL 116
IS 
BP 
EP 
DI 10.1016/j.engappai.2022.105460
PG 19
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA 5F8UX
UT WOS:000866588600013
DA 2023-11-10
ER

PT J
AU Chen, XH
   Zhao, Y
   Wang, Y
   Xu, PF
   You, HR
   Li, CJ
   Fu, YG
   Lin, YY
   Wang, ZY
AF Chen, Xiaohan
   Zhao, Yang
   Wang, Yue
   Xu, Pengfei
   You, Haoran
   Li, Chaojian
   Fu, Yonggan
   Lin, Yingyan
   Wang, Zhangyang
TI SmartDeal: Remodeling Deep Network Weights for Efficient Inference and Training
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Training; Matrix decomposition; Costs; Quantization (signal); Inference algorithms; Random access memory; Hardware acceleration; Data movement; deep network training; efficient machine learning; hardware accelerator
ID neural-networks; accelerator
AB The record-breaking performance of deep neural networks (DNNs) comes with heavy parameter budgets, which leads to external dynamic random access memory (DRAM) for storage. The prohibitive energy of DRAM accesses makes it nontrivial for DNN deployment on resource-constrained devices, calling for minimizing the movements of weights and data in order to improve the energy efficiency. Driven by this critical bottleneck, we present SmartDeal, a hardware-friendly algorithm framework to trade higher-cost memory storage/access for lower-cost computation, in order to aggressively boost the storage and energy efficiency, for both DNN inference and training. The core technique of SmartDeal is a novel DNN weight matrix decomposition framework with respective structural constraints on each matrix factor, carefully crafted to unleash the hardware-aware efficiency potential. Specifically, we decompose each weight tensor as the product of a small basis matrix and a large structurally sparse coefficient matrix whose nonzero elements are readily quantized to the power-of-2. The resulting sparse and readily quantized DNNs enjoy greatly reduced energy consumption in data movement as well as weight storage, while incurring minimal overhead to recover the original weights thanks to the required sparse bit-operations and cost-favorable computations. Beyond inference, we take another leap to embrace energy-efficient training, by introducing several customized techniques to address the unique roadblocks arising in training while preserving the SmartDeal structures. We also design a dedicated hardware accelerator to fully utilize the new weight structure to improve the real energy efficiency and latency performance. We conduct experiments on both vision and language tasks, with nine models, four datasets, and three settings (inference-only, adaptation, and fine-tuning). Our extensive results show that 1) being applied to inference, SmartDeal achieves up to 2.44x improvement in energy efficiency as evaluated using real hardware implementations and 2) being applied to training, SmartDeal can lead to 10.56x and 4.48x reduction in the storage and the training energy cost, respectively, with usually negligible accuracy loss, compared to state-of-the-art training baselines. Our source codes are available at: https://github.com/VITA-Group/SmartDeal.
C1 [Chen, Xiaohan; Wang, Zhangyang] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
   [Zhao, Yang; Wang, Yue; Xu, Pengfei; You, Haoran; Li, Chaojian; Fu, Yonggan; Lin, Yingyan] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.
C3 University of Texas System; University of Texas Austin; Rice University
RP Chen, XH (通讯作者)，Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM xiaohan.chen@utexas.edu; zy34@rice.edu; atlaswang@utexas.edu; px5@rice.edu; hy34@rice.edu; cl114@rice.edu; yf22@rice.edu; yingyan.lin@rice.edu
FU National Science Foundation (NSF) through the Real-Time Machine Learning Program [1937592, 2053279]; Direct For Computer & Info Scie & Enginr; Division of Computing and Communication Foundations [1937592] Funding Source: National Science Foundation; Direct For Computer & Info Scie & Enginr; Division of Computing and Communication Foundations [2053279] Funding Source: National Science Foundation
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), V0, PP382, DOI 10.1145/3123939.3123982
   [Anonymous], 2015, ADV NEURAL INFORM PR, V0, P0
   [Anonymous], 2018, P ICLR, V0, P0
   Ba J, 2014, ADV NEURAL INFORM PR, V0, P2654
   Banner Ron, 2018, ADV NEURAL INFORM PR, V0, PP5151, DOI 10.5555/3327345.3327421
   Bernstein J, 2018, ARXIV180204434, V80, P560
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chaojian Li, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12354), V0, PP500, DOI 10.1007/978-3-030-58545-7_29
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen T, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Ting, 2020, NEURIPS, V0, P2
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, V0, PP367, DOI 10.1109/ISCA.2016.40
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), V0, PP92, DOI 10.1145/2749469.2750389
   Esser Steven K, 2019, ARXIV190208153, V0, P0
   Fu Y`, 2020, ADV NEURAL INFORM PR, V0, P12127
   Gong RH, 2019, IEEE I CONF COMP VIS, V0, PP4851, DOI 10.1109/ICCV.2019.00495
   Gong Y, 2014, ARXIV14126115, V0, P0
   Gui S, 2019, ADVERSARIALLY TRAINE, V0, P0
   Han SY, 2016, IEEE ICC, V0, P0, DOI DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28, P0
   Han S, 2016, CONF PROC INT SYMP C, V0, PP243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Helwegen Koen, 2019, ADV NEURAL INFORM PR, V32, P7533
   Hinton Geoffrey, 2015, ARXIV150302531, V0, P0
   Howard AG, 2017, ABS170404861 CORR, V0, P0
   Hu Ting-Kuei, 2020, INT C LEARN REPR ICL, V0, P0
   Huang HT, 2018, IEEE T NANOTECHNOL, V17, P645, DOI 10.1109/TNANO.2017.2732698
   Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, V0, P876
   Kim C, 2019, ISSCC DIG TECH PAP I, V62, P136, DOI 10.1109/ISSCC.2019.8662447
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V0, P0
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), V0, PP749, DOI 10.1145/3297858.3304041
   Lee J, 2018, ISSCC DIG TECH PAP I, V0, PP218, DOI 10.1109/ISSCC.2018.8310262
   Liu Z, 2017, IEEE I CONF COMP VIS, V0, PP2755, DOI 10.1109/ICCV.2017.298
   Luo JH, 2017, IEEE I CONF COMP VIS, V0, PP5068, DOI 10.1109/ICCV.2017.541
   Mao HZ, 2017, IEEE COMPUT SOC CONF, V0, PP1927, DOI 10.1109/CVPRW.2017.241
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   Micikevicius P, 2018, ABS171003740 ARXIV, V0, P0, DOI DOI 10.1109/CAMAD.2018.8514963
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), V0, PP27, DOI 10.1145/3079856.3080254
   Polino Antonio, 2018, ARXIV180205668, V0, P0
   Qin ZD, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8010078
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Shen JH, 2020, AAAI CONF ARTIF INTE, V34, P5700
   Tailor SA, 2021, P INT C LEARN REPR, V0, P0
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Tung F, 2018, PROC CVPR IEEE, V0, PP7873, DOI 10.1109/CVPR.2018.00821
   Wang Haoran, 2020, ECCV, V0, P0
   Wang K, 2019, PROC CVPR IEEE, V0, PP8604, DOI 10.1109/CVPR.2019.00881
   Wang M, 2018, ARXIV181108589, V0, P0
   Wang Naigang, 2018, ADV NEURAL INFORM PR, V31, P7675
   Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25
   Wang Y, 2019, ADV NEURAL INFORM PR, V0, P5138
   Wang Y, 2020, IEEE J-STSP, V14, P623, DOI 10.1109/JSTSP.2020.2979669
   Wen W, 2016, ADV NEUR IN, V29, P0
   Wu JR, 2018, PR MACH LEARN RES, V80, P0
   Yang Guandao, 2019, PR MACH LEARN RES, V97, P7015
   Yang TJ, 2017, PROC CVPR IEEE, V0, PP6071, DOI 10.1109/CVPR.2017.643
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), V0, PP369, DOI 10.1145/3373376.3378514
   Yang YK, 2020, NEURAL NETWORKS, V125, P70, DOI 10.1016/j.neunet.2019.12.027
   You, 2020, ARXIV201012785, V0, P0
   You Haoran, 2019, ARXIV190911957, V0, P0
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), V0, PP548, DOI 10.1145/3079856.3080215
   Yu XY, 2017, PROC CVPR IEEE, V0, PP67, DOI 10.1109/CVPR.2017.15
   Zhang Peizhao, 2018, ARXIV181200090, V0, P0
   Zhang S, 2016, IEEE ACM INT S MICR, V0, PP1, DOI 10.1109/MICRO.2016.7783723
   Zhao Y, 2020, ANN I S COM, V0, PP954, DOI 10.1109/ISCA45697.2020.00082
   Zhou Shuchang, 2016, ARXIV160606160, V0, P0
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), V0, PP15, DOI 10.1109/MICRO.2018.00011
NR 75
TC 0
Z9 0
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2021.3138056
EA MAR 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA ZN2BW
UT WOS:000764847100001
PM 35235521
DA 2023-11-10
ER

PT J
AU Dutta, H
   Gupta, A
AF Dutta, Haimonti
   Gupta, Aayushee
TI PNRank: Unsupervised ranking of person name entities from noisy OCR text
SO DECISION SUPPORT SYSTEMS
LA English
DT Article
DE Unsupervised ranking; Kernel density estimation; OCR noise; Named entity recognition
ID people search; algorithm
AB Text databases have grown tremendously in number, size, and volume over the last few decades. Optical Character Recognition (OCR) software is used to scan the text and make them available in online repositories. The OCR transcription process is often not accurate resulting in large volumes of garbled text in the repositories. Spell correction and other post-processing of OCR text often prove to be very expensive and time-consuming. While it is possible to rely on the OCR model to assess the quality of text in a corpus, many natural language processing and information retrieval tasks prefer the extrinsic evaluation of the effect of noise on the task at hand. This paper examines the effect of noise on the unsupervised ranking of person name entities by first populating a list of person names using an out-of-the-box Named Entity Recognition (NER) software, extracting content-based features for the identified entities, and ranking them using a novel unsupervised Kernel Density Estimation (KDE) based ranking algorithm. This generative model has the ability to learn rankings using the data distribution and therefore requires limited manual intervention. Empirical results are presented on a carefully curated parallel corpus of OCR and clean text and "in the wild" using a large real-world corpus. Experiments on the parallel corpus reveals that even with a reasonable degree of noise in the dataset, it is possible to generate ranked lists using the KDE algorithm with a high degree of precision and recall. Furthermore, since the KDE algorithm has comparable performance to state-of-the-art unsupervised rankers, using it on real-world corpora is feasible. The paper concludes by reflecting on other methods for enhancing the performance of the unsupervised algorithm on OCR text such as cleaning entity names, disambiguating names concatenated to one another and correcting OCR errors that are statistically significant in the corpus.
C1 [Dutta, Haimonti] SUNY Buffalo, Dept Management Sci & Syst, 160 Jacobs Management Ctr, Buffalo, NY 14260 USA.
   [Gupta, Aayushee] IIIT Bangalore, Dept Comp Sci, Bengaluru, Karnataka, India.
C3 State University of New York (SUNY) System; State University of New York (SUNY) Buffalo
RP Dutta, H (通讯作者)，SUNY Buffalo, Dept Management Sci & Syst, 160 Jacobs Management Ctr, Buffalo, NY 14260 USA.
EM haimonti@buffalo.edu; aayushee1230@iiitd.ac.in
CR [Anonymous], 2019, PROC ANN INT C EXTEN, V0, P0
   [Anonymous], 2017, P IEEE VIS COMM IM P, V0, P0
   [Anonymous], 2010, P 4 WORKSHOP ANALYTI, V0, P0
   Bassil Y, 2012, COMPUTER INFORM SCI, V5, P37, DOI 10.5539/CIS.V5N3P37
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Borda JC, 1781, HIST LACAD EMIE ROYA, V0, P1
   Boros E, 2020, P 24 C COMPUTATIONAL, V0, P431
   Boros Emanuela, 2020, P C LABS EVALUATION, V2696, P1
   Boschetti F, 2009, LECT NOTES COMPUT SC, V5714, P156, DOI 10.1007/978-3-642-04346-8_17
   Conrad JG, 1994, SIGIR 94. PROCEEDINGS OF THE SEVENTEENTH ANNUAL INTERNATIONAL ACM-SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P260
   Dinarelli M, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1266
   Dong R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2363
   Drobac S, 2020, INT J DOC ANAL RECOG, V23, P279, DOI 10.1007/s10032-020-00359-9
   Fagin R, 2003, SIAM PROC S, V0, P28
   Finkel JR, 2005, ACL, V0, PP363, DOI 10.3115/1219840.1219885
   Fox EA, 1994, SECOND TEXT RETRIEVAL CONFERENCE (TREC-2) (NIST-SP 500-215), V0, P243
   Franzini G, 2018, FRONTIERS DIGITAL HU, V5, P4, DOI 10.3389/FDIGH.2018.00004
   Hamdi A, 2019, ACM-IEEE J CONF DIG, V0, PP333, DOI 10.1109/JCDL.2019.00057
   Hill MJ, 2019, DIGIT SCHOLARSH HUM, V34, P825, DOI 10.1093/llc/fqz024
   Hladek D, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9101670
   Jurafsky D, 2000, SPEECH LANGUAGE PROC, V0, P1
   Kalashnikov DV, 2008, IEEE T KNOWL DATA EN, V20, P1550, DOI 10.1109/TKDE.2008.78
   Kalashnikov DV, 2006, ACM T DATABASE SYST, V31, P716, DOI 10.1145/1138394.1138401
   Kalashnikov DV, 2007, PROC INT CONF DATA, V0, P1233
   KENDALL MG, 1948, BIOMETRIKA, V35, P291, DOI 10.2307/2332349
   Khirbat G, 2017, PROC AUSTRALAS LANG, V0, P119
   Klementiev A, 2008, P 25 INT C MACHINE L, V0, P472
   Klementiev A, 2007, LECT NOTES ARTIF INT, V4701, P616
   Klementiev A, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), V0, P1101
   Krippendorff K, 2011, COMMUN METHODS MEAS, V5, P93, DOI 10.1080/19312458.2011.568376
   KUKICH K, 1992, COMPUT SURV, V24, P377
   Li F, 2011, DECIS SUPPORT SYST, V51, P190, DOI 10.1016/j.dss.2010.12.007
   LingPipe, 2008, 393 SPELLING TUTORIA, V0, P0
   Lund WB, 2011, PROC INT CONF DOC, V0, PP764, DOI 10.1109/ICDAR.2011.303
   Ma Q, 2008, LECT NOTES COMPUT SC, V5176, P48
   Manning CD, 2008, INTRO INFORM RETRIEV, V0, PP1, DOI IR- book/information- retrieval-book.html
   McCallum A, 2003, EARLY RESULTS NAMED, V0, P0
   McCallum Andrew Kachites, 2002, MALLET MACHINE LEARN, V0, P0
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, ARXIV13013781 CS, V0, P0, DOI DOI 10.48550/ARXIV.1301.3781
   Miller D, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P316
   Norvig P, 2007, WRITE SPELL CORRECTO, V0, P0
   Reynaert M, 2011, INT J DOC ANAL RECOG, V14, P173, DOI 10.1007/s10032-010-0133-5
   Rigaud Christophe, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1588, DOI 10.1109/ICDAR.2019.00255
   Ruokolainen T, 2020, NAME NAME NAMED ENTI, V2612, P136
   Schaefer R, 1900, P33, V0, P0
   Scott DW, 2015, WILEY SER PROBAB ST, V0, PP1, DOI 10.1002/9781118575574
   Silverman Bernarda W, 2017, DENSITY ESTIMATION S, V0, P0, DOI DOI 10.1201/9781315140919
   Smith DA, 2018, PROJECT REPORT ANDRE, V0, P1
   Strange C, 2014, DIGIT HUMANITIES Q, V8, P0
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Taghva K, 1996, INFORM PROCESS MANAG, V32, P317, DOI 10.1016/0306-4573(95)00058-5
   Thompson P, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 1: DIGITIZATION & ACQUISITION, P0
   Traub MC, 2015, LECT NOTES COMPUT SC, V9316, P252, DOI 10.1007/978-3-319-24592-8_19
   van Strien D, 2020, ICAART: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1, P484, DOI 10.5220/0009169004840496
   Wang GA, 2013, DECIS SUPPORT SYST, V54, P1442, DOI 10.1016/j.dss.2012.12.020
   Zacharia G, 2000, DECIS SUPPORT SYST, V29, P371, DOI 10.1016/S0167-9236(00)00084-1
NR 58
TC 2
Z9 2
U1 5
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-9236
EI 1873-5797
J9 DECIS SUPPORT SYST
JI Decis. Support Syst.
PD JAN 15
PY 2022
VL 152
IS 
BP 
EP 
DI 10.1016/j.dss.2021.113662
EA NOV 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science
SC Computer Science; Operations Research & Management Science
GA XB5QU
UT WOS:000721384600009
DA 2023-11-10
ER

PT J
AU Rafique, A
   Rustam, F
   Narra, M
   Mehmood, A
   Lee, E
   Ashraf, I
AF Rafique, Adnan
   Rustam, Furqan
   Narra, Manideep
   Mehmood, Arif
   Lee, Ernesto
   Ashraf, Imran
TI Comparative analysis of machine learning methods to detect fake news in an Urdu <i>corpus</i>
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Fake news detection; Urdu corpus; Machine learning; Deep learning
AB Wide availability and large use of social media enable easy and rapid dissemination of news. The extensive spread of engineered news with intentionally false information has been observed over the past few years. Consequently, fake news detection has emerged as an important research area. Fake news detection in the Urdu language spoken by more than 230 million people has not been investigated very well. This study analyzes the use and efficacy of various machine learning classifiers along with a deep learning model to detect fake news in the Urdu language. Logistic regression, support vector machine, random forest (RF), naive Bayes, gradient boosting, and passive aggression have been utilized to this end. The influence of term frequency-inverse document frequency and BoW features has also been investigated. For experiments, a manually collected dataset that contains 900 news articles was used. Results suggest that RF performs better and achieves the highest accuracy of 0.92 for Urdu fake news with BoW features. In comparison with machine learning models, neural networks models long short term memory, and multi-layer perceptron are used. Machine learning models tend to show better performance than deep learning models.
C1 [Rafique, Adnan] COMSATS Inst Informat Technol, Dept Comp Sci, Lahore, Pakistan.
   [Rustam, Furqan] Univ Management & Technol, Dept Software Engn, Lahore, Pakistan.
   [Narra, Manideep] Indiana Inst Technol, Ft Wayne, IN USA.
   [Mehmood, Arif] Islamia Univ, Dept CS & IT, Bahawalpur, Pakistan.
   [Lee, Ernesto] Miami Dade Coll, Sch Engn & Technol, Miami, FL 33132 USA.
   [Ashraf, Imran] Yeungnam Univ, Informat & Commun Engn, Gyongsan, Daegu, South Korea.
C3 COMSATS University Islamabad (CUI); University of Management & Technology (UMT); Yeungnam University
RP Lee, E (通讯作者)，Miami Dade Coll, Sch Engn & Technol, Miami, FL 33132 USA.; Ashraf, I (通讯作者)，Yeungnam Univ, Informat & Commun Engn, Gyongsan, Daegu, South Korea.
EM elee@broward.edu; imranashraf@ynu.ac.kr
CR Abedalla A, 2019, ICAAI 2019 2019 3 IN, V0, P24
   Adeeba F, 2016, P C LANGUAGE TECHNOL, V0, P0
   Agarwal A, 2020, SN COMPUTER SCI, V1, P1
   Amjad M, 2020, ACM INT CONF PR SER, V0, PP37, DOI 10.1145/3441501.3441541
   Amjad M, 2020, J INTELL FUZZY SYST, V39, P2457, DOI 10.3233/JIFS-179905
   Anoop K, 2019, LINKING MINING HETER, V0, PP229?64, DOI 10.1007/978-3-030-01872-6_10
   Ashraf I, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9112337
   BOYD CR, 1987, J TRAUMA, V27, P370, DOI 10.1097/00005373-198704000-00005
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   CIGI-Ipsos Global Survey, 2019, INT SEC TRUST 3, V0, P0
   Daoud AA, 2019, INT J COMPUTER INFOR, V0, P0
   Felber T, 2021, CONSTRAINT 2021 MACH, V0, P0
   Gereme FB, 2019, PROCEEDINGS OF 2019 2ND INTERNATIONAL CONFERENCE ON BIG DATA TECHNOLOGIES (ICBDT 2019), V0, PP142, DOI 10.1145/3358528.3358567
   Helmstetter S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), V0, PP274, DOI 10.1109/ASONAM.2018.8508520
   Kaliyar R, 2018, IN2018 4 INT C COMPU, V0, P1
   Khalid M, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10082788
   Kim J, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP324, DOI 10.1145/3159652.3159734
   Korkmaz T, 2021, INT ADV RESEARCHES E, V5, P31, DOI 10.35860/iarej.779019
   Kwon S, 2013, IEEE DATA MINING, V0, PP1103, DOI 10.1109/ICDM.2013.61
   Metz C, 2016, BITTERSWEET SWEEPSTA, V0, P0
   Murphy KP, 2006, U BRIT COLUMBIA, V0, P0
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, P0, DOI 10.3389/fnbot.2013.00021
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, V0, P3391
   Posadas-Durán JP, 2019, J INTELL FUZZY SYST, V36, P4869, DOI 10.3233/JIFS-179034
   Rasool T, 2019, INT CONF COMPUT AUTO, V0, PP73, DOI 10.1145/3313991.3314008
   Scholkopf B, 1996, ARTIFICIAL NEURAL NETWORKS - ICANN 96. 1996 INTERNATIONAL CONFERENCE PROCEEDINGS, V0, P47
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), V0, PP436, DOI 10.1145/3341161.3342927
   Straka M, 2017, P CONLL 2017 SHARED, V0, P0, DOI DOI 10.18653/V1/K17-3009
   Tharani P, 2021, B POL ACAD SCI-TECH, V69, P0, DOI 10.24425/bpasts.2021.137728
   Tschiatschek S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP517, DOI 10.1145/3184558.3188722
   USCensus Bureau, 2020, LANG SPOK HOM AB SPE, V0, P0
   Wang WY, 2017, ARXIV PREPRINT, V0, P0, DOI DOI 10.48550/arXiv.1705.00648
   Wijeratne Y, 2019, NATURAL LANGUAGE PRO, V0, P0
   Wynne HE, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, V0, PP669, DOI 10.1145/3366030.3366116
   Yu SQ, 2020, ACMSE 2020: PROCEEDINGS OF THE 2020 ACM SOUTHEAST CONFERENCE, V0, PP324, DOI 10.1145/3374135.3385324
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.03.004
NR 36
TC 3
Z9 3
U1 1
U2 11
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUN 28
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1004
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 2U1ST
UT WOS:000822943300002
PM 35875651
DA 2023-11-10
ER

PT J
AU Lee, JH
   Yao, Y
   Özdemir, O
   Li, MD
   Weber, C
   Liu, ZY
   Wermter, S
AF Lee, Jae Hee
   Yao, Yuan
   Ozdemir, Ozan
   Li, Mengdi
   Weber, Cornelius
   Liu, Zhiyuan
   Wermter, Stefan
TI Spatial relation learning in complementary scenarios with deep neural networks
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE spatial relation learning; deep neural networks; hybrid architecture; embodied language learning; distant supervision; frame of reference
ID visual dialog
AB A cognitive agent performing in the real world needs to learn relevant concepts about its environment (e.g., objects, color, and shapes) and react accordingly. In addition to learning the concepts, it needs to learn relations between the concepts, in particular spatial relations between objects. In this paper, we propose three approaches that allow a cognitive agent to learn spatial relations. First, using an embodied model, the agent learns to reach toward an object based on simple instructions involving left-right relations. Since the level of realism and its complexity does not permit large-scale and diverse experiences in this approach, we devise as a second approach a simple visual dataset for geometric feature learning and show that recent reasoning models can learn directional relations in different frames of reference. Yet, embodied and simple simulation approaches together still do not provide sufficient experiences. To close this gap, we thirdly propose utilizing knowledge bases for disembodied spatial relation reasoning. Since the three approaches (i.e., embodied learning, learning from simple visual data, and use of knowledge bases) are complementary, we conceptualize a cognitive architecture that combines these approaches in the context of spatial relation learning.
C1 [Lee, Jae Hee; Ozdemir, Ozan; Li, Mengdi; Weber, Cornelius; Wermter, Stefan] Univ Hamburg, Dept Informat, Knowledge Technol Grp, Hamburg, Germany.
   [Yao, Yuan; Liu, Zhiyuan] Tsinghua Univ, Dept Comp Sci & Technol, Nat Language Proc Lab, Beijing, Peoples R China.
C3 University of Hamburg; Tsinghua University
RP Lee, JH (通讯作者)，Univ Hamburg, Dept Informat, Knowledge Technol Grp, Hamburg, Germany.
EM jae.heelee@uni-hamburg.de
FU Natural Science Foundation of China (NSFC); German Research Foundation (DFG) in Project Crossmodal Learning, NSFC;  [62061136001/DFG TRR-169]
CR Hudson DA, 2018, ARXIV, V0, P0
   Andreas J, 2016, PROC CVPR IEEE, V0, PP39, DOI 10.1109/CVPR.2016.12
   [Anonymous], 2017, EMBODIED MIND, V0, P0
   [Anonymous], 1992, 62 U CAL, V0, P0
   [Anonymous], 1986, CONSTR REALITY CHILD, V0, P0, DOI DOI 10.1017/CBO9780511527234
   [Anonymous], 2019, EMPIRICAL METHODS NA, V0, P0
   [Anonymous], 1998, WORDNET ELECT LEXICA, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2019, INT C LEARN REPR NEW, V0, P0
   Bengio Y, 2009, P 26 ANN INT C MACHI, V0, P0, DOI DOI 10.1145/1553374.1553380
   Bisk Y, 2020, ARXIV, V0, P0
   Chaplot D, 2020, 8 INT C LEARNING REP, V0, P0
   Chaplot DS, 2018, AAAI CONF ARTIF INTE, V0, P2819
   Chen L, 2021, ARXIV, V0, P0
   Chen VS, 2019, IEEE I CONF COMP VIS, V0, PP2580, DOI 10.1109/ICCV.2019.00267
   Chevalier-Boisvert M, 2018, ARXIV181008272, V0, P0
   Collell G, 2018, 32 AAAI C ARTIFICIAL, V0, P0
   Collell G, 2018, T ASSOC COMPUT LING, V6, P133, DOI 10.1162/tacl_a_00010
   Das A, 2017, IEEE I CONF COMP VIS, V0, PP2970, DOI 10.1109/ICCV.2017.321
   Devlin J, 2018, ARXIV, V1, P4171
   DICKINSON A, 1994, ANIM LEARN BEHAV, V22, P1, DOI 10.3758/BF03199951
   Dzifcak Juraj, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP4163, DOI 10.1109/ROBOT.2009.5152776
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Feldman J, 1996, INTEGRATION NATURAL, V0, PP205, DOI 10.1007/978-94-009-1639-515
   Freksa C, 2004, FRONT ARTIF INTEL AP, V110, P1122
   Gori M, 2005, IEEE IJCNN, V0, P729
   Goyal Y, 2017, P IEEE C COMP VIS PA, V0, P6904
   Hatori J, 2018, IEEE INT CONF ROBOT, V0, P3774
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Heinrich S, 2020, FRONT NEUROROBOTICS, V14, P0, DOI 10.3389/fnbot.2020.00052
   Janner M, 2021, ARXIV, V0, P0
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Johnson J, 2017, PROC CVPR IEEE, V0, PP1988, DOI 10.1109/CVPR.2017.215
   Kaiser L, 2017, ARXIV, V0, P0
   Keneshloo Y, 2020, IEEE T NEUR NET LEAR, V31, P2469, DOI 10.1109/TNNLS.2019.2929141
   Kerzel M, 2017, IEEE ROMAN, V0, PP113, DOI 10.1109/ROMAN.2017.8172289
   Kollar T, 2010, ACMIEEE INT CONF HUM, V0, PP259, DOI 10.1109/HRI.2010.5453186
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuhnle A, 2017, ARXIV, V0, P0
   Kumar V, 2013, EXPT ROBOTICS, V0, PP403, DOI 10.1007/978-3-319-00065-7_28
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Levinson SC, 1996, LANGUAGE SPACE, V109, P169
   Li Jiwei, 2016, EMNLP, V0, P0
   Li MD, 2021, IEEE INT C INT ROBOT, V0, PP2686, DOI 10.1109/IROS51168.2021.9635947
   Liu Z, 2020, SYNTH LECT ARTIF INT, V14, P1, DOI 10.2200/S00980ED1V01Y202001AIM045
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Lynch C, 2021, ROBOTICS SCI SYSTEMS, VXVII, P0
   Mao JY, 2019, FRONT NEUROROBOTICS, V13, P0, DOI 10.3389/fnbot.2019.00093
   Matuszek C, 2012, PREPRINT, V0, P0
   Hermann KM, 2017, ARXIV, V0, P0
   Nayak T, 2021, COGN COMPUT, V13, P1215, DOI 10.1007/s12559-021-09917-7
   Ozdemir O, 2021, IEEE INT C DEV LEARN, V0, P0, DOI DOI 10.1109/ICDL49984.2021.9515668
   Pathak D, 2017, IEEE COMPUT SOC CONF, V0, PP488, DOI 10.1109/CVPRW.2017.70
   Perez E, 2018, AAAI CONF ARTIF INTE, V0, P3942
   Peyre J, 2017, IEEE I CONF COMP VIS, V0, PP5189, DOI 10.1109/ICCV.2017.554
   Pramanik S, 2020, ARXIV, V0, P0
   Röder F, 2021, FRONT PSYCHOL, V12, P0, DOI 10.3389/fpsyg.2021.716671
   Shah Dhruv, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP13215, DOI 10.1109/ICRA48506.2021.9561936
   Shao L, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI, V0, P0
   Shridhar M, 2021, P 5 C ROBOT LEARNING, V0, P0
   Shridhar M, 2018, ARXIV, V0, P0
   Silver D, 2021, ARTIF INTELL, V299, P0, DOI 10.1016/j.artint.2021.103535
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Tellex S, 2020, ANNU REV CONTR ROBOT, V3, P25, DOI 10.1146/annurev-control-101119-071628
   Tenbrink T, 2002, KORREKTURABZUG KUENS, V16, P19
   Uc-Cetina V, 2022, ARXIV, V0, P0
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Y, 2019, IEEE I CONF COMP VIS, V0, PP2769, DOI 10.1109/ICCV.2019.00286
   Yamada T, 2018, IEEE ROBOT AUTOM LET, V3, P3441, DOI 10.1109/LRA.2018.2852838
   Yang JW, 2019, IEEE I CONF COMP VIS, V0, PP2040, DOI 10.1109/ICCV.2019.00213
   Yang KY, 2019, IEEE I CONF COMP VIS, V0, PP2051, DOI 10.1109/ICCV.2019.00214
   Yang W, 2019, P 7 INT C LEARN REPR, V0, P1
   Yao Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP15796, DOI 10.1109/ICCV48922.2021.01552
   Yi KX, 2018, ADV NEUR IN, V31, P0
   Zhang K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5682
   Zhao L, 2021, PATTERN RECOGN, V114, P0, DOI 10.1016/j.patcog.2021.107823
NR 79
TC 0
Z9 0
U1 0
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
EI 
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUL 28
PY 2022
VL 16
IS 
BP 
EP 
DI 10.3389/fnbot.2022.844753
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA 3Z5YI
UT WOS:000844492800001
PM 35966371
DA 2023-11-10
ER

PT J
AU Yenkikar, A
   Babu, CN
   Hemanth, DJ
AF Yenkikar, Anuradha
   Babu, C. Narendra
   Hemanth, D. Jude
TI Semantic relational machine learning model for sentiment analysis using cascade feature selection and heterogeneous classifier ensemble
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment analysis; Deep learning; Natural language processing; Ensemble model
AB The exponential rise in social media symbolscript microblogging sites like Twitter has sparked curiosity in sentiment analysis that exploits user feedback towards a targeted product or service. Considering its significance in business intelligence and decision-making, numerous efforts have been made in this area. However, lack of dictionaries, unannotated data, large-scale unstructured data, and low accuracies have plagued these approaches. Also, sentiment classification through classifier ensemble has been underexplored in literature. In this article, we propose a Semantic Relational Machine Learning (SRML) model that automatically classifies the sentiment of tweets by using classifier ensemble and optimal features. The model employs the Cascaded Feature Selection (CFS) strategy, a novel statistical assessment approach based on Wilcoxon rank sum test, univariate logistic regression assisted significant predictor test and cross-correlation test. It further uses the efficacy of word2vec-based continuous bag -of-words and n-gram feature extraction in conjunction with SentiWordNet for finding optimal features for classification. We experiment on six public Twitter sentiment datasets, the STS-Gold dataset, the Obama-McCain Debate (OMD) dataset, the healthcare reform (HCR) dataset and the SemEval2017 Task 4A, 4B and 4C on a heterogeneous classifier ensemble comprising fourteen individual classifiers from different paradigms. Results from the experimental study indicate that CFS supports in attaining a higher classification accuracy with up to 50% lesser features compared to count vectorizer approach. In Intra-model performance assessment, the Artificial Neural Network-Gradient Descent (ANN-GD) classifier performs comparatively better than other individual classifiers, but the Best Trained Ensemble (BTE) strategy outperforms on all metrics. In inter-model performance assessment with existing state-of-the-art systems, the proposed model achieved higher accuracy and outperforms more accomplished models employing quantum-inspired sentiment representation (QSR), transformer-based methods like BERT, BERTweet, RoBERTa and ensemble techniques. The research thus provides critical insights into implementing similar strategy into building more generic and robust expert system for sentiment analysis that can be leveraged across industries.
C1 [Yenkikar, Anuradha; Babu, C. Narendra] MS Ramaiah Univ Appl Sci, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
   [Hemanth, D. Jude] Karunya Univ, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
C3 M. S. Ramaiah University of Applied Sciences; Karunya Institute of Technology & Sciences
RP Hemanth, DJ (通讯作者)，Karunya Univ, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
EM judehemanth@karunya.edu
CR Abbas AK, 2020, J SW JIAOTONG U, V55, P1, DOI 10.35741/issn.0258-2724.55.1.9
   Alfaro C, 2016, ANN OPER RES, V236, P197, DOI 10.1007/s10479-013-1449-6
   Alsayat A, 2022, ARAB J SCI ENG, V47, P2499, DOI 10.1007/s13369-021-06227-w
   Annett M, 2008, LECT NOTES ARTIF INT, V5032, P25
   [Anonymous], 2013, EVALUATION DATASETS, V0, P0
   [Anonymous], 2006, P AAAI C ARTIFICIAL, V0, P0
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Aziz Roza HHama, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON ADVANCED SCIENCE AND ENGINEERING (ICOASE), V0, PP103, DOI 10.1109/ICOASE51841.2020.9436590
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   Balikas G, 2017, P 11 INT WORKSHOP SE, V0, P755
   Barreto S, 2021, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2105.14373
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Baziotis C, 2017, P 11 INT WORKSHOP SE, V0, PP747, DOI 10.18653/V1/S17-2126
   Bibi M, 2020, IEEE ACCESS, V8, P68580, DOI 10.1109/ACCESS.2020.2983859
   Bo Pang, 2008, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V2, P1, DOI 10.1561/1500000001
   Boiy Erik, 2007, 11TH INTERNATIONAL CONFERENCE ON ELECTRONIC PUBLISHING. OPENNESS IN DIGITAL PUBLISHING: AWARENESS, V0, P349
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Carvalho J, 2021, ARTIF INTELL REV, V54, P1887, DOI 10.1007/s10462-020-09895-6
   Carvalho J, 2016, FRONT ARTIF INTEL AP, V285, P769, DOI 10.3233/978-1-61499-672-9-769
   Carvalho J, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P110, DOI 10.1109/WI-IAT.2014.87
   Chen CM, 2006, IEEE CONF VIS ANAL, V0, P59
   Chinnalagu A, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.813
   Chintalapudi N, 2021, INFECT DIS REP, V13, P329, DOI 10.3390/idr13020032
   Cliche M, 2017, P SEMEVAL, V0, PP573, DOI 10.18653/V1/S17-2094
   Collomb A, 2014, RAPPORT RECHERCHE RR, V0, P0
   da Silva NFF, 2014, DECIS SUPPORT SYST, V66, P170, DOI 10.1016/j.dss.2014.07.003
   Davies A, 2011, P 5 SNA KDD WORKSHOP, V0, P99
   Diakopoulos NA, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1195
   Ding X, 2008, P 2008 INT C WEB SEA, V0, PP231, DOI 10.1145/1341531.1341561
   Go A, 2009, TWITTER SENTIMENT CL, V1, P1, DOI 10.1145/1526709.1526921
   Govindarajan M, 2013, IJACR, V3, P139
   Gui L, 2016, P 2016 C EMP METH NA, V0, P1639
   Haenlein M, 2010, J RELATIONSHIP MARKE, V9, P200, DOI 10.1080/15332667.2010.522474
   Aziz RHH, 2021, J CHIN INST ENG, V44, P562, DOI 10.1080/02533839.2021.1933598
   Heredia B, 2016, PROCEEDINGS OF 2016 IEEE 17TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI), V0, PP160, DOI 10.1109/IRI.2016.28
   Hu X, 2013, P 22 INT C WORLD WID, V0, P607
   Iqbal F, 2019, IEEE ACCESS, V7, P14637, DOI 10.1109/ACCESS.2019.2892852
   Jiang XC, 2022, PEERJ COMPUT SCI, V8, P0, DOI 10.7717/peerj-cs.1005
   Johnson Rie, 2015, ARXIV, V0, P0
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kamps J, 2004, P 4 INT C LANGUAGE R, V4, P1115
   Kazmaier J, 2022, EXPERT SYST APPL, V187, P0, DOI 10.1016/j.eswa.2021.115819
   Khan A, 2011, TRENDS APPL SCI RES, V6, P1141, DOI 10.3923/tasr.2011.1141.1157
   Kim Yoon, 2014, P 2014 C EMPIRICAL M, V0, PP1746, DOI 10.3115/V1/D14-1181
   Ko CR, 2021, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.408
   Kolovou A, 2017, P 11 INT WORKSH SEM, V0, P675
   Kumar S, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.660
   Lee Sophia Yat Mei, 2010, P NAACL HLT 2010 WOR, V0, P45
   Li JJ, 2016, INT J COMPUT INTELL, V15, P0, DOI 10.1142/S1469026816500036
   Li WY, 2014, EXPERT SYST APPL, V41, P1742, DOI 10.1016/j.eswa.2013.08.073
   Lilleberg J, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), V0, PP136, DOI 10.1109/ICCI-CC.2015.7259377
   Liu H, 2022, SMART METROSTATION S, V0, P237
   Lochter JV, 2016, EXPERT SYST APPL, V62, P243, DOI 10.1016/j.eswa.2016.06.025
   Lu HY, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.816
   Luo F, 2016, INT C COMP SUPP COOP, V0, PP276, DOI 10.1109/CSCWD.2016.7566001
   Mehta P, 2021, PEERJ COMPUT SCI, V0, P0, DOI DOI 10.7717/peerj-cs.476
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Nogueira CSD, 2014, P COLING 2014 25 INT, V0, PP69, DOI 10.1109/ICCAR.2017.7942788
   Paltoglou G, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P1386
   Prabowo R, 2009, J INFORMETR, V3, P143, DOI 10.1016/j.joi.2009.01.003
   Rosenthal S, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/v1/S17-2088
   Rouvier M, 2017, P 11 INT WORKSHOP SE, V0, P760
   Rozental A, 2017, P 11 INT WORKSHOP SE, V0, P653
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Speriosu Michael, 2011, P 1 WORKSH UNS LEARN, V0, PP53, DOI 10.1017/CB09781107415324.004
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Ting-Chun Peng, 2010, PROCEEDINGS OF THE 2010 IEEE/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE-INTELLIGENT AGENT TECHNOLOGY - WORKSHOPS (WI-IAT 2010), V0, PP243, DOI 10.1109/WI-IAT.2010.229
   TROUSSAS C, 2016, 2016 7 INT C INF INT, V0, P1
   Yang CC, 2010, PAC ASIA J ASSOC INF, V2, P73
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   Yeole AV, 2015, ICIIECS 2015 2015 IN, V0, P0
   Kermani FZ, 2020, EVOL INTELL, V13, P381, DOI 10.1007/s12065-019-00301-x
   Zhang YZ, 2019, APPL INTELL, V49, P3093, DOI 10.1007/s10489-019-01441-4
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
NR 74
TC 2
Z9 2
U1 1
U2 4
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD SEP 20
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1100
PG 34
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 5A8WT
UT WOS:000863162200002
PM 36262147
DA 2023-11-10
ER

PT J
AU Trisedya, BD
   Qi, JZ
   Wang, W
   Zhang, R
AF Trisedya, Bayu Distiawan
   Qi, Jianzhong
   Wang, Wei
   Zhang, Rui
TI GCP: Graph Encoder With Content-Planning for Sentence Generation From Knowledge Bases
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Natural language processing; triple-to-text generation; knowledge base
AB A knowledge base is a large repository of facts usually represented as triples, each consisting of a subject, a predicate, and an object. The triples together form a graph, i.e., a knowledge graph. The triple representation in a knowledge graph offers a simple interface for applications to access the facts. However, this representation is not in a natural language form, which is difficult for humans to understand. We address this problem by proposing a system to translate a set of triples (i.e., a graph) into natural sentences. We take an encoder-decoder based approach. Specifically, we propose a Graph encoder with Content-Planning capability (GCP) to encode an input graph. GCP not only works as an encoder but also serves as a content-planner by using an entity-order aware topological traversal to encode a graph. This way, GCP can capture the relationships between entities in a knowledge graph as well as providing information regarding the proper entity order for the decoder. Hence, the decoder can generate sentences with a proper entity mention ordering. Experimental results show that GCP achieves improvements over state-of-the-art models by up to 3:6%, 4:1%, and 3:8% in three common metrics BLEU, METEOR, and TER, respectively. The code is available at (https://github.com/ruizhang-ai/GCP/)
C1 [Trisedya, Bayu Distiawan] Univ Indonesia, Kota Depok 16424, JB, Indonesia.
   [Trisedya, Bayu Distiawan; Qi, Jianzhong] Univ Melbourne, Parkville, Vic, Australia.
   [Wang, Wei] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Zhang, Rui] Tsinghua Univ, Grad Sch Shengzhen, Dept Comp Sci, Shenzhen 518055, Peoples R China.
C3 University of Indonesia; University of Melbourne; Hong Kong University of Science & Technology; Tsinghua University
RP Zhang, R (通讯作者)，Tsinghua Univ, Grad Sch Shengzhen, Dept Comp Sci, Shenzhen 518055, Peoples R China.
EM bayu.trisedya@unimelb.edu.au; jianzhong.qi@unimelb.edu.au; weiwcs@ust.hk; rayteam@yeah.net
FU Indonesian Endowment Fund for Education (LPDP); Australian Research Council (ARC) [DP180102050]
CR [Anonymous], 2011, P 2011 C EMPIRICAL M, V0, P0
   [Anonymous], 2015, ICLR, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bontcheva K, 2004, LECT NOTES COMPUT SC, V3136, P324
   Bordes A, 2013, P NIPS, V0, P2787
   Cao YX, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1623, DOI 10.18653/v1/P17-1149
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Cimiano P, 2013, ENLG WORKSH, V0, P10
   Clark Jonathan H, 2011, P 49 ANN M ASS COMP, V0, P176
   Denkowski M, 2011, P 6 WORKSHOP STAT MA, V0, P0
   Duboue PA, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P172
   Duma Daniel, 2013, P 10 INT C COMPUTATI, V0, P83
   Fellbaum C, 1998, LANG SPEECH & COMMUN, V0, P1
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gardent C, 2017, P 10 INT C NAT LANG, V0, P0
   Gardent C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P179, DOI 10.18653/v1/P17-1017
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Ji GL, 2016, AAAI CONF ARTIF INTE, V0, P985
   Kipf TN, 2016, P INT C LEARNING REP, V0, P0
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Lebret Remi, 2016, P 2016 C EMP METH NA, V0, PP1203, DOI 10.18653/v1/D16-1128
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8
   Lin YK, 2015, AAAI CONF ARTIF INTE, V0, P2181
   Liu TY, 2018, AAAI CONF ARTIF INTE, V0, P4881
   Lu W, 2009, C EMP METH NAT LANG, V0, P400
   Luong M-T, 2015, P 2015 C EMP METH NA, V0, PP1412, DOI 10.18653/V1/D15-1166
   Marcheggiani Diego, 2018, P 11 INT C NAT LANG, V0, PP1, DOI 10.18653/V1/W18-6501
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Puduppully R, 2019, AAAI CONF ARTIF INTE, V0, P6908
   Reiter E, 2000, BUILDING NATURAL LAN, V0, P41
   Schwartz Ariel S, 2003, PAC SYMP BIOCOMPUT, V0, P451
   Sha L, 2018, AAAI CONF ARTIF INTE, V0, P5414
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, V0, P223
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Trisedya BD, 2020, AAAI CONF ARTIF INTE, V34, P9057
   Trisedya BD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P229
   Trisedya BD, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1627
   Trisedya BD, 2019, AAAI CONF ARTIF INTE, V0, P297
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Veličkovic P, 2018, ARXIV, V0, P0
   Vinyals O, 2015, P ADV NEURAL INFORM, V0, PP2692, DOI 10.48550/arxiv.1506.03134
   Vougiouklis P, 2018, J WEB SEMANT, V52-53, P1, DOI 10.1016/j.websem.2018.07.002
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang Z, 2014, P 2014 C EMP METH NA, V0, PP1591, DOI 10.3115/V1/D14-1167
   Wang Z, 2014, AAAI CONF ARTIF INTE, V0, P1112
   Wiseman S, 2017, P 2017 C EMPIRICAL M, V0, P0
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Yamada I, 2016, P 20 SIGNLL C COMP N, V0, P250
   Zhang R, 2021, ARXIV, V0, P0
   Zhong H, 2015, EMNLP, V2015, P267, DOI 10.18653/V1/D15-1031
NR 53
TC 0
Z9 0
U1 4
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD NOV 1
PY 2022
VL 44
IS 11
BP 7521
EP 7533
DI 10.1109/TPAMI.2021.3118703
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 5C5UY
UT WOS:000864325900021
PM 34623261
DA 2023-11-10
ER

PT J
AU Sun, XF
   Meng, YX
   Ao, X
   Wu, F
   Zhang, TW
   Li, JW
   Fan, C
AF Sun, Xiaofei
   Meng, Yuxian
   Ao, Xiang
   Wu, Fei
   Zhang, Tianwei
   Li, Jiwei
   Fan, Chun
TI Sentence Similarity Based on Contexts
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Existing methods to measure sentence similarity are faced with two challenges: (1) labeled datasets are usually limited in size, making them insufficient to train supervised neural models; and (2) there is a training-test gap for unsupervised language modeling (LM) based models to compute semantic scores between sentences, since sentence-level semantics are not explicitly modeled at training. This results in inferior performances in this task. In this work, we propose a new framework to address these two issues. The proposed framework is based on the core idea that the meaning of a sentence should be defined by its contexts, and that sentence similarity can be measured by comparing the probabilities of generating two sentences given the same context. The proposed framework is able to generate high-quality, large-scale dataset with semantic similarity scores between two sentences in an unsupervised manner, with which the train-test gap can be largely bridged. Extensive experiments show that the proposed framework achieves significant performance boosts over existing baselines under both the supervised and unsupervised settings across different datasets.
C1 [Sun, Xiaofei; Wu, Fei; Li, Jiwei] Zhejiang Univ, Hangzhou, Peoples R China.
   [Meng, Yuxian; Li, Jiwei] Shannon AI, Beijing, Peoples R China.
   [Ao, Xiang] Chinese Acad Sci, Beijing, Peoples R China.
   [Zhang, Tianwei] Nanyang Technol Univ, Singapore, Singapore.
   [Fan, Chun] Peking Univ, Comp Ctr, Beijing, Peoples R China.
   [Fan, Chun] Peking Univ, Natl Biomed Imaging Ctr, Beijing, Peoples R China.
   [Fan, Chun] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Zhejiang University; Chinese Academy of Sciences; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Peking University; Peking University; Peng Cheng Laboratory
RP Sun, XF (通讯作者)，Zhejiang Univ, Hangzhou, Peoples R China.
EM xiaofei_sun@shannonai.com; yuxian_meng@shannonai.com; aoxiang@ict.ac.cn; wufei@zju.edu.cn; tianwei.zhang@ntu.edu.sg; jiwei_li@shannonai.com; fanchun@pku.edu.cn
FU Science and Technology Innovation 2030 - "New Generation Artificial Intelligence" Major Project [2021ZD0110201]; Ministry of Science and Technology [2020YFC0832500]
CR Agirre E, 2016, P 10 INT WORKSH SEM, V0, PP497, DOI 10.18653/V1/S16-1081
   Agirre E, 2012, P 6 INT WORKSHOP SEM, V0, P385
   [Anonymous], 2015, P 9 INT WORKSH SEM E, V0, P0
   Arora S, 2017, ICLR, V0, P0
   Backurs Arturs, 2020, P 37 INT C MACHINE L, V0, P497
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Carlsson Fredrik, 2021, INT C LEARNING REPRE, V0, P0
   Cer D, 2018, ARXIV, V0, P0
   Cer Daniel M, 2017, ARXIV, V0, P0
   Chen Danqi, 2017, ARXIV, V0, P0
   Chen L, 2020, INT C MACHINE LEARNI, V0, P1542
   Conneau A, 2018, ARXIV, V0, P0
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, ARXIV, V0, P0
   Dor LE, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Eneko Agirre Daniel, 2013, SEM 2013 SHARED TASK, V0, P32
   Gong YC, 2018, ARXIV, V0, P0
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   He H, 2016, P 2016 C N AM CHAPT, V0, PP937, DOI 10.18653/V1/N16-1108
   Hill Felix, 2016, P NAACL HLT, V0, PP1367, DOI 10.18653/V1/N16-1162
   Huang G, 2016, ADV NEURAL INFORM PR, V0, P4862
   Huang JJ, 2021, ARXIV, V0, P0
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Kim S, 2019, AAAI CONF ARTIF INTE, V0, P6586
   Kim T, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2528
   Kingma DP, 2014, C TRACK P, V0, P0
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, V0, PP3294, DOI 10.5555/2969442.2969607
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Li BH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9119
   Li JW, 2017, ARXIV, V0, P0
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Lin ZH, 2017, ARXIV, V0, P0
   Liu B, 2021, ANAL METHODS-UK, V13, P3845, DOI 10.1039/d1ay00717c
   Liu YH, 2019, ARXIV, V0, P0
   Logeswaran L, 2018, ARXIV, V0, P0
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   MacCartney Bill, 2009, NATURAL LANGUAGE INF, V0, P0
   Mamdouh F, 2018, RES C MET SEM RES, V0, PP89, DOI 10.1007/978-3-030-14401-2_8
   Marelli Marco, 2014, P 9 INT C LANG RES E, V0, P216
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Misra Amita, 2016, P 17 ANN M SPECIAL I, V0, PP276, DOI 10.18653/v1/W16-3636
   Pang L, 2016, AAAI CONF ARTIF INTE, V0, P2793
   Parikh AP, 2016, DECOMPOSABLE ATTENTI, V0, P0, DOI DOI 10.48550/ARXIV.1606.01933
   Peng S, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2500, DOI 10.1145/3366423.3379998
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Reimers N, 2019, ARXIV, V0, P0
   Robertson SE, 1995, TEXT RETRIEVAL CONFERENCE (TREC-3) (NIST SP 500-225), V0, P109
   Rocktaschel Tim, 2015, ARXIV, V0, P0
   Sellam Thibault, 2020, P 58 ANN M ASS COMPU, V0, PP7881, DOI 10.18653/V1/2020.ACL-MAIN.704
   Seo M, 2018, ARXIV, V0, P0
   Shen Gehui, 2017, P 2017 C EMP METH NA, V0, PP1179, DOI 10.18653/V1/D17-1122
   Sparck-Jones K, 2004, J DOC, V60, P493, DOI 10.1108/00220410410560573
   Su Jianlin, 2021, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2103.15316
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Tan CQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4411
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang B, 2020, IEEE-ACM T AUDIO SPE, V28, P2146, DOI 10.1109/TASLP.2020.3008390
   Wang Zhiguo, 2016, P COLING 2016 26 INT, V0, P1340
   Wiebe J, 2014, P 8 INT WORKSH SEM E, V0, PP81, DOI 10.3115/v1/S14-2010
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Wu LF, 2018, ARXIV, V0, P0
   Wu XH, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), V0, PP1998, DOI 10.1109/ICCT.2017.8359979
   Wu ZF, 2020, ARXIV, V0, P0
   Yan YM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5065
   Yang MM, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3076
   Yang RQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4699
   Yin WP, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P63
   Yokoi S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2944
   Yurochkin M, 2019, P ADV NEURAL INFORM, V32, P1601
   Zhang Tianyi, 2020, ICLR, V0, P0
NR 72
TC 4
Z9 4
U1 0
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAY 16
PY 2022
VL 10
IS 
BP 573
EP 588
DI 10.1162/tacl_a_00477
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9NQ
UT WOS:000923420000001
DA 2023-11-10
ER

PT J
AU Alsubhi, K
   Jamal, A
   Alhothali, A
AF Alsubhi, Kholoud
   Jamal, Amani
   Alhothali, Areej
TI Deep learning-based approach for Arabic open domain question answering
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Arabic open domain question answering; Transformer-based models for question answering; Dense information retrieval approach
AB Open-domain question answering (OpenQA) is one of the most challenging yet widely investigated problems in natural language processing. It aims at building a system that can answer any given question from large-scale unstructured text or structured knowledge-base. To solve this problem, researchers traditionally use information retrieval methods to retrieve the most relevant documents and then use answer extractions techniques to extract the answer or passage from the candidate documents. In recent years, deep learning techniques have shown great success in OpenQA by using dense representation for document retrieval and reading comprehension for answer extraction. However, despite the advancement in the English language OpenQA, other languages such as Arabic have received less attention and are often addressed using traditional methods. In this paper, we use deep learning methods for Arabic OpenQA. The model consists of document retrieval to retrieve passages relevant to a question from large-scale free text resources such as Wikipedia and an answer reader to extract the precise answer to the given question. The model implements dense passage retriever for the passage retrieval task and the AraELECTRA for the reading comprehension task. The result was compared to traditional Arabic OpenQA approaches and deep learning methods in the English OpenQA. The results show that the dense passage retriever outperforms the traditional Term Frequency-Inverse Document Frequency (TF-IDF) information retriever in terms of the top-20 passage retrieval accuracy and improves our end-to-end question answering system in two Arabic question-answering benchmark datasets.
C1 [Alsubhi, Kholoud; Jamal, Amani; Alhothali, Areej] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.
C3 King Abdulaziz University
RP Alsubhi, K (通讯作者)，King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.
EM kalsobhi0013@stu.kau.edu.sa
CR Ahmed W, 2017, INT J ADV RES COMPUT, V8, P2849, DOI 10.26483/ijarcs.v8i1.2849
   Ahmed Waheeb, 2017, INT J ENG RES, V6, P142
   Ahmed Waheeb, 2016, INT J COMPUTATIONAL, V12, P18
   Almiman A, 2020, ALEX ENG J, V59, P4427, DOI 10.1016/j.aej.2020.07.048
   [Anonymous], 2009, ENCY DATABASE SYST, V0, P0, DOI DOI 10.1007/978-0-387-39940-9_561
   Antoun W, 1900, P191, V0, P0
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Attardi W, 2015, WIKIEXTRACTOR, V0, P0
   Bird S, 2008, P 3 WORKSH ISS TEACH, V13, P62, DOI 10.3115/1627306.1627317
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Clark JH, 2020, T ASSOC COMPUT LING, V8, P454, DOI 10.1162/tacl_a_00317
   Clark K, 2020, ARXIV PREPRINT, V0, P0
   Cui Yiming, 2020, P 28 INT C COMPUTATI, V0, PP6717, DOI 10.18653/V1/2020.COLING-MAIN.589
   Devlin J, 2018, ARXIV, V1, P4171
   elastic, 2021, FREE OPEN SEARCH CRE, V0, P0
   Guu K, 2020, ARXIV PREPRINT, V0, P0
   Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2545
   Huang Z, 2020, IEEE ACCESS, V8, P94341, DOI 10.1109/ACCESS.2020.2988903
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6086
   Lewis P, 2020, P 58 ANN M ASS COMPU, V0, PP7315, DOI 10.18653/V1/2020.ACL-MAIN.653
   Mozannar H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), V0, P108
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rusic M, 2021, NLP SOLUTIONS STREAM, V0, P0
   Sammut C, 2017, ENCY MACHINE LEARNIN, V2nd, P0, DOI 10.1007/978-1-4899-7687-1_68
   Teufel S, 2007, TEXT SPEECH LANG TEC, V37, P163
   Voidful, 2021, VOIDFULDPR CTX ENCOD, V0, P0
   Wikimedia Foundation, 2021, ARW DUMP PROGR 20210, V0, P0
   Wu Y, 2016, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.1609.08144
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P72
   Zhang Zhirui, 2018, CONLL 2018 22 C COMP, V0, PP190, DOI 10.18653/V1/K18-1019
   Zhu F, 2021, ARXIV PREPRINT, V0, P0, DOI DOI 10.48550/arXiv.2101.00774
NR 37
TC 5
Z9 5
U1 1
U2 6
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD MAY 4
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.952
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 1I4NZ
UT WOS:000797207800001
PM 35634104
DA 2023-11-10
ER

PT J
AU Catelli, R
   Bevilacqua, L
   Mariniello, N
   di Carlo, VS
   Magaldi, M
   Fujita, H
   De Pietro, G
   Esposito, M
AF Catelli, Rosario
   Bevilacqua, Luca
   Mariniello, Nicola
   di Carlo, Vladimiro Scotto
   Magaldi, Massimo
   Fujita, Hamido
   De Pietro, Giuseppe
   Esposito, Massimo
TI Cross lingual transfer learning for sentiment analysis of Italian TripAdvisor reviews
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Transfer learning; Sentiment analysis; Italian dataset; BERT; TripAdvisor; Reviews
AB Over the years, the attention of the scientific world towards the techniques of sentiment analysis has increased considerably, driven by industry. The arrival of the Google BERT language model has confirmed the superiority of models based on a particular structure of artificial neural network called Transformer, from which many variants have resulted. These models are generally pre-trained on large text corpora and only later specialized according to the precise task to be faced on much smaller amounts of data. For these reasons, countless versions were developed to meet the specific needs of each language, especially in the case of languages with relatively few datasets available. At the same time, models that were pre-trained for multiple languages became widespread, providing greater flexibility of use in exchange for lower performance. This study shows how the use of techniques to transfer learning from languages with high resources to languages with low resources provides an important performance increase: a multilingual BERT model fine tuned on a mixed English/Italian dataset (using for the English a literature dataset and for the Italian a reviews dataset created ad-hoc from the well-known platform TripAdvisor), provides much higher performance than models specific to Italian. Overall, the results obtained by comparing the different possible approaches indicate which one is the most promising to pursue in order to obtain the best results in low resource scenarios.
C1 [Catelli, Rosario; De Pietro, Giuseppe; Esposito, Massimo] Natl Res Council CNR, Inst High Performance Comp & Networking ICAR, Naples, Italy.
   [Fujita, Hamido] Ho Chi Minh City Univ Technol HUTECH, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Fujita, Hamido] Natl Taipei Univ Technol, Taipei, Taiwan.
   [Fujita, Hamido] I Somet Inc Assoc, Morioka, Iwate, Japan.
   [Bevilacqua, Luca; Mariniello, Nicola; di Carlo, Vladimiro Scotto; Magaldi, Massimo] Engn Ingn Informat SpA, Naples, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR); Vietnam National University Hochiminh City; Ho Chi Minh City University of Technology (HUTECH); National Taipei University of Technology
RP Catelli, R (通讯作者)，Natl Res Council CNR, Inst High Performance Comp & Networking ICAR, Naples, Italy.
EM rosario.catelli@icar.cnr.it; luca.bevilacqua@eng.it; nicola.mariniello@eng.it; vladimiro.scottodicarlo@eng.it; massimo.magaldi@eng.it; h.fujita@hutech.edu.vn; giuseppe.depietro@icar.cnr.it; massimo.esposito@icar.cnr.it
FU Innovation for Data Elaboration in Heritage Areas (IDEHA) project from the National Operational Programme (PON) of the Italian Ministry of Education, University and Research (MIUR) [ARS01_00421, 2059]
CR Agüero-Torales MM, 2021, APPL SOFT COMPUT, V107, P0, DOI 10.1016/j.asoc.2021.107373
   Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   Alayba AM, 2018, LECT NOTES COMPUT SC, V11015, P179, DOI 10.1007/978-3-319-99740-7_12
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Arkhipov M, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP2019), V0, P89
   Augustyniak L, 2021, COMPUT SPEECH LANG, V69, P0, DOI 10.1016/j.csl.2021.101217
   Basarslan MS, 2021, SAKARYA U J COMPUT I, V4, P35, DOI 10.35377/saucis.04.01.833026
   Baziotis C, 2017, P 11 INT WORKSHOP SE, V0, PP747, DOI 10.18653/V1/S17-2126
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Cao K, 2016, P 1 WORKSH REPR LEAR, V0, PP18, DOI 10.18653/V1/W16-1603
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Colón-Ruiz C, 2020, J BIOMED INFORM, V110, P0, DOI 10.1016/j.jbi.2020.103539
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   de Vries W, 2019, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diamantini C, 2016, 2016 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), V0, PP188, DOI 10.1109/CTS.2016.0048
   Garneau N, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5546
   Guarasci R, 2022, COMPUT SPEECH LANG, V71, P0, DOI 10.1016/j.csl.2021.101261
   Hao YB, 2020, IEEE T KNOWL DATA EN, V32, P1909, DOI 10.1109/TKDE.2019.2913379
   Haque TU, 2018, 2018 IEEE INT C INN, V0, PP1, DOI 10.1109/ICIRD.2018.8376299
   Heinzerling B, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P2989
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hutto CJ, 2014, ICWSM, V0, P0, DOI DOI 10.1609/ICWSM.V8I1.14550
   Hvingelby R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P4597
   Jiang QN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6280
   Kapociute-Dzikiene J, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10121412
   Karthikeyan K, 2020, 8 INT C LEARNING REP, V0, P0
   Kokalj E, 2021, P EACL HACK NEWS MED, V0, P16
   Kuratov Y, 2019, ARXIV, V0, P0
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample Guillaume, 2018, 6 INT C LEARNING REP, V0, P0
   Le H, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P2479
   Li D, 2016, 2016 FIRST IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND THE INTERNET (ICCCI 2016), V0, PP471, DOI 10.1109/CCI.2016.7778967
   Li MZ, 2021, APPL INTELL, V51, P5016, DOI 10.1007/s10489-020-02101-8
   Li Y, 2017, COGN COMPUT, V9, P843, DOI 10.1007/s12559-017-9492-2
   Liu YH, 2019, ARXIV, V0, P0
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Mosbach M, 2021, INT C LEARN REPR, V0, P0
   Mukherjee S, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P3092
   Mulcaire P, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3912
   Nozza D, 2020, ARXIV, V0, P0
   Ott M, 2011, P 49 ANN M ASS COMPU, V1, P309, DOI 10.1145/2567948.2577293
   Ott Myle, 2013, HLT NAACL, V0, P497
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Park SM, 2021, INFORM FUSION, V67, P41, DOI 10.1016/j.inffus.2020.10.009
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Perikos I, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), V0, P273
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Polignano M, 2019, CEUR WORKSHOP PROC, VVolume 2481, P1
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ray B, 2021, APPL SOFT COMPUT, V98, P0, DOI 10.1016/j.asoc.2020.106935
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Sahin GG, 2020, COMPUT LINGUIST, V46, P335, DOI 10.1162/COLI_a_00376
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Singla Z, 2017, INT CONF COMPUT, V0, P1
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Vaswani A, 2017, ARXIV, V30, P5998
   Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P833
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zhang Tianyi, 2021, P ICLR, V0, P0
   Zhu Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P912
NR 67
TC 2
Z9 2
U1 3
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2022
VL 209
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118246
EA AUG 2022
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 4R4YQ
UT WOS:000856772000006
DA 2023-11-10
ER

PT J
AU Mukta, MSH
   Islam, MA
   Khan, FA
   Hossain, A
   Razik, S
   Hossain, S
   Mahmud, J
AF Mukta, Md Saddam Hossain
   Islam, Md Adnanul
   Khan, Faisal Ahamed
   Hossain, Afjal
   Razik, Shuvanon
   Hossain, Shazzad
   Mahmud, Jalal
TI A Comprehensive Guideline for Bengali Sentiment Annotation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Annotation guideline; sentiment analysis; natural language processing
ID interrater reliability; emotion
AB Sentiment Analysis (SA) is a Natural Language Processing (NLP) and an Information Extraction (1E) task that primarily aims to obtain the writer's feelings expressed in positive or negative by analyzing a large number of documents. SA is also widely studied in the fields of data mining, web mining, text mining, and information retrieval. The fundamental task in sentiment analysis is to classify the polarity of a given content as Positive, Negative, or Neutral. Although extensive research has been conducted in this area of computational linguistics, most of the research work has been carried out in the context of English language. However, Bengali sentiment expression has varying degree of sentiment labels, which can be plausibly distinct from English language. Therefore, sentiment assessment of Bengali language is undeniably important to be developed and executed properly. In sentiment analysis, the prediction potential of an automatic modeling is completely dependent on the quality of dataset annotation. Bengali sentiment annotation is a challenging task due to diversified structures (syntax) of the language and its different degrees of innate sentiments (i.e., weakly and strongly positive/negative sentiments). Thus, in this article, we propose a novel and precise guideline for the researchers, linguistic experts, and referees to annotate Bengali sentences immaculately with a view to building effective datasets for automatic sentiment prediction efficiently.
C1 [Mukta, Md Saddam Hossain; Islam, Md Adnanul; Khan, Faisal Ahamed; Hossain, Afjal; Razik, Shuvanon; Hossain, Shazzad] Giga Tech Ltd, Dhaka 1215, Bangladesh.
   [Mukta, Md Saddam Hossain; Hossain, Shazzad] United Int Univ, Dhaka 1212, Bangladesh.
   [Islam, Md Adnanul] Mil Inst Sci & Technol, Dhaka 1216, Bangladesh.
   [Mahmud, Jalal] IBM Almaden Res Ctr, San Jose, CA USA.
C3 United International University (UIU); International Business Machines (IBM)
RP Mukta, MSH (通讯作者)，Giga Tech Ltd, Dhaka 1215, Bangladesh.; Mukta, MSH (通讯作者)，United Int Univ, Dhaka 1212, Bangladesh.
EM saddam@cse.uiu.ac.bd; islamadnan2265@gmail.com; faisal.cse06@gigatechltd.com; vanon.razik@gigatechltd.com; shazzad.hossain@gigatechltd.com; jumahmud@us.ibm.com
FU Information and Communication Technology Division (ICT-Division) under the Ministry of Posts, Telecommunications and Information Technology of the Government of the People's Republic of Bangladesh
CR Alam F, 2020, ADV ENG MATER, V22, P0, DOI 10.1002/adem.202000483
   Aman S, 2007, LECT NOTES ARTIF INT, V4629, P196
   Anik MSH, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON NETWORKING, V0, P120
   [Anonymous], 2016, P 15 ANN C N AM CHAP, V0, P0, DOI DOI 10.18653/V1/N16-1095
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, V0, P452
   Banik Nayan, 2019, 1 INT C ADV SCI ENG, V0, PP1, DOI 10.1109/ICASERT.2019.8934481
   Barnes J, 2017, P 8 WORKSHOP COMPUTA, V0, PP2, DOI 10.18653/V1/W17-5202
   Bosco C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P4158
   Chowdhury S, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, V0, P0
   de Castilho RE, 2016, P WORKSHOP LANGUAGE, V0, PP76, DOI 10.1016/J.JBI.2015.08.020
   Devlin J, 2018, BERT PRETRAINING DEE, V0, P0, DOI DOI 10.18653/V1/N19-PROCEEDINGSOFNAACLHLT1423
   Emon MIS, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON NETWORKING, V0, P109, DOI 10.1145/3362966.3362977
   Esuli Andrea, 2006, LREC, V0, P0, DOI DOI 10.1155/2015/715730
   Francisca J, 2011, INDIAN J COMPUTER SC, V2, P334
   Hasan HMMahmudul, 2020, 2020 THIRD INTERNATIONAL CONFERENCE ON SMART SYSTEMS AND INVENTIVE TECHNOLOGY (ICSSIT), V0, PP1131, DOI 10.1109/ICSSIT48917.2020.9214196
   Hendrycks D, 2016, PROC INT C LEARN REP, V0, P1
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, V0, P755
   Islam M, 2016, P 7 ANN S COMP DEV, V0, P0
   Kaur Amandeep, 2013, JOURNAL OF EMERGING TECHNOLOGIES IN WEB INTELLIGENCE, V5, P367, DOI 10.4304/jetwi.5.4.367-371
   Khan EM, 2020, ACM T INTERACT INTEL, V10, P0, DOI 10.1145/3338244
   Liu B, 2011, DATA CENTRIC SYST AP, V0, PP459, DOI 10.1007/978-3-642-19460-3_11
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Loshchilov I, 2017, MACH LEARN, V0, PP1, DOI 10.48550/arXiv.1711.05101
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Maehlum P, 2019, P 22 NORDIC C COMPUT, V0, P121
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mohammad S, 2016, P 7 WORKSH COMP APPR, V0, PP174, DOI 10.18653/V1/W16-0429
   Mohammad SM, 2015, INFORM PROCESS MANAG, V51, P480, DOI 10.1016/j.ipm.2014.09.003
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Mozetic I, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0155036
   Mukta MSH, 2016, SOC NETW ANAL MIN, V6, P0, DOI 10.1007/s13278-016-0383-4
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Pak Alexander, 2010, P 7 INT C LANGUAGE R, V0, P0
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Saura JR, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11030917
   REXACH JG, 1998, REV ALICANTINA ESTUD, V11, P139, DOI 10.14198/RAEI.1998.11.11
   Rosenthal S, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/v1/S17-2088
   Salinca A, 2016, INT SYMP SYMB NUMERI, V0, PP247, DOI 10.1109/SYNASC.2015.46
   Sarker S, 2020, BANGLABERT BENGALI M, V0, P0
   Shen CL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3654
   Speriosu Michael, 2011, P 1 WORKSH UNS LEARN, V0, PP53, DOI 10.1017/CB09781107415324.004
   Stone Philip J, 1963, P MAY 21 23 1963 SPR, V0, PP241, DOI 10.1145/1461551.1461583
   Tang Duyu, 2014, P COLING 2014 25 INT, V0, P172
   Toprak C, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P575
   Tuhin RA, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), V0, PP360, DOI 10.1109/ccoms.2019.8821658
   Van de Kauter M, 2015, LANG RESOUR EVAL, V49, P685, DOI 10.1007/s10579-015-9297-4
   Vinodhini G, 2012, INT J-TORONTO, V2, P282
   Wilson TS, 2005, PHIL EDUC, V0, PP347, DOI 10.3115/1220575.1220619
   Xinyu Wang, 2013, TRENDS AND APPLICATIONS IN KNOWLEDGE DISCOVERY AND DATA MINING. PAKDD 2013 INTERNATIONAL WORKSHOPS: DMAPPS, V0, P0
   Zapf A, 2016, BMC MED RES METHODOL, V16, P0, DOI 10.1186/s12874-016-0200-9
NR 51
TC 2
Z9 2
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2022
VL 21
IS 2
BP 
EP 
DI 10.1145/3474363
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0C7CH
UT WOS:000775466500009
DA 2023-11-10
ER

PT J
AU Wang, H
   Lin, GS
   Hoi, SCH
   Miao, CY
AF Wang, Hao
   Lin, Guosheng
   Hoi, Steven C. H.
   Miao, Chunyan
TI Decomposing generation networks with structure prediction for recipe generation
SO PATTERN RECOGNITION
LA English
DT Article
DE Text generation; Vision-and-language
AB Recipe generation from food images and ingredients is a challenging task, which requires the interpretation of the information from another modality. Different from the image captioning task, where the captions usually have one sentence, cooking instructions contain multiple sentences and have obvious structures. To help the model capture the recipe structure and avoid missing some cooking details, we propose a novel framework: Decomposing Generation Networks (DGN) with structure prediction, to get more structured and complete recipe generation outputs. Specifically, we split each cooking instruction into several phases, and assign different sub-generators to each phase. Our approach includes two novel ideas: (i) learning the recipe structures with the global structure prediction component and (ii) producing recipe phases in the sub-generator output component based on the predicted structure. Extensive experiments on the challenging large-scale Recipe1M dataset validate the effectiveness of our proposed model, which improves the performance over the state-of-the-art results. (c) 2022 Elsevier Ltd. All rights reserved.
C1 [Wang, Hao; Lin, Guosheng; Miao, Chunyan] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Hoi, Steven C. H.] Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
   [Wang, Hao; Miao, Chunyan] Nanyang Technol Univ, Joint NTU UBC Res Ctr Excellence Act Living Elder, Singapore, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Singapore Management University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Miao, CY (通讯作者)，Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.; Miao, CY (通讯作者)，Nanyang Technol Univ, Joint NTU UBC Res Ctr Excellence Act Living Elder, Singapore, Singapore.
EM hao005@e.ntu.edu.sg; gslin@ntu.edu.sg; chhoi@smu.edu.sg; ascymiao@ntu.edu.sg
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Andreas J, 2016, PROC CVPR IEEE, V0, PP39, DOI 10.1109/CVPR.2016.12
   [Anonymous], 2006, 11 C EUROPEAN CHAPTE, V0, P0, DOI DOI 10.1145/1083784.1083789
   Bai ZW, 2021, PATTERN RECOGN, V110, P0, DOI 10.1016/j.patcog.2020.107538
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Bosselut A, 2018, INT C LEARN REPR, V0, P0
   Chandu KR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6040
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2018, ARXIV, V1, P4171
   Hao Wang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12372), V0, PP359, DOI 10.1007/978-3-030-58583-9_22
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Honnibal M, 2017, SPACY 2 NATURAL LANG, V0, P0
   Hudson Drew Arad, 2018, ICLR, V0, P0
   Krause J, 2017, PROC CVPR IEEE, V0, PP3337, DOI 10.1109/CVPR.2017.356
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Matsuda Y, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), V0, PP25, DOI 10.1109/ICME.2012.157
   Min WQ, 2019, ACM COMPUT SURV, V52, P0, DOI 10.1145/3329168
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paszke Adam, 2017, NEURIPS, V0, P0
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Salvador A, 2019, PROC CVPR IEEE, V0, PP10445, DOI 10.1109/CVPR.2019.01070
   Salvador A, 2017, PROC CVPR IEEE, V0, PP3068, DOI 10.1109/CVPR.2017.327
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang H, 2019, PROC CVPR IEEE, V0, PP11564, DOI 10.1109/CVPR.2019.01184
   Wang JB, 2020, PATTERN RECOGN, V98, P0, DOI 10.1016/j.patcog.2019.107075
   Wolf T, 1900, P38, V0, P0
   Xiao XY, 2019, PATTERN RECOGN, V90, P285, DOI 10.1016/j.patcog.2019.01.028
   Xiujun I, 2020, ECCV, V0, P0
   Yang X, 2019, IEEE I CONF COMP VIS, V0, PP4249, DOI 10.1109/ICCV.2019.00435
   Yu J, 2020, PATTERN RECOGN, V108, P0, DOI 10.1016/j.patcog.2020.107563
   Zhang PC, 2021, PROC CVPR IEEE, V0, PP5575, DOI 10.1109/CVPR46437.2021.00553
   Zhou LW, 2018, AAAI CONF ARTIF INTE, V0, P7590
NR 34
TC 0
Z9 0
U1 1
U2 7
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD JUN 15
PY 2022
VL 126
IS 
BP 
EP 
DI 10.1016/j.patcog.2022.108578
EA FEB 2022
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA ZH7AD
UT WOS:000761086100002
DA 2023-11-10
ER

PT J
AU Maisonnave, M
   Delbianco, F
   Tohme, F
   Milios, E
   Maguitman, AG
AF Maisonnave, Mariano
   Delbianco, Fernando
   Tohme, Fernando
   Milios, Evangelos
   Maguitman, Ana G.
TI Causal graph extraction from news: a comparative study of time-series causality learning techniques
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Digital text media; Causal graph extraction; Variable extraction; Time-series causality learning; Information extraction from news
ID model
AB Causal graph extraction from news has the potential to aid in the understanding of complex scenarios. In particular, it can help explain and predict events, as well as conjecture about possible cause-effect connections. However, limited work has addressed the problem of large-scale extraction of causal graphs from news articles. This article presents a novel framework for extracting causal graphs from digital text media. The framework relies on topic-relevant variables representing terms and ongoing events that are selected from a domain under analysis by applying specially developed information retrieval and natural language processing methods. Events are represented as event-phrase embeddings, which make it possible to group similar events into semantically cohesive clusters. A time series of the selected variables is given as input to a causal structure learning techniques to learn a causal graph associated with the topic that is being examined. The complete framework is applied to the New York Times dataset, which covers news for a period of 246 months (roughly 20 years), and is illustrated through a case study. An initial evaluation based on synthetic data is carried out to gain insight into the most effective time-series causality learning techniques. This evaluation comprises a systematic analysis of nine state-of-the-art causal structure learning techniques and two novel ensemble methods derived from the most effective techniques. Subsequently, the complete framework based on the most promising causal structure learning technique is evaluated with domain experts in a real-world scenario through the use of the presented case study. The proposed analysis offers valuable insights into the problems of identifying topic-relevant variables from large volumes of news and learning causal graphs from time series.
C1 [Maisonnave, Mariano; Maguitman, Ana G.] Univ Nacl Sur, Dept Ciencias Ingn Comp, Bahia Blanca, Buenos Aires, Argentina.
   [Maisonnave, Mariano; Milios, Evangelos] Dalhousie Univ, Fac Comp Sci, Halifax, NS, Canada.
   [Delbianco, Fernando; Tohme, Fernando] Inst Matemat Bahia Blanca, Bahia Blanca, Buenos Aires, Argentina.
   [Delbianco, Fernando; Tohme, Fernando] Univ Nacl Sur, Dept Econ, Bahia Blanca, Buenos Aires, Argentina.
   [Maguitman, Ana G.] UNS CONICET, Inst Ciencias Ingn Comp, Bahia Blanca, Buenos Aires, Argentina.
C3 National University of the South; Dalhousie University; National University of the South; Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET)
RP Maisonnave, M; Maguitman, AG (通讯作者)，Univ Nacl Sur, Dept Ciencias Ingn Comp, Bahia Blanca, Buenos Aires, Argentina.; Maisonnave, M (通讯作者)，Dalhousie Univ, Fac Comp Sci, Halifax, NS, Canada.; Maguitman, AG (通讯作者)，UNS CONICET, Inst Ciencias Ingn Comp, Bahia Blanca, Buenos Aires, Argentina.
EM mariano.maisonnave@cs.uns.edu.ar; agm@cs.uns.edu.ar
FU CONICET, Universidad Nacional del Sur [PGI-UNS 24/N051, PGI-UNS 24/E145]; ANPCyT [PICT 2019-01640, PICT 2019-02302, PICT 2019-03944]; LARA project; New Frontiers in Research Fund Exploration Grant; Department of Foreign Affairs, Trade and Development Canada; Compute Canada; ACENET
CR Balashankar A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2338
   Bareinboim E, 2015, CAUSAL INFERENCE BIG, V0, P0
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Chiquet J, 2009, BIOINFORMATICS, V25, P417, DOI 10.1093/bioinformatics/btn637
   Dehkharghani R, 2014, EXPERT SYST APPL, V41, P4950, DOI 10.1016/j.eswa.2014.02.024
   Devlin J, 2019, ARXIV, V0, P0
   Girju R, 2002, P 15 INT FLOR ART IN, V0, P360
   Glymour Madelyn, 2016, CAUSAL INFERENCE STA, V2, P4
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Heckman JJ, 2007, HBK ECON, V2, P4779, DOI 10.1016/S1573-4412(07)06070-9
   Heindorf S, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP3023, DOI 10.1145/3340531.3412763
   Heinze-Deml C, 2018, ANNU REV STAT APPL, V5, P371, DOI 10.1146/annurev-statistics-031017-100630
   Joshi S, 2010, P 14 WSEAS INT C COM, VII, P446
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Khetan Vivek, 2022, INTELLIGENT COMPUTING: PROCEEDINGS OF THE 2021 COMPUTING CONFERENCE. LECTURE NOTES IN NETWORKS AND SYSTEMS, V0, PP965, DOI 10.1007/978-3-030-80119-9_64
   Koller Daphne, 2009, PROBABILISTIC GRAPHI, V0, P0
   Li JY, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3359995
   Lu Cheng, 2022, IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, V3, P924, DOI 10.1109/TAI.2022.3150264
   Maisonnave M, 2020, MENDELEY DATA V1, V0, P0
   Maisonnave M, 2021, ARXIV, V0, P0
   Maisonnave M, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102483
   Maisonnave M, 2019, INTELIGENCIA ARTIFIC, V22, P61, DOI 10.4114/intartif.vol22iss63pp61-80
   Meinshausen N, 2020, OBERWOLFACH REP, V16, P1499
   Moreo A, 2020, IEEE T KNOWL DATA EN, V32, P302, DOI 10.1109/TKDE.2018.2883446
   Nicholson W, 2017, ARXIV, V0, P0
   Pearl J, 2009, CAUSALITY MODELS REA, V0, P0, DOI DOI 10.1017/CBO9780511803161
   Peters J, 2017, ADAPT COMPUT MACH LE, V0, P0
   Radinsky Kira, 2012, P 21 INT C WORLD WID, V0, PP909, DOI 10.1145/2187836.2187958
   Rudin C, 2019, WHY ARE WE USING BLA, V1, P10, DOI 10.1162/99608f92.5a8a3a3d
   Runge J, 2019, SCI ADV, V5, P0, DOI 10.1126/sciadv.aau4996
   Runge J, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-10105-3
   Sanchez-Graillet O, 2004, P 4 INT C LANG RES E, V0, P0
   Sandhaus Evan, 2008, NEW YORK TIMES ANNOT, V0, P0
   Scheines R, 1998, MULTIVAR BEHAV RES, V33, P65, DOI 10.1207/s15327906mbr3301_3
   Schreiber T, 2000, PHYS REV LETT, V85, P461, DOI 10.1103/PhysRevLett.85.461
   Sculley D, 2010, P 19 INT C WORLD WID, V0, PP1177, DOI 10.1145/1772690.1772862
   Shimizu S, 2006, J MACH LEARN RES, V7, P2003
   Shimizu S, 2011, J MACH LEARN RES, V12, P1225
   Silverstein C, 2000, DATA MIN KNOWL DISC, V4, P163, DOI 10.1023/A:1009891813863
   SIMS CA, 1980, ECONOMETRICA, V48, P1, DOI 10.2307/1912017
   Spirtes P, 1991, SOCIAL SCIENCE COMPUTER REVIEW, V9, P62, DOI 10.1177/089443939100900106
   Nguyen TH, 2018, AAAI CONF ARTIF INTE, V0, P5900
   Thorndike RL, 1953, PSYCHOMETRIKA, V18, P267, DOI 10.1007/BF02289263
   Varian HR, 2014, J ECON PERSPECT, V28, P3, DOI 10.1257/jep.28.2.3
   Walker C, 2006, LINGUIST DATA CONSOR, V0, P57
   Yang J, 2021, ARXIV, V0, P0
   Zhang TT, 2019, DATA INTELLIGENCE, V1, P99, DOI 10.1162/dint_a_00014
NR 47
TC 1
Z9 1
U1 2
U2 8
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD AUG 3
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1066
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 3Q3UV
UT WOS:000838160900002
PM 35967930
DA 2023-11-10
ER

PT J
AU Fedus, W
   Zoph, B
   Shazeer, N
AF Fedus, William
   Zoph, Barret
   Shazeer, Noam
TI Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE mixture-of-experts; natural language processing; sparsity; large-scale machine learning; distributed computing
ID mixtures
AB In deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) models defy this and instead select different parameters for each in-coming example. The result is a sparsely-activated model-with an outrageous number of parameters-but a constant computational cost. However, despite several notable suc-cesses of MoE, widespread adoption has been hindered by complexity, communication costs, and training instability. We address these with the introduction of the Switch Transformer. We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs. Our proposed training techniques mitigate the instabilities, and we show large sparse models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off T5-Base and T5-Large (Raffel et al., 2019) to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the "Colossal Clean Crawled Corpus", and achieve a 4x speedup over the T5-XXL model.1
C1 [Fedus, William; Zoph, Barret; Shazeer, Noam] Google, Mountain View, CA 94043 USA.
C3 Google Incorporated
RP Fedus, W (通讯作者)，Google, Mountain View, CA 94043 USA.
EM LIAMFEDUS@GooGLE.CoM; BARRETZoPH@GooGLE.CoM; NoAM@GooGLE.CoM
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Beltagy I, 2020, ARXIV PREPRINT ARXIV, V2004, P05150
   Berant J, 2013, P 2013 C EMPIRICAL M, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Child Rewon, 2019, ARXIV190410509, V0, P0, DOI DOI 10.48550/ARXIV.1904.10509
   Cho Kyunghyun, 2014, ARXIV14067362, V0, P0
   Clark P, 2018, CORR, V0, P0
   Correia GM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2174
   Devlin J, 2018, ARXIV, V1, P4171
   Eigen David, 2013, ARXIV13124314, V0, P0
   Fan A, 2021, J MACH LEARN RES, V22, P0
   Fedus W, 2018, ICLR, V0, P1
   Gale Trevor, 2020, ARXIV200610901, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gray Scott, 2017, GPU KERNELS BLOCK SP, V0, P0
   Guu K, 2020, PR MACH LEARN RES, V119, P0
   Harlap A, 2018, ARXIV180603377, V0, P0
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Hinton Geoffrey, 2015, ARXIV150302531, V0, P0
   Hooker S, 2020, ARXIV200906489, Vabs, P0
   Huang YP, 2019, ADV NEUR IN, V32, P0
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Kaplan Jared, 2020, ARXIV200108361, V0, P0
   Kitaev Nikita, 2020, ARXIV200104451, V0, P0
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lample Guillaume, 2019, ADV NEURAL INFORM PR, V32, P0
   Lee K, 2021, ARXIV210706499, V0, P0
   Lepikhin Dmitry, 2020, GSHARD SCALING GIANT, V0, P0
   Micikevicius P, 2017, ARXIV171003740, V0, P0
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Nie Yixin, 2019, ARXIV191014599, V0, P0
   Puigcerver Joan, 2020, ARXIV200913239, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel Colin, 2019, ARXIV191010683, V0, P0
   Rajbhandari S, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Ramachandran Prajit, 2018, INT C LEARN REPR, V0, P0
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P5418
   Rosenbaum Clemens, 2017, ARXIV171101239, V0, P0
   Sakaguchi K, 2020, AAAI CONF ARTIF INTE, V34, P8732
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Shazeer Noam, 2020, GLU VARIANTS IMPROVE, V0, P0
   Shazeer Noam, 2017, ARXIV170106538, V0, P0
   Shazeer Noam, 2018, P ADV NEUR INF PROC, V0, P10414
   Shoeybi M, 2019, ARXIV, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3645
   Sukhbaatar Sainbayar, 2019, ARXIV190507799, V0, P0
   Sutton R, 2019, BITTER LESSON, V0, P0
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Taylor Wilson L, 1953, JOURNALISM QUART, V30, P415
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang Shibo, 2019, GOOGLE CLOUD BLOG, V0, P0
   Xue L, 2020, ARXIV201011934, V0, P0
   Yang Zhilin, 2020, XLNET GEN AUTOGRESSI, V0, P0
   Zaheer M, 2020, ADV NEUR IN, V33, P0
NR 61
TC 19
Z9 19
U1 1
U2 1
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
EI 
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD JUN 15
PY 2022
VL 23
IS 
BP 
EP 
DI 
PG 39
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA I5RV3
UT WOS:001003360300001
DA 2023-11-10
ER

PT J
AU Soldevila, M
   Ziliani, B
   Silvestre, B
AF Soldevila, Mallku
   Ziliani, Beta
   Silvestre, Bruno
TI From Specification to Testing: Semantics Engineering for Lua 5.2
SO JOURNAL OF AUTOMATED REASONING
LA English
DT Article
DE Semantics; Operational semantics; Imperative languages; Domain specific languages; Lua; Reduction semantics; Randomized testing
ID formal semantics
AB We provide a formal semantics for a large subset of the Lua programming language, in its version 5.2. The semantics is a major part of an ongoing effort to construct reliable tools to analyze Lua code. In this work, we present the details of several key aspects of the language, like the semantics of its only structured data-type (tables), its meta-programming mechanism (metatables), error handling, and how these mechanisms are used to define a complex dynamic semantics that must deal with several possible erroneous situations during run time, given the nature of the language. The semantics is mechanized in Redex, a DSL specially designed to specify and debug operational semantics. We validated the mechanization in two ways: first, by executing within Redex the test suite of the reference interpreter of Lua, and second, by specifying and performing random testing of its fundamental properties using the redex-check tool. Together, they evidence that our model soundly captures the semantics of the selected fragment of the language. Additionally, we address some of the performance problems that typically arise when testing a mechanization in Redex, by using a simple implementation of a reachability-based garbage collector that captures key aspects of Lua's. By collecting syntactic garbage, we reduce the size of configurations during run time. Finally, we briefly discuss this avenue of development of our semantics, together with the implementation of a prototype tool to perform static analysis of Lua programs.
C1 [Soldevila, Mallku; Ziliani, Beta] UNC, FAMAF, Cordoba, Argentina.
   [Soldevila, Mallku] Consejo Nacl Invest Cient & Tecn, Cordoba, Argentina.
   [Ziliani, Beta] Manas Tech, Cordoba, Argentina.
   [Silvestre, Bruno] Univ Fed Goias, INF, Goiania, Go, Brazil.
C3 National University of Cordoba; Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET); Universidade Federal de Goias
RP Soldevila, M (通讯作者)，UNC, FAMAF, Cordoba, Argentina.; Soldevila, M (通讯作者)，Consejo Nacl Invest Cient & Tecn, Cordoba, Argentina.
EM mes0107@famaf.unc.edu.ar; beta@mpi-sws.org; brunoos@inf.ufg.br
FU UNC SECyT (Argentina) [Consolidar II 33620180101063CB]; ANPCyT (Argentina) [PICT D 2017-3315]; CONICET, Argentina
CR Adobe, 2019, AD LIGHTR, V0, P0
   [Anonymous], 2018, LUA DEV LUA IMPLEMEN, V0, P0
   [Anonymous], 2017, LUA DEV US, V0, P0
   [Anonymous], 2013, LUA DEVTEAM LUA 5 2, V0, P0
   [Anonymous], 2018, LUAT, V0, P0
   Bodin M, 2014, ACM SIGPLAN NOTICES, V49, P87, DOI 10.1145/2535838.2535876
   de Moura AL, 2004, J UNIVERS COMPUT SCI, V10, P910
   Donnelly K, 2006, ISMM 06 P 5 INT S ME, V0, PP126, DOI 10.1145/1133956.1133974
   Felleisen M, 2009, SEMANTICS ENG PLT RE, V0, P0
   Felleisen M, 1987, THESIS INDIANA U, V0, P0
   Gabay Y, 2007, ACM SIGPLAN NOTICES, V42, P9, DOI 10.1145/1294297.1294299
   Graham-Cumming J, 2013, CLOUDFLARES NEW WAF, V0, P0
   Guha A, 2010, LECT NOTES COMPUT SC, V6183, P126, DOI 10.1007/978-3-642-14107-2_7
   Haas A, 2017, ACM SIGPLAN NOTICES, V52, P185, DOI 10.1145/3140587.3062363
   Ierusalimschy R, 1996, SOFTWARE PRACT EXPER, V26, P635, DOI 10.1002/(SICI)1097-024X(199606)26:6<635::AID-SPE26>3.0.CO;2-P
   Ierusalimschy R, 2001, BRAZ S PROGR LANG, V0, P0
   Ierusalimschy R, 2013, LUA 5 2 REFERENCE MA, V0, P0
   Ierusalimschy R, 2003, PROGRAMMING LUA, V0, P0
   Igarashi A, 2001, ACM T PROGR LANG SYS, V23, P396, DOI 10.1145/503502.503505
   Klein C, 1900, P285, V0, P0
   Klein C, 2009, P SCHEM FUNCT PROGR, V0, P26
   Klein C, 2011, APLAS 11, V0, P0
   Krebbers R, 2013, LECT NOTES COMPUT SC, V7794, P257, DOI 10.1007/978-3-642-37075-5_17
   Leal MA, 2005, J UNIVERS COMPUT SCI, V11, P1198
   Lin H, 2015, THESIS SAN JOSE STAT, V0, P0
   Lua Developers, 2014, LUA AN, V0, P0
   Lua Developers, 2009, EXPR STAT, V0, P0
   Lua Developers, 2020, LUA DIR, V0, P0
   Maffeis S, 2008, LECT NOTES COMPUT SC, V5356, P307
   Manura D, 2007, VARARG 2 CLASS CITIZ, V0, P0
   Mascarenhasde Queiroz F, 2009, THESIS PONTIFICIA U, V0, P0
   Pierce Benjamin C, 2002, TYPES PROGRAMMING LA, V0, P0
   Politz JG, 2013, OOPSLA 13, V0, P0
   Politz JG, 2013, ACM SIGPLAN NOTICES, V48, P1, DOI 10.1145/2480360.2384579
   Soldevila M, 2020, P 22 INT S PRINCIPLE, V0, P0
   Soldevila M, 2017, ACM SIGPLAN NOTICES, V52, P75, DOI 10.1145/3170472.3133848
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0168-7433
EI 1573-0670
J9 J AUTOM REASONING
JI J. Autom. Reasoning
PD NOV 15
PY 2022
VL 66
IS 4
BP 905
EP 952
DI 10.1007/s10817-022-09638-y
EA AUG 2022
PG 48
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5Z0WK
UT WOS:000839372300001
DA 2023-11-10
ER

PT J
AU Smetanin, S
   Komarov, M
AF Smetanin, Sergey
   Komarov, Mikhail
TI The voice of Twitter: observable subjective well-being inferred from tweets in Russian
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Computing; Analysis Subjective well-being; Observable subjective well-being; Happiness index; social networks; User-generated content; Sentiment analysis; Computational social science; Machine learning; Language models
ID sentiment analysis; reliability; validity
AB As one of the major platforms of communication, social networks have become a valuable source of opinions and emotions. Considering that sharing of emotions offline and online is quite similar, historical posts from social networks seem to be a valuable source of data for measuring observable subjective well-being (OSWB). In this study, we calculated OSWB indices for the Russian-speaking segment of Twitter using the Affective Social Data Model for Socio-Technical Interactions. This model utilises demographic information and post-stratification techniques to make the data sample representative, by selected characteristics, of the general population of a country. For sentiment analysis, we fine-tuned RuRoBERTa-Large on RuSentiTweet and achieved new state-of-the-art results of F1 = 0.7229. Several calculated OSWB indicators demonstrated moderate Spearman's correlation with the traditional survey-based net affect (rs = 0.469 and rs = 0.5332, p < 0.05) and positive affect (rs = 0.5177 and rs = 0.548, p < 0.05) indices in Russia.
C1 [Smetanin, Sergey; Komarov, Mikhail] HSE Univ, Moscow, Russia.
C3 HSE University (National Research University Higher School of Economics)
RP Smetanin, S (通讯作者)，HSE Univ, Moscow, Russia.
EM sismetanin@gmail.com
FU HPC facilities at HSE University
CR [Алмакаева АМALMAKAEVA AM], 2020, МОНИТОРИНГ ОБЩЕСТВЕННОГО МНЕНИЯ: ЭКОНОМИЧЕСКИЕ И СОЦИАЛЬНЫЕ ПЕРЕМЕНЫ THE MONITORING OF PUBLIC OPINION: ECONOMIC & SOCIAL CHANGES MONITORING OBSHCHESTVENNOGO MNENIYA: EKONOMICHESKIE I SOTSIALNYE PEREMENY, V0, P4
   [Anonymous], 2016, PROC COMPUT LINGUIST, V0, P0
   [Anonymous], 2016, INT J SOCIAL SCI HUM, V0, P0, DOI DOI 10.7763/IJSSH.2016.V6.640
   Arefyev A, 2013, DEMOSCOPE WEEKLY, V0, P571
   Averchenkov V, 2015, COMM COM INF SC, V535, P583, DOI 10.1007/978-3-319-23766-4_46
   Bogachev DS, 2020, P 6 INT C LASER PLAS, V0, P101
   [Богданов МБBOGDANOV Mikhail B], 2021, МОНИТОРИНГ ОБЩЕСТВЕННОГО МНЕНИЯ: ЭКОНОМИЧЕСКИЕ И СОЦИАЛЬНЫЕ ПЕРЕМЕНЫ MONITORING OF PUBLIC OPINION: ECONOMIC AND SOCIAL CHANGES MONITORING OBSHCHESTVENNOGO MNENIYA: EKONOMICHESKIE I SOTSIALNYE PEREMENY, V0, PP304, DOI 10.14515/monitoring.2021.1.1760
   Borodkina O, 2019, LECT NOTES COMPUT SC, V11938, P32, DOI 10.1007/978-3-030-34770-3_3
   Brand Analytics, 2021, SOC NETW RUSS NUMB T, V0, P0
   [Бродовская ЕВBrodovskaya EV], 2016, МОНИТОРИНГ ОБЩЕСТВЕННОГО МНЕНИЯ: ЭКОНОМИЧЕСКИЕ И СОЦИАЛЬНЫЕ ПЕРЕМЕНЫ THE MONITORING OF PUBLIC OPINION: ECONOMIC & SOCIAL CHANGES MONITORING OBSHCHESTVENNOGO MNENIYA: EKONOMICHESKIE I SOTSIALNYE PEREMENY, V0, PP283, DOI 10.14515/monitoring.2016.1.13
   BusinesStat, 2021, GEOGRAPHICAL DISTRIB, V0, P0
   Chizhic A, 2016, P 19 SCI PRACTICAL S, V19, P61
   Derks D, 2008, COMPUT HUM BEHAV, V24, P766, DOI 10.1016/j.chb.2007.04.004
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dzogang Fabon, 2017, BRAIN NEUROSCI ADV, V1, P2398212817744501, DOI 10.1177/2398212817744501
   Dzogang F, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0197002
   Federal State Statistics Service (Russia), 2021, POP RUSS FED GEND AG, V0, P0
   FOM, 2022, DOM FIELD OP, V0, P0
   Gao Y, 2022, IEEE ACCESS, V10, P4374, DOI 10.1109/ACCESS.2020.3036101
   GESIS, 2020, POP COUNTR REG, V0, P0
   Golubev A, 2021, P COMP LING INT TECH, V0, PP268, DOI 10.28995/2075-7182-2021-20-268-277
   Höchtl J, 2016, J ORG COMP ELECT COM, V26, P147, DOI 10.1080/10919392.2015.1125187
   Hox JJ, 2017, METHODOLOGY-EUR, V13, P3, DOI 10.1027/1614-2241/a000127
   Iacus SM, 2017, STAT DATA SCI NEW CH, V0, P537
   Jakobi A, 2017, LECT NOTES GEOINF CA, V0, PP197, DOI 10.1007/978-3-319-45123-7_15
   Kaganov V, 2021, LANGUAGE POLICY RUSS, V0, P0
   Kalabikhina IE, 2021, MATHEMATICS-BASEL, V9, P0, DOI 10.3390/math9090987
   Kapteyn A, 2015, SOC INDIC RES, V123, P625, DOI 10.1007/s11205-014-0753-0
   Kofanova E, 2010, MONITORING PUBLIC OP, V96, P208
   Koltsova O, 2019, MEDIA COMMUN-LISBON, V7, P145, DOI 10.17645/mac.v7i3.1894
   Kostenetskiy PS, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1740, P0, DOI 10.1088/1742-6596/1740/1/012050
   Kotelnikov E, 2021, COMPUT LINGUIST, V0, P433
   Kotelnikova A, 2021, CEUR WORKSHOP PROC, V0, P73
   Krueger AB, 2008, J PUBLIC ECON, V92, P1833, DOI 10.1016/j.jpubeco.2007.12.015
   Kuratov Y, 2019, ABS190507213 CORR, V0, P0
   Leetaru K, 2019, IS TWITTERS SPRITZER, V0, P0
   Levin KA, 2014, SOC INDIC RES, V119, P1047, DOI 10.1007/s11205-013-0507-4
   Litvinova T, 2017, CEUR WORKSHOP PROC, V0, P105
   Litvinova T, 2017, WORKING NOTES FIRE 2, V0, P1
   Litvinova T, 2016, PROCEEDINGS OF THE INTERNATIONAL FRUCT CONFERENCE ON INTELLIGENCE, V0, P29
   Loukachevitch NV, 2015, COMPUT LINGUIST, V2, P3
   Lucas RE, 2018, HDB WELL BEING, V0, P0
   Lukashevich N, 2016, PROC INT C DIALOGUE, V0, P416
   Markov I, 2017, CEUR WORKSHOP PROC, V0, P0
   Medialogia, 2021, PUBL SOC NETW VKONT, V0, P0
   Mozetic I, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0155036
   Nemeth R, 2021, PATHWAYS SOCIAL SCI, V0, PP49, DOI 10.1007/978-3-030-54936-73
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Odnoklassniki, 2021, OK MED 2022, V0, P0
   Panchenko A, 2014, COMPUT LINGUIST, V2, P506
   Panchenko A, 2014, COMM COM INF SC, V436, P169, DOI 10.1007/978-3-319-12580-0_17
   Pavliy B, 2016, B TOYAMA U INT STUDI, V8, P99
   Pontiki M, 2016, P 10 INT WORKSH SEM, V0, PP19, DOI 10.18653/V1/S16-1002
   [Посевкин РВPosevkin RV], 2015, НАУЧНО-ТЕХНИЧЕСКИЙ ВЕСТНИК ИНФОРМАЦИОННЫХ ТЕХНОЛОГИЙ МЕХАНИКИ И ОПТИКИ SCIENTIFIC AND TECHNICAL JOURNAL OF INFORMATION TECHNOLOGIES MECHANICS AND OPTICS NAUCHNO-TEKHNICHESKII VESTNIK INFORMATSIONNYKH TEKHNOLOGII MEKHANIKI I OPTIKI, V15, P169, DOI 10.17586/2226-1494-2015-15-1-169-171
   Qi JY, 2015, INFORM MANAGE-AMSTER, V52, P859, DOI 10.1016/j.im.2015.06.002
   Ridhwan KM, 2021, INT J INFORM MANAGEM, V0, PP100021, DOI 10.1016/J.JJIMEI.2021.100021
   RIME B, 1991, COGNITION EMOTION, V5, P435, DOI 10.1080/02699939108411052
   Rimé B, 2020, CURR OPIN PSYCHOL, V31, P127, DOI 10.1016/j.copsyc.2019.08.024
   [Родионова ЛАRodionova L], 2015, ПРИКЛАДНАЯ ЭКОНОМЕТРИКА APPLIED ECONOMETRICS PRIKLADNAYA EKONOMETRIKA, V0, P64
   Rogers Anna, 2018, P 27 INT C COMP LING, V0, P755
   Rubtsova Y, 2013, T 15 VSEROSSIISKOY N, V0, P269
   Sberbank, 2021, 2 ONL HUM SBERDEVICE, V0, P0
   Sboev A, 2019, INT C DYNAMICS, V0, P91
   Shavrina T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4717
   [Щекотин ЕВSHCHEKOTIN EV], 2020, МОНИТОРИНГ ОБЩЕСТВЕННОГО МНЕНИЯ: ЭКОНОМИЧЕСКИЕ И СОЦИАЛЬНЫЕ ПЕРЕМЕНЫ THE MONITORING OF PUBLIC OPINION: ECONOMIC & SOCIAL CHANGES MONITORING OBSHCHESTVENNOGO MNENIYA: EKONOMICHESKIE I SOTSIALNYE PEREMENY, V0, P78
   Sloan L, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0142209
   Sloan L, 2013, SOCIOL RES ONLINE, V18, P0, DOI 10.5153/sro.3001
   [Сметанин СИSmetanin SI], 2017, ТРУДЫ ИНСТИТУТА СИСТЕМНОГО ПРОГРАММИРОВАНИЯ РАН TRUDY INSTITUTA SISTEMNOGO PROGRAMMIROVANIYA RAN, V29, P315, DOI 10.15514/ISPRAS-2017-29(4)-22
   Smetanin S, 2022, PEERJ COMPUT SCI, V8, P0, DOI 10.7717/peerj-cs.1039
   Smetanin S, 2022, MATHEMATICS-BASEL, V10, P0, DOI 10.3390/math10162947
   Smetanin S, 2022, IEEE ACCESS, V10, P18886, DOI 10.1109/ACCESS.2022.3149897
   Smetanin S, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102484
   Smetanin S, 2020, IEEE ACCESS, V8, P110693, DOI 10.1109/ACCESS.2020.3002215
   STOCK WA, 1994, INT J AGING HUM DEV, V38, P221, DOI 10.2190/MGGY-KFN3-M4YR-DFN4
   Svetlov K, 2019, PROC CONF OPEN INNOV, V0, PP299, DOI 10.23919/fruct48121.2019.8981501
   Sydorenko V, 2020, TRANSP RES PROC, V44, P102, DOI 10.1016/j.trpro.2020.02.015
   Tolmachev V, 2019, COLLOQ-J, V13, P320
   Trotsuk I, 2019, MOSCOW STATE U B SER, V18, P7, DOI 10.24290/1029-3736-2019-25-3-7-35
   VCIOM, 2019, HALL AL HOL, V0, P0
   VCIOM, 2022, HAPP IND, V0, P0
   VCIOM, 2019, LAB DAT EXTR DAY, V0, P0
   VCIOM, 2004, MAY 1 LAB DAY JUST D, V0, P0
   VCIOM, 2018, HOL CALEND WHAT RUSS, V0, P0
   Vermeulen A, 2018, COMPUT HUM BEHAV, V84, P211, DOI 10.1016/j.chb.2018.02.022
   Volovikova M, 2018, SOCIAL EC PSYCHOL, V3, P31
   Wang D, 2021, SOC NETW ANAL MIN, V11, P0, DOI 10.1007/s13278-021-00728-0
   Wang YZ, 2015, ACM T WEB, V9, P0, DOI 10.1145/2746366
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   World Food Programme, 2017, INTR POSTSTR, V0, P0
   WWS, 2020, FIELDW SAMPL, V0, P0
   Zhuang L, 2021, P 20 CHINESE NATL C, V0, P1218
NR 91
TC 0
Z9 0
U1 1
U2 2
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD DEC 20
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1181
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 7M2WY
UT WOS:000906517000002
PM 37346309
DA 2023-11-10
ER

PT J
AU Ross, J
   Belgodere, B
   Chenthamarakshan, V
   Padhi, I
   Mroueh, Y
   Das, P
AF Ross, Jerret
   Belgodere, Brian
   Chenthamarakshan, Vijil
   Padhi, Inkit
   Mroueh, Youssef
   Das, Payel
TI Large-scale chemical language representations capture molecular structure and properties
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
AB Large language models have recently emerged with extraordinary capabilities, and these methods can be applied to model other kinds of sequence, such as string representations of molecules. Ross and colleagues have created a transformer-based model, trained on a large dataset of molecules, which provides good results on property prediction tasks. Models based on machine learning can enable accurate and fast molecular property predictions, which is of interest in drug discovery and material design. Various supervised machine learning models have demonstrated promising performance, but the vast chemical space and the limited availability of property labels make supervised learning challenging. Recently, unsupervised transformer-based language models pretrained on a large unlabelled corpus have produced state-of-the-art results in many downstream natural language processing tasks. Inspired by this development, we present molecular embeddings obtained by training an efficient transformer encoder model, MoLFormer, which uses rotary positional embeddings. This model employs a linear attention mechanism, coupled with highly distributed training, on SMILES sequences of 1.1 billion unlabelled molecules from the PubChem and ZINC datasets. We show that the learned molecular representation outperforms existing baselines, including supervised and self-supervised graph neural networks and language models, on several downstream tasks from ten benchmark datasets. They perform competitively on two others. Further analyses, specifically through the lens of attention, demonstrate that MoLFormer trained on chemical SMILES indeed learns the spatial relationships between atoms within a molecule. These results provide encouraging evidence that large-scale molecular language models can capture sufficient chemical and structural information to predict various distinct molecular properties, including quantum-chemical properties.
C1 [Ross, Jerret; Belgodere, Brian; Chenthamarakshan, Vijil; Padhi, Inkit; Mroueh, Youssef; Das, Payel] IBM Res, Yorktown Hts, NY 10598 USA.
C3 International Business Machines (IBM)
RP Ross, J; Das, P (通讯作者)，IBM Res, Yorktown Hts, NY 10598 USA.
EM rossja@us.ibm.com; daspa@us.ibm.com
CR Altae-Tran H, 2017, ACS CENTRAL SCI, V3, P283, DOI 10.1021/acscentsci.6b00367
   [Anonymous], 2007, DAYLIGHT CHEM INFORM, V0, P0
   Beltagy I, 2020, ARXIV, V0, P0
   Bommasani Rishi, 2021, ARXIV, V0, P0
   Chen PF, 2019, ARXIV, V0, P0
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chithrananda S, 2020, ARXIV, V0, P0
   Choromanski K, 2021, PROC 9 INT C LEARNIN, V0, P0
   Defferrard M, 2016, ADV NEUR IN, V29, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duvenaudt D, 2015, ADV NEUR IN, V28, P0
   Fang XM, 2022, NAT MACH INTELL, V4, P127, DOI 10.1038/s42256-021-00438-4
   Gao W, 2022, 36 C NEURAL INFORM P, V0, P0
   Gasteiger Johannes, 2020, INT C LEARN REPR, V0, P0
   Gilmer J, 2017, PR MACH LEARN RES, V70, P0
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Hu W, 2020, 8 INT C LEARNING REP, V0, P0
   ipf TN, 2017, 5 INT C LEARN REPR I, V0, P0
   Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+
   Jo J, 2020, METHODS, V179, P65, DOI 10.1016/j.ymeth.2020.05.009
   Katharopoulos A, 2020, PR MACH LEARN RES, V119, P0
   Ke G, 2021, 9 INT C LEARNING REP, V0, P0
   Kim Sunghwan, 2019, NUCLEIC ACIDS RES, V47, PD1102, DOI 10.1093/nar/gky1033
   Kirkpatrick P, 2004, NATURE, V432, P823, DOI 10.1038/432823a
   Kitaev Nikita, 2020, ARXIV200104451, V0, P0
   Krenn M, 2020, MACH LEARN-SCI TECHN, V1, P0, DOI 10.1088/2632-2153/aba947
   Li Y, 2016, 4 INT C LEARNING REP, V0, P0
   Liao R, 2019, 7 INT C LEARNING REP, V0, P0
   Liu S, 2022, INT C LEARNING REPRE, V0, P0
   Liu Shichen, 2019, ADV NEURAL INFORM PR, V32, P0
   Liu YH, 2019, ARXIV, V0, P0
   Lu CQ, 2019, AAAI CONF ARTIF INTE, V0, P1052
   Öztürk H, 2018, BIOINFORMATICS, V34, P821, DOI 10.1093/bioinformatics/bty593
   Park S, 2019, PMLR, V0, PP230, DOI 10.48550/ARXIV.1908.06760
   Paul A, 2018, ARXIV, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rives A, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2016239118
   Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t
   Rupp M, 2012, PHYS REV LETT, V108, P0, DOI 10.1103/PhysRevLett.108.058301
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Schutt Kristof T, 2017, ADV NEURAL INFORM PR, V0, P1
   Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576
   Shaw Peter, 2018, NAACL, V0, PP5, DOI 10.18653/V1/N18-2074
   Shiwei Wang, 2020, 2020 IEEE 5TH INTERNATIONAL CONFERENCE ON IMAGE, Vision and Computing (ICIVC), P29, DOI 10.1109/ICIVC50857.2020.9177456
   Su JL, 2022, ARXIV, V0, P0
   Urbina F, 2022, NAT MACH INTELL, V4, P189, DOI 10.1038/s42256-022-00465-9
   van den Oord A, 2019, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Velickovic P, 2018, P 6 INT C LEARN REPR, V0, P0
   Vishnu A, 2018, SMILES2VEC INTERPRET, V0, P0, DOI DOI 10.48550/ARXIV.1712.02034
   Wang YY, 2022, NAT MACH INTELL, V4, P279, DOI 10.1038/s42256-022-00447-x
   WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005
   Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a
   Xiong ZP, 2020, J MED CHEM, V63, P8749, DOI 10.1021/acs.jmedchem.9b00959
   Yang K, 2019, J CHEM INF MODEL, V59, P3370, DOI 10.1021/acs.jcim.9b00237
   You Y, 2020, INT C LEARNING REPRE, V0, P0
NR 56
TC 10
Z9 9
U1 20
U2 36
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD DEC 15
PY 2022
VL 4
IS 12
BP 
EP 
DI 10.1038/s42256-022-00580-7
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 7Z6CX
UT WOS:000915646400002
DA 2023-11-10
ER

PT J
AU Liang, T
   Wang, WY
   Lv, FM
AF Liang, Tao
   Wang, Wenya
   Lv, Fengmao
TI Weakly Supervised Domain Adaptation for Aspect Extraction via Multilevel Interaction Transfer
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Feature extraction; Data mining; Annotations; Adaptation models; Transfer learning; Portable computers; Correlation; Aspect term extraction; deep learning; domain adaptation; natural language processing; transfer learning
AB Fine-grained aspect term extraction is an essential subtask in aspect-based opinion analysis. It aims to identify the aspect terms (also known as opinion targets) of a product or service in each sentence. To learn a good aspect extraction model, an expensive annotation process is usually involved to acquire sufficient token-level labels for each domain, which is not realistic. To address this limitation, some previous works propose domain adaptation strategies to transfer knowledge from a sufficiently labeled source domain to unlabeled target domains. However, due to both the difficulty of fine-grained prediction problems and the large domain gap between different domains, the performance is still far from satisfactory. In this work, we conduct a pioneer study on leveraging sentence-level aspect category labels that can be usually available in commercial services, such as review sites or social media to promote token-level transfer for extraction purpose. Specifically, the aspect category information can be used to construct pivot knowledge for transfer with the assumption that the interactions between the sentence-level aspect category and the token-level aspect terms are invariant across domains. To this end, we propose a novel multilevel reconstruction mechanism that aligns both the fine- and coarse-grained information in multiple levels of abstractions. Comprehensive experiments over several benchmark data sets clearly demonstrate that our approach can fully utilize the sentence-level aspect category labels to improve cross-domain aspect term extraction with a large performance gain.
C1 [Liang, Tao] Southwest Jiaotong Univ, Sch Comp Sci & Artificial Intelligence, Shenzhen 611756, Peoples R China.
   [Liang, Tao] Tencent, Platform & Content Grp, Shenzhen 518000, Peoples R China.
   [Wang, Wenya] Nanyang Technol Univ, Sch Comp Sci AndEngn, Singapore 639798, Singapore.
   [Lv, Fengmao] Southwest Jiaotong Univ, Sch Comp Sci & Artificial Intelligence, Chengdu 611756, Peoples R China.
   [Lv, Fengmao] Southwestern Univ Finance & Econ, Ctr Stat Res, Chengdu 611130, Peoples R China.
C3 Southwest Jiaotong University; Tencent; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Southwest Jiaotong University; Southwestern University of Finance & Economics - China
RP Lv, FM (通讯作者)，Southwest Jiaotong Univ, Sch Comp Sci & Artificial Intelligence, Chengdu 611756, Peoples R China.
EM taoliangdpg@126.com; wangwy@ntu.edu.sg; fengmaolv@126.com
FU Lee Kuan Yew Postdoctoral Fellowship of Singapore [200604393R]; National Natural Science Foundation of China [11829101]; Fundamental Research Funds for the Central Universities of China [JBK1806002]
CR [Anonymous], 2014, NIPS WORKSH DEEP LEA, V0, P0
   [Anonymous], 2010, 23 INT C COMP LING, V0, P0
   [Anonymous], 2010, PROC C EMPIRICAL MET, V0, P0
   [Anonymous], 2008, WWW 08 PROCEEDING 17, V0, P0, DOI DOI 10.1145/1367497.1367513
   [Anonymous], 2010, P 23 INT C COMPUTATI, V0, P0
   Chen C, 2020, AAAI CONF ARTIF INTE, V34, P3422
   Chen ZY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P347
   Ding Y, 2017, AAAI CONF ARTIF INTE, V0, P3436
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Gong CG, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7035
   He RD, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P388, DOI 10.18653/v1/P17-1036
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, V0, P755
   Jiang L, 2011, PROC 49 ANN M ASS CO, V0, P151
   Jin W, 2009, ICME INT C COMPL MED, V0, PP465, DOI 10.1109/ICCME.2009.4906624
   Jing LL, 2022, INT J OCCUP SAF ERGO, V28, P842, DOI 10.1080/10803548.2020.1835234
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Li F, 2010, P 23 INT C COMPUTATI, V0, P653
   Li FT, 2010, AAAI CONF ARTIF INTE, V0, P1371
   Li JJ, 2019, IEEE T IMAGE PROCESS, V28, P6103, DOI 10.1109/TIP.2019.2924174
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li Xin, 2017, P 2017 C EMP METH NA, V0, P2886
   Li Z, 2019, AAAI CONF ARTIF INTE, V0, P4253
   Liu K, 2012, P 2012 JOINT C EMP M, V0, P1346
   Liu K, 2013, P 23 INT JOINT C ART, V13, P2134
   Liu P, 2015, EMNLP, V0, P1433
   Long MS, 2017, PR MACH LEARN RES, V70, P0
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4068
   Mei Q, 2007, P 16 INT C WORLD WID, V0, PP171, DOI 10.1145/1242572.1242596
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pang B, 2008, FDN TRENDS R INFORM, V2, P1135, DOI 10.1561/9781601981516
   Pereg Oren, 2020, PROC INT C COMPUT LI, V0, PP1772, DOI 10.18653/v1/2020.coling-main.158
   Pontiki M, 2014, P 8 INT WORKSHOP SEM, V0, PP27, DOI 10.3115/v1/s14-2004
   Pontiki Maria, 2015, P 9 INT WORKSH SEM E, V0, PP486, DOI 10.18653/v1/s15-2082
   Popescu A-M, 2005, P HUMAN LANGUAGE TEC, V0, PP339, DOI 10.3115/1220575.1220618
   Qiu GA, 2011, COMPUT LINGUIST, V37, P9, DOI 10.1162/coli_a_00034
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Soleimani H, 2015, IEEE T KNOWL DATA EN, V27, P824, DOI 10.1109/TKDE.2014.2345378
   Toprak C, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P575
   Wang WY, 2019, COMPUT LINGUIST, V45, P705, DOI 10.1162/COLI_a_00362
   Wang WY, 2019, AAAI CONF ARTIF INTE, V0, P7192
   Wang WY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2171
   Wang WY, 2017, AAAI CONF ARTIF INTE, V0, P3316
   WenyaWang Sinno Jialin Pan, 2016, ARXIV160306679, V0, P0
   Xu H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Yin Y, 2016, P 25 INT JOINT C ART, V0, PP2979, DOI 10.48550/ARXIV.1605.07843
   Yue Lu, 2009, P 18 INT C WORLD WID, V0, PP131, DOI 10.1145/1526709.1526728
   Zellinger W, 2017, ARXIV170208811, V0, P1
   Zhu Xiaoyan, 2012, P 50 ANN M ASS COMP, V0, P410
   Zhuang L, 2006, P 15 ACM INT C INFOR, V0, PP43, DOI 10.1145/1183614.1183625
NR 52
TC 3
Z9 3
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD OCT 15
PY 2022
VL 33
IS 10
BP 5818
EP 5829
DI 10.1109/TNNLS.2021.3071474
EA APR 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 5C3XB
UT WOS:000733495700001
PM 33872162
DA 2023-11-10
ER

PT J
AU Zhao, S
   Zhang, TY
   Hu, M
   Chang, W
   You, FC
AF Zhao, Shuai
   Zhang, Tianyu
   Hu, Man
   Chang, Wen
   You, Fucheng
TI AP-BERT: enhanced pre-trained model through average pooling
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Pre-trained model; Token embedding; Average pooling; BERT; Deep learning; Natural language processing
AB BERT, a pre-trained language model on the large-scale corpus, has made breakthrough progress in NLP tasks. However, the experimental data shows that the BERT model's application effect in Chinese tasks is not ideal. The reason is that we believe that only character-level embedding can be obtained through BERT. However, a single Chinese character often cannot express their comprehensive meaning. To improve the model's ability to understand phrase-level semantic information, this paper proposes an enhanced BERT based on the average pooling(AP-BERT). Our model uses an average pooling layer to act on token embedding and reconstructs the model's input embedding, which can effectively improve BERT's application effect in Chinese natural language processing. Experimental data show that our proposed method has been enhanced in the four tasks of Chinese text classification, named entity recognition, reading comprehension, and summary generation. This method can not only improve the application effect of the BERT model in Chinese tasks but also can be well applied to other pre-trained language models.
C1 [Zhao, Shuai] Jinan Univ, Coll Informat Sci & Technol, Guangzhou, Peoples R China.
   [Zhang, Tianyu; Hu, Man; Chang, Wen; You, Fucheng] Beijing Inst Graph Commun, Sch Informat Engn, Comp Sci, Beijing, Peoples R China.
C3 Jinan University
RP Zhao, S (通讯作者)，Jinan Univ, Coll Informat Sci & Technol, Guangzhou, Peoples R China.
EM 17839192463@163.com; zty0308go@163.com; human190707@163.com; mr_changwen@163.com; youfucheng@bigc.edu.cn
FU National Natural Science Foundation of China [61773229]; Beijing Municipal Natural Science Foundation [KZ201710015010]
CR Bengio Y, 2001, ADV NEUR IN, V13, P932
   Brown BT, 2019, ARXIV200514165, V0, P0
   Chen, 2018, FAST ABSTRACTIVE SUM, V0, P0
   Chopra S, 2016, P 2016 C N AM ASS CO, V0, P93
   Collobert R, 2007, C PAP ACL, V0, P0
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Gu JJ, 2020, PROC CVPR IEEE, V0, PP3009, DOI 10.1109/CVPR42600.2020.00308
   GU Y, 2020, INT C NAT LANG PROC, V0, P0
   Guo J, 2014, P COLING, V2014, P497
   He W, 2018, MACHINE READING FOR QUESTION ANSWERING, V0, P37
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang ZJ, 2019, PROC CVPR IEEE, V0, PP6402, DOI 10.1109/CVPR.2019.00657
   Jiao X, 2020, FINDINGS ASS COMPUTA, V0, PP4163, DOI 10.18653/v1/2020.findings-emnlp.372
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Joulin Armand, 2016, ARXIV161203651, V0, P0
   Kaliyev A, 2017, INT C SPEECH COMP, V0, P0
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Lai SW, 2015, AAAI CONF ARTIF INTE, V0, P2267
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lauscher Anne, 2019, ARXIV190902339, V0, P0
   Levow G, 2006, P 5 SIGHAN WORKSH CH, V0, P108
   Li J, 2007, EMNLP CONLL, V0, P774
   Lin JCW, 2021, KNOWL-BASED SYST, V212, P0, DOI 10.1016/j.knosys.2020.106548
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu X, 2020, CORR, V0, P0
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3730
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   McCann Bryan, 2017, ADV NEURAL INFORM PR, V0, P6297
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Peters Matthew E, 2019, EMNLP IJCNLP, V0, P0
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Shao C C, 2019, ARXIV180600920, V0, P0
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Su Tzu-Ray, 2017, P 2017 C EMP METH NA, V0, P264
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P384
   Vaswani A, 2017, ARXIV, V30, P5998
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Wang Y, 2018, J TSINGHUA U SCI TEC, V0, P0
   Xie H, 2018, NOV ATT BAS CNN MOD, V0, P0
   Yang X, 2019, PROC CVPR IEEE, V0, PP10677, DOI 10.1109/CVPR.2019.01094
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yin Rongchao, 2016, P 2016 C EMP METH NA, V0, PP981, DOI 10.18653/V1/D16-1100
   Yu A, 2018, 2018 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC), V0, P0
   Yu Wang, 2020, 2020 12TH INTERNATIONAL CONFERENCE ON INTELLIGENT HUMAN-MACHINE SYSTEMS AND CYBERNETICS (IHMSC), V0, PP23, DOI 10.1109/IHMSC49165.2020.00013
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
   Zhou DX, 2020, NEURAL NETWORKS, V124, P319, DOI 10.1016/j.neunet.2020.01.018
NR 53
TC 7
Z9 7
U1 13
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD NOV 15
PY 2022
VL 52
IS 14
BP 15929
EP 15937
DI 10.1007/s10489-022-03190-3
EA MAR 2022
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6H0HG
UT WOS:000770528600001
DA 2023-11-10
ER

PT J
AU Hou, ZJ
   Salazar, J
   Polovets, G
AF Hou, Zejiang
   Salazar, Julian
   Polovets, George
TI Meta-Learning the Difference: Preparing Large Language Models for Efficient Adaptation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Large pretrained language models (PLMs) are often domain- or task-adapted via finetuning or prompting. Finetuning requires modifying all of the parameters and having enough data to avoid overfitting while prompting requires no training and few examples but limits performance. Instead, we prepare PLMs for data- and parameter-efficient adaptation by learning to learn the difference between general and adapted PLMs. This difference is expressed in terms of model weights and sublayer structure through our proposed dynamic low-rank reparameterization and learned architecture controller. Experiments on few-shot dialogue completion, low-resource abstractive summarization, and multi-domain language modeling show improvements in adaptation time and performance over direct finetuning or preparation via domain-adaptive pretraining. Ablations show our task-adaptive reparameterization (TARP) and model search (TAMS) components individually improve on other parameter-efficient transfer like adapters and structure-learning methods like learned sparsification.
C1 [Hou, Zejiang] Princeton Univ, Princeton, NJ 08544 USA.
   [Hou, Zejiang; Salazar, Julian; Polovets, George] Amazon AWS AI, Seattle, WA USA.
C3 Princeton University
RP Hou, ZJ (通讯作者)，Princeton Univ, Princeton, NJ 08544 USA.
EM zejiangh@princeton.edu; julsal@amazon.com; polovg@amazon.com
CR Aghajanyan A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5799
   Alec Radford, 2019, LANGUAGE MODELS ARE, V0, P0
   Armen Aghajanyan, 2021, PROC ACLIJCNLP, V1, P7319
   Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1538
   Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1
   Bengio Y, 1991, IJCNN-91-SEATTLE: INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (CAT. NO.91CH3049-4), V0, P0, DOI DOI 10.1109/IJCNN.1991.155621
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Dai Andrew M, 2015, NIPS, V0, P0
   Dou ZY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1192
   Edward JHu, 2022, INT C LEARNING REPRE, V0, P0
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Gardent C, 2017, P 10 INT C NAT LANG, V0, P0
   Guo DM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4884
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, V0, PP8342, DOI 10.18653/V1/2020.ACL-MAIN.740
   Hambardzumyan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4921
   He J, 2022, INT C LEARN REPR, V0, P0
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   ju I, 2019, ICLR, V0, P0
   Karimi Mahabadi R, 2021, ADV NEURAL INFORM PR, V0, P1022
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3045
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582
   Lilian Weng, 2018, METALEARNING LEARNIN, V0, P0
   Lin Z, 2020, FINDINGS ASS COMPUTA, V0, P441
   Liu X, 2021, ARXIV, V0, P0
   Liu Y, 2019, ROBUSTLY OPTIMIZED B, V0, P0
   Madotto A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5454
   Nan Linyong, 2021, P 2021 C N AM CHAPTE, V0, P432
   Novikova J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), V0, P201
   Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P487
   Pham H, 2018, PR MACH LEARN RES, V80, P0
   Press O, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2996
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rebuffi SA, 2018, PROC CVPR IEEE, V0, PP8119, DOI 10.1109/CVPR.2018.00847
   Schmidhuber J, 1987, EVOLUTIONARY PRINCIP, V0, P0
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   So DR, 2021, P ADV NEURAL INFORM, V0, P6010
   Song Y, 2020, ARXIV191014326, V0, PP5832, DOI 10.18653/V1/2020.ACL-MAIN.517
   Stickland AC, 2019, PR MACH LEARN RES, V97, P0
   Sun QR, 2019, PROC CVPR IEEE, V0, PP403, DOI 10.1109/CVPR.2019.00049
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wolf T, 2020, ARXIV, V0, P0
   Yu T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5892
   Zhang Aston, 2021, ICLR, V0, P0
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2226
   Zhao Yuekai, 2021, FINDINGS ASS COMPUTA, V0, PP4254, DOI 10.18653/V1/2021.FINDINGS-ACL.372
NR 48
TC 2
Z9 2
U1 8
U2 10
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD NOV 22
PY 2022
VL 10
IS 
BP 1249
EP 1265
DI 10.1162/tacl_a_00517
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8I3HO
UT WOS:000921616400002
DA 2023-11-10
ER

PT J
AU Lu, XL
   Chow, TWS
AF Lu, Xiaolei
   Chow, Tommy W. S.
TI Weak Disambiguation for Partial Structured Output Learning
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article
DE Cutting plane algorithm; partial structured output learning; piecewise large margin; weak disambiguation
AB Existing disambiguation strategies for partial structured output learning just cannot generalize well to solve the problem that there are some candidates that can be false positive or similar to the ground-truth label. In this article, we propose a novel weak disambiguation for partial structured output learning (WD-PSL). First, a piecewise large margin formulation is generalized to partial structured output learning, which effectively avoids handling a large number of candidate-structured outputs for complex structures. Second, in the proposed weak disambiguation strategy, each candidate label is assigned with a confidence value indicating how likely it is the true label, which aims to reduce the negative effects of wrong ground-truth label assignment in the learning process. Then, two large margins are formulated to combine two types of constraints which are the disambiguation between candidates and noncandidates, and the weak disambiguation for candidates. In the framework of alternating optimization, a new 2n-slack variables cutting plane algorithm is developed to accelerate each iteration of optimization. The experimental results on several sequence labeling tasks of natural language processing show the effectiveness of the proposed model.
C1 [Lu, Xiaolei; Chow, Tommy W. S.] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Chow, TWS (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM xiaoleilu2-c@my.cityu.edu.hk; eetchow@cityu.edu.hk
FU [9220083]
CR Alahari K, 2010, PROC CVPR IEEE, V0, PP895, DOI 10.1109/CVPR.2010.5540123
   Avinesh PVS, 2007, P IJCAI WORKSHOP SHA, V0, P21
   Brefeld U, 2006, P 23 INT C MACH LEAR, V0, PP145, DOI 10.1145/1143844.1143863
   Chengtao Li, 2013, MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES. EUROPEAN CONFERENCE (ECML PKDD 2013). PROCEEDINGS: LNCS 8189, V0, PP336, DOI 10.1007/978-3-642-40991-2_22
   Chu X, 2016, ADV NEURAL INFORM PR, V0, P316
   Cour T, 2011, J MACH LEARN RES, V12, P1501
   Cour T, 2009, PROC CVPR IEEE, V0, PP919, DOI 10.1109/CVPRW.2009.5206667
   Dong SL, 2019, IEEE T CYBERNETICS, V49, P2294, DOI 10.1109/TCYB.2018.2824799
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jiao F, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Jin Rong, 2003, ADV NEURAL INFORM PR, V0, P921
   Joachims T, 2009, MACH LEARN, V77, P27, DOI 10.1007/S10994-009-5108-8
   JUANG BH, 1991, TECHNOMETRICS, V33, P251, DOI 10.2307/1268779
   Kim Y-B, 2015, P 2015 C N AM CHAPTE, V0, P84
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Liao L, 2007, INT J ROBOT RES, V26, P119, DOI 10.1177/0278364907073775
   Lou X, 2012, PROC 29 INT C MACHIN, V0, P371
   Lyu G, 2018, SELF PACED REGULARIZ, V0, P0
   Marcus M, 2006, BUILDING LARGE ANNOT, V0, P0
   Nguyen N, 2008, P 14 ACM SIGKDD INT, V0, P551
   Sang EF, 2000, INTRO CONLL 2000 SHA, V0, P0
   Sarawagi S, 2005, ADV NEURAL INFORM PR, V0, P1185
   Sutton C, 2009, MACH LEARN, V77, P165, DOI 10.1007/s10994-009-5112-z
   Tckstrm Oscar, 2013, T ASS COMPUTATIONAL, V1, P1, DOI 10.1162/tacl_a_00205
   Tsochantaridis I, 2004, P 21 INT C MACH LEAR, V0, P104
   Tsuboi Y, 2008, P 22 INT C COMPUTATI, V1, P897, DOI 10.3115/1599081.1599194
   Wu X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2868
   Yu F, 2016, AS C MACH LEARN PMLR, V0, P96
   Zhang ML, 2017, IEEE T KNOWL DATA EN, V29, P2155, DOI 10.1109/TKDE.2017.2721942
   Zhang ML, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P4048
   Zhong ZL, 2020, IEEE T CYBERNETICS, V50, P3318, DOI 10.1109/TCYB.2019.2915094
   Zhou Y, 2017, IEEE T CYBERNETICS, V47, P4443, DOI 10.1109/TCYB.2016.2611534
NR 32
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD FEB 15
PY 2022
VL 52
IS 2
BP 1258
EP 1268
DI 10.1109/TCYB.2020.3000053
PG 11
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Automation & Control Systems; Computer Science
GA ZB4KT
UT WOS:000756813500047
PM 32574146
DA 2023-11-10
ER

PT J
AU Zhang, H
   Yang, SY
   Zhu, HQ
AF Zhang, Han
   Yang, Suyi
   Zhu, Hongqing
TI CJE-TIG: Zero-shot cross-lingual text-to-image generation by Corpora-based Joint Encoding
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Cross-lingual pre-training; Text-to-image synthesis; Universal contextual word vector space; Semantic alignment; Joint adversarial training
AB Recently, text-to-Image (T2I) generation has been well developed by improving synthesis authenticity, text-consistency and generation diversity. However, large amount of pairwise image-text data required restricts generalization of synthesis models only to its pre-trained language. In this paper, a cross-lingual pre-training method is proposed to adapt target low-resource language to pre-trained generative models. As far as we known, this is the first time that arbitrary input languages could access T2I generation. This joint encoding scheme fulfills both universal and visual semantic alignment. With any prepared GAN-based T2I framework, pre-trained source encoder model could be easily fine-tuned to construct target encoder model and hence entirely enable transfer of T2I synthesis ability between languages. After that, a semantic-level alignment independent of source T2I structure is established to guarantee optimal text consistency and detail generation. Different from monolingual T2I methods that apply discriminator to enhance generation quality, we use an adversarial training scheme that optimizes the sentence-level alignment along with the word-level alignment with a self-attention mechanism. Considering of training for low-resource languages lack of parallel texts in practice, target input embedding is designed available for zero-shot learning. Experimental results prove robustness of the proposed cross-lingual T2I pre-training on multiple downstream generative models and target languages applied.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Han; Zhu, Hongqing] East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
   [Yang, Suyi] Kings Coll London, Dept Math Nat Math & Engn Sci, London WC2R 2LS, England.
C3 East China University of Science & Technology; University of London; King's College London
RP Zhu, HQ (通讯作者)，East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
EM hqzhu@ecust.edu.cn
FU National Natural Science Foundation of China [61872143]
CR Abad A, 2020, INT CONF ACOUST SPEE, V0, PP6909, DOI 10.1109/ICASSP40776.2020.9054468
   Aldarmaki H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3906
   [Anonymous], 2016, P 2016 C N AM CHAPTE, V0, P0
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Artetxe M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7674
   Bahdanau D, 2016, ARXIV, V0, P0
   Chen Q, 2021, PROC CVPR IEEE, V0, PP13034, DOI 10.1109/CVPR46437.2021.01284
   Chi ZW, 2020, AAAI CONF ARTIF INTE, V34, P7570
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Cui YM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1586
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Elliott Desmond, 2016, P 5 WORKSHOP VISION, V0, P0
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hermann KM, 2013, ARXIV13126173, V0, P0
   Ji ZY, 2020, IEEE I C VI COM I PR, V0, PP265, DOI 10.1109/vcip49819.2020.9301888
   Koehn P, 2005, P MACHINE TRANSLATIO, V0, P79
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample G, 2018, INT C LEARNING REPRE, V0, P0
   Lan WY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1549, DOI 10.1145/3123266.3123366
   Lee Cheolhyoung, 2019, ARXIV190911299, V0, P0
   Li B, 2019, ADV NEURAL INFORM PR, V0, P2063
   Li SY, 2021, KNOWL-BASED SYST, V218, P0, DOI 10.1016/j.knosys.2021.106827
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu X, 2021, KNOWL-BASED SYST, V212, P0, DOI 10.1016/j.knosys.2020.106611
   Martinek J, 2020, ARXIV200509260, V0, P0
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mirza M, 2014, ARXIV14111784, V0, P0, DOI DOI 10.48550/ARXIV.1411.1784
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Qiao TT, 2019, PROC CVPR IEEE, V0, PP1505, DOI 10.1109/CVPR.2019.00160
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Reed S, 2016, PR MACH LEARN RES, V48, P0
   Robnik-Sikonja M, 2020, ARXIV200507456, V0, P0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Schuster S, 2018, NAACL, V0, P0
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   Schuster Tal, 2019, P 2019 C N AM CHAPT, V0, P0
   Tian L, 1900, V2021, V0, P603
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wah C, 2011, CNSTR2011001 CALTECH, V0, P0
   Wang YX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5721
   Wehrmann J, 2019, IEEE I CONF COMP VIS, V0, PP5803, DOI 10.1109/ICCV.2019.00590
   Wu CS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P917
   Xing Chao, 2015, PROC 2015 C N AM CHA, V0, PP1006, DOI 10.3115/V1/N15-1104
   Xu T, 2018, PROC CVPR IEEE, V0, PP1316, DOI 10.1109/CVPR.2018.00143
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, V0, PP5908, DOI 10.1109/ICCV.2017.629
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, P0, DOI 10.1145/3383184
   Zhou DY, 2021, KNOWL-BASED SYST, V227, P0, DOI 10.1016/j.knosys.2021.107200
   Zhu MF, 2019, PROC CVPR IEEE, V0, PP5795, DOI 10.1109/CVPR.2019.00595
NR 54
TC 2
Z9 2
U1 3
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD MAR 5
PY 2022
VL 239
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.108006
EA JAN 2022
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0V9BI
UT WOS:000788633300003
DA 2023-11-10
ER

PT J
AU Husain, F
   Uzuner, O
AF Husain, Fatemah
   Uzuner, Ozlem
TI Investigating the Effect of Preprocessing Arabic Text on Offensive Language and Hate Speech Detection
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Artificial neural networks; offensive language detection; natural language processing; Arabic language; machine learning
AB Preprocessing of input text can play a key role in text classification by reducing dimensionality and removing unnecessary content. This study aims to investigate the impact of preprocessing on Arabic offensive language classification. We explore six preprocessing techniques: conversion of emojis to Arabic textual labels, normalization of different forms of Arabic letters, normalization of selected nouns from dialectal Arabic to Modern Standard Arabic, conversion of selected hyponyms to hypernyms, hashtag segmentation, and basic cleaning such as removing numbers, kashidas, diacritics, and HTML tags. We also experiment with raw text and a combination of all six preprocessing techniques. We apply different types of classifiers in our experiments including traditional machine learning, ensemble machine learning, Artificial Neural Networks, and Bidirectional Encoder Representations from Transformers (BERT)-based models to analyze the impact of preprocessing. Our results demonstrate significant variations in the effects of preprocessing on each classifier type and on each dataset. Classifiers that are based on BERT do not benefit from preprocessing, while traditional machine learning classifiers do. However, these results can benefit from validation on larger datasets that cover broader domains and dialects.
C1 [Husain, Fatemah] Kuwait Univ, Sabah AlSalem Univ City Alshadadiya, POB 5969, Safat 13060, Kuwait.
   [Uzuner, Ozlem] George Mason Univ, 4400 Univ Dr,5359 Nguyen Engn Bldg,MSN 1G8, Fairfax, VA 22030 USA.
C3 Kuwait University; George Mason University
RP Husain, F (通讯作者)，Kuwait Univ, Sabah AlSalem Univ City Alshadadiya, POB 5969, Safat 13060, Kuwait.
EM f.husain@ku.edu.kw; ouzuner@gmu.edu
CR Alharbi AI, 2020, P 4 WORKSH OP SOURC, V0, P91
   [Anonymous], 2010, SYNTHESIS LECT HUMAN, V0, P0, DOI DOI 10.2200/S00274ED1V01Y201006HLT007
   [Anonymous], 2015, INT SCI INDEX, V0, P0
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Darwish K, 2014, P EMNLP 2014 WORKSHO, V0, P217
   Duwairi R, 2014, J INF SCI, V40, P501, DOI 10.1177/0165551514534143
   El Gayar Neamat, 2018, SERIES LANGUAGE PROC, V4, P1, DOI 10.1142/10693
   HaCohen-Kerner Y, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0232525
   Haddad H, 2019, COMM COM INF SC, V1108, P251, DOI 10.1007/978-3-030-32959-4_18
   HamdyMubarak Kareem Darwish, 2020, P 4 WORKSHOP OPEN SO, V4, P0
   Husain F, 2020, P 4 WORKSHOP OPEN SO, V0, P53
   Husain F, 2020, P 14 INT WORKSHOP SE, V0, P0
   Husain F, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3421504
   Husain Fatemah, 2020, ARABIC OFFENSIVE LAN, V0, P0
   Kamiran F, 2020, P 4 WORKSH OP SOURC, V0, P71
   Mulki H, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, V0, P111
   Orsan C, 2018, P 1 WORKSHOP TROLLIN, V0, P113
   Saad MK, 2010, IMPACT TEXT PREPROCE, V0, P0
   Safaya A, 2020, P 14 WORKSH SEM EV, V0, P2054
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Woo H, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/1958149
NR 23
TC 4
Z9 4
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL 15
PY 2022
VL 21
IS 4
BP 
EP 
DI 10.1145/3501398
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1L2VC
UT WOS:000799149600010
DA 2023-11-10
ER

PT J
AU Chen, XY
   Jin, P
   Cai, P
   Wang, HJ
   Dai, XY
   Chen, JJ
AF Chen, Xingyuan
   Jin, Peng
   Cai, Ping
   Wang, Hongjun
   Dai, Xinyu
   Chen, Jiajun
TI The detection of distributional discrepancy for language GANs
SO CONNECTION SCIENCE
LA English
DT Article
DE Text generation; generative adversarial nets; distributional discrepancy
AB A pre-trained neural language model (LM) is usually used to generate texts. Due to exposure bias, the generated text is not as good as real text. Many researchers claimed they employed the Generative Adversarial Nets (GAN) to alleviate this issue by feeding reward signals from a discriminator to update the LM (generator). However, some researchers argued that GAN did not work by evaluating the generated texts with a quality-diversity metric such as Bleu versus self-Bleu, and language model score versus reverse language model score. Unfortunately, these two-dimension metrics are not reliable. Furthermore, the existing methods only assessed the final generated texts, thus neglecting the dynamic evaluating the adversarial learning process. Different from the above-mentioned methods, we adopted the most recent metric functions, which measure the distributional discrepancy between real and generated text. Besides that, we design a comprehensive experiment to investigate the performance during the learning process. First, we evaluate a language model with two functions and identify a large discrepancy. Then, several methods with the detected discrepancy signal to improve the generator were tried. Experimenting with two language GANs on two benchmark datasets, we found that the distributional discrepancy increases with more adversarial learning rounds. Our research provides convicted evidence that the language GANs fail.
C1 [Chen, Xingyuan; Dai, Xinyu; Chen, Jiajun] Nanjing Univ, Dept Comp Sci & Technol, Nanjing, Peoples R China.
   [Jin, Peng] Leshan Normal Univ, Sch Elect Engn & Artificial Intelligence, Leshan, Peoples R China.
   [Cai, Ping; Wang, Hongjun] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
C3 Nanjing University; Leshan Normal University; Southwest Jiaotong University
RP Dai, XY; Chen, JJ (通讯作者)，Nanjing Univ, Dept Comp Sci & Technol, Nanjing, Peoples R China.
EM daixinyu@nju.edu.cn; chenjj@nju.edu.cn
FU National Natural Science Foundation of China [61936012, 61976114, 81373056]; National Key Research and Development Program of China [2018YFB1005102]
CR Bengio S, 2015, ADV NEUR IN, V28, P0
   Caccia M, 2018, ARXIV181102549, V0, P0
   Cai P, 2021, KNOWL-BASED SYST, V217, P0, DOI 10.1016/j.knosys.2021.106850
   Cao ZX, 2021, CONNECT SCI, V33, P911, DOI 10.1080/09540091.2021.1912711
   Che T, 2017, MAXIMUM LIKELIHOOD A, V0, P0
   Chen L, 2018, P 32 INT C NEURAL IN, V0, P4671
   dAutume Cyprien de Masson, 2019, ADV NEURAL INFORM PR, V0, PP4300, DOI 10.5555/3454287.3454674
   Fedus W, 2018, ICLR, V0, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu FQ, 2018, IEEE T EVOLUT COMPUT, V22, P211, DOI 10.1109/TEVC.2017.2695579
   Guo JX, 2018, AAAI CONF ARTIF INTE, V0, P5141
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He T, 2021, EXPOSURE BIAS VERSUS, V0, P0
   Jang E, 2017, P INT C LEARN REPR, V0, P1
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Li Y, 2022, CONNECT SCI, V34, P492, DOI 10.1080/09540091.2021.2021143
   Lin K, 2017, PROC 31 INT C NEURAL, V0, P3158
   Lin NK, 2022, CONNECT SCI, V34, P29, DOI 10.1080/09540091.2021.1937942
   Nie Weili, 2018, INT C LEARN REPR, V0, P0
   Ondrej C<prime>ifka, 2018, ARXIV180407972, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0
   Salimans T, 2016, ADV NEUR IN, V29, P0
   Santoro A, 2018, ADV NEUR IN, V31, P0
   Semeniuta S, 2018, ABS180604936 CORR, V0, P0
   Shi Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4361
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Vaswani A, 2017, NIPS, V30, P0
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu Q, 2021, CONNECT SCI, V33, P341, DOI 10.1080/09540091.2020.1822780
   Wu ST, 2022, CONNECT SCI, V34, P44, DOI 10.1080/09540091.2021.1940101
   Xu JJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3940
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
   Zellers R, 2019, ADV NEUR IN, V32, P0
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1097, DOI 10.1145/3209978.3210080
NR 37
TC 1
Z9 1
U1 2
U2 7
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0954-0091
EI 1360-0494
J9 CONNECT SCI
JI Connect. Sci.
PD DEC 31
PY 2022
VL 34
IS 1
BP 1736
EP 1750
DI 10.1080/09540091.2022.2080182
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA 2C4IM
UT WOS:000810833900001
DA 2023-11-10
ER

PT J
AU Schlegel, K
   Neubert, P
   Protzel, P
AF Schlegel, Kenny
   Neubert, Peer
   Protzel, Peter
TI A comparison of vector symbolic architectures
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Article
DE Vector symbolic architectures; Hypervectors; High-dimensional computing; Hyperdimensional computing
ID representation; binding; model
AB Vector Symbolic Architectures combine a high-dimensional vector space with a set of carefully designed operators in order to perform symbolic computations with large numerical vectors. Major goals are the exploitation of their representational power and ability to deal with fuzziness and ambiguity. Over the past years, several VSA implementations have been proposed. The available implementations differ in the underlying vector space and the particular implementations of the VSA operators. This paper provides an overview of eleven available VSA implementations and discusses their commonalities and differences in the underlying vector space and operators. We create a taxonomy of available binding operations and show an important ramification for non self-inverse binding operations using an example from analogical reasoning. A main contribution is the experimental comparison of the available implementations in order to evaluate (1) the capacity of bundles, (2) the approximation quality of non-exact unbinding operations, (3) the influence of combining binding and bundling operations on the query answering performance, and (4) the performance on two example applications: visual place- and language-recognition. We expect this comparison and systematization to be relevant for development of VSAs, and to support the selection of an appropriate VSA for a particular task. The implementations are available.
C1 [Schlegel, Kenny; Neubert, Peer; Protzel, Peter] Tech Univ Chemnitz, Fac Elect Engn, Chemnitz, Germany.
C3 Technische Universitat Chemnitz
RP Schlegel, K (通讯作者)，Tech Univ Chemnitz, Fac Elect Engn, Chemnitz, Germany.
EM kenny.schlegel@etit.tu-chemnitz.de; peer.neubert@etit.tu-chemnitz.de; peter.protzel@etit.tu-chemnitz.de
FU Projekt DEAL
CR Ahmad S, 2019, CAN WE BE SO DENSE B, V0, P0
   Ahmad S, 2015, ARXIV150307469, V0, P0
   [Anonymous], 2018, COGNITIVE COMPUTING, V0, P0
   [Anonymous], 1997, CONNECTIONIST SYSTEM, V0, P0
   Badino H, 2011, IEEE INT VEH SYM, V0, PP794, DOI 10.1109/IVS.2011.5940504
   Bellman, 1961, ADAPTIVE CONTROL PRO, V0, P0
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Cheung B, 2019, NEURIPS, V0, P10868
   Danihelka I, 2016, PR MACH LEARN RES, V48, P0
   Eliasmith C, 2013, BUILD BRAIN NEURAL A, V0, P0, DOI DOI 10.1093/ACPROF:OSO/9780199794546.001.0001
   Frady EP, 2018, NEURAL COMPUT, V30, P1449, DOI 10.1162/neco_a_01084
   Frady EP, 2023, IEEE T NEUR NET LEAR, V34, P2191, DOI 10.1109/TNNLS.2021.3105949
   Gallant SI, 2013, NEURAL COMPUT, V25, P2038, DOI 10.1162/NECO_a_00467
   Gayler RW, 1998, ADV ANALOGY RES INTE, V0, P1
   Gayler RW, 2009, PROC NEW FRONTIERS A, V0, P165
   Gayler Ross W, 2003, ICCSASCS INT C COGNI, V0, P133
   Glover A, 2014, DAY NIGHT LATERAL PO, V0, P0
   Glover AJ, 2010, IEEE INT CONF ROBOT, V0, PP3507, DOI 10.1109/ROBOT.2010.5509547
   Gosmann J, 2019, NEURAL COMPUT, V31, P849, DOI 10.1162/neco_a_01179
   Joshi A, 2017, LECT NOTES COMPUT SC, V10106, P265, DOI 10.1007/978-3-319-52289-0_21
   Kanerva P, 1996, ARTIFICIAL NEURAL NETWORKS - ICANN 96. 1996 INTERNATIONAL CONFERENCE PROCEEDINGS, V0, P869
   Kanerva P, 2001, COMPUTING LARGE RAND, V0, P0
   Kanerva P, 2010, AAAI FALL S QUANTUM, V0, P2
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Karunaratne G, 2021, NAT COMMUN, V12, P0, DOI 10.1038/s41467-021-22364-0
   Karunaratne G, 2020, NAT ELECTRON, V3, P327, DOI 10.1038/s41928-020-0410-3
   Kelly MA, 2013, CAN J EXP PSYCHOL, V67, P79, DOI 10.1037/a0030301
   Kleyko D, 2018, THESIS LULEA U TECHN, V0, P0
   Kleyko D, 2020, NEURAL COMPUT APPL, V32, P3675, DOI 10.1007/s00521-019-04397-1
   Kleyko D, 2018, IEEE T NEUR NET LEAR, V29, P5880, DOI 10.1109/TNNLS.2018.2814400
   Kleyko D, 2015, BIOL INSPIR COGN ARC, V14, P57, DOI 10.1016/j.bica.2015.09.002
   Kleyko D, 2015, IEEE INTL CONF IND I, V0, PP1219, DOI 10.1109/INDIN.2015.7281909
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Laiho Mika, 2015, 2015 IEEE BIOMEDICAL CIRCUITS AND SYSTEMS CONFERENCE (BIOCAS), V0, PP1, DOI 10.1109/BioCAS.2015.7348414
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Milford MJ, 2012, IEEE INT CONF ROBOT, V0, PP1643, DOI 10.1109/ICRA.2012.6224623
   NEUBERT P, 2021, P ROB SCI SYST RSS, V0, P0
   Neubert P, 2021, PROC CVPR IEEE, V0, PP16933, DOI 10.1109/CVPR46437.2021.01666
   Neubert P, 2019, IEEE ROBOT AUTOM LET, V4, P3200, DOI 10.1109/LRA.2019.2927096
   Osipov E, 2017, IEEE IND ELEC, V0, PP3276, DOI 10.1109/IECON.2017.8216554
   Plate TA, 2003, HOLOGRAPHIC REDUCED, V0, P0
   PLATE TA, 1995, IEEE T NEURAL NETWOR, V6, P623, DOI 10.1109/72.377968
   Plate TA, 1994, THESIS U TORONTO CAN, V0, P0
   Rachkovskij DA, 2001, IEEE T KNOWL DATA EN, V13, P261, DOI 10.1109/69.917565
   Rachkovskij DA, 2001, NEURAL COMPUT, V13, P411, DOI 10.1162/089976601300014592
   Rachkovskij DA, 2012, COMPUT INTELL-US, V28, P106, DOI 10.1111/j.1467-8640.2011.00423.x
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   Schubert S, 2020, IEEE INT CONF ROBOT, V0, PP4372, DOI 10.1109/icra40945.2020.9197044
   SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M
   Sünderhauf N, 2015, IEEE INT C INT ROBOT, V0, PP4297, DOI 10.1109/IROS.2015.7353986
   Sunderhauf N, 2013, P IEEE INT C ROB AUT, V0, P0
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Tissera MD, 2014, IEEE INT C SEMANT CO, V0, PP171, DOI 10.1109/ICSC.2014.38
   Widdows D, 2004, GEOMETRY MEANING, VVolume 773, P0
   Widdows D, 2015, LOG J IGPL, V23, P141, DOI 10.1093/jigpal/jzu028
   Yilmaz O, 2015, NEURAL COMPUT, V27, P2661, DOI 10.1162/NECO_a_00787
NR 57
TC 13
Z9 13
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
EI 1573-7462
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD AUG 15
PY 2022
VL 55
IS 6
BP 4523
EP 4555
DI 10.1007/s10462-021-10110-3
EA DEC 2021
PG 33
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 2W8KB
UT WOS:000730496000001
DA 2023-11-10
ER

PT J
AU Zaidi, SSA
   Fraz, MM
   Shahzad, M
   Khan, S
AF Zaidi, Syed S. Ali
   Fraz, Muhammad Moazam
   Shahzad, Muhammad
   Khan, Sharifullah
TI A multiapproach generalized framework for automated solution suggestion of support tickets
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE action extraction; artificial intelligence; automated resolution; natural language processing; solution suggestion; ticket resolution recommendation
AB Nowadays, customer support systems are one of the key factors in maintaining any big company's reputation and success. These systems are capable of handling a large number of tickets systemically and provides a mechanism to track/logs the communication between customer and support agents. Companies invest huge amounts of money in training support agents and deploying customer care services for their products and services. Support agents are responsible for handling different customer queries and implementing required actions to solve a particular issue or problem raised by the service/product user. In a bigger picture, customer support systems could receive a large amount of ticket raised depending upon the number of users and services being offered. Customer care service gets directly affected due to the high volume of tickets and a limited number of support agents. Therefore, providing support agents with the recommendations about the possible resolution actions for a new ticket would be helpful and can save a lot of time. This study is focused on the development of an end-to-end framework for suggesting resolution actions rather than recommending free form resolution text against a newly raised ticket. To develop such a system, the pipeline is broadly divided into four components that are data preprocessing, actions extractor, resolution predictor, and evaluation. In actions extractor module, we have proposed a technique to identify and extract actionable phrases from resolution text. For resolution predictor, we have proposed two different pipelines that are referred as "Similarity Search Model" and "End-to-End Model." The similarity search method is based on a ticket similarity search to find the most relevant historical tickets which then leads to corresponding resolution actions. On the other hand, end-to-end model make use of actions extractor module directly and implemented in a way to directly predict resolution actions. To compare and evaluate the mentioned methods on the same ground, we also proposed an actions evaluation criterion which uses BertScore and METEOR score jointly to compute the score against actual and predicted actions for a particular test ticket. The analysis and experiments are performed on the real-world IBM ticket data set. Overall, we observed that end-to-end model outperformed similarity search-based methods and achieved better performance and scores comparatively. The trained models and code are available at .
C1 [Zaidi, Syed S. Ali] IBM Corp, Adv Analyt Div, Global Business Serv, Islamabad, Pakistan.
   [Zaidi, Syed S. Ali; Fraz, Muhammad Moazam; Shahzad, Muhammad; Khan, Sharifullah] Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci SEECS, Sect H-12, Islamabad 44000, Pakistan.
   [Shahzad, Muhammad] Tech Univ Munich TUM, Data Sci Earth Observat, Dept Aerosp & Geodesy, Munich, Germany.
   [Khan, Sharifullah] Pak Austria Fachhsch Inst Appl Sci & Technol, Haripur, Pakistan.
C3 National University of Sciences & Technology - Pakistan; Technical University of Munich
RP Fraz, MM (通讯作者)，Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci SEECS, Sect H-12, Islamabad 44000, Pakistan.
EM moazam.fraz@seecs.edu.pk
CR AAIo AI, 2020, ALLENNLP NATURAL LAN, V0, P0
   Ali R, 2018, EXPERT SYST, V35, P0, DOI 10.1111/exsy.12242
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, V0, PP65, DOI 10.3115/1626355.1626389
   Bok K, 2020, CONCURR COMP-PRACT E, V32, P0, DOI 10.1002/cpe.5572
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chakravarthy DG, 2021, J AMB INTEL HUM COMP, V12, P6181, DOI 10.1007/s12652-020-02187-5
   Chrissy Kidd JH, 2019, IT SUPPORT LEVELS CL, V0, P0
   Conneau A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1699
   Facebook-Open-Source, 2020, FASTT PRETR LANG MOD, V0, P0
   Garage I, 2021, IBM TIVOLI INTEGRATE, V0, P0
   Huang CF, 2021, QUAL RELIAB ENG INT, V37, P2214, DOI 10.1002/qre.2853
   Hugging-Face, 2021, PRETR BERT EMB, V0, P0
   Inc S, 2020, SPLUNK COMMERICAL MA, V0, P0
   Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4
   Khurram I, 2021, COGN COMPUT, V13, P595, DOI 10.1007/s12559-019-09697-1
   Lahitani AR, 2016, 2016 4TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT, V0, P205
   Lamb Alex M, 2016, ADV NEURAL INFORM PR, V0, P4601
   Liu YW, 2021, INT J INTELL SYST, V36, P3174, DOI 10.1002/int.22412
   Majumder G, 2016, COMPUT SIST, V20, P647, DOI 10.13053/CyS-20-4-2506
   Màrquez L, 2008, COMPUT LINGUIST, V34, P145, DOI 10.1162/coli.2008.34.2.145
   Merrouni ZA, 2020, J INTELL INF SYST, V54, P391, DOI 10.1007/s10844-019-00558-9
   Morawski J, 2017, INT J INTELL SYST, V32, P1062, DOI 10.1002/int.21884
   Mukunthan MA, 2019, CONCURR COMP-PRACT E, V31, P0, DOI 10.1002/cpe.5297
   Muni DP, 2017, PROCEEDINGS OF THE FOURTH ACM IKDD CONFERENCES ON DATA SCIENCES (CODS 17), V0, P0, DOI DOI 10.1145/3041823.3041831
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Revina A, 2021, INTERPRETABLE ARTIFI, V937, P293
   Subramanian Sandeep, 2018, P 6 INT C LEARN REPR, V0, P0
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Tao LQ, 2017, INFORM SCIENCES, V415, P269, DOI 10.1016/j.ins.2017.06.030
   Thompson VU, 2015, 2015 7TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, V0, P577
   Vorontsov IE, 2013, ALGORITHM MOL BIOL, V8, P0, DOI 10.1186/1748-7188-8-23
   Wu YL, 2020, INFORM SCIENCES, V517, P100, DOI 10.1016/j.ins.2019.12.031
   Xu J, 2020, DATA KNOWL ENG, V127, P0, DOI 10.1016/j.datak.2020.101800
   Zendesk, 2020, BUSINESS IMPACT CUST, V0, P0
   Zendesk, 2020, ZENDESK BENCHMARK YO, V0, P0
   Zhou WB, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2181, DOI 10.1145/3097983.3098190
   Zhou WB, 2016, IEEE T NETW SERV MAN, V13, P954, DOI 10.1109/TNSM.2016.2587807
   Zhou W, 2015, INT CONF NETW SER, V0, PP15, DOI 10.1109/CNSM.2015.7367333
NR 40
TC 8
Z9 8
U1 3
U2 9
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD JUN 15
PY 2022
VL 37
IS 6
BP 3654
EP 3681
DI 10.1002/int.22701
EA SEP 2021
PG 28
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0U7RB
UT WOS:000702353600001
DA 2023-11-10
ER

PT J
AU Li, PF
   Zhang, M
   Lin, PJ
   Wan, J
   Jiang, M
AF Li, Pengfei
   Zhang, Min
   Lin, Peijie
   Wan, Jian
   Jiang, Ming
TI Conditional Embedding Pre-Training Language Model for Image Captioning
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Image captioning; Layer normalization; Transformer; UNILM; Visual embedding
AB The pre-trained language model can not only learn language representations with different granularity from a large number of corpus, but also provide a good initialization for downstream tasks. Aggregation or alignment of text features and visual features as input of pre-training language model is the mainstream approach to deal with visual-language tasks. People can accurately describe an image by constantly referring to the visual information and key text information of the image. Inspired by this idea, we no longer follow main-stream approach, and propose to adjust the pre-training language model processing by using high-low visual features as conditional inputs. Specifically, conditional embedding layer normalization (CELN) we proposed is an effective mechanism for embedding visual features into pre-training language models for feature selection. We apply CELN to transformers in the unified pre-training language model (UNILM). This model parameter adjustment mechanism is an innovative attempt in pre-training language model. Extensive experiments on two challenging benchmarks (MSCOCO and Visual Genome datasets)demonstrate that this seminal work is effective. Code and models are publicly available at: https://github.com/1pfworld/CE-UNILM.
C1 [Li, Pengfei; Zhang, Min; Lin, Peijie; Wan, Jian; Jiang, Ming] Hangzhou Dianzi Univ, Baiyang Rd 2, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Zhang, M (通讯作者)，Hangzhou Dianzi Univ, Baiyang Rd 2, Hangzhou, Zhejiang, Peoples R China.
EM lipf@hdu.edu.cn; hz_andy@163.com; linpeijie@hdu.edu.cn; wanjian@hdu.edu.cn; jmzju@163.com
FU Zhejiang Provincial Technical Plan Project [2020C03105, 2021C01129]
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Ba LJ, 2016, CORR ARXIV160706450, V0, P0
   Bao B, 2020, SCI CHINA TECHNOL SC, V63, P10
   Bodla N, 2017, IEEE I CONF COMP VIS, V0, PP5562, DOI 10.1109/ICCV.2017.593
   Chen L, 2017, PROC CVPR IEEE, V0, PP6298, DOI 10.1109/CVPR.2017.667
   de Vries H, 2017, ADV NEUR IN, V30, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gao ZL, 2020, COMPLEXITY, V2020, P0, DOI 10.1155/2020/5075487
   Herdade S, 2019, ADV NEUR IN, V32, P0
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Jia X, 2015, IEEE I CONF COMP VIS, V0, PP2407, DOI 10.1109/ICCV.2015.277
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li, 2017, 2017 IEEE C COMPUTER, V0, P3668
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu DQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP1416, DOI 10.1145/3240508.3240632
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Longteng Guo, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2018, PROC CVPR IEEE, V0, PP7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, V0, PP3242, DOI 10.1109/CVPR.2017.345
   Mahia RN, 2018, IEEE T CIRCUITS-II, V65, P216, DOI 10.1109/TCSII.2017.2706968
   Mathews A, 2016, AAAI CONF ARTIF INTE, V0, P3574
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Miyato Takeru, 2018, ARXIV180205957, V0, PP1, DOI 10.48550/ARXIV.1802.05957
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Schuster S, 2015, P 4 WORKSH VIS LANG, V0, P7080
   Shizhe Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9959, DOI 10.1109/CVPR42600.2020.00998
   Su SY, 2020, P 2020 C EMP METH NA, V0, P4930
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Ulyanov D, 2016, CORR ARXIV160708022, V0, P0
   VEDANTAM R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wu Q, 2016, PROC CVPR IEEE, V0, PP203, DOI 10.1109/CVPR.2016.29
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w
   Xiang LY, 2020, MATH BIOSCI ENG, V17, P1041, DOI 10.3934/mbe.2020055
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, V0, PP10677, DOI 10.1109/CVPR.2019.01094
   Yang Zhilin, 2016, ADV NEURAL INFORM PR, V0, P0
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yu F, 2020, COMPLEXITY, V2020, P0, DOI 10.1155/2020/5859273
   Zhang H, 2019, PR MACH LEARN RES, V97, P0
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
NR 55
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD DEC 15
PY 2022
VL 54
IS 6
BP 4987
EP 5003
DI 10.1007/s11063-022-10844-3
EA JUN 2022
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5U5PN
UT WOS:000810831800003
DA 2023-11-10
ER

PT J
AU Loureiro, D
   Camacho-Collados, J
   Jorge, AM
AF Loureiro, Daniel
   Camacho-Collados, Jose
   Jorge, Alipio Mario
TI LMMS reloaded: Transformer-based sense embeddings for disambiguation and beyond
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Semantic representations; Neural language models
ID representation; language; model; word
AB Distributional semantics based on neural approaches is a cornerstone of Natural Language Processing, with surprising connections to human meaning representation as well. Recent Transformer-based Language Models have proven capable of producing contextual word representations that reliably convey sense-specific information, simply as a product of self supervision. Prior work has shown that these contextual representations can be used to accurately represent large sense inventories as sense embeddings, to the extent that a distance-based solution to Word Sense Disambiguation (WSD) tasks outperforms models trained specifically for the task. Still, there remains much to understand on how to use these Neural Language Models (NLMs) to produce sense embeddings that can better harness each NLM's meaning representation abilities. In this work we introduce a more principled approach to leverage information from all layers of NLMs, informed by a probing analysis on 14 NLM variants. We also emphasize the versatility of these sense embeddings in contrast to task-specific models, applying them on several sense-related tasks, besides WSD, while demonstrating improved performance using our proposed approach over prior work focused on sense embeddings. Finally, we discuss unexpected findings regarding layer and model performance variations, and potential applications for downstream tasks.& nbsp;(c) 2022 Elsevier B.V. All rights reserved.
C1 [Loureiro, Daniel; Jorge, Alipio Mario] Univ Porto, FCUP, Dept Comp Sci, LIAAD INESC TEC, Porto, Portugal.
   [Camacho-Collados, Jose] Cardiff Univ, Sch Comp Sci & Informat, Cardiff, Wales.
C3 Universidade do Porto; INESC TEC; Cardiff University
RP Loureiro, D (通讯作者)，Univ Porto, FCUP, Dept Comp Sci, LIAAD INESC TEC, Porto, Portugal.
EM daniel.b.loureiro@inesctec.pt; camachocolladosj@cardiff.ac.uk; amjorge@fc.up.pt
FU EU; Fundacao para a Ciencia e Tecnologia [DFA/BD/9028/2020]; UKRI Future Leaders Fellowship [MR/T042001/1]
CR Ammanabrolu P, 2020, AAAI CONF ARTIF INTE, V34, P7375
   [Anonymous], 2006, THESIS U PENNSYLVANI, V0, P0
   [Anonymous], 1998, ENCY APPL LING, V0, P0, DOI DOI 10.7551/MITPRESS/7287.001.0001
   [Anonymous], 2017, SEMEVAL ACL, V0, P0, DOI DOI 10.18653/V1/S17-2002
   [Anonymous], 2001, P 23 ANN C COGNITIVE, V0, P0
   Armendariz CS, 2020, P 14 WORKSH SEM EV, V0, PP36, DOI 10.18653/V1/2020.SEMEVAL-1.3
   Armendariz CS, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5870
   Athiwaratkun B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1
   Barba E, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P1492
   Bender EM, 2020, C SESSION P 58 ANN M, V0, P0
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bevilacqua M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2854
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blevins T, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1006
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Cai ZGG, 2017, COGNITIVE PSYCHOL, V98, P73, DOI 10.1016/j.cogpsych.2017.08.003
   Camacho J, 2015, P C N AM CHAPT ASS C, V0, P567
   Camacho-Collados J, 2018, J ARTIF INTELL RES, V63, P743, DOI 10.1613/jair.1.11259
   Camacho-Collados J, 2016, ARTIF INTELL, V240, P36, DOI 10.1016/j.artint.2016.07.005
   Chronis G, 2020, P CONLL, V0, P0, DOI DOI 10.18653/V1/2020.CONLL-1.17
   Colla D, 2020, KNOWL-BASED SYST, V206, P0, DOI 10.1016/j.knosys.2020.106346
   Colla D, 2020, DATA BRIEF, V32, P0, DOI 10.1016/j.dib.2020.106267
   Colla D, 2020, COMPUT LINGUIST, V46, P289, DOI 10.1162/coli_a_0037
   Collobert R, 2007, P 45 ANN M ASS COMPU, V0, P560
   Collobert R, 2008, P 25 INT C MACH LEAR, V0, PP160, DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2018, ARXIV, V1, P4171
   Dodge Jesse, 2020, ARXIV200206305, V0, P0
   Dong, 2006, HOWNET COMPUTATION M, V0, P0
   Erk K, 2016, SEMANT PRAGMAT, V9, P0, DOI 10.3765/sp.9.17
   Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P55
   Firth JR, 1935, T PHILOL SOC, V34, P36, DOI https://doi.org/10.1111/j.1467-968X.1935.tb01254.x
   Flekova L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2029
   Goldberg Y, 2017, SYNTHESIS LECT HUMAN, V10, P1
   Guo CA, 2017, PR MACH LEARN RES, V70, P0
   Hamilton WL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1489
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Huang EH, 2012, ACL, V1, P873
   Huang LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3509
   Iacobacci I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P95
   Ide N, 2010, P ACL 2010 C SHORT P, V0, P68
   Kapanipathi P, 2020, AAAI CONF ARTIF INTE, V34, P8074
   Klein DE, 2001, J MEM LANG, V45, P259, DOI 10.1006/jmla.2001.2779
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Kuznetsov I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P171
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Levine Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4656
   Lewis M, 2020, P 58 ANN M ASS COMP, V0, P0
   Li J, 2015, P 2015 C EMP METH NA, V0, PP1722, DOI 10.18653/v1/D15-1200
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2829
   Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Loureiro D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3514
   Loureiro D, 2021, COMPUT LINGUIST, V47, P387, DOI 10.1162/coli_a_00405
   Loureiro D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5682
   Loureiro Daniel, 2019, P 5 WORKSH SEM DEEP, V0, P1
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Mancini M, 2017, P 21 C COMPUTATIONAL, V0, PP100, DOI 10.18653/V1/K17-1012
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, V0, PP51, DOI 10.18653/V1/K16-1006
   Merrill W, 2021, ARXIV210410809, V0, P0
   Meyer Christian M, 2012, WIKTIONARY NEW RIVAL, V0, P2
   Mickus Timothee, 2020, P SOC COMPUTATION LI, V0, P279
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Miller George A, 1994, HUMAN LANGUAGE TECHN, V0, P0
   Navigli R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P216
   Navigli R, 2009, ACM COMPUT SURV, V41, P0, DOI 10.1145/1459352.1459355
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, V0, PP1059, DOI 10.3115/V1/D14-1113
   Osgood Charles Egerton, 1957, MEASUREMENT MEANING, V0, P0
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Pasini T, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4936
   Pelevina M, 2016, P OF THE 1 WORKSHOP, V0, PP174, DOI 10.18653/v1/W16-1620
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pereira F, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-03068-4
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P43
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Piantadosi ST, 2012, COGNITION, V122, P280, DOI 10.1016/j.cognition.2011.10.004
   Pilehvar M T, 2016, P 2016 C EMPIRICAL M, V0, PP1680, DOI 10.18653/V1/D16-1174
   Pilehvar MT, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1267
   Pilehvar MT, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1857, DOI 10.18653/v1/P17-1170
   Radach R, 2017, J EYE MOVEMENT RES, V10, P0, DOI 10.16910/JEMR.10.6.1
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99
   Reif E, 2019, NEURIPS, V0, P0
   Reisinger J, 2010, HUMAN LANGUAGE TECHN, V0, P109
   Rodd JM, 2020, PERSPECT PSYCHOL SCI, V15, P411, DOI 10.1177/1745691619885860
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Salton G, 1971, RETRIEVAL RESULTS FU, V0, P0
   Scarlini B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3528
   Scarlini B, 2020, AAAI CONF ARTIF INTE, V34, P8758
   Schutze H, 1992, PROCEEDINGS. SUPERCOMPUTING 92. (CAT. NO.92CH3216-9), V0, PP787, DOI 10.1109/SUPERC.1992.236684
   Soler AG, 1900, P2021, V0, P0
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Tandon N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP115, DOI 10.18653/v1/P17-4020
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Tenney Ian, 2019, INT C LEARN REPR, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vial L, 2019, P 10 GLOB WORDNET C, V0, P108
   Vial L, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1027
   Voita E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4396
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5797
   Vu Thuy, 2016, P 2016 C N AM ASS CO, V0, P1262
   Vulic I, 2020, P 2020 C EMP METH NA, V0, P7222
   Wang A, 2019, ADV NEUR IN, V32, P0
   Wittgenstein L, 1953, PHILOSOPHICAL INVEST, V0, P0
   Wolf T, 1900, P38, V0, P0
   Yaghoobzadeh Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P236
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yarowsky D, 1995, P ACL, V0, PP189, DOI 10.3115/981658.981684
   Yuan D, 2016, PROC COLING, V0, P1374
   Zhou X, 1900, V2021, V0, P3143
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 124
TC 2
Z9 2
U1 3
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD APR 15
PY 2022
VL 305
IS 
BP 
EP 
DI 10.1016/j.artint.2022.103661
EA JAN 2022
PG 33
WC Computer Science, Artificial Intelligence
SC Computer Science
GA ZR3DG
UT WOS:000767667600001
DA 2023-11-10
ER

PT J
AU Liu, RB
   Jia, CY
   Wei, JS
   Xu, GX
   Vosoughi, S
AF Liu, Ruibo
   Jia, Chenyan
   Wei, Jason
   Xu, Guangxuan
   Vosoughi, Soroush
TI Quantifying and alleviating political bias in language models
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Bias in language models; Natural language generation; Political bias; Measuring bias; Mitigating bias
AB Current large-scale language models can be politically biased as a result of the data they are trained on, potentially causing serious problems when they are deployed in real-world settings. In this paper, we first describe metrics for measuring political bias in GPT-2 generation, and discuss several interesting takeaways: 1) The generation of vanilla GPT-2 model is mostly liberal-leaning, 2) Such political bias depends on the sensitive attributes mentioned in the context, and 3) Priming the generation with a explicit political identifier, the extent of political bias is imbalanced (between liberal and conservative). We then propose a reinforcement learning (RL) framework for mitigating such political biases in generated text: By using rewards from word embeddings or a classifier, our RL framework guides debiased generation without having access to the training data or requiring the model to be retrained. In empirical experiments on three attributes sensitive to political bias (gender, location, and topic), our methods reduced bias according to both our metrics and human evaluation, while maintaining readability and semantic coherence. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Ruibo; Vosoughi, Soroush] Dartmouth Coll, Hanover, NH 03755 USA.
   [Jia, Chenyan] Univ Texas Austin, Austin, TX 78712 USA.
   [Wei, Jason] Protago Labs, Baltimore, MD USA.
   [Xu, Guangxuan] Univ Calif Los Angeles, Los Angeles, CA USA.
C3 Dartmouth College; University of Texas System; University of Texas Austin; University of California System; University of California Los Angeles
RP Vosoughi, S (通讯作者)，Dartmouth Coll, Hanover, NH 03755 USA.
EM ruibo.liu.gr@dartmouth.edu; Soroush.Vosoughi@dartmouth.edu
CR AGARWAL A, 2019, P MACHINE LEARNING R, V97, P0
   [Anonymous], 2013, ICWSM, V0, P0
   Arpan LM, 2003, JOURNALISM MASS COMM, V80, P265, DOI 10.1177/107769900308000203
   Barikeri S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1941
   Bawden R, 2020, FINDINGS ASS COMPUTA, V0, P918
   Blodgett Su Lin, 2020, P 58 ANN M ASS COMPU, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.485
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bolukbasi T, 2016, NEURAL INFORM PROCES, V0, PP4349, DOI 10.5555/3157382
   Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P7
   Brown Tom B, 2020, ADV NEUR IN, V0, P0
   Chen HY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4834
   Chen ZW, 2020, CHIN CONT DECIS CONF, V0, PP314, DOI 10.1109/CCDC49329.2020.9164328
   Corbett-Davies S, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP797, DOI 10.1145/3097983.3098095
   DAlessio D, 2007, LEA COMMUN SER, V0, P103
   Dai N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5997
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Danks D, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4691
   Dathathri Sumanth, 2020, 8 INT C LEARN REPR I, V0, P0
   DEVKOTA P, 2018, P 2018 C EMP METH NA, V0, PP2799, DOI 10.18653/V1/D18-1302
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dinan E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8173
   Donini M, 2018, ADV NEUR IN, V31, P0
   Fan LS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6343
   Feldman L, 2011, POLIT BEHAV, V33, P407, DOI 10.1007/s11109-010-9139-4
   Flanagin AJ, 2000, JOURNALISM MASS COMM, V77, P515, DOI 10.1177/107769900007700304
   Freitag M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P61
   Garg N, 2018, P NATL ACAD SCI USA, V115, PE3635, DOI 10.1073/pnas.1720347115
   Goel N, 2018, AAAI CONF ARTIF INTE, V0, P3029
   Groeling T, 2013, ANNU REV POLIT SCI, V16, P129, DOI 10.1146/annurev-polisci-040811-115123
   Heafield K, 2011, P 6 WORKSH STAT MACH, V0, P187
   Hooker S, 2021, PATTERNS, V2, P0, DOI 10.1016/j.patter.2021.100241
   Huang C, 2018, P 2018 C N AM CHAPT, V2, P49, DOI 10.18653/V1/N18-2008
   Jia C, 2021, INT J COMMUN, V15, P22
   Jiang R, 2019, P MACHINE LEARNING R, V115, P862
   Jiang S, 2020, AAAI CONF ARTIF INTE, V34, P13669
   Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4
   Joseph K, 2017, P 2017 C EMP METH NA, V0, PP1115, DOI 10.18653/V1/D17-1116
   Kamiran F, 2012, KNOWL INF SYST, V33, P1, DOI 10.1007/s10115-011-0463-8
   Kamishima Toshihiro, 2012, MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES. PROCEEDINGS OF THE EUROPEAN CONFERENCE (ECML PKDD 2012), V0, PP35, DOI 10.1007/978-3-642-33486-3_3
   Kusner MJ, 2017, ADV NEURAL INFORM PR, V30, P4066
   Linardatos P, 2021, ENTROPY-SWITZ, V23, P0, DOI 10.3390/e23010018
   Liu R, 2021, P 15 INT AAAI C WEB, V0, P2021
   Liu R, 2021, FINDINGS ASS COMPUTA, V2021, P4332
   Liu R, 2021, P 59 ANN M ASS COMP, V2021, P6677
   Liu RB, 2021, AAAI CONF ARTIF INTE, V35, P14857
   Lucy L, 2021, P 3 WORKSH NARR UND, V0, P48
   Marlin Benjamin M, 2007, P 23 C UNC ART INT, V0, P267
   Maudslay RH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5267
   McSherry F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P627
   Mehrabi N, 2021, ACM COMPUT SURV, V54, P0, DOI 10.1145/3457607
   Metzger MJ, 2020, COMMUN RES, V47, P3, DOI 10.1177/0093650215613136
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Misra I, 2016, PROC CVPR IEEE, V0, PP2930, DOI 10.1109/CVPR.2016.320
   Mitchell M, 2019, FAT*19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, V0, P0
   Munos R, 2016, P 30 INT C NEUR INF, V0, P1054
   Munson SA, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1457
   Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1953
   Peng B, 2020, FINDINGS ASS COMPUTA, V0, P172
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Plank Barbara, 2014, P 14 C EUROPEAN CHAP, V0, P742
   Rabin J, 2012, LECT NOTES COMPUT SC, V6667, P435, DOI 10.1007/978-3-642-24785-9_37
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reif E, 2019, NEURIPS, V0, P0
   Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1668
   Sap Maarten, 2020, P 58 ANN M ASS COMP, V0, PP5477, DOI 10.18653/V1/2020.ACL-MAIN.486
   Sheng EM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4275
   Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3407
   Sheng Emily, 2020, ARXIV200500268, V0, P0, DOI DOI 10.18653/v1/2020.findings-emnlp.291
   Stanovsky G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1679
   Tufekci Z, 2014, ICWSM, V8, P505
   Vaswani A, 2017, ARXIV, V30, P5998
   Vidgen B, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1667
   Vig J, 2020, NEURIPS, V0, P0
   Vraga EK, 2009, NEWSPAPER RES J, V30, P68, DOI 10.1177/073953290903000406
   Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2153
   Wang XY, 2020, P CHIN MARK INT CONF, V0, P897
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Yang J, 2020, AAAI 20, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zemel Rich, 2013, ICML, V0, P0, DOI DOI 10.5555/3042817.3042973
   Zhang BH, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, V0, P0
   Zhang GH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4134
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
   Zhao H, 2020, 8 INT C LEARN REPR I, V0, P0
   Zhao H, 2019, ADV NEURAL INFORM PR, V0, P15649
   Zhao Jieyu, 2018, P 2018 C N AM CHAPT, V2, P0, DOI 10.18653/V1/N18-2003
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   ZHOU XZ, 2020, FINDINGS ASS COMPUTA, V0, PP65, DOI 10.5209/CLAC.71996
   Zhu J, 2020, ICLR, V0, P0
NR 99
TC 4
Z9 4
U1 9
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD MAR 15
PY 2022
VL 304
IS 
BP 
EP 
DI 10.1016/j.artint.2021.103654
EA JAN 2022
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA ZS0KB
UT WOS:000768161000005
DA 2023-11-10
ER

PT J
AU Ma, HC
   Wang, ZQ
   Zhou, XB
   Zhou, GD
   Zhou, QL
AF Ma, Hongchao
   Wang, Zhongqing
   Zhou, Xiabing
   Zhou, Guodong
   Zhou, Qinglei
TI Emotion Recognition with Conversational Generation Transfer
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Emotion recognition in conversation; conversational generation; transfer learning
AB Emotion recognition in conversation is one of the essential tasks of natural language processing. However, this task's annotation data is insufficient since such data is hard to collect and annotate. Meanwhile, there is large-scale data for conversational generation, and this data does not need annotation manually. But, whether the vector space between different datasets is similar will be a problem. Therefore, we utilize a same dataset to train the conversational generator and the classifier, and transfer knowledge between them. In particular, we propose an Emotion Recognition with Conversational Generation Transfer (ERCGT) framework to model the interaction among utterances by transfer learning. First, we train a conversational generator. In the second step, a transfer learning model is used to transfer the knowledge of generator to the emotion recognition model. Empirical studies illustrate the effectiveness of the proposed framework over several strong baselines on three benchmark emotion classification datasets.
C1 [Ma, Hongchao; Zhou, Qinglei] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
   [Wang, Zhongqing; Zhou, Xiabing; Zhou, Guodong] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
C3 Zhengzhou University; Soochow University - China
RP Zhou, QL (通讯作者)，Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
EM ma-hc@foxmail.com; wangzq@suda.edu.cn; zhouxiabing@suda.edu.cn; gdzhou@suda.edu.cn; ieqlzhou@zzu.edu.cn
FU National Key Research and Development Program of China [2016YFB0800100]; National Natural Science Foundation of China [61572444, 61972133, 61806137, 61702149, 61836007, 61702518]; Jiangsu High School Research Grant [18KJB520043]
CR Aguilar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P991
   [Anonymous], 2017, P 2017 C EMP METH NA, V0, P0, DOI DOI 10.18653/V1/D17-1169
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen SY, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1597
   Dahou A, 2016, P COLING 2016 26 INT, V0, P2418
   Danescu-Niculescu-Mizil C, 2011, P WORKSH COGN MOD CO, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dinan E, 2018, ARXIV181101241, V0, P0
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ghosal D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P154
   Gideon J, 2017, INTERSPEECH, V0, PP1098, DOI 10.21437/Interspeech.2017-1637
   Gu Yue, 2018, PROC CONF ASSOC COMPUT LINGUIST MEET, V2018, P2379
   Hazarika D, 2018, ASS COMPUTATIONAL LI, V0, PP2594, DOI 10.18653/v1/d18-1280
   Hazarika D, 2021, INFORM FUSION, V65, P1, DOI 10.1016/j.inffus.2020.06.005
   Hazarika Devamanyu, 2018, PROC CONF, V2018, P2122, DOI 10.18653/v1/n18-1193
   Huang Minlie, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Jia Wei, 2019, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 8TH CCF INTERNATIONAL CONFERENCE, V0, P0
   Jiao WX, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P397
   Li Qintong, 2020, P 28 INT C COMP LING, V0, PP4454, DOI 10.18653/V1/2020.COLING-MAIN.394
   Li Yanran, 2017, IJCNLP, V0, P0
   Lowe Ryan, 2015, P 16 ANN M SPECIAL I, V0, PP285, DOI 10.18653/v1/W15-4640
   Majumder N, 2019, AAAI CONF ARTIF INTE, V0, P6818
   Matsumoto S, 2005, LECT NOTES ARTIF INT, V3518, P301
   Morris MW, 2000, RES ORGAN BEHAV, V22, P1, DOI 10.1016/S0191-3085(00)22002-9
   OKeefe T, 2009, P 14 AUSTR DOC COMP, V0, P67
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Park Y, 2018, P 2018 C N AM CHAPT, V1, P1792, DOI 10.18653/V1/N18-1162
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P527
   Poria S, 2019, IEEE ACCESS, V7, P100943, DOI 10.1109/ACCESS.2019.2929050
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Sato, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Serban IV, 2017, AAAI CONF ARTIF INTE, V0, P3295
   Zhang CL, 2009, J AM SOC INF SCI TEC, V60, P2474, DOI 10.1002/asi.21206
   Zhang D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5415
   Zhou GY, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3344788
   Zhou H, 2018, AAAI CONF ARTIF INTE, V0, P730
NR 37
TC 0
Z9 0
U1 3
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL 15
PY 2022
VL 21
IS 4
BP 
EP 
DI 10.1145/3494532
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1L2VC
UT WOS:000799149600007
DA 2023-11-10
ER

PT J
AU Li, TY
   Precup, D
   Rabusseau, G
AF Li, Tianyu
   Precup, Doina
   Rabusseau, Guillaume
TI Connecting weighted automata, tensor networks and recurrent neural networks through spectral learning
SO MACHINE LEARNING
LA English
DT Article; Early Access
DE Weighted automata; Spectral learning; Recurrent neural networks; Tensor networks; Tensor train decomposition
ID finite-state automata; matrix recovery
AB In this paper, we present connections between three models used in different research fields: weighted finite automata (WFA) from formal languages and linguistics, recurrent neural networks used in machine learning, and tensor networks which encompasses a set of optimization techniques for high-order tensors used in quantum physics and numerical analysis. We first present an intrinsic relation between WFA and the tensor train decomposition, a particular form of tensor network. This relation allows us to exhibit a novel low rank structure of the Hankel matrix of a function computed by a WFA and to design an efficient spectral learning algorithm leveraging this structure to scale the algorithm up to very large Hankel matrices. We then unravel a fundamental connection between WFA and second-order recurrent neural networks (2-RNN): in the case of sequences of discrete symbols, WFA and 2-RNN with linear activation functions are expressively equivalent. Leveraging this equivalence result combined with the classical spectral learning algorithm for weighted automata, we introduce the first provable learning algorithm for linear 2-RNN defined over sequences of continuous input vectors. This algorithm relies on estimating low rank sub-blocks of the Hankel tensor, from which the parameters of a linear 2-RNN can be provably recovered. The performances of the proposed learning algorithm are assessed in a simulation study on both synthetic and real-world data.
C1 [Li, Tianyu] McGill Univ, Mila, Montreal, PQ, Canada.
   [Precup, Doina] McGill Univ, CCAI Chair Mila, Montreal, PQ, Canada.
   [Rabusseau, Guillaume] Univ Montreal, CCAI Chair Mila, Montreal, PQ, Canada.
   [Rabusseau, Guillaume] Univ Montreal, DIRO, Montreal, PQ, Canada.
C3 McGill University; McGill University; Universite de Montreal; Universite de Montreal
RP Rabusseau, G (通讯作者)，Univ Montreal, CCAI Chair Mila, Montreal, PQ, Canada.; Rabusseau, G (通讯作者)，Univ Montreal, DIRO, Montreal, PQ, Canada.
EM grabus@iro.umontreal.ca
FU Canadian Institute for Advanced Research (CIFAR AI chair program); Fonds de Recherche du Quebec-Nature et technologies [271273]
CR Angluin D, 1988, MACHINE LEARNING, V2, P319, DOI 10.1007/BF00116828
   [Anonymous], 2017, THESIS, V0, P0
   [Anonymous], 2011, GENERATING TEXT RECU, V0, P0
   Avcu E, 2017, P C LOG MACH LEARN N, V0, P20
   Ayache S, 2018, EXPLAINING BLACK BOX, V0, P81
   Bailly R, 2009, GRAMMATICAL INFERENC, V0, P33
   Balle B, 2012, SPECTRAL LEARNING GE, V0, P2159
   Balle B, 2014, MACH LEARN, V96, P33, DOI 10.1007/s10994-013-5416-x
   Biamonte J, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Boots B, 2011, INT J ROBOT RES, V30, P954, DOI 10.1177/0278364911404092
   Cai TT, 2015, ANN STAT, V43, P102, DOI 10.1214/14-AOS1267
   Candès EJ, 2011, IEEE T INFORM THEORY, V57, P2342, DOI 10.1109/TIT.2011.2111771
   Carlyl JW, 1971, JOURNAL OF COMPUTER AND SYSTEM SCIENCES, V5, P26, DOI 10.1016/S0022-0000(71)80005-3
   Caron R, 2005, WSMR REPORT, V0, P05
   Chen Y, 2018, RECURRENT NEURAL NET, V0, P2261
   Cichocki A, 2016, FOUND TRENDS MACH LE, V9, PI, DOI 10.1561/2200000059
   Cohen N, 2016, 29 ANN C LEARNING TH, V0, P698
   Critch A, 2013, THESIS U CALIFORNIA, V0, P0
   Critch A, 2014, SYMMETRY INTEGR GEOM, V10, P0, DOI 10.3842/SIGMA.2014.095
   Denis F, 2008, FUND INFORM, V86, P41
   Downey C, 2017, ADV NEURAL INFORM PR, V0, P6055
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Federer H, 2014, GEOMETRIC MEASURE TH, V0, P0
   FLIESS M, 1974, J MATH PURE APPL, V53, P197
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Giles CL, 1990, ADV NEURAL INFORM PR, V0, P380
   GILES CL, 1992, NEURAL COMPUT, V4, P393, DOI 10.1162/neco.1992.4.3.393
   Glaude H, 2016, PR MACH LEARN RES, V48, P0
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Han ZY, 2018, PHYS REV X, V8, P0, DOI 10.1103/PhysRevX.8.031012
   Hillar CJ, 2013, J ACM, V60, P0, DOI 10.1145/2512329
   Holtz S, 2012, SIAM J SCI COMPUT, V34, PA683, DOI 10.1137/100818893
   Hsu DJ, 2009, SPECTRAL ALGORITHM L, V0, P0
   Jain P, 2010, GUARANTEED RANK MINI, V0, P937
   Khrulkov V, 2018, EXPRESSIVE POWER REC, V0, P0
   Kingma DP, 2015, PROC ICLR 2015, V0, P0
   Klus S, 2018, NONLINEARITY, V31, P3359, DOI 10.1088/1361-6544/aabc8f
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   LEE YC, 1986, PHYSICA D, V22, P276, DOI 10.1016/0167-2789(86)90300-6
   Li T, 2018, NONLINEAR WEIGHTED F, V0, P679
   Lin Q, 2016, SHORT TERM TIME SERI, V0, P0
   Lubich C, 2013, SIAM J MATRIX ANAL A, V34, P470, DOI 10.1137/120885723
   Ma XD, 2019, ADV NEUR IN, V32, P0
   Merrill W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P443
   Mikolov T, 2011, INT CONF ACOUST SPEE, V0, P5528
   Novikov A, 2015, ADV NEUR IN, V28, P0
   Novikov A, 2014, PR MACH LEARN RES, V32, P811
   Omlin CW, 1996, J ACM, V43, P937, DOI 10.1145/235809.235811
   Orús R, 2014, ANN PHYS-NEW YORK, V349, P117, DOI 10.1016/j.aop.2014.06.013
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Peng H, 2018, RATIONAL RECURRENCES, V0, P1203
   Pollack JB, 1991, CONNECTIONIST APPROA, V0, P123
   Quattoni A, 2017, PR MACH LEARN RES, V54, P1477
   Rabusseau G, 2017, MULTITASK SPECTRAL L, V0, P2585
   Rabusseau G, 2016, THESIS AIX MARSEILLE, V0, P0
   Rabusseau G, 2019, PR MACH LEARN RES, V89, P0
   Rauhut H, 2017, LINEAR ALGEBRA APPL, V523, P220, DOI 10.1016/j.laa.2017.02.028
   Recasens A, 2013, SPECTRAL LEARNING SE, V0, P289
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Schmidt, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Schollwöck U, 2011, ANN PHYS-NEW YORK, V326, P96, DOI 10.1016/j.aop.2010.09.012
   Sedghi H, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Siegelmann HT, 1992, P 5 ANN WORKSH COMP, V0, PP440, DOI 10.1145/130385.130432
   Socher R, 2013, ADV NEURAL INFORM PR, V0, P926
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Stoudenmire EM, 2016, ADV NEUR IN, V29, P0
   Thon M, 2015, J MACH LEARN RES, V16, P103
   Tjandra A, 2017, IEEE IJCNN, V0, PP4451, DOI 10.1109/IJCNN.2017.7966420
   Wang WQ, 2017, IEEE I CONF COMP VIS, V0, PP5698, DOI 10.1109/ICCV.2017.607
   Weiss G, 2018, PR MACH LEARN RES, V80, P0
   Wu YH, 2016, ADV NEUR IN, V29, P0
   Yang YC, 2017, PR MACH LEARN RES, V70, P0
   Yu RC, 2017, IEEE I CONF COMP VIS, V0, PP1068, DOI 10.1109/ICCV.2017.121
NR 73
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1007/s10994-022-06164-1
EA MAR 2022
PG 35
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0E8CH
UT WOS:000776902200001
DA 2023-11-10
ER

PT J
AU Elazar, Y
   Basmov, V
   Goldberg, Y
   Tsarfaty, R
AF Elazar, Yanai
   Basmov, Victoria
   Goldberg, Yoav
   Tsarfaty, Reut
TI Text-based NP Enrichment
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID pragmatics; corpus
AB Understanding the relations between entities denoted by NPs in a text is a critical part of human-like natural language understanding. However, only a fraction of such relations is covered by standard NLP tasks and benchmarks nowadays. In this work, we propose a novel task termed text-based NP enrichment (TNE), in which we aim to enrich each NP in a text with all the preposition-mediated relations-either explicit or implicit-that hold between it and other NPs in the text. The relations are represented as triplets, each denoted by two NPs related via a preposition. Humans recover such relations seamlessly, while current state-of-the-art models struggle with them due to the implicit nature of the problem. We build the first large-scale dataset for the problem, provide the formal framing and scope of annotation, analyze the data, and report the results of fine-tuned language models on the task, demonstrating the challenge it poses to current technology. A webpage with a data-exploration UI, a demo, and links to the code, models, and leaderboard, to foster further research into this challenging problem can be found at: .
C1 [Elazar, Yanai; Basmov, Victoria; Goldberg, Yoav; Tsarfaty, Reut] Bar Ilan Univ, Allen Inst Artificial Intelligence, Comp Sci Dept, Ramat Gan, Israel.
C3 Bar Ilan University
RP Elazar, Y (通讯作者)，Bar Ilan Univ, Allen Inst Artificial Intelligence, Comp Sci Dept, Ramat Gan, Israel.
EM yanaiela@gmail.com; vikasaeta@gmail.com; yoav.goldberg@gmail.com; reut.tsarfaty@gmail.com
FU PBC fellowship; Google PhD fellowship; European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme [802774, 677352]
CR [Anonymous], 2010, SEMANTIC ROLE LABELI, V0, P0, DOI DOI 10.2200/S00239ED1V01Y200912HLT006
   [Anonymous], 2009, P WORKSHOP SEMANTIC, V0, P0, DOI DOI 10.3115/1621969.1621988
   [Anonymous], 2000, ZAS PAPERS LINGUISTI, V0, P0, DOI DOI 10.21248/ZASPIL.17.2000.46
   [Anonymous], 1995, 3 WORKSH VER LARG CO, V0, P0
   [Anonymous], 1983, COMPOSITIONALITY, V0, P0
   [Anonymous], 2016, ADV LANGUAGE LIT STU, V0, P0, DOI DOI 10.7575/AIAC.ALLS.V.7N.1P.175
   Barker Christian, 1995, DISSERTATIONS, V0, P189
   Carston R, 2009, INT REV PRAGMAT, V1, P35, DOI 10.1163/187731009X455839
   Cattan A, 2021, 10TH CONFERENCE ON LEXICAL AND COMPUTATIONAL SEMANTICS (SEM 2021), V0, P143
   Cheng Pengxiang, 2019, P AAAI C ARTIFICIAL, V33, P6284, DOI 10.1609/aaai.v33i01.33016284
   Choi E, 2021, T ASSOC COMPUT LING, V9, P447, DOI 10.1162/tacl_a_00377
   Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924
   Clark Herbert H, 1975, THEORETICAL ISSUES N, V0, P0, DOI DOI 10.3115/980190.980237
   de Bruin J, 1988, 26TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS. PROCEEDINGS OF THE CONFERENCE, V0, P25
   Dunietz Jesse, 2020, P 58 ANN M ASS COMP, V0, PP7839, DOI 10.18653/V1/2020.ACL-MAIN.701
   FitzGerald N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2051
   Frege Gottlob, 1960, TRANSLATIONS PHILOS, V0, P36
   Gardent Claire, 2003, P 4 INT WORKSHOP LIN, V0, P0
   GARDILL M, 2018, PROC IEEE 28 INTWORK, V0, PP1, DOI 10.18653/V1/W18-2501
   Gerber M, 2012, COMPUT LINGUIST, V38, P755, DOI 10.1162/COLI_a_00110
   Gessler Luke, 2021, SCIL, V0, P0
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Grishina Yulia, 2016, P WORKSHOP COREFEREN, V0, PP7, DOI 10.18653/v1/W16-0702
   Grishman R, 1996, P 16 C COMPUTATIONAL, V0, PP466, DOI 10.3115/992628.992709
   He Luheng, 2015, P 2015 C EMP METH NA, V0, PP643, DOI 10.18653/V1/D15-1076
   Honnibal Matthew, 2020, SPACY IND STRENGTH N, V0, P0
   Hou Y, 2013, P 2013 C N AM CHAPT, V0, P907
   Hou YF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1938
   Hou YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1428
   Hou YF, 2018, COMPUT LINGUIST, V44, P237, DOI 10.1162/COLI_a_00315
   Hou Yufang, 2013, P 2013 C EMPIRICAL M, V0, P814
   Hou Yufang, 2018, SHORT PAPERS, V2, P1, DOI 10.18653/v1/N18-2001
   Hou Yufang, 2014, P 2014 C EMPIRICAL M, V0, PP2082, DOI 10.3115/v1/D14-1222
   Hou Yufang, 2021, FINDINGS ASS COMPUTA, V0, PP1377, DOI 10.18653/v1/2021.findings-emnlp.119
   Hwang JD, 2016, P 10 LINGUISTIC ANNO, V0, P99
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kaushik D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5010
   Keith Katherine, 2017, PROC C EMPIRICAL MET, V0, P1547
   Kingma DP, 2014, C TRACK P, V0, P0
   Klein Ayal, 2020, P 28 INT C COMP LING, V0, P3069
   Kobayashi H, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P1652
   Lee Kenton, 2017, P 2017 C EMP METH NA, V0, PP188, DOI 10.18653/V1/D17-1018
   Lobner S, 2015, STUDIES LANGUAGE COG, V0, PP15, DOI 10.1515/9783110720129
   Lobner Sebastian, 1985, J SEMANT, V4, P279, DOI 10.1093/JOS/4.4.279
   Loebner Sebastian, 1998, APPROACHES DISCOURSE, V0, P0
   Markert K, 2012, P 50 ANN M ASS COMPU, V1, P795
   Martin JH, 2009, SPEECH LANGUAGE PROC, V0, P0
   Matsui T, 2001, LECT NOTES ARTIF INT, V2116, P248
   Meyers A, 2004, P LREC 2004, V0, P0
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Nedoluzhko A, 2013, P 7 LING ANN WORKSH, V0, P103
   Newell E, 2018, P 11 INT C LANGUAGE, V0, P0
   Pagel Janis, 2018, P 1 WORKSHOP COMPUTA, V0, PP50, DOI 10.18653/v1/W18-0706
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Pandit O, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P4153
   Poesio M, 1998, COMPUT LINGUIST, V24, P183
   Pradhan S, 2012, JOINT C EMNLP CONLL, V0, P1
   Pyatkin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2804
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Roesiger I, 2018, P 27 INT C COMPUTATI, V0, P3516
   Rösiger I, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P382
   Roesiger Ina, 2018, P 1 WORKSHOP COMPUTA, V0, PP44, DOI 10.18653/v1/W18-0705
   Roit P, 2020, P 58 ANN M ASS COMP, V0, PP7008, DOI 10.18653/V1/2020.ACL-MAIN.626
   Rosiger Ina, 2018, P 1 WORKSHOP COMPUTA, V0, PP23, DOI 10.18653/v1/W18-0703
   Ruppenhofer J, 2016, FRAMENET 2 EXTENDED, V0, P0
   Schneider N, 2015, P 9 LINGUISTIC ANNOT, V0, P112
   Schneider N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P185
   Tenney Ian, 2018, INT C LEARNING REPRE, V0, P0
   Uryupina O, 2020, NAT LANG ENG, V26, P95, DOI 10.1017/S1351324919000056
   Vilain M, 1995, P 6 MESSAGE UNDERSTA, V0, PP45, DOI 10.3115/1072399.1072405
   Weischedel Ralph, 2013, ONTONOTES RELEASE 50, V0, P0
NR 71
TC 1
Z9 1
U1 1
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD JUL 27
PY 2022
VL 10
IS 
BP 764
EP 784
DI 10.1162/tacl_a_00488
PG 21
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9KU
UT WOS:000923412600002
DA 2023-11-10
ER

PT J
AU Wang, Y
   Chew, AWZ
   Zhang, LM
AF Wang, Ying
   Chew, Alvin Wei Ze
   Zhang, Limao
TI Deep learning modeling of public's sentiments towards temporal evolution of COVID-19 transmission
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Text sentiment classification; Global sentiment evolution; COVID-19 transmission; Deep learning; Twitter data; Natural language processing
ID classification; prediction
AB Public sentiments towards global pandemics are important for public health assessment and disease control. This study develops a modularized deep learning framework to quantify public sentiments towards COVID-19, followed by leveraging the predicted sentiments to model and forecast the daily growth rate of confirmed COVID-19 cases globally, via a proposed G parameter. In the proposed framework, public sentiments are first modeled via a valence dimensional indicator, instead of discrete schemas, and are classified into 4 primary emotional categories: (a) neutral; (b) negative; (c) positive; (d) ambivalent, by using multiple word embedding models and classifiers for text sentiments analyses and classification. The trained model is subsequently applied to analyze large volumes (millions in quantity) of daily Tweets pertaining to COVID-19, ranging from 22 Jan 2020 to 10 May 2020. The results demonstrate that the global community gradually evokes both positive and negative sentiments towards COVID-19 over time compared to the dominant neural emotion at its inception. The predicted time-series sentiments are then leveraged to train a deep neural network (DNN) to model and forecast the G parameter by achieving the lowest possible mean absolute percentage error (MAPE) score of around 17.0% during the model's testing step with the optimal model configuration.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Chew, Alvin Wei Ze] Nanyang Technol Univ, Sch Civil & Environm Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Chew, Alvin Wei Ze] Bentley Syst Res Off, 1 Harbourfront Pl,HarbourFront Tower One, Singapore 098633, Singapore.
   [Zhang, Limao] Huazhong Univ Sci & Technol, Sch Civil & Hydraul Engn, 1037 Luoyu Rd, Wuhan 430074, Hubei, Peoples R China.
C3 Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Huazhong University of Science & Technology
RP Zhang, LM (通讯作者)，Huazhong Univ Sci & Technol, Sch Civil & Hydraul Engn, 1037 Luoyu Rd, Wuhan 430074, Hubei, Peoples R China.
EM ying006@e.ntu.edu.sg; Alvin.Chew@bentley.com; zlm@hust.edu.cn
FU SINGA scholarship; Microsoft Corporation [00011000272]
CR Alamoodi AH, 2021, EXPERT SYST APPL, V167, P0, DOI 10.1016/j.eswa.2020.114155
   Appel O, 2018, APPL INTELL, V48, P1176, DOI 10.1007/s10489-017-0966-4
   Azzaoui AEL, 2021, SUSTAIN CITIES SOC, V71, P0, DOI 10.1016/j.scs.2021.102993
   Bhapkar HR, 2020, J MED SYST, V44, P0, DOI 10.1007/s10916-020-01668-6
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Borra S, 2020, CURR PSYCHIAT RES RE, V16, P283, DOI 10.2174/2666082216999200917143247
   Briesemeister BB, 2012, SAGE OPEN, V2, P0, DOI 10.1177/2158244012466558
   Cahyani Denis Eka, 2021, 2021 INTERNATIONAL SEMINAR ON APPLICATION FOR TECHNOLOGY OF INFORMATION AND COMMUNICATION (ISEMANTIC), V0, PP87, DOI 10.1109/iSemantic52711.2021.9573243
   Cao Y, 2022, 2022 7 INT C CLOUD C, V0, PP139, DOI 10.1109/ICCCBDA55098.2022.9778873
   Centorrino P, 2021, J COMPUT SCI-NETH, V53, P0, DOI 10.1016/j.jocs.2021.101357
   Chakraborty K, 2020, APPL SOFT COMPUT, V97, P0, DOI 10.1016/j.asoc.2020.106754
   Chen BH, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), V0, PP854, DOI 10.1109/HPCC/SmartCity/DSS.2018.00142
   Chew AWZ, 2021, KNOWL-BASED SYST, V233, P0, DOI 10.1016/j.knosys.2021.107417
   Chew AWZ, 2021, SUSTAIN CITIES SOC, V75, P0, DOI 10.1016/j.scs.2021.103231
   Cho H, 2014, KNOWL-BASED SYST, V71, P61, DOI 10.1016/j.knosys.2014.06.001
   Dang Y, 2010, IEEE INTELL SYST, V25, P46, DOI 10.1109/MIS.2009.105
   Daulatkar Sonal, 2022, 2022 9TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), V0, PP460, DOI 10.23919/INDIACom54597.2022.9763272
   Desai PS, 2021, EXPERT SYST APPL, V180, P0, DOI 10.1016/j.eswa.2021.115104
   Dey N, 2020, DIGITAL GOV RES PRAC, V2, P1, DOI 10.1145/3428088
   Du YP, 2020, KNOWL-BASED SYST, V204, P0, DOI 10.1016/j.knosys.2020.106162
   Dwarampudi M, 2019, ARXIV, V0, P0
   El Akrouchi M, 2021, KNOWL-BASED SYST, V212, P0, DOI 10.1016/j.knosys.2020.106650
   Fong SJ, 2021, ARTIF INTELL, V0, P47
   Garcia K, 2021, APPL SOFT COMPUT, V101, P0, DOI 10.1016/j.asoc.2020.107057
   Go A, 2009, SENTIMENT CLASSIFICA, V0, P1
   Górska A, 2022, CITIES, V121, P0, DOI 10.1016/j.cities.2021.103453
   Gupta I, 2022, 2022 1 INT C INFORMA, V0, PP229, DOI 10.1109/ici53355.2022.9786887
   Gupta M, 2021, CMC-COMPUT MATER CON, V67, P933, DOI 10.32604/cmc.2021.014221
   Gupta M, 2021, APPL SOFT COMPUT, V101, P0, DOI 10.1016/j.asoc.2020.107039
   Gupta R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5109, DOI 10.1109/ICASSP.2018.8461414
   Gusterson H, 2020, SOC ANTHROPOL, V28, P275, DOI 10.1111/1469-8676.12880
   Hollis G, 2017, MEM COGNITION, V45, P1350, DOI 10.3758/s13421-017-0732-1
   Jones JH, 2020, AM J HUM BIOL, V32, P0, DOI 10.1002/ajhb.23512
   Khoo CSG, 2018, J INF SCI, V44, P491, DOI 10.1177/0165551517703514
   Lan ZR, 2019, IEEE T COGN DEV SYST, V11, P85, DOI 10.1109/TCDS.2018.2826840
   Leitch D, 2017, J COMPUT SCI-NETH, V21, P1, DOI 10.1016/j.jocs.2017.04.002
   Li B, 2021, SUSTAIN CITIES SOC, V66, P0, DOI 10.1016/j.scs.2020.102685
   Lopez C, 2020, COVID19 TWEETS DATAS, V0, P0
   Lwin May Oo, 2020, JMIR PUBLIC HEALTH SURVEILL, V6, Pe19447, DOI 10.2196/19447
   Machuca Cristian R, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1828, P0, DOI 10.1088/1742-6596/1828/1/012104
   Maiti A, 2021, SUSTAIN CITIES SOC, V68, P0, DOI 10.1016/j.scs.2021.102784
   Marathe A, 2021, P 2021 INT C COMMUNI, V0, P1
   Miglani A, 2020, CORONAVIRUS TWEETS N, V0, P0
   Montesclaros JMLP, 2020, CO20030 COVID 19 GLO, V0, P0
   Oberlander LAM, 2018, P 27 INT C COMP LING, V0, P2104
   Ogden RS, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0235871
   Ogie RI, 2022, INT J DISAST RISK RE, V70, P0, DOI 10.1016/j.ijdrr.2022.102783
   Pan Y, 2022, SUSTAIN CITIES SOC, V77, P0, DOI 10.1016/j.scs.2021.103508
   Pan Y, 2021, SUSTAIN CITIES SOC, V75, P0, DOI 10.1016/j.scs.2021.103254
   Pan Y, 2021, AUTOMAT CONSTR, V122, P0, DOI 10.1016/j.autcon.2020.103517
   Panagopoulos G, 2021, AAAI CONF ARTIF INTE, V35, P4838
   Qian W, 2021, J COMPUT SCI-NETH, V54, P0, DOI 10.1016/j.jocs.2021.101419
   Ranganathan S, 2020, J INDIAN I SCI, V100, P525, DOI 10.1007/s41745-020-00179-0
   Ren ZY, 2020, IEEE ACCESS, V8, P93464, DOI 10.1109/ACCESS.2020.2995211
   Roster K, 2022, CHAOS SOLITON FRACT, V161, P0, DOI 10.1016/j.chaos.2022.112306
   Sailunaz K, 2019, J COMPUT SCI-NETH, V36, P0, DOI 10.1016/j.jocs.2019.05.009
   Salathé M, 2011, PLOS COMPUT BIOL, V7, P0, DOI 10.1371/journal.pcbi.1002199
   Srivastava V, 2020, PERS UBIQUIT COMPUT, V0, P0, DOI DOI 10.1007/s00779-020-01462-8
   Tareq Alaa, 2021, 2021 INTERNATIONAL CONFERENCE ON DATA ANALYTICS FOR BUSINESS AND INDUSTRY (ICDABI), V0, PP245, DOI 10.1109/ICDABI53623.2021.9655932
   Wang J, 2022, INT J DISAST RISK RE, V67, P0, DOI 10.1016/j.ijdrr.2021.102693
   Wu GB, 2022, CITIES, V120, P0, DOI 10.1016/j.cities.2021.103490
   Xiang Y, 2021, INFECT DIS MODEL, V6, P324, DOI 10.1016/j.idm.2021.01.001
   Yang YX, 2022, INT J DISAST RISK RE, V70, P0, DOI 10.1016/j.ijdrr.2021.102762
   Yao ZR, 2021, CITIES, V116, P0, DOI 10.1016/j.cities.2021.103273
   Ye XY, 2021, CITIES, V109, P0, DOI 10.1016/j.cities.2020.103041
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yuan ZG, 2018, KNOWL-BASED SYST, V155, P1, DOI 10.1016/j.knosys.2018.05.004
   Yue CY, 2021, APPL INTELL, V51, P3174, DOI 10.1007/s10489-020-02021-7
   Zhang GW, 2021, AUTOMAT CONSTR, V128, P0, DOI 10.1016/j.autcon.2021.103764
   Zhang YF, 2020, IEEE ACCESS, V8, P70071, DOI 10.1109/ACCESS.2020.2986027
   Zhao FH, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), V0, PP57, DOI 10.1109/ITOEC49072.2020.9141701
   Zhao L, 2020, SOC BEHAV PERSONAL, V48, P0, DOI 10.2224/sbp.9829
   Zou XM, 2021, EXPERT SYST APPL, V169, P0, DOI 10.1016/j.eswa.2020.114322
NR 73
TC 0
Z9 0
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD DEC 15
PY 2022
VL 131
IS 
BP 
EP 
DI 10.1016/j.asoc.2022.109728
EA NOV 2022
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 6W0HM
UT WOS:000895417000002
PM 36281433
DA 2023-11-10
ER

PT J
AU Gérardin, C
   Wajsbürt, P
   Vaillant, P
   Bellamine, A
   Carrat, F
   Tannier, X
AF Gerardin, Christel
   Wajsburt, Perceval
   Vaillant, Pascal
   Bellamine, Ali
   Carrat, Fabrice
   Tannier, Xavier
TI Multilabel classification of medical concepts for patient clinical profile identification
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Biomedical concepts; Multilabel classification; NER; Transformers; Multilingual NLP
AB Background: The development of electronic health records has provided a large volume of unstructured biomedical information. Extracting patient characteristics from these data has become a major challenge, especially in languages other than English. Methods: Inspired by the French Text Mining Challenge (DEFT 2021) [1] in which we participated, our study proposes a multilabel classification of clinical narratives, allowing us to automatically extract the main features of a patient report. Our system is an end-to-end pipeline from raw text to labels with two main steps: named entity recognition and multilabel classification. Both steps are based on a neural network architecture based on transformers. To train our final classifier, we extended the dataset with all English and French Unified Medical Language System (UMLS) vocabularies related to human diseases. We focus our study on the multilingualism of training resources and models, with experiments combining French and English in different ways (multilingual embeddings or translation). Results: We obtained an overall average micro-F1 score of 0.811 for the multilingual version, 0.807 for the French-only version and 0.797 for the translated version. Conclusion: Our study proposes an original multilabel classification of French clinical notes for patient pheno-typing. We show that a multilingual algorithm trained on annotated real clinical notes and UMLS vocabularies leads to the best results.
C1 [Gerardin, Christel; Carrat, Fabrice] Sorbonne Univ, Inst Pierre Louis Epidemiol & Sante Publ, INSERM, 27 Rue Chaligny, F-75012 Paris, France.
   [Gerardin, Christel; Bellamine, Ali] Sorbonne Univ, AP HP, Dept Med Interne, Paris, France.
   [Wajsburt, Perceval; Tannier, Xavier] Sorbonne Univ, Univ Sorbonne Paris Nord, Lab Infomat Med & Ingn Connaissances Sante LIMICS, INSERM, F-75006 Paris, France.
   [Vaillant, Pascal] Sorbonne Univ, Univ Sorbonne Paris Nord, Lab Informat Med & Ingn Connaissances eSante LIMI, INSERM, F-93000 Bobigny, France.
   [Carrat, Fabrice] Sorbonne Univ, Hop St Antoine, AP HP, Publ Hlth Dept, Paris, France.
C3 Sorbonne Universite; Institut National de la Sante et de la Recherche Medicale (Inserm); Sorbonne Universite; Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Paul-Brousse - APHP; Universite Paris Cite; Hopital Universitaire Hotel-Dieu - APHP; Hopital Universitaire Cochin - APHP; Hopital Universitaire Saint-Louis - APHP; Institut National de la Sante et de la Recherche Medicale (Inserm); Sorbonne Universite; Sorbonne Universite; Institut National de la Sante et de la Recherche Medicale (Inserm); Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Paul-Brousse - APHP; Sorbonne Universite; Hopital Universitaire Saint-Antoine - APHP; Universite Paris Cite; Hopital Universitaire Hotel-Dieu - APHP; Hopital Universitaire Saint-Louis - APHP; Hopital Universitaire Cochin - APHP
RP Gérardin, C (通讯作者)，IPLESP, 27 Rue Chaligny, F-75012 Paris, France.
EM christel.ducroz-gerardin@iplesp.upmc.fr
CR Alsentzer E, 2019, ARXIV, V0, P0
   Anthony LFWolff, 2020, 950 WORKSHOP CHALLEN, V0, P0
   Bayer S, 2021, DRUG SAFETY, V44, P0, DOI 10.1007/s40264-020-00996-3
   Billami MB, 2021, ACTES 28E C TRAITEME, V0, P82
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, PD267, DOI 10.1093/nar/gkh061
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chen L, 2019, J AM MED INFORM ASSN, V26, P1218, DOI 10.1093/jamia/ocz109
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Feng JY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1478
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gehrmann S, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0192360
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Grouin C, 2021, ACT 28 C TRAIT AUT L, V0, P1
   Hamidi F, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), V0, P0, DOI DOI 10.1145/3173574.3173582
   Hiot N, 2021, TRAITEMENT AUTOMATIQ, V0, P41
   Jaeyoung K, 2017, ARXIV, V0, P0
   Kingma DP, 2015, PROC ICLR 2015, V0, P0
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lamy JB, 2015, STUD HEALTH TECHNOL, V210, P924, DOI 10.3233/978-1-61499-512-8-924
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Martin L, 2020, P 58 ANN M ASS COMP, V0, PP7203, DOI 10.18653/v1/2020.acl-main.645
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Miotto R, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep26094
   Névéol A, 2018, J BIOMED SEMANT, V9, P0, DOI 10.1186/s13326-018-0179-8
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P101
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Savova GK, 2010, J AM MED INFORM ASSN, V17, P507, DOI 10.1136/jamia.2009.001560
   Shang JY, 2019, ARXIV, V0, P0
   Soni S, 2020, AMIA ANN S P, V1150, P0
   Tiedemann Jorg, 2020, P 22 ANN C EUR ASS M, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wajsbürt P, 2021, J BIOMED INFORM, V114, P0, DOI 10.1016/j.jbi.2021.103684
   Weng WH, 2017, BMC MED INFORM DECIS, V17, P0, DOI 10.1186/s12911-017-0556-8
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yang Z, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-58178-1
   Yu J, 2020, P 58 ANN M ASS COMPU, V0, PP6470, DOI 10.18653/v1/2020.acl-main.577
   Zhang D, 2020, P 5 MACHINE LEARNING, V126, P566
NR 38
TC 3
Z9 3
U1 6
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JUN 15
PY 2022
VL 128
IS 
BP 
EP 
DI 10.1016/j.artmed.2022.102311
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA 7W2TX
UT WOS:000913368000001
PM 35534148
DA 2023-11-10
ER

PT J
AU Shi, SM
   Wu, X
   Su, RH
   Huang, HY
AF Shi, Shumin
   Wu, Xing
   Su, Rihai
   Huang, Heyan
TI Low-resource Neural Machine Translation: Methods and Trends
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Low-resource; neural machine translation; semi-supervised; unsupervised; transfer learning; pivot-based methods; data augmentation
ID network; zero
AB Neural Machine Translation (NMT) brings promising improvements in translation quality, but until recently, these models rely on large-scale parallel corpora. As such corpora only exist on a handful of language pairs, the translation performance is far from the desired effect in the majority of low-resource languages. Thus, developing low-resource language translation techniques is crucial and it has become a popular research field in neural machine translation. In this article, we make an overall review of existing deep learning techniques in low-resource NMT. We first show the research status as well as some widely used low-resource datasets. Then, we categorize the existing methods and show some representative works detailedly. Finally, we summarize the common characters among them and outline the future directions in this field.
C1 [Shi, Shumin; Wu, Xing; Su, Rihai; Huang, Heyan] Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing 100089, Peoples R China.
C3 Beijing Institute of Technology
RP Shi, SM (通讯作者)，Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing 100089, Peoples R China.
EM bjssm@bit.edu.cn; wuxing@bit.edu.cn; surihai@bit.edu.cn; hhy63@bit.edu.cn
FU National Natural Science Foundation of China [61671064, 61732005]
CR Artetxe M, 2020, ARXIV, V0, P0
   Artetxe M, 2018, ARXIV, V0, P0
   Artetxe M, 2019, ARXIV, V0, P0
   Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042
   Bahdanau D, 2016, ARXIV, V0, P0
   Banerjee Satanjeev, 2005, P ACL WORKSHOP INTRI, V0, PP65, DOI 10.3115/1626355.1626389
   Bertoldi N, 2009, P 4 WORKSHOP STAT MA, V0, P182
   Bojar O, 2011, P 6 WORKSHOP STAT MA, V0, P330
   Brown PF, 1993, COMPUTATIONAL LINGUISTICS, V19, P263
   Bugliarello E, 2020, ARXIV, V0, P0
   Carbonell J, 2006, P 7 C ASS MACH TRANS, V0, P19
   Caswell I, 2019, ARXIV, V0, P0
   Chen Y, 2017, ARXIV, V0, P0
   Chen Y, 2018, AAAI CONF ARTIF INTE, V0, P5086
   Cheng Y, 2019, JOINT TRAINING NEURA, V0, PP25, DOI 10.1007/978-981-32-9748-7_3
   Cheng Y, 2019, JOINT TRAINING NEURA, V0, PP41, DOI 10.1007/978-981-32-9748-7_4
   Chiang D, 2005, P 43 ANN M ASS COMP, V0, PP263, DOI 10.3115/1219840.1219873
   Chimalamarri S, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3390298
   Chronopoulou A, 2020, ARXIV, V0, P0
   Collins M, 2005, P 43 ANN M ASS COMP, V43, P531, DOI 10.3115/1219840.1219906
   Cotterell R, 2018, ARXIV, V0, P0
   Currey A, 2017, P 2 C MACH TRANSL, V0, PP148, DOI 10.18653/V1/W17-4715
   Currey A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P24
   Devlin J, 2019, ARXIV, V0, P0
   Dou Qing, 2012, P 2012 JOINT C EMP M, V0, P266
   Peters ME, 2018, ARXIV, V0, P0
   Edunov S, 2018, ARXIV, V0, P0
   El Kholy Ahmed, 2013, P 51 ANN M ASS COMPU, V2, P412
   Fadaee M, 2018, ARXIV, V0, P0
   Fadaee M, 2017, ARXIV, V0, P0
   Farajian MA, 2017, P 2 C MACHINE TRANSL, V0, P127
   Firat O, 2016, ARXIV, V0, P0
   Fujita A, 2020, P 58 ANN M ASS COMP, V0, PP5990, DOI 10.18653/V1/2020.ACL-MAIN.532
   Gal Y, 2016, ADV NEUR IN, V29, P0
   Ganin Y, 2017, ADV COMPUT VIS PATT, V0, PP189, DOI 10.1007/978-3-319-58347-1_10
   Gao F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5539
   Gibadullin Ilshat, 2019, ARXIV, V0, P0
   Gu JT, 2018, ARXIV, V0, P0
   Gu Jiatao, 2018, ARXIV, V0, P0
   Gulcehre C, 2015, ARXIV, V0, P0
   Guo JL, 2019, AAAI CONF ARTIF INTE, V0, P3723
   Guzman F, 2019, ARXIV, V0, P0
   He D, 2016, ADV NEUR IN, V29, P0
   Imankulova A, 2019, ARXIV, V0, P0
   Imankulova A, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3341726
   Irvine A, 2014, P 18 C COMPUTATIONAL, V0, P160
   Irvine A, 2016, NAT LANG ENG, V22, P517, DOI 10.1017/S1351324916000127
   Irvine Ann, 2013, P 8 WORKSHOP STAT MA, V0, P262
   Isozaki Hideki, 2010, P JOINT 5 WORKSHOP S, V0, P244
   Ji BJ, 2020, AAAI CONF ARTIF INTE, V34, P115
   Johnson Melvin, 2017, T ASSOC COMPUT LING, V0, PP339, DOI 10.1162/tacl_a_00065
   Karakanta A, 2018, MACH TRANSL, V32, P167, DOI 10.1007/s10590-017-9203-5
   Khayrallah H, 2020, ARXIV, V0, P0
   Kim Y, 2019, ARXIV, V0, P0
   Kim Y, 2019, ARXIV, V0, P0
   Kim Y, 2019, ARXIV, V0, P0
   Klementiev A, 2012, P 13 C EUR CHAPT ASS, V0, P130
   Kocmi T, 2018, ARXIV, V0, P0
   Koehn P, 2003, STAT PHRASE BASED TR, V0, P0
   Lample G, 2018, ARXIV, V0, P0
   Lample G, 2018, ARXIV, V0, P0
   Lee Jason, 2017, T ASSOC COMPUT LING, V5, P365, DOI 10.1162/tacl_a_00067
   Leng YC, 2019, ARXIV, V0, P0
   Li GL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5689
   Li RM, 2020, AAAI CONF ARTIF INTE, V34, P8245, DOI 10.1609/aaai.v34i05.6339
   Li Xiaoqing, 2016, ARXIV, V0, P0
   Liu D, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON MECHANICAL, V0, P39, DOI 10.1109/ICMCCE48743.2019.00017
   Liu ZH, 2021, ARXIV, V0, P0
   Luo GX, 2019, IEEE ACCESS, V7, P154157, DOI 10.1109/ACCESS.2019.2936002
   Luong MT, 2015, ARXIV, V0, P0
   Lakew SM, 2018, ARXIV, V0, P0
   Maimaiti M, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3464427
   Maimaiti M, 2019, ACM T ASIAN LOW-RESO, V18, P0, DOI 10.1145/3314945
   Nakayama H, 2017, MACH TRANSL, V31, P49, DOI 10.1007/s10590-017-9197-z
   Nguyen XP, 2020, ARXIV, V0, P0
   Pan BY, 2019, ARXIV, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Paul Michael, 2013, ACM TRANSACTIONS ON ASIAN LANGUAGE INFORMATION PROCESSING, V12, P0, DOI 10.1145/2505126
   Pham H, 2021, ARXIV, V0, P0
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, V0, PP392, DOI 10.1080/1472586x.2015.1113070.
   Pourdamghani N, 2019, ARXIV, V0, P0
   Pourdamghani Nima, 2017, P 2017 C EMP METH NA, V0, PP2513, DOI 10.18653/V1/D17-1266
   Nguyen TQ, 2017, ARXIV, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Ravi Sujith, 2011, P 49 ANN M ASS COMP, V0, P12
   Ren S, 2018, ARXIV, V0, P0
   Ren S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3498
   Ren Shuo, 2019, ARXIV, V0, P0
   Shavarani HS, 2021, ARXIV, V0, P0
   Sen S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3083
   Sennrich R, 2019, ARXIV, V0, P0
   Sennrich R, 2016, ARXIV, V0, P0
   Sennrich R, 2016, ARXIV, V0, P0
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, V0, P223
   Sun HP, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1235
   Sutskever I, 2014, ARXIV, V0, P0
   Vaswani A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1706.03762
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Hoang VCD, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, V0, P18
   Wang Rui, 2021, ARXIV, V0, P0
   Wang XY, 2018, ARXIV, V0, P0
   Wei HR, 2020, ARXIV, V0, P0
   Weng RX, 2019, ARXIV, V0, P0
   Weng RX, 2020, AAAI CONF ARTIF INTE, V34, P9266
   Wu JW, 2019, ARXIV, V0, P0
   Xia YC, 2016, ARXIV, V0, P0
   Xie Z, 2017, ARXIV, V0, P0
   Xu JT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1580
   Yang Z, 2018, ARXIV, V0, P0
   Zahabi ST, 2013, P 51 ANN M ASS COMPU, V0, P318
   Zhang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1959, DOI 10.18653/v1/P17-1179
   Zheng H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4251
   Zheng Zaixiang, 2019, P INT C LEARNING REP, V0, P0
   Zhou CT, 2019, ARXIV, V0, P0
   Zong, 2016, P 2016 C EMP METH NA, V0, PP1535, DOI 10.18653/V1/D16-1160
   Zoph B, 2016, ARXIV, V0, P0
NR 116
TC 0
Z9 0
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2022
VL 21
IS 5
BP 
EP 
DI 10.1145/3524300
PG 22
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9Z2DN
UT WOS:000950956700019
DA 2023-11-10
ER

PT J
AU Jang, M
   Kang, P
AF Jang, Myeongjun
   Kang, Pilsung
TI Sentence transition matrix: An efficient approach that preserves sentence semantics
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Sentence embedding; Sentence semantics; Transition matrix; Paraphrase; Natural language processing
AB Sentence embedding is an influential research topic in natural language processing (NLP). Generation of sentence vectors that reflect the intrinsic meaning of sentences is crucial for improving performance in various NLP tasks. Therefore, numerous supervised and unsupervised sentence-representation approaches have been proposed since the advent of the distributed representation of words. These approaches have been evaluated on semantic textual similarity (STS) tasks designed to measure the degree of semantic information preservation; neural network-based supervised embedding models typically deliver state-of-the-art performance. However, these models have limitations in that they have numerous learnable parameters and thus require large amounts of specific types of labeled training data. Pretrained language modelbased approaches, which have become a predominant trend in the NLP field, alleviate this issue to some extent; however, it is still necessary to collect sufficient labeled data for the fine-tuning process is still necessary. Herein, we propose an efficient approach that learns a transition matrix tuning a sentence embedding vector to capture the latent semantic meaning. Our proposed method has two practical advantages: (1) it can be applied to any sentence embedding method, and (2) it can deliver robust performance in STS tasks with only a few training examples.
C1 [Jang, Myeongjun] Univ Oxford, Dept Comp Sci, Oxford, England.
   [Kang, Pilsung] Korea Univ, Sch Ind Management Engn, Seoul, South Korea.
C3 University of Oxford; Korea University
RP Kang, P (通讯作者)，Korea Univ, Sch Ind Management Engn, Seoul, South Korea.
EM myeongjun.jang@cs.ox.ac.uk; pilsung_kang@korea.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT) [NRF-2019R1F1A1060338]; Korea Institute for Advancement of Technology (KIAT) - Korea Government (MOTIE) [P0008691]
CR Agirre E, 2016, P 10 INT WORKSH SEM, V0, PP497, DOI 10.18653/V1/S16-1081
   Agirre E, 2013, P 2 JOINT C LEX COMP, V1, P32
   Agirre E, 2012, P 6 INT WORKSHOP SEM, V0, P385
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Arora S, 2017, ICLR, V0, P0
   Artetxe Mikel, 2017, 6 INT C LEARN REPR I, V0, P0
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P169
   Clark Kevin, 2020, ICLR, V0, P0
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2018, ARXIV, V1, P4171
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   Gupta A, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Hill Felix, 2016, P NAACL HLT, V0, PP1367, DOI 10.18653/V1/N16-1162
   Hu BT, 2014, ADV NEUR IN, V27, P0
   Jang M, 2020, INFORM SCIENCES, V541, P123, DOI 10.1016/j.ins.2020.05.129
   Kenter T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P941
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Koch Gregory, 2015, P INT C MACH LEARN W, V2, P0, DOI 10.1136/BMJ.2.5108.1355-C
   Lample G, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Lample Guillaume, 2017, ARXIV171100043, V0, P0
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Le Q, 2014, INT C MACHINE LEARNI, V32, P0, DOI 10.1145/2740908.2742760
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Maas Andrew, 2011, ACL, V1, P7, DOI 10.5555/2002472.2002491
   Marelli M, 2014, P 8 INT WORKSH SEM E, V0, PP1, DOI 10.3115/v1/S14-2001
   Mihalcea Rada, 2015, P 9 INT WORKSH SEM E, V0, P0, DOI DOI 10.18653/V1/S15-2045
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Pham NT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P971
   Pagliardini Matteo, 2017, ARXIV170302507, V0, P0, DOI DOI 10.18653/V1/N18-1049
   Pang B, 2005, P ACL, V0, PP115, DOI 10.3115/1219840.1219855
   Pearson K, 1985, P R SOC LOND, V58, P240, DOI 10.1098/RSPL.1895.0041
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Prakash A, 2016, ARXIV161003098, V0, P2923
   Smith SL, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Sun Y, 2019, ENHANCED REPRESENTAT, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wada T, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Wan SX, 2016, AAAI CONF ARTIF INTE, V0, P2835
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wiebe J, 2014, P 8 INT WORKSH SEM E, V0, PP81, DOI 10.3115/v1/S14-2010
   Wieting J, 2015, ARXIV151108198, V0, P0
   Wu Y, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Xu R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhu YK, 2015, IEEE I CONF COMP VIS, V0, PP19, DOI 10.1109/ICCV.2015.11
NR 53
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN 15
PY 2022
VL 71
IS 
BP 
EP 
DI 10.1016/j.csl.2021.101266
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA ZI4NN
UT WOS:000761599000004
DA 2023-11-10
ER

PT J
AU Zaib, M
   Zhang, WE
   Sheng, QZ
   Mahmood, A
   Zhang, Y
AF Zaib, Munazza
   Zhang, Wei Emma
   Sheng, Quan Z.
   Mahmood, Adnan
   Zhang, Yang
TI Conversational question answering: a survey
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Question answering; Conversational agents; Conversational machine reading comprehension; Knowledge base; Conversational AI
ID systems; network
AB Question answering (QA) systems provide a way of querying the information available in various formats including, but not limited to, unstructured and structured data in natural languages. It constitutes a considerable part of conversational artificial intelligence (AI) which has led to the introduction of a special research topic on conversational question answering (CQA), wherein a system is required to understand the given context and then engages in multi-turn QA to satisfy a user's information needs. While the focus of most of the existing research work is subjected to single-turn QA, the field of multi-turn QA has recently grasped attention and prominence owing to the availability of large-scale, multi-turn QA datasets and the development of pre-trained language models. With a good amount of models and research papers adding to the literature every year recently, there is a dire need of arranging and presenting the related work in a unified manner to streamline future research. This survey is an effort to present a comprehensive review of the state-of-the-art research trends of CQA primarily based on reviewed papers over the recent years. Our findings show that there has been a trend shift from single-turn to multi-turn QA which empowers the field of Conversational AI from different perspectives. This survey is intended to provide an epitome for the research community with the hope of laying a strong foundation for the field of CQA.
C1 [Zaib, Munazza; Sheng, Quan Z.; Mahmood, Adnan; Zhang, Yang] Macquarie Univ, Fac Sci & Engn, Sch Comp, Sydney, NSW 2109, Australia.
   [Zhang, Wei Emma] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
C3 Macquarie University; University of Adelaide
RP Zaib, M; Sheng, QZ (通讯作者)，Macquarie Univ, Fac Sci & Engn, Sch Comp, Sydney, NSW 2109, Australia.
EM munazza-zaib@hdr.mq.edu.au; michael.sheng@mq.edu.au
FU Macquarie University, Sydney, Australia [20201589]; Australian Research Council (ARC) [DP200102298]; Australian Research Council [DP200102298] Funding Source: Australian Research Council
CR Bahdanau D, 2016, ARXIV, V0, P0
   Bao Junwei, 2016, P COLING 2016 26 INT, V0, P2503
   Beaver I, 2020, AAAI CONF ARTIF INTE, V34, P2602
   Bhutani N, 2020, FIRST WORKSHOP ON NATURAL LANGUAGE INTERFACES, V0, P1
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4762
   Bouziane A, 2015, PROCEDIA COMPUT SCI, V73, P366, DOI 10.1016/j.procs.2015.12.005
   Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5016
   Cascante-Bonilla P, 2019, ARXIV, V0, P0
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chen Qu, 2021, ADVANCES IN INFORMATION RETRIEVAL. 43RD EUROPEAN CONFERENCE ON IR RESEARCH, V0, P529, DOI 10.1007/978-3-030-72113-8_35
   Chen Y, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1230
   CHENG J, 2019, COMPUT LINGUIST, V0, P0
   Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2174
   Christmann P, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP729, DOI 10.1145/3357384.3358016
   Chung Junyoung, 2014, NIPS 2014 WORKSH DEE, V0, P0
   Cui L, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP97, DOI 10.18653/v1/P17-4017
   Cui WY, 2017, PROC VLDB ENDOW, V10, P565, DOI 10.14778/3055540.3055549
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhingra B, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P484, DOI 10.18653/v1/P17-1045
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Fu Bin, 2020, ARXIV, V0, P0
   Gao JF, 2019, FOUND TRENDS INF RET, V13, P127, DOI 10.1561/1500000074
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Guo D, 2018, ADV NEURAL INFORM PR, V0, P2946
   Gupta S, 2020, P 28 INT C COMPUTATI, V0, P2739
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Hewlett D, 2017, P 2017 C EMPIRICALME, V0, PP2011, DOI 10.18653/V1/D17-1214
   Higashinaka R, 2008, P IJCNLP, V0, P01
   Huang Hsin-Yuan, 2019, P INT C LEARN REPR, V0, P0
   Huang LF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2391
   Iyyer M, 2014, EMNLP, V0, PP633, DOI 10.3115/V1/D14-1070
   Iyyer M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1821, DOI 10.18653/v1/P17-1167
   Jiang K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P318
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   KACUPAJ E, 1900, P850, V0, P0
   Kocisk T, 2018, T ASSOC COMPUT LING, V0, P0
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2829
   Liu SS, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9183698
   Liu SS, 2019, IEEE ACCESS, V7, P27736, DOI 10.1109/ACCESS.2019.2901547
   Lu XL, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP105, DOI 10.1145/3331184.3331252
   Luong T, 2015, P C EMPIRICAL METHOD, V0, PP1412, DOI 10.18653/V1/D15-1166
   Lv SW, 2020, AAAI CONF ARTIF INTE, V34, P8449
   Martinez-Gil J, 2015, COMPUT SCI REV, V18, P1, DOI 10.1016/j.cosrev.2015.09.001
   McCann Bryan, 2017, ADV NEURAL INFORM PR, V0, P6297
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Miller Alexander, 2016, ARXIV160603126, V0, P0
   Miller Alexander, 2017, PROC C EMPIRICAL MET, V0, PP79, DOI 10.18653/v1/D17-2014
   Mishra A, 2016, J KING SAUD UNIV-COM, V28, P345, DOI 10.1016/j.jksuci.2014.10.007
   Mitchell T, 2018, COMMUN ACM, V61, P103, DOI 10.1145/3191513
   Monz C, 2011, NAT LANG ENG, V17, P425, DOI 10.1017/S1351324910000276
   Müller T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5902
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Nguyen T, 2016, P INT MICR VEH COMP, V0, PP1, DOI 10.13031/AIM.20162444593
   Ohsugi Y, 2019, NLP FOR CONVERSATIONAL AI, V0, P11
   Ostermann S, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3567
   Pasupat P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1470
   Peng B, 2020, FINDINGS ASS COMPUTA, V0, P172
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pinto D, 2002, JCDL 2002. PROCEEDINGS OF THE SECOND ACM/IEEE-CS JOINT CONFERENCE ON DIGITAL LIBRARIES, V0, PP46, DOI 10.1145/544220.544228
   Plepi J, 2021, LECT NOTES COMPUT SC, V12731, P356, DOI 10.1007/978-3-030-77385-4_21
   Qi P, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2590
   Qiu MH, 2021, AAAI CONF ARTIF INTE, V35, P13718
   Qu C, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP539, DOI 10.1145/3397271.3401110
   Qu C, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP1391, DOI 10.1145/3357384.3357905
   Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1133, DOI 10.1145/3331184.3331341
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4932
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Ren LL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2780
   Richardson M, 2013, P 2013 C EMPIRICAL M, V0, P193
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saeidi M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2087
   Saha A, 2018, AAAI CONF ARTIF INTE, V0, P705
   Sap M, 2019, AAAI CONF ARTIF INTE, V0, P3027
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Seo Min Joon, 2017, ICLR, V0, P0
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Sharma A, 2019, AAAI CONF ARTIF INTE, V0, P1360
   Shen D, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Shen T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2442
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Suhr A, 2018, P C N AM CHAPTER ASS, V0, P2238
   Sun R, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP1405, DOI 10.1145/3340531.3411947
   Suster S, 2018, P NAACL HLT, V1, P1551, DOI 10.18653/V1/N18-1140
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Tian ZL, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P231, DOI 10.18653/v1/P17-2036
   Trischler Adam, 2017, P 2 WORKSH REPR LEAR, V0, PP191, DOI 10.18653/V1/W17-2623
   Trivedi P, 2017, LECT NOTES COMPUT SC, V10588, P210, DOI 10.1007/978-3-319-68204-4_22
   Vaswani A, 2017, ARXIV, V30, P5998
   Velickovic P, 2018, P ICLR, V0, P0
   Vinyals O, 2015, P ADV NEURAL INFORM, V0, PP2692, DOI 10.48550/arxiv.1506.03134
   Wang H, 2018, P 27 INT C COMP LING, V0, P1941
   Welbl J, 2017, P 3 WORKSHOP NOISY U, V0, PP94, DOI 10.18653/v1/W17-4413
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   Wu J, 2015, IEEE-ACM T AUDIO SPE, V23, P2026, DOI 10.1109/TASLP.2015.2462712
   Wu Y, 2016, ARXIV, V0, P0
   Xiong Wenhan, 2021, INT C LEARNING REPRE, V0, P0
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, PP2013, DOI 10.18653/V1/D15-1237
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yatskar M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2318
   Yeh Y, 2019, P 2 WORKSH MACH READ, V0, PP86, DOI 10.18653/V1/D19-5812
   Zaib M, 2021, PARALLEL ARCHITECTUR, V0, PP47, DOI 10.1007/978-981-16-0010-4_5
   Zaib M, 2020, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2020), V0, P0, DOI DOI 10.1145/3373017.3373028
   Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P93
   Zhang YF, 2018, CIKM18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP177, DOI 10.1145/3269206.3271776
   Zhong WJ, 2019, LECT NOTES ARTIF INT, V11838, P16, DOI 10.1007/978-3-030-32233-5_2
   Zhu C, 2018, ARXIV, V0, P0
   Zhu CG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1261
   Zou XH, 2020, J PHYS CONF SER, V1487, P0, DOI 10.1088/1742-6596/1487/1/012016
NR 119
TC 4
Z9 4
U1 7
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD DEC 15
PY 2022
VL 64
IS 12
BP 3151
EP 3195
DI 10.1007/s10115-022-01744-y
EA SEP 2022
PG 45
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 5M4QB
UT WOS:000850403300002
DA 2023-11-10
ER

PT J
AU Sun, JT
   Zhang, QY
AF Sun, Jing-Tao
   Zhang, Qiu-Yu
TI Product typicality attribute mining method based on a topic clustering ensemble
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Article
DE LDA models; Integrated learning; Non-negative matrix factorization; Mean-shift algorithm
ID fusion; find
AB Despite the extensive application of topic models in natural language processing tasks in recent years, the Chinese texts of short comments characterised by large scale, high noise and small information points have put forward higher requirements for the accuracy and stability of the results, which fails to be satisfied by existing topic models. In this paper, a product typicality attribute mining method based on a topic clustering ensemble was proposed. By introducing multiple topic models into ensemble learning, the problems of semantic representation loss, clustering inefficiency and lack of interpretability in the mining of product typicality attributes of short comment texts should be solved. By an effective combination of the topic clustering algorithm based on the diversity of speech, the topic clustering ensemble algorithm based on the Non-negative matrix factorization, and the interpretation method of product typicality attributes based on the mean-shift algorithm, an unsupervised model of product typicality attribute mining for short comment texts is constructed. As shown by the experimental results, the modelling method assumes favourable performance in topic clustering and feature selection, suggesting its advantages in product typicality attribute identification and interpretability compared with common methods.
C1 [Sun, Jing-Tao] Xian Univ Posts & Telecommun, Sch Comp Sci & Technol, Xian 710121, Shaanxi, Peoples R China.
   [Sun, Jing-Tao] Xian Univ Posts & Telecommun, Shaanxi Key Lab Network Data Anal & Intelligent P, Xian 710121, Shaanxi, Peoples R China.
   [Sun, Jing-Tao] Xian Key Lab Big Data & Intelligent Comp, Xian 710121, Shaanxi, Peoples R China.
   [Zhang, Qiu-Yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Gansu, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of Posts & Telecommunications; Lanzhou University of Technology
RP Sun, JT (通讯作者)，Xian Univ Posts & Telecommun, Sch Comp Sci & Technol, Xian 710121, Shaanxi, Peoples R China.; Sun, JT (通讯作者)，Xian Univ Posts & Telecommun, Shaanxi Key Lab Network Data Anal & Intelligent P, Xian 710121, Shaanxi, Peoples R China.; Sun, JT (通讯作者)，Xian Key Lab Big Data & Intelligent Comp, Xian 710121, Shaanxi, Peoples R China.
EM sun2651@qq.com
FU Science and Technology Project in Shaanxi Province of China [2021KW-16]; special fund construction project of key disciplines in ordinary colleges and universities in Shaanxi Province
CR Ammour N, 2015, SIGNAL IMAGE VIDEO P, V9, P727, DOI 10.1007/s11760-013-0499-1
   Bai L, 2020, INFORM FUSION, V61, P36, DOI 10.1016/j.inffus.2020.03.009
   Banerjee B, 2015, IEEE GEOSCI REMOTE S, V12, P741, DOI 10.1109/LGRS.2014.2360833
   Berikov VB, 2018, PATTERN RECOGNITION AND IMAGE ANALYSIS, V28, P1, DOI 10.1134/S1054661818010029
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Buenaño-Fernandez D, 2020, IEEE ACCESS, V8, P35318, DOI 10.1109/ACCESS.2020.2974983
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   Hou TJ, 2019, EXPERT SYST APPL, V132, P141, DOI 10.1016/j.eswa.2019.04.069
   Hu Zhong-kai, 2013, JOURNAL OF ZHEJIANG UNIVERSITY. ENGINEERING SCIENCE, V47, P1475, DOI 10.3785/j.issn.1008-973X.2013.08.023
   Huang D, 2018, IEEE T CYBERNETICS, V48, P1460, DOI 10.1109/TCYB.2017.2702343
   Jiang D, 2021, IEEE ACCESS, V9, P22253, DOI 10.1109/ACCESS.2021.3055433
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li FJ, 2019, ARTIF INTELL, V273, P37, DOI 10.1016/j.artint.2018.12.007
   Lin ZJ, 2017, 2017 32ND YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), V0, PP1194, DOI 10.1109/YAC.2017.7967594
   Liu HF, 2018, DATA MIN KNOWL DISC, V32, P385, DOI 10.1007/s10618-017-0539-5
   Ma Bai-zhang, 2014, COMPUTER INTEGRATED MANUFACTURING SYSTEMS, V20, P96
   Mojarad M, 2019, INT J UNCERTAIN FUZZ, V27, P97, DOI 10.1142/S0218488519500053
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nikolenko S, 2015, LECT NOTES ARTIF INT, V9414, P67, DOI 10.1007/978-3-319-27101-9_5
   Nilashi M, 2017, COMPUT IND ENG, V109, P357, DOI 10.1016/j.cie.2017.05.016
   Poria S, 2016, IEEE IJCNN, V0, PP4465, DOI 10.1109/IJCNN.2016.7727784
   Qiao ZL, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, V0, P1821
   Rathore P, 2018, IEEE T FUZZY SYST, V26, P1510, DOI 10.1109/TFUZZ.2017.2729501
   Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Wahyudi E, 2019, 3 INT C INFORMATICS, V0, P1
   [王连喜 Wang Lianxi], 2015, 计算机应用研究 APPLICATION RESEARCH OF COMPUTERS, V32, P1305
   Wang T, 2019, J CHONGQING TECHNOLO, V36, P9
   Wang XH, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS), V0, PP35, DOI 10.1109/ICSRS.2018.00015
   Wang X, 2019, IEICE T INF SYST, VE102D, P2148, DOI 10.1587/transinf.2018EDP7243
   Wong W, 2020, METHODSX, V7, P0, DOI 10.1016/j.mex.2020.100916
   Xiao WC, 2016, NEUROCOMPUTING, V173, P1362, DOI 10.1016/j.neucom.2015.09.009
   [徐峻岭 Xu Junling], 2012, 计算机研究与发展 JOURNAL OF COMPUTER RESEARCH AND DEVELOPMENT, V49, P372
   Yang WL, 2021, KNOWL-BASED SYST, V231, P0, DOI 10.1016/j.knosys.2021.107457
   Yi SY, 2020, IEEE T NEUR NET LEAR, V31, P2153, DOI 10.1109/TNNLS.2019.2928755
   Yildirim P, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), V0, PP639, DOI 10.1109/UBMK.2017.8093487
   [游丽平 You Liping], 2019, 小型微型计算机系统 JOURNAL OF CHINESE COMPUTER SYSTEMS, V40, P236
   Yousefnezhad M, 2018, IEEE T CYBERNETICS, V48, P486, DOI 10.1109/TCYB.2016.2642999
   Zhou J, 2019, NEUROCOMPUTING, V357, P66, DOI 10.1016/j.neucom.2019.04.078
   Zhou P, 2022, INFORM FUSION, V78, P171, DOI 10.1016/j.inffus.2021.09.003
   Zhou P, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P4112
NR 41
TC 1
Z9 1
U1 12
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
EI 1573-7462
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD DEC 15
PY 2022
VL 55
IS 8
BP 6629
EP 6654
DI 10.1007/s10462-022-10163-y
EA MAR 2022
PG 26
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5V1ZW
UT WOS:000768645700001
DA 2023-11-10
ER

PT J
AU Ahn, S
   Yi, H
   Bae, H
   Yoon, S
   Paek, Y
AF Ahn, Sunwoo
   Yi, Hayoon
   Bae, Ho
   Yoon, Sungroh
   Paek, Yunheung
TI Data Embedding Scheme for Efficient Program Behavior Modeling With Neural Networks
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
LA English
DT Article
DE Data models; Runtime; Computational modeling; Analytical models; Neural networks; Codes; Adaptation models; Artificial neural network; deep learning; feature embedding; natural language processing; program behavior modeling
AB As modern programs grow in size and complexity, the importance of program behavior modeling is emerging in various areas. Because of the large amount of data generated by a target program and the difficulty of runtime analysis, previous works in these areas employ deep learning. However, they did not sufficiently consider the input of a target program, since, in our view, program behavior is a history of computational steps consisting of a function and its input arguments. A naive, intuitive way to embed the value of $x$ as it is in a vector representation creates a tremendously large vector size. Instead, we found that all the values inducing the same runtime behavior can be represented as one identical characteristic value (CV). In this paper, we show that not only can a characteristic value sequence replace the argument input, but it is also efficient to use it as an input vector for a neural network. This efficiency comes from modeling the whole program with multiple LSTM-RNN models and reducing the input space of the neural network. To demonstrate the effectiveness of this replacement, we performed experiments on the problem of program behavior anomaly detection. Our results show that our model achieves better detection performance compared to previous models and similar detection performance even with smaller model sizes. We also provide a visualization of the embedded vectors extracted from the embedding layer in the neural network model to prove that the CV sequence well represents the arguments.
C1 [Ahn, Sunwoo; Yi, Hayoon; Yoon, Sungroh; Paek, Yunheung] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 08826, South Korea.
   [Ahn, Sunwoo; Yi, Hayoon; Paek, Yunheung] Seoul Natl Univ, Interuniv Semicond Res Ctr, Seoul 08826, South Korea.
   [Bae, Ho] Ewha Womans Univ, Dept Cyber Secur, Seoul 03760, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU); Ewha Womans University
RP Yoon, S; Paek, Y (通讯作者)，Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 08826, South Korea.
EM swahn@sor.snu.ac.kr; hyyi@sor.snu.ac.kr; hobae@ewha.ac.kr; sry-oon@snu.ac.kr; ypaek@snu.ac.kr
FU BK21 FOUR Program of the Education and Research Program for Future ICT Pioneers, Seoul National University in 2021; Institute of Information and communications Technology Planning and Evaluation (IITP) - Korea government (MSIT) [2021-0-01343, 2020-0-01840, 2021-0-02068]; National Research Foundation of Korea (NRF) - Korea government (MSIT) [NRF-2020R1A2B5B03095204, NRF-2018R1A2B3001628]; Ewha Womans University; Inter-University Semiconductor Research Center, Seoul National University
CR [Anonymous], 2016, LSTM BASED SYSTEM CA, V0, P0
   Cheng LH, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON GRAPHICS AND SIGNAL PROCESSING (ICGSP 2018), V0, PP109, DOI 10.1145/3282286.3282306
   Costa G, 2010, LECT NOTES COMPUT SC, V6186, P41, DOI 10.1007/978-3-642-16074-5_4
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Ding SHH, 2019, P IEEE S SECUR PRIV, V0, PP472, DOI 10.1109/SP.2019.00003
   Du M, 2017, CCS17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, V0, PP1285, DOI 10.1145/3133956.3134015
   Free software foundation, 2020, GNU SCREEN, V0, P0
   Golunski D, 2016, CVE 2016 6664 MYSQL, V0, P0
   Golunski D, 2016, CVE 2016 6663 MYSQL, V0, P0
   Komatwar R, 2021, J APPL SEC RES, V16, P390, DOI 10.1080/19361610.2020.1796162
   Kui Xu, 2016, 2016 46TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS (DSN). PROCEEDINGS, V0, PP467, DOI 10.1109/DSN.2016.49
   Li Z, 2018, VULDEEPECKER ADEEP L, V0, P0
   Liu FC, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS19), V0, PP1777, DOI 10.1145/3319535.3363224
   McInnes Leland, 2020, ARXIV, V0, P0
   Mendis C, 2019, PR MACH LEARN RES, V97, P0
   Mirsky Y, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), V0, P0, DOI DOI 10.14722/ndss.2018.23204
   Mu DL, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), V0, PP924, DOI 10.1109/ASE.2019.00090
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Ravi S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P887
   She DD, 2020, P IEEE S SECUR PRIV, V0, PP1527, DOI 10.1109/SP40000.2020.00022
   Shen Y, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, V0, P905
   Shen Y, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS18), V0, PP592, DOI 10.1145/3243734.3243811
   Shu XK, 2015, CCS15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, V0, PP401, DOI 10.1145/2810103.2813654
   Smilkov D, 2016, EMBEDDING PROJECTOR, V0, P0
   Tavallaee M, 2009, 2009 IEEE S COMPUTAT, V0, PP1, DOI 10.1109/CISDA.2009.5356528
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiphos Research Ltd, 2017, EDB ID 41154 GNU SCR, V0, P0
   Yi H, 2018, MIMICRY RESILIENT PR, V0, P0
   Zuo F, 2018, NEURAL MACHINE TRANS, V0, P0
NR 32
TC 0
Z9 0
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2471-285X
EI 
J9 IEEE TETCI
JI IEEE Trans. Emerg. Top. Comput. Intell.
PD AUG 15
PY 2022
VL 6
IS 4
BP 982
EP 993
DI 10.1109/TETCI.2022.3146425
EA MAY 2022
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3D1AM
UT WOS:000795111300001
DA 2023-11-10
ER

PT J
AU Yadav, H
   Husain, S
   Futrell, R
AF Yadav, Himanshu
   Husain, Samar
   Futrell, Richard
TI Assessing Corpus Evidence for Formal and Psycholinguistic Constraints on Nonprojectivity
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID natural-language; word-order; dependency; context; memory; perspective; complexity; ambiguity; distance
AB Formal constraints on crossing dependencies have played a large role in research on the formal complexity of natural language grammars and parsing. Here we ask whether the apparent evidence for constraints on crossing dependencies in treebanks might arise because of independent constraints on trees, such as low arity and dependency length minimization. We address this question using two sets of experiments. In Experiment 1, we compare the distribution of formal properties of crossing dependencies, such as gap degree, between real trees and baseline trees matched for rate of crossing dependencies and various other properties. In Experiment 2, we model whether two dependencies cross, given certain psycholinguistic properties of the dependencies. We find surprisingly weak evidence for constraints originating from the mild context-sensitivity literature (gap degree and well-nestedness) beyond what can be explained by constraints on rate of crossing dependencies, topological properties of the trees, and dependency length. However, measures that have emerged from the parsing literature (e.g., edge degree, end-point crossings, and heads' depth difference) differ strongly between real and random trees. Modeling results show that cognitive metrics relating to information locality and working-memory limitations affect whether two dependencies cross or not, but they do not fully explain the distribution of crossing dependencies in natural languages. Together these results suggest that crossing constraints are better characterized by processing pressures than by mildly context-sensitive constraints.
C1 [Yadav, Himanshu] Univ Potsdam, Dept Linguist, Potsdam, Germany.
   [Husain, Samar] Indian Inst Technol, Dept Humanities & Social Sci, Delhi, India.
   [Futrell, Richard] Univ Calif Irvine, Dept Language Sci, Irvine, CA USA.
C3 University of Potsdam; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi; University of California System; University of California Irvine
RP Yadav, H (通讯作者)，Univ Potsdam, Dept Linguist, Potsdam, Germany.
EM hyadav@uni-potsdam.de; samar@hss.iitd.ac.in; rfutrell@uci.edu
FU NVIDIA GPU
CR ADES AE, 1982, LINGUIST PHILOS, V4, P517, DOI 10.1007/BF00360804
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   [Anonymous], 1991, SYNTACTIC PARSING ST, V0, P0
   [Anonymous], 1998, LOGICAL ASPECTS COMP, V0, P0
   [Anonymous], 1982, MENTAL REPRESENTATIO, V0, P0
   [Anonymous], 1991, FDN ISSUES NATURAL L, V0, P0
   [Anonymous], 1986, LANG COGNITIVE PROC, V0, P0
   [Anonymous], 1985, NATURAL LANGUAGE PAR, V0, P0
   [Anonymous], 1918, ARCH MATH PHYS, V0, P0
   [Anonymous], 1996, INT C LOGICAL ASPECT, V0, P0
   BODIRSKY M, 2005, P 10 C FORM GRAMM 9, V0, P00195
   Boston Marisa Ferrara, 2010, THE MATHEMATICS OF LANGUAGE. 10TH AND 11TH BIENNIAL CONFERENCE, V0, P1, DOI 10.1007/978-3-642-14322-9_1
   Branigan HP, 2008, LINGUA, V118, P172, DOI 10.1016/j.lingua.2007.02.003
   BRESNAN J, 1982, LINGUIST INQ, V13, P613
   Chang F, 2009, J MEM LANG, V61, P374, DOI 10.1016/j.jml.2009.07.006
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Chomsky N, 1995, LECT GOVT BINDING, V0, P0
   Chomsky N, 1957, SYNTACTIC STRUCTURES, V0, P0, DOI DOI 10.1515/9783112316009
   Chomsky N, 2007, STUD GENERAT GRAMM, V89, P1
   Chomsky Noam, 1986, KNOWLEDGE LANGUAGE I, V0, P0
   EISNER J, 1999, P 37 ANN M ASS COMP, V0, PP457, DOI 10.3115/1034678.1034748
   Ferreira F, 1998, MEM COGNITION, V26, P88, DOI 10.3758/BF03211372
   Ferreira VS, 2000, COGNITIVE PSYCHOL, V40, P296, DOI 10.1006/cogp.1999.0730
   Cancho RFI, 2006, EUROPHYS LETT, V76, P1228, DOI 10.1209/epl/i2006-10406-0
   Ferrer-i-Cancho R, 2018, PHYSICA A, V493, P311, DOI 10.1016/j.physa.2017.10.048
   Ferrer-I-Cancho R, 2014, EPL-EUROPHYS LETT, V108, P0, DOI 10.1209/0295-5075/108/58003
   Ferrer-i-Cancho R, 2022, PHYS REV E, V105, P0, DOI 10.1103/PhysRevE.105.014308
   Ferrer-i-Cancho R, 2022, J QUANT LINGUIST, V29, P165, DOI 10.1080/09296174.2020.1778387
   Ferrer-I-Cancho R, 2016, COMPLEXITY, V21, P320, DOI 10.1002/cplx.21810
   Ferrer-i-Cancho R, 2013, COGNITIVE SCI, V37, P1565, DOI 10.1111/cogs.12061
   Ferrer-i-Cancho Ramon, 2014, ABS14112645 CORR, Vabs/1411.2645, P0
   FRAZIER L, 1987, NAT LANG LINGUIST TH, V5, P519, DOI 10.1007/BF00138988
   Frazier L, 1985, NATURAL LANGUAGE PAR, V0, P129
   Frazier L, 1979, COMPREHENDING SENTEN, V0, P0
   Futrell Richard, 2019, P 1 WORKSH QUANT SYN, V0, PP2, DOI 10.18653/v1/W19-7902
   GERDES K, 2019, P 18 INT WORKSH TREE, V0, PP126, DOI 10.18653/V1/W19-7814
   Gerdes Kim, 2018, P 2 WORKSH UN DEP UD, V0, P0, DOI DOI 10.18653/V1/W18-6008
   Gibson E, 1999, LANG COGNITIVE PROC, V14, P225, DOI 10.1080/016909699386293
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Gibson E, 2019, TRENDS COGN SCI, V23, P389, DOI 10.1016/j.tics.2019.02.003
   Gómez-Rodríguez C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2664
   Gómez-Rodriguez C, 2017, PHYS REV E, V96, P0, DOI 10.1103/PhysRevE.96.062304
   Gómez-Rodríguez C, 2011, COMPUT LINGUIST, V37, P541, DOI 10.1162/COLI_a_00060
   Gomez-Rodriguez Carlos, 2019, ABS190806629 CORR, Vabs/1908.06629, P0
   Grog Thomas, 2009, SKY J LINGUISTICS, V22, P43
   Hahn M, 2021, PSYCHOL REV, V128, P726, DOI 10.1037/rev0000269
   Havelka J, 2007, P 45 ANN M ASS COMP, V0, P608
   Hawkins JA, 2004, EFFICIENCY COMPLEXIT, V0, P0
   HAYS DG, 1964, LANGUAGE, V40, P511, DOI 10.2307/411934
   Hofmeister P, 2010, LANGUAGE, V86, P366
   Holan Tomas, 1998, PROCESSING DEPENDENC, V0, P21
   Hopcroft J, 2007, ADDISON WESLEY SERIE, V3rd, P0
   Hotz G, 1996, THEOR COMPUT SCI, V161, P205, DOI 10.1016/0304-3975(95)00114-X
   Hudson R, 1990, ENGLISH WORD GRAMMAR, V0, P0
   HUSAIN S, 2015, J EYE MOVEMENT RES, V8, P0, DOI 10.16910/JEMR.8.2.3
   Husain S, 2020, FRONT PSYCHOL, V11, P0, DOI 10.3389/fpsyg.2020.00454
   Husain S, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0100986
   Husain Samar, 2015, P 3 INT C DEPENDENCY, V0, P141
   Jaeger TF, 2011, WIRES COGN SCI, V2, P323, DOI 10.1002/wcs.126
   JOSHI AK, 1990, LANG COGNITIVE PROC, V5, P1, DOI 10.1080/01690969008402095
   Kaiser E, 2004, COGNITION, V94, P113, DOI 10.1016/j.cognition.2004.01.002
   Kuhlmann M, 2013, COMPUT LINGUIST, V39, P355, DOI 10.1162/COLI_a_00125
   Kuhlmann Marco, 2007, THESIS U SAARLANDES, V0, P0
   Kuhlmann Marco, 2006, P COLING ACL 2006 MA, V0, PP507, DOI 10.3115/1273073.1273139
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Levy R, 2012, COGNITION, V122, P12, DOI 10.1016/j.cognition.2011.07.012
   Lewis RL, 2005, COGNITIVE SCI, V29, P375, DOI 10.1207/s15516709cog0000_25
   Liu HT, 2017, PHYS LIFE REV, V21, P171, DOI 10.1016/j.plrev.2017.03.002
   MacDonald MC, 2013, FRONT PSYCHOL, V4, P0, DOI 10.3389/fpsyg.2013.00226
   Mahowald K, 2013, COGNITION, V126, P313, DOI 10.1016/j.cognition.2012.09.010
   Marcus Solomon, 1965, Z F R MATHEMATISCHE, V11, P181, DOI 10.1002/malq.19650110212
   Melcuk I, 1988, DEPENDENCY SYNTAX TH, V0, P0
   Momma S, 2021, COGNITIVE PSYCHOL, V129, P0, DOI 10.1016/j.cogpsych.2021.101411
   NIVRE J, 2006, 11 C EUR CHAPT ASS C, V0, P73
   Nivre J, 2015, LECT NOTES COMPUT SC, V9041, P3, DOI 10.1007/978-3-319-18111-0_1
   Nivre Joakim, 2007, HUMAN LANGUAGE TECHN, V0, P396
   Nivre Joakim, 2015, UNIVERSAL DEPENDENCI, V0, P0
   Phillips C, 2005, COGNITIVE BRAIN RES, V22, P407, DOI 10.1016/j.cogbrainres.2004.09.012
   Piantadosi ST, 2014, PSYCHON B REV, V21, P1112, DOI 10.3758/s13423-014-0585-6
   Pitler E, 2013, T ASSOC COMPUT LING, V1, P13, DOI 10.1162/TACL_A_00206
   Pollard C, 1994, HEAD DRIVEN PHRASE S, V0, P0
   Ristic B, 2022, J EXP PSYCHOL LEARN, V48, P829, DOI 10.1037/xlm0000863
   Sag Ivan A, 1999, SYNTACTIC THEORY FOR, V0, P0
   SATTA G, 1992, 30TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P89
   Schutzenberger MP, 1963, COMPUTER PROGRAMMING, V0, PP118, DOI 10.1016/S0049-237X(08)72023-8
   Scontras G, 2017, COGNITIVE SCI, V41, P2280, DOI 10.1111/cogs.12495
   SEKI H, 1991, THEOR COMPUT SCI, V88, P191, DOI 10.1016/0304-3975(91)90374-B
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013
   Staub A, 2018, J MEM LANG, V98, P26, DOI 10.1016/j.jml.2017.09.003
   Steedman M, 2011, NON-TRANSFORMATIONAL SYNTAX: FORMAL AND EXPLICIT MODELS OF GRAMMAR, V0, P181
   Temperley D, 2018, ANNU REV LINGUIST, V4, P67, DOI 10.1146/annurev-linguistics-011817-045617
   Tesniere L, 1959, ELEMENTS SYNTAXE STR, V0, P0
   TRUESWELL JC, 1994, J MEM LANG, V33, P285, DOI 10.1006/jmla.1994.1014
   Weir David, 1988, THESIS U PENNSYLVANI, V0, P0
   Yadav H, 2021, LINGUIST VANGUARD, V7, P0, DOI 10.1515/lingvan-2019-0070
   Yadav H, 2020, COGNITIVE SCI, V44, P0, DOI 10.1111/cogs.12822
   Yadav Himanshu, 2019, P 18 INT WORKSHOP TR, V0, PP2, DOI 10.18653/v1/W19-7802
   Yadav Himanshu, 2020, 26 ARCH MECH LANG PR, V0, Pe12822
   Yadav Himanshu, 2017, P 4 INT C DEPENDENCY, V0, P276
   YLIJYRA A, 2003, P 2 WORKSH TREEB LIN, V0, P189
   YNGVE VICTOR H, 1960, PROC AMER PHIL SOC, V104, P444
   Zipf GK, 1950, J CLIN PSYCHOL, V6, P306
NR 102
TC 0
Z9 0
U1 3
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN 15
PY 2022
VL 48
IS 2
BP 375
EP 401
DI 10.1162/coli_a_00437
PG 27
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA H1QU6
UT WOS:000993786300005
DA 2023-11-10
ER

PT J
AU Wang, QL
   Wen, ZY
   Ding, KY
   Zhao, Q
   Yang, M
   Yu, XQ
   Xu, RF
AF Wang, Qianlong
   Wen, Zhiyuan
   Ding, Keyang
   Zhao, Qin
   Yang, Min
   Yu, Xiaoqi
   Xu, Ruifeng
TI Improving sequence labeling with labeled clue sentences
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Labeled clue sentences; Sequence labeling; Pre -trained language models
ID relation extraction; joint entity
AB Pre-trained language models (PLMs) have achieved noticeable success on a variety of natural language processing tasks, such as sequence labeling. In particular, the existing sequence labeling methods fine-tune PLMs on large-scale labeled data, which can avoid training the sequence labeling models from scratch. The fine-tuning process still requires large amounts of labeled training data so as to be effective. However, obtaining rich annotated data for sequence labeling is a time-consuming and expensive process, creating a substantial barrier for directly applying the PLMs trained on general-purpose large-scale text data to sequence labeling. In this paper, we investigate sequence labeling tasks from a novel perspective and propose a general framework that uses labeled clue sentences to mitigate the problem of insufficient annotation data for sequence labeling. Specifically, we first retrieve the labeled clue sentences for each original sentence in the training set based on the semantic (or syntactic) relevance. Here, the number of annotated clue sentences determines the expansion degree of the training set. Then, we modify the transformer's self-attention mechanism to not only exploit the contextual information of the original sentence but also leverage the contextual and label information of the labeled clue sentences. In addition, we devise a mask label strategy to further avoid over-fitting by randomly masking out the labels of certain tokens in the clue sentence and then predicting these mask labels based on the context of the tokens corresponding to the mask labels. We verify the effectiveness and generalizability of the proposed framework on three sequence labeling tasks, including Chinese Named Entity Recognition, English Named Entity Recognition, and Aspect Term Extraction. Extensive experimental results show that our method can yield state-of-the-art or competitive results on the three tasks.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Wang, Qianlong; Wen, Zhiyuan; Ding, Keyang; Zhao, Qin; Xu, Ruifeng] Harbin Inst Technol, Shenzhen, Peoples R China.
   [Yang, Min] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
   [Yu, Xiaoqi] China Merchants Secur Co LTD, Hong Kong, Peoples R China.
   [Wang, Qianlong; Xu, Ruifeng] Guangdong Prov Key Lab Novel Secur Intelligence Te, Shenzhen, Peoples R China.
   [Wang, Qianlong; Xu, Ruifeng] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Peng Cheng Laboratory
RP Xu, RF (通讯作者)，Harbin Inst Technol, Shenzhen, Peoples R China.
EM qlwang15@outlook.com; wenzhiyuan2012@gmail.com; keyang.ding@stu.hit.edu.cn; zhaoqin@hit.edu.cn; min.yang@siat.ac.cn; yuxiaoqi@cmschina.com.cn; xuruifeng@hit.edu.cn
FU National Natural Science Foundation of China [62006062, 62176076]; Shenzhen Foundational Research Funding [JCYJ20200109113441941]; Shenzhen Key Technology Project [JSGG20210802154400001]; Major Key Project [PCL2021A06]; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies [2022B12120100 05]; Joint Lab of HITSZ; China Merchants Securities
CR Bekoulis G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2830
   Bekoulis G, 2018, EXPERT SYST APPL, V114, P34, DOI 10.1016/j.eswa.2018.07.032
   Chen Z, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2107
   Chen Z, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3685
   Chernyshevich Maryna, 2014, P 8 INT WORKSH SEM E, V0, PP309, DOI 10.3115/V1/S14-2051
   Dai X, 2021, P 28 INT C COMPUTATI, V0, P3861
   Dat Quoc Nguyen, 2019, ADVANCES IN INFORMATION RETRIEVAL. 41ST EUROPEAN CONFERENCE ON IR RESEARCH, V0, P729, DOI 10.1007/978-3-030-15712-8_47
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dodge J, 2020, ARXIV, V0, P0
   Eberts M, 2020, FRONT ARTIF INTEL AP, V325, P2006, DOI 10.3233/FAIA200321
   Fawzi A, 2016, IEEE IMAGE PROC, V0, PP3688, DOI 10.1109/ICIP.2016.7533048
   Gupta P, 2016, P COLING 2016 26 INT, V0, P2537
   He RD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P504
   Hu D, 2020, ARXIV, V0, P0
   Lafferty J, 2001, P INT C MACH LEARN, V0, PP282, DOI 10.1038/NPROT.2006.61
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lan Zhenzhong, 2019, ABS190911942, V0, P0
   Levow G, 2006, P 5 SIGHAN WORKSH CH, V0, P108
   Li K, 2020, P 58 ANN M ASS COMP, V0, PP7056, DOI 10.18653/v1/2020.acl-main.631
   Li X, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P17
   Li X, 2020, P 58 ANN M ASS COMPU, V0, PP5849, DOI 10.18653/V1/2020.ACL-MAIN.519
   Li X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4194
   Liu YH, 2019, ARXIV, V0, P0
   Ma DH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3538
   Mao Y, 2021, AAAI CONF ARTIF INTE, V35, P13543
   Meng YX, 2019, ADV NEURAL INFORM PR, V0, P2742
   Mosbach Marius, 2020, ARXIV200604884, V0, P0
   Nie Y, 2020, P 2020 C EMP METH NA, V0, P1383
   Peng M, 2020, P 58 ANN M ASS COMP, V0, PP5951, DOI 10.18653/v1/2020.acl-main.528
   Peng N, 2015, P 2015 C EMP METH NA, V0, PP548, DOI 10.18653/V1/D15-1064
   Pontiki M, 2014, P 8 INT WORKSHOP SEM, V0, PP27, DOI 10.3115/v1/s14-2004
   Pontiki M, 2016, P 10 INT WORKSH SEM, V0, PP19, DOI 10.18653/V1/S16-1002
   Pontiki Maria, 2015, P 9 INT WORKSH SEM E, V0, PP486, DOI 10.18653/v1/s15-2082
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sun Y, 2019, ARXIV, V0, P0
   Sun ZJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2065
   Toh Z, 2016, PROC 10 INT WORKSHOP, V0, PP282, DOI 10.18653/V1/S16-1045
   Toh Z, 2014, P 8 INT WORKSH SEM E, V0, P235
   Tran T, 2019, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Venugopalan M, 2022, KNOWL-BASED SYST, V246, P0, DOI 10.1016/j.knosys.2022.108668
   Vicente IS, 2015, P 9 INT WORKSHOP SEM, V0, P748
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6382
   Weischedel R, 2011, ONTONOTES RELEASE 4, V0, P0
   Wu S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1529
   Xiaonan L, 2020, P 58 ANN M ASS COMPU, V0, PP6836, DOI 10.18653/V1/2020.ACL-MAIN.611
   Xu CW, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2269, DOI 10.1145/3357384.3358117
   Xu H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6442
   Yan H, 2021, LONG PAPERS, V1, P0
   Yin D, 2020, AAAI CONF ARTIF INTE, V34, P13977
   Yu J, 2020, P 58 ANN M ASS COMPU, V0, PP6470, DOI 10.18653/v1/2020.acl-main.577
   Zhang RZ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8566
   Zhang Tianyi, 2021, P ICLR, V0, P0
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zhu Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3384
NR 59
TC 1
Z9 1
U1 5
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD DEC 5
PY 2022
VL 257
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.109828
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5I8CB
UT WOS:000868577000002
DA 2023-11-10
ER

PT J
AU Tam, NT
   Trung, HT
   Yin, HZ
   Vinh, TV
   Sakong, D
   Zheng, BL
   Hung, NQV
AF Nguyen Thanh Tam
   Huynh Thanh Trung
   Yin, Hongzhi
   Tong Van Vinh
   Sakong, Darnbi
   Zheng, Bolong
   Nguyen Quoc Viet Hung
TI Entity Alignment for Knowledge Graphs With Multi-Order Convolutional Networks
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Logic gates; Knowledge engineering; Data models; Biological system modeling; Task analysis; Correlation; Urban areas; Knowledge graph; entity alignment; network embedding; graph convolutional neural network
AB Knowledge graphs (KGs) have become popular structures for unifying real-world entities by modelling the relationships between them and their attributes. To support multilingual applications, a significant number of language-specific KGs have been built by different parties using various data sources. As a result, these monolingual KGs are often disconnected, causing semantic heterogeneity and detracting from the original purpose of KGs. Entity alignment - the task of identifying corresponding entities across different KGs - has attracted a great deal of attention in both academia and industry. However, existing alignment techniques often require large amounts of labelled data, are unable to encode multi-modal data simultaneously, and enforce only a few consistency constraints. In this paper, we propose an end-to-end, unsupervised entity alignment framework for cross-lingual KGs that fuses different types of information in order to fully exploit the richness of KG data. The model captures the relation-based correlation between entities by using a multi-order graph convolutional neural (GCN) model that is designed to satisfy the consistency constraints, while incorporating the attribute-based correlation via a translation machine. We adopt a late-fusion mechanism to combine all the information together, which allows these approaches to complement each other and thus enhances the final alignment result, and makes the model more robust to consistency violations. Empirical results for various scenarios on real-world and synthetic KGs show that our model is up to 22.71 percent more accurate and orders of magnitude faster than existing baselines. We also demonstrate its sensitivity to hyper-parameters, effort saving in terms of labelling, and the robustness against adversarial conditions.
C1 [Nguyen Thanh Tam] Ho Chi Minh City Univ Technol HUTECH, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Huynh Thanh Trung; Tong Van Vinh; Sakong, Darnbi; Nguyen Quoc Viet Hung] Griffith Univ, Nathan, Qld 4111, Australia.
   [Yin, Hongzhi] Univ Queensland, St Lucia, Qld 4072, Australia.
   [Zheng, Bolong] Huazhong Univ Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Vietnam National University Hochiminh City; Ho Chi Minh City University of Technology (HUTECH); Griffith University; University of Queensland; Huazhong University of Science & Technology
RP Yin, HZ (通讯作者)，Univ Queensland, St Lucia, Qld 4072, Australia.
EM thanhtamlhp@gmail.com; thanhtrunghuynh93@gmail.com; db.hongzhi@gmail.com; vinhbachkhoait@gmail.com; dobbydarnbi@gmail.com; zblchris@gmail.com; quocviethung1@gmail.com
FU Vietnam National Foundation for Science and Technology Development (NAFOSTED) [102.01-2019.323]
CR Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bordes A, 2013, P ADV NEUR INF PROC, V0, P2787
   Cao YX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1452
   Chen C, 1900, V2019, V0, P0
   Chen HX, 2019, PROC INT CONF DATA, V0, PP590, DOI 10.1109/ICDE.2019.00059
   Chen HX, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP1177, DOI 10.1145/3219819.3219986
   Chen M, 2015, IEEE T KNOWL DATA EN, V27, P1465, DOI 10.1109/TKDE.2014.2382599
   Chen MH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1511
   Dehmamy N, 2019, INT C NEURAL INF PRO, V0, P15 387
   Dong M, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP569, DOI 10.1145/3357384.3357994
   Duong CT, 2020, PROC INT CONF DATA, V0, PP1990, DOI 10.1109/ICDE48307.2020.00222
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Hamilton William L, 2017, ADV NEURAL INFORM PR, V0, P1025
   Hu S, 2018, IEEE T KNOWL DATA EN, V30, P824, DOI 10.1109/TKDE.2017.2766634
   Trung HT, 2020, PROC INT CONF DATA, V0, PP85, DOI 10.1109/ICDE48307.2020.00015
   Trung HT, 2020, EXPERT SYST APPL, V140, P0, DOI 10.1016/j.eswa.2019.112883
   Jayaram N, 2015, IEEE T KNOWL DATA EN, V27, P2797, DOI 10.1109/TKDE.2015.2426696
   Ji GL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P687
   Kipf T N, 2016, ICLR, V0, P0
   Kollias G, 2012, IEEE T KNOWL DATA EN, V24, P2232, DOI 10.1109/TKDE.2011.174
   Koutra D, 2013, IEEE DATA MINING, V0, PP389, DOI 10.1109/ICDM.2013.152
   Lin Y, 2015, P AAAI C ART INT, V0, P2181
   Luo ZL, 2017, IEEE T KNOWL DATA EN, V29, P2125, DOI 10.1109/TKDE.2017.2720734
   Man T, 2016, P 25 INT JOINT C ART, V16, P1823, DOI 10.5555/3060832.3060876
   Nassar H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP619, DOI 10.1145/3178876.3186128
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Phan MC, 2019, IEEE T KNOWL DATA EN, V31, P1383, DOI 10.1109/TKDE.2018.2857493
   Ren YX, 2019, PROC INT CONF DATA, V0, PP1690, DOI 10.1109/ICDE.2019.00174
   Song Q, 2018, IEEE T KNOWL DATA EN, V30, P1887, DOI 10.1109/TKDE.2018.2807442
   Sun ZQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4396
   Sun ZQ, 2017, LECT NOTES COMPUT SC, V10587, P628, DOI 10.1007/978-3-319-68288-4_37
   Tang J, 2017, ACM SIGKDD EXPLORATI, V18, P5, DOI 10.1145/3068777.3068781
   Duong CT, 2019, ARXIV, V0, P0
   Duong CT, 2019, ARXIV, V0, P0
   Nguyen TT, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.113857
   Huynh TT, 2019, LECT NOTES ARTIF INT, V11671, P698, DOI 10.1007/978-3-030-29911-8_54
   Wang CG, 2016, AAAI CONF ARTIF INTE, V0, P2130
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang WQ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP545, DOI 10.1145/3331184.3331258
   Wang Z, 2014, P 28 AAAI C ARTIFICI, V0, P1112
   Wang ZC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P349
   Wu YT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5278
   Xie Q, 2020, P ADV NEUR INF PROC, V0, P1
   Xu KYL, 2018, PR MACH LEARN RES, V80, P0
   Xu K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3156
   Zhang FZ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP353, DOI 10.1145/2939672.2939673
   Zhang S, 2019, IEEE T KNOWL DATA EN, V31, P1680, DOI 10.1109/TKDE.2018.2866440
   Zhang S, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1345, DOI 10.1145/2939672.2939766
   Zhang YY, 2018, AAAI CONF ARTIF INTE, V0, P6069
   Zheng WG, 2016, IEEE T KNOWL DATA EN, V28, P1805, DOI 10.1109/TKDE.2016.2530063
   Zhu H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4258
   Zhu QN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1943
NR 52
TC 17
Z9 17
U1 2
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD SEPT 1
PY 2022
VL 34
IS 9
BP 4201
EP 4214
DI 10.1109/TKDE.2020.3038654
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 3O1VG
UT WOS:000836626800012
DA 2023-11-10
ER

PT J
AU Do, P
   Phan, THV
AF Phuc Do
   Phan, Truong H., V
TI Developing a BERT based triple classification model using knowledge graph embedding for question answering system
SO APPLIED INTELLIGENCE
LA English
DT Article
DE BERT based triple classification model; Knowledge graph embedding; Meta-path; Motif finding
AB The current BERT-based question answering systems use a question and a contextual text to find the answer. This causes the systems to return wrong answers or nothing if the text contains irrelevant contents with the input question. Besides, the systems haven't answered yes-no and aggregate questions yet. Besides that, the systems only concentrate on the contents of text regardless of the relationship between entities in the corpus. This systems cannot validate the answer. In this paper, we presented a solution to solve these issues by using the BERT model and the knowledge graph to enhance a question answering system. We combined content-based and linked-based information for knowledge graph representation learning and classified triples into one of three classes such as base class, derived class, or non-existent class. We then used the BERT model to build two classifiers: BERT-based text classification for content information and BERT-based triple classification for link information. The former was able to make a contextual embedding vector for representing triples that were used to classify into the three above classes. The latter generated all path instances from all meta paths of a large heterogeneous information network by running the Motif Search method of Apache Spark on a distributed environment. After creating the path instances, we produced triples from these path instances. We made content-based information by converting triples into natural language text with labels and considered them as a text classification problem. Our proposed solution outperformed other embedding methods with an average accuracy of 92.34% on benchmark datasets and the Motif Finding algorithm with an average executive time improvement of 37% on the distributed environment.
C1 [Phuc Do; Phan, Truong H., V] Vietnam Natl Univ, Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Phan, Truong H., V] Van Lang Univ, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City; Van Lang University
RP Do, P (通讯作者)，Vietnam Natl Univ, Univ Informat Technol, Ho Chi Minh City, Vietnam.
EM phucdo@uit.edu.vn; truongphv.ncs@grad.uit.edu.vn
FU Vietnam National University Ho Chi Minh City (VNU-HCMC) [DS2020-26-01]
CR Ankur D, 2016, GRADES 2016, V0, P0
   [Anonymous], 1998, WORDNET ELECT LEXICA, V0, P0, DOI DOI 10.7551/MITPRESS/7287.001.0001
   [Anonymous], 2015, SPARK COOKBOOK, V0, P0
   [Anonymous], 2015, BIG DATA ANAL SPARK, V0, P0
   Chi Sun XQ, 2020, ARXIV190505583V3CSCL, V0, P0
   Devlin Jacob, 2019, BERT PRE TRAINING DE, V0, P4171
   Do P, 2019, HDB RES CLOUD COMPUT, V0, P271
   Galkin, 2020, KNOWLEDGE GRAPHS NAT, V0, P0
   HU BB, 2018, LEVERAGING METAPATH, V0, P1531
   Ji GL, 2016, AAAI CONF ARTIF INTE, V0, P985
   Kingma DP, 2015, PROC ICLR 2015, V0, P0
   Kurt Bollacker, 2008, P 2008 ACM SIGMOD IN, V0, P0
   Liang Yao CM, 2019, ARXIV190903193V2CSCL, V0, P0
   Lijun Chang XL, 2015, 18 INT C EXT DAT TEC, V0, P0
   Liu HP, 2018, IEEE T KNOWL DATA EN, V30, P488, DOI 10.1109/TKDE.2017.2773492
   Manish Munikar SS, 2020, ARXIV191003474V1CSCL, V0, P0
   Meng CP, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), V0, PP754, DOI 10.1145/2736277.2741123
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Muangprathub J, 2014, APPL MATH SCI, V8, P507
   Ni Lao WW, 2010, KDD 10, V0, P0
   Phuc Do, 2018, J INFORM TELECOMMUN, V0, P1
   Santiago Gonzalez-Carvajal EC-M, 2020, ARXIV200513012V1CSCL, V0, P0
   Shi BX, 2017, AAAI CONF ARTIF INTE, V0, P1236
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Siva Reddy, 2019, ARXIV180807042V2, V0, P0
   Socher R, 2013, ADV NEURAL INFORM PR, V0, P926
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Suchanek FM, 2007, WWW, V0, PP697, DOI 10.1145/1242572.1242667
   Sunt YZ, 2011, PROC VLDB ENDOW, V4, P992
   Tomasz Drabas DL, 2017, LEARNING PYSPARK, V0, P0
   Ueno K, 2017, DATA SCI ENG, V2, P22, DOI 10.1007/s41019-016-0024-y
   Wang Z, 2016, P 25 INT JOINT C ART, V0, P4
   Xiangnan Kong, 2012, CIKM 12, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu JF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5408
   Zhang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3198
   Zichen Z, 2018, IEEE ICDM 2018, V0, P0
NR 37
TC 20
Z9 22
U1 7
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JAN 15
PY 2022
VL 52
IS 1
BP 636
EP 651
DI 10.1007/s10489-021-02460-w
EA MAY 2021
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YG8PL
UT WOS:000648365100002
DA 2023-11-10
ER

PT J
AU Kuang, L
   Ge, F
   Zhang, LY
AF Kuang, Li
   Ge, Fan
   Zhang, Lingyan
TI Suggesting method names based on graph neural network with salient information modelling
SO EXPERT SYSTEMS
LA English
DT Article
DE deep learning; method naming; neural networks; program comprehension
AB Descriptive method names have a great impact on improving program readability and facilitating software maintenance. Recently, due to high similarity between the task of method naming and text summarization, large amount of research based on natural language processing has been conducted to generate method names. However, method names are much shorter compared to long source code sequences. The salient information of the whole code snippet account for an relatively small part. Additionally, unlike natural language, source code has complicated structure information. Thus, modelling the salient information from highly structured input presents a great challenge. To tackle this problem, we propose a graph neural network (GNN)-based model with a novel salient information selection layer. Specifically, to comprehensively encode the tokens of the source code, we employ a GNN-based encoder, which can be directly applied to the code graph to ensure that the syntactic information of code structure and semantic information of code sequence can be modelled sufficiently. To effectively discriminate the salient information, we introduce an information selection layer which contains two parts: a global filter gate used to filter irrelevant information, and a semantic-aware convolutional layer used to focus on the semantic information contained in code sequence. To improve the precision of the copy mechanism when decoding, we introduce a salient feature enhanced attention mechanism to facilitate the accuracy of copying tokens from input. Experimental results on an open source dataset indicate that our proposed model, equipped with the salient information selection layer, can effectively improve method naming performance compared to other state-of-the-art models.
C1 [Kuang, Li; Ge, Fan; Zhang, Lingyan] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
C3 Central South University
RP Zhang, LY (通讯作者)，Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
EM lingyan_zhang@csu.edu.cn
FU Fundamental Research Funds for the Central Universities of Central South University [2021zzts0730]; National Key R&D Program of China [2018YFB1402800]
CR Allamanis M, 2018, LEARNING REPRESENT P, V0, P0
   Allamanis M, 2016, PR MACH LEARN RES, V48, P0
   Allamanis M, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, V0, PP38, DOI 10.1145/2786805.2786849
   Alon U, 2019, P ACM PROGRAM LANG, V3, P0, DOI 10.1145/3290353
   Alon U, 2018, ACM SIGPLAN NOTICES, V53, P404, DOI 10.1145/3296979.3192412
   Alon Uri, 2019, P 7 INT C LEARN REPR, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Butler S, 2009, WORK CONF REVERSE EN, V0, PP31, DOI 10.1109/WCRE.2009.50
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Cvitkovic M, 2019, PR MACH LEARN RES, V97, P0
   Fernandes Patrick, 2019, STRUCTURED NEURAL SU, V0, P0
   Haiduc S, 2010, 2010 32ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), V0, PP223, DOI 10.1145/1810295.1810335
   Haiduc S, 2010, PROCEEDINGS 17TH WORKING CONFERENCE ON REVERSE ENGINEERING (WCRE 2010), V0, PP35, DOI 10.1109/WCRE.2010.13
   He KM, 2015, DELVING DEEP RECTIFI, V0, P0
   Host EW, 2009, LECT NOTES COMPUT SC, V5653, P294, DOI 10.1007/978-3-642-03013-0_14
   Hu X, 2018, INT C PROGRAM COMPRE, V0, PP200, DOI 10.1145/3196321.3196334
   Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073
   Jia Robin, 2017, ADVERSARIAL EXAMPLES, V0, P0
   Jiang L, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), V0, PP614, DOI 10.1109/ASE.2019.00062
   King DB, 2015, ACS SYM SER, V1214, P1
   Lawrie D, 2006, INT C PROGRAM COMPRE, V0, PP3, DOI 10.1109/ICPC.2006.51
   LeClair A, 2019, PROC INT CONF SOFTW, V0, PP795, DOI 10.1109/ICSE.2019.00087
   Li Y, 2016, P ICLR 16 OPENREVIEW, V0, P0
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Liu A, 2017, GET POINT SUMMARIZAT, V0, P0
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Nguyen S, 2020, PROC INT CONF SOFTW, V0, PP1372, DOI 10.1145/3377811.3380926
   Sridhara G, 2010, AUTOMATICALLY GENERA, V0, PP43, DOI 10.1145/1858996.1859006
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Takang AA, 1996, J PROGRAM LANG, V4, P143
   Vinyals O, 2015, ADV NEURAL INFORM PR, V28, P0
   Wan Y, 2018, IEEE INT CONF AUTOM, V0, PP397, DOI 10.1145/3238147.3238206
   Xia X, 2018, IEEE T SOFTWARE ENG, V44, P951, DOI 10.1109/TSE.2017.2734091
   Xu SH, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN WORKSHOP ON PARTIAL EVALUATION AND PROGRAM MANIPULATION (PEPM 19), V0, PP10, DOI 10.1145/3294032.3294079
   Zhou Y, 2019, ADV NEURAL INFORM PR, V0, P10197
NR 35
TC 0
Z9 0
U1 3
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JUL 15
PY 2022
VL 39
IS 6
BP 
EP 
DI 10.1111/exsy.13030
EA MAY 2022
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA 2I2CT
UT WOS:000794004900001
DA 2023-11-10
ER

PT J
AU Lauscher, A
   Wachsmuth, H
   Gurevych, I
   Glavas, G
AF Lauscher, Anne
   Wachsmuth, Henning
   Gurevych, Iryna
   Glavas, Goran
TI Scientia Potentia Est-On the Role of Knowledge in Computational Argumentation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Despite extensive research efforts in recent years, computational argumentation (CA) remains one of the most challenging areas of natural language processing. The reason for this is the inherent complexity of the cognitive processes behind human argumentation, which integrate a plethora of different types of knowledge, ranging from topic-specific facts and common sense to rhetorical knowledge. The integration of knowledge from such a wide range in CA requires modeling capabilities far beyond many other natural language understanding tasks. Existing research on mining, assessing, reasoning over, and generating arguments largely acknowledges that much more knowledge is needed to accurately model argumentation computationally. However, a systematic overview of the types of knowledge introduced in existing CA models is missing, hindering targeted progress in the field. Adopting the operational definition of knowledge as any task-relevant normative information not provided as input, the survey paper at hand fills this gap by (1) proposing a taxonomy of types of knowledge required in CA tasks, (2) systematizing the large body of CA work according to the reliance on and exploitation of these knowledge types for the four main research areas in CA, and (3) outlining and discussing directions for future research efforts in CA.
C1 [Lauscher, Anne] Bocconi Univ, MilaNLP, Milan, Italy.
   [Wachsmuth, Henning] Paderborn Univ, Dept Comp Sci, Paderborn, Germany.
   [Gurevych, Iryna] Tech Univ Darmstadt, Ubiquitous Knowledge Proc Lab, Darmstadt, Germany.
   [Glavas, Goran] Univ Wurzburg, CAIDAS, Wurzburg, Germany.
C3 Bocconi University; University of Paderborn; Technical University of Darmstadt; University of Wurzburg
RP Lauscher, A (通讯作者)，Bocconi Univ, MilaNLP, Milan, Italy.; Wachsmuth, H (通讯作者)，Paderborn Univ, Dept Comp Sci, Paderborn, Germany.
EM anne.lauscher@unibocconi.it; henningw@upb.de; gurevych@ukp.informatik.tu-darmstadt.de; goran.glavas@uni-wuerzburg.de
CR Accuosto P, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P41
   Ajjour Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2922
   Ajjour Yamen, 2017, P 4 WORKSH ARG MIN, V0, P118
   Aker Ahmet, 2017, P 4 WORKSHOP ARGUMEN, V0, PP91, DOI 10.18653/v1/W17-5112
   Al Khatib Khalid, 2020, P 58 ANN M ASS COMPU, V0, P7067
   Al-Khatib K, 2020, AAAI CONF ARTIF INTE, V34, P7367
   Al-Khatib Khalid, 2016, C N AM CHAPTER ASS C, V0, PP1395, DOI 10.18653/v1/N16-1165
   AlKhatib K, 2021, P 2 WORKSHOP SCHOLAR, V0, P56
   Alshomary M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P224
   Alshomary M, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP1969, DOI 10.1145/3397271.3401186
   Alshomary M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P4334
   [Anonymous], 2003, THE USE OF ARGUMENT, V0, P0
   [Anonymous], 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   [Anonymous], 2014, P COLING 2014 25 INT, V0, P0
   [Anonymous], 2012, SYNTHESIS LECT HUMAN, V0, P0
   Aristotle George A, 2007, RHETORIC THEORY CIVI, V0, P0
   Athar A, 2011, P ACL 2011 STUD SESS, V0, P81
   Atkinson K, 2017, AI MAG, V38, P25, DOI 10.1609/aimag.v38i3.2704
   Bar-Haim R, 2017, PROC 4 WORKSHOP ARGU, V0, PP32, DOI 10.18653/V1/W17-5104
   Bar-Haim R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P39
   Bar-Haim R, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P251
   Becker M, 2021, P DEEP LEARNING INSI, V0, PP11, DOI 10.18653/V1/2021.DEELIO-1.2
   Bentahar J, 2010, ARTIF INTELL REV, V33, P211, DOI 10.1007/s10462-010-9154-1
   Bilu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1013
   Bilu Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P525
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Boltuic Filip, 2017, P 8 WORKSHOP COMPUTA, V0, PP74, DOI 10.18653/v1/W17-5210
   Boltuzic F, 2014, P 1 WORKSH ARG MIN, V0, PP49, DOI 10.3115/V1/W14-2107
   Boltuzic F, 2016, P 3 WORKSHOP ARGUMEN, V0, PP124, DOI 10.18653/v1/w16-2815
   Botschen T, 2018, P 5 WORKSHOP ARGUMEN, V0, P90
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Brassard A, 2018, P 12 INT WORKSH SEM, V0, PP1133, DOI 10.18653/v1/s18-1192
   Cabrio E, 2012, P 50 ANN M ASS COMP, V2, P208
   Cabrio E, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5427
   Carenini G, 2006, ARTIF INTELL, V170, P925, DOI 10.1016/j.artint.2006.05.003
   Carstens L, 2015, P 2 WORKSH ARG MIN, V0, P29
   Chakrabarty T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2933
   Chalaguine Lisa Andreevna, 2017, P STUDENT RES WORKSH, V0, PP75, DOI 10.18653/v1/E17-4008
   Chen W-F, 2018, P 11 INT C NAT LANG, V0, P79
   Choi H, 2018, P 12 INT WORKSH SEM, V0, PP773, DOI 10.18653/V1/S18-1122
   Clark Kevin, 2020, ICLR, V0, P0
   Cocarascu O, 2017, P 2017 C EMPIRICAL M, V0, P1374
   Dagan Ido, 2013, SYNTHESIS LECT HUMAN, V0, P0, DOI DOI 10.2200/S00509ED1V01Y201305HLT023
   Daxenberger Johannes, 2017, P 2017 C EMPIRICAL M, V0, PP2055, DOI 10.18653/v1/D17-1218
   Delobelle P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P203
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   DRETSKE F, 1983, BEHAV BRAIN SCI, V6, P55, DOI 10.1017/S0140525X00014631
   Dumani L, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP957, DOI 10.1145/3331184.3331282
   DUNG PM, 1995, ARTIF INTELL, V77, P321, DOI 10.1016/0004-3702(94)00041-X
   Durmus E, 2018, P 2018 C N AM CHAPT, V1, P1035
   Durmus E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P602
   Durmus E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4630
   Dusmanu M, 2018, P 2017 C EMPIRICAL M, V0, P2317
   Egan Charlie, 2016, P 3 WORKSHOP ARGUMEN, V0, PP134, DOI 10.18653/v1/W16-2816
   Eger S, 2018, P 27 INT C COMP LING, V0, P831
   Eger S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P11, DOI 10.18653/v1/P17-1002
   Eide SR, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P52
   El Baff R, 2019, P 12 INT C NAT LANG, V0, PP54, DOI 10.18653/V1/W19-8607
   El Baff R, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3154
   El Baff Roxanne, 2018, P 22 C COMPUTATIONAL, V0, PP454, DOI 10.18653/v1/K18-1044
   Feng Vanessa Wei, 2011, P 49 ANN M ASS COMPU, V0, P987
   Freeman JB, 2011, ARGUM LIB, V18, P1, DOI 10.1007/978-94-007-0357-5
   Galassi A, 2018, P 5 WORKSHOP ARGUMEN, V0, PP1, DOI 10.18653/v1/W18-5201
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gemechu D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P516
   Ghosh D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P549
   GILBERT GN, 1977, SOC STUD SCI, V7, P113
   Gleize M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P967
   GOLDMAN AI, 1967, J PHILOS, V64, P357, DOI 10.2307/2024268
   Gottschalk-Mazouz Niels, 2013, ONTOS VERLAG PUBLICA, V0, P7
   Graham J, 2013, ADV EXP SOC PSYCHOL, V47, P55, DOI 10.1016/B978-0-12-407236-7.00002-4
   Graham J, 2009, J PERS SOC PSYCHOL, V96, P1029, DOI 10.1037/a0015141
   Gretz S, 2020, EMNLP FINDINGS, V0, PP528, DOI 10.18653/v1/2020.findings-emnlp.47
   Gretz S, 2020, AAAI CONF ARTIF INTE, V34, P7805
   Gururangan Suchin, 2020, DONT STOP PRETRAININ, V0, PP8342, DOI 10.18653/V1/2020.ACL-MAIN.740
   Habernal I, 2016, P 2016 C EMP METH NA, V0, PP1214, DOI 10.18653/V1/D16-1129
   Habernal I, 2014, P WORKSH FRONT CONN, V0, P0
   Habernal I, 2018, P 2018 C N AM CHAPT, V1, P1930, DOI 10.18653/V1/N18-1175
   Habernal I, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1589
   Habernal I, 2017, COMPUT LINGUIST, V43, P125, DOI 10.1162/COLI_a_00276
   Habernal Ivan, 2018, P NAACL HLT 2018, V0, PP386, DOI 10.18653/v1/N18-1036
   Habernal Ivan, 2018, P 11 INT C LANGUAGE, V0, P0
   Haddadan S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4684
   Haidt J, 2004, DAEDALUS-US, V133, P55, DOI 10.1162/0011526042365555
   Hamblin Charles L, 1970, FALLACIES, V0, P0
   Hasan KS, 2014, P 2014 C EMPIRICAL M, V0, P751
   Hawthorne J, 2002, PHILOS PHENOMEN RES, V65, P247, DOI 10.1111/j.1933-1592.2002.tb00201.x
   Hewett F, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P98
   Hidey C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1756
   Hou Yufang, 2017, P 4 WORKSHOP ARGUMEN, V0, PP60, DOI 10.18653/V1/W17-5107
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, V0, P755
   Hua XY, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2131
   Hua XY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P591
   Hua XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2661
   Hua XY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P219
   Huber L, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P35
   Ji Lu, 2018, P 27 INT C COMP LING, V0, P3703
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Jo Y, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P11
   Kobbe J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P50
   Kobbe Jonathan, 2020, P 7 WORKSHOP ARGUMEN, V0, P30
   Kotonya N, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P156
   Kouylekov Milen, 2010, P ASS COMP LING SYST, V0, P42
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lauscher A, 2020, P DEEP LEARNING INSI, V0, P43
   Lauscher A, 2021, ARXIV, V0, P0
   Lauscher A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3326
   Lauscher Anne, 2020, 27 INT C COMPUTATION, V0, PP4563, DOI 10.18653/v1/2020.coling-main.402
   Lawrence J, 2015, P 2 WORKSHOP ARGUMEN, V0, PP127, DOI 10.3115/V1/W15-0516
   Lawrence J, 2017, P 4 WORKSHOP ARGUMEN, V0, P108
   Lawrence J, 2019, COMPUT LINGUIST, V45, P765, DOI 10.1162/COLI_a_00364
   Lawrence John, 2017, P 4 WORKSHOP ARGUMEN, V0, P39
   Le DT, 2018, P 5 WORKSHOP ARGUMEN, V0, PP121, DOI 10.18653/V1/W18-5215
   Levy Ran, 2017, P 4 WORKSH ARG MIN, V0, PP79, DOI 10.18653/V1/W17-5110
   Li JL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8905
   Liebeck M, 2016, P 3 WORKSHOP ARGUMEN, V0, P144
   Liebeck M, 2018, P 12 INT WORKSH SEM, V0, PP1114, DOI 10.18653/V1/S18-1188
   Liga D, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P92
   Lin BY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1274
   Lin JF, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P67
   Ling W, 2016, P 2016 C N AM CHAPTE, V0, PP47, DOI 10.18653/V1/N16-1007
   Lippi Marco, 2015, THEORY AND APPLICATIONS OF FORMAL ARGUMENTATION.THIRD INTERNATIONAL WORKSHOP (TAFA 2015). REVISED SELECTED PAPERS: LNCS 9524, V0, PP163, DOI 10.1007/978-3-319-28460-6_10
   Liu Y, 2008, IEEE DATA MINING, V0, PP443, DOI 10.1109/ICDM.2008.94
   Lloyd Keith, 2007, RHETOR REV, V26, P365, DOI 10.1080/07350190701577892
   Lugini Luca, 2018, P 5 WORKSHOP ARGUMEN, V0, PP57, DOI 10.18653/v1/W18-5208
   Lukin S, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P742
   Maxwell F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P653
   Mcburney P, 2021, J APPL LOG-IFCOLOG, V8, P263
   McDowell John, 2014, THEAETETUS, V0, P0
   Mensonides Jean-Christophe, 2019, P 3 INT C NATURAL LA, V0, P25
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Moens MF, 2018, ARGUM COMPUT, V9, P1, DOI 10.3233/AAC-170025
   Morio G, 2018, P 5 WORKSH ARG MIN B, V0, P11
   Morio G, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3259
   Niculae V, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P985, DOI 10.18653/v1/P17-1091
   Niven T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4658
   Ong Nathan, 2014, P 1 WORKSHOP ARGUMEN, V0, P24
   Opitz J, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P25
   Passon M, 2018, P 5 WORKSH ARG MIN, V0, PP35, DOI 10.18653/V1/W18-5205
   Paul D, 2020, FRONT ARTIF INTEL AP, V326, P319, DOI 10.3233/FAIA200515
   Peldszus A, 2015, P 2015 C EMP METH NA, V2015, P938, DOI 10.18653/V1/D15-1110
   Persing I, 2010, P 2010 C EMP METH NA, V0, P229
   Persing I, 2016, PROC C N AM ASS COMP, V0, PP1384, DOI 10.18653/V1/N16-1164
   Persing I, 2013, LONG PAPERS, VVolume 1, P260, DOI 10.3115/V1/P14-1144
   Persing I, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6795
   Persing I, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4082
   Persing I, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2174
   Persing I, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1534
   Persing I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P543
   Petasis G, 2019, P 6 WORKSH ARG MIN, V0, P1
   Ponti EM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2362
   Ponti Edoardo M, 2022, ARXIV, V0, P0
   Porco A, 2020, P 28 INT C COMPUTATI, V0, PP396, DOI 10.18653/V1/2020.COLING-MAIN.35
   Potash P, 2017, P 2017 C EMP METH NA, V0, PP1364, DOI 10.18653/V1/D17-1143
   Potash P, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P146
   Potthast M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1117, DOI 10.1145/3331184.3331327
   Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4932
   Rajendran Pavithra, 2018, P 11 INT C LANGUAGE, V0, P0
   Rajendran Pavithra, 2018, P 2018 C N AM CHAPTE, V0, PP28, DOI 10.18653/v1/N18-2005
   Ranade Sarvesh, 2013, P SIGDIAL 2013 C, V0, P61
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P567
   Reisert Paul, 2015, P 2 WORKSHOP ARGUMEN, V0, P45
   Rinott Ruty, 2015, EMNLP, V0, PP440, DOI 10.18653/v1/D15-1050
   Rumshisky A, 2017, P 8 INT JOINT C NATU, V0, P342
   Saint-Dizier Patrick, 2017, P 4 WORKSHOP ARGUMEN, V0, PP85, DOI 10.18653/v1/W17-5111
   Sap M, 2020, P 58 ANN M ASS COMPU, V0, PP27, DOI 10.18653/V1/2020.ACL-TUTORIALS.7
   Sato M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2015): SYSTEM DEMONSTRATIONS, V0, P109
   Schaefer R, 2021, IT-INF TECHNOL, V63, P45, DOI 10.1515/itit-2020-0053
   Schiller B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P380
   Schulz C, 2018, P 2018 C N AM CHAPT, V2, P35
   Scialom Thomas, 2020, P 2020 C EMP METH NA, V0, PP2625, DOI 10.18653/v1/2020. findings- emnlp.238
   Shnarch E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P599
   Shnarch Eyal, 2017, P 2017 C EMP METH NA, V0, PP1345, DOI 10.18653/V1/D17-1140
   Simpson Edwin D, 2018, T ASS COMPUTATIONAL, V6, P357, DOI 10.1162/tacl_a_00026
   Sirrianni J, 2020, P 58 ANN M ASS COMP, V0, PP5746, DOI 10.18653/v1/2020.acl-main.509
   Skitalinskaya G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1718
   Slonim N, 2018, FRONT ARTIF INTEL AP, V305, P4, DOI 10.3233/978-1-61499-906-5-4
   Sobhani P, 2017, P EACL, V0, P551
   Sobhani P, 2015, P 2 WORKSH ARG MIN, V0, P67
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Somasundaran S, 2010, P NAACL HLT 2010 WOR, V0, P116
   Song Yi, 2014, P 1 WORKSHOP ARGUMEN, V0, P69
   Spliethover M, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), V0, P74
   Stab C, 2014, P 2014 C EMP METH NA, V0, PP46, DOI 10.3115/V1/D14-1006
   Stab C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3664
   Stab C, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P980
   Stab C, 2017, COMPUT LINGUIST, V43, P619, DOI 10.1162/COLI_a_00295
   Stab Christian, 2016, P 3 WORKSHOP ARGUMEN, V0, P113
   Stab Christian, 2018, P 2018 C N AM CHAPTE, V0, PP21, DOI 10.18653/V1/N18-5005
   Stede Manfred, 2018, SYNTHESIS LECT HUMAN, V11(, P1, DOI 10.1007/978-3-031-02169-5
   Sui Guobin, 2018, P 12 INT WORKSHOP SE, V0, PP1129, DOI 10.18653/v1/S18-1191
   Sun Qingying, 2018, P 27 INT C COMPUTATI, V0, P2399
   Syed Shahbaz, 2020, P 28 INT C COMPUTATI, V0, PP5384, DOI 10.18653/v1/2020.coling-main.470
   Tan CH, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16), V0, PP613, DOI 10.1145/2872427.2883081
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Teufel S, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P110
   Teufel Simone, 2009, P 2009 C EMP METH NA, V0, PP1493, DOI 10.3115/1699648.1699696
   Tian Junfeng, 2018, P 12 INT WORKSHOP SE, V0, PP1094, DOI 10.18653/v1/S18-1184
   Toledo A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5625
   Toledo-Ronen O, 2020, FINDINGS ASS COMPUTA, V0, P303
   Toledo-Ronen Orith, 2016, P 3 WORKSHOP ARGUMEN, V0, PP119, DOI 10.18653/v1/W16-2814
   Trautmann D, 2020, AAAI CONF ARTIF INTE, V34, P9048
   Trautmann Dietrich, 2020, P 7 WORKSHOP ARGUMEN, V0, P41
   Vreeswijk GAW, 1997, ARTIF INTELL, V90, P225, DOI 10.1016/S0004-3702(96)00041-0
   Wachsmuth H, 2018, P 27 INT C COMPUTATI, V0, P3753
   Wachsmuth H, 2016, 26 INT C COMPUTATION, V0, P1680
   Wachsmuth H, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P176
   Wachsmuth H, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1117
   Wachsmuth Henning, 2020, P 28 INT C COMPUTATI, V0, PP6739, DOI 10.18653/v1/2020.coling-main.592
   Wachsmuth Henning, 2017, 4 WORKSH ARG MIN ARG, V0, PP49, DOI 10.18653/v1/w17-5106
   Walton D, 2008, ARGUMENTATION SCHEMES, V0, PP1, DOI 10.1017/CBO9780511802034
   Wang H, 2020, P 28 INT C COMPUTATI, V0, PP5480, DOI 10.18653/v1/2020.colingmain.478
   [王末 Wang Mo], 2020, 数据分析与知识发现 DATA ANALYSIS AND KNOWLEDGE DISCOVERY, V4, P60
   Wei ZY, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P195
   Williams Adina, 2017, ARXIV170405426, V0, P0
   Yang D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3620
   Yunfan Gu, 2018, P 5 WORKSHOP ARGUMEN, V0, PP97, DOI 10.18653/v1/2020.acl-main.740
   Zukerman I, 2000, P 1 INT NAT LANG GEN, V0, PP55, DOI 10.3115/1118253.1118262
NR 219
TC 1
Z9 1
U1 3
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD DEC 22
PY 2022
VL 10
IS 
BP 1392
EP 1422
DI 10.1162/tacl_a_00525
PG 31
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8I3JF
UT WOS:000921620700001
DA 2023-11-10
ER

PT J
AU Han, JB
   Wang, HZ
AF Han, Jiabao
   Wang, Hongzhi
TI A meta learning approach for open information extraction
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Open information extraction; Meta learning
AB As one of the most important research topics in the field of natural language processing, open information extraction has achieved gratifying research findings in recent years. Even if so much effort is put into the work of open information extraction, there are still many shortcomings and great room for improvement in the existing system. The traditional open information extraction task relies heavily on the artificially defined extraction paradigm, and it will produce error accumulation and propagation. The end-to-end model relies on a large number of training data, and it is hard to re-train with the increase of the model. To cope with the difficulty of updating parameters of large neural network models, in this paper, we propose a solution based on the meta-learning framework, we design a neural network-based converter module, which effectively combines the learned model parameters with the new model parameters. Then update the parameters of the original open information extraction model using the parameters calculated by the converter. This can not only avoid the problem of error propagation of traditional models but also effectively deal with the iterative updating of open information extraction models. We employ a large and public Open IE benchmark to demonstrate the performance of our approach. The experimental results show that our model can achieve better performance than existing baselines, and compared with the re-training model, our strategy can not only greatly shorten the update time of the model, but also not lose the performance of the model completely re-trained with all the training data.
C1 [Han, Jiabao; Wang, Hongzhi] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, HZ (通讯作者)，Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM jiabaohan@outlook.com; wangzh@hit.edu.cn
FU NSFC [U1866602, 61772157]
CR Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   Bahdanau D, 2016, ARXIV, V0, P0
   Binici K, 2021, ARXIVABS210805698 CO, V0, P0
   Cetto M, 2018, GRAPHENE 1807 11276, V0, P0
   Chong YW, 2021, APPL INTELL, V51, P5219, DOI 10.1007/s10489-020-02107-2
   Christensen J, 2010, P NAACL HLT 2010 1 I, V0, P52
   Cui L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P407
   del Corro L, 2013, P 22 INT C WORLD WID, V0, PP355, DOI 10.1145/2488388.2488420
   Diaz-Aviles E, 2012, P 6 ACM C REC SYST, V0, PP59, DOI 10.1145/2365952.2365968
   Etzioni O, 2011, P 22 INT JOINT C ART, V0, PP3, DOI 10.5591/978-1-57735-516-8/IJCAI11-012
   Etzioni O, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1409360.1409378
   Fader A, 2011, P C EMPIRICAL METHOD, V0, PP1535, DOI 10.1234/12345678
   Feng Y, 2021, KNOWL-BASED SYST, V217, P0, DOI 10.1016/j.knosys.2021.106829
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Gashteovski K, 2017, P 2017 C EMP METH NA, V0, P2620
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Han J, 2021, NEURAL PROCESS LETT, V0, P1
   Hoffman J, 2014, 2 INT C LEARN REPR I, V0, P0
   Huang HY, 2021, INFORM FUSION, V76, P145, DOI 10.1016/j.inffus.2021.05.013
   Ioffe Sergey, 2015, ARXIV 1502 03167, V0, P448
   Liu MY, 2016, ADV NEUR IN, V29, P0
   Madan A, 1900, P2730, V0, P0, DOI DOI 10.1109/ICASSP39728.2021.9414437
   Mausam, 2016, P 25 INT JOINT C ART, V0, P4074
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Pal Harinder, 2016, P 5 WORKSH AUT KNOWL, V0, PP35, DOI 10.18653/V1/W16-1307
   Pascanu R, 2013, P 30 INT C MACHINE L, V0, P0
   Patterson DA, 2021, ARXIVABS210410350 CO, V0, P0
   Saha S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P317, DOI 10.18653/v1/P17-2050
   Salthouse TA, 2000, HDB AGING COGNITION, V0, P359
   Schmitz M, 2012, P 2012 JOINT C EMPIR, V0, P523
   Schneider Rudolf, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Stanovsky G, 2016, P 2016 C EMPIRICAL M, V0, P2300
   Stanovsky G, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Stanovsky Gabriel, 2018, P 2018 C N AM CHAPTE, V0, PP885, DOI 10.18653/v1/N18-1081
   Sun J, 2021, IEEE T IMAGE PROCESS, V30, P2935, DOI 10.1109/TIP.2021.3056889
   Triantafillou E, 2020, DATASET DATASETS LEA, V0, P26
   Tzeng E, 2017, PROC CVPR IEEE, V0, PP2962, DOI 10.1109/CVPR.2017.316
   Wu F, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P118
   Yates A, 2007, P HUM LANG TECHN ANN, V0, PP25, DOI 10.3115/1614164.1614177
   Yin M, 2020, 8 INT C LEARN REPR I, V0, P0
   Yu T, 2019, META WORLD BENCHMARK, V0, P0
   Zhang Y, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP1479, DOI 10.1145/3397271.3401167
NR 44
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD AUG 15
PY 2022
VL 34
IS 15
BP 12681
EP 12694
DI 10.1007/s00521-022-07114-7
EA MAR 2022
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3E6IS
UT WOS:000769862900006
DA 2023-11-10
ER

PT J
AU Zhang, SK
   Jiang, L
   Tan, JL
AF Zhang, Shaokang
   Jiang, Lei
   Tan, Jianlong
TI Cross-domain knowledge distillation for text classification
SO NEUROCOMPUTING
LA English
DT Article
DE Knowledge distillation; Domain adaptation; Multi -teacher knowledge vote; Text classification
AB Most text classification methods achieve great success based on the large-scale annotated data and the pre-trained language models. However, the labeled data is insufficient in practice, and the pre-trained language models are difficult to deploy due to their high computing resources and slow inference speed. In this paper, we propose cross-domain knowledge distillation, where the teacher and student tasks belong to different domains. It not only acquires knowledge from multiple teachers but also accelerates inference and reduces model size. Specifically, we train the pre-trained language models on factual knowledge obtained by aligned Wikipedia text to Wikidata triplets and fine-tune it as the teacher model. Then we use the heterogeneous multi-teacher knowledge distillation to transfer knowledge from the multiple teacher models to the student model. Multi-teacher knowledge vote can distill knowledge related to the target domain. Moreover, we also introduce the teacher assistant to help distill large pre-trained language models. Finally, we reduce the difference between the source domain and target domain by multi-source domain adaptation to solve the domain shift problem. Experiments on the mul-tiple public datasets demonstrate that our method can achieve competitive performance while having fewer parameters and less inference time.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Shaokang; Jiang, Lei; Tan, Jianlong] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   [Zhang, Shaokang; Jiang, Lei; Tan, Jianlong] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Zhang, SK (通讯作者)，Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.; Zhang, SK (通讯作者)，Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
EM zhangshaokang@iie.ac.cn
CR Borgwardt KM, 2006, BIOINFORMATICS, V22, PE49, DOI 10.1093/bioinformatics/btl242
   Chen C, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), V0, PP2613, DOI 10.1145/3442381.3449814
   Clark K, 2019, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Dong CH, 2021, ARXIV, V0, P0
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Gong YC, 2014, ARXIV, V0, P0
   Guo H, 2020, ARXIV, V0, P0
   Han S, 2015, ADV NEUR IN, V28, P0
   Hinton G, 2015, ARXIV, V0, P0
   Jiao XQ, 2020, ARXIV, V0, P0
   Lan ZZ, 2020, ARXIV, V0, P0
   Li YC, 2021, NEUROCOMPUTING, V463, P368, DOI 10.1016/j.neucom.2021.08.019
   Li Z, 2018, 32 AAAI C ARTIFICIAL, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Peng ML, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2505
   Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042
   Sanh V, 2020, ARXIV, V0, P0
   Serban IV, 2016, AAAI CONF ARTIF INTE, V0, P3776
   Sun S, 2019, ARXIV, V0, P0
   Sun ZQ, 2020, ARXIV, V0, P0
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Tang RP, 2019, ARXIV, V0, P0
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang RZ, 2020, ARXIV, V0, P0
   Wang Wenhui, 2020, ARXIV200210957, V0, P0, DOI DOI 10.1145/3308558.3313562
   Wu C, 2021, ARXIV, V0, P0
   Yang Z, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM 20), V0, PP690, DOI 10.1145/3336191.3371792
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yim J, 2017, PROC CVPR IEEE, V0, PP7130, DOI 10.1109/CVPR.2017.754
   Zhan ZQ, 2020, NEUROCOMPUTING, V406, P1, DOI 10.1016/j.neucom.2020.03.093
   Zhang B, 2021, P 59 ANN M ASS COMPU, V1, P5423, DOI 10.18653/V1/2021.ACL-LONG.421
   Zhao H, 2018, 6 INT C LEARNING REP, V0, P0
NR 35
TC 1
Z9 1
U1 8
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 14
PY 2022
VL 509
IS 
BP 11
EP 20
DI 10.1016/j.neucom.2022.08.061
EA AUG 2022
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4F2ND
UT WOS:000848351800002
DA 2023-11-10
ER

PT J
AU Yin, GZ
   Wang, X
   Zhang, HL
   Wang, JL
AF Yin, Gongzhu
   Wang, Xing
   Zhang, Hongli
   Wang, Jinlin
TI Cost-effective CNNs-based prototypical networks for few-shot relation classification across domains
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Relation classification; Few-shot learning; Domain adaptation; Prototypical network
AB This paper studies few-shot relation classification under domain shift, which is quite a challenging inductive task in practice. Previous work focusing on few-shot relation classification usually adopted prototypical networks, whose performance dramatically dropped when adapting to diverse domains. Some researches introduced large pretrained language models, which consume massive time and computation resources. To address the above issues, we propose cost-effective CNNs-based prototypical networks in this paper. Specifically, a multichannel encoder (MCE) is adopted to capture general domain invariant features respectively from the entity and the context, then they are aggregated according to relation classes. When encoding the context, we propose an attention mechanism based on the dependency trees of sentences to effectively select helpful grams. To get further improvements, we leverage the unlabeled data from the target domain by pseudo-labeling and introduce a method to select instances with high confidence via information entropy. We conducted experiments on two public datasets: FewRel 2.0 and FewTAC. The results demonstrate that our approaches not only largely enhance the effectiveness of original prototypical networks, but also achieve competitive results with large pretrained models with faster speeds and much fewer computational costs. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Yin, Gongzhu; Wang, Xing; Zhang, Hongli; Wang, Jinlin] Harbin Inst Technol, Sch Cyberspace Sci, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Zhang, HL (通讯作者)，Harbin Inst Technol, Sch Cyberspace Sci, Harbin, Heilongjiang, Peoples R China.
EM yingz@hit.edu.cn; wxhit@hit.edu.cn; zhanghongli@hit.edu.cn; wangjl@hit.edu.cn
FU National Key Research and Development Program of China [2016YFE0206700]
CR [Anonymous], 2009, RES LANG COMPUT, V0, P0, DOI DOI 10.1007/S11168-009-9061-2
   Bunescu RC, 2005, PROC ADV NEURAL INF, V0, P171
   Bunescu RC, 2005, P C HUM LANG TECHN E, V0, PP724, DOI 10.3115/1220575.1220666
   Cong X, 2020, MACHINE LEARNING KNO, V0, PP624, DOI 10.1007/2F978-3-030-67661-2_37
   Daojian Zeng, 2014, P COLING 25 INT C CO, V0, P2335
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dozat T, 2017, ICLR, V0, P0
   Fangchao Liu, 2021, CHINESE COMPUTATIONAL LINGUISTICS: 20TH CHINA NATIONAL CONFERENCE, V0, Proceedings. Lecture Notes in Computer Science
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Gao TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6250
   Gao TY, 2019, AAAI CONF ARTIF INTE, V0, P6407
   Geng XQ, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP415, DOI 10.1145/3340531.3411858
   Guo ZJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P241
   Han X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4803
   Koch Gregory, 2015, P INT C MACH LEARN W, V2, P0, DOI 10.1136/BMJ.2.5108.1355-C
   Li Q, 2020, KNOWL-BASED SYST, V194, P0, DOI 10.1016/j.knosys.2020.105488
   Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124
   Min Bonan, 2013, P 2013 C N AM CHAPT, V0, PP777, DOI 10.1186/S40537-016-0043-6
   Mintz M, 2009, P JOINT C 47 ANN M A, V0, PP1003, DOI 10.3115/1690219.1690287
   Peng H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3661
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qin YX, 2021, KNOWL-BASED SYST, V213, P0, DOI 10.1016/j.knosys.2020.106609
   Qu M, 2020, INT C MACH LEARN, V0, P7867
   Ren Haopeng, 2020, P 28 INT C COMP LING, V0, PP1618, DOI 10.18653/V1/2020.COLINGMAIN.142
   Snell J, 2017, ADV NEUR IN, V30, P0
   Song LF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2226
   Stoica G, 2021, AAAI CONF ARTIF INTE, V35, P13843
   Sung F, 2018, PROC CVPR IEEE, V0, PP1199, DOI 10.1109/CVPR.2018.00131
   Vinyals Oriol, 2016, ADV NEURAL INFORM PR, V29, P0, DOI 10.48550/ARXIV.1606.04080
   Wang Y, 2020, P 28 INT C COMPUTATI, V0, P5799
   Wen Qian, 2021, 2021 IEEE 6TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS), V0, PP134, DOI 10.1109/ICCCS52626.2021.9449297
   Xie YX, 2020, KNOWL-BASED SYST, V194, P0, DOI 10.1016/j.knosys.2020.105548
   Xu Y, 2015, P 2015 C EMP METH NA, V0, PP1785, DOI 10.18653/V1/D15-1206
   Yang KJ, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP2273, DOI 10.1145/3340531.3412153
   Yu M, 2015, P 2015 C N AM CHAPT, V0, PP1374, DOI 10.3115/V1/N15-1155
   Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205
   Zeng D, 2015, P 2015 C EMPIRICAL M, V0, P1753
   Zhang JW, 2021, KDD 21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2183, DOI 10.1145/3447548.3467438
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2205
   Zheng SC, 2016, KNOWL-BASED SYST, V114, P12, DOI 10.1016/j.knosys.2016.09.019
   Zhou G, 2005, P 43 ANN M ASS COMPU, V0, P0, DOI DOI 10.3115/1219840.1219893
NR 41
TC 2
Z9 2
U1 10
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD OCT 11
PY 2022
VL 253
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.109470
EA AUG 2022
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 6M8DD
UT WOS:000889091500006
DA 2023-11-10
ER

PT J
AU Laskar, MTR
   Hoque, E
   Huang, JX
AF Laskar, Md Tahmid Rahman
   Hoque, Enamul
   Huang, Jimmy Xiangji
TI Domain Adaptation with Pre-trained Transformers for Query-Focused Abstractive Text Summarization
SO COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB The Query-Focused Text Summarization (QFTS) task aims at building systems that generate the summary of the text document(s) based on the given query. A key challenge in addressing this task is the lack of large labeled data for training the summarization model. In this article, we address this challenge by exploring a series of domain adaptation techniques. Given the recent success of pre-trained transformer models in a wide range of natural language processing tasks, we utilize such models to generate abstractive summaries for the QFTS task for both single-document and multi-document scenarios. For domain adaptation, we apply a variety of techniques using pre-trained transformer-based summarization models including transfer learning, weakly supervised learning, and distant supervision. Extensive experiments on six datasets show that our proposed approach is very effective in generating abstractive summaries for the QFTS task while setting a new state-of-the-art result in several datasets across a set of automatic and human evaluation metrics.
C1 [Laskar, Md Tahmid Rahman] Dialpad Canada Inc, Vancouver, BC, Canada.
   [Laskar, Md Tahmid Rahman; Huang, Jimmy Xiangji] York Univ, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
   [Hoque, Enamul] York Univ, Sch Informat Technol, Toronto, ON, Canada.
C3 York University - Canada; York University - Canada
RP Laskar, MTR (通讯作者)，Dialpad Canada Inc, Vancouver, BC, Canada.; Laskar, MTR (通讯作者)，York Univ, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
EM tahmedge@cse.yorku.ca; enamulh@yorku.ca; jhuang@yorku.ca
FU Natural Sciences~& Engineering Research Council (NSERC) of Canada; York Research Chairs (YRC) program; ORF-RE (Ontario Research Fund-Research Excellence) award in BON Alliance
CR Abdullah DM, 2020, P 13 INT C NATURAL L, V0, P80
   [Anonymous], 2007, P 30 ANN INT ACM SIG, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Aryal Chudamani, 2020, ADVANCES IN ARTIFICIAL INTELLIGENCE. 33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P118, DOI 10.1007/978-3-030-47358-7_11
   Brown TB, 2020, ARXIV, V0, P0
   Baumel T, 2018, ARXIV, V0, P0
   Beltagy I, 2020, ARXIV, V0, P0
   Chopra S, 2016, P 2016 C N AM ASS CO, V0, P93
   Choromanski K, 2021, ARXIV, V0, P0
   Clark K, 2020, ARXIV, V0, P0
   Deng Y, 2019, ARXIV, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong Li, 2019, ADV NEURAL INFORM PR, V32, P13042
   Fabbri AR, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P704
   Feigenblat G, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP961, DOI 10.1145/3077136.3080690
   Fu Xue Yong, 2021, P 7 WORKSH NOIS US G, V0, PP168, DOI 10.18653/v1/2021.wnut-1.19
   Garg S, 2019, ARXIV, V0, P0
   Goodwin Travis R, 2020, PROC INT CONF COMPUT LING, V2020, P5640
   Haghighi Aria, 2009, P HUM LANG TECHN 200, V0, P0, DOI DOI 10.3115/1620754.1620807
   Hermann KM, 2015, ADV NEURAL INFORM PR, V0, P0
   Huang XJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP307, DOI 10.1145/1571941.1571995
   Huang Xiangji, 2005, P 14 TEXT RETRIEVAL, V0, P56
   Ishigaki Tatsuya, 2020, ADVANCES IN INFORMATION RETRIEVAL. 42ND EUROPEAN CONFERENCE ON IR RESEARCH, V0, P174, DOI 10.1007/978-3-030-45442-5_22
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI20), V0, P0, DOI DOI 10.1145/3313831.3376467
   Kitaev Nikita, 2020, ARXIV200104451, V0, P0
   Kulkarni S, 2020, ARXIV, V0, P0
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lai T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5953
   Lan ZZ, 2020, ARXIV, V0, P0
   Laskar Md Tahmid Rahman, 2020, ADVANCES IN ARTIFICIAL INTELLIGENCE. 33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P342, DOI 10.1007/978-3-030-47358-7_35
   Laskar MTR, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5505
   Laskar Md Tahmid Rahman, 2020, P COLING, V0, P5647
   Lewis M, 2019, ARXIV, V0, P0
   Li W, 2021, IEEE T KNOWL DATA EN, V33, P43, DOI 10.1109/TKDE.2019.2922957
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu XD, 2019, ARXIV, V0, P0
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3730
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Liu YH, 2019, ARXIV, V0, P0
   Louis A, 2013, COMPUT LINGUIST, V39, P267, DOI 10.1162/COLI_a_00123
   Ma S, 2016, P COLING 2016, V0, P1514
   MengqiuWang Noah A, 2007, P 2007 JOINT C EMP M, V0, P22
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Nema P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1063, DOI 10.18653/v1/P17-1098
   Nishida K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2273
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Pasunuru R, 2021, ARXIV, V0, P0
   Paulus R, 2017, DEEP REINFORCED MODE, V0, P0
   Peters ME, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), V0, P7
   Qi Weizhen, 2020, FINDINGS ASS COMPUTA, V0, PP2401, DOI 10.18653/v1/2020.findingsemnlp.217
   Qiu XP, 2021, ARXIV, V0, P0
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, ARXIV, V0, P0
   Ramponi Alan, 2020, P 28 INT C COMPUTATI, V0, PP6838, DOI 10.18653/V1/2020.COLING-MAIN.603
   Reiter E, 2018, COMPUT LINGUIST, V44, P393, DOI 10.1162/COLI.a.00322
   Roitman H, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2577, DOI 10.1145/3366423.3380009
   Rush AM, 2015, P EMNLP 15, V0, P0
   Sanh Victor, 2021, ARXIV, V0, P0, DOI DOI 10.1145/3295750.3298916
   Savery M, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-00667-z
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Song KT, 2019, PR MACH LEARN RES, V97, P0
   Su D, 2020, ARXIV, V0, P0
   Su D, 2021, ARXIV, V0, P0
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Laskar MTR, 2020, ARXIV, V0, P0
   Tay Y, 2022, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wan XJ, 2014, SIGIR14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP787, DOI 10.1145/2600428.2609559
   Wan XJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), V0, P1586
   Wang Dingding, 2008, P 17 ACM C INF KNOWL, V0, PP1435, DOI 10.1145/1458082.1458319
   Wang SN, 2020, ARXIV, V0, P0
   Wang YZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1918
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Xenouleas S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6005
   Xie YJ, 2020, ARXIV, V0, P0
   Xu Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3632
   Xu Yumo, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Xu Yumo, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Yang Yi, 2015, P 2015 C EMP METH NA, V0, PP2013, DOI 10.18653/V1/D15-1237
   Yao JG, 2017, KNOWL INF SYST, V53, P297, DOI 10.1007/s10115-017-1042-4
   Yao JG, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1376
   Young T, 2018, ARXIV, V0, P0
   Yu XH, 2012, IEEE T KNOWL DATA EN, V24, P720, DOI 10.1109/TKDE.2010.269
   Yuan WZ, 2021, ARXIV, V0, P0
   Zaheer M, 2021, ARXIV, V0, P0
   Zhang JQ, 2020, ARXIV, V0, P0
   Zhang Tianyi, 2019, ICLR, V0, P0
   Zhong M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5905
   Zhong SH, 2015, EXPERT SYST APPL, V42, P8146, DOI 10.1016/j.eswa.2015.05.034
   Zhou GY, 2021, INFORM SCIENCES, V547, P103, DOI 10.1016/j.ins.2020.08.037
NR 90
TC 3
Z9 3
U1 6
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0891-2017
EI 1530-9312
J9 COMPUT LINGUIST
JI Comput. Linguist.
PD JUN 15
PY 2022
VL 48
IS 2
BP 279
EP 320
DI 10.1162/coli_a_00434
PG 42
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA H1QU6
UT WOS:000993786300002
DA 2023-11-10
ER

PT J
AU Aljedaani, W
   Rustam, F
   Mkaouer, MW
   Ghallab, A
   Rupapara, V
   Washington, PB
   Lee, E
   Ashraf, I
AF Aljedaani, Wajdi
   Rustam, Furqan
   Mkaouer, Mohamed Wiem
   Ghallab, Abdullatif
   Rupapara, Vaibhav
   Washington, Patrick Bernard
   Lee, Ernesto
   Ashraf, Imran
TI Sentiment analysis on Twitter data integrating TextBlob and deep learning models: The case of US airline industry
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Knowledge-based systems; Sentiment analysis; Lexicon-based approach; Machine learning; Natural language processing
AB Twitter being among the popular social media platforms, provide peoples' opinions regarding specific ideas, products, services, etc. The large amounts of shared data as tweets can help extract users' sentiment and provide valuable feedback to improve the quality of products and services alike. Similar to other service industries, the airline industry utilizes such feedback for determining customers' satisfaction levels and improving the quality of experience where needed. This, of course, requires accurate sentiments from the user tweets. Existing sentiment analysis models suffer from low accuracy on account of the contradictions found in the tweet text and the assigned label. From this perspective, this study proposes a hybrid sentiment analysis approach where the lexicon-based methods are used with deep learning models to improve sentiment accuracy. Experiments involve analyzing the impact of TextBlob on the classification accuracy of models as against the original annotations, considering that the probability of the false annotations cannot be overlooked. Furthermore, the efficacy of TextBlob against Afinn and VADER (Valence Aware Dictionary for Sentiment Reasoning) is also evaluated. The CNN (Convolutional Neural Network), LSTM (Long Short-Term Memory), GRU (Gated Recurrent Unit), and CNN-LSTM are deployed in comparison with state-of-the-art machine learning models. Additionally, the efficiency and efficacy of TF-IDF (Term Frequency-Inverse Document Frequency) and BoW (Bag of Words) are also investigated. Results suggest that models perform better when trained using the TextBlob assigned sentiments as compared to the original sentiments in the dataset. LSTM-GRU outperforms all models and previous studies with the highest 0.97 accuracy and 0.96 F1 scores. From machine learning models, the support vector classifier and extra tree classifier achieve the highest accuracy score of 0.92, with TF-IDF and BoW, respectively. Despite the good performance of the models using the TextBlob labels, TextBlob-based annotation cannot replace humans. Our stance is that with humans, bias, error-proneness, and subjectivity cannot be ignored; so we propose that the TextBlob-annotated labels can be used as assistance for human annotators where human annotators can wet the TextBlob-annotated dataset.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Aljedaani, Wajdi] Univ North Texas, USA, TX 76203 USA.
   [Rustam, Furqan] Univ Management & Technol, Sch Syst & Technol, Dept Software Engn, Lahore 54770, Pakistan.
   [Mkaouer, Mohamed Wiem] Rochester Inst Technol, Rochester, NY USA.
   [Ghallab, Abdullatif] Univ Sci & Technol, Fac Comp & Informat Technol, Sanaa, Yemen.
   [Rupapara, Vaibhav] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
   [Washington, Patrick Bernard] Morehouse Coll, Div Business Adm & Econ, Atlanta, GA USA.
   [Lee, Ernesto] Miami Dade Coll, Coll Engn & Technol, Miami, FL 33176 USA.
   [Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 University of North Texas System; University of North Texas Denton; University of Management & Technology (UMT); Rochester Institute of Technology; State University System of Florida; Florida International University; Morehouse College; Yeungnam University
RP Ashraf, I (通讯作者)，Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM imranashraf@ynu.ac.kr
CR Al-Qahtani R, 2021, PREDICT SENTIMENT AI, V0, P0
   Aljarah I, 2017, PROC NEW TRENDS INFO, V0, P176
   Alkhazi B, 2020, APPL SOFT COMPUT, V95, P0, DOI 10.1016/j.asoc.2020.106667
   Anandarajan M, 1900, V2, V0, P0
   [Anonymous], 2012, INT J COMPUTER SCI, V0, P0
   [Anonymous], 2018, INT J COMPUT INF ENG, V0, P0
   [Anonymous], 2013, P 8 WORKSHOP INNOVAT, V0, P0
   Baker DMA, 2013, AMERICAN JOURNAL OF TOURISM RESEARCH, V2, P67
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, V0, P452
   Banerjee S, 2019, J GLOB MARK, V32, P377
   Bocca FF, 2016, COMPUT ELECTRON AGR, V128, P67, DOI 10.1016/j.compag.2016.08.015
   Chiong R, 2021, IEEE INTELL SYST, V36, P99, DOI 10.1109/MIS.2021.3093660
   Dai AA, 2022, INT J DATA SCI ANAL, V14, P17, DOI 10.1007/s41060-022-00315-2
   Deitel PJ, 2020, INTRO PYTHON COMPUTE, V0, P0
   DEVAKUNCHARI R, 2014, INT J SCI RES PUBL, V4, P1
   Devitt A, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1063
   Dzisevic R, 2019, 2019 OP C EL ELECT, V0, PP1, DOI 10.1109/estream.2019.8732167
   Eler DM, 2018, INFORMATION, V9, P0, DOI 10.3390/info9040100
   Eshan SC, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), V0, P0
   Gilbert CHE, 2014, 8 INT C WEBL SOC MED, V81, P82
   Gupta P, 2021, IEEE T COMPUT SOC SY, V8, P992, DOI 10.1109/TCSS.2020.3042446
   Hasan A, 2018, MATH COMPUT APPL, V23, P0, DOI 10.3390/mca23010011
   Hasib Khan Md, 2021, PROCEEDINGS OF 2021 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY FOR SUSTAINABLE DEVELOPMENT (ICICT4SD), V0, PP450, DOI 10.1109/ICICT4SD50815.2021.9396879
   Hayashi C, 1998, DATA SCI CLASSIFICAT, V0, P40
   Horrigan J, 2008, ONLINE SHOPPING INTE, V0, P0
   Jamil R, 2021, PEERJ COMPUT SCI, V7, P0, DOI 10.7717/peerj-cs.645
   Keramatfar A, 2022, COGN COMPUT, V14, P2234, DOI 10.1007/s12559-021-09986-8
   Khairnar J, 2013, INT J SCI RES PUBLIC, V3, P1
   Kumari S, 2022, ACTA SCI-TECHNOL, V44, P0, DOI 10.4025/actascitechnol.v44i1.58658
   Kwon HJ, 2021, INFORMATION, V12, P0, DOI 10.3390/info12020078
   Li J, 2019, TURK J ELECTR ENG CO, V27, P1794, DOI 10.3906/elk-1806-38
   Liang B, 2022, KNOWL-BASED SYST, V235, P0, DOI 10.1016/j.knosys.2021.107643
   Liu Y, 2017, EXPERT SYST APPL, V80, P323, DOI 10.1016/j.eswa.2017.03.042
   Mujahid M, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11188438
   Pandey AC, 2017, INFORM PROCESS MANAG, V53, P764, DOI 10.1016/j.ipm.2017.02.004
   Qaisi LM, 2016, INT CONF COMP SCI, V0, P0
   Rainie L, 2007, ELECTION 2006 ONLINE, V0, P2010
   Rane A, 2018, P INT COMP SOFTW APP, V0, PP769, DOI 10.1109/COMPSAC.2018.00114
   Reshi AA, 2022, HEALTHCARE-BASEL, V10, P0, DOI 10.3390/healthcare10030411
   Rustam F, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21111078
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Safdari N, 2019, PROC SPIE, V10989, P0, DOI 10.1117/12.2519226
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Sarkar Dipanjan, 2019, TEXT ANAL PYTHON PRA, V0, P0
   Sarkar S, 1900, V2, V0, P0
   Sazzed S, 2021, MACH LEARN APPL, V4, P100026, DOI 10.1016/J.MLWA.2021.100026
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Umer M, 2021, COMPUT INTELL-US, V37, P409, DOI 10.1111/coin.12415
   Vijayarani S, 2016, ADV COMPUTATIONAL IN, V3, P37
   Vo Hung T, 2016, J COMPUT SCI INF TEC, V6, P27
   Xie KL, 2016, J TRAVEL TOUR MARK, V33, P211, DOI 10.1080/10548408.2015.1050538
   Ye Q, 2009, INT J HOSP MANAG, V28, P180, DOI 10.1016/j.ijhm.2008.06.011
   Zhao AP, 2021, KNOWL-BASED SYST, V227, P0, DOI 10.1016/j.knosys.2021.107220
NR 58
TC 12
Z9 12
U1 8
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 14
PY 2022
VL 255
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.109780
EA SEP 2022
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4Z9WF
UT WOS:000862548500003
DA 2023-11-10
ER

PT J
AU Maier, B
   Narayanan, SM
   de Castro, G
   Goncharov, M
   Paus, C
   Schott, M
AF Maier, B.
   Narayanan, S. M.
   de Castro, G.
   Goncharov, M.
   Paus, Ch
   Schott, M.
TI Pile-up mitigation using attention
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE LHC; HL-LHC; pile-up; transformers; machine learning
AB Particle production from secondary proton-proton collisions, commonly referred to as pile-up, impair the sensitivity of both new physics searches and precision measurements at large hadron collider (LHC) experiments. We propose a novel algorithm, Puma, for modeling pile-up with the help of deep neural networks based on sparse transformers. These attention mechanisms were developed for natural language processing but have become popular in other applications. In a realistic detector simulation, our method outperforms classical benchmark algorithms for pile-up mitigation in key observables. It provides a perspective for mitigating the effects of pile-up in the high luminosity era of the LHC, where up to 200 proton-proton collisions are expected to occur simultaneously.
C1 [Maier, B.] CERN, Geneva, Switzerland.
   [de Castro, G.] CALTECH, Pasadena, CA 91125 USA.
   [Goncharov, M.; Paus, Ch] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Schott, M.] Johannes Gutenberg Univ Mainz, Mainz, Germany.
C3 European Organization for Nuclear Research (CERN); California Institute of Technology; Massachusetts Institute of Technology (MIT); Johannes Gutenberg University of Mainz
RP Maier, B (通讯作者)，CERN, Geneva, Switzerland.
EM benedikt.maier@cern.ch
FU U.S. National Science Foundation [PHY-1624356]; U.S. Department of Energy Office of Science Office of Nuclear Physics [DE-SC0011939]; U.S. Department of Energy (DOE) [DE-SC0011939] Funding Source: U.S. Department of Energy (DOE)
CR Bahdanau D, 2016, ARXIV, V0, P0
   Beltagy Iz, 2020, ARXIV 200405150, V0, P0
   Bertolini D, 2014, J HIGH ENERGY PHYS, V0, P0, DOI DOI 10.1007/JHEP10(2014)059
   Brun R, 1997, NUCL INSTRUM METH A, V389, P81, DOI 10.1016/S0168-9002(97)00048-X
   Cacciari M, 2015, EUR PHYS J C, V75, P0, DOI 10.1140/epjc/s10052-015-3267-2
   Child R, 2019, ARXIV 190410509, V0, P0
   Corke R, 2011, J HIGH ENERGY PHYS, V0, P0, DOI DOI 10.1007/JHEP03(2011)032
   de Favereau J, 2014, J HIGH ENERGY PHYS, V0, P0, DOI DOI 10.1007/JHEP02(2014)057
   Kingma DP, 2014, ADAM METHOD STOCHAST, V0, P0
   Komiske PT, 2017, J HIGH ENERGY PHYS, V0, P0, DOI DOI 10.1007/JHEP12(2017)051
   Malaviya C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P370
   Martínez JA, 2019, EUR PHYS J PLUS, V134, P0, DOI 10.1140/epjp/i2019-12710-3
   Mikuni V, 2020, EUR PHYS J PLUS, V135, P0, DOI 10.1140/epjp/s13360-020-00497-3
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Sirunyan AM, 2017, JINST, V12, P10003, DOI 10.1088/1748-0221/12/10/P10003
   Sjöstrand T, 2015, COMPUT PHYS COMMUN, V191, P159, DOI 10.1016/j.cpc.2015.01.024
   Smith LN, 2017, IEEE WINT CONF APPL, V0, PP464, DOI 10.1109/WACV.2017.58
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wolf T, 2019, ARXIV 191003771, V0, P0
   Zhao G, 2020, SPARSE TRANSFORMER C, V0, P0
NR 20
TC 4
Z9 4
U1 0
U2 2
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD JUN 1
PY 2022
VL 3
IS 2
BP 
EP 
DI 10.1088/2632-2153/ac7198
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences
SC Computer Science; Science & Technology - Other Topics
GA 1T8AT
UT WOS:000804949500001
DA 2023-11-10
ER

PT J
AU Xu, YM
   Lapata, M
AF Xu, Yumo
   Lapata, Mirella
TI Document Summarization with Latent Queries
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB The availability of large-scale datasets has driven the development of neural models that create generic summaries for single or multiple documents. For query-focused summarization (QFS), labeled training data in the form of queries, documents, and summaries is not readily available. We provide a unified modeling framework for any kind of summarization, under the assumption that all summaries are a response to a query, which is observed in the case of QFS and latent in the case of generic summarization. We model queries as discrete latent variables over document tokens, and learn representations compatible with observed and unobserved query verbalizations. Our framework formulates summarization as a generative process, and jointly optimizes a latent query model and a conditional language model. Despite learning from generic summarization data only, our approach outperforms strong comparison systems across benchmarks, query types, document settings, and target domains.(1)
C1 [Xu, Yumo; Lapata, Mirella] Univ Edinburgh, Inst Language Cognit & Computat, Sch Informat, 10 Crichton St, Edinburgh EH89AB, Scotland.
C3 University of Edinburgh
RP Xu, YM (通讯作者)，Univ Edinburgh, Inst Language Cognit & Computat, Sch Informat, 10 Crichton St, Edinburgh EH89AB, Scotland.
EM yumo.xu@ed.ac.uk; mlap@inf.ed.ac.uk
FU European Research Council (Lapata) [681760]; Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA) [FA8650-17-C-9118]; European Research Council (ERC) [681760] Funding Source: European Research Council (ERC)
CR Abdullah DM, 2020, P 13 INT C NATURAL L, V0, P80
   [Anonymous], 2006, DOC UND C, V0, P0
   [Anonymous], 2015, P ADV NEUR INF PROC, V0, P0
   Badrinath R, 2011, LECT NOTES COMPUT SC, V6611, P641, DOI 10.1007/978-3-642-20161-5_64
   Bajaj P, 2018, ARXIV, V0, P0
   Baumel T, 2018, ARXIV, V0, P0
   Baumel T, 2016, AAAI CONF ARTIF INTE, V0, P2573
   Cao ZQ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P152
   Chen S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P5935
   Dang HT, 2006, P WORKSHOP TASK FOCU, V0, P48
   Dang HT, 2005, P 2005 DOCUMENT UNDE, V0, P1
   Devlin J, 2018, ARXIV, V1, P4171
   Dou Z-Y, 2021, 2021 C N AM CHAPTER, V0, P0, DOI DOI 10.18653/V1/2021.NAACL-MAIN.384
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Gehrmann S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4098
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Higgins Irina, 2016, BETA VAE LEARNING BA, V0, P0
   Jang E, 2017, ARXIV, V0, P0
   Jin HQ, 2020, AAAI CONF ARTIF INTE, V34, P8026
   Kuhn Harold W, 1951, P 2 BERK S MATH STAT, V0, P481
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Laskar Md Tahmid Rahman, 2020, ADVANCES IN ARTIFICIAL INTELLIGENCE. 33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P342, DOI 10.1007/978-3-030-47358-7_35
   Laskar Md Tahmid Rahman, 2020, P COLING, V0, P5647
   Lebanoff L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4131
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li PJ, 2017, AAAI CONF ARTIF INTE, V0, P3497
   Li Piji, 2017, P 2017 C EMP METH NA, V0, PP2081, DOI 10.18653/V1/D17-1221
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P150
   Liu PJ, 2018, P 6 INT C LEARNING R, V0, P0
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3730
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1797
   Nema P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1063, DOI 10.18653/v1/P17-1098
   Perez-Beltrachini Laura, 2021, JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH, V71, P371
   Perez-Beltrachini L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5107
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rush AM, 2015, P EMNLP 15, V0, P0
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Su D, 2020, ARXIV200503975, V0, P0, DOI DOI 10.18653/v1/2020.nlpcovid19-2.14
   Su Dan, 2019, P 2 WORKSHOP MACHINE, V0, PP203, DOI 10.18653/V1/D19-5827
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Vaswani A, 2017, ARXIV, V30, P5998
   Wan XJ, 2014, SIGIR14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP787, DOI 10.1145/2600428.2609559
   Wan XJ, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2903
   Wang ZJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P485
   Xu Y, 2021, P 59 ANN M ASS COMPU, V1, P6096
   Xu Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3632
   Zhong Ming, 2020, P 58 ANN M ASS COMP, V0, PP6197, DOI 10.18653/V1/2020.ACL-MAIN.552
   Zhu H, 2019, ARXIV, V0, P0
NR 51
TC 4
Z9 4
U1 2
U2 2
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD MAY 4
PY 2022
VL 10
IS 
BP 623
EP 638
DI 10.1162/tacl_a_00480
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9OC
UT WOS:000923421200006
DA 2023-11-10
ER

PT J
AU Ji, SX
   Jiang, WQ
   Walid, A
   Li, X
AF Ji, Shaoxiong
   Jiang, Wenqi
   Walid, Anwar
   Li, Xue
TI Dynamic Sampling and Selective Masking for Communication-Efficient Federated Learning
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Article
AB Federated learning (FL) is a novel machine learning setting that enables on-device intelligence via decentralized training and federated optimization. Deep neural networks' rapid development facilitates the learning techniques for modeling complex problems and emerges into federated deep learning under the federated setting. However, the tremendous amount of model parameters burdens the communication network with a high load of transportation. This article introduces two approaches for improving communication efficiency by dynamic sampling and top-k selective masking. The former controls the fraction of selected client models dynamically, while the latter selects parameters with top-k largest values of difference for federated updating. Experiments on convolutional image classification and recurrent language modeling are conducted on three public datasets to show our proposed methods' effectiveness.
C1 [Ji, Shaoxiong] Aalto Univ, Dept Comp Sci, Helsinki 02150, Finland.
   [Jiang, Wenqi] Columbia Univ, Comp Sci, New York, NY 10027 USA.
   [Walid, Anwar] Nokia Bell Labs, Math Network Syst, Murray Hill, NJ 07069 USA.
   [Li, Xue] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
C3 Aalto University; Columbia University; Nokia Corporation; Nokia Bell Labs; University of Queensland
RP Ji, SX (通讯作者)，Aalto Univ, Dept Comp Sci, Helsinki 02150, Finland.
EM shaoxiong.ji@aalto.fi; wenqi.j@columbia.edu; anwar.walid@nokia-bell-labs.com; xueli@itee.uq.edu.au
CR [Anonymous], 2016, CORR, V0, P0
   Chen MZ, 2021, IEEE T WIREL COMMUN, V20, P269, DOI 10.1109/TWC.2020.3024629
   Hamer J, 2020, P 37 INT C MACH LEAR, V119, P3973
   Ji SX, 2019, IEEE IJCNN, V0, P0, DOI DOI 10.23919/apnoms.2019.8892896
   Jiang J, 2020, WORLD WIDE WEB, V23, P2653, DOI 10.1007/s11280-019-00775-w
   Liu Y, 2020, IEEE INTELL SYST, V35, P70, DOI 10.1109/MIS.2020.2988525
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Peterson D, 2019, WORKSHOP FEDERATED L, V0, P0
   Reisizadeh A, 2020, PR MACH LEARN RES, V108, P2021
   Roselander J, 2019, P MACH LEARN SYST, V0, P0
   Rothchild Daniel, 2020, P 37 INT C MACH LEAR, V0, P8253
   Sattler F, 2020, IEEE T NEUR NET LEAR, V31, P3400, DOI 10.1109/TNNLS.2019.2944481
   Yang ZH, 2021, IEEE T WIREL COMMUN, V20, P1935, DOI 10.1109/TWC.2020.3037554
   Zheng HD, 2020, IEEE INTELL SYST, V35, P5, DOI 10.1109/MIS.2020.3010335
NR 14
TC 5
Z9 5
U1 9
U2 31
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
EI 1941-1294
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD MAR-APR 15
PY 2022
VL 37
IS 2
BP 27
EP 34
DI 10.1109/MIS.2021.3114610
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1L9UD
UT WOS:000799624600005
DA 2023-11-10
ER

PT J
AU De, A
   Bandyopadhyay, D
   Gain, B
   Ekbal, A
AF De, Arkadipta
   Bandyopadhyay, Dibyanayan
   Gain, Baban
   Ekbal, Asif
TI A Transformer-Based Approach to Multilingual Fake News Detection in Low-Resource Languages
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Fake news detection; low-resource languages; multilingual; Hindi; Swahili; Indonesian; Vietnamese
AB Fake news classification is one of the most interesting problems that has attracted huge attention to the researchers of artificial intelligence, natural language processing, and machine learning (ML). Most of the current works on fake news detection are in the English language, and hence this has limited its widespread usability, especially outside the English literate population. Although there has been a growth in multilingual web content, fake news classification in low-resource languages is still a challenge due to the non-availability of an annotated corpus and tools. This article proposes an effective neural model based on the multilingual Bidirectional Encoder Representations from Transformer (BERT) for domain-agnostic multilingual fake news classification. Large varieties of experiments, including language-specific and domain-specific settings, are conducted. The proposed model achieves high accuracy in domain-specific and domain-agnostic experiments, and it also outperforms the current state-of-the-art models. We perform experiments on zero-shot settings to assess the effectiveness of language-agnostic feature transfer across different languages, showing encouraging results. Cross-domain transfer experiments are also performed to assess language-independent feature transfer of the model. We also offer a multilingual multidomain fake news detection dataset of five languages and seven different domains that could be useful for the research and development in resource-scarce scenarios.
C1 [De, Arkadipta] Indian Inst Technol Hyderabad, Hyderabad, India.
   [Bandyopadhyay, Dibyanayan; Gain, Baban; Ekbal, Asif] Indian Inst Technol Patna, Patna, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Hyderabad; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Patna
RP De, A (通讯作者)，Indian Inst Technol Hyderabad, Hyderabad, India.
EM ai20mtech14002@iith.ac.in; dibyanayan@gmail.com; gainbaban@gmail.com; asif@iitp.ac.in
FU Artificial Intelligence-Natural Language ProcessingMachine Learning (AI-NLP-ML) Laboratory at the Indian Institute of Technology Patna, India; project "HELIOS-Hate, Hyperpartisan, and Hyperpluralism Elicitation and Observer System" - Wipro
CR Abonizio HQ, 2020, FUTURE INTERNET, V12, P0, DOI 10.3390/fi12050087
   Agarap AF, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Barthel Michael, 2016, PEW RES CTR, V15, P12
   Bhatt Gaurav, 2017, ARXIV171203935 CORR, V0, P0
   Cer D, 2018, ARXIV180311175 CORR, V0, P0
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   Conroy NK, 2015, P ASS INFORM SCI TEC, V52, P1, DOI 10.1002/PRA2.2015.145052010082
   Devlin J, 2018, ARXIV, V1, P4171
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Goodyear Michael, 2020, FAKE NEWS TIME COVID, V0, P0, DOI DOI 10.2139/ssrn.3740639
   Guibon Gael, 2019, MULTILINGUAL FAKE NE, V0, P0
   Hanselowski A, 2018, P 27 INT C COMPUTATI, V0, P1859
   Jamieson KH, 2008, ECHO CHAMBER RUSH LI, V0, P0
   Kai Shu, 2017, ACM SIGKDD EXPLORATIONS NEWSLETTER, V19, P22, DOI 10.1145/3137597.3137600
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Nickerson RS, 1998, REV GEN PSYCHOL, V2, P175
   Ofcom, 2020, COVID 19 NEWS INF CO, V0, P0
   Pagliardini Matteo, 2017, ARXIV170302507, V0, P0, DOI DOI 10.18653/V1/N18-1049
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, V0, P3391
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rubin VL, 2015, PROC ASS INF SCI TEC, V52, P1
   Saikh T, 2019, P 16 INT C NATURAL L, V0, PP230, DOI 10.48550/arXiv.2005.04938
   Thorne J, 2018, LONG PAPERS, V0, PP809, DOI 10.18653/V1/N18-1074
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang A, 2019, ICLR 2019, V0, P0
   WHO, 2020, CORONAVIRUS DIS COVI, V0, P0
   Wu Y, 2016, ARXIV, V0, P0
   Zellers R, 2019, ADV NEUR IN, V32, P0
NR 31
TC 2
Z9 2
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JAN 15
PY 2022
VL 21
IS 1
BP 
EP 
DI 10.1145/3472619
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YU8KX
UT WOS:000752286700010
DA 2023-11-10
ER

PT J
AU Zagar, A
   Robnik-Sikonja, M
AF Zagar, Ales
   Robnik-Sikonja, Marko
TI Cross-lingual transfer of abstractive summarizer to less-resource language
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
LA English
DT Article
DE Automatic summarization; Text generation; Deep neural networks; Language models; Cross-lingual embeddings; Abstractive summarization
AB Automatic text summarization extracts important information from texts and presents the information in the form of a summary. Abstractive summarization approaches progressed significantly by switching to deep neural networks, but results are not yet satisfactory, especially for languages where large training sets do not exist. In several natural language processing tasks, a cross-lingual model transfer is successfully applied in less-resource languages. For summarization, the cross-lingual model transfer was not attempted due to a non-reusable decoder side of neural models that cannot correct target language generation. In our work, we use a pre-trained English summarization model based on deep neural networks and sequence-to-sequence architecture to summarize Slovene news articles. We address the problem of inadequate decoder by using an additional language model for the evaluation of the generated text in target language. We test several cross-lingual summarization models with different amounts of target data for fine-tuning. We assess the models with automatic evaluation measures and conduct a small-scale human evaluation. Automatic evaluation shows that the summaries of our best cross-lingual model are useful and of quality similar to the model trained only in the target language. Human evaluation shows that our best model generates summaries with high accuracy and acceptable readability. However, similar to other abstractive models, our models are not perfect and may occasionally produce misleading or absurd content.
C1 [Zagar, Ales; Robnik-Sikonja, Marko] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
C3 University of Ljubljana
RP Zagar, A (通讯作者)，Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
EM ales.zagar@fri.uni-lj.si; marko.robnik@fri.uni-lj.si
FU Slovene Research Agency [P6-0411, J6-2581]; European social fund and Republic of Slovenia, Ministry of Education, Science and Sport; Ministry of Culture of Republic of Slovenia through project Development of Slovene in Digital Environment; European Union's Horizon 2020 Programme project EMBEDDIA (Cross-Lingual Embeddings for Less-Represented Languages in European News Media) [825153]
CR Adams O, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P937
   Aksenov D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6680
   [Anonymous], 2017, P 2017 C EMPIRICAL M, V0, P0
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Baevski A, 2018, INT C LEARN REPR, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bois R, 2014, 21 TRAIT AUT LANG NA, V2, P550
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chelba Ciprian, 2014, ONE BILLION WORD BEN, V0, P0
   Chen YC, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P675
   Chi ZW, 2020, AAAI CONF ARTIF INTE, V34, P7570
   Chollet Francois, 2018, P 13 C ASS MACHINE T, V1, P193
   Cohan A, 2018, ARXIV180405685, V0, P0, DOI DOI 10.18653/v1/n18-2097
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Dou Z-Y, 2020, ARXIV201008014, V0, P0
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Fecht P, 2019, SWISS TEXT, V0, P0
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Graff D, 2003, LINGUISTIC DATA CONS, V4, P34, DOI 10.35111/0Z6Y-Q265
   GRAVE E, 2018, LANGUAGE RESOURCES E, V0, P0
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI 10.18653/V1/N18-1065
   Hu Baotian, 2015, EMNLP, V0, PP1967, DOI 10.18653/V1/D15-1229
   Krek S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P3340
   Lample G, 2018, INT C LEARNING REPRE, V0, P0
   Li Li, 2013, 2013 IEEE PROCEEDINGS OF 14TH INTERNATIONAL VACUUM ELECTRONICS CONFERENCE (IVEC2013), V0, P1
   Lin C-Y, 2002, P ACL 02 WORKSHOP AU, V0, P74
   Martinc M, 2021, COMPUT LINGUIST, V47, P141, DOI 10.1162/COLI_a_00398
   Merrouni ZA, 2020, J INTELL INF SYST, V54, P391, DOI 10.1007/s10844-019-00558-9
   Mihalcea Rada, 2004, P ACL 2004 INTERACTI, V0, PP170, DOI 10.3115/1219044.1219064
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Ouyang J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2025
   Over P, 2007, INFORM PROCESS MANAG, V43, P1506, DOI 10.1016/j.ipm.2007.01.019
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qi Weizhen, 2020, FINDINGS ASS COMPUTA, V0, PP2401, DOI 10.18653/v1/2020.findingsemnlp.217
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajani Nazneen, 2021, ARXIV210508209, V0, P0
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Scialom T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8051
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Straka Milan, 2018, P 11 INT C LANG RES, V0, P0
   Suppa M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P6725
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vinyals O, 2015, P ADV NEURAL INFORM, V0, PP2692, DOI 10.48550/arxiv.1506.03134
   Zhang Jingqing, 2020, P INT C MACH LEARN, V0, PP11328, DOI 10.1038/S41746-021-00437-0
   Zhang Tianyi, 2019, ICLR, V0, P0
   Zhu JN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3054
   Zidarn R, 2020, THESIS U LJUBLJANA F, V0, P0
NR 51
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0925-9902
EI 1573-7675
J9 J INTELL INF SYST
JI J. Intell. Inf. Syst.
PD FEB 15
PY 2022
VL 58
IS 1
BP 153
EP 173
DI 10.1007/s10844-021-00663-8
EA SEP 2021
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA YX6LS
UT WOS:000698081200001
DA 2023-11-10
ER

PT J
AU Liu, MY
   Tu, ZY
   Zhang, T
   Su, TH
   Xu, XF
   Wang, ZJ
AF Liu, Mingyi
   Tu, Zhiying
   Zhang, Tong
   Su, Tonghua
   Xu, Xiaofei
   Wang, Zhongjie
TI LTP: A New Active Learning Strategy for CRF-Based Named Entity Recognition
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Active learning; Learning strategies; Named entity recognition; CRF
AB In recent years, deep learning has achieved great success in many natural language processing tasks, including named entity recognition. The shortcoming is that a large quantity of manually annotated data is usually required. Previous studies have demonstrated that active learning can considerably reduce the cost of data annotation, but there is still plenty of room for improvement. In real applications, we found that existing uncertainty-based active learning strategies have two shortcomings. First, these strategies prefer to choose long sequences explicitly or implicitly, which increases the annotation burden of annotators. Second, some strategies need to revise and modify the model to generate additional information for sample selection, which increases the workload of the developer and increases the training/prediction time of the model. In this paper, we first examine traditional active learning strategies in specific cases of Word2Vec-BiLSTM-CRF and Bert-CRF that have been widely used in named entity recognition on several typical datasets. Then, we propose an uncertainty-based active learning strategy called the lowest token probability (LTP), which combines the input and output of conditional random field (CRF) to select informative instances. LTP is a simple and powerful strategy that does not favor long sequences and does not need to revise the model. We test LTP on multiple real-world datasets, the experiment results show that compared with existing state-of-the-art selection strategies, LTP can reduce about 20% annotation tokens while maintaining competitive performance on both sentence-level accuracy and entity-level F1-score. Additionally, LTP significantly outperformed all other strategies in selecting valid samples, which dramatically reduced the invalid annotation times of the labelers.
C1 [Liu, Mingyi; Tu, Zhiying; Zhang, Tong; Su, Tonghua; Xu, Xiaofei; Wang, Zhongjie] Harbin Inst Technol, Fac Comp, Harbin, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, ZJ (通讯作者)，Harbin Inst Technol, Fac Comp, Harbin, Peoples R China.
EM rainy@hit.edu.cn
FU National Key Research and Development Program of China [2018YFB1402500]; National Science Foundation of China [61832004, 61772155, 61802089, 61832014]
CR Awasthi P, 2014, STOC14: PROCEEDINGS OF THE 46TH ANNUAL 2014 ACM SYMPOSIUM ON THEORY OF COMPUTING, V0, PP449, DOI 10.1145/2591796.2591839
   Boreshban Y, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Chen YK, 2015, J BIOMED INFORM, V58, P11, DOI 10.1016/j.jbi.2015.09.010
   Chiu Jason PC, 2016, T ASS COMPUTATIONAL, V4, P357, DOI 10.1162/tacl_a_00104
   Claveau V, 2018, LECT NOTES COMPUT SC, V10761, P30, DOI 10.1007/978-3-319-77113-7_3
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Culotta A, 2005, AAAI, V0, P746
   Dasgupta S, 2005, LECT NOTES COMPUT SC, V3559, P249, DOI 10.1007/11503415_17
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duta IC, 2016, INT WORK CONTENT MUL, V0, P0
   Gal Y, 2016, ADV NEUR IN, V29, P0
   Gal Y, 2017, PR MACH LEARN RES, V70, P0
   Kim Seokhwan, 2006, P HUM LANG TECHN C N, V0, P69
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lewis DD, 1994, MACHINE LEARNING P 1, V0, PP148, DOI 10.1016/B978-1-55860-335-6.50026-X
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Li S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P138
   Limsopatham N, 2016, BIDIRECTIONAL LSTM N, V0, P0
   Lyu Z, 2020, TWORKSHOP UNCERTAINT, V0, P0
   Marcheggiani Diego, 2014, EMNLP, V0, P0
   Mesnil G, 2013, INTERSPEECH, V0, P3738
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Min KR, 2015, LECT NOTES ARTIF INT, V9362, P520, DOI 10.1007/978-3-319-25207-0_48
   Peng N, 2015, P 2015 C EMP METH NA, V0, PP548, DOI 10.18653/V1/D15-1064
   Peng NY, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P149
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Qiu XP, 2015, LECT NOTES ARTIF INT, V9362, P541, DOI 10.1007/978-3-319-25207-0_50
   Ritter A, 2011, P C EMP METH NAT LAN, V0, PP1524, DOI 10.1075/LI.30.1.03NAD
   Rosenstein MT, 2005, P NIPS WORKSH TRANSF, V898, P1
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Scheffer T, 2001, P 4 INT C ADV INTELL, V0, P309
   Settles B, 2008, P 2008 C EMPIRICAL M, V0, P1070
   Seung HS, 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP287, DOI 10.1145/130385.130417
   Shen Y, 2017, P 2 WORKSHOP REPRESE, V0, PP252, DOI 10.18653/V1/W17-2630
   Siddhant A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2904
   Strubell E, 2017, P 2017 C EMPIRICAL M, V0, PP2670, DOI 10.18653/V1/D17-1283
   Vandoni J, 2019, INT J APPROX REASON, V104, P166, DOI 10.1016/j.ijar.2018.11.007
   Wei K, 2015, PR MACH LEARN RES, V37, P1954
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yang Zhilin, 2016, ADV NEURAL INFORM PR, V0, P0
   Yu K, 2015, COMPUT INTEL NEUROSC, V0, P0
   Zhang Y, 2021, NLPCC, V0, P447
NR 43
TC 4
Z9 5
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD JUN 15
PY 2022
VL 54
IS 3
BP 2433
EP 2454
DI 10.1007/s11063-021-10737-x
EA JAN 2022
PG 22
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1O2WZ
UT WOS:000741972800001
DA 2023-11-10
ER

PT J
AU Wang, ZJ
   Xue, JY
   Wan, XL
   Zhu, AC
   Li, YF
   Zhu, XM
   Hu, FQ
AF Wang, Zijie
   Xue, Jingyi
   Wan, Xili
   Zhu, Aichun
   Li, Yifeng
   Zhu, Xiaomei
   Hu, Fangqiang
TI ASPD-Net: Self-aligned part mask for improving text-based person re-identification with adversarial representation learning
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Part mask detection; Text-based person re-identification; Adversarial learning
ID network
AB Text-based person re-identification aims to retrieve images of the corresponding person from a large visual database according to a natural language description. When it comes to visual local information extraction, most of the state-of-the-art methods adopt either a strict uniform strategy which can be too rough to catch local details properly, or pre-processing with external cues which may suffer from the deviations of the pre-trained model and the large computation consumption. In this paper, we proposed an Adversarial Self -aligned Part Detecting Network (ASPD-Net) model which extracts and combines multi-granular visual and textual features. A novel Self-aligned Part Mask Module was presented to autonomously learn the information of human body parts, and obtain visual local features in a soft-attention manner by using K Self-aligned Part Mask Detectors. Regarding the main model branches as a generator, a discriminator is employed to determine whether the representation vector comes from the visual modality or the textual modality. With Adversarial Loss training, ASPD-Net can learn more robust representations, as long as it successfully tricks the discriminator. Experimental results demonstrate that the proposed ASPD-Net outperforms the previous methods and achieves the state-of-the-art performance on the CUHK-PEDES and RSTPReid datasets.
C1 [Wang, Zijie; Xue, Jingyi; Wan, Xili; Zhu, Aichun; Li, Yifeng; Zhu, Xiaomei; Hu, Fangqiang] Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing, Peoples R China.
   [Zhu, Aichun] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou, Peoples R China.
C3 Nanjing Tech University; China University of Mining & Technology
RP Wan, XL (通讯作者)，Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing, Peoples R China.
EM xiliwan@njtech.edu.cn
FU National Natural Science Foundation of China [62101245]; China Postdoctoral Science Foundation [2019M661999]; Natural Science Research of Jiangsu Higher Education Institutions of China [19KJB520009]; Future Network Scientific Research Fund Project, China [FNSRFP-2021-YB-21]
CR Aggarwal S, 2020, IEEE WINT CONF APPL, V0, PP2606, DOI 10.1109/WACV45572.2020.9093640
   Aichun Zhu, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP209, DOI 10.1145/3474085.3475369
   Chen DP, 2018, LECT NOTES COMPUT SC, V11220, P56, DOI 10.1007/978-3-030-01270-0_4
   Chen F, 2021, INFORM SCIENCES, V549, P1, DOI 10.1016/j.ins.2020.11.004
   Chen TL, 2018, IEEE WINT CONF APPL, V0, PP1879, DOI 10.1109/WACV.2018.00208
   Cheng D, 2016, PROC CVPR IEEE, V0, PP1335, DOI 10.1109/CVPR.2016.149
   Daihong J, 2021, SCI PROGRAMMING-NETH, V0, P0
   Jiang DH, 2022, SOFT COMPUT, V26, P3631, DOI 10.1007/s00500-022-06822-5
   Ding ZF, 2021, ARXIV, V0, P0
   Faghri Fartash, 2018, P BRIT MACHINE VISIO, V0, P0
   Han X, 2021, ARXIV, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hou RB, 2019, PROC CVPR IEEE, V0, PP9309, DOI 10.1109/CVPR.2019.00954
   Jing Y, 2020, AAAI CONF ARTIF INTE, V34, P11189
   Li HF, 2021, INFORM SCIENCES, V559, P46, DOI 10.1016/j.ins.2021.01.016
   Li S, 2017, IEEE I CONF COMP VIS, V0, PP1908, DOI 10.1109/ICCV.2017.209
   Li S, 2017, PROC CVPR IEEE, V0, PP5187, DOI 10.1109/CVPR.2017.551
   Li X, 2018, P EUROPEAN C COMPUTE, V0, P280
   Lin T-Y, 2014, P EUROPEAN C COMPUTE, V0, P740
   Liu JW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP665, DOI 10.1145/3343031.3350991
   Liu JX, 2018, PROC CVPR IEEE, V0, PP4099, DOI 10.1109/CVPR.2018.00431
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Reed S, 2016, PROC CVPR IEEE, V0, PP49, DOI 10.1109/CVPR.2016.13
   Sarafianos N, 2019, IEEE I CONF COMP VIS, V0, PP5813, DOI 10.1109/ICCV.2019.00591
   Simonyan K, 2015, ARXIV, V0, P0
   Song CF, 2018, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, V0, PP3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wang JC, 2021, INFORM SCIENCES, V562, P370, DOI 10.1016/j.ins.2021.03.028
   Wang ZJ, 2021, LECT NOTES COMPUT SC, V13020, P462, DOI 10.1007/978-3-030-88007-1_38
   Wang ZJ, 2022, KNOWL-BASED SYST, V248, P0, DOI 10.1016/j.knosys.2022.108891
   Wang ZJ, 2020, J ELECTRON IMAGING, V29, P0, DOI 10.1117/1.JEI.29.4.043028
   Wei SE, 2016, PROC CVPR IEEE, V0, PP4724, DOI 10.1109/CVPR.2016.511
   Xia B, 2019, IEEE I CONF COMP VIS, V0, PP3759, DOI 10.1109/ICCV.2019.00386
   Yan Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP13376, DOI 10.1109/CVPR42600.2020.01339
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yi D, 2014, INT C PATT RECOG, V0, PP34, DOI 10.1109/ICPR.2014.16
   Yuan Y, 2020, NEUROCOMPUTING, V378, P387, DOI 10.1016/j.neucom.2019.10.083
   Zhang GQ, 2021, INFORM SCIENCES, V578, P525, DOI 10.1016/j.ins.2021.07.058
   Zhang J, 2019, IEEE ACCESS, V7, P95496, DOI 10.1109/ACCESS.2019.2929854
   Zhang YL, 2021, INFORM SCIENCES, V568, P133, DOI 10.1016/j.ins.2021.03.048
   Zhao HY, 2017, PROC CVPR IEEE, V0, PP907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, V0, PP3239, DOI 10.1109/ICCV.2017.349
   Zhao Y, 2021, PATTERN RECOGN, V116, P0, DOI 10.1016/j.patcog.2021.107938
   Zhe Wang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12357), V0, PP402, DOI 10.1007/978-3-030-58610-2_24
   Zheng KC, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP3441, DOI 10.1145/3394171.3413864
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, P0, DOI 10.1145/3383184
   Zhong Z, 2019, PROC CVPR IEEE, V0, PP598, DOI 10.1109/CVPR.2019.00069
   Zhu AC, 2022, IEEE T INTELL TRANSP, V23, P8090, DOI 10.1109/TITS.2021.3075859
   Zhu AC, 2020, NEUROCOMPUTING, V414, P90, DOI 10.1016/j.neucom.2020.07.068
NR 54
TC 1
Z9 1
U1 4
U2 27
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD NOV 15
PY 2022
VL 116
IS 
BP 
EP 
DI 10.1016/j.engappai.2022.105419
PG 12
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA 5A2VE
UT WOS:000862748800008
DA 2023-11-10
ER

PT J
AU Li, K
   Zhou, C
   Luo, X
   Benitez, J
   Liao, QY
AF Li, Kai
   Zhou, Cheng
   Luo, Xin (Robert)
   Benitez, Jose
   Liao, Qinyu
TI Impact of information timeliness and richness on public engagement on social media during COVID-19 pandemic: An empirical investigation based on NLP and machine learning
SO DECISION SUPPORT SYSTEMS
LA English
DT Article
DE Natural language processing (NLP) for societal benefit; Information timeliness; Information richness; Public engagement; Social media; Health emergencies
ID management; participation; facebook; systems; user; emergency; dimensions; community; support; quality
AB This paper investigates how information timeliness and richness affect public engagement using text data from China's largest social media platform during times of the COVID-19 pandemic. We utilize a similarity calculation method based on natural language processing (NLP) and text mining to evaluate three dimensions of information timeliness: retrospectiveness, immediateness, and prospectiveness. Public engagement is divided into breadth and depth. The empirical results show that information retrospectiveness is negatively associated with public engagement breadth but positively with depth. Both information immediateness and prospectiveness improved the breadth and depth of public engagement. Interestingly, information richness has a positive moderating effect on the relationships between information retrospectiveness, prospectiveness, and public engagement breadth but no significant effects on immediateness; meanwhile, it has a negative moderating effect on the relationship between retrospectiveness and depth but a positive effect on immediateness, prospectiveness. In the extension analysis, we constructed a supervised NLP model to identify and classify health emergency-related information (epidemic prevention and help-seeking) automatically. We find that public engagement differs in the two emergency-related information categories. The findings can promote a more responsive public health strategy that magnifies the transfer speed for critical information and mitigates the negative impacts of information uncertainty or false information.
C1 [Li, Kai; Zhou, Cheng] Nankai Univ, Business Sch, Tianjin, Peoples R China.
   [Luo, Xin (Robert)] Univ New Mexico, Albuquerque, NM USA.
   [Benitez, Jose] EDHEC Business Sch, Roubaix, France.
   [Liao, Qinyu] Univ Texas Rio Grande Valley, Brownsville, TX USA.
C3 Nankai University; University of New Mexico; Universite Catholique de Lille; EDHEC Business School; University of Texas System; University of Texas Rio Grande Valley
RP Benitez, J (通讯作者)，EDHEC Business Sch, Roubaix, France.
EM likai@nankai.edu.cn; zhoucheng1017@163.com; xinluo@unm.edu; jose.benitez@edhec.edu; qinyu.liao@utrgv.edu
FU Scientific Research Project of Liberal Arts Development Fund of Nankai University [ZB21BZ0214]; National Social Science Foundation of China [72132007]; Major Program of the National Natural Science Foundation of China [72091311]; European Regional Development Fund (European Union); Government of Spain [ECO2017-84138-P]; Regional Government of Andalusia [A-SEJ-154-UGR18]; Slovenian Research Agency [P5-0410]
CR Adam Nabil, 2007, 2007 IEEE INTELLIGENCE AND SECURITY INFORMATICS, V0, PP16, DOI 10.1109/ISI.2007.379523
   Agarwal N, 2010, P 15 INT C INF QUAL, V0, P234
   Agostino D, 2016, PUBLIC MANAG REV, V18, P1289, DOI 10.1080/14719037.2015.1100320
   Ahmed H, 2017, DETECTING OPINION SP, V0, P74
   Aiken LS, 1991, MULTIPLE REGRESSION, V0, P0
   [Anonymous], 2005, J CONTINGENC CRIS MA, V0, P0
   [Anonymous], 2009, P 42 ANN HAW INT C S, V0, P0
   Atoji Y, 2004, ELECTR ENG JPN, V147, P60, DOI 10.1002/eej.10233
   Bamberger P, 2008, ACAD MANAGE J, V51, P839, DOI 10.5465/AMJ.2008.34789630
   Bonsón E, 2019, GOV INFORM Q, V36, P480, DOI 10.1016/j.giq.2019.03.001
   Brubaker PJ, 2018, PUBLIC RELAT REV, V44, P342, DOI 10.1016/j.pubrev.2018.04.010
   Castillo C, 2011, P 20 INT C WORLD WID, V0, P675
   Chatfield AT, 2018, GOV INFORM Q, V35, P259, DOI 10.1016/j.giq.2017.09.004
   Chen Q, 2020, COMPUT HUM BEHAV, V110, P0, DOI 10.1016/j.chb.2020.106380
   Chen R, 2005, LECT NOTES COMPUT SC, V3495, P81
   Chew C, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0014118
   Chun JW, 2017, COMPUT HUM BEHAV, V74, P120, DOI 10.1016/j.chb.2017.04.010
   Chung JE, 2017, COMPUT HUM BEHAV, V74, P112, DOI 10.1016/j.chb.2017.04.025
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   DAFT RL, 1987, MIS QUART, V11, P355, DOI 10.2307/248682
   Dawes SS, 2004, SOC SCI COMPUT REV, V22, P52, DOI 10.1177/0894439303259887
   Gálvez-Rodríguez MD, 2019, ONLINE INFORM REV, V43, P219, DOI 10.1108/OIR-09-2016-0286
   Denktas-Sakar G, 2020, SERV IND J, V40, P866, DOI 10.1080/02642069.2018.1561874
   DOLL WJ, 1988, MIS QUART, V12, P259, DOI 10.2307/248851
   Eckert S, 2018, HEALTH COMMUN, V33, P1389, DOI 10.1080/10410236.2017.1351278
   Elbanna A, 2019, INT J INFORM MANAGE, V47, P112, DOI 10.1016/j.ijinfomgt.2019.01.011
   ElShinnawy M, 1997, INT J HUM-COMPUT ST, V46, P443, DOI 10.1006/ijhc.1996.0099
   Emerson MF, 2012, NY TIMES, V0, P0
   Filieri R, 2014, J TRAVEL RES, V53, P44, DOI 10.1177/0047287513481274
   Goh KY, 2013, INFORM SYST RES, V24, P88, DOI 10.1287/isre.1120.0469
   Guidry JPD, 2020, HEALTH COMMUN, V35, P1137, DOI 10.1080/10410236.2019.1620089
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW13 COMPANION), V0, P729
   Han LS, 2013, IEEE T KNOWL DATA EN, V25, P1307, DOI 10.1109/TKDE.2012.30
   Harrison S, 2019, GOV INFORM Q, V36, P501, DOI 10.1016/j.giq.2019.04.002
   Hobbs J, 2004, J HEALTH COMMUN, V9, P67, DOI 10.1080/10810730490271638
   Hong WY, 2014, INFORM SYST RES, V25, P111, DOI 10.1287/isre.2013.0501
   Huang S, 2011, INT J BURNS TRAUMA, V1, P1
   Ikegami E, 2000, SOC RES, V67, P989
   Jenvald J, 2003, INT J EMERG MANAG, V1, P82
   Ji YG, 2019, PUBLIC RELAT REV, V45, P88, DOI 10.1016/j.pubrev.2018.12.001
   Jiang SH, 2016, J HEALTH COMMUN, V21, P755, DOI 10.1080/10810730.2016.1157653
   Jiang TT, 2019, INFORM PROCESS MANAG, V56, P29, DOI 10.1016/j.ipm.2018.08.005
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kang Y, 2020, J MANAG ANAL, V7, P139, DOI 10.1080/23270012.2020.1756939
   Katz E, 1973, PUBLIC OPIN QUART, V37, P509, DOI 10.1086/268109
   Khobzi H, 2019, INTERNET RES, V29, P2, DOI 10.1108/IntR-04-2017-0161
   Kim C, 2017, PUBLIC RELAT REV, V43, P441, DOI 10.1016/j.pubrev.2017.02.006
   Kim JK, 2007, DECIS SUPPORT SYST, V44, P235, DOI 10.1016/j.dss.2007.04.002
   Kim J, 2018, INT J INFORM MANAGE, V40, P153, DOI 10.1016/j.ijinfomgt.2018.02.003
   Kim SE, 2017, INFORM MANAGE-AMSTER, V54, P687, DOI 10.1016/j.im.2017.02.009
   Kontogiannis T, 1996, INT J HUM-COMPUT ST, V45, P75, DOI 10.1006/ijhc.1996.0043
   Lan YF, 2010, COMPUT EDUC, V55, P723, DOI 10.1016/j.compedu.2010.03.005
   Lee CH, 2020, IND MANAGE DATA SYST, V120, P1501, DOI 10.1108/IMDS-12-2019-0711
   Lee G, 2012, GOV INFORM Q, V29, P492, DOI 10.1016/j.giq.2012.06.001
   Lee J, 2018, PUBLIC RELAT REV, V44, P201, DOI 10.1016/j.pubrev.2017.10.002
   Lee M, 2021, J TRAVEL RES, V60, P670, DOI 10.1177/0047287520934874
   Li LF, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102313
   Li LF, 2020, IEEE T COMPUT SOC SY, V7, P556, DOI 10.1109/TCSS.2020.2980007
   Li LF, 2018, INT J INFORM MANAGE, V38, P34, DOI 10.1016/j.ijinfomgt.2017.08.008
   Lin HF, 2007, TOTAL QUAL MANAG BUS, V18, P363, DOI 10.1080/14783360701231302
   Liu YX, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102259
   Miller H, 1996, INFORM SYST MANAGE, V13, P79, DOI 10.1080/10580539608906992
   Moorhead SA, 2013, J MED INTERNET RES, V15, P0, DOI 10.2196/jmir.1933
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Neely SR, 2018, J HOMEL SECUR EMERG, V15, P0, DOI 10.1515/jhsem-2016-0067
   Rahim AIA, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16040591
   Reed MS, 2008, BIOL CONSERV, V141, P2417, DOI 10.1016/j.biocon.2008.07.014
   Rousseau C, 2015, PUBLIC UNDERST SCI, V24, P225, DOI 10.1177/0963662513495149
   Rowe G, 2004, SCI TECHNOL HUM VAL, V29, P512, DOI 10.1177/0162243903259197
   Shi J, 2018, INTERNET RES, V28, P393, DOI 10.1108/IntR-01-2017-0038
   Signorini A, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0019467
   Stark A, 2014, AUST J POLIT SCI, V49, P300, DOI 10.1080/10361146.2014.899966
   Tang ZH, 2015, NAT HAZARDS, V79, P171, DOI 10.1007/s11069-015-1835-2
   Van de Walle B, 2007, COMMUN ACM, V50, P29, DOI 10.1145/1226736.1226760
   Wang RY, 1996, JOURNAL OF MANAGEMENT INFORMATION SYSTEMS, V12, P5
   Xie KL, 2016, J TRAVEL TOUR MARK, V33, P211, DOI 10.1080/10548408.2015.1050538
   Xie YG, 2017, TELEMAT INFORM, V34, P740, DOI 10.1016/j.tele.2016.05.023
   Xu WA, 2018, COMPUT HUM BEHAV, V89, P199, DOI 10.1016/j.chb.2018.07.041
   Yan W, 2014, TSINGHUA SCI TECHNOL, V19, P531, DOI 10.1109/TST.2014.6919830
   Yin CX, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102345
   Yin CX, 2018, INFORM TECHNOL PEOPL, V31, P741, DOI 10.1108/ITP-12-2016-0300
   Yoo W, 2016, COMPUT HUM BEHAV, V62, P34, DOI 10.1016/j.chb.2016.03.058
   Zhang L, 2017, ASIAN J COMMUN, V27, P322, DOI 10.1080/01292986.2017.1290124
   Zhou C, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102554
NR 84
TC 15
Z9 15
U1 40
U2 114
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-9236
EI 1873-5797
J9 DECIS SUPPORT SYST
JI Decis. Support Syst.
PD NOV 15
PY 2022
VL 162
IS 
BP 
EP 
DI 10.1016/j.dss.2022.113752
EA SEP 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science
SC Computer Science; Operations Research & Management Science
GA 4X1LQ
UT WOS:000860611900002
PM 35185227
DA 2023-11-10
ER

PT J
AU Liu, ZY
   Prud'hommeaux, E
AF Liu, Zoey
   Prud'hommeaux, Emily
TI Data-driven Model Generalizability in Crosslinguistic Low-resource Morphological Segmentation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Common designs of model evaluation typically focus on monolingual settings, where different models are compared according to their performance on a single data set that is assumed to be representative of all possible data for the task at hand. While this may be reasonable for a large data set, this assumption is difficult to maintain in low-resource scenarios, where artifacts of the data collection can yield data sets that are outliers, potentially making conclusions about model performance coincidental. To address these concerns, we investigate model generalizability in crosslinguistic low-resource scenarios. Using morphological segmentation as the test case, we compare three broad classes of models with different parameterizations, taking data from 11 languages across 6 language families. In each experimental setting, we evaluate all models on a first data set, then examine their performance consistency when introducing new randomly sampled data sets with the same size and when applying the trained models to unseen test sets of varying sizes. The results demonstrate that the extent of model generalization depends on the characteristics of the data set, and does not necessarily rely heavily on the data set size. Among the characteristics that we studied, the ratio of morpheme overlap and that of the average number of morphemes per word between the training and test sets are the two most prominent factors. Our findings suggest that future work should adopt random sampling to construct data sets with different sizes in order to make more responsible claims about model evaluation.
C1 [Liu, Zoey; Prud'hommeaux, Emily] Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA.
C3 Boston College
RP Liu, ZY (通讯作者)，Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA.
EM zoey.liu@bc.edu; prudhome@bc.edu
FU National Science Foundation [2127309, 1761562]; Direct For Social, Behav & Economic Scie; Division Of Behavioral and Cognitive Sci [1761562] Funding Source: National Science Foundation; Division Of Computer and Network Systems; Direct For Computer & Info Scie & Enginr [2127309] Funding Source: National Science Foundation
CR Ablimit M, 2010, INT CONF SIGN PROCES, V0, PP581, DOI 10.1109/ICOSP.2010.5656065
   Afify M, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P277
   Akyurek E, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4934
   [Anonymous], 2013, P 2013 C N AM CHAPTE, V0, P0
   [Anonymous], 2010, P OF THE 11 M OF THE, V0, P0
   Ansari E, 2019, P INT C REC ADV NAT, V0, P52
   Arjovsky M, 2017, PR MACH LEARN RES, V70, P0
   Bahdanau D, 2015, P 3 INT C LEARN REPR, V0, P0
   Baker Mark C, 1997, COMPLEX PREDICATES, V0, P247
   Bender Emily M, 2018, T ASSOC COMPUT LING, V6, P587, DOI 10.1162/TACL_A_00041
   Berg-Kirkpatrick Taylor, 2012, P 2012 JOINT C EMPIR, V0, P995
   Blevins T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1606
   Card D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9263
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Clifton Ann, 2011, P 49 ANN M ASS COMPU, V0, P32
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, P1
   Cotterell R, 2015, P 19 C COMP NAT LANG, V0, PP164, DOI 10.18653/V1/K15
   Cotterell R, 2016, P 2016 C N AM CHAPTE, V0, PP664, DOI 10.18653/v1/N16- 1080
   Cotterell Ryan, 2016, P 2016 C EMP METH NA, V0, PP2325, DOI 10.18653/v1/d16-1256
   Creutz M, 2002, P ACL 2002 WORKSH MO, V0, PP21, DOI 10.3115/1118647.1118650
   Zeiler MD, 2012, ARXIV, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dhar Prajit, 2021, P 23 NORDIC C COMPUT, V0, P74
   Dodge J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2185
   Dror R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1383
   Ebrahim Ansari Zdenek, 2019, PERSIAN MORPHOLOGICA, V0, P0
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Eyigoz Elif, 2013, P 2013 C N AM CHAPTE, V0, P32
   Freeze Ray A, 1989, MAYO CAPOMOS SINALOA, V0, P0
   Futrell Richard, 2019, P 2019 C N AM CHAPTE, V1, P32, DOI 10.18653/V1/N19-1004
   Garrett A, 2011, INT J LEXICOGR, V24, P405, DOI 10.1093/ijl/ecr018
   Gebru Timnit, 2018, P 5 WORKSHOP FAIRNES, V0, P0
   Gomez Paula, 1999, HUICHOL SAN ANDR S C, V0, P0
   Gorman K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, PP2786, DOI 10.18653/v1/p19-1267
   Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2545
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1725
   Jia Robin, 2017, P 2017 C EMP METH NA, V0, PP2021, DOI 10.18653/V1/D17-1215
   Kann Katharina, 2018, P 2018 C N AM CHAPTE, V1, P47
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   Kondratyuk D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2779
   Lafferty J, 2001, CONDITIONAL RANDOM F, V0, P282
   Lake B, 2018, PR MACH LEARN RES, V80, P0
   Lastra de Suarez Yolanda, 1980, NAHUATL ACAXOCHITLAN, V0, P0
   LEVENSHTVI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI 10.1353/LAN.2019.0015
   Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035
   Linzen Tal, 2020, P 58 ANN M ASS COMP, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.465
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Liu Zoey, 2021, P 1 WORKSHOP NATURAL, V0, PP90, DOI 10.18653/v1/2021.americasnlp-1.10
   M?ller T, 2013, P 2013 C EMP METH NA, V0, P322
   Marcus MP, 1993, COMPUT LINGUIST, V19, P313, DOI 10.21236/ADA273556
   Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1192
   McCoy RT, 2020, P 3 BLACKBOXNLPWORKS, V0, P217
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   McCoy RThomas, 2018, P COGSCI, V0, P2093
   Meek BA, 2012, WE ARE OUR LANGUAGE, V0, P0
   Mueller A, 2020, P 58 ANN M ASS COMPU, V0, P5523
   Naoaki Okazaki, 2007, CRFSUITE FAST IMPLEM, V0, P0
   Cuong NV, 2014, J MACH LEARN RES, V15, P981
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Ramponi Alan, 2020, P 28 INT C COMPUTATI, V0, PP6838, DOI 10.18653/V1/2020.COLING-MAIN.603
   Reimers N, 2017, P C EMPIRICAL METHOD, V0, PP338, DOI 10.18653/V1/D17-1035
   Richard Harald BaayenR, 1996, CELEX LEXICAL DATABA, V0, P0
   RISSANEN J, 1989, STOCHASTIC COMPLEXIT, V0, P0
   Ruokolainen T, 2013, P 17 C COMP NAT LANG, V0, P29
   Seeker W, 2015, T ASSOC COMPUT LING, V3, P359, DOI 10.1162/TACL_A_00144
   Sogaard A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1823
   Sorokin A, 2018, COMM COM INF SC, V930, P3, DOI 10.1007/978-3-030-01204-5_1
   Spence Justin, 2013, THESIS U CALIFORNIA, V0, P0
   Spiegler S, 2010, P 23 INT C COMP LING, V0, PP1020, DOI 10.1109/ANZIIS.1995.705747
   Szymanski P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P2203
   Tachbelie MY, 2014, SPEECH COMMUN, V56, P181, DOI 10.1016/j.specom.2013.01.008
   Thrush T, 2020, P 3 BLACKBOXNLP WORK, V0, PP265, DOI 10.18653/V1/2020.BLACKBOXNLP-1.25
   VANDENBOSCH A, 1999, P 37 ANN M ASS COMP, V0, P285
   Vieira T, 2016, P 2016 C EMPIRICAL M, V0, PP1973, DOI 10.18653/v1/D16-1206
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang YW, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5604
   Weber N, 2018, P WORKSHOP GENERALIZ, V0, PP24, DOI 10.18653/v1/W18-1004
   Wicentowski, 2010, P 11 M ACL SPEC INT, V0, P87
   Wilcox E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4640
   Wilcox E, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3302
   Xiang BL, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P2784
   Zhou X, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P8215
NR 83
TC 0
Z9 0
U1 3
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD APR 6
PY 2022
VL 10
IS 
BP 393
EP 413
DI 10.1162/tacl_a_00467
PG 21
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9LI
UT WOS:000923414000004
DA 2023-11-10
ER

PT J
AU Mahata, SK
   Garain, A
   Das, D
   Bandyopadhyay, S
AF Mahata, Sainik Kumar
   Garain, Avishek
   Das, Dipankar
   Bandyopadhyay, Sivaji
TI Simplification of English and Bengali Sentences for Improving Quality of Machine Translation
SO NEURAL PROCESSING LETTERS
LA English
DT Article
ID web
AB Training translation systems with complex and compound sentences are generally considered computationally tough and such systems fail to process, the large syntactical information given out by these sentences. This issue subsequently, affects the overall quality of translations. On the other hand, simple sentences are shorter by nature and produce less syntactical information. Therefore, it would be safe to say that training translation systems using simple sentences only, would result in better translation output. However, training a translation system requires a large and quality parallel corpus involving two natural languages. While parallel corpus for various language pairs is abundant, such lexicons for low-resourced languages, consisting of only simple sentences are rare. In such a scenario, the development of such a parallel lexicon is the initial purpose of the present work. Building the same would require differentiating complex and/or compound sentences from the overall corpus and then converting them into simple sentences. Since, the work includes two languages, English and Bengali, different algorithms to accomplish the same, is documented in this paper. Converting complex and compound sentences to simple instances results in fragmenting sentences into two or more segments, which then needs to be aligned to make them semantically similar. Hence, a basic alignment technique has also been proposed to mitigate this problem. After developing the parallel corpus, we needed to check for its effectiveness in solving the quality issues of translation systems discussed earlier. For this, state-of-the-art translation modules like Statistical Machine Translation and Neural Machine Translation, have been trained using the developed corpus as well as with the raw parallel corpus consisting of sentences of mixed complexities. The performance of these translation models has been compared using automated as well as manual evaluation metrics. The results are promising and prove that translation systems do perform better when trained using simple sentence language pairs.
C1 [Mahata, Sainik Kumar] Inst Engn & Management, Kolkata, India.
   [Garain, Avishek; Das, Dipankar; Bandyopadhyay, Sivaji] Jadavpur Univ, Kolkata, India.
C3 Institute of Engineering & Management (IEM), Kolkata; Jadavpur University
RP Mahata, SK (通讯作者)，Inst Engn & Management, Kolkata, India.
EM sainik.mahata@gmail.com; avishekgarain@gmail.com; dipankar.dipnil2005@gmail.com; sivaji_cse_ju@yahoo.com
CR Al Mumin MA, 2019, J COMPUTER SCI, V15, P1022
   [Anonymous], 2011, INT J COMPUT APPL, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Banerjee Tamali, 2018, P 32 PAC AS C LANG I, V0, P0
   Chollet F, 2015, KERAS, V0, P0
   Chung J, 2016, ARXIV160306147 CORR, V0, P0
   Das A, 2014, INT CONF ASIAN LANG, V0, PP91, DOI 10.1109/IALP.2014.6973488
   FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309
   Garain Avishek, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), V0, PP672, DOI 10.1109/ISCON47742.2019.9036207
   Guo H, 2018, P 27 INT C COMP LING, V0, P462
   Heafield K, 2011, P 6 WORKSH STAT MACH, V0, P187
   ISLAM M, 2021, NEURAL COMPUT APPL, V0, P0
   Islam MA, 2017, PROCEEDINGS OF 2017 4TH INTERNATIONAL CONFERENCE ON NETWORKING, V0, P95
   Kim YB, 1994, T IPSJ, V35, P0
   Koehn P, 2007, P 45 ANN M ACL INT P, V0, PP177, DOI 10.3115/1557769.1557821
   Lardilleux Adrien, 2009, P REC ADV NAT LANG P, V0, P214
   Lita LV, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P152
   Mahata SK, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P283
   Mahata SK, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Och FJ, 2003, COMPUTATIONAL LINGUISTICS, V29, P19, DOI 10.1162/089120103321337421
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Rahman M, 2019, P INT C COP INF TECH, V0, PP1, DOI 10.1109/ICCITECHN.2018.8631938
   Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578
   Resnik P, 1998, LECT NOTES ARTIF INT, V1529, P72
   Snover Matthew, 2006, P 7 C ASS MACHINE TR, V0, P223
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vu T, 2018, ARXIV180407445 CORR, V0, P0
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Zhang X, 2017, P 2017 C EMP METH NA, V0, PP584, DOI 10.18653/V1/D17-1062
NR 29
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD AUG 15
PY 2022
VL 54
IS 4
BP 3115
EP 3139
DI 10.1007/s11063-022-10755-3
EA FEB 2022
PG 25
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3T0LR
UT WOS:000755431300001
DA 2023-11-10
ER

PT J
AU Yan, M
   Pan, Y
AF Yan, Ming
   Pan, Yi
TI Meta-learning for compressed language model: A multiple choice question answering study
SO NEUROCOMPUTING
LA English
DT Article
DE End-to-end reptile; Compressed pretrained-language-model; Meta-learning; Multiple-choice question answering
AB Model compression is a promising approach for reducing the model size of pretrained-language-models (PLMs) on low resource edge devices and applications. Unfortunately, the compression process always accompanies a cost of performance degradation, especially for the low resource downstream tasks, i.e., multiple-choice question answering. To address the degradation issue of model compression on PLMs, we proposed an end-to-end reptile (ETER) meta-learning approach to improving the performance of PLMs on the low resource multiple-choice question answering task. Specifically, our ETER improves the traditional two-stage meta-learning to an end-to-end manner, integrating the target finetuning stage into the meta training stage. To strengthen the generic meta-learning, ETER employs two-level meta-task construction from instance-level and domain-level to enrich its task generalization. What is more, ETER optimizes meta-learning by parameter constraints to reduce its parameter learning space. Experiments demonstrate that ETER significantly improved the performance of compressed PLMs and achieved large superiority over the baselines on different datasets.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Yan, Ming] Agcy Sci Technol & Res, Singapore, Singapore.
   [Pan, Yi] Georgia State Univ, Atlanta, GA 30303 USA.
C3 Agency for Science Technology & Research (A*STAR); University System of Georgia; Georgia State University
RP Yan, M (通讯作者)，Agcy Sci Technol & Res, Singapore, Singapore.
EM yan_ming@ihpc.a-star.edu.sg
FU Agency for Science, Technology and Research (A*STAR) under its AME Programmatic Funding Scheme [A18A1b0045]; Science and Technology Innovation Program of Sichuan Province [2018RZ0129]
CR Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen Z, 2018, ARXIV180305655, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Ganesh Prakhar, 2020, ARXIV200211985, V0, P0
   Gordon Mitchell A, 2020, COMPRESSING BERT STU, V0, P0
   Guo DY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P855
   Jiang Z, 2020, ADV NEURAL INFORM PR, V0, P0
   Jiao X, 2020, FINDINGS ASS COMPUTA, V0, PP4163, DOI 10.18653/v1/2020.findings-emnlp.372
   Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8010
   Jin Di, 2020, ARXIV200913081, V0, P0
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y
   Liu Z, 2020, ARXIV200511700, V0, P0
   Nichol Alex, 2018, ARXIV180302999, V0, P0
   Ostermann S, 2018, P 12 INT WORKSHOP SE, V0, P747
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Raganato A, 2020, FINDINGS ASS COMPUTA, V0, PP556, DOI 10.18653/V1/2020.FINDINGS-EMNLP.49
   Rajpurkar P, 2016, P 2016 C EMP METH NA, V0, PP2383, DOI 10.18653/V1/D16-1264
   Richardson M, 2013, P 2013 C EMPIRICAL M, V0, P193
   Sanh V, 2020, ADV NEURAL INFORM PR, V33, P20378
   Sanh Victor, 2020, DISTILBERT DISTILLED, V0, P0
   Santoro A, 2016, PR MACH LEARN RES, V48, P0
   Sennrich R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P211
   Shen DH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1839
   Shen S, 2019, ARXIV190905840, V0, P0
   Si C, 2019, ARXIV191012391, V0, P0
   Snell Jake, 2017, NEURIPS, V0, P0
   Sun K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2633
   Sun K, 2019, T ASSOC COMPUT LING, V7, P217, DOI 10.1162/tacl_a_00264
   Sun QR, 2019, PROC CVPR IEEE, V0, PP403, DOI 10.1109/CVPR.2019.00049
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2158
   Tay Yi, 2020, ARXIV200500743, V0, P0
   Trischler Adam, 2017, P 2 WORKSH REPR LEAR, V0, PP191, DOI 10.18653/V1/W17-2623
   Vinyals Oriol, 2016, P NEURIPS, V0, P0
   Wang L, 2018, P 12 INT WORKSHOP SE, V0, PP758, DOI 10.18653/v1/S18-1120
   Wang Z, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6151
   Wolf T, 1900, P38, V0, P0
   Xia JN, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2393, DOI 10.1145/3357384.3358165
   Yan Ming, 2020, P 58 ANN M ASS COMPU, V0, P7331
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zafrir Ofir, 2019, 2019 FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS), V0, PP36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zhao Sanqiang, 2019, ARXIV190911687, V0, P0
   Zhu C, 2020, ARXIV190911764, V0, P0
   Zhu P, 2020, ABS200109415 CORR, V0, P0
NR 49
TC 4
Z9 4
U1 4
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAY 28
PY 2022
VL 487
IS 
BP 181
EP 189
DI 10.1016/j.neucom.2021.01.148
EA MAR 2022
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1B5WQ
UT WOS:000792507600002
DA 2023-11-10
ER

PT J
AU Korzeniewska, A
   Mitsuhashi, T
   Wang, YJ
   Asano, E
   Franaszczuk, PJ
   Crone, NE
AF Korzeniewska, Anna
   Mitsuhashi, Takumi
   Wang, Yujing
   Asano, Eishi
   Franaszczuk, Piotr J.
   Crone, Nathan E.
TI Significance of event related causality (ERC) in eloquent neural networks
SO NEURAL NETWORKS
LA English
DT Article
DE Neural networks interactions; Multivariate autoregressive model; Granger causality; Short-time direct directed transfer function; Information flow; Time-frequency analysis
ID top-down facilitation; comparing splines; granger causality; information-flow; brain; dynamics; speech; electrocorticography; potentials; language
AB Neural activity emerges and propagates swiftly between brain areas. Investigation of these transient large-scale flows requires sophisticated statistical models. We present a method for assessing the statistical confidence of event-related neural propagation. Furthermore, we propose a criterion for statistical model selection, based on both goodness of fit and width of confidence intervals. We show that event-related causality (ERC) with two-dimensional (2D) moving average, is an efficient estimator of task-related neural propagation and that it can be used to determine how different cognitive task demands affect the strength and directionality of neural propagation across human cortical networks. Using electrodes surgically implanted on the surface of the brain for clinical testing prior to epilepsy surgery, we recorded electrocorticographic (ECoG) signals as subjects performed three naming tasks: naming of ambiguous and unambiguous visual objects, and as a contrast, naming to auditory description. ERC revealed robust and statistically significant patterns of high gamma activity propagation, consistent with models of visually and auditorily cued word production. Interestingly, ambiguous visual stimuli elicited more robust propagation from visual to auditory cortices relative to unambiguous stimuli, whereas naming to auditory description elicited propagation in the opposite direction, consistent with recruitment of modalities other than those of the stimulus during object recognition and naming. The new method introduced here is uniquely suitable to both research and clinical applications and can be used to estimate the statistical significance of neural propagation for both cognitive neuroscientific studies and functional brain mapping prior to resective surgery for epilepsy and brain tumors.
C1 [Korzeniewska, Anna; Wang, Yujing; Franaszczuk, Piotr J.; Crone, Nathan E.] Johns Hopkins Univ, Dept Neurol, Sch Med, Baltimore, MD USA.
   [Mitsuhashi, Takumi; Asano, Eishi] Wayne State Univ, Dept Neurol, Sch Med, Detroit, MI USA.
   [Franaszczuk, Piotr J.] Human Res & Engn Directorate, CCDC Army Res Lab, Aberdeen Proving Ground, MD USA.
C3 Johns Hopkins University; Wayne State University
RP Korzeniewska, A (通讯作者)，Johns Hopkins Univ, Dept Neurol, 600 N Wolfe St,Meyer 2-147, Baltimore, MD 21287 USA.
EM akorzen@jhmi.edu
FU National Institutes of Health, United States [NINDS R01-NS088606, NINDS R01-NS091139, NINDS R01NS064033]
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   ALTES RA, 1980, J ACOUST SOC AM, V67, P1232, DOI 10.1121/1.384165
   Asano E, 2009, BRAIN, V132, P1038, DOI 10.1093/brain/awp025
   Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2
   Bar M, 1996, PERCEPTION, V25, P343, DOI 10.1068/p250343
   Bar M, 2006, P NATL ACAD SCI USA, V103, P449, DOI 10.1073/pnas.0507062103
   Blinowska KJ, 2009, GENE, V435, P104, DOI 10.1016/j.gene.2009.01.009
   Blinowska KJ, 2011, MED BIOL ENG COMPUT, V49, P521, DOI 10.1007/s11517-011-0739-x
   Bose E, 2017, NURS RES, V66, P12, DOI 10.1097/NNR.0000000000000193
   Cervenka MC, 2013, NEUROIMAGE, V69, P267, DOI 10.1016/j.neuroimage.2012.12.037
   Chaudhuri SE, 2015, SPECTRAL ANAL STOCK, V0, PP232, DOI 10.1109/DSP-SPE.2015.7369558
   Cho-Hisamoto Y, 2015, CLIN NEUROPHYSIOL, V126, P17, DOI 10.1016/j.clinph.2014.03.034
   Dapretto M, 1999, NEURON, V24, P427, DOI 10.1016/S0896-6273(00)80855-7
   Ding MZ, 2000, BIOL CYBERN, V83, P35, DOI 10.1007/s004229900137
   DUBRULE O, 1986, COMPUT GEOSCI, V12, P729, DOI 10.1016/0098-3004(86)90051-8
   DUBRULE O, 1984, COMPUT GEOSCI, V10, P327, DOI 10.1016/0098-3004(84)90030-X
   Eger E, 2007, CEREB CORTEX, V17, P2123, DOI 10.1093/cercor/bhl119
   Forseth KJ, 2018, BRAIN, V141, P2112, DOI 10.1093/brain/awy120
   Fujita A, 2007, BMC SYST BIOL, V1, P0, DOI 10.1186/1752-0509-1-39
   Ghosh SS, 2010, NEUROIMAGE, V53, P85, DOI 10.1016/j.neuroimage.2010.05.075
   Gibbons SJ, 2008, GEOPHYS J INT, V172, P405, DOI 10.1111/j.1365-246X.2007.03650.x
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Griffaton J, 2014, ISMA 2014, V0, P2809
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004
   Hamberger MJ, 2009, J INT NEUROPSYCH SOC, V15, P529, DOI 10.1017/S1355617709090754
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hossain MS, 2012, GLOBAL J MANAGEMENT, V12, P41
   Ikegaya N, 2019, CLIN NEUROPHYSIOL, V130, P1446, DOI 10.1016/j.clinph.2019.04.008
   Indefrey P, 2011, FRONT PSYCHOL, V2, P0, DOI 10.3389/fpsyg.2011.00255
   Kaminski M, 2019, INT J NEURAL SYST, V29, P0, DOI 10.1142/S0129065718500466
   Kaminski M, 2016, FRONT COMPUT NEUROSC, V10, P0, DOI 10.3389/fncom.2016.00114
   KAMINSKI MJ, 1991, BIOL CYBERN, V65, P203, DOI 10.1007/BF00198091
   Kanemoto S, 1984, NUCL TECHNOLOGY US, V67, P0
   Karlsson B, 2013, IEEE ENG MED BIO, V0, PP7444, DOI 10.1109/EMBC.2013.6611279
   Korzeniewska A, 2014, NEUROIMAGE, V101, P96, DOI 10.1016/j.neuroimage.2014.06.078
   Korzeniewska A, 2003, J NEUROSCI METH, V125, P195, DOI 10.1016/S0165-0270(03)00052-9
   Korzeniewska A, 2011, EPILEPSY CURR, V12, P0
   Korzeniewska A, 2008, HUM BRAIN MAPP, V29, P1170, DOI 10.1002/hbm.20458
   Korzeniewska A, 2020, PROG NEUROBIOL, V189, P0, DOI 10.1016/j.pneurobio.2020.101788
   Korzeniewska A, 2011, NEUROIMAGE, V56, P2218, DOI 10.1016/j.neuroimage.2011.03.030
   KOSCIELNY AJ, 1984, J CLIMATOL, V4, P347, DOI 10.1002/joc.3370040402
   Kostoglou K, 2019, IEEE T BIO-MED ENG, V66, P3257, DOI 10.1109/TBME.2019.2903012
   Lachaux JP, 2012, PROG NEUROBIOL, V98, P279, DOI 10.1016/j.pneurobio.2012.06.008
   Mac Nally R, 2010, ECOL APPL, V20, P1417, DOI 10.1890/09-1724.1
   Mainy N, 2008, HUM BRAIN MAPP, V29, P1215, DOI 10.1002/hbm.20457
   Mu WJ, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-01045-4
   Nakai Y, 2019, EPILEPSIA, V60, P255, DOI 10.1111/epi.14648
   Nakai Y, 2017, BRAIN, V140, P1351, DOI 10.1093/brain/awx051
   Narayan PK, 2009, ENERG POLICY, V37, P229, DOI 10.1016/j.enpol.2008.08.020
   Niessing J, 2005, SCIENCE, V309, P948, DOI 10.1126/science.1110948
   Nishida M, 2017, CLIN NEUROPHYSIOL, V128, P1473, DOI 10.1016/j.clinph.2017.05.002
   Omran EE, 2012, INTERNATIONAL JOURNAL OF GEOSCIENCES, V3, P574
   Oryani B, 2020, ENERGIES, V13, P0, DOI 10.3390/en13164268
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Ray S, 2008, J NEUROSCI, V28, P11526, DOI 10.1523/JNEUROSCI.2848-08.2008
   Robinson TP, 2006, COMPUT ELECTRON AGR, V50, P97, DOI 10.1016/j.compag.2005.07.003
   Ruppert D, 2003, SEMIPARAMETRIC REGRE, V0, P0
   Sawant S, 2022, METHODS ECOL EVOL, V13, P459, DOI 10.1111/2041-210X.13765
   Smith SW, 1999, SCI ENG GUIDE DIGITA, V2nd ed., P0
   Stolk A, 2018, NAT PROTOC, V13, P1699, DOI 10.1038/s41596-018-0009-6
   Sussillo D, 2004, EURASIP J APPL SIG P, V2004, P29, DOI 10.1155/S1110865704310048
   TAKANAMI T, 1991, ANN I STAT MATH, V43, P407, DOI 10.1007/BF00053364
   TJOSTHEIM D, 1979, IEEE T PATTERN ANAL, V1, P80, DOI 10.1109/TPAMI.1979.4766878
   Turhan-Sayan G, 2002, APPL OPTIMIZAT, V0, PP429, DOI 10.1007/978-1-4757-3613-7_22
   Wang YJ, 2021, FRONT HUM NEUROSCI, V15, P0, DOI 10.3389/fnhum.2021.661976
   Wang YJ, 2021, CEREB CORTEX, V31, P2058, DOI 10.1093/cercor/bhaa344
   Wang YJ, 2016, NEUROLOGY, V86, P1181, DOI 10.1212/WNL.0000000000002525
   WICKENS DD, 1970, PSYCHOL REV, V77, P1, DOI 10.1037/h0028569
   Yan RQ, 2009, TRIBOL INT, V42, P293, DOI 10.1016/j.triboint.2008.06.013
   Yue TX, 2013, T GIS, V17, P943, DOI 10.1111/tgis.12019
   Zivot E, 2006, MODELING FINANCIAL T, V0, PP385, DOI 10.1007/978-0-387-32348-0
NR 71
TC 3
Z9 3
U1 2
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD MAY 15
PY 2022
VL 149
IS 
BP 204
EP 216
DI 10.1016/j.neunet.2022.02.002
EA MAR 2022
PG 13
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA 1F4SR
UT WOS:000795159500002
PM 35248810
DA 2023-11-10
ER

PT J
AU Nassif, AB
   Elnagar, A
   Elgendy, O
   Afadar, Y
AF Nassif, Ali Bou
   Elnagar, Ashraf
   Elgendy, Omar
   Afadar, Yaman
TI Arabic fake news detection based on deep contextualized embedding models
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Arabic fake news; Natural language processing; Contextualized models; Deep learning
AB Social media is becoming a source of news for many people due to its ease and freedom of use. As a result, fake news has been spreading quickly and easily regardless of its credibility, especially in the last decade. Fake news publishers take advantage of critical situations such as the Covid-19 pandemic and the American presidential elections to affect societies negatively. Fake news can seriously impact society in many fields including politics, finance, sports, etc. Many studies have been conducted to help detect fake news in English, but research conducted on fake news detection in the Arabic language is scarce. Our contribution is twofold: first, we have constructed a large and diverse Arabic fake news dataset. Second, we have developed and evaluated transformer-based classifiers to identify fake news while utilizing eight state-of-the-art Arabic contextualized embedding models. The majority of these models had not been previously used for Arabic fake news detection. We conduct a thorough analysis of the state-of-the-art Arabic contextualized embedding models as well as comparison with similar fake news detection systems. Experimental results confirm that these state-of-the-art models are robust, with accuracy exceeding 98%.
C1 [Nassif, Ali Bou; Elgendy, Omar; Afadar, Yaman] Univ Sharjah, Dept Comp Engn, POB 27272, Sharjah, U Arab Emirates.
   [Nassif, Ali Bou] Western Univ, London, ON N6A 3K7, Canada.
   [Elnagar, Ashraf] Univ Sharjah, Dept Comp Sci, POB 27272, Sharjah, U Arab Emirates.
C3 University of Sharjah; Western University (University of Western Ontario); University of Sharjah
RP Nassif, AB (通讯作者)，Univ Sharjah, Dept Comp Engn, POB 27272, Sharjah, U Arab Emirates.; Nassif, AB (通讯作者)，Western Univ, London, ON N6A 3K7, Canada.
EM anassif@sharjah.ac.ae; ashraf@sharjah.ac.ae; u20106090@sharjah.ac.ae; u17104387@sharjah.ac.ae
FU University of Sharjah
CR Al-Yahya M, 2021, COMPLEXITY, V2021, P0, DOI 10.1155/2021/5516945
   Alkhair M, 2019, COMM COM INF SC, V1108, P292, DOI 10.1007/978-3-030-32959-4_21
   Alwaneen TH, 2022, ARTIF INTELL REV, V55, P207, DOI 10.1007/s10462-021-10031-1
   Antoun W, 2020, 2020 IEEE INT C INF, V0, P0
   Antoun W, 2020, P 4 WORKSHOP OPEN SO, V0, P9
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Chowdhury SA, 2020, P 5 AR NAT LANG PROC, V0, P0
   Conneau A, 2020, P 58 ANN M ASS COMP, V0, P0
   de Souza JV, 2020, SOC NETW ANAL MIN, V10, P0, DOI 10.1007/s13278-020-00659-2
   Douai A, 2019, IEMED MEDITERR YB, V16, P124
   El Ballouli R, 2017, CAT CREDIBILITY ANAL, V0, P6271
   Elmadany A, 2020, P 5 AR NAT LANG PROC, V0, P6984
   Ameur MSH, 2021, PROCEDIA COMPUT SCI, V189, P232, DOI 10.1016/j.procs.2021.05.086
   Haouari F, 2019, BIGIR CLEF 2019 AUTO, V0, P0
   Helwe C, 2019, ASSESSING ARABIC WEB, V0, P0
   Hijazi H, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21248424
   Injadat M, 2021, ARTIF INTELL REV, V54, P3299, DOI 10.1007/s10462-020-09948-w
   Injadat M, 2016, NEUROCOMPUTING, V214, P654, DOI 10.1016/j.neucom.2016.06.045
   Jardaneh G, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), V0, PP596, DOI 10.1109/JEEIT.2019.8717386
   Kaliyar RK, 2018, 2018 4 INT C COMP CO, V0, P0
   Lan W, 2020, P 2020 C EMP METH NA, V0, P0
   Mehta D, 2021, SOC NETW ANAL MIN, V11, P0, DOI 10.1007/s13278-021-00738-y
   Nagoudi EMB, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Nassif AB, 2022, MATHEMATICS-BASEL, V10, P0, DOI 10.3390/math10040564
   Nassif AB, 2022, ACM T ASIAN LOW-RESO, V21, P0, DOI 10.1145/3466171
   Nassif AB, 2021, APPL SOFT COMPUT, V98, P0, DOI 10.1016/j.asoc.2020.106836
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Oueslati O, 2020, FUTURE GENER COMP SY, V112, P408, DOI 10.1016/j.future.2020.05.034
   Ozbay FA, 2020, PHYSICA A, V540, P0, DOI 10.1016/j.physa.2019.123174
   Rangel F, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), V0, PP86, DOI 10.1109/ISI.2019.8823378
   Saadany H, 2020, FAKE REAL STUDY ARAB, V0, P0
   Sabbeh Sahar F, 2018, JOURNAL OF THEORETICAL AND APPLIED INFORMATION TECHNOLOGY, V96, P2327
   Safaya Ali, 2020, KUISAIL SEMEVAL 2020, V0, P0
   Sutanto DH, 2015, ARPN J ENG APPL SCI, V10, P9941
   Traylor T, 2019, PROCEEDINGS13TH IEEE, V0, P0
   Vilares D, 2019, PROC 2018 IEEE S SER, V2018, P0
   Wang, 2013, ENCY SYSTEMBIOL, V0, P0
   Yang K, 2019, ARXIV190707347, V0, P0
NR 38
TC 12
Z9 12
U1 5
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD SEP 15
PY 2022
VL 34
IS 18
BP 16019
EP 16032
DI 10.1007/s00521-022-07206-4
EA MAY 2022
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3Z6BV
UT WOS:000790100400002
PM 35529091
DA 2023-11-10
ER

PT J
AU Wang, SL
   Wang, ZY
   Che, WX
   Zhao, SD
   Liu, T
AF Wang, Shaolei
   Wang, Zhongyuan
   Che, Wanxiang
   Zhao, Sendong
   Liu, Ting
TI Combining Self-supervised Learning and Active Learning for Disfluency Detection
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Disfluency detection; self-supervised learning; active learning; pre-training technology
AB Spoken language is fundamentally different from the written language in that it contains frequent disfluencies or parts of an utterance that are corrected by the speaker. Disfluency detection (removing these disfluencies) is desirable to clean the input for use in downstream NLP tasks. Most existing approaches to disfluency detection heavily rely on human-annotated data, which is scarce and expensive to obtain in practice. To tackle the training data bottleneck, in this work, we investigate methods for combining self-supervised learning and active learning for disfluency detection. First, we construct large-scale pseudo training data by randomly adding or deleting words fromunlabeled data and propose two self-supervised pre-training tasks: (i) a tagging task to detect the added noisy words and (ii) sentence classification to distinguish original sentences from grammatically incorrect sentences. We then combine these two tasks to jointly pre-train a neural network. The pre-trained neural network is then fine-tuned using human-annotated disfluency detection training data. The self-supervised learning method can capture task-special knowledge for disfluency detection and achieve better performance when fine-tuning on a small annotated dataset compared to other supervised methods. However, limited in that the pseudo training data are generated based on simple heuristics and cannot fully cover all the disfluency patterns, there is still a performance gap compared to the supervised models trained on the full training dataset. We further explore how to bridge the performance gap by integrating active learning during the fine-tuning process. Active learning strives to reduce annotation costs by choosing the most critical examples to label and can address the weakness of self-supervised learning with a small annotated dataset. We show that by combining self-supervised learning with active learning, our model is able to match state-of-the-art performance with just about 10% of the original training data on both the commonly used English Switchboard test set and a set of in-house annotated Chinese data.
C1 [Wang, Shaolei; Wang, Zhongyuan; Che, Wanxiang; Zhao, Sendong; Liu, Ting] Harbin Inst Technol, 2 YiKuang St,Tech & Innovat Bldg,HIT Sci Pk, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Che, WX (通讯作者)，Harbin Inst Technol, 2 YiKuang St,Tech & Innovat Bldg,HIT Sci Pk, Harbin 150001, Heilongjiang, Peoples R China.
EM slwang@ir.hit.edu.cn; zywang@ir.hit.edu.cn; car@ir.hit.edu.cn; sdzhao@ir.hit.edu.cn; tliu@ir.hit.edu.cn
FU National Key R&D Program of China [2020AAA0106501]; National Natural Science Foundation of China (NSFC) [61976072, 61772153]
CR Agrawal P, 2015, IEEE I CONF COMP VIS, V0, PP37, DOI 10.1109/ICCV.2015.13
   Alonso HM, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P44
   andAbhinavGupta XiaolongWang, 2015, P INT C COMP VIS ICC, V0, P0
   [Anonymous], 1995, DYSFLUENCY ANNOTATIO, V0, P0
   Bach N, 2019, INTERSPEECH, V0, PP4230, DOI 10.21437/Interspeech.2019-1336
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bingel J, 2017, P 15 C EUR CHAPT ASS, V0, PP164, DOI 10.18653/V1/E17-2026
   Burr Settles, 2009, ACTIVE LEARNING LITE, V0, P0
   Charniak E, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P118
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, P0, DOI 10.1155/2014/575246
   Culotta A, 2005, AAAI, V0, P746
   Devlin J, 2018, ARXIV, V1, P4171
   Dong QQ, 2019, AAAI CONF ARTIF INTE, V0, P6351
   Dongyu Ru, 2020, FINDINGS ASS COMPUTA, V0, PP4908, DOI 10.18653/V1/2020.FINDINGS-EMNLP
   Ein-Dor L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7949
   Ferguson James, 2015, P 2015 C N AM CHAPTE, V0, P257
   Fernando B, 2017, PROC CVPR IEEE, V0, PP5729, DOI 10.1109/CVPR.2017.607
   Gal Y, 2016, PR MACH LEARN RES, V48, P0
   Georgila Kallirroi, 2009, P N AM CHAPT ASS COM, V0, P0
   Gissin Daniel, 2019, ARXIV190706347, V0, P0
   Godfrey JJ, 1992, ICASSP-92: 1992 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P517, DOI 10.1109/ICASSP.1992.225858
   Hendrycks Dan, 2016, ARXIV160608415, V0, P0
   Honnibal Matthew, 2014, T ASSOC COMPUT LING, V2, P0
   Hough J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P849
   Johnson Mark, 2004, P ANN M ASS COMP LIN, V0, P0
   Lewis DD, 1994, SIGIR 94. PROCEEDINGS OF THE SEVENTEENTH ANNUAL INTERNATIONAL ACM-SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P3
   Liu Ming, 2018, P 22 C COMPUTATIONAL, V0, P334
   Liu T, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P102, DOI 10.18653/v1/P17-1010
   Lou PJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3754
   Lou PJ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P547, DOI 10.18653/v1/P17-2087
   Lou PJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4610
   Lou PJ, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2756
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Ostendorf M, 2013, INTERSPEECH, V0, P2623
   Peng H, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2037, DOI 10.18653/v1/P17-1186
   Peris A, 2018, P 22 C COMP NAT LANG, V0, PP151, DOI 10.18653/V1/K18-1015
   Prabhu A, 2019, P 2019 C EMP METH NA, V0, PP4058, DOI 10.18653/v1/D19-1417
   Qian Xian, 2013, P C N AM ASS COMP LI, V0, P820
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rasooli Mohammad Sadegh, 2013, P 2013 C EMPIRICAL M, V0, P124
   Sener Ozan, 2017, INT C LEARN REPR, V0, P0
   ShaoleiWang WChe, 2020, P AAAI C ART INT AAA, V0, P0
   Shen Y, 2017, P 2 WORKSHOP REPRESE, V0, PP252, DOI 10.18653/V1/W17-2630
   Shriberg EE, 1994, PRELIMINARIES THEORY, V0, P0
   Siddhant A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2904
   Tanaka Tomohiro, 2019, 2019 ASIA-PACIFIC SIGNAL AND INFORMATION PROCESSING ASSOCIATION ANNUAL SUMMIT AND CONFERENCE (APSIPA ASC), V0, PP1009, DOI 10.1109/APSIPAASC47483.2019.9023119
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang S, 2017, P 2017 C EMP METH NA, V0, P2785
   Wang Shaolei, 2016, P INT C COMP LING CO, V0, P0
   Wu Shuangzhi, 2015, P ANN M ASS COMP LIN, V0, P0
   Xu Bo, 2018, P INT C COMP LING CO, V0, P0
   Yoshikawa Masashi, 2016, P EMPIRICAL METHODS, V0, P0
   Zayats V, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P86
   Zayats V, 2016, INTERSPEECH, V0, PP2523, DOI 10.21437/Interspeech.2016-1247
   Zayats Vicky, 2018, ARXIV181107236, V0, P0
   Zayats Victoria, 2014, P INTERSPEECH C INTE, V0, P0
   Zhang Ye, 2016, P AAAI C ART INT, V31, P0
   Zhao Y, 2020, FINDINGS ASS COMPUTA, V0, PP1796, DOI 10.18653/v1/2020.findingsemnlp.162
   Zwarts Simon, 2010, PROC COLING, V0, P1371
NR 60
TC 2
Z9 2
U1 2
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAY 15
PY 2022
VL 21
IS 3
BP 
EP 
DI 10.1145/3487290
PG 25
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0H0SQ
UT WOS:000778450600020
DA 2023-11-10
ER

PT J
AU Hu, M
   Peng, JJ
   Zhang, WQ
   Hu, JX
   Qi, LZ
   Zhang, HX
AF Hu, Miao
   Peng, Junjie
   Zhang, Wenqiang
   Hu, Jingxiang
   Qi, Lizhe
   Zhang, Huanxiang
TI Text Representation Model for Multiple Language Forms in Spoken Chinese Expression
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Multi-language forms; syllabic features; intent understanding; spoken language
AB Mixture of multiple language forms in spoken Chinese is a common but unfavorable issue.. It increases the difficulty of intent understanding and leads to inconvenience for information communication. Existing studies on intent recognition mainly focus on single language form or parallel multilingual language while paying little attention to spoken texts including multiple language forms. In considering that it is hard to capture the semantics of an expression with multiple language forms, it is important to study the problem. To solve this issue, a text representation model for the spoken Chinese expression mixed with English and Chinese Pinyin is proposed. And the feature matrix is built to mine the composition information of English and Pinyin. Besides, the model can efficiently distinguish English from Chinese Pinyin even though both fragments are composed of English letters. Meanwhile, it can effectively process the problem of hidden text information since the problem has been transformed into the Chinese translation task of English and Pinyin. In addition, to verify the performance of the model, the texts processed by this model are used as the input of the classifier. extensive experiments on a large online logistics manual customer service corpus show that this text representation model is correct and effective. It can not only eliminate the obstacles of the mixing of multiple language forms but also bring better results for intent understanding.
C1 [Hu, Miao; Peng, Junjie; Hu, Jingxiang; Zhang, Huanxiang] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Peng, Junjie] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
   [Peng, Junjie] Fudan Univ, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
   [Zhang, Wenqiang; Qi, Lizhe] Fudan Univ, Acad Engn & Technol, Shanghai, Peoples R China.
   [Zhang, Wenqiang] Fudan Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University; Fudan University; Fudan University; Fudan University
RP Peng, JJ (通讯作者)，Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.; Peng, JJ (通讯作者)，Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.; Peng, JJ (通讯作者)，Fudan Univ, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
EM jjie.peng@shu.edu.cn; wqzhang@fudan.edu.cn
FU Open Project Program of Shanghai Key Laboratory of Data Science [2020090600004]; Shanghai software and integrated circuit industry development project [RX-RJJC-07-19-4847]
CR Amine BM, 2007, I C COMP SYST APPLIC, V0, PP848, DOI 10.1109/AICCSA.2007.370731
   Celikyilmaz A, 2011, 2011 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU), V0, PP425, DOI 10.1109/ASRU.2011.6163969
   Chen H, 2016, COMPUT APPL SOFTW, V0, P68
   Duan JY, 2019, LECT NOTES ARTIF INT, V11838, P471, DOI 10.1007/978-3-030-32233-5_37
   Figueroa A, 2016, IEEE INTERNET COMPUT, V20, P8, DOI 10.1109/MIC.2015.22
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Haffner P, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P632
   Huang CW, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), V0, PP845, DOI 10.1109/asru46091.2019.9003825
   Jiang ZF, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 1, PROCEEDINGS
   Jiao Liu, 2018, WEB INFORMATION SYSTEMS AND APPLICATIONS. 15TH INTERNATIONAL CONFERENCE, V0, P27, DOI 10.1007/978-3-030-02934-0_3
   Jun W, 2003, APPLLINGUISTICS, V2, P2
   Kim Y, 2014, PREPRINT, V0, P0
   Li CL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3824
   Matsuyoshi Y, 2018, ASIAPAC SIGN INFO PR, V0, PP1752, DOI 10.23919/APSIPA.2018.8659636
   McCallum A, 1998, AAAI 98 WORKSH LEARN, V0, PP41, DOI 10.1109/TSMC.1985.6313426
   Mishra A, 2016, J KING SAUD UNIV-COM, V28, P345, DOI 10.1016/j.jksuci.2014.10.007
   Ni X, 2009, P 18 INT C WORLD WID, V0, P1155
   Ravuri S, 2016, INT CONF ACOUST SPEE, V0, PP6075, DOI 10.1109/ICASSP.2016.7472844
   Sidorov G, 2014, EXPERT SYST APPL, V41, P853, DOI 10.1016/j.eswa.2013.08.015
   Tseng C-RHEI, 2003, CROSS LINGUAL PORTAB, V0, P0
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wang JP, 2015, AAAI CONF ARTIF INTE, V0, P339
   Yu RY, 2018, NEURAL COMPUT APPL, V29, P707, DOI 10.1007/s00521-016-2477-3
   Zhang Q, 2019, AS C MACH LEARN PMLR, V0, P425
   Zhao ZY, 2019, DATA INTELLIGENCE, V1, P187, DOI 10.1162/dint_a_00007
   Zhong J, 2019, PREPRINT, V0, P0
NR 26
TC 2
Z9 2
U1 3
U2 6
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD JUN 30
PY 2022
VL 36
IS 08
BP 
EP 
DI 10.1142/S0218001422530044
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 2S3PK
UT WOS:000821707100007
DA 2023-11-10
ER

PT J
AU Mamta
   Ekbal, A
   Bhattacharyya, P
AF Mamta
   Ekbal, Asif
   Bhattacharyya, Pushpak
TI Exploring Multi-lingual, Multi-task, and Adversarial Learning for Low-resource Sentiment Analysis
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Sentiment analysis; low-resource language; multi-task; multi-lingual; adversarial training
ID products; lexicon; set
AB Deep learning has become most prominent in solving various Natural Language Processing (NLP) tasks including sentiment analysis. However, these techniques require a considerably large amount of annotated corpus, which is not easy to obtain for most of the languages, especially under the scenario of low-resource settings. In this article, we propose a deep multi-task multi-lingual adversarial framework to solve the resource-scarcity problem of sentiment analysis by leveraging the useful and relevant knowledge from a high-resource language. To transfer the knowledge between the different languages, both the languages are mapped to the shared semantic space using cross-lingual word embeddings. We evaluate our proposed architecture on a low-resource language, Hindi, using English as the high-resource language. Experiments show that our proposed model achieves an accuracy of 60.09% for the movie review dataset and 72.14% for the product review dataset. The effectiveness of our proposed approach is demonstrated with significant performance gains over the state-of-the-art systems and translation-based baselines.
C1 [Mamta; Ekbal, Asif; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Patna, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of Technology System (IIT System)
RP Ekbal, A (通讯作者)，Indian Inst Technol Patna, Patna, Bihar, India.
EM mamta20118@gmail.com; asif.ekbal@gmail.com; pb@iitb.ac.in
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Ahmad Z, 2020, EXPERT SYST APPL, V139, P0, DOI 10.1016/j.eswa.2019.112851
   Akhtar MS, 2020, IEEE COMPUT INTELL M, V15, P64, DOI 10.1109/MCI.2019.2954667
   Akhtar MS, 2017, KNOWL-BASED SYST, V125, P116, DOI 10.1016/j.knosys.2017.03.020
   Akhtar Md Shad, 2016, P COLING 2016 26 INT, V0, P482
   Akhtar Md Shad, 2018, P 2018 C N AM CHAPTE, V0, P572
   Akhtar Md Shad, 2017, P 2017 C EMPIRICAL M, V0, P540
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Attia M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P635
   BAKLIWAL A, 2013, SENTIMENT ANAL POLIT, V0, P0
   Bhattacharyya P, 2010, P ICON 8 INT C NAT L, V0, P0
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chaturvedi I, 2018, INFORM FUSION, V44, P65, DOI 10.1016/j.inffus.2017.12.006
   Chen X, 2018, T ASSOC COMPUT LING, V6, P557, DOI 10.1162/TACL_A_00039
   Chikersal P, 2015, P 9 INT WORKSH SEM E, V0, PP647, DOI 10.18653/V1/S15-2108
   Chung JY, 2015, PR MACH LEARN RES, V37, P2067
   Conneau A, 2018, ARXIV, V0, P0
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   Dey A, 2018, EXPERT SYST APPL, V103, P92, DOI 10.1016/j.eswa.2018.03.004
   Can EF, 2018, ARXIV, V0, P0
   Ghiassi M, 2018, EXPERT SYST APPL, V106, P197, DOI 10.1016/j.eswa.2018.04.006
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gulli A, 2017, DEEP LEARNING KERAS, V0, P0
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Hu JJ, 2020, PR MACH LEARN RES, V119, P0
   Joshi A, 2012, P COLING 2012 POST, V1, P73
   Kingma DP, 2014, C TRACK P, V0, P0
   Kumar S, 2019, INFORM FUSION, V52, P41, DOI 10.1016/j.inffus.2018.11.001
   Lin Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P799
   Liu Pengfei, 2017, ADVERSARIAL MULTITAS, V0, P0
   Liu Y, 2017, INFORM FUSION, V36, P149, DOI 10.1016/j.inffus.2016.11.012
   Lou YX, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3389035
   Mamta, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P5046
   Masumura R, 2018, P 27 INT C COMP LING, V0, P3586
   Mishra Sudhanshu, 2021, SN COMPUT SCI, V2, P72, DOI 10.1007/s42979- 021- 00455-5
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, P0, DOI 10.1145/3003433
   OHare Neil, 2009, P 1 INT CIKM WORKSHO, V0, PP9, DOI 10.1145/1651461.1651464
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, V0, PP79, DOI 10.3115/1118693.1118704
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Shuang K, 2020, INFORM FUSION, V61, P13, DOI 10.1016/j.inffus.2020.03.003
   Singhal P, 2016, P COLING 2016 26 INT, V0, P3053
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thakkar G, 2021, CLEOPATRA WWW, V0, PP76, DOI 10.48550/arXiv.2212.07160
   Valdivia A, 2018, INFORM FUSION, V44, P126, DOI 10.1016/j.inffus.2018.03.007
   Van de Kauter M, 2015, EXPERT SYST APPL, V42, P4999, DOI 10.1016/j.eswa.2015.02.007
   Wu CH, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP1091, DOI 10.1145/3357384.3357973
   Wu FZ, 2017, INFORM FUSION, V35, P26, DOI 10.1016/j.inffus.2016.09.001
   Yadav S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5234
   Ye X, 2021, EXPERT SYST APPL, V166, P0, DOI 10.1016/j.eswa.2020.113987
   Zhou X, 2016, P 2016 C EMPIRICAL M, V0, PP247, DOI 10.18653/V1/D16-1024
NR 52
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2022
VL 21
IS 5
BP 
EP 
DI 10.1145/3514498
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9Z2DN
UT WOS:000950956700020
DA 2023-11-10
ER

PT J
AU Luo, G
   Zhou, YY
   Sun, XS
   Wang, Y
   Cao, LJ
   Wu, YJ
   Huang, FY
   Ji, RR
AF Luo, Gen
   Zhou, Yiyi
   Sun, Xiaoshuai
   Wang, Yan
   Cao, Liujuan
   Wu, Yongjian
   Huang, Feiyue
   Ji, Rongrong
TI Towards Lightweight Transformer Via Group-Wise Transformation for Vision-and-Language Tasks
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Transformers; Task analysis; Computational modeling; Benchmark testing; Visualization; Convolution; Head; Lightweight transformer; visual question answering; image captioning; reference expression comprehension
AB Despite the exciting performance, Transformer is criticized for its excessive parameters and computation cost. However, compressing Transformer remains as an open problem due to its internal complexity of the layer designs, i.e., Multi-Head Attention (MHA) and Feed-Forward Network (FFN). To address this issue, we introduce Group-wise Transformation towards a universal yet lightweight Transformer for vision-and-language tasks, termed as LW-Transformer. LW-Transformer applies Group-wise Transformation to reduce both the parameters and computations of Transformer, while also preserving its two main properties, i.e., the efficient attention modeling on diverse subspaces of MHA, and the expanding-scaling feature transformation of FFN. We apply LW-Transformer to a set of Transformer-based networks, and quantitatively measure them on three vision-and-language tasks and six benchmark datasets. Experimental results show that while saving a large number of parameters and computations, LW-Transformer achieves very competitive performance against the original Transformer networks for vision-and-language tasks. To examine the generalization ability, we apply LW-Transformer to the task of image classification, and build its network based on a recently proposed image Transformer called Swin-Transformer, where the effectiveness can be also confirmed.
C1 [Luo, Gen; Zhou, Yiyi; Sun, Xiaoshuai; Cao, Liujuan; Ji, Rongrong] Xiamen Univ, Dept Artificial Intelligence, Media Analyt & Comp Lab, Xiamen 361005, Peoples R China.
   [Wang, Yan] Microsoft, Beijing 100080, Peoples R China.
   [Wu, Yongjian; Huang, Feiyue] Tencent Technol Shanghai Co Ltd, Shenzhen 518000, Peoples R China.
C3 Xiamen University
RP Zhou, YY (通讯作者)，Xiamen Univ, Dept Artificial Intelligence, Media Analyt & Comp Lab, Xiamen 361005, Peoples R China.
EM luogen@stu.xmu.edu.cn; zhouyiyi@xmu.edu.cn; xssun@xmu.edu.cn; yanwang@ee.columbia.edu; caoliujuan@xmu.edu.cn; littlekenwu@tencent.com; garyhuang@tencent.com; rrji@xmu.edu.cn
FU National Science Fund for Distinguished Young Scholars [62025603]; National Natural Science Foundation of China [U21B2037, 62176222, 62176223, 62176226, 62072386, 62072387, 62072389, 62002305]; China Postdoctoral Science Foundation [2021T40397]; Guangdong Basic and Applied Basic Research Foundation [2019B1515120049]; Natural Science Foundation of Fujian Province of China [2021J01002]
CR Alberti C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2131
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2005, P ACL WORKSHOP INTRI, V0, P0
   [Anonymous], 2018, INT C MACH LEARN STO, V0, P0
   [Anonymous], 2018, PROC INT C LEARN REP, V0, P0
   Antol S, 2015, IEEE I CONF COMP VIS, V0, PP2425, DOI 10.1109/ICCV.2015.279
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, V0, P8102
   Ben-younes H, 2017, IEEE I CONF COMP VIS, V0, PP2631, DOI 10.1109/ICCV.2017.285
   Carion Nicolas, 2020, ARXIV200512872, V0, P0
   Chelba C, 2013, ARXIV PREPRINT ARXIV, V0, P0
   Chen Xinlei, 2015, ARXIV150400325, V0, P0
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Choromanski KM, 2020, PROC INT C LEARN REP, V0, P0
   Chu X, 2021, ADV NEURAL INF PROCE, V34, P9355, DOI 10.48550/ARXIV.2104.13840
   Cornia Marcella, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10575, DOI 10.1109/CVPR42600.2020.01059
   Cornia M, 2019, ARXIV191002974, V0, P0
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, V0, PP3008, DOI 10.1109/CVPRW50498.2020.00359
   Dai Zihang, 2019, ARXIV190102860, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2018, ARXIV, V1, P4171
   El-Nouby A, 1900, V2021, V0, P0
   Fan A, 2019, ARXIV, V103, P1
   Fukui Akira, 2016, ARXIV160601847, V0, PP457, DOI 10.18653/V1/D16-1044
   Gao P, 2019, IEEE I CONF COMP VIS, V0, PP5824, DOI 10.1109/ICCV.2019.00592
   Gao P, 2019, PROC CVPR IEEE, V0, PP6632, DOI 10.1109/CVPR.2019.00680
   Goyal Y, 2017, PROC CVPR IEEE, V0, PP6325, DOI 10.1109/CVPR.2017.670
   Guo QP, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1315
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Herdade S, 2019, ADV NEUR IN, V32, P0
   Howard Andrew G, 2017, ARXIV170404861, V0, P0
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/TPAMI.2019.2913372
   Hu RH, 2019, IEEE I CONF COMP VIS, V0, PP10293, DOI 10.1109/ICCV.2019.01039
   Hu RH, 2017, PROC CVPR IEEE, V0, PP4418, DOI 10.1109/CVPR.2017.470
   Hu RH, 2016, PROC CVPR IEEE, V0, PP4555, DOI 10.1109/CVPR.2016.493
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang L, 2019, IEEE I CONF COMP VIS, V0, PP4633, DOI 10.1109/ICCV.2019.00473
   Hudson DA, 2019, PROC CVPR IEEE, V0, PP6693, DOI 10.1109/CVPR.2019.00686
   Jiao X, 2020, FINDINGS ASS COMPUTA, V0, PP4163, DOI 10.18653/v1/2020.findings-emnlp.372
   Johnson J, 2017, PROC CVPR IEEE, V0, PP1988, DOI 10.1109/CVPR.2017.215
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, V0, PP787, DOI 10.3115/V1/D14-1086
   Kim JH, 2018, ADV NEUR IN, V31, P0
   Kim Jin-Hwa, 2016, ARXIV161004325, V0, P0, DOI DOI 10.48550/arXiv.1610.04325
   Kingma DP, 2014, C TRACK P, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V0, P0
   Li Gen, 2019, ARXIV190806066, V0, P2
   Li G, 2019, IEEE I CONF COMP VIS, V0, PP8927, DOI 10.1109/ICCV.2019.00902
   Li Liunian Harold, 2019, ARXIV190803557, V0, P0
   Li Y, 2021, ARXIV210712292, V0, P0
   Li YA, 2021, AAAI CONF ARTIF INTE, V35, P8518
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Liu DQ, 2019, IEEE I CONF COMP VIS, V0, PP4672, DOI 10.1109/ICCV.2019.00477
   Liu JY, 2017, IEEE I CONF COMP VIS, V0, PP4866, DOI 10.1109/ICCV.2017.520
   Liu SQ, 2017, IEEE I CONF COMP VIS, V0, PP873, DOI 10.1109/ICCV.2017.100
   Liu XH, 2018, LECT NOTES COMPUT SC, V11219, P353, DOI 10.1007/978-3-030-01267-0_21
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP9992, DOI 10.1109/ICCV48922.2021.00986
   Lu J, 2019, ARXIV191202315, V0, P0
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Ma Ningning, 2018, P EUR C COMP VIS ECC, V0, PP116, DOI 10.1007/978-3-030-01264-9_8
   Ma XD, 2019, ADV NEUR IN, V32, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Perez E, 2018, PROC AAAI C ARTIF IN, V32, P0
   Qin Y, 2019, PROC CVPR IEEE, V0, PP8359, DOI 10.1109/CVPR.2019.00856
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Santoro A, 2017, P ADV NEUR INF PROC, V0, P4967
   Shen S, 2019, ARXIV190905840, V0, P0
   So DR, 2019, PR MACH LEARN RES, V97, P0
   Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710
   Sukhbaatar Sainbayar, 2019, ARXIV190507799, V0, P0
   Szegedy C, 2017, PROC 31 AAAI C ARTIF, V31, P0
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5100
   Tao D, 2020, ARXIV200412070, V0, P0
   Tian James Yi, 2019, ARXIV191206638, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Wang Sinong, 2020, ARXIV200604768, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yao T, 2019, IEEE I CONF COMP VIS, V0, PP2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yingwei Pan, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10968, DOI 10.1109/CVPR42600.2020.01098
   Yu LC, 2018, PROC CVPR IEEE, V0, PP1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2017, PROC CVPR IEEE, V0, PP3521, DOI 10.1109/CVPR.2017.375
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1114
   Yu Z, 2019, PROC CVPR IEEE, V0, PP6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, V0, PP1839, DOI 10.1109/ICCV.2017.202
   Yu Zhou, 2019, ARXIV190804107, V0, P0
   Yun S, 2019, IEEE I CONF COMP VIS, V0, PP6022, DOI 10.1109/ICCV.2019.00612
   Zafrir Ofir, 2019, 2019 FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS), V0, PP36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zhang Hongyi, 2017, ABS171009412 CORR, V0, P0
   Zhang X, 2018, PROC CVPR IEEE, V0, PP6848, DOI 10.1109/CVPR.2018.00716
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou L, 2019, ARXIV190911059, V0, P0
NR 99
TC 8
Z9 8
U1 27
U2 90
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PD JUN 15
PY 2022
VL 31
IS 
BP 3386
EP 3398
DI 10.1109/TIP.2021.3139234
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1D4ZT
UT WOS:000793811000006
PM 35471883
DA 2023-11-10
ER

PT J
AU Dziri, N
   Rashkin, H
   Linzen, T
   Reitter, D
AF Dziri, Nouha
   Rashkin, Hannah
   Linzen, Tal
   Reitter, David
TI Evaluating Attribution in Dialogue Systems: The BEGIN Benchmark
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Knowledge-grounded dialogue systems powered by large language models often generate responses that, while fluent, are not attributable to a relevant source of information. Progress towards models that do not exhibit this issue requires evaluation metrics that can quantify its prevalence. To this end, we introduce the Benchmark for Evaluation of Grounded INteraction (BEGIN), comprising 12k dialogue turns generated by neural dialogue systems trained on three knowledge-grounded dialogue corpora. We collect human annotations assessing the extent to which the models' responses can be attributed to the given background information. We then use BEGIN to analyze eight evaluation metrics. We find that these metrics rely on spurious correlations, do not reliably distinguish attributable abstractive responses from unattributable ones, and perform substantially worse when the knowledge source is longer. Our findings underscore the need for more sophisticated and robust evaluation metrics for knowledge-grounded dialogue.
C1 [Dziri, Nouha] Univ Alberta, Edmonton, AB, Canada.
   [Rashkin, Hannah; Linzen, Tal; Reitter, David] Google Res, Mountain View, CA USA.
   [Linzen, Tal] NYU, New York, NY USA.
C3 University of Alberta; Google Incorporated; New York University
RP Dziri, N (通讯作者)，Univ Alberta, Edmonton, AB, Canada.
EM dziri@cs.ualberta.ca; hrashkin@google.com; linzen@google.com; reitter@google.com
CR Adiwardana D, 2020, ARXIV, V0, P0
   Amy Pu, 2021, P 2021 C EMPIRICAL M, V0, PP751, DOI 10.18653/v1/2021.emnlp-main.58
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bhandari M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9347
   Bunt H, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P549
   Cao Z, 2018, P AAAI C ARTIFICIAL, V32, P0, DOI 10.1609/AAAI.V32I1.11912
   Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2174
   Dan Bender, 2014, ERG SEMANTIC DOCUMEN, V0, P0
   Dhingra B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4884
   Dinan Emily, 2019, 7 INT C LEARNING REP, V0, P0
   Durmus E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1443
   Durmus Esin, 2020, P 58 ANN M ASS COMP, V0, PP5055, DOI 10.18653/v1/2020.acl-main.454
   Dziri N, 2022, ARXIV, V0, P0
   Dziri N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P2197
   Dziri N, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3806
   Dziri Nouha, 2022, CORR ARXIV PREPRINT, V0, P0
   Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373
   Falke T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2214
   Freitag M, 2021, T ASSOC COMPUT LING, V9, P1460, DOI 10.1162/tacl_a_00437
   Gabriel Saadia, 2021, FINDINGS ASS COMPUTA, V0, PP478, DOI 10.18653/V1/2021.FINDINGS-ACL.42
   Gehrmann S, 2022, ARXIV, V0, P0
   Gehrmann S, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, V0, P0
   Gopalakrishnan K, 2019, INTERSPEECH, V0, PP1891, DOI 10.21437/Interspeech.2019-3079
   Grice, 1989, STUDIES WAY WORDS, V0, P0
   Grusky Max, 2018, P 2018 C N AM CHAPT, V1, P708, DOI 10.18653/V1/N18-1065
   Gupta P, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3785
   He Pengcheng, 2020, ARXIV200603654, V0, P0
   Jovanovic M, 2021, IEEE INTERNET COMPUT, V25, P44, DOI 10.1109/MIC.2020.3037151
   Kang D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P718
   Kingma DP, 2014, C TRACK P, V0, P0
   Kochmar E, 2022, INT J ARTIF INTELL E, V32, P323, DOI 10.1007/s40593-021-00267-x
   Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9332
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li J, 2016, P 2016 C N AM CHAPT, V0, PP110, DOI 10.18653/v1/n16-1014
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, P0, DOI DOI 10.2307/3105454
   Liu YH, 2019, ARXIV, V0, P0
   Mathur Nitika, 2020, P 58 ANN M ASS COMP, V0, P0, DOI DOI 10.18653/v1/2020.acl-main.448
   Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1906
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Min J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2339
   Montani Ines, 2023, ZENODO, V0, P0
   Nan F, 2021, P 59 ANN M ASS COMPU, V1, P6881
   Or Honovich, 2021, P 2021 C EMPIRICAL M, V0, PP7856, DOI 10.18653/v1/2021.emnlp-main.619
   Pagnoni A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P4812
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Prabhumoye S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P4274
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rashkin H, 2022, ARXIV, V0, P0
   Rashkin H, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P704
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P300
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Sellam Thibault, 2020, P 58 ANN M ASS COMPU, V0, PP7881, DOI 10.18653/V1/2020.ACL-MAIN.704
   Keskar NS, 2019, ARXIV, V0, P0
   Shuster K, 2021, FIND ASS COMP LING E, V0, PP3784, DOI 10.18653/V1/2021.FINDINGSEMNLP.320
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stiles WB, 1992, DESCRIBING TALK TAXO, V0, P0
   Tian R, 2020, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Alex, 2020, P 58 ANN M ASS COMP, V0, PP5008, DOI 10.18653/V1/2020.ACL-MAIN.450
   Welleck S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3731
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Wolf T, 2019, TRANSFERTRANSFO TRAN, V0, P0
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yang Shanshan, 2019, P 2019 3 INT C ED E, V0, PP79, DOI 10.1145/3371647.3371659
   Yeh Y-T, 2021, 1 WORKSHOP EVALUATIO, V0, P15
   Yuan W, 2021, ADV NEURAL INFORM PR, V0, P27263
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang Tianyi, 2020, ICLR, V0, P0
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
   Zhou Kangyan, 2018, 2018 C EMPIRICAL MET, V0, PP708, DOI 10.18653/v1/D18-1076
NR 74
TC 1
Z9 1
U1 5
U2 6
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD SEP 19
PY 2022
VL 10
IS 
BP 1066
EP 1083
DI 10.1162/tacl_a_00506
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9OO
UT WOS:000923422400005
DA 2023-11-10
ER

PT J
AU Do, P
   Le, H
   Pham, AB
   Nguyen, CH
AF Phuc Do
   Hung Le
   Pham, An B.
   Nguyen, Cuong H.
TI Using BERT and Knowledge Graph for detecting triples in Vietnamese text
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Natural Language Processing; BERT; Knowledge Graph; Contextual understanding; Triple classification
AB One of the challenges in constructing Knowledge Graphs from text is verifying the correctness of the produced results. Each language has its unique characteristics, so a Knowledge Graphs construction system may perform better on certain languages and worse on others. In order to detect the most suitable Knowledge Graph construction systems for Vietnamese, in this paper, we propose a method to classify triples extracted from such systems into two categories: Existent and Non-existent. Vietnamese is a low-resource language with limited natural language processing tools and datasets. By combining BERT with a self-constructed Vietnamese Knowledge Graph, we build a classification model to verify the existence of triples in paragraphs. Our results suggest that BERT can learn contextual relations between words from a large amount of text, even for a low-resource language like Vietnamese. BERT's adaptive capability to detect meaningful triples is also shown and discussed. The outcome of this paper could potentially be used to build more sophisticated systems to solve Knowledge Graph construction and Triple Classification tasks in low resource languages.
C1 [Phuc Do; Hung Le; Pham, An B.; Nguyen, Cuong H.] Vietnam Natl Univ Ho Chi Minh City, Univ Informat Technol, Quarter 6, Ho Chi Minh City, Vietnam.
   [Hung Le] Japan Adv Inst Sci & Technol, Human Informat Sci, 1-1 Asahidai, Nomi, Ishikawa 9231292, Japan.
C3 Vietnam National University Hochiminh City; Japan Advanced Institute of Science & Technology (JAIST)
RP Do, P (通讯作者)，Vietnam Natl Univ Ho Chi Minh City, Univ Informat Technol, Quarter 6, Ho Chi Minh City, Vietnam.
EM phucdo@uit.edu.vn; 15520283@gm.uit.edu.vn; 16520016@gm.uit.edu.vn; 16520148@gm.uit.edu.vn
FU Vietnam National University Ho Chi Minh City (VNU-HCMC) [DS2020-26-01]
CR Amazon, 2019, COMPUTATION LANGUAGE, V0, P0
   An Bo, 2018, P 2018 C N AM CHAPT, V0, P0
   Chen DG, 2021, COMPUT INTEL NEUROSC, V2021, P0, DOI 10.1155/2021/8810366
   Clark Kevin, 2020, ICLR, V0, P0
   Nguyen DQ, 2019, SEMANT WEB, V10, P947, DOI 10.3233/SW-180318
   Dettmers T, 2018, AAAI CONF ARTIF INTE, V0, P1811
   Devlin J, 2018, ARXIV, V1, P4171
   Do P, 2021, COMPUTATIONAL SCI TE, V0, P0, DOI DOI 10.1007/978-981-33-4069-5_1
   Do P, 2022, NEURAL COMPUT APPL, V34, P8393, DOI 10.1007/s00521-020-05495-1
   Phuc D, 2019, J INTELL FUZZY SYST, V37, P7555, DOI 10.3233/JIFS-179362
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Ji GL, 2016, AAAI CONF ARTIF INTE, V0, P985
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, V0, PP55, DOI 10.3115/v1/p14-5010
   Nguyen DQ, 2020, PHOBERT PRETRAINED L, V0, P0
   QIN XL, 2017, P IEEE C COMP VIS PA, V0, P1
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rumelhart D, 1986, PARALLEL DISTRIBUTED, V1, P0
   Socher, 2017, ARXIV161101576, V0, P0
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Ho T, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), V0, PP268, DOI 10.1109/KSE.2015.54
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang H, 2020, ARXIV181100147, V0, P0
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang Z, 2016, P 25 INT JOINT C ART, V0, P4
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI, V0, P0
   Xiao H, 2015, TRANSG GENERATIVE MI, V0, P0
   Yao Liang, 2019, ABS190903193 CORR, V0, P0
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
NR 29
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD OCT 15
PY 2022
VL 34
IS 20
BP 17999
EP 18013
DI 10.1007/s00521-022-07439-3
EA JUN 2022
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4W2BD
UT WOS:000807908300002
DA 2023-11-10
ER

PT J
AU Haneef, F
   Sindhu, MA
AF Haneef, Farah
   Sindhu, Muddassar A.
TI DLIQ: A Deterministic Finite Automaton Learning Algorithm through Inverse Queries
SO INFORMATION TECHNOLOGY AND CONTROL
LA English
DT Article
DE Automaton learning; complete learning algorithm; delta inverse transitions; inverse query; live completeset; distinguishing string
AB Automaton learning has attained a renewed interest in many interesting areas of software engineering including formal verification, software testing and model inference. An automaton learning algorithm typically learns the regular language of a Deterministic Finite Automaton (DFA) with the help of queries. These queries are posed by the learner (Learning Algorithm) to a Minimally Adequate Teacher ( MAT). The MAT can generally answer two types of queries asked by the learning algorithm; membership queries and equivalence queries. Learning algorithms can be categorized into three broad categories: incremental, sequential and complete learning algorithms. Likewise, these can be designed for 1-bit learning or k-bit learning. Existing automaton learning algorithms have polynomial (at-least cubic) time complexity in the presence of a MAT. Therefore, sometimes these algorithms are unable to learn large complex software systems. In this research work, we have reduced the time complexity of the DFA learning into lower bounds (from cubic to square form). For this, we introduce an efficient complete DFA learning algorithm through Inverse Queries (DLIQ) based on the concept of inverse queries introduced by John Hopcroft for state minimization of a DFA. The DLIQ algorithm takes O(vertical bar P-s vertical bar vertical bar F vertical bar + vertical bar Sigma vertical bar N) complexity in the presence of a MAT which is also equipped to answer inverse queries. We give a theoretical analysis of the proposed algorithm along with providing an empirical analysis of DLIQ and ID (Identification of regular languages) algorithms. For this, we implement an evaluation framework. Results depict that in terms of time complexity our proposed algorithm DLIQ is more efficient than the ID algorithm.
C1 [Haneef, Farah; Sindhu, Muddassar A.] Quaid I Azam Univ, Dept Comp Sci, Islamabad 45320, Pakistan.
C3 Quaid I Azam University
RP Haneef, F (通讯作者)，Quaid I Azam Univ, Dept Comp Sci, Islamabad 45320, Pakistan.
EM farah@cs.qau.edu.pk
FU Higher Education Commission of Pakistan (HEC) [9223/Federal/NRPU/RD/HEC/2017]
CR ANGLUIN D, 1981, INFORM CONTROL, V51, P76, DOI 10.1016/S0019-9958(81)90090-5
   ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6
   Angluin D, 2015, LECT NOTES ARTIF INT, V9355, P119, DOI 10.1007/978-3-319-24486-0_8
   [Anonymous], 1994, INTRO COMPUTATIONAL, V0, P0
   Berg T, 2005, ELECTRON NOTES THEOR, V118, P3, DOI 10.1016/j.entcs.2004.12.015
   Boehm BW, 1978, RES DIRECTIONS SOFTW, V0, P0
   Cassel S, 2016, FORM ASP COMPUT, V28, P233, DOI 10.1007/s00165-016-0355-5
   CLEAVELAND R, 1990, LECT NOTES COMPUT SC, V407, P24
   Cleaveland R, 1989, P 9 IFIP S PROTOCOL, V0, P0
   Cleaveland R, 1988, 10 U ED LAB FDN COMP, V0, P0
   Dupont P, 1996, GRAMMATICAL INFERENCE: LEARNING SYNTAX FROM SENTENCES. THIRD INTERNATIONAL COLLOQUIUM, V0, P222, DOI 10.1007/BFb0033357
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Groce A, 2006, LOG J IGPL, V14, P729, DOI 10.1093/jigpal/jzl007
   Hessel Anders, 2008, FORMAL METHODS AND TESTING. AN OUTCOME OF THE FORTEST NETWORK. REVISED SELECTED PAPERS, V0, PP77, DOI 10.1007/978-3-540-78917-8_3
   Hopcroft John, 1971, THEORY MACHINES COMP, V0, PP189, DOI 10.1016/B978-0-12-417750-5.50022-1
   Isberner M, 2014, LECT NOTES COMPUT SC, V8734, P307, DOI 10.1007/978-3-319-11164-3_26
   Mathur HM, 2013, DISPLACEMENT RESETTL, V0, P0
   Mazhar R, 2021, ACTA INFORM, V58, P611, DOI 10.1007/s00236-020-00387-2
   Meinke K, 2010, CORRECTNESS PERFORMA, V0, P0
   Meinke K, 2011, LECT NOTES COMPUT SC, V6706, P134, DOI 10.1007/978-3-642-21768-5_11
   Michaliszyn J, 2022, ARTIF INTELL, V307, P0, DOI 10.1016/j.artint.2022.103710
   Michaliszyn J, 2020, FRONT ARTIF INTEL AP, V325, P2370, DOI 10.3233/FAIA200367
   Oncina, 1992, ADV STRUCTURAL SYNTA, V5, P99, DOI 10.1142/9789812797919_0007
   Parekh R, 1998, GRAMMATICAL INFERENCE. 4TH INTERNATIONAL COLLOQUIUM, V0, P37, DOI 10.1007/BFb0054062
   Parrow J, 1987, P 7 IFIP S PROTOCOL, V0, P0
   Peled D, 1999, INT FED INFO PROC, V28, P225
   Pellegrino G, 2017, INT C GRAMMATICAL IN, V0, P120
   Petrenko A, 2019, SOFTWARE QUAL J, V27, P651, DOI 10.1007/s11219-018-9429-3
   Seijas PL, 2018, SOFTWARE QUAL J, V26, P1519, DOI 10.1007/s11219-017-9399-x
   Sheinvald S, 2019, INT S FORM METH, V0, PP633, DOI 10.1007/978-3-030-30942-8_37
   Smetsers R, 2014, INT C GRAMMATICAL IN, V0, P167
   Smetsers R, 2018, LECT NOTES COMPUT SC, V10792, P182, DOI 10.1007/978-3-319-77313-1_14
   Vaandrager F, 2017, COMMUN ACM, V60, P85, DOI 10.1145/2967606
   Walker D, 1988, ECSLFCS8845 U ED, V0, P0
NR 34
TC 1
Z9 1
U1 0
U2 0
PU KAUNAS UNIV TECHNOLOGY
PI KAUNAS
PA KAUNAS UNIV TECHNOL, DEPT ELECTRONICS ENGINEERING, STUDENTU STR 50, KAUNAS, LT-51368, LITHUANIA
SN 1392-124X
EI 
J9 INF TECHNOL CONTROL
JI Inf. Technol. Control
PD JUN 15
PY 2022
VL 51
IS 4
BP 611
EP 624
DI 10.5755/j01.itc.51.4.31394
PG 14
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Automation & Control Systems; Computer Science
GA E6HC6
UT WOS:000976520600001
DA 2023-11-10
ER

PT J
AU Drury, B
   Oliveira, HG
   Lopes, AD
AF Drury, Brett
   Oliveira, Hugo Goncalo
   Lopes, Alneu de Andrade
TI A survey of the extraction and applications of causal relations
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article
DE Causal relations; Survey; Sentiment; Event prediction; Information retrieval; Cause identification
ID knowledge; text; information; corpus
AB Causationin written natural language can express a strong relationship between events and facts. Causation in the written form can be referred to as a causal relation where a cause event entails the occurrence of an effect event. A cause and effect relationship is stronger than a correlation between events, and therefore aggregated causal relations extracted from large corpora can be used in numerous applications such as question-answering and summarisation to produce superior results than traditional approaches. Techniques like logical consequence allow causal relations to be used in niche practical applications such as event prediction which is useful for diverse domains such as security and finance. Until recently, the use of causal relations was a relatively unpopular technique because the causal relation extraction techniques were problematic, and the relations returned were incomplete, error prone or simplistic. The recent adoption of language models and improved relation extractors for natural language such as Transformer-XL (Dai et al. (2019). Transformer-xl: Attentive language models beyond a fixed-length context. arXiv preprint arXiv:1901.02860) has seen a surge of research interest in the possibilities of using causal relations in practical applications. Until now, there has not been an extensive survey of the practical applications of causal relations; therefore, this survey is intended precisely to demonstrate the potential of causal relations. It is a comprehensive survey of the work on the extraction of causal relations and their applications, while also discussing the nature of causation and its representation in text.
C1 [Drury, Brett] LIAAD INESC Tec, R Dr Roberto Frias, Porto, Portugal.
   [Oliveira, Hugo Goncalo] Univ Coimbra, Dept Informat Engn, CISUC, Coimbra, Portugal.
   [Lopes, Alneu de Andrade] Univ Sao Paulo, ICMC, Av Trab Sao Carlense, Sao Paulo, Brazil.
C3 Universidade do Porto; INESC TEC; Universidade de Coimbra; Universidade de Sao Paulo
RP Drury, B (通讯作者)，LIAAD INESC Tec, R Dr Roberto Frias, Porto, Portugal.
EM brett.drury@gmail.com
FU State of Sao Paulo Research Foundation (FAPESP), Brazil; national funds through FCT [UID/CEC/00326/2020]; European Social Fund; Brazilian National Council for Scientific and Technological Development (CNPq) [304040/2019-3]
CR Abinesh S, 2017, THESIS NUIG GALWAY I, V0, P0
   Ackerman EJM, 2013, THESIS TU DRESDEN, V0, P0
   Adams FC, 2008, J COSMOL ASTROPART P, V0, P0, DOI DOI 10.1088/1475-7516/2008/08/010
   Agueda CP, 2010, THESIS U PONTIFICIA, V0, P0
   Akbik A, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P54
   Akl HA, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Aliseda A, 2006, SYNTH LIBR, V330, P0
   ALTENBERG B, 1984, STUD LINGUISTICA, V38, P20, DOI 10.1111/j.1467-9582.1984.tb00734.x
   [Anonymous], 2012, INT J INNOVATIVE RES, V0, P0
   [Anonymous], 2013, CAUSATION USERS GUID, V0, P0
   [Anonymous], 2008, LEX RES EV C, V0, P0
   [Anonymous], 2011, P FLAIRS C, V0, P0
   [Anonymous], 2005, MAKING THINGS HAPPEN, V0, P0
   [Anonymous], 2013, 2 JOINT C LEXICAL CO, V0, P0, DOI DOI 10.1017/S1351324914000060
   Bakal G, 2018, J BIOMED INFORM, V82, P189, DOI 10.1016/j.jbi.2018.05.003
   Barik B, 2017, EXTRACTING CAUSAL RE, V0, P131
   BARROW JD, 1980, SCI AM, V242, P118, DOI 10.1038/scientificamerican0480-118
   Beebee H, 2015, OXFORD HDB CAUSATION, V0, P0
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bhaskoro SB, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY SYSTEMS AND INNOVATION (ICITSI), V0, P0
   Blanco E, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P310
   Bui QC, 2010, BMC BIOINFORMATICS, V11, P0, DOI 10.1186/1471-2105-11-101
   Cao MY, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0199303
   Cao MY, 2016, INT CONF SEMANT, V0, PP32, DOI 10.1109/SKG.2016.34
   Cao YN, 2014, PROCEDIA COMPUT SCI, V29, P478, DOI 10.1016/j.procs.2014.05.043
   Cao YN, 2012, INFORMATION-TOKYO, V15, P427
   Cao YN, 2015, LECT NOTES ARTIF INT, V9403, P588, DOI 10.1007/978-3-319-25159-2_53
   Casati R, 2020, STANFORD ENCY PHILOS, V2020, P0
   Caselli T, 2017, P EV STOR NEWS WORKS, V0, PP77, DOI 10.18653/V1/W17-2711
   Chan K, 2005, INT J INTELL SYST, V20, P327, DOI 10.1002/int.20069
   Chen, 2017, P 2017 C EMP METH NA, V0, PP2758, DOI 10.18653/V1/D17-1292
   Chen YL, 2020, ADV SOC SCI EDUC HUM, V471, P198
   Chen Ying, 2010, P CCF INT C NAT LANG, V0, P179
   Cole SV, 2006, PROCEEDINGS OF THE IEEE SOUTHEASTCON 2006, V0, PP125, DOI 10.1109/second.2006.1629336
   Collins J, 2004, CAUSATION COUNTERFAC, V0, PP1, DOI 10.7551/MITPRESS/1752.001.0001
   Copley B, 2015, CAUSATION GRAMMATICA, V1, P0
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Danescu-Niculescu-Mizil C, 2011, P WORKSH COGN MOD CO, V0, P0
   Dasgupta T, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), V0, P306
   Datta S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP1689, DOI 10.1145/3397271.3401207
   Datta S, 2020, ACM INT CONF PR SER, V0, PP14, DOI 10.1145/3441501.3441513
   Degand L, 2000, J PRAGMATICS, V32, P687, DOI 10.1016/S0378-2166(99)00066-1
   Degand L, 1994, P 7 INT WORKSH NAT L, V0, P108
   Dehkharghani R, 2014, EXPERT SYST APPL, V41, P4950, DOI 10.1016/j.eswa.2014.02.024
   Devlin J, 2018, ARXIV, V1, P4171
   Ding X, 2014, P 2014 C EMP METH NA, V0, P1415
   Do QX, 2011, P C EMPIRICAL METHOD, V0, P294
   Drury B, 2015, OSLO STUDIES LANGUAG, V7, P379
   Drury B, 2016, P 20 INT DAT ENG APP, V0, P364
   Dunietz J, 2015, P LAWIX 9 LING ANN W, V0, P188
   Dunietz J, 2017, P 11 LING ANN WORKSH, V0, PP95, DOI 10.18653/V1/W17-0812
   Eisenschlos J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5702
   Fajcik Martin, 2020, ARXIV PREPRINT ARXIV, V0, P437
   Girju R, 2003, P ACL 2003 WORKSH MU, V12, P76, DOI 10.3115/1119312.1119322
   Girju R, 2002, AAAI S, V0, P0
   Gordon A, 2012, SEM 2012, V1, P394
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Grivaz C, 2012, AUTOMATIC EXTRACTION, V0, P0
   Gui L, 2016, COMM COM INF SC, V669, P98, DOI 10.1007/978-981-10-2993-6_8
   Gui Lin, 2014, P CCF INT C NAT LANG, V0, PP457, DOI 10.1007/978-3-662-45924-9_
   Hashimoto C, 2015, AAAI CONF ARTIF INTE, V0, P2396
   Hashimoto C, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P987
   Hassanzadeh O, 2020, AAAI CONF ARTIF INTE, V34, P13610
   Hendrickx I, 2009, P WORKSH SEM EV REC, V0, PP94, DOI 10.3115/1621969.1621986
   Hidey C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1424
   Higashinaka R, 2008, ACM T ASIAN LANGUAGE, V7, P1, DOI 10.1145/1362782.1362785
   Higashinaka R, 2008, P INT JOINT C NAT LA, VI, P418
   HITCHCOCK CR, 1995, PHILOS STUD, V78, P257, DOI 10.1007/BF00990114
   Hu Z, 2017, P EVENTS STORIES NEW, V0, P52
   Ishii H, 2010, P ANN HICSS, V0, P1536
   Ittoo A, 2011, LECT NOTES COMPUT SC, V6716, P52, DOI 10.1007/978-3-642-22327-3_6
   Izumi K, 2019, P 1 WORKSH FIN TECHN, V0, P61
   Jastrzebski S, 2017, ABS170202170 CORR, V0, P0
   Jensen FV, 2007, BAYESIAN NETWORKS DE, V0, P0
   Jin X, 1900, P739, V0, P0
   Joskowicz L, 1989, PROCEEDINGS OF THE ANNUAL AI SYSTEMS IN GOVERNMENT CONFERENCE (IEEE CAT. NO.89CH2715-1), V0, PP195, DOI 10.1109/AISIG.1989.47325
   Kaneko K, 2014, P 28 PAC AS C LANG I, V0, P460
   Kaneko K, 2014, P EACL 2014 WORKSH C, V0, P33
   Khoo C, 2002, INFO SCI KNOW MANAGE, V3, P51
   Khoo CS-G, 1996, THESIS SYRACUSE U, V0, P0
   Khoo CSG, 2001, INFORM PROCESS MANAG, V37, P119, DOI 10.1016/S0306-4573(00)00022-4
   Kilicoglu H, 2016, P 15 WORKSH BIOM NAT, V0, P46
   Kim HD, 2012, P 21 ACM INT C INF K, V0, P2689
   Kim HD, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, PP885, DOI 10.1145/2505515.2505612
   Kolomiyets O, 2011, INFORM SCIENCES, V181, P5412, DOI 10.1016/j.ins.2011.07.047
   Krishnan A, 2014, IEEE INT C BIOINF BI, V0, PP226, DOI 10.1109/BIBE.2014.44
   Kumar S, 2017, SURVEY DEEP LEARNING, V0, P0
   Kunneman FA, 2012, 24 BEN C ART INT MAA, V0, P0
   Kyriakakis M, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), V0, P292
   Lee SYM, 2013, COMPUT INTELL-US, V29, P390, DOI 10.1111/j.1467-8640.2012.00459.x
   Lee Sophia Yat Mei, 2010, P NAACL HLT 2010 WOR, V0, P45
   Levin B, 1986, NEW YORK TIMES, V8, P0
   Levin Beth, 1993, ENGLISH VERB CLASSES, V0, P0
   Li WY, 2014, EXPERT SYST APPL, V41, P1742, DOI 10.1016/j.eswa.2013.08.073
   Li WJ, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Li ZN, 2021, NEUROCOMPUTING, V423, P207, DOI 10.1016/j.neucom.2020.08.078
   Li ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4201
   Li ZH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5708
   Liu J, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3608
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4487
   Lorenz G, 1999, PRAG BEYOND NEW SER, V63, P55
   Luo ZY, 2016, FIFTEENTH INTERNATIONAL CONFERENCE ON THE PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, V0, P421
   MACKIE JL, 1965, AM PHILOS QUART, V2, P245
   Mackie John, 1974, CEMENT UNIVERSE STUD, V0, P0
   Maekawa K, 2014, LANG RESOUR EVAL, V48, P345, DOI 10.1007/s10579-013-9261-0
   Marcu D, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P368
   Mariko D, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Medsker L, 1999, RECURRENT NEURAL NET, V0, P0, DOI DOI 10.1201/9781003040620
   Mehrabi S, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 1, P339, DOI 10.1109/ICMLA.2013.69
   Mellor D, 1998, INT LIB PHILOS PSYCH, V0, P0
   Mihaila C, 2013, ACL STUD RES WORKSH, V0, P38
   Mihaila C, 2014, BIOMED ENG ONLINE, V13, P0, DOI 10.1186/1475-925X-13-S2-S1
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P52
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Miranda A, 2012, MOVE MEANINGFUL INTE, V0, P33
   Mirza P, 1900, P64, V0, P0
   Mirza P, 2016, ARXIV PREPRINT ARXIV, V0, P0
   Mirza P, 2014, P COLING 2014, V0, P2097
   Mirza P, 2014, 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: STUDENT RESEARCH WORKSHOP (ACL 2014), V0, P10
   Mostafazadeh N, 2016, P 4 WORKSH EV, V0, PP51, DOI 10.18653/V1/W16-1007
   Mou Lili, 2016, P 2016 C EMP METH NA, V0, PP479, DOI 10.18653/V1/D16-1046
   Mulkar-Mehta R, 2011, FLAIRS C, V0, P0
   Mulkar-Mehta R, 2011, 6 INT C KNOWL CAPT B, V0, P0
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, V0, P1
   Neeleman Ad, 2012, THETA SYSTEM ARGUMEN, V0, PP20, DOI 10.1093/acprof:oso/9780199602513.003.0002
   Ning Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2278
   Nwaike K, 2020, ARXIV PREPRINT ARXIV, V0, P0
   OGorman Tim, 2016, P 2 WORKSH COMP NEWS, V0, PP47, DOI 10.18653/V1/W16-5706
   Oh JH, 2013, P 51 ANN M ASS COMPU, V0, P1733
   Ojha AA, 2020, LITK RSA SEMEVAL 202, V0, P0
   Onyshkevych B, 1993, P 5 C MESS UND ASS C, V0, P19
   Ovchinnikova E, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   Ovchinnikova E, 2014, TEXT SPEECH LANG TEC, V47, P107, DOI 10.1007/978-94-007-7284-7_7
   Page L, 1999, PAGERANK CITATION RA, VVolume 8090, P422
   Palmer M, 2017, OXFORD HDB COGNITIVE, V0, PP315, DOI 10.1093/oxfordhb/9780199842193.013.15.
   Papanikolaou Yannis, 2019, P 2 WORKSHOP DEEP LE, V0, P67
   Pearl J, 2018, THE BOOK OF WHY, V0, P0
   Pearl J, 2012, P 28 C UNCERTAINTY A, V0, P3
   Pechsiri C, 2007, IEICE T INF SYST, VE90D, P1523, DOI 10.1093/ietisy/e90-d.10.1523
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/V1/D14-1162
   Pichotta K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P279
   Ponti EM, 2017, P 2 WORKSH LINK MOD, V0, P25
   Preethi PG, 2015, PROCEDIA COMPUT SCI, V48, P84, DOI 10.1016/j.procs.2015.04.154
   Psillos S, 2007, BOST STUD PHILOS HIS, V252, P93
   Puente C, 2017, IEEE INT CONF FUZZY, V0, P0
   Puente C, 2017, J APPL LOGIC, V24, P3, DOI 10.1016/j.jal.2016.11.020
   Puente C, 2013, PROCEEDINGS OF THE 2013 JOINT IFSA WORLD CONGRESS AND NAFIPS ANNUAL MEETING (IFSA/NAFIPS), V0, PP513, DOI 10.1109/IFSA-NAFIPS.2013.6608453
   Puente C, 2013, FLEXIBLE QUERY ANSWERING SYSTEMS. 10TH INTERNATIONAL CONFERENCE, V0, P91, DOI 10.1007/978-3-642-40769-7_8
   Puente C, 2014, P INT C ART INT ICAI, V1, P0
   Qiu JN, 2017, PROCEDIA COMPUT SCI, V112, P1623, DOI 10.1016/j.procs.2017.08.252
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Radinsky K, 2013, P 6 ACM INT C WEB SE, V0, PP255, DOI 10.1145/2433396.2433431
   Radinsky Kira, 2012, P 21 INT C WORLD WID, V0, PP909, DOI 10.1145/2187836.2187958
   Riaz M, 2014, EACL 2014 WORKSHOP C, V0, P48
   Riaz M, 2010, THESIS U ILLINOIS, V0, P0
   Riaz M, 2010, IEEE INT C SEMANT CO, V0, PP361, DOI 10.1109/ICSC.2010.19
   Rotmensch M, 2017, SCI REP-UK, V7, P0, DOI 10.1038/s41598-017-05778-z
   Russell S, 2003, ARTIF INTELL, Vsecond, P0
   Sadek Jawad, 2013, NATURAL LANGUAGE PROCESSING AND INFORMATION SYSTEMS. 18TH INTERNATIONAL CONFERENCE ON APPLICATIONS OF NATURAL LANGUAGE TO INFORMATION SYSTEMS, V0, P400, DOI 10.1007/978-3-642-38824-8_48
   Sakai H, 2007, INT FED INFO PROC, V0, P205
   Sakaji H, 2008, LECT NOTES ARTIF INT, V5012, P977, DOI 10.1007/978-3-540-68125-0_102
   Sakaji H, 2008, LECT NOTES ARTIF INT, V5345, P111, DOI 10.1007/978-3-540-89447-6_12
   Sanchez-Graillet O, 2004, P 4 INT C LANG RES E, V0, P0
   Sastre J, 2020, IEEE INT C BIOINFORM, V0, PP2513, DOI 10.1109/BIBM49941.2020.9313350
   Schuler Karin Kipper, 2005, THESIS, V0, P0
   Shapiro SC, 1992, ENCY ARTIFICIAL INTE, V2nd, P0
   Sharp Rebecca, 2016, P 2016 C EMPIRICAL M, V0, P138
   Sizov G, 2013, P TEXTGRAPHS 8 GRAPH, V0, P61
   Sogaard A, 2013, SEMISUPERVISED LEARN, V0, P0
   Son Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3350
   Son Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P654, DOI 10.18653/v1/P17-2103
   Spinoza Benedictus de, 1996, ETHICS, V0, P0
   Tran GB, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW13 COMPANION), V0, P343
   VanVactor JD, 2010, J HOMEL SECUR EMERG, V7, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   VENDLER Z, 1967, J PHILOS, V64, P704, DOI 10.2307/2023854
   Weber N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7583
   Wolf T, 2019, ARXIV, V0, P0
   Wu JL, 2012, BMC MED INFORM DECIS, V12, P0, DOI 10.1186/1472-6947-12-72
   Xinyu Zuo, 2020, CHINESE COMPUTATIONAL LINGUISTICS. 19TH CHINA NATIONAL CONFERENCE, V0, P113, DOI 10.1007/978-3-030-63031-7_9
   Xu RF, 2017, TSINGHUA SCI TECHNOL, V22, P646, DOI 10.23919/TST.2017.8195347
   Yang B, 2020, P C JAP SOC ART INT, V0, P0
   Yang Xiaoyu, 2020, P 14 WORKSH SEM EV B, V0, P322
   Yang YY, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2161, DOI 10.1145/3357384.3358156
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu B, 2020, P 28 INT C COMPUTATI, V0, PP4860, DOI 10.18653/V1/2020.COLING-MAIN.427
   Yu B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4664
   Yu HQ, 2020, P FUT TECHN C, V0, PP30, DOI 10.1007/978-3-030-63092-8_3
   Yu HQ, 2020, 2020 7TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS RESEARCH AND APPLICATIONS, V0, P49, DOI 10.1145/3440067.3440077
   Zhang YT, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16), V0, PP649, DOI 10.1145/2872427.2883013
   Zhang YT, 2016, ACM T INFORM SYST, V35, P0, DOI 10.1145/2937752
   Zhao SD, 2017, WSDM17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP335, DOI 10.1145/3018661.3018707
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zuo X, 2020, P INT C COMP LING, V0, P1544
NR 197
TC 1
Z9 1
U1 6
U2 34
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD MAY 15
PY 2022
VL 28
IS 3
BP 361
EP 400
DI 10.1017/S135132492100036X
EA JAN 2022
PG 40
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 0I9SZ
UT WOS:000744758700001
DA 2023-11-10
ER

PT J
AU He, XL
   Nassar, I
   Kiros, J
   Haffari, G
   Norouzi, M
AF He, Xuanli
   Nassar, Islam
   Kiros, Jamie
   Haffari, Gholamreza
   Norouzi, Mohammad
TI Generate, Annotate, and Learn: NLP with Synthetic Text
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB This paper studies the use of language models as a source of synthetic unlabeled text for NLP. We formulate a general framework called "generate, annotate, and learn (GAL)" to take advantage of synthetic text within knowledge distillation, self-training, and few-shot learning applications. To generate high-quality task-specific text, we either fine-tune LMs on inputs from the task of interest, or prompt large LMs with few examples. We use the best available classifier to annotate synthetic text with soft pseudo labels for knowledge distillation and self-training, and use LMs to obtain hard labels for few-shot learning. We train new supervised models on the combination of labeled and pseudo-labeled data, which results in significant gains across several applications. We investigate key components of GAL and present theoretical and empirical arguments against the use of class-conditional LMs to generate synthetic labeled text instead of unlabeled text. GAL achieves new state-of-the-art knowledge distillation results for 6-layer transformers on the GLUE leaderboard.
C1 [He, Xuanli; Nassar, Islam; Haffari, Gholamreza] Monash Univ, Melbourne, Australia.
   [Kiros, Jamie; Norouzi, Mohammad] Brain Team, Google Res, Toronto, ON, Canada.
C3 Monash University
RP He, XL (通讯作者)，Monash Univ, Melbourne, Australia.
EM xuanli.he1@monash.edu; gholamreza.haffari@monash.edu; mnorouzi@google.com
FU Multi-modal Australian ScienceS Imaging and Visualisation Environment (MASSIVE); Air Force Research Laboratory; DARPA [FA8750-19-2-0501]
CR Abney S, 2004, COMPUTATIONAL LINGUISTICS, V30, P365, DOI 10.1162/0891201041850876
   Adams Wei Yu, 2018, ICLR, V0, P0
   AGRAWALA AK, 1970, IEEE T INFORM THEORY, V16, P373, DOI 10.1109/TIT.1970.1054472
   Alberti C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6168
   [Anonymous], 2007, P 45 ANN M ASS COMPU, V0, P0
   Brown TB, 2020, ARXIV, V0, P0
   Bisk Y, 2020, AAAI CONF ARTIF INTE, V34, P7432
   Bucilua C, 2006, P 12 ACM SIGKDD INT, V0, PP535, DOI 10.1145/1150402.1150464
   Carmon Y, 2019, ADV NEUR IN, V32, P0
   Chapelle O, 2001, ADV NEUR IN, V13, P416
   Chen Ting, 2020, NEURIPS, V0, P2
   Chen Y, 2020, MOL INFORM, V39, P0, DOI 10.1002/minf.202000171
   Clark Kevin, 2020, ICLR, V0, P0
   Du JF, 2020, ARXIV, V0, P0
   Eisner Jason, 2005, P HUMAN LANGUAGE TEC, V0, PP395, DOI 10.3115/1220575.1220625
   Feng SY, 2021, FINDINGS ASS COMPUTA, V0, PP968, DOI 10.18653/V1/2021.FINDINGS-ACL.84
   FRALICK SC, 1967, IEEE T INFORM THEORY, V13, P57, DOI 10.1109/TIT.1967.1053952
   Furlanello T, 2018, INT C MACHINE LEARNI, V0, P1607
   Gao Leo, 2021, FRAMEWORK FEW SHOT L, V0, P0
   Gowal S, 2021, ADV NEURAL INFORM PR, V34, P0
   Guan J, 2020, T ASSOC COMPUT LING, V8, P93, DOI 10.1162/tacl_a_00302
   Haffari Gholamreza, 2007, UAI 2007 P 23 C UNCE, V0, P159
   He Pengcheng, 2020, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.2006.03654
   Hernandez Danny, 2021, SCALING LAWS TRANSFE, V0, P0
   Hinton G, 2015, ARXIV, V0, P0
   Jiao XQ, 2020, ARXIV, V0, P0
   Kim Yoon, 2016, ARXIV160607947, V0, P0, DOI DOI 10.18653/V1
   Kobayashi S, 2018, P 2018 C N AM CHAPTE, V2, P452, DOI 10.18653/v1/N18-2072
   Kumar A, 2020, PR MACH LEARN RES, V119, P0
   Kumar V, 2021, ARXIV, V0, P0
   Lichtarge J, 2019, ARXIV, V0, P0
   Liu YH, 2019, ARXIV, V0, P0
   Maruf S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1275
   Marzoev A, 2020, ARXIV, V0, P0
   Miculicich L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2947
   Mobahi Hossein, 2020, ADV NEURAL INFORM PR, V33, P0
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), V0, P314
   Norouzi S, 2020, ARXIV, V0, P0
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Orbach Eyal, 2020, P 28 INT C COMPUTATI, V0, P2329
   Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, V0, P48
   Oymak S, 2020, ARXIV, V0, P0
   Qizhe Xie, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10684, DOI 10.1109/CVPR42600.2020.01070
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Raghunathan A, 2020, INT C MACHINE LEARNI, V0, P7909
   Rashid Ahmad, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Ravuri SV, 2019, NEURIPS, V0, P12268
   Rush AM, 2015, P EMNLP 15, V0, P0
   Sanh V, 2019, ARXIV, V0, P0
   SCUDDER HJ, 1965, IEEE T INFORM THEORY, V11, P363, DOI 10.1109/tit.1965.1053799
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Shen DH, 2020, ARXIV, V0, P0
   Shleifer S, 2019, ARXIV, V0, P0
   Sohn K, 2020, ARXIV, V0, P0
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4323
   Sun Y, 2019, ARXIV, V0, P0
   Vu TT, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P3335
   Vu T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5715
   VAPNIK V, 1992, ADV NEUR IN, V4, P831
   Voita E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1264
   Wang AL, 2020, ARXIV, V0, P0
   Wang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4465
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Wang BL, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P2760
   Wang Ben, 2021, GPT J 6B 6 BILLION P, V0, P0
   Wang X, 2018, P ADV NEUR INF PROC, V31, P1
   Wang YS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1332
   Wei Colin, 2021, INT C LEARNING REPRE, V0, P0
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P6382
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Wu X, 2019, LECT NOTES COMPUT SC, V11539, P84, DOI 10.1007/978-3-030-22747-0_7
   Xu CW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7859
   Yang YB, 2020, ARXIV, V0, P0
   YangWang William, 2015, P 2015 C EMP METH NA, V0, PP2557, DOI 10.18653/V1/D15-1306
   Yarowsky D, 1995, P ACL, V0, PP189, DOI 10.3115/981658.981684
   Zhang H, 2018, P INT C LEARN REPR, V0, PP1, DOI 10.48550/ARXIV.1710.09412
   Zhang LF, 2019, IEEE I CONF COMP VIS, V0, PP3712, DOI 10.1109/ICCV.2019.00381
NR 78
TC 3
Z9 3
U1 3
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD AUG 12
PY 2022
VL 10
IS 
BP 826
EP 842
DI 10.1162/tacl_a_00492
PG 17
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8I3JG
UT WOS:000921620800001
DA 2023-11-10
ER

PT J
AU Zhang, LL
   Zhou, ZX
   Ji, PY
   Mei, AX
AF Zhang, Lingling
   Zhou, Zhenxiong
   Ji, Pengyu
   Mei, Aoxue
TI Application of Attention Mechanism with Prior Information in Natural Language Processing
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Artificial intelligence; attention mechanism; deep learning; machine translation; natural language processing; sparse mapping
AB When using deep learning methods to model natural language, a recurrent neural network that can map input sequences to output sequences is usually used. Considering that natural language contains more complicated syntactic structures, and the performance of cyclic neural networks in long sentence processing will decrease, scholars have introduced an attention mechanism into the model, which has improved the above problems to a certain extent. The existing attention mechanism still has some shortcomings, such as the inability to explicitly obtain the known syntactic structure information in the sentence, and the poor interpretability of the output probability. In response to the above problems, this article will improve the attention mechanism in the recurrent neural network model. Firstly, the prior information in the natural language sequence is constructed as a graph model through syntactic analysis and other means, and then the graph structure regularization term is introduced into the sparse mapping. A new function netmax is constructed to replace the softmax function in the traditional attention mechanism, thereby improving the performance of the model and making the degree of association. The input values corresponding to larger input samples are closer, making the output of the attention mechanism easier to understand. The innovation of this paper mainly lies in that the weight calculation method which can be widely used in the attention mechanism is proposed by combining the deep learning model with statistical knowledge, which opens a channel to introduce the prior information for the deep learning model in natural language processing tasks.
C1 [Zhang, Lingling; Ji, Pengyu; Mei, Aoxue] Beihua Univ, Coll Comp Sci & Technol, Jilin 132022, Jilin, Peoples R China.
   [Zhou, Zhenxiong] Beihua Univ, Coll Elect & Informat Engn, Jilin 132022, Jilin, Peoples R China.
C3 Beihua University; Beihua University
RP Zhou, ZX (通讯作者)，3999 East Binjiang Rd, Jilin, Jilin, Peoples R China.
EM zhangling_beihuaa@163.com; 742884852@qq.com; 1712261543@qq.com; 659374288@qq.com
FU Science and Technology Development Plan Project at Jilin Province [20200404203yy]; Science and Technology Project in the 13th Five Year Plan of Education Department at Jilin Province [JJKH20200048KJ]; Research on Teaching Reform of Higher Education in Jilin Province [JLZX205620190724110543]
CR Bahdanau D, 2016, ARXIV, V0, P0
   Chen X, 2010, ARXIV PREPRINT ARXIV, V0, P0
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Chorowski J, 2015, ADV NEUR IN, V28, P0
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Hallac D, 2015, KDD15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP387, DOI 10.1145/2783258.2783313
   Kalchbrenner N, 2013, P 2013 C EMPIRICAL M, V0, PP1700, DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P127
   Luong Minh-Thang, 2015, ARXIV151106114, V0, P0
   Ma LB, 2021, IEEE T SYST MAN CY-S, V51, P6723, DOI 10.1109/TSMC.2020.2963943
   Martins AFT, 2016, PR MACH LEARN RES, V48, P0
   Niculae V, 2017, CORR, V0, P0
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Rocktaschel Tim, 2015, ARXIV150906664, V0, P0
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Sutskever Ilya, 2014, NEURIPS, V0, P0, DOI DOI 10.5555/2969033.2969173
   Wang Feng, 2016, ABS160106823 CORR, V0, P0, DOI DOI 10.48550/ARXIV.1601.06823
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yuan M, 2006, J ROYAL STAT SOC B, V68, P49
NR 20
TC 1
Z9 1
U1 5
U2 13
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD JUN 15
PY 2022
VL 31
IS 04
BP 
EP 
DI 10.1142/S0218213022400085
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 2E7VN
UT WOS:000812432900001
DA 2023-11-10
ER

PT J
AU Goldman, O
   Tsarfaty, R
AF Goldman, Omer
   Tsarfaty, Reut
TI Morphology Without Borders: Clause-Level Morphology
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID inflection
AB Morphological tasks use large multi-lingual datasets that organize words into inflection tables, which then serve as training and evaluation data for various tasks. However, a closer inspection of these data reveals profound cross-linguistic inconsistencies, which arise from the lack of a clear linguistic and operational definition of what is a word, and which severely impair the universality of the derived tasks. To overcome this deficiency, we propose to view morphology as a clause-level phenomenon, rather than word-level. It is anchored in a fixed yet inclusive set of features, that encapsulates all functions realized in a saturated clause. We deliver MightyMorph, a novel dataset for clause-level morphology covering 4 typologically different languages: English, German, Turkish, and Hebrew. We use this dataset to derive 3 clause-level morphological tasks: inflection, reinflection and analysis. Our experiments show that the clause-level tasks are substantially harder than the respective word-level tasks, while having comparable complexity across languages. Furthermore, redefining morphology to the clause-level provides a neat interface with contextualized language models (LMs) and allows assessing the morphological knowledge encoded in these models and their usability for morphological tasks. Taken together, this work opens up new horizons in the study of computational morphology, leaving ample space for studying neural morphology cross-linguistically.
C1 [Goldman, Omer; Tsarfaty, Reut] Bar Ilan Univ, Ramat Gan, Israel.
C3 Bar Ilan University
RP Goldman, O (通讯作者)，Bar Ilan Univ, Ramat Gan, Israel.
EM omer.goldman@gmail.com; reut.tsarfaty@biu.ac.il
FU European Research Council [677352]; Ministry of Science and Technology [0002214]; European Research Council (ERC) [677352] Funding Source: European Research Council (ERC)
CR Abdul-Mageed M, 2011, P 49 ANN M ASS COMP, V0, P587
   Abney Steven P, 1991, PRINCIPLE BASED PARS, V0, PP257, DOI 10.1007/978-94-011-3474-3_10
   ACKERMAN F, 2004, PROJECTING MORPHOLOG, V0, P111
   Ackerman F, 2009, ANALOGY GRAMMAR FORM, V0, P54
   Alan Hall T, 1999, STUDIES PHONOLOGICAL, V174, P22, DOI 10.1075/cilt.174.02hal
   Amram Adam, 2018, P 27 INT C COMPUTATI, V0, P2242
   Anderson SR, 1992, A MORPHOUS MORPHOLOG, V0, P0, DOI DOI 10.1017/CBO9780511586262
   [Anonymous], 1985, MORPHOLOGY STUDY REL, V0, P0, DOI DOI 10.1075/TSL.9
   [Anonymous], 2013, P 2013 C EMP METH NA, V0, P0
   Barzdins G, 2007, P 16 NORD C COMP LIN, V0, P13
   Basirat A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P1376
   Batsuren Khuyagbaatar, 2022, P 13 LANGUAGE RESOUR, V0, P0
   Bostrom Kaj, 2020, ARXIV200403720, V0, P0
   BRESNAN J, 1995, NAT LANG LINGUIST TH, V13, P181, DOI 10.1007/BF00992782
   Bresnan Joan, 2015, LEXICAL FUNCTIONAL S, V0, P0, DOI DOI 10.1002/9781119105664
   BUCHHOLZ S, 1999, P JOINT SIGDAT C EMP, V0, P239
   Cotterell Ryan, 2017, P CONLL SIGMORPHON 2, V0, PP1, DOI 10.18653/V1/K17-2001
   Cotterell Ryan, 2016, P 14 SIGMORPHON WORK, V0, PP10, DOI 10.18653/V1/W16-2002
   de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI 10.1162/coli_a_00402
   Dixon R, 2002, WORD CROSS LINGUISTI, V0, PP1, DOI 10.1017/CBO9780511486241.002
   Duanmu S, 2011, NEW APPROACHES CHINE, V0, PP135, DOI 10.1515/9783110809084.135
   Gazdar Gerald, 1985, GEN PHRASE STRUCTURE, V0, P0
   Goldman O, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P864
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P3483
   Guriel David, 2022, P 60 ANN M ASS COMPU, V0, P0, DOI DOI 10.18653/v1/2022.acl-short.21
   Halle Morris, 1993, VIEW BUILDING, V0, P111
   Haspelmath M, 2011, FOLIA LINGUIST, V45, P31, DOI 10.1515/FLIN.2011.002
   Hofmann V, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3594
   John Sylak-Glassman, 2016, COMPOSITION USE UNIV, V0, P0
   Joseph Brian D, 2003, HDB HIST LINGUISTICS, V0, P472
   Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66
   Lewis M, 2020, 58 ANN M ASS COMP LI, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Makarov Peter, 2018, P 27 INT C COMPUTATI, V0, P83
   Minkov Einat, 2007, P 45 ANN M ASS COMPU, V0, P128
   Mpiranya Fidele, 2014, SWAHILI GRAMMAR WORK, V0, P0, DOI DOI 10.4324/9781315750699
   Nakagawa T, 2004, P 20 INT C COMP LING, V0, PP466, DOI 10.3115/1220355.1220422
   Norde Muriel, 2009, DEGRAMMATICALIZATION, V0, P0, DOI DOI 10.1093/acprof:oso/9780199207923.001.0001
   Packard Jerome L, 2000, MORPHOLOGY CHINESE L, V0, P0, DOI DOI 10.1017/CBO9780511486821
   Park Hyunji, 2021, P 1 WORKSHOP NATURAL, V0, PP131, DOI 10.18653/V1/2021.AMERICASNLP-1.14
   Peters B, 2020, 17TH SIGMORPHON WORKSHOP ON COMPUTATIONAL RESEARCH IN PHONETICS PHONOLOGY, V0, P63
   Pimentel T, 2021, P 18 SIGMORPHON WORK, V0, PP229, DOI 10.18653/v1/2021.sigmorphon-1.25
   Pollard C, 1994, HEAD DRIVEN PHRASE S, V0, P0
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Richens Richard H, 1952, P C MECH TRANSLATION, V0, P0
   SCALISE S, 1988, LINGUISTICS, V26, P561, DOI 10.1515/ling.1988.26.4.561
   Schuster M, 2012, INT CONF ACOUST SPEE, V0, PP5149, DOI 10.1109/ICASSP.2012.6289079
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shieber Stuart, 1986, INTRO UNIFICATION BA, V0, P0
   Silfverberg M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2883
   Sylak-Glassman J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P674
   Terry Winograd, 1971, PROCEDURES REPRESENT, V0, P0
   Traugott Elizabeth, 2003, GRAMMATICALIZATION, V2nd edition, P0, DOI 10.1017/CBO9781139165525
   Webster Donald Humphry, 1968, LETS LEARN ESKIMO, V0, P0
   Wilkes Arnett, 2012, COMPLETE ZULU BEGINN, V0, P0
   Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P483
   Xue N, 2003, COMPUT LINGUIST, V8, P29, DOI 10.3115/1119250.1119278
   ZWICKY AM, 1983, LANGUAGE, V59, P502, DOI 10.2307/413900
NR 57
TC 0
Z9 0
U1 2
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD DEC 23
PY 2022
VL 10
IS 
BP 1455
EP 1472
DI 10.1162/tacl_a_00528
PG 18
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9XN
UT WOS:000923445700004
DA 2023-11-10
ER

PT J
AU Zahid, F
   Tanveer, A
   Kuo, MMY
   Sinha, R
AF Zahid, Farzana
   Tanveer, Awais
   Kuo, Matthew M. Y.
   Sinha, Roopak
TI A systematic mapping of semi-formal and formal methods in requirements engineering of industrial Cyber-Physical systems
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article
DE Formal methods; Industrial Cyber-Physical system; Requirements engineering; Semi-formal methods; Systematic mapping study
ID verification; classification; simulation; languages; design
AB The requirements engineering of Industrial Cyber-Physical Systems is extremely challenging due to large system sizes, component heterogeneity, involvement of multi-discipline stakeholders and machines, and continuous evolution. Formal and semi-formal languages, techniques, tools and frameworks can assist by providing repeatable and rigorous structures for eliciting, specifying, analysing, verifying and maintaining requirements. Various approaches have been proposed, but a contemporary and comprehensive study providing a landscape of the state-of-the-art is currently missing. This article reports a systematic mapping study covering 93 primary studies published between 2009 and October 2020. We categorise surveyed studies by current research directions in the use of semi-formal and formal methods for Requirements Engineering phases for Industrial Cyber-Physical Systems. We also identify gaps in current research and develop a novel conceptual model capturing the relationship between available formalisms and Requirements Engineering activities. We find that extensive work has been carried out on the formal analysis and verification of safety and timings requirements. However, the use of semi-formal notations, works on key phases like requirements elicitation and management, and the adoption of industrial standards are largely missing. Moreover, we find no literature providing methods to handle privacy and trust requirements, which have become critical concerns in this area.
C1 [Zahid, Farzana; Tanveer, Awais; Kuo, Matthew M. Y.; Sinha, Roopak] Auckland Univ Technol, Sch Engn Comp & Math Sci, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Zahid, F (通讯作者)，Auckland Univ Technol, Sch Engn Comp & Math Sci, Auckland 1010, New Zealand.
EM farzana.zahid@autuni.ac.nz; awais.tanveer@aut.ac.nz; matthew.kuo@aut.ac.nz; roopak.sinha@aut.ac.nz
CR Adepu S, 2016, IFIP ADV INF COMM TE, V471, P91, DOI 10.1007/978-3-319-33630-5_7
   Adepu S, 2016, ADV INTELL SYST COMP, V426, P75, DOI 10.1007/978-3-319-29643-2_6
   Adepu S, 2016, IEEE HI ASS SYS ENGR, V0, PP141, DOI 10.1109/HASE.2016.14
   Ahmad E, 2015, SCI CHINA INFORM SCI, V58, P0, DOI 10.1007/s11432-015-5346-2
   Akella R, 2009, P INT COMP SOFTW APP, V0, P654
   Akkaya I, 2016, P IEEE, V104, P997, DOI 10.1109/JPROC.2015.2512265
   [Anonymous], 2012, MODEL BASED ENG AADL, V0, P0
   [Anonymous], 2004, CONCEPTS TECHNIQUES, V0, P0
   [Anonymous], 2007, REACTIVE SYSTEMS MOD, V0, P0, DOI DOI 10.1017/CBO9780511814105
   [Anonymous], 1995, SYSTEM REQUIREMENTS, V0, P0
   Askarpour Mehrnoosh, 2019, FROM SOFTWARE ENGINEERING TO FORMAL METHODS AND TOOLS, V0, P110, DOI 10.1007/978-3-030-30985-5_8
   Bae K, 2015, SCI COMPUT PROGRAM, V103, P13, DOI 10.1016/j.scico.2014.09.011
   Balasubramaniyan S, 2016, MICROPROCESS MICROSY, V42, P37, DOI 10.1016/j.micpro.2015.12.006
   Bartocci E, 2020, P 29 ACM SIGS INT S, V0, PP569, DOI 10.1145/3395363.3404369
   Bartocci E, 2019, LECT NOTES COMPUT SC, V11724, P69, DOI 10.1007/978-3-030-30446-1_4
   Bernardi S, 2020, J SYST SOFTWARE, V0, P110
   Bingqing Xu, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE INTERNET OF THINGS (ITHINGS) AND IEEE CYBER, V0, P804, DOI 10.1109/GreenCom-iThings-CPSCom.2013.143
   Bouskela D, 2017, CAN J ELECT COMPUT E, V40, P66, DOI 10.1109/CJECE.2016.2630421
   Bouskela D, 2018, ANN IEEE SYST CONF, V0, P412
   Bray T, 2017, 8259 RFC, V0, P0, DOI DOI 10.17487/RFC8259
   Bu L, 2011, ACM SIGBED REV, V8, P7, DOI 10.1145/2000367.2000368
   Cengic G, 2010, IEEE T IND INFORM, V6, P145, DOI 10.1109/TII.2010.2040393
   Charters S, 2007, GUIDELINES PERFORMIN, V0, P0
   Chen YX, 2018, IEEE IND ELEC, V0, PP4687, DOI 10.1109/IECON.2018.8591171
   Clarke EM, 2011, LECT NOTES COMPUT SC, V6996, P1, DOI 10.1007/978-3-642-24372-1_1
   Clavel Manuel, 2007, ALL MAUDE HIGH PERFO, V0, P0
   Colombo AW, 2017, IEEE IND ELECTRON M, V11, P6, DOI 10.1109/MIE.2017.2648857
   Colombo AW, 2014, CONSERVATION AGR, V22, P4, DOI 10.1007/978-3-319-11620-4
   Dang T, 2016, INT C COMPLEX SYSTEM, V0, P57
   Davis JA, 2013, LECT NOTES COMPUT SC, V8187, P63, DOI 10.1007/978-3-642-41010-9_5
   Denno PO, 2014, C SYST ENG RES CSER, V0, P0
   Derigent W, 2021, J INTELL MANUF, V32, P1797, DOI 10.1007/s10845-020-01532-x
   Drozdov D, 2019, IEEE INT C EMERG, V0, PP1682, DOI 10.1109/ETFA.2019.8869293
   Drozdov D, 2017, STUD COMPUT INTELL, V694, P35, DOI 10.1007/978-3-319-51100-9_4
   Du DH, 2018, SCI COMPUT PROGRAM, V166, P71, DOI 10.1016/j.scico.2018.05.005
   Dyba Tore, 2007, 2007 FIRST INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT, V0, P225
   Fairley Richard E, 2014, GUIDE SOFTWARE ENG B, V0, P0
   Ferrante Orlando, 2017, MODEL-BASED SAFETY AND ASSESSMENT. 5TH INTERNATIONAL SYMPOSIUM, V0, P243, DOI 10.1007/978-3-319-64119-5_16
   Fink GA, 2017, INTELL DAT CENT SYST, V0, PP129, DOI 10.1016/B978-0-12-803801-7.00009-2
   Fisher A, 2014, COMPLEX SYSTEMS DESI, V0, PP21, DOI 10.1007/978-3-319-02812-5_2
   France R, 1998, COMPUT STAND INTER, V19, P325, DOI 10.1016/S0920-5489(98)00020-8
   Franceschini F, 2016, J INFORMETR, V10, P933, DOI 10.1016/j.joi.2016.07.003
   Frechette S, 2016, CURRENT STANDARDS LA, V8107, P39
   Fritz S, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY AND MANAGEMENT (ICITM 2019), V0, PP85, DOI 10.1109/ICITM.2019.8710732
   Fuchs A, 2010, P INT WORKSH SEC DEP, V0, P1
   Gabmeyer S, 2019, SOFTW SYST MODEL, V18, P473, DOI 10.1007/s10270-017-0591-z
   Garcia L, 2019, ACM IEEE INT CONF CY, V0, PP47, DOI 10.1145/3302509.3311036
   Gawanmeh A, 2017, IEEE INT CON DIS, V0, PP91, DOI 10.1109/ICDCSW.2017.59
   Geraldes AA, 2018, ACM TRANS CYBER-PHYS, V2, P0, DOI 10.1145/3140237
   Gómez FJ, 2020, SIMUL MODEL PRACT TH, V103, P0, DOI 10.1016/j.simpat.2020.102095
   Goorden M, 2019, LECT NOTES COMPUT SC, V11687, P76, DOI 10.1007/978-3-030-27008-7_5
   Gracia T J H, 2018, B CIENTIFICO CIENC E, V6, P0, DOI 10.1007/978-3-319-40895-8
   Grassler Iris, 2020, ADVANCED, V0, P0
   Guttag John V, 1993, LARCH LANGUAGES TOOL, V0, P0
   Hachicha M, 2019, PROCEDIA COMPUT SCI, V159, P1853, DOI 10.1016/j.procs.2019.09.357
   Hall A, 2005, 7 INT C FORM ENG MET, V0, P0, DOI DOI 10.1007/11576280_1
   Haolan Zhan, 2019, UNIFYING THEORIES OF PROGRAMMING. 7TH INTERNATIONAL SYMPOSIUM, V0, P109, DOI 10.1007/978-3-030-31038-7_6
   Hissam SA, 1900, P1, V0, P0
   Hofmann M, 2013, RAPIDMINER DATA MINI, V0, P0, DOI DOI 10.1201/b16023
   Huang JW, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16030382
   Huang L, 2019, 2019 IEEE 19TH INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, V0, P228, DOI 10.1109/QRS.2019.00039
   Huth M, 2004, LOGIC COMPUTER SCI M, V2nd ed., P0
   Iglesias A, 2017, 21ST INTERNATIONAL SYSTEMS & SOFTWARE PRODUCT LINE CONFERENCE (SPLC 2017), VOL 1, P195, DOI 10.1145/3106195.3106223
   Jalali S, 2012, INT SYMP EMP SOFTWAR, V0, PP29, DOI 10.1145/2372251.2372257
   Jeon B, 2020, J INTELL MANUF, V31, P1837, DOI 10.1007/s10845-020-01539-4
   Jue W, 2019, IEEE IND ELEC, V0, PP2883, DOI 10.1109/IECON.2019.8926665
   Kallel S, 2011, THESIS TU, V0, P0
   Kang EY, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, V0, PP1492, DOI 10.1145/3167132.3167291
   Kang E, 2016, 2016 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR SMART CYBER-PHYSICAL SYSTEMS (SESCPS), V0, PP22, DOI 10.1109/SEsCPS.2016.012
   Kaur A, 2012, P 2 INT C COMP SCI E, V0, P524
   Keshav S, 2007, ACM SIGCOMM COMP COM, V37, P83, DOI 10.1145/1273445.1273458
   Khan MU, 2019, J SYST SOFTWARE, V149, P396, DOI 10.1016/j.jss.2018.12.018
   Kim J, 2019, IEEE ICST WORKSHOP, V0, PP148, DOI 10.1109/ICSTW.2019.00043
   Kitchenham B, 2010, INFORM SOFTWARE TECH, V52, P792, DOI 10.1016/j.infsof.2010.03.006
   Knüppel A, 2020, LECT NOTES COMPUT SC, V12076, P203, DOI 10.1007/978-3-030-45234-6_10
   Krueger M, 2011, SYSTEMS ENG HDB GUID, V0, P0
   Kulvatunyou B, 2014, IFIP ADV INF COMM TE, V439, P658
   Kumar P, 2012, DES AUT CON, V0, P688
   Lan Q, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Lana CA, 2019, IEEE SYST J, V13, P2201, DOI 10.1109/JSYST.2018.2874061
   LeMay E, 2011, PROCEEDINGS OF THE 2011 EIGHTH INTERNATIONAL CONFERENCE ON QUANTITATIVE EVALUATION OF SYSTEMS (QEST 2011), V0, PP191, DOI 10.1109/QEST.2011.34
   Li F, 2016, L N INST COMP SCI SO, V173, P0, DOI 10.1007/978-3-319-44350-8_22
   Li NY, 2020, J SYST SOFTWARE, V170, P0, DOI 10.1016/j.jss.2020.110742
   Li YJ, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), V0, P1305
   Liang YY, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND ENGINEERING APPLICATIONS, V0, PP1, DOI 10.1109/ISDEA.2013.406
   Lichen Zhang, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE INTERNET OF THINGS (ITHINGS) AND IEEE CYBER, V0, P1486, DOI 10.1109/GreenCom-iThings-CPSCom.2013.262
   Lichen Zhang, 2011, PROCEEDINGS OF THE 2011 IEEE 5TH INTERNATIONAL SYMPOSIUM ON THEORETICAL ASPECTS OF SOFTWARE ENGINEERING (TASE 2011), V0, PP213, DOI 10.1109/TASE.2011.37
   Lima BM, 2018, INT J SPORT PHYSIOL, V13, P1164, DOI 10.1123/ijspp.2018-0072
   Lin Q, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS18), V0, PP525, DOI 10.1145/3196494.3196546
   Loucopoulos P, 2019, LECT NOTES COMPUT SC, V11483, P276, DOI 10.1007/978-3-030-21290-2_18
   Maldonado J C, 2010, PROC EASE 10, V0, P1
   Mancini T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, V0, P0
   Mandayam K, 1995, CSL9504 SRI INT, V0, P0
   Mann C, 2009, KYBERNETES, V0, PP38, DOI 10.1108/k.2009.06738aae.004
   Mashkoor A, 2012, LECT NOTES COMPUT SC, V7335, P419, DOI 10.1007/978-3-642-31137-6_32
   Mattsson S, 1999, TUTORIAL RATIONALE V, V0, P1
   Menghi C, 2019, ESEC/FSE2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP27, DOI 10.1145/3338906.3338920
   Meseguer J, 2012, THEOR COMPUT SCI, V451, P1, DOI 10.1016/j.tcs.2012.05.040
   Metsälä S, 2017, LECT NOTES ARTIF INT, V10444, P125, DOI 10.1007/978-3-319-64635-0_10
   Misson HA, 2019, 2019 IX BRAZILIAN SYMPOSIUM ON COMPUTING SYSTEMS ENGINEERING (SBESC), V0, P0, DOI DOI 10.1109/sbesc49506.2019.9046084
   Monostori L, 2016, CIRP ANN-MANUF TECHN, V65, P621, DOI 10.1016/j.cirp.2016.06.005
   Mühlfelder M, 2019, ADV INTELL SYST, V822, P391, DOI 10.1007/978-3-319-96077-7_41
   Nägele T, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL CYBER PHYSICAL SYSTEMS (ICPS 2019), V0, PP133, DOI 10.1109/icphys.2019.8780355
   Nejati S, 2019, ESEC/FSE2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP1015, DOI 10.1145/3338906.3340444
   Nuzzo P, 2019, ACM T EMBED COMPUT S, V18, P0, DOI 10.1145/3243216
   Nuzzo P, 2018, DES AUT TEST EUROPE, V0, PP839, DOI 10.23919/DATE.2018.8342122
   Object Management Group, 2011, UML PROF MOD AN REAL, V0, P0
   Olveczky PC, 2007, HIGHER-ORDER AND SYMBOLIC COMPUTATION, V20, P161, DOI 10.1007/s10990-007-9001-5
   Oztemel E, 2020, J INTELL MANUF, V31, P127, DOI 10.1007/s10845-018-1433-8
   Pagliari L, 2020, J SOFTW-EVOL PROC, V32, P0, DOI 10.1002/smr.2179
   Penzenstadler B, 2012, PROCEEDINGS OF THE 2012 IEEE SECOND WORKSHOP ON REQUIREMENTS ENGINEERING FOR SYSTEMS, V0, P20, DOI 10.1109/RES4.2012.6347692
   Petersen K, 2015, INFORM SOFTWARE TECH, V64, P1, DOI 10.1016/j.infsof.2015.03.007
   Pierce K, 2019, SOFTW SYST MODEL, V0, P1
   Rashid A, 2019, INT WORKSHOP FORMAL, V0, P3
   Rashid A, 2021, J SYST ARCHITECT, V112, P0, DOI 10.1016/j.sysarc.2020.101850
   Ribeiro FGC, 2016, IFAC PAPERSONLINE, V49, P42, DOI 10.1016/j.ifacol.2016.11.123
   Robinson S, 2007, P 2007 SPRING SIM MU, V0, P152
   Rocchetto M, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS17), V0, PP114, DOI 10.1145/3052973.3053024
   Roscoe B, 1998, THEORY PRACTICE CONC, V0, P0
   Ruchkin I, 2015, DOCT S 18 ACM IEEEE, V0, P0
   Sakarovitch J, 2009, ELEMENTS AUTOMATA TH, V0, P0
   Saleh MS, 2015, INT CONF SMART GR C, V0, PP195, DOI 10.1109/ICSGCE.2015.7454295
   Sanford F, 2020, MODELING STANDARDS, V0, P0
   Sanwal MU, 2013, LECT NOTES COMPUT SC, V7971, P358, DOI 10.1007/978-3-642-39637-3_29
   Seceleanu C, 2017, SCI COMPUT PROGRAM, V133, P216, DOI 10.1016/j.scico.2016.09.007
   Sepúlveda S, 2016, INFORM SOFTWARE TECH, V69, P16, DOI 10.1016/j.infsof.2015.08.007
   Singh M, 2013, IOSR J COMPUTER ENG, V11, P37
   Singh NK, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL CYBER PHYSICAL SYSTEMS (ICPS 2019), V0, PP417, DOI 10.1109/icphys.2019.8780383
   Sinha R, 2019, ACM TRANS CYBER-PHYS, V3, P0, DOI 10.1145/3203208
   Sinha R, 2015, IEEE INT C ENG COMP, V0, PP198, DOI 10.1109/ICECCS.2015.32
   Strauss E, 1998, CLIN ORTHOP RELAT R, V0, P2
   Sun HY, 2015, ASIA PAC SOFWR ENG, V0, PP254, DOI 10.1109/APSEC.2015.58
   Takbiri Y, 2019, 4 INT C COMB CRYPT C, V0, P0
   Theelen BD, 2007, MEMOCODE07: FIFTH ACM & IEEE INTERNATIONAL CONFERENCE ON FORMAL METHODS AND MODELS FOR CO-DESIGN, V0, P139, DOI 10.1109/MEMCOD.2007.371231
   Tröls M, 2021, J SOFTW-EVOL PROC, V33, P0, DOI 10.1002/smr.2308
   Ullman J D, 2000, INTRO AUTOMATA THEOR, V32, P60
   Vegendla A, 2018, J INF TECHNOL RES, V11, P49, DOI 10.4018/JITR.2018010104
   Vogel-Heuser B, 2014, MECHATRONICS, V24, P883, DOI 10.1016/j.mechatronics.2014.05.003
   von Birgelen A, 2018, IMPROVE INNOVATIVE M, V8, P55, DOI 10.1007/978-3-662-57805-6_4
   Wang J, 2007, HDB DYN SYST MODEL, V1, P24
   Wang R, 2011, COMPUT IND, V62, P23, DOI 10.1016/j.compind.2010.05.015
   Westman J, 2014, SPECIFYING STRUCTURI, V0, P0
   Wieringa R, 2006, REQUIR ENG, V11, P102, DOI 10.1007/s00766-005-0021-6
   Wiesner S, 2017, IJAT, V11, P17 ? 28, DOI 10.20965/ijat.2017.p0017
   Wiesner S, 2015, IFIP ADV INF COMM TE, V460, P49, DOI 10.1007/978-3-319-22759-7_6
   Wisniewski R, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20195565
   Wortmann A, 2020, SOFTW SYST MODEL, V19, P67, DOI 10.1007/s10270-019-00757-6
   Wu X, 2020, INT J ADV MANUF TECH, V111, P243, DOI 10.1007/s00170-020-06110-2
   You J, 2012, IET INT C INF SCI CO, V0, P0, DOI DOI 10.1049/cp.2012.2353
   Yu W, 2013, INT J HYBRID INF TEC, V6, P15, DOI 10.1007/S00769-009-0627-3
   Yu WJ, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL CYBER PHYSICAL SYSTEMS (ICPS 2019), V0, PP173, DOI 10.1109/icphys.2019.8780271
   Zhang LC, 2013, 2013 IEEE 15TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS & 2013 IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (HPCC_EUC), V0, PP2096, DOI 10.1109/HPCC.and.EUC.2013.301
   Zhang LC, 2013, IEEE INT C COMPUT, V0, PP603, DOI 10.1109/CSE.2013.95
   Zhang LC, 2014, PROCEEDINGS OF THE 2014 20TH INTERNATIONAL CONFERENCE ON AUTOMATION AND COMPUTING (ICAC14), V0, PP55, DOI 10.1109/IConAC.2014.6935460
   Zhang LC, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), V0, PP236, DOI 10.1109/ICInfA.2013.6720302
   Zhang M, 2015, P 2015 INT S SOFTWAR, V0, P397
   Zhang YS, 2020, IEEE T MULTIMEDIA, V22, P2844, DOI 10.1109/TMM.2020.2966887
   Zheng X, 2017, IEEE SYST J, V11, P2614, DOI 10.1109/JSYST.2015.2496293
   Zheng X, 2015, 2015 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR SMART CYBER-PHYSICAL SYSTEMS (SESCPS), V0, PP15, DOI 10.1109/SEsCPS.2015.11
NR 159
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD AUG 15
PY 2022
VL 33
IS 6
BP 1603
EP 1638
DI 10.1007/s10845-021-01753-8
EA APR 2021
PG 36
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
SC Computer Science; Engineering
GA 2O2EH
UT WOS:000635874100001
DA 2023-11-10
ER

PT J
AU Das, AK
   Thumu, B
   Sarkar, A
   Vimal, S
   Das, AK
AF Das, Ajit Kumar
   Thumu, Bhaavanaa
   Sarkar, Apurba
   Vimal, S.
   Das, Asit Kumar
TI Graph-Based Text Summarization and Its Application on COVID-19 Twitter Data
SO INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Natural language processing; text summarization; graph based summary; independent set; COVID-19 twitter data
AB Large volumes of structured and semi-structured data are being generated every day. Processing this large amount of data and extracting important information is a challenging task. The goal of an automatic text summarization is to preserve the key information and the overall meaning of the article to be summarized. In this paper, a graph-based approach is followed to generate an extractive summary, where sentences of the article are considered as vertices, and weighted edges are introduced based on the cosine similarities among the vertices. A possible subset of maximal independent sets of vertices of the graph is identified with the assumption that adjacent vertices provide sentences with similar information. The degree centrality and clustering coefficient of the vertices are used to compute the score of each of the maximal independent sets. The set with the highest score provides the final summary of the article. The proposed method is evaluated using the benchmark BBC News data to demonstrate its effectiveness and is applied to the COVID-19 Twitter data to express its applicability in topic modeling. Both the application and comparative study with other methods illustrate the efficacy of the proposed methodology.
C1 [Das, Ajit Kumar; Sarkar, Apurba; Das, Asit Kumar] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah 711103, W Bengal, India.
   [Thumu, Bhaavanaa] Indian Inst Informat Technol Design & Mfg, Chennai, Tamil Nadu, India.
   [Vimal, S.] Ramco Inst Technol, Rajapalayam, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST); Indian Institute of Information Technology, Design & Manufacturing, Kancheepuram
RP Das, AK (通讯作者)，Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah 711103, W Bengal, India.
EM writetoajit@yahoo.com; ced17i021@iiitdm.ac.in; sarkar@cs.iiests.ac.in; svimalphd@gmail.com; akdas@cs.iiests.ac.in
CR Abuobieda A, 2013, LECT NOTES COMPUT SC, V7803, P78, DOI 10.1007/978-3-642-36543-0_9
   Ahmed M, 2014, C IND ELECT APPL, V0, PP1780, DOI 10.1109/ICIEA.2014.6931456
   [Anonymous], 2009, P 2009 SIAM INT C DA, V0, P0
   [Anonymous], 2017, 2017 IEEE INT C SIGN, V0, P0
   Bossard Aurelien, 2017, P INT C REC ADV NAT, V0, P111
   Connelly Lynne M, 2016, MEDSURG NURS, V25, P61
   Das A, 2021, FUTURE GENER COMP SY, V118, P339, DOI 10.1016/j.future.2021.01.027
   Dutta Madhurima, 2019, EMERGING TECHNOLOGIES IN DATA MINING AND INFORMATION SECURITY. PROCEEDINGS OF IEMIS 2018. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 813), V0, PP179, DOI 10.1007/978-981-13-1498-8_16
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Genest P-E, 2012, P 50 ANN M ASS COMP, V2, P354
   Gupta S, 2019, EXPERT SYST APPL, V121, P49, DOI 10.1016/j.eswa.2018.12.011
   Gupta Vishal, 2010, JOURNAL OF EMERGING TECHNOLOGIES IN WEB INTELLIGENCE, V2, P258, DOI 10.4304/jetwi.2.3.258-268
   Hark C, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102187
   Hovy, 2000, P 18 INT C COMP LING, V0, P0
   LAM FC, 1983, BIOMETRIKA, V70, P510
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin H, 2019, AAAI CONF ARTIF INTE, V0, P9815
   Liu Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1745
   Mallick C, 2021, INTERDISCIP SCI, V13, P229, DOI 10.1007/s12539-020-00412-5
   Mallick C, 2019, ADV INTELL SYST, V758, P137, DOI 10.1007/978-981-13-0514-6_14
   Mallick C, 2019, ADV INTELL SYST, V758, P825, DOI 10.1007/978-981-13-0514-6_78
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Moawad IF, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES2012), V0, PP132, DOI 10.1109/ICCES.2012.6408498
   Mohan MJ, 2016, PROCEDIA COMPUT SCI, V87, P32, DOI 10.1016/j.procs.2016.05.122
   Moratanch N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, V0, P265
   Nagwani N, 2015, J BIG DATA-GER, V2, P0, DOI 10.1186/s40537-015-0020-5
   Oya T, 2014, P 8 INT NAT LANG GEN, V0, P0
   Ozsoy MG, 2011, J INF SCI, V37, P405, DOI 10.1177/0165551511408848
   Rajas RPK, 2020, INT J ADV SCI TECHNO, V29, P8215
   Sharaff A, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), V0, PP906, DOI 10.1109/ICCS45141.2019.9065722
   Singh P, 2020, 2020 INT C EMERGING, V0, P1
   Sunitha C, 2016, PROCEDIA COMPUT SCI, V87, P25, DOI 10.1016/j.procs.2016.05.121
   Tanaka H, 2009, WORKSHOP LANGUAGE GE, V0, P39
   Uçkan T, 2020, EGYPT INFORM J, V21, P145, DOI 10.1016/j.eij.2019.12.002
   Ullah S, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON NETWORKING, V0, P48, DOI 10.1145/3362966.3362971
   Vijayarani S, 2015, INT J COMPUT SCI COM, V5, P7, DOI 10.1016/J.PR0CS.2013.05.286
   Zhu JN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4154
NR 37
TC 1
Z9 1
U1 0
U2 5
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-4885
EI 1793-6411
J9 INT J UNCERTAIN FUZZ
JI Int. J. Uncertainty Fuzziness Knowl.-Based Syst.
PD JUN 15
PY 2022
VL 30
IS 03
BP 513
EP 540
DI 10.1142/S0218488522400190
PG 28
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3G0YE
UT WOS:000831082100011
DA 2023-11-10
ER

PT J
AU Ghayoomi, M
   Mousavian, M
AF Ghayoomi, Masood
   Mousavian, Maryam
TI Deep transfer learning for COVID-19 fake news detection in Persian
SO EXPERT SYSTEMS
LA English
DT Article
DE contextualized text representation; COVID-19; deep neural network; fake news detection; transfer learning
ID misinformation
AB The spread of fake news on social media has increased dramatically in recent years. Hence, fake news detection systems have received researchers' attention globally. During the COVID-19 outbreak in 2019 and the worldwide epidemic, the importance of this issue becomes more apparent. Due to the importance of the issue, a large number of researchers have begun to collect English datasets and to study COVID-19 fake news detection. However, there are a large number of low-resource languages, including Persian, that cannot develop accurate tools for automatic COVID-19 fake news detection due to the lack of annotated data for the task. In this article, we aim to develop a corpus for Persian in the domain of COVID-19 where the fake news is annotated and to provide a model for detecting Persian COVID-19 fake news. With the impressive advancement of multilingual pre-trained language models, the idea of cross-lingual transfer learning can be proposed to improve the generalization of models trained with low-resource language datasets. Accordingly, we use the state-of-the-art deep cross-lingual contextualized language model, XLM-RoBERTa, and the parallel convolutional neural networks to detect Persian COVID-19 fake news. Moreover, we use the idea of knowledge transferring across-domains to improve the results by using both the English COVID-19 dataset and the general domain Persian fake news dataset. The combination of both cross-lingual and cross-domain transfer learning has outperformed the models and it has beaten the baseline by 2.39% significantly.
C1 [Ghayoomi, Masood] Inst Humanities & Cultural Studies, Fac Linguist, Tehran, Iran.
   [Mousavian, Maryam] Amirkabir Univ Technol, Comp Engn Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Ghayoomi, M (通讯作者)，Inst Humanities & Cultural Studies, Fac Linguist, Tehran, Iran.
EM m.ghayoomi@ihcs.ac.ir
FU Iran National Science Foundation [99009204]
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Al-Rakhami MS, 2020, IEEE ACCESS, V8, P155961, DOI 10.1109/ACCESS.2020.3019600
   Al-Zaman, 2021, JOURNALISM MEDIA, V2, P100, DOI 10.3390/JOURNALMEDIA2010007
   Allport GW, 1947, PSYCHOL RUMOR, V0, P0
   Barua Z, 2020, PROG DISASTER SCI, V8, P0, DOI 10.1016/j.pdisas.2020.100119
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Conneau A, 2019, ADV NEUR IN, V32, P0
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Cui Limeng, 2020, ARXIV200600885, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Ghayoomi, 2019, LANG LINGUIST-TAIWAN, V14, P21
   Goldani MH, 2021, APPL SOFT COMPUT, V101, P0, DOI 10.1016/j.asoc.2020.106991
   Goldani MH, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102418
   Gundapu S, 2021, TRANSFORMER BASED AU, V0, P0
   Huang YF, 2020, EXPERT SYST APPL, V159, P0, DOI 10.1016/j.eswa.2020.113584
   Jahanbakhsh-Nagadeh Z, 2020, MODEL MEASURE SPREAD, V0, P0
   Jahanbakhsh-Nagadeh Z, 2021, SIGNAL DATA PROCESSI, V18, P29
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Liu C, 2019, LECT NOTES ARTIF INT, V11776, P172, DOI 10.1007/978-3-030-29563-9_17
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5070
   Lopez CE, 2020, UNDERSTANDING PERCEP, V0, P0
   Mahmoodabad SD, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), V0, PP597, DOI 10.1109/ISTEL.2018.8661007
   Memon SA, 2020, CHARACTERIZING COVID, V0, P0
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Muller Martin, 2020, ARXIV200507503, V0, P0
   Nasir JA, 2021, INT J INFORM MANAGE, V1, P0, DOI 10.1016/j.jjimei.2020.100007
   Patwa P, 2021, P COMBATING ONLINE H, V0, P21
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qazi Umair, 2020, SIGSPATIAL SPECIAL, V12, P6, DOI 10.1145/3404820.3404823
   Salem FKA, 2019, P INT AAAI C WEB SOC, V13, P573
   Samadi M, 2021, ACM T ASIAN LOW-RESO, V21, P10
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Seifikar M, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), V0, PP424, DOI 10.1109/ISTEL.2018.8661059
   Swire-Thompson B, 2020, ANNU REV PUBL HEALTH, V41, P433, DOI 10.1146/annurev-publhealth-040119-094127
   van Der Linden S, 2020, FRONT PSYCHOL, V11, P0, DOI 10.3389/fpsyg.2020.566790
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wani A, 2021, EVALUATING DEEP LEAR, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yang ZJ, 2016, ADV SOC SCI EDUC HUM, V64, P1480
   Zamani S, 2017, IRAN CONF ELECTR ENG, V0, PP1532, DOI 10.1109/IranianCEE.2017.7985287
   Zarharan M, 2019, PERSIAN STANCE CLASS, V0, P0
   Zarocostas J, 2020, LANCET, V395, P676, DOI 10.1016/S0140-6736(20)30461-X
NR 45
TC 10
Z9 10
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD SEP 15
PY 2022
VL 39
IS 8
BP 
EP 
DI 10.1111/exsy.13008
EA APR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA 3P1YF
UT WOS:000777507100001
PM 35599852
DA 2023-11-10
ER

PT J
AU Do, P
   Phan, T
   Le, H
   Gupta, BB
AF Do, Phuc
   Phan, Trung
   Le, Hung
   Gupta, Brij B.
TI Building a knowledge graph by using cross-lingual transfer method and distributed MinIE algorithm on apache spark
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Knowledge graph; Cross-lingual transfer method; Distributed MinIE; Natural language processing; Triples extraction
AB The simplest and effective way to store human knowledge through centuries was using text. Along with the advancement of technology nowadays, the volume of text has grown to be larger and larger. To extract useful information from this amount of text becomes an exceptionally complex task. As an effort to solve that problem, in this paper, we present a pipeline to extract core knowledge from large quantity text using distributed computing. The components of our pipeline are systems that were known to yield good results. The outputs of our proposed system are stored in a knowledge graph. A knowledge graph is a graph for storing knowledge in the form of triples (head, relation, tail). Some of the existing knowledge graphs in the world are Google knowledge graph, YAGO, DBLP, or DBpedia. These knowledge graphs have one thing in common-they are in English. The English language is studied by many researchers in the world and it had become a rich-resource language (with many natural language processing tools and data set). Vietnamese, on the other hand, is a low-resource language. Therefore, we use cross-lingual transfer method to build a Vietnamese knowledge graph. Firstly, we collect data in form of text about Vietnam tourism, which was written mostly in Vietnamese, using Google search and Wikipedia. In the next step, we translate them into English with Google Translate and use English Natural Language Processing tools like Stanford Parser, Co-referencing, ClausIE, MinIE to extract useful triples from this text. Lastly, the triples are translated back to Vietnamese to build a Vietnam tourism knowledge graph. Since we are working with massive text, we develop a distributed algorithm to extract triples from sentences of massive text. This is a distributed version of MinIE, which was originally developed for a single machine model. In Apache Spark framework, we divide massive text into many smaller parts and move them to the worker nodes with distributed MinIE function. Spark distributed MinIE will extract the triples of sentences in the local text of this worker node in parallel. Finally, the result of worker nodes will be sent back to the master node for building the knowledge graph. We conduct experiments with the distributed MinIE on spark cluster to prove the outperformance of our proposed algorithm.
C1 [Do, Phuc; Phan, Trung; Le, Hung] Vietnam Natl Univ, Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Gupta, Brij B.] Natl Inst Technol, Kurukshetra, Haryana, India.
   [Gupta, Brij B.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Gupta, Brij B.] Staffordshire Univ, Stoke On Trent ST4 2DE, Staffs, England.
C3 Vietnam National University Hochiminh City; National Institute of Technology (NIT System); National Institute of Technology Kurukshetra; Asia University Taiwan; Staffordshire University
RP Gupta, BB (通讯作者)，Natl Inst Technol, Kurukshetra, Haryana, India.; Gupta, BB (通讯作者)，Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Gupta, BB (通讯作者)，Staffordshire Univ, Stoke On Trent ST4 2DE, Staffs, England.
EM phucdo@uit.edu.vn; trungphansg@gmail.com; hungle1abc@gmail.com; bbgupta@nitkkr.ac.in
FU Vietnam National University Ho Chi Minh City (VNU-HCMC) [DS2020-26-01]
CR Al-Ayyoub M, 2018, J COMPUT SCI-NETH, V26, P522, DOI 10.1016/j.jocs.2017.11.011
   Al-Qerem A, 2020, SOFT COMPUT, V24, P5695, DOI 10.1007/s00500-019-04220-y
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   [Anonymous], 2020, KNOWLEDGE GRAPH COOK, V0, P0
   ASTM International, 2019, C61819 ASTM INT, V0, P0
   Bhushan K, 2019, J AMB INTEL HUM COMP, V10, P1985, DOI 10.1007/s12652-018-0800-9
   Caroro RA, 2020, INT J SOFTW SCI COMP, V12, P34, DOI 10.4018/IJSSCI.2020040103
   del Corro L, 2013, P 22 INT C WORLD WID, V0, PP355, DOI 10.1145/2488388.2488420
   Do P, 2019, HDB RES CLOUD COMPUT, V0, P271
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Drabas DLTomasz, 2017, LEARNING PYSPARK, V0, P0
   Ehrlinger L, 2016, DEFINITION KNOWLEDGE, V0, P0
   Gavrilov Andrei Dmitri, 2018, INTERNATIONAL JOURNAL OF SOFTWARE SCIENCE AND COMPUTATIONAL INTELLIGENCE, V10, P19, DOI 10.4018/IJSSCI.2018100102
   Hossain K, 2019, INT J CLOUD APPL COM, V9, P43, DOI 10.4018/IJCAC.2019040103
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   Jadad HA, 2019, INT J CLOUD APPL COM, V9, P58, DOI 10.4018/IJCAC.2019070104
   Kejriwal Mayank, 2019, DOMAIN SPECIFIC KNOW, V0, P0, DOI DOI 10.1007/978-3-030-12375-8
   Lazib Lydia, 2019, INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING AND NETWORKING, V13, P211
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   RGLdC Kiril Gashteovski, 2017, P 2017 C EMP METH NA, V0, P0
   Suchanek F, 2007, P 16 INT C WORLD WID, V0, P0, DOI DOI 10.1145/1242572.1242667
   Talb D, 2017, INTRO NATURAL LANGUA, V0, P0
   Tanon TP, 2020, SEMANTIC WEB, V0, P0
   Wolf T, 1900, P38, V0, P0
   Yadav R, 2015, SPARK COOKBOOK, V0, P0
NR 26
TC 9
Z9 9
U1 3
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUN 15
PY 2022
VL 34
IS 11
BP 8393
EP 8409
DI 10.1007/s00521-020-05495-1
EA NOV 2020
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1O7GM
UT WOS:000592168200008
DA 2023-11-10
ER

PT J
AU Klemen, M
   Krsnik, L
   Robnik-Sikonja, M
AF Klemen, Matej
   Krsnik, Luka
   Robnik-Sikonja, Marko
TI Enhancing deep neural networks with morphological information
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Deep learning; Natural language processing; Morphologically rich languages; Transformers; Morphological additions
ID named entity recognition
AB Deep learning approaches are superior in natural language processing due to their ability to extract informative features and patterns from languages. The two most successful neural architectures are LSTM and transformers, used in large pretrained language models such as BERT. While cross-lingual approaches are on the rise, most current natural language processing techniques are designed and applied to English, and less-resourced languages are lagging behind. In morphologically rich languages, information is conveyed through morphology, for example, through affixes modifying stems of words. The existing neural approaches do not explicitly use the information on word morphology. We analyse the effect of adding morphological features to LSTM and BERT models. As a testbed, we use three tasks available in many less-resourced languages: named entity recognition (NER), dependency parsing (DP) and comment filtering (CF). We construct baselines involving LSTM and BERT models, which we adjust by adding additional input in the form of part of speech (POS) tags and universal features. We compare the models across several languages from different language families. Our results suggest that adding morphological features has mixed effects depending on the quality of features and the task. The features improve the performance of LSTM-based models on the NER and DP tasks, while they do not benefit the performance on the CF task. For BERT-based models, the added morphological features only improve the performance on DP when they are of high quality (i.e., manually checked) while not showing any practical improvement when they are predicted. Even for high-quality features, the improvements are less pronounced in language-specific BERT variants compared to massively multilingual BERT models. As in NER and CF datasets manually checked features are not available, we only experiment with predicted features and find that they do not cause any practical improvement in performance.
C1 [Klemen, Matej; Krsnik, Luka; Robnik-Sikonja, Marko] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
C3 University of Ljubljana
RP Klemen, M (通讯作者)，Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana, Slovenia.
EM matej.klemen@fri.uni-lj.si
FU European Union's Horizon 2020 Programme project EMBEDDIA (Cross-Lingual Embeddings for Less-Represented Languages in European News Media) [825153]; Slovene Research Agency [P6-0411]; Ministry of Culture of the Republic of Slovenia through project Development of Slovene in Digital Environment (RSDO)
CR Anderson M, 2020, P 24 C COMPUTATIONAL, V0, P69
   [Anonymous], 1908, BIOMETRIKA, V6, P1
   [Anonymous], 2006, 100 STAT TESTS, V0, P0, DOI DOI 10.4135/9781849208499
   [Anonymous], 2017, P CONLL 2017 SHARED, V0, P0
   [Anonymous], 2016, ARXIV160306270, V0, P0
   Arkhipov M, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP2019), V0, P89
   Ballesteros M, 2015, P 2015 C EMP METH NA, V0, PP349, DOI 10.18653/V1/D15-1041
   Benajiba Y, 2007, LECT NOTES COMPUT SC, V4394, P143
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Chen DD, 2014, J ANAL METHODS CHEM, V2014, P0, DOI 10.1155/2014/575246
   Collobert R, 2008, P 25 INT C MACH LEAR, V0, PP160, DOI 10.1145/1390156.1390177
   Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126
   Devlin J, 2018, ARXIV, V1, P4171
   Dozat T, 2016, INCORPORATING NESTER, V0, P2013
   Dozat T, 2017, P CONLL 2017 SHARED, V0, PP20, DOI 10.18653/V1/K17-3002
   Edmiston Daniel, 2020, ARXIV200403032, V0, P0
   Elazar Y, 2021, T ASSOC COMPUT LING, V9, P160, DOI 10.1162/tacl_a_00359
   Evkoski B, 2021, PLOS ONE, V16, P0, DOI 10.1371/journal.pone.0256175
   Farahani M, 2021, NEURAL PROCESS LETT, V53, P3831, DOI 10.1007/s11063-021-10528-4
   Fortuna P, 2018, ACM COMPUT SURV, V51, P0, DOI 10.1145/3232676
   Gao L, 2017, INT C REC ADV NAT LA, V0, PP260, DOI 10.26615/978-954-452-049-6-036
   Georgakopoulos SV, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), V0, P0, DOI DOI 10.1145/3200947.3208069
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Grünewaid S, 2021, IWPT 2021: THE 17TH INTERNATIONAL CONFERENCE ON PARSING TECHNOLOGIES: PROCEEDINGS OF THE CONFERENCE (INCLUDING THE IWPT 2021 SHARED TASK), V0, P131
   Güngör O, 2019, NAT LANG ENG, V25, P147, DOI 10.1017/S1351324918000281
   Hajic Jan, 2017, P CONLL 2017 SHAR TA, V0, P0
   Han J, 2019, PROC 13 INT WORKSHOP, V0, P652
   Houquan Zhou, 2020, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 9TH CCF INTERNATIONAL CONFERENCE, V0, P179, DOI 10.1007/978-3-030-60450-9_15
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/685404
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3651
   Ji T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2475
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kapociute-Dzikiene J, 2013, P 4 WORKSH STAT PARS, V0, P12
   Khallash M, 2013, P 4 WORKSH STAT PARS, V0, P97
   Kiperwasser E, 2016, T ASS COMPUTATIONAL, V4, P313, DOI 10.1162/TACL_A_00101
   Kondratyuk D, 2019, EMNLP, V0, P2779
   Krek Simon, 2019, TRAINING CORPUS SSJ5, V0, P0
   Kulmizev A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2755
   Kuratov Y, 2019, COMPUT LINGUIST, V0, P0
   Kuru O, 2016, P COLING 2016 26 INT, V0, P911
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Levow G, 2006, P 5 SIGHAN WORKSH CH, V0, P108
   Li Z, 2018, P 27 INT C COMP LING, V0, P3203
   Lim K, 2018, P CONLL 2018 SHAR TA, V0, PP143, DOI 10.18653/v1/K18-2014
   Lim K, 2020, AAAI CONF ARTIF INTE, V34, P8344
   Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, P241
   Nguyen LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), V0, P1
   Ljubesic N, 2018, TRAINING CORPUS HR50, V0, P0
   Malmasi S, 2017, P INT C RECENT ADV N, V0, PP467, DOI 10.26615/978-954-452-049-6-062
   Martin JH, 2009, SPEECH LANGUAGE PROC, V0, P0
   Marton Y, 2010, P 1 WORKSH STAT PARS, V0, P13
   McDonald R, 2005, P C HUM LANG TECHN E, V0, PP523, DOI 10.3115/1220575.1220641
   Mikhailov V, 2021, P 3 WORKSH COMP TYP, V0, PP97, DOI 10.18653/v1/2021.sigtyp-1.10
   Miok Kristian, 2019, STATISTICAL LANGUAGE AND SPEECH PROCESSING. 7TH INTERNATIONAL CONFERENCE, V0, P286, DOI 10.1007/978-3-030-31372-2_24
   Mohseni M, 2019, P 1 INT WORKSHOP NLP, V0, P23
   Moon J, 2020, P 8 INT WORKSH NAT L, V0, P25
   Nemeskey DM, 2021, 17 C HUNG COMP LING, V0, P0
   Nguyen DQ, 2018, P CONLL 2018 SHARED, V0, PP81, DOI 10.18653/V1/K18-2008
   Nivre J, 2003, P 8 INT C PARS TECHN, V0, P149
   Nivre J, 2020, UNIVERSAL DEPENDENCI, V0, P0
   Ozates SB, 2018, P CONLL SHAR TASK MU, V0, PP238, DOI 10.18653/v1/K18-2024
   Paikens P, 2012, FRONT ARTIF INTEL AP, V247, P169, DOI 10.3233/978-1-61499-133-5-169
   Pei WZ, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P313
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P101
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Ruokolainen T, 2020, LANG RESOUR EVAL, V54, P247, DOI 10.1007/s10579-019-09471-7
   Safaya A, 2020, P 14 WORKSH SEM EV, V0, P2054
   Sang Erik FTjong Kim, 2003, P 7 C NATURAL LANGUA, V4, P142
   Santos CN, 2015, P NEWS 2015 5 NAM EN, V0, PP25, DOI 10.18653/V1/W15-3904
   Scheffler T, 2018, 14 C NAT LANG PROC K, V6, P8
   SEDDAH D, 2010, P NAACL HLT 2010 1 W, V0, P0
   Seeker Wolfgang, 2011, P 12 INT C PARS TECH, V0, P58
   Seker A, 2021, ARXIV210404052, V0, P0
   Shtovba S, 2019, CEUR WORKSHOP P, V2353, P313
   Simeonova L, 2019, P INT C REC ADV NAT, V0, P1104
   Starostin A, 2016, ANN INT C DIAL, V0, P0
   Straka Milan, 2018, P CONLL 2018 SHARED, V0, PP197, DOI 10.18653/V1/K18-2020
   Straková J, 2016, LECT NOTES ARTIF INT, V9924, P173, DOI 10.1007/978-3-319-45510-5_20
   Taghizadeh N, 2019, P 1 INT WORKSHOP NLP, V0, P9
   Tanvir H, 2021, NODALIDA 2021, V0, P11
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Tkachenko A, 2013, P 4 BIENNIAL INT WOR, V0, P78
   Ulcar M, 2020, LECT NOTES ARTIF INT, V12284, P104, DOI 10.1007/978-3-030-58323-1_11
   Uskudarli S, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Van Hee Cynthia, 2015, P INT C REC ADV NAT, V0, P672
   Vania C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2573
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Virtanen A, 2019, ARXIV191207076, V0, P0
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wilcoxon F, 1970, SELECTED TABLES MATH, V1, P171
   Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1391, DOI 10.1145/3038912.3052591
   Yamada H, 2003, P 8 INT WORKSH PARS, V0, P195
   Zampieri M, 2019, P 13 INT WORKSHOP SE, V0, PP75, DOI 10.18653/V1/S19-2010
   Zampieri M, 2020, P 14 WORKSHOP SEMANT, V0, P1425
   Zhou J, 2020, P FINDINGS ASS COMPU, V0, P4450
NR 96
TC 0
Z9 0
U1 5
U2 10
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324922000080
EA FEB 2022
PG 26
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA ZD9HB
UT WOS:000758504100001
DA 2023-11-10
ER

PT J
AU Mehra, P
   Verma, SK
AF Mehra, Pramod
   Verma, Shashi Kant
TI BERIS: An mBERT-based Emotion Recognition Algorithm from Indian Speech
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE mBERT; emotion recognition; MFCC; LPC; Pitch
ID sentiment analysis; language; system; identification; transformer; performance; extraction
AB Emotions, the building blocks of the human intellect, play a vital role in Artificial Intelligence (AI). For a robust AI-based machine, it is important that the machine understands human emotions. COVID-19 has introduced the world to no-touch intelligent systems. With an influx of users, it is critical to create devices that can communicate in a local dialect. A multilingual system is required in countries like India, which has a large population and a diverse range of languages. Given the importance of multilingual emotion recognition, this research introduces BERIS, an Indian language emotion detection system. From the Indian sound recording, BERIS estimates both acoustic and textual characteristics. To extract the textual features, we used Multilingual Bidirectional Encoder Representations from Transformers. For acoustics, BERIS computes the Mel Frequency Cepstral Coefficients and Linear Prediction coefficients, and Pitch. The features extracted are merged in a linear array. Since the dialogues are of varied lengths, the data are normalized to have arrays of equal length. Finally, we split the data into training and validated set to construct a predictive model. The model can predict emotions from the new input. On all the datasets presented, quantitative and qualitative evaluations show that the proposed algorithm outperforms state-of-the-art approaches.
C1 [Mehra, Pramod] Uttarakhand Tech Univ, PO Chandanwadi, Dehra Dun 248001, Uttarakhand, India.
   [Verma, Shashi Kant] GB Pant Engn Coll, Pauri Garhwal 246194, Uttarakhand, India.
C3 Uttarakhand Technical University
RP Mehra, P (通讯作者)，Uttarakhand Tech Univ, PO Chandanwadi, Dehra Dun 248001, Uttarakhand, India.
EM pamodmehra11@gmail.com; skverma.gbpec@rediffmail.com
CR Aarti B, 2018, SADHANA-ACAD P ENG S, V43, P0, DOI 10.1007/s12046-018-0841-y
   Agrawal A, 2020, J INTERDISCIP MATH, V23, P311, DOI 10.1080/09720502.2020.1721926
   Ajibola Alim S, 2018, NATURAL ARTIFICIAL I, V0, P0, DOI DOI 10.5772/intechopen.80419
   [Anonymous], 2011, P 6 C SPEECH TECHNOL, V0, P0, DOI DOI 10.1109/SPED.2011.5940729
   Aouani Hadhami, 2020, PROCEDIA COMPUTER SCIENCE, V176, P251, DOI 10.1016/j.procs.2020.08.027
   Ashrafi I, 2020, IEEE ACCESS, V8, P58206, DOI 10.1109/ACCESS.2020.2982427
   Babasaheb D, 2015, INT J COMPUT APPL, V125, P2, DOI 10.1.1.695.8629
   Bansal S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), V0, P1865
   Ben Letaifa L, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP2020), V0, P0, DOI DOI 10.1109/atsip49331.2020.9231766
   Benlahbib A, 2020, IEEE ACCESS, V8, P96550, DOI 10.1109/ACCESS.2020.2996805
   Bharti Deepak, 2020, 2020 INTERNATIONAL CONFERENCE ON SMART ELECTRONICS AND COMMUNICATION (ICOSEC), V0, PP491, DOI 10.1109/ICOSEC49089.2020.9215376
   Billa J, 2018, INTERSPEECH, V0, PP3207, DOI 10.21437/Interspeech.2018-2473
   Bisio I, 2013, IEEE T EMERG TOP COM, V1, P244, DOI 10.1109/TETC.2013.2274797
   Chadha AN, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1669, DOI 10.1109/ICCSP.2016.7754447
   Chaloupka J, 2012, ELMAR PROC, V0, P223
   Chandran A, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P676, DOI 10.1109/ICACCI.2017.8125919
   Chen DM, 2020, IEEE ACCESS, V8, P213232, DOI 10.1109/ACCESS.2020.3041605
   Cummins N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP478, DOI 10.1145/3123266.3123371
   Das A, 2020, IEEE ACCESS, V8, P181432, DOI 10.1109/ACCESS.2020.3028241
   Fang M, 2019, P INT C LEARN REPR I, V0, PP1, DOI 10.1109/ICSIDP47821.2019.9172986
   Garg K, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P2098, DOI 10.1109/ICACCI.2016.7732361
   Gill AS, 2016, INT J ENG COMPUT SCI, V5, P18551
   Gogoi S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), V0, PP32, DOI 10.1109/ICCMC.2017.8282709
   Govind D, 2017, P INT C ADV COMPUTIN, V0, P0
   Hao X, 2020, INTERSPEECH, V0, PP2687, DOI 10.21437/Interspeech.2020-1539
   Hou JQ, 2020, IEEE ACCESS, V8, P225088, DOI 10.1109/ACCESS.2020.3042672
   Hou JQ, 2020, IEEE ACCESS, V8, P132367, DOI 10.1109/ACCESS.2020.3002863
   ITAKURA F, 1975, J ACOUST SOC AM, V57, PS35, DOI 10.1121/1.1995189
   Jiang D, 2020, IEEE ACCESS, V8, P162004, DOI 10.1109/ACCESS.2020.3019500
   Karim F, 2019, IEEE ACCESS, V7, P67718, DOI 10.1109/ACCESS.2019.2916828
   Lakomkin E, 2019, IEEE INT CONF ROBOT, V0, PP7976, DOI 10.1109/ICRA.2019.8794468
   Li XL, 2020, IEEE ACCESS, V8, P128042, DOI 10.1109/ACCESS.2020.3009012
   Liu Z, 2020, IEEE ACCESS, V8, P184036, DOI 10.1109/ACCESS.2020.3027622
   Londhe ND, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P780, DOI 10.1109/ICCSP.2016.7754251
   Luo YL, 2020, IEEE ACCESS, V8, P46007, DOI 10.1109/ACCESS.2020.2978163
   Minsky M, 2007, EMOTION MACHINE COMM, V0, P0
   Minsky M, 1986, SOC MIND, V0, P0
   Mohammadi M, 2021, 2020 28 EUR SIGN PRO, V0, PP1, DOI 10.1109/IC- CIA52082.2021.9403587
   Mullah HU, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ADVANCED COMPUTING AND COMMUNICATION (ISACC), V0, PP124, DOI 10.1109/ISACC.2015.7377327
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Nath S, 2018, MACHINE IDENTIFICATI, V0, P0
   Patil A, 2019, J INFORM OPTIM SCI, V40, P1731, DOI 10.1080/02522667.2019.1703266
   Polasi PK, 2016, INT J SPEECH TECHNOL, V19, P75, DOI 10.1007/s10772-015-9326-0
   Pulugundla B, 2018, INTERSPEECH, V0, PP3182, DOI 10.21437/Interspeech.2018-1302
   Rajisha TM, 2016, PROC TECH, V24, P1097, DOI 10.1016/j.protcy.2016.05.242
   Reddy MG, 2015, P INT C COMPUTER COM, V0, PP1, DOI 10.1109/IC4.2015.7375669
   Shrawankar U, 2010, INT C COMPUT ENG APP, V0, PP358, DOI 10.1109/ICCEA.2010.76
   Singh Jaspreet, 2019, 2019 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), V0, P202
   Sirsa H, 2013, J PHONETICS, V41, P393, DOI 10.1016/j.wocn.2013.07.004
   Sowmya V, 2020, MACHINE INTELLIGENCE AND SIGNAL PROCESSING. PROCEEDINGS OF INTERNATIONAL CONFERENCE, V0, P125, DOI 10.1007/978-981-15-1366-4_10
   Strengers Y, 2021, SMART WIFE WHY SIRI, V0, P0
   Su MH, 2020, IEEE-ACM T AUDIO SPE, V28, P2061, DOI 10.1109/TASLP.2020.3006731
   Tang TC, 2020, IEEE ACCESS, V8, P193248, DOI 10.1109/ACCESS.2020.3030468
   Vijayendra AD, 2016, PROCEDIA COMPUT SCI, V93, P668, DOI 10.1016/j.procs.2016.07.259
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang JR, 2016, MULTIMEDIA SYST, V22, P315, DOI 10.1007/s00530-015-0499-9
   Wang RY, 2020, IEEE ACCESS, V8, P135591, DOI 10.1109/ACCESS.2020.3011744
   Wang TY, 2020, IEEE ACCESS, V8, P138162, DOI 10.1109/ACCESS.2020.3012595
   Wu JF, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9163396
   Yang CL, 2019, PROC CVPR IEEE, V0, PP2854, DOI 10.1109/CVPR.2019.00297
   You FC, 2020, IEEE ACCESS, V8, P178946, DOI 10.1109/ACCESS.2020.2999665
   Zhou CR, 2020, IEEE ACCESS, V8, P214454, DOI 10.1109/ACCESS.2020.3040408
NR 62
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2022
VL 21
IS 5
BP 
EP 
DI 10.1145/3517195
PG 19
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9Z2DN
UT WOS:000950956700022
DA 2023-11-10
ER

PT J
AU Alotaibi, F
   Gupta, V
AF Alotaibi, Fahd
   Gupta, Vishal
TI Sentiment Analysis System using Hybrid Word Embeddings with Convolutional Recurrent Neural Network
SO INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY
LA English
DT Article
DE Analysis of sentiments; convolutional neural networks; part of speech tagging; natural language processing; word2Vec; GloVe; fastText; hybrid embedding; recurrent neural networks
AB There have been wide ranges of innovations in sentiment analysis in recent past, with most effective ones involving use of various word embeddings methods for analysis of sentiments. GloVe and Word2Vec are acclaimed to be two most frequently used. A common problem with simple pre-trained embedding methods is that these ignore information related to sentiments of input texts and further depend on large text corpus for training purpose and generation of relevant vectors which is hindrance to researches involving smaller sized corpuses. The aim of proposed study is to propose a novel methodology for sentiment analysis that uses hybrid embeddings with a target to enhance features of available pre-trained embedding. Proposed hybrid embeddings use Part of Speech (POS) tagging and word2position vector over fastText with varied assortments of attached vectors to the pre-trained embedding vectors. The resultant form of hybrid embeddings is fed to our ensemble network-Convolutional Recurrent Neural Network (CRNN). The methodology has been tested for accuracy via different Ensemble models of deep learning and standard sentiment dataset with accuracy value of 90.21 using Movie Review (MVR) Dataset V2. Results show that proposed methodology is effective for sentiment analysis and is capable of incorporating even more linguistic knowledge-based techniques to further improve results of sentiment analysis.
C1 [Alotaibi, Fahd] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
   [Gupta, Vishal] Panjab Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Chandigarh, India.
C3 King Abdulaziz University; Panjab University
RP Alotaibi, F (通讯作者)，King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
EM fsalotaibi@kau.edu.sa; vishal@pu.ac.in
FU Deanship of Scientific Research (DSR) , King Abdulaziz University Jeddah
CR Alghamdi N, 2019, P SAI INT SYST C, V0, P306
   Alqaraleh S, 2021, INT ARAB J INF TECHN, V18, P554, DOI 10.34028/18/4/7
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Deriu J, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1045, DOI 10.1145/3038912.3052611
   Fu XH, 2017, NEUROCOMPUTING, V241, P18, DOI 10.1016/j.neucom.2017.01.079
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   Joulin Armand, 2016, ARXIV160701759, V0, P0
   Khan FH, 2016, COGN COMPUT, V8, P614, DOI 10.1007/s12559-016-9386-8
   Kim Y, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/v1/D14-1181
   Lauren P, 2018, NEUROCOMPUTING, V277, P129, DOI 10.1016/j.neucom.2017.01.117
   Li Y, 2017, COGN COMPUT, V9, P843, DOI 10.1007/s12559-017-9492-2
   Ma YK, 2018, COGN COMPUT, V10, P639, DOI 10.1007/s12559-018-9549-x
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P52
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Qin PD, 2016, NEUROCOMPUTING, V190, P1, DOI 10.1016/j.neucom.2015.12.091
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Ren YF, 2016, AAAI CONF ARTIF INTE, V0, P3038
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Santos I, 2017, 2017 IEEE LATIN AMERICAN CONFERENCE ON COMPUTATIONAL INTELLIGENCE (LA-CCI), V0, P0
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP959, DOI 10.1145/2766462.2767830
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Zhang HL, 2014, 2014 11TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), V0, PP262, DOI 10.1109/WISA.2014.55
NR 25
TC 2
Z9 2
U1 2
U2 13
PU ZARKA PRIVATE UNIV
PI ZARQA
PA COLL COMPUTING & INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN
SN 1683-3198
EI 
J9 INT ARAB J INF TECHN
JI Int. Arab J. Inf. Technol.
PD MAY 15
PY 2022
VL 19
IS 3
BP 330
EP 335
DI 10.34028/iajit/19/3/6
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1O2XV
UT WOS:000801202800006
DA 2023-11-10
ER

PT J
AU Gomez, MJ
   Calderón, M
   Sánchez, V
   Clemente, FJG
   Ruipérez-Valiente, JA
AF Gomez, Manuel J.
   Calderon, Mario
   Sanchez, Victor
   Clemente, Felix J. Garcia
   Ruiperez-Valiente, Jose A.
TI Large scale analysis of open MOOC reviews to support learners' course selection
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Massive Open Online Courses; Natural language processing; Sentiment analysis; Recommendation systems; Online education
ID online courses; course recommendation; challenges; system
AB The recent pandemic has changed the way we see education. During recent years, Massive Open Online Course (MOOC) providers, such as Coursera or edX, are reporting millions of new users signing up on their platforms. Though online review systems are standard among many verticals, no standardized or fully decentralized review systems exist in the MOOC ecosystem. In this vein, we believe that there is an opportunity to leverage available open MOOC reviews in order to build simpler and more transparent reviewing systems, allowing users to really identify the best courses out there. Specifically, in our research we analyze 2.4 million reviews (which is the largest MOOC reviews dataset used until now) from five different platforms in order to determine the following: (1) if the numeric ratings provide discriminant information to learners, (2) if NLP-driven sentiment analysis on textual reviews could provide valuable information to learners, (3) if we can leverage NLP-driven topic finding techniques to infer themes that could be important for learners, and (4) if we can use these models to effectively characterize MOOCs based on the open reviews. Results show that numeric ratings are clearly biased (63% of them are 5-star ratings), and the topic modeling reveals some interesting topics related with course advertisements, the real applicability, or the difficulty of the different courses.
C1 [Gomez, Manuel J.; Clemente, Felix J. Garcia; Ruiperez-Valiente, Jose A.] Univ Murcia, Calle Campus Univ, E-30100 Murcia, Spain.
   [Calderon, Mario; Sanchez, Victor] SkillMapper, 6 Rue Steinkerque, F-75018 Paris, France.
C3 University of Murcia
RP Gomez, MJ (通讯作者)，Univ Murcia, Calle Campus Univ, E-30100 Murcia, Spain.
EM manueljesus.gomezm@um.es; mano@skillinapper.com; victor@skillmapper.com; fgarcia@um.es; jruiperez@um.es
CR Aher Sunita B, 2014, JOURNAL OF THE INSTITUTION OF ENGINEERS (INDIA) SERIES B (ELECTRICAL, V0, P0
   Aher SB, 2012, INT J COMPUTER APPL, V40, P1
   Al-Badarenah A, 2016, INT J ADV COMPUT SC, V7, P166
   Al-Rahmi W, 2019, DATA BRIEF, V22, P118, DOI 10.1016/j.dib.2018.11.139
   Al-Rahmi WM, 2018, COMPUT EDUC, V121, P59, DOI 10.1016/j.compedu.2018.02.010
   Bartolomé A, 2015, COMUNICAR, V22, P91, DOI 10.3916/C44-2015-10
   Bezerra L, 2017, REV ESPACIOS, V38, P0
   Bhattacharjee J, 2018, FASTTEXT QUICK START, V0, P0
   BILLINGTON P, 2013, J HIGHER ED THEORY P, V13, P36
   Briedis H, 2020, ADAPTING NEXT NORMAL, V0, P0
   Castillo NM, 2015, INF TECHNOL INT DEV, V11, P35
   Central C, 2021, CLASS CENTR, V0, P0
   Chang HM, 2016, IEEE INT CONF ADV LE, V0, PP23, DOI 10.1109/ICALT.2016.42
   Chen XL, 2020, LECT NOTES COMPUT SC, V12115, P73, DOI 10.1007/978-3-030-59413-8_6
   Coursera, 2021, IMP REP 2021 SERV WO, V0, P0
   Coursera, 2021, INTR NEW TOOLS FEAT, V0, P0
   Danino R, 2021, CREHANA, V0, P0
   Deng RQ, 2021, INT J EDUC TECHNOL H, V18, P0, DOI 10.1186/s41239-021-00244-3
   Dhawan Shivangi, 2020, JOURNAL OF EDUCATIONAL TECHNOLOGY SYSTEMS, V49, P5, DOI 10.1177/0047239520934018
   Ebert C, 2009, IEEE SOFTWARE, V26, P88, DOI 10.1109/MS.2009.144
   Elbagir Shihab, 2019, INTERNATIONAL MULTICONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS 2019 (IMECS 2019). PROCEEDINGS. LECTURE NOTES IN ENGINEERING AND COMPUTER SCIENCE, V0, P12
   Gamage D, 2016, 24 INT C ED, V0, P0
   Graham S, 2012, GETTING STARTED TOPI, V0, P0
   Gutl C, 2014, LEARNING TECHNOLOGY, V0, P0, DOI DOI 10.1007/978-3-319-10671-7_4
   Hew KF, 2014, EDUC RES REV-NETH, V12, P45, DOI 10.1016/j.edurev.2014.05.001
   Huang L, 2019, IEEE ACCESS, V7, P19550, DOI 10.1109/ACCESS.2019.2897979
   Jobe W, 2014, P SITE 2014 SOC INF, V0, P1580
   Kapadia Sh, 2019, EVALUATE TOPIC MODEL, V0, P0
   Kapoor N, 2020, 5 INT C COMMUNICATIO, V0, PP883, DOI 10.1109/ICCES48766.2020.9137993
   Khalid A, 2020, INT REV RES OPEN DIS, V21, P255
   Khalil, 2014, EDMEDIA INNOVATE LEA, V0, PP1236, DOI 10.1007/S11575-006-0100-Z
   Knoos J, 2021, SENTIMENT ANAL MOOC, V0, P0
   Kouzis-Loukas D, 2016, LEARNING SCRAPY, V0, P0
   Lan M, 2020, INT J EDUC TECHNOL H, V17, P0, DOI 10.1186/s41239-020-0179-5
   Li LY, 2022, COMPUT EDUC, V176, P0, DOI 10.1016/j.compedu.2021.104354
   Liyanagunawardena TR, 2014, DROPOUT MOOC PARTICI, V0, P0
   Lohr S, 2020, NEW YORK TIMES, V0, P26
   Loria Steven, 2018, TEXTBLOB DOCUMENTATI, V0, P0, DOI DOI 10.1109/ICDM.2008.94
   Melé D, 2017, J BUS ETHICS, V140, P609, DOI 10.1007/s10551-016-3328-y
   OCallaghan D, 2015, EXPERT SYST APPL, V42, P5645, DOI 10.1016/j.eswa.2015.02.055
   Ouertani HC, 2017, LECT N EDUC TECHNOL, V0, PP137, DOI 10.1007/978-981-10-2419-1_20
   Pappano L, 2012, NEW YORK TIMES, V0, P0
   Platzi, 2021, PLATZI, V0, P0
   Purkayastha N, 2021, LIB PHILOS PRACT, V0, PP1, DOI 10.2139/ssrn.3978886
   Qi C, 2021, IEEE ACCESS, V9, P35439, DOI 10.1109/ACCESS.2021.3062052
   Röder M, 2015, WSDM15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP399, DOI 10.1145/2684822.2685324
   Rowan N, 2021, WHAT IS DOMESTIKA, V0, P0
   Saxton MD, 2018, THEOLOGICAL LIB, V11, P18, DOI 10.31046/TL.V11I1.506
   Scheibehenne B, 2010, J CONSUM RES, V37, P409, DOI 10.1086/651235
   Shah D, 2021, NUMBERS MOOCS 2020, V0, P0
   SkillMapper, 2022, DID YOU PAY ONL COUR, V0, P0
   Terras MM, 2015, BRIT J EDUC TECHNOL, V46, P472, DOI 10.1111/bjet.12274
   Terry-Jack M, 2019, NLP PRETRAINED SENTI, V0, P0
   Udemy, 2021, US, V0, P0
   van der Aalst W, 2016, PROCESS MINING DATA, V0, P0, DOI DOI 10.1007/978-3-662-49851-4
   Vanitha V, 2019, COMPUT ELECTR ENG, V77, P325, DOI 10.1016/j.compeleceng.2019.06.016
   Wen M, 2014, P ED DATA MINING, V0, P130
   Yao LM, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P937
   Zhang H, 2018, MULTIMED TOOLS APPL, V77, P7051, DOI 10.1007/s11042-017-4620-2
NR 59
TC 4
Z9 4
U1 23
U2 37
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 30
PY 2022
VL 210
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118400
EA AUG 2022
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 4R5OZ
UT WOS:000856814500004
DA 2023-11-10
ER

PT J
AU Zhou, KY
   Yang, JK
   Loy, CC
   Liu, ZW
AF Zhou, Kaiyang
   Yang, Jingkang
   Loy, Chen Change
   Liu, Ziwei
TI Learning to Prompt for Vision-Language Models
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article
AB Large pre-trained vision-language models like CLIP have shown great potential in learning representations that are transferable across a wide range of downstream tasks. Different from the traditional representation learning that is based mostly on discretized labels, vision-language pre-training aligns images and texts in a common feature space, which allows zero-shot transfer to a downstream task via prompting, i.e., classification weights are synthesized from natural language describing classes of interest. In this work, we show that a major challenge for deploying such models in practice is prompt engineering, which requires domain expertise and is extremely time-consuming-one needs to spend a significant amount of time on words tuning since a slight change in wording could have a huge impact on performance. Inspired by recent advances in prompt learning research in natural language processing (NLP), we propose Context Optimization (CoOp), a simple approach specifically for adapting CLIP-like vision-language models for downstream image recognition. Concretely, CoOp models a prompt's context words with learnable vectors while the entire pre-trained parameters are kept fixed. To handle different image recognition tasks, we provide two implementations of CoOp: unified context and class-specific context. Through extensive experiments on 11 datasets, we demonstrate that CoOp requires as few as one or two shots to beat hand-crafted prompts with a decent margin and is able to gain significant improvements over prompt engineering with more shots, e.g., with 16 shots the average gain is around 15% (with the highest reaching over 45%). Despite being a learning-based approach, CoOp achieves superb domain generalization performance compared with the zero-shot model using hand-crafted prompts.
C1 [Zhou, Kaiyang; Yang, Jingkang; Loy, Chen Change; Liu, Ziwei] Nanyang Technol Univ, S Lab, Singapore, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Zhou, KY (通讯作者)，Nanyang Technol Univ, S Lab, Singapore, Singapore.
EM kaiyang.zhou@ntu.edu.sg; jingkang001@ntu.edu.sg; ccloy@ntu.edu.sg; ziwei.liu@ntu.edu.sg
FU RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative
CR Ba JL, 2015, IEEE I CONF COMP VIS, V0, PP4247, DOI 10.1109/ICCV.2015.483
   Bommasani R, 2021, ARXIV, V0, P0
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Cimpoi M, 2014, PROC CVPR IEEE, V0, PP3606, DOI 10.1109/CVPR.2014.461
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Desai K, 2021, PROC CVPR IEEE, V0, PP11157, DOI 10.1109/CVPR46437.2021.01101
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, V0, PP2584, DOI 10.1109/ICCV.2013.321
   Frome Andrea, 2013, ADV NEURAL INFORM PR, V26, P2
   Furst A, 2021, ARXIV, V0, P0
   Gao P, 2021, ARXIV, V0, P0
   Gao T, 2020, ARXIV, V0, P0
   Gomez L, 2017, PROC CVPR IEEE, V0, PP2017, DOI 10.1109/CVPR.2017.218
   He Kaiming, 2020, P IEEE CVF C COMP VI, V0, PP9729, DOI 10.1109/CVPR42600.2020.00975
   Helber Patrick, 2019, IEEE J SELECTED TOPI, V0, P0, DOI DOI 10.1109/JSTARS.2019.2918242
   Henaff Olivier, 2020, PR MACH LEARN RES, V0, PP4182, DOI 10.5555/3524938.3525329
   Hendrycks D, 2021, PROC CVPR IEEE, V0, PP15257, DOI 10.1109/CVPR46437.2021.01501
   Hendrycks Dan, 2021, ICCV, V0, P0
   Jia C, 2021, PR MACH LEARN RES, V139, P0
   Jia M, 2022, ARXIV, V0, P0
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Joulin A, 2016, LECT NOTES COMPUT SC, V9911, P67, DOI 10.1007/978-3-319-46478-7_5
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), V0, PP554, DOI 10.1109/ICCVW.2013.77
   Lester B, 2021, ARXIV, V0, P0
   Li A, 2017, IEEE I CONF COMP VIS, V0, PP4193, DOI 10.1109/ICCV.2017.449
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li X, 2021, ARXIV, V0, P0
   Li Y, 2021, ARXIV, V0, P0
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Maji S, 2013, ARXIV, V0, P0
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   PARKHI OM, 2012, PROC CVPR IEEE, V0, PP3498, DOI 10.1109/CVPR.2012.6248092
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Radford A, 2021, PR MACH LEARN RES, V139, P0
   Recht B, 2019, PR MACH LEARN RES, V97, P0
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P4222
   Singh A, 2021, ARXIV, V0, P0
   Socher R, 2013, ADV NEURAL INFORM PR, V26, P0
   Soomro Khurram, 2012, ARXIV12120402, V0, P0
   Taori Rohan, 2020, ADV NEURAL INF PROCE, V33, P18583
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Dequan, 2021, INT C LEARN REPR, V0, P0
   Wang HH, 2019, ADV NEUR IN, V32, P0
   Xiao JX, 2010, PROC CVPR IEEE, V0, PP3485, DOI 10.1109/CVPR.2010.5539970
   Yuan L, 2021, ARXIV, V0, P0
   Yuan Tian, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP71, DOI 10.1007/978-3-030-58568-6_5
   Zhang Y, 2020, ARXIV, V0, P0
   Zhong Z, 2021, NAACL, V0, P0
   Zhou K, 2022, ARXIV, V0, P0
   Zhou K, 2021, ARXIV, V0, P0
NR 55
TC 53
Z9 54
U1 17
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD SEP 15
PY 2022
VL 130
IS 9
BP 2337
EP 2348
DI 10.1007/s11263-022-01653-1
EA JUL 2022
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 3T2LG
UT WOS:000833995900001
DA 2023-11-10
ER

PT J
AU Karthik, E
   Sethukarasi, T
AF Karthik, E.
   Sethukarasi, T.
TI A Centered Convolutional Restricted Boltzmann Machine Optimized by Hybrid Atom Search Arithmetic Optimization Algorithm for Sentimental Analysis
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Sentiment analysis; Social media; Hybrid optimization; Centered convolutional restricted Boltzmann machines; User behavioral analysis
ID neural-network
AB Sentiment analysis uses natural language processing (NLP) to track online conversations and uncover additional information about a subject, business, or theme. Existing machine-learning algorithms are accurate and perform well, but they struggle to reduce computational time and cope with the noisy and high-dimensional feature space of social media data. To resolve these concerns, this paper introduced a Centered Convolutional Restricted Boltzmann Machines (CCRBM), a revolutionary deep learning technique for user behavioral sentimental analysis. The DBN architecture is mainly selected in this work due to its ability to extract in-depth sentimental features, dimensionality reduction, and higher classification accuracy. However, the improper parameter setting can lead to non-convergence, large randomness, and weak generalization capability. To tackle this issue, this work proposes a Hybrid Atom Search Arithmetic Optimization (HASAO) approach, which optimizes DBN parameters such as batch size and decay rate while minimizing DBN issues such as randomness and instability. The performance of the proposed model is analyzed by comparing it with different baseline models and the accuracy value above 90% for the nine datasets proves the efficiency of the proposed technique. When compared to the existing techniques, the proposed methodology offers improved accuracy and speedup capacity.
C1 [Karthik, E.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Ramapuram Campus, Chennai 600089, Tamil Nadu, India.
   [Sethukarasi, T.] RMK Engn Coll, Dept Comp Sci & Engn, Kavaraipettai, India.
C3 SRM Institute of Science & Technology Chennai; R.M.K. Engineering College
RP Karthik, E (通讯作者)，SRM Inst Sci & Technol, Dept Comp Sci & Engn, Ramapuram Campus, Chennai 600089, Tamil Nadu, India.
EM ekarthik.phd@gmail.com
CR Abdalgader K, 2020, IEEE ACCESS, V8, P179955, DOI 10.1109/ACCESS.2020.3028260
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, P0, DOI 10.1016/j.cma.2020.113609
   Alam M, 2020, COMPUT COMMUN, V154, P129, DOI 10.1016/j.comcom.2020.02.044
   Alhalabi W, 2021, FUTURE GENER COMP SY, V116, P132, DOI 10.1016/j.future.2020.10.027
   Alharbi ASM, 2019, COGN SYST RES, V54, P50, DOI 10.1016/j.cogsys.2018.10.001
   [Anonymous], 2020, DEMOGRAPHICS SOCIAL, V0, P0
   [Anonymous], 2009, SCHOLARPEDIA, V0, P0
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   Baumgartner J, 2020, INT AAAI ASS ADV ART, V0, PP830, DOI 10.1609/ICWSM.V14I1.7347
   Chen L, 2019, INT J HUM-COMPUT ST, V121, P4, DOI 10.1016/j.ijhcs.2017.09.005
   Es-Sabery F, 2021, IEEE ACCESS, V9, P17943, DOI 10.1109/ACCESS.2021.3053917
   Feng S, 2021, IEEE T INTELL TRANSP, V22, P5635, DOI 10.1109/TITS.2020.2988309
   Gao JY, 2016, NEUROCOMPUTING, V214, P708, DOI 10.1016/j.neucom.2016.06.055
   Goh CK, 2008, IEEE T NEURAL NETWOR, V19, P1531, DOI 10.1109/TNN.2008.2000444
   Ji Y, 2020, KNOWL-BASED SYST, V203, P0, DOI 10.1016/j.knosys.2020.106091
   Jose J, 2021, BIOMED SIGNAL PROCES, V66, P0, DOI 10.1016/j.bspc.2021.102480
   Karthik E, 2022, J SUPERCOMPUT, V78, P5333, DOI 10.1007/s11227-021-04028-4
   Li D, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102290
   Mukherjee S, 2017, TECHNOL SOC, V48, P19, DOI 10.1016/j.techsoc.2016.10.003
   N L, 2019, IMDB DATASET 50K MOV, V0, P0
   Papa JP, 2015, J COMPUT SCI-NETH, V9, P14, DOI 10.1016/j.jocs.2015.04.014
   Perikos I, 2021, KNOWL-BASED SYST, V229, P0, DOI 10.1016/j.knosys.2021.107332
   Rana S, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), V0, PP106, DOI 10.1109/NGCT.2016.7877399
   Salakhutdinov R, 2009, ARTIF INTELL, V5, P448, DOI 10.1109/CVPRW.2009.5206577
   Srinivasa-Desikan B, 2018, NATURAL LANGUAGE PRO, V0, P0
   Trupthi M, 2017, IEEE INT ADV COMPUT, V0, PP915, DOI 10.1109/IACC.2017.0186
   Vashishtha S, 2019, EXPERT SYST APPL, V138, P0, DOI 10.1016/j.eswa.2019.112834
   Vinu S, 2016, INT J INTELL ENG SYS, V9, P117, DOI 10.22266/IJIES2016.0930.12
   Yelp I, 2020, YELP DATASET, V0, P0
   Yoo S, 2018, EXPERT SYST APPL, V105, P102, DOI 10.1016/j.eswa.2018.03.055
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
   Zhang Y, 2021, NEUROCOMPUTING, V462, P101, DOI 10.1016/j.neucom.2021.07.072
   Zhao JH, 2020, PATTERN RECOGN LETT, V138, P397, DOI 10.1016/j.patrec.2020.07.035
   Zhao WG, 2019, KNOWL-BASED SYST, V163, P283, DOI 10.1016/j.knosys.2018.08.030
   Zhao WG, 2019, FUTURE GENER COMP SY, V91, P601, DOI 10.1016/j.future.2018.05.037
NR 35
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD OCT 15
PY 2022
VL 54
IS 5
BP 4123
EP 4151
DI 10.1007/s11063-022-10797-7
EA APR 2022
PG 29
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5Q5YI
UT WOS:000777065000001
DA 2023-11-10
ER

PT J
AU Uddin, MZ
   Dysthe, KK
   Folstad, A
   Brandtzaeg, PB
AF Uddin, Md Zia
   Dysthe, Kim Kristoffer
   Folstad, Asbjorn
   Brandtzaeg, Petter Bae
TI Deep learning for prediction of depressive symptoms in a large textual dataset
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Prediction; Depression; LSTM; RNN; Text; AI; XAI
ID emotion recognition; model
AB Depression is a common illness worldwide with potentially severe implications. Early identification of depressive symptoms is a crucial first step towards assessment, intervention, and relapse prevention. With an increase in data sets with relevance for depression, and the advancement of machine learning, there is a potential to develop intelligent systems to detect symptoms of depression in written material. This work proposes an efficient approach using Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) to identify texts describing self-perceived symptoms of depression. The approach is applied on a large dataset from a public online information channel for young people in Norway. The dataset consists of youth's own text-based questions on this information channel. Features are then provided from a one-hot process on robust features extracted from the reflection of possible symptoms of depression pre-defined by medical and psychological experts. The features are better than conventional approaches, which are mostly based on the word frequencies (i.e., some topmost frequent words are chosen as features from the whole text dataset and applied to model the underlying events in any text message) rather than symptoms. Then, a deep learning approach is applied (i.e., RNN) to train the time-sequential features discriminating texts describing depression symptoms from posts with no such descriptions (non-depression posts). Finally, the trained RNN is used to automatically predict depression posts. The system is compared against conventional approaches where it achieved superior performance than others. The linear discriminant space clearly reveals the robustness of the features by generating better clustering than other traditional features. Besides, since the features are based on the possible symptoms of depression, the system may generate meaningful explanations of the decision from machine learning models using an explainable Artificial Intelligence (XAI) algorithm called Local Interpretable Model-Agnostic Explanations (LIME). The proposed depression symptom feature-based approach shows superior performance compared to the traditional general word frequency-based approaches where frequency of the features gets more importance than the specific symptoms of depression. Although the proposed approach is applied on a Norwegian dataset, a similar robust approach can be applied on other depression datasets developed in other languages with proper annotations and symptom-based feature extraction. Thus, the depression prediction approach can be adopted to contribute to develop better mental health care technologies such as intelligent chatbots.
C1 [Uddin, Md Zia; Folstad, Asbjorn; Brandtzaeg, Petter Bae] SINTEF Digital, Oslo, Norway.
   [Dysthe, Kim Kristoffer; Brandtzaeg, Petter Bae] Univ Oslo, Oslo, Norway.
C3 SINTEF; University of Oslo
RP Uddin, MZ (通讯作者)，SINTEF Digital, Oslo, Norway.
EM zia.uddin@sintef.no; k.k.dysthe@medisin.uio.no; asf@sintef.no
FU Research Council of Norway [262848]
CR Allouch M, 1900, P1, V0, P0
   Baines T, 2013, J CLIN PSYCHOL MED S, V20, P263, DOI 10.1007/s10880-012-9337-9
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Cohen JR, 2019, CHILD PSYCHIAT HUM D, V50, P647, DOI 10.1007/s10578-019-00869-6
   Coyne JC, 2001, PSYCHOL ASSESSMENT, V13, P163, DOI 10.1037//1040-3590.13.2.163
   Deboeverie F, 2016, IEEE CONF COMPU INTE, V0, P0
   Depression W, 2017, OTH COMM MENT DIS GL, V0, P1
   Desmet B, 2013, EXPERT SYST APPL, V40, P6351, DOI 10.1016/j.eswa.2013.05.050
   Ding Y, 2020, IEEE ACCESS, V8, P75616, DOI 10.1109/ACCESS.2020.2987523
   Dong YZ, 2021, NEUROCOMPUTING, V441, P279, DOI 10.1016/j.neucom.2021.02.019
   Fortino G, 2015, INFORM FUSION, V22, P50, DOI 10.1016/j.inffus.2014.03.005
   Fortino G, 2014, FUTURE GENER COMP SY, V35, P62, DOI 10.1016/j.future.2013.12.015
   Fusar-Poli P, 2014, SCHIZOPHRENIA BULL, V40, P120, DOI 10.1093/schbul/sbs136
   Gardner-Lubbe S, 2021, J APPL STAT, V48, P1917, DOI 10.1080/02664763.2020.1780569
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Govindasamy KA, 2021, 2021 5 INT C INT COM, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Häfner H, 2005, EUR ARCH PSY CLIN N, V255, P167, DOI 10.1007/s00406-005-0584-8
   Hassan MM, 2019, INFORM FUSION, V51, P10, DOI 10.1016/j.inffus.2018.10.009
   Havigerová JM, 2019, FRONT PSYCHOL, V10, P0, DOI 10.3389/fpsyg.2019.00513
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   John Short, 1976, SOCIAL PSYCHOL TELEC, V0, P0
   Kessler RC, 2013, ANNU REV PUBL HEALTH, V34, P119, DOI 10.1146/annurev-publhealth-031912-114409
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Kumari T, 2020, ARTIF INTELL, V0, PP199, DOI 10.1201/9780367854737-12
   Liu PD, 2021, IEEE T FUZZY SYST, V29, P2565, DOI 10.1109/TFUZZ.2020.3003501
   Picard RW, 2003, INT J HUM-COMPUT ST, V59, P55, DOI 10.1016/S1071-5819(03)00052-1
   Sak H, 2014, INTERSPEECH, V0, P338
   Sim AYL, 2018, IEEE DATA MINING, V0, PP1236, DOI 10.1109/ICDM.2018.00165
   Strapparava C, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1556
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314
   Uddin MZ, 2019, INT SYM MED INFORM, V0, PP1, DOI 10.1109/ismict.2019.8743759
   Uddin MZ, 2020, INFORM FUSION, V55, P105, DOI 10.1016/j.inffus.2019.08.004
   Vannatta RA, 2020, SAGE RES METHODS FDN, V0, P0, DOI DOI 10.4135/9781526421036889610
   Wang N, 2014, SOC INDIC RES, V115, P483, DOI 10.1007/s11205-012-9996-9
   Wang R, 2021, IEEE J BIOMED HEALTH, V25, P4289, DOI 10.1109/JBHI.2021.3076762
   Wang SF, 2021, IEEE T AFFECT COMPUT, V12, P821, DOI 10.1109/TAFFC.2019.2900240
   Weinberger AH, 2018, PSYCHOL MED, V48, P1308, DOI 10.1017/S0033291717002781
   World Health Organization, 2017, DEPR OTH COMM MENT D, V0, P0
   Yang H, 2012, BIOMED INFORM INSIGH, V5, P17, DOI 10.4137/BII.S8948
   Yildirim E, 2018, ZBORNIK RADOVA GEOEX, V0, P0
   Yuan XF, 2021, IEEE T IND ELECTRON, V68, P4404, DOI 10.1109/TIE.2020.2984443
   Zaremba W, 2014, PREPRINT, V0, P0
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
NR 47
TC 18
Z9 18
U1 5
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JAN 15
PY 2022
VL 34
IS 1
BP 721
EP 744
DI 10.1007/s00521-021-06426-4
EA AUG 2021
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YE3WM
UT WOS:000690372700002
DA 2023-11-10
ER

PT J
AU Cerda, P
   Varoquaux, G
AF Cerda, Patricio
   Varoquaux, Gael
TI Encoding High-Cardinality String Categorical Variables
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Encoding; Statistical analysis; Cleaning; Semantics; Natural language processing; Data models; Machine learning; Statistical learning; string categorical variables; autoML; interpretable machine learning; large-scale data; min-hash; Gamma-Poisson factorization
ID algorithms
AB Statistical models usually require vector representations of categorical variables, using for instance one-hot encoding. This strategy breaks down when the number of categories grows, as it creates high-dimensional feature vectors. Additionally, for string entries, one-hot encoding does not capture morphological information in their representation. Here, we seek low-dimensional encoding of high-cardinality string categorical variables. Ideally, these should be: scalable to many categories; interpretable to end users; and facilitate statistical analysis. We introduce two encoding approaches for string categories: a Gamma-Poisson matrix factorizationon substring counts, and a min-hash encoder, for fast approximation of string similarities. We show that min-hash turns set inclusions into inequality relations that are easier to learn. Both approaches are scalable and streamable. Experiments on real and simulated data show that these methods improve supervised learning with high-cardinality categorical variables. We recommend the following: if scalability is central, the min-hash encoder is the best option as it does not require any data fit; if interpretability is important, the Gamma-Poisson factorization is the best alternative, as it can be interpreted as one-hot encoding on inferred categories with informative feature names. Both models enable autoML on string entries as they remove the need for feature engineering or data cleaning.
C1 [Cerda, Patricio; Varoquaux, Gael] INRIA, Parietal Team, F-78150 Rocquencourt, France.
C3 Inria
RP Cerda, P (通讯作者)，INRIA, Parietal Team, F-78150 Rocquencourt, France.
EM patriciocerdareyes@gmail.com; gael.varoquaux@normalesup.org
FU [ANR-17-CE230018-01]
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   Altmann A, 2010, BIOINFORMATICS, V26, P1340, DOI 10.1093/bioinformatics/btq134
   ANGELL RC, 1983, INFORM PROCESS MANAG, V19, P255, DOI 10.1016/0306-4573(83)90022-5
   Appleby A, 2014, MURMURHASH3, V0, P0
   Arora S, 2017, P 5 INT C LEARN REPR, V152, P107
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Bottou L, 2008, ADV NEURAL INFORM PR, V20, P161, DOI 10.7751/mitpress/8996.003.0015
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, V0, PP21, DOI 10.1109/SEQUEN.1997.666900
   Broder AZ, 2000, J COMPUT SYST SCI, V60, P630, DOI 10.1006/jcss.1999.1690
   Canny J, 2004, PROCEEDINGS OF SHEFFIELD SIGIR 2004. THE TWENTY-SEVENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP122, DOI 10.1145/1008992.1009016
   Cerda P, 2018, MACH LEARN, V107, P1477, DOI 10.1007/s10994-018-5724-2
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Christen P, 2012, DATA MATCHING CONCEP, V0, P0
   Chum O, 2008, BMVC, V810, P812, DOI 10.5244/C.22.50
   Cohen J, 2013, APPL MULTIPLE REGRES, V0, P0, DOI DOI 10.4324/9780203774441
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Devlin J, 2018, ARXIV, V1, P4171
   Dua D, 2017, UCI MACHINE LEARNING, V0, P0
   Elmagarmid AK, 2007, IEEE T KNOWL DATA EN, V19, P1, DOI 10.1109/TKDE.2007.250581
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, V0, P518
   Gomaa WH, 2013, INT J COMPUTER APPL, V68, P0, DOI 10.5120/11638-7118
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Hutter F, 2019, SPRING SER CHALLENGE, V0, PP1, DOI 10.1007/978-3-030-05318-5
   Hutter F, 2015, P ICML WORKSH RES EF, V0, P1
   Ji JQ, 2013, IEEE DATA MINING, V0, PP301, DOI 10.1109/ICDM.2013.119
   Johnson William B, 1984, CONTEMP MATH-SINGAP, V26, P1, DOI 10.1090/CONM/026/737400
   Kim W, 2003, DATA MIN KNOWL DISC, V7, P81, DOI 10.1023/A:1021564703268
   Klein D, 2003, P 7 C NAT LANG LEARN, V0, PP180, DOI 10.3115/1119176.1119204
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lefèvre A, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), V0, PP313, DOI 10.1109/ASPAA.2011.6082314
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, V0, P1
   Lu JH, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2975, DOI 10.1145/3357384.3360319
   Micci-Barreca D, 2001, ACM SIGKDD EXPLORATI, V3, P27, DOI 10.1145/507533.507538
   Mikolov T, 2013, ARXIV13013781 CS, V0, P0, DOI DOI 10.48550/ARXIV.1301.3781
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P52
   NEMENYI P, 1962, BIOMETRICS, V18, P263
   Oliveira P, 2005, P 2005 INT C INF QUA, V0, P1
   Olsony RS, 2018, BIOCOMPUT-PAC SYM, V0, P192
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Prokhorenkova L, 2018, ADV NEUR IN, V31, P0
   Pyle D, 1999, DATA PREPARATION DAT, V0, P0
   Rahimi Ali, 2007, ADV NEURAL INFORM PR, V20, P4, DOI 10.5555/2981562.2981710
   Rahm E, 2000, IEEE DATA ENG B, V23, P3
   Shrivastava Anshumali, 2012, MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES. PROCEEDINGS OF THE EUROPEAN CONFERENCE (ECML PKDD 2012), V0, PP474, DOI 10.1007/978-3-642-33460-3_36
   Vinh NX, 2010, J MACH LEARN RES, V11, P2837
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Weinberger K, 2009, INT C MACH LEARN ICM, V0, P0, DOI DOI 10.1145/1553374.1553516
   Winkler WE, 2006, OVERVIEW RECORD LINK, V0, P0
NR 50
TC 29
Z9 29
U1 4
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD MAR 1
PY 2022
VL 34
IS 3
BP 1164
EP 1176
DI 10.1109/TKDE.2020.2992529
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA YU4KL
UT WOS:000752013800011
DA 2023-11-10
ER

PT J
AU Sinclair, A
   Jumelet, J
   Zuidema, W
   Fernández, R
AF Sinclair, Arabella
   Jumelet, Jaap
   Zuidema, Willem
   Fernandez, Raquel
TI Structural Persistence in Language Models: Priming as a Window into Abstract Language Representations
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
ID syntactic structure; neural-networks; corpus; comprehension; alignment
AB We investigate the extent to which modern neural language models are susceptible to structural priming, the phenomenon whereby the structure of a sentence makes the same structure more probable in a follow-up sentence. We explore how priming can be used to study the potential of these models to learn abstract structural information, which is a prerequisite for good performance on tasks that require natural language understanding skills. We introduce a novel metric and release Prime-LM, a large corpus where we control for various linguistic factors that interact with priming strength. We find that Transformer models indeed show evidence of structural priming, but also that the generalizations they learned are to some extent modulated by semantic information. Our experiments also show that the representations acquired by the models may not only encode abstract sequential structure but involve certain level of hierarchical syntactic information. More generally, our study shows that the priming paradigm is a useful, additional tool for gaining insights into the capacities of language models and opens the door to future priming-based investigations that probe the model's internal states.(1)
C1 [Sinclair, Arabella] Univ Aberdeen, Sch Nat & Comp Sci, Aberdeen, Scotland.
   [Sinclair, Arabella; Jumelet, Jaap; Zuidema, Willem; Fernandez, Raquel] Univ Amsterdam, Inst Log Language & Computat, Amsterdam, Netherlands.
C3 University of Aberdeen; University of Amsterdam
RP Sinclair, A (通讯作者)，Univ Aberdeen, Sch Nat & Comp Sci, Aberdeen, Scotland.; Sinclair, A (通讯作者)，Univ Amsterdam, Inst Log Language & Computat, Amsterdam, Netherlands.
EM arabella.sinclair@abdn.ac.uk; j.w.d.jumelet@uva.nl; zuidema@uva.nl; raquel.fernandez@uva.nl
FU European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme [819455]
CR Alishahi A, 2019, NAT LANG ENG, V25, P543, DOI 10.1017/S135132491900024X
   Baroni Marco, 2022, ALGEBRAIC SYSTEMS RE, V0, P0
   Bernolet S, 2010, COGNITION, V114, P455, DOI 10.1016/j.cognition.2009.11.005
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   BOCK K, 1989, COGNITION, V31, P163, DOI 10.1016/0010-0277(89)90022-X
   Bock K, 2000, J EXP PSYCHOL GEN, V129, P177, DOI 10.1037//0096-3445.129.2.177
   Bock K, 2007, COGNITION, V104, P437, DOI 10.1016/j.cognition.2006.07.003
   Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303
   Branigan HP, 2006, LANG COGNITIVE PROC, V21, P974, DOI 10.1080/016909600824609
   Branigan HP, 1999, PSYCHON B REV, V6, P635, DOI 10.3758/BF03212972
   Bresnan Joan, 2007, COGNITIVE FDN INTERP, V0, P69
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Chang F, 2000, J PSYCHOLINGUIST RES, V29, P217, DOI 10.1023/A:1005101313330
   Chomsky N, 1957, SYNTACTIC STRUCTURES, V0, P0, DOI DOI 10.1515/9783112316009
   Cleland AA, 2003, J MEM LANG, V49, P214, DOI 10.1016/S0749-596X(03)00060-3
   Cochran, 1977, SAMPLING TECHNIQUES, V0, P0
   Davies M, 2009, INT J CORPUS LINGUIS, V14, P159, DOI 10.1075/ijcl.14.2.02dav
   Davis Forrest, 2020, P 24 C COMPUTATIONAL, V0, PP396, DOI 10.18653/v1/2020.conll-1.32
   Devlin J, 2018, ARXIV, V1, P4171
   Dubey A, 2008, COGNITION, V109, P326, DOI 10.1016/j.cognition.2008.09.006
   Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298
   Fine AB, 2013, COGNITIVE SCI, V37, P578, DOI 10.1111/cogs.12022
   Foster Mary Ellen, 2007, P 11 EUROPEAN WORKSH, V0, PP33, DOI 10.3115/1610163.1610170
   Fu ZH, 2021, AAAI CONF ARTIF INTE, V35, P12848
   Futrell R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P32
   Gauthier J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P70
   Goldwater MB, 2011, COGNITIVE SCI, V35, P156, DOI 10.1111/j.1551-6709.2010.01150.x
   Gries ST, 2005, J PSYCHOLINGUIST RES, V34, P365, DOI 10.1007/s10936-005-6139-3
   Gulordava K, 2018, P 2018 C N AM CHAPT, V1, P1195, DOI 10.18653/V1/N18-1108
   Hessel J, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P204
   Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129
   Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1725
   Hupkes D, 2018, J ARTIF INTELL RES, V61, P907, DOI 10.1613/jair.1.11196
   Ivanova I, 2017, LANG COGN NEUROSCI, V32, P175, DOI 10.1080/23273798.2016.1236976
   Ivanova I, 2012, COGNITION, V122, P193, DOI 10.1016/j.cognition.2011.10.013
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013
   Jeffreys H, 1961, THEORY PROBABILITY, V3rd, P0
   Jozefowicz R, 2016, ARXIV, V0, P0
   Jumelet J, 2021, FINDINGS ASS COMPUTA, V0, PP4958, DOI 10.18653/V1/2021.FINDINGS-ACL.439
   Jumelet Jaap, 2020, P 3 BLACKBOXNLP WORK, V0, PP342, DOI 10.18653/v1/2020.blackboxnlp-1.32
   Kaschak MP, 2011, PSYCHON B REV, V18, P1133, DOI 10.3758/s13423-011-0157-y
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Kassner N, 2020, PROC 58 ANN M ASS CO, V0, PP7811, DOI 10.18653/v1/2020.acl-main.698
   Kodner J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P1757
   Kutuzov Andrei, 2017, P 21 NORDIC C COMPUT, V0, P271
   Lakretz Y, 2021, COGNITION, V213, P0, DOI 10.1016/j.cognition.2021.104699
   Lakretz Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P11
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Li B, 2022, LONG PAPERS, V0, PP7410, DOI 10.18653/V1/2022.ACL-LONG.512
   Linzen T, 2016, T ASSOC COMPUT LING, V4, P521, DOI 10.1353/LAN.2019.0015
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Lovering Charles, 2021, INT C LEARN REPR, V0, P0
   Mahowald K, 2016, J MEM LANG, V91, P5, DOI 10.1016/j.jml.2016.03.009
   Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1192
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   Merriam-Webster Inc, 1989, WEBSTERS DICT ENGLIS, V0, P0
   Nelson DL, 2004, BEHAV RES METH INS C, V36, P402, DOI 10.3758/BF03195588
   Newman B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P3710
   Pham Thang, 2021, FINDINGS ASS COMPUTA, V0, PP1145, DOI 10.18653/V1/2021.FINDINGS-ACL.98
   Pickering MJ, 2008, PSYCHOL BULL, V134, P427, DOI 10.1037/0033-2909.134.3.427
   Pickering MJ, 2013, J EXP PSYCHOL LEARN, V39, P890, DOI 10.1037/a0029181
   Pickering MJ, 1998, J MEM LANG, V39, P633, DOI 10.1006/jmla.1998.2592
   Prasad, 2019, P 23 C COMP NAT LANG, V0, PP66, DOI 10.18653/v1/k19-1007
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reitter D, 2014, J MEM LANG, V76, P29, DOI 10.1016/j.jml.2014.05.008
   Reitter D, 2011, COGNITIVE SCI, V35, P587, DOI 10.1111/j.1551-6709.2010.01165.x
   Reitter David, 2007, P 29 ANN M COGNITIVE, V0, P0
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2699
   Sanh Victor, 2019, P 5 WORKSHOP ENERGY, V0, P0
   Scheepers C, 2003, COGNITION, V89, P179, DOI 10.1016/S0010-0277(03)00119-7
   Schrimpf M, 2020, BIORXIV, V0, P0, DOI DOI 10.1101/2020.06.26.174482
   Segaert K, 2016, J MEM LANG, V91, P59, DOI 10.1016/j.jml.2016.03.011
   Sid Black, 2021, GITHUB REPOSITORY, V0, P0, DOI DOI 10.18653/v1/2022.bigscience-1.9
   Sinha K, 2021, P 59 ANN M ASS COMPU, V1, P7329, DOI 10.18653/V1/2021.ACL-LONG.569
   Sinha K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P2888
   Tayyar Madabushi H, 2020, P 28 INT C COMP LING, V0, PP4020, DOI 10.18653/V1/2020.COLING-MAIN.355
   Tenney I, 2019, P 7 INT C LEARNING R, V0, P0
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4593
   Tooley KM, 2014, COGNITION, V132, P101, DOI 10.1016/j.cognition.2014.04.002
   Tree JEF, 1999, J PSYCHOLINGUIST RES, V28, P71, DOI 10.1023/A:1023239604158
   Vamvas Jannis, 2021, P 4 BLACKBOXNLP WORK, V0, PP58, DOI 10.18653/v1/2021.blackboxnlp-1.5
   van Schijndel M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4704
   Vaswani A, 2017, ARXIV, V30, P5998
   Voita E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P183
   Warstadt A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2877
   Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321
   Wheeldon LR, 2003, LANG COGNITIVE PROC, V18, P431, DOI 10.1080/01690960244000063
   White JC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P132
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, V0, P270
NR 91
TC 1
Z9 1
U1 4
U2 4
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD SEP 19
PY 2022
VL 10
IS 
BP 1031
EP 1050
DI 10.1162/tacl_a_00504
PG 20
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9OO
UT WOS:000923422400003
DA 2023-11-10
ER

PT J
AU Linder, J
   La Fleur, A
   Chen, ZB
   Ljubetic, A
   Baker, D
   Kannan, S
   Seelig, G
AF Linder, Johannes
   La Fleur, Alyssa
   Chen, Zibo
   Ljubetic, Ajasja
   Baker, David
   Kannan, Sreeram
   Seelig, Georg
TI Interpreting neural networks for biological sequences by learning stochastic masks
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
ID alternative polyadenylation; glycine residues; deep; prediction; variants; mutation; gene
AB Neural networks have become a useful approach for predicting biological function from large-scale DNA and protein sequence data; however, researchers are often unable to understand which features in an input sequence are important for a given model, making it difficult to explain predictions in terms of known biology. The authors introduce scrambler networks, a feature attribution method tailor-made for discrete sequence inputs. Sequence-based neural networks can learn to make accurate predictions from large biological datasets, but model interpretation remains challenging. Many existing feature attribution methods are optimized for continuous rather than discrete input patterns and assess individual feature importance in isolation, making them ill-suited for interpreting nonlinear interactions in molecular sequences. Here, building on work in computer vision and natural language processing, we developed an approach based on deep learning-scrambler networks-wherein the most important sequence positions are identified with learned input masks. Scramblers learn to predict position-specific scoring matrices where unimportant nucleotides or residues are scrambled by raising their entropy. We apply scramblers to interpret the effects of genetic variants, uncover nonlinear interactions between cis-regulatory elements, explain binding specificity for protein-protein interactions, and identify structural determinants of de novo-designed proteins. We show that scramblers enable efficient attribution across large datasets and result in high-quality explanations, often outperforming state-of-the-art methods.
C1 [Linder, Johannes; La Fleur, Alyssa; Seelig, Georg] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
   [Chen, Zibo; Ljubetic, Ajasja; Baker, David] Univ Washington, Inst Prot Design, Seattle, WA 98195 USA.
   [Kannan, Sreeram; Seelig, Georg] Univ Washington, Dept Elect & Comp Engn, Seattle, WA 98195 USA.
C3 University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle
RP Linder, J (通讯作者)，Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
EM jlinder2@cs.washington.edu
FU NIH [R21HG010945]; NSF [2021552, 1908003, 1703403]; Division of Computing and Communication Foundations; Direct For Computer & Info Scie & Enginr [1908003] Funding Source: National Science Foundation; Emerging Frontiers; Direct For Biological Sciences [2021552] Funding Source: National Science Foundation
CR Alford RF, 2017, J CHEM THEORY COMPUT, V13, P3031, DOI 10.1021/acs.jctc.7b00125
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   ALTAY C, 1991, HEMOGLOBIN, V15, P327, DOI 10.3109/03630269109027887
   Ancona Marco, 2018, ICLR, V0, P0
   Anishchenko I, 2021, NATURE, V600, P547, DOI 10.1038/s41586-021-04184-w
   Araujo PR, 2012, COMP FUNCT GENOM, V0, P0, DOI DOI 10.1155/2012/475731
   Arefeen A, 2019, BIOINFORMATICS, V35, P4577, DOI 10.1093/bioinformatics/btz283
   Avsec Z, 2021, NAT GENET, V53, P354, DOI 10.1038/s41588-021-00782-6
   Bogard N, 2019, CELL, V178, P91, DOI 10.1016/j.cell.2019.04.046
   Calvo SE, 2009, P NATL ACAD SCI USA, V106, P7507, DOI 10.1073/pnas.0810916106
   Carter B, 2019, PR MACH LEARN RES, V89, P567
   Carter B, 2020, J COMPUT BIOL, V27, P1219, DOI 10.1089/cmb.2019.0339
   Chang C-H, 2018, EXPLAINING IMAGE CLA, V0, P0
   Chaudhury S, 2010, BIOINFORMATICS, V26, P689, DOI 10.1093/bioinformatics/btq007
   Chen J, 2018, INT C MACHINE LEARNI, V80, P883
   Chen ZB, 2019, NATURE, V565, P106, DOI 10.1038/s41586-018-0802-y
   Cheng J, 2019, GENOME BIOL, V20, P0, DOI 10.1186/s13059-019-1653-z
   Chung J, 2017, ARXIV160901704, V0, P1
   COVERT I, 2021, J MACH LEARN RES, V22, P1
   Dabkowski P, 2017, ADV NEUR IN, V30, P0
   Danckwardt S, 2004, BLOOD, V104, P428, DOI 10.1182/blood-2003-08-2894
   Di Giammartino DC, 2011, MOL CELL, V43, P853, DOI 10.1016/j.molcel.2011.08.017
   Elkon R, 2013, NAT REV GENET, V14, P496, DOI 10.1038/nrg3482
   Eraslan G, 2019, NAT REV GENET, V20, P389, DOI 10.1038/s41576-019-0122-6
   Fong R, 2019, IEEE I CONF COMP VIS, V0, PP2950, DOI 10.1109/ICCV.2019.00304
   Fong RC, 2017, IEEE I CONF COMP VIS, V0, PP3449, DOI 10.1109/ICCV.2017.371
   Ford AS, 2020, PROTEIN SCI, V29, P43, DOI 10.1002/pro.3721
   Garin I, 2010, P NATL ACAD SCI USA, V107, P3105, DOI 10.1073/pnas.0910533107
   Guan WJ, 2020, EUR RESPIR J, V55, P0, DOI 10.1183/13993003.00597-2020
   Jaganathan K, 2019, CELL, V176, P535, DOI 10.1016/j.cell.2018.12.015
   Jang Eric, 2016, ARXIV161101144, V0, P0
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Kelley DR, 2018, GENOME RES, V28, P739, DOI 10.1101/gr.227819.117
   Kelley DR, 2016, GENOME RES, V26, P990, DOI 10.1101/gr.200535.115
   Krieger F, 2005, J AM CHEM SOC, V127, P3346, DOI 10.1021/ja042798i
   Lanchantin J, 2017, BIOCOMPUT-PAC SYM, V0, PP254, DOI 10.1142/9789813207813_0025
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZX, 2022, GENOM PROTEOM BIOINF, V20, P483, DOI 10.1016/j.gpb.2020.05.004
   Linder J, 2021, BMC BIOINFORMATICS, V22, P0, DOI 10.1186/s12859-021-04437-5
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Maguire JB, 2018, J CHEM THEORY COMPUT, V14, P2751, DOI 10.1021/acs.jctc.8b00033
   Medina-Trillo C, 2016, EUR J HUM GENET, V24, P672, DOI 10.1038/ejhg.2015.169
   Movva R, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0218073
   Norn C, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2017228118
   Parrini C, 2005, STRUCTURE, V13, P1143, DOI 10.1016/j.str.2005.04.022
   Sample PJ, 2019, NAT BIOTECHNOL, V37, P803, DOI 10.1038/s41587-019-0164-5
   Schreiber J, 2020, LEDIDI DESIGNING GEN, V0, P0, DOI DOI 10.1101/2020.05.21.109686
   Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7
   Shi YS, 2012, RNA, V18, P2105, DOI 10.1261/rna.035899.112
   Shrikumar A, 2017, PR MACH LEARN RES, V70, P0
   Simonyan K, 2013, ARXIV13126034, V0, P0
   Singh M, 2018, PROC 22 ACM SIGKDD I, V0, P1135
   Singh S, 2019, QUANT BIOL, V7, P122, DOI 10.1007/s40484-019-0154-0
   Springenberg Jost Tobias, 2014, ARXIV14126806, V0, P0, DOI DOI 10.48550/ARXIV.1412.6806
   Stacey SN, 2011, NAT GENET, V43, P1098, DOI 10.1038/ng.926
   Sundararajan M, 2017, PR MACH LEARN RES, V70, P0
   Talukder A, 2021, BRIEF BIOINFORM, V22, P0, DOI 10.1093/bib/bbaa177
   Tian B, 2017, NAT REV MOL CELL BIO, V18, P18, DOI 10.1038/nrm.2016.116
   Whiffin N, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-019-10717-9
   Wylenzek M, 2001, THROMB HAEMOSTASIS, V85, P943
   Yang JY, 2020, P NATL ACAD SCI USA, V117, P1496, DOI 10.1073/pnas.1914677117
   Yoon JY, 2018, INT PSYCHOGERIATR, V30, P1519, DOI 10.1017/S1041610218000194
   Yoshio TD, 1997, MOL CELL BIOL, V17, P3907, DOI 10.1128/MCB.17.7.3907
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng WW, 2020, BIOINFORMATICS, V36, P496, DOI 10.1093/bioinformatics/btz562
   Zhou J, 2015, NAT METHODS, V12, P931, DOI 10.1038/nmeth.3547
   Zintgraf Luisa M, 2017, ICLR, V0, P0
NR 67
TC 4
Z9 4
U1 6
U2 32
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD JAN 15
PY 2022
VL 4
IS 1
BP 41
EP +
DI 10.1038/s42256-021-00428-6
EA JAN 2022
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA YQ3YR
UT WOS:000746785300005
PM 35966405
DA 2023-11-10
ER

PT J
AU Tian, YYS
   Wan, Y
   Lyu, LJ
   Yao, DZ
   Jin, H
   Sun, LC
AF Tian, Yuanyishu
   Wan, Yao
   Lyu, Lingjuan
   Yao, Dezhong
   Jin, Hai
   Sun, Lichao
TI FEDBERT: When Federated Learning Meets Pre-training
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE Federated learning; pre-training; BERT; NLP
AB The fast growth of pre-trained models (PTMs) has brought natural language processing to a new era, which has become a dominant technique for various natural language processing (NLP) applications. Every user can download the weights of PTMs, then fine-tune the weights for a task on the local side. However, the pre-training of a model relies heavily on accessing a large-scale of training data and requires a vast amount of computing resources. These strict requirements make it impossible for any single client to pre-train such a model. To grant clients with limited computing capability to participate in pre-training a large model, we propose a new learning approach, FEDBERT, that takes advantage of the federated learning and split learning approaches, resorting to pre-training BERT in a federated way. FEDBERT can prevent sharing the raw data information and obtain excellent performance. Extensive experiments on seven GLUE tasks demonstrate that FEDBERT can maintain its effectiveness without communicating to the sensitive local data of clients.
C1 [Tian, Yuanyishu; Wan, Yao; Yao, Dezhong; Jin, Hai] Huazhong Univ Sci & Technol, Serv Comp Technol & Syst Lab, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol,Cluster & Grid Comp Lab, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
   [Lyu, Lingjuan] Sony AI, Minato Ku, 1-7-1 Konan, Tokyo, Japan.
   [Sun, Lichao] Lehigh Univ, 113 Res Dr, Bethlehem, PA 18015 USA.
C3 Huazhong University of Science & Technology; Lehigh University
RP Yao, DZ (通讯作者)，Huazhong Univ Sci & Technol, Serv Comp Technol & Syst Lab, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol,Cluster & Grid Comp Lab, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.; Sun, LC (通讯作者)，Lehigh Univ, 113 Res Dr, Bethlehem, PA 18015 USA.
EM yystian@hust.edu.cn; wanyao@hust.edu.cn; Lingjuan.Lv@sony.com; dyao@hust.edu.cn; hjin@hust.edu.cn; lis221@lehigh.edu
FU National Natural Science Foundation of China [62102157]; Fundamental Research Funds for the Central Universities [HUST:2020kfyXJJS019]
CR Abedi Ali, 2020, ARXIV, V0, P0
   Abuadbba Sharif, 2020, ASIA CCS 20: PROCEEDINGS OF THE 15TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, V0, PP305, DOI 10.1145/3320269.3384740
   Beltagy I, 2019, ARXIV, V0, P0
   Bentivogli Luisa, 2009, P 2 TEXT AN C, V0, P0
   Bonawitz K, 2017, CCS17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, V0, PP1175, DOI 10.1145/3133956.3133982
   Bonawitz Keith, 2019, P MACH LEARN SYST, V1, P374
   Ceballos I, 2020, ARXIV, V0, P0
   Cer D, 2017, P 11 INT WORKSHOP SE, V0, PP1, DOI 10.18653/V1/S17-2001
   Clark Kevin, 2020, P INT C LEARNING REP, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Dolan B, 2005, 3 INT WORKSH PAR IWP, V0, P1
   Gao Y, 2020, ARXIV, V0, P0
   Ge S, 2020, ARXIV, V0, P0
   Geyer RC, 2017, ARXIV, V0, P0
   Gupta O, 2018, J NETW COMPUT APPL, V116, P1, DOI 10.1016/j.jnca.2018.05.003
   Hardy S, 2017, ARXIV, V0, P0
   He Chaoyang, 2020, ARXIV200713518, V0, P0
   HongyiWang Kartik Sreenivasan, 2020, P C ADV NEURAL INFOR, V0, P0
   Hsu Tzu-Ming Harry, 2020, PROC EUR C COMPUT VI, V0, PP76, DOI 10.1007/978-3-030-58607-25
   Jiang D, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP1071, DOI 10.1145/3357384.3357909
   Kairouz P, 2021, FOUND TRENDS MACH LE, V14, P1, DOI 10.1561/2200000083
   Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li LJ, 2019, IEEE I CONF COMP VIS, V0, PP10312, DOI 10.1109/ICCV.2019.01041
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Li X, 2019, ARXIV, V0, P0
   Liu QD, 2021, PROC CVPR IEEE, V0, PP1013, DOI 10.1109/CVPR46437.2021.00107
   Liu Y, 2020, AAAI CONF ARTIF INTE, V34, P13172
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Lu J, 2019, ARXIV, V0, P0
   Lyu L, 2020, IEEE IJCNN, V0, P1
   Lyu L, 2020, ARXIV, V0, P0
   Lyu Lingjuan, 2020, ABS200302133 CORR, V0, P0
   Matsubara Yoshitomo, 2020, ARXIV, V0, P0
   McMahan HB, 2018, P 6 INT C LEARNING R, V0, P0
   McMahan HB, 2016, ARXIV, V0, P0
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Melamud Oren, 2016, P 20 SIGNLL C COMP N, V0, PP51, DOI 10.18653/V1/K16-1006
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Peng H, 2021, ARXIV, V0, P0
   Peng H, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, P1416, DOI 10.1145/3459637.3482252
   Peng H, 2022, IEEE T COMPUT, V71, P628, DOI 10.1109/TC.2021.3057082
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rieke N, 2020, NPJ DIGIT MED, V3, P0, DOI 10.1038/s41746-020-00323-1
   Seif Mohamed, 2020, ARXIV, V0, P0
   Sennrich R, 2015, ARXIV, V0, P0
   Singh A, 2019, ARXIV, V0, P0
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Song K, 2019, ARXIV, V0, P0
   Sun C, 2019, IEEE I CONF COMP VIS, V0, PP7463, DOI 10.1109/ICCV.2019.00756
   Sun L, 2021, ARXIV, V0, PP3436, DOI 10.18653/v1/2020.coling-main.305
   Sun Y, 2019, ARXIV, V0, P0
   Thapa C, 2020, ARXIV, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vepakomma P, 2018, ARXIV, V0, P0
   Wang A, 2019, ICLR 19, V0, P0
   Wang Hongyi, 2020, ARXIV200206440, V0, P0
   Wang J, 2021, ARXIV, V0, P0
   Wang Y, 2019, ARXIV, V0, P0
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Xu XH, 2022, IEEE T IND INFORM, V18, P4788, DOI 10.1109/TII.2021.3113708
   Yang D, 2021, MED IMAGE ANAL, V70, P0, DOI 10.1016/j.media.2021.101992
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3298981
   Yao D, 2021, ARXIV, V0, P0
   ZHANG Ke, 2021, P C ADV NEURAL INFOR, V0, P0
NR 69
TC 12
Z9 12
U1 8
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2157-6904
EI 2157-6912
J9 ACM T INTEL SYST TEC
JI ACM Trans. Intell. Syst. Technol.
PD AUG 15
PY 2022
VL 13
IS 4
BP 
EP 
DI 10.1145/3510033
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 4E7QL
UT WOS:000848016400015
DA 2023-11-10
ER

PT J
AU Xu, XQ
   Xie, JL
   Wang, HH
   Lin, MW
AF Xu, Xiuqin
   Xie, Jialiang
   Wang, Honghui
   Lin, Mingwei
TI Online education satisfaction assessment based on cloud model and fuzzy TOPSIS
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Online education; Satisfaction assessment; Cloud model; Fuzzy TOPSIS; Possibility degree matrix
ID group decision-making; linguistic term sets; algorithm; selection
AB During the COVID-19, colleges organized online education on a massive scale. To make better use of online education in the post-epidemic era, this paper conducts an online education satisfaction survey with four types of colleges and 129,325 students propose a fuzzy TOPSIS (technique for order preference by similarity to ideal solution) method based on the cloud model to rank the satisfaction of different colleges. Firstly, based on the characteristics of online education during the COVID-19, we build an evaluation indicator system from four dimensions: technology, instructor, learner and environment including, 10 indicators and 94 sub-indicators. Secondly, the cloud model is used to quantitatively describe the natural language and uncertainty in a large amount of assessment information. The cloud model generator is used for sub-indicators and achieves an effective and flexible conversion between linguistic information and quantitative values. The cloud model of indicators are presented by integrating the corresponding sub-indicators. The weights of indicators are determined by the entropy method based on the cloud model and possibility degree matrix, which eliminates the judgment of decision-makers and has great power for handling practical problems with unknown weight information. Finally, a fuzzy TOPSIS method based on the cloud model is proposed to rank the satisfaction of online education of different colleges. The proposed method is compared with other existing methods to shown its merits. The experimental result is consistent with the proportion of students who accept online education in the post-epidemic era. According to the second questionnaire, as the qualitative evaluation of the cloud model of indicators increases, the qualitative evaluation of satisfaction of different types of colleges will also increase. It indicates that the method proposed in this paper is practical.
C1 [Xu, Xiuqin; Xie, Jialiang; Wang, Honghui] Jimei Univ, Coll Sci, Xiamen 361021, Fujian, Peoples R China.
   [Xu, Xiuqin] Putian Univ, Coll Math & Finance, Putian 351100, Fujian, Peoples R China.
   [Lin, Mingwei] Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Fujian, Peoples R China.
C3 Jimei University; Putian University; Fujian Normal University
RP Xie, JL (通讯作者)，Jimei Univ, Coll Sci, Xiamen 361021, Fujian, Peoples R China.
EM xiejialiang@jmu.edu.cn
CR Abidah A, 2020, STUD PHILOS SCI ED, V1, P38, DOI 10.46627/sipose.v1i1.9
   Al-Fraihat D, 2020, COMPUT HUM BEHAV, V102, P67, DOI 10.1016/j.chb.2019.08.004
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   BELENSON SM, 1973, OPER RES QUART, V24, P65, DOI 10.2307/3008036
   Boran FE, 2009, EXPERT SYST APPL, V36, P11363, DOI 10.1016/j.eswa.2009.03.039
   Çalik A, 2021, SOFT COMPUT, V25, P2253, DOI 10.1007/s00500-020-05294-9
   Capuano N, 2018, INT J INTELL SYST, V33, P1555, DOI 10.1002/int.21997
   Capuano N, 2018, IEEE T FUZZY SYST, V26, P1704, DOI 10.1109/TFUZZ.2017.2744605
   Cevikcan E, 2009, J MULT-VALUED LOG S, V15, P181
   Chen CT, 2006, INT J PROD ECON, V102, P289, DOI 10.1016/j.ijpe.2005.03.009
   Chen CT, 2000, FUZZY SET SYST, V114, P1, DOI 10.1016/S0165-0114(97)00377-1
   Cheng S, 2021, IEEE T SYST MAN CY-S, V51, P6901, DOI 10.1109/TSMC.2020.2964282
   Deng ZP, 2021, IEEE T INTELL TRANSP, V22, P7155, DOI 10.1109/TITS.2020.3002455
   Du YX, 2020, CLIN PHARMACOL THER, V108, P242, DOI 10.1002/cpt.1844
   Garg R, 2019, IEEE T EDUC, V62, P11, DOI 10.1109/TE.2018.2814611
   Gay GHE, 2016, J COMPUT HIGH EDUC, V28, P199, DOI 10.1007/s12528-016-9115-z
   Guo P, 2020, MATHEMATICS-BASEL, V8, P0, DOI 10.3390/math8091491
   Huang C, 2020, KNOWL INF SYST, V62, P4373, DOI 10.1007/s10115-020-01491-y
   Jeong JS, 2020, HELIYON, V6, P0, DOI 10.1016/j.heliyon.2020.e04706
   Jung I, 2011, ETR&D-EDUC TECH RES, V59, P445, DOI 10.1007/s11423-010-9171-4
   Kiliç M, 2015, APPL SOFT COMPUT, V27, P399, DOI 10.1016/j.asoc.2014.11.028
   Lee TS, 2019, MATHEMATICS-BASEL, V7, P0, DOI 10.3390/math7100918
   Li D, 2007, ARTIF INTELL, V0, P0
   Li D, 1995, J COMPUT RES DEV, V32, P15
   Li DY, 1998, KNOWL-BASED SYST, V10, P431, DOI 10.1016/S0950-7051(98)00038-0
   Lin MW, 2020, ARTIF INTELL REV, V53, P3647, DOI 10.1007/s10462-019-09774-9
   Lin MW, 2019, NONLINEAR DYNAM, V96, P2125, DOI 10.1007/s11071-019-04910-0
   Lin MW, 2018, J OPER RES SOC, V69, P157, DOI 10.1057/s41274-017-0182-y
   Liu HC, 2015, SOFT COMPUT, V19, P1085, DOI 10.1007/s00500-014-1321-x
   Opricovic S, 1998, FACULTY CIVIL ENG BE, V2, P5
   Pang Q, 2016, INFORM SCIENCES, V369, P128, DOI 10.1016/j.ins.2016.06.021
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Peng HG, 2018, INT J HOSP MANAG, V68, P124, DOI 10.1016/j.ijhm.2017.10.001
   Peng HG, 2017, INT J SYST SCI, V48, P3316, DOI 10.1080/00207721.2017.1367433
   Regueras LM, 2009, IEEE T EDUC, V52, P279, DOI 10.1109/TE.2008.928198
   Rodríguez RM, 2012, IEEE T FUZZY SYST, V20, P109, DOI 10.1109/TFUZZ.2011.2170076
   ROY B, 1968, REV FR INFORM RECH O, V2, P57
   Saaty TL, 1985, CHAPTER 4 SYSTEMS CH, V0, P0
   Shoufan A, 2020, IEEE T EDUC, V63, P314, DOI 10.1109/TE.2020.2989921
   Sun PC, 2008, COMPUT EDUC, V50, P1183, DOI 10.1016/j.compedu.2006.11.007
   Sun Q, 2022, IEEE T FUZZY SYST, V30, P1287, DOI 10.1109/TFUZZ.2021.3057705
   Wang Hong-li, 2005, CONTROL AND DECISION, V20, P679
   Wang JQ, 2015, IEEE T FUZZY SYST, V23, P542, DOI 10.1109/TFUZZ.2014.2317500
   Wang JQ, 2015, GROUP DECIS NEGOT, V24, P171, DOI 10.1007/s10726-014-9385-7
   Wang Jian-qiang, 2012, CONTROL AND DECISION, V27, P1185
   Wang P, 2020, J INF PROCESS SYST, V16, P1169, DOI 10.3745/JIPS.01.0059
   Wang SL, 2019, CHINESE J ELECTRON, V28, P470, DOI 10.1049/cje.2018.09.020
   Wu J, 2021, INFORM FUSION, V67, P80, DOI 10.1016/j.inffus.2020.10.010
   Xu, 2019, FUZZY INFORM ENG, V1094, P107
   Xu QW, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0193576
   Xu ZS, 2001, J SYST ENG, V16, P311
   Yang WG, 2019, MATH PROBL ENG, V2019, P0, DOI 10.1155/2019/8761681
   Yoon K, 1981, MULTIPLE ATTRIBUTE D, V0, P0, DOI DOI 10.1007/978-3-642-48318-9
   Yue N, 2019, FUZZY INFORM ENG, V1094, P73
   Yue N, 2020, SOFT COMPUT, V24, P12131, DOI 10.1007/s00500-019-04651-7
   Yue N, 2020, FUZZY OPTIM DECIS MA, V19, P391, DOI 10.1007/s10700-020-09325-w
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang LH, 2019, J CLEAN PROD, V206, P1123, DOI 10.1016/j.jclepro.2018.09.059
   Zhao Kun, 2015, CONTROL AND DECISION, V30, P395, DOI 10.13195/j.kzyjc.2013.1773
   Zubascu, 2020, U LOCKDOWN GOOD BAD, V0, P0
NR 61
TC 5
Z9 5
U1 10
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD SEP 15
PY 2022
VL 52
IS 12
BP 13659
EP 13674
DI 10.1007/s10489-022-03289-7
EA MAR 2022
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5B4QI
UT WOS:000764963100003
PM 35280109
DA 2023-11-10
ER

PT J
AU Skvorc, T
   Gantar, P
   Robnik-Sikonja, M
AF Skvorc, Tadej
   Gantar, Polona
   Robnik-Sikonja, Marko
TI MICE: Mining Idioms with Contextual Embeddings
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Machine learning; Natural language processing; Idiomatic expressions; Word embeddings; Contextual embeddings; Cross-lingual transfer
AB Idiomatic expressions can be problematic for natural language processing applications as their meaning cannot be inferred from their constituting words. A lack of successful methodological approaches and sufficiently large datasets prevents the development of machine learning approaches for detecting idioms, especially for expressions that do not occur in the training set. We present an approach called MICE that uses contextual embeddings for that purpose. We present a new dataset of multi-word expressions with literal and idiomatic meanings and use it to train a classifier based on two state-of-the-art contextual word embeddings: ELMo and BERT. We show that deep neural networks using both embeddings perform much better than existing approaches and are capable of detecting idiomatic word use, even for expressions that were not present in the training set. We demonstrate the cross-lingual transfer of developed models and analyze the size of the required dataset. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Skvorc, Tadej; Robnik-Sikonja, Marko] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia.
   [Skvorc, Tadej] Jozef Stefan Inst, Jamova Cesta 39, Ljubljana 1000, Slovenia.
   [Gantar, Polona] Univ Ljubljana, Fac Arts, Ljubljana 1000, Slovenia.
C3 University of Ljubljana; Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute; University of Ljubljana
RP Skvorc, T (通讯作者)，Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia.
EM tadej.skvorc@fri.uni-lj.si; apolonija.gantar@guest.arnes.si; marko.robnik@fri.uni-lj.si
CR [Anonymous], 2015, DEEP LEARNING NAT, V0, P0
   Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288
   Berk G, 2018, P JOINT WORKSH LING, V0, P248
   Bojanowski P, 2017, T ASSOC COMPUT LING, V5, P135, DOI 10.1162/tacl_a_00051
   Boros T, 2018, P JOINT WORKSH LING, V0, P254
   Cavar Damir, 2012, PRACE FILOLOGICZNE, V63, P51
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Cook P, 2008, P LREC WORKSH SHAR T, V0, P19
   Devlin J, 2018, ARXIV, V1, P4171
   Ehren R, 2018, P JOINT WORKSH LING, V0, P261
   Fadaee M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P925
   Gantar P, 2011, NATURAL LANGUAGE PRO, V0, P72
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Klyueva Natalia, 2017, P 13 WORKSH MULT EXP, V0, P60
   Korkontzelos I, 2013, 2 JOINT C LEX COMP S, V0, P39
   Krek S, 2016, P LANG TECHN DIG HUM, V0, P200
   Li XL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2744
   Liu CS, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1723
   Liu CS, 2017, AAAI CONF ARTIF INTE, V0, P3230
   Ljubesic N, 2011, LECT NOTES ARTIF INT, V6836, P395, DOI 10.1007/978-3-642-23538-2_50
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Miok K, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pirs G, 2019, J MACH LEARN RES, V20, P0
   Pontes ELinhares, 2020, 20 ACM IEEE JOINT C, V0, P0
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Ramisch C, 1900, P222, V0, P0
   Robnik-Sikonja M, 2020, CROSS LINGUAL TRANSF, V0, P0
   Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640
   Savary A, 2017, P 13 WORKSH MULT EXP, V0, P31
   Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599
   Sporleder Caroline, 2009, P 12 C EUR ACL, V0, P754
   Ulcar M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P4731
   Ulcar M, 2020, LECT NOTES ARTIF INT, V12284, P104, DOI 10.1007/978-3-030-58323-1_11
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Zhang Xiang, 2015, NEURIPS, V0, P0, DOI DOI 10.5555/2969239.2969312
NR 37
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JAN 10
PY 2022
VL 235
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107606
EA OCT 2021
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WP1HS
UT WOS:000712891900003
DA 2023-11-10
ER

PT J
AU Nguyen, KV
   Huynh, TV
   Nguyen, DV
   Nguyen, AGT
   Nguyen, NLT
AF Kiet Van Nguyen
   Tin Van Huynh
   Duc-Vu Nguyen
   Anh Gia-Tuan Nguyen
   Ngan Luu-Thuy Nguyen
TI New Vietnamese Corpus for Machine Reading Comprehension of Health News Articles
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Machine reading comprehension; question answering; Vietnamese
AB Machine reading comprehension is a natural language understanding task where the computing system is required to read a text and then find the answer to a specific question posed by a human. Large-scale and highquality corpora are necessary for evaluating machine reading comprehension models. Furthermore, machine reading comprehension (MRC) for the health sector has potential for practical applications; nevertheless, MRC research in this domain is currently scarce. This article presents UIT-ViNewsQA, a new corpus for the Vietnamese language to evaluate MRC models for the healthcare textual domain. The corpus consists of 22,057 human-generated question-answer pairs. Crowd-workers create the questions and answers on a collection of 4,416 online Vietnamese healthcare news articles, where the answers are textual spans extracted from the corresponding articles. We introduce a process for creating a high-quality corpus for the Vietnamese machine reading comprehension task. Linguistically, our corpus accommodates diversity in question and answer types. In addition, we conduct experiments and compare the effectiveness of different MRC methods based on the neural networks and transformer architectures. Experimental results on our corpus show that the MRC system based on ALBERT architecture outperforms the neural network architectures and the BERT-based approach, an exact match score of 65.26% and an F1-score of 84.89%. The best machine model achieves about 10.90% F1-score less efficiently than humans, which proves that exploring machine models on UIT-ViNewsQA to surpass humans is challenging for researchers in the future. Our corpus is publicly available on our website: http://nlp.uit.edu.vn/datasets for research purposes.
C1 [Kiet Van Nguyen; Tin Van Huynh; Duc-Vu Nguyen; Anh Gia-Tuan Nguyen; Ngan Luu-Thuy Nguyen] Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Kiet Van Nguyen; Tin Van Huynh; Duc-Vu Nguyen; Anh Gia-Tuan Nguyen; Ngan Luu-Thuy Nguyen] Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Nguyen, NLT (通讯作者)，Univ Informat Technol, Ho Chi Minh City, Vietnam.; Nguyen, NLT (通讯作者)，Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
FU Vingroup JSC; Vingroup Innovation Foundation (VINIF), Institute of Big Data [VINIF.2021.TS.026]; Vietnam National University HoChiMinh City (VNU-HCM) [DS2022-26-01]
CR Aniol A, 2019, 2019 SEVENTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING WORKSHOPS (CANDARW 2019), V0, PP180, DOI 10.1109/CANDARW.2019.00039
   [Anonymous], 2013, P 2013 C EMP METH NA, V0, P0
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Shao CC, 2019, ARXIV, V0, P0
   Conneau Alexis, 2020, ASS COMPUT LINGUIST, V0, PP8440, DOI 10.18653/v1/2020.acl-main.747
   Cui Y, 2016, P COLING 2016 26 INT, V0, P0
   Cui YM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P5883
   Cui Yiming, 2020, P 28 INT C COMPUTATI, V0, PP6717, DOI 10.18653/V1/2020.COLING-MAIN.589
   dHoffschmidt M, 2020, FINDINGS ASS COMPUTA, V2020, P1193
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368
   Efimov Pavel, 2020, SBERQUAD RUSSIAN REA, V0, P3
   Gupta D, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3359988
   He W, 2018, MACHINE READING FOR QUESTION ANSWERING, V0, P37
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Hill F, 2016, ARXIV, V0, P0
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang Hsin-Yuan, 2018, P INT C LEARN REPR, V0, P0
   Jin Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2567
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Jurczyk T, 2016, PROC INT C TOOLS ART, V0, PP820, DOI 10.1109/ICTAI.2016.0128
   Nguyen KV, 2018, INT CONF KNOWL SYS, V0, PP19, DOI 10.1109/KSE.2018.8573337
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Lai G, 2017, EMNLP, V0, PP785, DOI 10.18653/V1/D17-1082
   Lan Z, 2019, P INT C LEARNING REP, V0, P0
   Lim S, 2019, ARXIV, V0, P0
   Nguyen AT, 2020, FINDINGS ASS COMPUTA, V0, PP4079, DOI 10.18653/V1/2020.FINDINGS-EMNLP.364
   Nguyen K, 2020, P 28 INT C COMPUTATI, V0, P2595
   Nguyen KV, 2020, IEEE ACCESS, V8, P201404, DOI 10.1109/ACCESS.2020.3035701
   Nguyen Luan Thanh, 2021, LECT NOTES COMPUTER, V12798, P0
   Nguyen Nhung Thi-Hong, 2021, NEW TRENDS INTELLIGE, V0, P618
   Nguyen QT, 2018, LANG RESOUR EVAL, V52, P269, DOI 10.1007/s10579-017-9398-3
   Park C, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3365679
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Do P, 2021, ACM T ASIAN LOW-RESO, V20, P0, DOI 10.1145/3453651
   Le-Hong P, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP1049, DOI 10.1145/3184558.3191535
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Seo M, 2018, ARXIV, V0, P0
   Sun K, 2019, T ASSOC COMPUT LING, V7, P217, DOI 10.1162/tacl_a_00264
   Suster S, 2018, P NAACL HLT, V1, P1551, DOI 10.18653/V1/N18-1140
   Trischler Adam, 2017, P 2 WORKSH REPR LEAR, V0, PP191, DOI 10.18653/V1/W17-2623
   Wadhwa S, 2018, MACHINE READING FOR QUESTION ANSWERING, V0, P89
   Wang SH, 2016, ARXIV, V0, P0
   Wang SH, 2018, AAAI CONF ARTIF INTE, V0, P5981
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Weissenborn D, 2017, P 21 C COMP NAT LANG, V0, PP271, DOI 10.18653/V1/K17-1028
   Xie QZ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2344
   Yang W, 2019, ARXIV, V0, P0
   Yu Adams Wei, 2018, ARXIV180409541, V0, P0
   Zhang X, 2018, AAAI CONF ARTIF INTE, V0, P5706
NR 53
TC 3
Z9 3
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2022
VL 21
IS 5
BP 
EP 
DI 10.1145/3527631
PG 28
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9Z2DN
UT WOS:000950956700021
DA 2023-11-10
ER

PT J
AU Zhan, XL
   Huang, YY
   Dong, X
   Cao, QX
   Liang, XD
AF Zhan, Xunlin
   Huang, Yinya
   Dong, Xiao
   Cao, Qingxing
   Liang, Xiaodan
TI PathReasoner: Explainable reasoning paths for commonsense question answering
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Commonsense reasoning; Knowledge graph; Reasoning path; Interpretability
AB Commonsense question answering has attracted increasing attention as a challenging task requiring the human reasoning process of answering questions with the help of abundant commonsense knowledge. Existing methods mostly resort to large pre-trained language models and face many difficulties when dealing with the out-of-scope reasoning target, and are unaware of explainable structured information. In this paper, we explore explicitly incorporate external reasoning paths with structured information to explain and facilitate commonsense QA. For this purpose, we propose a PathReasoner to both extract and learn from such structured information. The proposed PathReasoner consists of two main components, a path finder and a hierarchical path learner. To answer a commonsense question, the path finder first retrieves explainable reasoning paths from a large-scale knowledge graph, then the path learner encodes the paths with hierarchical encoders and uses the path features to predict the answers. The experiments on two typical commonsense QA datasets demonstrate the effectiveness of the PathReasoner. The case study gives insightful findings that the reasoning paths provide explainable information for the question answering through the PathReasoner. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Zhan, Xunlin; Huang, Yinya; Cao, Qingxing; Liang, Xiaodan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510000, Peoples R China.
   [Dong, Xiao] Sun Yat Sen Univ, Sch Artificial Intelligence, Zhuhai 528478, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Liang, XD (通讯作者)，Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510000, Peoples R China.
EM zhanxlin@mail2.sysu.edu.cn; yinya.el.huang@gmail.com; dx.icandoit@gmail.com; caoqx@mail2.sysu.edu.cn; xdliang328@gmail.com
FU National Natural Science Foundation of China [61976233, U19A2073]; Guangdong Provincial Natural Science Foundation of China [2019B1515120039]
CR [Anonymous], 2014, INTERSPEECH 2014 15, V0, P0
   Asai Akari, 2019, INT C LEARNING REPRE, V0, P0
   Assante M, 2019, FUTURE GENER COMP SY, V101, P555, DOI 10.1016/j.future.2019.05.063
   Berant J, 2013, P 2013 C EMPIRICAL M, V0, P0
   Boratko M, 2020, P 2020 C EMPIRICAL M, V0, P1122
   Bordes Antoine, 2015, ARXIV150602075, V0, P0
   Cai Q, 2013, P MAIN C SHAR TASK S, V1, P328
   Cao Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P357
   Chen Q, 2020, PROC COLING C, V0, P2583
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duan N, 1900, V2021, V0, P0
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hermann KM, 2015, ADV NEUR IN, V28, P0
   Huang L, 2019, ADV NEUR IN, V32, P0
   Huang Yutao, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Kingma DP, 2014, C TRACK P, V0, P0
   Kumar V, 2016, INT CONF ADVAN COMPU, V0, P0
   Levesque HJ, 2012, P INT WORKSHOP TEMPO, V0, P552
   Li RH, 2021, KNOWL-BASED SYST, V220, P0, DOI 10.1016/j.knosys.2021.106936
   Liang X, 2021, DAGN DISCOURSE AWARE, V0, P0
   Lim Jungwoo, 2020, P 28 INT C COMPUTATI, V0, PP2459, DOI 10.18653/v1/2020.coling-main.222
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2829
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Lv Shangwen, 2020, AAAI, V0, P0
   Miller Alexander, 2016, ARXIV160603126, V0, P0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Parikh A, 2016, PROC C EMPIR METHODS, V0, PP2249, DOI 10.18653/v1/D16-1244
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4932
   Richardson M, 2013, P 2013 C EMPIRICAL M, V0, P193
   Sap M, 2019, AAAI CONF ARTIF INTE, V0, P3027
   Speer R, 2017, AAAI CONF ARTIF INTE, V0, P4444
   Sukhbaatar S, 2015, ADV NEUR IN, V28, P0
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Tandon Niket, 2019, EMNLP, V0, P0
   Thomason Jesse, 2019, 2019 INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP6934, DOI 10.1109/ICRA.2019.8794287
   Trischler Adam, 2017, P 2 WORKSH REPR LEAR, V0, PP191, DOI 10.18653/V1/W17-2623
   Tu Ming, 2019, ACL, V0, P0
   Welbl J, 2018, T ASSOC COMPUT LING, V6, P287
   Weston J, 2015, ARXIV14103916, V0, P0
   Weston J, 2016, ICLR, V0, P1
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2369
   Yu J, 2020, PATTERN RECOGN, V108, P0, DOI 10.1016/j.patcog.2020.107563
   Zhang HM, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP201, DOI 10.1145/3366423.3380107
   Zhang Tianyi, 2020, ICLR, V0, P0
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P1441
   Zhong WJ, 2019, LECT NOTES ARTIF INT, V11838, P16, DOI 10.1007/978-3-030-32233-5_2
   Zhuo Y, 2020, P 28 INT C COMP LING, V0, PP5347, DOI 10.18653/v1/2020
NR 49
TC 7
Z9 7
U1 4
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JAN 10
PY 2022
VL 235
IS 
BP 
EP 
DI 10.1016/j.knosys.2021.107612
EA OCT 2021
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WW8BM
UT WOS:000718134800006
DA 2023-11-10
ER

PT J
AU Fragkos, G
   Johnson, J
   Tsiropoulou, EE
AF Fragkos, Georgios
   Johnson, Jay
   Tsiropoulou, Eirini Eleni
TI Dynamic Role-Based Access Control Policy for Smart Grid Applications: An Offline Deep Reinforcement Learning Approach
SO IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS
LA English
DT Article
DE Training; Access control; Smart grids; Structured Query Language; Reinforcement learning; Man-machine systems; Laboratories; Bayesian belief; deep reinforcement learning (RL); distributed energy resources (DER); machine learning (ML); offline policy improvement; role based access control (RBAC); smart gird; trust
ID database intrusion; security; systems
AB Role-based access control (RBAC) is adopted in the information and communication technology domain for authentication purposes. However, due to a very large number of entities within organizational access control (AC) systems, static RBAC management can be inefficient, costly, and can lead to cybersecurity threats. In this article, a novel hybrid RBAC model is proposed, based on the principles of offline deep reinforcement learning (RL) and Bayesian belief networks. The considered framework utilizes a fully offline RL agent, which models the behavioral history of users as a Bayesian belief-based trust indicator. Thus, the initial static RBAC policy is improved in a dynamic manner through off-policy learning while guaranteeing compliance of the internal users with the security rules of the system. By deploying our implementation within the smart grid domain and specifically within a Distributed Energy Resources (DER) ecosystem, we provide an end-to-end proof of concept of our model. Finally, detailed analysis and evaluation regarding the offline training phase of the RL agent are provided, while the online deployment of the hybrid RL-based RBAC model into the DER ecosystem highlights its key operation features and salient benefits over traditional RBAC models.
C1 [Fragkos, Georgios; Tsiropoulou, Eirini Eleni] Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
   [Johnson, Jay] Sandia Natl Labs, Albuquerque, NM 87185 USA.
C3 University of New Mexico; United States Department of Energy (DOE); Sandia National Laboratories
RP Tsiropoulou, EE (通讯作者)，Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
EM gfragkos@unm.edu; jjohns2@sandia.gov; eirini@unm.edu
FU U.S. Department of Energy Solar Energy Technologies Office; Sandia National Laboratories; U.S. Department of Energy's National Nuclear Security Administration [DE-NA0003525]
CR Abou El Kalam A, 2018, DTUC18: PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON DIGITAL TOOLS & USES CONGRESS, V0, P0, DOI DOI 10.1145/3240117.3240136
   Afshar M, 2021, 2021 IEEE INT SYST C, V0, P1
   [Anonymous], 2013, STANDARDIZATION SMAR, V0, P0
   [Anonymous], 2020, SUNSPEC MODBUS SPECI, V0, P0
   [Anonymous], 2018, 20305 IEEE, V0, P0
   [Anonymous], 2011, REL STAND BULK EL SY, V0, P0
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bottou L, 2013, J MACH LEARN RES, V14, P3207
   Boyan JA, 2002, MACH LEARN, V49, P233, DOI 10.1023/A:1017936530646
   Bu SJ, 2020, INFORM SCIENCES, V512, P123, DOI 10.1016/j.ins.2019.09.055
   Bu SJ, 2019, LECT NOTES ARTIF INT, V11734, P145, DOI 10.1007/978-3-030-29859-3_13
   Cabi S, 2019, ARXIV190912200, V0, P0
   Cabral LM, 2005, EC TRUST REPUTATION, V2005, P0
   Cao ZC, 2019, IEEE T AUTOM SCI ENG, V16, P825, DOI 10.1109/TASE.2018.2862380
   Chavez A, 2019, 2019 IEEE CYBERPELS (CYBERPELS), V0, P0, DOI DOI 10.1109/cyberpels.2019.8925064
   Dulac-Arnold G, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Foerster JN, 2018, AAAI CONF ARTIF INTE, V0, P2974
   Hepworth AJ, 2021, IEEE-CAA J AUTOMATIC, V8, P1281, DOI 10.1109/JAS.2020.1003545
   IEEE, 2016, 18492016 IEEE, V0, PP1, DOI 10.1109/IEEESTD.2016.7740858
   Jayaprakash S, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), V0, PP1413, DOI 10.1109/ICICCT.2018.8473029
   Jiang L, 2020, IEEE-CAA J AUTOMATIC, V7, P1179, DOI 10.1109/JAS.2019.1911732
   Jiang N, 2016, PR MACH LEARN RES, V48, P0
   Johnson J, 2021, SAND20210977, V0, P0
   Johnson J, 2019, IET CYBER PHYS SYST, V4, P240, DOI 10.1049/iet-cps.2018.5014
   Johnson J, 2018, WORL CON PHOTOVOLT E, V0, PP2492, DOI 10.1109/PVSC.2018.8547588
   Kim TY, 2019, COMM COM INF SC, V1142, P131, DOI 10.1007/978-3-030-36808-1_15
   Kim TY, 2019, LECT NOTES ARTIF INT, V11734, P123, DOI 10.1007/978-3-030-29859-3_11
   Levine Sergey, 2020, ARXIV200501643, V0, P0
   Liu CH, 2021, IEEE-CAA J AUTOMATIC, V8, P1686, DOI 10.1109/JAS.2021.1004141
   Mitra B, 2016, ACM COMPUT SURV, V48, P0, DOI 10.1145/2871148
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ninghui Li, 2006, ACM TRANSACTIONS ON INFORMATION AND SYSTEMS SECURITY, V9, P391, DOI 10.1145/1187441.1187442
   Outchakoucht A, 2017, INT J ADV COMPUT SC, V8, P417
   Paszke Adam, 2019, NEURIPS, V0, P0
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3234150
   Saenko I, 2016, PROC INT S INTELL DI, V0, P89
   Srivastava K, 2020, MODERN APPROACHES MA, V0, PP129, DOI 10.1007/978-3-030-38445-610
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Tay B, 2020, IEEE ACCESS, V8, P153403, DOI 10.1109/ACCESS.2020.3015616
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Xiao L, 2018, IEEE WIREL COMMUN, V25, P116, DOI 10.1109/MWC.2018.1700291
   Zhang D, 2021, IEEE-CAA J AUTOMATIC, V8, P319, DOI 10.1109/JAS.2021.1003820
   Zhang PY, 2021, IEEE T SYST MAN CY-S, V51, P1805, DOI 10.1109/TSMC.2019.2906310
   Zhou L, 2019, FUTURE GENER COMP SY, V93, P548, DOI 10.1016/j.future.2018.04.043
NR 44
TC 12
Z9 13
U1 10
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2291
EI 2168-2305
J9 IEEE T HUM-MACH SYST
JI IEEE T. Hum.-Mach. Syst.
PD AUG 15
PY 2022
VL 52
IS 4
BP 761
EP 773
DI 10.1109/THMS.2022.3163185
EA APR 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA 3C5VS
UT WOS:000788906700001
DA 2023-11-10
ER

PT J
AU Li, J
   Chiu, B
   Feng, SS
   Wang, H
AF Li, Jing
   Chiu, Billy
   Feng, Shanshan
   Wang, Hao
TI Few-Shot Named Entity Recognition via Meta-Learning
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Natural language processing; sequence labeling; few-shot learning; meta-learning
AB Few-shot learning under the N-way K-shot setting (i.e., K annotated samples for each of N classes) has been widely studied in relation extraction (e.g., FewRel) and image classification (e.g., Mini-ImageNet). Named entity recognition (NER) is typically framed as a sequence labeling problem where the entity classes are inherently entangled together because the entity number and classes in a sentence are not known in advance, leaving the N-way K-shot NER problem so far unexplored. In this paper, we first formally define a more suitable N-way K-shot setting for NER. Then we propose FEWNER, a novel meta-learning approach for few-shot NER. FEWNER separates the entire network into a task-independent part and a task-specific part. During training in FEWNER, the task-independent part is meta-learned across multiple tasks and the task-specific part is learned for each individual task in a low-dimensional space. At test time, FEWNER keeps the task-independent part fixed and adapts to a new task via gradient descent by updating only the task-specific part, resulting in it being less prone to overfitting and more computationally efficient. Compared with pre-trained language models (e.g., BERT and ELMo) which obtain the transferability in an implicit manner (i.e., relying on large-scale corpora), FEWNER explicitly optimizes the capability of "learning to adapt quickly" through meta-learning. The results demonstrate that FEwNER achieves state-of-the-art performance against nine baseline methods by significant margins on three adaptation experiments (i.e., intra-domain cross-type, cross-domain intra-type and cross-domain cross-type).
C1 [Li, Jing; Chiu, Billy; Feng, Shanshan] Incept Inst Artificial Intelligence, Abu Dhabi 54115, U Arab Emirates.
   [Wang, Hao] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Feng, SS (通讯作者)，Incept Inst Artificial Intelligence, Abu Dhabi 54115, U Arab Emirates.
EM jingli.phd@hotmail.com; hon.chiu@inceptioniai.org; victor_fengss@foxmail.com; wanghao.hku@gmail.com
CR Akbik A, 2018, P 27 INT C COMPUTATI, V0, P1638
   [Anonymous], 2018, P 2018 C N AM CHAPT, V0, P0
   [Anonymous], 1998, LEARNING LEARN, V0, P0
   Beryozkin G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P140
   Changki Lee, 2007, 30TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P799
   Cieliebak M, 2017, W NUT, V0, P166
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Daume III Hal, 2007, P 45 ANN M ASS COMP, V0, PP256, DOI 10.48550/ARXIV.0907.1815
   Devlin Jacob, 2019, BERT PRE TRAINING DE, V0, P4171
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Finn C, 2019, P MACHINE LEARNING R, V0, P1920
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Fisher J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5840
   Fritzler A, 2019, SAC 19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, V0, PP993, DOI 10.1145/3297280.3297378
   Ghaddar Abbas, 2018, P 27 INT C COMP LING, V0, P1896
   Giorgi JM, 2018, BIOINFORMATICS, V34, P4087, DOI 10.1093/bioinformatics/bty449
   Gu JT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3622
   Guo JF, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP267, DOI 10.1145/1571941.1571989
   Guo QP, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1315
   Han X, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Hou YT, 2019, ARXIV, V0, P0
   Huang P, 2018, P C N AM ASS COMP LI, V0, P732
   Huang ZH, 2015, ARXIV, V0, P0
   Ji ZC, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16), V0, PP1271, DOI 10.1145/2872427.2883067
   Jia C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2464
   Lample G, 2016, P NAACL HLT, V0, P0, DOI DOI 10.18653/V1/N16-1030
   Lee JY, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P4470
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Li J, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5053
   Li J, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4166
   Li P H, 2017, P 2017 C EMP METH NA, V0, PP2664, DOI 10.18653/V1/D17-1282
   Li YJ, 2019, PR MACH LEARN RES, V97, P0
   Li YY, 2005, LECT NOTES ARTIF INT, V3635, P319
   Lin BY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2012
   Lin Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P799
   Liu LY, 2018, AAAI CONF ARTIF INTE, V0, P5253
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   MALOUF R, 2002, P 6 C NAT LANG LEARN, V0, P0
   Mishra N, 2018, PROC INT C LEARN REP, V0, P0
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Obamuyide A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5873
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perez E, 2018, AAAI CONF ARTIF INTE, V0, P3942
   Qian K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2639
   Radford A, 2019, OPENAI BLOG, V1, P1
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rajeswaran A, 2019, ADV NEUR IN, V32, P0
   Ravi S, 2017, ICLR 16, V0, P0
   Santoro A, 2016, PR MACH LEARN RES, V48, P0
   Schmidhuber, 1995, LEARNING LEARN LEARN, V0, P0
   Shen Y, 2018, PROC INT C LEARN REP, V0, P0
   Snell J, 2017, ADV NEUR IN, V30, P0
   Strubell E, 2017, P 2017 C EMPIRICAL M, V0, PP2670, DOI 10.18653/V1/D17-1283
   Vinyals Oriol, 2016, ADV NEURAL INFORM PR, V29, P0, DOI 10.48550/ARXIV.1606.04080
   Wang X, 2019, BIOINFORMATICS, V35, P1745, DOI 10.1093/bioinformatics/bty869
   Wang YX, 2018, PROC CVPR IEEE, V0, PP7278, DOI 10.1109/CVPR.2018.00760
   Wu Q, 2020, AAAI, V0, P9274
   Yan H, 2019, ARXIV, V0, P0
   Yang Z, 2017, PROC INT C LEARN REP, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yao Huaxiu, 2019, PR MACH LEARN RES, V0, P7045
   Yoon J, 2018, ADV NEUR IN, V31, P0
   Zhang SD, 2013, J BIOMED INFORM, V46, P1088, DOI 10.1016/j.jbi.2013.08.004
   Zhou JT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3461
   Zhuo JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1413
   Zintgraf Luisa, 2019, PR MACH LEARN RES, V0, P7693
NR 66
TC 20
Z9 20
U1 10
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD SEPT 1
PY 2022
VL 34
IS 9
BP 4245
EP 4256
DI 10.1109/TKDE.2020.3038670
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 3O1VG
UT WOS:000836626800015
DA 2023-11-10
ER

PT J
AU Fakhfakh, S
   Ben Jemaa, Y
AF Fakhfakh, Sana
   Ben Jemaa, Yousra
TI Deep Learning Shape Trajectories for Isolated Word Sign Language Recognition
SO INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY
LA English
DT Article
DE Sign language; isolated word recognition; shape trajectory analysis; deep learning; RWTH-Boston dataset; SIGNUM corpora
AB In this paper, we propose an efficient trajectories analysis solution for the recognition of Isolated Word Sign Language (IWSL). The key technique innovation in this work is the shape trajectories analysis based on the deep learning method and achieved impressive results on different IWSL data sets: German: Rheinisch Westf??lische Technische Hochschule(RWTH): RWTH-Boston-50 and RWTH-Boston-104(95.83%), Signer-Independent Continuous Sign Language Recognition for Large Vocabulary Using Subunit Models (SIGNUM: 98.21%) and new Tunisian Sign Language database (TunSigns: 98%).
C1 [Fakhfakh, Sana; Ben Jemaa, Yousra] El Manar Univ Tunis, L3S Lab, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar
RP Fakhfakh, S (通讯作者)，El Manar Univ Tunis, L3S Lab, Tunis, Tunisia.
EM sana.fakhfakh@enis.tn; yousra.benjemaa@enis.tn
CR Agrawal SC, 2016, INT J APPL PATTERN R, V3, P99, DOI 10.1504/IJAPR.2016.079048
   [Anonymous], 2012, TRENDS TOPICS COMPUT, V0, P0
   Balaji SR, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), V0, PP469, DOI 10.1109/ISCO.2017.7856037
   Ben Tanfous A, 2018, PROC CVPR IEEE, V0, PP2840, DOI 10.1109/CVPR.2018.00300
   Bhuyan MK, 2008, WORLD ACAD SCI ENG T, V2, P753
   Boulares M, 2012, PROCEDIA COMPUT SCI, V13, P133, DOI 10.1016/j.procs.2012.09.122
   Fakhfakh S, 2017, I C COMP SYST APPLIC, V0, PP774, DOI 10.1109/AICCSA.2017.67
   Gopura RARC, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, V0, P269, DOI 10.1109/ICCAR.2017.7942701
   Li GF, 2019, IEEE ACCESS, V7, P23713, DOI 10.1109/ACCESS.2018.2887223
   Lim K, 1900, V78, V0, P19917
   Lin WY, 2013, PATTERN RECOGN, V46, P662, DOI 10.1016/j.patcog.2012.09.014
   Mohandes M, 2013, 2013 COMPUTING, V0, P90, DOI 10.1109/ComComAp.2013.6533615
   Noubigh Z, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), V0, PP69, DOI 10.1109/ASAR.2017.8067762
   Sidig AAI, 2018, INT J ADV COMPUT SC, V9, P283
   Singh K, 1900, P211, V0, P0
   Sokhib T, 2020, INT ARAB J INF TECHN, V17, P137, DOI 10.34028/iajit/17/1/16
   Teow MYW, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), V0, PP167, DOI 10.1109/I2CACIS.2017.8239052
   Von Agris U, 2007, GESTURE HUMAN COMPUT, V0, P11
   Zhang QS, 2018, PROC CVPR IEEE, V0, PP8827, DOI 10.1109/CVPR.2018.00920
NR 19
TC 2
Z9 2
U1 2
U2 5
PU ZARKA PRIVATE UNIV
PI ZARQA
PA COLL COMPUTING & INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN
SN 1683-3198
EI 
J9 INT ARAB J INF TECHN
JI Int. Arab J. Inf. Technol.
PD JUL 15
PY 2022
VL 19
IS 4
BP 660
EP 666
DI 10.34028/iajit/19/4/10
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 2Y7DR
UT WOS:000826053300010
DA 2023-11-10
ER

PT J
AU Paassen, B
   Schulz, A
   Stewart, TC
   Hammer, B
AF Paassen, Benjamin
   Schulz, Alexander
   Stewart, Terrence C.
   Hammer, Barbara
TI Reservoir Memory Machines as Neural Computers
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Reservoirs; Computational modeling; Computers; Task analysis; Recurrent neural networks; Turing machines; Training; Differentiable neural computers (DNCs); echo state networks; finite state machines (FSMs); memory-augmented neural networks; neural Turing machines; reservoir computing
ID echo state networks; computational power
AB Differentiable neural computers (DNCs) extend artificial neural networks with an explicit memory without interference, thus enabling the model to perform classic computation tasks, such as graph traversal. However, such models are difficult to train, requiring long training times and large datasets. In this work, we achieve some of the computational capabilities of DNCs with a model that can be trained very efficiently, namely, an echo state network with an explicit memory without interference. This extension enables echo state networks to recognize all regular languages, including those that contractive echo state networks provably cannot recognize. Furthermore, we demonstrate experimentally that our model performs comparably to its fully trained deep version on several typical benchmark tasks for DNCs.
C1 [Paassen, Benjamin] Univ Sydney, Sch Comp Sci, Sydney, NSW 2008, Australia.
   [Paassen, Benjamin] Humboldt Univ, Dept Comp Sci, D-12489 Berlin, Germany.
   [Schulz, Alexander; Hammer, Barbara] Bielefeld Univ, Fac Technol, D-33619 Bielefeld, Germany.
   [Stewart, Terrence C.] Natl Res Council Canada, Ottawa, ON K1A 0R6, Canada.
C3 University of Sydney; Humboldt University of Berlin; University of Bielefeld; National Research Council Canada
RP Paassen, B (通讯作者)，Univ Sydney, Sch Comp Sci, Sydney, NSW 2008, Australia.
EM b.paassen@araneae-online.net
FU German Research Foundation (DFG) [PA 3460/1-1, PA 3460/2-1]
CR [Anonymous], 2012, 2012D U WAT WAT CAN, V0, P0
   Boedecker J, 2012, THEOR BIOSCI, V131, P205, DOI 10.1007/s12064-011-0146-8
   Cho K, 2014, ARXIV14061078, V0, P0, DOI DOI 10.3115/v1/d14
   Collier M, 2018, LECT NOTES COMPUT SC, V11141, P94, DOI 10.1007/978-3-030-01424-7_10
   Csordas R, 2019, P 7 INT C LEARN REPR, V0, P7299
   de la Higuera C, 2010, GRAMMATICAL INFERENC, V0, PP237, DOI 10.1017/CBO9781139194655.013
   Farkas I, 2016, NEURAL NETWORKS, V83, P109, DOI 10.1016/j.neunet.2016.07.012
   Gallicchio C, 2018, NEURAL NETWORKS, V108, P33, DOI 10.1016/j.neunet.2018.08.002
   Gallicchio C, 2011, NEURAL NETWORKS, V24, P440, DOI 10.1016/j.neunet.2011.02.002
   Giles CL, 1989, P NIPS 1989, V0, P380
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Grigoryeva L, 2018, NEURAL NETWORKS, V108, P495, DOI 10.1016/j.neunet.2018.08.025
   Hammer B, 2003, NEURAL COMPUT, V15, P1897, DOI 10.1162/08997660360675080
   Hammer B, 1996, THEORETISCHE INFORM, V0, P0
   Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277
   Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019
   Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955
   Maass W, 2004, J COMPUT SYST SCI, V69, P593, DOI 10.1016/j jcss.2004.04.001
   Moore E, 1956, AUTOMATA STUDIES, V34, P129, DOI 10.1515/9781400882618-006
   Paassen B, 2020, IEEE IJCNN, V0, P0, DOI DOI 10.1109/ijcnn48605.2020.9207165
   Rae JW, 2016, ADV NEUR IN, V29, P0
   Rodan A, 2012, NEURAL COMPUT, V24, P1822, DOI 10.1162/NECO_a_00297
   Rodan A, 2011, IEEE T NEURAL NETWOR, V22, P131, DOI 10.1109/TNN.2010.2089641
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   SIEGELMANN HT, 1995, J COMPUT SYST SCI, V50, P132, DOI 10.1006/jcss.1995.1013
   Sima J, 1998, J ACM, V45, P155, DOI 10.1145/273865.273914
   Voelker AR, 2019, ADV NEUR IN, V32, P0
   Weiss Karl, 2016, JOURNAL OF BIG DATA, V3, P0, DOI 10.1186/s40537-016-0043-6
   YAMANE T, 2019, PROC ICONIP, V0, P389
   Yildiz IB, 2012, NEURAL NETWORKS, V35, P1, DOI 10.1016/j.neunet.2012.07.005
NR 31
TC 2
Z9 2
U1 5
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2022
VL 33
IS 6
BP 2575
EP 2585
DI 10.1109/TNNLS.2021.3094139
EA JUL 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1T4KK
UT WOS:000732105100001
PM 34255637
DA 2023-11-10
ER

PT J
AU Kumar, KS
   Sulochana, CH
   Radhamani, AS
   Kumar, TA
AF Kumar, K. Suresh
   Sulochana, C. Helen
   Radhamani, A. S.
   Kumar, T. Ananth
TI Sentiment lexicon for cross-domain adaptation with multi-domain dataset in Indian languages enhanced with BERT classification model
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Cross-domain adaptation (CDA); BERT classification; modified multi-layer fuzzy convolutional neural networks (M-FCNN)
AB Many websites are attempting to offer a platform for users or customers to leave their reviews and comments about the products or services in their native languages. The cross-domain adaptation (CDA) analyses sentiment across domains. The sentiment lexicon falls short resulting in issues like feature mismatch, sparsity, polarity mismatch and polysemy. In this research, an augmented sentiment dictionary is developed in our native regional language (Tamil) that intends to construct the contextual links between terms in multi-domain datasets to reduce problems like polarity mismatch, feature mismatch, and polysemy. Data from the source domain and target domain both labeled and unlabeled are used in the proposed dictionary. To be more specific, the initial dictionary uses normalised pointwise mutual information (nPMI) to derive contextual weight, whereas the final dictionary uses the value of terms across all reviews to compute the accurate rank score. Here, a deep learning model called BERT is used for sentiment classification. For cross-domain adaptation, a modified multi-layer fuzzy-based convolutional neural network (M-FCNN) is deployed. This work aims to build a single dictionary using large number of vocabularies for classifying the reviews in Tamil for several target domains. This extendible dictionary enhances the accuracy of CDA greatly when compared to existing baseline techniques and easily handles a large number of terms in different domains.
C1 [Kumar, K. Suresh; Kumar, T. Ananth] IFET Coll Engn Autonomous, Villupuram, Tamil Nadu, India.
   [Sulochana, C. Helen] St Xaviers Catholic Coll Engn, Kanyakumari, Tamil Nadu, India.
   [Radhamani, A. S.] Amrita Coll Engn & Technol, Nagerkoil, India.
RP Kumar, KS; Kumar, TA (通讯作者)，IFET Coll Engn Autonomous, Villupuram, Tamil Nadu, India.
EM sureshkumarkskphd@gmail.com; tananthkumar@ifet.ac.in
CR Abu Farha I, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102438
   Al-Moslmi T, 2017, IEEE ACCESS, V5, P16173, DOI 10.1109/ACCESS.2017.2690342
   Alhammi HA, 2020, INT J COMPUT THEORY, V12, P0
   Anbukkarasi S, 2022, IETE J RES, V0, P0, DOI DOI 10.1080/03772063.2022.2043786
   Anbukkarasi S, 2020, PROC 4 INT C COMPUT, V0, P449
   [Anonymous], 2022, KSK11065 CROSSD TAM, V0, P0
   [Anonymous], 2019, N L IMDB DATASET 50K, V0, P0
   [Anonymous], 2015, INT S SOC SCI ISSS 2, V0, P0
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, V0, P452
   Behera RK, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102435
   Chakravarthi BR, 2022, LANG RESOUR EVAL, V56, P765, DOI 10.1007/s10579-022-09583-7
   Devlin J, 2019, ARXIV, V0, P0
   Dhanith PRJ, 2019, INT J COMPUT APPL, V0, P1
   Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594
   Hsu MJ, 2020, INT J FUZZY SYST, V22, P1, DOI 10.1007/s40815-019-00764-1
   Jardim Sandra, 2022, PROCEDIA COMPUTER SCIENCE, V0, PP199, DOI 10.1016/j.procs.2021.12.006
   Keshavarz H, 2017, 2017 2ND CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC), V0, PP83, DOI 10.1109/CSIEC.2017.7940153
   Li D, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102290
   Li WB, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102592
   Liu WF, 2021, PATTERN RECOGN, V110, P0, DOI 10.1016/j.patcog.2020.107658
   Marcacini RM, 2018, DECIS SUPPORT SYST, V114, P70, DOI 10.1016/j.dss.2018.08.009
   Meng JN, 2021, INTELL DATA ANAL, V25, P627, DOI 10.3233/IDA-205130
   Meskele D, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102211
   Munikar M, 2019, 2019 ARTIFICIAL INTE, V1, P1, DOI 10.1109/AITB48515.2019.8947435
   Nguyen Thi Mai Trang, 2020, PROCEEDINGS OF THE 2020 9TH INTERNATIONAL CONFERENCE SYSTEM MODELING AND ADVANCEMENT IN RESEARCH TRENDS (SMART), V0, PP201, DOI 10.1109/SMART50582.2020.9337155
   Nithya K, 2022, 2022 6TH INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), V0, PP1112, DOI 10.1109/ICCMC53470.2022.9754163
   Padmamala R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, V0, P0
   Park J, 2021, ARXIV, V0, P0
   Patil RS, 2022, SOC NETW ANAL MIN, V12, P0, DOI 10.1007/s13278-022-00877-w
   Poddar H, 2019, ZOMATO BANGALORE RES, V0, P0
   Prasad SS, 2016, INT CONF CONTEMP, V0, P323
   Pronoza E, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102674
   Rao YH, 2014, WORLD WIDE WEB, V17, P723, DOI 10.1007/s11280-013-0221-9
   Raveendirarasa V, 2020, 2020 5 INT C INFORM, V0, P1
   Rui Man, 2021, 2021 IEEE ASIA-PACIFIC CONFERENCE ON IMAGE PROCESSING, V0, P769, DOI 10.1109/IPEC51340.2021.9421110
   Sangil Maria Jihan, 2022, 2022 IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGY AND SOCIETY (ISTAS), V0, PP1, DOI 10.1109/ISTAS55053.2022.10227103
   Singh RK, 2021, ARTIF INTELL REV, V54, P1385, DOI 10.1007/s10462-020-09884-9
   Sivasankar E, 2021, SOFT COMPUT, V25, P3697, DOI 10.1007/s00500-020-05400-x
   Smetanin S, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102484
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sumathy B, 2022, COMPUT INTEL NEUROSC, V2022, P0, DOI 10.1155/2022/5906797
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Tanaka H, 2020, CONF TECHNOL APPL, V0, PP232, DOI 10.1109/TAAI51410.2020.00050
   Thavareesan S, 2020, MERCON 2020: 6TH INTERNATIONAL MULTIDISCIPLINARY MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON), V0, PP272, DOI 10.1109/MERCon50084.2020.9185369
   Vilares D, 2017, INFORM PROCESS MANAG, V53, P595, DOI 10.1016/j.ipm.2017.01.004
   Yang TT, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102681
   Yu X, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102691
   Zhao HL, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102656
   Zhao L, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102641
   Zhou C, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102679
   Zhou SC, 2021, 2021 IEEE 6TH INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS (ICBDA 2021), V0, PP316, DOI 10.1109/ICBDA51983.2021.9403180
   Zhu WH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P7588, DOI 10.1109/ICASSP39728.2021.9414148
NR 52
TC 0
Z9 0
U1 1
U2 5
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2022
VL 43
IS 5
BP 6433
EP 6450
DI 10.3233/JIFS-220448
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4X8SS
UT WOS:000861108300075
DA 2023-11-10
ER

PT J
AU Christmas, J
AF Christmas, J.
TI Non-stationary, online variational Bayesian learning, with circular variables
SO PATTERN RECOGNITION
LA English
DT Article
DE Online learning; processing; Variational methods; Bayes procedures
ID spectral-analysis; inference; models; family
AB We introduce an online variational Bayesian model for tracking changes in a non-stationary, multivariate, temporal signal, using as an example the changing frequency and amplitude of a noisy sinusoidal signal over time. The model incorporates each observation as it arrives and then discards it, and places priors over precision hyperparameters to ensure that (i) the posterior probability distributions do not become overly tight, which would impede its ability to recognise and track changes, and (ii) no values in the system are able to continuously increase and hence exceed the numerical representation of the programming language. It is thus able to perform truly online processing for an infinitely long set of observations. Only a single round of updates in the variational Bayesian scheme per observation is used, and the complexity of the algorithm is constant in time. The proposed method is demonstrated on a large number of synthetic datasets, comparing the results from the full model (with precision hyperparameters as variables with priors) with those from the base model where the precision hyperparameters are fixed values. The full model is also demonstrated on a set of real climate data. (c) 2021 Published by Elsevier Ltd.
C1 [Christmas, J.] Univ Exeter, Exeter, Devon, England.
C3 University of Exeter
RP Christmas, J (通讯作者)，Univ Exeter, Exeter, Devon, England.
EM J.T.Christmas@exeter.ac.uk
CR Andrieu C, 1999, IEEE T SIGNAL PROCES, V47, P2667, DOI 10.1109/78.790649
   [Anonymous], 2003, 4 INT S IND COMP AN, V0, P0
   [Anonymous], 1988, MAXIMUM ENTROPY BAYE, V0, P0
   Attias H, 2000, ADV NEUR IN, V12, P209
   Badiu MA, 2017, IEEE T SIGNAL PROCES, V65, P2247, DOI 10.1109/TSP.2017.2655489
   Beal MJ, 2003, VARIATIONAL ALGORITH, V0, P0
   Beal MJ, 2003, BAYESIAN STATISTICS 7, V0, P453
   Bishop CM, 2006, PATTERN RECOGN, V0, P738
   Broderick T, 2013, ADV NEURAL INFORM PR, V0, P1727
   Christmas J, 2014, IEEE T SIGNAL PROCES, V62, P2871, DOI 10.1109/TSP.2014.2316139
   Christmas J, 2011, IEEE T SIGNAL PROCES, V59, P48, DOI 10.1109/TSP.2010.2080271
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Djuric P, 1993, SIMULTANEOUS DETECTI, V0, P0
   DOU L, 1995, INVERSE PROBL, V11, P1069, DOI 10.1088/0266-5611/11/5/011
   Fourier JBJ, 1822, THEORIE ANAL CHALEUR, V0, P0
   Fu H, 2007, IEEE T SIGNAL PROCES, V55, P834, DOI 10.1109/TSP.2006.888055
   Gatto R, 2007, STAT METHODOL, V4, P341
   Ghahramani Z, 2001, ADV NEUR IN, V13, P507
   HARRIS FJ, 1978, P IEEE, V66, P51, DOI 10.1109/PROC.1978.10837
   Hoffman M, 2010, ADV NEURAL INFORM PR, V23, P0, DOI 10.5555/2997189.2997285
   Hoffman MD, 2013, J MACH LEARN RES, V14, P1303
   Jaynes E, 1983, P 3 WORKSH MAX ENTR, V0, P0
   Johnson MJ, 2014, PR MACH LEARN RES, V32, P1854
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Korzeniewski B, 2012, GLOBAL HIST CLIMATOL, V0, P0, DOI DOI 10.7289/V5D21VHZ
   Lappalainen H, 2000, PERSP NEURAL COMP, V0, P75
   Li ZG, 2021, J AM STAT ASSOC, V116, P1595, DOI 10.1080/01621459.2020.1860770
   Luts J, 2014, J COMPUT GRAPH STAT, V23, P589, DOI 10.1080/10618600.2013.810150
   MacKay DJC, 1995, ENSEMBLE LEARNING EV, V0, P0
   MacKay DJC, 1997, TECHNICAL REPORT, V0, P0
   MAKSIMOV VM, 1967, THEOR PROBAB APPL+, V12, P267, DOI 10.1137/1112029
   Mardia KV, 2000, DIRECTIONAL STAT, V0, P0
   Masegosa AR, 2020, MATHEMATICS-BASEL, V8, P0, DOI 10.3390/math8111942
   Nielsen J, 2009, SINUSOIDAL PARAMETER, V0, P0
   Nielsen JK, 2011, IEEE T AUDIO SPEECH, V19, P1986, DOI 10.1109/TASL.2011.2108285
   Quinn A, 2011, INT CONF ACOUST SPEE, V0, P4276
   Taghia J, 2014, IEEE T PATTERN ANAL, V36, P1701, DOI 10.1109/TPAMI.2014.2306426
   Tsiligkaridis T, 2015, IEEE INT WORKS MACH, V0, P0
   Turner R, 2011, ADV NEURAL INF PROCE, V0, P981
   Wang JB, 2021, IEEE T IND INFORM, V17, P5314, DOI 10.1109/TII.2020.3031497
   Wipf DP, 2011, IEEE T INFORM THEORY, V57, P6236, DOI 10.1109/TIT.2011.2162174
   Yang ZY, 2020, J PROCESS CONTR, V85, P52, DOI 10.1016/j.jprocont.2019.10.010
   Zhang L, 2018, INT J COMPUT VISION, V126, P797, DOI 10.1007/s11263-018-1080-8
NR 43
TC 1
Z9 1
U1 0
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD FEB 15
PY 2022
VL 122
IS 
BP 
EP 
DI 10.1016/j.patcog.2021.108340
EA SEP 2021
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WD4CW
UT WOS:000704891800003
DA 2023-11-10
ER

PT J
AU Geva, M
   Wolfson, T
   Berant, J
AF Geva, Mor
   Wolfson, Tomer
   Berant, Jonathan
TI <i>Break, Perturb, Build</i>: Automatic Perturbation of Reasoning Paths Through Question Decomposition
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
LA English
DT Article
AB Recent efforts to create challenge benchmarks that test the abilities of natural language understanding models have largely depended on human annotations. In this work, we introduce the "Break, Perturb, Build" (BPB) framework for automatic reasoning-oriented perturbation of question-answer pairs. BPB represents a question by decomposing it into the reasoning steps that are required to answer it, symbolically perturbs the decomposition, and then generates new question-answer pairs. We demonstrate the effectiveness of BPB by creating evaluation sets for three reading comprehension (RC) benchmarks, generating thousands of high-quality examples without human intervention. We evaluate a range of RC models on our evaluation sets, which reveals large performance gaps on generated examples compared to the original data. Moreover, symbolic perturbations enable fine-grained analysis of the strengths and limitations of models. Last, augmenting the training data with examples generated by BPB helps close the performance gaps, without any drop on the original data distribution.
C1 [Geva, Mor] Tel Aviv Univ, Sch Comp Sci, Tel Aviv, Israel.
   Allen Inst Artificial Intelligence, Tel Aviv, Israel.
C3 Tel Aviv University
RP Geva, M (通讯作者)，Tel Aviv Univ, Sch Comp Sci, Tel Aviv, Israel.
EM morgeva@mail.tau.ac.il; tomerwol@mail.tau.ac.il; joberant@cs.tau.ac.il
CR Alzantot M, 2018, P 2018 C EMPIRICAL M, V0, PP2890, DOI 10.18653/v1/D18-1316
   Asai Akari, 2020, INT C LEARNING REPRE, V0, P0
   Asai Akari, 2020, P 58 ANN M ASS COMPU, V0, P5642
   Bitton Y, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P94
   Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924
   Devlin J, 2018, ARXIV, V1, P4171
   Du XY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1342, DOI 10.18653/v1/P17-1123
   Dua D, 2021, ARXIV, V0, P0
   Dua Dheeru, 2019, N AM CHAPTER ASS COM, V0, P0
   Duan N, 2017, P 2017 C EMP METH NA, V0, PP866, DOI 10.18653/V1/D17-1090
   Ferguson J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1137
   Finegan-Dollak C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P351
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gardner Matt, 2020, FINDINGS ASS COMPUTA, V0, P1307
   Goel K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), V0, P42
   Jia Robin, 2017, P 2017 C EMP METH NA, V0, PP2021, DOI 10.18653/V1/D17-1215
   Joshi N, 2022, ARXIV, V0, P0
   Kaushik Divyansh, 2021, ASS COMPUTATIONAL LI, V0, P0, DOI DOI 10.18653/v1/2021.acl-long.517
   Kaushik Divyansh, 2020, INT C LEARNING REPRE, V0, P0
   Keysers Daniel, 2020, INT C LEARNING REPRE, V0, P0
   Khashabi D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P163
   Khashabi Daniel, 2020, FINDINGS ASS COMPUTA, V0, PP1896, DOI 10.18653/V1/2020.FINDINGS-EMNLP.171
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lewis Mike, 2020, P 58 ANN M ASS COMPU, V0, PP7871, DOI 10.18653/V1/2020.ACL-MAIN.703
   Li C, 2020, P 3 BLACKBOXNLP WORK, V0, PP126, DOI 10.18653/V1/2020.BLACKBOXNLP-1.12
   Liu YH, 2019, ARXIV, V0, P0
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3428
   Mille S, 2021, 35 C NEURAL INFORM P, V0, P0
   Naik A, 2018, P 27 INT C COMPUTATI, V0, P2340
   Nan LY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), V0, P432
   Nangia N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1221
   Novikova J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), V0, P201
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   Rajpurkar Pranav, 2016, ARXIV, V0, P2383
   Rakshit Geetanjali, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Ribeiro Marco Tulio, 2020, P 58 ANN M ASS COMPU, V0, PP4902, DOI 10.18653/V1/2020.ACL-MAIN.442
   Ross A, 2022, ARXIV, V0, P0
   Segal E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P3074
   Shu Chang, 2021, FINDINGS ASS COMPUTA, V0, PP4414, DOI 10.18653/v1/2021.findings-acl.388
   Wang SY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P9066
   Wolfson T, 2020, T ASSOC COMPUT LING, V8, P183, DOI 10.1162/tacl_a_00309
   Wu Tongshuang, 2021, P 59 ANN M ASS COMP, V1, P0, DOI 10.18653/v1/2021.acl long. 523
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2369
NR 43
TC 1
Z9 1
U1 1
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 
EI 2307-387X
J9 T ASSOC COMPUT LING
JI Trans. Assoc. Comput. Linguist.
PD FEB 9
PY 2022
VL 10
IS 
BP 111
EP 126
DI 10.1162/tacl_a_00450
PG 16
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA 8K9NR
UT WOS:000923420100001
DA 2023-11-10
ER

PT J
AU Chen, YW
   Tsai, YH
   Yang, MH
AF Chen, Yi-Wen
   Tsai, Yi-Hsuan
   Yang, Ming-Hsuan
TI Understanding Synonymous Referring Expressions via Contrastive Features
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article
DE Referring expression comprehension; Contrastive learning; Transfer learning; Synonymous sentences
AB Referring expression comprehension aims to localize objects identified by natural language descriptions. This is a challenging task as it requires understanding of both visual and language domains. One nature is that each object can be described by synonymous sentences with paraphrases, and such varieties in languages have critical impact on learning a comprehension model. While prior work usually treats each sentence and attends it to an object separately, we focus on learning a referring expression comprehension model that considers the property in synonymous sentences. To this end, we develop an end-to-end trainable framework to learn contrastive features on the image and object instance levels, where features extracted from synonymous sentences to describe the same object should be closer to each other after mapping to the visual domain. We conduct extensive experiments to evaluate the proposed algorithm on several benchmark datasets, and demonstrate that our method performs favorably against the state-of-the-art approaches. Furthermore, since the varieties in expressions become larger across datasets when they describe objects in different ways, we present the cross-dataset and transfer learning settings to validate the ability of our learned transferable features.
C1 [Chen, Yi-Wen; Yang, Ming-Hsuan] Univ Calif Merced, Merced, CA 95343 USA.
   [Tsai, Yi-Hsuan] Phiar, Redwood City, CA USA.
C3 University of California System; University of California Merced
RP Yang, MH (通讯作者)，Univ Calif Merced, Merced, CA 95343 USA.
EM ychen319@ucmerced.edu; wasidennis@gmail.com; mhyang@ucmerced.edu
CR Chen L, 2021, AAAI CONF ARTIF INTE, V35, P1036
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chen Yi-Wen, 2019, BMVC, V0, P0
   Chen Z, 2020, CVPR, V0, P0
   Deng Jiajun, 2021, ICCV, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Gan Zhe, 2020, NEURIPS, V2, P0
   Hadsell R, 2006, P 2006 IEEE COMP SOC, V2, P1735, DOI 10.1109/CVPR.2006.100
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/ICCV.2017.322
   He Kaiming, 2020, P IEEE CVF C COMP VI, V0, PP9729, DOI 10.1109/CVPR42600.2020.00975
   Hu RH, 2016, PROC CVPR IEEE, V0, PP4555, DOI 10.1109/CVPR.2016.493
   Huang BB, 2021, PROC CVPR IEEE, V0, PP16883, DOI 10.1109/CVPR46437.2021.01661
   Hudson DA, 2019, PROC CVPR IEEE, V0, PP6693, DOI 10.1109/CVPR.2019.00686
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Kaiming He, 2016, 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP770, DOI 10.1109/CVPR.2016.90
   Kalantidis Yannis, 2020, NEURIPS, V2, P3
   Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, V0, PP787, DOI 10.3115/V1/D14-1086
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kipf T N, 2016, ICLR, V0, P0
   Liao Yue, 2020, CVPR, V0, PP10880, DOI 10.1109/CVPR42600.2020.01089
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JY, 2017, IEEE I CONF COMP VIS, V0, PP4866, DOI 10.1109/ICCV.2017.520
   Liu XH, 2019, PROC CVPR IEEE, V0, PP1950, DOI 10.1109/CVPR.2019.00205
   Lu JS, 2019, ADV NEUR IN, V32, P0
   Luo RT, 2017, PROC CVPR IEEE, V0, PP3125, DOI 10.1109/CVPR.2017.333
   Mao JH, 2016, PROC CVPR IEEE, V0, PP11, DOI 10.1109/CVPR.2016.9
   Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Sadhu A, 2019, IEEE I CONF COMP VIS, V0, PP4693, DOI 10.1109/ICCV.2019.00479
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Sibei Yang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12364), V0, PP589, DOI 10.1007/978-3-030-58529-7_35
   Sohn K, 2016, ADV NEUR IN, V29, P0
   Van den Oord Aaron, 2018, ARXIV, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang L, 2016, PROC CVPR IEEE, V0, PP5005, DOI 10.1109/CVPR.2016.541
   Xiujun I, 2020, ECCV, V0, P0
   Yamaguchi M, 2017, IEEE I CONF COMP VIS, V0, PP1462, DOI 10.1109/ICCV.2017.162
   Yang SB, 2019, IEEE I CONF COMP VIS, V0, PP4643, DOI 10.1109/ICCV.2019.00474
   Yang ZY, 2019, IEEE I CONF COMP VIS, V0, PP4682, DOI 10.1109/ICCV.2019.00478
   Yang Zhengyuan, 2020, ECCV, V0, P0
   Yen-Chun Chen, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12375), V0, PP104, DOI 10.1007/978-3-030-58577-8_7
   Yu LC, 2018, PROC CVPR IEEE, V0, PP1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2017, PROC CVPR IEEE, V0, PP3521, DOI 10.1109/CVPR.2017.375
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zhang HW, 2018, PROC CVPR IEEE, V0, PP4158, DOI 10.1109/CVPR.2018.00437
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhuang BH, 2018, PROC CVPR IEEE, V0, PP4252, DOI 10.1109/CVPR.2018.00447
NR 49
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD OCT 15
PY 2022
VL 130
IS 10
BP 2501
EP 2516
DI 10.1007/s11263-022-01647-z
EA AUG 2022
PG 16
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 4L1FI
UT WOS:000839412400001
DA 2023-11-10
ER

PT J
AU Zandie, R
   Mahoor, MH
AF Zandie, Rohola
   Mahoor, Mohammad H.
TI Topical language generation using transformers
SO NATURAL LANGUAGE ENGINEERING
LA English
DT Article; Early Access
DE Natural language generation; Probabilistic model; Topical language generation; Transformers
AB Large-scale transformer-based language models (LMs) demonstrate impressive capabilities in open-text generation. However, controlling the generated text's properties such as the topic, style, and sentiment is challenging and often requires significant changes to the model architecture or retraining and fine-tuning the model on new supervised data. This paper presents a novel approach for topical language generation (TLG) by combining a pre-trained LM with topic modeling information. We cast the problem using Bayesian probability formulation with topic probabilities as a prior, LM probabilities as the likelihood, and TLG probability as the posterior. In learning the model, we derive the topic probability distribution from the user-provided document's natural structure. Furthermore, we extend our model by introducing new parameters and functions to influence the quantity of the topical features presented in the generated text. This feature would allow us to easily control the topical properties of the generated text. Our experimental results demonstrate that our model outperforms the state-of-the-art results on coherency, diversity, and fluency while being faster in decoding.
C1 [Zandie, Rohola; Mahoor, Mohammad H.] Univ Denver, Dept Elect & Comp Engn, Denver, CO 80208 USA.
C3 University of Denver
RP Mahoor, MH (通讯作者)，Univ Denver, Dept Elect & Comp Engn, Denver, CO 80208 USA.
EM mohammad.mahoor@du.edu
CR Baheti A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P3970
   Baldi P, 2010, NEURAL NETWORKS, V23, P649, DOI 10.1016/j.neunet.2009.12.007
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bowman Samuel R, 2015, ARXIV151106349, V0, P0
   Brown TB, 2020, P 34 INT C NEUR INF, V0, P0
   Correia GM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2174
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dethlefs N, 2015, NAT LANG ENG, V21, P391, DOI 10.1017/S1351324913000375
   Dziri N, 2018, ARXIV181101063, V0, P0
   Fu ZX, 2018, AAAI CONF ARTIF INTE, V0, P663
   Gage Philip, 1994, C USERS J ARCHIVE, V12, P23, DOI 10.5555/177910.177914
   Ghazvininejad M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP43, DOI 10.18653/v1/P17-4008
   Goodfellow I, 2016, ARXIV170100160, V0, P0, DOI DOI 10.1038/NATURE14539
   Gopalakrishnan K, 2019, INTERSPEECH, V0, PP1891, DOI 10.21437/Interspeech.2019-3079
   Guo JX, 2018, AAAI CONF ARTIF INTE, V0, P5141
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Hoffman Matthew, 2010, ADV NEURAL INFORM PR, V0, P856
   Holtzman A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1638
   Holtzman Ari, 2020, ICLR, V0, P0
   Hu Z, 2017, PR MACH LEARN RES, V0, P0
   Huang J, 2005, MAXIMUM LIKELIHOOD E, V0, P0
   Kannan A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP955, DOI 10.1145/2939672.2939801
   Keskar Nitish Shirish, 2019, CTRL CONDITIONAL TRA, V0, P0
   Lau JH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P355, DOI 10.18653/v1/P17-1033
   Li J, 2018, P 2018 C N AM CHAPT, V1, P1865, DOI 10.18653/V1/N18-1169
   Li M, 2020, P 58 ANN M ASS COMPU, V0, PP4715, DOI 10.18653/V1/2020.ACL-MAIN.428
   Malandrakis N, 2019, P 3 WORKSHOP NEURAL, V0, PP90, DOI 10.18653/v1/d19-5609
   Martins AFT, 2016, PR MACH LEARN RES, V48, P0
   Mikolov Tomas, 2013, INT C LEARN REPR, V0, P0
   Mueller J, 2017, P 34 INT C MACHINE L, V0, P2536
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2463
   Prabhumoye S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P866
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Röder M, 2015, WSDM15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP399, DOI 10.1145/2684822.2685324
   See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702
   Singh A, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Stahlberg F, 2018, P 3 C MACH TRANSL RE, V0, PP204, DOI 10.18653/V1/W18-6321
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Welleck Sean, 2020, ABS190804319 ARXIV, V0, P0
   Xing C, 2017, AAAI CONF ARTIF INTE, V0, P3351
   Xu JJ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P979
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
   Zhang Y, 2018, LONG PAPERS, V1, P1528
   Zhao Y, 2018, INT C LEARN REPR, V0, P0
NR 46
TC 1
Z9 1
U1 4
U2 17
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1351-3249
EI 1469-8110
J9 NAT LANG ENG
JI Nat. Lang. Eng.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1017/S1351324922000031
EA FEB 2022
PG 23
WC Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA YT1QE
UT WOS:000751141300001
DA 2023-11-10
ER

PT J
AU Smetanin, S
AF Smetanin, Sergey
TI RuSentiTweet: a sentiment analysis dataset of general domain tweets in Russian
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Sentiment dataset; Sentiment analysis; Russian
ID twitter; recognition; emotion
AB The Russian language is still not as well-resourced as English, especially in the field of sentiment analysis of Twitter content. Though several sentiment analysis datasets of tweets in Russia exist, they all are either automatically annotated or manually annotated by one annotator. Thus, there is no inter-annotator agreement, or annotation may be focused on a specific domain. In this article, we present RuSentiTweet, a new sentiment analysis dataset of general domain tweets in Russian. RuSentiTweet is currently the largest in its class for Russian, with 13,392 tweets manually annotated with moderate inter-rater agreement into five classes: Positive, Neutral, Negative, Speech Act, and Skip. As a source of data, we used Twitter Stream Grab, a historical collection of tweets obtained from the general Twitter API stream, which provides a 1% sample of the public tweets. Additionally, we released a RuBERT-based sentiment classification model that achieved F-1 = 0.6594 on the test subset.
C1 [Smetanin, Sergey] Natl Res Univ Higher Sch Econ, Grad Sch Business, Dept Business Informat, Moscow, Russia.
C3 HSE University (National Research University Higher School of Economics)
RP Smetanin, S (通讯作者)，Natl Res Univ Higher Sch Econ, Grad Sch Business, Dept Business Informat, Moscow, Russia.
EM sismetanin@gmail.com
CR Abu Kausar M, 2021, INT J ADV COMPUT SC, V12, P415
   Ahmadi Z, 2017, LECT NOTES ARTIF INT, V10558, P144, DOI 10.1007/978-3-319-67786-6_11
   Aly M, 2013, P 51 ANN M ASS COMP, V2, P494
   [Anonymous], 2016, PROC COMPUT LINGUIST, V0, P0
   [Anonymous], 2013, COMPUT LINGUIST, V0, P0
   [Anonymous], 2016, INT J SOCIAL SCI HUM, V0, P0, DOI DOI 10.7763/IJSSH.2016.V6.640
   Antonakaki D, 2021, EXPERT SYST APPL, V164, P0, DOI 10.1016/j.eswa.2020.114006
   Araslanov E, 2020, 2020 INT C DATA ANAL, V0, P1
   Arefyev A, 2013, DEMOSCOPE WEEKLY, V0, P571
   Babakov N, 2021, P 8 WORKSHOP BALTO S, V0, P26
   Babakov N, 2022, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2203.02392
   Babii Alexander, 2021, WEBSCI 21: 13TH ACM WEB SCIENCE CONFERENCE 2021, V0, PP112, DOI 10.1145/3447535.3462499
   Babii A, 2020, COMPUT LINGUIST, V1002, P0
   Barnes J, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, V0, P12
   Baylis P, 2020, J PUBLIC ECON, V184, P0, DOI 10.1016/j.jpubeco.2020.104161
   Baylis P, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0195750
   Baymurzina D, 2019, PROC INT C DIALOGUE, V18, P53
   Beckler DT, 2018, BMC MED RES METHODOL, V18, P0, DOI 10.1186/s12874-018-0606-7
   Bermingham A, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP784, DOI 10.1145/1571941.1572127
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Bird Steven, 2009, NATURAL LANGUAGE PRO, V0, P0
   Borodkina O, 2019, LECT NOTES COMPUT SC, V11938, P32, DOI 10.1007/978-3-030-34770-3_3
   Buntoro GA, 2016, INT J COMPUTER APPL, V136, P23, DOI 10.5120/IJCA2016908288
   Chetviorkin I, 2013, PROC INT C DIALOGUE, V2, P1
   Chetvirokin I, 2013, COMPUT LINGUIST, V0, P2
   Chizhik A, 2016, NEW INFORM TECHNOLOG, V19, P61
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dzogang Fabon, 2017, BRAIN NEUROSCI ADV, V1, P2398212817744501, DOI 10.1177/2398212817744501
   Dzogang F, 2017, LECT NOTES COMPUT SC, V10584, P63, DOI 10.1007/978-3-319-68765-0_6
   Fiok K, 2021, EXPERT SYST APPL, V186, P0, DOI 10.1016/j.eswa.2021.115771
   Golubev A, 2020, ARTIF INTELL, V0, P109
   Hillaire G, 2021, OPEN WORLD LEARNING, V0, PP171, DOI 10.4324/9781003177098-15
   Hillaire GE, 2021, UNDERSTANDING EMOTIO, V0, P0
   Khiabani PJ, 2020, J INF SCI, V46, P340, DOI 10.1177/0165551519837187
   Kanev Anton I, 2022, 2022 CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (ELCONRUS), V0, PP326, DOI 10.1109/ElConRus54750.2022.9755568
   Kazyulina M, 2020, INT C ANAL IMAGES SO, V0, P135
   Kirilenko AP, 2017, TOURISM MANAGE, V63, P54, DOI 10.1016/j.tourman.2017.06.007
   Konstantinov A, 2021, RECENT RES CONTROL E, V0, P462
   Korablinov Vladislav, 2020, THE SEMANTIC WEB - ISWC 2020. 19TH INTERNATIONAL SEMANTIC WEB CONFERENCE. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12507), V0, PP97, DOI 10.1007/978-3-030-62466-8_7
   Kostenetskiy PS, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1740, P0, DOI 10.1088/1742-6596/1740/1/012050
   Kotelnikov E, 2021, COMPUT LINGUIST, V0, P433
   Kotelnikova AV, 2020, 2020 INT MULTICONFER, V0, PP1, DOI 10.1109/FarEastCon50210.2020.9271333
   Krippendorff K, 2004, HUM COMMUN RES, V30, P411, DOI 10.1111/j.1468-2958.2004.tb00738.x
   Krippendorff K, 1980, CONTENT ANAL INTRO I, V0, P0
   Kumar P, 2022, NEURAL NETWORKS, V150, P392, DOI 10.1016/j.neunet.2022.03.017
   Kuratov Y, 2019, ABS190507213 CORR, V0, P0
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Larsen ME, 2015, IEEE J BIOMED HEALTH, V19, P1246, DOI 10.1109/JBHI.2015.2403839
   Leetaru K, 2019, FORBES, V0, P0
   Li MD, 2018, IND MANAGE DATA SYST, V118, P1804, DOI 10.1108/IMDS-12-2017-0582
   Lopatin V, 2017, LANGUAGES WORLD, V0, P276
   Loukachevitch NV, 2015, COMPUT LINGUIST, V2, P3
   Lukashevich N, 2016, PROC INT C DIALOGUE, V0, P416
   Mozetic I, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0155036
   Muhammad SH, 2022, ARXIV, V0, P0
   Pak A, 2012, COMPUT LINGUIST, V11, P37
   Pavliy B, 2016, B TOYAMA U INT STUDI, V8, P99
   Pontiki M, 2016, P 10 INT WORKSH SEM, V0, PP19, DOI 10.18653/V1/S16-1002
   Pronoza E, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2021.102674
   Read J, 2005, P ACL STUDENT RES WO, V0, PP43, DOI 10.3115/1628960.1628969
   Rodina Julia, 2020, P 28 INT C COMP LING, V0, P1037
   Rogers Anna, 2018, P 27 INT C COMP LING, V0, P755
   Rosstat, 2022, MAN PEOPL LIV RUSS R, V0, P0
   Rubtsova Y, 2013, T 15 VSEROSSIISKOY N, V0, P269
   Salminen JO, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, V0, P80, DOI 10.1109/SNAMS.2018.8554744
   Smetanin S, 2020, COMPUT LINGUIST, V0, P0
   [Сметанин СИSmetanin SI], 2017, ТРУДЫ ИНСТИТУТА СИСТЕМНОГО ПРОГРАММИРОВАНИЯ РАН TRUDY INSTITUTA SISTEMNOGO PROGRAMMIROVANIYA RAN, V29, P315, DOI 10.15514/ISPRAS-2017-29(4)-22
   Smetanin S, 2021, CONF BUS INFORM, V0, PP65, DOI 10.1109/CBI52690.2021.10056
   Smetanin S, 2021, INFORM PROCESS MANAG, V58, P0, DOI 10.1016/j.ipm.2020.102484
   Smetanin S, 2020, IEEE ACCESS, V8, P110693, DOI 10.1109/ACCESS.2020.3002215
   Smetanin S, 2019, CONF BUS INFORM, V0, PP482, DOI 10.1109/CBI.2019.00062
   Szczepanski M, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-03100-6
   Szmigiera M, 2022, MOST SPOKEN LANGUAGE, V0, P0
   ten Thij M, 2014, P INT C DAT AN DAT A, V0, P12
   Tripto NI, 2018, 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING (ICBSLP), V0, P0
   Wang YZ, 2015, ACM T WEB, V9, P0, DOI 10.1145/2746366
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Zueva N, 2020, P 4 WORKSHOP ONLINE, V0, P0, DOI DOI 10.18653/V1/2020.ALW-1.8
NR 78
TC 2
Z9 2
U1 1
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 19
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.1039
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA 9Y3LM
UT WOS:000950360900003
PM 36092008
DA 2023-11-10
ER

PT J
AU Yan, SY
   Zhao, JN
   Xu, L
AF Yan, Shiyang
   Zhao, Jianan
   Xu, Lin
TI Adaptive multi-task learning for cross domain and modal person re-identification
SO NEUROCOMPUTING
LA English
DT Article
DE Multi -task learning; Deep metric learning; Transfer learning; Cross modal Fusion; Person re-identification
ID similarity
AB Person re-identification (re-ID) aims at matching a person-of-interest across various non-overlap cam-eras with distinguished visual appearance variances. Pre-existing research methods mainly employ deep neural models to train large-scale person re-ID datasets, achieving good performance. However, these methods are primarily deployed only on visual data, which can be easily influenced by the environment variances (e.g., viewpoints, poses, and illuminations). In this paper, we propose an adaptive multi-task learning (MTL) scheme for cross domain and modal person re-ID. It can effectively utilize the visual and language information from multiple datasets for improving learning performance. Comprehensive experiments are also conducted on the widely-used person re-ID datasets, i.e., Market-1501 and DukeMTMC-reID, validating the effectiveness of the proposed method. It can model the domain differ-ence and the relationship between the vision and language modalities and achieve state-of-the-art per-formance. The source code of our proposed method will be available at https://github.com/emdata-ailab/ Multitask_Learning_ReID.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Yan, Shiyang] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing, Peoples R China.
   [Zhao, Jianan; Xu, Lin] Shanghai Em Data Technol Co Ltd, Shanghai, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Xu, L (通讯作者)，Shanghai Em Data Technol Co Ltd, Shanghai, Peoples R China.
EM lin.xu5470@gmail.com
FU National Natural Science Foundation of China [6210021502]; Natural Science Foundation of Jiangsu [BK20210646]; Shanghai Rising-Star Program [20QB1405500]; Open Project of Key Laboratory of Ministry of Public Security for Road Traffic Safety [2020ZDSYSKFKT03-1]; Development and Application of Intelligent Diagnosis System for Mixed Traffic Char-acteristics [2019-RGZN-01023]
CR Aneja J, 2018, PROC CVPR IEEE, V0, PP5561, DOI 10.1109/CVPR.2018.00583
   Bai S, 2017, AAAI CONF ARTIF INTE, V0, P1281
   Bai X, 2020, PATTERN RECOGN, V98, P0, DOI 10.1016/j.patcog.2019.107036
   Bucher M, 2016, LECT NOTES COMPUT SC, V9909, P730, DOI 10.1007/978-3-319-46454-1_44
   Chang YS, 2020, PATTERN RECOGN LETT, V130, P306, DOI 10.1016/j.patrec.2018.08.011
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chen DP, 2018, LECT NOTES COMPUT SC, V11220, P56, DOI 10.1007/978-3-030-01270-0_4
   Chen WH, 2017, PROC CVPR IEEE, V0, PP1320, DOI 10.1109/CVPR.2017.145
   Chen Z, 2018, PR MACH LEARN RES, V80, P0
   Chopra S, 2005, PROC CVPR IEEE, V0, PP539, DOI 10.1109/cvpr.2005.202
   Cornia Marcella, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10575, DOI 10.1109/CVPR42600.2020.01059
   Deng WJ, 2018, PROC CVPR IEEE, V0, PP994, DOI 10.1109/CVPR.2018.00110
   Ding G, 2019, PATTERN RECOGN LETT, V0, P91
   Fang PF, 2019, IEEE I CONF COMP VIS, V0, PP8029, DOI 10.1109/ICCV.2019.00812
   Ge Yixiao, 2018, NIPS, V0, P0
   Grabner A, 2018, PROC CVPR IEEE, V0, PP3022, DOI 10.1109/CVPR.2018.00319
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   He XW, 2018, PROC CVPR IEEE, V0, PP1945, DOI 10.1109/CVPR.2018.00208
   Kendall A, 2018, PROC CVPR IEEE, V0, PP7482, DOI 10.1109/CVPR.2018.00781
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, V0, PP418, DOI 10.1109/CVPRW.2016.59
   Li DW, 2017, PROC CVPR IEEE, V0, PP7398, DOI 10.1109/CVPR.2017.782
   Li S, 2017, PROC CVPR IEEE, V0, PP5187, DOI 10.1109/CVPR.2017.551
   Li W, 2014, PROC CVPR IEEE, V0, PP152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, V0, PP2197, DOI 10.1109/CVPR.2015.7298832
   Lin X, 2019, ADV NEUR IN, V32, P0
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu J, 2016, ACMMM, V0, P0
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Miao JX, 2019, IEEE I CONF COMP VIS, V0, PP542, DOI 10.1109/ICCV.2019.00063
   Schumann A, 2017, IEEE COMPUT SOC CONF, V0, PP1435, DOI 10.1109/CVPRW.2017.186
   Shi YX, 2021, IEEE T MULTIMEDIA, V23, P3264, DOI 10.1109/TMM.2020.3023272
   Song HO, 2016, PROC CVPR IEEE, V0, PP4004, DOI 10.1109/CVPR.2016.434
   Su C, 2017, IEEE I CONF COMP VIS, V0, PP3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, V0, PP3820, DOI 10.1109/ICCV.2017.410
   Tao R, 2016, PROC CVPR IEEE, V0, PP1420, DOI 10.1109/CVPR.2016.158
   Wei LH, 2018, PROC CVPR IEEE, V0, PP79, DOI 10.1109/CVPR.2018.00016
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wohlhart P, 2015, PROC CVPR IEEE, V0, PP3109, DOI 10.1109/CVPR.2015.7298930
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Yan F, 2018, INT C PATT RECOG, V0, PP2136, DOI 10.1109/ICPR.2018.8545582
   Yan S, 2018, ICPR, V0, P0
   Yan SY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5342
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Yi D, 2014, INT C PATT RECOG, V0, PP34, DOI 10.1109/ICPR.2014.16
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Yu T, 2020, ICLR, V0, P0
   Zhai Y, 2019, IEEE COMPUT SOC CONF, V0, PP1526, DOI 10.1109/CVPRW.2019.00194
   Zhang G, 2018, ACML, V0, P0
   Zhang Y, 2016, ICML, V0, P0
   Zhang ZZ, 2020, PROC CVPR IEEE, V0, PP3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZM, 2016, PROC CVPR IEEE, V0, PP6034, DOI 10.1109/CVPR.2016.649
   Zhao LM, 2017, IEEE I CONF COMP VIS, V0, PP3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2015, PROC CVPR IEEE, V0, PP1741, DOI 10.1109/CVPR.2015.7298783
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, P0, DOI 10.1145/3159171
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, V0, PP3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, PROC CVPR IEEE, V0, PP3652, DOI 10.1109/CVPR.2017.389
NR 67
TC 0
Z9 0
U1 5
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAY 14
PY 2022
VL 486
IS 
BP 123
EP 134
DI 10.1016/j.neucom.2021.11.016
EA MAR 2022
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0V1ZM
UT WOS:000788143500010
DA 2023-11-10
ER

PT J
AU Rouhou, AC
   Dhiaf, M
   Kessentini, Y
   Ben Salem, S
AF Rouhou, Ahmed Cheikh
   Dhiaf, Marwa
   Kessentini, Yousri
   Ben Salem, Sinda
TI Transformer-based approach for joint handwriting and named entity recognition in historical document
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Named-entity-recognition; Text block recognition; Transformer; IEHHR competition
AB The extraction of relevant information carried out by named entities in handwriting documents is still a challenging task. Unlike traditional information extraction approaches that usually face text transcription and named entity recognition as separate subsequent tasks, we propose in this paper an end-to-end transformer-based approach to jointly perform these two tasks. The proposed approach operates at the paragraph level, which brings two main benefits. First, it allows the model to avoid unrecoverable early errors due to line segmentation. Second, it allows the model to exploit larger bi-dimensional context information to identify the semantic categories, reaching a higher final prediction accuracy. We also explore different training scenarios to show their effect on the performance and we demonstrate that a two-stage learning strategy can make the model reach a higher final prediction accuracy. As far as we know, this work presents the first approach that adopts the transformer networks for named entity recognition in handwritten documents. We achieve the new state-of-the-art performance in the ICDAR 2017 Information Extraction competition using the Esposalles database, for the complete task, even though the proposed technique does not use any dictionaries, language modeling, or post-processing. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Rouhou, Ahmed Cheikh; Dhiaf, Marwa; Ben Salem, Sinda] InstaDeep, Tunis, Tunisia.
   [Dhiaf, Marwa; Kessentini, Yousri] Digital Res Ctr Sfax, Sfax, Tunisia.
   [Dhiaf, Marwa; Kessentini, Yousri] SM RTS Lab Signals Syst aRtificial Intelligence &, Sfax, Tunisia.
C3 Centre de Recherche en Numerique de Sfax (CRNS); Universite de Sfax
RP Rouhou, AC (通讯作者)，InstaDeep, Tunis, Tunisia.
EM a.cheikhrouhou@instadeep.com
CR Bluche T, 2017, PROC INT CONF DOC, V0, PP1050, DOI 10.1109/ICDAR.2017.174
   Carbonell M, 2020, PATTERN RECOGN LETT, V136, P219, DOI 10.1016/j.patrec.2020.05.001
   Carbonell M, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), V0, PP399, DOI 10.1109/DAS.2018.52
   Coquenet D, 2020, ARXIV201203868, V0, P0
   Deng YT, 2017, PR MACH LEARN RES, V70, P0
   Dhiaf M, 2021, 28 INT C NEURAL INFO, V0, P0
   Dinarelli M, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1266
   Fornés A, 2017, PROC INT CONF DOC, V0, PP1389, DOI 10.1109/ICDAR.2017.227
   Hamdi A, 2019, ACM-IEEE J CONF DIG, V0, PP333, DOI 10.1109/JCDL.2019.00057
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Toledo JI, 2019, PATTERN RECOGN, V86, P27, DOI 10.1016/j.patcog.2018.08.020
   Kang L, 2020, CORR, V0, P0
   Lee J, 2020, IEEE COMPUT SOC CONF, V0, PP2326, DOI 10.1109/CVPRW50498.2020.00281
   Martin L, 2019, CAMEMBERT TASTY FREN, V0, P0
   Mechi Olfa, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP369, DOI 10.1109/ICDAR.2019.00066
   Michael Johannes, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1286, DOI 10.1109/ICDAR.2019.00208
   Monnier T, 2020, INT CONF FRONT HAND, V0, PP91, DOI 10.1109/ICFHR2020.2020.00027
   Romero V, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING (HIP 19), V0, PP66, DOI 10.1145/3352631.3352637
   Romero V, 2013, PATTERN RECOGN, V46, P1658, DOI 10.1016/j.patcog.2012.11.024
   Ruokolainen T, 2020, NAME NAME NAMED ENTI, V2612, P136
   Schall M, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), V0, PP405, DOI 10.1109/DAS.2018.36
   Souibgui MA, 2020, IEEE T PATTERN ANAL, V0, P0
   Souibgui MA, 2021, INT C PATT RECOG, V0, PP5413, DOI 10.1109/ICPR48806.2021.9413255
   Toledo JI, 2016, S SSPR, V0, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Xie ZC, 2019, NEUROCOMPUTING, V350, P271, DOI 10.1016/j.neucom.2019.04.001
   Yousef M, 2020, CORR, V0, P0
NR 27
TC 11
Z9 11
U1 6
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD MAR 15
PY 2022
VL 155
IS 
BP 128
EP 134
DI 10.1016/j.patrec.2021.11.010
EA MAR 2022
PG 7
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1N0OC
UT WOS:000800362500018
DA 2023-11-10
ER

PT J
AU Huang, T
   Luo, T
   Yan, M
   Zhou, JT
   Goh, R
AF Huang, Tian
   Luo, Tao
   Yan, Ming
   Zhou, Joey Tianyi
   Goh, Rick
TI RCT: Resource Constrained Training for Edge AI
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Training; Quantization (signal); Memory management; Neural networks; Computational modeling; System-on-chip; Program processors; Efficient training; memory efficient; neural network; quantization; weight update
ID neural-networks
AB Efficient neural network training is essential for in situ training of edge artificial intelligence (AI) and carbon footprint reduction in general. Train neural network on the edge is challenging because there is a large gap between limited resources on edge and the resource requirement of current training methods. Existing training methods are based on the assumption that the underlying computing infrastructure has sufficient memory and energy supplies. These methods involve two copies of the model parameters, which is usually beyond the capacity of on-chip memory in processors. The data movement between off-chip and on-chip memory incurs large amounts of energy. We propose resource constrained training (RCT) to realize resource-efficient training for edge devices and servers. RCT only keeps a quantized model throughout the training so that the memory requirement for model parameters in training is reduced. It adjusts per-layer bitwidth dynamically to save energy when a model can learn effectively with lower precision. We carry out experiments with representative models and tasks in image classification, natural language processing, and crowd counting applications. Experiments show that on average, 8-15-bit weight update is sufficient for achieving SOTA performance in these applications. RCT saves 63.5%-80% memory for model parameters and saves more energy for communications. Through experiments, we observe that the common practice on the first/last layer in model compression does not apply to efficient training. Also, interestingly, the more challenging a dataset is, the lower bitwidth is required for efficient training.
C1 [Huang, Tian; Luo, Tao; Goh, Rick] ASTAR, Inst High Performance Comp, Singapore 138632, Singapore.
   [Yan, Ming; Zhou, Joey Tianyi] ASTAR, Ctr Frontier AI Res, Singapore 138632, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); Agency for Science Technology & Research (A*STAR)
RP Luo, T (通讯作者)，ASTAR, Inst High Performance Comp, Singapore 138632, Singapore.
EM huang_tian@ihpc.a-star.edu.sg; leto.luo@gmail.com; yan_ming@ihpc.a-star.edu.sg; joey_zhou@ihpc.a-star.edu.sg; gohsm@ihpc.a-star.edu.sg
FU Singapore Government's Research, Innovation and Enterprise 2020 Plan (Advanced Manufacturing and Engineering Domain) [A1687b0033, A1892b0026, A18A1b0045]; SERC Central Research Fund (Use-Inspired Basic Research)
CR Bai HL, 2021, ARXIV, V0, P0
   Banner Ron, 2018, ADV NEURAL INFORM PR, V0, PP5151, DOI 10.5555/3327345.3327421
   Baskin C, 2018, ARXIV, V0, P0
   Chan AB, 2008, PROC CVPR IEEE, V0, PP1766, DOI 10.1109/cvpr.2008.4587569
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Choukroun Y, 2019, IEEE INT CONF COMP V, V0, PP3009, DOI 10.1109/ICCVW.2019.00363
   Dettmers T, 2019, ARXIV, V0, P0
   Devlin J, 2019, ARXIV, V0, P0
   Fang J, 2020, ARXIV, V0, P0
   Frankle Jonathan, 2019, ARXIV, V0, P0
   Gale T, 2019, ARXIV, V0, P0
   Gao GS, 2020, ARXIV, V0, P0
   Gong RH, 2019, IEEE I CONF COMP VIS, V0, PP4851, DOI 10.1109/ICCV.2019.00495
   Gou JP, 2021, ARXIV, V0, P0
   Guo Kaiyuan, 2018, ARXIV, V0, P0
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gustafson JL, 2017, END ERROR UNUM COMPU, V0, P0
   Han SY, 2016, IEEE ICC, V0, P0, DOI DOI 10.1109/ICC.2016.7511104
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Huang T, 2022, J PARALLEL DISTR COM, V166, P95, DOI 10.1016/j.jpdc.2022.04.005
   Huang T, 2020, INT CON DISTR COMP S, V0, PP1403, DOI 10.1109/ICDCS47774.2020.00185
   Huang YP, 2019, ARXIV, V0, P0
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Jacob B, 2018, PROC CVPR IEEE, V0, PP2704, DOI 10.1109/CVPR.2018.00286
   Jin Q, 2019, EFFICIENT TRAINING N, V0, P0
   Kim H, 2020, ARXIV, V0, P0
   Kim S, 2021, ARXIV, V0, P0
   Krishnamoorthi R, 2018, ARXIV, V0, P0
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2009, CIFAR 10, V0, P0
   Li C, 2018, LECT NOTES COMPUT SC, V11214, P746, DOI 10.1007/978-3-030-01249-6_45
   Li FF, 2016, ARXIV, V0, P0
   Lian DZ, 2019, PROC CVPR IEEE, V0, PP1821, DOI 10.1109/CVPR.2019.00192
   Lin H, 2020, ADV NEURAL INFORM PR, V33, P1796
   Liu CL, 2019, ARXIV, V0, P0
   Liu Z, 2019, ARXIV, V0, P0
   Luo Tao, 2021, IEEE TCAD, V0, P0
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Micikevicius Paulius, 2017, PREPRINT, V0, P0, DOI DOI 10.48550/ARXIV.1710.03740
   Nayak P, 2019, ARXIV, V0, P0
   Peng HY, 2019, PATTERN RECOGN LETT, V125, P91, DOI 10.1016/j.patrec.2019.03.026
   Rajpurkar P, 2016, ARXIV, V0, P0
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sam DB, 2021, IEEE T PATTERN ANAL, V43, P2739, DOI 10.1109/TPAMI.2020.2974830
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Shao J, 2015, PROC CVPR IEEE, V0, PP4657, DOI 10.1109/CVPR.2015.7299097
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Shkolnik M, 2020, ARXIV, V0, P0
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sohoni NS, 2022, ARXIV, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vaswani A, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1706.03762
   Wang AL, 2019, ARXIV, V0, P0
   Wang K, 2019, PROC CVPR IEEE, V0, PP8604, DOI 10.1109/CVPR.2019.00881
   Wang ZH, 2022, IEEE T NEUR NET LEAR, V0, P0, DOI DOI 10.1109/TNNLS.2022.3172941
   Wu BC, 2018, ARXIV, V0, P0
   Wu S, 2018, ARXIV, V0, P0
   Yang JW, 2019, PROC CVPR IEEE, V0, PP7300, DOI 10.1109/CVPR.2019.00748
   Yang YK, 2020, NEURAL NETWORKS, V125, P70, DOI 10.1016/j.neunet.2019.12.027
   Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), V0, PP811, DOI 10.1109/MICRO50266.2020.00071
   Zafrir O, 2019, ARXIV, V0, P0
   Zhang C, 2017, FPGA17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, V0, PP35, DOI 10.1145/3020078.3021727
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang Y, 2020, PROC INT C LEARN REP, V0, P1
   Zhou BL, 2012, PROC CVPR IEEE, V0, PP2871, DOI 10.1109/CVPR.2012.6248013
   Zhou S, 2016, ARXIV, V0, P0
   Zhou YR, 2018, AAAI CONF ARTIF INTE, V0, P4596
NR 69
TC 0
Z9 0
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2022.3190451
EA AUG 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 4C3YJ
UT WOS:000846393000001
PM 35998171
DA 2023-11-10
ER

PT J
AU Liu, Y
   Ng, MK
AF Liu, Ye
   Ng, Michael K.
TI Deep neural network compression by Tucker decomposition with nonlinear response
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Deep neural network compression; Convolution kernel; Low rank approximation; Tucker decomposition; Optimization
AB Deep neural networks have shown impressive performance in many areas, including computer vision and natural language processing. Millions of parameters in deep neural network limit its deployment in low-end devices due to intensive memory and expensive computational cost. In the literature, several network compression techniques based on tensor decompositions have been proposed to compress deep neural networks. Existing techniques are designed in each network unit by approximating linear response or kernel tensor using various tensor decomposition methods. What is more, research has shown that there exists significant redundancy between different filters and feature channels of kernel tensor in each convolution layer. In this paper, we propose a new algorithm to compress deep neural network by considering both nonlinear response and the multilinear low-rank constraint in the kernel tensor. To overcome the resulted difficulty of nonconvex optimization, we propose a convex relaxation scheme such that it can be solved by alternating direction method of multipliers (ADMM) directly. Thus, the Tucker-2 rank and the feature matrix of Tucker decomposition can be determined simultaneously. The effectiveness of the proposed method is evaluated on CIFAR-10 and large-scale ILSVRC12 datasets for CNNs including ResNet-18, AlexNet and GoogleNet. According to our numerical computation, the proposed method is able to obtain highly reduction in model size with a small loss in accuracy. The compression performance of the proposed method is better than existing methods. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Liu, Ye] South China Univ Technol, Sch Future Technol, Guangzhou, Guangdong, Peoples R China.
   [Ng, Michael K.] Univ Hong Kong, Dept Math, Pokfulam, Hong Kong, Peoples R China.
C3 South China University of Technology; University of Hong Kong
RP Liu, Y (通讯作者)，South China Univ Technol, Sch Future Technol, Guangzhou, Guangdong, Peoples R China.
EM yliu03@scut.edu.cn; mng@maths.hku.hk
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   [Anonymous], 2015, ADV NEURAL INFORM PR, V0, P0
   [Anonymous], 2015, INT C LEARNING REPRE, V0, P0
   [Anonymous], 1990, ADV NEURAL INFORM PR, V0, P0
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chen S, 1900, V2021, V0, P0
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Choi Y, 2016, ARXIV161201543, V0, P0
   Courbariaux M, 2015, ADV NEUR IN, V28, P0
   Denil Misha, 2013, ADV NEURAL INFORM PR, V0, PP2148, DOI 10.5555/2999792.2999852
   Denton Emily, 2014, ARXIV14040736, V0, P0, DOI DOI 10.5555/2968826.2968968
   Dong Yinpeng, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Gong Y, 2014, ARXIV14126115, V0, P0
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han SY, 2016, IEEE ICC, V0, P0, DOI DOI 10.1109/ICC.2016.7511104
   Hassibi B, 1993, ADV NEURAL INFORM PR, V0, PP164, DOI 10.5555/645753.668069
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He Y, 2019, PROC CVPR IEEE, V0, PP4335, DOI 10.1109/CVPR.2019.00447
   He YH, 2017, IEEE I CONF COMP VIS, V0, PP1398, DOI 10.1109/ICCV.2017.155
   Hu QH, 2018, LECT NOTES COMPUT SC, V11217, P657, DOI 10.1007/978-3-030-01261-8_39
   Hubara I, 2018, J MACH LEARN RES, V18, P0
   Jaderberg Max, 2014, ARXIV14053866, V0, P0, DOI DOI 10.5244/C.28.88
   Kim Y-D, 2015, COMPRESSION DEEP CON, V0, P0
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Li SQ, 2021, IEEE T NETW SCI ENG, V8, P2213, DOI 10.1109/TNSE.2021.3083739
   Li YW, 2019, IEEE I CONF COMP VIS, V0, PP5622, DOI 10.1109/ICCV.2019.00572
   Lyu B, 2023, IEEE T NEUR NET LEAR, V34, P1112, DOI 10.1109/TNNLS.2021.3104872
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Simonyan K, 2015, ARXIV, V0, P0
   Srinivas Suraj, 2015, ARXIV150706149, V0, P0, DOI DOI 10.5244/C.29.31
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun W, 2020, IEEE J SEL TOP SIGN, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tai Cheng, 2015, ARXIV151106067, V0, P0
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wang K, 2019, PROC CVPR IEEE, V0, PP8604, DOI 10.1109/CVPR.2019.00881
   Wen SP, 2021, IEEE T COMPUT AID D, V40, P1640, DOI 10.1109/TCAD.2020.3019993
   Wu JX, 2016, PROC CVPR IEEE, V0, PP4820, DOI 10.1109/CVPR.2016.521
   Xu Y, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Yawei Li, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8015, DOI 10.1109/CVPR42600.2020.00804
   Yu XY, 2017, PROC CVPR IEEE, V0, PP67, DOI 10.1109/CVPR.2017.15
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
NR 44
TC 8
Z9 8
U1 2
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD APR 6
PY 2022
VL 241
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.108171
EA FEB 2022
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0V2EK
UT WOS:000788156700006
DA 2023-11-10
ER

PT J
AU Pinto, JP
   Viana, P
   Teixeira, I
   Andrade, M
AF Pinto, Jose Pedro
   Viana, Paula
   Teixeira, Ines
   Andrade, Maria
TI Improving word embeddings in Portuguese: increasing accuracy while reducing the size of the corpus
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Natural language processing; Machine learning; Multimedia systems; Context awareness; Word2Vec
ID models
AB The subjectiveness of multimedia content description has a strong negative impact on tag-based information retrieval. In our work, we propose enhancing available descriptions by adding semantically related tags. To cope with this objective, we use a word embedding technique based on the Word2Vec neural network parameterized and trained using a new dataset built from online newspapers. A large number of news stories was scraped and pre-processed to build a new dataset. Our target language is Portuguese, one of the most spoken languages worldwide. The results achieved significantly outperform similar existing solutions developed in the scope of different languages, including Portuguese. Contributions include also an online application and API available for external use. Although the presented work has been designed to enhance multimedia content annotation, it can be used in several other application areas.
C1 [Pinto, Jose Pedro; Viana, Paula; Teixeira, Ines; Andrade, Maria] INESC TEC, Porto, Portugal.
   [Viana, Paula] Polytech Porto, Sch Engn, Porto, Portugal.
   [Andrade, Maria] Univ Porto, Fac Engn, Porto, Portugal.
C3 INESC TEC; Instituto Politecnico do Porto; Universidade do Porto
RP Viana, P (通讯作者)，INESC TEC, Porto, Portugal.; Viana, P (通讯作者)，Polytech Porto, Sch Engn, Porto, Portugal.
EM paula.viana@inesctec.pt
CR Baek JW, 2021, MULTIMED TOOLS APPL, V80, P34499, DOI 10.1007/s11042-019-08607-9
   Bhardwaj A, 2018, DEEP LEARNING ESSENT, V0, P0
   Bojanowski P, 2017, ARXIV, V0, P0
   Bruni E, 2011, P GEMS 2011 WORKSH G, V0, P22
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Chamberlain Benjamin P, 2020, RECSYS 20: FOURTEENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS, V0, PP732, DOI 10.1145/3383313.3418486
   Dridi A, 2019, IEEE ACCESS, V7, P176414, DOI 10.1109/ACCESS.2019.2957440
   Dusserre E, 2017, IWCS, V0, P0
   Hartmann N, 2017, ARXIV, V0, P0
   Hinton GE, 1986, P 8 ANN C COGN SCI S, V1, P12, DOI 10.1109/69.917563
   Hofstatter Sebastian, 2019, ADVANCES IN INFORMATION RETRIEVAL. 41ST EUROPEAN CONFERENCE ON IR RESEARCH, V0, P810, DOI 10.1007/978-3-030-15712-8_57
   Hu K, 2019, INFORM PROCESS MANAG, V56, P1185, DOI 10.1016/j.ipm.2019.02.014
   Nguyen HT, 2018, INFORM PROCESS MANAG, V54, P451, DOI 10.1016/j.ipm.2018.02.001
   IncF, 2020, FASTTEXT, V0, P0
   Joulin A, 2016, ARXIV, V0, P0
   Khatua A, 2019, INFORM PROCESS MANAG, V56, P247, DOI 10.1016/j.ipm.2018.10.010
   Lenci A, 2018, ANNU REV LINGUIST, V4, P151, DOI 10.1146/annurev-linguistics-030514-125254
   Liu CR, 2017, INTERSPEECH, V0, PP1686, DOI 10.21437/Interspeech.2017-965
   Mikolov T, 2013, ARXIV, V0, P0
   Tien NH, 2019, INFORM PROCESS MANAG, V56, P0, DOI 10.1016/j.ipm.2019.102090
   NLX-group, 2020, 60 4WANALOGIES, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Pinto JP, 2013, P 2013 ACM INT WORKS, V0, PP25, DOI 10.1145/2512142.2512154
   Pinto JP, 2019, ADV INTELL SYST, V833, P131, DOI 10.1007/978-3-319-98678-4_15
   Pinto JP, 2015, CVMP 2015: PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, V0, P0, DOI DOI 10.1145/2824840.2824853
   Rehurek R, 2010, P LREC 2010 WORKSHOP, V0, P45
   Rehurek R, 2019, GENSIM TOPIC MODELLI, V0, P0
   Rida-E-Fatima S, 2019, IEEE ACCESS, V7, P114795, DOI 10.1109/ACCESS.2019.2927281
   Rodrigues J, 2016, LECT NOTES ARTIF INT, V9727, P259, DOI 10.1007/978-3-319-41552-9_27
   Roy D, 2019, INFORM PROCESS MANAG, V56, P1026, DOI 10.1016/j.ipm.2018.10.009
   Santosh Kumar P, 2021, ADV INTELLIGENT SYST, V1165, P525, DOI 10.1007/978-981-15-5113-0_41
   Lee LSY, 2015, ARXIV, V0, P0
   Subba B, 2022, COMPUT INTELL-US, V38, P530, DOI 10.1111/coin.12478
   Sun F, 2016, ARXIV, V0, P0
   Svoboda L, 2016, INT C INTELLIGENT TE, V0, P103
   Svoboda L, 2017, ARXIV, V0, P0
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P384
   Venekoski V, 2017, P NODALIDA GOTH, V131, P231
   Viana P, 2017, HUM-CENT COMPUT INFO, V7, P0, DOI 10.1186/s13673-017-0094-5
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
NR 40
TC 0
Z9 0
U1 1
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JUL 18
PY 2022
VL 8
IS 
BP 
EP 
DI 10.7717/peerj-cs.964
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA C9YK0
UT WOS:000965386500001
PM 35875629
DA 2023-11-10
ER

PT J
AU Akram-Ali-Hammouri, Z
   Fernández-Delgado, M
   Cernadas, E
   Barro, S
AF Akram-Ali-Hammouri, Ziad
   Fernandez-Delgado, Manuel
   Cernadas, Eva
   Barro, Senen
TI Fast Support Vector Classification for Large-Scale Problems
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Classification; large-scale datasets; support vector machine; closed-form training; model selection
ID instance selection; optimization; kernel; parameter; machines
AB The support vector machine (SVM) is a very important machine learning algorithm with state-of-the-art performance on many classification problems. However, on large datasets it is very slow and requires much memory. To solve this defficiency, we propose the fast support vector classifier (FSVC) that includes: 1) an efficient closed-form training free of any numerical iterative procedure; 2) a small collection of class prototypes that avoids to store in memory an excessive number of support vectors; and 3) a fast method that selects the spread of the radial basis function kernel directly from data, without classifier execution nor iterative hyper-parameter tuning. The memory requirements of FSVC are very low, spending in average only 6.10(-7) sec. per pattern, input and class, and processing datasets up to 31 millions of patterns, 30,000 inputs and 131 classes in less than 1.5 hours (less than 3 hours with only 2GB of RAM). In average, the FSVC is 10 times faster, requires 12 times less memory and achieves 4.7 percent more performance than Liblinear, that fails on the 4 largest datasets by lack of memory, being 100 times faster and achieving only 6.7 percent less performance than Libsvm. The time spent by FSVC only depends on the dataset size and thus it can be accurately estimated for new datasets, while Libsvm or Liblinear are much slower on "difficult" datasets, even if they are small. The FSVC adjusts its requirements to the available memory, classifying large datasets in computers with limited memory. Code for the proposed algorithm in the Octave scientific programming language is provided.(1)
C1 [Akram-Ali-Hammouri, Ziad; Fernandez-Delgado, Manuel; Cernadas, Eva; Barro, Senen] Univ Santiago de Compostela CiTIUS, Ctr Singular Invest Tecnol Intelixentes, Santiago De Compostela 15782, Spain.
RP Fernández-Delgado, M (通讯作者)，Univ Santiago de Compostela CiTIUS, Ctr Singular Invest Tecnol Intelixentes, Santiago De Compostela 15782, Spain.
EM ziad.akram@rai.usc.es; manuel.fernandez.delgado@usc.es; eva.cernadas@usc.es; senen.barro@usc.es
FU Xunta de Galicia [2019-2022 ED431G-2019/04]; European RegionalDevelopment Fund (ERDF)
CR Bhavsar H, 2012, INT J ADV RES COMPUT, V1, P185
   Boyang Li, 2009, PROCEEDINGS 2009 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN 2009 - ATLANTA), V0, PP1784, DOI 10.1109/IJCNN.2009.5178618
   Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1961189.1961199
   Chen GX, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS
   Dai B, 2015, ARXIV, V0, P0
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fernández-Delgado M, 2014, NEURAL NETWORKS, V50, P60, DOI 10.1016/j.neunet.2013.11.002
   Friedrichs F, 2005, NEUROCOMPUTING, V64, P107, DOI 10.1016/j.neucom.2004.11.022
   Hazan E, 2011, ADV NEURAL INFORM PR, V0, P1233
   Kapp MN, 2012, APPL SOFT COMPUT, V12, P2550, DOI 10.1016/j.asoc.2012.04.001
   Liang X, 2013, PATTERN RECOGN LETT, V34, P1203, DOI 10.1016/j.patrec.2013.03.015
   Lin KM, 2003, IEEE T NEURAL NETWOR, V14, P1449, DOI 10.1109/TNN.2003.820828
   Liu ZL, 2014, J ALGORITHMS COMPUT, V8, P163
   Menezes MVF, 2019, PATTERN RECOGN LETT, V128, P1, DOI 10.1016/j.patrec.2019.08.001
   Nalepa J, 2019, ARTIF INTELL REV, V52, P857, DOI 10.1007/s10462-017-9611-1
   Pan XL, 2019, IEEE T NEUR NET LEAR, V30, P2263, DOI 10.1109/TNNLS.2018.2879800
   Pérez-Ortiz M, 2016, NEURAL PROCESS LETT, V44, P491, DOI 10.1007/s11063-015-9471-0
   Po-Sen Huang, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P205, DOI 10.1109/ICASSP.2014.6853587
   Rosales-Pérez A, 2017, IEEE T EVOLUT COMPUT, V21, P863, DOI 10.1109/TEVC.2017.2688863
   Schleif FM, 2017, PATTERN RECOGN, V71, P187, DOI 10.1016/j.patcog.2017.06.003
   Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4
   Shawe-Taylor J, 2011, NEUROCOMPUTING, V74, P3609, DOI 10.1016/j.neucom.2011.06.026
   Tharwat A, 2017, PATTERN RECOGN LETT, V93, P13, DOI 10.1016/j.patrec.2016.10.007
   Tsang IW, 2005, J MACH LEARN RES, V6, P363
   Verbiest N, 2016, APPL SOFT COMPUT, V38, P10, DOI 10.1016/j.asoc.2015.09.006
   Wang WJ, 2003, NEUROCOMPUTING, V55, P643, DOI 10.1016/S0925-2312(02)00632-X
   Wang Z, 2014, NEURAL COMPUT APPL, V24, P755, DOI 10.1007/s00521-012-1278-6
NR 28
TC 10
Z9 10
U1 5
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD OCT 1
PY 2022
VL 44
IS 10
BP 6184
EP 6195
DI 10.1109/TPAMI.2021.3085969
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 4N2UL
UT WOS:000853875300026
PM 34077354
DA 2023-11-10
ER

PT J
AU Rathnayake, H
   Sumanapala, J
   Rukshani, R
   Ranathunga, S
AF Rathnayake, Himashi
   Sumanapala, Janani
   Rukshani, Raveesha
   Ranathunga, Surangika
TI Adapter-based fine-tuning of pre-trained multilingual language models for code-mixed and code-switched text classification
SO KNOWLEDGE AND INFORMATION SYSTEMS
LA English
DT Article
DE Code-switching; Code-mixing; Text classification; Low-resource languages; Sinhala; XLM-R; Adapter
AB Code-mixing and code-switching are frequent features in online conversations. Classification of such text is challenging if one of the languages is low-resourced. Fine-tuning pre-trained multilingual language models is a promising avenue for code-mixed text classification. In this paper, we explore adapter-based fine-tuning of PMLMs for CMCS text classification. We introduce sequential and parallel stacking of adapters, continuous fine-tuning of adapters, and training adapters without freezing the original model as novel techniques with respect to single-task CMCS text classification. We also present a newly annotated dataset for the classification of Sinhala-English code-mixed and code-switched text data, where Sinhala is a low-resourced language. Our dataset of 10000 user comments has been manually annotated for five classification tasks: sentiment analysis, humor detection, hate speech detection, language identification, and aspect identification, thus making it the first publicly available Sinhala-English CMCS dataset with the largest number of task annotation types. In addition to this dataset, we also tested our proposed techniques on Kannada-English and Hindi-English datasets. These experiments confirm that our adapter-based PMLM fine-tuning techniques outperform or are on par with the basic fine-tuning of PMLM models.
C1 [Rathnayake, Himashi; Sumanapala, Janani; Rukshani, Raveesha; Ranathunga, Surangika] Univ Moratuwa, Dept Comp Sci & Engn, Katubedda 10400, Sri Lanka.
C3 University Moratuwa
RP Rathnayake, H (通讯作者)，Univ Moratuwa, Dept Comp Sci & Engn, Katubedda 10400, Sri Lanka.
EM himashi.17@ese.mrt.ac.lk; jananisudeeptha.17@cse.mrt.ac.lk; raveesha.17@cse.mrt.ac.lk; surangika@cse.mrt.ac.lk
FU Senate Research Committee (SRC) Grant of University of Moratuwa, Sri Lanka
CR Aguilar G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P1803
   [Anonymous], 2016, P 2 WORKSHOP COMPUTA, V0, P0
   Ansari, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Antoun Wissam, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON INFORMATICS, V0, P0
   Bohra A, 2018, P 2 WORKSH COMP MOD, V0, PP36, DOI 10.18653/v1/W18-1105
   Chakravarthi BR, 2022, LANG RESOUR EVAL, V56, P765, DOI 10.1007/s10579-022-09583-7
   Chakravarthi Bharathi Raja, 2020, P 1 JOINT WORKSHOP S, V0, P177
   Chathuranga S, 2021, P INT C RANLP 2021, V0, P256
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Das A, 2014, P 11 INT C NAT LANG, V0, P378
   Dhananjaya V, 2022, P 13 LANGUAGE RESOUR, V0, P0
   Friedman D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P6128
   Gundapu S, 2018, P 32 PAC AS C LANG I, V0, P0
   Hande A, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Houlsby N, 2019, PR MACH LEARN RES, V97, P0
   HuertasGarcia, 2021, THESIS, V0, P0
   Kakwani Divyanshu, 2020, FINDINGS ASS COMPUTA, V0, P4948
   Kamble S, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Kazhuparambil S, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Kenton JDMWC, 2019, UNIVERSAL LANGUAGE M, V0, P278
   Khandelwal A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1203
   Khanuja S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P3575
   Libovick J, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Mathur P, 2018, P 2 WORKSH AB LANG O, V0, PP138, DOI 10.18653/v1/W18-5118
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), V0, P18
   Mave D, 2018, COMPUTATIONAL APPROACHES TO LINGUISTIC CODE-SWITCHING, V0, P51
   Ousidhoum N, 2019, EMNLPIJCNLP 1, V0, P0
   Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), V0, P487
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P46
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7654
   Ruckle A, 2021, REPRESENTATION LEARN, V0, P0
   Rücklé A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P7930
   Sabty C, 2019, IEEE INT C SEMANT CO, V0, PP93, DOI 10.1109/ICOSC.2019.8665500
   Senevirathne, 2020, ARXIV PREPRINT ARXIV, V0, P0
   Smith I, 2019, INT CONF ASIAN LANG, V0, PP228, DOI 10.1109/ialp48816.2019.9037680
   Solorio T, 2014, P 1 WORKSH COMP APPR, V0, PP62, DOI 10.3115/V1/W14-3907
   Swami S, 2018, SCANNING ELECT MICRO, V0, P0
   Toftrup M, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P36
   Unal U, 2022, ANOMALYADAPTERS PARA, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vilares D, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P4149
   Wang Xinyi, 2021, FINDINGS ASS COMPUTA, V0, PP730, DOI 10.18653/v1/2021.findings-emnlp.63
   Yadav Siddharth, 2020, UNSUPERVISED SENTIME, V0, P0
NR 44
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0219-1377
EI 0219-3116
J9 KNOWL INF SYST
JI Knowl. Inf. Syst.
PD JUL 15
PY 2022
VL 64
IS 7
BP 1937
EP 1966
DI 10.1007/s10115-022-01698-1
EA JUL 2022
PG 30
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA 2Y6NM
UT WOS:000819885500001
DA 2023-11-10
ER

PT J
AU Treistman, A
   Mughaz, D
   Stulman, A
   Dvir, A
AF Treistman, Avraham
   Mughaz, Dror
   Stulman, Ariel
   Dvir, Amit
TI Word embedding dimensionality reduction using dynamic variance thresholding (DyVaT)
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Machine learning; Natural language processing; Learning styles; Feature selection
AB Natural language processing (NLP) provides a framework for large-scale text analysis. One common processing method uses vector space models (VSMs) which embed word attributes, called features, into highly dimensional vectors. Comprehensive VSMs are generated on sources such as the GoogleNews archive. A thesaurus, a collection of semantically-related words, can be created for a particular root word using cosine similarity with a given VSM. Many methods have been developed to reduce the complexity of these models by maintaining useful semantic information while discarding non-informative features. One such method, variance thresholding, retains high-variance features above a manually-determined threshold, providing higher differentiation between words for classification purposes. Our research developed a dimension-reducing methodology called dynamic variance thresholding (DyVaT). DyVaT reduces the specificity of word embeddings by maintaining low-variance features, allowing for a broader thesaurus preserving semantic similarity. A dynamic variance threshold, determining which low-variance features are retained, is selected using the kneedle algorithm, improving the current results. Our test case for examining the efficiency of DyVat in creating a contextual thesaurus is the visual, auditory and kinesthetic learning style context. We conclude that DyVaT is a valid method for generating loosely-connected word collections with potential uses in NLP classification or clustering tasks.
C1 [Treistman, Avraham; Dvir, Amit] Ariel Univ, Dept Comp Sci, Ramat HaGolan St 65, IL-40700 Ariel, Israel.
   [Treistman, Avraham; Mughaz, Dror; Stulman, Ariel] Jerusalem Coll Technol, Dept Comp Sci, 21 Havaad Haleumi St,POB 16031, IL-9372115 Jerusalem, Israel.
C3 Ariel University
RP Treistman, A (通讯作者)，Ariel Univ, Dept Comp Sci, Ramat HaGolan St 65, IL-40700 Ariel, Israel.
EM avi@treistman.com; myghaz@gmail.com; stulman@jct.ac.il; amitdv@g.ariel.ac.il
CR Agarwal N, 2020, EXPERT SYST APPL, V161, P0, DOI 10.1016/j.eswa.2020.113682
   Albon C, 2018, MACHINE LEARNING PYT, V0, P157
   Arano S, 2005, HIPERTEXT, V0, P3
   Arvai K, 2021, KNEED, V0, P0
   Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238
   Bird S, 2009, NATURAL LANGUAGE PRO, V0, P60
   Bojanowski PE, 2016, CORR, V0, P0, DOI DOI 10.1162/TACL_A_00051
   Celik O, 2020, AM J ENG RES, V9, P33
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Deshmukh V, 2014, ADV TECHNOLOGIES ELE, V0, P2
   Devlin J, 2019, ARXIV, V0, P0
   Ekstein K, 2013, LECT NOTES ELECT ENG, V0, PP79, DOI 10.1007/978-3-642-28807-4_12
   Geron A, 2019, HANDS ON MACHINE LEA, V2, P241
   Gupta L, 2021, DIFFERENCES WORD2VEC, V0, P0
   Hall T, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P314, DOI 10.1109/ICMLA.2012.226
   Hinton GE, 2003, ADV NEURAL INFORM PR, V15, P0, DOI 10.1109/TSMCB.2011.2106208
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Honnibal M, 2021, TRAINED MODELS PIPEL, V0, P0
   Huang C-C, 2009, INT J COMPUTATIONAL, V14, P0
   Jolliffe IT, 1990, WEATHER, V45, P375, DOI 10.1002/j.1477-8696.1990.tb05558.x
   Junior Methanias Colaco, 2021, JOURNAL OF THE BRAZILIAN COMPUTER SOCIETY, V27, P0, DOI 10.1186/s13173-021-00107-9
   Knuth DE, 1998, ART COMPUTER PROGRAM, V3, P0
   Landthaler J, 2017, EXTENDING THESAURI U, V0, P0
   LEVENSHTVI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   López-Ibáñez M, 2016, OPER RES PERSPECT, V3, P43, DOI 10.1016/j.orp.2016.09.002
   Melamud O, 2016, P C N AM CHAPTER ASS, V0, PP1030, DOI 10.18653/V1/N16-1118
   Merriam-Webstercom, 2021, THES N D MERR WEBST, V0, P0
   Migenda N, 2021, PLOS ONE, V16, P0, DOI 10.1371/journal.pone.0248896
   Mihaltz M, 2021, MMIHALTZ WORD2VEC GO, V0, P0
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Mikolov T, 2013, INT C LEARN REPRESEN, V0, P0
   Molina LC, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, V0, P306, DOI 10.1109/ICDM.2002.1183917
   NISO, 2010, GUIDELINES CONSTRUCT, V0, P0
   nltkorg, 2021, NLTK CORP STOPW CORP, V0, P0
   Omuya EO, 2021, EXPERT SYST APPL, V174, P0, DOI 10.1016/j.eswa.2021.114765
   Patel K, 2017, PROC 8 INT JOINT C N, V0, P31
   Patman F, 2003, IS SOUNDEX GOOD ENOU, V0, P0
   Peach N, 1995, J ROYAL STAT SOC SER, V0, P0, DOI DOI 10.2307/2983416
   Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   randomlists, 2002, RAND WORD GEN, V0, P0
   Raunak V, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), V0, P235
   Rezaeinia S, 2017, ARXIV, V0, P0
   Robins A, 2003, COMPUTER SCI ED, V13, P137, DOI 10.1076/CSED.13.2.137.14200
   Sarkar Dipanjan, 2019, TEXT ANAL PYTHON PRA, V0, P0
   Satopaa V, 2011, PROCEEDINGS OF THE 2011 31ST INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS (ICDCS WORKSHOPS), V0, PP166, DOI 10.1109/ICDCSW.2011.20
   Senel LK, 2018, IEEE-ACM T AUDIO SPE, V26, P1769, DOI 10.1109/TASLP.2018.2837384
   Suji M, 2021, EUR J MOL CLIN MED, V7, P7925
   Tolsa X, 2014, PROGR MATH, V307, P289, DOI 10.1007/978-3-319-00596-6_10
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Venkatesh B, 2019, CYBERN INF TECHNOL, V19, P3, DOI 10.2478/cait-2019-0001
   Zhang XL, 2015, AS C MACH LEARN FEBR, V0, P221
   Zhao QP, 2008, LECT NOTES COMPUT SC, V5259, P664, DOI 10.1007/978-3-540-88458-3_60
NR 53
TC 0
Z9 0
U1 1
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 1
PY 2022
VL 208
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.118157
EA JUL 2022
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 4R8GK
UT WOS:000856995100011
DA 2023-11-10
ER

PT J
AU Huertas-Tato, J
   Martín, A
   Camacho, D
AF Huertas-Tato, Javier
   Martin, Alejandro
   Camacho, David
TI SILT: Efficient transformer training for inter-lingual inference
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Natural language inference; Embeddings; Sentence alignment; Transformers; Deep learning
AB The ability of transformers to perform precision tasks such as question answering, Natural Language Inference(NLI) or summarizing, has enabled them to be ranked as one of the best paradigms to address Natural LanguageProcessing (NLP) tasks. NLI is one of the best scenarios to test these architectures, due to the knowledgerequired to understand complex sentences and established relationships between a hypothesis and a premise.Nevertheless, these models suffer from the incapacity to generalize to other domains or from difficulties to facemultilingual and interlingual scenarios. The leading pathway in the literature to address these issues involvedesigning and training extremely large architectures, but this causes unpredictable behaviors and establishesbarriers which impede broad access and fine tuning. In this paper, we propose a new architecture calledSiamese Inter-Lingual Transformer (SILT). This architecture is able to efficiently align multilingual embeddingsfor Natural Language Inference, allowing for unmatched language pairs to be processed. SILT leverages siamesepre-trained multi-lingual transformers with frozen weights where the two input sentences attend to eachother to later be combined through a matrix alignment method. The experimental results carried out in thispaper evidence that SILT allows to reduce drastically the number of trainable parameters while allowing forinter-lingual NLI and achieving state-of-the-art performance on common benchmarks.
C1 [Huertas-Tato, Javier; Martin, Alejandro; Camacho, David] Univ Politecn Madrid, Dept Sistemas Informat, Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Martín, A (通讯作者)，Univ Politecn Madrid, Dept Sistemas Informat, Madrid, Spain.
EM javier.huertas.tato@upm.es; alejandro.martin@upm.es; david.camacho@upm.es
FU ERDF A way of making Europe; European Union; European Union NextGenerationEU/PRTR; research project CIVIC: Intelligent characterization of the veracity of the information related to COVID-19 - BBVA FOUNDATION GRANTS FOR SCIENTIFIC RESEARCH TEAMS SARS-CoV-2 and COVID-19; European Commission under IBERIFIER -Iberian Digital Media Research and Fact-Checking Hub [2020-EU-IA-0252]; Convenio Plurianual with the Universidad Politecnica de Madrid in the actuation line of Programa de Excelencia para el Profesorado Universitario; MCIN/AEI [PLEC2021-007681, PID2020-117263GB-100]
CR Aghajanyan A, 2020, BETTER FINE FUNING R, V0, P0
   Amirkhani H, 2021, ARXIV200908820, V0, P0
   [Anonymous], 2018, 2018 4 INT C ADV EL, V0, P0, DOI DOI 10.1109/AEEICB.2018.8480917
   Aspillaga C, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), V0, P1882
   Belinkov Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P877
   Bowman Samuel R, 2015, P 2015 C EMP METH NA, V0, PP632, DOI 10.18653/V1/D15-1075
   Camburu OM, 2018, ADV NEUR IN, V31, P0
   CHEN Q, 2017, LONG PAPERS, V0, PP1657, DOI 10.18653/V1/P17-1152
   CHEN Q, 2018, LONG PAPERS, V0, P2406
   Conneau A, 2017, P C EMP METH NAT LAN, V0, PP670, DOI 10.18653/v1/d17-1070
   Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2475
   Conneau Alexis, 2020, P 58 ANN M ASS COMP, V0, PP8440, DOI 10.18653/V1/2020.ACL-MAIN.747
   Deng WL, 2019, INT C ELECTR MACH SY, V0, P3728
   Desai S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P295
   Devlin J, 2018, BERT PRETRAINING DEE, V0, P0, DOI DOI 10.18653/V1/N19-PROCEEDINGSOFNAACLHLT1423
   Fang YW, 2021, AAAI CONF ARTIF INTE, V35, P12776
   Gururangan Suchin, 2018, ARXIV180302324, V0, P0
   He He, 2019, P 2 WORKSH DEEP LEAR, V0, PP132, DOI 10.18653/V1/D19-6115
   Hu H, 2020, P 2020 C EMP METH NA, V0, P3512
   Huang HY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2485
   Kingma DP, 2014, C TRACK P, V0, P0
   Kumar Sawan, 2020, P 58 ANN M ASS COMPU, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.771
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Liu X, 2018, ARXIV180407888, V0, P0
   Marelli M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P0
   Parikh Ankur P, 2016, P 2016 C EMP METH NA, V0, P0, DOI DOI 10.18653/v1/D16-1244
   Passaro L, 2020, CLEF 2020, V2696, P0
   Pasunuru R, 2018, P C N AM CHAPT ASS C, V2, P646
   Poliak A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P67
   Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1133, DOI 10.1145/3331184.3331341
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3982
   Romanov A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1586
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Shimanaka H, 2018, P 3 C MACHINE TRANSL, V0, PP751, DOI 10.18653/v1/W18-6456
   Smith LN, 2017, IEEE WINT CONF APPL, V0, PP464, DOI 10.1109/WACV.2017.58
   Song Y, 2020, ARXIV200204815, V0, P0
   Tay Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1565
   Trivedi H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2948
   Vaswani A, 2017, ARXIV, V30, P5998
   Wang Alex, 2018, P 2018 EMNLP WORKSH, V2, P353, DOI 10.18653/v1/W18-5446
   Welleck S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P3731
   Williams A, 2018, P 2018 C N AM CHAPTE, V0, PP1112, DOI 10.18653/v1/N18-1101
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, V0, P38
   Yang XY, 2019, LECT NOTES ARTIF INT, V11489, P413, DOI 10.1007/978-3-030-18305-9_38
NR 45
TC 4
Z9 4
U1 1
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD AUG 15
PY 2022
VL 200
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.116923
EA APR 2022
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 1B5SE
UT WOS:000792495900007
DA 2023-11-10
ER

PT J
AU Narain, J
   Johnson, KT
   Quatieri, TF
   Picard, RW
   Maes, P
AF Narain, Jaya
   Johnson, Kristina T.
   Quatieri, Thomas F.
   Picard, Rosalind W.
   Maes, Pattie
TI Modeling Real-World Affective and Communicative Nonverbal Vocalizations From Minimally Speaking Individuals
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Affective computing; affect sensing and analysis; nonverbal speech; speech analysis
ID autism spectrum disorder; expressive language; children; emotion; gestures; intervention; recognition; infants; adults; risk
AB Nonverbal vocalizations from non- and minimally speaking individuals who speak fewer than 20 words (mv* individuals) convey important communicative and affective information. While nonverbal vocalizations that occur amidst typical speech and infant vocalizations have been studied extensively in the literature, there is limited prior work on vocalizations by mv* individuals. Our work is among the first studies of the communicative and affective information expressed in nonverbal vocalizations by mv* children and adults. We collected labeled vocalizations in real-world settings with eight mv* communicators, with communicative and affective labels provided in-the-moment by a close family member. Using evaluation strategies suitable for messy, real-world data, we show that nonverbal vocalizations can be classified by function (with 4- and 5-way classifications) with F1 scores above chance for all participants. We analyze labeling and data collection practices for each participating family, and discuss the classification results in the context of our novel real-world data collection protocol. The presented work includes results from the largest classification experiments with nonverbal vocalizations from mv* communicators to date.
C1 [Narain, Jaya; Johnson, Kristina T.; Picard, Rosalind W.; Maes, Pattie] MIT, Cambridge, MA 02139 USA.
   [Quatieri, Thomas F.] MIT, Lincoln Lab, Lexington, MA USA.
C3 Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Lincoln Laboratory
RP Narain, J (通讯作者)，MIT, Cambridge, MA 02139 USA.
EM jnarain8@gmail.com; ktj@mit.edu; quatieri@ll.mit.edu; picard@media.mit.edu; pattie@media.mit.edu
FU MIT Media Lab Consortium; Deshpande Center Technology to Improve Ability Program; Apple Scholars in AI/ML; NSF Graduate Research Fellowship Program; Hugh Hampton Young Fellowship Program
CR Anikin A, 2020, PHONETICA, V77, P327, DOI 10.1159/000504855
   Anikin A, 2018, Q J EXP PSYCHOL, V71, P622, DOI 10.1080/17470218.2016.1270976
   [Anonymous], 2012, P 3 WORKSH CHILD COM, V0, P0
   Bacon EC, 2019, AUTISM, V23, P699, DOI 10.1177/1362361318766241
   Banica IA, 2016, INT CONF COMM, V0, PP51, DOI 10.1109/ICComm.2016.7528261
   Batten A, 2005, IMPROV SCH, V8, P93, DOI 10.1177/1365480205049341
   Beukelman David R, 1998, AUGMENTATIVE ALTERNA, V0, P0
   Cañigueral R, 2019, FRONT PSYCHOL, V10, P0, DOI 10.3389/fpsyg.2019.00560
   Chiang CH, 2008, J AUTISM DEV DISORD, V38, P1898, DOI 10.1007/s10803-008-0586-2
   Chiang HM, 2009, RES AUTISM SPECT DIS, V3, P214, DOI 10.1016/j.rasd.2008.06.002
   Colgan SE, 2006, CHILD NEUROPSYCHOL, V12, P307, DOI 10.1080/09297040600701360
   Couper L, 2014, DEV NEUROREHABIL, V17, P99, DOI 10.3109/17518423.2013.870244
   de Marchena A, 2010, AUTISM RES, V3, P311, DOI 10.1002/aur.159
   Dietz PM, 2020, J AUTISM DEV DISORD, V50, P4258, DOI 10.1007/s10803-020-04494-4
   Donnellan E, 2020, DEVELOPMENTAL SCI, V23, P0, DOI 10.1111/desc.12843
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Eyben Florian, 2013, P 21 ACM INT C MULTI, V0, PP835, DOI 10.1016/J.SCHRES.2022.01.019
   Faso DJ, 2015, J AUTISM DEV DISORD, V45, P75, DOI 10.1007/s10803-014-2194-7
   Freitag M, 2018, J MACH LEARN RES, V18, P0
   Fuhr T, 2015, INT J HLTH PROFESSIO, V2, P4
   Gordon RG, 2015, J AUTISM DEV DISORD, V45, P2267, DOI 10.1007/s10803-015-2390-0
   Gratier M, 2011, DEV PSYCHOL, V47, P67, DOI 10.1037/a0020722
   Gregory A, 2018, J SPEECH LANG HEAR R, V61, P1591, DOI 10.1044/2018_JSLHR-S-17-0316
   Hamrick LR, 2019, AUTISM RES, V12, P1663, DOI 10.1002/aur.2176
   Hashemi J, 2021, IEEE T AFFECT COMPUT, V12, P215, DOI 10.1109/TAFFC.2018.2868196
   Holyfield C, 2017, AUGMENT ALTERN COMM, V33, P201, DOI 10.1080/07434618.2017.1370495
   Holz N, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-88431-0
   Hyde KK, 2019, REV J AUTISM DEV DIS, V6, P128, DOI 10.1007/s40489-019-00158-x
   Jaiswal M, 2021, ARXIV, V0, P0
   Johnson KT, 2022, PHONEMIC CONTENT NON, V0, P0
   Johnson KT, 2022, RECANVO DATABA UNPUB, V0, P0
   Johnson KT, 2020, P CHI C HUM FACT COM, V0, P1
   Knapp Mark, 1980, ESSENTIALS NONVERBAL, V0, P0
   Kogan MD, 2018, PEDIATRICS, V142, P0, DOI 10.1542/peds.2017-4161
   Kushki A, 2015, IEEE T BIO-MED ENG, V62, P990, DOI 10.1109/TBME.2014.2377555
   Lemaître G, 2017, J MACH LEARN RES, V18, P0
   Li XJ, 2020, INT CONF ACOUST SPEE, V0, PP8249, DOI 10.1109/ICASSP40776.2020.9054362
   Liu LC, 2019, IEEE-CAA J AUTOMATIC, V6, P778, DOI 10.1109/JAS.2019.1911435
   Marchi E, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P115
   Martin GE, 2009, TOP LANG DISORD, V29, P112, DOI 10.1097/TLD.0b013e3181a71fe1
   McDaniel J, 2018, RES DEV DISABIL, V72, P202, DOI 10.1016/j.ridd.2017.11.010
   Mehta DD, 2012, J ACOUST SOC AM, V132, P1732, DOI 10.1121/1.4739462
   Morgan L, 2018, COMMUN DISORD Q, V40, P3, DOI 10.1177/1525740118760215
   Morris SR, 2010, LANG SPEECH HEAR SER, V41, P223, DOI 10.1044/0161-1461(2009/08-0076)
   Narain J, 2019, P AI SOC GOOD WORKSH, V0, P0
   Narain J, 2021, THESIS MIT, V0, P0
   Narain J, 2020, P INT C MULTIMODAL I, V0, P0
   Oller DK, 2010, P NATL ACAD SCI USA, V107, P13354, DOI 10.1073/pnas.1003882107
   Peterson CC, 2015, J EXP CHILD PSYCHOL, V139, P35, DOI 10.1016/j.jecp.2015.04.012
   Picard RW, 2009, PHILOS T R SOC B, V364, P3575, DOI 10.1098/rstb.2009.0143
   Poggi I, 2018, PROC LAUGHTER WORKSH, V0, P50
   Rescorla L, 1996, J SPEECH HEAR RES, V39, P153, DOI 10.1044/jshr.3901.153
   Romski M, 2015, AUGMENT ALTERN COMM, V31, P181, DOI 10.3109/07434618.2015.1064163
   Rudovic O, 2018, IEEE INT C INT ROBOT, V0, PP339, DOI 10.1109/IROS.2018.8594177
   Sarabadani S, 2020, IEEE T AFFECT COMPUT, V11, P588, DOI 10.1109/TAFFC.2018.2820049
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schindler K, 2008, NEURAL NETWORKS, V21, P1238, DOI 10.1016/j.neunet.2008.05.003
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Sharma S, 2017, TENCON IEEE REGION, V0, PP3105, DOI 10.1109/TENCON.2017.8228395
   Sheinkopf SJ, 2012, AUTISM RES, V5, P331, DOI 10.1002/aur.1244
   Shue Yen, 2010, VOICE SOURCE SPEECH, V0, P0
   Sowden H, 2013, CLIN LINGUIST PHONET, V27, P922, DOI 10.3109/02699206.2013.818715
   Stone WL, 1997, J AUTISM DEV DISORD, V27, P677, DOI 10.1023/A:1025854816091
   Tager-Flusberg H, 2013, AUTISM RES, V6, P468, DOI 10.1002/aur.1329
   Tenenbaum EJ, 2020, AUTISM RES, V13, P1373, DOI 10.1002/aur.2293
   Trouvain J, 2012, P 11 INT WORKSHOP CO, V0, P36
   WASZHOCKERT O, 1964, EXPERIENTIA, V20, P154, DOI 10.1007/BF02150709
   Weisman O, 2016, IEEE T AFFECT COMPUT, V7, P337, DOI 10.1109/TAFFC.2015.2478468
   Wilhelm FH, 2010, BIOL PSYCHOL, V84, P552, DOI 10.1016/j.biopsycho.2010.01.017
   Wilson C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI20), V0, P0, DOI DOI 10.1145/3313831.3376171
   Wilson C, 2021, POLICY STUD-UK, V42, P173, DOI 10.1080/01442872.2019.1618808
   Zamagni E, 2011, NEUROPSYCHOLOGY, V25, P270, DOI 10.1037/a0021620
NR 74
TC 0
Z9 0
U1 3
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
EI 
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD OCT 1
PY 2022
VL 13
IS 4
BP 2238
EP 2253
DI 10.1109/TAFFC.2022.3208233
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA 6S4GV
UT WOS:000892948500041
DA 2023-11-10
ER

PT J
AU Srivastava, R
   Singh, P
   Rana, KPS
   Kumar, V
AF Srivastava, Ridam
   Singh, Prabhav
   Rana, K. P. S.
   Kumar, Vineet
TI A topic modeled unsupervised approach to single document extractive text summarization
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Automatic Text Summarization; Extractive summarization; Topic modeling; Clustering; K-Medoids; LDA
ID framework
AB Automatic Text Summarization (ATS) is an essential field in natural language processing that attempts to condense large text documents so that users can assimilate information quickly. It finds uses in medical document summarization, review generation, and opinion mining. This work investigated an unsupervised extractive summarization approach that combined clustering with topic modeling to reduce topic bias. Latent Dirichlet Allocation was used for topic modeling, while K-Medoids clustering was employed for summary generation. The approach was evaluated on three datasets-Wikihow, CNN/DailyMail, and the DUC2002 Corpus. The Recall Oriented-Understudy for Gisting Evaluation (ROUGE) metrics were used for comparative analysis against recently reported techniques, specifically ROUGE-1 (R-1), ROUGE-2 (R-2), and ROUGE-L (R-L). The suggested framework offered scores of 34.80%, 9.13%, and 32.30% on the Wikihow Dataset, 43.90%, 19.01%, and 41.50% on the CNN/DailyMail Dataset, and 49.35%, 31.53%, and 41.72% on the DUC2002 Corpus (R-1, R-2, R-L respectively). These reported metrics are found to be superior when compared to similar recent works. Further, execution time of the proposed method was also recorded and compared with counterparts, which established its superior speed. Based on these promising outcomes, it was concluded that an unsupervised extractive summarization approach with greater subtopic focus significantly improves over generic topic modeling semantic and deep learning approaches.
C1 [Srivastava, Ridam; Singh, Prabhav; Rana, K. P. S.; Kumar, Vineet] Netaji Subhas Univ Technol, Instrumentat & Control Engn Dept, Sector 3, New Delhi 110078, India.
C3 Netaji Subhas University of Technology
RP Srivastava, R; Singh, P; Rana, KPS; Kumar, V (通讯作者)，Netaji Subhas Univ Technol, Instrumentat & Control Engn Dept, Sector 3, New Delhi 110078, India.
EM ridams.ic18@nsut.ac.in; prabhavs.ic18@nsut.ac.in; kpsrana@nsut.ac.in; vineet.kumar@nsut.ac.in
CR Ailem M, 2019, TOPIC AUGMENTED GENE, V0, P0
   AKSENOV D, 2020, LREC 2020, V0, P6680
   Alguliyev RM, 2019, EXPERT SYST, V36, P0, DOI 10.1111/exsy.12340
   [Anonymous], 2022, DOC UND C, V0, P0
   [Anonymous], 2022, REVIEWCHOMP, V0, P0
   [Anonymous], 2008, PARTITIONING MEDOIDS, V0, PP68, DOI [10.1002/9780470316801.CH2, DOI 10.1002/9780470316801.CH2]
   Bae S, 2019, SUMMARY LEVEL TRAINI, V0, PP10, DOI 10.18653/v1/d19-5402
   Balakrishnan Vimala, 2014, LECTURE NOTES ON SOFTWARE ENGINEERING, V2, P262, DOI 10.7763/LNSE.2014.V2.134
   Barzilay R, 1999, INFORM FUSION CONTEX, V0, PP550, DOI 10.3115/1034678.1034760
   Begum N, 2009, INT J INNOV COMPUT I, V5, P1987
   Bing LD, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1587
   Bisong E, 2019, BUILDING MACHINE LEA, V0, PP59, DOI 10.1007/978-1-4842-4470-8_7
   Cai XY, 2021, KNOWL-BASED SYST, V222, P0, DOI 10.1016/j.knosys.2021.106996
   Chen LF, 2019, INT CONF KNOWL SYS, V0, PP435, DOI 10.1109/kse.2019.8919490
   CHUNG W, 2009, AMCIS 2009 P, V0, P0
   Contractions, 2022, PYPI, V0, P0
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, P0, DOI 10.1016/j.eswa.2020.113679
   El-Kassas WS, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102264
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fattah MA, 2014, APPL INTELL, V40, P592, DOI 10.1007/s10489-013-0490-0
   Fattah MA, 2009, COMPUT SPEECH LANG, V23, P126, DOI 10.1016/j.csl.2008.04.002
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Ganesan Kavita, 2010, P 23 INT C COMP LING, V0, P340
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hoffman M, 2010, ADV NEURAL INFORM PR, V23, P0, DOI 10.5555/2997189.2997285
   Le HT, 2013, 2013 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), V0, PP371, DOI 10.1109/SOCPAR.2013.7054161
   Issam KAR, 2020, INT J INNOV TECHNOL, V9, P0, DOI 10.35940/ijitee.F4611.049620
   JAIN A, 2018, P 2017 INT C MACH LE, V0, PP51, DOI 10.1109/MLDS.2017.12
   Jing BY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P133
   Joshi A, 2019, EXPERT SYST APPL, V129, P200, DOI 10.1016/j.eswa.2019.03.045
   Khan A, 2018, INT J PARALLEL PROG, V46, P992, DOI 10.1007/s10766-018-0560-3
   Ko Y, 2008, PATTERN RECOGN LETT, V29, P1366, DOI 10.1016/j.patrec.2008.02.008
   Kouris P, 2021, COMPUT LINGUIST, V47, P813, DOI 10.1162/coli_a_00417
   Li JJ, 2016, P 17 ANN M SPECIAL I, V0, P137
   Li Piji, 2017, P 2017 C EMP METH NA, V0, PP2091, DOI 10.18653/V1/D17-1222
   Lin C-Y, 2004, TEXT SUMMARIZATION B, V0, PP74, DOI 10.3115/V1/D14-1020
   Lin Chin-Yew, 2000, P 18 C COMPUTATIONAL, V0, PP495, DOI 10.3115/990820.990892
   Liu Y, 2019, ARXIV190407464, V0, P0
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lorenz-Spreen P, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-09311-w
   Ma TH, 2022, IEEE T COMPUT SOC SY, V9, P879, DOI 10.1109/TCSS.2021.3088506
   Mann WC, 1988, TEXT, V8, P243
   Mendoza M, 2014, EXPERT SYST APPL, V41, P4158, DOI 10.1016/j.eswa.2013.12.042
   Mihalcea Rada, 2004, P 42 ANN M ASS COMP, V0, P0, DOI DOI 10.3115/1219044.1219064
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Miller DL, 2019, ARXIV PREPRINT ARXIV, V0, P0
   MOAWAD IF, 2012, P ICCES 2012, V0, PP132, DOI 10.1109/ICCES.2012.6408498
   Moratanch N, 2016, PROCEEDINGS OF IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, V0, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2016)
   Moussa Mohammed Elsaid, 2018, FUTURE COMPUTING AND INFORMATICS JOURNAL, V3, P82, DOI 10.1016/j.fcij.2017.12.002
   Nallapati R, 2016, P 20 SIGNLL C COMP N, V0, PP280, DOI 10.18653/V1/K16-1028
   Ozsoy MG, 2011, J INF SCI, V37, P405, DOI 10.1177/0165551511408848
   Pandit Shraddha, 2011, INT J RES COMPUTER S, V2, P29, DOI 10.7815/IJORCS.21.2011.011
   Paulo P, 2022, USING TEXT SUMMARIZA, V0, P0
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Radev DR, 2004, MEAD A PLATFORM MULT, V0, P0, DOI DOI 10.7916/D8MG7XZT
   Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Rush A M, 2015, P 2015 C EMPIRICAL M, V0, P379
   Sabuna PM, 2018, P 2017 2 INT C INF T, V0, PP1, DOI 10.1109/ICITISEE.2017.8285473
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Strube M, 2015, P 2015 C EMPIRICAL M, V0, P1949
   Suleiman D, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/9365340
   Syed AA, 2021, IEEE ACCESS, V9, P13248, DOI 10.1109/ACCESS.2021.3052783
   Syed S, 2017, PR INT CONF DATA SC, V0, PP165, DOI 10.1109/DSAA.2017.61
   Talukder MAI, 2019, 2019 10 INT C COMPUT, V0, P0, DOI DOI 10.1109/ICCCNT45670.2019.8944839
   Tohalino JV, 2018, PHYSICA A, V503, P526, DOI 10.1016/j.physa.2018.03.013
   Tong Z, 2016, INT C COMPUTER SCI E, V0, PP201, DOI 10.5121/CSIT.2016.60616
   Wang S, 2017, IEEE INT CONGR BIG, V0, PP305, DOI 10.1109/BigDataCongress.2017.46
   Wei TT, 2015, EXPERT SYST APPL, V42, P2264, DOI 10.1016/j.eswa.2014.10.023
   Widyassari AP, 2020, J KING SAUD UNIV-COM, V34, P1029, DOI 10.1016/j.jksuci.2020.05.006
   Xu J, 2020, DISCOURSE AWARE NEUR, V0, PP5021, DOI 10.18653/V1/2020.ACL- MAIN.451
   Yang LB, 2014, INFORM SCIENCES, V260, P37, DOI 10.1016/j.ins.2013.11.026
   Zhang PY, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 1, P167, DOI 10.1109/ICCSIT.2009.5234971
   Zhang Y, 2016, IEEE IND ELEC, V0, PP918, DOI 10.1109/IECON.2016.7793761
   Zhong M, 2020, EXTRACTIVE SUMMARIZA, V0, PP6197, DOI 10.18653/V1/2020
NR 79
TC 12
Z9 12
U1 12
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JUN 21
PY 2022
VL 246
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.108636
EA APR 2022
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1G1AQ
UT WOS:000795588200012
DA 2023-11-10
ER

PT J
AU Yuan, J
   Zhu, S
   Huang, SY
   Zhang, HW
   Xiao, YQ
   Li, ZY
   Wang, M
AF Yuan, Jin
   Zhu, Shuai
   Huang, Shuyin
   Zhang, Hanwang
   Xiao, Yaoqiang
   Li, Zhiyong
   Wang, Meng
TI Discriminative Style Learning for Cross-Domain Image Captioning
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Decoding; Visualization; Syntactics; Semantics; Training; Logic gates; Birds; Cross-domain; image captioning; style; instruction-based LSTM
AB The cross-domain image captioning, which is trained on a source domain and generalized to other domains, usually faces the large domain shift problem. Although prior work has attempted to leverage both paired source and unpaired target data to minimize this shift, the performance is still unsatisfactory. One main reason lies in the large discrepancy in language expression between two domains, where diverse language styles are adopted to describe an image from different views, resulting in different semantic descriptions for an image. To tackle this problem, this paper proposes a Style-based Cross-domain Image Captioner (SCIC) which incorporates the discriminative style information into the encoder-decoder framework, and interprets an image as a special sentence according to external style instructions. Technically, we design a novel "Instruction-based LSTM", which adds the instruct gate to collect a style instruction, and then outputs a specified format according to that instruction. Two objectives are designed to train I-LSTM: 1) generating correct image descriptions and 2) generating correct styles, thus the model is expected to accurately capture the semantic meanings of an image by the special caption as well as understand the syntactic structure of the caption. We use MS-COCO as the source domain, and Oxford-102, CUB-200, Flickr30k as the target domains. Experimental results demonstrate that our model consistently outperforms the previous methods, and the style information incorporating with I-LSTM significantly improves the performance, with 5% CIDEr improvements at least on all datasets.
C1 [Yuan, Jin; Zhu, Shuai; Huang, Shuyin; Xiao, Yaoqiang; Li, Zhiyong] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Zhang, Hanwang] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Wang, Meng] Hefei Univ Technol, Sch Comp Sci, Hefei 230009, Peoples R China.
C3 Hunan University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Hefei University of Technology
RP Li, ZY (通讯作者)，Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM zhiyong.li@hnu.edu.cn
FU National Natural Science Foundation of China [61976086, 62020106007]; Special Project of Foshan Science and Technology Innovation Team [FS0AA-KJ9194402-0069]
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Bahdanau D, 2016, ARXIV, V0, P0
   Chen J, 2020, P IEEE CVF C COMP VI, V0, P10890
   Chen L, 2017, PROC CVPR IEEE, V0, PP6298, DOI 10.1109/CVPR.2017.667
   Chen TL, 2018, LECT NOTES COMPUT SC, V11214, P527, DOI 10.1007/978-3-030-01249-6_32
   Chen TH, 2017, IEEE I CONF COMP VIS, V0, PP521, DOI 10.1109/ICCV.2017.64
   Deshpande A, 2019, PROC CVPR IEEE, V0, PP10687, DOI 10.1109/CVPR.2019.01095
   Donahue J, 2015, PROC CVPR IEEE, V0, PP2625, DOI 10.1109/CVPR.2015.7298878
   Elliott D, 2013, P 2013 C EMP METH NA, V0, P1292
   Fang H, 2015, PROC CVPR IEEE, V0, PP1473, DOI 10.1109/CVPR.2015.7298754
   Gan C, 2017, PROC CVPR IEEE, V0, PP955, DOI 10.1109/CVPR.2017.108
   Gan Z, 2017, PROC CVPR IEEE, V0, PP1141, DOI 10.1109/CVPR.2017.127
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Guo LT, 2019, PROC CVPR IEEE, V0, PP4199, DOI 10.1109/CVPR.2019.00433
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He XW, 2019, PATTERN RECOGN LETT, V119, P229, DOI 10.1016/j.patrec.2017.10.018
   Hendricks LA, 2016, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2016.8
   Hodosh M, 2014, P TACL, V7, P67, DOI 10.1162/tacl_a_00166
   Huang YQ, 2020, IEEE T IMAGE PROCESS, V29, P4013, DOI 10.1109/TIP.2020.2969330
   Jia X, 2015, IEEE I CONF COMP VIS, V0, PP2407, DOI 10.1109/ICCV.2015.277
   Jiang WH, 2018, AAAI CONF ARTIF INTE, V0, P6959
   Kaiser Lukasz, 2016, P 4 INT C LEARN REPR, V0, P0
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kingma DP, 2014, C TRACK P, V0, P0
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuznetsova P, 2014, J T ASS COMPUT LINGU, V2, P351, DOI 10.1162/tacl_a_00188
   Li XY, 2019, IEEE T MULTIMEDIA, V21, P2117, DOI 10.1109/TMM.2019.2896516
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Longteng Guo, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2017, PROC CVPR IEEE, V0, PP3242, DOI 10.1109/CVPR.2017.345
   Luong M-T, 2015, P 2015 C EMP METH NA, V0, PP1412, DOI 10.18653/V1/D15-1166
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, V0, P747
   Moschitti A, 2006, LECT NOTES COMPUT SC, V4212, P318
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, V0, P722, DOI 10.1109/ICVGIP.2008.47
   Perdana Rizal Setya, 2019, 2019 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES). PROCEEDINGS, V0, PP24, DOI 10.1109/ELECSYM.2019.8901660
   Qin Y, 2019, PROC CVPR IEEE, V0, PP8359, DOI 10.1109/CVPR.2019.00856
   Reed S, 2016, PROC CVPR IEEE, V0, PP49, DOI 10.1109/CVPR.2016.13
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Shizhe Chen, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9959, DOI 10.1109/CVPR42600.2020.00998
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wang BR, 2019, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2019.00273
   Wu Q, 2016, PROC CVPR IEEE, V0, PP203, DOI 10.1109/CVPR.2016.29
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP1029, DOI 10.1145/3240508.3240640
   Xiao XY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2068
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang M, 2019, IEEE T MULTIMEDIA, V21, P1047, DOI 10.1109/TMM.2018.2869276
   Yao T, 2017, IEEE I CONF COMP VIS, V0, PP4904, DOI 10.1109/ICCV.2017.524
   Yingwei Pan, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10968, DOI 10.1109/CVPR42600.2020.01098
   You Q, 2018, ABS180110121 CORR, V0, P1
   Yuan J, 2020, ACM T MULTIM COMPUT, V16, P0, DOI 10.1145/3394955
   Zhao W, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1205
   Zhao W, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP29, DOI 10.1145/3132847.3132920
   Zhao WT, 2021, IEEE T IMAGE PROCESS, V30, P1180, DOI 10.1109/TIP.2020.3042086
   Zhao WT, 2020, AAAI CONF ARTIF INTE, V34, P12984
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS17), V0, PP305, DOI 10.1145/3126686.3126717
   Zhou YAN, 2020, PROC CVPR IEEE, V0, PP4776, DOI 10.1109/CVPR42600.2020.00483
NR 57
TC 3
Z9 3
U1 2
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PD JUN 15
PY 2022
VL 31
IS 
BP 1723
EP 1736
DI 10.1109/TIP.2022.3145158
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA YW5FK
UT WOS:000753438500002
PM 35085078
DA 2023-11-10
ER

PT J
AU Aravanis, T
   Peppas, P
AF Aravanis, Theofanis
   Peppas, Pavlos
TI Theory-relational belief revision
SO ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Belief change; Fixed binary relations over theories; Total Preorders; Uniform revision; Knowledge representation
ID logic
AB The prominent formal framework for belief change established by Alchourron, Gardenfors and Makinson circumscribes the territory of all rational belief-revision policies, encoded in the so-called AGM revision functions. A type of well-behaved and highly-expressive AGM revision function, induced from fixed total preorders over possible worlds, is that of uniform-revision operators (abbrev. UR operators). In this article, we introduce, both axiomatically and semantically (in terms of all popular constructive models for belief revision), a new class of AGM revision functions that is a proper sub-class of the class of AGM revision functions, but strictly larger (thus, more expressive) than the class of UR operators; hence, our proposal generalizes uniform revision. We call the presented operators theory-relational revision operators (abbrev. TR operators), since each such operator is uniquely defined through a single binary relation over theories of the language, called strong theory-relation. The connection between the semantic constructions of TR and UR operators is investigated, whereas, it is shown how a generalization (weakening) of a strong theory-relation -which is also a single fixed binary relation over theories, called weak theory-relation- can induce any AGM revision function. This latter result immediately proves an upper bound for the total number of AGM revision functions.
C1 [Aravanis, Theofanis] Univ Peloponnese, Sch Engn, Dept Mech Engn, Patras 26334, Greece.
   [Peppas, Pavlos] Univ Patras, Sch Engn, Dept Elect & Comp Engn, Patras 26500, Greece.
C3 University of Patras; University of Patras
RP Aravanis, T (通讯作者)，Univ Peloponnese, Sch Engn, Dept Mech Engn, Patras 26334, Greece.
EM taravanis@upatras.gr; pavlos@upatras.gr
CR ALCHOURRON CE, 1985, J SYMBOLIC LOGIC, V50, P510, DOI 10.2307/2274239
   Aravanis T, 2021, ANN MATH ARTIF INTEL, V89, P7, DOI 10.1007/s10472-019-09625-x
   Aravanis T, 2020, J LOGIC COMPUT, V30, P1357, DOI 10.1093/logcom/exaa058
   Areces C, 2001, FRONTIERS BELIEF REV, V22, P0
   Darwiche A, 1997, ARTIF INTELL, V89, P1, DOI 10.1016/S0004-3702(96)00038-0
   Gardenfors P, 1988, KNOWLEDGE FLUX MODEL, V0, P0
   Grdenfors P, 1988, P 2 C THEOR ASP REAS, V0, P8395
   GROVE A, 1988, J PHILOS LOGIC, V17, P157
   Heltweg P, 2021, THESIS U HAGEN GERMA, V0, P0
   KATSUNO H, 1991, ARTIF INTELL, V52, P263, DOI 10.1016/0004-3702(91)90069-V
   Lehmann D, 1995, P 14 INT JOINT C ART, V0, P0
   Parikh Rohit, 1999, LOGIC LANGUAGE COMPU, V2, P266
   Peppas P, 1995, NOTRE DAME JOURNAL OF FORMAL LOGIC, V36, P120, DOI 10.1305/ndjfl/1040308831
   Peppas P, 2016, P 15 EUROPEAN C LOGI, V0, P401414
   Peppas P, 2015, ARTIF INTELL, V229, P126, DOI 10.1016/j.artint.2015.08.007
   Peppas P, 2014, OUTST CONTRIB LOGIC, V3, P71, DOI 10.1007/978-94-007-7759-0_5
   Peppas P, 2008, FOUND ARTIF INTELL, V0, PP317, DOI 10.1016/S1574-6526(07)03008-8
   ROTT H, 1991, LECT NOTES ARTIF INT, V465, P135, DOI 10.1007/BFb0018420
   Schlechta K, 2004, COHERENT SYSTEMS, V0, P0
NR 19
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1012-2443
EI 1573-7470
J9 ANN MATH ARTIF INTEL
JI Ann. Math. Artif. Intell.
PD JUN 15
PY 2022
VL 90
IS 6
BP 573
EP 594
DI 10.1007/s10472-022-09794-2
EA APR 2022
PG 22
WC Computer Science, Artificial Intelligence; Mathematics, Applied
SC Computer Science; Mathematics
GA 2H4KV
UT WOS:000796011100001
DA 2023-11-10
ER

PT J
AU Yang, F
   Wang, WC
   Wang, F
   Fang, Y
   Tang, DY
   Huang, JZ
   Lu, H
   Yao, JH
AF Yang, Fan
   Wang, Wenchuan
   Wang, Fang
   Fang, Yuan
   Tang, Duyu
   Huang, Junzhou
   Lu, Hui
   Yao, Jianhua
TI scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data
SO NATURE MACHINE INTELLIGENCE
LA English
DT Article
AB Annotating cell types on the basis of single-cell RNA-seq data is a prerequisite for research on disease progress and tumour microenvironments. Here we show that existing annotation methods typically suffer from a lack of curated marker gene lists, improper handling of batch effects and difficulty in leveraging the latent gene-gene interaction information, impairing their generalization and robustness. We developed a pretrained deep neural network-based model, single-cell bidirectional encoder representations from transformers (scBERT), to overcome the challenges. Following BERT's approach to pretraining and fine-tuning, scBERT attains a general understanding of gene-gene interactions by being pretrained on huge amounts of unlabelled scRNA-seq data; it is then transferred to the cell type annotation task of unseen and user-specific scRNA-seq data for supervised fine-tuning. Extensive and rigorous benchmark studies validated the superior performance of scBERT on cell type annotation, novel cell type discovery, robustness to batch effects and model interpretability. Cell type annotation is a core task for single cell RNA-sequencing, but current bioinformatic tools struggle with some of the underlying challenges, including high dimensionality, data sparsity, batch effects and a lack of labels. In a self-supervised approach, a transformer model called scBERT is pretrained on millions of unlabelled public single cell RNA-seq data and then fine-tuned with a small number of labelled samples for cell annotation tasks.
C1 [Yang, Fan; Wang, Wenchuan; Wang, Fang; Fang, Yuan; Tang, Duyu; Yao, Jianhua] Tencent, AI Lab, Shenzhen, Peoples R China.
   [Wang, Wenchuan; Lu, Hui] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Sch Life Sci & Biotechnol,SJTU Yale Joint Ctr Bio, Shanghai, Peoples R China.
   [Fang, Yuan] Harvard Univ, Dept Mol & Cellular Biol, Cambridge, MA 02138 USA.
   [Fang, Yuan] Harvard Med Sch, Dept Immunol, Boston, MA 02115 USA.
   [Huang, Junzhou] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.
   [Lu, Hui] Shanghai Childrens Hosp, Shanghai Engn Res Ctr Big Data Pediat Precis Med, Ctr Biomed Informat, Shanghai, Peoples R China.
C3 Tencent; Shanghai Jiao Tong University; Harvard University; Harvard University; Harvard Medical School; University of Texas System; University of Texas Arlington; Shanghai Jiao Tong University
RP Yao, JH (通讯作者)，Tencent, AI Lab, Shenzhen, Peoples R China.; Lu, H (通讯作者)，Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Sch Life Sci & Biotechnol,SJTU Yale Joint Ctr Bio, Shanghai, Peoples R China.; Lu, H (通讯作者)，Shanghai Childrens Hosp, Shanghai Engn Res Ctr Big Data Pediat Precis Med, Ctr Biomed Informat, Shanghai, Peoples R China.
EM huilu@sjtu.edu.cn; jianhuayao@tencent.com
FU National Key R&D Program of China [2018YFC0910500]; SJTU-Yale Collaborative Research Seed Fund; Neil Shen's SJTU Medical Research and Key-Area Research; Development Program of Guangdong Province [2021B0101420005]
CR Abdelaal T, 2019, GENOME BIOL, V20, P0, DOI 10.1186/s13059-019-1795-z
   Alquicira-Hernandez J, 2019, GENOME BIOL, V20, P0, DOI 10.1186/s13059-019-1862-5
   Anders S, 2010, GENOME BIOL, V11, P0, DOI 10.1186/gb-2010-11-10-r106
   Aran D, 2019, NAT IMMUNOL, V20, P163, DOI 10.1038/s41590-018-0276-y
   Baron M, 2016, CELL SYST, V3, P346, DOI 10.1016/j.cels.2016.08.011
   Cao JY, 2019, NATURE, V566, P496, DOI 10.1038/s41586-019-0969-x
   Cao YH, 2020, FRONT GENET, V11, P0, DOI 10.3389/fgene.2020.00490
   Cao ZJ, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17281-7
   Choromanski Krzysztof Marcin, 2021, INT C LEARN REPR, V0, P0
   Cortal A, 2021, NAT BIOTECHNOL, V39, P1095, DOI 10.1038/s41587-021-00896-6
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du JC, 2019, BMC GENOMICS, V20, P0, DOI 10.1186/s12864-018-5370-x
   Franzén O, 2019, DATABASE-OXFORD, V0, P0, DOI DOI 10.1093/database/baz046
   Goldberg YJ, 2017, NEURAL NETWORK METHO, V10, P1, DOI 10.2200/S00762ED1V01Y201703HLT037
   Grabski IN, 2022, BIOSTATISTICS, V23, P1150, DOI 10.1093/biostatistics/kxac021
   Guo HY, 2021, GENOME BIOL, V22, P0, DOI 10.1186/s13059-021-02281-7
   Haghverdi L, 2018, NAT BIOTECHNOL, V36, P421, DOI 10.1038/nbt.4091
   Hao Yuhan, 2021, CELL, V184, P3573, DOI 10.1016/j.cell.2021.04.048
   He S, 2020, GENOME BIOL, V21, P0, DOI 10.1186/s13059-020-02210-0
   Tran HTN, 2020, GENOME BIOL, V21, P0, DOI 10.1186/s13059-019-1850-9
   Huang QH, 2021, GENOM PROTEOM BIOINF, V19, P267, DOI 10.1016/j.gpb.2020.07.004
   Hwang S, 2019, NUCLEIC ACIDS RES, V47, PD573, DOI 10.1093/nar/gky1126
   Kharchenko PV, 2014, NAT METHODS, V11, P740, DOI 10.1038/NMETH.2967
   Kimmel JC, 2021, GENOME RES, V31, P1781, DOI 10.1101/gr.268581.120
   Kiselev VY, 2018, NAT METHODS, V15, P359, DOI 10.1038/nmeth.4644
   Le, 2019, ADV NEURAL INFORM PR, V32, P0
   Li C, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-15185-0
   Litvinukova M, 2020, NATURE, V588, P466, DOI 10.1038/s41586-020-2797-4
   Lukassen S, 2020, EMBO J, V39, P0, DOI 10.15252/embj.20105114
   Ma FY, 2020, BIOINFORMATICS, V36, P533, DOI 10.1093/bioinformatics/btz592
   MacParland SA, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-06318-7
   Mahajan A, 2018, NAT GENET, V50, P1505, DOI 10.1038/s41588-018-0241-6
   McDavid A, 2013, BIOINFORMATICS, V29, P461, DOI 10.1093/bioinformatics/bts714
   Menden K, 2020, SCI ADV, V6, P0, DOI 10.1126/sciadv.aba2619
   Moffitt JR, 2018, SCIENCE, V362, P792, DOI 10.1126/science.aau5324
   Muraro MJ, 2016, CELL SYST, V3, P385, DOI 10.1016/j.cels.2016.09.002
   Nica AC, 2013, GENOME RES, V23, P1554, DOI 10.1101/gr.150706.112
   Parmar N, 2018, PR MACH LEARN RES, V80, P0
   Pasquini G, 2021, COMPUT STRUCT BIOTEC, V19, P961, DOI 10.1016/j.csbj.2021.01.015
   Plass M, 2018, SCIENCE, V360, P0, DOI 10.1126/science.aaq1723
   Pliner HA, 2019, NAT METHODS, V16, P983, DOI 10.1038/s41592-019-0535-3
   Qiu P, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-14976-9
   Schaum N, 2018, NATURE, V562, P367, DOI 10.1038/s41586-018-0590-4
   Segerstolpe Å, 2016, CELL METAB, V24, P593, DOI 10.1016/j.cmet.2016.08.020
   Serra A, 2018, BIOINFORMATICS, V34, P625, DOI 10.1093/bioinformatics/btx642
   Tucker NR, 2020, CIRCULATION, V142, P466, DOI 10.1161/CIRCULATIONAHA.119.045401
   Wang T, 2021, NAT COMMUN, V12, P0, DOI 10.1038/s41467-020-20646-7
   Wang TX, 2019, GENOME BIOL, V20, P0, DOI 10.1186/s13059-019-1764-6
   Wang XR, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-12773-7
   Xie P, 2019, NUCLEIC ACIDS RES, V47, P0, DOI 10.1093/nar/gkz116
   Xin YR, 2016, CELL METAB, V24, P608, DOI 10.1016/j.cmet.2016.08.018
   Yang, 2022, SCBERT LARGE SCALE P, V0, P0, DOI DOI 10.5281/zenodo.6572672
   Yin P, 2020, P 58 ANN M ASS COMP, V0, PP8413, DOI 10.18653/V1/2020.ACL-MAIN.745
   Ying Chengxuan, 2021, ADV NEURAL INFORM PR, V0, P34
   Yun S, 2019, ADV NEUR IN, V32, P0
   Zhang XX, 2019, NUCLEIC ACIDS RES, V47, PD721, DOI 10.1093/nar/gky900
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhang Z, 2019, GENES-BASEL, V10, P0, DOI 10.3390/genes10070531
   Zhao XL, 2020, BRIEF BIOINFORM, V21, P1581, DOI 10.1093/bib/bbz096
   ZHENG GX, 2017, NATURE, V0008, P0
NR 60
TC 15
Z9 15
U1 26
U2 63
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 
EI 2522-5839
J9 NAT MACH INTELL
JI Nat. Mach. Intell.
PD OCT 15
PY 2022
VL 4
IS 10
BP 852
EP +
DI 10.1038/s42256-022-00534-z
EA SEP 2022
PG 27
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 5M4UW
UT WOS:000859605000002
DA 2023-11-10
ER

PT J
AU Yang, P
   Ge, YY
   Yao, Y
   Yang, Y
AF Yang, Peng
   Ge, Yanyan
   Yao, Yu
   Yang, Ying
TI GCN-based document representation for keyphrase generation enhanced by maximizing mutual information
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Keyphrase generation; Sequence-to-sequence; Graph convolutional network; Mutual information
AB Keyphrase generation is an important fundamental task of natural language processing, which can help users quickly obtain valuable information from a large number of documents especially when they are facing with informal social media text. Existing Recurrent Neural Network (RNN) based keyphrase generation approaches cannot properly model the dependency structure of the informal text, which is often implicit between those distant words and plays an important role in extracting salient information. To obtain core features of text, we apply Graph Convolutional Network (GCN) on document-level graph to capture dependency structure information. The GCN-based node representations are further fed into a predictor network to provide potential candidates for copying mechanism. Moreover, we utilize a novel variational selector network to determine the final selection probability of each word in a phrase, which relies on its probabilities of copying from a given document and being generated from a vocabulary. Eventually, we introduce an enhancement mechanism to maximize the mutual information between document and generated keyphrase, thus ensuring the consistency between them. Experiment results show that our model outperforms previous state-of-the-art baselines on three social datasets, including Weibo, Twitter and StackExchange. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Yang, Peng; Ge, Yanyan; Yao, Yu; Yang, Ying] Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Yang, Peng] Southeast Univ, Sch Cyber Sci & Engn, Nanjing, Peoples R China.
   [Yang, Peng; Ge, Yanyan; Yao, Yu; Yang, Ying] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Peoples R China.
C3 Southeast University - China; Southeast University - China; Southeast University - China
RP Yang, P (通讯作者)，Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China.
EM pengyang@seu.edu.cn
FU Consulting Project of Chinese Academy of Engineering [2020-XY-5, 2018-XY-07]; Fundamental Research Funds for the Central Universities, China; Collaborative Innovation Center of Novel Software Technology and Industrialization, China
CR Alsentzer Emily, 2020, ADV NEURAL INFORM PR, V33, P8017
   [Anonymous], 2012, P 18 ACM SIGKDD INT, V0, P0, DOI DOI 10.1145/2339530.2339592
   [Anonymous], 2007, ADV NEURAL INFORM PR, V0, P0
   Barker K, 2000, LECT NOTES ARTIF INT, V1822, P40
   Battaglia PW, 2016, NIPS, V0, P4502
   Belghazi MI, 2018, PR MACH LEARN RES, V80, P0
   Blei DM, 2017, J AM STAT ASSOC, V112, P859, DOI 10.1080/01621459.2017.1285773
   Caruana R, 2001, ADV NEUR IN, V13, P402
   Chan HP, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2163
   Chawla K, 2020, FINDINGS ASS COMPUTA, V0, PP2340, DOI 10.18653/V1/2020.FINDINGS-EMNLP.212
   Chen J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P4057
   Chen W, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2846
   Christopoulou F, 2019, P 2019 C EMP METH NA, V0, PP4925, DOI 10.18653/v1/D19-1498
   Devon Hjelm R, 2019, ICLR, V0, P0
   Gilmer J, 2017, PR MACH LEARN RES, V70, P0
   Grineva M, 2009, P 18 INT C WORLD WID, V0, PP661, DOI 10.1145/1526709.1526798
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Hasan KS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1262
   Hassani K, 2020, P ICML 2020, VVolume 119, P4116, DOI 10.48550/ARXIV.2006.05582
   Hua XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2661
   Jiang X, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP756, DOI 10.1145/1571941.1572113
   Kang D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6533
   Kingma DP, 2014, C TRACK P, V0, P0
   Kipf TN, 2017, P INT C LEARN REPR, V0, PP1, DOI 10.1109/ICDM.2019.00070
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, V0, PP67, DOI 10.18653/v1/P17-4012
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   LeCun A, 1990, HANDWRITTEN DIGIT RE, V0, PP396, DOI 10.1111/DSU.12130
   Lee DB, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P208
   Li W, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4843
   LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36
   Liu B, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP1106, DOI 10.1145/3308558.3313737
   Liu Z, 2010, P 2010 C EMP METH NA, V0, P366
   Liu Z, 2009, P 2009 C EMP METH NA, V0, PP257, DOI 10.3115/1699510.1699544
   Luan Y, 2017, EMPIRICAL METHODS NA, V0, PP2641, DOI 10.18653/V1/D17-1279
   Medelyan O, 2009, P 2009 C EMP METH NA, V0, PP1318, DOI 10.3115/1699648.1699678
   Meng R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P582, DOI 10.18653/v1/P17-1054
   Miao YS, 2017, PR MACH LEARN RES, V70, P0
   Mihalcea Rada, 2004, P 2004 C EMP METH NA, V0, PP404, DOI 10.3115/1219044.1219064
   Nimah I, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP1063, DOI 10.1145/3178876.3186005
   Peng Z, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP259, DOI 10.1145/3366423.3380112
   Qiu L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P6140
   Sun Fan-Yun, 2020, INT C LEARNING REPRE, V0, P0
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   van den Oord Aaron, 2018, ARXIV180703748, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Velickovi P, 2018, INT C LEARNING REPRE, V0, P0
   velickovic P, 2019, INT C LEARNING REPRE, V0, P0
   Villmow J, 2018, PROC INT C MACH LEAR, V0, P210
   Wang Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2516
   Witten IH, 2005, DESIGN USABILITY DIG, V0, PP129, DOI 10.4018/978-1-59140-441-5.CH008
   Zhang Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1601
   Yao L, 2019, AAAI CONF ARTIF INTE, V0, P7370
   Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P4568
   Zhang Q, 2016, P 2016 C EMPIRICAL M, V0, PP836, DOI 10.18653/V1/D16-1080
   Zhang Y, 2018, IEEE ACCESS, V6, P46047, DOI 10.1109/ACCESS.2018.2865589
   Zhang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P334
   Zhao J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P5224
NR 60
TC 4
Z9 4
U1 4
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD MAY 11
PY 2022
VL 243
IS 
BP 
EP 
DI 10.1016/j.knosys.2022.108488
EA MAR 2022
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 2Q5PN
UT WOS:000820474200014
DA 2023-11-10
ER

PT J
AU Hussain, Y
   Huang, ZQ
   Zhou, Y
   Khan, IA
AF Hussain, Yasir
   Huang, Zhiqiu
   Zhou, Yu
   Khan, Izhar Ahmed
TI Exploring the Impact of Balanced and Imbalanced Learning in Source Code Suggestion
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE Deep learning; source code modeling; balanced and imbalanced learning; weighted learning
ID classification; smote
AB Studies have confirmed the robust performance of machine learning classifiers for various source code modeling tasks. In general, machine learning approaches are incapable of handling imbalanced datasets, since they are sensitive to the choice of diverse classes. Therefore, these approaches may lean towards the classes with a large percentage of observations. In this work, we investigate and explore the impact of balanced and imbalanced learning on source code suggestion task otherwise known as code completion, covering a large number of imbalanced classes. We further explore the impact of vocabulary size on modeling performance. First, we provide the essentials to formulate the problem of source code suggestion as a classification task and investigate the level of imbalanced classes. Second, we train the four most adapted neural language models as a baseline to assess the modeling performance. Third, we impose two diverse class balancing techniques, TomekLinks and AllKNN, to balance the datasets and evaluate their impact on the modeling performance. Finally, we trained these models with a weighted imbalanced learning approach and compared the performance with balanced learning approaches. Additionally, we train models by varying the vocabulary size to study their impact. In total, we trained 230 models on 10 real-world software projects and extensively evaluated these models with widely used performance metrics such as Precision, Recall, FScore, mean reciprocal rank (MRR), and Receiver operating characteristics (ROC). Additionally, we employed ANOVA statistical analysis to study the statistical significance and differences between these approaches. This study has demonstrated that the modeling performance decreases during balanced model training, whereas the weighted imbalance training produces comparable results and is more efficient in terms of time cost. Additionally, this study exhibits that a large size of vocabulary does not necessarily improve the modeling performance when out-of-vocabulary predictions are disregarded.
C1 [Hussain, Yasir; Huang, Zhiqiu; Zhou, Yu; Khan, Izhar Ahmed] Nanjing Univ Aeronaut & Astronaut NUAA, Coll Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Hussain, Y (通讯作者)，Nanjing Univ Aeronaut & Astronaut NUAA, Coll Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
EM yaxirhuxxain@nuaa.edu.cn; zqhuang@nuaa.edu.cn; zhouyu@nuaa.edu.cn; izhar@nuaa.edu.cn
FU National Natural Science Foundation of China [61972197, 61802179]; Natural Science Foundation of Jiangsu Province [BK20201292]; Qing Lan Project
CR Allamanis M, 2016, PR MACH LEARN RES, V48, P0
   Alon U, 2019, P ACM PROGRAM LANG, V3, P0, DOI 10.1145/3290353
   Nguyen AT, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P323, DOI 10.1109/SANER.2018.8330220
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   DAS SR, 1972, IEEE T COMPUT, VC 21, P1239, DOI 10.1109/T-C.1972.223484
   Drummond C, 2003, P WORKSH LEARN IMB D, V0, P1
   Elhassan AT, 2016, GLOBAL J TECHNOLOGY, V01, P0, DOI 10.4172/2229-8711.s1111
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Foody GM, 1999, INT J REMOTE SENS, V20, P3549, DOI 10.1080/014311699211192
   FUNAHASHI K, 1993, NEURAL NETWORKS, V6, P801, DOI 10.1016/S0893-6080(05)80125-X
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Guo H, 2004, SIGKDD EXPLORATIONS, V6, P30, DOI 10.1145/1007730.1007736
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, V0, PP1322, DOI 10.1109/IJCNN.2008.4633969
   Hindle A, 2012, PROC INT CONF SOFTW, V0, PP837, DOI 10.1109/ICSE.2012.6227135
   Hu X, 2020, EMPIR SOFTW ENG, V25, P2179, DOI 10.1007/s10664-019-09730-9
   Hu X, 2018, INT C PROGRAM COMPRE, V0, PP200, DOI 10.1145/3196321.3196334
   Hussain Y, 2020, INT J SOFTW ENG KNOW, V30, P649, DOI 10.1142/S0218194020500230
   Hussain Y, 2020, ELECTRON LETT, V56, P604, DOI 10.1049/el.2020.0500
   Hussain Y, 2020, INFORM SOFTWARE TECH, V125, P0, DOI 10.1016/j.infsof.2020.106309
   Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073
   Japkowicz N, 2002, INTELLIGENT DATA ANALYSIS, V6, P429
   Kotsiantis S, 2006, GESTS INT T COMPUTER, V30, P25
   Kovács G, 2019, NEUROCOMPUTING, V366, P352, DOI 10.1016/j.neucom.2019.06.100
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kuncheva LI, 2019, PROG ARTIF INTELL, V8, P215, DOI 10.1007/s13748-019-00172-4
   Liu C, 2016, NEURAL CODE COMPLETI, V0, P0
   Mi Q, 2018, INFORM SOFTWARE TECH, V104, P60, DOI 10.1016/j.infsof.2018.07.006
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mou LL, 2016, AAAI CONF ARTIF INTE, V0, P1287
   Prati RC, 2009, IICAI, V0, P359
   Raychev V, 2014, ACM SIGPLAN NOTICES, V49, P419, DOI 10.1145/2666356.2594321
   Ripley BD, 1996, PATTERN RECOGN, V0, P0
   Santos EA, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P311, DOI 10.1109/SANER.2018.8330219
   Sethi A, 2018, AAAI CONF ARTIF INTE, V0, P7339
   Stetco A, 2019, RENEW ENERG, V133, P620, DOI 10.1016/j.renene.2018.10.047
   TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769, DOI 10.1109/tsmc.1976.4309452
   TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448
   White M, 2015, 12TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2015), V0, PP334, DOI 10.1109/MSR.2015.38
   Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258
   Ye W, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2309, DOI 10.1145/3366423.3380295
   Zhou Y, 2022, IEEE T SOFTWARE ENG, V48, P2157, DOI 10.1109/TSE.2021.3053111
   Zhou Y, 2019, J SYST SOFTWARE, V156, P328, DOI 10.1016/j.jss.2019.07.087
NR 48
TC 0
Z9 0
U1 3
U2 4
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD OCT 15
PY 2022
VL 32
IS 10
BP 1499
EP 1526
DI 10.1142/S0218194022500589
EA OCT 2022
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 6J4GM
UT WOS:000876546400001
DA 2023-11-10
ER

PT J
AU Wullach, T
   Adler, A
   Minkov, E
AF Wullach, Tomer
   Adler, Amir
   Minkov, Einat
TI Character-level HyperNetworks for Hate Speech Detection
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Hate speech detection; Neural networks; Text generation
AB The massive spread ofhate speech, hateful content targeted at specific subpopulations, is a problem of criticalsocial importance. Automated methods of hate speech detection typically employ state-of-the-art deep learning(DL)-based text classifiers-large pretrained neural language models of over 100 million parameters, adaptingthese models to the task of hate speech detection using relevant labeled datasets. Unfortunately, there areonly a few public labeled datasets of limited size that are available for this purpose. We make severalcontributions with high potential for advancing this state of affairs. We present HyperNetworks for hate speechdetection, a special class of DL networks whose weights are regulated by a small-scale auxiliary network.These architectures operate at character-level, as opposed to word or subword-level, and are several ordersof magnitude smaller compared to the popular DL classifiers. We further show that training hate detectionclassifiers using additional large amounts of automatically generated examples is beneficial in general, yetthis practice especially boosts the performance of the proposed HyperNetworks. We report the results ofextensive experiments, assessing the performance of multiple neural architectures on hate detection using fivepublic datasets. The assessed methods include the pretrained language models of BERT, RoBERTa, ALBERT,MobileBERT and CharBERT, a variant of BERT that incorporates character alongside subword embeddings. Inaddition to the traditional setup of within-dataset evaluation, we perform cross-dataset evaluation experiments,testing the generalization of the various models in conditions of data shift. Our results show that the proposedHyperNetworks achieve performance that is competitive, and better in some cases, than these pretrainedlanguage models, while being smaller by orders of magnitude
C1 [Wullach, Tomer; Minkov, Einat] Univ Haifa, Dept Informat Syst, Haifa, Israel.
   [Adler, Amir] Braude Coll Engn, Dept Elect Engn, Karmiel, Israel.
   [Adler, Amir] MIT, McGovern Inst Brain Res, Cambridge, MA USA.
C3 University of Haifa; Braude Academic College of Engineering; Massachusetts Institute of Technology (MIT)
RP Wullach, T (通讯作者)，Univ Haifa, Dept Informat Syst, Haifa, Israel.
EM tomerw@originai.co; adleram@braude.ac.il; einatm@is.haifa.ac.il
FU Facebook Content Policy Research on Social Media Platforms Research Award
CR Abadi Mart<prime>in, 2015, TENSOR FLOW LARGE SC, V0, P0
   [Anonymous], 2018, EUR SEM WEB C, V0, P0, DOI DOI 10.1049/JOE.2017.0388
   Badjatiya P, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP759, DOI 10.1145/3041021.3054223
   Basile V, 2019, P 13 INT WORKSH SEM, V0, P54
   Beddiar DR, 2021, ONLINE SOC NETW MEDI, V24, P0, DOI 10.1016/J.OSNEM.2021.100153
   Behzadi M, 2021, IEEE INT C SEMANT CO, V0, PP199, DOI 10.1109/ICSC50631.2021.00042
   Caselli T, 2020, ARXIV201012472, V0, P0
   Davidson T, 2017, AUTOMATED HATE SPEEC, V11, P512, DOI 10.1609/icwsm.v11i1.14955
   De Gibert O, 2019, PROC 2 WORKSHOP ABUS, V0, P0, DOI DOI 10.18653/v1/w18-5102
   de Vries W, 2021, FINDINGS ASS COMPUTA, V0, P0
   Devlin J, 2018, ARXIV, V1, P4171
   Feng SY, 2021, FINDINGS ASS COMPUTA, V0, PP968, DOI 10.18653/V1/2021.FINDINGS-ACL.84
   Founta AM, 2019, P 10 ACM C WEB SCI, V0, P0
   Founta Antigoni-Maria, 2018, 12 AAAI ICWSM, V0, P0
   Glorot X, 2010, P 13 INT C ARTIFICIA, V0, P249
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gururangan Suchin, 2020, P ANN M ASS COMP LIN, V0, P0
   Ha David, 2017, ICLR, V1, P0
   Isaksen V, 2020, P 4 WORKSH ONL AB HA, V0, P0
   Jiao X, 2020, FINDINGS ASS COMPUTA, V0, P0
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Kudo T, 2018, P ANN M ASS COMP LIN, V0, P0
   Kumar A, 2020, P 6 WORKSH NOIS US G, V0, P0
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Ma W, 2020, P 28 INT C COMP LING, V0, P0
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Mandl T, 2021, ARXIV210805927, V0, P0
   Mathew B, 2021, 35 AAAI C ART INT, V0, P0
   Mehdad Yashar, 2016, P 17 ANN M SPECIAL I, V0, PP299, DOI 10.18653/V1/W16-3638
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Miok K, 2021, COGN COMPUT, V0, P1
   Modha S, 2020, EXPERT SYST APPL, V161, P0, DOI 10.1016/j.eswa.2020.113725
   Mozafari M, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0237861
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Radford A, 2019, LANGUAGE MODELS ARE, V0, P0, DOI DOI 10.1109/CVPRW.2017.228
   Radford Alec, 2018, IMPROVING LANGUAGE U, V0, P0
   Rizos G, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP991, DOI 10.1145/3357384.3358040
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Sarkar D, 2021, FINDINGS ASS COMPUTA, V0, P0
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, P2158
   Tran T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P7486
   Vijayaraghavan P, 2016, SEMEVAL, V0, PP413, DOI 10.18653/v1/S16-1067
   Waseem Zeerak, 2016, P NAACL STUD RES WOR, V0, PP88, DOI 10.18653/V1/N16-2013
   Wiegand M, 2019, P 2019 C N AM CHAPT, V0, P0
   Wullach T, 2021, FINDINGS ASS COMPUTA, V0, P0
   Wullach T, 2021, IEEE INTERNET COMPUT, V25, P48, DOI 10.1109/MIC.2020.3033161
   Zhang Xiang, 2015, NEURIPS, V0, P0, DOI DOI 10.5555/2969239.2969312
   ZHU ZJ, 2021, J IND PRODUCTION ENG, V0, P0, DOI DOI 10.1111/1541-4337.12754
NR 49
TC 2
Z9 2
U1 2
U2 12
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 1
PY 2022
VL 205
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.117571
EA MAY 2022
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 2T9QU
UT WOS:000822801600009
DA 2023-11-10
ER

PT J
AU Liu, JP
   Chen, T
   Wang, C
   Liang, JQ
   Chen, LH
   Xiao, YH
   Chen, YW
   Jin, K
AF Liu, Jingping
   Chen, Tao
   Wang, Chao
   Liang, Jiaqing
   Chen, Lihan
   Xiao, Yanghua
   Chen, Yunwen
   Jin, Ke
TI VoCSK: Verb-oriented commonsense knowledge mining with taxonomy-guided induction
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Commonsense knowledge; Verb phrases; Probabilistic taxonomy
ID large-scale
AB Commonsense knowledge acquisition is one of the fundamental issues in realizing human- level AI. However, commonsense knowledge is difficult to obtain because it is a human consensus and rarely explicitly appears in texts or other data. In this paper, we focus on the automatic acquisition of a typical kind of implicit verb-oriented commonsense knowledge (e.g., "person eats food "), which is the concept-level knowledge of verb phrases. For this purpose, we propose a taxonomy-guided induction method to mine verb-oriented commonsense knowledge from verb phrases with the help of a probabilistic taxonomy. First, we design an entropy-based triplet filter to cope with noisy verb phrases. Then, we propose a joint model based on the minimum description length principle and a neural language model to generate verb-oriented commonsense knowledge. Besides, we introduce two strategies to accelerate the computation, including the simulated annealing-based approximate solution and the verb phrase clustering method. Finally, we conduct extensive experiments to prove that our solution is more effective than competitors in mining verb-oriented commonsense knowledge. We construct a commonsense knowledge base called VoCSK, containing 259 verbs and 18,406 verb-oriented commonsense knowledge. To verify the usefulness of VoCSK, we utilize the knowledge in this KB to improve the model performance on two downstream applications. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Liu, Jingping; Chen, Tao; Wang, Chao; Liang, Jiaqing; Chen, Lihan; Xiao, Yanghua] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
   [Chen, Yunwen; Jin, Ke] DataGrand Inc, Shanghai, Peoples R China.
C3 Fudan University
RP Xiao, YH (通讯作者)，Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
EM jpliu17@fudan.edu.cn; chentao20@fudan.edu.cn; 17110240038@fudan.edu.cn; l.j.q.light@gmail.com; lhc825@gmail.com; shawyh@fudan.edu.cn; chentao20@fudan.edu.cn; jinke@datagrand.com
FU National Key Research and Development Project [2020AAA0109302]; Shanghai Science and Technology Innovation Action Plan [19511120400]; Shanghai Municipal Science and Technology Major Project [2021SHZDZX0103]
CR AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855
   Baker CF, 1998, P COLING ACL, V0, P0
   Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Berant J, 2011, P 49 ANN M ASS COMPU, V1, P610
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Cheng J, 2015, P 24 ACM INT C INFOR, V0, P133
   Cover T, 2006, ELEMENTS INFORM THEO, V2nd ed., P0
   Cummins R, 2015, ACM T INFORM SYST, V33, P0, DOI 10.1145/2746231
   Dai H, 2021, ULTRA FINE ENTITY TY, V0, P0
   Dang HT, 2004, INVESTIGATIONS ROLE, V0, P0
   Dekang Lin, 2001, KDD-2001. PROCEEDINGS OF THE SEVENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P323
   Devlin J, 2018, ARXIV, V1, P4171
   Ester M, 1996, DENSITY BASED ALGORI, V0, P226
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   FM Suchanek, 2007, WWW, V0, P697
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Gupta A, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP1329, DOI 10.1145/3132847.3133041
   Hassan H, 2018, ACHIEVING HUMAN PARI, V0, P0
   Hua W, 2015, PROC INT CONF DATA, V0, PP495, DOI 10.1109/ICDE.2015.7113309
   Huang ZQ, 2021, SIGIR 21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP2101, DOI 10.1145/3404835.3463100
   Kipper-Schuler K, 2005, THESIS, V0, P0
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kurland O, 2010, ACM T INFORM SYST, V28, P0, DOI 10.1145/1852102.1852104
   Lan Zhenzhong, 2019, ARXIV190911942, V0, P0
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Levesque H, 2012, P KR ROM IT, V0, P0
   Levin Beth, 1993, ENGLISH VERB CLASSES, V0, P0
   Liang JQ, 2017, AAAI CONF ARTIF INTE, V0, P1178
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Liu JP, 2020, PROC INT CONF DATA, V0, PP1830, DOI 10.1109/ICDE48307.2020.00181
   Liu Y, 2019, ROBERTA ROBUSTLY OPT, V0, P0
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Niles I, 2001, FORMAL ONTOLOGY IN INFORMATION SYSTEMS. COLLECTED PAPERS FROM THE SECOND INTERNATIONAL CONFERENCE, V0, PP2, DOI 10.1145/505168.505170
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Pan SNJ, 2013, ACM T INFORM SYST, V31, P0, DOI 10.1145/2457465.2457467
   Pasca M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2832
   Raffel C, 2020, J MACH LEARN RES, V21, P0
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Seitner J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P360
   Song Y, 2011, P 22 INT JOINT C ART, VThree, P2330
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Tandon N, 2014, WSDM14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP523, DOI 10.1145/2556195.2556245
   Tandon N, 2016, AAAI CONF ARTIF INTE, V0, P243
   Tandon N, 2014, AAAI CONF ARTIF INTE, V0, P166
   Tandon N, 2017, SIGMOD REC, V46, P49, DOI 10.1145/3186549.3186562
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wang Z, 2015, CIKM, V0, P0
   Wang ZY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P3264
   Wolf T, 1900, P38, V0, P0
   Wu W, 2011, MSRTR201125, V0, P0
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang Sheng, 2017, T ASS COMPUTATIONAL, V5, P379, DOI 10.1162/tacla00068
   Zhang Y, 2020, P 58 ANN M ASS COMPU, V0, PP8151, DOI 10.18653/V1/2020.ACL-MAIN.725
NR 57
TC 1
Z9 1
U1 3
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD SEP 15
PY 2022
VL 310
IS 
BP 
EP 
DI 10.1016/j.artint.2022.103744
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 2Z3GF
UT WOS:000826469600001
DA 2023-11-10
ER

PT J
AU Akinwumi, Y
   Ayeni, J
   Arekete, S
   Odim, M
   Ogunde, A
   Oguntunde, B
AF Akinwumi, Yetunde
   Ayeni, Joshua
   Arekete, Samson
   Odim, Mba
   Ogunde, Adewale
   Oguntunde, Bosede
TI XAPP: An Implementation of SAX-Based Method for Mapping XML Document to and from a Relational Database
SO INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY
LA English
DT Article
DE Extensible markup language; XML document; relational database; reconstruction time; mapping time
AB Extensible Markup Language (XML) is the standard medium for data exchange among businesses over the Internet, hence the need for effective management. However, since XML was not designed for storage and retrieval, its management has become an open research area in the database community. Existing mapping techniques for XML-to-relational database adopt either the structural mapping or the model mapping. Though numerous mapping approaches have been developed, mapping and reconstruction time had been problematic, especially when the document size is large and can hardly fit into main memory. In this research, an application codenamed XAPP, a new lightweight application that adopts a novel model mapping approach was developed using Simple API for XML (SAX) parser. XAPP accepts a document with or without Document Type Definition (DTD). It implements two algorithms: one maps XML data to a relational database and improves mapping time, and the other reconstructs an XML document from a relational database to improve reconstruction time and minimise memory usage. The performance of XAPP was analysed and compared with the Document Object Model (DOM) algorithm. XAPP proves to perform significantly better than the DOM-based algorithm in terms of mapping and reconstruction time, and memory efficiency. The correctness of XAPP was also verified.
C1 [Akinwumi, Yetunde; Ayeni, Joshua; Arekete, Samson; Odim, Mba; Ogunde, Adewale; Oguntunde, Bosede] Redeemers Univ, Dept Comp Sci, Ede, Nigeria.
C3 Redeemers University
RP Akinwumi, Y (通讯作者)，Redeemers Univ, Dept Comp Sci, Ede, Nigeria.
EM Akinyetty16@gmail.com; ayenij@run.edu.ng; areketes@mn.edu.ng; odimm@run.edu.ng; ogundea@run.edu.ng; oguntunden@run.edu.ng
CR Ahmad K, 2011, LECT NOTES ARTIF INT, V6591, P100, DOI 10.1007/978-3-642-20039-7_10
   Atay M, 2007, INFORM SYST, V32, P458, DOI 10.1016/j.is.2005.12.008
   Bousalem Zakaria, 2015, JOURNAL OF SOFTWARE, V10, P1389, DOI 10.17706/jsw.10.12.1389-1401
   Dwebi I, 2010, THESIS U HUDDERSFIEL, V0, P0
   Fakharaldien Mohammed Adam Ibrahim, 2012, INT J PHYS SCI, V7, P4012
   Miklau G, 2003, XML DATA REPOSITORY, V0, P0
   Qtaish A, 2016, KNOWL-BASED SYST, V114, P167, DOI 10.1016/j.knosys.2016.10.009
   Seif E, 2011, THESIS U KHARTOUM, V0, P0
   Subramaniam S, 2012, KNOWL-BASED SYST, V27, P369, DOI 10.1016/j.knosys.2011.11.007
   Trabelsi Z, 2004, INT ARAB J INF TECHN, V1, P93
   Wang Q, 2012, PHYSCS PROC, V33, P1621, DOI 10.1016/j.phpro.2012.05.261
   Zhu HC, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), V0, P839
NR 12
TC 0
Z9 0
U1 0
U2 4
PU ZARKA PRIVATE UNIV
PI ZARQA
PA COLL COMPUTING & INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN
SN 1683-3198
EI 
J9 INT ARAB J INF TECHN
JI Int. Arab J. Inf. Technol.
PD JUL 15
PY 2022
VL 19
IS 4
BP 582
EP 588
DI 10.34028/iajit/19/4/2
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 2Y7DR
UT WOS:000826053300003
DA 2023-11-10
ER

PT J
AU Jiang, WH
   Yan, L
   Tu, YF
   Zhou, XS
   Ma, ZM
AF Jiang, Weihao
   Yan, Li
   Tu, Yaofeng
   Zhou, Xiangsheng
   Ma, Zongmin
TI PG-explorer: Resource Description Framework data exploration with property graphs
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE RDF; Property graphs; Graph database; Semantic data; Data exploration
ID rdf; query
AB The Resource Description Framework (RDF) has been widely applied to represent and exchange domain infor-mation because of its machine-readable characteristic. With a huge amount of RDF data available, retrieving RDF data is essential, so that many RDF query approaches have been developed. But many traditional approaches generally require users to know RDF model and query language, and this seriously prevents a large number of common non-expert users from obtaining information in RDF datasets. In this paper, we propose an approach that users can explore massive RDF datasets by interactively manipulating property graphs. Our approach provides users with a series of operations in interactively constructing property graphs to describe their query intents. To efficiently explore massive RDF datasets, we convert RDF data into property graphs for storage. This can greatly reduce the size of massive RDF datasets and more importantly the converted property graphs can instruct users to understand the underlying structure of RDF datasets, which is very useful in users' construction of their query property graphs. The constructed query property graphs are finally transformed into expressions with the query language of graph databases. With high-performance graph databases as query engines, we developed an RDF data exploration system - PG-Explorer. Through experiments over real-world datasets, we evaluated the effectiveness and superiority of our approach. The user study demonstrates that the proposed approach simplifies users' exploration of RDF data and can satisfy their exploration needs.
C1 [Jiang, Weihao; Yan, Li; Ma, Zongmin] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Ma, Zongmin] Collaborat Innovat Ctr Novel Software Technol & I, Nanjing 210000, Peoples R China.
   [Tu, Yaofeng; Zhou, Xiangsheng] ZTE Corp, Nanjing Branch, Nanjing 210012, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; ZTE
RP Ma, ZM (通讯作者)，Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
EM zongminma@nuaa.edu.cn
FU Basic Research Program of Jiangsu Province [BK20191274]; National Natural Science Foundation of China [62176121, 61772269]
CR Abreu DD, 2013, P 2013 INT SEM WEB C, V1034, P0
   Ali Waqas, 2021, ABS210213027 CORR, V0, P0
   Angles R, 2019, AMW, V0, P0
   [Anonymous], 2014, LEARNING CYPHER, V0, P0
   [Anonymous], 2015, GRAPH DATABASES, V0, P0
   Arenas M, 2016, J WEB SEMANT, V37-38, P55, DOI 10.1016/j.websem.2015.12.002
   Bednar P, 2014, 2014 IEEE 12TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI), V0, PP361, DOI 10.1109/SAMI.2014.6822440
   Bollacker Kurt, 2008, P 2008 ACM SIGMOD IN, V0, PP1247, DOI 10.1145/1376616.1376746
   Bouhali R, 2015, IFIP ADV INF COMM TE, V458, P177, DOI 10.1007/978-3-319-23868-5_13
   Chen J, 2016, PROC INT CONF DATA, V0, PP1350, DOI 10.1109/ICDE.2016.7498342
   Deligiannidis L, 2007, P ACM 1 WORKSH CYB I, V0, PP39, DOI 10.1145/1317353.1317362
   Diefenbach D, 2020, LECT NOTES COMPUT SC, V12123, P429, DOI 10.1007/978-3-030-49461-2_25
   Francis N, 2018, INT CONF MANAGE DATA, V0, PP1433, DOI 10.1145/3183713.3190657
   Heim P, 2010, LECT NOTES COMPUT SC, V6088, P288, DOI 10.1007/978-3-642-13486-9_20
   Heim P, 2009, LECT NOTES COMPUT SC, V5887, P182, DOI 10.1007/978-3-642-10543-2_21
   Hodler EA, 2019, GRAPH ALGORITHMS, V0, P0
   Hu X, 2018, INFORM SCIENCES, V454, P363, DOI 10.1016/j.ins.2018.04.042
   Leskinen P, 2018, P 4 INT WORKSH VIS I, V0, P53
   Ma RZ, 2016, J INTELL FUZZY SYST, V30, P183, DOI 10.3233/IFS-151745
   Ma ZM, 2018, J DATABASE MANAGE, V29, P1, DOI 10.4018/JDM.2018100101
   Ma ZM, 2016, KNOWL ENG REV, V31, P391, DOI 10.1017/S0269888916000217
   Oommen BJ, 2002, COMPUT J, V45, P494, DOI 10.1093/comjnl/45.5.494
   Ouksili H, 2018, DATA KNOWL ENG, V113, P171, DOI 10.1016/j.datak.2017.06.003
   Popov IO, 2011, LECT NOTES COMPUT SC, V7031, P553, DOI 10.1007/978-3-642-25073-6_35
   Regino AG, 2021, SEMANT WEB, V12, P517, DOI 10.3233/SW-200398
   Rodriguez Marko A, 2010, BULLETIN OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY, V36, P35, DOI 10.1002/bult.2010.1720360610
   Seufert S, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW16 COMPANION), V0, PP251, DOI 10.1145/2872518.2890528
   Suchanek F, 2007, P 16 INT C WORLD WID, V0, P0, DOI DOI 10.1145/1242572.1242667
   Tomaszuk D, 2016, COMM COM INF SC, V672, P104, DOI 10.1007/978-3-319-49157-8_9
   Tzitzikas Y, 2017, J INTELL INF SYST, V48, P329, DOI 10.1007/s10844-016-0413-8
   Vang KJ, 2013, J INF COMMUN ETHICS, V0, P0
   Vargas H, 2019, LECT NOTES COMPUT SC, V11778, P647, DOI 10.1007/978-3-030-30793-6_37
   Wagner Andreas, 2011, DATABASE AND EXPERT SYSTEMS APPLICATIONS. PROCEEDINGS 22ND INTERNATIONAL CONFERENCE, V0, P303, DOI 10.1007/978-3-642-23088-2_22
   Yan L, 2017, COMPUTING, V99, P481, DOI 10.1007/s00607-017-0554-9
NR 34
TC 0
Z9 0
U1 0
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JUL 15
PY 2022
VL 198
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.116789
EA MAR 2022
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 1C1WR
UT WOS:000792918500004
DA 2023-11-10
ER

PT J
AU Loscos, D
   Martí-Oliet, N
   Rodríguez, I
AF Loscos, Daniel
   Marti-Oliet, Narciso
   Rodriguez, Ismael
TI Generalization and completeness of stochastic local search algorithms
SO SWARM AND EVOLUTIONARY COMPUTATION
LA English
DT Article
DE Stochastic local search; Evolutionary computation; Swarm intelligence; Formal languages; Operational semantics; Generalization; Computability; Turing-completeness
ID particle swarm optimization; ant colony optimization; evolutionary algorithms; convergence analysis; metaheuristics; selection
AB A B S T R A C T We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO.
C1 [Loscos, Daniel; Marti-Oliet, Narciso; Rodriguez, Ismael] Univ Complutense Madrid, Dept Sistemas Informat & Comp, Fac Informat, Madrid 28040, Spain.
C3 Complutense University of Madrid
RP Rodríguez, I (通讯作者)，Univ Complutense Madrid, Dept Sistemas Informat & Comp, Fac Informat, Madrid 28040, Spain.
EM dloscos@ucm.es; narciso@ucm.es; isrodrig@ucm.es
CR [Anonymous], 2006, GENETIC ALGORITHMS, V0, P0, DOI DOI 10.1016/j.asoc.2009.08.029
   [Anonymous], 2006, EVOLUTIONARY COMPUTA, V0, P0
   Arora S, 2009, COMPUTATIONAL COMPLEXITY: A MODERN APPROACH, V0, PP1, DOI 10.1017/CBO9780511804090
   Back T, 1997, HDB EVOLUTIONARY COM, V0, P0
   Cantú-Paz E, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, V0, P91
   Chuan L, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS
   Cutland NJ, 1980, COMPUTABILITY INTRO, V0, P0
   Das S, 2011, SWARM EVOL COMPUT, V1, P71, DOI 10.1016/j.swevo.2011.05.005
   Dorigo M, 1999, PROCEEDINGS OF THE 1999 CONGRESS ON EVOLUTIONARY COMPUTATION-CEC99 (CAT. NO. 99TH8406), V0, PP1470, DOI 10.1109/CEC.1999.782657
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Ducatelle F, 2005, INT J COMPUT INTELL, V5, P169, DOI 10.1142/S1469026805001556
   Eberhart RC, 2001, SWARM INTELL-US, V0, P0, DOI DOI 10.1016/B978-155860595-4/50007-3
   Friedrich T, 2015, EVOL COMPUT, V23, P543, DOI 10.1162/EVCO_a_00159
   Gong YJ, 2015, APPL SOFT COMPUT, V34, P286, DOI 10.1016/j.asoc.2015.04.061
   Hoos HH, 1900, P1085, V0, P0, DOI DOI 10.1007/978-3-662-43505- 2_54
   Hoos HH, 2004, STOCHASTIC LOCAL SEA, V0, P0
   Hutter Frank, 2011, LEARNING AND INTELLIGENT OPTIMIZATION. 5TH INTERNATIONAL CONFERENCE, V0, P507, DOI 10.1007/978-3-642-25566-3_40
   Hutter F, 2009, J ARTIF INTELL RES, V36, P267, DOI 10.1613/jair.2861
   Jiang M, 2007, INFORM PROCESS LETT, V102, P8, DOI 10.1016/j.ipl.2006.10.005
   Jiao LC, 2013, INFORM SCIENCES, V228, P90, DOI 10.1016/j.ins.2012.12.013
   Johnson AW, 2002, DISCRETE APPL MATH, V119, P37, DOI 10.1016/S0166-218X(01)00264-5
   Kang Q, 2012, INT J ARTIF INTELL T, V21, P0, DOI 10.1142/S021821301240012X
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Karaboga D, 2011, APPL SOFT COMPUT, V11, P3021, DOI 10.1016/j.asoc.2010.12.001
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS (CAT. NO.95CH35828), V0, PP1942, DOI 10.1109/ICNN.1995.488968
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Koza JR, 1989, IJCAI-89 PROCEEDINGS OF THE ELEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P768
   Laumanns M, 2004, IEEE T EVOLUT COMPUT, V8, P170, DOI 10.1109/TEVC.2004.823470
   Liu QF, 2016, INFORM SCIENCES, V363, P154, DOI 10.1016/j.ins.2016.04.050
   López-Ibáñez M, 2016, OPER RES PERSPECT, V3, P43, DOI 10.1016/j.orp.2016.09.002
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   MITRA D, 1986, ADV APPL PROBAB, V18, P747, DOI 10.2307/1427186
   Molina D, 2020, COMPREHENSIVE TAXONO, V0, P0
   Naidoo A, 2008, LECT NOTES COMPUT SC, V4971, P350, DOI 10.1007/978-3-540-78671-9_30
   Nolte A, 1996, ALGORITHMS - ESA 96. FOURTH ANNUAL EUROPEAN SYMPOSIUM. PROCEEDINGS, V0, P138
   Olmo JL, 2014, WIRES DATA MIN KNOWL, V4, P445, DOI 10.1002/widm.1138
   Pinto PC, 2009, IEEE T EVOLUT COMPUT, V13, P767, DOI 10.1109/TEVC.2009.2024142
   Qian C, 2019, ARTIF INTELL, V275, P279, DOI 10.1016/j.artint.2019.06.005
   Qiu CY, 2013, INT J COMPUT INT SYS, V6, P822, DOI 10.1080/18756891.2013.805584
   Rabanal P, 2007, LECT NOTES COMPUT SC, V4618, P163
   Rabanal P, 2016, PROCEDIA COMPUT SCI, V80, P289, DOI 10.1016/j.procs.2016.05.321
   RICE HG, 1953, T AM MATH SOC, V74, P358, DOI 10.2307/1990888
   Rodríguez I, 2017, APPL SOFT COMPUT, V55, P178, DOI 10.1016/j.asoc.2017.01.036
   Rudolph G, 1998, FUNDAMENTA INFORMATICAE, V35, P67
   Sekara M, 2015, PROCEDIA COMPUT SCI, V51, P954, DOI 10.1016/j.procs.2015.05.234
   Sörensen K, 2015, INT T OPER RES, V22, P3, DOI 10.1111/itor.12001
   Teller A, 1994, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON EVOLUTIONARY COMPUTATION. IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE (CAT. NO.94TH0650-2), V0, PP136, DOI 10.1109/ICEC.1994.350027
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
NR 51
TC 0
Z9 0
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2210-6502
EI 2210-6510
J9 SWARM EVOL COMPUT
JI Swarm Evol. Comput.
PD FEB 15
PY 2022
VL 68
IS 
BP 
EP 
DI 10.1016/j.swevo.2021.100982
EA JAN 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA 0W0TO
UT WOS:000788750900012
DA 2023-11-10
ER

PT J
AU Weiss, G
   Goldberg, Y
   Yahav, E
AF Weiss, Gail
   Goldberg, Yoav
   Yahav, Eran
TI Extracting automata from recurrent neural networks using queries and counterexamples (extended version)
SO MACHINE LEARNING
LA English
DT Article; Early Access
DE Recurrent neural networks; Automata; Deterministic finite automata; Exact learning; Extraction
ID context-free grammars; weighted automata; identification
AB We consider the problem of extracting a deterministic finite automaton (DFA) from a trained recurrent neural network (RNN). We present a novel algorithm that uses exact learning and abstract interpretation to perform efficient extraction of a minimal DFA describing the state dynamics of a given RNN. We use Angluin's L* algorithm as a learner and the given RNN as an oracle, refining the abstraction of the RNN only as much as necessary for answering equivalence queries. Our technique allows DFA-extraction from the RNN while avoiding state explosion, even when the state vectors are large and fine differentiation is required between RNN states. We experiment on multi-layer GRUs and LSTMs with state-vector dimensions, alphabet sizes, and underlying DFA which are significantly larger than in previous DFA-extraction work. Aditionally, we discuss when it may be relevant to apply the technique to RNNs trained as language models rather than binary classifiers, and present experiments on some such examples. In some of our experiments, the underlying target language can be described with a succinct DFA, yet we find that the extracted DFA is large and complex. These are cases in which the RNN has failed to learn the intended generalisation, and our extraction procedure highlights words which are misclassified by the seemingly "perfect" RNN.
C1 [Weiss, Gail; Yahav, Eran] Technion, Haifa, Israel.
   [Goldberg, Yoav] Bar Ilan Univ, Ramat Gan, Israel.
C3 Technion Israel Institute of Technology; Bar Ilan University
RP Weiss, G (通讯作者)，Technion, Haifa, Israel.
EM sgailw@cs.technon.ac.il; yogo@cs.biu.ac.il; yahave@cs.techmon.ac.il
FU European Research Council (ERC) under the European Union [802774]
CR Adi Y, 2016, CORR, V0, P0
   ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6
   Arras L, 2017, EXPLAINING RECURRENT, V0, P0
   Ayache S, 2018, P 14 INT C GRAMMATIC, V0, P81103
   Balle B, 2014, MACH LEARN, V96, P33, DOI 10.1007/s10994-013-5416-x
   Berg T, 2005, ELECTRON NOTES THEOR, V118, P3, DOI 10.1016/j.entcs.2004.12.015
   Boser BE, 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP144, DOI 10.1145/130385.130401
   Casey M, 1998, NEURAL COMPUT, V10, P1067, DOI 10.1162/089976698300017340
   Cechin AL, 2003, SCCC 2003: XXIII INTERNATIONAL CONFERENCE OF THE CHILEAN COMPUTER SCIENCE SOCIETY, V0, P73
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Clark A, 2007, J MACH LEARN RES, V8, P1725
   Clark A, 2010, LECT NOTES ARTIF INT, V6339, P24, DOI 10.1007/978-3-642-15488-1_4
   Cleeremans A, 1989, NEURAL COMPUT, V1, P372, DOI 10.1162/neco.1989.1.3.372
   Cohen M, 2017, INDUCING REGULAR GRA, V0, P0
   DUlizia A, 2011, ARTIF INTELL REV, V36, P1, DOI 10.1007/s10462-010-9199-1
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769
   Giles CL, 1990, ADV NEURAL INFORM PR, V0, P0
   Goldberg Y, 2017, NEURAL NETWORK METHO, V0, P0
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   GOLDMAN SA, 1995, J COMPUT SYST SCI, V50, P20, DOI 10.1006/jcss.1995.1003
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gorman K, 2016, T ASSOC COMPUT LING, V4, P507, DOI 10.1162/TACL_A_00114
   GOUDREAU MW, 1994, IEEE T NEURAL NETWOR, V5, P511, DOI 10.1109/72.286928
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hewitt J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P1978
   Isberner M, 2014, LECT NOTES COMPUT SC, V8734, P307, DOI 10.1007/978-3-319-11164-3_26
   Jacobsson H, 2005, NEURAL COMPUT, V17, P1223, DOI 10.1162/0899766053630350
   Karpathy A, 2015, IEEE T PATTERN ANAL, V0, P0, DOI DOI 10.1109/TPAMI.2016.2598339
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Lei T, 2016, ARXIV, V0, P0
   Li J, 2015, VISUALIZING UNDERSTA, V0, P0
   Linzen Tal, 2016, T ASS COMPUTATIONAL, V0, P0
   Mayr F, 2018, LECT NOTES COMPUT SC, V11015, P350, DOI 10.1007/978-3-319-99740-7_25
   Murdoch WJ, 2017, AUTOMATIC RULE EXTRA, V0, P0
   Okudono T, 2020, AAAI CONF ARTIF INTE, V34, P5306
   Omlin CW, 2000, KNOWLEDGE-BASED NEUROCOMPUTING, V0, P63
   Omlin CW, 1996, NEURAL NETWORKS, V9, P41, DOI 10.1016/0893-6080(95)00086-0
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   SAKAKIBARA Y, 1992, INFORM COMPUT, V97, P23, DOI 10.1016/0890-5401(92)90003-X
   Shi X, 2016, P 2016 C EMP METH NA, V0, PP1526, DOI 10.18653/V1/D16-1159
   Shibata C, 2016, THEOR COMPUT SCI, V620, P46, DOI 10.1016/j.tcs.2015.10.037
   Strobelt H, 2016, ARXIV160607461, V0, P0
   Suzgun M, 2019, DEEP LEARNING AND FORMAL LANGUAGES: BUILDING BRIDGES, V0, P44
   Tellier I, 2006, REVIEQ DINTELLIGENCE, V20, P775, DOI 10.3166/ria.20.775-804
   Tomita M, 1982, P 4 ANN C COGN SCI, V0, P0
   Wang CQ, 2019, PR MACH LEARN RES, V97, P0
   Wang Q, 2017, EMPIRICAL EVALUATION, V0, P0
   Wang Q, 2018, COMP RULE EXTRACTION, V0, P0
   Weiss G, 2019, ADV NEUR IN, V32, P0
   Weiss G, 2018, PR MACH LEARN RES, V80, P0
   Weiss G, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P740
   Yellin Daniel M, 2021, TOOLS AND ALGORITHMS FOR THE CONSTRUCTION AND ANALYSIS OF SYSTEMS. 27TH INTERNATIONAL CONFERENCE, V0, P0
   Yokomori T, 2003, THEOR COMPUT SCI, V298, P179, DOI 10.1016/S0304-3975(02)00423-1
   Yoshinaka R, 2016, DISTRIBUTIONAL LEARN, V0, PP143, DOI 10.1007/978-3-662-48395-4_6
   Yoshinaka R, 2019, J COMPUT SYST SCI, V104, P359, DOI 10.1016/j.jcss.2017.07.004
   ZENG Z, 1993, NEURAL COMPUT, V5, P976, DOI 10.1162/neco.1993.5.6.976
   Zhang XY, 2021, AAAI CONF ARTIF INTE, V35, P11699
NR 59
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1007/s10994-022-06163-2
EA JUN 2022
PG 43
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1Y2DW
UT WOS:000807954400001
DA 2023-11-10
ER

PT J
AU Imran, AS
   Yang, R
   Kastrati, Z
   Daudpota, SM
   Shaikh, S
AF Imran, Ali Shariq
   Yang, Ru
   Kastrati, Zenun
   Daudpota, Sher Muhammad
   Shaikh, Sarang
TI The impact of synthetic text generation for sentiment analysis using GAN based models
SO EGYPTIAN INFORMATICS JOURNAL
LA English
DT Article
DE Text generation; Sentiment analysis; SentiGAN; CatGAN; Deep learning; Language modeling; Machine learning; GANs; Generative adversarial networks; Data imbalance
AB Data imbalance in datasets is a common issue where the number of instances in one or more categories far exceeds the others, so is the case with the educational domain. Collecting feedback on a course on a large scale and the lack of publicly available datasets in this domain limits models' performance, espe-cially for deep neural network based models which are data hungry. A model trained on such an imbal-anced dataset would naturally favor the majority class. However, the minority class could be critical for decision-making in prediction systems, and therefore it is usually desirable to train a model with equally high class-level accuracy. This paper addresses the data imbalance issue for the sentiment analysis of users' opinions task on two educational feedback datasets utilizing synthetic text generation deep learn-ing models. Two state-of-the-art text generation GAN models namely CatGAN and SentiGAN, are employed for synthesizing text used to balance the highly imbalanced datasets in this study. Particular emphasis is given to the diversity of synthetically generated samples for populating minority classes. Experimental results on highly imbalanced datasets show significant improvement in models' perfor-mance on CR23K and CR100K after balancing with synthetic data for the sentiment classification task.(c) 2022 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artificial Intel-ligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creative-commons.org/licenses/by-nc-nd/4.0/).
C1 [Imran, Ali Shariq; Yang, Ru] Norwegian Univ Sci & Technol NTNU, Dept Comp Sci IDI, N-2815 Gjovik, Norway.
   [Kastrati, Zenun] Linnaeus Univ, Dept Informat, S-35195 Vaxjo, Sweden.
   [Daudpota, Sher Muhammad] Sukkur IBA Univ, Dept Comp Sci, Sukkur 65200, Pakistan.
   [Shaikh, Sarang] Norwegian Univ Sci & Technol NTNU, Dept Informat Secur & Commun Technol IIK, N-2815 Gjovik, Norway.
C3 Norwegian University of Science & Technology (NTNU); Linnaeus University; Sukkur IBA University; Norwegian University of Science & Technology (NTNU)
RP Imran, AS (通讯作者)，Norwegian Univ Sci & Technol NTNU, Dept Comp Sci IDI, N-2815 Gjovik, Norway.
EM ali.imran@ntnu.no; ru.yang@ntnu.no; zenun.kastrati@lnu.se; sher@iba-suk.edu.pk; sarang.shaikh@nutu.no
CR Estrada MLB, 2020, EXPERT SYST APPL, V150, P0, DOI 10.1016/j.eswa.2020.113265
   Che T, 2017, ARXIV, V0, P0
   Dinh-Hong Vu, 2021, RESEARCH IN INTELLIGENT AND COMPUTING IN ENGINEERING. SELECT PROCEEDINGS OF RICE 2020. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1254), V0, PP827, DOI 10.1007/978-981-15-7527-3_78
   Edalati M, 2021, LECT NOTES NETWORKS, V0, PP11, DOI 10.1007/978-3-030-82199-9_2
   Fatima N, 2022, IEEE ACCESS, V10, P53490, DOI 10.1109/ACCESS.2022.3174108
   Guo B, 2021, ACM T INTEL SYST TEC, V12, P0, DOI 10.1145/3439816
   Guo JX, 2018, AAAI CONF ARTIF INTE, V0, P5141
   Htar Htar Lwin, 2020, 2020 17TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, V0, P0
   Ibne Akhtar Nahid, 2021, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON TRENDS IN COMPUTATIONAL AND COGNITIVE ENGINEERING. PROCEEDINGS OF TCCE 2020. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1309), V0, PP103, DOI 10.1007/978-981-33-4673-4_9
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Kastrati Zenun, 2020, ICCAI 20: PROCEEDINGS OF THE 2020 6TH INTERNATIONAL CONFERENCE ON COMPUTING AND ARTIFICIAL INTELLIGENCE, V0, PP510, DOI 10.1145/3404555.3404633
   Kastrati Z, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10101133
   Kastrati Z, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11093986
   Kastrati Z, 2020, IEEE ACCESS, V8, P106799, DOI 10.1109/ACCESS.2020.3000739
   Katragadda S, 2020, INT CONF ADVAN COMPU, V0, PP1161, DOI 10.1109/ICACCS48705.2020.9074334
   Koufakou A, 2016, IEEE IJCNN, V0, PP3138, DOI 10.1109/IJCNN.2016.7727599
   Li L, 2021, INT CORE J ENG, V7, P525
   Li Zhongliang, 2019, 22 INT C ART INT STA, V0, P3089
   Lin KV, 2018, ARXIV, V0, P0
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P8425
   Logeswaran L, 2018, ADV NEUR IN, V31, P0
   Lu S, 2019, PR MACH LEARN RES, V0, P0
   Masum Abu Kaisar Mohammad, 2021, SOFT COMPUTING TECHNIQUES AND APPLICATIONS. PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION (IC3 2020). ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1248), V0, PP491, DOI 10.1007/978-981-15-7394-1_45
   Montahaei E, 2021, NEUROCOMPUTING, V448, P364, DOI 10.1016/j.neucom.2021.03.097
   Nadakuduti SS, 2021, FRONT PLANT SCI, V11, P0, DOI 10.3389/fpls.2020.637159
   Nie Weili, 2018, INT C LEARN REPR, V0, P0
   Nogueira CSD, 2014, P COLING 2014 25 INT, V0, PP69, DOI 10.1109/ICCAR.2017.7942788
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Rebuffel Clement, 2020, ADVANCES IN INFORMATION RETRIEVAL, V0, P0
   Sadriu Shpetim, 2022, PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE: 5TH MEDITERRANEAN CONFERENCE, V0, Proceedings. Communications in Computer and Information Science (1543)
   Shaikh S, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11020869
   Sindhu I, 2019, IEEE ACCESS, V7, P108729, DOI 10.1109/ACCESS.2019.2928872
   Socher Richard, 2013, P 2013 C EMPIRICAL M, V26, P0, DOI 10.1371/JOURNAL.PONE.0073791
   Song L, 2021, US PATENT APP., V0, Patent No. [16/883,475, 16883475]
   Vanaja S, 2018, 2018 INT C INV RES C, V0, P1275
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang K, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4446
   Xu J, 2018, DP GAN DIVERSITY PRO, V0, P0
   Xu JH, 2021, P 2021 IEEE 10 GLOB, V0, P963
   Yu L, 2017, AAAI C ARTIFICIAL IN, V490, P0
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
   Zhu YM, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1097, DOI 10.1145/3209978.3210080
NR 42
TC 7
Z9 7
U1 3
U2 14
PU CAIRO UNIV, FAC COMPUTERS & INFORMATION
PI GIZA GOVERNORATE
PA AHMED ZEWAIL, AD DOQI, GIZA GOVERNORATE, 00000, EGYPT
SN 1110-8665
EI 2090-4754
J9 EGYPT INFORM J
JI Egypt. Inform. J.
PD SEP 15
PY 2022
VL 23
IS 3
BP 547
EP 557
DI 10.1016/j.eij.2022.05.006
EA SEP 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering
SC Computer Science
GA 5C2EW
UT WOS:000864079800015
DA 2023-11-10
ER

PT J
AU Zhou, PF
   Ying, KN
   Wang, ZH
   Guo, DY
   Bai, C
AF Zhou, Pengfei
   Ying, Kaining
   Wang, Zhenhua
   Guo, Dongyan
   Bai, Cong
TI Self-Supervised Enhancement for Named Entity Disambiguation via Multimodal Graph Convolution
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Task analysis; Convolution; Semantics; Internet; Bit error rate; Visualization; Pipelines; Graph convolutional network (GCN); multimodal data; named entity disambiguation (NED); self-supervised learning (SSL)
AB Named entity disambiguation (NED) finds the specific meaning of an entity mention in a particular context and links it to a target entity. With the emergence of multimedia, the modalities of content on the Internet have become more diverse, which poses difficulties for traditional NED, and the vast amounts of information make it impossible to manually label every kind of ambiguous data to train a practical NED model. In response to this situation, we present MMGraph, which uses multimodal graph convolution to aggregate visual and contextual language information for accurate entity disambiguation for short texts, and a self-supervised simple triplet network (SimTri) that can learn useful representations in multimodal unlabeled data to enhance the effectiveness of NED models. We evaluated these approaches on a new dataset, MMFi, which contains multimodal supervised data and large amounts of unlabeled data. Our experiments confirm the state-of-the-art performance of MMGraph on two widely used benchmarks and MMFi. SimTri further improves the performance of NED methods. The dataset and code are available at https://github.com/LanceZPF/NNED_MMGraph.
C1 [Zhou, Pengfei; Ying, Kaining; Wang, Zhenhua; Guo, Dongyan; Bai, Cong] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
   [Zhou, Pengfei] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Zhou, Pengfei] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China.
C3 Zhejiang University of Technology; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Bai, C (通讯作者)，Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
EM zpf4wp@outlook.com; ykn@zjut.edu.cn; zhhwang@zjut.edu.cn; guodongyan@zjut.edu.cn; congbai@zjut.edu.cn
FU Zhejiang Provincial Natural Science Foundation of China [LR21F020002, LY21F020024, LY22F030015]; Natural Science Foundation of China [U20A20196]
CR Adjali Omar, 2020, ADVANCES IN INFORMATION RETRIEVAL, V0, P0
   [Anonymous], 2016, HLT NAACL, V0, P0, DOI DOI 10.18653/V1/N16-1150
   Bai C, 2021, DISPLAYS, V70, P0, DOI 10.1016/j.displa.2021.102069
   Blanco R, 2015, WSDM15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP179, DOI 10.1145/2684822.2685317
   Bromley J, 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Broscheit Samuel, 2019, P 23 C COMP NAT LANG, V0, PP677, DOI 10.18653/V1/K19-1063
   Che W, 2020, ARXIV200911616, V2009, P11616
   Chen T, 2020, BIG SELF SUPERVISED, V0, PP1, DOI 10.48550/ARXIV.2006.10029
   Chen T, 2020, PR MACH LEARN RES, V119, P0
   Chen XC, 2020, IEEE IJCNN, V0, P0, DOI DOI 10.1109/ijcnn48605.2020.9207010
   Chen XL, 2021, PROC CVPR IEEE, V0, PP15745, DOI 10.1109/CVPR46437.2021.01549
   Cheng J, 2019, PROC CHINA C KNOWL G, V0, P0
   Cucurull Guillem, 2018, INT C LEARN REPR, V0, P1
   Devlin J, 2018, ARXIV, V1, P4171
   Devon Hjelm R, 2019, ICLR, V0, P0
   Doersch C, 2017, IEEE I CONF COMP VIS, V0, PP2070, DOI 10.1109/ICCV.2017.226
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R, V0, P0
   Feng ZF, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), V0, P735
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Ganea Octavian-Eugen, 2017, P 2017 C EMP METH NA, V0, P2619
   Gori M, 2005, IEEE IJCNN, V0, P729
   Grill JB, 2020, BOOTSTRAP YOUR OWN L, V33, P21271
   Gutmann Michael, 2010, P 13 INT C ART INT S, V0, PP297, DOI 10.1145/3292500.3330651
   Hadsell Raia, 2006, 2006 IEEE COMPUTER S, V2, P1735
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He Kaiming, 2020, P IEEE CVF C COMP VI, V0, PP9729, DOI 10.1109/CVPR42600.2020.00975
   Huang H, 2015, ARXIV150407678, V0, P0
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, P2333
   Huang Y, 2021, ADV NEURAL INFORM PR, V0, P0
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Jing LL, 2022, INT J OCCUP SAF ERGO, V28, P842, DOI 10.1080/10803548.2020.1835234
   Kannan AV, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP3417, DOI 10.1145/3340531.3417439
   Kipf T N, 2016, ICLR, V0, P0
   Kolitsas N, 2018, P 22 C COMP NAT LANG, V0, PP519, DOI 10.18653/V1/K18-1050
   Korbar B, 2018, ADV NEUR IN, V31, P0
   Li B, 2021, IEEE INT SYMP CIRC S, V0, P0, DOI DOI 10.1109/ISCAS51556.2021.9401486
   Li CY, 2019, AAAI CONF ARTIF INTE, V0, P6666
   Liu X, 2020, SELF SUPERVISED LEAR, V0, P0
   Liu Y, 2019, LECT NOTES COMPUT SC, V11503, P459, DOI 10.1007/978-3-030-21348-0_30
   Maas AL, 2013, 30 INT C MACH LEARN, V0, PP3, DOI 10.1109/ICCV.2017.304
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, PP1, DOI 10.1162/153244303322533223
   Milne D, 2008, P INT C INFORM KNOWL, V0, PP509, DOI 10.1145/1458082.1458150
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Moon S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2000
   Mulang IO, 2020, CIKM 20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, V0, PP2157, DOI 10.1145/3340531.3412159
   Navigli R, 2009, ACM COMPUT SURV, V41, P0, DOI 10.1145/1459352.1459355
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Owens A, 2018, LECT NOTES COMPUT SC, V11210, P639, DOI 10.1007/978-3-030-01231-1_39
   Pathak D, 2016, PROC CVPR IEEE, V0, PP2536, DOI 10.1109/CVPR.2016.278
   Patrick M, 1900, P2020, V0, P0
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Le P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1595
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Radhakrishnan P, 2018, P 2018 C N AM CHAPT, V1, P1844, DOI 10.18653/V1/N18
   Rasiwasia N, 2010, P 18 ACM INT C MULT, V0, PP251, DOI 10.1145/1873951.1873987
   Rizzo G, 2017, SEMANT WEB, V8, P667, DOI 10.3233/SW-170276
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sevgili Ö, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, V0, P315
   Shahbazi H, 2018, P INT C COMP LING, V0, P2170
   Shen W, 2015, IEEE T KNOWL DATA EN, V27, P443, DOI 10.1109/TKDE.2014.2327028
   Strube M, 2006, P AAAI, V0, P1419
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P5027
   Sun Maosong, 2016, THULAC EFFICIENT LEX, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wei DL, 2018, PROC CVPR IEEE, V0, PP8052, DOI 10.1109/CVPR.2018.00840
   Xu B, 2017, LECT NOTES ARTIF INT, V10351, P428, DOI 10.1007/978-3-319-60045-1_44
   Xu DJ, 2019, PROC CVPR IEEE, V0, PP10326, DOI 10.1109/CVPR.2019.01058
   Yamada I, 2017, T ASS COMPUTATIONAL, V5, P397, DOI 10.1162/TACL_A_00069
   Yao FL, 2023, IEEE T NEUR NET LEAR, V34, P228, DOI 10.1109/TNNLS.2021.3093416
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Zhang R, 2017, PROC CVPR IEEE, V0, PP645, DOI 10.1109/CVPR.2017.76
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhen LL, 2022, IEEE T NEUR NET LEAR, V33, P798, DOI 10.1109/TNNLS.2020.3029181
   Zhou L, 2003, J AM SOC INF SCI TEC, V54, P115, DOI 10.1002/asi.10193
   Zhou PF, 2022, IEEE INTERNET THINGS, V9, P6335, DOI 10.1109/JIOT.2020.2996009
   Zhou RW, 2020, IEEE T NEUR NET LEAR, V31, P1592, DOI 10.1109/TNNLS.2019.2920905
NR 79
TC 0
Z9 0
U1 14
U2 31
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1109/TNNLS.2022.3173179
EA MAY 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 1K1HM
UT WOS:000798360300001
PM 35560079
DA 2023-11-10
ER

PT J
AU Yang, YX
   Guo, ZX
   He, ZF
AF Yang, Yaxu
   Guo, Zixue
   He, Zefang
TI Multi-attribute decision making method based on probabilistic linguistic term sets and its application in the evaluation of emergency logistics capacity
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Emergency logistics capacity; probabilistic linguistic term sets; quality function deployment (QFD)
AB The occurrence of public health emergency will cause huge economic losses and casualties, which posed a huge threat to the economic and social development. In response to the emergency, a large amount of emergency relief supplies will be transported to the affected areas. Faced with this public health emergency of international concern, the concept of emergency logistics capacity and the evaluation model based on probabilistic linguistic term sets are proposed. In this paper, the emergency logistics capability evaluation is transformed into user demand evaluation, and the importance of each index of emergency logistics capability is determined by using Quality Function Deployment (QFD) and prospect theory. Under the probabilistic language information environment, a multi-attribute decision making method is established by using TODIM method. Finally, an example is given to verify the feasibility of the proposed method.
C1 [Yang, Yaxu; Guo, Zixue] Hebei Univ, Sch Management, Baoding, Peoples R China.
   [He, Zefang] Beijing Wuzi Univ, Sch Informat, Beijing, Peoples R China.
C3 Hebei University; Beijing Wuzi University
RP Guo, ZX (通讯作者)，Hebei Univ, Sch Management, Baoding, Peoples R China.
EM guo_zx@163.com
FU National Social Science Foundation of China [20BTJ012]; Social Science Foundation of Hebei province of China [HB18GL008]; Beijing Intelligent Logistics System Collaborative Innovation Center [BILSCIC-2019KF-15]; Philosophy and Social Science key cultivation project of Hebei University [2019HPY035]
CR AIKENS CH, 1985, EUR J OPER RES, V22, P263, DOI 10.1016/0377-2217(85)90246-2
   Carter WN, 1992, DISAS MANAGE, V0, P5
   Gou XJ, 2016, INFORM SCIENCES, V372, P407, DOI 10.1016/j.ins.2016.08.034
   Guo ZX, 2019, J INTELL FUZZY SYST, V37, P5351, DOI 10.3233/JIFS-190509
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Ken B, 1984, DISASTER, V8, P57
   Li J, 2007, J LANZHOU JIAOTONG U, V26, P64
   Lin MW, 2019, NONLINEAR DYNAM, V96, P2125, DOI 10.1007/s11071-019-04910-0
   Liu PD, 2019, COMPUT IND ENG, V131, P282, DOI 10.1016/j.cie.2019.04.004
   [刘小群 Liu Xiaoqun], 2007, 灾害学 JOURNAL OF CATASTROPHOLOGY, V22, P123
   Luo SZ, 2019, J OPER RES SOC, V70, P2039, DOI 10.1080/01605682.2018.1510806
   Ma X, 2017, LOGISTICS TECHNOLOGY, V08, P87
   Mingke He, 2003, CHINA LOGIST PURCH, V23, P18
   Mo HM, 2020, SYMMETRY-BASEL, V12, P0, DOI 10.3390/sym12030380
   Mo HM, 2018, INT J FUZZY SYST, V20, P2458, DOI 10.1007/s40815-018-0514-3
   [欧忠文 Ou Zhongwen], 2004, 重庆大学学报 JOURNAL OF CHONGQING UNIVERSITY, V27, P164
   Pang Q, 2016, INFORM SCIENCES, V369, P128, DOI 10.1016/j.ins.2016.06.021
   Rodríguez RM, 2012, IEEE T FUZZY SYST, V20, P109, DOI 10.1109/TFUZZ.2011.2170076
   Sun H, 2010, CHINA SAFETY SCI J, V20, P166
   Sun Jun, 2014, JOURNAL OF BEIJING UNIVERSITY OF TECHNOLOGY, V40, P1354
   Torra V, 2010, INT J INTELL SYST, V25, P529, DOI 10.1002/int.20418
   Tufekci S, 1998, IEEE T ENG MANAGE, V45, P103, DOI 10.1109/TEM.1998.669742
   Vinodh S, 2010, J CLEAN PROD, V18, P833, DOI 10.1016/j.jclepro.2009.12.024
   Wang XK, 2019, EXPERT SYST, V36, P0, DOI 10.1111/exsy.12352
   Wu XL, 2019, EUR J OPER RES, V272, P1017, DOI 10.1016/j.ejor.2018.07.044
   Xu ZS, 2017, SOFT COMPUTING APPL, V357, P411, DOI 10.1007/978-3-319-60207-3_24
   Yao G, 2012, COMMERCIAL TIMES, V23, P44
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang YX, 2016, APPL SOFT COMPUT, V49, P817, DOI 10.1016/j.asoc.2016.08.045
NR 30
TC 2
Z9 2
U1 21
U2 72
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PD JUN 15
PY 2022
VL 42
IS 3
BP 2157
EP 2168
DI 10.3233/JIFS-211495
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA YV6PO
UT WOS:000752849700058
DA 2023-11-10
ER

PT J
AU Xu, F
   Dan, YJ
   Yan, KY
   Ma, Y
   Wang, MW
AF Xu, Fan
   Dan, Yangjie
   Yan, Keyu
   Ma, Yong
   Wang, Mingwen
TI Low-Resource Language Discrimination toward Chinese Dialects with Transfer Learning and Data Augmentation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Low-resource; chinese dialects; dialects discrimination; transfer learning; data augmentation
AB Chinese dialects discrimination is a challenging natural language processing task due to scarce annotation resource. In this article, we develop a novel Chinese dialects discrimination framework with transfer learning and data augmentation (CDDTLDA) in order to overcome the shortage of resources. To be more specific, we first use a relatively larger Chinese dialects corpus to train a source-side automatic speech recognition (ASR) model. Then, we adopt a simple but effective data augmentation method (i.e., speed, pitch, and noise disturbance) to augment the target-side low-resource Chinese dialects, and fine-tune another target ASR model based on the previous source-side ASR model. Meanwhile, the potential common semantic features between source-side and target-side ASR models can be captured by using self-attention mechanism. Finally, we extract the hidden semantic representation in the target ASR model to conduct Chinese dialects discrimination. Our extensive experimental results demonstrate that our model significantly outperforms state-of-the-art methods on two benchmark Chinese dialects corpora.
C1 [Xu, Fan; Dan, Yangjie; Yan, Keyu; Ma, Yong; Wang, Mingwen] Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
C3 Jiangxi Normal University
RP Wang, MW (通讯作者)，Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
EM xufan@jxnu.edu.cn; 2314872656@qq.com; 156183394@qq.com; 1259993675@qq.com; mwwang@jxnu.edu.cn
FU National Natural Science Foundation of China (NSFC) [61772246, 62162031, 62066020, 61876074]; Natural Science Foundation of Jiangxi Province [20192ACBL21030, 20192AE191005]
CR [Anonymous], 2006, J QUANT LINGUIST, V0, P0, DOI DOI 10.1080/09296170500500694
   [Anonymous], 2013, P 51 ANN M ASS COMPU, V0, P0
   [Anonymous], 2016, P 3 WORKSH NLP SIM L, V0, P0
   [Anonymous], 2014, P 1 WORKSH APPL NLP, V0, P0, DOI DOI 10.3115/V1/W14-5316
   Dai W, 2007, P 24 INT C MACH LEAR, V0, PP193, DOI 10.1145/1273496.1273521
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dehak N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P864
   Dras M, 2015, P PAC ASS COMP LING, V0, P53
   Etienne Caroline, 2018, P WORKSH SPEECH MUS, V0, P0
   Gomez-Adorno H, 2017, P 4 WORKSH NLP SIM L, V0, P137
   GREFENSTETTE G, 1995, P 3 INT C STAT AN TE, V0, P0
   IFLYTEK, 2018, RANK LIST IFLYTEK WO, V0, P0
   IFLYTEK, 2018, IFLYTEK WORLD WID CO, V0, P0
   Jauhiainen T, 2019, J ARTIF INTELL RES, V65, P675
   Jia Y, 2018, ADV NEUR IN, V31, P0
   Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3
   Ljubesic N, 2015, INFORM-J COMPUT INFO, V39, P1
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park DS, 2019, INTERSPEECH, V0, PP2613, DOI 10.21437/Interspeech.2019-2680
   Ren Yi, 2019, P 36 INT C MACH LEAR, V0, P0
   Sgouropoulos Dimitris, 2019, P C INT SPEECH COMM, V0, P0
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Simoes A, 2014, P 3 S LANG APPL TECH, V0, PP251, DOI 10.4230/OASICS.SLATE.2014.251
   Snyder David, 2018, P OD 2018 SPEAK LANG, V0, P0
   Su JS, 2021, IEEE T PATTERN ANAL, V43, P1530, DOI 10.1109/TPAMI.2019.2954406
   Tiedemann Jorg, 2012, P INT C COMP LING, V0, P0
   Wang Y, 2018, P INT C MACH LEARN, V0, P5123
   Wu N, 2019, P 6 WORKSH NLP SIM L, V0, PP54, DOI 10.18653/V1/W19-1406
   Xu F, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3389021
   Xu Fan, 2015, P JOINT WORKSH LANG, V0, P85
   Xu Fan, 2018, P 11 INT C LANG RES, V0, P0
   Zampieri M, 2017, VARDIAL, V2017, P1, DOI 10.18653/v1/W17-1201
   Zampieri M, 2019, P 6 WORKSH NLP SIM L, V0, PP1, DOI 10.18653/V1/W19-1401
   Zeng JL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P447
   Zeng JL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P845
   Zhang B, 2019, IEEE-ACM T AUDIO SPE, V27, P2278, DOI 10.1109/TASLP.2019.2946480
NR 37
TC 0
Z9 0
U1 3
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD MAR 15
PY 2022
VL 21
IS 2
BP 
EP 
DI 10.1145/3473499
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 0C7CH
UT WOS:000775466500006
DA 2023-11-10
ER

PT J
AU Yan, M
   Yang, JX
   Chen, C
   Zhou, JT
   Pan, Y
   Zeng, Z
AF Yan, Ming
   Yang, Jianxi
   Chen, Cen
   Zhou, Joey Tianyi
   Pan, Yi
   Zeng, Zeng
TI Enhanced gradient learning for deep neural networks
SO IET IMAGE PROCESSING
LA English
DT Article
AB Deep neural networks have achieved great success in both computer vision and natural language processing tasks. How to improve the gradient flows is crucial in training very deep neural networks. To address this challenge, a gradient enhancement approach is proposed through constructing the short circuit neural connections. The proposed short circuit is a unidirectional neural connection that back propagates the sensitivities rather than gradients in neural networks from the deep layers to the shallow layers. Moreover, the short circuit is further formulated as a gradient truncation operation in its connecting layers, which can be plugged into the backbone models without introducing extra training parameters. Extensive experiments demonstrate that the deep neural networks, with the help of short circuit connection, gain a large margin of improvement over the baselines on both computer vision and natural language processing tasks. The work provides the promising solution to the low-resource scenarios, such as, intelligence transport systems of computer vision, question answering of natural language processing.
C1 [Yang, Jianxi] Chongqing Jiaotong Univ, AI Res Ctr, Sch Informat Sci & Engn, Chongqing, Peoples R China.
   [Yan, Ming; Zhou, Joey Tianyi] Age Sci Technol & Res, Inst High Performance Comp, Singapore, Singapore.
   [Chen, Cen; Zeng, Zeng] Agcy Sci Technol & Res, Inst Infocomm Res, Singapore, Singapore.
   [Pan, Yi] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
C3 Chongqing Jiaotong University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS
RP Yang, JX (通讯作者)，Chongqing Jiaotong Univ, AI Res Ctr, Sch Informat Sci & Engn, Chongqing, Peoples R China.
EM yjx@cqjtu.edu.cn
FU ShenzhenKQTDProject [KQTD20200820113106007]; Science andTechnologyResearch Program of ChongqingMunicipal EducationCommission of China [KJZD-M202000702]
CR Amari S, 2000, NEURAL COMPUT, V12, P1399, DOI 10.1162/089976600300015420
   [Anonymous], 2010, P 13 INT C ART INT S, V0, P0
   [Anonymous], 2020, P 2020 IEEE CVF C CO, V0, P0
   [Anonymous], 2018, P 56 ANN M ASS COMP, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2019, P 2019 C N AM CHAPT, V0, P0
   [Anonymous], 2016, RESIDUAL NETWORKS BE, V0, P0
   Britz D, 2017, P 2017 C EMP METH NA, V0, PP1442, DOI 10.18653/v1/D17-1151
   Castillo E, 2004, TECHNOMETRICS, V46, P430, DOI 10.1198/004017004000000509
   Castillo E, 2006, J MACH LEARN RES, V7, P1159
   Chen DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2358
   Cho Kyunghyun, 2014, EMNLP 2014 2014 C EM, V0, P0, DOI DOI 10.3115/V1
   Devlin J, 2018, ARXIV, V1, P4171
   Dey R, 2017, MIDWEST SYMP CIRCUIT, V0, PP1597, DOI 10.1109/MWSCAS.2017.8053243
   Dhingra B, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1832, DOI 10.18653/v1/P17-1168
   FUNAHASHI K, 1993, NEURAL NETWORKS, V6, P801, DOI 10.1016/S0893-6080(05)80125-X
   Glorot Xavier, 2011, P 14 INT C ART INT S, V0, PP315, DOI 10.1002/ECS2.1832
   Gruber N, 2020, FRONT ARTIF INTELL, V3, P0, DOI 10.3389/frai.2020.00040
   He K, 2015, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, PROC CVPR IEEE, V0, PP5353, DOI 10.1109/CVPR.2015.7299173
   Hong GZ, 2021, PROC CVPR IEEE, V0, PP12070, DOI 10.1109/CVPR46437.2021.01190
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jin D, 2019, MMM MULTI STAGE MULT, V0, P0
   Kolesnikov Alexander, 2020, EUR C COMP VIS ECCV, V0, P0
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V0, P0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Maas AL, 2013, 30 INT C MACH LEARN, V0, PP3, DOI 10.1109/ICCV.2017.304
   Merkhofer E, 2018, SEMEVAL, V0, P1078
   Mozer MC, 1995, BACKPROPAGATION THEO, V0, P137
   Nedic A, 2020, IEEE SIGNAL PROC MAG, V37, P92, DOI 10.1109/MSP.2020.2975210
   Perez E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P2402
   Real E, 2019, AAAI CONF ARTIF INTE, V0, P4780
   Srivastava RK, 2015, ADV NEUR IN, V28, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Wang L, 2018, P 12 INT WORKSHOP SE, V0, PP758, DOI 10.18653/v1/S18-1120
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xia JN, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM 19), V0, PP2393, DOI 10.1145/3357384.3358165
   Yan Ming, 2020, P 58 ANN M ASS COMPU, V0, P7331
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   ZahediNasab R, 2020, NEUROCOMPUTING, V381, P306, DOI 10.1016/j.neucom.2019.11.090
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu C, 2019, P INT C LEARN REPR, V0, P0
NR 44
TC 0
Z9 0
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9659
EI 1751-9667
J9 IET IMAGE PROCESS
JI IET Image Process.
PD FEB 15
PY 2022
VL 16
IS 2
BP 365
EP 377
DI 10.1049/ipr2.12353
EA NOV 2021
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA YB1FC
UT WOS:000715891500001
DA 2023-11-10
ER

PT J
AU Flores, AM
   Pavan, MC
   Paraboni, I
AF Flores, Arthur Marcal
   Pavan, Matheus Camasmie
   Paraboni, Ivandre
TI User profiling and satisfaction inference in public information access services
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
LA English
DT Article
DE Natural language processing; Text classification; Information access; E-government
ID customer satisfaction; personality
AB Public information access services are provided by dozens of countries around the world as a means to promote transparency and democracy, and present a number of research opportunities for the development of computational models that help understand both users and their needs. Based on these observations, the present work discusses how the use of Natural Language Processing (NLP) methods may harvest valuable knowledge about citizen-government communication in user profiling and satisfaction inference tasks. More specifically, from a large text dataset of this kind, we build a number of models using a range of supervised machine learning methods - including bidirectional long short-term memory networks (LSTMs), pre-trained context-sensitive embeddings (BERT) and others - and show that these outperform textual and non-textual baseline alternatives alike. This outcome makes a case in favour of NLP methods for these tasks, and paves the way for further applications in the public information access domain.
C1 [Flores, Arthur Marcal; Pavan, Matheus Camasmie; Paraboni, Ivandre] Univ Sao Paulo, Av Arlindo Bettio 1000, Sao Paulo, Brazil.
C3 Universidade de Sao Paulo
RP Paraboni, I (通讯作者)，Univ Sao Paulo, Av Arlindo Bettio 1000, Sao Paulo, Brazil.
EM arthurmarcal@gmail.com; matheus.pavan@usp.br; ivandre@usp.br
FU University of Sao Paulo PRP [668/2018]
CR Alvarez-Carmona M, 2015, CLEF 2015, V0, P9
   Ando A, 2020, IEEE-ACM T AUDIO SPE, V28, P715, DOI 10.1109/TASLP.2020.2966857
   [Anonymous], 2014, LEXILE FRAMEWORK APP, V0, P0
   [Anonymous], 2009, P 18 ACM C INFORM KN, V0, P0
   Auguste J, 2019, INT CONF ACOUST SPEE, V0, PP7385, DOI 10.1109/ICASSP.2019.8683896
   Balage Filho PP, 2013, P 9 BRAZ S INF HUM L, V0, P215
   Basile A, 2017, WORKING NOTES CLEF 2, V0, P0
   Berka P, 2020, J INTELL INF SYST, V55, P51, DOI 10.1007/s10844-019-00591-8
   Clifton-Sprigg J, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0228392
   Custodio JE, 2018, WORKING NOTES PAPERS, V2125, P7
   De Rango F, 2019, IEEE ACM DIS SIM, V0, PP251, DOI 10.1109/ds-rt47707.2019.8958692
   de Sousa RF, 2020, ISYS BRAZILIAN J INF, V13, P06, DOI 10.5753/isys.2020.821
   dos Santos VG, 2017, LECT NOTES ARTIF INT, V10415, P29, DOI 10.1007/978-3-319-64206-2_4
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, V0, PP211, DOI 10.1145/3172944.3172961
   Felix N, 2020, THESIS U FEDERAL GOI, V0, P0, DOI DOI 10.13140/RG.2.2.34738.96961
   Flekova L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P313
   Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532
   Gallagher C, 2019, INT J DATA WAREHOUS, V15, P21, DOI 10.4018/IJDWM.2019100102
   GOLDBERG LR, 1990, J PERS SOC PSYCHOL, V59, P1216, DOI 10.1037/0022-3514.59.6.1216
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Hartmann, 2017, ARXIV170806025, V0, P0
   Higashinaka Ryuichiro, 2010, P SIGDIAL 2010 C, V0, P18
   Hsieh FC, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P2566
   Isbister T, 2017, EUR INTELL SECUR INF, V0, PP54, DOI 10.1109/EISIC.2017.16
   Kim S, 2017, LECT NOTES COMPUT SC, V10624, P471, DOI 10.1007/978-3-319-70694-8_17
   Kumar S, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0224-1
   Liu F, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P754
   Liu Y, 2008, PROC 31 ANN INT ACM, V0, PP483, DOI 10.1145/1390334.1390417
   López-Santillán R, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2020.102227
   McLean G, 2017, COMPUT HUM BEHAV, V76, P494, DOI 10.1016/j.chb.2017.08.005
   McNamara DS, 2014, AUTOMATED EVALUATION OF TEXT AND DISCOURSE WITH COH-METRIX, V0, P1
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mikolov T, 2017, SHORT PAPERS, V0, PP427, DOI 10.18653/v1/e17
   Mikolov T, 2013, P 2013 C N AM CHAPT, V0, P0
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P1
   Myers IB, 1980, GIFTS DIFFERING, V0, P0
   Nguyen D, 2014, P COLING 2014 25 INT, V0, P1950
   Pardo FMR, 2017, WORKING NOTES CLEF 2, V0, P26
   Park K, 2015, 24 ACM INT C INFORM, V0, PP1879, DOI 10.1145/2806416.2806621
   Pennebaker JW, 2001, INQUIRY WORD COUNT L, V0, P0
   Pennington Jeffrey, 2014, P 2014 C EMP METH NA, V0, P0, DOI DOI 10.3115/V1/D14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, PP1499, DOI 10.5771/9783845286846
   Pizarro J, 2019, NOTEBOOK PAPERS, V0, P10
   Polignano M, 2020, LECT NOTES COMPUT SC, V12252, P135, DOI 10.1007/978-3-030-58811-3_10
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Price S, 2020, WORKING NOTES CLEF 2, V0, P0
   Rangel F, 2015, CLEF 2015 EV LABS WO, V0, P8
   Rangel F, 2018, WORKING NOTES PAPERS, V0, P38
   Rangel F, 2020, NAT LANG ENG, V26, P641, DOI 10.1017/S1351324920000108
   Scarton CE, 2010, LINGUAMATICA, V2, P45
   Silva B, 2018, IEEE LAT AM T, V16, P1256, DOI 10.1109/TLA.2018.8362165
   Singh LG, 2021, J INTELL INF SYST, V56, P379, DOI 10.1007/s10844-020-00616-7
   Song KS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P198
   Souza F, 2019, ARXIV190910649, V0, P0
   Takahashi T, 2018, WORKING NOTES PAPERS, V2125, P12
   Tang DY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P1340
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Verhoeven B, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1632
   Vidales Gonzáles Carlos, 2015, COMUN. SOC, V0, P11
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yom-Tov GB, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP1689, DOI 10.1145/3184558.3191628
   Zeng Z, 2018, J INFORM PROCESSING, V26, P768, DOI 10.2197/ipsjjip.26.768
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1253
NR 63
TC 4
Z9 4
U1 7
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0925-9902
EI 1573-7675
J9 J INTELL INF SYST
JI J. Intell. Inf. Syst.
PD FEB 15
PY 2022
VL 58
IS 1
BP 67
EP 89
DI 10.1007/s10844-021-00661-w
EA AUG 2021
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA YX6LS
UT WOS:000681148300001
DA 2023-11-10
ER

PT J
AU Kim, DJ
   Oh, TH
   Choi, J
   Kweon, IS
AF Kim, Dong-Jin
   Oh, Tae-Hyun
   Choi, Jinsoo
   Kweon, In So
TI Dense Relational Image Captioning via Multi-Task Triple-Stream Networks
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Task analysis; Visualization; Proposals; Dogs; Motorcycles; Natural languages; Genomics; Dense captioning; image captioning; visual relationship; relational analysis; scene graph
AB We introduce dense relational captioning, a novel image captioning task which aims to generate multiple captions with respect to relational information between objects in a visual scene. Relational captioning provides explicit descriptions for each relationship between object combinations. This framework is advantageous in both diversity and amount of information, leading to a comprehensive image understanding based on relationships, e.g., relational proposal generation. For relational understanding between objects, the part-of-speech (POS; i.e., subject-object-predicate categories) can be a valuable prior information to guide the causal sequence of words in a caption. We enforce our framework to learn not only to generate captions but also to understand the POS of each word. To this end, we propose the multi-task triple-stream network (MTTSNet) which consists of three recurrent units responsible for each POS which is trained by jointly predicting the correct captions and POS for each word. In addition, we found that the performance of MTTSNet can be improved by modulating the object embeddings with an explicit relational module. We demonstrate that our proposed model can generate more diverse and richer captions, via extensive experimental analysis on large scale datasets and several metrics. Then, we present applications of our framework to holistic image captioning, scene graph generation, and retrieval tasks.
C1 [Kim, Dong-Jin; Choi, Jinsoo; Kweon, In So] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
   [Oh, Tae-Hyun] Pohang Univ Sci & Technol, Dept Elect Engn, Pohang 37673, South Korea.
   [Oh, Tae-Hyun] Pohang Univ Sci & Technol, Grad Sch AI GSAI, Pohang 37673, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Pohang University of Science & Technology (POSTECH); Pohang University of Science & Technology (POSTECH)
RP Kweon, IS (通讯作者)，Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.; Oh, TH (通讯作者)，Pohang Univ Sci & Technol, Dept Elect Engn, Pohang 37673, South Korea.; Oh, TH (通讯作者)，Pohang Univ Sci & Technol, Grad Sch AI GSAI, Pohang 37673, South Korea.
EM djnjusa@kaist.ac.kr; taehyun@postech.ac.kr; jinsc37@kaist.ac.kr; iskweon77@kaist.ac.kr
FU Institute for Information & Communications Technology Promotion (IITP) - Korea Government [2017-0-01772]; IITP grants - Korea Government [2019-0-01906]; Artificial Intelligence Graduate School Program [2021-0-02068]; Artificial Intelligence Innovation Hub
CR Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Andreas J, 2016, PROC CVPR IEEE, V0, PP39, DOI 10.1109/CVPR.2016.12
   Chao YW, 2018, IEEE WINT CONF APPL, V0, PP381, DOI 10.1109/WACV.2018.00048
   Chen FH, 2018, PROC CVPR IEEE, V0, PP1345, DOI 10.1109/CVPR.2018.00146
   Chen Gao, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12357), V0, PP696, DOI 10.1007/978-3-030-58610-2_41
   Cho JW, 2021, IEEE COMPUT SOC CONF, V0, PP1592, DOI 10.1109/CVPRW53098.2021.00175
   Dai B, 2017, ADV NEUR IN, V30, P0
   Dai B, 2017, IEEE I CONF COMP VIS, V0, PP2989, DOI 10.1109/ICCV.2017.323
   Dai B, 2017, PROC CVPR IEEE, V0, PP3298, DOI 10.1109/CVPR.2017.352
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, V0, PP376, DOI 10.3115/V1/W14-3348
   Donahue J, 2015, PROC CVPR IEEE, V0, PP2625, DOI 10.1109/CVPR.2015.7298878
   Dong-Jin Kim, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12366), V0, PP718, DOI 10.1007/978-3-030-58589-1_43
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2018, PROC CVPR IEEE, V0, PP8359, DOI 10.1109/CVPR.2018.00872
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1162/neco.1997.9.8.1735
   Gu JX, 2019, PROC CVPR IEEE, V0, PP1969, DOI 10.1109/CVPR.2019.00207
   Gupta N, 2020, ICLR, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, V0, PP3588, DOI 10.1109/CVPR.2018.00378
   Hu RH, 2018, LECT NOTES COMPUT SC, V11211, P55, DOI 10.1007/978-3-030-01234-2_4
   Hu RH, 2017, IEEE I CONF COMP VIS, V0, PP804, DOI 10.1109/ICCV.2017.93
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Johnson J, 2017, IEEE I CONF COMP VIS, V0, PP3008, DOI 10.1109/ICCV.2017.325
   Johnson J, 2016, PROC CVPR IEEE, V0, PP4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, V0, PP3128, DOI 10.1109/CVPR.2015.7298932
   Kim D-J, 2019, P C EMPIRICAL METHOD, V0, P2012
   Kim DJ, 2021, IEEE T IMAGE PROCESS, V30, P9150, DOI 10.1109/TIP.2021.3113563
   Kim DJ, 2019, PROC CVPR IEEE, V0, PP6264, DOI 10.1109/CVPR.2019.00643
   Kim DJ, 2018, IEEE WINT CONF APPL, V0, PP1699, DOI 10.1109/WACV.2018.00189
   Kim JH, 2017, ARXIV, V0, P0
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Kottur S, 2018, LECT NOTES COMPUT SC, V11219, P160, DOI 10.1007/978-3-030-01267-0_10
   Krause J, 2017, PROC CVPR IEEE, V0, PP3337, DOI 10.1109/CVPR.2017.356
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Land MF, 2002, NEUROCASE, V8, P80, DOI 10.1093/neucas/8.1.80
   Li Y, 2017, PROC IEEE C COMPUT V, V0, P0
   Li YK, 2018, LECT NOTES COMPUT SC, V11205, P346, DOI 10.1007/978-3-030-01246-5_21
   Li YK, 2017, IEEE I CONF COMP VIS, V0, PP1270, DOI 10.1109/ICCV.2017.142
   Li YL, 2019, PROC CVPR IEEE, V0, PP3580, DOI 10.1109/CVPR.2019.00370
   Liang XD, 2017, PROC CVPR IEEE, V0, PP4408, DOI 10.1109/CVPR.2017.469
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu DQ, 2019, IEEE I CONF COMP VIS, V0, PP4672, DOI 10.1109/ICCV.2019.00477
   Loper E, 2002, P ACL 02 WORKSHOP EF, V1, P63, DOI 10.3115/1118108.1118117
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JS, 2017, PROC CVPR IEEE, V0, PP3242, DOI 10.1109/CVPR.2017.345
   Mottaghi R, 2014, PROC CVPR IEEE, V0, PP891, DOI 10.1109/CVPR.2014.119
   Nair V, 2010, P 27 INT C MACHINE L, V0, P0
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Ordonez Vicente, 2011, ADV NEURAL INFORM PR, V24, P5
   Peyre J, 2017, IEEE I CONF COMP VIS, V0, PP5189, DOI 10.1109/ICCV.2017.554
   Plummer BA, 2017, IEEE I CONF COMP VIS, V0, PP1946, DOI 10.1109/ICCV.2017.213
   Qi MS, 2019, PROC CVPR IEEE, V0, PP3952, DOI 10.1109/CVPR.2019.00408
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghi MA, 2011, PROC CVPR IEEE, V0, PP1745, DOI 10.1109/CVPR.2011.5995711
   Shetty R, 2017, IEEE I CONF COMP VIS, V0, PP4155, DOI 10.1109/ICCV.2017.445
   Simonyan K, 2015, INT C LEARN REPR ICL, V0, P730
   Soomro K, 2012, ARXIV, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan GC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P745
   Tian JJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3576
   Venugopalan S, 2017, PROC CVPR IEEE, V0, PP1170, DOI 10.1109/CVPR.2017.130
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Wang LW, 2017, ADV NEUR IN, V30, P0
   Wang WB, 2019, PROC CVPR IEEE, V0, PP8180, DOI 10.1109/CVPR.2019.00838
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Woo S, 2018, ADV NEUR IN, V31, P0
   Xu DF, 2017, PROC CVPR IEEE, V0, PP3097, DOI 10.1109/CVPR.2017.330
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yang LJ, 2017, PROC CVPR IEEE, V0, PP1978, DOI 10.1109/CVPR.2017.214
   Yang X, 2018, LECT NOTES COMPUT SC, V11216, P38, DOI 10.1007/978-3-030-01258-8_3
   Yang X, 2019, IEEE I CONF COMP VIS, V0, PP4249, DOI 10.1109/ICCV.2019.00435
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yin GJ, 2018, LECT NOTES COMPUT SC, V11207, P330, DOI 10.1007/978-3-030-01219-9_20
   You QZ, 2016, PROC CVPR IEEE, V0, PP4651, DOI 10.1109/CVPR.2016.503
   Yu RC, 2017, IEEE I CONF COMP VIS, V0, PP1068, DOI 10.1109/ICCV.2017.121
   Zellers R, 2018, PROC CVPR IEEE, V0, PP5831, DOI 10.1109/CVPR.2018.00611
   Zhang HW, 2017, IEEE I CONF COMP VIS, V0, PP4243, DOI 10.1109/ICCV.2017.454
   Zhang HW, 2017, PROC CVPR IEEE, V0, PP3107, DOI 10.1109/CVPR.2017.331
   Zhang J, 2017, PROC CVPR IEEE, V0, PP5226, DOI 10.1109/CVPR.2017.555
   Zhuang BH, 2017, IEEE I CONF COMP VIS, V0, PP589, DOI 10.1109/ICCV.2017.71
NR 84
TC 8
Z9 8
U1 6
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD NOV 1
PY 2022
VL 44
IS 11
BP 7348
EP 7362
DI 10.1109/TPAMI.2021.3119754
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 5C5UY
UT WOS:000864325900011
PM 34648432
DA 2023-11-10
ER

PT J
AU Rao, ZB
   He, MY
   Dai, YC
   Shen, ZL
AF Rao, Zhibo
   He, Mingyi
   Dai, Yuchao
   Shen, Zhelun
TI Sliding space-disparity transformer for stereo matching
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Stereo matching; Space-disparity attention mechanism; Transformer; Sliding windows
AB Transformers have achieved impressive performance in natural language processing and computer vision, including text translation, semantic segmentation, etc. However, due to excessive self-attention computation and memory occupation, the stereo matching task does not share its success. To promote this technology in stereo matching, especially with limited hardware resources, we propose a sliding space-disparity transformer named SSD-former. According to matching modeling, we simplify transformer for achieving faster speed, memory-friendly, and competitive performance. First, we employ the sliding window scheme to limit the self-attention operations in the cost volume for adapting to different resolutions, bringing efficiency and flexibility. Second, our space-disparity transformer remarkably reduces memory occupation and computation, only computing the current patch's self-attention with two parts: (1) all patches of current disparity level at the whole spatial location and (2) the patches of different disparity levels at the exact spatial location. The experiments demonstrate that: (1) different from the standard transformer, SSD-former is faster and memory-friendly; (2) compared with 3D convolution methods, SSD-former has a larger receptive field and provides an impressive speed, showing great potential in stereo matching; and (3) our model obtains state-of-the-art performance and a faster speed on the multiple popular datasets, achieving the best speed-accuracy trade-off.
C1 [Rao, Zhibo; He, Mingyi; Dai, Yuchao] Northwestern Polytech Univ, Xian 710129, Peoples R China.
   [Shen, Zhelun] Baidu Res, Beijing 100193, Peoples R China.
C3 Northwestern Polytechnical University; Baidu
RP He, MY (通讯作者)，Northwestern Polytech Univ, Xian 710129, Peoples R China.
EM myhe@nwpu.edu.cn
FU National Natural Science Foundation of China [61671387, 61420106007, 61871325, 62001396]
CR Beltagy I, 2020, ARXIV, V0, P0
   Brown TB, 2020, P ADV NEUR INF PROC, V33, P1877
   Carion Nicolas, 2020, ECCV, V0, P0, DOI DOI 10.1007/978-3-030-58452-813
   Chang JR, 2018, PROC CVPR IEEE, V0, PP5410, DOI 10.1109/CVPR.2018.00567
   Chen YP, 2018, LECT NOTES COMPUT SC, V11205, P364, DOI 10.1007/978-3-030-01246-5_22
   Cheng Xuelian, 2020, ADV NEURAL INF PROCE, V0, P22158
   Cornia Marcella, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10575, DOI 10.1109/CVPR42600.2020.01059
   Dai Y, 2020, IEEE J OCEANIC ENG, V45, P699, DOI 10.1109/JOE.2019.2899689
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   DiGangi MA, 2019, P MACH TRANSL SUMM 1, V0, P21
   Ding YZ, 2020, NEURAL COMPUT APPL, V32, P11217, DOI 10.1007/s00521-020-04702-3
   Ding YH, 2022, NEURAL COMPUT APPL, V34, P2623, DOI 10.1007/s00521-021-05898-8
   Dosovitskiy Alexey, 2021, PROC 9 INT C LEARN R, V0, P0
   Duggal S, 2019, IEEE I CONF COMP VIS, V0, PP4383, DOI 10.1109/ICCV.2019.00448
   Fang X, 2021, NEURAL COMPUT APPL, V33, P9663, DOI 10.1007/s00521-021-05730-3
   Fang YQ, 2020, NEURAL COMPUT APPL, V32, P14603, DOI 10.1007/s00521-020-05146-5
   Feihu Zhang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12347), V0, PP420, DOI 10.1007/978-3-030-58536-5_25
   Geiger Andreas, 2012, CVPR, V0, P0
   Guo XY, 2019, PROC CVPR IEEE, V0, PP3268, DOI 10.1109/CVPR.2019.00339
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMI.2007.1166
   Hu B, 2021, NEURAL COMPUT APPL, V33, P10351, DOI 10.1007/s00521-021-05796-z
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kendall A, 2017, IEEE I CONF COMP VIS, V0, PP66, DOI 10.1109/ICCV.2017.17
   Kim TH, 2018, LECT NOTES COMPUT SC, V11207, P111, DOI 10.1007/978-3-030-01219-9_7
   Li DM, 2021, NEURAL COMPUT APPL, V33, P8143, DOI 10.1007/s00521-020-04912-9
   Li XY, 2021, NEURAL COMPUT APPL, V33, P8031, DOI 10.1007/s00521-020-05545-8
   Li X, 2022, IEEE SIGNAL PROC LET, V29, P60, DOI 10.1109/LSP.2021.3125264
   Li ZS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP6177, DOI 10.1109/ICCV48922.2021.00614
   Liang Justin, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9128, DOI 10.1109/CVPR42600.2020.00915
   Liu H, 2018, IEEE T PATTERN ANAL, V40, P2546, DOI 10.1109/TPAMI.2017.2734779
   Mayer N, 2016, PROC CVPR IEEE, V0, PP4040, DOI 10.1109/CVPR.2016.438
   MENZE M, 2015, PROC CVPR IEEE, V0, PP3061, DOI 10.1109/CVPR.2015.7298925
   Potamias RA, 2020, NEURAL COMPUT APPL, V32, P17309, DOI 10.1007/s00521-020-05102-3
   Rao ZB, 2022, IEEE T NEUR NET LEAR, V0, P0, DOI DOI 10.1109/TNNLS.2022.3146306
   Rao ZB, 2021, IEEE T GEOSCI REMOTE, V59, P6138, DOI 10.1109/TGRS.2020.3029527
   Rao ZB, 2022, VISUAL COMPUT, V38, P77, DOI 10.1007/s00371-020-02001-5
   Rao ZB, 2020, APSIPA TRANS SIGNAL, V9, P0, DOI 10.1017/ATSIP.2020.16
   Schöps T, 2017, PROC CVPR IEEE, V0, PP2538, DOI 10.1109/CVPR.2017.272
   Seki A, 2017, PROC CVPR IEEE, V0, PP6640, DOI 10.1109/CVPR.2017.703
   So DR, 2019, PR MACH LEARN RES, V97, P0
   Tankovich V, 2021, PROC CVPR IEEE, V0, PP14357, DOI 10.1109/CVPR46437.2021.01413
   Vaswani A, 2017, ARXIV, V30, P5998
   Wu ZY, 2019, IEEE I CONF COMP VIS, V0, PP7483, DOI 10.1109/ICCV.2019.00758
   Xu HF, 2020, PROC CVPR IEEE, V0, PP1956, DOI 10.1109/CVPR42600.2020.00203
   Yang FZ, 2020, PROC CVPR IEEE, V0, PP5790, DOI 10.1109/CVPR42600.2020.00583
   Yang GS, 2019, PROC CVPR IEEE, V0, PP5510, DOI 10.1109/CVPR.2019.00566
   Yin ZC, 2019, PROC CVPR IEEE, V0, PP6037, DOI 10.1109/CVPR.2019.00620
   Zbontar J, 2016, J MACH LEARN RES, V17, P0
   Zhai ML, 2021, NEURAL COMPUT APPL, V33, P3209, DOI 10.1007/s00521-020-05192-z
   Zhang FH, 2019, PROC CVPR IEEE, V0, PP185, DOI 10.1109/CVPR.2019.00027
   Zhang YM, 2020, AAAI CONF ARTIF INTE, V34, P12926
   Zhang ZS, 2020, AAAI CONF ARTIF INTE, V34, P9636
   Zheng SX, 2021, PROC CVPR IEEE, V0, PP6877, DOI 10.1109/CVPR46437.2021.00681
   Zhong Y, 2017, ARXIV, V0, P0
NR 54
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD DEC 15
PY 2022
VL 34
IS 24
BP 21863
EP 21876
DI 10.1007/s00521-022-07621-7
EA AUG 2022
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 5Z4IY
UT WOS:000836540000004
DA 2023-11-10
ER

PT J
AU Painsky, A
AF Painsky, Amichai
TI Convergence Guarantees for the Good-Turing Estimator
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE Good-Turing Estimator; Occupancy Probability; Natural Language Model-ing; Missing Mass
ID occupancy counts; sample; probability; number; coverage; formula
AB Consider a finite sample from an unknown distribution over a countable alphabet. The occupancy probability (OP) refers to the total probability of symbols that appear exactly k times in the sample. Estimating the OP is a basic problem in large alphabet modeling, with a variety of applications in machine learning, statistics and information theory. The Good-Turing (GT) framework is perhaps the most popular OP estimation scheme. Classical results show that the GT estimator converges to the OP, for every k independently. In this work we introduce new exact convergence guarantees for the GT estimator, based on worst-case mean squared error analysis. Our scheme improves upon currently known results. Further, we introduce a novel simultaneous convergence rate, for any desired set of occupancy probabilities. This allows us to quantify the unified performance of OP estimators, and introduce a novel estimation framework with favorable convergence guarantees.
C1 [Painsky, Amichai] Tel Aviv Univ, Dept Ind Engn, Tel Aviv, Israel.
C3 Tel Aviv University
RP Painsky, A (通讯作者)，Tel Aviv Univ, Dept Ind Engn, Tel Aviv, Israel.
EM amichaip@tauex.tau.ac.il
FU Israel Science Foundation [963/21]
CR Acharya J, 2018, IEEE INT SYMP INFO, V0, PP326, DOI 10.1109/ISIT.2018.8437620
   Anari Nima, 2020, ADV NEURAL INFORM PR, V33, P20272
   Battiston Marco, 2020, ANN INSTITUT HENRI P, V0, P0
   Ben-Hamou A, 2017, BERNOULLI, V23, P249, DOI 10.3150/15-BEJ743
   Berend D, 2013, ELECTRON COMMUN PROB, V18, P1, DOI 10.1214/ECP.v18-2359
   Budianu C, 2004, INT CONF ACOUST SPEE, V0, P1029
   Chanprakon P, 2019, 5 INT C ENG APPL SCI, V0, PP1, DOI 10.1109/ICEAST.2019.8802528
   CHAO A, 1981, ANN STAT, V9, P1339, DOI 10.1214/aos/1176345651
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Church KW, 1991, COMPUTER SPEECH AND LANGUAGE, V5, P19, DOI 10.1016/0885-2308(91)90016-J
   Cohen Shir, 2022, IEEE T SIGNAL PROCES, V0, P0
   Decrouez G, 2018, BERNOULLI, V24, P1910, DOI 10.3150/16-BEJ915
   Drukh E, 2005, J MACH LEARN RES, V6, P1231
   EFRON B, 1976, BIOMETRIKA, V63, P435, DOI 10.2307/2335721
   Favaro S, 2016, BIOMETRICS, V72, P136, DOI 10.1111/biom.12366
   Favaro S, 2012, BIOMETRICS, V68, P1188, DOI 10.1111/j.1541-0420.2012.01793.x
   Fisher RA, 1943, J ANIM ECOL, V12, P42, DOI 10.2307/1411
   Gale W, 1994, CORPUS BASED RES LAN, V0, P189
   Gale WA, 1995, J QUANT LINGUIST, V2, P217, DOI 10.1080/09296179508590051
   Gao FQ, 2013, ANN STAT, V41, P641, DOI 10.1214/13-AOS1091
   Gao Z, 2007, P NATL ACAD SCI USA, V104, P2927, DOI 10.1073/pnas.0607077104
   GOOD IJ, 1956, BIOMETRIKA, V43, P45
   GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344
   Grabchak M, 2017, MACH LEARN, V106, P1771, DOI 10.1007/s10994-016-5620-6
   Hao Yi, 2019, ADV NEURAL INFORM PR, V32, P0
   JUANG BH, 1994, IEEE T SIGNAL PROCES, V42, P496, DOI 10.1109/78.275640
   KARLIN S, 1967, J MATH MECH, V17, P373
   KRICHEVSKY RE, 1981, IEEE T INFORM THEORY, V27, P199, DOI 10.1109/TIT.1981.1056331
   Laplace P-S, 1825, PIERRE SIMON LAPLACE, V13, P0
   Lijoi A, 2007, BIOMETRIKA, V94, P769, DOI 10.1093/biomet/asm061
   Mao CX, 2002, BIOMETRIKA, V89, P669, DOI 10.1093/biomet/89.3.669
   McAllester D, 2000, P 13 ANN C COMP LEAR, V0, P1
   Mitrinovic DS, 1970, ANAL INEQUALITIES, V61, P0
   Mossel E, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21010028
   NADAS A, 1991, AM J MATH-S, V11, P299
   Ohannessian MI, 2012, C LEARN THEOR, V0, P21
   Orlitsky A, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, V0, P306
   Orlitsky A, 2004, IEEE T INFORM THEORY, V50, P1469, DOI 10.1109/TIT.2004.830761
   Orlitsky A, 2003, SCIENCE, V302, P427, DOI 10.1126/science.1088284
   Orlitsky A, 2004, P 20 C UNC ART INT, V0, P426
   Orlitsky A, 2015, ADV NEURAL INFORM PR, V0, PP2143, DOI 10.5555/2969442.2969479
   Orlitsky A, 2016, P NATL ACAD SCI USA, V113, P13283, DOI 10.1073/pnas.1607774113
   Painsky A, 2021, 2021 IEEE INFORMATION THEORY WORKSHOP (ITW), V0, P0, DOI DOI 10.1109/ITW48936.2021.9611389
   Painsky A, 2023, J AM STAT ASSOC, V118, P1890, DOI 10.1080/01621459.2021.2020658
   Painsky A, 2020, IEEE T INFORM THEORY, V66, P1658, DOI 10.1109/TIT.2019.2958705
   Painsky A, 2018, IEEE INT SYMP INFO, V0, PP936, DOI 10.1109/ISIT.2018.8437786
   Pavlichin DS, 2019, J MACH LEARN RES, V20, P0
   Prohorov YV, 1953, USPEKHI MAT NAUK, V8, P135
   Rajaraman Nikhilesh, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY (ISIT), V0, PP3025, DOI 10.1109/ISIT.2017.8007085
   Robbins H, 1995, AM MATH MON, V62, P26, DOI 10.2307/2308012
   Saichev AI, 2009, THEORY ZIPFS LAW, V632, P0
   Skorski M, 2021, ARXIV, V0, P0
   THISTED R, 1987, BIOMETRIKA, V74, P445, DOI 10.2307/2336684
   US Census Bureau, 2014, FREQ OCC SURN CENS, V0, P0
   Zhang CH, 2005, ANN STAT, V33, P2022, DOI 10.1214/009053605000000390
   Zhang ZY, 2007, J QUANT LINGUIST, V14, P222, DOI 10.1080/09296170701514189
NR 56
TC 0
Z9 0
U1 1
U2 1
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
EI 
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PD JUN 15
PY 2022
VL 23
IS 
BP 
EP 
DI 
PG 37
WC Automation & Control Systems; Computer Science, Artificial Intelligence
SC Automation & Control Systems; Computer Science
GA I5MT7
UT WOS:001003227800001
DA 2023-11-10
ER

PT J
AU Özer, H
   Korkmaz, EE
AF Ozer, Hilal
   Korkmaz, Emin Erkan
TI Transmorph: a transformer based morphological disambiguator for Turkish
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
LA English
DT Article
DE Natural language analysis; agglutinative languages; machine learning methods; morphological disambiguation; morphological analysis; transformer network
AB The agglutinative nature of the Turkish language has a complex morphological structure, and there are generally more than one parse for a given word. Before further processing, morphological disambiguation is required to determine the correct morphological analysis of a word. Morphological disambiguation is one of the first and crucial steps in natural language processing since its success determines later analyses. In our proposed morphological disambiguation method, we used a transformer-based sequence-to-sequence neural network architecture. Transformers are commonly used in various NLP tasks, and they produce state-of-the-art results in machine translation. However, to the best of our knowledge, transformer-based encoder-decoders have not been studied in morphological disambiguation. In this study, in addition to character level tokenization, three input subword representations are evaluated, which are unigram, bytepair, and wordpiece tokenization methods. We have achieved the best accuracy with character input representation which is 96.25%. Although the proposed model is developed for Turkish language, it is not language-dependent, so it can be applied to a larger set of languages.
C1 [Ozer, Hilal; Korkmaz, Emin Erkan] Yeditepe Univ, Dept Comp Engn, Fac Engn, Istanbul, Turkey.
C3 Yeditepe University
RP Özer, H (通讯作者)，Yeditepe Univ, Dept Comp Engn, Fac Engn, Istanbul, Turkey.
EM hilal.ozer@std.yeditepe.edu.tr
CR Akyürek E, 2019, T ASSOC COMPUT LING, V7, P567, DOI 10.1162/tacl_a_00286
   [Anonymous], 2007, STRUCTURE, V0, P0
   [Anonymous], 2009, P BIENNIAL GSCL C, V0, P0
   Antworth EL, 1990, PC KIMMO 2 LEVEL PRO, V0, P0
   BAYES T, 1958, BIOMETRIKA, V45, P296
   Çöltekin Ç, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1079
   Cunningham JP, 2007, ADV NEURAL INFORM PR, V20, P329
   Daybelge T, 2007, P REC ADV NAT LANG P, V0, P145
   Defazio A, 2021, ARXIV, V0, P0
   Eryigit G, 2004, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND APPLICATIONS, Vols 1and 2, P299
   Esref Y, 2019, P 2019 27 SIGNAL PRO, V0, P1
   Geva M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), V0, P5484
   Görgün O, 2012, COMPUTER AND INFORMATION SCIENCES II, V0, PP77, DOI 10.1007/978-1-4471-2155-8_9
   Güngör O, 2019, NAT LANG ENG, V25, P147, DOI 10.1017/S1351324918000281
   Hakkani-Tür DZ, 2002, COMPUT HUMANITIES, V36, P381, DOI 10.1023/A:1020271707826
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/NECO.1997.9.8.1735
   Kalender M, 2018, IEEE T KNOWL DATA EN, V30, P367, DOI 10.1109/TKDE.2017.2761743
   Kalender M, 2017, TURK J ELECTR ENG CO, V25, P2388, DOI 10.3906/elk-1512-102
   Kayabas A, 2019, TURK J ELECTR ENG CO, V27, P3837, DOI 10.3906/elk-1902-125
   Koskenniemi K, 1983, 2 LEVEL MORPHOLOGY G, V0, P0
   Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, V0, P66
   Libovicky J, 2018, P 3 C MACH TRANSL RE, V0, PP253, DOI 10.18653/V1/W18-6326
   Mikolov T, 2013, P 26 INT C NEUR INF, V2, P3111
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P1659
   Oflazer K, 1994, LITERARY & LINGUISTIC COMPUTING, V9, P137, DOI 10.1093/llc/9.2.137
   Oflazer K, 1996, P C EMPIRICAL METHOD, V0, P0
   Oflazer K, 1994, P 4 C APPL NAT LANG, V0, PP144, DOI 10.3115/974358.974391
   Orhan U, 2020, ACM T ASIAN LOW-RESO, V19, P0, DOI 10.1145/3397967
   Ozturel A, 2019, P 14 INT C FIN STAT, V0, PP65, DOI 10.18653/V1/W19-3110
   Pan YR, 2020, FUTURE INTERNET, V12, P0, DOI 10.3390/fi12060096
   Rumelhart DE, 1985, TECHNICAL REPORT, V0, P0, DOI DOI 10.1016/b978-1-4832-1446-7.50035-2
   Sak H, 2009, P ACL IJCNLP 2009 C, V0, P273
   Sak H, 2008, LECT NOTES ARTIF INT, V5221, P417
   Sak H, 2007, LECT NOTES COMPUT SC, V4394, P107
   Seker A, 2020, FINDINGS ASS COMPUTA, V0, PP4368, DOI 10.18653/V1/2020.FINDINGS-EMNLP.391
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shaw Peter, 2018, NAACL, V0, PP5, DOI 10.18653/V1/N18-2074
   Shen Q, 2016, P COLING 2016 26 INT, V0, P181
   Sutskever I, 2014, ADV NEURAL INFORM PR, VVolume 27, P3104
   Vaswani A, 2017, PROC ADV NEURAL INF, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wu Y, 2016, ARXIV, V0, P0
   Yildiz E, 2019, 16TH SIGMORPHON WORKSHOP ON COMPUTATIONAL RESEARCH IN PHONETICS PHONOLOGY, V0, P25
   Yildiz E, 2016, AAAI CONF ARTIF INTE, V0, P2863
   Yildiz OT, 2019, P INT C RECENT ADV N, V0, P1364
   Yuret D, 2006, P MAIN C HUM LANG TE, V0, PP328, DOI 10.3115/1220835.1220877
   Zhu SL, 2018, WIRELESS PERS COMMUN, V102, P2527, DOI 10.1007/s11277-018-5274-8
NR 46
TC 1
Z9 1
U1 2
U2 2
PU Tubitak Scientific & Technological Research Council Turkey
PI ANKARA
PA ATATURK BULVARI NO 221, KAVAKLIDERE, TR-06100 ANKARA, TURKIYE
SN 1300-0632
EI 1303-6203
J9 TURK J ELECTR ENG CO
JI Turk. J. Electr. Eng. Comput. Sci.
PD JUN 15
PY 2022
VL 30
IS 5
BP 1897
EP 1913
DI 10.55730/1300-0632.3912
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 7J6XM
UT WOS:000904725600015
DA 2023-11-10
ER

PT J
AU Almuzaini, HA
   Azmi, AM
AF Almuzaini, Huda A.
   Azmi, Aqil M.
TI An unsupervised annotation of Arabic texts using multi-label topic modeling and genetic algorithm
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Arabic corpus; Topic modeling; Multi-label annotation; Genetic algorithm; Latent Dirichlet allocation; Crowdsourcing
ID lda
AB Every day the world produces an enormous amount of textual data. This unstructured text is of little use unless it is labeled using a combination of categories, keywords, tags. Humans can never annotate such massive data, and with a growing divide between the daily produced data and those annotated, the only alternative is to mechanize it. Automatic annotation process helps in saving resources in terms of time and cost. The process of multi-label annotation involves associating a document with multiple relevant labels. This paper proposes an unsupervised model to annotate corpus using multi-labels automatically. The model is based on multi-label topic modeling and genetic algorithm (GA). Topic modeling is a technique to extract the hidden topics from text, and the GA is used to find the optimal number of topics. We hyper-tuned the parameters of the topic modeling using two different training methods: variational Bayes and Gibbs sampling. The class imbalance in a corpus can affect the result of topic modeling, where the majority class dominates the minority class. We overcome this problem using the partitioning method. Though the proposed model was developed for the Arabic dataset, it is language neutral. We tested our model on three large Arabic corpora and three large English social media datasets. For the Arabic language, our work being the first work that tackles multi-label annotation, we needed a reference to compare our model. For the Arabic corpus, we compared the result of automatic annotation against humans using crowdsourcing (whose labeling was checked for quality). The analysis of the annotation shows an agreement among models (machine vs. human) of 79.30%. Moreover, for the English dataset, the results are quite competitive.
C1 [Almuzaini, Huda A.; Azmi, Aqil M.] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11543, Saudi Arabia.
C3 King Saud University
RP Azmi, AM (通讯作者)，King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11543, Saudi Arabia.
EM hamozeani@imamu.edu.sa; aqil@ksu.edu.sa
CR Alhawarat M, 2018, IEEE ACCESS, V6, P42740, DOI 10.1109/ACCESS.2018.2852648
   Almuzaini HA, 2020, IEEE ACCESS, V8, P127913, DOI 10.1109/ACCESS.2020.3009217
   Alzanin SM, 2019, KNOWL-BASED SYST, V185, P0, DOI 10.1016/j.knosys.2019.104945
   [Anonymous], 2010, P NIPS US, V0, P0
   [Anonymous], 2021, 10 MOST SPOKEN LANGU, V0, P0
   [Anonymous], 2017, ERGODICTHEORY DYNAMI, V0, P0
   Asuncion A, 2012, ARXIV PREPRINT ARXIV, V0, P0
   Awasare VK, 2017, 2 INT C EL COMP COMM, V0, P1
   Ayadi R, 2015, COMM COM INF SC, V538, P491, DOI 10.1007/978-3-319-24770-0_42
   Ayadi R, 2014, INT J INF RETR RES, V4, P57, DOI 10.4018/ijirr.2014040104
   Basu Sugato, 2002, ICML, V0, P3
   Benz D, 2010, VLDB J, V19, P849, DOI 10.1007/s00778-010-0208-4
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brahmi A, 2012, INFORM RETRIEVAL, V15, P33, DOI 10.1007/s10791-011-9171-y
   Burkhardt Sophie, 2019, ACM SIGKDD EXPLORATIONS NEWSLETTER, V21, P61, DOI 10.1145/3373464.3373474
   Cai LK, 2020, IEEE ACCESS, V8, P152183, DOI 10.1109/ACCESS.2020.3017382
   Canini KR, 2009, P INT C ART INT STAT, V5, P65
   Chouigui A, 2017, I C COMP SYST APPLIC, V0, PP135, DOI 10.1109/AICCSA.2017.22
   Chu Z, 2021, 3 C AUTOMATED KNOWLE, V0, P0
   Dietz L, 2007, P 24 INT C MACHINE L, V0, PP233, DOI 10.1145/1273496.1273526
   Dong H, 2021, IEEE T NEUR NET LEAR, V32, P2224, DOI 10.1109/TNNLS.2020.3002798
   El Bazi I, 2018, INT J INTELLIGENT EN, V11, P229
   El-Alami FZ, 2020, J INF COMMUN TECHNOL, V19, P381
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, P0, DOI 10.1016/j.ipm.2019.102121
   Fujino A, 2005, PROC NATL CONF ARTIF, V0, P764
   Gao X, 2021, ENG APPL ARTIF INTEL, V97, P0, DOI 10.1016/j.engappai.2020.104034
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Guellil I, 2020, SOC NETW ANAL MIN, V10, P0, DOI 10.1007/s13278-020-00688-x
   Guellil I, 2018, LECT NOTES ARTIF INT, V10989, P557, DOI 10.1007/978-3-030-00563-4_54
   He DB, 2019, IEEE ACCESS, V7, P131593, DOI 10.1109/ACCESS.2019.2940516
   Hofmann T, 1999, SIGIR99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP50, DOI 10.1145/312624.312649
   Imane G, 2019, INT J WEB INF SYST, V15, P594, DOI 10.1108/IJWIS-03-2019-0008
   Jelodar H, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Jiang HQ, 2022, PSYCHOL HEALTH MED, V27, P1977, DOI 10.1080/13548506.2021.1990367
   Jo T, 2006, THESIS, V0, P0
   Johnsen JW, 2019, IEEE INT CONF BIG DA, V0, PP4248, DOI 10.1109/BigData47090.2019.9006006
   Kelaiaia A, 2016, INT ARAB J INF TECHN, V13, P332
   Khoja S, 1999, STEMMING ARABIC TEXT, V0, P0
   Kulkarni A, 2021, ARXIV PREPRINT ARXIV, V0, P0
   Kwaik KA, 2020, P 4 WORKSHOP OPEN SO, V0, P1
   Mifrah S, 2020, INT J ADV TRENDS COM, V0, PP5756, DOI 10.30534/IJATCSE/2020/231942020
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Mimno David, 2011, EMNLP 11 P C EMPIRIC, V0, PP262, DOI 10.5555/2145432.2145462
   Mimno David, 2009, P 2009 C EMPIRICAL M, V2, P880, DOI 10.3115/1699571.1699627
   Molavi Mohammadreza, 2020, ADDRESSING GLOBAL CHALLENGES AND QUALITY EDUCATION. 15TH EUROPEAN CONFERENCE ON TECHNOLOGY ENHANCED LEARNING, V0, P455, DOI 10.1007/978-3-030-57717-9_44
   Moscato P, 2003, INT SER OPER RES MAN, V57, P105, DOI 10.1007/0-306-48056-5_5
   Naili M, 2017, ARABIC TOPIC IDENTIF, V0, P0
   Papadimitriou CH, 2000, J COMPUT SYST SCI, V61, P217, DOI 10.1006/jcss.2000.1711
   Papanikolaou Y, 2017, J MACH LEARN RES, V18, P1
   Patibandla RSMLakshmi, 2018, INTELLIGENT ENGINEERING INFORMATICS. PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON FICTA. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 695), V0, PP421, DOI 10.1007/978-981-10-7566-7_41
   Pavlinek M, 2017, EXPERT SYST APPL, V80, P83, DOI 10.1016/j.eswa.2017.03.020
   Perez F, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Radford A, 2019, OPENAI BLOG, V0, P0
   Raff Edward, 2020, EXPLORATORY ANAL COV, V0, P0
   Röder M, 2015, WSDM15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP399, DOI 10.1145/2684822.2685324
   Rosen-Zvi Michal, 2004, P 20 C UNCERTAINTY A, V0, PP487, DOI 10.5555/1036843.1036902
   Saad MK, 2010, 6 INT S ELECT ELECT, V0, P1
   Schofeld Alexandra, 2017, P 15 C EUR CHAPT ASS, V2, P432, DOI 10.18653/V1/E17-2069
   Settles Burr, 2009, COMPUTER SCI TECHNIC, V0, P0
   Smola A, 2010, PROC VLDB ENDOW, V3, P703, DOI 10.14778/1920841.1920931
   Stevens K, 2012, P 2012 JOINT C EMP M, V0, P952
   Taghva K, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P152, DOI 10.1109/ITCC.2005.90
   Taware R, 2021, INT C MACH LEARN OPT, V0, P0
   Wan XJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2297
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang H, 2013, P 23 INT JOINT C ART, V0, P2719
   Wang MZ, 2021, PROC VLDB ENDOW, V14, P1964, DOI 10.14778/3476249.3476255
   Xiao YQ, 2021, KNOWL-BASED SYST, V224, P0, DOI 10.1016/j.knosys.2021.107094
   Xing YY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2882
   Yao LM, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P937
   Zha DC, 2019, KNOWL INF SYST, V61, P137, DOI 10.1007/s10115-018-1280-0
   Zhan W, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1305, DOI 10.1145/3097983.3098141
   Zhang H, 2020, LECT NOTES COMPUT SC, V12113, P227, DOI 10.1007/978-3-030-59416-9_14
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhu Y, 2009, LECT NOTES ARTIF INT, V5914, P134
   Zrigui Mounir, 2012, CIT. JOURNAL OF COMPUTING AND INFORMATION TECHNOLOGY, V20, P125, DOI 10.2498/cit.1001770
NR 76
TC 3
Z9 3
U1 3
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD OCT 1
PY 2022
VL 203
IS 
BP 
EP 
DI 10.1016/j.eswa.2022.117384
EA MAY 2022
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA 1S0FK
UT WOS:000803735400001
DA 2023-11-10
ER

PT J
AU Martinez-Cruz, C
   Rueda, AJ
   Popescu, M
   Keller, JM
AF Martinez-Cruz, Carmen
   Rueda, Antonio J.
   Popescu, Mihail
   Keller, James M.
TI New Linguistic Description Approach for Time Series and Its Application to Bed Restlessness Monitoring for Eldercare
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Linguistics; Natural languages; Time series analysis; Market research; Monitoring; Heart rate; Fluctuations; Bed restlessness (BR); eldercare; fuzzy set theory; linguistic summaries; natural language generation; time series (TS)
ID fuzzy
AB Time-series analysis has been an active area of research for years, with important applications in forecasting or discovery of hidden information such as patterns or anomalies in observed data. In recent years, the use of time-series analysis techniques for the generation of descriptions and summaries in natural language of any variable, such as temperature, heart rate, or CO2 emission has received increasing attention. Natural language has been recognized as more effective than traditional graphical representations of numerical data in many cases, in particular, in situations where a large amount of data needs to be inspected or when the user lacks the necessary background and skills to interpret it. In this article, we describe a novel mechanism to generate linguistic descriptions of time series using natural language and fuzzy logic techniques. The proposed method generates quality summaries capturing the time-series features that are relevant for a user in a particular application, and can be easily customized for different domains. This approach has been successfully applied to the generation of linguistic descriptions of bed restlessness data from residents at TigerPlace (Columbia, MO, USA), which is used as a case study to illustrate the modeling process and show the quality of the descriptions obtained.
C1 [Martinez-Cruz, Carmen; Rueda, Antonio J.] Univ Jaen, Dept Informat, Jaen 23071, Spain.
   [Martinez-Cruz, Carmen; Rueda, Antonio J.] Univ Jaen, Ctr Estudios Avanzados Tecnol Informac & Comunica, Jaen 23071, Spain.
   [Popescu, Mihail] Univ Missouri, Dept Hlth Management & Informat, Columbia, MO 65211 USA.
   [Keller, James M.] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
C3 Universidad de Jaen; Universidad de Jaen; University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia
RP Martinez-Cruz, C (通讯作者)，Univ Jaen, Dept Informat, Jaen 23071, Spain.; Martinez-Cruz, C (通讯作者)，Univ Jaen, Ctr Estudios Avanzados Tecnol Informac & Comunica, Jaen 23071, Spain.
EM cmcruz@ujaen.es; ajrueda@ujaen.es; popescum@health.missouri.edu; kellerj@missouri.edu
FU EU [85718]; Spanish Ministry of Science, Innovation and Universities; European Regional Development Fund - ERDF (Fondo Europeo de Desarrollo Regional -FEDER) [PGC2018-096156-B-I00]; Andalusian Health Service [PI-0387-2018]; University of Jaen [EI_TIC01]; National Library of Medicine (NLM) [R01LM012221]
CR Alvarez-Alvarez A, 2013, ENG APPL ARTIF INTEL, V26, P13, DOI 10.1016/j.engappai.2012.01.022
   Banaee H, 2013, IEEE SYS MAN CYBERN, V0, PP3876, DOI 10.1109/SMC.2013.661
   Boran FE, 2016, EXPERT SYST APPL, V61, P356, DOI 10.1016/j.eswa.2016.05.044
   Castillo-Ortega RM, 2011, J MULT-VALUED LOG S, V17, P157
   Chung F-L, 2001, JOINT C ARTIFICIAL I, V0, P1
   Demiris G, 2006, ASSIST TECHNOL RES S, V19, P66
   Peláez-Aguilera MD, 2019, COMPLEXITY, V0, P0, DOI DOI 10.1155/2019/2694126
   Ruiz MD, 2016, FUZZY SET SYST, V294, P125, DOI 10.1016/j.fss.2015.10.002
   Doran D, 2017, WHAT DOES EXPLAINABL, V0, P0
   Douglas David H, 1973, CARTOGRAPHICA INT J, V0, P0, DOI DOI 10.1002/9780470669488.CH2
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Heise D, 2011, IEEE ENG MED BIO, V0, PP4356, DOI 10.1109/IEMBS.2011.6091081
   Hoppner F, 2002, GI JAHRESTAGUNG, V0, P777
   Jain A, 2019, J BIOMED INFORM, V96, P0, DOI 10.1016/j.jbi.2019.103240
   Jain S, 2015, INTEGR STEM EDU CONF, V0, PP1, DOI 10.1109/ISECon.2015.7119898
   Kacprzyk J, 2016, WIRES DATA MIN KNOWL, V6, P37, DOI 10.1002/widm.1175
   Kacprzyk J, 2010, COMM COM INF SC, V80, P436
   Kaczmarek-Majer K, 2019, INFORM SCIENCES, V478, P580, DOI 10.1016/j.ins.2018.11.036
   Keogh Eamonn, 1993, P DAT MIN TIM SER DA, V0, P1
   Lesot MJ, 2016, FUZZY SET SYST, V292, P307, DOI 10.1016/j.fss.2014.10.019
   Marín N, 2016, FUZZY SET SYST, V285, P6, DOI 10.1016/j.fss.2015.04.014
   Mattson MP, 2014, FRONT NEUROSCI-SWITZ, V8, P0, DOI 10.3389/fnins.2014.00265
   Novak V, 2016, INSIGHT FUZZY MODEL, V0, P0
   Novák V, 2008, FUZZY SET SYST, V159, P1229, DOI 10.1016/j.fss.2007.12.008
   Novák V, 2016, INT J APPROX REASON, V78, P192, DOI 10.1016/j.ijar.2016.07.006
   Novák V, 2016, FUZZY SET SYST, V285, P52, DOI 10.1016/j.fss.2015.07.017
   Novák V, 2015, P ANN HICSS, V0, PP1493, DOI 10.1109/HICSS.2015.181
   Novák V, 2013, INT J GEN SYST, V42, P21, DOI 10.1080/03081079.2012.710436
   Ramer U, 1972, COMPUT VISION GRAPH, V1, P244, DOI 10.1016/S0146-664X(72)80017-0
   Ramos-Soto A, 2016, FUZZY SET SYST, V285, P31, DOI 10.1016/j.fss.2015.06.019
   Rantz MJ, 2008, J HOUS ELDER, V22, P66, DOI 10.1080/02763890802097045
   Rantz MJ, 2010, J GERONTOL NURS, V36, P13, DOI 10.3928/00989134-20091204-02
   Reiter E, 2005, ARTIF INTELL, V167, P137, DOI 10.1016/j.artint.2005.06.006
   Trivino G, 2013, INT J APPROX REASON, V54, P22, DOI 10.1016/j.ijar.2012.07.004
   Wilbik A, 2014, IEEE T FUZZY SYST, V22, P110, DOI 10.1109/TFUZZ.2013.2249517
   YAGER RR, 1982, INFORM SCIENCES, V28, P69, DOI 10.1016/0020-0255(82)90033-0
   Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904
   Zadeh LA, 2000, ADV SOFT COMP, V0, P3
   Zadeh LA, 1972, J CYBERNETICS, V2, P4, DOI 10.1080/01969727208542910
   Zemankova-Leech M, 1984, FUZZY RELATIONAL DAT, V0, P0
NR 40
TC 2
Z9 2
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD APR 15
PY 2022
VL 30
IS 4
BP 1048
EP 1059
DI 10.1109/TFUZZ.2021.3052107
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 0D6PL
UT WOS:000776115000017
PM 35722448
DA 2023-11-10
ER

PT J
AU Wu, XH
   Wang, TR
   Fan, YP
   Yu, FJ
AF Wu, Xiaohua
   Wang, Tengrui
   Fan, Youping
   Yu, Fangjian
TI Chinese Event Extraction via Graph Attention Network
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE Event extraction; graph neural network
AB Event extraction plays an important role in natural language processing (NLP) applications, including question answering and information retrieval. Most of the previous state-of-the-art methods were lack of ability in capturing features in long range. Recent methods applied dependency tree via dependency-bridge and attention-based graph. However, most of the automatic processing tools used in those methods show poor performance on Chinese texts due to mismatching between word segmentation and labels, which results in error propagation. In this article, we propose a novel character-level Chinese event extraction framework via graph attention network (CAEE). We build our model upon the sequence labeling model, but enhance it with word information by incorporating the word lexicon into the character representations. We further exploit the inter-dependencies between event triggers and argument by building a word-character-based graph network via syntactic shortcut arcs with dependency-parsing. The architecture of the graph minimizes error propagation, which is the result of the error detection of the word boundaries in the processing of Chinese texts. To demonstrate the effectiveness of our work, we build a large-scale real-world corpus consisting of announcements of Chinese financial news without golden entities. Experiments on the corpus show that our approach achieves competitive results compared with previous work in the field of Chinese texts.
C1 [Wu, Xiaohua; Wang, Tengrui; Fan, Youping; Yu, Fangjian] Univ Elect Sci & Technol China, Sch Informat & Software Engn, 4,Sect 2,North Jianshe Rd, Chengdu 610054, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Wang, TR (通讯作者)，Univ Elect Sci & Technol China, Sch Informat & Software Engn, 4,Sect 2,North Jianshe Rd, Chengdu 610054, Sichuan, Peoples R China.
EM wuxh@uestc.edu.cn; tengruiwang@std.uestc.edu.cn; youpingfan@std.uestc.edu.cn; yufaji@std.uestc.edu.cn
FU National Natural Science Foundation of China [61872065]; Sichuan Science and Technology Program [2021YFG0305]
CR [Anonymous], 1997, NEURAL COMPUT, V0, P0, DOI DOI 10.1162/neco.1997.9.8.1735
   Cai D, 2020, AAAI CONF ARTIF INTE, V34, P7464
   Chen C, 2012, P 24 INT C COMPUTATI, V0, P529
   Chen YB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P167
   Cho Kyunghyun, 2014, ARXIV PREPRINT ARXIV, V4, P4, DOI 10.3115/v1/w14-4012
   Devlin J, 2018, ARXIV, V1, P4171
   Gui T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P1040
   Kipf TN, 2016, P INT C LEARNING REP, V0, P0
   Li S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P138
   Lin Hanhe, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Liu SL, 2016, AAAI CONF ARTIF INTE, V0, P2993
   Liu Shulin, 2016, ACL, V0, P0
   Liu X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1247
   Mikolov T, 2013, EFFICIENT ESTIMATION, V0, P0
   Nguyen TH, 2016, P 2016 C N AM CHAPTE, V0, PP300, DOI 10.18653/V1/N16-1034
   Peng M, 2020, P 58 ANN M ASS COMP, V0, PP5951, DOI 10.18653/v1/2020.acl-main.528
   Sha L, 2018, AAAI CONF ARTIF INTE, V0, P5916
   Song L, 2018, ARXIV180711334, V0, P0
   Sui DAB, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P3830
   Nguyen TH, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P365
   Velickovi Petar, 2017, ARXIV171010903, V0, P0
   Yang B, 2016, PROC 2016 C N AM CHA, V0, P289
   Zeng Y, 2016, LECT NOTES COMPUT SC, V10102, P275, DOI 10.1007/978-3-319-50496-4_23
   Zhang Shuai, 2020, ARXIVCSCL200900901, V0, P0
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zheng S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), V0, P337
NR 26
TC 0
Z9 0
U1 5
U2 28
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD JUL 15
PY 2022
VL 21
IS 4
BP 
EP 
DI 10.1145/3494533
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 1L2VC
UT WOS:000799149600008
DA 2023-11-10
ER

PT J
AU Tang, YQ
   Xie, Y
   Zhang, CQ
   Zhang, ZZ
   Zhang, WS
AF Tang, Yongqiang
   Xie, Yuan
   Zhang, Changqing
   Zhang, Zhizhong
   Zhang, Wensheng
TI One-Step Multiview Subspace Segmentation via Joint Skinny Tensor Learning and Latent Clustering
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article
DE Tensors; Optimization; Clustering methods; Computational modeling; Clustering algorithms; Semantics; Matrix decomposition; Multiview clustering; multiview representations; subspace clustering; tensor singular value decomposition (t-SVD)
ID algorithm; factorization; robust; graph
AB Multiview subspace clustering (MSC) has attracted growing attention due to the extensive value in various applications, such as natural language processing, face recognition, and time-series analysis. In this article, we are devoted to address two crucial issues in MSC: 1) high computational cost and 2) cumbersome multistage clustering. Existing MSC approaches, including tensor singular value decomposition (t-SVD)-MSC that has achieved promising performance, generally utilize the dataset itself as the dictionary and regard representation learning and clustering process as two separate parts, thus leading to the high computational overhead and unsatisfactory clustering performance. To remedy these two issues, we propose a novel MSC model called joint skinny tensor learning and latent clustering (JSTC), which can learn high-order skinny tensor representations and corresponding latent clustering assignments simultaneously. Through such a joint optimization strategy, the multiview complementary information and latent clustering structure can be exploited thoroughly to improve the clustering performance. An alternating direction minimization algorithm, which owns low computational complexity and can be run in parallel when solving several key subproblems, is carefully designed to optimize the JSTC model. Such a nice property makes our JSTC an appealing solution for large-scale MSC problems. We conduct extensive experiments on ten popular datasets and compare our JSTC with 12 competitors. Five commonly used metrics, including four external measures (NMI, ACC, F-score, and RI) and one internal metric (SI), are adopted to evaluate the clustering quality. The experimental results with the Wilcoxon statistical test demonstrate the superiority of the proposed method in both clustering performance and operational efficiency.
C1 [Tang, Yongqiang; Zhang, Wensheng] Chinese Acad Sci, Res Ctr Precis Sensing & Control, Inst Automat, Beijing 100190, Peoples R China.
   [Xie, Yuan; Zhang, Zhizhong] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200241, Peoples R China.
   [Zhang, Changqing] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Zhang, Wensheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; East China Normal University; Tianjin University; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Zhang, WS (通讯作者)，Chinese Acad Sci, Res Ctr Precis Sensing & Control, Inst Automat, Beijing 100190, Peoples R China.; Zhang, WS (通讯作者)，Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
EM yongqiang.tang@ia.ac.cn; yxie@sei.ecnu.edu.cn; zhangchangqing@tju.edu.cn; zzzhang@cs.ecnu.edu.cn; zhangwenshengia@hotmail.com
FU Key-Area Research and Development Program of Guangdong Province [2019B010153002]; National Natural Science Foundation of China [U1936206, 61976212, 61906190, 61876183, 61772524]; Natural Science Foundation of Shanghai [20ZR1417700]; Research Program of Zhejiang Lab [2019KD0AC02]
CR Arbelaitz O, 2013, PATTERN RECOGN, V46, P243, DOI 10.1016/j.patcog.2012.07.021
   Bao L, 2007, APPL NUMER MATH, V57, P521, DOI 10.1016/j.apnum.2006.07.005
   BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582
   Blaschko MB, 2008, PROC CVPR IEEE, V0, PP93, DOI 10.1109/cvpr.2008.4587586
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai X, 2013, 23 INT JOINT C ARTIF, V0, P0
   CAO XC, 2015, PROC CVPR IEEE, V0, PP586, DOI 10.1109/CVPR.2015.7298657
   Chao G, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Chaudhuri K, 2009, P 26 ANN INT C MACHI, V0, PP129, DOI 10.1145/1553374.1553391
   Ding Chris, 2006, P 12 ACM SIGKDD INT, V0, PP126, DOI 10.1145/1150402.1150420
   Dong XW, 2014, IEEE T SIGNAL PROCES, V62, P905, DOI 10.1109/TSP.2013.2295553
   Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P3476
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Gao HC, 2015, IEEE I CONF COMP VIS, V0, PP4238, DOI 10.1109/ICCV.2015.482
   GOLUB GH, 1979, IEEE T AUTOMAT CONTR, V24, P909, DOI 10.1109/TAC.1979.1102170
   HAN J, 2020, IEEE T KNOWL DATA EN, V0, P0
   Huang A, 2008, P 6 NZ COMP SCI RES, V4, P9
   Huang SD, 2020, PATTERN RECOGN, V97, P0, DOI 10.1016/j.patcog.2019.107015
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Kang Z, 2020, NEURAL NETWORKS, V122, P279, DOI 10.1016/j.neunet.2019.10.010
   Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711
   Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020
   Kumar A, 2011, ADV NEURAL INFORM PR, V24, P0, DOI 10.5555/2986459.2986617
   KumarA Daume H, 2011, ICML, V0, PP393, DOI 10.5555/3104482.3104532
   Li YM, 2019, IEEE T KNOWL DATA EN, V31, P1863, DOI 10.1109/TKDE.2018.2872063
   Lin Z, 2011, ADV NEURAL INFORM PR, V0, PP612, DOI 10.1007/S11263-013-0611-6
   Lipor J, 2020, PATTERN RECOGN, V104, P0, DOI 10.1016/j.patcog.2020.107328
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2017, IEEE T PATTERN ANAL, V39, P47, DOI 10.1109/TPAMI.2016.2539946
   Liu XW, 2020, IEEE T PATTERN ANAL, V42, P1191, DOI 10.1109/TPAMI.2019.2892416
   Liu YJ, 2023, IEEE T NEUR NET LEAR, V34, P2732, DOI 10.1109/TNNLS.2021.3107600
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Oh TH, 2018, IEEE T PATTERN ANAL, V40, P376, DOI 10.1109/TPAMI.2017.2677440
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Semerci O, 2014, IEEE T IMAGE PROCESS, V23, P1678, DOI 10.1109/TIP.2014.2305840
   Shi M, 2020, DATA MIN KNOWL DISC, V34, P75, DOI 10.1007/s10618-019-00659-7
   Strehl A, 2000, WORKSH ART INT WEB S, V58, P64
   Sun S, 2019, MULTIVIEW MACHINE LE, V0, P0
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P1724, DOI 10.1109/TMM.2018.2889560
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810
   Wang J, 2018, IEEE T CYBERNETICS, V48, P2620, DOI 10.1109/TCYB.2017.2747400
   Wang Q, 2022, IEEE T PATTERN ANAL, V44, P390, DOI 10.1109/TPAMI.2020.3007673
   Wang Q, 2020, IEEE T PATTERN ANAL, V42, P46, DOI 10.1109/TPAMI.2018.2875002
   Wang Q, 2019, IEEE T NEUR NET LEAR, V30, P1265, DOI 10.1109/TNNLS.2018.2861209
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Wang X, 2013, SDM, V0, PP234, DOI 10.1137/1.9781611972832.26
   Wang XM, 2019, IEEE T CYBERNETICS, V49, P3333, DOI 10.1109/TCYB.2018.2842052
   Xiao Cai, 2011, 2011 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP1977, DOI 10.1109/CVPR.2011.5995740
   Xiaobo Wang, 2017, 2017 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP1, DOI 10.1109/CVPR.2017.8
   Xie Y, 2020, IEEE T CYBERNETICS, V50, P572, DOI 10.1109/TCYB.2018.2869789
   Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2
   Xu C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P3974
   Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976
   XU M, 2019, IEEE C ELEC DEVICES, V0, PNI331
   Ye YK, 2016, INT C PATT RECOG, V0, PP1583, DOI 10.1109/ICPR.2016.7899863
   Zhang CQ, 2020, IEEE T PATTERN ANAL, V42, P86, DOI 10.1109/TPAMI.2018.2877660
   Zhang CQ, 2015, IEEE I CONF COMP VIS, V0, PP1582, DOI 10.1109/ICCV.2015.185
   Zhang GY, 2020, KNOWL-BASED SYST, V189, P0, DOI 10.1016/j.knosys.2019.105126
   Zhang ZM, 2014, PROC CVPR IEEE, V0, PP3842, DOI 10.1109/CVPR.2014.485
   Zhao HD, 2017, AAAI CONF ARTIF INTE, V0, P2921
   Zhou P, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), V0, P4105
   Zhou T, 2020, IEEE T CYBERNETICS, V50, P3517, DOI 10.1109/TCYB.2019.2918495
   Zhu XZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3271
NR 69
TC 13
Z9 13
U1 1
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD SEP 15
PY 2022
VL 52
IS 9
BP 9179
EP 9193
DI 10.1109/TCYB.2021.3053057
EA MAR 2021
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Automation & Control Systems; Computer Science
GA 3W0SV
UT WOS:000732252800001
PM 33661745
DA 2023-11-10
ER

PT J
AU Wang, CZ
   Nong, ZH
   Gao, CY
   Li, ZJ
   Zeng, JC
   Xing, ZC
   Liu, Y
AF Wang, Chaozheng
   Nong, Zhenhao
   Gao, Cuiyun
   Li, Zongjie
   Zeng, Jichuan
   Xing, Zhenchang
   Liu, Yang
TI Enriching query semantics for code search with reinforcement learning
SO NEURAL NETWORKS
LA English
DT Article
DE Code search; Query semantics; Semantic enrichment; Reinforcement learning
AB Code search is a common practice for developers during software implementation. The challenges of accurate code search mainly lie in the knowledge gap between source code and natural language (i.e., queries). Due to the limited code-query pairs and large code-description pairs available, the prior studies based on deep learning techniques focus on learning the semantic matching relation between source code and corresponding description texts for the task, and hypothesize that the semantic gap between descriptions and user queries is marginal. In this work, we found that the code search models trained on code-description pairs may not perform well on user queries, which indicates the semantic distance between queries and code descriptions. To mitigate the semantic distance for more effective code search, we propose QueCos, a Query-enriched Code search model. QueCos learns to generate semantic enriched queries to capture the key semantics of given queries with reinforcement learning (RL). With RL, the code search performance is considered as a reward for producing accurate semantic enriched queries. The enriched queries are finally employed for code search. Experiments on the benchmark datasets show that QueCos can significantly outperform the state-of-the-art code search models. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Wang, Chaozheng; Nong, Zhenhao; Gao, Cuiyun; Li, Zongjie] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
   [Zeng, Jichuan] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Xing, Zhenchang] Australian Natl Univ, Res Sch Comp Sci, Canberra, ACT, Australia.
   [Liu, Yang] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Harbin Institute of Technology; Chinese University of Hong Kong; Australian National University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University
RP Gao, CY (通讯作者)，Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
EM wangchaozheng@stu.hit.edu.cn; nongzhenhao@stu.hit.edu.cn; gaocuiyun@hit.edu.cn; lizongjie@stu.hit.edu.cn; jczeng@cse.cuhk.edu.hk; zhenchang.xing@anu.edu.au; yangliu@ntu.edu.sg
FU National Natural Science Foundation of China [62002084]; Stable support plan for colleges and universities in Shenzhen [GXWD20201230155427003-20200730101839009]; National Research Foundation, Singapore [AISG2-RP-2020-019]; National Research Foundation; Prime Ministers Office, Singapore [NRF2018NCR-NCR005-0001]; National Re-search Foundation [NRF2018NCR-NSOE003-0001]
CR Lam AN, 2017, INT C PROGRAM COMPRE, V0, PP218, DOI 10.1109/ICPC.2017.24
   Bahdanau D, 2016, ARXIV, V0, P0
   Baltes S, 2018, IEEE WORK CONF MIN S, V0, PP319, DOI 10.1145/3196398.3196430
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Cambronero J, 2019, ESEC/FSE2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, V0, PP964, DOI 10.1145/3338906.3340458
   Devlin J, 2018, ARXIV, V1, P4171
   Feng Z, 2020, EMNLP, V0, P0
   Gu WC, 2021, NEURAL NETWORKS, V141, P385, DOI 10.1016/j.neunet.2021.04.019
   Gu XD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), V0, PP933, DOI 10.1145/3180155.3180167
   Guo D, 2020, ARXIV200908366 CORR, V0, P0
   Huang Q, 2019, SOFTWARE PRACT EXPER, V49, P1600, DOI 10.1002/spe.2736
   Husain H, 2019, ABS190909436 CORR, V0, P0
   Lan Z, 2020, CORR, V0, P1
   Leacock C, 1998, LANG SPEECH & COMMUN, V0, P265
   LeClair A, 2020, INT C PROGRAM COMPRE, V0, PP184, DOI 10.1145/3387904.3389268
   Li Y, 2019, P ACM PROGRAM LANG, V3, P0, DOI 10.1145/3360588
   Linstead E, 2009, DATA MIN KNOWL DISC, V18, P300, DOI 10.1007/s10618-008-0118-x
   Liu JK, 2019, M CONT JURISPRUD CHI, V0, PP29, DOI 10.1007/978-981-13-3756-7_2
   Liu Yinhan, 2019, ARXIV190711692, V0, P0
   Lu ML, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, V0, P0
   Lv F, 2015, IEEE INT CONF AUTOM, V0, PP260, DOI 10.1109/ASE.2015.42
   McMillan C, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), V0, PP111, DOI 10.1145/1985793.1985809
   Mnih V, 2016, PR MACH LEARN RES, V48, P0
   Nie LM, 2016, IEEE T SERV COMPUT, V9, P771, DOI 10.1109/TSC.2016.2560165
   Sachdev S, 2018, MAPL18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, V0, PP31, DOI 10.1145/3211346.3211353
   Sutton RS, 1998, INTRO REINFORCEMENT, V135, P0
   Vaswani A, 2017, ARXIV, V30, P5998
   Wan Y, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), V0, PP13, DOI 10.1109/ASE.2019.00012
   Wang WH, 2020, ACM T SOFTW ENG METH, V29, P0, DOI 10.1145/3409331
   Wei B, 2019, ARXIV, V0, P0
   Yao ZY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2203, DOI 10.1145/3308558.3313632
   Ye W, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), V0, PP2309, DOI 10.1145/3366423.3380295
   Zhang J, 2019, PROC INT CONF SOFTW, V0, PP783, DOI 10.1109/ICSE.2019.00086
   Zhu QH, 2020, IEEE INT CONF AUTOM, V0, PP883, DOI 10.1145/3324884.3416530
NR 34
TC 5
Z9 8
U1 4
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD JAN 15
PY 2022
VL 145
IS 
BP 22
EP 32
DI 10.1016/j.neunet.2021.09.025
EA OCT 2021
PG 11
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA WN9MT
UT WOS:000712090100003
PM 34710788
DA 2023-11-10
ER

PT J
AU Kumar, K
AF Kumar, Krishan
TI DEAF-BSL: Deep lEArning Framework for British Sign Language recognition
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING
LA English
DT Article
DE 3D CNN; disability; ASL; hand gestures; finger-spelling; BSL corpus
ID hand gesture recognition
AB The recent development of disability studies in academic bodies has expedited the promotion of investigation on disability. With computer-aided tools, communication between the impaired person and someone who does not understand sign language could be accessible. A large number of people across the world are using sign language (e.g., British Sign Language (BSL), Asian Sign Language (ASL), Indian Sign Language (ISL), etc.) with hand gestures for communication. In BSL recognition, the involvement of both hands overlapping each other becomes the main challenge. Moreover, BSL comprises ambiguous signs concerning viewpoint. However, existing traditional techniques seem in-stable, less accurate, and inefficient. In this work, the BSL fingerspelling alphabet recognition problem explores using a Deep learning framework to address the above-mentioned concerns. Convolutional Neural Network (CNN) is employed to detect and recognize for classification of 26 alphabets after being trained on the BSL corpus dataset. The proposed work outperforms the existing works with better precision (6%), recall (4%), and F-measure ((5) over tilde%). It reported better results on the BSL corpus dataset and webcam videos. The model achieved better accuracy (98.0%) for a large lexicon of words than previous models (Goh & Holden [6]: 69.5%, Rambhau [9]: 79.2%, and Liwicki et al. [8]: 92.5%). The 3D CNN-based proposal performs robust hand detection, much more accurate sign recognition, more scalability, and less ambiguity in BSL finger-spelling recognition.
C1 [Kumar, Krishan] NIT Uttarakhand, Dept Comp Sci & Engn, Srinagar 246174, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Uttarakhand
RP Kumar, K (通讯作者)，NIT Uttarakhand, Dept Comp Sci & Engn, Srinagar 246174, Uttarakhand, India.
EM kkberwal@nituk.ac.in
CR [Anonymous], 2008, P 19 BRIT MACHINE VI, V0, P0
   Bowden R, 2004, LECT NOTES COMPUT SC, V3021, P390
   Feng B, 2017, IEEE T HUM-MACH SYST, V47, P511, DOI 10.1109/THMS.2016.2616278
   FERIS R, 2004, COMP VIS PATT REC WO, V0, PP155, DOI 10.1109/TSMCA.2004.824852
   GOH P, 2005, THESIS U W AUSTR, V0, P0
   Goh P, 2006, IEEE IMAGE PROC, V0, PP2741, DOI 10.1109/ICIP.2006.313114
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Isaacs J, 2004, SE SYM SYS THRY, V0, P132
   Jang Y, 2017, IEEE T HUM-MACH SYST, V47, P113, DOI 10.1109/THMS.2016.2611824
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kyle J, 1981, SPEC EDUC FORWARD TRENDS, V8, P19
   Le Cun Yann, 1989, ADV NEURAL INFORM PR, V0, P141
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Liang H, 2014, IEEE T MULTIMEDIA, V16, P1241, DOI 10.1109/TMM.2014.2306177
   Liwicki Stephan, 2009, 2009 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPR WORKSHOPS), V0, PP50, DOI 10.1109/CVPR.2009.5204291
   Lu ZY, 2014, IEEE T HUM-MACH SYST, V44, P293, DOI 10.1109/THMS.2014.2302794
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Rambhau Pingale Prerna, 2013, INT J SCI RES PUBLIC, V3, P10
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Shanableh T, 2007, IEEE T SYST MAN CY B, V37, P641, DOI 10.1109/TSMCB.2006.889630
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang LC, 2014, IEEE T MULTIMEDIA, V16, P751, DOI 10.1109/TMM.2014.2298382
   Woll Bencie, 1987, LANGUAGE COMMUNICATI, V0, P11
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
NR 27
TC 4
Z9 4
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2375-4699
EI 2375-4702
J9 ACM T ASIAN LOW-RESO
JI ACM Trans. Asian Low-Resour. Lang. Inf. Process.
PD SEP 15
PY 2022
VL 21
IS 5
BP 
EP 
DI 10.1145/3513004
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 9Z2DN
UT WOS:000950956700017
DA 2023-11-10
ER

PT J
AU Chu, CH
   Oliveira, V
   Virgo, FG
   Otani, M
   Garcia, N
   Nakashima, Y
AF Chu, Chenhui
   Oliveira, Vinicius
   Virgo, Felix Giovanni
   Otani, Mayu
   Garcia, Noa
   Nakashima, Yuta
TI The semantic typology of visually grounded paraphrases
SO COMPUTER VISION AND IMAGE UNDERSTANDING
LA English
DT Article
DE Vision and language; Image interpretation; Visual grounded paraphrases; Semantic typology; Dataset
AB Visually grounded paraphrases (VGPs) are different phrasal expressions describing the same visual concept in an image. Previous studies treat VGP identification as a binary classification task, which ignores various phenomena behind VGPs (i.e., different linguistic interpretation of the same visual concept) such as linguistic paraphrases and VGPs from different aspects. In this paper, we propose semantic typology for VGPs, aiming to elucidate the VGP phenomena and deepen the understanding about how human beings interpret vision with language. We construct a large VGP dataset that annotates the class to which each VGP pair belongs according to our typology. In addition, we present a classification model that fuses language and visual features for VGP classification on our dataset. Experiments indicate that joint language and vision representation learning is important for VGP classification. We further demonstrate that our VGP typology can boost the performance of visually grounded textual entailment.
C1 [Chu, Chenhui; Virgo, Felix Giovanni] Kyoto Univ, Sakyo Ku, Yoshida Honmachi, Kyoto 6068501, Japan.
   [Oliveira, Vinicius] Ecole Polytech, Route Saclay, F-91120 Palaiseau, France.
   [Otani, Mayu] CyberAgent Inc, Shibuya Ku, 40-1 Abema Towers,Udagawacho, Tokyo 1500042, Japan.
   [Garcia, Noa; Nakashima, Yuta] Osaka Univ, 1-1 Yamadaoka, Suita, Osaka 5650871, Japan.
C3 Kyoto University; Institut Polytechnique de Paris; Osaka University
RP Chu, CH (通讯作者)，Kyoto Univ, Sakyo Ku, Yoshida Honmachi, Kyoto 6068501, Japan.
EM chu@i.kyoto-u.ac.jp
FU ACT-I, JST; JSPS KAKENHI [18H03264]; Grants-in-Aid for Scientific Research [18H03264] Funding Source: KAKEN
CR Aafaq N, 2020, ACM COMPUT SURV, V52, P0, DOI 10.1145/3355390
   Androutsopoulos I, 2010, J ARTIF INTELL RES, V38, P135, DOI 10.1613/jair.2985
   [Anonymous], 2006, P HUMAN LANGUAGE TEC, V0, P0
   [Anonymous], 2013, P EMNLP C, V0, P0
   [Anonymous], 2013, P 2013 C N AM CHAPT, V0, P0
   Baker CF, 1998, 36 ANN M ASS COMPUTA, V0, PP86, DOI 10.3115/980845.980860
   Benikova D, 2017, P RANLP 2017, V0, P0, DOI DOI 10.26615/978-954-452-049-6_014
   Berant J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1415, DOI 10.3115/v1/p14-1133
   Bhagat R, 2013, COMPUT LINGUIST, V39, P463, DOI 10.1162/COLI_a_00166
   Callison-Burch C, 2006, P MAIN C HUMAN LANGU, V0, P17
   Chen K, 2017, IEEE I CONF COMP VIS, V0, PP824, DOI 10.1109/ICCV.2017.95
   Chu C, 2018, P 27 INT C COMP LING, V0, P3479
   Chu CH, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, V0, P644
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2018, ARXIV, V1, P4171
   Dolan B, 2004, P 20 INT C COMP LING, V0, P0, DOI DOI 10.3115/1220355.1220406
   Dong WJ, 2021, IEEE ACCESS, V9, P349, DOI 10.1109/ACCESS.2020.3046719
   Faruqui Manaal, 2015, P 2015 C N AM CHAPT, V0, PP1606, DOI 10.3115/v1/N15-1184
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Fukui Akira, 2016, ARXIV160601847, V0, PP457, DOI 10.18653/V1/D16-1044
   Goodman S, 2016, UNDERSTANDING IMAGE, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hodosh M, 2014, P TACL, V7, P67, DOI 10.1162/tacl_a_00166
   Hossain MZ, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3295748
   King DB, 2015, ACS SYM SER, V1214, P1
   Kovatchev V, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), V0, P1384
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Liu Dacheng, 2019, IEEE T PATTERN ANAL, V0, P0
   Lu JS, 2019, ADV NEUR IN, V32, P0
   MacCartney B, 2009, THESIS STANFORD U ST, V0, P0
   Mikolov T, 2013, ARXIV13013781 CS, V0, P0, DOI DOI 10.48550/ARXIV.1301.3781
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Otani M, 2019, P ICCV 2019 MDALC WO, V0, P0
   Otani M, 2020, NEUROCOMPUTING, V404, P165, DOI 10.1016/j.neucom.2020.04.066
   Pavlick E, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1512
   Plummer BA, 2017, IEEE I CONF COMP VIS, V0, PP1946, DOI 10.1109/ICCV.2017.213
   Plummer BA, 2015, IEEE I CONF COMP VIS, V0, PP2641, DOI 10.1109/ICCV.2015.303
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Richang Hong, 2015, IEEE TRANSACTIONS ON BIG DATA, V1, P152, DOI 10.1109/TBDATA.2016.2515640
   Riezler Stefan, 2007, P 45 ANN M ASS COMPU, V0, P464
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Samaran J, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P81
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Simonyan K, 2015, ARXIV, V0, P0
   Vila M, 2014, OPEN J MODERN LINGUI, V4, P205, DOI 10.4236/OJML.2014.41016
   Vila M, 2015, LANG RESOUR EVAL, V49, P77, DOI 10.1007/s10579-014-9272-5
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Vu HT, 2018, P 27 INT C COMPUTATI, V0, P2354
   Wang L, 2016, PROC CVPR IEEE, V0, PP5005, DOI 10.1109/CVPR.2016.541
   Wang MZ, 2016, LECT NOTES COMPUT SC, V9912, P696, DOI 10.1007/978-3-319-46484-8_42
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xiujun I, 2020, ECCV, V0, P0
   Yang Shuai, 2020, ECCV, V0, P0
   Yeh RA, 2017, ADV NEURAL INFORM PR, V0, P1909
   Yu Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1114
   Zhengyuan Yang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP387, DOI 10.1007/978-3-030-58568-6_23
NR 56
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1077-3142
EI 1090-235X
J9 COMPUT VIS IMAGE UND
JI Comput. Vis. Image Underst.
PD JAN 15
PY 2022
VL 215
IS 
BP 
EP 
DI 10.1016/j.cviu.2021.103333
EA DEC 2021
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA XX4OD
UT WOS:000736276200001
DA 2023-11-10
ER

